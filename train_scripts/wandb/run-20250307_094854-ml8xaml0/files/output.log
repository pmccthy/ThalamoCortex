2025-03-07 09:49:16,147 - INFO - Running hyperparameter combination 1 of 1
2025-03-07 09:49:16,147 - INFO - 0_CTCNet_TC_multi_post_activation_reciprocal
2025-03-07 09:49:16,148 - INFO - Loading data...
2025-03-07 09:49:17,647 - INFO - Done loading.
2025-03-07 09:49:17,648 - INFO - Building model and optimiser...
2025-03-07 09:49:17,674 - INFO - =================================================================
Layer (type:depth-idx)                   Param #
=================================================================
├─Sequential: 1-1                        --
|    └─Linear: 2-1                       32,832
|    └─ReLU: 2-2                         --
├─Linear: 1-2                            16,640
├─Linear: 1-3                            16,640
├─Sequential: 1-4                        --
|    └─Linear: 2-3                       401,664
|    └─ReLU: 2-4                         --
├─Sequential: 1-5                        --
|    └─Linear: 2-5                       65,792
|    └─ReLU: 2-6                         --
├─Sequential: 1-6                        --
|    └─Linear: 2-7                       2,570
=================================================================
Total params: 536,138
Trainable params: 536,138
Non-trainable params: 0
=================================================================
2025-03-07 09:49:17,676 - INFO - Done.
2025-03-07 09:49:17,677 - INFO - Training...
2025-03-07 09:49:17,677 - INFO - Beginning epoch 1/800
2025-03-07 09:49:17,808 - INFO - training batch 1, loss: 2.302, 32/28000 datapoints
2025-03-07 09:49:18,197 - INFO - training batch 51, loss: 2.304, 1632/28000 datapoints
2025-03-07 09:49:18,577 - INFO - training batch 101, loss: 2.307, 3232/28000 datapoints
2025-03-07 09:49:19,115 - INFO - training batch 151, loss: 2.302, 4832/28000 datapoints
2025-03-07 09:49:20,080 - INFO - training batch 201, loss: 2.290, 6432/28000 datapoints
2025-03-07 09:49:21,864 - INFO - training batch 251, loss: 2.307, 8032/28000 datapoints
2025-03-07 09:49:22,419 - INFO - training batch 301, loss: 2.298, 9632/28000 datapoints
2025-03-07 09:49:22,777 - INFO - training batch 351, loss: 2.303, 11232/28000 datapoints
2025-03-07 09:49:23,151 - INFO - training batch 401, loss: 2.299, 12832/28000 datapoints
2025-03-07 09:49:23,577 - INFO - training batch 451, loss: 2.307, 14432/28000 datapoints
2025-03-07 09:49:24,113 - INFO - training batch 501, loss: 2.301, 16032/28000 datapoints
2025-03-07 09:49:24,734 - INFO - training batch 551, loss: 2.312, 17632/28000 datapoints
2025-03-07 09:49:25,509 - INFO - training batch 601, loss: 2.292, 19232/28000 datapoints
2025-03-07 09:49:26,086 - INFO - training batch 651, loss: 2.308, 20832/28000 datapoints
2025-03-07 09:49:26,441 - INFO - training batch 701, loss: 2.296, 22432/28000 datapoints
2025-03-07 09:49:26,900 - INFO - training batch 751, loss: 2.305, 24032/28000 datapoints
2025-03-07 09:49:27,310 - INFO - training batch 801, loss: 2.294, 25632/28000 datapoints
2025-03-07 09:49:27,728 - INFO - training batch 851, loss: 2.302, 27232/28000 datapoints
2025-03-07 09:49:28,073 - INFO - validation batch 1, loss: 2.295, 32/6976 datapoints
2025-03-07 09:49:28,532 - INFO - validation batch 51, loss: 2.306, 1632/6976 datapoints
2025-03-07 09:49:28,779 - INFO - validation batch 101, loss: 2.307, 3232/6976 datapoints
2025-03-07 09:49:30,063 - INFO - validation batch 151, loss: 2.308, 4832/6976 datapoints
2025-03-07 09:49:30,947 - INFO - validation batch 201, loss: 2.312, 6432/6976 datapoints
2025-03-07 09:49:31,625 - INFO - Epoch 1/800 done.
2025-03-07 09:49:31,626 - INFO - Final validation performance:
Loss: 2.306, top-1 acc: 0.101top-5 acc: 0.101
2025-03-07 09:49:31,629 - INFO - Beginning epoch 2/800
2025-03-07 09:49:32,279 - INFO - training batch 1, loss: 2.302, 32/28000 datapoints
2025-03-07 09:49:41,993 - INFO - training batch 51, loss: 2.304, 1632/28000 datapoints
2025-03-07 09:49:42,411 - INFO - training batch 101, loss: 2.306, 3232/28000 datapoints
2025-03-07 09:49:42,976 - INFO - training batch 151, loss: 2.302, 4832/28000 datapoints
2025-03-07 09:49:43,393 - INFO - training batch 201, loss: 2.290, 6432/28000 datapoints
2025-03-07 09:49:43,794 - INFO - training batch 251, loss: 2.306, 8032/28000 datapoints
2025-03-07 09:49:44,313 - INFO - training batch 301, loss: 2.298, 9632/28000 datapoints
2025-03-07 09:49:44,740 - INFO - training batch 351, loss: 2.302, 11232/28000 datapoints
2025-03-07 09:49:45,402 - INFO - training batch 401, loss: 2.299, 12832/28000 datapoints
2025-03-07 09:49:46,677 - INFO - training batch 451, loss: 2.307, 14432/28000 datapoints
2025-03-07 09:49:47,063 - INFO - training batch 501, loss: 2.300, 16032/28000 datapoints
2025-03-07 09:49:47,863 - INFO - training batch 551, loss: 2.311, 17632/28000 datapoints
2025-03-07 09:49:48,599 - INFO - training batch 601, loss: 2.292, 19232/28000 datapoints
2025-03-07 09:49:49,879 - INFO - training batch 651, loss: 2.306, 20832/28000 datapoints
2025-03-07 09:49:51,596 - INFO - training batch 701, loss: 2.295, 22432/28000 datapoints
2025-03-07 09:49:52,051 - INFO - training batch 751, loss: 2.304, 24032/28000 datapoints
2025-03-07 09:49:52,498 - INFO - training batch 801, loss: 2.293, 25632/28000 datapoints
2025-03-07 09:49:53,018 - INFO - training batch 851, loss: 2.300, 27232/28000 datapoints
2025-03-07 09:49:53,265 - INFO - validation batch 1, loss: 2.294, 32/6976 datapoints
2025-03-07 09:49:53,473 - INFO - validation batch 51, loss: 2.305, 1632/6976 datapoints
2025-03-07 09:49:53,671 - INFO - validation batch 101, loss: 2.305, 3232/6976 datapoints
2025-03-07 09:49:54,061 - INFO - validation batch 151, loss: 2.307, 4832/6976 datapoints
2025-03-07 09:49:54,492 - INFO - validation batch 201, loss: 2.310, 6432/6976 datapoints
2025-03-07 09:49:54,622 - INFO - Epoch 2/800 done.
2025-03-07 09:49:54,624 - INFO - Final validation performance:
Loss: 2.304, top-1 acc: 0.101top-5 acc: 0.101
2025-03-07 09:49:54,630 - INFO - Beginning epoch 3/800
2025-03-07 09:49:54,672 - INFO - training batch 1, loss: 2.301, 32/28000 datapoints
2025-03-07 09:49:55,466 - INFO - training batch 51, loss: 2.303, 1632/28000 datapoints
2025-03-07 09:49:56,269 - INFO - training batch 101, loss: 2.303, 3232/28000 datapoints
2025-03-07 09:49:56,887 - INFO - training batch 151, loss: 2.300, 4832/28000 datapoints
2025-03-07 09:49:57,263 - INFO - training batch 201, loss: 2.287, 6432/28000 datapoints
2025-03-07 09:49:57,647 - INFO - training batch 251, loss: 2.304, 8032/28000 datapoints
2025-03-07 09:49:58,065 - INFO - training batch 301, loss: 2.295, 9632/28000 datapoints
2025-03-07 09:49:58,431 - INFO - training batch 351, loss: 2.297, 11232/28000 datapoints
2025-03-07 09:49:58,845 - INFO - training batch 401, loss: 2.293, 12832/28000 datapoints
2025-03-07 09:49:59,331 - INFO - training batch 451, loss: 2.301, 14432/28000 datapoints
2025-03-07 09:49:59,804 - INFO - training batch 501, loss: 2.288, 16032/28000 datapoints
2025-03-07 09:50:00,325 - INFO - training batch 551, loss: 2.302, 17632/28000 datapoints
2025-03-07 09:50:01,015 - INFO - training batch 601, loss: 2.280, 19232/28000 datapoints
2025-03-07 09:50:01,430 - INFO - training batch 651, loss: 2.284, 20832/28000 datapoints
2025-03-07 09:50:01,787 - INFO - training batch 701, loss: 2.261, 22432/28000 datapoints
2025-03-07 09:50:02,152 - INFO - training batch 751, loss: 2.266, 24032/28000 datapoints
2025-03-07 09:50:02,557 - INFO - training batch 801, loss: 2.264, 25632/28000 datapoints
2025-03-07 09:50:02,955 - INFO - training batch 851, loss: 2.221, 27232/28000 datapoints
2025-03-07 09:50:03,141 - INFO - validation batch 1, loss: 2.221, 32/6976 datapoints
2025-03-07 09:50:03,256 - INFO - validation batch 51, loss: 2.257, 1632/6976 datapoints
2025-03-07 09:50:03,368 - INFO - validation batch 101, loss: 2.228, 3232/6976 datapoints
2025-03-07 09:50:03,477 - INFO - validation batch 151, loss: 2.267, 4832/6976 datapoints
2025-03-07 09:50:03,589 - INFO - validation batch 201, loss: 2.247, 6432/6976 datapoints
2025-03-07 09:50:03,628 - INFO - Epoch 3/800 done.
2025-03-07 09:50:03,628 - INFO - Final validation performance:
Loss: 2.244, top-1 acc: 0.214top-5 acc: 0.214
2025-03-07 09:50:03,629 - INFO - Beginning epoch 4/800
2025-03-07 09:50:03,639 - INFO - training batch 1, loss: 2.277, 32/28000 datapoints
2025-03-07 09:50:04,086 - INFO - training batch 51, loss: 2.283, 1632/28000 datapoints
2025-03-07 09:50:04,464 - INFO - training batch 101, loss: 2.206, 3232/28000 datapoints
2025-03-07 09:50:04,834 - INFO - training batch 151, loss: 2.245, 4832/28000 datapoints
2025-03-07 09:50:05,184 - INFO - training batch 201, loss: 2.140, 6432/28000 datapoints
2025-03-07 09:50:05,545 - INFO - training batch 251, loss: 2.281, 8032/28000 datapoints
2025-03-07 09:50:05,979 - INFO - training batch 301, loss: 2.136, 9632/28000 datapoints
2025-03-07 09:50:06,355 - INFO - training batch 351, loss: 2.112, 11232/28000 datapoints
2025-03-07 09:50:06,732 - INFO - training batch 401, loss: 2.055, 12832/28000 datapoints
2025-03-07 09:50:07,068 - INFO - training batch 451, loss: 2.081, 14432/28000 datapoints
2025-03-07 09:50:07,441 - INFO - training batch 501, loss: 1.841, 16032/28000 datapoints
2025-03-07 09:50:07,806 - INFO - training batch 551, loss: 2.022, 17632/28000 datapoints
2025-03-07 09:50:08,180 - INFO - training batch 601, loss: 1.877, 19232/28000 datapoints
2025-03-07 09:50:08,555 - INFO - training batch 651, loss: 1.894, 20832/28000 datapoints
2025-03-07 09:50:09,083 - INFO - training batch 701, loss: 1.746, 22432/28000 datapoints
2025-03-07 09:50:09,453 - INFO - training batch 751, loss: 1.906, 24032/28000 datapoints
2025-03-07 09:50:09,964 - INFO - training batch 801, loss: 1.822, 25632/28000 datapoints
2025-03-07 09:50:10,332 - INFO - training batch 851, loss: 1.760, 27232/28000 datapoints
2025-03-07 09:50:10,520 - INFO - validation batch 1, loss: 1.701, 32/6976 datapoints
2025-03-07 09:50:10,626 - INFO - validation batch 51, loss: 2.049, 1632/6976 datapoints
2025-03-07 09:50:10,736 - INFO - validation batch 101, loss: 1.820, 3232/6976 datapoints
2025-03-07 09:50:10,836 - INFO - validation batch 151, loss: 2.103, 4832/6976 datapoints
2025-03-07 09:50:10,938 - INFO - validation batch 201, loss: 1.618, 6432/6976 datapoints
2025-03-07 09:50:10,976 - INFO - Epoch 4/800 done.
2025-03-07 09:50:10,977 - INFO - Final validation performance:
Loss: 1.858, top-1 acc: 0.409top-5 acc: 0.409
2025-03-07 09:50:10,978 - INFO - Beginning epoch 5/800
2025-03-07 09:50:10,988 - INFO - training batch 1, loss: 2.023, 32/28000 datapoints
2025-03-07 09:50:11,376 - INFO - training batch 51, loss: 2.031, 1632/28000 datapoints
2025-03-07 09:50:11,756 - INFO - training batch 101, loss: 1.693, 3232/28000 datapoints
2025-03-07 09:50:12,145 - INFO - training batch 151, loss: 1.961, 4832/28000 datapoints
2025-03-07 09:50:12,533 - INFO - training batch 201, loss: 1.946, 6432/28000 datapoints
2025-03-07 09:50:12,907 - INFO - training batch 251, loss: 1.964, 8032/28000 datapoints
2025-03-07 09:50:13,283 - INFO - training batch 301, loss: 1.866, 9632/28000 datapoints
2025-03-07 09:50:13,668 - INFO - training batch 351, loss: 1.931, 11232/28000 datapoints
2025-03-07 09:50:14,053 - INFO - training batch 401, loss: 1.767, 12832/28000 datapoints
2025-03-07 09:50:14,432 - INFO - training batch 451, loss: 1.752, 14432/28000 datapoints
2025-03-07 09:50:14,819 - INFO - training batch 501, loss: 1.383, 16032/28000 datapoints
2025-03-07 09:50:15,186 - INFO - training batch 551, loss: 1.733, 17632/28000 datapoints
2025-03-07 09:50:15,561 - INFO - training batch 601, loss: 1.588, 19232/28000 datapoints
2025-03-07 09:50:15,929 - INFO - training batch 651, loss: 1.565, 20832/28000 datapoints
2025-03-07 09:50:16,258 - INFO - training batch 701, loss: 1.451, 22432/28000 datapoints
2025-03-07 09:50:16,605 - INFO - training batch 751, loss: 1.761, 24032/28000 datapoints
2025-03-07 09:50:16,945 - INFO - training batch 801, loss: 1.564, 25632/28000 datapoints
2025-03-07 09:50:17,271 - INFO - training batch 851, loss: 1.589, 27232/28000 datapoints
2025-03-07 09:50:17,437 - INFO - validation batch 1, loss: 1.429, 32/6976 datapoints
2025-03-07 09:50:17,529 - INFO - validation batch 51, loss: 2.040, 1632/6976 datapoints
2025-03-07 09:50:17,618 - INFO - validation batch 101, loss: 1.654, 3232/6976 datapoints
2025-03-07 09:50:17,717 - INFO - validation batch 151, loss: 2.058, 4832/6976 datapoints
2025-03-07 09:50:17,809 - INFO - validation batch 201, loss: 1.349, 6432/6976 datapoints
2025-03-07 09:50:17,847 - INFO - Epoch 5/800 done.
2025-03-07 09:50:17,848 - INFO - Final validation performance:
Loss: 1.706, top-1 acc: 0.431top-5 acc: 0.431
2025-03-07 09:50:17,850 - INFO - Beginning epoch 6/800
2025-03-07 09:50:17,861 - INFO - training batch 1, loss: 1.962, 32/28000 datapoints
2025-03-07 09:50:18,201 - INFO - training batch 51, loss: 1.948, 1632/28000 datapoints
2025-03-07 09:50:18,546 - INFO - training batch 101, loss: 1.497, 3232/28000 datapoints
2025-03-07 09:50:18,890 - INFO - training batch 151, loss: 1.890, 4832/28000 datapoints
2025-03-07 09:50:19,209 - INFO - training batch 201, loss: 1.939, 6432/28000 datapoints
2025-03-07 09:50:19,525 - INFO - training batch 251, loss: 1.858, 8032/28000 datapoints
2025-03-07 09:50:19,846 - INFO - training batch 301, loss: 1.808, 9632/28000 datapoints
2025-03-07 09:50:20,197 - INFO - training batch 351, loss: 1.849, 11232/28000 datapoints
2025-03-07 09:50:20,519 - INFO - training batch 401, loss: 1.709, 12832/28000 datapoints
2025-03-07 09:50:20,851 - INFO - training batch 451, loss: 1.646, 14432/28000 datapoints
2025-03-07 09:50:21,189 - INFO - training batch 501, loss: 1.278, 16032/28000 datapoints
2025-03-07 09:50:21,537 - INFO - training batch 551, loss: 1.658, 17632/28000 datapoints
2025-03-07 09:50:22,041 - INFO - training batch 601, loss: 1.535, 19232/28000 datapoints
2025-03-07 09:50:23,377 - INFO - training batch 651, loss: 1.449, 20832/28000 datapoints
2025-03-07 09:50:23,827 - INFO - training batch 701, loss: 1.369, 22432/28000 datapoints
2025-03-07 09:50:24,900 - INFO - training batch 751, loss: 1.724, 24032/28000 datapoints
2025-03-07 09:50:25,234 - INFO - training batch 801, loss: 1.485, 25632/28000 datapoints
2025-03-07 09:50:25,688 - INFO - training batch 851, loss: 1.529, 27232/28000 datapoints
2025-03-07 09:50:25,905 - INFO - validation batch 1, loss: 1.336, 32/6976 datapoints
2025-03-07 09:50:25,996 - INFO - validation batch 51, loss: 2.022, 1632/6976 datapoints
2025-03-07 09:50:26,081 - INFO - validation batch 101, loss: 1.601, 3232/6976 datapoints
2025-03-07 09:50:26,187 - INFO - validation batch 151, loss: 2.041, 4832/6976 datapoints
2025-03-07 09:50:26,301 - INFO - validation batch 201, loss: 1.262, 6432/6976 datapoints
2025-03-07 09:50:26,332 - INFO - Epoch 6/800 done.
2025-03-07 09:50:26,332 - INFO - Final validation performance:
Loss: 1.652, top-1 acc: 0.443top-5 acc: 0.443
2025-03-07 09:50:26,335 - INFO - Beginning epoch 7/800
2025-03-07 09:50:26,345 - INFO - training batch 1, loss: 1.940, 32/28000 datapoints
2025-03-07 09:50:26,783 - INFO - training batch 51, loss: 1.911, 1632/28000 datapoints
2025-03-07 09:50:27,144 - INFO - training batch 101, loss: 1.423, 3232/28000 datapoints
2025-03-07 09:50:27,512 - INFO - training batch 151, loss: 1.868, 4832/28000 datapoints
2025-03-07 09:50:27,856 - INFO - training batch 201, loss: 1.912, 6432/28000 datapoints
2025-03-07 09:50:28,189 - INFO - training batch 251, loss: 1.792, 8032/28000 datapoints
2025-03-07 09:50:28,530 - INFO - training batch 301, loss: 1.779, 9632/28000 datapoints
2025-03-07 09:50:28,865 - INFO - training batch 351, loss: 1.788, 11232/28000 datapoints
2025-03-07 09:50:29,268 - INFO - training batch 401, loss: 1.678, 12832/28000 datapoints
2025-03-07 09:50:29,603 - INFO - training batch 451, loss: 1.592, 14432/28000 datapoints
2025-03-07 09:50:29,939 - INFO - training batch 501, loss: 1.242, 16032/28000 datapoints
2025-03-07 09:50:30,268 - INFO - training batch 551, loss: 1.613, 17632/28000 datapoints
2025-03-07 09:50:30,598 - INFO - training batch 601, loss: 1.519, 19232/28000 datapoints
2025-03-07 09:50:30,939 - INFO - training batch 651, loss: 1.380, 20832/28000 datapoints
2025-03-07 09:50:31,289 - INFO - training batch 701, loss: 1.328, 22432/28000 datapoints
2025-03-07 09:50:31,631 - INFO - training batch 751, loss: 1.699, 24032/28000 datapoints
2025-03-07 09:50:31,962 - INFO - training batch 801, loss: 1.441, 25632/28000 datapoints
2025-03-07 09:50:32,292 - INFO - training batch 851, loss: 1.490, 27232/28000 datapoints
2025-03-07 09:50:32,463 - INFO - validation batch 1, loss: 1.284, 32/6976 datapoints
2025-03-07 09:50:32,583 - INFO - validation batch 51, loss: 1.997, 1632/6976 datapoints
2025-03-07 09:50:32,676 - INFO - validation batch 101, loss: 1.569, 3232/6976 datapoints
2025-03-07 09:50:32,771 - INFO - validation batch 151, loss: 2.017, 4832/6976 datapoints
2025-03-07 09:50:32,866 - INFO - validation batch 201, loss: 1.209, 6432/6976 datapoints
2025-03-07 09:50:32,902 - INFO - Epoch 7/800 done.
2025-03-07 09:50:32,902 - INFO - Final validation performance:
Loss: 1.615, top-1 acc: 0.453top-5 acc: 0.453
2025-03-07 09:50:32,904 - INFO - Beginning epoch 8/800
2025-03-07 09:50:32,915 - INFO - training batch 1, loss: 1.913, 32/28000 datapoints
2025-03-07 09:50:33,265 - INFO - training batch 51, loss: 1.878, 1632/28000 datapoints
2025-03-07 09:50:33,682 - INFO - training batch 101, loss: 1.378, 3232/28000 datapoints
2025-03-07 09:50:34,194 - INFO - training batch 151, loss: 1.849, 4832/28000 datapoints
2025-03-07 09:50:35,024 - INFO - training batch 201, loss: 1.881, 6432/28000 datapoints
2025-03-07 09:50:41,685 - INFO - training batch 251, loss: 1.736, 8032/28000 datapoints
2025-03-07 09:50:43,027 - INFO - training batch 301, loss: 1.755, 9632/28000 datapoints
2025-03-07 09:50:44,273 - INFO - training batch 351, loss: 1.737, 11232/28000 datapoints
2025-03-07 09:50:48,114 - INFO - training batch 401, loss: 1.651, 12832/28000 datapoints
2025-03-07 09:50:49,305 - INFO - training batch 451, loss: 1.556, 14432/28000 datapoints
2025-03-07 09:50:49,756 - INFO - training batch 501, loss: 1.223, 16032/28000 datapoints
2025-03-07 09:50:50,275 - INFO - training batch 551, loss: 1.578, 17632/28000 datapoints
2025-03-07 09:50:50,913 - INFO - training batch 601, loss: 1.510, 19232/28000 datapoints
2025-03-07 09:50:51,638 - INFO - training batch 651, loss: 1.328, 20832/28000 datapoints
2025-03-07 09:50:52,128 - INFO - training batch 701, loss: 1.302, 22432/28000 datapoints
2025-03-07 09:50:52,696 - INFO - training batch 751, loss: 1.680, 24032/28000 datapoints
2025-03-07 09:50:53,130 - INFO - training batch 801, loss: 1.408, 25632/28000 datapoints
2025-03-07 09:50:53,551 - INFO - training batch 851, loss: 1.461, 27232/28000 datapoints
2025-03-07 09:50:53,768 - INFO - validation batch 1, loss: 1.247, 32/6976 datapoints
2025-03-07 09:50:53,894 - INFO - validation batch 51, loss: 1.972, 1632/6976 datapoints
2025-03-07 09:50:54,056 - INFO - validation batch 101, loss: 1.544, 3232/6976 datapoints
2025-03-07 09:50:54,228 - INFO - validation batch 151, loss: 1.987, 4832/6976 datapoints
2025-03-07 09:50:54,394 - INFO - validation batch 201, loss: 1.169, 6432/6976 datapoints
2025-03-07 09:50:54,455 - INFO - Epoch 8/800 done.
2025-03-07 09:50:54,456 - INFO - Final validation performance:
Loss: 1.584, top-1 acc: 0.460top-5 acc: 0.460
2025-03-07 09:50:54,461 - INFO - Beginning epoch 9/800
2025-03-07 09:50:54,476 - INFO - training batch 1, loss: 1.884, 32/28000 datapoints
2025-03-07 09:50:55,074 - INFO - training batch 51, loss: 1.846, 1632/28000 datapoints
2025-03-07 09:50:55,664 - INFO - training batch 101, loss: 1.343, 3232/28000 datapoints
2025-03-07 09:50:56,201 - INFO - training batch 151, loss: 1.831, 4832/28000 datapoints
2025-03-07 09:50:56,622 - INFO - training batch 201, loss: 1.849, 6432/28000 datapoints
2025-03-07 09:50:57,208 - INFO - training batch 251, loss: 1.684, 8032/28000 datapoints
2025-03-07 09:50:57,937 - INFO - training batch 301, loss: 1.734, 9632/28000 datapoints
2025-03-07 09:50:58,704 - INFO - training batch 351, loss: 1.695, 11232/28000 datapoints
2025-03-07 09:50:59,146 - INFO - training batch 401, loss: 1.626, 12832/28000 datapoints
2025-03-07 09:50:59,495 - INFO - training batch 451, loss: 1.529, 14432/28000 datapoints
2025-03-07 09:50:59,864 - INFO - training batch 501, loss: 1.211, 16032/28000 datapoints
2025-03-07 09:51:00,220 - INFO - training batch 551, loss: 1.550, 17632/28000 datapoints
2025-03-07 09:51:00,633 - INFO - training batch 601, loss: 1.501, 19232/28000 datapoints
2025-03-07 09:51:01,073 - INFO - training batch 651, loss: 1.287, 20832/28000 datapoints
2025-03-07 09:51:01,408 - INFO - training batch 701, loss: 1.281, 22432/28000 datapoints
2025-03-07 09:51:01,768 - INFO - training batch 751, loss: 1.664, 24032/28000 datapoints
2025-03-07 09:51:02,260 - INFO - training batch 801, loss: 1.380, 25632/28000 datapoints
2025-03-07 09:51:02,592 - INFO - training batch 851, loss: 1.438, 27232/28000 datapoints
2025-03-07 09:51:02,784 - INFO - validation batch 1, loss: 1.214, 32/6976 datapoints
2025-03-07 09:51:02,886 - INFO - validation batch 51, loss: 1.947, 1632/6976 datapoints
2025-03-07 09:51:02,987 - INFO - validation batch 101, loss: 1.523, 3232/6976 datapoints
2025-03-07 09:51:03,100 - INFO - validation batch 151, loss: 1.958, 4832/6976 datapoints
2025-03-07 09:51:03,195 - INFO - validation batch 201, loss: 1.135, 6432/6976 datapoints
2025-03-07 09:51:03,237 - INFO - Epoch 9/800 done.
2025-03-07 09:51:03,237 - INFO - Final validation performance:
Loss: 1.556, top-1 acc: 0.465top-5 acc: 0.465
2025-03-07 09:51:03,239 - INFO - Beginning epoch 10/800
2025-03-07 09:51:03,250 - INFO - training batch 1, loss: 1.855, 32/28000 datapoints
2025-03-07 09:51:03,718 - INFO - training batch 51, loss: 1.816, 1632/28000 datapoints
2025-03-07 09:51:04,076 - INFO - training batch 101, loss: 1.314, 3232/28000 datapoints
2025-03-07 09:51:04,411 - INFO - training batch 151, loss: 1.812, 4832/28000 datapoints
2025-03-07 09:51:04,836 - INFO - training batch 201, loss: 1.820, 6432/28000 datapoints
2025-03-07 09:51:05,166 - INFO - training batch 251, loss: 1.635, 8032/28000 datapoints
2025-03-07 09:51:05,509 - INFO - training batch 301, loss: 1.714, 9632/28000 datapoints
2025-03-07 09:51:05,875 - INFO - training batch 351, loss: 1.661, 11232/28000 datapoints
2025-03-07 09:51:06,301 - INFO - training batch 401, loss: 1.603, 12832/28000 datapoints
2025-03-07 09:51:06,678 - INFO - training batch 451, loss: 1.508, 14432/28000 datapoints
2025-03-07 09:51:07,047 - INFO - training batch 501, loss: 1.203, 16032/28000 datapoints
2025-03-07 09:51:07,407 - INFO - training batch 551, loss: 1.527, 17632/28000 datapoints
2025-03-07 09:51:08,080 - INFO - training batch 601, loss: 1.493, 19232/28000 datapoints
2025-03-07 09:51:09,141 - INFO - training batch 651, loss: 1.251, 20832/28000 datapoints
2025-03-07 09:51:09,588 - INFO - training batch 701, loss: 1.264, 22432/28000 datapoints
2025-03-07 09:51:10,394 - INFO - training batch 751, loss: 1.649, 24032/28000 datapoints
2025-03-07 09:51:10,808 - INFO - training batch 801, loss: 1.354, 25632/28000 datapoints
2025-03-07 09:51:11,193 - INFO - training batch 851, loss: 1.418, 27232/28000 datapoints
2025-03-07 09:51:11,356 - INFO - validation batch 1, loss: 1.187, 32/6976 datapoints
2025-03-07 09:51:11,454 - INFO - validation batch 51, loss: 1.928, 1632/6976 datapoints
2025-03-07 09:51:11,549 - INFO - validation batch 101, loss: 1.506, 3232/6976 datapoints
2025-03-07 09:51:11,646 - INFO - validation batch 151, loss: 1.928, 4832/6976 datapoints
2025-03-07 09:51:11,787 - INFO - validation batch 201, loss: 1.105, 6432/6976 datapoints
2025-03-07 09:51:11,837 - INFO - Epoch 10/800 done.
2025-03-07 09:51:11,837 - INFO - Final validation performance:
Loss: 1.531, top-1 acc: 0.471top-5 acc: 0.471
2025-03-07 09:51:11,840 - INFO - Beginning epoch 11/800
2025-03-07 09:51:11,866 - INFO - training batch 1, loss: 1.826, 32/28000 datapoints
2025-03-07 09:51:12,292 - INFO - training batch 51, loss: 1.787, 1632/28000 datapoints
2025-03-07 09:51:12,610 - INFO - training batch 101, loss: 1.287, 3232/28000 datapoints
2025-03-07 09:51:12,994 - INFO - training batch 151, loss: 1.795, 4832/28000 datapoints
2025-03-07 09:51:13,327 - INFO - training batch 201, loss: 1.792, 6432/28000 datapoints
2025-03-07 09:51:13,699 - INFO - training batch 251, loss: 1.591, 8032/28000 datapoints
2025-03-07 09:51:14,078 - INFO - training batch 301, loss: 1.695, 9632/28000 datapoints
2025-03-07 09:51:14,461 - INFO - training batch 351, loss: 1.632, 11232/28000 datapoints
2025-03-07 09:51:14,837 - INFO - training batch 401, loss: 1.581, 12832/28000 datapoints
2025-03-07 09:51:15,170 - INFO - training batch 451, loss: 1.490, 14432/28000 datapoints
2025-03-07 09:51:15,598 - INFO - training batch 501, loss: 1.196, 16032/28000 datapoints
2025-03-07 09:51:15,954 - INFO - training batch 551, loss: 1.508, 17632/28000 datapoints
2025-03-07 09:51:16,313 - INFO - training batch 601, loss: 1.486, 19232/28000 datapoints
2025-03-07 09:51:16,618 - INFO - training batch 651, loss: 1.219, 20832/28000 datapoints
2025-03-07 09:51:17,040 - INFO - training batch 701, loss: 1.250, 22432/28000 datapoints
2025-03-07 09:51:17,388 - INFO - training batch 751, loss: 1.634, 24032/28000 datapoints
2025-03-07 09:51:17,687 - INFO - training batch 801, loss: 1.331, 25632/28000 datapoints
2025-03-07 09:51:18,032 - INFO - training batch 851, loss: 1.400, 27232/28000 datapoints
2025-03-07 09:51:18,186 - INFO - validation batch 1, loss: 1.162, 32/6976 datapoints
2025-03-07 09:51:18,291 - INFO - validation batch 51, loss: 1.911, 1632/6976 datapoints
2025-03-07 09:51:18,387 - INFO - validation batch 101, loss: 1.491, 3232/6976 datapoints
2025-03-07 09:51:18,491 - INFO - validation batch 151, loss: 1.898, 4832/6976 datapoints
2025-03-07 09:51:18,602 - INFO - validation batch 201, loss: 1.080, 6432/6976 datapoints
2025-03-07 09:51:18,646 - INFO - Epoch 11/800 done.
2025-03-07 09:51:18,646 - INFO - Final validation performance:
Loss: 1.508, top-1 acc: 0.476top-5 acc: 0.476
2025-03-07 09:51:18,648 - INFO - Beginning epoch 12/800
2025-03-07 09:51:18,662 - INFO - training batch 1, loss: 1.797, 32/28000 datapoints
2025-03-07 09:51:19,048 - INFO - training batch 51, loss: 1.759, 1632/28000 datapoints
2025-03-07 09:51:19,425 - INFO - training batch 101, loss: 1.263, 3232/28000 datapoints
2025-03-07 09:51:19,799 - INFO - training batch 151, loss: 1.779, 4832/28000 datapoints
2025-03-07 09:51:20,170 - INFO - training batch 201, loss: 1.767, 6432/28000 datapoints
2025-03-07 09:51:20,543 - INFO - training batch 251, loss: 1.548, 8032/28000 datapoints
2025-03-07 09:51:20,945 - INFO - training batch 301, loss: 1.676, 9632/28000 datapoints
2025-03-07 09:51:21,344 - INFO - training batch 351, loss: 1.606, 11232/28000 datapoints
2025-03-07 09:51:21,726 - INFO - training batch 401, loss: 1.560, 12832/28000 datapoints
2025-03-07 09:51:22,104 - INFO - training batch 451, loss: 1.475, 14432/28000 datapoints
2025-03-07 09:51:22,503 - INFO - training batch 501, loss: 1.191, 16032/28000 datapoints
2025-03-07 09:51:22,877 - INFO - training batch 551, loss: 1.492, 17632/28000 datapoints
2025-03-07 09:51:23,246 - INFO - training batch 601, loss: 1.479, 19232/28000 datapoints
2025-03-07 09:51:23,611 - INFO - training batch 651, loss: 1.190, 20832/28000 datapoints
2025-03-07 09:51:24,001 - INFO - training batch 701, loss: 1.238, 22432/28000 datapoints
2025-03-07 09:51:24,366 - INFO - training batch 751, loss: 1.620, 24032/28000 datapoints
2025-03-07 09:51:24,789 - INFO - training batch 801, loss: 1.309, 25632/28000 datapoints
2025-03-07 09:51:25,101 - INFO - training batch 851, loss: 1.384, 27232/28000 datapoints
2025-03-07 09:51:25,270 - INFO - validation batch 1, loss: 1.140, 32/6976 datapoints
2025-03-07 09:51:25,368 - INFO - validation batch 51, loss: 1.896, 1632/6976 datapoints
2025-03-07 09:51:25,471 - INFO - validation batch 101, loss: 1.477, 3232/6976 datapoints
2025-03-07 09:51:25,576 - INFO - validation batch 151, loss: 1.869, 4832/6976 datapoints
2025-03-07 09:51:25,676 - INFO - validation batch 201, loss: 1.057, 6432/6976 datapoints
2025-03-07 09:51:25,735 - INFO - Epoch 12/800 done.
2025-03-07 09:51:25,736 - INFO - Final validation performance:
Loss: 1.488, top-1 acc: 0.481top-5 acc: 0.481
2025-03-07 09:51:25,737 - INFO - Beginning epoch 13/800
2025-03-07 09:51:25,759 - INFO - training batch 1, loss: 1.767, 32/28000 datapoints
2025-03-07 09:51:26,369 - INFO - training batch 51, loss: 1.731, 1632/28000 datapoints
2025-03-07 09:51:27,017 - INFO - training batch 101, loss: 1.241, 3232/28000 datapoints
2025-03-07 09:51:27,471 - INFO - training batch 151, loss: 1.761, 4832/28000 datapoints
2025-03-07 09:51:27,779 - INFO - training batch 201, loss: 1.744, 6432/28000 datapoints
2025-03-07 09:51:28,130 - INFO - training batch 251, loss: 1.509, 8032/28000 datapoints
2025-03-07 09:51:28,451 - INFO - training batch 301, loss: 1.658, 9632/28000 datapoints
2025-03-07 09:51:28,850 - INFO - training batch 351, loss: 1.585, 11232/28000 datapoints
2025-03-07 09:51:29,238 - INFO - training batch 401, loss: 1.540, 12832/28000 datapoints
2025-03-07 09:51:29,609 - INFO - training batch 451, loss: 1.461, 14432/28000 datapoints
2025-03-07 09:51:30,016 - INFO - training batch 501, loss: 1.187, 16032/28000 datapoints
2025-03-07 09:51:30,391 - INFO - training batch 551, loss: 1.478, 17632/28000 datapoints
2025-03-07 09:51:30,883 - INFO - training batch 601, loss: 1.472, 19232/28000 datapoints
2025-03-07 09:51:31,248 - INFO - training batch 651, loss: 1.164, 20832/28000 datapoints
2025-03-07 09:51:31,580 - INFO - training batch 701, loss: 1.227, 22432/28000 datapoints
2025-03-07 09:51:31,949 - INFO - training batch 751, loss: 1.606, 24032/28000 datapoints
2025-03-07 09:51:32,341 - INFO - training batch 801, loss: 1.287, 25632/28000 datapoints
2025-03-07 09:51:32,659 - INFO - training batch 851, loss: 1.369, 27232/28000 datapoints
2025-03-07 09:51:32,834 - INFO - validation batch 1, loss: 1.118, 32/6976 datapoints
2025-03-07 09:51:32,952 - INFO - validation batch 51, loss: 1.883, 1632/6976 datapoints
2025-03-07 09:51:33,055 - INFO - validation batch 101, loss: 1.465, 3232/6976 datapoints
2025-03-07 09:51:33,176 - INFO - validation batch 151, loss: 1.840, 4832/6976 datapoints
2025-03-07 09:51:33,312 - INFO - validation batch 201, loss: 1.036, 6432/6976 datapoints
2025-03-07 09:51:33,382 - INFO - Epoch 13/800 done.
2025-03-07 09:51:33,383 - INFO - Final validation performance:
Loss: 1.469, top-1 acc: 0.484top-5 acc: 0.484
2025-03-07 09:51:33,385 - INFO - Beginning epoch 14/800
2025-03-07 09:51:33,401 - INFO - training batch 1, loss: 1.737, 32/28000 datapoints
2025-03-07 09:51:34,057 - INFO - training batch 51, loss: 1.704, 1632/28000 datapoints
2025-03-07 09:51:34,529 - INFO - training batch 101, loss: 1.221, 3232/28000 datapoints
2025-03-07 09:51:35,366 - INFO - training batch 151, loss: 1.743, 4832/28000 datapoints
2025-03-07 09:51:35,875 - INFO - training batch 201, loss: 1.722, 6432/28000 datapoints
2025-03-07 09:51:36,200 - INFO - training batch 251, loss: 1.471, 8032/28000 datapoints
2025-03-07 09:51:36,510 - INFO - training batch 301, loss: 1.640, 9632/28000 datapoints
2025-03-07 09:51:36,875 - INFO - training batch 351, loss: 1.564, 11232/28000 datapoints
2025-03-07 09:51:37,172 - INFO - training batch 401, loss: 1.521, 12832/28000 datapoints
2025-03-07 09:51:37,553 - INFO - training batch 451, loss: 1.448, 14432/28000 datapoints
2025-03-07 09:51:37,868 - INFO - training batch 501, loss: 1.183, 16032/28000 datapoints
2025-03-07 09:51:38,199 - INFO - training batch 551, loss: 1.465, 17632/28000 datapoints
2025-03-07 09:51:38,513 - INFO - training batch 601, loss: 1.465, 19232/28000 datapoints
2025-03-07 09:51:38,860 - INFO - training batch 651, loss: 1.140, 20832/28000 datapoints
2025-03-07 09:51:39,171 - INFO - training batch 701, loss: 1.217, 22432/28000 datapoints
2025-03-07 09:51:39,506 - INFO - training batch 751, loss: 1.592, 24032/28000 datapoints
2025-03-07 09:51:39,839 - INFO - training batch 801, loss: 1.266, 25632/28000 datapoints
2025-03-07 09:51:40,181 - INFO - training batch 851, loss: 1.356, 27232/28000 datapoints
2025-03-07 09:51:40,384 - INFO - validation batch 1, loss: 1.099, 32/6976 datapoints
2025-03-07 09:51:40,615 - INFO - validation batch 51, loss: 1.870, 1632/6976 datapoints
2025-03-07 09:51:40,781 - INFO - validation batch 101, loss: 1.454, 3232/6976 datapoints
2025-03-07 09:51:40,904 - INFO - validation batch 151, loss: 1.811, 4832/6976 datapoints
2025-03-07 09:51:41,002 - INFO - validation batch 201, loss: 1.018, 6432/6976 datapoints
2025-03-07 09:51:41,037 - INFO - Epoch 14/800 done.
2025-03-07 09:51:41,038 - INFO - Final validation performance:
Loss: 1.450, top-1 acc: 0.490top-5 acc: 0.490
2025-03-07 09:51:41,039 - INFO - Beginning epoch 15/800
2025-03-07 09:51:41,050 - INFO - training batch 1, loss: 1.707, 32/28000 datapoints
2025-03-07 09:51:41,507 - INFO - training batch 51, loss: 1.677, 1632/28000 datapoints
2025-03-07 09:51:41,821 - INFO - training batch 101, loss: 1.201, 3232/28000 datapoints
2025-03-07 09:51:42,216 - INFO - training batch 151, loss: 1.725, 4832/28000 datapoints
2025-03-07 09:51:42,527 - INFO - training batch 201, loss: 1.701, 6432/28000 datapoints
2025-03-07 09:51:42,874 - INFO - training batch 251, loss: 1.435, 8032/28000 datapoints
2025-03-07 09:51:43,175 - INFO - training batch 301, loss: 1.623, 9632/28000 datapoints
2025-03-07 09:51:43,518 - INFO - training batch 351, loss: 1.545, 11232/28000 datapoints
2025-03-07 09:51:43,816 - INFO - training batch 401, loss: 1.502, 12832/28000 datapoints
2025-03-07 09:51:44,163 - INFO - training batch 451, loss: 1.435, 14432/28000 datapoints
2025-03-07 09:51:44,475 - INFO - training batch 501, loss: 1.179, 16032/28000 datapoints
2025-03-07 09:51:44,839 - INFO - training batch 551, loss: 1.452, 17632/28000 datapoints
2025-03-07 09:51:45,151 - INFO - training batch 601, loss: 1.459, 19232/28000 datapoints
2025-03-07 09:51:45,487 - INFO - training batch 651, loss: 1.117, 20832/28000 datapoints
2025-03-07 09:51:45,811 - INFO - training batch 701, loss: 1.207, 22432/28000 datapoints
2025-03-07 09:51:46,136 - INFO - training batch 751, loss: 1.578, 24032/28000 datapoints
2025-03-07 09:51:46,464 - INFO - training batch 801, loss: 1.244, 25632/28000 datapoints
2025-03-07 09:51:46,763 - INFO - training batch 851, loss: 1.343, 27232/28000 datapoints
2025-03-07 09:51:46,940 - INFO - validation batch 1, loss: 1.080, 32/6976 datapoints
2025-03-07 09:51:47,036 - INFO - validation batch 51, loss: 1.857, 1632/6976 datapoints
2025-03-07 09:51:47,136 - INFO - validation batch 101, loss: 1.442, 3232/6976 datapoints
2025-03-07 09:51:47,235 - INFO - validation batch 151, loss: 1.784, 4832/6976 datapoints
2025-03-07 09:51:47,336 - INFO - validation batch 201, loss: 1.001, 6432/6976 datapoints
2025-03-07 09:51:47,376 - INFO - Epoch 15/800 done.
2025-03-07 09:51:47,377 - INFO - Final validation performance:
Loss: 1.433, top-1 acc: 0.494top-5 acc: 0.494
2025-03-07 09:51:47,379 - INFO - Beginning epoch 16/800
2025-03-07 09:51:47,390 - INFO - training batch 1, loss: 1.677, 32/28000 datapoints
2025-03-07 09:51:47,789 - INFO - training batch 51, loss: 1.650, 1632/28000 datapoints
2025-03-07 09:51:48,154 - INFO - training batch 101, loss: 1.182, 3232/28000 datapoints
2025-03-07 09:51:48,506 - INFO - training batch 151, loss: 1.705, 4832/28000 datapoints
2025-03-07 09:51:48,884 - INFO - training batch 201, loss: 1.682, 6432/28000 datapoints
2025-03-07 09:51:49,241 - INFO - training batch 251, loss: 1.399, 8032/28000 datapoints
2025-03-07 09:51:49,601 - INFO - training batch 301, loss: 1.604, 9632/28000 datapoints
2025-03-07 09:51:49,983 - INFO - training batch 351, loss: 1.527, 11232/28000 datapoints
2025-03-07 09:51:50,351 - INFO - training batch 401, loss: 1.483, 12832/28000 datapoints
2025-03-07 09:51:50,746 - INFO - training batch 451, loss: 1.420, 14432/28000 datapoints
2025-03-07 09:51:51,079 - INFO - training batch 501, loss: 1.174, 16032/28000 datapoints
2025-03-07 09:51:51,414 - INFO - training batch 551, loss: 1.438, 17632/28000 datapoints
2025-03-07 09:51:51,761 - INFO - training batch 601, loss: 1.452, 19232/28000 datapoints
2025-03-07 09:51:52,101 - INFO - training batch 651, loss: 1.094, 20832/28000 datapoints
2025-03-07 09:51:52,436 - INFO - training batch 701, loss: 1.198, 22432/28000 datapoints
2025-03-07 09:51:52,784 - INFO - training batch 751, loss: 1.562, 24032/28000 datapoints
2025-03-07 09:51:53,095 - INFO - training batch 801, loss: 1.223, 25632/28000 datapoints
2025-03-07 09:51:53,434 - INFO - training batch 851, loss: 1.329, 27232/28000 datapoints
2025-03-07 09:51:53,635 - INFO - validation batch 1, loss: 1.060, 32/6976 datapoints
2025-03-07 09:51:53,738 - INFO - validation batch 51, loss: 1.844, 1632/6976 datapoints
2025-03-07 09:51:53,841 - INFO - validation batch 101, loss: 1.430, 3232/6976 datapoints
2025-03-07 09:51:53,944 - INFO - validation batch 151, loss: 1.757, 4832/6976 datapoints
2025-03-07 09:51:54,089 - INFO - validation batch 201, loss: 0.985, 6432/6976 datapoints
2025-03-07 09:51:54,146 - INFO - Epoch 16/800 done.
2025-03-07 09:51:54,147 - INFO - Final validation performance:
Loss: 1.415, top-1 acc: 0.502top-5 acc: 0.502
2025-03-07 09:51:54,148 - INFO - Beginning epoch 17/800
2025-03-07 09:51:54,160 - INFO - training batch 1, loss: 1.647, 32/28000 datapoints
2025-03-07 09:51:54,584 - INFO - training batch 51, loss: 1.623, 1632/28000 datapoints
2025-03-07 09:51:54,893 - INFO - training batch 101, loss: 1.162, 3232/28000 datapoints
2025-03-07 09:51:55,239 - INFO - training batch 151, loss: 1.685, 4832/28000 datapoints
2025-03-07 09:51:55,543 - INFO - training batch 201, loss: 1.662, 6432/28000 datapoints
2025-03-07 09:51:55,901 - INFO - training batch 251, loss: 1.364, 8032/28000 datapoints
2025-03-07 09:51:56,199 - INFO - training batch 301, loss: 1.584, 9632/28000 datapoints
2025-03-07 09:51:56,537 - INFO - training batch 351, loss: 1.507, 11232/28000 datapoints
2025-03-07 09:51:56,848 - INFO - training batch 401, loss: 1.465, 12832/28000 datapoints
2025-03-07 09:51:57,188 - INFO - training batch 451, loss: 1.406, 14432/28000 datapoints
2025-03-07 09:51:57,496 - INFO - training batch 501, loss: 1.170, 16032/28000 datapoints
2025-03-07 09:51:57,870 - INFO - training batch 551, loss: 1.423, 17632/28000 datapoints
2025-03-07 09:51:58,190 - INFO - training batch 601, loss: 1.444, 19232/28000 datapoints
2025-03-07 09:51:58,525 - INFO - training batch 651, loss: 1.072, 20832/28000 datapoints
2025-03-07 09:51:58,872 - INFO - training batch 701, loss: 1.188, 22432/28000 datapoints
2025-03-07 09:51:59,192 - INFO - training batch 751, loss: 1.541, 24032/28000 datapoints
2025-03-07 09:51:59,528 - INFO - training batch 801, loss: 1.201, 25632/28000 datapoints
2025-03-07 09:51:59,861 - INFO - training batch 851, loss: 1.315, 27232/28000 datapoints
2025-03-07 09:52:00,031 - INFO - validation batch 1, loss: 1.042, 32/6976 datapoints
2025-03-07 09:52:00,129 - INFO - validation batch 51, loss: 1.828, 1632/6976 datapoints
2025-03-07 09:52:00,223 - INFO - validation batch 101, loss: 1.416, 3232/6976 datapoints
2025-03-07 09:52:00,321 - INFO - validation batch 151, loss: 1.730, 4832/6976 datapoints
2025-03-07 09:52:00,428 - INFO - validation batch 201, loss: 0.970, 6432/6976 datapoints
2025-03-07 09:52:00,473 - INFO - Epoch 17/800 done.
2025-03-07 09:52:00,473 - INFO - Final validation performance:
Loss: 1.397, top-1 acc: 0.508top-5 acc: 0.508
2025-03-07 09:52:00,474 - INFO - Beginning epoch 18/800
2025-03-07 09:52:00,486 - INFO - training batch 1, loss: 1.617, 32/28000 datapoints
2025-03-07 09:52:00,875 - INFO - training batch 51, loss: 1.596, 1632/28000 datapoints
2025-03-07 09:52:01,243 - INFO - training batch 101, loss: 1.142, 3232/28000 datapoints
2025-03-07 09:52:01,602 - INFO - training batch 151, loss: 1.664, 4832/28000 datapoints
2025-03-07 09:52:01,956 - INFO - training batch 201, loss: 1.643, 6432/28000 datapoints
2025-03-07 09:52:02,303 - INFO - training batch 251, loss: 1.330, 8032/28000 datapoints
2025-03-07 09:52:02,696 - INFO - training batch 301, loss: 1.562, 9632/28000 datapoints
2025-03-07 09:52:03,166 - INFO - training batch 351, loss: 1.486, 11232/28000 datapoints
2025-03-07 09:52:03,591 - INFO - training batch 401, loss: 1.446, 12832/28000 datapoints
2025-03-07 09:52:03,924 - INFO - training batch 451, loss: 1.391, 14432/28000 datapoints
2025-03-07 09:52:04,227 - INFO - training batch 501, loss: 1.166, 16032/28000 datapoints
2025-03-07 09:52:04,572 - INFO - training batch 551, loss: 1.407, 17632/28000 datapoints
2025-03-07 09:52:04,877 - INFO - training batch 601, loss: 1.434, 19232/28000 datapoints
2025-03-07 09:52:05,213 - INFO - training batch 651, loss: 1.048, 20832/28000 datapoints
2025-03-07 09:52:05,513 - INFO - training batch 701, loss: 1.177, 22432/28000 datapoints
2025-03-07 09:52:05,868 - INFO - training batch 751, loss: 1.520, 24032/28000 datapoints
2025-03-07 09:52:06,165 - INFO - training batch 801, loss: 1.180, 25632/28000 datapoints
2025-03-07 09:52:06,488 - INFO - training batch 851, loss: 1.300, 27232/28000 datapoints
2025-03-07 09:52:06,659 - INFO - validation batch 1, loss: 1.024, 32/6976 datapoints
2025-03-07 09:52:06,771 - INFO - validation batch 51, loss: 1.813, 1632/6976 datapoints
2025-03-07 09:52:06,869 - INFO - validation batch 101, loss: 1.401, 3232/6976 datapoints
2025-03-07 09:52:06,966 - INFO - validation batch 151, loss: 1.702, 4832/6976 datapoints
2025-03-07 09:52:07,061 - INFO - validation batch 201, loss: 0.955, 6432/6976 datapoints
2025-03-07 09:52:07,101 - INFO - Epoch 18/800 done.
2025-03-07 09:52:07,101 - INFO - Final validation performance:
Loss: 1.379, top-1 acc: 0.517top-5 acc: 0.517
2025-03-07 09:52:07,102 - INFO - Beginning epoch 19/800
2025-03-07 09:52:07,113 - INFO - training batch 1, loss: 1.586, 32/28000 datapoints
2025-03-07 09:52:07,472 - INFO - training batch 51, loss: 1.569, 1632/28000 datapoints
2025-03-07 09:52:07,822 - INFO - training batch 101, loss: 1.122, 3232/28000 datapoints
2025-03-07 09:52:08,354 - INFO - training batch 151, loss: 1.642, 4832/28000 datapoints
2025-03-07 09:52:08,780 - INFO - training batch 201, loss: 1.622, 6432/28000 datapoints
2025-03-07 09:52:09,104 - INFO - training batch 251, loss: 1.296, 8032/28000 datapoints
2025-03-07 09:52:09,427 - INFO - training batch 301, loss: 1.542, 9632/28000 datapoints
2025-03-07 09:52:09,780 - INFO - training batch 351, loss: 1.463, 11232/28000 datapoints
2025-03-07 09:52:10,124 - INFO - training batch 401, loss: 1.427, 12832/28000 datapoints
2025-03-07 09:52:10,561 - INFO - training batch 451, loss: 1.376, 14432/28000 datapoints
2025-03-07 09:52:10,931 - INFO - training batch 501, loss: 1.160, 16032/28000 datapoints
2025-03-07 09:52:11,335 - INFO - training batch 551, loss: 1.392, 17632/28000 datapoints
2025-03-07 09:52:11,798 - INFO - training batch 601, loss: 1.430, 19232/28000 datapoints
2025-03-07 09:52:12,263 - INFO - training batch 651, loss: 1.027, 20832/28000 datapoints
2025-03-07 09:52:12,605 - INFO - training batch 701, loss: 1.166, 22432/28000 datapoints
2025-03-07 09:52:12,976 - INFO - training batch 751, loss: 1.500, 24032/28000 datapoints
2025-03-07 09:52:13,280 - INFO - training batch 801, loss: 1.156, 25632/28000 datapoints
2025-03-07 09:52:13,650 - INFO - training batch 851, loss: 1.285, 27232/28000 datapoints
2025-03-07 09:52:13,807 - INFO - validation batch 1, loss: 1.004, 32/6976 datapoints
2025-03-07 09:52:13,906 - INFO - validation batch 51, loss: 1.801, 1632/6976 datapoints
2025-03-07 09:52:14,010 - INFO - validation batch 101, loss: 1.384, 3232/6976 datapoints
2025-03-07 09:52:14,109 - INFO - validation batch 151, loss: 1.672, 4832/6976 datapoints
2025-03-07 09:52:14,209 - INFO - validation batch 201, loss: 0.939, 6432/6976 datapoints
2025-03-07 09:52:14,248 - INFO - Epoch 19/800 done.
2025-03-07 09:52:14,248 - INFO - Final validation performance:
Loss: 1.360, top-1 acc: 0.523top-5 acc: 0.523
2025-03-07 09:52:14,249 - INFO - Beginning epoch 20/800
2025-03-07 09:52:14,259 - INFO - training batch 1, loss: 1.553, 32/28000 datapoints
2025-03-07 09:52:14,619 - INFO - training batch 51, loss: 1.542, 1632/28000 datapoints
2025-03-07 09:52:14,990 - INFO - training batch 101, loss: 1.101, 3232/28000 datapoints
2025-03-07 09:52:15,343 - INFO - training batch 151, loss: 1.617, 4832/28000 datapoints
2025-03-07 09:52:15,773 - INFO - training batch 201, loss: 1.600, 6432/28000 datapoints
2025-03-07 09:52:16,442 - INFO - training batch 251, loss: 1.261, 8032/28000 datapoints
2025-03-07 09:52:16,770 - INFO - training batch 301, loss: 1.519, 9632/28000 datapoints
2025-03-07 09:52:17,104 - INFO - training batch 351, loss: 1.439, 11232/28000 datapoints
2025-03-07 09:52:17,399 - INFO - training batch 401, loss: 1.407, 12832/28000 datapoints
2025-03-07 09:52:17,741 - INFO - training batch 451, loss: 1.360, 14432/28000 datapoints
2025-03-07 09:52:18,211 - INFO - training batch 501, loss: 1.152, 16032/28000 datapoints
2025-03-07 09:52:18,646 - INFO - training batch 551, loss: 1.374, 17632/28000 datapoints
2025-03-07 09:52:18,951 - INFO - training batch 601, loss: 1.426, 19232/28000 datapoints
2025-03-07 09:52:19,299 - INFO - training batch 651, loss: 1.005, 20832/28000 datapoints
2025-03-07 09:52:19,592 - INFO - training batch 701, loss: 1.153, 22432/28000 datapoints
2025-03-07 09:52:19,933 - INFO - training batch 751, loss: 1.479, 24032/28000 datapoints
2025-03-07 09:52:20,223 - INFO - training batch 801, loss: 1.132, 25632/28000 datapoints
2025-03-07 09:52:20,557 - INFO - training batch 851, loss: 1.270, 27232/28000 datapoints
2025-03-07 09:52:20,746 - INFO - validation batch 1, loss: 0.983, 32/6976 datapoints
2025-03-07 09:52:20,845 - INFO - validation batch 51, loss: 1.787, 1632/6976 datapoints
2025-03-07 09:52:20,935 - INFO - validation batch 101, loss: 1.364, 3232/6976 datapoints
2025-03-07 09:52:21,025 - INFO - validation batch 151, loss: 1.640, 4832/6976 datapoints
2025-03-07 09:52:21,112 - INFO - validation batch 201, loss: 0.923, 6432/6976 datapoints
2025-03-07 09:52:21,143 - INFO - Epoch 20/800 done.
2025-03-07 09:52:21,143 - INFO - Final validation performance:
Loss: 1.340, top-1 acc: 0.530top-5 acc: 0.530
2025-03-07 09:52:21,144 - INFO - Beginning epoch 21/800
2025-03-07 09:52:21,153 - INFO - training batch 1, loss: 1.519, 32/28000 datapoints
2025-03-07 09:52:21,517 - INFO - training batch 51, loss: 1.515, 1632/28000 datapoints
2025-03-07 09:52:21,892 - INFO - training batch 101, loss: 1.078, 3232/28000 datapoints
2025-03-07 09:52:22,239 - INFO - training batch 151, loss: 1.591, 4832/28000 datapoints
2025-03-07 09:52:22,588 - INFO - training batch 201, loss: 1.577, 6432/28000 datapoints
2025-03-07 09:52:22,959 - INFO - training batch 251, loss: 1.225, 8032/28000 datapoints
2025-03-07 09:52:23,317 - INFO - training batch 301, loss: 1.495, 9632/28000 datapoints
2025-03-07 09:52:23,662 - INFO - training batch 351, loss: 1.412, 11232/28000 datapoints
2025-03-07 09:52:24,021 - INFO - training batch 401, loss: 1.387, 12832/28000 datapoints
2025-03-07 09:52:24,380 - INFO - training batch 451, loss: 1.342, 14432/28000 datapoints
2025-03-07 09:52:24,753 - INFO - training batch 501, loss: 1.141, 16032/28000 datapoints
2025-03-07 09:52:25,123 - INFO - training batch 551, loss: 1.355, 17632/28000 datapoints
2025-03-07 09:52:25,483 - INFO - training batch 601, loss: 1.423, 19232/28000 datapoints
2025-03-07 09:52:25,844 - INFO - training batch 651, loss: 0.982, 20832/28000 datapoints
2025-03-07 09:52:26,216 - INFO - training batch 701, loss: 1.140, 22432/28000 datapoints
2025-03-07 09:52:26,681 - INFO - training batch 751, loss: 1.455, 24032/28000 datapoints
2025-03-07 09:52:27,046 - INFO - training batch 801, loss: 1.106, 25632/28000 datapoints
2025-03-07 09:52:27,377 - INFO - training batch 851, loss: 1.255, 27232/28000 datapoints
2025-03-07 09:52:27,544 - INFO - validation batch 1, loss: 0.962, 32/6976 datapoints
2025-03-07 09:52:27,640 - INFO - validation batch 51, loss: 1.772, 1632/6976 datapoints
2025-03-07 09:52:27,743 - INFO - validation batch 101, loss: 1.343, 3232/6976 datapoints
2025-03-07 09:52:27,841 - INFO - validation batch 151, loss: 1.606, 4832/6976 datapoints
2025-03-07 09:52:27,955 - INFO - validation batch 201, loss: 0.907, 6432/6976 datapoints
2025-03-07 09:52:27,996 - INFO - Epoch 21/800 done.
2025-03-07 09:52:27,996 - INFO - Final validation performance:
Loss: 1.318, top-1 acc: 0.538top-5 acc: 0.538
2025-03-07 09:52:27,997 - INFO - Beginning epoch 22/800
2025-03-07 09:52:28,006 - INFO - training batch 1, loss: 1.484, 32/28000 datapoints
2025-03-07 09:52:28,394 - INFO - training batch 51, loss: 1.487, 1632/28000 datapoints
2025-03-07 09:52:28,760 - INFO - training batch 101, loss: 1.054, 3232/28000 datapoints
2025-03-07 09:52:29,175 - INFO - training batch 151, loss: 1.562, 4832/28000 datapoints
2025-03-07 09:52:29,564 - INFO - training batch 201, loss: 1.552, 6432/28000 datapoints
2025-03-07 09:52:29,879 - INFO - training batch 251, loss: 1.189, 8032/28000 datapoints
2025-03-07 09:52:30,191 - INFO - training batch 301, loss: 1.468, 9632/28000 datapoints
2025-03-07 09:52:30,504 - INFO - training batch 351, loss: 1.383, 11232/28000 datapoints
2025-03-07 09:52:30,824 - INFO - training batch 401, loss: 1.367, 12832/28000 datapoints
2025-03-07 09:52:31,137 - INFO - training batch 451, loss: 1.322, 14432/28000 datapoints
2025-03-07 09:52:31,448 - INFO - training batch 501, loss: 1.130, 16032/28000 datapoints
2025-03-07 09:52:31,774 - INFO - training batch 551, loss: 1.335, 17632/28000 datapoints
2025-03-07 09:52:32,082 - INFO - training batch 601, loss: 1.420, 19232/28000 datapoints
2025-03-07 09:52:32,403 - INFO - training batch 651, loss: 0.957, 20832/28000 datapoints
2025-03-07 09:52:32,756 - INFO - training batch 701, loss: 1.125, 22432/28000 datapoints
2025-03-07 09:52:33,108 - INFO - training batch 751, loss: 1.427, 24032/28000 datapoints
2025-03-07 09:52:33,498 - INFO - training batch 801, loss: 1.080, 25632/28000 datapoints
2025-03-07 09:52:34,046 - INFO - training batch 851, loss: 1.238, 27232/28000 datapoints
2025-03-07 09:52:34,226 - INFO - validation batch 1, loss: 0.940, 32/6976 datapoints
2025-03-07 09:52:34,340 - INFO - validation batch 51, loss: 1.754, 1632/6976 datapoints
2025-03-07 09:52:34,451 - INFO - validation batch 101, loss: 1.317, 3232/6976 datapoints
2025-03-07 09:52:34,570 - INFO - validation batch 151, loss: 1.570, 4832/6976 datapoints
2025-03-07 09:52:34,678 - INFO - validation batch 201, loss: 0.890, 6432/6976 datapoints
2025-03-07 09:52:34,718 - INFO - Epoch 22/800 done.
2025-03-07 09:52:34,718 - INFO - Final validation performance:
Loss: 1.294, top-1 acc: 0.546top-5 acc: 0.546
2025-03-07 09:52:34,719 - INFO - Beginning epoch 23/800
2025-03-07 09:52:34,728 - INFO - training batch 1, loss: 1.449, 32/28000 datapoints
2025-03-07 09:52:35,088 - INFO - training batch 51, loss: 1.458, 1632/28000 datapoints
2025-03-07 09:52:35,409 - INFO - training batch 101, loss: 1.029, 3232/28000 datapoints
2025-03-07 09:52:35,754 - INFO - training batch 151, loss: 1.531, 4832/28000 datapoints
2025-03-07 09:52:36,148 - INFO - training batch 201, loss: 1.521, 6432/28000 datapoints
2025-03-07 09:52:36,528 - INFO - training batch 251, loss: 1.151, 8032/28000 datapoints
2025-03-07 09:52:36,911 - INFO - training batch 301, loss: 1.438, 9632/28000 datapoints
2025-03-07 09:52:37,280 - INFO - training batch 351, loss: 1.350, 11232/28000 datapoints
2025-03-07 09:52:37,628 - INFO - training batch 401, loss: 1.344, 12832/28000 datapoints
2025-03-07 09:52:37,961 - INFO - training batch 451, loss: 1.299, 14432/28000 datapoints
2025-03-07 09:52:38,359 - INFO - training batch 501, loss: 1.119, 16032/28000 datapoints
2025-03-07 09:52:38,692 - INFO - training batch 551, loss: 1.311, 17632/28000 datapoints
2025-03-07 09:52:39,031 - INFO - training batch 601, loss: 1.418, 19232/28000 datapoints
2025-03-07 09:52:39,359 - INFO - training batch 651, loss: 0.930, 20832/28000 datapoints
2025-03-07 09:52:39,697 - INFO - training batch 701, loss: 1.108, 22432/28000 datapoints
2025-03-07 09:52:40,003 - INFO - training batch 751, loss: 1.393, 24032/28000 datapoints
2025-03-07 09:52:40,341 - INFO - training batch 801, loss: 1.051, 25632/28000 datapoints
2025-03-07 09:52:40,643 - INFO - training batch 851, loss: 1.222, 27232/28000 datapoints
2025-03-07 09:52:40,816 - INFO - validation batch 1, loss: 0.915, 32/6976 datapoints
2025-03-07 09:52:40,922 - INFO - validation batch 51, loss: 1.737, 1632/6976 datapoints
2025-03-07 09:52:41,021 - INFO - validation batch 101, loss: 1.287, 3232/6976 datapoints
2025-03-07 09:52:41,122 - INFO - validation batch 151, loss: 1.531, 4832/6976 datapoints
2025-03-07 09:52:41,220 - INFO - validation batch 201, loss: 0.871, 6432/6976 datapoints
2025-03-07 09:52:41,257 - INFO - Epoch 23/800 done.
2025-03-07 09:52:41,258 - INFO - Final validation performance:
Loss: 1.268, top-1 acc: 0.557top-5 acc: 0.557
2025-03-07 09:52:41,259 - INFO - Beginning epoch 24/800
2025-03-07 09:52:41,269 - INFO - training batch 1, loss: 1.413, 32/28000 datapoints
2025-03-07 09:52:41,626 - INFO - training batch 51, loss: 1.425, 1632/28000 datapoints
2025-03-07 09:52:42,036 - INFO - training batch 101, loss: 1.002, 3232/28000 datapoints
2025-03-07 09:52:42,374 - INFO - training batch 151, loss: 1.499, 4832/28000 datapoints
2025-03-07 09:52:42,723 - INFO - training batch 201, loss: 1.490, 6432/28000 datapoints
2025-03-07 09:52:43,038 - INFO - training batch 251, loss: 1.112, 8032/28000 datapoints
2025-03-07 09:52:43,381 - INFO - training batch 301, loss: 1.405, 9632/28000 datapoints
2025-03-07 09:52:43,676 - INFO - training batch 351, loss: 1.313, 11232/28000 datapoints
2025-03-07 09:52:44,011 - INFO - training batch 401, loss: 1.320, 12832/28000 datapoints
2025-03-07 09:52:44,306 - INFO - training batch 451, loss: 1.274, 14432/28000 datapoints
2025-03-07 09:52:44,654 - INFO - training batch 501, loss: 1.103, 16032/28000 datapoints
2025-03-07 09:52:44,960 - INFO - training batch 551, loss: 1.285, 17632/28000 datapoints
2025-03-07 09:52:45,288 - INFO - training batch 601, loss: 1.416, 19232/28000 datapoints
2025-03-07 09:52:45,596 - INFO - training batch 651, loss: 0.903, 20832/28000 datapoints
2025-03-07 09:52:45,941 - INFO - training batch 701, loss: 1.089, 22432/28000 datapoints
2025-03-07 09:52:46,246 - INFO - training batch 751, loss: 1.359, 24032/28000 datapoints
2025-03-07 09:52:46,596 - INFO - training batch 801, loss: 1.019, 25632/28000 datapoints
2025-03-07 09:52:46,899 - INFO - training batch 851, loss: 1.204, 27232/28000 datapoints
2025-03-07 09:52:47,073 - INFO - validation batch 1, loss: 0.888, 32/6976 datapoints
2025-03-07 09:52:47,163 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-07 09:52:47,250 - INFO - validation batch 101, loss: 1.256, 3232/6976 datapoints
2025-03-07 09:52:47,340 - INFO - validation batch 151, loss: 1.489, 4832/6976 datapoints
2025-03-07 09:52:47,427 - INFO - validation batch 201, loss: 0.853, 6432/6976 datapoints
2025-03-07 09:52:47,456 - INFO - Epoch 24/800 done.
2025-03-07 09:52:47,457 - INFO - Final validation performance:
Loss: 1.241, top-1 acc: 0.569top-5 acc: 0.569
2025-03-07 09:52:47,457 - INFO - Beginning epoch 25/800
2025-03-07 09:52:47,467 - INFO - training batch 1, loss: 1.372, 32/28000 datapoints
2025-03-07 09:52:47,827 - INFO - training batch 51, loss: 1.392, 1632/28000 datapoints
2025-03-07 09:52:48,179 - INFO - training batch 101, loss: 0.973, 3232/28000 datapoints
2025-03-07 09:52:48,527 - INFO - training batch 151, loss: 1.466, 4832/28000 datapoints
2025-03-07 09:52:48,929 - INFO - training batch 201, loss: 1.458, 6432/28000 datapoints
2025-03-07 09:52:49,295 - INFO - training batch 251, loss: 1.071, 8032/28000 datapoints
2025-03-07 09:52:49,643 - INFO - training batch 301, loss: 1.368, 9632/28000 datapoints
2025-03-07 09:52:49,999 - INFO - training batch 351, loss: 1.273, 11232/28000 datapoints
2025-03-07 09:52:50,346 - INFO - training batch 401, loss: 1.295, 12832/28000 datapoints
2025-03-07 09:52:50,701 - INFO - training batch 451, loss: 1.249, 14432/28000 datapoints
2025-03-07 09:52:51,058 - INFO - training batch 501, loss: 1.083, 16032/28000 datapoints
2025-03-07 09:52:51,419 - INFO - training batch 551, loss: 1.258, 17632/28000 datapoints
2025-03-07 09:52:51,778 - INFO - training batch 601, loss: 1.413, 19232/28000 datapoints
2025-03-07 09:52:52,138 - INFO - training batch 651, loss: 0.873, 20832/28000 datapoints
2025-03-07 09:52:52,499 - INFO - training batch 701, loss: 1.069, 22432/28000 datapoints
2025-03-07 09:52:52,858 - INFO - training batch 751, loss: 1.320, 24032/28000 datapoints
2025-03-07 09:52:53,217 - INFO - training batch 801, loss: 0.986, 25632/28000 datapoints
2025-03-07 09:52:53,620 - INFO - training batch 851, loss: 1.186, 27232/28000 datapoints
2025-03-07 09:52:53,860 - INFO - validation batch 1, loss: 0.861, 32/6976 datapoints
2025-03-07 09:52:54,044 - INFO - validation batch 51, loss: 1.700, 1632/6976 datapoints
2025-03-07 09:52:54,224 - INFO - validation batch 101, loss: 1.220, 3232/6976 datapoints
2025-03-07 09:52:55,280 - INFO - validation batch 151, loss: 1.442, 4832/6976 datapoints
2025-03-07 09:52:55,535 - INFO - validation batch 201, loss: 0.835, 6432/6976 datapoints
2025-03-07 09:52:55,822 - INFO - Epoch 25/800 done.
2025-03-07 09:52:55,822 - INFO - Final validation performance:
Loss: 1.212, top-1 acc: 0.583top-5 acc: 0.583
2025-03-07 09:52:55,823 - INFO - Beginning epoch 26/800
2025-03-07 09:52:55,835 - INFO - training batch 1, loss: 1.328, 32/28000 datapoints
2025-03-07 09:53:00,672 - INFO - training batch 51, loss: 1.356, 1632/28000 datapoints
2025-03-07 09:53:04,440 - INFO - training batch 101, loss: 0.942, 3232/28000 datapoints
2025-03-07 09:53:06,387 - INFO - training batch 151, loss: 1.432, 4832/28000 datapoints
2025-03-07 09:53:08,431 - INFO - training batch 201, loss: 1.423, 6432/28000 datapoints
2025-03-07 09:53:08,983 - INFO - training batch 251, loss: 1.030, 8032/28000 datapoints
2025-03-07 09:53:09,625 - INFO - training batch 301, loss: 1.328, 9632/28000 datapoints
2025-03-07 09:53:10,148 - INFO - training batch 351, loss: 1.227, 11232/28000 datapoints
2025-03-07 09:53:10,660 - INFO - training batch 401, loss: 1.270, 12832/28000 datapoints
2025-03-07 09:53:11,502 - INFO - training batch 451, loss: 1.222, 14432/28000 datapoints
2025-03-07 09:53:11,962 - INFO - training batch 501, loss: 1.061, 16032/28000 datapoints
2025-03-07 09:53:12,539 - INFO - training batch 551, loss: 1.227, 17632/28000 datapoints
2025-03-07 09:53:13,014 - INFO - training batch 601, loss: 1.409, 19232/28000 datapoints
2025-03-07 09:53:13,545 - INFO - training batch 651, loss: 0.842, 20832/28000 datapoints
2025-03-07 09:53:14,027 - INFO - training batch 701, loss: 1.047, 22432/28000 datapoints
2025-03-07 09:53:14,460 - INFO - training batch 751, loss: 1.273, 24032/28000 datapoints
2025-03-07 09:53:14,912 - INFO - training batch 801, loss: 0.950, 25632/28000 datapoints
2025-03-07 09:53:15,354 - INFO - training batch 851, loss: 1.169, 27232/28000 datapoints
2025-03-07 09:53:15,588 - INFO - validation batch 1, loss: 0.830, 32/6976 datapoints
2025-03-07 09:53:15,756 - INFO - validation batch 51, loss: 1.680, 1632/6976 datapoints
2025-03-07 09:53:15,923 - INFO - validation batch 101, loss: 1.181, 3232/6976 datapoints
2025-03-07 09:53:16,068 - INFO - validation batch 151, loss: 1.391, 4832/6976 datapoints
2025-03-07 09:53:16,251 - INFO - validation batch 201, loss: 0.815, 6432/6976 datapoints
2025-03-07 09:53:16,305 - INFO - Epoch 26/800 done.
2025-03-07 09:53:16,306 - INFO - Final validation performance:
Loss: 1.180, top-1 acc: 0.599top-5 acc: 0.599
2025-03-07 09:53:16,309 - INFO - Beginning epoch 27/800
2025-03-07 09:53:16,322 - INFO - training batch 1, loss: 1.284, 32/28000 datapoints
2025-03-07 09:53:16,739 - INFO - training batch 51, loss: 1.315, 1632/28000 datapoints
2025-03-07 09:53:17,122 - INFO - training batch 101, loss: 0.911, 3232/28000 datapoints
2025-03-07 09:53:17,444 - INFO - training batch 151, loss: 1.395, 4832/28000 datapoints
2025-03-07 09:53:17,802 - INFO - training batch 201, loss: 1.384, 6432/28000 datapoints
2025-03-07 09:53:18,140 - INFO - training batch 251, loss: 0.990, 8032/28000 datapoints
2025-03-07 09:53:18,474 - INFO - training batch 301, loss: 1.284, 9632/28000 datapoints
2025-03-07 09:53:18,811 - INFO - training batch 351, loss: 1.179, 11232/28000 datapoints
2025-03-07 09:53:19,198 - INFO - training batch 401, loss: 1.242, 12832/28000 datapoints
2025-03-07 09:53:19,603 - INFO - training batch 451, loss: 1.192, 14432/28000 datapoints
2025-03-07 09:53:20,058 - INFO - training batch 501, loss: 1.036, 16032/28000 datapoints
2025-03-07 09:53:20,472 - INFO - training batch 551, loss: 1.196, 17632/28000 datapoints
2025-03-07 09:53:20,829 - INFO - training batch 601, loss: 1.407, 19232/28000 datapoints
2025-03-07 09:53:21,167 - INFO - training batch 651, loss: 0.811, 20832/28000 datapoints
2025-03-07 09:53:21,470 - INFO - training batch 701, loss: 1.025, 22432/28000 datapoints
2025-03-07 09:53:21,812 - INFO - training batch 751, loss: 1.224, 24032/28000 datapoints
2025-03-07 09:53:22,109 - INFO - training batch 801, loss: 0.911, 25632/28000 datapoints
2025-03-07 09:53:22,461 - INFO - training batch 851, loss: 1.155, 27232/28000 datapoints
2025-03-07 09:53:22,617 - INFO - validation batch 1, loss: 0.799, 32/6976 datapoints
2025-03-07 09:53:22,734 - INFO - validation batch 51, loss: 1.660, 1632/6976 datapoints
2025-03-07 09:53:22,872 - INFO - validation batch 101, loss: 1.137, 3232/6976 datapoints
2025-03-07 09:53:22,992 - INFO - validation batch 151, loss: 1.339, 4832/6976 datapoints
2025-03-07 09:53:23,090 - INFO - validation batch 201, loss: 0.794, 6432/6976 datapoints
2025-03-07 09:53:23,128 - INFO - Epoch 27/800 done.
2025-03-07 09:53:23,129 - INFO - Final validation performance:
Loss: 1.146, top-1 acc: 0.614top-5 acc: 0.614
2025-03-07 09:53:23,130 - INFO - Beginning epoch 28/800
2025-03-07 09:53:23,140 - INFO - training batch 1, loss: 1.236, 32/28000 datapoints
2025-03-07 09:53:23,484 - INFO - training batch 51, loss: 1.273, 1632/28000 datapoints
2025-03-07 09:53:23,814 - INFO - training batch 101, loss: 0.876, 3232/28000 datapoints
2025-03-07 09:53:24,161 - INFO - training batch 151, loss: 1.359, 4832/28000 datapoints
2025-03-07 09:53:24,551 - INFO - training batch 201, loss: 1.342, 6432/28000 datapoints
2025-03-07 09:53:24,873 - INFO - training batch 251, loss: 0.950, 8032/28000 datapoints
2025-03-07 09:53:25,225 - INFO - training batch 301, loss: 1.238, 9632/28000 datapoints
2025-03-07 09:53:26,892 - INFO - training batch 351, loss: 1.129, 11232/28000 datapoints
2025-03-07 09:53:27,345 - INFO - training batch 401, loss: 1.214, 12832/28000 datapoints
2025-03-07 09:53:27,700 - INFO - training batch 451, loss: 1.158, 14432/28000 datapoints
2025-03-07 09:53:28,049 - INFO - training batch 501, loss: 1.006, 16032/28000 datapoints
2025-03-07 09:53:28,394 - INFO - training batch 551, loss: 1.164, 17632/28000 datapoints
2025-03-07 09:53:28,756 - INFO - training batch 601, loss: 1.405, 19232/28000 datapoints
2025-03-07 09:53:29,146 - INFO - training batch 651, loss: 0.778, 20832/28000 datapoints
2025-03-07 09:53:29,543 - INFO - training batch 701, loss: 0.999, 22432/28000 datapoints
2025-03-07 09:53:29,907 - INFO - training batch 751, loss: 1.169, 24032/28000 datapoints
2025-03-07 09:53:30,327 - INFO - training batch 801, loss: 0.870, 25632/28000 datapoints
2025-03-07 09:53:30,869 - INFO - training batch 851, loss: 1.139, 27232/28000 datapoints
2025-03-07 09:53:31,067 - INFO - validation batch 1, loss: 0.765, 32/6976 datapoints
2025-03-07 09:53:31,178 - INFO - validation batch 51, loss: 1.636, 1632/6976 datapoints
2025-03-07 09:53:31,329 - INFO - validation batch 101, loss: 1.088, 3232/6976 datapoints
2025-03-07 09:53:31,417 - INFO - validation batch 151, loss: 1.283, 4832/6976 datapoints
2025-03-07 09:53:31,680 - INFO - validation batch 201, loss: 0.775, 6432/6976 datapoints
2025-03-07 09:53:31,720 - INFO - Epoch 28/800 done.
2025-03-07 09:53:31,720 - INFO - Final validation performance:
Loss: 1.109, top-1 acc: 0.628top-5 acc: 0.628
2025-03-07 09:53:31,721 - INFO - Beginning epoch 29/800
2025-03-07 09:53:31,730 - INFO - training batch 1, loss: 1.186, 32/28000 datapoints
2025-03-07 09:53:32,064 - INFO - training batch 51, loss: 1.226, 1632/28000 datapoints
2025-03-07 09:53:32,465 - INFO - training batch 101, loss: 0.841, 3232/28000 datapoints
2025-03-07 09:53:32,880 - INFO - training batch 151, loss: 1.324, 4832/28000 datapoints
2025-03-07 09:53:33,307 - INFO - training batch 201, loss: 1.295, 6432/28000 datapoints
2025-03-07 09:53:33,655 - INFO - training batch 251, loss: 0.909, 8032/28000 datapoints
2025-03-07 09:53:34,030 - INFO - training batch 301, loss: 1.189, 9632/28000 datapoints
2025-03-07 09:53:34,387 - INFO - training batch 351, loss: 1.076, 11232/28000 datapoints
2025-03-07 09:53:34,747 - INFO - training batch 401, loss: 1.186, 12832/28000 datapoints
2025-03-07 09:53:35,135 - INFO - training batch 451, loss: 1.124, 14432/28000 datapoints
2025-03-07 09:53:35,480 - INFO - training batch 501, loss: 0.974, 16032/28000 datapoints
2025-03-07 09:53:35,845 - INFO - training batch 551, loss: 1.131, 17632/28000 datapoints
2025-03-07 09:53:36,209 - INFO - training batch 601, loss: 1.401, 19232/28000 datapoints
2025-03-07 09:53:36,607 - INFO - training batch 651, loss: 0.747, 20832/28000 datapoints
2025-03-07 09:53:37,002 - INFO - training batch 701, loss: 0.971, 22432/28000 datapoints
2025-03-07 09:53:37,318 - INFO - training batch 751, loss: 1.108, 24032/28000 datapoints
2025-03-07 09:53:37,681 - INFO - training batch 801, loss: 0.829, 25632/28000 datapoints
2025-03-07 09:53:38,020 - INFO - training batch 851, loss: 1.123, 27232/28000 datapoints
2025-03-07 09:53:38,190 - INFO - validation batch 1, loss: 0.727, 32/6976 datapoints
2025-03-07 09:53:38,307 - INFO - validation batch 51, loss: 1.613, 1632/6976 datapoints
2025-03-07 09:53:38,411 - INFO - validation batch 101, loss: 1.039, 3232/6976 datapoints
2025-03-07 09:53:38,502 - INFO - validation batch 151, loss: 1.227, 4832/6976 datapoints
2025-03-07 09:53:38,597 - INFO - validation batch 201, loss: 0.756, 6432/6976 datapoints
2025-03-07 09:53:38,635 - INFO - Epoch 29/800 done.
2025-03-07 09:53:38,635 - INFO - Final validation performance:
Loss: 1.073, top-1 acc: 0.645top-5 acc: 0.645
2025-03-07 09:53:38,636 - INFO - Beginning epoch 30/800
2025-03-07 09:53:38,645 - INFO - training batch 1, loss: 1.135, 32/28000 datapoints
2025-03-07 09:53:38,997 - INFO - training batch 51, loss: 1.177, 1632/28000 datapoints
2025-03-07 09:53:39,483 - INFO - training batch 101, loss: 0.803, 3232/28000 datapoints
2025-03-07 09:53:39,822 - INFO - training batch 151, loss: 1.287, 4832/28000 datapoints
2025-03-07 09:53:40,305 - INFO - training batch 201, loss: 1.247, 6432/28000 datapoints
2025-03-07 09:53:40,681 - INFO - training batch 251, loss: 0.870, 8032/28000 datapoints
2025-03-07 09:53:41,140 - INFO - training batch 301, loss: 1.138, 9632/28000 datapoints
2025-03-07 09:53:41,582 - INFO - training batch 351, loss: 1.023, 11232/28000 datapoints
2025-03-07 09:53:41,911 - INFO - training batch 401, loss: 1.159, 12832/28000 datapoints
2025-03-07 09:53:42,339 - INFO - training batch 451, loss: 1.091, 14432/28000 datapoints
2025-03-07 09:53:42,673 - INFO - training batch 501, loss: 0.941, 16032/28000 datapoints
2025-03-07 09:53:44,535 - INFO - training batch 551, loss: 1.099, 17632/28000 datapoints
2025-03-07 09:53:45,576 - INFO - training batch 601, loss: 1.396, 19232/28000 datapoints
2025-03-07 09:53:46,319 - INFO - training batch 651, loss: 0.715, 20832/28000 datapoints
2025-03-07 09:53:46,913 - INFO - training batch 701, loss: 0.942, 22432/28000 datapoints
2025-03-07 09:53:47,336 - INFO - training batch 751, loss: 1.043, 24032/28000 datapoints
2025-03-07 09:53:47,739 - INFO - training batch 801, loss: 0.788, 25632/28000 datapoints
2025-03-07 09:53:48,081 - INFO - training batch 851, loss: 1.110, 27232/28000 datapoints
2025-03-07 09:53:48,246 - INFO - validation batch 1, loss: 0.689, 32/6976 datapoints
2025-03-07 09:53:48,339 - INFO - validation batch 51, loss: 1.591, 1632/6976 datapoints
2025-03-07 09:53:48,436 - INFO - validation batch 101, loss: 0.988, 3232/6976 datapoints
2025-03-07 09:53:48,533 - INFO - validation batch 151, loss: 1.171, 4832/6976 datapoints
2025-03-07 09:53:48,650 - INFO - validation batch 201, loss: 0.741, 6432/6976 datapoints
2025-03-07 09:53:48,684 - INFO - Epoch 30/800 done.
2025-03-07 09:53:48,685 - INFO - Final validation performance:
Loss: 1.036, top-1 acc: 0.663top-5 acc: 0.663
2025-03-07 09:53:48,686 - INFO - Beginning epoch 31/800
2025-03-07 09:53:48,696 - INFO - training batch 1, loss: 1.085, 32/28000 datapoints
2025-03-07 09:53:49,067 - INFO - training batch 51, loss: 1.126, 1632/28000 datapoints
2025-03-07 09:53:49,427 - INFO - training batch 101, loss: 0.765, 3232/28000 datapoints
2025-03-07 09:53:49,825 - INFO - training batch 151, loss: 1.253, 4832/28000 datapoints
2025-03-07 09:53:50,173 - INFO - training batch 201, loss: 1.192, 6432/28000 datapoints
2025-03-07 09:53:50,559 - INFO - training batch 251, loss: 0.834, 8032/28000 datapoints
2025-03-07 09:53:50,953 - INFO - training batch 301, loss: 1.085, 9632/28000 datapoints
2025-03-07 09:53:51,413 - INFO - training batch 351, loss: 0.971, 11232/28000 datapoints
2025-03-07 09:53:51,765 - INFO - training batch 401, loss: 1.135, 12832/28000 datapoints
2025-03-07 09:53:52,297 - INFO - training batch 451, loss: 1.056, 14432/28000 datapoints
2025-03-07 09:53:53,113 - INFO - training batch 501, loss: 0.906, 16032/28000 datapoints
2025-03-07 09:53:53,493 - INFO - training batch 551, loss: 1.067, 17632/28000 datapoints
2025-03-07 09:53:54,080 - INFO - training batch 601, loss: 1.392, 19232/28000 datapoints
2025-03-07 09:53:54,489 - INFO - training batch 651, loss: 0.683, 20832/28000 datapoints
2025-03-07 09:53:54,880 - INFO - training batch 701, loss: 0.913, 22432/28000 datapoints
2025-03-07 09:53:55,242 - INFO - training batch 751, loss: 0.975, 24032/28000 datapoints
2025-03-07 09:53:55,576 - INFO - training batch 801, loss: 0.747, 25632/28000 datapoints
2025-03-07 09:53:55,962 - INFO - training batch 851, loss: 1.097, 27232/28000 datapoints
2025-03-07 09:53:56,120 - INFO - validation batch 1, loss: 0.650, 32/6976 datapoints
2025-03-07 09:53:56,214 - INFO - validation batch 51, loss: 1.572, 1632/6976 datapoints
2025-03-07 09:53:56,307 - INFO - validation batch 101, loss: 0.935, 3232/6976 datapoints
2025-03-07 09:53:56,403 - INFO - validation batch 151, loss: 1.116, 4832/6976 datapoints
2025-03-07 09:53:56,500 - INFO - validation batch 201, loss: 0.727, 6432/6976 datapoints
2025-03-07 09:53:56,538 - INFO - Epoch 31/800 done.
2025-03-07 09:53:56,539 - INFO - Final validation performance:
Loss: 1.000, top-1 acc: 0.681top-5 acc: 0.681
2025-03-07 09:53:56,540 - INFO - Beginning epoch 32/800
2025-03-07 09:53:56,551 - INFO - training batch 1, loss: 1.036, 32/28000 datapoints
2025-03-07 09:53:56,906 - INFO - training batch 51, loss: 1.074, 1632/28000 datapoints
2025-03-07 09:53:57,261 - INFO - training batch 101, loss: 0.726, 3232/28000 datapoints
2025-03-07 09:53:57,655 - INFO - training batch 151, loss: 1.221, 4832/28000 datapoints
2025-03-07 09:53:58,030 - INFO - training batch 201, loss: 1.133, 6432/28000 datapoints
2025-03-07 09:53:58,354 - INFO - training batch 251, loss: 0.799, 8032/28000 datapoints
2025-03-07 09:53:58,706 - INFO - training batch 301, loss: 1.033, 9632/28000 datapoints
2025-03-07 09:53:59,163 - INFO - training batch 351, loss: 0.923, 11232/28000 datapoints
2025-03-07 09:53:59,925 - INFO - training batch 401, loss: 1.112, 12832/28000 datapoints
2025-03-07 09:54:01,055 - INFO - training batch 451, loss: 1.022, 14432/28000 datapoints
2025-03-07 09:54:01,458 - INFO - training batch 501, loss: 0.869, 16032/28000 datapoints
2025-03-07 09:54:01,893 - INFO - training batch 551, loss: 1.034, 17632/28000 datapoints
2025-03-07 09:54:02,313 - INFO - training batch 601, loss: 1.382, 19232/28000 datapoints
2025-03-07 09:54:02,772 - INFO - training batch 651, loss: 0.654, 20832/28000 datapoints
2025-03-07 09:54:03,295 - INFO - training batch 701, loss: 0.883, 22432/28000 datapoints
2025-03-07 09:54:03,637 - INFO - training batch 751, loss: 0.907, 24032/28000 datapoints
2025-03-07 09:54:04,026 - INFO - training batch 801, loss: 0.707, 25632/28000 datapoints
2025-03-07 09:54:04,364 - INFO - training batch 851, loss: 1.086, 27232/28000 datapoints
2025-03-07 09:54:04,547 - INFO - validation batch 1, loss: 0.609, 32/6976 datapoints
2025-03-07 09:54:04,645 - INFO - validation batch 51, loss: 1.555, 1632/6976 datapoints
2025-03-07 09:54:04,767 - INFO - validation batch 101, loss: 0.882, 3232/6976 datapoints
2025-03-07 09:54:04,881 - INFO - validation batch 151, loss: 1.063, 4832/6976 datapoints
2025-03-07 09:54:04,992 - INFO - validation batch 201, loss: 0.715, 6432/6976 datapoints
2025-03-07 09:54:05,036 - INFO - Epoch 32/800 done.
2025-03-07 09:54:05,037 - INFO - Final validation performance:
Loss: 0.965, top-1 acc: 0.696top-5 acc: 0.696
2025-03-07 09:54:05,038 - INFO - Beginning epoch 33/800
2025-03-07 09:54:05,053 - INFO - training batch 1, loss: 0.987, 32/28000 datapoints
2025-03-07 09:54:05,426 - INFO - training batch 51, loss: 1.022, 1632/28000 datapoints
2025-03-07 09:54:05,772 - INFO - training batch 101, loss: 0.688, 3232/28000 datapoints
2025-03-07 09:54:06,128 - INFO - training batch 151, loss: 1.193, 4832/28000 datapoints
2025-03-07 09:54:06,527 - INFO - training batch 201, loss: 1.071, 6432/28000 datapoints
2025-03-07 09:54:06,873 - INFO - training batch 251, loss: 0.767, 8032/28000 datapoints
2025-03-07 09:54:07,241 - INFO - training batch 301, loss: 0.983, 9632/28000 datapoints
2025-03-07 09:54:07,593 - INFO - training batch 351, loss: 0.879, 11232/28000 datapoints
2025-03-07 09:54:07,945 - INFO - training batch 401, loss: 1.091, 12832/28000 datapoints
2025-03-07 09:54:08,375 - INFO - training batch 451, loss: 0.988, 14432/28000 datapoints
2025-03-07 09:54:09,391 - INFO - training batch 501, loss: 0.832, 16032/28000 datapoints
2025-03-07 09:54:09,933 - INFO - training batch 551, loss: 1.003, 17632/28000 datapoints
2025-03-07 09:54:10,342 - INFO - training batch 601, loss: 1.370, 19232/28000 datapoints
2025-03-07 09:54:10,854 - INFO - training batch 651, loss: 0.626, 20832/28000 datapoints
2025-03-07 09:54:11,478 - INFO - training batch 701, loss: 0.853, 22432/28000 datapoints
2025-03-07 09:54:11,818 - INFO - training batch 751, loss: 0.839, 24032/28000 datapoints
2025-03-07 09:54:12,145 - INFO - training batch 801, loss: 0.669, 25632/28000 datapoints
2025-03-07 09:54:12,507 - INFO - training batch 851, loss: 1.076, 27232/28000 datapoints
2025-03-07 09:54:12,746 - INFO - validation batch 1, loss: 0.570, 32/6976 datapoints
2025-03-07 09:54:12,898 - INFO - validation batch 51, loss: 1.542, 1632/6976 datapoints
2025-03-07 09:54:13,222 - INFO - validation batch 101, loss: 0.829, 3232/6976 datapoints
2025-03-07 09:54:13,321 - INFO - validation batch 151, loss: 1.012, 4832/6976 datapoints
2025-03-07 09:54:13,444 - INFO - validation batch 201, loss: 0.705, 6432/6976 datapoints
2025-03-07 09:54:13,484 - INFO - Epoch 33/800 done.
2025-03-07 09:54:13,485 - INFO - Final validation performance:
Loss: 0.932, top-1 acc: 0.711top-5 acc: 0.711
2025-03-07 09:54:13,485 - INFO - Beginning epoch 34/800
2025-03-07 09:54:13,497 - INFO - training batch 1, loss: 0.940, 32/28000 datapoints
2025-03-07 09:54:13,837 - INFO - training batch 51, loss: 0.971, 1632/28000 datapoints
2025-03-07 09:54:14,183 - INFO - training batch 101, loss: 0.651, 3232/28000 datapoints
2025-03-07 09:54:14,520 - INFO - training batch 151, loss: 1.168, 4832/28000 datapoints
2025-03-07 09:54:14,987 - INFO - training batch 201, loss: 1.018, 6432/28000 datapoints
2025-03-07 09:54:15,324 - INFO - training batch 251, loss: 0.738, 8032/28000 datapoints
2025-03-07 09:54:15,659 - INFO - training batch 301, loss: 0.936, 9632/28000 datapoints
2025-03-07 09:54:16,034 - INFO - training batch 351, loss: 0.838, 11232/28000 datapoints
2025-03-07 09:54:16,397 - INFO - training batch 401, loss: 1.072, 12832/28000 datapoints
2025-03-07 09:54:16,767 - INFO - training batch 451, loss: 0.954, 14432/28000 datapoints
2025-03-07 09:54:17,162 - INFO - training batch 501, loss: 0.795, 16032/28000 datapoints
2025-03-07 09:54:17,483 - INFO - training batch 551, loss: 0.972, 17632/28000 datapoints
2025-03-07 09:54:17,841 - INFO - training batch 601, loss: 1.355, 19232/28000 datapoints
2025-03-07 09:54:18,165 - INFO - training batch 651, loss: 0.601, 20832/28000 datapoints
2025-03-07 09:54:18,503 - INFO - training batch 701, loss: 0.823, 22432/28000 datapoints
2025-03-07 09:54:18,846 - INFO - training batch 751, loss: 0.775, 24032/28000 datapoints
2025-03-07 09:54:19,181 - INFO - training batch 801, loss: 0.633, 25632/28000 datapoints
2025-03-07 09:54:19,511 - INFO - training batch 851, loss: 1.066, 27232/28000 datapoints
2025-03-07 09:54:19,680 - INFO - validation batch 1, loss: 0.532, 32/6976 datapoints
2025-03-07 09:54:19,776 - INFO - validation batch 51, loss: 1.532, 1632/6976 datapoints
2025-03-07 09:54:19,872 - INFO - validation batch 101, loss: 0.777, 3232/6976 datapoints
2025-03-07 09:54:19,964 - INFO - validation batch 151, loss: 0.966, 4832/6976 datapoints
2025-03-07 09:54:20,092 - INFO - validation batch 201, loss: 0.698, 6432/6976 datapoints
2025-03-07 09:54:20,141 - INFO - Epoch 34/800 done.
2025-03-07 09:54:20,142 - INFO - Final validation performance:
Loss: 0.901, top-1 acc: 0.726top-5 acc: 0.726
2025-03-07 09:54:20,143 - INFO - Beginning epoch 35/800
2025-03-07 09:54:20,152 - INFO - training batch 1, loss: 0.894, 32/28000 datapoints
2025-03-07 09:54:20,489 - INFO - training batch 51, loss: 0.921, 1632/28000 datapoints
2025-03-07 09:54:20,866 - INFO - training batch 101, loss: 0.615, 3232/28000 datapoints
2025-03-07 09:54:21,196 - INFO - training batch 151, loss: 1.146, 4832/28000 datapoints
2025-03-07 09:54:21,516 - INFO - training batch 201, loss: 0.969, 6432/28000 datapoints
2025-03-07 09:54:21,904 - INFO - training batch 251, loss: 0.711, 8032/28000 datapoints
2025-03-07 09:54:22,267 - INFO - training batch 301, loss: 0.894, 9632/28000 datapoints
2025-03-07 09:54:22,591 - INFO - training batch 351, loss: 0.802, 11232/28000 datapoints
2025-03-07 09:54:22,928 - INFO - training batch 401, loss: 1.054, 12832/28000 datapoints
2025-03-07 09:54:23,289 - INFO - training batch 451, loss: 0.922, 14432/28000 datapoints
2025-03-07 09:54:23,644 - INFO - training batch 501, loss: 0.758, 16032/28000 datapoints
2025-03-07 09:54:24,116 - INFO - training batch 551, loss: 0.943, 17632/28000 datapoints
2025-03-07 09:54:24,494 - INFO - training batch 601, loss: 1.338, 19232/28000 datapoints
2025-03-07 09:54:24,826 - INFO - training batch 651, loss: 0.577, 20832/28000 datapoints
2025-03-07 09:54:25,160 - INFO - training batch 701, loss: 0.795, 22432/28000 datapoints
2025-03-07 09:54:25,516 - INFO - training batch 751, loss: 0.714, 24032/28000 datapoints
2025-03-07 09:54:25,916 - INFO - training batch 801, loss: 0.601, 25632/28000 datapoints
2025-03-07 09:54:26,267 - INFO - training batch 851, loss: 1.058, 27232/28000 datapoints
2025-03-07 09:54:26,434 - INFO - validation batch 1, loss: 0.497, 32/6976 datapoints
2025-03-07 09:54:26,526 - INFO - validation batch 51, loss: 1.523, 1632/6976 datapoints
2025-03-07 09:54:26,621 - INFO - validation batch 101, loss: 0.726, 3232/6976 datapoints
2025-03-07 09:54:26,795 - INFO - validation batch 151, loss: 0.923, 4832/6976 datapoints
2025-03-07 09:54:26,925 - INFO - validation batch 201, loss: 0.695, 6432/6976 datapoints
2025-03-07 09:54:26,960 - INFO - Epoch 35/800 done.
2025-03-07 09:54:26,961 - INFO - Final validation performance:
Loss: 0.873, top-1 acc: 0.739top-5 acc: 0.739
2025-03-07 09:54:26,962 - INFO - Beginning epoch 36/800
2025-03-07 09:54:26,973 - INFO - training batch 1, loss: 0.851, 32/28000 datapoints
2025-03-07 09:54:27,458 - INFO - training batch 51, loss: 0.876, 1632/28000 datapoints
2025-03-07 09:54:27,945 - INFO - training batch 101, loss: 0.581, 3232/28000 datapoints
2025-03-07 09:54:28,428 - INFO - training batch 151, loss: 1.126, 4832/28000 datapoints
2025-03-07 09:54:28,812 - INFO - training batch 201, loss: 0.924, 6432/28000 datapoints
2025-03-07 09:54:29,211 - INFO - training batch 251, loss: 0.687, 8032/28000 datapoints
2025-03-07 09:54:29,703 - INFO - training batch 301, loss: 0.856, 9632/28000 datapoints
2025-03-07 09:54:30,206 - INFO - training batch 351, loss: 0.766, 11232/28000 datapoints
2025-03-07 09:54:30,718 - INFO - training batch 401, loss: 1.038, 12832/28000 datapoints
2025-03-07 09:54:31,064 - INFO - training batch 451, loss: 0.891, 14432/28000 datapoints
2025-03-07 09:54:31,613 - INFO - training batch 501, loss: 0.719, 16032/28000 datapoints
2025-03-07 09:54:32,286 - INFO - training batch 551, loss: 0.913, 17632/28000 datapoints
2025-03-07 09:54:32,630 - INFO - training batch 601, loss: 1.317, 19232/28000 datapoints
2025-03-07 09:54:33,047 - INFO - training batch 651, loss: 0.556, 20832/28000 datapoints
2025-03-07 09:54:33,392 - INFO - training batch 701, loss: 0.768, 22432/28000 datapoints
2025-03-07 09:54:33,926 - INFO - training batch 751, loss: 0.656, 24032/28000 datapoints
2025-03-07 09:54:34,347 - INFO - training batch 801, loss: 0.571, 25632/28000 datapoints
2025-03-07 09:54:34,760 - INFO - training batch 851, loss: 1.053, 27232/28000 datapoints
2025-03-07 09:54:35,012 - INFO - validation batch 1, loss: 0.465, 32/6976 datapoints
2025-03-07 09:54:35,120 - INFO - validation batch 51, loss: 1.512, 1632/6976 datapoints
2025-03-07 09:54:35,229 - INFO - validation batch 101, loss: 0.677, 3232/6976 datapoints
2025-03-07 09:54:35,354 - INFO - validation batch 151, loss: 0.886, 4832/6976 datapoints
2025-03-07 09:54:35,476 - INFO - validation batch 201, loss: 0.696, 6432/6976 datapoints
2025-03-07 09:54:35,514 - INFO - Epoch 36/800 done.
2025-03-07 09:54:35,515 - INFO - Final validation performance:
Loss: 0.847, top-1 acc: 0.753top-5 acc: 0.753
2025-03-07 09:54:35,516 - INFO - Beginning epoch 37/800
2025-03-07 09:54:35,526 - INFO - training batch 1, loss: 0.809, 32/28000 datapoints
2025-03-07 09:54:35,919 - INFO - training batch 51, loss: 0.833, 1632/28000 datapoints
2025-03-07 09:54:36,270 - INFO - training batch 101, loss: 0.548, 3232/28000 datapoints
2025-03-07 09:54:36,679 - INFO - training batch 151, loss: 1.108, 4832/28000 datapoints
2025-03-07 09:54:37,101 - INFO - training batch 201, loss: 0.884, 6432/28000 datapoints
2025-03-07 09:54:37,469 - INFO - training batch 251, loss: 0.667, 8032/28000 datapoints
2025-03-07 09:54:37,828 - INFO - training batch 301, loss: 0.821, 9632/28000 datapoints
2025-03-07 09:54:38,218 - INFO - training batch 351, loss: 0.735, 11232/28000 datapoints
2025-03-07 09:54:38,581 - INFO - training batch 401, loss: 1.025, 12832/28000 datapoints
2025-03-07 09:54:38,982 - INFO - training batch 451, loss: 0.862, 14432/28000 datapoints
2025-03-07 09:54:39,369 - INFO - training batch 501, loss: 0.682, 16032/28000 datapoints
2025-03-07 09:54:39,715 - INFO - training batch 551, loss: 0.886, 17632/28000 datapoints
2025-03-07 09:54:40,089 - INFO - training batch 601, loss: 1.295, 19232/28000 datapoints
2025-03-07 09:54:40,595 - INFO - training batch 651, loss: 0.536, 20832/28000 datapoints
2025-03-07 09:54:41,401 - INFO - training batch 701, loss: 0.742, 22432/28000 datapoints
2025-03-07 09:54:41,794 - INFO - training batch 751, loss: 0.602, 24032/28000 datapoints
2025-03-07 09:54:42,118 - INFO - training batch 801, loss: 0.545, 25632/28000 datapoints
2025-03-07 09:54:42,473 - INFO - training batch 851, loss: 1.046, 27232/28000 datapoints
2025-03-07 09:54:42,658 - INFO - validation batch 1, loss: 0.435, 32/6976 datapoints
2025-03-07 09:54:42,770 - INFO - validation batch 51, loss: 1.498, 1632/6976 datapoints
2025-03-07 09:54:42,869 - INFO - validation batch 101, loss: 0.632, 3232/6976 datapoints
2025-03-07 09:54:42,962 - INFO - validation batch 151, loss: 0.852, 4832/6976 datapoints
2025-03-07 09:54:43,068 - INFO - validation batch 201, loss: 0.699, 6432/6976 datapoints
2025-03-07 09:54:43,107 - INFO - Epoch 37/800 done.
2025-03-07 09:54:43,107 - INFO - Final validation performance:
Loss: 0.823, top-1 acc: 0.765top-5 acc: 0.765
2025-03-07 09:54:43,108 - INFO - Beginning epoch 38/800
2025-03-07 09:54:43,118 - INFO - training batch 1, loss: 0.769, 32/28000 datapoints
2025-03-07 09:54:43,505 - INFO - training batch 51, loss: 0.796, 1632/28000 datapoints
2025-03-07 09:54:43,856 - INFO - training batch 101, loss: 0.518, 3232/28000 datapoints
2025-03-07 09:54:44,258 - INFO - training batch 151, loss: 1.091, 4832/28000 datapoints
2025-03-07 09:54:44,630 - INFO - training batch 201, loss: 0.852, 6432/28000 datapoints
2025-03-07 09:54:45,019 - INFO - training batch 251, loss: 0.648, 8032/28000 datapoints
2025-03-07 09:54:45,482 - INFO - training batch 301, loss: 0.791, 9632/28000 datapoints
2025-03-07 09:54:45,914 - INFO - training batch 351, loss: 0.706, 11232/28000 datapoints
2025-03-07 09:54:46,233 - INFO - training batch 401, loss: 1.012, 12832/28000 datapoints
2025-03-07 09:54:46,593 - INFO - training batch 451, loss: 0.833, 14432/28000 datapoints
2025-03-07 09:54:46,948 - INFO - training batch 501, loss: 0.646, 16032/28000 datapoints
2025-03-07 09:54:47,293 - INFO - training batch 551, loss: 0.860, 17632/28000 datapoints
2025-03-07 09:54:47,629 - INFO - training batch 601, loss: 1.271, 19232/28000 datapoints
2025-03-07 09:54:47,984 - INFO - training batch 651, loss: 0.516, 20832/28000 datapoints
2025-03-07 09:54:48,330 - INFO - training batch 701, loss: 0.717, 22432/28000 datapoints
2025-03-07 09:54:48,671 - INFO - training batch 751, loss: 0.555, 24032/28000 datapoints
2025-03-07 09:54:49,021 - INFO - training batch 801, loss: 0.522, 25632/28000 datapoints
2025-03-07 09:54:49,394 - INFO - training batch 851, loss: 1.038, 27232/28000 datapoints
2025-03-07 09:54:49,578 - INFO - validation batch 1, loss: 0.407, 32/6976 datapoints
2025-03-07 09:54:49,693 - INFO - validation batch 51, loss: 1.486, 1632/6976 datapoints
2025-03-07 09:54:49,834 - INFO - validation batch 101, loss: 0.591, 3232/6976 datapoints
2025-03-07 09:54:49,945 - INFO - validation batch 151, loss: 0.823, 4832/6976 datapoints
2025-03-07 09:54:50,057 - INFO - validation batch 201, loss: 0.705, 6432/6976 datapoints
2025-03-07 09:54:50,147 - INFO - Epoch 38/800 done.
2025-03-07 09:54:50,148 - INFO - Final validation performance:
Loss: 0.802, top-1 acc: 0.776top-5 acc: 0.776
2025-03-07 09:54:50,149 - INFO - Beginning epoch 39/800
2025-03-07 09:54:50,167 - INFO - training batch 1, loss: 0.732, 32/28000 datapoints
2025-03-07 09:54:50,821 - INFO - training batch 51, loss: 0.761, 1632/28000 datapoints
2025-03-07 09:54:51,454 - INFO - training batch 101, loss: 0.492, 3232/28000 datapoints
2025-03-07 09:54:53,230 - INFO - training batch 151, loss: 1.076, 4832/28000 datapoints
2025-03-07 09:54:54,226 - INFO - training batch 201, loss: 0.822, 6432/28000 datapoints
2025-03-07 09:54:56,348 - INFO - training batch 251, loss: 0.631, 8032/28000 datapoints
2025-03-07 09:54:58,297 - INFO - training batch 301, loss: 0.765, 9632/28000 datapoints
2025-03-07 09:54:58,907 - INFO - training batch 351, loss: 0.678, 11232/28000 datapoints
2025-03-07 09:54:59,404 - INFO - training batch 401, loss: 1.000, 12832/28000 datapoints
2025-03-07 09:54:59,850 - INFO - training batch 451, loss: 0.807, 14432/28000 datapoints
2025-03-07 09:55:00,233 - INFO - training batch 501, loss: 0.613, 16032/28000 datapoints
2025-03-07 09:55:00,599 - INFO - training batch 551, loss: 0.836, 17632/28000 datapoints
2025-03-07 09:55:01,069 - INFO - training batch 601, loss: 1.246, 19232/28000 datapoints
2025-03-07 09:55:01,452 - INFO - training batch 651, loss: 0.499, 20832/28000 datapoints
2025-03-07 09:55:01,907 - INFO - training batch 701, loss: 0.694, 22432/28000 datapoints
2025-03-07 09:55:02,317 - INFO - training batch 751, loss: 0.512, 24032/28000 datapoints
2025-03-07 09:55:02,735 - INFO - training batch 801, loss: 0.501, 25632/28000 datapoints
2025-03-07 09:55:03,100 - INFO - training batch 851, loss: 1.031, 27232/28000 datapoints
2025-03-07 09:55:03,310 - INFO - validation batch 1, loss: 0.382, 32/6976 datapoints
2025-03-07 09:55:03,454 - INFO - validation batch 51, loss: 1.476, 1632/6976 datapoints
2025-03-07 09:55:03,603 - INFO - validation batch 101, loss: 0.554, 3232/6976 datapoints
2025-03-07 09:55:03,744 - INFO - validation batch 151, loss: 0.798, 4832/6976 datapoints
2025-03-07 09:55:03,883 - INFO - validation batch 201, loss: 0.714, 6432/6976 datapoints
2025-03-07 09:55:03,934 - INFO - Epoch 39/800 done.
2025-03-07 09:55:03,935 - INFO - Final validation performance:
Loss: 0.785, top-1 acc: 0.783top-5 acc: 0.783
2025-03-07 09:55:03,938 - INFO - Beginning epoch 40/800
2025-03-07 09:55:03,950 - INFO - training batch 1, loss: 0.698, 32/28000 datapoints
2025-03-07 09:55:04,345 - INFO - training batch 51, loss: 0.727, 1632/28000 datapoints
2025-03-07 09:55:04,711 - INFO - training batch 101, loss: 0.468, 3232/28000 datapoints
2025-03-07 09:55:05,062 - INFO - training batch 151, loss: 1.061, 4832/28000 datapoints
2025-03-07 09:55:05,413 - INFO - training batch 201, loss: 0.794, 6432/28000 datapoints
2025-03-07 09:55:05,855 - INFO - training batch 251, loss: 0.617, 8032/28000 datapoints
2025-03-07 09:55:06,234 - INFO - training batch 301, loss: 0.742, 9632/28000 datapoints
2025-03-07 09:55:06,599 - INFO - training batch 351, loss: 0.656, 11232/28000 datapoints
2025-03-07 09:55:06,985 - INFO - training batch 401, loss: 0.987, 12832/28000 datapoints
2025-03-07 09:55:07,412 - INFO - training batch 451, loss: 0.782, 14432/28000 datapoints
2025-03-07 09:55:08,081 - INFO - training batch 501, loss: 0.581, 16032/28000 datapoints
2025-03-07 09:55:09,187 - INFO - training batch 551, loss: 0.814, 17632/28000 datapoints
2025-03-07 09:55:09,657 - INFO - training batch 601, loss: 1.224, 19232/28000 datapoints
2025-03-07 09:55:10,224 - INFO - training batch 651, loss: 0.483, 20832/28000 datapoints
2025-03-07 09:55:10,708 - INFO - training batch 701, loss: 0.672, 22432/28000 datapoints
2025-03-07 09:55:11,233 - INFO - training batch 751, loss: 0.474, 24032/28000 datapoints
2025-03-07 09:55:11,580 - INFO - training batch 801, loss: 0.483, 25632/28000 datapoints
2025-03-07 09:55:11,977 - INFO - training batch 851, loss: 1.024, 27232/28000 datapoints
2025-03-07 09:55:12,217 - INFO - validation batch 1, loss: 0.359, 32/6976 datapoints
2025-03-07 09:55:12,339 - INFO - validation batch 51, loss: 1.466, 1632/6976 datapoints
2025-03-07 09:55:12,439 - INFO - validation batch 101, loss: 0.520, 3232/6976 datapoints
2025-03-07 09:55:12,690 - INFO - validation batch 201, loss: 0.725, 6432/6976 datapoints
2025-03-07 09:55:12,792 - INFO - Epoch 40/800 done.
2025-03-07 09:55:12,792 - INFO - Final validation performance:
Loss: 0.769, top-1 acc: 0.789top-5 acc: 0.789
2025-03-07 09:55:12,794 - INFO - Beginning epoch 41/800
2025-03-07 09:55:12,807 - INFO - training batch 1, loss: 0.666, 32/28000 datapoints
2025-03-07 09:55:13,996 - INFO - training batch 51, loss: 0.696, 1632/28000 datapoints
2025-03-07 09:55:14,327 - INFO - training batch 101, loss: 0.448, 3232/28000 datapoints
2025-03-07 09:55:14,699 - INFO - training batch 151, loss: 1.046, 4832/28000 datapoints
2025-03-07 09:55:15,076 - INFO - training batch 201, loss: 0.767, 6432/28000 datapoints
2025-03-07 09:55:15,459 - INFO - training batch 251, loss: 0.605, 8032/28000 datapoints
2025-03-07 09:55:15,852 - INFO - training batch 301, loss: 0.722, 9632/28000 datapoints
2025-03-07 09:55:16,204 - INFO - training batch 351, loss: 0.636, 11232/28000 datapoints
2025-03-07 09:55:16,605 - INFO - training batch 401, loss: 0.974, 12832/28000 datapoints
2025-03-07 09:55:16,917 - INFO - training batch 451, loss: 0.759, 14432/28000 datapoints
2025-03-07 09:55:17,346 - INFO - training batch 501, loss: 0.553, 16032/28000 datapoints
2025-03-07 09:55:17,671 - INFO - training batch 551, loss: 0.793, 17632/28000 datapoints
2025-03-07 09:55:18,133 - INFO - training batch 601, loss: 1.202, 19232/28000 datapoints
2025-03-07 09:55:18,509 - INFO - training batch 651, loss: 0.468, 20832/28000 datapoints
2025-03-07 09:55:19,026 - INFO - training batch 701, loss: 0.652, 22432/28000 datapoints
2025-03-07 09:55:19,836 - INFO - training batch 751, loss: 0.443, 24032/28000 datapoints
2025-03-07 09:55:20,286 - INFO - training batch 801, loss: 0.467, 25632/28000 datapoints
2025-03-07 09:55:20,841 - INFO - training batch 851, loss: 1.018, 27232/28000 datapoints
2025-03-07 09:55:21,065 - INFO - validation batch 1, loss: 0.339, 32/6976 datapoints
2025-03-07 09:55:21,224 - INFO - validation batch 51, loss: 1.456, 1632/6976 datapoints
2025-03-07 09:55:21,355 - INFO - validation batch 101, loss: 0.489, 3232/6976 datapoints
2025-03-07 09:55:21,477 - INFO - validation batch 151, loss: 0.756, 4832/6976 datapoints
2025-03-07 09:55:21,663 - INFO - validation batch 201, loss: 0.736, 6432/6976 datapoints
2025-03-07 09:55:21,733 - INFO - Epoch 41/800 done.
2025-03-07 09:55:21,734 - INFO - Final validation performance:
Loss: 0.755, top-1 acc: 0.797top-5 acc: 0.797
2025-03-07 09:55:21,735 - INFO - Beginning epoch 42/800
2025-03-07 09:55:21,753 - INFO - training batch 1, loss: 0.636, 32/28000 datapoints
2025-03-07 09:55:22,264 - INFO - training batch 51, loss: 0.668, 1632/28000 datapoints
2025-03-07 09:55:22,591 - INFO - training batch 101, loss: 0.431, 3232/28000 datapoints
2025-03-07 09:55:22,965 - INFO - training batch 151, loss: 1.032, 4832/28000 datapoints
2025-03-07 09:55:23,307 - INFO - training batch 201, loss: 0.739, 6432/28000 datapoints
2025-03-07 09:55:23,653 - INFO - training batch 251, loss: 0.594, 8032/28000 datapoints
2025-03-07 09:55:24,060 - INFO - training batch 301, loss: 0.704, 9632/28000 datapoints
2025-03-07 09:55:24,452 - INFO - training batch 351, loss: 0.617, 11232/28000 datapoints
2025-03-07 09:55:24,803 - INFO - training batch 401, loss: 0.959, 12832/28000 datapoints
2025-03-07 09:55:25,150 - INFO - training batch 451, loss: 0.739, 14432/28000 datapoints
2025-03-07 09:55:25,494 - INFO - training batch 501, loss: 0.528, 16032/28000 datapoints
2025-03-07 09:55:25,842 - INFO - training batch 551, loss: 0.772, 17632/28000 datapoints
2025-03-07 09:55:26,224 - INFO - training batch 601, loss: 1.180, 19232/28000 datapoints
2025-03-07 09:55:26,561 - INFO - training batch 651, loss: 0.453, 20832/28000 datapoints
2025-03-07 09:55:26,970 - INFO - training batch 701, loss: 0.632, 22432/28000 datapoints
2025-03-07 09:55:27,362 - INFO - training batch 751, loss: 0.415, 24032/28000 datapoints
2025-03-07 09:55:27,687 - INFO - training batch 801, loss: 0.452, 25632/28000 datapoints
2025-03-07 09:55:28,083 - INFO - training batch 851, loss: 1.011, 27232/28000 datapoints
2025-03-07 09:55:28,236 - INFO - validation batch 1, loss: 0.320, 32/6976 datapoints
2025-03-07 09:55:28,333 - INFO - validation batch 51, loss: 1.447, 1632/6976 datapoints
2025-03-07 09:55:28,423 - INFO - validation batch 101, loss: 0.462, 3232/6976 datapoints
2025-03-07 09:55:28,514 - INFO - validation batch 151, loss: 0.738, 4832/6976 datapoints
2025-03-07 09:55:28,607 - INFO - validation batch 201, loss: 0.747, 6432/6976 datapoints
2025-03-07 09:55:28,644 - INFO - Epoch 42/800 done.
2025-03-07 09:55:28,645 - INFO - Final validation performance:
Loss: 0.743, top-1 acc: 0.802top-5 acc: 0.802
2025-03-07 09:55:28,645 - INFO - Beginning epoch 43/800
2025-03-07 09:55:28,655 - INFO - training batch 1, loss: 0.607, 32/28000 datapoints
2025-03-07 09:55:29,083 - INFO - training batch 51, loss: 0.639, 1632/28000 datapoints
2025-03-07 09:55:29,421 - INFO - training batch 101, loss: 0.417, 3232/28000 datapoints
2025-03-07 09:55:29,775 - INFO - training batch 151, loss: 1.017, 4832/28000 datapoints
2025-03-07 09:55:30,127 - INFO - training batch 201, loss: 0.716, 6432/28000 datapoints
2025-03-07 09:55:30,481 - INFO - training batch 251, loss: 0.584, 8032/28000 datapoints
2025-03-07 09:55:30,810 - INFO - training batch 301, loss: 0.686, 9632/28000 datapoints
2025-03-07 09:55:31,170 - INFO - training batch 351, loss: 0.599, 11232/28000 datapoints
2025-03-07 09:55:31,558 - INFO - training batch 401, loss: 0.945, 12832/28000 datapoints
2025-03-07 09:55:31,903 - INFO - training batch 451, loss: 0.720, 14432/28000 datapoints
2025-03-07 09:55:32,290 - INFO - training batch 501, loss: 0.504, 16032/28000 datapoints
2025-03-07 09:55:32,775 - INFO - training batch 551, loss: 0.753, 17632/28000 datapoints
2025-03-07 09:55:33,168 - INFO - training batch 601, loss: 1.160, 19232/28000 datapoints
2025-03-07 09:55:33,566 - INFO - training batch 651, loss: 0.439, 20832/28000 datapoints
2025-03-07 09:55:33,902 - INFO - training batch 701, loss: 0.614, 22432/28000 datapoints
2025-03-07 09:55:34,302 - INFO - training batch 751, loss: 0.393, 24032/28000 datapoints
2025-03-07 09:55:34,682 - INFO - training batch 801, loss: 0.439, 25632/28000 datapoints
2025-03-07 09:55:35,046 - INFO - training batch 851, loss: 1.005, 27232/28000 datapoints
2025-03-07 09:55:35,195 - INFO - validation batch 1, loss: 0.305, 32/6976 datapoints
2025-03-07 09:55:35,288 - INFO - validation batch 51, loss: 1.437, 1632/6976 datapoints
2025-03-07 09:55:35,380 - INFO - validation batch 101, loss: 0.438, 3232/6976 datapoints
2025-03-07 09:55:35,486 - INFO - validation batch 151, loss: 0.723, 4832/6976 datapoints
2025-03-07 09:55:35,591 - INFO - validation batch 201, loss: 0.757, 6432/6976 datapoints
2025-03-07 09:55:35,628 - INFO - Epoch 43/800 done.
2025-03-07 09:55:35,628 - INFO - Final validation performance:
Loss: 0.732, top-1 acc: 0.806top-5 acc: 0.806
2025-03-07 09:55:35,629 - INFO - Beginning epoch 44/800
2025-03-07 09:55:35,647 - INFO - training batch 1, loss: 0.580, 32/28000 datapoints
2025-03-07 09:55:36,012 - INFO - training batch 51, loss: 0.615, 1632/28000 datapoints
2025-03-07 09:55:36,372 - INFO - training batch 101, loss: 0.405, 3232/28000 datapoints
2025-03-07 09:55:36,772 - INFO - training batch 151, loss: 1.002, 4832/28000 datapoints
2025-03-07 09:55:37,167 - INFO - training batch 201, loss: 0.692, 6432/28000 datapoints
2025-03-07 09:55:37,499 - INFO - training batch 251, loss: 0.576, 8032/28000 datapoints
2025-03-07 09:55:37,860 - INFO - training batch 301, loss: 0.672, 9632/28000 datapoints
2025-03-07 09:55:38,211 - INFO - training batch 351, loss: 0.581, 11232/28000 datapoints
2025-03-07 09:55:38,576 - INFO - training batch 401, loss: 0.930, 12832/28000 datapoints
2025-03-07 09:55:39,094 - INFO - training batch 451, loss: 0.702, 14432/28000 datapoints
2025-03-07 09:55:39,463 - INFO - training batch 501, loss: 0.483, 16032/28000 datapoints
2025-03-07 09:55:39,940 - INFO - training batch 551, loss: 0.735, 17632/28000 datapoints
2025-03-07 09:55:40,282 - INFO - training batch 601, loss: 1.142, 19232/28000 datapoints
2025-03-07 09:55:40,629 - INFO - training batch 651, loss: 0.426, 20832/28000 datapoints
2025-03-07 09:55:40,962 - INFO - training batch 701, loss: 0.597, 22432/28000 datapoints
2025-03-07 09:55:41,302 - INFO - training batch 751, loss: 0.373, 24032/28000 datapoints
2025-03-07 09:55:41,695 - INFO - training batch 801, loss: 0.427, 25632/28000 datapoints
2025-03-07 09:55:42,048 - INFO - training batch 851, loss: 0.997, 27232/28000 datapoints
2025-03-07 09:55:42,216 - INFO - validation batch 1, loss: 0.290, 32/6976 datapoints
2025-03-07 09:55:42,327 - INFO - validation batch 51, loss: 1.427, 1632/6976 datapoints
2025-03-07 09:55:42,448 - INFO - validation batch 101, loss: 0.415, 3232/6976 datapoints
2025-03-07 09:55:42,568 - INFO - validation batch 151, loss: 0.708, 4832/6976 datapoints
2025-03-07 09:55:42,661 - INFO - validation batch 201, loss: 0.769, 6432/6976 datapoints
2025-03-07 09:55:42,698 - INFO - Epoch 44/800 done.
2025-03-07 09:55:42,698 - INFO - Final validation performance:
Loss: 0.722, top-1 acc: 0.811top-5 acc: 0.811
2025-03-07 09:55:42,699 - INFO - Beginning epoch 45/800
2025-03-07 09:55:42,712 - INFO - training batch 1, loss: 0.555, 32/28000 datapoints
2025-03-07 09:55:43,073 - INFO - training batch 51, loss: 0.593, 1632/28000 datapoints
2025-03-07 09:55:43,422 - INFO - training batch 101, loss: 0.396, 3232/28000 datapoints
2025-03-07 09:55:43,771 - INFO - training batch 151, loss: 0.986, 4832/28000 datapoints
2025-03-07 09:55:44,123 - INFO - training batch 201, loss: 0.667, 6432/28000 datapoints
2025-03-07 09:55:44,564 - INFO - training batch 251, loss: 0.568, 8032/28000 datapoints
2025-03-07 09:55:44,906 - INFO - training batch 301, loss: 0.660, 9632/28000 datapoints
2025-03-07 09:55:45,286 - INFO - training batch 351, loss: 0.569, 11232/28000 datapoints
2025-03-07 09:55:45,632 - INFO - training batch 401, loss: 0.915, 12832/28000 datapoints
2025-03-07 09:55:45,994 - INFO - training batch 451, loss: 0.685, 14432/28000 datapoints
2025-03-07 09:55:46,340 - INFO - training batch 501, loss: 0.464, 16032/28000 datapoints
2025-03-07 09:55:46,677 - INFO - training batch 551, loss: 0.717, 17632/28000 datapoints
2025-03-07 09:55:47,018 - INFO - training batch 601, loss: 1.125, 19232/28000 datapoints
2025-03-07 09:55:47,356 - INFO - training batch 651, loss: 0.414, 20832/28000 datapoints
2025-03-07 09:55:47,697 - INFO - training batch 701, loss: 0.581, 22432/28000 datapoints
2025-03-07 09:55:48,085 - INFO - training batch 751, loss: 0.357, 24032/28000 datapoints
2025-03-07 09:55:48,416 - INFO - training batch 801, loss: 0.417, 25632/28000 datapoints
2025-03-07 09:55:48,760 - INFO - training batch 851, loss: 0.989, 27232/28000 datapoints
2025-03-07 09:55:48,925 - INFO - validation batch 1, loss: 0.278, 32/6976 datapoints
2025-03-07 09:55:49,018 - INFO - validation batch 51, loss: 1.419, 1632/6976 datapoints
2025-03-07 09:55:49,109 - INFO - validation batch 101, loss: 0.395, 3232/6976 datapoints
2025-03-07 09:55:49,206 - INFO - validation batch 151, loss: 0.697, 4832/6976 datapoints
2025-03-07 09:55:49,296 - INFO - validation batch 201, loss: 0.777, 6432/6976 datapoints
2025-03-07 09:55:49,332 - INFO - Epoch 45/800 done.
2025-03-07 09:55:49,332 - INFO - Final validation performance:
Loss: 0.713, top-1 acc: 0.817top-5 acc: 0.817
2025-03-07 09:55:49,333 - INFO - Beginning epoch 46/800
2025-03-07 09:55:49,343 - INFO - training batch 1, loss: 0.530, 32/28000 datapoints
2025-03-07 09:55:49,689 - INFO - training batch 51, loss: 0.574, 1632/28000 datapoints
2025-03-07 09:55:50,030 - INFO - training batch 101, loss: 0.388, 3232/28000 datapoints
2025-03-07 09:55:50,379 - INFO - training batch 151, loss: 0.966, 4832/28000 datapoints
2025-03-07 09:55:50,694 - INFO - training batch 201, loss: 0.643, 6432/28000 datapoints
2025-03-07 09:55:51,035 - INFO - training batch 251, loss: 0.558, 8032/28000 datapoints
2025-03-07 09:55:51,379 - INFO - training batch 301, loss: 0.648, 9632/28000 datapoints
2025-03-07 09:55:51,741 - INFO - training batch 351, loss: 0.552, 11232/28000 datapoints
2025-03-07 09:55:52,098 - INFO - training batch 401, loss: 0.901, 12832/28000 datapoints
2025-03-07 09:55:52,438 - INFO - training batch 451, loss: 0.667, 14432/28000 datapoints
2025-03-07 09:55:52,872 - INFO - training batch 501, loss: 0.446, 16032/28000 datapoints
2025-03-07 09:55:53,267 - INFO - training batch 551, loss: 0.699, 17632/28000 datapoints
2025-03-07 09:55:53,596 - INFO - training batch 601, loss: 1.109, 19232/28000 datapoints
2025-03-07 09:55:53,970 - INFO - training batch 651, loss: 0.400, 20832/28000 datapoints
2025-03-07 09:55:54,406 - INFO - training batch 701, loss: 0.565, 22432/28000 datapoints
2025-03-07 09:55:54,864 - INFO - training batch 751, loss: 0.341, 24032/28000 datapoints
2025-03-07 09:55:55,237 - INFO - training batch 801, loss: 0.409, 25632/28000 datapoints
2025-03-07 09:55:55,639 - INFO - training batch 851, loss: 0.979, 27232/28000 datapoints
2025-03-07 09:55:55,809 - INFO - validation batch 1, loss: 0.267, 32/6976 datapoints
2025-03-07 09:55:55,920 - INFO - validation batch 51, loss: 1.413, 1632/6976 datapoints
2025-03-07 09:55:56,033 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-07 09:55:56,166 - INFO - validation batch 151, loss: 0.689, 4832/6976 datapoints
2025-03-07 09:55:56,268 - INFO - validation batch 201, loss: 0.777, 6432/6976 datapoints
2025-03-07 09:55:56,304 - INFO - Epoch 46/800 done.
2025-03-07 09:55:56,304 - INFO - Final validation performance:
Loss: 0.705, top-1 acc: 0.823top-5 acc: 0.823
2025-03-07 09:55:56,305 - INFO - Beginning epoch 47/800
2025-03-07 09:55:56,315 - INFO - training batch 1, loss: 0.508, 32/28000 datapoints
2025-03-07 09:55:56,676 - INFO - training batch 51, loss: 0.559, 1632/28000 datapoints
2025-03-07 09:55:57,029 - INFO - training batch 101, loss: 0.381, 3232/28000 datapoints
2025-03-07 09:55:57,343 - INFO - training batch 151, loss: 0.951, 4832/28000 datapoints
2025-03-07 09:55:57,742 - INFO - training batch 201, loss: 0.623, 6432/28000 datapoints
2025-03-07 09:55:58,102 - INFO - training batch 251, loss: 0.550, 8032/28000 datapoints
2025-03-07 09:55:58,454 - INFO - training batch 301, loss: 0.637, 9632/28000 datapoints
2025-03-07 09:55:58,834 - INFO - training batch 351, loss: 0.538, 11232/28000 datapoints
2025-03-07 09:55:59,260 - INFO - training batch 401, loss: 0.883, 12832/28000 datapoints
2025-03-07 09:55:59,624 - INFO - training batch 451, loss: 0.652, 14432/28000 datapoints
2025-03-07 09:55:59,970 - INFO - training batch 501, loss: 0.430, 16032/28000 datapoints
2025-03-07 09:56:00,330 - INFO - training batch 551, loss: 0.684, 17632/28000 datapoints
2025-03-07 09:56:00,731 - INFO - training batch 601, loss: 1.095, 19232/28000 datapoints
2025-03-07 09:56:01,104 - INFO - training batch 651, loss: 0.387, 20832/28000 datapoints
2025-03-07 09:56:01,435 - INFO - training batch 701, loss: 0.547, 22432/28000 datapoints
2025-03-07 09:56:01,847 - INFO - training batch 751, loss: 0.328, 24032/28000 datapoints
2025-03-07 09:56:02,182 - INFO - training batch 801, loss: 0.402, 25632/28000 datapoints
2025-03-07 09:56:02,517 - INFO - training batch 851, loss: 0.970, 27232/28000 datapoints
2025-03-07 09:56:02,688 - INFO - validation batch 1, loss: 0.255, 32/6976 datapoints
2025-03-07 09:56:02,826 - INFO - validation batch 51, loss: 1.407, 1632/6976 datapoints
2025-03-07 09:56:02,945 - INFO - validation batch 101, loss: 0.365, 3232/6976 datapoints
2025-03-07 09:56:03,055 - INFO - validation batch 151, loss: 0.677, 4832/6976 datapoints
2025-03-07 09:56:03,151 - INFO - validation batch 201, loss: 0.781, 6432/6976 datapoints
2025-03-07 09:56:03,185 - INFO - Epoch 47/800 done.
2025-03-07 09:56:03,186 - INFO - Final validation performance:
Loss: 0.697, top-1 acc: 0.827top-5 acc: 0.827
2025-03-07 09:56:03,187 - INFO - Beginning epoch 48/800
2025-03-07 09:56:03,198 - INFO - training batch 1, loss: 0.488, 32/28000 datapoints
2025-03-07 09:56:03,603 - INFO - training batch 51, loss: 0.545, 1632/28000 datapoints
2025-03-07 09:56:04,028 - INFO - training batch 101, loss: 0.375, 3232/28000 datapoints
2025-03-07 09:56:04,417 - INFO - training batch 151, loss: 0.937, 4832/28000 datapoints
2025-03-07 09:56:04,826 - INFO - training batch 201, loss: 0.601, 6432/28000 datapoints
2025-03-07 09:56:05,190 - INFO - training batch 251, loss: 0.545, 8032/28000 datapoints
2025-03-07 09:56:05,556 - INFO - training batch 301, loss: 0.627, 9632/28000 datapoints
2025-03-07 09:56:05,988 - INFO - training batch 351, loss: 0.527, 11232/28000 datapoints
2025-03-07 09:56:06,352 - INFO - training batch 401, loss: 0.866, 12832/28000 datapoints
2025-03-07 09:56:06,704 - INFO - training batch 451, loss: 0.639, 14432/28000 datapoints
2025-03-07 09:56:07,041 - INFO - training batch 501, loss: 0.416, 16032/28000 datapoints
2025-03-07 09:56:07,377 - INFO - training batch 551, loss: 0.672, 17632/28000 datapoints
2025-03-07 09:56:07,726 - INFO - training batch 601, loss: 1.082, 19232/28000 datapoints
2025-03-07 09:56:08,076 - INFO - training batch 651, loss: 0.373, 20832/28000 datapoints
2025-03-07 09:56:08,420 - INFO - training batch 701, loss: 0.533, 22432/28000 datapoints
2025-03-07 09:56:08,777 - INFO - training batch 751, loss: 0.316, 24032/28000 datapoints
2025-03-07 09:56:09,130 - INFO - training batch 801, loss: 0.395, 25632/28000 datapoints
2025-03-07 09:56:09,496 - INFO - training batch 851, loss: 0.961, 27232/28000 datapoints
2025-03-07 09:56:09,696 - INFO - validation batch 1, loss: 0.246, 32/6976 datapoints
2025-03-07 09:56:09,808 - INFO - validation batch 51, loss: 1.399, 1632/6976 datapoints
2025-03-07 09:56:09,911 - INFO - validation batch 101, loss: 0.352, 3232/6976 datapoints
2025-03-07 09:56:10,005 - INFO - validation batch 151, loss: 0.664, 4832/6976 datapoints
2025-03-07 09:56:10,101 - INFO - validation batch 201, loss: 0.789, 6432/6976 datapoints
2025-03-07 09:56:10,145 - INFO - Epoch 48/800 done.
2025-03-07 09:56:10,145 - INFO - Final validation performance:
Loss: 0.690, top-1 acc: 0.831top-5 acc: 0.831
2025-03-07 09:56:10,146 - INFO - Beginning epoch 49/800
2025-03-07 09:56:10,158 - INFO - training batch 1, loss: 0.471, 32/28000 datapoints
2025-03-07 09:56:10,523 - INFO - training batch 51, loss: 0.531, 1632/28000 datapoints
2025-03-07 09:56:10,871 - INFO - training batch 101, loss: 0.369, 3232/28000 datapoints
2025-03-07 09:56:11,235 - INFO - training batch 151, loss: 0.925, 4832/28000 datapoints
2025-03-07 09:56:11,599 - INFO - training batch 201, loss: 0.578, 6432/28000 datapoints
2025-03-07 09:56:11,986 - INFO - training batch 251, loss: 0.540, 8032/28000 datapoints
2025-03-07 09:56:12,324 - INFO - training batch 301, loss: 0.618, 9632/28000 datapoints
2025-03-07 09:56:12,672 - INFO - training batch 351, loss: 0.518, 11232/28000 datapoints
2025-03-07 09:56:13,116 - INFO - training batch 401, loss: 0.851, 12832/28000 datapoints
2025-03-07 09:56:15,038 - INFO - training batch 451, loss: 0.626, 14432/28000 datapoints
2025-03-07 09:56:15,851 - INFO - training batch 501, loss: 0.404, 16032/28000 datapoints
2025-03-07 09:56:16,272 - INFO - training batch 551, loss: 0.659, 17632/28000 datapoints
2025-03-07 09:56:16,852 - INFO - training batch 601, loss: 1.071, 19232/28000 datapoints
2025-03-07 09:56:17,235 - INFO - training batch 651, loss: 0.359, 20832/28000 datapoints
2025-03-07 09:56:17,673 - INFO - training batch 701, loss: 0.521, 22432/28000 datapoints
2025-03-07 09:56:18,056 - INFO - training batch 751, loss: 0.307, 24032/28000 datapoints
2025-03-07 09:56:18,376 - INFO - training batch 801, loss: 0.389, 25632/28000 datapoints
2025-03-07 09:56:18,723 - INFO - training batch 851, loss: 0.951, 27232/28000 datapoints
2025-03-07 09:56:18,906 - INFO - validation batch 1, loss: 0.237, 32/6976 datapoints
2025-03-07 09:56:19,042 - INFO - validation batch 51, loss: 1.391, 1632/6976 datapoints
2025-03-07 09:56:19,167 - INFO - validation batch 101, loss: 0.342, 3232/6976 datapoints
2025-03-07 09:56:19,261 - INFO - validation batch 151, loss: 0.653, 4832/6976 datapoints
2025-03-07 09:56:19,358 - INFO - validation batch 201, loss: 0.796, 6432/6976 datapoints
2025-03-07 09:56:19,394 - INFO - Epoch 49/800 done.
2025-03-07 09:56:19,394 - INFO - Final validation performance:
Loss: 0.684, top-1 acc: 0.835top-5 acc: 0.835
2025-03-07 09:56:19,395 - INFO - Beginning epoch 50/800
2025-03-07 09:56:19,407 - INFO - training batch 1, loss: 0.454, 32/28000 datapoints
2025-03-07 09:56:19,782 - INFO - training batch 51, loss: 0.518, 1632/28000 datapoints
2025-03-07 09:56:20,096 - INFO - training batch 101, loss: 0.365, 3232/28000 datapoints
2025-03-07 09:56:20,429 - INFO - training batch 151, loss: 0.912, 4832/28000 datapoints
2025-03-07 09:56:20,808 - INFO - training batch 201, loss: 0.558, 6432/28000 datapoints
2025-03-07 09:56:21,170 - INFO - training batch 251, loss: 0.536, 8032/28000 datapoints
2025-03-07 09:56:21,520 - INFO - training batch 301, loss: 0.610, 9632/28000 datapoints
2025-03-07 09:56:21,865 - INFO - training batch 351, loss: 0.510, 11232/28000 datapoints
2025-03-07 09:56:22,241 - INFO - training batch 401, loss: 0.837, 12832/28000 datapoints
2025-03-07 09:56:22,601 - INFO - training batch 451, loss: 0.613, 14432/28000 datapoints
2025-03-07 09:56:22,979 - INFO - training batch 501, loss: 0.394, 16032/28000 datapoints
2025-03-07 09:56:24,267 - INFO - training batch 551, loss: 0.647, 17632/28000 datapoints
2025-03-07 09:56:24,627 - INFO - training batch 601, loss: 1.057, 19232/28000 datapoints
2025-03-07 09:56:25,248 - INFO - training batch 651, loss: 0.345, 20832/28000 datapoints
2025-03-07 09:56:25,620 - INFO - training batch 701, loss: 0.508, 22432/28000 datapoints
2025-03-07 09:56:26,014 - INFO - training batch 751, loss: 0.298, 24032/28000 datapoints
2025-03-07 09:56:26,374 - INFO - training batch 801, loss: 0.383, 25632/28000 datapoints
2025-03-07 09:56:26,697 - INFO - training batch 851, loss: 0.941, 27232/28000 datapoints
2025-03-07 09:56:27,177 - INFO - validation batch 1, loss: 0.230, 32/6976 datapoints
2025-03-07 09:56:27,270 - INFO - validation batch 51, loss: 1.386, 1632/6976 datapoints
2025-03-07 09:56:27,366 - INFO - validation batch 101, loss: 0.332, 3232/6976 datapoints
2025-03-07 09:56:27,458 - INFO - validation batch 151, loss: 0.641, 4832/6976 datapoints
2025-03-07 09:56:27,560 - INFO - validation batch 201, loss: 0.802, 6432/6976 datapoints
2025-03-07 09:56:27,605 - INFO - Epoch 50/800 done.
2025-03-07 09:56:27,606 - INFO - Final validation performance:
Loss: 0.678, top-1 acc: 0.838top-5 acc: 0.838
2025-03-07 09:56:27,607 - INFO - Beginning epoch 51/800
2025-03-07 09:56:27,616 - INFO - training batch 1, loss: 0.439, 32/28000 datapoints
2025-03-07 09:56:27,994 - INFO - training batch 51, loss: 0.505, 1632/28000 datapoints
2025-03-07 09:56:28,345 - INFO - training batch 101, loss: 0.359, 3232/28000 datapoints
2025-03-07 09:56:28,696 - INFO - training batch 151, loss: 0.899, 4832/28000 datapoints
2025-03-07 09:56:29,152 - INFO - training batch 201, loss: 0.539, 6432/28000 datapoints
2025-03-07 09:56:29,538 - INFO - training batch 251, loss: 0.531, 8032/28000 datapoints
2025-03-07 09:56:29,963 - INFO - training batch 301, loss: 0.604, 9632/28000 datapoints
2025-03-07 09:56:30,304 - INFO - training batch 351, loss: 0.502, 11232/28000 datapoints
2025-03-07 09:56:30,687 - INFO - training batch 401, loss: 0.823, 12832/28000 datapoints
2025-03-07 09:56:31,691 - INFO - training batch 451, loss: 0.601, 14432/28000 datapoints
2025-03-07 09:56:32,497 - INFO - training batch 501, loss: 0.385, 16032/28000 datapoints
2025-03-07 09:56:32,975 - INFO - training batch 551, loss: 0.636, 17632/28000 datapoints
2025-03-07 09:56:33,563 - INFO - training batch 601, loss: 1.041, 19232/28000 datapoints
2025-03-07 09:56:34,272 - INFO - training batch 651, loss: 0.332, 20832/28000 datapoints
2025-03-07 09:56:34,642 - INFO - training batch 701, loss: 0.497, 22432/28000 datapoints
2025-03-07 09:56:34,959 - INFO - training batch 751, loss: 0.291, 24032/28000 datapoints
2025-03-07 09:56:35,300 - INFO - training batch 801, loss: 0.377, 25632/28000 datapoints
2025-03-07 09:56:35,636 - INFO - training batch 851, loss: 0.930, 27232/28000 datapoints
2025-03-07 09:56:35,797 - INFO - validation batch 1, loss: 0.223, 32/6976 datapoints
2025-03-07 09:56:35,893 - INFO - validation batch 51, loss: 1.381, 1632/6976 datapoints
2025-03-07 09:56:35,992 - INFO - validation batch 101, loss: 0.324, 3232/6976 datapoints
2025-03-07 09:56:36,112 - INFO - validation batch 151, loss: 0.627, 4832/6976 datapoints
2025-03-07 09:56:36,212 - INFO - validation batch 201, loss: 0.808, 6432/6976 datapoints
2025-03-07 09:56:36,246 - INFO - Epoch 51/800 done.
2025-03-07 09:56:36,247 - INFO - Final validation performance:
Loss: 0.673, top-1 acc: 0.840top-5 acc: 0.840
2025-03-07 09:56:36,248 - INFO - Beginning epoch 52/800
2025-03-07 09:56:36,258 - INFO - training batch 1, loss: 0.425, 32/28000 datapoints
2025-03-07 09:56:36,640 - INFO - training batch 51, loss: 0.492, 1632/28000 datapoints
2025-03-07 09:56:37,025 - INFO - training batch 101, loss: 0.354, 3232/28000 datapoints
2025-03-07 09:56:37,359 - INFO - training batch 151, loss: 0.886, 4832/28000 datapoints
2025-03-07 09:56:37,757 - INFO - training batch 201, loss: 0.524, 6432/28000 datapoints
2025-03-07 09:56:38,101 - INFO - training batch 251, loss: 0.528, 8032/28000 datapoints
2025-03-07 09:56:38,441 - INFO - training batch 301, loss: 0.597, 9632/28000 datapoints
2025-03-07 09:56:39,185 - INFO - training batch 351, loss: 0.496, 11232/28000 datapoints
2025-03-07 09:56:39,553 - INFO - training batch 401, loss: 0.809, 12832/28000 datapoints
2025-03-07 09:56:40,086 - INFO - training batch 451, loss: 0.589, 14432/28000 datapoints
2025-03-07 09:56:40,862 - INFO - training batch 501, loss: 0.376, 16032/28000 datapoints
2025-03-07 09:56:42,467 - INFO - training batch 551, loss: 0.625, 17632/28000 datapoints
2025-03-07 09:56:42,953 - INFO - training batch 601, loss: 1.030, 19232/28000 datapoints
2025-03-07 09:56:43,318 - INFO - training batch 651, loss: 0.320, 20832/28000 datapoints
2025-03-07 09:56:43,666 - INFO - training batch 701, loss: 0.487, 22432/28000 datapoints
2025-03-07 09:56:45,386 - INFO - training batch 751, loss: 0.284, 24032/28000 datapoints
2025-03-07 09:56:46,028 - INFO - training batch 801, loss: 0.372, 25632/28000 datapoints
2025-03-07 09:56:46,415 - INFO - training batch 851, loss: 0.920, 27232/28000 datapoints
2025-03-07 09:56:46,636 - INFO - validation batch 1, loss: 0.217, 32/6976 datapoints
2025-03-07 09:56:46,901 - INFO - validation batch 51, loss: 1.372, 1632/6976 datapoints
2025-03-07 09:56:47,055 - INFO - validation batch 101, loss: 0.315, 3232/6976 datapoints
2025-03-07 09:56:47,165 - INFO - validation batch 151, loss: 0.615, 4832/6976 datapoints
2025-03-07 09:56:47,259 - INFO - validation batch 201, loss: 0.813, 6432/6976 datapoints
2025-03-07 09:56:47,301 - INFO - Epoch 52/800 done.
2025-03-07 09:56:47,301 - INFO - Final validation performance:
Loss: 0.667, top-1 acc: 0.842top-5 acc: 0.842
2025-03-07 09:56:47,304 - INFO - Beginning epoch 53/800
2025-03-07 09:56:47,312 - INFO - training batch 1, loss: 0.412, 32/28000 datapoints
2025-03-07 09:56:47,598 - INFO - training batch 51, loss: 0.480, 1632/28000 datapoints
2025-03-07 09:56:48,032 - INFO - training batch 101, loss: 0.351, 3232/28000 datapoints
2025-03-07 09:56:48,389 - INFO - training batch 151, loss: 0.876, 4832/28000 datapoints
2025-03-07 09:56:49,003 - INFO - training batch 201, loss: 0.509, 6432/28000 datapoints
2025-03-07 09:56:49,417 - INFO - training batch 251, loss: 0.524, 8032/28000 datapoints
2025-03-07 09:56:49,690 - INFO - training batch 301, loss: 0.591, 9632/28000 datapoints
2025-03-07 09:56:49,976 - INFO - training batch 351, loss: 0.489, 11232/28000 datapoints
2025-03-07 09:56:50,263 - INFO - training batch 401, loss: 0.796, 12832/28000 datapoints
2025-03-07 09:58:17,800 - INFO - training batch 451, loss: 0.578, 14432/28000 datapoints
2025-03-07 09:58:18,460 - INFO - training batch 501, loss: 0.368, 16032/28000 datapoints
2025-03-07 09:58:18,995 - INFO - training batch 551, loss: 0.612, 17632/28000 datapoints
2025-03-07 09:58:19,446 - INFO - training batch 601, loss: 1.013, 19232/28000 datapoints
2025-03-07 09:58:20,126 - INFO - training batch 651, loss: 0.307, 20832/28000 datapoints
2025-03-07 09:58:20,505 - INFO - training batch 701, loss: 0.477, 22432/28000 datapoints
2025-03-07 09:58:20,855 - INFO - training batch 751, loss: 0.279, 24032/28000 datapoints
2025-03-07 09:58:21,197 - INFO - training batch 801, loss: 0.366, 25632/28000 datapoints
2025-03-07 09:58:21,781 - INFO - training batch 851, loss: 0.910, 27232/28000 datapoints
2025-03-07 09:58:22,002 - INFO - validation batch 1, loss: 0.212, 32/6976 datapoints
2025-03-07 09:58:22,374 - INFO - validation batch 51, loss: 1.360, 1632/6976 datapoints
2025-03-07 09:58:22,659 - INFO - validation batch 101, loss: 0.308, 3232/6976 datapoints
2025-03-07 09:58:23,043 - INFO - validation batch 151, loss: 0.606, 4832/6976 datapoints
2025-03-07 09:58:23,278 - INFO - validation batch 201, loss: 0.817, 6432/6976 datapoints
2025-03-07 09:58:23,346 - INFO - Epoch 53/800 done.
2025-03-07 09:58:23,358 - INFO - Final validation performance:
Loss: 0.661, top-1 acc: 0.844top-5 acc: 0.844
2025-03-07 09:58:23,363 - INFO - Beginning epoch 54/800
2025-03-07 09:58:23,386 - INFO - training batch 1, loss: 0.401, 32/28000 datapoints
2025-03-07 09:58:23,881 - INFO - training batch 51, loss: 0.469, 1632/28000 datapoints
2025-03-07 09:58:24,204 - INFO - training batch 101, loss: 0.350, 3232/28000 datapoints
2025-03-07 09:58:24,526 - INFO - training batch 151, loss: 0.865, 4832/28000 datapoints
2025-03-07 09:58:24,821 - INFO - training batch 201, loss: 0.495, 6432/28000 datapoints
2025-03-07 09:58:25,078 - INFO - training batch 251, loss: 0.519, 8032/28000 datapoints
2025-03-07 09:58:25,373 - INFO - training batch 301, loss: 0.587, 9632/28000 datapoints
2025-03-07 09:58:25,676 - INFO - training batch 351, loss: 0.483, 11232/28000 datapoints
2025-03-07 09:58:25,947 - INFO - training batch 401, loss: 0.786, 12832/28000 datapoints
2025-03-07 09:58:26,195 - INFO - training batch 451, loss: 0.566, 14432/28000 datapoints
2025-03-07 09:58:26,421 - INFO - training batch 501, loss: 0.361, 16032/28000 datapoints
2025-03-07 09:58:26,648 - INFO - training batch 551, loss: 0.600, 17632/28000 datapoints
2025-03-07 09:58:26,962 - INFO - training batch 601, loss: 0.998, 19232/28000 datapoints
2025-03-07 09:58:27,207 - INFO - training batch 651, loss: 0.294, 20832/28000 datapoints
2025-03-07 09:58:27,435 - INFO - training batch 701, loss: 0.467, 22432/28000 datapoints
2025-03-07 09:58:27,670 - INFO - training batch 751, loss: 0.274, 24032/28000 datapoints
2025-03-07 09:58:27,902 - INFO - training batch 801, loss: 0.361, 25632/28000 datapoints
2025-03-07 09:58:28,147 - INFO - training batch 851, loss: 0.900, 27232/28000 datapoints
2025-03-07 09:58:28,288 - INFO - validation batch 1, loss: 0.206, 32/6976 datapoints
2025-03-07 09:58:28,369 - INFO - validation batch 51, loss: 1.351, 1632/6976 datapoints
2025-03-07 09:58:29,365 - INFO - validation batch 101, loss: 0.301, 3232/6976 datapoints
2025-03-07 09:58:29,678 - INFO - validation batch 151, loss: 0.599, 4832/6976 datapoints
2025-03-07 09:58:29,886 - INFO - validation batch 201, loss: 0.821, 6432/6976 datapoints
2025-03-07 09:58:29,942 - INFO - Epoch 54/800 done.
2025-03-07 09:58:29,943 - INFO - Final validation performance:
Loss: 0.656, top-1 acc: 0.847top-5 acc: 0.847
2025-03-07 09:58:29,943 - INFO - Beginning epoch 55/800
2025-03-07 09:58:29,951 - INFO - training batch 1, loss: 0.392, 32/28000 datapoints
2025-03-07 09:58:30,495 - INFO - training batch 51, loss: 0.458, 1632/28000 datapoints
2025-03-07 09:58:31,068 - INFO - training batch 101, loss: 0.348, 3232/28000 datapoints
2025-03-07 09:58:31,560 - INFO - training batch 151, loss: 0.856, 4832/28000 datapoints
2025-03-07 09:58:32,247 - INFO - training batch 201, loss: 0.481, 6432/28000 datapoints
2025-03-07 09:58:32,569 - INFO - training batch 251, loss: 0.516, 8032/28000 datapoints
2025-03-07 09:58:32,900 - INFO - training batch 301, loss: 0.583, 9632/28000 datapoints
2025-03-07 09:58:33,196 - INFO - training batch 351, loss: 0.477, 11232/28000 datapoints
2025-03-07 09:58:33,530 - INFO - training batch 401, loss: 0.774, 12832/28000 datapoints
2025-03-07 09:58:34,314 - INFO - training batch 451, loss: 0.556, 14432/28000 datapoints
2025-03-07 09:58:35,007 - INFO - training batch 501, loss: 0.354, 16032/28000 datapoints
2025-03-07 09:58:35,479 - INFO - training batch 551, loss: 0.588, 17632/28000 datapoints
2025-03-07 09:58:37,127 - INFO - training batch 601, loss: 0.985, 19232/28000 datapoints
2025-03-07 09:58:38,524 - INFO - training batch 651, loss: 0.281, 20832/28000 datapoints
2025-03-07 09:58:39,470 - INFO - training batch 701, loss: 0.459, 22432/28000 datapoints
2025-03-07 09:58:40,115 - INFO - training batch 751, loss: 0.270, 24032/28000 datapoints
2025-03-07 09:58:40,493 - INFO - training batch 801, loss: 0.356, 25632/28000 datapoints
2025-03-07 09:58:40,786 - INFO - training batch 851, loss: 0.890, 27232/28000 datapoints
2025-03-07 09:58:40,953 - INFO - validation batch 1, loss: 0.202, 32/6976 datapoints
2025-03-07 09:58:41,069 - INFO - validation batch 51, loss: 1.343, 1632/6976 datapoints
2025-03-07 09:58:41,167 - INFO - validation batch 101, loss: 0.296, 3232/6976 datapoints
2025-03-07 09:58:41,282 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-07 09:58:41,403 - INFO - validation batch 201, loss: 0.825, 6432/6976 datapoints
2025-03-07 09:58:41,445 - INFO - Epoch 55/800 done.
2025-03-07 09:58:41,445 - INFO - Final validation performance:
Loss: 0.651, top-1 acc: 0.848top-5 acc: 0.848
2025-03-07 09:58:41,447 - INFO - Beginning epoch 56/800
2025-03-07 09:58:41,456 - INFO - training batch 1, loss: 0.384, 32/28000 datapoints
2025-03-07 09:58:41,766 - INFO - training batch 51, loss: 0.448, 1632/28000 datapoints
2025-03-07 09:58:42,030 - INFO - training batch 101, loss: 0.346, 3232/28000 datapoints
2025-03-07 09:58:42,271 - INFO - training batch 151, loss: 0.847, 4832/28000 datapoints
2025-03-07 09:58:42,519 - INFO - training batch 201, loss: 0.471, 6432/28000 datapoints
2025-03-07 09:58:42,750 - INFO - training batch 251, loss: 0.512, 8032/28000 datapoints
2025-03-07 09:58:42,974 - INFO - training batch 301, loss: 0.579, 9632/28000 datapoints
2025-03-07 09:58:43,237 - INFO - training batch 351, loss: 0.471, 11232/28000 datapoints
2025-03-07 09:58:43,542 - INFO - training batch 401, loss: 0.765, 12832/28000 datapoints
2025-03-07 09:58:43,833 - INFO - training batch 451, loss: 0.546, 14432/28000 datapoints
2025-03-07 09:58:44,458 - INFO - training batch 501, loss: 0.348, 16032/28000 datapoints
2025-03-07 09:58:46,015 - INFO - training batch 551, loss: 0.577, 17632/28000 datapoints
2025-03-07 09:58:47,829 - INFO - training batch 601, loss: 0.973, 19232/28000 datapoints
2025-03-07 09:58:48,622 - INFO - training batch 651, loss: 0.268, 20832/28000 datapoints
2025-03-07 09:58:49,409 - INFO - training batch 701, loss: 0.449, 22432/28000 datapoints
2025-03-07 09:58:49,918 - INFO - training batch 751, loss: 0.266, 24032/28000 datapoints
2025-03-07 09:58:50,287 - INFO - training batch 801, loss: 0.351, 25632/28000 datapoints
2025-03-07 09:58:50,567 - INFO - training batch 851, loss: 0.878, 27232/28000 datapoints
2025-03-07 09:58:50,713 - INFO - validation batch 1, loss: 0.198, 32/6976 datapoints
2025-03-07 09:58:50,808 - INFO - validation batch 51, loss: 1.334, 1632/6976 datapoints
2025-03-07 09:58:50,918 - INFO - validation batch 101, loss: 0.291, 3232/6976 datapoints
2025-03-07 09:58:51,047 - INFO - validation batch 151, loss: 0.578, 4832/6976 datapoints
2025-03-07 09:58:51,163 - INFO - validation batch 201, loss: 0.832, 6432/6976 datapoints
2025-03-07 09:58:51,203 - INFO - Epoch 56/800 done.
2025-03-07 09:58:51,204 - INFO - Final validation performance:
Loss: 0.646, top-1 acc: 0.849top-5 acc: 0.849
2025-03-07 09:58:51,207 - INFO - Beginning epoch 57/800
2025-03-07 09:58:51,216 - INFO - training batch 1, loss: 0.376, 32/28000 datapoints
2025-03-07 09:58:51,508 - INFO - training batch 51, loss: 0.437, 1632/28000 datapoints
2025-03-07 09:58:51,761 - INFO - training batch 101, loss: 0.344, 3232/28000 datapoints
2025-03-07 09:58:52,051 - INFO - training batch 151, loss: 0.836, 4832/28000 datapoints
2025-03-07 09:58:52,321 - INFO - training batch 201, loss: 0.462, 6432/28000 datapoints
2025-03-07 09:58:52,594 - INFO - training batch 251, loss: 0.509, 8032/28000 datapoints
2025-03-07 09:58:52,869 - INFO - training batch 301, loss: 0.576, 9632/28000 datapoints
2025-03-07 09:58:53,128 - INFO - training batch 351, loss: 0.466, 11232/28000 datapoints
2025-03-07 09:58:53,379 - INFO - training batch 401, loss: 0.755, 12832/28000 datapoints
2025-03-07 09:58:53,631 - INFO - training batch 451, loss: 0.535, 14432/28000 datapoints
2025-03-07 09:58:53,891 - INFO - training batch 501, loss: 0.342, 16032/28000 datapoints
2025-03-07 09:58:54,125 - INFO - training batch 551, loss: 0.567, 17632/28000 datapoints
2025-03-07 09:58:54,359 - INFO - training batch 601, loss: 0.962, 19232/28000 datapoints
2025-03-07 09:58:54,602 - INFO - training batch 651, loss: 0.256, 20832/28000 datapoints
2025-03-07 09:58:54,848 - INFO - training batch 701, loss: 0.441, 22432/28000 datapoints
2025-03-07 09:58:55,095 - INFO - training batch 751, loss: 0.263, 24032/28000 datapoints
2025-03-07 09:58:55,345 - INFO - training batch 801, loss: 0.347, 25632/28000 datapoints
2025-03-07 09:58:55,583 - INFO - training batch 851, loss: 0.867, 27232/28000 datapoints
2025-03-07 09:58:55,704 - INFO - validation batch 1, loss: 0.194, 32/6976 datapoints
2025-03-07 09:58:55,785 - INFO - validation batch 51, loss: 1.325, 1632/6976 datapoints
2025-03-07 09:58:55,865 - INFO - validation batch 101, loss: 0.286, 3232/6976 datapoints
2025-03-07 09:58:55,940 - INFO - validation batch 151, loss: 0.567, 4832/6976 datapoints
2025-03-07 09:58:56,014 - INFO - validation batch 201, loss: 0.838, 6432/6976 datapoints
2025-03-07 09:58:56,041 - INFO - Epoch 57/800 done.
2025-03-07 09:58:56,041 - INFO - Final validation performance:
Loss: 0.642, top-1 acc: 0.851top-5 acc: 0.851
2025-03-07 09:58:56,042 - INFO - Beginning epoch 58/800
2025-03-07 09:58:56,049 - INFO - training batch 1, loss: 0.369, 32/28000 datapoints
2025-03-07 09:58:56,283 - INFO - training batch 51, loss: 0.428, 1632/28000 datapoints
2025-03-07 09:58:56,518 - INFO - training batch 101, loss: 0.341, 3232/28000 datapoints
2025-03-07 09:58:57,070 - INFO - training batch 151, loss: 0.826, 4832/28000 datapoints
2025-03-07 09:58:57,327 - INFO - training batch 201, loss: 0.456, 6432/28000 datapoints
2025-03-07 09:58:57,783 - INFO - training batch 251, loss: 0.505, 8032/28000 datapoints
2025-03-07 09:58:58,039 - INFO - training batch 301, loss: 0.575, 9632/28000 datapoints
2025-03-07 09:58:58,282 - INFO - training batch 351, loss: 0.461, 11232/28000 datapoints
2025-03-07 09:58:58,544 - INFO - training batch 401, loss: 0.746, 12832/28000 datapoints
2025-03-07 09:58:58,808 - INFO - training batch 451, loss: 0.525, 14432/28000 datapoints
2025-03-07 09:58:59,062 - INFO - training batch 501, loss: 0.335, 16032/28000 datapoints
2025-03-07 09:58:59,302 - INFO - training batch 551, loss: 0.557, 17632/28000 datapoints
2025-03-07 09:58:59,540 - INFO - training batch 601, loss: 0.951, 19232/28000 datapoints
2025-03-07 09:58:59,777 - INFO - training batch 651, loss: 0.245, 20832/28000 datapoints
2025-03-07 09:59:00,032 - INFO - training batch 701, loss: 0.432, 22432/28000 datapoints
2025-03-07 09:59:00,291 - INFO - training batch 751, loss: 0.259, 24032/28000 datapoints
2025-03-07 09:59:00,524 - INFO - training batch 801, loss: 0.342, 25632/28000 datapoints
2025-03-07 09:59:00,755 - INFO - training batch 851, loss: 0.857, 27232/28000 datapoints
2025-03-07 09:59:00,874 - INFO - validation batch 1, loss: 0.191, 32/6976 datapoints
2025-03-07 09:59:00,940 - INFO - validation batch 51, loss: 1.321, 1632/6976 datapoints
2025-03-07 09:59:01,006 - INFO - validation batch 101, loss: 0.282, 3232/6976 datapoints
2025-03-07 09:59:01,076 - INFO - validation batch 151, loss: 0.556, 4832/6976 datapoints
2025-03-07 09:59:01,141 - INFO - validation batch 201, loss: 0.843, 6432/6976 datapoints
2025-03-07 09:59:01,164 - INFO - Epoch 58/800 done.
2025-03-07 09:59:01,164 - INFO - Final validation performance:
Loss: 0.639, top-1 acc: 0.853top-5 acc: 0.853
2025-03-07 09:59:01,165 - INFO - Beginning epoch 59/800
2025-03-07 09:59:01,174 - INFO - training batch 1, loss: 0.363, 32/28000 datapoints
2025-03-07 09:59:01,407 - INFO - training batch 51, loss: 0.418, 1632/28000 datapoints
2025-03-07 09:59:01,691 - INFO - training batch 101, loss: 0.339, 3232/28000 datapoints
2025-03-07 09:59:01,996 - INFO - training batch 151, loss: 0.816, 4832/28000 datapoints
2025-03-07 09:59:02,256 - INFO - training batch 201, loss: 0.450, 6432/28000 datapoints
2025-03-07 09:59:02,502 - INFO - training batch 251, loss: 0.502, 8032/28000 datapoints
2025-03-07 09:59:02,742 - INFO - training batch 301, loss: 0.573, 9632/28000 datapoints
2025-03-07 09:59:02,989 - INFO - training batch 351, loss: 0.454, 11232/28000 datapoints
2025-03-07 09:59:03,230 - INFO - training batch 401, loss: 0.739, 12832/28000 datapoints
2025-03-07 09:59:03,478 - INFO - training batch 451, loss: 0.516, 14432/28000 datapoints
2025-03-07 09:59:03,727 - INFO - training batch 501, loss: 0.328, 16032/28000 datapoints
2025-03-07 09:59:03,973 - INFO - training batch 551, loss: 0.548, 17632/28000 datapoints
2025-03-07 09:59:04,239 - INFO - training batch 601, loss: 0.938, 19232/28000 datapoints
2025-03-07 09:59:04,505 - INFO - training batch 651, loss: 0.234, 20832/28000 datapoints
2025-03-07 09:59:04,745 - INFO - training batch 701, loss: 0.425, 22432/28000 datapoints
2025-03-07 09:59:05,039 - INFO - training batch 751, loss: 0.255, 24032/28000 datapoints
2025-03-07 09:59:05,338 - INFO - training batch 801, loss: 0.338, 25632/28000 datapoints
2025-03-07 09:59:05,620 - INFO - training batch 851, loss: 0.847, 27232/28000 datapoints
2025-03-07 09:59:05,746 - INFO - validation batch 1, loss: 0.188, 32/6976 datapoints
2025-03-07 09:59:05,829 - INFO - validation batch 51, loss: 1.314, 1632/6976 datapoints
2025-03-07 09:59:05,946 - INFO - validation batch 101, loss: 0.277, 3232/6976 datapoints
2025-03-07 09:59:06,049 - INFO - validation batch 151, loss: 0.545, 4832/6976 datapoints
2025-03-07 09:59:06,154 - INFO - validation batch 201, loss: 0.847, 6432/6976 datapoints
2025-03-07 09:59:06,192 - INFO - Epoch 59/800 done.
2025-03-07 09:59:06,193 - INFO - Final validation performance:
Loss: 0.634, top-1 acc: 0.854top-5 acc: 0.854
2025-03-07 09:59:06,193 - INFO - Beginning epoch 60/800
2025-03-07 09:59:06,206 - INFO - training batch 1, loss: 0.357, 32/28000 datapoints
2025-03-07 09:59:06,514 - INFO - training batch 51, loss: 0.408, 1632/28000 datapoints
2025-03-07 09:59:06,776 - INFO - training batch 101, loss: 0.336, 3232/28000 datapoints
2025-03-07 09:59:07,063 - INFO - training batch 151, loss: 0.805, 4832/28000 datapoints
2025-03-07 09:59:07,332 - INFO - training batch 201, loss: 0.445, 6432/28000 datapoints
2025-03-07 09:59:07,648 - INFO - training batch 251, loss: 0.498, 8032/28000 datapoints
2025-03-07 09:59:07,923 - INFO - training batch 301, loss: 0.572, 9632/28000 datapoints
2025-03-07 09:59:08,209 - INFO - training batch 351, loss: 0.448, 11232/28000 datapoints
2025-03-07 09:59:08,488 - INFO - training batch 401, loss: 0.731, 12832/28000 datapoints
2025-03-07 09:59:08,799 - INFO - training batch 451, loss: 0.507, 14432/28000 datapoints
2025-03-07 09:59:09,175 - INFO - training batch 501, loss: 0.323, 16032/28000 datapoints
2025-03-07 09:59:09,576 - INFO - training batch 551, loss: 0.540, 17632/28000 datapoints
2025-03-07 09:59:09,870 - INFO - training batch 601, loss: 0.924, 19232/28000 datapoints
2025-03-07 09:59:10,151 - INFO - training batch 651, loss: 0.224, 20832/28000 datapoints
2025-03-07 09:59:10,473 - INFO - training batch 701, loss: 0.418, 22432/28000 datapoints
2025-03-07 09:59:10,748 - INFO - training batch 751, loss: 0.251, 24032/28000 datapoints
2025-03-07 09:59:11,016 - INFO - training batch 801, loss: 0.334, 25632/28000 datapoints
2025-03-07 09:59:11,279 - INFO - training batch 851, loss: 0.836, 27232/28000 datapoints
2025-03-07 09:59:11,401 - INFO - validation batch 1, loss: 0.185, 32/6976 datapoints
2025-03-07 09:59:11,480 - INFO - validation batch 51, loss: 1.305, 1632/6976 datapoints
2025-03-07 09:59:11,559 - INFO - validation batch 101, loss: 0.274, 3232/6976 datapoints
2025-03-07 09:59:11,640 - INFO - validation batch 151, loss: 0.537, 4832/6976 datapoints
2025-03-07 09:59:11,715 - INFO - validation batch 201, loss: 0.851, 6432/6976 datapoints
2025-03-07 09:59:11,741 - INFO - Epoch 60/800 done.
2025-03-07 09:59:11,741 - INFO - Final validation performance:
Loss: 0.631, top-1 acc: 0.856top-5 acc: 0.856
2025-03-07 09:59:11,741 - INFO - Beginning epoch 61/800
2025-03-07 09:59:11,749 - INFO - training batch 1, loss: 0.352, 32/28000 datapoints
2025-03-07 09:59:12,007 - INFO - training batch 51, loss: 0.400, 1632/28000 datapoints
2025-03-07 09:59:12,251 - INFO - training batch 101, loss: 0.334, 3232/28000 datapoints
2025-03-07 09:59:12,496 - INFO - training batch 151, loss: 0.795, 4832/28000 datapoints
2025-03-07 09:59:12,895 - INFO - training batch 201, loss: 0.438, 6432/28000 datapoints
2025-03-07 09:59:13,144 - INFO - training batch 251, loss: 0.494, 8032/28000 datapoints
2025-03-07 09:59:13,444 - INFO - training batch 301, loss: 0.571, 9632/28000 datapoints
2025-03-07 09:59:13,726 - INFO - training batch 351, loss: 0.441, 11232/28000 datapoints
2025-03-07 09:59:13,958 - INFO - training batch 401, loss: 0.723, 12832/28000 datapoints
2025-03-07 09:59:14,203 - INFO - training batch 451, loss: 0.499, 14432/28000 datapoints
2025-03-07 09:59:14,437 - INFO - training batch 501, loss: 0.317, 16032/28000 datapoints
2025-03-07 09:59:14,671 - INFO - training batch 551, loss: 0.531, 17632/28000 datapoints
2025-03-07 09:59:14,905 - INFO - training batch 601, loss: 0.912, 19232/28000 datapoints
2025-03-07 09:59:15,142 - INFO - training batch 651, loss: 0.215, 20832/28000 datapoints
2025-03-07 09:59:15,397 - INFO - training batch 701, loss: 0.412, 22432/28000 datapoints
2025-03-07 09:59:15,640 - INFO - training batch 751, loss: 0.248, 24032/28000 datapoints
2025-03-07 09:59:15,881 - INFO - training batch 801, loss: 0.331, 25632/28000 datapoints
2025-03-07 09:59:16,125 - INFO - training batch 851, loss: 0.825, 27232/28000 datapoints
2025-03-07 09:59:16,245 - INFO - validation batch 1, loss: 0.182, 32/6976 datapoints
2025-03-07 09:59:16,322 - INFO - validation batch 51, loss: 1.296, 1632/6976 datapoints
2025-03-07 09:59:16,416 - INFO - validation batch 101, loss: 0.271, 3232/6976 datapoints
2025-03-07 09:59:16,514 - INFO - validation batch 151, loss: 0.529, 4832/6976 datapoints
2025-03-07 09:59:16,603 - INFO - validation batch 201, loss: 0.856, 6432/6976 datapoints
2025-03-07 09:59:16,627 - INFO - Epoch 61/800 done.
2025-03-07 09:59:16,627 - INFO - Final validation performance:
Loss: 0.627, top-1 acc: 0.857top-5 acc: 0.857
2025-03-07 09:59:16,628 - INFO - Beginning epoch 62/800
2025-03-07 09:59:16,636 - INFO - training batch 1, loss: 0.347, 32/28000 datapoints
2025-03-07 09:59:16,908 - INFO - training batch 51, loss: 0.392, 1632/28000 datapoints
2025-03-07 09:59:17,208 - INFO - training batch 101, loss: 0.331, 3232/28000 datapoints
2025-03-07 09:59:17,462 - INFO - training batch 151, loss: 0.785, 4832/28000 datapoints
2025-03-07 09:59:17,713 - INFO - training batch 201, loss: 0.433, 6432/28000 datapoints
2025-03-07 09:59:17,965 - INFO - training batch 251, loss: 0.491, 8032/28000 datapoints
2025-03-07 09:59:18,230 - INFO - training batch 301, loss: 0.571, 9632/28000 datapoints
2025-03-07 09:59:18,477 - INFO - training batch 351, loss: 0.436, 11232/28000 datapoints
2025-03-07 09:59:18,722 - INFO - training batch 401, loss: 0.713, 12832/28000 datapoints
2025-03-07 09:59:18,974 - INFO - training batch 451, loss: 0.490, 14432/28000 datapoints
2025-03-07 09:59:19,222 - INFO - training batch 501, loss: 0.312, 16032/28000 datapoints
2025-03-07 09:59:19,469 - INFO - training batch 551, loss: 0.522, 17632/28000 datapoints
2025-03-07 09:59:19,713 - INFO - training batch 601, loss: 0.901, 19232/28000 datapoints
2025-03-07 09:59:19,967 - INFO - training batch 651, loss: 0.206, 20832/28000 datapoints
2025-03-07 09:59:20,223 - INFO - training batch 701, loss: 0.405, 22432/28000 datapoints
2025-03-07 09:59:20,544 - INFO - training batch 751, loss: 0.246, 24032/28000 datapoints
2025-03-07 09:59:20,813 - INFO - training batch 801, loss: 0.327, 25632/28000 datapoints
2025-03-07 09:59:21,055 - INFO - training batch 851, loss: 0.815, 27232/28000 datapoints
2025-03-07 09:59:21,184 - INFO - validation batch 1, loss: 0.179, 32/6976 datapoints
2025-03-07 09:59:21,257 - INFO - validation batch 51, loss: 1.287, 1632/6976 datapoints
2025-03-07 09:59:21,346 - INFO - validation batch 101, loss: 0.268, 3232/6976 datapoints
2025-03-07 09:59:21,432 - INFO - validation batch 151, loss: 0.521, 4832/6976 datapoints
2025-03-07 09:59:21,512 - INFO - validation batch 201, loss: 0.862, 6432/6976 datapoints
2025-03-07 09:59:21,540 - INFO - Epoch 62/800 done.
2025-03-07 09:59:21,541 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.858top-5 acc: 0.858
2025-03-07 09:59:21,541 - INFO - Beginning epoch 63/800
2025-03-07 09:59:21,549 - INFO - training batch 1, loss: 0.343, 32/28000 datapoints
2025-03-07 09:59:21,785 - INFO - training batch 51, loss: 0.385, 1632/28000 datapoints
2025-03-07 09:59:22,065 - INFO - training batch 101, loss: 0.330, 3232/28000 datapoints
2025-03-07 09:59:22,336 - INFO - training batch 151, loss: 0.775, 4832/28000 datapoints
2025-03-07 09:59:22,576 - INFO - training batch 201, loss: 0.429, 6432/28000 datapoints
2025-03-07 09:59:22,826 - INFO - training batch 251, loss: 0.487, 8032/28000 datapoints
2025-03-07 09:59:23,075 - INFO - training batch 301, loss: 0.571, 9632/28000 datapoints
2025-03-07 09:59:23,312 - INFO - training batch 351, loss: 0.432, 11232/28000 datapoints
2025-03-07 09:59:23,551 - INFO - training batch 401, loss: 0.705, 12832/28000 datapoints
2025-03-07 09:59:23,782 - INFO - training batch 451, loss: 0.483, 14432/28000 datapoints
2025-03-07 09:59:24,016 - INFO - training batch 501, loss: 0.306, 16032/28000 datapoints
2025-03-07 09:59:24,262 - INFO - training batch 551, loss: 0.514, 17632/28000 datapoints
2025-03-07 09:59:24,499 - INFO - training batch 601, loss: 0.892, 19232/28000 datapoints
2025-03-07 09:59:24,737 - INFO - training batch 651, loss: 0.196, 20832/28000 datapoints
2025-03-07 09:59:24,970 - INFO - training batch 701, loss: 0.400, 22432/28000 datapoints
2025-03-07 09:59:25,206 - INFO - training batch 751, loss: 0.244, 24032/28000 datapoints
2025-03-07 09:59:25,440 - INFO - training batch 801, loss: 0.324, 25632/28000 datapoints
2025-03-07 09:59:25,685 - INFO - training batch 851, loss: 0.806, 27232/28000 datapoints
2025-03-07 09:59:25,804 - INFO - validation batch 1, loss: 0.177, 32/6976 datapoints
2025-03-07 09:59:25,876 - INFO - validation batch 51, loss: 1.280, 1632/6976 datapoints
2025-03-07 09:59:25,949 - INFO - validation batch 101, loss: 0.266, 3232/6976 datapoints
2025-03-07 09:59:26,023 - INFO - validation batch 151, loss: 0.513, 4832/6976 datapoints
2025-03-07 09:59:26,097 - INFO - validation batch 201, loss: 0.867, 6432/6976 datapoints
2025-03-07 09:59:26,121 - INFO - Epoch 63/800 done.
2025-03-07 09:59:26,121 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.859top-5 acc: 0.859
2025-03-07 09:59:26,122 - INFO - Beginning epoch 64/800
2025-03-07 09:59:26,128 - INFO - training batch 1, loss: 0.339, 32/28000 datapoints
2025-03-07 09:59:26,376 - INFO - training batch 51, loss: 0.377, 1632/28000 datapoints
2025-03-07 09:59:26,624 - INFO - training batch 101, loss: 0.328, 3232/28000 datapoints
2025-03-07 09:59:26,867 - INFO - training batch 151, loss: 0.767, 4832/28000 datapoints
2025-03-07 09:59:27,148 - INFO - training batch 201, loss: 0.423, 6432/28000 datapoints
2025-03-07 09:59:27,396 - INFO - training batch 251, loss: 0.483, 8032/28000 datapoints
2025-03-07 09:59:27,647 - INFO - training batch 301, loss: 0.570, 9632/28000 datapoints
2025-03-07 09:59:27,901 - INFO - training batch 351, loss: 0.426, 11232/28000 datapoints
2025-03-07 09:59:28,157 - INFO - training batch 401, loss: 0.696, 12832/28000 datapoints
2025-03-07 09:59:28,404 - INFO - training batch 451, loss: 0.477, 14432/28000 datapoints
2025-03-07 09:59:28,647 - INFO - training batch 501, loss: 0.301, 16032/28000 datapoints
2025-03-07 09:59:28,910 - INFO - training batch 551, loss: 0.505, 17632/28000 datapoints
2025-03-07 09:59:29,193 - INFO - training batch 601, loss: 0.883, 19232/28000 datapoints
2025-03-07 09:59:29,497 - INFO - training batch 651, loss: 0.189, 20832/28000 datapoints
2025-03-07 09:59:29,768 - INFO - training batch 701, loss: 0.395, 22432/28000 datapoints
2025-03-07 09:59:30,050 - INFO - training batch 751, loss: 0.243, 24032/28000 datapoints
2025-03-07 09:59:30,391 - INFO - training batch 801, loss: 0.321, 25632/28000 datapoints
2025-03-07 09:59:30,808 - INFO - training batch 851, loss: 0.797, 27232/28000 datapoints
2025-03-07 09:59:30,956 - INFO - validation batch 1, loss: 0.175, 32/6976 datapoints
2025-03-07 09:59:31,165 - INFO - validation batch 51, loss: 1.273, 1632/6976 datapoints
2025-03-07 09:59:31,395 - INFO - validation batch 101, loss: 0.264, 3232/6976 datapoints
2025-03-07 09:59:31,573 - INFO - validation batch 151, loss: 0.504, 4832/6976 datapoints
2025-03-07 09:59:31,690 - INFO - validation batch 201, loss: 0.870, 6432/6976 datapoints
2025-03-07 09:59:31,727 - INFO - Epoch 64/800 done.
2025-03-07 09:59:31,729 - INFO - Final validation performance:
Loss: 0.617, top-1 acc: 0.860top-5 acc: 0.860
2025-03-07 09:59:31,730 - INFO - Beginning epoch 65/800
2025-03-07 09:59:31,746 - INFO - training batch 1, loss: 0.335, 32/28000 datapoints
2025-03-07 09:59:32,215 - INFO - training batch 51, loss: 0.371, 1632/28000 datapoints
2025-03-07 09:59:32,661 - INFO - training batch 101, loss: 0.327, 3232/28000 datapoints
2025-03-07 09:59:33,007 - INFO - training batch 151, loss: 0.757, 4832/28000 datapoints
2025-03-07 09:59:33,329 - INFO - training batch 201, loss: 0.418, 6432/28000 datapoints
2025-03-07 09:59:33,660 - INFO - training batch 251, loss: 0.479, 8032/28000 datapoints
2025-03-07 09:59:34,089 - INFO - training batch 301, loss: 0.571, 9632/28000 datapoints
2025-03-07 09:59:34,475 - INFO - training batch 351, loss: 0.422, 11232/28000 datapoints
2025-03-07 09:59:34,792 - INFO - training batch 401, loss: 0.688, 12832/28000 datapoints
2025-03-07 09:59:35,110 - INFO - training batch 451, loss: 0.470, 14432/28000 datapoints
2025-03-07 09:59:35,485 - INFO - training batch 501, loss: 0.297, 16032/28000 datapoints
2025-03-07 09:59:35,808 - INFO - training batch 551, loss: 0.497, 17632/28000 datapoints
2025-03-07 09:59:36,124 - INFO - training batch 601, loss: 0.873, 19232/28000 datapoints
2025-03-07 09:59:36,445 - INFO - training batch 651, loss: 0.181, 20832/28000 datapoints
2025-03-07 09:59:36,741 - INFO - training batch 701, loss: 0.389, 22432/28000 datapoints
2025-03-07 09:59:37,020 - INFO - training batch 751, loss: 0.241, 24032/28000 datapoints
2025-03-07 09:59:37,293 - INFO - training batch 801, loss: 0.317, 25632/28000 datapoints
2025-03-07 09:59:37,588 - INFO - training batch 851, loss: 0.785, 27232/28000 datapoints
2025-03-07 09:59:37,758 - INFO - validation batch 1, loss: 0.173, 32/6976 datapoints
2025-03-07 09:59:37,863 - INFO - validation batch 51, loss: 1.267, 1632/6976 datapoints
2025-03-07 09:59:37,958 - INFO - validation batch 101, loss: 0.261, 3232/6976 datapoints
2025-03-07 09:59:38,046 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-07 09:59:38,133 - INFO - validation batch 201, loss: 0.873, 6432/6976 datapoints
2025-03-07 09:59:38,162 - INFO - Epoch 65/800 done.
2025-03-07 09:59:38,162 - INFO - Final validation performance:
Loss: 0.614, top-1 acc: 0.862top-5 acc: 0.862
2025-03-07 09:59:38,163 - INFO - Beginning epoch 66/800
2025-03-07 09:59:38,171 - INFO - training batch 1, loss: 0.332, 32/28000 datapoints
2025-03-07 09:59:38,446 - INFO - training batch 51, loss: 0.364, 1632/28000 datapoints
2025-03-07 09:59:38,725 - INFO - training batch 101, loss: 0.327, 3232/28000 datapoints
2025-03-07 09:59:39,013 - INFO - training batch 151, loss: 0.746, 4832/28000 datapoints
2025-03-07 09:59:39,343 - INFO - training batch 201, loss: 0.412, 6432/28000 datapoints
2025-03-07 09:59:39,748 - INFO - training batch 251, loss: 0.475, 8032/28000 datapoints
2025-03-07 09:59:40,108 - INFO - training batch 301, loss: 0.571, 9632/28000 datapoints
2025-03-07 09:59:40,553 - INFO - training batch 351, loss: 0.416, 11232/28000 datapoints
2025-03-07 09:59:40,980 - INFO - training batch 401, loss: 0.680, 12832/28000 datapoints
2025-03-07 09:59:41,433 - INFO - training batch 451, loss: 0.463, 14432/28000 datapoints
2025-03-07 09:59:41,775 - INFO - training batch 501, loss: 0.293, 16032/28000 datapoints
2025-03-07 09:59:42,129 - INFO - training batch 551, loss: 0.489, 17632/28000 datapoints
2025-03-07 09:59:42,452 - INFO - training batch 601, loss: 0.864, 19232/28000 datapoints
2025-03-07 09:59:42,756 - INFO - training batch 651, loss: 0.174, 20832/28000 datapoints
2025-03-07 09:59:43,057 - INFO - training batch 701, loss: 0.385, 22432/28000 datapoints
2025-03-07 09:59:43,332 - INFO - training batch 751, loss: 0.239, 24032/28000 datapoints
2025-03-07 09:59:43,588 - INFO - training batch 801, loss: 0.313, 25632/28000 datapoints
2025-03-07 09:59:43,839 - INFO - training batch 851, loss: 0.776, 27232/28000 datapoints
2025-03-07 09:59:43,973 - INFO - validation batch 1, loss: 0.172, 32/6976 datapoints
2025-03-07 09:59:44,054 - INFO - validation batch 51, loss: 1.262, 1632/6976 datapoints
2025-03-07 09:59:44,128 - INFO - validation batch 101, loss: 0.259, 3232/6976 datapoints
2025-03-07 09:59:44,208 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-07 09:59:44,301 - INFO - validation batch 201, loss: 0.876, 6432/6976 datapoints
2025-03-07 09:59:44,326 - INFO - Epoch 66/800 done.
2025-03-07 09:59:44,326 - INFO - Final validation performance:
Loss: 0.611, top-1 acc: 0.863top-5 acc: 0.863
2025-03-07 09:59:44,327 - INFO - Beginning epoch 67/800
2025-03-07 09:59:44,334 - INFO - training batch 1, loss: 0.328, 32/28000 datapoints
2025-03-07 09:59:44,591 - INFO - training batch 51, loss: 0.357, 1632/28000 datapoints
2025-03-07 09:59:44,856 - INFO - training batch 101, loss: 0.328, 3232/28000 datapoints
2025-03-07 09:59:45,168 - INFO - training batch 151, loss: 0.737, 4832/28000 datapoints
2025-03-07 09:59:45,455 - INFO - training batch 201, loss: 0.407, 6432/28000 datapoints
2025-03-07 09:59:45,803 - INFO - training batch 251, loss: 0.470, 8032/28000 datapoints
2025-03-07 09:59:46,122 - INFO - training batch 301, loss: 0.571, 9632/28000 datapoints
2025-03-07 09:59:46,394 - INFO - training batch 351, loss: 0.411, 11232/28000 datapoints
2025-03-07 09:59:46,714 - INFO - training batch 401, loss: 0.672, 12832/28000 datapoints
2025-03-07 09:59:47,125 - INFO - training batch 451, loss: 0.457, 14432/28000 datapoints
2025-03-07 09:59:47,584 - INFO - training batch 501, loss: 0.288, 16032/28000 datapoints
2025-03-07 09:59:47,926 - INFO - training batch 551, loss: 0.482, 17632/28000 datapoints
2025-03-07 09:59:48,276 - INFO - training batch 601, loss: 0.854, 19232/28000 datapoints
2025-03-07 09:59:48,595 - INFO - training batch 651, loss: 0.168, 20832/28000 datapoints
2025-03-07 09:59:49,062 - INFO - training batch 701, loss: 0.380, 22432/28000 datapoints
2025-03-07 09:59:49,477 - INFO - training batch 751, loss: 0.237, 24032/28000 datapoints
2025-03-07 09:59:51,007 - INFO - training batch 801, loss: 0.310, 25632/28000 datapoints
2025-03-07 09:59:52,102 - INFO - training batch 851, loss: 0.766, 27232/28000 datapoints
2025-03-07 09:59:52,580 - INFO - validation batch 1, loss: 0.171, 32/6976 datapoints
2025-03-07 09:59:52,791 - INFO - validation batch 51, loss: 1.256, 1632/6976 datapoints
2025-03-07 09:59:52,936 - INFO - validation batch 101, loss: 0.258, 3232/6976 datapoints
2025-03-07 09:59:53,072 - INFO - validation batch 151, loss: 0.479, 4832/6976 datapoints
2025-03-07 09:59:53,239 - INFO - validation batch 201, loss: 0.877, 6432/6976 datapoints
2025-03-07 09:59:53,351 - INFO - Epoch 67/800 done.
2025-03-07 09:59:53,351 - INFO - Final validation performance:
Loss: 0.608, top-1 acc: 0.864top-5 acc: 0.864
2025-03-07 09:59:53,352 - INFO - Beginning epoch 68/800
2025-03-07 09:59:53,364 - INFO - training batch 1, loss: 0.326, 32/28000 datapoints
2025-03-07 09:59:54,134 - INFO - training batch 51, loss: 0.351, 1632/28000 datapoints
2025-03-07 09:59:54,464 - INFO - training batch 101, loss: 0.328, 3232/28000 datapoints
2025-03-07 09:59:54,777 - INFO - training batch 151, loss: 0.727, 4832/28000 datapoints
2025-03-07 09:59:55,033 - INFO - training batch 201, loss: 0.402, 6432/28000 datapoints
2025-03-07 09:59:55,294 - INFO - training batch 251, loss: 0.466, 8032/28000 datapoints
2025-03-07 09:59:55,582 - INFO - training batch 301, loss: 0.572, 9632/28000 datapoints
2025-03-07 09:59:55,891 - INFO - training batch 351, loss: 0.407, 11232/28000 datapoints
2025-03-07 09:59:56,310 - INFO - training batch 401, loss: 0.664, 12832/28000 datapoints
2025-03-07 09:59:56,581 - INFO - training batch 451, loss: 0.451, 14432/28000 datapoints
2025-03-07 09:59:57,946 - INFO - training batch 501, loss: 0.283, 16032/28000 datapoints
2025-03-07 09:59:58,752 - INFO - training batch 551, loss: 0.474, 17632/28000 datapoints
2025-03-07 09:59:59,952 - INFO - training batch 601, loss: 0.846, 19232/28000 datapoints
2025-03-07 10:00:00,714 - INFO - training batch 651, loss: 0.162, 20832/28000 datapoints
2025-03-07 10:00:01,912 - INFO - training batch 701, loss: 0.376, 22432/28000 datapoints
2025-03-07 10:00:02,441 - INFO - training batch 751, loss: 0.234, 24032/28000 datapoints
2025-03-07 10:00:02,926 - INFO - training batch 801, loss: 0.307, 25632/28000 datapoints
2025-03-07 10:00:04,081 - INFO - training batch 851, loss: 0.757, 27232/28000 datapoints
2025-03-07 10:00:04,591 - INFO - validation batch 1, loss: 0.169, 32/6976 datapoints
2025-03-07 10:00:04,685 - INFO - validation batch 51, loss: 1.250, 1632/6976 datapoints
2025-03-07 10:00:04,782 - INFO - validation batch 101, loss: 0.258, 3232/6976 datapoints
2025-03-07 10:00:04,884 - INFO - validation batch 151, loss: 0.471, 4832/6976 datapoints
2025-03-07 10:00:04,977 - INFO - validation batch 201, loss: 0.880, 6432/6976 datapoints
2025-03-07 10:00:05,010 - INFO - Epoch 68/800 done.
2025-03-07 10:00:05,011 - INFO - Final validation performance:
Loss: 0.605, top-1 acc: 0.864top-5 acc: 0.864
2025-03-07 10:00:05,013 - INFO - Beginning epoch 69/800
2025-03-07 10:00:05,023 - INFO - training batch 1, loss: 0.322, 32/28000 datapoints
2025-03-07 10:00:05,363 - INFO - training batch 51, loss: 0.343, 1632/28000 datapoints
2025-03-07 10:00:05,679 - INFO - training batch 101, loss: 0.329, 3232/28000 datapoints
2025-03-07 10:00:06,321 - INFO - training batch 151, loss: 0.718, 4832/28000 datapoints
2025-03-07 10:00:07,583 - INFO - training batch 201, loss: 0.397, 6432/28000 datapoints
2025-03-07 10:00:08,112 - INFO - training batch 251, loss: 0.461, 8032/28000 datapoints
2025-03-07 10:00:08,766 - INFO - training batch 301, loss: 0.573, 9632/28000 datapoints
2025-03-07 10:00:09,149 - INFO - training batch 351, loss: 0.403, 11232/28000 datapoints
2025-03-07 10:00:09,856 - INFO - training batch 401, loss: 0.656, 12832/28000 datapoints
2025-03-07 10:00:10,579 - INFO - training batch 451, loss: 0.444, 14432/28000 datapoints
2025-03-07 10:00:10,976 - INFO - training batch 501, loss: 0.279, 16032/28000 datapoints
2025-03-07 10:00:12,148 - INFO - training batch 551, loss: 0.467, 17632/28000 datapoints
2025-03-07 10:00:12,789 - INFO - training batch 601, loss: 0.836, 19232/28000 datapoints
2025-03-07 10:00:13,068 - INFO - training batch 651, loss: 0.157, 20832/28000 datapoints
2025-03-07 10:00:13,861 - INFO - training batch 701, loss: 0.373, 22432/28000 datapoints
2025-03-07 10:00:14,461 - INFO - training batch 751, loss: 0.232, 24032/28000 datapoints
2025-03-07 10:00:14,950 - INFO - training batch 801, loss: 0.304, 25632/28000 datapoints
2025-03-07 10:00:15,869 - INFO - training batch 851, loss: 0.746, 27232/28000 datapoints
2025-03-07 10:00:16,064 - INFO - validation batch 1, loss: 0.169, 32/6976 datapoints
2025-03-07 10:00:16,151 - INFO - validation batch 51, loss: 1.248, 1632/6976 datapoints
2025-03-07 10:00:16,249 - INFO - validation batch 101, loss: 0.257, 3232/6976 datapoints
2025-03-07 10:00:16,375 - INFO - validation batch 151, loss: 0.461, 4832/6976 datapoints
2025-03-07 10:00:16,574 - INFO - validation batch 201, loss: 0.882, 6432/6976 datapoints
2025-03-07 10:00:16,673 - INFO - Epoch 69/800 done.
2025-03-07 10:00:16,674 - INFO - Final validation performance:
Loss: 0.603, top-1 acc: 0.864top-5 acc: 0.864
2025-03-07 10:00:16,675 - INFO - Beginning epoch 70/800
2025-03-07 10:00:16,699 - INFO - training batch 1, loss: 0.320, 32/28000 datapoints
2025-03-07 10:00:17,261 - INFO - training batch 51, loss: 0.337, 1632/28000 datapoints
2025-03-07 10:00:18,389 - INFO - training batch 101, loss: 0.331, 3232/28000 datapoints
2025-03-07 10:00:18,740 - INFO - training batch 151, loss: 0.710, 4832/28000 datapoints
2025-03-07 10:00:19,178 - INFO - training batch 201, loss: 0.391, 6432/28000 datapoints
2025-03-07 10:00:19,537 - INFO - training batch 251, loss: 0.457, 8032/28000 datapoints
2025-03-07 10:00:19,822 - INFO - training batch 301, loss: 0.577, 9632/28000 datapoints
2025-03-07 10:00:20,237 - INFO - training batch 351, loss: 0.398, 11232/28000 datapoints
2025-03-07 10:00:20,711 - INFO - training batch 401, loss: 0.647, 12832/28000 datapoints
2025-03-07 10:00:22,192 - INFO - training batch 451, loss: 0.438, 14432/28000 datapoints
2025-03-07 10:00:23,029 - INFO - training batch 501, loss: 0.274, 16032/28000 datapoints
2025-03-07 10:00:23,781 - INFO - training batch 551, loss: 0.459, 17632/28000 datapoints
2025-03-07 10:00:24,181 - INFO - training batch 601, loss: 0.828, 19232/28000 datapoints
2025-03-07 10:00:24,589 - INFO - training batch 651, loss: 0.153, 20832/28000 datapoints
2025-03-07 10:00:25,116 - INFO - training batch 701, loss: 0.369, 22432/28000 datapoints
2025-03-07 10:00:25,471 - INFO - training batch 751, loss: 0.231, 24032/28000 datapoints
2025-03-07 10:00:25,761 - INFO - training batch 801, loss: 0.301, 25632/28000 datapoints
2025-03-07 10:00:26,028 - INFO - training batch 851, loss: 0.735, 27232/28000 datapoints
2025-03-07 10:00:26,168 - INFO - validation batch 1, loss: 0.169, 32/6976 datapoints
2025-03-07 10:00:26,262 - INFO - validation batch 51, loss: 1.246, 1632/6976 datapoints
2025-03-07 10:00:26,363 - INFO - validation batch 101, loss: 0.257, 3232/6976 datapoints
2025-03-07 10:00:26,498 - INFO - validation batch 151, loss: 0.453, 4832/6976 datapoints
2025-03-07 10:00:26,642 - INFO - validation batch 201, loss: 0.883, 6432/6976 datapoints
2025-03-07 10:00:26,682 - INFO - Epoch 70/800 done.
2025-03-07 10:00:26,682 - INFO - Final validation performance:
Loss: 0.601, top-1 acc: 0.866top-5 acc: 0.866
2025-03-07 10:00:26,685 - INFO - Beginning epoch 71/800
2025-03-07 10:00:26,698 - INFO - training batch 1, loss: 0.316, 32/28000 datapoints
2025-03-07 10:00:27,005 - INFO - training batch 51, loss: 0.332, 1632/28000 datapoints
2025-03-07 10:00:27,315 - INFO - training batch 101, loss: 0.329, 3232/28000 datapoints
2025-03-07 10:00:27,689 - INFO - training batch 151, loss: 0.698, 4832/28000 datapoints
2025-03-07 10:00:28,103 - INFO - training batch 201, loss: 0.387, 6432/28000 datapoints
2025-03-07 10:00:28,538 - INFO - training batch 251, loss: 0.452, 8032/28000 datapoints
2025-03-07 10:00:28,807 - INFO - training batch 301, loss: 0.578, 9632/28000 datapoints
2025-03-07 10:00:29,138 - INFO - training batch 351, loss: 0.394, 11232/28000 datapoints
2025-03-07 10:00:29,464 - INFO - training batch 401, loss: 0.638, 12832/28000 datapoints
2025-03-07 10:00:29,803 - INFO - training batch 451, loss: 0.433, 14432/28000 datapoints
2025-03-07 10:00:30,084 - INFO - training batch 501, loss: 0.270, 16032/28000 datapoints
2025-03-07 10:00:30,390 - INFO - training batch 551, loss: 0.450, 17632/28000 datapoints
2025-03-07 10:00:30,658 - INFO - training batch 601, loss: 0.819, 19232/28000 datapoints
2025-03-07 10:00:30,912 - INFO - training batch 651, loss: 0.148, 20832/28000 datapoints
2025-03-07 10:00:31,159 - INFO - training batch 701, loss: 0.366, 22432/28000 datapoints
2025-03-07 10:00:31,429 - INFO - training batch 751, loss: 0.229, 24032/28000 datapoints
2025-03-07 10:00:31,673 - INFO - training batch 801, loss: 0.297, 25632/28000 datapoints
2025-03-07 10:00:31,931 - INFO - training batch 851, loss: 0.722, 27232/28000 datapoints
2025-03-07 10:00:32,103 - INFO - validation batch 1, loss: 0.168, 32/6976 datapoints
2025-03-07 10:00:32,295 - INFO - validation batch 51, loss: 1.242, 1632/6976 datapoints
2025-03-07 10:00:32,466 - INFO - validation batch 101, loss: 0.257, 3232/6976 datapoints
2025-03-07 10:00:32,550 - INFO - validation batch 151, loss: 0.445, 4832/6976 datapoints
2025-03-07 10:00:32,636 - INFO - validation batch 201, loss: 0.885, 6432/6976 datapoints
2025-03-07 10:00:32,667 - INFO - Epoch 71/800 done.
2025-03-07 10:00:32,668 - INFO - Final validation performance:
Loss: 0.599, top-1 acc: 0.866top-5 acc: 0.866
2025-03-07 10:00:32,668 - INFO - Beginning epoch 72/800
2025-03-07 10:00:32,676 - INFO - training batch 1, loss: 0.314, 32/28000 datapoints
2025-03-07 10:00:33,079 - INFO - training batch 51, loss: 0.326, 1632/28000 datapoints
2025-03-07 10:00:33,372 - INFO - training batch 101, loss: 0.327, 3232/28000 datapoints
2025-03-07 10:00:33,645 - INFO - training batch 151, loss: 0.689, 4832/28000 datapoints
2025-03-07 10:00:33,908 - INFO - training batch 201, loss: 0.383, 6432/28000 datapoints
2025-03-07 10:00:34,159 - INFO - training batch 251, loss: 0.448, 8032/28000 datapoints
2025-03-07 10:00:34,438 - INFO - training batch 301, loss: 0.580, 9632/28000 datapoints
2025-03-07 10:00:34,688 - INFO - training batch 351, loss: 0.389, 11232/28000 datapoints
2025-03-07 10:00:34,955 - INFO - training batch 401, loss: 0.631, 12832/28000 datapoints
2025-03-07 10:00:35,455 - INFO - training batch 451, loss: 0.427, 14432/28000 datapoints
2025-03-07 10:00:35,715 - INFO - training batch 501, loss: 0.266, 16032/28000 datapoints
2025-03-07 10:00:35,969 - INFO - training batch 551, loss: 0.443, 17632/28000 datapoints
2025-03-07 10:00:36,213 - INFO - training batch 601, loss: 0.810, 19232/28000 datapoints
2025-03-07 10:00:36,470 - INFO - training batch 651, loss: 0.144, 20832/28000 datapoints
2025-03-07 10:00:36,707 - INFO - training batch 701, loss: 0.363, 22432/28000 datapoints
2025-03-07 10:00:36,961 - INFO - training batch 751, loss: 0.229, 24032/28000 datapoints
2025-03-07 10:00:37,213 - INFO - training batch 801, loss: 0.294, 25632/28000 datapoints
2025-03-07 10:00:37,473 - INFO - training batch 851, loss: 0.712, 27232/28000 datapoints
2025-03-07 10:00:37,587 - INFO - validation batch 1, loss: 0.167, 32/6976 datapoints
2025-03-07 10:00:37,653 - INFO - validation batch 51, loss: 1.239, 1632/6976 datapoints
2025-03-07 10:00:37,726 - INFO - validation batch 101, loss: 0.257, 3232/6976 datapoints
2025-03-07 10:00:37,793 - INFO - validation batch 151, loss: 0.439, 4832/6976 datapoints
2025-03-07 10:00:37,863 - INFO - validation batch 201, loss: 0.886, 6432/6976 datapoints
2025-03-07 10:00:37,885 - INFO - Epoch 72/800 done.
2025-03-07 10:00:37,885 - INFO - Final validation performance:
Loss: 0.598, top-1 acc: 0.867top-5 acc: 0.867
2025-03-07 10:00:37,886 - INFO - Beginning epoch 73/800
2025-03-07 10:00:37,895 - INFO - training batch 1, loss: 0.311, 32/28000 datapoints
2025-03-07 10:00:38,133 - INFO - training batch 51, loss: 0.320, 1632/28000 datapoints
2025-03-07 10:00:38,372 - INFO - training batch 101, loss: 0.324, 3232/28000 datapoints
2025-03-07 10:00:38,600 - INFO - training batch 151, loss: 0.680, 4832/28000 datapoints
2025-03-07 10:00:38,843 - INFO - training batch 201, loss: 0.377, 6432/28000 datapoints
2025-03-07 10:00:39,103 - INFO - training batch 251, loss: 0.444, 8032/28000 datapoints
2025-03-07 10:00:39,354 - INFO - training batch 301, loss: 0.582, 9632/28000 datapoints
2025-03-07 10:00:39,613 - INFO - training batch 351, loss: 0.385, 11232/28000 datapoints
2025-03-07 10:00:39,866 - INFO - training batch 401, loss: 0.625, 12832/28000 datapoints
2025-03-07 10:00:40,106 - INFO - training batch 451, loss: 0.422, 14432/28000 datapoints
2025-03-07 10:00:40,360 - INFO - training batch 501, loss: 0.263, 16032/28000 datapoints
2025-03-07 10:00:40,823 - INFO - training batch 551, loss: 0.435, 17632/28000 datapoints
2025-03-07 10:00:41,072 - INFO - training batch 601, loss: 0.802, 19232/28000 datapoints
2025-03-07 10:00:41,370 - INFO - training batch 651, loss: 0.141, 20832/28000 datapoints
2025-03-07 10:00:41,640 - INFO - training batch 701, loss: 0.360, 22432/28000 datapoints
2025-03-07 10:00:41,992 - INFO - training batch 751, loss: 0.228, 24032/28000 datapoints
2025-03-07 10:00:42,380 - INFO - training batch 801, loss: 0.292, 25632/28000 datapoints
2025-03-07 10:00:42,662 - INFO - training batch 851, loss: 0.702, 27232/28000 datapoints
2025-03-07 10:00:42,969 - INFO - validation batch 1, loss: 0.167, 32/6976 datapoints
2025-03-07 10:00:43,063 - INFO - validation batch 51, loss: 1.238, 1632/6976 datapoints
2025-03-07 10:00:43,188 - INFO - validation batch 101, loss: 0.257, 3232/6976 datapoints
2025-03-07 10:00:43,324 - INFO - validation batch 151, loss: 0.432, 4832/6976 datapoints
2025-03-07 10:00:43,415 - INFO - validation batch 201, loss: 0.889, 6432/6976 datapoints
2025-03-07 10:00:43,461 - INFO - Epoch 73/800 done.
2025-03-07 10:00:43,464 - INFO - Final validation performance:
Loss: 0.596, top-1 acc: 0.868top-5 acc: 0.868
2025-03-07 10:00:43,466 - INFO - Beginning epoch 74/800
2025-03-07 10:00:43,475 - INFO - training batch 1, loss: 0.308, 32/28000 datapoints
2025-03-07 10:00:43,814 - INFO - training batch 51, loss: 0.314, 1632/28000 datapoints
2025-03-07 10:00:44,368 - INFO - training batch 101, loss: 0.322, 3232/28000 datapoints
2025-03-07 10:00:44,741 - INFO - training batch 151, loss: 0.669, 4832/28000 datapoints
2025-03-07 10:00:45,072 - INFO - training batch 201, loss: 0.373, 6432/28000 datapoints
2025-03-07 10:00:45,353 - INFO - training batch 251, loss: 0.441, 8032/28000 datapoints
2025-03-07 10:00:45,616 - INFO - training batch 301, loss: 0.584, 9632/28000 datapoints
2025-03-07 10:00:45,927 - INFO - training batch 351, loss: 0.381, 11232/28000 datapoints
2025-03-07 10:00:46,181 - INFO - training batch 401, loss: 0.618, 12832/28000 datapoints
2025-03-07 10:00:46,422 - INFO - training batch 451, loss: 0.418, 14432/28000 datapoints
2025-03-07 10:00:46,658 - INFO - training batch 501, loss: 0.259, 16032/28000 datapoints
2025-03-07 10:00:46,908 - INFO - training batch 551, loss: 0.428, 17632/28000 datapoints
2025-03-07 10:00:47,149 - INFO - training batch 601, loss: 0.795, 19232/28000 datapoints
2025-03-07 10:00:47,413 - INFO - training batch 651, loss: 0.137, 20832/28000 datapoints
2025-03-07 10:00:47,684 - INFO - training batch 701, loss: 0.357, 22432/28000 datapoints
2025-03-07 10:00:48,246 - INFO - training batch 751, loss: 0.226, 24032/28000 datapoints
2025-03-07 10:00:50,282 - INFO - training batch 801, loss: 0.289, 25632/28000 datapoints
2025-03-07 10:00:50,799 - INFO - training batch 851, loss: 0.692, 27232/28000 datapoints
2025-03-07 10:00:51,035 - INFO - validation batch 1, loss: 0.166, 32/6976 datapoints
2025-03-07 10:00:51,218 - INFO - validation batch 51, loss: 1.234, 1632/6976 datapoints
2025-03-07 10:00:51,337 - INFO - validation batch 101, loss: 0.257, 3232/6976 datapoints
2025-03-07 10:00:51,434 - INFO - validation batch 151, loss: 0.427, 4832/6976 datapoints
2025-03-07 10:00:51,559 - INFO - validation batch 201, loss: 0.890, 6432/6976 datapoints
2025-03-07 10:00:51,607 - INFO - Epoch 74/800 done.
2025-03-07 10:00:51,607 - INFO - Final validation performance:
Loss: 0.595, top-1 acc: 0.868top-5 acc: 0.868
2025-03-07 10:00:51,608 - INFO - Beginning epoch 75/800
2025-03-07 10:00:51,619 - INFO - training batch 1, loss: 0.305, 32/28000 datapoints
2025-03-07 10:00:52,041 - INFO - training batch 51, loss: 0.310, 1632/28000 datapoints
2025-03-07 10:00:52,377 - INFO - training batch 101, loss: 0.320, 3232/28000 datapoints
2025-03-07 10:00:52,681 - INFO - training batch 151, loss: 0.660, 4832/28000 datapoints
2025-03-07 10:00:52,933 - INFO - training batch 201, loss: 0.367, 6432/28000 datapoints
2025-03-07 10:00:53,206 - INFO - training batch 251, loss: 0.437, 8032/28000 datapoints
2025-03-07 10:00:53,481 - INFO - training batch 301, loss: 0.585, 9632/28000 datapoints
2025-03-07 10:00:53,767 - INFO - training batch 351, loss: 0.379, 11232/28000 datapoints
2025-03-07 10:00:54,022 - INFO - training batch 401, loss: 0.611, 12832/28000 datapoints
2025-03-07 10:00:54,299 - INFO - training batch 451, loss: 0.415, 14432/28000 datapoints
2025-03-07 10:00:54,542 - INFO - training batch 501, loss: 0.256, 16032/28000 datapoints
2025-03-07 10:00:54,818 - INFO - training batch 551, loss: 0.422, 17632/28000 datapoints
2025-03-07 10:00:55,083 - INFO - training batch 601, loss: 0.787, 19232/28000 datapoints
2025-03-07 10:00:55,324 - INFO - training batch 651, loss: 0.134, 20832/28000 datapoints
2025-03-07 10:00:55,557 - INFO - training batch 701, loss: 0.355, 22432/28000 datapoints
2025-03-07 10:00:55,807 - INFO - training batch 751, loss: 0.225, 24032/28000 datapoints
2025-03-07 10:00:56,042 - INFO - training batch 801, loss: 0.286, 25632/28000 datapoints
2025-03-07 10:00:56,275 - INFO - training batch 851, loss: 0.682, 27232/28000 datapoints
2025-03-07 10:00:56,385 - INFO - validation batch 1, loss: 0.166, 32/6976 datapoints
2025-03-07 10:00:56,449 - INFO - validation batch 51, loss: 1.231, 1632/6976 datapoints
2025-03-07 10:00:56,514 - INFO - validation batch 101, loss: 0.257, 3232/6976 datapoints
2025-03-07 10:00:56,588 - INFO - validation batch 151, loss: 0.422, 4832/6976 datapoints
2025-03-07 10:00:56,656 - INFO - validation batch 201, loss: 0.891, 6432/6976 datapoints
2025-03-07 10:00:56,677 - INFO - Epoch 75/800 done.
2025-03-07 10:00:56,677 - INFO - Final validation performance:
Loss: 0.593, top-1 acc: 0.868top-5 acc: 0.868
2025-03-07 10:00:56,678 - INFO - Beginning epoch 76/800
2025-03-07 10:00:56,684 - INFO - training batch 1, loss: 0.304, 32/28000 datapoints
2025-03-07 10:00:56,910 - INFO - training batch 51, loss: 0.304, 1632/28000 datapoints
2025-03-07 10:00:57,153 - INFO - training batch 101, loss: 0.317, 3232/28000 datapoints
2025-03-07 10:00:57,414 - INFO - training batch 151, loss: 0.648, 4832/28000 datapoints
2025-03-07 10:00:57,656 - INFO - training batch 201, loss: 0.361, 6432/28000 datapoints
2025-03-07 10:00:57,892 - INFO - training batch 251, loss: 0.433, 8032/28000 datapoints
2025-03-07 10:00:58,122 - INFO - training batch 301, loss: 0.587, 9632/28000 datapoints
2025-03-07 10:00:58,357 - INFO - training batch 351, loss: 0.375, 11232/28000 datapoints
2025-03-07 10:00:58,586 - INFO - training batch 401, loss: 0.606, 12832/28000 datapoints
2025-03-07 10:00:58,819 - INFO - training batch 451, loss: 0.411, 14432/28000 datapoints
2025-03-07 10:00:59,046 - INFO - training batch 501, loss: 0.253, 16032/28000 datapoints
2025-03-07 10:00:59,276 - INFO - training batch 551, loss: 0.415, 17632/28000 datapoints
2025-03-07 10:00:59,509 - INFO - training batch 601, loss: 0.778, 19232/28000 datapoints
2025-03-07 10:00:59,739 - INFO - training batch 651, loss: 0.132, 20832/28000 datapoints
2025-03-07 10:00:59,968 - INFO - training batch 701, loss: 0.352, 22432/28000 datapoints
2025-03-07 10:01:00,196 - INFO - training batch 751, loss: 0.225, 24032/28000 datapoints
2025-03-07 10:01:00,434 - INFO - training batch 801, loss: 0.284, 25632/28000 datapoints
2025-03-07 10:01:00,677 - INFO - training batch 851, loss: 0.671, 27232/28000 datapoints
2025-03-07 10:01:00,790 - INFO - validation batch 1, loss: 0.166, 32/6976 datapoints
2025-03-07 10:01:00,857 - INFO - validation batch 51, loss: 1.229, 1632/6976 datapoints
2025-03-07 10:01:00,934 - INFO - validation batch 101, loss: 0.257, 3232/6976 datapoints
2025-03-07 10:01:01,009 - INFO - validation batch 151, loss: 0.415, 4832/6976 datapoints
2025-03-07 10:01:01,079 - INFO - validation batch 201, loss: 0.894, 6432/6976 datapoints
2025-03-07 10:01:01,106 - INFO - Epoch 76/800 done.
2025-03-07 10:01:01,106 - INFO - Final validation performance:
Loss: 0.592, top-1 acc: 0.868top-5 acc: 0.868
2025-03-07 10:01:01,107 - INFO - Beginning epoch 77/800
2025-03-07 10:01:01,115 - INFO - training batch 1, loss: 0.300, 32/28000 datapoints
2025-03-07 10:01:01,361 - INFO - training batch 51, loss: 0.299, 1632/28000 datapoints
2025-03-07 10:01:01,606 - INFO - training batch 101, loss: 0.314, 3232/28000 datapoints
2025-03-07 10:01:01,873 - INFO - training batch 151, loss: 0.638, 4832/28000 datapoints
2025-03-07 10:01:02,107 - INFO - training batch 201, loss: 0.354, 6432/28000 datapoints
2025-03-07 10:01:02,336 - INFO - training batch 251, loss: 0.430, 8032/28000 datapoints
2025-03-07 10:01:02,581 - INFO - training batch 301, loss: 0.588, 9632/28000 datapoints
2025-03-07 10:01:02,831 - INFO - training batch 351, loss: 0.371, 11232/28000 datapoints
2025-03-07 10:01:03,090 - INFO - training batch 401, loss: 0.600, 12832/28000 datapoints
2025-03-07 10:01:03,334 - INFO - training batch 451, loss: 0.407, 14432/28000 datapoints
2025-03-07 10:01:03,586 - INFO - training batch 501, loss: 0.250, 16032/28000 datapoints
2025-03-07 10:01:03,846 - INFO - training batch 551, loss: 0.409, 17632/28000 datapoints
2025-03-07 10:01:04,095 - INFO - training batch 601, loss: 0.770, 19232/28000 datapoints
2025-03-07 10:01:04,343 - INFO - training batch 651, loss: 0.129, 20832/28000 datapoints
2025-03-07 10:01:04,575 - INFO - training batch 701, loss: 0.350, 22432/28000 datapoints
2025-03-07 10:01:04,820 - INFO - training batch 751, loss: 0.224, 24032/28000 datapoints
2025-03-07 10:01:05,057 - INFO - training batch 801, loss: 0.282, 25632/28000 datapoints
2025-03-07 10:01:05,291 - INFO - training batch 851, loss: 0.660, 27232/28000 datapoints
2025-03-07 10:01:05,418 - INFO - validation batch 1, loss: 0.166, 32/6976 datapoints
2025-03-07 10:01:05,492 - INFO - validation batch 51, loss: 1.227, 1632/6976 datapoints
2025-03-07 10:01:05,561 - INFO - validation batch 101, loss: 0.256, 3232/6976 datapoints
2025-03-07 10:01:05,628 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-07 10:01:05,700 - INFO - validation batch 201, loss: 0.895, 6432/6976 datapoints
2025-03-07 10:01:05,721 - INFO - Epoch 77/800 done.
2025-03-07 10:01:05,721 - INFO - Final validation performance:
Loss: 0.591, top-1 acc: 0.869top-5 acc: 0.869
2025-03-07 10:01:05,721 - INFO - Beginning epoch 78/800
2025-03-07 10:01:05,728 - INFO - training batch 1, loss: 0.298, 32/28000 datapoints
2025-03-07 10:01:05,967 - INFO - training batch 51, loss: 0.294, 1632/28000 datapoints
2025-03-07 10:01:06,201 - INFO - training batch 101, loss: 0.311, 3232/28000 datapoints
2025-03-07 10:01:06,436 - INFO - training batch 151, loss: 0.626, 4832/28000 datapoints
2025-03-07 10:01:06,675 - INFO - training batch 201, loss: 0.346, 6432/28000 datapoints
2025-03-07 10:01:06,962 - INFO - training batch 251, loss: 0.427, 8032/28000 datapoints
2025-03-07 10:01:07,358 - INFO - training batch 301, loss: 0.590, 9632/28000 datapoints
2025-03-07 10:01:07,890 - INFO - training batch 351, loss: 0.367, 11232/28000 datapoints
2025-03-07 10:01:08,429 - INFO - training batch 401, loss: 0.594, 12832/28000 datapoints
2025-03-07 10:01:08,675 - INFO - training batch 451, loss: 0.403, 14432/28000 datapoints
2025-03-07 10:01:08,926 - INFO - training batch 501, loss: 0.246, 16032/28000 datapoints
2025-03-07 10:01:09,198 - INFO - training batch 551, loss: 0.402, 17632/28000 datapoints
2025-03-07 10:01:09,478 - INFO - training batch 601, loss: 0.762, 19232/28000 datapoints
2025-03-07 10:01:09,754 - INFO - training batch 651, loss: 0.127, 20832/28000 datapoints
2025-03-07 10:01:10,003 - INFO - training batch 701, loss: 0.348, 22432/28000 datapoints
2025-03-07 10:01:10,271 - INFO - training batch 751, loss: 0.223, 24032/28000 datapoints
2025-03-07 10:01:10,523 - INFO - training batch 801, loss: 0.279, 25632/28000 datapoints
2025-03-07 10:01:10,771 - INFO - training batch 851, loss: 0.649, 27232/28000 datapoints
2025-03-07 10:01:10,889 - INFO - validation batch 1, loss: 0.165, 32/6976 datapoints
2025-03-07 10:01:10,959 - INFO - validation batch 51, loss: 1.225, 1632/6976 datapoints
2025-03-07 10:01:11,030 - INFO - validation batch 101, loss: 0.257, 3232/6976 datapoints
2025-03-07 10:01:11,103 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-07 10:01:11,173 - INFO - validation batch 201, loss: 0.895, 6432/6976 datapoints
2025-03-07 10:01:11,197 - INFO - Epoch 78/800 done.
2025-03-07 10:01:11,197 - INFO - Final validation performance:
Loss: 0.590, top-1 acc: 0.871top-5 acc: 0.871
2025-03-07 10:01:11,198 - INFO - Beginning epoch 79/800
2025-03-07 10:01:11,204 - INFO - training batch 1, loss: 0.296, 32/28000 datapoints
2025-03-07 10:01:11,438 - INFO - training batch 51, loss: 0.289, 1632/28000 datapoints
2025-03-07 10:01:11,679 - INFO - training batch 101, loss: 0.309, 3232/28000 datapoints
2025-03-07 10:01:12,010 - INFO - training batch 151, loss: 0.616, 4832/28000 datapoints
2025-03-07 10:01:12,251 - INFO - training batch 201, loss: 0.340, 6432/28000 datapoints
2025-03-07 10:01:12,477 - INFO - training batch 251, loss: 0.423, 8032/28000 datapoints
2025-03-07 10:01:12,730 - INFO - training batch 301, loss: 0.591, 9632/28000 datapoints
2025-03-07 10:01:12,991 - INFO - training batch 351, loss: 0.365, 11232/28000 datapoints
2025-03-07 10:01:13,229 - INFO - training batch 401, loss: 0.587, 12832/28000 datapoints
2025-03-07 10:01:13,469 - INFO - training batch 451, loss: 0.400, 14432/28000 datapoints
2025-03-07 10:01:13,729 - INFO - training batch 501, loss: 0.245, 16032/28000 datapoints
2025-03-07 10:01:13,960 - INFO - training batch 551, loss: 0.396, 17632/28000 datapoints
2025-03-07 10:01:14,225 - INFO - training batch 601, loss: 0.756, 19232/28000 datapoints
2025-03-07 10:01:14,470 - INFO - training batch 651, loss: 0.125, 20832/28000 datapoints
2025-03-07 10:01:14,701 - INFO - training batch 701, loss: 0.346, 22432/28000 datapoints
2025-03-07 10:01:14,943 - INFO - training batch 751, loss: 0.223, 24032/28000 datapoints
2025-03-07 10:01:15,179 - INFO - training batch 801, loss: 0.277, 25632/28000 datapoints
2025-03-07 10:01:15,424 - INFO - training batch 851, loss: 0.641, 27232/28000 datapoints
2025-03-07 10:01:15,550 - INFO - validation batch 1, loss: 0.165, 32/6976 datapoints
2025-03-07 10:01:15,629 - INFO - validation batch 51, loss: 1.224, 1632/6976 datapoints
2025-03-07 10:01:15,716 - INFO - validation batch 101, loss: 0.258, 3232/6976 datapoints
2025-03-07 10:01:15,796 - INFO - validation batch 151, loss: 0.399, 4832/6976 datapoints
2025-03-07 10:01:15,869 - INFO - validation batch 201, loss: 0.897, 6432/6976 datapoints
2025-03-07 10:01:15,895 - INFO - Epoch 79/800 done.
2025-03-07 10:01:15,895 - INFO - Final validation performance:
Loss: 0.589, top-1 acc: 0.872top-5 acc: 0.872
2025-03-07 10:01:15,896 - INFO - Beginning epoch 80/800
2025-03-07 10:01:15,905 - INFO - training batch 1, loss: 0.293, 32/28000 datapoints
2025-03-07 10:01:16,166 - INFO - training batch 51, loss: 0.285, 1632/28000 datapoints
2025-03-07 10:01:16,514 - INFO - training batch 101, loss: 0.306, 3232/28000 datapoints
2025-03-07 10:01:16,756 - INFO - training batch 151, loss: 0.606, 4832/28000 datapoints
2025-03-07 10:01:17,048 - INFO - training batch 201, loss: 0.334, 6432/28000 datapoints
2025-03-07 10:01:17,301 - INFO - training batch 251, loss: 0.420, 8032/28000 datapoints
2025-03-07 10:01:17,544 - INFO - training batch 301, loss: 0.593, 9632/28000 datapoints
2025-03-07 10:01:17,775 - INFO - training batch 351, loss: 0.362, 11232/28000 datapoints
2025-03-07 10:01:18,043 - INFO - training batch 401, loss: 0.582, 12832/28000 datapoints
2025-03-07 10:01:18,277 - INFO - training batch 451, loss: 0.397, 14432/28000 datapoints
2025-03-07 10:01:18,526 - INFO - training batch 501, loss: 0.242, 16032/28000 datapoints
2025-03-07 10:01:18,772 - INFO - training batch 551, loss: 0.390, 17632/28000 datapoints
2025-03-07 10:01:19,021 - INFO - training batch 601, loss: 0.747, 19232/28000 datapoints
2025-03-07 10:01:19,265 - INFO - training batch 651, loss: 0.123, 20832/28000 datapoints
2025-03-07 10:01:19,516 - INFO - training batch 701, loss: 0.344, 22432/28000 datapoints
2025-03-07 10:01:19,755 - INFO - training batch 751, loss: 0.223, 24032/28000 datapoints
2025-03-07 10:01:19,993 - INFO - training batch 801, loss: 0.275, 25632/28000 datapoints
2025-03-07 10:01:20,229 - INFO - training batch 851, loss: 0.631, 27232/28000 datapoints
2025-03-07 10:01:20,347 - INFO - validation batch 1, loss: 0.166, 32/6976 datapoints
2025-03-07 10:01:20,412 - INFO - validation batch 51, loss: 1.222, 1632/6976 datapoints
2025-03-07 10:01:20,481 - INFO - validation batch 101, loss: 0.259, 3232/6976 datapoints
2025-03-07 10:01:20,569 - INFO - validation batch 151, loss: 0.394, 4832/6976 datapoints
2025-03-07 10:01:20,660 - INFO - validation batch 201, loss: 0.899, 6432/6976 datapoints
2025-03-07 10:01:20,693 - INFO - Epoch 80/800 done.
2025-03-07 10:01:20,694 - INFO - Final validation performance:
Loss: 0.588, top-1 acc: 0.872top-5 acc: 0.872
2025-03-07 10:01:20,694 - INFO - Beginning epoch 81/800
2025-03-07 10:01:20,703 - INFO - training batch 1, loss: 0.291, 32/28000 datapoints
2025-03-07 10:01:21,015 - INFO - training batch 51, loss: 0.280, 1632/28000 datapoints
2025-03-07 10:01:21,254 - INFO - training batch 101, loss: 0.304, 3232/28000 datapoints
2025-03-07 10:01:21,545 - INFO - training batch 151, loss: 0.595, 4832/28000 datapoints
2025-03-07 10:01:21,782 - INFO - training batch 201, loss: 0.328, 6432/28000 datapoints
2025-03-07 10:01:22,121 - INFO - training batch 251, loss: 0.416, 8032/28000 datapoints
2025-03-07 10:01:22,363 - INFO - training batch 301, loss: 0.595, 9632/28000 datapoints
2025-03-07 10:01:22,635 - INFO - training batch 351, loss: 0.359, 11232/28000 datapoints
2025-03-07 10:01:22,931 - INFO - training batch 401, loss: 0.577, 12832/28000 datapoints
2025-03-07 10:01:23,212 - INFO - training batch 451, loss: 0.394, 14432/28000 datapoints
2025-03-07 10:01:23,481 - INFO - training batch 501, loss: 0.239, 16032/28000 datapoints
2025-03-07 10:01:23,728 - INFO - training batch 551, loss: 0.383, 17632/28000 datapoints
2025-03-07 10:01:24,002 - INFO - training batch 601, loss: 0.738, 19232/28000 datapoints
2025-03-07 10:01:24,496 - INFO - training batch 651, loss: 0.121, 20832/28000 datapoints
2025-03-07 10:01:25,261 - INFO - training batch 701, loss: 0.342, 22432/28000 datapoints
2025-03-07 10:01:25,646 - INFO - training batch 751, loss: 0.222, 24032/28000 datapoints
2025-03-07 10:01:26,029 - INFO - training batch 801, loss: 0.272, 25632/28000 datapoints
2025-03-07 10:01:26,329 - INFO - training batch 851, loss: 0.621, 27232/28000 datapoints
2025-03-07 10:01:26,476 - INFO - validation batch 1, loss: 0.166, 32/6976 datapoints
2025-03-07 10:01:26,580 - INFO - validation batch 51, loss: 1.221, 1632/6976 datapoints
2025-03-07 10:01:26,684 - INFO - validation batch 101, loss: 0.261, 3232/6976 datapoints
2025-03-07 10:01:26,766 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-07 10:01:26,843 - INFO - validation batch 201, loss: 0.900, 6432/6976 datapoints
2025-03-07 10:01:26,867 - INFO - Epoch 81/800 done.
2025-03-07 10:01:26,867 - INFO - Final validation performance:
Loss: 0.587, top-1 acc: 0.873top-5 acc: 0.873
2025-03-07 10:01:26,868 - INFO - Beginning epoch 82/800
2025-03-07 10:01:26,875 - INFO - training batch 1, loss: 0.288, 32/28000 datapoints
2025-03-07 10:01:27,125 - INFO - training batch 51, loss: 0.275, 1632/28000 datapoints
2025-03-07 10:01:27,375 - INFO - training batch 101, loss: 0.301, 3232/28000 datapoints
2025-03-07 10:01:27,677 - INFO - training batch 151, loss: 0.584, 4832/28000 datapoints
2025-03-07 10:01:28,184 - INFO - training batch 201, loss: 0.322, 6432/28000 datapoints
2025-03-07 10:01:28,551 - INFO - training batch 251, loss: 0.413, 8032/28000 datapoints
2025-03-07 10:01:28,854 - INFO - training batch 301, loss: 0.596, 9632/28000 datapoints
2025-03-07 10:01:29,164 - INFO - training batch 351, loss: 0.357, 11232/28000 datapoints
2025-03-07 10:01:29,522 - INFO - training batch 401, loss: 0.571, 12832/28000 datapoints
2025-03-07 10:01:29,805 - INFO - training batch 451, loss: 0.391, 14432/28000 datapoints
2025-03-07 10:01:30,215 - INFO - training batch 501, loss: 0.237, 16032/28000 datapoints
2025-03-07 10:01:30,791 - INFO - training batch 551, loss: 0.377, 17632/28000 datapoints
2025-03-07 10:01:31,369 - INFO - training batch 601, loss: 0.729, 19232/28000 datapoints
2025-03-07 10:01:31,908 - INFO - training batch 651, loss: 0.119, 20832/28000 datapoints
2025-03-07 10:01:32,704 - INFO - training batch 701, loss: 0.341, 22432/28000 datapoints
2025-03-07 10:01:33,052 - INFO - training batch 751, loss: 0.221, 24032/28000 datapoints
2025-03-07 10:01:33,322 - INFO - training batch 801, loss: 0.269, 25632/28000 datapoints
2025-03-07 10:01:33,684 - INFO - training batch 851, loss: 0.611, 27232/28000 datapoints
2025-03-07 10:01:33,843 - INFO - validation batch 1, loss: 0.166, 32/6976 datapoints
2025-03-07 10:01:33,937 - INFO - validation batch 51, loss: 1.220, 1632/6976 datapoints
2025-03-07 10:01:34,017 - INFO - validation batch 101, loss: 0.262, 3232/6976 datapoints
2025-03-07 10:01:34,103 - INFO - validation batch 151, loss: 0.385, 4832/6976 datapoints
2025-03-07 10:01:34,187 - INFO - validation batch 201, loss: 0.900, 6432/6976 datapoints
2025-03-07 10:01:34,218 - INFO - Epoch 82/800 done.
2025-03-07 10:01:34,218 - INFO - Final validation performance:
Loss: 0.587, top-1 acc: 0.873top-5 acc: 0.873
2025-03-07 10:01:34,219 - INFO - Beginning epoch 83/800
2025-03-07 10:01:34,226 - INFO - training batch 1, loss: 0.286, 32/28000 datapoints
2025-03-07 10:01:34,499 - INFO - training batch 51, loss: 0.270, 1632/28000 datapoints
2025-03-07 10:01:34,784 - INFO - training batch 101, loss: 0.299, 3232/28000 datapoints
2025-03-07 10:01:35,049 - INFO - training batch 151, loss: 0.572, 4832/28000 datapoints
2025-03-07 10:01:35,298 - INFO - training batch 201, loss: 0.315, 6432/28000 datapoints
2025-03-07 10:01:35,547 - INFO - training batch 251, loss: 0.410, 8032/28000 datapoints
2025-03-07 10:01:35,984 - INFO - training batch 301, loss: 0.598, 9632/28000 datapoints
2025-03-07 10:01:36,281 - INFO - training batch 351, loss: 0.353, 11232/28000 datapoints
2025-03-07 10:01:36,617 - INFO - training batch 401, loss: 0.566, 12832/28000 datapoints
2025-03-07 10:01:36,908 - INFO - training batch 451, loss: 0.389, 14432/28000 datapoints
2025-03-07 10:01:37,180 - INFO - training batch 501, loss: 0.234, 16032/28000 datapoints
2025-03-07 10:01:37,468 - INFO - training batch 551, loss: 0.372, 17632/28000 datapoints
2025-03-07 10:01:37,779 - INFO - training batch 601, loss: 0.721, 19232/28000 datapoints
2025-03-07 10:01:38,066 - INFO - training batch 651, loss: 0.118, 20832/28000 datapoints
2025-03-07 10:01:38,402 - INFO - training batch 701, loss: 0.339, 22432/28000 datapoints
2025-03-07 10:01:38,831 - INFO - training batch 751, loss: 0.219, 24032/28000 datapoints
2025-03-07 10:01:39,214 - INFO - training batch 801, loss: 0.266, 25632/28000 datapoints
2025-03-07 10:01:39,659 - INFO - training batch 851, loss: 0.601, 27232/28000 datapoints
2025-03-07 10:01:39,917 - INFO - validation batch 1, loss: 0.167, 32/6976 datapoints
2025-03-07 10:01:40,141 - INFO - validation batch 51, loss: 1.220, 1632/6976 datapoints
2025-03-07 10:01:40,356 - INFO - validation batch 101, loss: 0.263, 3232/6976 datapoints
2025-03-07 10:01:40,478 - INFO - validation batch 151, loss: 0.379, 4832/6976 datapoints
2025-03-07 10:01:40,584 - INFO - validation batch 201, loss: 0.901, 6432/6976 datapoints
2025-03-07 10:01:40,617 - INFO - Epoch 83/800 done.
2025-03-07 10:01:40,618 - INFO - Final validation performance:
Loss: 0.586, top-1 acc: 0.873top-5 acc: 0.873
2025-03-07 10:01:40,618 - INFO - Beginning epoch 84/800
2025-03-07 10:01:40,627 - INFO - training batch 1, loss: 0.284, 32/28000 datapoints
2025-03-07 10:01:40,992 - INFO - training batch 51, loss: 0.266, 1632/28000 datapoints
2025-03-07 10:01:41,303 - INFO - training batch 101, loss: 0.296, 3232/28000 datapoints
2025-03-07 10:01:41,583 - INFO - training batch 151, loss: 0.562, 4832/28000 datapoints
2025-03-07 10:01:41,847 - INFO - training batch 201, loss: 0.308, 6432/28000 datapoints
2025-03-07 10:01:42,105 - INFO - training batch 251, loss: 0.406, 8032/28000 datapoints
2025-03-07 10:01:42,466 - INFO - training batch 301, loss: 0.598, 9632/28000 datapoints
2025-03-07 10:01:42,698 - INFO - training batch 351, loss: 0.349, 11232/28000 datapoints
2025-03-07 10:01:43,000 - INFO - training batch 401, loss: 0.560, 12832/28000 datapoints
2025-03-07 10:01:43,334 - INFO - training batch 451, loss: 0.386, 14432/28000 datapoints
2025-03-07 10:01:43,610 - INFO - training batch 501, loss: 0.231, 16032/28000 datapoints
2025-03-07 10:01:43,850 - INFO - training batch 551, loss: 0.366, 17632/28000 datapoints
2025-03-07 10:01:44,083 - INFO - training batch 601, loss: 0.715, 19232/28000 datapoints
2025-03-07 10:01:44,318 - INFO - training batch 651, loss: 0.116, 20832/28000 datapoints
2025-03-07 10:01:44,549 - INFO - training batch 701, loss: 0.337, 22432/28000 datapoints
2025-03-07 10:01:44,836 - INFO - training batch 751, loss: 0.219, 24032/28000 datapoints
2025-03-07 10:01:45,071 - INFO - training batch 801, loss: 0.264, 25632/28000 datapoints
2025-03-07 10:01:45,313 - INFO - training batch 851, loss: 0.590, 27232/28000 datapoints
2025-03-07 10:01:45,439 - INFO - validation batch 1, loss: 0.168, 32/6976 datapoints
2025-03-07 10:01:45,509 - INFO - validation batch 51, loss: 1.219, 1632/6976 datapoints
2025-03-07 10:01:45,581 - INFO - validation batch 101, loss: 0.264, 3232/6976 datapoints
2025-03-07 10:01:45,648 - INFO - validation batch 151, loss: 0.375, 4832/6976 datapoints
2025-03-07 10:01:45,713 - INFO - validation batch 201, loss: 0.902, 6432/6976 datapoints
2025-03-07 10:01:45,736 - INFO - Epoch 84/800 done.
2025-03-07 10:01:45,736 - INFO - Final validation performance:
Loss: 0.586, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:01:45,737 - INFO - Beginning epoch 85/800
2025-03-07 10:01:45,746 - INFO - training batch 1, loss: 0.282, 32/28000 datapoints
2025-03-07 10:01:46,000 - INFO - training batch 51, loss: 0.262, 1632/28000 datapoints
2025-03-07 10:01:46,272 - INFO - training batch 101, loss: 0.294, 3232/28000 datapoints
2025-03-07 10:01:46,573 - INFO - training batch 151, loss: 0.551, 4832/28000 datapoints
2025-03-07 10:01:46,930 - INFO - training batch 201, loss: 0.301, 6432/28000 datapoints
2025-03-07 10:01:47,264 - INFO - training batch 251, loss: 0.403, 8032/28000 datapoints
2025-03-07 10:01:47,539 - INFO - training batch 301, loss: 0.600, 9632/28000 datapoints
2025-03-07 10:01:47,879 - INFO - training batch 351, loss: 0.347, 11232/28000 datapoints
2025-03-07 10:01:48,330 - INFO - training batch 401, loss: 0.554, 12832/28000 datapoints
2025-03-07 10:01:48,627 - INFO - training batch 451, loss: 0.384, 14432/28000 datapoints
2025-03-07 10:01:49,001 - INFO - training batch 501, loss: 0.228, 16032/28000 datapoints
2025-03-07 10:01:49,359 - INFO - training batch 551, loss: 0.361, 17632/28000 datapoints
2025-03-07 10:01:49,765 - INFO - training batch 601, loss: 0.706, 19232/28000 datapoints
2025-03-07 10:01:50,128 - INFO - training batch 651, loss: 0.114, 20832/28000 datapoints
2025-03-07 10:01:50,460 - INFO - training batch 701, loss: 0.336, 22432/28000 datapoints
2025-03-07 10:01:50,841 - INFO - training batch 751, loss: 0.216, 24032/28000 datapoints
2025-03-07 10:01:51,395 - INFO - training batch 801, loss: 0.261, 25632/28000 datapoints
2025-03-07 10:01:52,089 - INFO - training batch 851, loss: 0.581, 27232/28000 datapoints
2025-03-07 10:01:52,294 - INFO - validation batch 1, loss: 0.168, 32/6976 datapoints
2025-03-07 10:01:52,475 - INFO - validation batch 51, loss: 1.220, 1632/6976 datapoints
2025-03-07 10:01:52,630 - INFO - validation batch 101, loss: 0.267, 3232/6976 datapoints
2025-03-07 10:01:52,770 - INFO - validation batch 151, loss: 0.369, 4832/6976 datapoints
2025-03-07 10:01:52,879 - INFO - validation batch 201, loss: 0.902, 6432/6976 datapoints
2025-03-07 10:01:53,013 - INFO - Epoch 85/800 done.
2025-03-07 10:01:53,015 - INFO - Final validation performance:
Loss: 0.585, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:01:53,017 - INFO - Beginning epoch 86/800
2025-03-07 10:01:53,063 - INFO - training batch 1, loss: 0.280, 32/28000 datapoints
2025-03-07 10:01:53,858 - INFO - training batch 51, loss: 0.258, 1632/28000 datapoints
2025-03-07 10:01:54,213 - INFO - training batch 101, loss: 0.291, 3232/28000 datapoints
2025-03-07 10:01:54,591 - INFO - training batch 151, loss: 0.541, 4832/28000 datapoints
2025-03-07 10:01:54,931 - INFO - training batch 201, loss: 0.295, 6432/28000 datapoints
2025-03-07 10:01:55,234 - INFO - training batch 251, loss: 0.400, 8032/28000 datapoints
2025-03-07 10:01:55,542 - INFO - training batch 301, loss: 0.601, 9632/28000 datapoints
2025-03-07 10:01:55,850 - INFO - training batch 351, loss: 0.344, 11232/28000 datapoints
2025-03-07 10:01:56,114 - INFO - training batch 401, loss: 0.550, 12832/28000 datapoints
2025-03-07 10:01:56,406 - INFO - training batch 451, loss: 0.381, 14432/28000 datapoints
2025-03-07 10:01:56,729 - INFO - training batch 501, loss: 0.226, 16032/28000 datapoints
2025-03-07 10:01:57,000 - INFO - training batch 551, loss: 0.357, 17632/28000 datapoints
2025-03-07 10:01:57,363 - INFO - training batch 601, loss: 0.698, 19232/28000 datapoints
2025-03-07 10:01:57,812 - INFO - training batch 651, loss: 0.112, 20832/28000 datapoints
2025-03-07 10:01:58,180 - INFO - training batch 701, loss: 0.335, 22432/28000 datapoints
2025-03-07 10:01:58,630 - INFO - training batch 751, loss: 0.215, 24032/28000 datapoints
2025-03-07 10:01:58,975 - INFO - training batch 801, loss: 0.258, 25632/28000 datapoints
2025-03-07 10:01:59,245 - INFO - training batch 851, loss: 0.571, 27232/28000 datapoints
2025-03-07 10:01:59,368 - INFO - validation batch 1, loss: 0.169, 32/6976 datapoints
2025-03-07 10:01:59,439 - INFO - validation batch 51, loss: 1.221, 1632/6976 datapoints
2025-03-07 10:01:59,520 - INFO - validation batch 101, loss: 0.268, 3232/6976 datapoints
2025-03-07 10:01:59,608 - INFO - validation batch 151, loss: 0.366, 4832/6976 datapoints
2025-03-07 10:01:59,687 - INFO - validation batch 201, loss: 0.902, 6432/6976 datapoints
2025-03-07 10:01:59,714 - INFO - Epoch 86/800 done.
2025-03-07 10:01:59,715 - INFO - Final validation performance:
Loss: 0.585, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:01:59,715 - INFO - Beginning epoch 87/800
2025-03-07 10:01:59,724 - INFO - training batch 1, loss: 0.278, 32/28000 datapoints
2025-03-07 10:01:59,986 - INFO - training batch 51, loss: 0.253, 1632/28000 datapoints
2025-03-07 10:02:00,238 - INFO - training batch 101, loss: 0.289, 3232/28000 datapoints
2025-03-07 10:02:00,488 - INFO - training batch 151, loss: 0.530, 4832/28000 datapoints
2025-03-07 10:02:00,727 - INFO - training batch 201, loss: 0.288, 6432/28000 datapoints
2025-03-07 10:02:01,010 - INFO - training batch 251, loss: 0.397, 8032/28000 datapoints
2025-03-07 10:02:01,255 - INFO - training batch 301, loss: 0.602, 9632/28000 datapoints
2025-03-07 10:02:01,513 - INFO - training batch 351, loss: 0.341, 11232/28000 datapoints
2025-03-07 10:02:01,801 - INFO - training batch 401, loss: 0.545, 12832/28000 datapoints
2025-03-07 10:02:02,051 - INFO - training batch 451, loss: 0.379, 14432/28000 datapoints
2025-03-07 10:02:02,284 - INFO - training batch 501, loss: 0.224, 16032/28000 datapoints
2025-03-07 10:02:02,550 - INFO - training batch 551, loss: 0.351, 17632/28000 datapoints
2025-03-07 10:02:02,797 - INFO - training batch 601, loss: 0.689, 19232/28000 datapoints
2025-03-07 10:02:03,029 - INFO - training batch 651, loss: 0.111, 20832/28000 datapoints
2025-03-07 10:02:03,270 - INFO - training batch 701, loss: 0.334, 22432/28000 datapoints
2025-03-07 10:02:03,503 - INFO - training batch 751, loss: 0.214, 24032/28000 datapoints
2025-03-07 10:02:03,731 - INFO - training batch 801, loss: 0.256, 25632/28000 datapoints
2025-03-07 10:02:03,964 - INFO - training batch 851, loss: 0.561, 27232/28000 datapoints
2025-03-07 10:02:04,082 - INFO - validation batch 1, loss: 0.170, 32/6976 datapoints
2025-03-07 10:02:04,146 - INFO - validation batch 51, loss: 1.221, 1632/6976 datapoints
2025-03-07 10:02:04,213 - INFO - validation batch 101, loss: 0.271, 3232/6976 datapoints
2025-03-07 10:02:04,280 - INFO - validation batch 151, loss: 0.361, 4832/6976 datapoints
2025-03-07 10:02:04,345 - INFO - validation batch 201, loss: 0.901, 6432/6976 datapoints
2025-03-07 10:02:04,367 - INFO - Epoch 87/800 done.
2025-03-07 10:02:04,368 - INFO - Final validation performance:
Loss: 0.585, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:02:04,368 - INFO - Beginning epoch 88/800
2025-03-07 10:02:04,374 - INFO - training batch 1, loss: 0.276, 32/28000 datapoints
2025-03-07 10:02:04,618 - INFO - training batch 51, loss: 0.249, 1632/28000 datapoints
2025-03-07 10:02:04,857 - INFO - training batch 101, loss: 0.286, 3232/28000 datapoints
2025-03-07 10:02:05,101 - INFO - training batch 151, loss: 0.521, 4832/28000 datapoints
2025-03-07 10:02:05,369 - INFO - training batch 201, loss: 0.282, 6432/28000 datapoints
2025-03-07 10:02:05,612 - INFO - training batch 251, loss: 0.393, 8032/28000 datapoints
2025-03-07 10:02:05,849 - INFO - training batch 301, loss: 0.603, 9632/28000 datapoints
2025-03-07 10:02:06,104 - INFO - training batch 351, loss: 0.339, 11232/28000 datapoints
2025-03-07 10:02:06,408 - INFO - training batch 401, loss: 0.540, 12832/28000 datapoints
2025-03-07 10:02:06,658 - INFO - training batch 451, loss: 0.376, 14432/28000 datapoints
2025-03-07 10:02:06,903 - INFO - training batch 501, loss: 0.221, 16032/28000 datapoints
2025-03-07 10:02:07,171 - INFO - training batch 551, loss: 0.346, 17632/28000 datapoints
2025-03-07 10:02:07,409 - INFO - training batch 601, loss: 0.679, 19232/28000 datapoints
2025-03-07 10:02:07,697 - INFO - training batch 651, loss: 0.109, 20832/28000 datapoints
2025-03-07 10:02:07,940 - INFO - training batch 701, loss: 0.332, 22432/28000 datapoints
2025-03-07 10:02:08,199 - INFO - training batch 751, loss: 0.213, 24032/28000 datapoints
2025-03-07 10:02:08,488 - INFO - training batch 801, loss: 0.254, 25632/28000 datapoints
2025-03-07 10:02:08,836 - INFO - training batch 851, loss: 0.549, 27232/28000 datapoints
2025-03-07 10:02:08,986 - INFO - validation batch 1, loss: 0.172, 32/6976 datapoints
2025-03-07 10:02:09,086 - INFO - validation batch 51, loss: 1.223, 1632/6976 datapoints
2025-03-07 10:02:09,172 - INFO - validation batch 101, loss: 0.273, 3232/6976 datapoints
2025-03-07 10:02:09,286 - INFO - validation batch 151, loss: 0.356, 4832/6976 datapoints
2025-03-07 10:02:09,366 - INFO - validation batch 201, loss: 0.902, 6432/6976 datapoints
2025-03-07 10:02:09,399 - INFO - Epoch 88/800 done.
2025-03-07 10:02:09,400 - INFO - Final validation performance:
Loss: 0.585, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:02:09,400 - INFO - Beginning epoch 89/800
2025-03-07 10:02:09,408 - INFO - training batch 1, loss: 0.274, 32/28000 datapoints
2025-03-07 10:02:09,713 - INFO - training batch 51, loss: 0.244, 1632/28000 datapoints
2025-03-07 10:02:10,014 - INFO - training batch 101, loss: 0.282, 3232/28000 datapoints
2025-03-07 10:02:10,355 - INFO - training batch 151, loss: 0.511, 4832/28000 datapoints
2025-03-07 10:02:10,651 - INFO - training batch 201, loss: 0.276, 6432/28000 datapoints
2025-03-07 10:02:10,924 - INFO - training batch 251, loss: 0.390, 8032/28000 datapoints
2025-03-07 10:02:11,275 - INFO - training batch 301, loss: 0.604, 9632/28000 datapoints
2025-03-07 10:02:11,590 - INFO - training batch 351, loss: 0.334, 11232/28000 datapoints
2025-03-07 10:02:11,939 - INFO - training batch 401, loss: 0.535, 12832/28000 datapoints
2025-03-07 10:02:12,268 - INFO - training batch 451, loss: 0.374, 14432/28000 datapoints
2025-03-07 10:02:12,543 - INFO - training batch 501, loss: 0.218, 16032/28000 datapoints
2025-03-07 10:02:13,003 - INFO - training batch 551, loss: 0.342, 17632/28000 datapoints
2025-03-07 10:02:13,582 - INFO - training batch 601, loss: 0.669, 19232/28000 datapoints
2025-03-07 10:02:14,241 - INFO - training batch 651, loss: 0.107, 20832/28000 datapoints
2025-03-07 10:02:14,827 - INFO - training batch 701, loss: 0.331, 22432/28000 datapoints
2025-03-07 10:02:15,224 - INFO - training batch 751, loss: 0.211, 24032/28000 datapoints
2025-03-07 10:02:15,622 - INFO - training batch 801, loss: 0.251, 25632/28000 datapoints
2025-03-07 10:02:16,161 - INFO - training batch 851, loss: 0.539, 27232/28000 datapoints
2025-03-07 10:02:16,660 - INFO - validation batch 1, loss: 0.173, 32/6976 datapoints
2025-03-07 10:02:16,961 - INFO - validation batch 51, loss: 1.224, 1632/6976 datapoints
2025-03-07 10:02:17,196 - INFO - validation batch 101, loss: 0.276, 3232/6976 datapoints
2025-03-07 10:02:17,640 - INFO - validation batch 151, loss: 0.353, 4832/6976 datapoints
2025-03-07 10:02:17,973 - INFO - validation batch 201, loss: 0.901, 6432/6976 datapoints
2025-03-07 10:02:18,076 - INFO - Epoch 89/800 done.
2025-03-07 10:02:18,079 - INFO - Final validation performance:
Loss: 0.585, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:02:18,086 - INFO - Beginning epoch 90/800
2025-03-07 10:02:18,173 - INFO - training batch 1, loss: 0.272, 32/28000 datapoints
2025-03-07 10:02:19,826 - INFO - training batch 51, loss: 0.240, 1632/28000 datapoints
2025-03-07 10:02:20,575 - INFO - training batch 101, loss: 0.280, 3232/28000 datapoints
2025-03-07 10:02:21,218 - INFO - training batch 151, loss: 0.500, 4832/28000 datapoints
2025-03-07 10:02:21,706 - INFO - training batch 201, loss: 0.270, 6432/28000 datapoints
2025-03-07 10:02:22,245 - INFO - training batch 251, loss: 0.387, 8032/28000 datapoints
2025-03-07 10:02:23,796 - INFO - training batch 301, loss: 0.605, 9632/28000 datapoints
2025-03-07 10:02:24,756 - INFO - training batch 351, loss: 0.332, 11232/28000 datapoints
2025-03-07 10:02:25,473 - INFO - training batch 401, loss: 0.531, 12832/28000 datapoints
2025-03-07 10:02:26,153 - INFO - training batch 451, loss: 0.373, 14432/28000 datapoints
2025-03-07 10:02:26,700 - INFO - training batch 501, loss: 0.216, 16032/28000 datapoints
2025-03-07 10:02:27,210 - INFO - training batch 551, loss: 0.336, 17632/28000 datapoints
2025-03-07 10:02:27,570 - INFO - training batch 601, loss: 0.661, 19232/28000 datapoints
2025-03-07 10:02:27,892 - INFO - training batch 651, loss: 0.105, 20832/28000 datapoints
2025-03-07 10:02:28,270 - INFO - training batch 701, loss: 0.331, 22432/28000 datapoints
2025-03-07 10:02:28,824 - INFO - training batch 751, loss: 0.208, 24032/28000 datapoints
2025-03-07 10:02:29,288 - INFO - training batch 801, loss: 0.249, 25632/28000 datapoints
2025-03-07 10:02:29,676 - INFO - training batch 851, loss: 0.531, 27232/28000 datapoints
2025-03-07 10:02:29,859 - INFO - validation batch 1, loss: 0.172, 32/6976 datapoints
2025-03-07 10:02:29,989 - INFO - validation batch 51, loss: 1.225, 1632/6976 datapoints
2025-03-07 10:02:30,121 - INFO - validation batch 101, loss: 0.278, 3232/6976 datapoints
2025-03-07 10:02:30,240 - INFO - validation batch 151, loss: 0.350, 4832/6976 datapoints
2025-03-07 10:02:30,474 - INFO - validation batch 201, loss: 0.901, 6432/6976 datapoints
2025-03-07 10:02:30,515 - INFO - Epoch 90/800 done.
2025-03-07 10:02:30,516 - INFO - Final validation performance:
Loss: 0.585, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:02:30,519 - INFO - Beginning epoch 91/800
2025-03-07 10:02:30,527 - INFO - training batch 1, loss: 0.269, 32/28000 datapoints
2025-03-07 10:02:31,058 - INFO - training batch 51, loss: 0.236, 1632/28000 datapoints
2025-03-07 10:02:31,791 - INFO - training batch 101, loss: 0.276, 3232/28000 datapoints
2025-03-07 10:02:32,323 - INFO - training batch 151, loss: 0.489, 4832/28000 datapoints
2025-03-07 10:02:32,663 - INFO - training batch 201, loss: 0.265, 6432/28000 datapoints
2025-03-07 10:02:33,124 - INFO - training batch 251, loss: 0.384, 8032/28000 datapoints
2025-03-07 10:02:33,476 - INFO - training batch 301, loss: 0.605, 9632/28000 datapoints
2025-03-07 10:02:33,781 - INFO - training batch 351, loss: 0.329, 11232/28000 datapoints
2025-03-07 10:02:34,092 - INFO - training batch 401, loss: 0.527, 12832/28000 datapoints
2025-03-07 10:02:34,377 - INFO - training batch 451, loss: 0.371, 14432/28000 datapoints
2025-03-07 10:02:34,669 - INFO - training batch 501, loss: 0.214, 16032/28000 datapoints
2025-03-07 10:02:34,993 - INFO - training batch 551, loss: 0.332, 17632/28000 datapoints
2025-03-07 10:02:35,459 - INFO - training batch 601, loss: 0.652, 19232/28000 datapoints
2025-03-07 10:02:35,860 - INFO - training batch 651, loss: 0.104, 20832/28000 datapoints
2025-03-07 10:02:36,220 - INFO - training batch 701, loss: 0.330, 22432/28000 datapoints
2025-03-07 10:02:36,628 - INFO - training batch 751, loss: 0.204, 24032/28000 datapoints
2025-03-07 10:02:36,956 - INFO - training batch 801, loss: 0.246, 25632/28000 datapoints
2025-03-07 10:02:37,575 - INFO - training batch 851, loss: 0.522, 27232/28000 datapoints
2025-03-07 10:02:38,077 - INFO - validation batch 1, loss: 0.174, 32/6976 datapoints
2025-03-07 10:02:38,430 - INFO - validation batch 51, loss: 1.229, 1632/6976 datapoints
2025-03-07 10:02:38,647 - INFO - validation batch 101, loss: 0.282, 3232/6976 datapoints
2025-03-07 10:02:38,806 - INFO - validation batch 151, loss: 0.346, 4832/6976 datapoints
2025-03-07 10:02:38,913 - INFO - validation batch 201, loss: 0.899, 6432/6976 datapoints
2025-03-07 10:02:38,947 - INFO - Epoch 91/800 done.
2025-03-07 10:02:38,947 - INFO - Final validation performance:
Loss: 0.586, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:02:38,949 - INFO - Beginning epoch 92/800
2025-03-07 10:02:38,961 - INFO - training batch 1, loss: 0.269, 32/28000 datapoints
2025-03-07 10:02:39,418 - INFO - training batch 51, loss: 0.233, 1632/28000 datapoints
2025-03-07 10:02:39,835 - INFO - training batch 101, loss: 0.274, 3232/28000 datapoints
2025-03-07 10:02:40,217 - INFO - training batch 151, loss: 0.480, 4832/28000 datapoints
2025-03-07 10:02:40,556 - INFO - training batch 201, loss: 0.259, 6432/28000 datapoints
2025-03-07 10:02:40,886 - INFO - training batch 251, loss: 0.380, 8032/28000 datapoints
2025-03-07 10:02:41,213 - INFO - training batch 301, loss: 0.606, 9632/28000 datapoints
2025-03-07 10:02:41,542 - INFO - training batch 351, loss: 0.325, 11232/28000 datapoints
2025-03-07 10:02:41,875 - INFO - training batch 401, loss: 0.523, 12832/28000 datapoints
2025-03-07 10:02:42,217 - INFO - training batch 451, loss: 0.369, 14432/28000 datapoints
2025-03-07 10:02:42,541 - INFO - training batch 501, loss: 0.212, 16032/28000 datapoints
2025-03-07 10:02:42,893 - INFO - training batch 551, loss: 0.327, 17632/28000 datapoints
2025-03-07 10:02:43,327 - INFO - training batch 601, loss: 0.643, 19232/28000 datapoints
2025-03-07 10:02:44,011 - INFO - training batch 651, loss: 0.102, 20832/28000 datapoints
2025-03-07 10:02:45,172 - INFO - training batch 701, loss: 0.329, 22432/28000 datapoints
2025-03-07 10:02:46,545 - INFO - training batch 751, loss: 0.204, 24032/28000 datapoints
2025-03-07 10:02:47,129 - INFO - training batch 801, loss: 0.243, 25632/28000 datapoints
2025-03-07 10:02:47,877 - INFO - training batch 851, loss: 0.513, 27232/28000 datapoints
2025-03-07 10:02:48,202 - INFO - validation batch 1, loss: 0.175, 32/6976 datapoints
2025-03-07 10:02:48,431 - INFO - validation batch 51, loss: 1.232, 1632/6976 datapoints
2025-03-07 10:02:48,594 - INFO - validation batch 101, loss: 0.285, 3232/6976 datapoints
2025-03-07 10:02:48,704 - INFO - validation batch 151, loss: 0.343, 4832/6976 datapoints
2025-03-07 10:02:48,835 - INFO - validation batch 201, loss: 0.898, 6432/6976 datapoints
2025-03-07 10:02:48,873 - INFO - Epoch 92/800 done.
2025-03-07 10:02:48,873 - INFO - Final validation performance:
Loss: 0.586, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:02:48,874 - INFO - Beginning epoch 93/800
2025-03-07 10:02:48,889 - INFO - training batch 1, loss: 0.267, 32/28000 datapoints
2025-03-07 10:02:49,393 - INFO - training batch 51, loss: 0.229, 1632/28000 datapoints
2025-03-07 10:02:49,741 - INFO - training batch 101, loss: 0.272, 3232/28000 datapoints
2025-03-07 10:02:50,187 - INFO - training batch 151, loss: 0.469, 4832/28000 datapoints
2025-03-07 10:02:50,678 - INFO - training batch 201, loss: 0.254, 6432/28000 datapoints
2025-03-07 10:02:51,068 - INFO - training batch 251, loss: 0.377, 8032/28000 datapoints
2025-03-07 10:02:51,701 - INFO - training batch 301, loss: 0.605, 9632/28000 datapoints
2025-03-07 10:02:52,383 - INFO - training batch 351, loss: 0.323, 11232/28000 datapoints
2025-03-07 10:02:53,138 - INFO - training batch 401, loss: 0.519, 12832/28000 datapoints
2025-03-07 10:02:53,694 - INFO - training batch 451, loss: 0.368, 14432/28000 datapoints
2025-03-07 10:02:54,220 - INFO - training batch 501, loss: 0.209, 16032/28000 datapoints
2025-03-07 10:02:54,611 - INFO - training batch 551, loss: 0.323, 17632/28000 datapoints
2025-03-07 10:02:54,983 - INFO - training batch 601, loss: 0.634, 19232/28000 datapoints
2025-03-07 10:02:55,313 - INFO - training batch 651, loss: 0.100, 20832/28000 datapoints
2025-03-07 10:02:55,649 - INFO - training batch 701, loss: 0.328, 22432/28000 datapoints
2025-03-07 10:02:55,959 - INFO - training batch 751, loss: 0.201, 24032/28000 datapoints
2025-03-07 10:02:56,276 - INFO - training batch 801, loss: 0.241, 25632/28000 datapoints
2025-03-07 10:02:56,574 - INFO - training batch 851, loss: 0.504, 27232/28000 datapoints
2025-03-07 10:02:56,716 - INFO - validation batch 1, loss: 0.174, 32/6976 datapoints
2025-03-07 10:02:56,812 - INFO - validation batch 51, loss: 1.232, 1632/6976 datapoints
2025-03-07 10:02:56,923 - INFO - validation batch 101, loss: 0.287, 3232/6976 datapoints
2025-03-07 10:02:57,009 - INFO - validation batch 151, loss: 0.340, 4832/6976 datapoints
2025-03-07 10:02:57,090 - INFO - validation batch 201, loss: 0.900, 6432/6976 datapoints
2025-03-07 10:02:57,115 - INFO - Epoch 93/800 done.
2025-03-07 10:02:57,115 - INFO - Final validation performance:
Loss: 0.587, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:02:57,117 - INFO - Beginning epoch 94/800
2025-03-07 10:02:57,125 - INFO - training batch 1, loss: 0.265, 32/28000 datapoints
2025-03-07 10:02:57,452 - INFO - training batch 51, loss: 0.224, 1632/28000 datapoints
2025-03-07 10:02:57,787 - INFO - training batch 101, loss: 0.269, 3232/28000 datapoints
2025-03-07 10:02:58,124 - INFO - training batch 151, loss: 0.459, 4832/28000 datapoints
2025-03-07 10:02:58,451 - INFO - training batch 201, loss: 0.248, 6432/28000 datapoints
2025-03-07 10:02:58,819 - INFO - training batch 251, loss: 0.375, 8032/28000 datapoints
2025-03-07 10:02:59,237 - INFO - training batch 301, loss: 0.605, 9632/28000 datapoints
2025-03-07 10:02:59,702 - INFO - training batch 351, loss: 0.319, 11232/28000 datapoints
2025-03-07 10:03:00,157 - INFO - training batch 401, loss: 0.515, 12832/28000 datapoints
2025-03-07 10:03:00,725 - INFO - training batch 451, loss: 0.366, 14432/28000 datapoints
2025-03-07 10:03:01,125 - INFO - training batch 501, loss: 0.206, 16032/28000 datapoints
2025-03-07 10:03:01,492 - INFO - training batch 551, loss: 0.319, 17632/28000 datapoints
2025-03-07 10:03:01,799 - INFO - training batch 601, loss: 0.631, 19232/28000 datapoints
2025-03-07 10:03:02,428 - INFO - training batch 651, loss: 0.098, 20832/28000 datapoints
2025-03-07 10:03:02,777 - INFO - training batch 701, loss: 0.328, 22432/28000 datapoints
2025-03-07 10:03:03,192 - INFO - training batch 751, loss: 0.195, 24032/28000 datapoints
2025-03-07 10:03:03,566 - INFO - training batch 801, loss: 0.238, 25632/28000 datapoints
2025-03-07 10:03:03,912 - INFO - training batch 851, loss: 0.494, 27232/28000 datapoints
2025-03-07 10:03:04,145 - INFO - validation batch 1, loss: 0.174, 32/6976 datapoints
2025-03-07 10:03:04,379 - INFO - validation batch 51, loss: 1.236, 1632/6976 datapoints
2025-03-07 10:03:04,488 - INFO - validation batch 101, loss: 0.289, 3232/6976 datapoints
2025-03-07 10:03:04,579 - INFO - validation batch 151, loss: 0.338, 4832/6976 datapoints
2025-03-07 10:03:04,670 - INFO - validation batch 201, loss: 0.899, 6432/6976 datapoints
2025-03-07 10:03:04,706 - INFO - Epoch 94/800 done.
2025-03-07 10:03:04,706 - INFO - Final validation performance:
Loss: 0.587, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:03:04,707 - INFO - Beginning epoch 95/800
2025-03-07 10:03:04,714 - INFO - training batch 1, loss: 0.263, 32/28000 datapoints
2025-03-07 10:03:05,121 - INFO - training batch 51, loss: 0.221, 1632/28000 datapoints
2025-03-07 10:03:06,196 - INFO - training batch 101, loss: 0.267, 3232/28000 datapoints
2025-03-07 10:03:06,906 - INFO - training batch 151, loss: 0.449, 4832/28000 datapoints
2025-03-07 10:03:07,344 - INFO - training batch 201, loss: 0.242, 6432/28000 datapoints
2025-03-07 10:03:07,697 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-07 10:03:08,103 - INFO - training batch 301, loss: 0.606, 9632/28000 datapoints
2025-03-07 10:03:08,408 - INFO - training batch 351, loss: 0.317, 11232/28000 datapoints
2025-03-07 10:03:08,731 - INFO - training batch 401, loss: 0.510, 12832/28000 datapoints
2025-03-07 10:03:09,079 - INFO - training batch 451, loss: 0.365, 14432/28000 datapoints
2025-03-07 10:03:09,387 - INFO - training batch 501, loss: 0.205, 16032/28000 datapoints
2025-03-07 10:03:09,705 - INFO - training batch 551, loss: 0.313, 17632/28000 datapoints
2025-03-07 10:03:09,994 - INFO - training batch 601, loss: 0.624, 19232/28000 datapoints
2025-03-07 10:03:10,287 - INFO - training batch 651, loss: 0.097, 20832/28000 datapoints
2025-03-07 10:03:10,575 - INFO - training batch 701, loss: 0.328, 22432/28000 datapoints
2025-03-07 10:03:10,861 - INFO - training batch 751, loss: 0.194, 24032/28000 datapoints
2025-03-07 10:03:11,148 - INFO - training batch 801, loss: 0.235, 25632/28000 datapoints
2025-03-07 10:03:11,439 - INFO - training batch 851, loss: 0.485, 27232/28000 datapoints
2025-03-07 10:03:11,587 - INFO - validation batch 1, loss: 0.177, 32/6976 datapoints
2025-03-07 10:03:11,683 - INFO - validation batch 51, loss: 1.241, 1632/6976 datapoints
2025-03-07 10:03:11,771 - INFO - validation batch 101, loss: 0.293, 3232/6976 datapoints
2025-03-07 10:03:11,859 - INFO - validation batch 151, loss: 0.337, 4832/6976 datapoints
2025-03-07 10:03:11,962 - INFO - validation batch 201, loss: 0.897, 6432/6976 datapoints
2025-03-07 10:03:11,997 - INFO - Epoch 95/800 done.
2025-03-07 10:03:11,997 - INFO - Final validation performance:
Loss: 0.589, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:03:11,998 - INFO - Beginning epoch 96/800
2025-03-07 10:03:12,008 - INFO - training batch 1, loss: 0.262, 32/28000 datapoints
2025-03-07 10:03:12,341 - INFO - training batch 51, loss: 0.218, 1632/28000 datapoints
2025-03-07 10:03:12,677 - INFO - training batch 101, loss: 0.264, 3232/28000 datapoints
2025-03-07 10:03:13,043 - INFO - training batch 151, loss: 0.439, 4832/28000 datapoints
2025-03-07 10:03:13,408 - INFO - training batch 201, loss: 0.237, 6432/28000 datapoints
2025-03-07 10:03:13,753 - INFO - training batch 251, loss: 0.368, 8032/28000 datapoints
2025-03-07 10:03:14,071 - INFO - training batch 301, loss: 0.606, 9632/28000 datapoints
2025-03-07 10:03:14,404 - INFO - training batch 351, loss: 0.315, 11232/28000 datapoints
2025-03-07 10:03:14,738 - INFO - training batch 401, loss: 0.506, 12832/28000 datapoints
2025-03-07 10:03:15,137 - INFO - training batch 451, loss: 0.364, 14432/28000 datapoints
2025-03-07 10:03:15,774 - INFO - training batch 501, loss: 0.202, 16032/28000 datapoints
2025-03-07 10:03:16,336 - INFO - training batch 551, loss: 0.310, 17632/28000 datapoints
2025-03-07 10:03:16,655 - INFO - training batch 601, loss: 0.616, 19232/28000 datapoints
2025-03-07 10:03:16,957 - INFO - training batch 651, loss: 0.095, 20832/28000 datapoints
2025-03-07 10:03:17,271 - INFO - training batch 701, loss: 0.327, 22432/28000 datapoints
2025-03-07 10:03:17,620 - INFO - training batch 751, loss: 0.191, 24032/28000 datapoints
2025-03-07 10:03:17,929 - INFO - training batch 801, loss: 0.233, 25632/28000 datapoints
2025-03-07 10:03:18,322 - INFO - training batch 851, loss: 0.476, 27232/28000 datapoints
2025-03-07 10:03:18,530 - INFO - validation batch 1, loss: 0.176, 32/6976 datapoints
2025-03-07 10:03:18,626 - INFO - validation batch 51, loss: 1.242, 1632/6976 datapoints
2025-03-07 10:03:18,727 - INFO - validation batch 101, loss: 0.295, 3232/6976 datapoints
2025-03-07 10:03:18,841 - INFO - validation batch 151, loss: 0.334, 4832/6976 datapoints
2025-03-07 10:03:18,957 - INFO - validation batch 201, loss: 0.897, 6432/6976 datapoints
2025-03-07 10:03:18,987 - INFO - Epoch 96/800 done.
2025-03-07 10:03:18,987 - INFO - Final validation performance:
Loss: 0.589, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:03:18,988 - INFO - Beginning epoch 97/800
2025-03-07 10:03:18,996 - INFO - training batch 1, loss: 0.259, 32/28000 datapoints
2025-03-07 10:03:19,391 - INFO - training batch 51, loss: 0.212, 1632/28000 datapoints
2025-03-07 10:03:19,789 - INFO - training batch 101, loss: 0.261, 3232/28000 datapoints
2025-03-07 10:03:20,070 - INFO - training batch 151, loss: 0.429, 4832/28000 datapoints
2025-03-07 10:03:20,359 - INFO - training batch 201, loss: 0.231, 6432/28000 datapoints
2025-03-07 10:03:20,630 - INFO - training batch 251, loss: 0.366, 8032/28000 datapoints
2025-03-07 10:03:20,908 - INFO - training batch 301, loss: 0.607, 9632/28000 datapoints
2025-03-07 10:03:21,220 - INFO - training batch 351, loss: 0.312, 11232/28000 datapoints
2025-03-07 10:03:21,536 - INFO - training batch 401, loss: 0.502, 12832/28000 datapoints
2025-03-07 10:03:21,864 - INFO - training batch 451, loss: 0.362, 14432/28000 datapoints
2025-03-07 10:03:22,175 - INFO - training batch 501, loss: 0.200, 16032/28000 datapoints
2025-03-07 10:03:22,465 - INFO - training batch 551, loss: 0.306, 17632/28000 datapoints
2025-03-07 10:03:22,771 - INFO - training batch 601, loss: 0.606, 19232/28000 datapoints
2025-03-07 10:03:23,072 - INFO - training batch 651, loss: 0.093, 20832/28000 datapoints
2025-03-07 10:03:23,494 - INFO - training batch 701, loss: 0.327, 22432/28000 datapoints
2025-03-07 10:03:23,805 - INFO - training batch 751, loss: 0.188, 24032/28000 datapoints
2025-03-07 10:03:24,081 - INFO - training batch 801, loss: 0.231, 25632/28000 datapoints
2025-03-07 10:03:24,383 - INFO - training batch 851, loss: 0.469, 27232/28000 datapoints
2025-03-07 10:03:24,607 - INFO - validation batch 1, loss: 0.177, 32/6976 datapoints
2025-03-07 10:03:24,779 - INFO - validation batch 51, loss: 1.246, 1632/6976 datapoints
2025-03-07 10:03:24,882 - INFO - validation batch 101, loss: 0.297, 3232/6976 datapoints
2025-03-07 10:03:24,982 - INFO - validation batch 151, loss: 0.332, 4832/6976 datapoints
2025-03-07 10:03:25,090 - INFO - validation batch 201, loss: 0.895, 6432/6976 datapoints
2025-03-07 10:03:25,125 - INFO - Epoch 97/800 done.
2025-03-07 10:03:25,125 - INFO - Final validation performance:
Loss: 0.590, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:03:25,126 - INFO - Beginning epoch 98/800
2025-03-07 10:03:25,139 - INFO - training batch 1, loss: 0.257, 32/28000 datapoints
2025-03-07 10:03:25,573 - INFO - training batch 51, loss: 0.209, 1632/28000 datapoints
2025-03-07 10:03:25,972 - INFO - training batch 101, loss: 0.259, 3232/28000 datapoints
2025-03-07 10:03:26,321 - INFO - training batch 151, loss: 0.419, 4832/28000 datapoints
2025-03-07 10:03:26,640 - INFO - training batch 201, loss: 0.227, 6432/28000 datapoints
2025-03-07 10:03:26,962 - INFO - training batch 251, loss: 0.362, 8032/28000 datapoints
2025-03-07 10:03:27,278 - INFO - training batch 301, loss: 0.607, 9632/28000 datapoints
2025-03-07 10:03:27,613 - INFO - training batch 351, loss: 0.310, 11232/28000 datapoints
2025-03-07 10:03:27,950 - INFO - training batch 401, loss: 0.498, 12832/28000 datapoints
2025-03-07 10:03:28,264 - INFO - training batch 451, loss: 0.361, 14432/28000 datapoints
2025-03-07 10:03:28,559 - INFO - training batch 501, loss: 0.198, 16032/28000 datapoints
2025-03-07 10:03:28,857 - INFO - training batch 551, loss: 0.302, 17632/28000 datapoints
2025-03-07 10:03:29,136 - INFO - training batch 601, loss: 0.598, 19232/28000 datapoints
2025-03-07 10:03:29,412 - INFO - training batch 651, loss: 0.092, 20832/28000 datapoints
2025-03-07 10:03:29,705 - INFO - training batch 701, loss: 0.327, 22432/28000 datapoints
2025-03-07 10:03:30,035 - INFO - training batch 751, loss: 0.185, 24032/28000 datapoints
2025-03-07 10:03:30,894 - INFO - training batch 801, loss: 0.228, 25632/28000 datapoints
2025-03-07 10:03:31,350 - INFO - training batch 851, loss: 0.460, 27232/28000 datapoints
2025-03-07 10:03:31,526 - INFO - validation batch 1, loss: 0.178, 32/6976 datapoints
2025-03-07 10:03:31,637 - INFO - validation batch 51, loss: 1.249, 1632/6976 datapoints
2025-03-07 10:03:31,735 - INFO - validation batch 101, loss: 0.301, 3232/6976 datapoints
2025-03-07 10:03:31,826 - INFO - validation batch 151, loss: 0.329, 4832/6976 datapoints
2025-03-07 10:03:31,926 - INFO - validation batch 201, loss: 0.892, 6432/6976 datapoints
2025-03-07 10:03:31,962 - INFO - Epoch 98/800 done.
2025-03-07 10:03:31,963 - INFO - Final validation performance:
Loss: 0.590, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:03:31,965 - INFO - Beginning epoch 99/800
2025-03-07 10:03:31,975 - INFO - training batch 1, loss: 0.255, 32/28000 datapoints
2025-03-07 10:03:32,328 - INFO - training batch 51, loss: 0.205, 1632/28000 datapoints
2025-03-07 10:03:32,628 - INFO - training batch 101, loss: 0.257, 3232/28000 datapoints
2025-03-07 10:03:32,977 - INFO - training batch 151, loss: 0.409, 4832/28000 datapoints
2025-03-07 10:03:33,274 - INFO - training batch 201, loss: 0.222, 6432/28000 datapoints
2025-03-07 10:03:33,558 - INFO - training batch 251, loss: 0.359, 8032/28000 datapoints
2025-03-07 10:03:33,898 - INFO - training batch 301, loss: 0.608, 9632/28000 datapoints
2025-03-07 10:03:34,568 - INFO - training batch 351, loss: 0.307, 11232/28000 datapoints
2025-03-07 10:03:35,044 - INFO - training batch 401, loss: 0.494, 12832/28000 datapoints
2025-03-07 10:03:35,619 - INFO - training batch 451, loss: 0.361, 14432/28000 datapoints
2025-03-07 10:03:36,060 - INFO - training batch 501, loss: 0.196, 16032/28000 datapoints
2025-03-07 10:03:36,429 - INFO - training batch 551, loss: 0.297, 17632/28000 datapoints
2025-03-07 10:03:36,765 - INFO - training batch 601, loss: 0.590, 19232/28000 datapoints
2025-03-07 10:03:37,241 - INFO - training batch 651, loss: 0.090, 20832/28000 datapoints
2025-03-07 10:03:37,623 - INFO - training batch 701, loss: 0.327, 22432/28000 datapoints
2025-03-07 10:03:37,977 - INFO - training batch 751, loss: 0.181, 24032/28000 datapoints
2025-03-07 10:03:38,300 - INFO - training batch 801, loss: 0.226, 25632/28000 datapoints
2025-03-07 10:03:38,689 - INFO - training batch 851, loss: 0.450, 27232/28000 datapoints
2025-03-07 10:03:38,858 - INFO - validation batch 1, loss: 0.179, 32/6976 datapoints
2025-03-07 10:03:38,959 - INFO - validation batch 51, loss: 1.253, 1632/6976 datapoints
2025-03-07 10:03:39,061 - INFO - validation batch 101, loss: 0.303, 3232/6976 datapoints
2025-03-07 10:03:39,162 - INFO - validation batch 151, loss: 0.327, 4832/6976 datapoints
2025-03-07 10:03:39,259 - INFO - validation batch 201, loss: 0.892, 6432/6976 datapoints
2025-03-07 10:03:39,296 - INFO - Epoch 99/800 done.
2025-03-07 10:03:39,297 - INFO - Final validation performance:
Loss: 0.591, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:03:39,298 - INFO - Beginning epoch 100/800
2025-03-07 10:03:39,308 - INFO - training batch 1, loss: 0.254, 32/28000 datapoints
2025-03-07 10:03:39,628 - INFO - training batch 51, loss: 0.201, 1632/28000 datapoints
2025-03-07 10:03:39,933 - INFO - training batch 101, loss: 0.254, 3232/28000 datapoints
2025-03-07 10:03:40,228 - INFO - training batch 151, loss: 0.399, 4832/28000 datapoints
2025-03-07 10:03:40,542 - INFO - training batch 201, loss: 0.217, 6432/28000 datapoints
2025-03-07 10:03:40,859 - INFO - training batch 251, loss: 0.356, 8032/28000 datapoints
2025-03-07 10:03:41,183 - INFO - training batch 301, loss: 0.608, 9632/28000 datapoints
2025-03-07 10:03:41,528 - INFO - training batch 351, loss: 0.305, 11232/28000 datapoints
2025-03-07 10:03:41,823 - INFO - training batch 401, loss: 0.490, 12832/28000 datapoints
2025-03-07 10:03:42,129 - INFO - training batch 451, loss: 0.359, 14432/28000 datapoints
2025-03-07 10:03:42,440 - INFO - training batch 501, loss: 0.194, 16032/28000 datapoints
2025-03-07 10:03:42,754 - INFO - training batch 551, loss: 0.293, 17632/28000 datapoints
2025-03-07 10:03:43,084 - INFO - training batch 601, loss: 0.582, 19232/28000 datapoints
2025-03-07 10:03:43,428 - INFO - training batch 651, loss: 0.088, 20832/28000 datapoints
2025-03-07 10:03:43,790 - INFO - training batch 701, loss: 0.327, 22432/28000 datapoints
2025-03-07 10:03:44,150 - INFO - training batch 751, loss: 0.178, 24032/28000 datapoints
2025-03-07 10:03:45,291 - INFO - training batch 801, loss: 0.224, 25632/28000 datapoints
2025-03-07 10:03:45,770 - INFO - training batch 851, loss: 0.442, 27232/28000 datapoints
2025-03-07 10:03:45,927 - INFO - validation batch 1, loss: 0.180, 32/6976 datapoints
2025-03-07 10:03:46,022 - INFO - validation batch 51, loss: 1.257, 1632/6976 datapoints
2025-03-07 10:03:46,122 - INFO - validation batch 101, loss: 0.307, 3232/6976 datapoints
2025-03-07 10:03:46,290 - INFO - validation batch 151, loss: 0.325, 4832/6976 datapoints
2025-03-07 10:03:46,421 - INFO - validation batch 201, loss: 0.890, 6432/6976 datapoints
2025-03-07 10:03:46,544 - INFO - Epoch 100/800 done.
2025-03-07 10:03:46,544 - INFO - Final validation performance:
Loss: 0.592, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:03:46,545 - INFO - Beginning epoch 101/800
2025-03-07 10:03:46,577 - INFO - training batch 1, loss: 0.253, 32/28000 datapoints
2025-03-07 10:03:47,263 - INFO - training batch 51, loss: 0.198, 1632/28000 datapoints
2025-03-07 10:03:47,623 - INFO - training batch 101, loss: 0.252, 3232/28000 datapoints
2025-03-07 10:03:48,061 - INFO - training batch 151, loss: 0.392, 4832/28000 datapoints
2025-03-07 10:03:48,738 - INFO - training batch 201, loss: 0.213, 6432/28000 datapoints
2025-03-07 10:03:49,241 - INFO - training batch 251, loss: 0.353, 8032/28000 datapoints
2025-03-07 10:03:49,554 - INFO - training batch 301, loss: 0.607, 9632/28000 datapoints
2025-03-07 10:03:49,827 - INFO - training batch 351, loss: 0.302, 11232/28000 datapoints
2025-03-07 10:03:50,140 - INFO - training batch 401, loss: 0.486, 12832/28000 datapoints
2025-03-07 10:03:50,438 - INFO - training batch 451, loss: 0.358, 14432/28000 datapoints
2025-03-07 10:03:50,862 - INFO - training batch 501, loss: 0.192, 16032/28000 datapoints
2025-03-07 10:03:51,426 - INFO - training batch 551, loss: 0.289, 17632/28000 datapoints
2025-03-07 10:03:51,984 - INFO - training batch 601, loss: 0.573, 19232/28000 datapoints
2025-03-07 10:03:52,491 - INFO - training batch 651, loss: 0.087, 20832/28000 datapoints
2025-03-07 10:03:52,912 - INFO - training batch 701, loss: 0.327, 22432/28000 datapoints
2025-03-07 10:03:53,525 - INFO - training batch 751, loss: 0.176, 24032/28000 datapoints
2025-03-07 10:03:54,024 - INFO - training batch 801, loss: 0.221, 25632/28000 datapoints
2025-03-07 10:03:54,819 - INFO - training batch 851, loss: 0.431, 27232/28000 datapoints
2025-03-07 10:03:55,029 - INFO - validation batch 1, loss: 0.182, 32/6976 datapoints
2025-03-07 10:03:55,334 - INFO - validation batch 51, loss: 1.259, 1632/6976 datapoints
2025-03-07 10:03:55,586 - INFO - validation batch 101, loss: 0.309, 3232/6976 datapoints
2025-03-07 10:03:55,740 - INFO - validation batch 151, loss: 0.323, 4832/6976 datapoints
2025-03-07 10:03:55,871 - INFO - validation batch 201, loss: 0.887, 6432/6976 datapoints
2025-03-07 10:03:55,935 - INFO - Epoch 101/800 done.
2025-03-07 10:03:55,936 - INFO - Final validation performance:
Loss: 0.592, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:03:55,939 - INFO - Beginning epoch 102/800
2025-03-07 10:03:55,952 - INFO - training batch 1, loss: 0.251, 32/28000 datapoints
2025-03-07 10:03:56,376 - INFO - training batch 51, loss: 0.195, 1632/28000 datapoints
2025-03-07 10:03:56,675 - INFO - training batch 101, loss: 0.249, 3232/28000 datapoints
2025-03-07 10:03:56,993 - INFO - training batch 151, loss: 0.383, 4832/28000 datapoints
2025-03-07 10:03:57,279 - INFO - training batch 201, loss: 0.208, 6432/28000 datapoints
2025-03-07 10:03:57,601 - INFO - training batch 251, loss: 0.350, 8032/28000 datapoints
2025-03-07 10:03:57,904 - INFO - training batch 301, loss: 0.609, 9632/28000 datapoints
2025-03-07 10:03:58,248 - INFO - training batch 351, loss: 0.300, 11232/28000 datapoints
2025-03-07 10:03:58,610 - INFO - training batch 401, loss: 0.482, 12832/28000 datapoints
2025-03-07 10:03:58,959 - INFO - training batch 451, loss: 0.356, 14432/28000 datapoints
2025-03-07 10:03:59,287 - INFO - training batch 501, loss: 0.190, 16032/28000 datapoints
2025-03-07 10:03:59,649 - INFO - training batch 551, loss: 0.286, 17632/28000 datapoints
2025-03-07 10:03:59,965 - INFO - training batch 601, loss: 0.566, 19232/28000 datapoints
2025-03-07 10:04:00,263 - INFO - training batch 651, loss: 0.085, 20832/28000 datapoints
2025-03-07 10:04:00,540 - INFO - training batch 701, loss: 0.326, 22432/28000 datapoints
2025-03-07 10:04:00,840 - INFO - training batch 751, loss: 0.175, 24032/28000 datapoints
2025-03-07 10:04:01,141 - INFO - training batch 801, loss: 0.219, 25632/28000 datapoints
2025-03-07 10:04:01,459 - INFO - training batch 851, loss: 0.422, 27232/28000 datapoints
2025-03-07 10:04:01,611 - INFO - validation batch 1, loss: 0.180, 32/6976 datapoints
2025-03-07 10:04:01,710 - INFO - validation batch 51, loss: 1.263, 1632/6976 datapoints
2025-03-07 10:04:01,791 - INFO - validation batch 101, loss: 0.311, 3232/6976 datapoints
2025-03-07 10:04:01,882 - INFO - validation batch 151, loss: 0.320, 4832/6976 datapoints
2025-03-07 10:04:01,964 - INFO - validation batch 201, loss: 0.887, 6432/6976 datapoints
2025-03-07 10:04:02,000 - INFO - Epoch 102/800 done.
2025-03-07 10:04:02,000 - INFO - Final validation performance:
Loss: 0.592, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:04:02,001 - INFO - Beginning epoch 103/800
2025-03-07 10:04:02,008 - INFO - training batch 1, loss: 0.249, 32/28000 datapoints
2025-03-07 10:04:02,271 - INFO - training batch 51, loss: 0.191, 1632/28000 datapoints
2025-03-07 10:04:02,621 - INFO - training batch 101, loss: 0.246, 3232/28000 datapoints
2025-03-07 10:04:02,929 - INFO - training batch 151, loss: 0.372, 4832/28000 datapoints
2025-03-07 10:04:03,245 - INFO - training batch 201, loss: 0.205, 6432/28000 datapoints
2025-03-07 10:04:03,556 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-07 10:04:03,852 - INFO - training batch 301, loss: 0.608, 9632/28000 datapoints
2025-03-07 10:04:04,095 - INFO - training batch 351, loss: 0.298, 11232/28000 datapoints
2025-03-07 10:04:04,381 - INFO - training batch 401, loss: 0.477, 12832/28000 datapoints
2025-03-07 10:04:04,637 - INFO - training batch 451, loss: 0.355, 14432/28000 datapoints
2025-03-07 10:04:04,893 - INFO - training batch 501, loss: 0.188, 16032/28000 datapoints
2025-03-07 10:04:05,131 - INFO - training batch 551, loss: 0.282, 17632/28000 datapoints
2025-03-07 10:04:05,475 - INFO - training batch 601, loss: 0.558, 19232/28000 datapoints
2025-03-07 10:04:05,784 - INFO - training batch 651, loss: 0.083, 20832/28000 datapoints
2025-03-07 10:04:06,121 - INFO - training batch 701, loss: 0.326, 22432/28000 datapoints
2025-03-07 10:04:06,839 - INFO - training batch 751, loss: 0.170, 24032/28000 datapoints
2025-03-07 10:04:07,195 - INFO - training batch 801, loss: 0.217, 25632/28000 datapoints
2025-03-07 10:04:07,550 - INFO - training batch 851, loss: 0.412, 27232/28000 datapoints
2025-03-07 10:04:07,707 - INFO - validation batch 1, loss: 0.182, 32/6976 datapoints
2025-03-07 10:04:07,801 - INFO - validation batch 51, loss: 1.263, 1632/6976 datapoints
2025-03-07 10:04:07,891 - INFO - validation batch 101, loss: 0.315, 3232/6976 datapoints
2025-03-07 10:04:08,008 - INFO - validation batch 151, loss: 0.317, 4832/6976 datapoints
2025-03-07 10:04:08,130 - INFO - validation batch 201, loss: 0.884, 6432/6976 datapoints
2025-03-07 10:04:08,172 - INFO - Epoch 103/800 done.
2025-03-07 10:04:08,173 - INFO - Final validation performance:
Loss: 0.592, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:04:08,173 - INFO - Beginning epoch 104/800
2025-03-07 10:04:08,186 - INFO - training batch 1, loss: 0.248, 32/28000 datapoints
2025-03-07 10:04:08,497 - INFO - training batch 51, loss: 0.189, 1632/28000 datapoints
2025-03-07 10:04:08,749 - INFO - training batch 101, loss: 0.244, 3232/28000 datapoints
2025-03-07 10:04:09,015 - INFO - training batch 151, loss: 0.364, 4832/28000 datapoints
2025-03-07 10:04:09,309 - INFO - training batch 201, loss: 0.201, 6432/28000 datapoints
2025-03-07 10:04:09,583 - INFO - training batch 251, loss: 0.345, 8032/28000 datapoints
2025-03-07 10:04:09,864 - INFO - training batch 301, loss: 0.608, 9632/28000 datapoints
2025-03-07 10:04:10,145 - INFO - training batch 351, loss: 0.295, 11232/28000 datapoints
2025-03-07 10:04:10,404 - INFO - training batch 401, loss: 0.473, 12832/28000 datapoints
2025-03-07 10:04:10,750 - INFO - training batch 451, loss: 0.353, 14432/28000 datapoints
2025-03-07 10:04:11,004 - INFO - training batch 501, loss: 0.186, 16032/28000 datapoints
2025-03-07 10:04:11,260 - INFO - training batch 551, loss: 0.279, 17632/28000 datapoints
2025-03-07 10:04:11,516 - INFO - training batch 601, loss: 0.549, 19232/28000 datapoints
2025-03-07 10:04:11,862 - INFO - training batch 651, loss: 0.081, 20832/28000 datapoints
2025-03-07 10:04:12,165 - INFO - training batch 701, loss: 0.325, 22432/28000 datapoints
2025-03-07 10:04:12,429 - INFO - training batch 751, loss: 0.167, 24032/28000 datapoints
2025-03-07 10:04:12,688 - INFO - training batch 801, loss: 0.215, 25632/28000 datapoints
2025-03-07 10:04:12,988 - INFO - training batch 851, loss: 0.402, 27232/28000 datapoints
2025-03-07 10:04:13,112 - INFO - validation batch 1, loss: 0.182, 32/6976 datapoints
2025-03-07 10:04:13,193 - INFO - validation batch 51, loss: 1.267, 1632/6976 datapoints
2025-03-07 10:04:13,304 - INFO - validation batch 101, loss: 0.319, 3232/6976 datapoints
2025-03-07 10:04:13,381 - INFO - validation batch 151, loss: 0.316, 4832/6976 datapoints
2025-03-07 10:04:13,454 - INFO - validation batch 201, loss: 0.885, 6432/6976 datapoints
2025-03-07 10:04:13,477 - INFO - Epoch 104/800 done.
2025-03-07 10:04:13,477 - INFO - Final validation performance:
Loss: 0.594, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:04:13,478 - INFO - Beginning epoch 105/800
2025-03-07 10:04:13,486 - INFO - training batch 1, loss: 0.246, 32/28000 datapoints
2025-03-07 10:04:13,735 - INFO - training batch 51, loss: 0.186, 1632/28000 datapoints
2025-03-07 10:04:14,003 - INFO - training batch 101, loss: 0.240, 3232/28000 datapoints
2025-03-07 10:04:14,242 - INFO - training batch 151, loss: 0.354, 4832/28000 datapoints
2025-03-07 10:04:14,520 - INFO - training batch 201, loss: 0.197, 6432/28000 datapoints
2025-03-07 10:04:14,762 - INFO - training batch 251, loss: 0.343, 8032/28000 datapoints
2025-03-07 10:04:15,072 - INFO - training batch 301, loss: 0.609, 9632/28000 datapoints
2025-03-07 10:04:15,361 - INFO - training batch 351, loss: 0.292, 11232/28000 datapoints
2025-03-07 10:04:15,664 - INFO - training batch 401, loss: 0.470, 12832/28000 datapoints
2025-03-07 10:04:16,098 - INFO - training batch 451, loss: 0.352, 14432/28000 datapoints
2025-03-07 10:04:16,439 - INFO - training batch 501, loss: 0.183, 16032/28000 datapoints
2025-03-07 10:04:16,749 - INFO - training batch 551, loss: 0.276, 17632/28000 datapoints
2025-03-07 10:04:17,005 - INFO - training batch 601, loss: 0.540, 19232/28000 datapoints
2025-03-07 10:04:17,263 - INFO - training batch 651, loss: 0.079, 20832/28000 datapoints
2025-03-07 10:04:17,520 - INFO - training batch 701, loss: 0.326, 22432/28000 datapoints
2025-03-07 10:04:17,780 - INFO - training batch 751, loss: 0.166, 24032/28000 datapoints
2025-03-07 10:04:18,053 - INFO - training batch 801, loss: 0.213, 25632/28000 datapoints
2025-03-07 10:04:18,427 - INFO - training batch 851, loss: 0.393, 27232/28000 datapoints
2025-03-07 10:04:18,559 - INFO - validation batch 1, loss: 0.181, 32/6976 datapoints
2025-03-07 10:04:18,638 - INFO - validation batch 51, loss: 1.268, 1632/6976 datapoints
2025-03-07 10:04:18,723 - INFO - validation batch 101, loss: 0.321, 3232/6976 datapoints
2025-03-07 10:04:18,808 - INFO - validation batch 151, loss: 0.313, 4832/6976 datapoints
2025-03-07 10:04:18,914 - INFO - validation batch 201, loss: 0.884, 6432/6976 datapoints
2025-03-07 10:04:18,947 - INFO - Epoch 105/800 done.
2025-03-07 10:04:18,948 - INFO - Final validation performance:
Loss: 0.594, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:04:18,949 - INFO - Beginning epoch 106/800
2025-03-07 10:04:18,958 - INFO - training batch 1, loss: 0.244, 32/28000 datapoints
2025-03-07 10:04:19,642 - INFO - training batch 51, loss: 0.182, 1632/28000 datapoints
2025-03-07 10:04:19,998 - INFO - training batch 101, loss: 0.236, 3232/28000 datapoints
2025-03-07 10:04:20,299 - INFO - training batch 151, loss: 0.347, 4832/28000 datapoints
2025-03-07 10:04:20,576 - INFO - training batch 201, loss: 0.193, 6432/28000 datapoints
2025-03-07 10:04:20,880 - INFO - training batch 251, loss: 0.340, 8032/28000 datapoints
2025-03-07 10:04:21,227 - INFO - training batch 301, loss: 0.609, 9632/28000 datapoints
2025-03-07 10:04:21,624 - INFO - training batch 351, loss: 0.289, 11232/28000 datapoints
2025-03-07 10:04:21,950 - INFO - training batch 401, loss: 0.466, 12832/28000 datapoints
2025-03-07 10:04:22,312 - INFO - training batch 451, loss: 0.350, 14432/28000 datapoints
2025-03-07 10:04:22,601 - INFO - training batch 501, loss: 0.181, 16032/28000 datapoints
2025-03-07 10:04:22,862 - INFO - training batch 551, loss: 0.271, 17632/28000 datapoints
2025-03-07 10:04:23,150 - INFO - training batch 601, loss: 0.531, 19232/28000 datapoints
2025-03-07 10:04:23,427 - INFO - training batch 651, loss: 0.077, 20832/28000 datapoints
2025-03-07 10:04:23,745 - INFO - training batch 701, loss: 0.326, 22432/28000 datapoints
2025-03-07 10:04:24,004 - INFO - training batch 751, loss: 0.161, 24032/28000 datapoints
2025-03-07 10:04:24,309 - INFO - training batch 801, loss: 0.210, 25632/28000 datapoints
2025-03-07 10:04:24,621 - INFO - training batch 851, loss: 0.386, 27232/28000 datapoints
2025-03-07 10:04:24,761 - INFO - validation batch 1, loss: 0.182, 32/6976 datapoints
2025-03-07 10:04:24,839 - INFO - validation batch 51, loss: 1.273, 1632/6976 datapoints
2025-03-07 10:04:24,916 - INFO - validation batch 101, loss: 0.324, 3232/6976 datapoints
2025-03-07 10:04:25,003 - INFO - validation batch 151, loss: 0.310, 4832/6976 datapoints
2025-03-07 10:04:25,080 - INFO - validation batch 201, loss: 0.882, 6432/6976 datapoints
2025-03-07 10:04:25,107 - INFO - Epoch 106/800 done.
2025-03-07 10:04:25,107 - INFO - Final validation performance:
Loss: 0.594, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:04:25,109 - INFO - Beginning epoch 107/800
2025-03-07 10:04:25,116 - INFO - training batch 1, loss: 0.241, 32/28000 datapoints
2025-03-07 10:04:25,381 - INFO - training batch 51, loss: 0.179, 1632/28000 datapoints
2025-03-07 10:04:25,632 - INFO - training batch 101, loss: 0.232, 3232/28000 datapoints
2025-03-07 10:04:25,886 - INFO - training batch 151, loss: 0.337, 4832/28000 datapoints
2025-03-07 10:04:26,151 - INFO - training batch 201, loss: 0.190, 6432/28000 datapoints
2025-03-07 10:04:26,428 - INFO - training batch 251, loss: 0.338, 8032/28000 datapoints
2025-03-07 10:04:26,682 - INFO - training batch 301, loss: 0.608, 9632/28000 datapoints
2025-03-07 10:04:26,928 - INFO - training batch 351, loss: 0.287, 11232/28000 datapoints
2025-03-07 10:04:27,192 - INFO - training batch 401, loss: 0.462, 12832/28000 datapoints
2025-03-07 10:04:27,467 - INFO - training batch 451, loss: 0.349, 14432/28000 datapoints
2025-03-07 10:04:27,821 - INFO - training batch 501, loss: 0.179, 16032/28000 datapoints
2025-03-07 10:04:28,080 - INFO - training batch 551, loss: 0.268, 17632/28000 datapoints
2025-03-07 10:04:28,358 - INFO - training batch 601, loss: 0.523, 19232/28000 datapoints
2025-03-07 10:04:28,709 - INFO - training batch 651, loss: 0.075, 20832/28000 datapoints
2025-03-07 10:04:28,999 - INFO - training batch 701, loss: 0.326, 22432/28000 datapoints
2025-03-07 10:04:29,331 - INFO - training batch 751, loss: 0.162, 24032/28000 datapoints
2025-03-07 10:04:29,818 - INFO - training batch 801, loss: 0.208, 25632/28000 datapoints
2025-03-07 10:04:30,171 - INFO - training batch 851, loss: 0.375, 27232/28000 datapoints
2025-03-07 10:04:30,363 - INFO - validation batch 1, loss: 0.183, 32/6976 datapoints
2025-03-07 10:04:30,486 - INFO - validation batch 51, loss: 1.277, 1632/6976 datapoints
2025-03-07 10:04:30,653 - INFO - validation batch 101, loss: 0.327, 3232/6976 datapoints
2025-03-07 10:04:30,830 - INFO - validation batch 151, loss: 0.310, 4832/6976 datapoints
2025-03-07 10:04:31,008 - INFO - validation batch 201, loss: 0.879, 6432/6976 datapoints
2025-03-07 10:04:31,105 - INFO - Epoch 107/800 done.
2025-03-07 10:04:31,105 - INFO - Final validation performance:
Loss: 0.595, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:04:31,108 - INFO - Beginning epoch 108/800
2025-03-07 10:04:31,120 - INFO - training batch 1, loss: 0.240, 32/28000 datapoints
2025-03-07 10:04:31,650 - INFO - training batch 51, loss: 0.177, 1632/28000 datapoints
2025-03-07 10:04:32,082 - INFO - training batch 101, loss: 0.229, 3232/28000 datapoints
2025-03-07 10:04:32,424 - INFO - training batch 151, loss: 0.328, 4832/28000 datapoints
2025-03-07 10:04:32,755 - INFO - training batch 201, loss: 0.187, 6432/28000 datapoints
2025-03-07 10:04:33,025 - INFO - training batch 251, loss: 0.335, 8032/28000 datapoints
2025-03-07 10:04:33,290 - INFO - training batch 301, loss: 0.608, 9632/28000 datapoints
2025-03-07 10:04:33,578 - INFO - training batch 351, loss: 0.285, 11232/28000 datapoints
2025-03-07 10:04:33,840 - INFO - training batch 401, loss: 0.457, 12832/28000 datapoints
2025-03-07 10:04:34,109 - INFO - training batch 451, loss: 0.347, 14432/28000 datapoints
2025-03-07 10:04:34,400 - INFO - training batch 501, loss: 0.177, 16032/28000 datapoints
2025-03-07 10:04:34,687 - INFO - training batch 551, loss: 0.265, 17632/28000 datapoints
2025-03-07 10:04:34,952 - INFO - training batch 601, loss: 0.513, 19232/28000 datapoints
2025-03-07 10:04:35,206 - INFO - training batch 651, loss: 0.074, 20832/28000 datapoints
2025-03-07 10:04:35,472 - INFO - training batch 701, loss: 0.326, 22432/28000 datapoints
2025-03-07 10:04:35,754 - INFO - training batch 751, loss: 0.158, 24032/28000 datapoints
2025-03-07 10:04:36,063 - INFO - training batch 801, loss: 0.205, 25632/28000 datapoints
2025-03-07 10:04:36,313 - INFO - training batch 851, loss: 0.368, 27232/28000 datapoints
2025-03-07 10:04:36,441 - INFO - validation batch 1, loss: 0.181, 32/6976 datapoints
2025-03-07 10:04:36,554 - INFO - validation batch 51, loss: 1.280, 1632/6976 datapoints
2025-03-07 10:04:36,689 - INFO - validation batch 101, loss: 0.330, 3232/6976 datapoints
2025-03-07 10:04:36,829 - INFO - validation batch 151, loss: 0.308, 4832/6976 datapoints
2025-03-07 10:04:36,934 - INFO - validation batch 201, loss: 0.879, 6432/6976 datapoints
2025-03-07 10:04:36,969 - INFO - Epoch 108/800 done.
2025-03-07 10:04:36,970 - INFO - Final validation performance:
Loss: 0.596, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:04:36,970 - INFO - Beginning epoch 109/800
2025-03-07 10:04:36,977 - INFO - training batch 1, loss: 0.238, 32/28000 datapoints
2025-03-07 10:04:37,241 - INFO - training batch 51, loss: 0.174, 1632/28000 datapoints
2025-03-07 10:04:37,514 - INFO - training batch 101, loss: 0.227, 3232/28000 datapoints
2025-03-07 10:04:37,782 - INFO - training batch 151, loss: 0.320, 4832/28000 datapoints
2025-03-07 10:04:38,077 - INFO - training batch 201, loss: 0.183, 6432/28000 datapoints
2025-03-07 10:04:38,350 - INFO - training batch 251, loss: 0.333, 8032/28000 datapoints
2025-03-07 10:04:38,741 - INFO - training batch 301, loss: 0.608, 9632/28000 datapoints
2025-03-07 10:04:39,149 - INFO - training batch 351, loss: 0.281, 11232/28000 datapoints
2025-03-07 10:04:39,474 - INFO - training batch 401, loss: 0.453, 12832/28000 datapoints
2025-03-07 10:04:39,834 - INFO - training batch 451, loss: 0.346, 14432/28000 datapoints
2025-03-07 10:04:40,209 - INFO - training batch 501, loss: 0.175, 16032/28000 datapoints
2025-03-07 10:04:40,545 - INFO - training batch 551, loss: 0.262, 17632/28000 datapoints
2025-03-07 10:04:40,838 - INFO - training batch 601, loss: 0.506, 19232/28000 datapoints
2025-03-07 10:04:41,125 - INFO - training batch 651, loss: 0.072, 20832/28000 datapoints
2025-03-07 10:04:41,433 - INFO - training batch 701, loss: 0.326, 22432/28000 datapoints
2025-03-07 10:04:41,738 - INFO - training batch 751, loss: 0.154, 24032/28000 datapoints
2025-03-07 10:04:42,126 - INFO - training batch 801, loss: 0.203, 25632/28000 datapoints
2025-03-07 10:04:42,461 - INFO - training batch 851, loss: 0.358, 27232/28000 datapoints
2025-03-07 10:04:42,628 - INFO - validation batch 1, loss: 0.181, 32/6976 datapoints
2025-03-07 10:04:42,720 - INFO - validation batch 51, loss: 1.284, 1632/6976 datapoints
2025-03-07 10:04:42,824 - INFO - validation batch 101, loss: 0.332, 3232/6976 datapoints
2025-03-07 10:04:42,919 - INFO - validation batch 151, loss: 0.309, 4832/6976 datapoints
2025-03-07 10:04:43,004 - INFO - validation batch 201, loss: 0.875, 6432/6976 datapoints
2025-03-07 10:04:43,028 - INFO - Epoch 109/800 done.
2025-03-07 10:04:43,028 - INFO - Final validation performance:
Loss: 0.596, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:04:43,029 - INFO - Beginning epoch 110/800
2025-03-07 10:04:43,036 - INFO - training batch 1, loss: 0.236, 32/28000 datapoints
2025-03-07 10:04:43,358 - INFO - training batch 51, loss: 0.171, 1632/28000 datapoints
2025-03-07 10:04:43,668 - INFO - training batch 101, loss: 0.223, 3232/28000 datapoints
2025-03-07 10:04:44,027 - INFO - training batch 151, loss: 0.311, 4832/28000 datapoints
2025-03-07 10:04:44,450 - INFO - training batch 201, loss: 0.181, 6432/28000 datapoints
2025-03-07 10:04:44,959 - INFO - training batch 251, loss: 0.330, 8032/28000 datapoints
2025-03-07 10:04:45,510 - INFO - training batch 301, loss: 0.607, 9632/28000 datapoints
2025-03-07 10:04:46,725 - INFO - training batch 351, loss: 0.279, 11232/28000 datapoints
2025-03-07 10:04:47,189 - INFO - training batch 401, loss: 0.448, 12832/28000 datapoints
2025-03-07 10:04:47,561 - INFO - training batch 451, loss: 0.344, 14432/28000 datapoints
2025-03-07 10:04:47,866 - INFO - training batch 501, loss: 0.173, 16032/28000 datapoints
2025-03-07 10:04:48,425 - INFO - training batch 551, loss: 0.259, 17632/28000 datapoints
2025-03-07 10:04:49,068 - INFO - training batch 601, loss: 0.498, 19232/28000 datapoints
2025-03-07 10:04:49,529 - INFO - training batch 651, loss: 0.071, 20832/28000 datapoints
2025-03-07 10:04:49,934 - INFO - training batch 701, loss: 0.326, 22432/28000 datapoints
2025-03-07 10:04:50,215 - INFO - training batch 751, loss: 0.154, 24032/28000 datapoints
2025-03-07 10:04:50,629 - INFO - training batch 801, loss: 0.201, 25632/28000 datapoints
2025-03-07 10:04:50,904 - INFO - training batch 851, loss: 0.350, 27232/28000 datapoints
2025-03-07 10:04:51,031 - INFO - validation batch 1, loss: 0.181, 32/6976 datapoints
2025-03-07 10:04:51,122 - INFO - validation batch 51, loss: 1.288, 1632/6976 datapoints
2025-03-07 10:04:51,232 - INFO - validation batch 101, loss: 0.336, 3232/6976 datapoints
2025-03-07 10:04:51,339 - INFO - validation batch 151, loss: 0.305, 4832/6976 datapoints
2025-03-07 10:04:51,454 - INFO - validation batch 201, loss: 0.873, 6432/6976 datapoints
2025-03-07 10:04:51,478 - INFO - Epoch 110/800 done.
2025-03-07 10:04:51,479 - INFO - Final validation performance:
Loss: 0.597, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:04:51,479 - INFO - Beginning epoch 111/800
2025-03-07 10:04:51,497 - INFO - training batch 1, loss: 0.234, 32/28000 datapoints
2025-03-07 10:04:51,851 - INFO - training batch 51, loss: 0.168, 1632/28000 datapoints
2025-03-07 10:04:52,158 - INFO - training batch 101, loss: 0.221, 3232/28000 datapoints
2025-03-07 10:04:52,429 - INFO - training batch 151, loss: 0.304, 4832/28000 datapoints
2025-03-07 10:04:52,709 - INFO - training batch 201, loss: 0.177, 6432/28000 datapoints
2025-03-07 10:04:53,063 - INFO - training batch 251, loss: 0.328, 8032/28000 datapoints
2025-03-07 10:04:53,350 - INFO - training batch 301, loss: 0.609, 9632/28000 datapoints
2025-03-07 10:04:53,677 - INFO - training batch 351, loss: 0.278, 11232/28000 datapoints
2025-03-07 10:04:53,958 - INFO - training batch 401, loss: 0.444, 12832/28000 datapoints
2025-03-07 10:04:54,204 - INFO - training batch 451, loss: 0.342, 14432/28000 datapoints
2025-03-07 10:04:54,450 - INFO - training batch 501, loss: 0.171, 16032/28000 datapoints
2025-03-07 10:04:54,684 - INFO - training batch 551, loss: 0.257, 17632/28000 datapoints
2025-03-07 10:04:54,943 - INFO - training batch 601, loss: 0.490, 19232/28000 datapoints
2025-03-07 10:04:55,174 - INFO - training batch 651, loss: 0.069, 20832/28000 datapoints
2025-03-07 10:04:55,407 - INFO - training batch 701, loss: 0.326, 22432/28000 datapoints
2025-03-07 10:04:55,657 - INFO - training batch 751, loss: 0.149, 24032/28000 datapoints
2025-03-07 10:04:55,893 - INFO - training batch 801, loss: 0.199, 25632/28000 datapoints
2025-03-07 10:04:56,168 - INFO - training batch 851, loss: 0.343, 27232/28000 datapoints
2025-03-07 10:04:56,286 - INFO - validation batch 1, loss: 0.181, 32/6976 datapoints
2025-03-07 10:04:56,360 - INFO - validation batch 51, loss: 1.296, 1632/6976 datapoints
2025-03-07 10:04:56,446 - INFO - validation batch 101, loss: 0.339, 3232/6976 datapoints
2025-03-07 10:04:56,513 - INFO - validation batch 151, loss: 0.306, 4832/6976 datapoints
2025-03-07 10:04:56,589 - INFO - validation batch 201, loss: 0.872, 6432/6976 datapoints
2025-03-07 10:04:56,619 - INFO - Epoch 111/800 done.
2025-03-07 10:04:56,620 - INFO - Final validation performance:
Loss: 0.599, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:04:56,620 - INFO - Beginning epoch 112/800
2025-03-07 10:04:56,629 - INFO - training batch 1, loss: 0.233, 32/28000 datapoints
2025-03-07 10:04:56,913 - INFO - training batch 51, loss: 0.166, 1632/28000 datapoints
2025-03-07 10:04:57,167 - INFO - training batch 101, loss: 0.218, 3232/28000 datapoints
2025-03-07 10:04:57,421 - INFO - training batch 151, loss: 0.296, 4832/28000 datapoints
2025-03-07 10:04:57,700 - INFO - training batch 201, loss: 0.175, 6432/28000 datapoints
2025-03-07 10:04:57,985 - INFO - training batch 251, loss: 0.325, 8032/28000 datapoints
2025-03-07 10:04:58,262 - INFO - training batch 301, loss: 0.608, 9632/28000 datapoints
2025-03-07 10:04:58,527 - INFO - training batch 351, loss: 0.276, 11232/28000 datapoints
2025-03-07 10:04:58,764 - INFO - training batch 401, loss: 0.440, 12832/28000 datapoints
2025-03-07 10:04:59,000 - INFO - training batch 451, loss: 0.341, 14432/28000 datapoints
2025-03-07 10:04:59,235 - INFO - training batch 501, loss: 0.169, 16032/28000 datapoints
2025-03-07 10:04:59,528 - INFO - training batch 551, loss: 0.253, 17632/28000 datapoints
2025-03-07 10:04:59,765 - INFO - training batch 601, loss: 0.481, 19232/28000 datapoints
2025-03-07 10:05:00,007 - INFO - training batch 651, loss: 0.068, 20832/28000 datapoints
2025-03-07 10:05:00,289 - INFO - training batch 701, loss: 0.325, 22432/28000 datapoints
2025-03-07 10:05:00,540 - INFO - training batch 751, loss: 0.148, 24032/28000 datapoints
2025-03-07 10:05:00,765 - INFO - training batch 801, loss: 0.196, 25632/28000 datapoints
2025-03-07 10:05:00,992 - INFO - training batch 851, loss: 0.336, 27232/28000 datapoints
2025-03-07 10:05:01,102 - INFO - validation batch 1, loss: 0.180, 32/6976 datapoints
2025-03-07 10:05:01,173 - INFO - validation batch 51, loss: 1.297, 1632/6976 datapoints
2025-03-07 10:05:01,278 - INFO - validation batch 101, loss: 0.342, 3232/6976 datapoints
2025-03-07 10:05:01,352 - INFO - validation batch 151, loss: 0.304, 4832/6976 datapoints
2025-03-07 10:05:01,428 - INFO - validation batch 201, loss: 0.870, 6432/6976 datapoints
2025-03-07 10:05:01,466 - INFO - Epoch 112/800 done.
2025-03-07 10:05:01,467 - INFO - Final validation performance:
Loss: 0.599, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:05:01,467 - INFO - Beginning epoch 113/800
2025-03-07 10:05:01,475 - INFO - training batch 1, loss: 0.231, 32/28000 datapoints
2025-03-07 10:05:01,752 - INFO - training batch 51, loss: 0.163, 1632/28000 datapoints
2025-03-07 10:05:01,988 - INFO - training batch 101, loss: 0.214, 3232/28000 datapoints
2025-03-07 10:05:02,227 - INFO - training batch 151, loss: 0.288, 4832/28000 datapoints
2025-03-07 10:05:02,494 - INFO - training batch 201, loss: 0.172, 6432/28000 datapoints
2025-03-07 10:05:02,737 - INFO - training batch 251, loss: 0.322, 8032/28000 datapoints
2025-03-07 10:05:02,981 - INFO - training batch 301, loss: 0.609, 9632/28000 datapoints
2025-03-07 10:05:03,229 - INFO - training batch 351, loss: 0.274, 11232/28000 datapoints
2025-03-07 10:05:03,485 - INFO - training batch 401, loss: 0.436, 12832/28000 datapoints
2025-03-07 10:05:03,778 - INFO - training batch 451, loss: 0.339, 14432/28000 datapoints
2025-03-07 10:05:04,072 - INFO - training batch 501, loss: 0.168, 16032/28000 datapoints
2025-03-07 10:05:04,340 - INFO - training batch 551, loss: 0.250, 17632/28000 datapoints
2025-03-07 10:05:04,620 - INFO - training batch 601, loss: 0.470, 19232/28000 datapoints
2025-03-07 10:05:04,858 - INFO - training batch 651, loss: 0.066, 20832/28000 datapoints
2025-03-07 10:05:05,133 - INFO - training batch 701, loss: 0.325, 22432/28000 datapoints
2025-03-07 10:05:05,384 - INFO - training batch 751, loss: 0.148, 24032/28000 datapoints
2025-03-07 10:05:05,637 - INFO - training batch 801, loss: 0.194, 25632/28000 datapoints
2025-03-07 10:05:05,881 - INFO - training batch 851, loss: 0.329, 27232/28000 datapoints
2025-03-07 10:05:06,033 - INFO - validation batch 1, loss: 0.179, 32/6976 datapoints
2025-03-07 10:05:06,110 - INFO - validation batch 51, loss: 1.303, 1632/6976 datapoints
2025-03-07 10:05:06,187 - INFO - validation batch 101, loss: 0.347, 3232/6976 datapoints
2025-03-07 10:05:06,259 - INFO - validation batch 151, loss: 0.301, 4832/6976 datapoints
2025-03-07 10:05:06,329 - INFO - validation batch 201, loss: 0.869, 6432/6976 datapoints
2025-03-07 10:05:06,356 - INFO - Epoch 113/800 done.
2025-03-07 10:05:06,357 - INFO - Final validation performance:
Loss: 0.600, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:05:06,357 - INFO - Beginning epoch 114/800
2025-03-07 10:05:06,366 - INFO - training batch 1, loss: 0.229, 32/28000 datapoints
2025-03-07 10:05:06,681 - INFO - training batch 51, loss: 0.160, 1632/28000 datapoints
2025-03-07 10:05:06,921 - INFO - training batch 101, loss: 0.212, 3232/28000 datapoints
2025-03-07 10:05:07,170 - INFO - training batch 151, loss: 0.281, 4832/28000 datapoints
2025-03-07 10:05:07,434 - INFO - training batch 201, loss: 0.169, 6432/28000 datapoints
2025-03-07 10:05:07,684 - INFO - training batch 251, loss: 0.320, 8032/28000 datapoints
2025-03-07 10:05:07,960 - INFO - training batch 301, loss: 0.609, 9632/28000 datapoints
2025-03-07 10:05:08,372 - INFO - training batch 351, loss: 0.272, 11232/28000 datapoints
2025-03-07 10:05:08,624 - INFO - training batch 401, loss: 0.432, 12832/28000 datapoints
2025-03-07 10:05:09,316 - INFO - training batch 451, loss: 0.337, 14432/28000 datapoints
2025-03-07 10:05:09,870 - INFO - training batch 501, loss: 0.165, 16032/28000 datapoints
2025-03-07 10:05:10,140 - INFO - training batch 551, loss: 0.247, 17632/28000 datapoints
2025-03-07 10:05:10,435 - INFO - training batch 601, loss: 0.463, 19232/28000 datapoints
2025-03-07 10:05:10,710 - INFO - training batch 651, loss: 0.064, 20832/28000 datapoints
2025-03-07 10:05:11,226 - INFO - training batch 701, loss: 0.324, 22432/28000 datapoints
2025-03-07 10:05:11,494 - INFO - training batch 751, loss: 0.147, 24032/28000 datapoints
2025-03-07 10:05:11,772 - INFO - training batch 801, loss: 0.191, 25632/28000 datapoints
2025-03-07 10:05:12,027 - INFO - training batch 851, loss: 0.323, 27232/28000 datapoints
2025-03-07 10:05:12,141 - INFO - validation batch 1, loss: 0.179, 32/6976 datapoints
2025-03-07 10:05:12,209 - INFO - validation batch 51, loss: 1.309, 1632/6976 datapoints
2025-03-07 10:05:12,286 - INFO - validation batch 101, loss: 0.351, 3232/6976 datapoints
2025-03-07 10:05:12,362 - INFO - validation batch 151, loss: 0.301, 4832/6976 datapoints
2025-03-07 10:05:12,437 - INFO - validation batch 201, loss: 0.868, 6432/6976 datapoints
2025-03-07 10:05:12,462 - INFO - Epoch 114/800 done.
2025-03-07 10:05:12,462 - INFO - Final validation performance:
Loss: 0.602, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:05:12,463 - INFO - Beginning epoch 115/800
2025-03-07 10:05:12,470 - INFO - training batch 1, loss: 0.227, 32/28000 datapoints
2025-03-07 10:05:12,743 - INFO - training batch 51, loss: 0.157, 1632/28000 datapoints
2025-03-07 10:05:13,001 - INFO - training batch 101, loss: 0.209, 3232/28000 datapoints
2025-03-07 10:05:13,286 - INFO - training batch 151, loss: 0.273, 4832/28000 datapoints
2025-03-07 10:05:13,530 - INFO - training batch 201, loss: 0.167, 6432/28000 datapoints
2025-03-07 10:05:13,755 - INFO - training batch 251, loss: 0.316, 8032/28000 datapoints
2025-03-07 10:05:14,006 - INFO - training batch 301, loss: 0.610, 9632/28000 datapoints
2025-03-07 10:05:14,240 - INFO - training batch 351, loss: 0.270, 11232/28000 datapoints
2025-03-07 10:05:14,483 - INFO - training batch 401, loss: 0.429, 12832/28000 datapoints
2025-03-07 10:05:14,723 - INFO - training batch 451, loss: 0.336, 14432/28000 datapoints
2025-03-07 10:05:14,979 - INFO - training batch 501, loss: 0.164, 16032/28000 datapoints
2025-03-07 10:05:15,254 - INFO - training batch 551, loss: 0.244, 17632/28000 datapoints
2025-03-07 10:05:15,510 - INFO - training batch 601, loss: 0.456, 19232/28000 datapoints
2025-03-07 10:05:15,808 - INFO - training batch 651, loss: 0.063, 20832/28000 datapoints
2025-03-07 10:05:16,077 - INFO - training batch 701, loss: 0.324, 22432/28000 datapoints
2025-03-07 10:05:16,325 - INFO - training batch 751, loss: 0.146, 24032/28000 datapoints
2025-03-07 10:05:16,555 - INFO - training batch 801, loss: 0.188, 25632/28000 datapoints
2025-03-07 10:05:16,775 - INFO - training batch 851, loss: 0.315, 27232/28000 datapoints
2025-03-07 10:05:16,885 - INFO - validation batch 1, loss: 0.178, 32/6976 datapoints
2025-03-07 10:05:16,949 - INFO - validation batch 51, loss: 1.312, 1632/6976 datapoints
2025-03-07 10:05:17,023 - INFO - validation batch 101, loss: 0.356, 3232/6976 datapoints
2025-03-07 10:05:17,099 - INFO - validation batch 151, loss: 0.301, 4832/6976 datapoints
2025-03-07 10:05:17,166 - INFO - validation batch 201, loss: 0.868, 6432/6976 datapoints
2025-03-07 10:05:17,191 - INFO - Epoch 115/800 done.
2025-03-07 10:05:17,192 - INFO - Final validation performance:
Loss: 0.603, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:05:17,192 - INFO - Beginning epoch 116/800
2025-03-07 10:05:17,201 - INFO - training batch 1, loss: 0.226, 32/28000 datapoints
2025-03-07 10:05:17,434 - INFO - training batch 51, loss: 0.154, 1632/28000 datapoints
2025-03-07 10:05:17,664 - INFO - training batch 101, loss: 0.206, 3232/28000 datapoints
2025-03-07 10:05:17,883 - INFO - training batch 151, loss: 0.266, 4832/28000 datapoints
2025-03-07 10:05:18,109 - INFO - training batch 201, loss: 0.165, 6432/28000 datapoints
2025-03-07 10:05:18,344 - INFO - training batch 251, loss: 0.314, 8032/28000 datapoints
2025-03-07 10:05:18,605 - INFO - training batch 301, loss: 0.610, 9632/28000 datapoints
2025-03-07 10:05:18,871 - INFO - training batch 351, loss: 0.269, 11232/28000 datapoints
2025-03-07 10:05:19,395 - INFO - training batch 401, loss: 0.424, 12832/28000 datapoints
2025-03-07 10:05:19,686 - INFO - training batch 451, loss: 0.333, 14432/28000 datapoints
2025-03-07 10:05:19,914 - INFO - training batch 501, loss: 0.162, 16032/28000 datapoints
2025-03-07 10:05:20,168 - INFO - training batch 551, loss: 0.243, 17632/28000 datapoints
2025-03-07 10:05:20,407 - INFO - training batch 601, loss: 0.450, 19232/28000 datapoints
2025-03-07 10:05:20,655 - INFO - training batch 651, loss: 0.061, 20832/28000 datapoints
2025-03-07 10:05:20,896 - INFO - training batch 701, loss: 0.323, 22432/28000 datapoints
2025-03-07 10:05:21,149 - INFO - training batch 751, loss: 0.144, 24032/28000 datapoints
2025-03-07 10:05:21,383 - INFO - training batch 801, loss: 0.186, 25632/28000 datapoints
2025-03-07 10:05:21,638 - INFO - training batch 851, loss: 0.309, 27232/28000 datapoints
2025-03-07 10:05:21,750 - INFO - validation batch 1, loss: 0.177, 32/6976 datapoints
2025-03-07 10:05:21,816 - INFO - validation batch 51, loss: 1.314, 1632/6976 datapoints
2025-03-07 10:05:21,890 - INFO - validation batch 101, loss: 0.359, 3232/6976 datapoints
2025-03-07 10:05:21,954 - INFO - validation batch 151, loss: 0.299, 4832/6976 datapoints
2025-03-07 10:05:22,073 - INFO - validation batch 201, loss: 0.865, 6432/6976 datapoints
2025-03-07 10:05:22,099 - INFO - Epoch 116/800 done.
2025-03-07 10:05:22,099 - INFO - Final validation performance:
Loss: 0.603, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:05:22,100 - INFO - Beginning epoch 117/800
2025-03-07 10:05:22,106 - INFO - training batch 1, loss: 0.224, 32/28000 datapoints
2025-03-07 10:05:22,371 - INFO - training batch 51, loss: 0.151, 1632/28000 datapoints
2025-03-07 10:05:22,666 - INFO - training batch 101, loss: 0.204, 3232/28000 datapoints
2025-03-07 10:05:23,324 - INFO - training batch 151, loss: 0.258, 4832/28000 datapoints
2025-03-07 10:05:23,718 - INFO - training batch 201, loss: 0.162, 6432/28000 datapoints
2025-03-07 10:05:24,077 - INFO - training batch 251, loss: 0.311, 8032/28000 datapoints
2025-03-07 10:05:24,738 - INFO - training batch 301, loss: 0.609, 9632/28000 datapoints
2025-03-07 10:05:25,077 - INFO - training batch 351, loss: 0.266, 11232/28000 datapoints
2025-03-07 10:05:25,442 - INFO - training batch 401, loss: 0.421, 12832/28000 datapoints
2025-03-07 10:05:25,821 - INFO - training batch 451, loss: 0.333, 14432/28000 datapoints
2025-03-07 10:05:26,137 - INFO - training batch 501, loss: 0.162, 16032/28000 datapoints
2025-03-07 10:05:26,504 - INFO - training batch 551, loss: 0.240, 17632/28000 datapoints
2025-03-07 10:05:26,867 - INFO - training batch 601, loss: 0.441, 19232/28000 datapoints
2025-03-07 10:05:27,270 - INFO - training batch 651, loss: 0.060, 20832/28000 datapoints
2025-03-07 10:05:27,585 - INFO - training batch 701, loss: 0.322, 22432/28000 datapoints
2025-03-07 10:05:27,885 - INFO - training batch 751, loss: 0.143, 24032/28000 datapoints
2025-03-07 10:05:28,220 - INFO - training batch 801, loss: 0.183, 25632/28000 datapoints
2025-03-07 10:05:28,494 - INFO - training batch 851, loss: 0.303, 27232/28000 datapoints
2025-03-07 10:05:28,636 - INFO - validation batch 1, loss: 0.177, 32/6976 datapoints
2025-03-07 10:05:28,722 - INFO - validation batch 51, loss: 1.319, 1632/6976 datapoints
2025-03-07 10:05:28,797 - INFO - validation batch 101, loss: 0.363, 3232/6976 datapoints
2025-03-07 10:05:28,872 - INFO - validation batch 151, loss: 0.299, 4832/6976 datapoints
2025-03-07 10:05:28,947 - INFO - validation batch 201, loss: 0.864, 6432/6976 datapoints
2025-03-07 10:05:28,970 - INFO - Epoch 117/800 done.
2025-03-07 10:05:28,970 - INFO - Final validation performance:
Loss: 0.604, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:05:28,971 - INFO - Beginning epoch 118/800
2025-03-07 10:05:28,978 - INFO - training batch 1, loss: 0.222, 32/28000 datapoints
2025-03-07 10:05:29,237 - INFO - training batch 51, loss: 0.149, 1632/28000 datapoints
2025-03-07 10:05:29,546 - INFO - training batch 101, loss: 0.201, 3232/28000 datapoints
2025-03-07 10:05:29,834 - INFO - training batch 151, loss: 0.251, 4832/28000 datapoints
2025-03-07 10:05:30,088 - INFO - training batch 201, loss: 0.159, 6432/28000 datapoints
2025-03-07 10:05:30,530 - INFO - training batch 251, loss: 0.308, 8032/28000 datapoints
2025-03-07 10:05:30,919 - INFO - training batch 301, loss: 0.609, 9632/28000 datapoints
2025-03-07 10:05:31,248 - INFO - training batch 351, loss: 0.265, 11232/28000 datapoints
2025-03-07 10:05:31,493 - INFO - training batch 401, loss: 0.417, 12832/28000 datapoints
2025-03-07 10:05:31,741 - INFO - training batch 451, loss: 0.332, 14432/28000 datapoints
2025-03-07 10:05:32,023 - INFO - training batch 501, loss: 0.160, 16032/28000 datapoints
2025-03-07 10:05:32,286 - INFO - training batch 551, loss: 0.238, 17632/28000 datapoints
2025-03-07 10:05:32,528 - INFO - training batch 601, loss: 0.436, 19232/28000 datapoints
2025-03-07 10:05:32,769 - INFO - training batch 651, loss: 0.058, 20832/28000 datapoints
2025-03-07 10:05:33,033 - INFO - training batch 701, loss: 0.322, 22432/28000 datapoints
2025-03-07 10:05:33,315 - INFO - training batch 751, loss: 0.140, 24032/28000 datapoints
2025-03-07 10:05:33,584 - INFO - training batch 801, loss: 0.180, 25632/28000 datapoints
2025-03-07 10:05:33,836 - INFO - training batch 851, loss: 0.297, 27232/28000 datapoints
2025-03-07 10:05:33,964 - INFO - validation batch 1, loss: 0.175, 32/6976 datapoints
2025-03-07 10:05:34,036 - INFO - validation batch 51, loss: 1.320, 1632/6976 datapoints
2025-03-07 10:05:34,125 - INFO - validation batch 101, loss: 0.367, 3232/6976 datapoints
2025-03-07 10:05:34,211 - INFO - validation batch 151, loss: 0.296, 4832/6976 datapoints
2025-03-07 10:05:34,369 - INFO - validation batch 201, loss: 0.863, 6432/6976 datapoints
2025-03-07 10:05:34,435 - INFO - Epoch 118/800 done.
2025-03-07 10:05:34,435 - INFO - Final validation performance:
Loss: 0.604, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:05:34,436 - INFO - Beginning epoch 119/800
2025-03-07 10:05:34,495 - INFO - training batch 1, loss: 0.220, 32/28000 datapoints
2025-03-07 10:05:34,851 - INFO - training batch 51, loss: 0.146, 1632/28000 datapoints
2025-03-07 10:05:35,145 - INFO - training batch 101, loss: 0.199, 3232/28000 datapoints
2025-03-07 10:05:35,488 - INFO - training batch 151, loss: 0.245, 4832/28000 datapoints
2025-03-07 10:05:35,759 - INFO - training batch 201, loss: 0.157, 6432/28000 datapoints
2025-03-07 10:05:36,003 - INFO - training batch 251, loss: 0.306, 8032/28000 datapoints
2025-03-07 10:05:36,244 - INFO - training batch 301, loss: 0.607, 9632/28000 datapoints
2025-03-07 10:05:36,513 - INFO - training batch 351, loss: 0.264, 11232/28000 datapoints
2025-03-07 10:05:36,827 - INFO - training batch 401, loss: 0.413, 12832/28000 datapoints
2025-03-07 10:05:37,164 - INFO - training batch 451, loss: 0.330, 14432/28000 datapoints
2025-03-07 10:05:37,401 - INFO - training batch 501, loss: 0.158, 16032/28000 datapoints
2025-03-07 10:05:37,676 - INFO - training batch 551, loss: 0.235, 17632/28000 datapoints
2025-03-07 10:05:37,977 - INFO - training batch 601, loss: 0.430, 19232/28000 datapoints
2025-03-07 10:05:38,298 - INFO - training batch 651, loss: 0.057, 20832/28000 datapoints
2025-03-07 10:05:38,555 - INFO - training batch 701, loss: 0.321, 22432/28000 datapoints
2025-03-07 10:05:38,792 - INFO - training batch 751, loss: 0.139, 24032/28000 datapoints
2025-03-07 10:05:39,028 - INFO - training batch 801, loss: 0.177, 25632/28000 datapoints
2025-03-07 10:05:39,263 - INFO - training batch 851, loss: 0.290, 27232/28000 datapoints
2025-03-07 10:05:39,386 - INFO - validation batch 1, loss: 0.174, 32/6976 datapoints
2025-03-07 10:05:39,466 - INFO - validation batch 51, loss: 1.326, 1632/6976 datapoints
2025-03-07 10:05:39,560 - INFO - validation batch 101, loss: 0.370, 3232/6976 datapoints
2025-03-07 10:05:39,637 - INFO - validation batch 151, loss: 0.296, 4832/6976 datapoints
2025-03-07 10:05:39,712 - INFO - validation batch 201, loss: 0.861, 6432/6976 datapoints
2025-03-07 10:05:39,736 - INFO - Epoch 119/800 done.
2025-03-07 10:05:39,736 - INFO - Final validation performance:
Loss: 0.605, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:05:39,737 - INFO - Beginning epoch 120/800
2025-03-07 10:05:39,747 - INFO - training batch 1, loss: 0.219, 32/28000 datapoints
2025-03-07 10:05:39,998 - INFO - training batch 51, loss: 0.142, 1632/28000 datapoints
2025-03-07 10:05:40,228 - INFO - training batch 101, loss: 0.197, 3232/28000 datapoints
2025-03-07 10:05:40,471 - INFO - training batch 151, loss: 0.238, 4832/28000 datapoints
2025-03-07 10:05:40,700 - INFO - training batch 201, loss: 0.154, 6432/28000 datapoints
2025-03-07 10:05:40,940 - INFO - training batch 251, loss: 0.303, 8032/28000 datapoints
2025-03-07 10:05:41,186 - INFO - training batch 301, loss: 0.608, 9632/28000 datapoints
2025-03-07 10:05:41,454 - INFO - training batch 351, loss: 0.262, 11232/28000 datapoints
2025-03-07 10:05:41,686 - INFO - training batch 401, loss: 0.410, 12832/28000 datapoints
2025-03-07 10:05:41,915 - INFO - training batch 451, loss: 0.329, 14432/28000 datapoints
2025-03-07 10:05:42,171 - INFO - training batch 501, loss: 0.157, 16032/28000 datapoints
2025-03-07 10:05:42,402 - INFO - training batch 551, loss: 0.233, 17632/28000 datapoints
2025-03-07 10:05:42,670 - INFO - training batch 601, loss: 0.422, 19232/28000 datapoints
2025-03-07 10:05:42,922 - INFO - training batch 651, loss: 0.055, 20832/28000 datapoints
2025-03-07 10:05:43,154 - INFO - training batch 701, loss: 0.320, 22432/28000 datapoints
2025-03-07 10:05:43,403 - INFO - training batch 751, loss: 0.138, 24032/28000 datapoints
2025-03-07 10:05:43,640 - INFO - training batch 801, loss: 0.175, 25632/28000 datapoints
2025-03-07 10:05:43,869 - INFO - training batch 851, loss: 0.284, 27232/28000 datapoints
2025-03-07 10:05:43,981 - INFO - validation batch 1, loss: 0.173, 32/6976 datapoints
2025-03-07 10:05:44,072 - INFO - validation batch 51, loss: 1.327, 1632/6976 datapoints
2025-03-07 10:05:44,140 - INFO - validation batch 101, loss: 0.375, 3232/6976 datapoints
2025-03-07 10:05:44,212 - INFO - validation batch 151, loss: 0.294, 4832/6976 datapoints
2025-03-07 10:05:44,282 - INFO - validation batch 201, loss: 0.862, 6432/6976 datapoints
2025-03-07 10:05:44,307 - INFO - Epoch 120/800 done.
2025-03-07 10:05:44,307 - INFO - Final validation performance:
Loss: 0.606, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:05:44,307 - INFO - Beginning epoch 121/800
2025-03-07 10:05:44,315 - INFO - training batch 1, loss: 0.217, 32/28000 datapoints
2025-03-07 10:05:44,612 - INFO - training batch 51, loss: 0.140, 1632/28000 datapoints
2025-03-07 10:05:44,896 - INFO - training batch 101, loss: 0.194, 3232/28000 datapoints
2025-03-07 10:05:45,140 - INFO - training batch 151, loss: 0.233, 4832/28000 datapoints
2025-03-07 10:05:45,375 - INFO - training batch 201, loss: 0.152, 6432/28000 datapoints
2025-03-07 10:05:45,632 - INFO - training batch 251, loss: 0.300, 8032/28000 datapoints
2025-03-07 10:05:45,856 - INFO - training batch 301, loss: 0.607, 9632/28000 datapoints
2025-03-07 10:05:46,084 - INFO - training batch 351, loss: 0.261, 11232/28000 datapoints
2025-03-07 10:05:46,330 - INFO - training batch 401, loss: 0.406, 12832/28000 datapoints
2025-03-07 10:05:46,565 - INFO - training batch 451, loss: 0.327, 14432/28000 datapoints
2025-03-07 10:05:46,793 - INFO - training batch 501, loss: 0.155, 16032/28000 datapoints
2025-03-07 10:05:47,047 - INFO - training batch 551, loss: 0.231, 17632/28000 datapoints
2025-03-07 10:05:47,289 - INFO - training batch 601, loss: 0.416, 19232/28000 datapoints
2025-03-07 10:05:47,538 - INFO - training batch 651, loss: 0.054, 20832/28000 datapoints
2025-03-07 10:05:47,773 - INFO - training batch 701, loss: 0.319, 22432/28000 datapoints
2025-03-07 10:05:48,007 - INFO - training batch 751, loss: 0.137, 24032/28000 datapoints
2025-03-07 10:05:48,231 - INFO - training batch 801, loss: 0.172, 25632/28000 datapoints
2025-03-07 10:05:48,463 - INFO - training batch 851, loss: 0.277, 27232/28000 datapoints
2025-03-07 10:05:48,585 - INFO - validation batch 1, loss: 0.172, 32/6976 datapoints
2025-03-07 10:05:48,649 - INFO - validation batch 51, loss: 1.330, 1632/6976 datapoints
2025-03-07 10:05:48,717 - INFO - validation batch 101, loss: 0.379, 3232/6976 datapoints
2025-03-07 10:05:48,781 - INFO - validation batch 151, loss: 0.294, 4832/6976 datapoints
2025-03-07 10:05:48,844 - INFO - validation batch 201, loss: 0.862, 6432/6976 datapoints
2025-03-07 10:05:48,867 - INFO - Epoch 121/800 done.
2025-03-07 10:05:48,867 - INFO - Final validation performance:
Loss: 0.607, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:05:48,868 - INFO - Beginning epoch 122/800
2025-03-07 10:05:48,875 - INFO - training batch 1, loss: 0.217, 32/28000 datapoints
2025-03-07 10:05:49,105 - INFO - training batch 51, loss: 0.137, 1632/28000 datapoints
2025-03-07 10:05:49,351 - INFO - training batch 101, loss: 0.192, 3232/28000 datapoints
2025-03-07 10:05:49,577 - INFO - training batch 151, loss: 0.228, 4832/28000 datapoints
2025-03-07 10:05:49,811 - INFO - training batch 201, loss: 0.149, 6432/28000 datapoints
2025-03-07 10:05:50,039 - INFO - training batch 251, loss: 0.298, 8032/28000 datapoints
2025-03-07 10:05:50,270 - INFO - training batch 301, loss: 0.605, 9632/28000 datapoints
2025-03-07 10:05:50,499 - INFO - training batch 351, loss: 0.259, 11232/28000 datapoints
2025-03-07 10:05:50,740 - INFO - training batch 401, loss: 0.402, 12832/28000 datapoints
2025-03-07 10:05:50,980 - INFO - training batch 451, loss: 0.326, 14432/28000 datapoints
2025-03-07 10:05:51,232 - INFO - training batch 501, loss: 0.153, 16032/28000 datapoints
2025-03-07 10:05:51,499 - INFO - training batch 551, loss: 0.228, 17632/28000 datapoints
2025-03-07 10:05:51,736 - INFO - training batch 601, loss: 0.409, 19232/28000 datapoints
2025-03-07 10:05:51,960 - INFO - training batch 651, loss: 0.053, 20832/28000 datapoints
2025-03-07 10:05:52,188 - INFO - training batch 701, loss: 0.318, 22432/28000 datapoints
2025-03-07 10:05:52,417 - INFO - training batch 751, loss: 0.135, 24032/28000 datapoints
2025-03-07 10:05:52,645 - INFO - training batch 801, loss: 0.169, 25632/28000 datapoints
2025-03-07 10:05:52,873 - INFO - training batch 851, loss: 0.271, 27232/28000 datapoints
2025-03-07 10:05:52,984 - INFO - validation batch 1, loss: 0.171, 32/6976 datapoints
2025-03-07 10:05:53,052 - INFO - validation batch 51, loss: 1.334, 1632/6976 datapoints
2025-03-07 10:05:53,124 - INFO - validation batch 101, loss: 0.384, 3232/6976 datapoints
2025-03-07 10:05:53,198 - INFO - validation batch 151, loss: 0.293, 4832/6976 datapoints
2025-03-07 10:05:53,270 - INFO - validation batch 201, loss: 0.862, 6432/6976 datapoints
2025-03-07 10:05:53,294 - INFO - Epoch 122/800 done.
2025-03-07 10:05:53,294 - INFO - Final validation performance:
Loss: 0.609, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:05:53,295 - INFO - Beginning epoch 123/800
2025-03-07 10:05:53,303 - INFO - training batch 1, loss: 0.214, 32/28000 datapoints
2025-03-07 10:05:53,535 - INFO - training batch 51, loss: 0.134, 1632/28000 datapoints
2025-03-07 10:05:53,778 - INFO - training batch 101, loss: 0.189, 3232/28000 datapoints
2025-03-07 10:05:54,003 - INFO - training batch 151, loss: 0.222, 4832/28000 datapoints
2025-03-07 10:05:54,231 - INFO - training batch 201, loss: 0.147, 6432/28000 datapoints
2025-03-07 10:05:54,456 - INFO - training batch 251, loss: 0.295, 8032/28000 datapoints
2025-03-07 10:05:54,690 - INFO - training batch 301, loss: 0.606, 9632/28000 datapoints
2025-03-07 10:05:54,918 - INFO - training batch 351, loss: 0.259, 11232/28000 datapoints
2025-03-07 10:05:55,142 - INFO - training batch 401, loss: 0.398, 12832/28000 datapoints
2025-03-07 10:05:55,366 - INFO - training batch 451, loss: 0.323, 14432/28000 datapoints
2025-03-07 10:05:55,612 - INFO - training batch 501, loss: 0.152, 16032/28000 datapoints
2025-03-07 10:05:55,830 - INFO - training batch 551, loss: 0.225, 17632/28000 datapoints
2025-03-07 10:05:56,045 - INFO - training batch 601, loss: 0.401, 19232/28000 datapoints
2025-03-07 10:05:56,292 - INFO - training batch 651, loss: 0.051, 20832/28000 datapoints
2025-03-07 10:05:56,545 - INFO - training batch 701, loss: 0.317, 22432/28000 datapoints
2025-03-07 10:05:56,795 - INFO - training batch 751, loss: 0.134, 24032/28000 datapoints
2025-03-07 10:05:57,021 - INFO - training batch 801, loss: 0.166, 25632/28000 datapoints
2025-03-07 10:05:57,260 - INFO - training batch 851, loss: 0.265, 27232/28000 datapoints
2025-03-07 10:05:57,384 - INFO - validation batch 1, loss: 0.171, 32/6976 datapoints
2025-03-07 10:05:57,449 - INFO - validation batch 51, loss: 1.337, 1632/6976 datapoints
2025-03-07 10:05:57,524 - INFO - validation batch 101, loss: 0.387, 3232/6976 datapoints
2025-03-07 10:05:57,592 - INFO - validation batch 151, loss: 0.293, 4832/6976 datapoints
2025-03-07 10:05:57,700 - INFO - validation batch 201, loss: 0.860, 6432/6976 datapoints
2025-03-07 10:05:57,736 - INFO - Epoch 123/800 done.
2025-03-07 10:05:57,736 - INFO - Final validation performance:
Loss: 0.610, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:05:57,737 - INFO - Beginning epoch 124/800
2025-03-07 10:05:57,746 - INFO - training batch 1, loss: 0.212, 32/28000 datapoints
2025-03-07 10:05:58,047 - INFO - training batch 51, loss: 0.132, 1632/28000 datapoints
2025-03-07 10:05:58,301 - INFO - training batch 101, loss: 0.186, 3232/28000 datapoints
2025-03-07 10:05:58,841 - INFO - training batch 151, loss: 0.216, 4832/28000 datapoints
2025-03-07 10:05:59,080 - INFO - training batch 201, loss: 0.144, 6432/28000 datapoints
2025-03-07 10:05:59,318 - INFO - training batch 251, loss: 0.293, 8032/28000 datapoints
2025-03-07 10:05:59,558 - INFO - training batch 301, loss: 0.605, 9632/28000 datapoints
2025-03-07 10:05:59,791 - INFO - training batch 351, loss: 0.259, 11232/28000 datapoints
2025-03-07 10:06:00,022 - INFO - training batch 401, loss: 0.394, 12832/28000 datapoints
2025-03-07 10:06:01,257 - INFO - training batch 501, loss: 0.150, 16032/28000 datapoints
2025-03-07 10:06:01,491 - INFO - training batch 551, loss: 0.223, 17632/28000 datapoints
2025-03-07 10:06:01,725 - INFO - training batch 601, loss: 0.395, 19232/28000 datapoints
2025-03-07 10:06:01,966 - INFO - training batch 651, loss: 0.050, 20832/28000 datapoints
2025-03-07 10:06:02,189 - INFO - training batch 701, loss: 0.316, 22432/28000 datapoints
2025-03-07 10:06:02,417 - INFO - training batch 751, loss: 0.132, 24032/28000 datapoints
2025-03-07 10:06:02,641 - INFO - training batch 801, loss: 0.163, 25632/28000 datapoints
2025-03-07 10:06:02,867 - INFO - training batch 851, loss: 0.259, 27232/28000 datapoints
2025-03-07 10:06:02,994 - INFO - validation batch 1, loss: 0.170, 32/6976 datapoints
2025-03-07 10:06:03,058 - INFO - validation batch 51, loss: 1.341, 1632/6976 datapoints
2025-03-07 10:06:03,118 - INFO - validation batch 101, loss: 0.389, 3232/6976 datapoints
2025-03-07 10:06:03,179 - INFO - validation batch 151, loss: 0.292, 4832/6976 datapoints
2025-03-07 10:06:03,247 - INFO - validation batch 201, loss: 0.861, 6432/6976 datapoints
2025-03-07 10:06:03,272 - INFO - Epoch 124/800 done.
2025-03-07 10:06:03,273 - INFO - Final validation performance:
Loss: 0.611, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:06:03,273 - INFO - Beginning epoch 125/800
2025-03-07 10:06:03,280 - INFO - training batch 1, loss: 0.210, 32/28000 datapoints
2025-03-07 10:06:03,532 - INFO - training batch 51, loss: 0.129, 1632/28000 datapoints
2025-03-07 10:06:03,785 - INFO - training batch 101, loss: 0.184, 3232/28000 datapoints
2025-03-07 10:06:04,022 - INFO - training batch 151, loss: 0.211, 4832/28000 datapoints
2025-03-07 10:06:04,255 - INFO - training batch 201, loss: 0.143, 6432/28000 datapoints
2025-03-07 10:06:04,488 - INFO - training batch 251, loss: 0.290, 8032/28000 datapoints
2025-03-07 10:06:04,722 - INFO - training batch 301, loss: 0.604, 9632/28000 datapoints
2025-03-07 10:06:04,955 - INFO - training batch 351, loss: 0.257, 11232/28000 datapoints
2025-03-07 10:06:05,208 - INFO - training batch 401, loss: 0.391, 12832/28000 datapoints
2025-03-07 10:06:05,451 - INFO - training batch 451, loss: 0.322, 14432/28000 datapoints
2025-03-07 10:06:05,725 - INFO - training batch 501, loss: 0.148, 16032/28000 datapoints
2025-03-07 10:06:06,172 - INFO - training batch 551, loss: 0.221, 17632/28000 datapoints
2025-03-07 10:06:06,588 - INFO - training batch 601, loss: 0.388, 19232/28000 datapoints
2025-03-07 10:06:06,973 - INFO - training batch 651, loss: 0.049, 20832/28000 datapoints
2025-03-07 10:06:07,337 - INFO - training batch 701, loss: 0.316, 22432/28000 datapoints
2025-03-07 10:06:07,605 - INFO - training batch 751, loss: 0.131, 24032/28000 datapoints
2025-03-07 10:06:07,893 - INFO - training batch 801, loss: 0.161, 25632/28000 datapoints
2025-03-07 10:06:08,205 - INFO - training batch 851, loss: 0.253, 27232/28000 datapoints
2025-03-07 10:06:08,392 - INFO - validation batch 1, loss: 0.170, 32/6976 datapoints
2025-03-07 10:06:08,490 - INFO - validation batch 51, loss: 1.345, 1632/6976 datapoints
2025-03-07 10:06:08,578 - INFO - validation batch 101, loss: 0.395, 3232/6976 datapoints
2025-03-07 10:06:08,669 - INFO - validation batch 151, loss: 0.295, 4832/6976 datapoints
2025-03-07 10:06:08,759 - INFO - validation batch 201, loss: 0.861, 6432/6976 datapoints
2025-03-07 10:06:08,791 - INFO - Epoch 125/800 done.
2025-03-07 10:06:08,791 - INFO - Final validation performance:
Loss: 0.613, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:06:08,792 - INFO - Beginning epoch 126/800
2025-03-07 10:06:08,802 - INFO - training batch 1, loss: 0.208, 32/28000 datapoints
2025-03-07 10:06:09,202 - INFO - training batch 51, loss: 0.127, 1632/28000 datapoints
2025-03-07 10:06:09,531 - INFO - training batch 101, loss: 0.182, 3232/28000 datapoints
2025-03-07 10:06:09,929 - INFO - training batch 151, loss: 0.205, 4832/28000 datapoints
2025-03-07 10:06:10,231 - INFO - training batch 201, loss: 0.140, 6432/28000 datapoints
2025-03-07 10:06:10,645 - INFO - training batch 251, loss: 0.288, 8032/28000 datapoints
2025-03-07 10:06:10,904 - INFO - training batch 301, loss: 0.604, 9632/28000 datapoints
2025-03-07 10:06:11,204 - INFO - training batch 351, loss: 0.257, 11232/28000 datapoints
2025-03-07 10:06:11,492 - INFO - training batch 401, loss: 0.386, 12832/28000 datapoints
2025-03-07 10:06:11,773 - INFO - training batch 451, loss: 0.319, 14432/28000 datapoints
2025-03-07 10:06:12,067 - INFO - training batch 501, loss: 0.147, 16032/28000 datapoints
2025-03-07 10:06:12,348 - INFO - training batch 551, loss: 0.219, 17632/28000 datapoints
2025-03-07 10:06:12,623 - INFO - training batch 601, loss: 0.380, 19232/28000 datapoints
2025-03-07 10:06:12,895 - INFO - training batch 651, loss: 0.048, 20832/28000 datapoints
2025-03-07 10:06:13,180 - INFO - training batch 701, loss: 0.315, 22432/28000 datapoints
2025-03-07 10:06:13,456 - INFO - training batch 751, loss: 0.130, 24032/28000 datapoints
2025-03-07 10:06:13,739 - INFO - training batch 801, loss: 0.158, 25632/28000 datapoints
2025-03-07 10:06:14,042 - INFO - training batch 851, loss: 0.248, 27232/28000 datapoints
2025-03-07 10:06:14,256 - INFO - validation batch 1, loss: 0.170, 32/6976 datapoints
2025-03-07 10:06:14,334 - INFO - validation batch 51, loss: 1.348, 1632/6976 datapoints
2025-03-07 10:06:14,401 - INFO - validation batch 101, loss: 0.398, 3232/6976 datapoints
2025-03-07 10:06:14,466 - INFO - validation batch 151, loss: 0.293, 4832/6976 datapoints
2025-03-07 10:06:14,555 - INFO - validation batch 201, loss: 0.861, 6432/6976 datapoints
2025-03-07 10:06:14,591 - INFO - Epoch 126/800 done.
2025-03-07 10:06:14,591 - INFO - Final validation performance:
Loss: 0.614, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:06:14,592 - INFO - Beginning epoch 127/800
2025-03-07 10:06:14,600 - INFO - training batch 1, loss: 0.207, 32/28000 datapoints
2025-03-07 10:06:14,952 - INFO - training batch 51, loss: 0.124, 1632/28000 datapoints
2025-03-07 10:06:15,345 - INFO - training batch 101, loss: 0.179, 3232/28000 datapoints
2025-03-07 10:06:15,932 - INFO - training batch 151, loss: 0.200, 4832/28000 datapoints
2025-03-07 10:06:16,331 - INFO - training batch 201, loss: 0.139, 6432/28000 datapoints
2025-03-07 10:06:16,598 - INFO - training batch 251, loss: 0.284, 8032/28000 datapoints
2025-03-07 10:06:16,841 - INFO - training batch 301, loss: 0.603, 9632/28000 datapoints
2025-03-07 10:06:17,104 - INFO - training batch 351, loss: 0.255, 11232/28000 datapoints
2025-03-07 10:06:17,390 - INFO - training batch 401, loss: 0.383, 12832/28000 datapoints
2025-03-07 10:06:17,675 - INFO - training batch 451, loss: 0.317, 14432/28000 datapoints
2025-03-07 10:06:17,959 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-07 10:06:18,235 - INFO - training batch 551, loss: 0.216, 17632/28000 datapoints
2025-03-07 10:06:18,478 - INFO - training batch 601, loss: 0.373, 19232/28000 datapoints
2025-03-07 10:06:18,742 - INFO - training batch 651, loss: 0.046, 20832/28000 datapoints
2025-03-07 10:06:19,014 - INFO - training batch 701, loss: 0.314, 22432/28000 datapoints
2025-03-07 10:06:19,295 - INFO - training batch 751, loss: 0.128, 24032/28000 datapoints
2025-03-07 10:06:19,554 - INFO - training batch 801, loss: 0.155, 25632/28000 datapoints
2025-03-07 10:06:19,844 - INFO - training batch 851, loss: 0.243, 27232/28000 datapoints
2025-03-07 10:06:20,097 - INFO - validation batch 1, loss: 0.169, 32/6976 datapoints
2025-03-07 10:06:20,324 - INFO - validation batch 51, loss: 1.350, 1632/6976 datapoints
2025-03-07 10:06:20,573 - INFO - validation batch 101, loss: 0.401, 3232/6976 datapoints
2025-03-07 10:06:20,899 - INFO - validation batch 151, loss: 0.293, 4832/6976 datapoints
2025-03-07 10:06:21,010 - INFO - validation batch 201, loss: 0.860, 6432/6976 datapoints
2025-03-07 10:06:21,036 - INFO - Epoch 127/800 done.
2025-03-07 10:06:21,036 - INFO - Final validation performance:
Loss: 0.615, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:06:21,037 - INFO - Beginning epoch 128/800
2025-03-07 10:06:21,045 - INFO - training batch 1, loss: 0.205, 32/28000 datapoints
2025-03-07 10:06:21,374 - INFO - training batch 51, loss: 0.122, 1632/28000 datapoints
2025-03-07 10:06:21,647 - INFO - training batch 101, loss: 0.176, 3232/28000 datapoints
2025-03-07 10:06:21,918 - INFO - training batch 151, loss: 0.196, 4832/28000 datapoints
2025-03-07 10:06:22,271 - INFO - training batch 201, loss: 0.136, 6432/28000 datapoints
2025-03-07 10:06:22,528 - INFO - training batch 251, loss: 0.282, 8032/28000 datapoints
2025-03-07 10:06:22,766 - INFO - training batch 301, loss: 0.601, 9632/28000 datapoints
2025-03-07 10:06:22,995 - INFO - training batch 351, loss: 0.254, 11232/28000 datapoints
2025-03-07 10:06:23,224 - INFO - training batch 401, loss: 0.379, 12832/28000 datapoints
2025-03-07 10:06:23,455 - INFO - training batch 451, loss: 0.316, 14432/28000 datapoints
2025-03-07 10:06:23,679 - INFO - training batch 501, loss: 0.144, 16032/28000 datapoints
2025-03-07 10:06:23,933 - INFO - training batch 551, loss: 0.214, 17632/28000 datapoints
2025-03-07 10:06:24,168 - INFO - training batch 601, loss: 0.371, 19232/28000 datapoints
2025-03-07 10:06:24,408 - INFO - training batch 651, loss: 0.045, 20832/28000 datapoints
2025-03-07 10:06:24,630 - INFO - training batch 701, loss: 0.313, 22432/28000 datapoints
2025-03-07 10:06:24,850 - INFO - training batch 751, loss: 0.128, 24032/28000 datapoints
2025-03-07 10:06:25,068 - INFO - training batch 801, loss: 0.153, 25632/28000 datapoints
2025-03-07 10:06:25,302 - INFO - training batch 851, loss: 0.237, 27232/28000 datapoints
2025-03-07 10:06:25,413 - INFO - validation batch 1, loss: 0.168, 32/6976 datapoints
2025-03-07 10:06:25,482 - INFO - validation batch 51, loss: 1.351, 1632/6976 datapoints
2025-03-07 10:06:25,543 - INFO - validation batch 101, loss: 0.404, 3232/6976 datapoints
2025-03-07 10:06:25,605 - INFO - validation batch 151, loss: 0.294, 4832/6976 datapoints
2025-03-07 10:06:25,666 - INFO - validation batch 201, loss: 0.860, 6432/6976 datapoints
2025-03-07 10:06:25,687 - INFO - Epoch 128/800 done.
2025-03-07 10:06:25,687 - INFO - Final validation performance:
Loss: 0.615, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:06:25,688 - INFO - Beginning epoch 129/800
2025-03-07 10:06:25,694 - INFO - training batch 1, loss: 0.204, 32/28000 datapoints
2025-03-07 10:06:25,945 - INFO - training batch 51, loss: 0.119, 1632/28000 datapoints
2025-03-07 10:06:26,170 - INFO - training batch 101, loss: 0.173, 3232/28000 datapoints
2025-03-07 10:06:26,416 - INFO - training batch 151, loss: 0.190, 4832/28000 datapoints
2025-03-07 10:06:26,637 - INFO - training batch 201, loss: 0.134, 6432/28000 datapoints
2025-03-07 10:06:26,870 - INFO - training batch 251, loss: 0.279, 8032/28000 datapoints
2025-03-07 10:06:27,089 - INFO - training batch 301, loss: 0.600, 9632/28000 datapoints
2025-03-07 10:06:27,321 - INFO - training batch 351, loss: 0.252, 11232/28000 datapoints
2025-03-07 10:06:27,568 - INFO - training batch 401, loss: 0.376, 12832/28000 datapoints
2025-03-07 10:06:27,812 - INFO - training batch 451, loss: 0.314, 14432/28000 datapoints
2025-03-07 10:06:28,061 - INFO - training batch 501, loss: 0.142, 16032/28000 datapoints
2025-03-07 10:06:28,298 - INFO - training batch 551, loss: 0.212, 17632/28000 datapoints
2025-03-07 10:06:28,551 - INFO - training batch 601, loss: 0.358, 19232/28000 datapoints
2025-03-07 10:06:28,795 - INFO - training batch 651, loss: 0.044, 20832/28000 datapoints
2025-03-07 10:06:29,023 - INFO - training batch 701, loss: 0.311, 22432/28000 datapoints
2025-03-07 10:06:29,259 - INFO - training batch 751, loss: 0.126, 24032/28000 datapoints
2025-03-07 10:06:29,505 - INFO - training batch 801, loss: 0.150, 25632/28000 datapoints
2025-03-07 10:06:29,736 - INFO - training batch 851, loss: 0.232, 27232/28000 datapoints
2025-03-07 10:06:29,880 - INFO - validation batch 1, loss: 0.168, 32/6976 datapoints
2025-03-07 10:06:29,950 - INFO - validation batch 51, loss: 1.353, 1632/6976 datapoints
2025-03-07 10:06:30,018 - INFO - validation batch 101, loss: 0.409, 3232/6976 datapoints
2025-03-07 10:06:30,090 - INFO - validation batch 151, loss: 0.291, 4832/6976 datapoints
2025-03-07 10:06:30,161 - INFO - validation batch 201, loss: 0.862, 6432/6976 datapoints
2025-03-07 10:06:30,182 - INFO - Epoch 129/800 done.
2025-03-07 10:06:30,182 - INFO - Final validation performance:
Loss: 0.617, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:06:30,183 - INFO - Beginning epoch 130/800
2025-03-07 10:06:30,193 - INFO - training batch 1, loss: 0.201, 32/28000 datapoints
2025-03-07 10:06:30,654 - INFO - training batch 51, loss: 0.117, 1632/28000 datapoints
2025-03-07 10:06:30,970 - INFO - training batch 101, loss: 0.170, 3232/28000 datapoints
2025-03-07 10:06:31,259 - INFO - training batch 151, loss: 0.187, 4832/28000 datapoints
2025-03-07 10:06:31,583 - INFO - training batch 201, loss: 0.132, 6432/28000 datapoints
2025-03-07 10:06:31,884 - INFO - training batch 251, loss: 0.278, 8032/28000 datapoints
2025-03-07 10:06:32,186 - INFO - training batch 301, loss: 0.599, 9632/28000 datapoints
2025-03-07 10:06:32,474 - INFO - training batch 351, loss: 0.252, 11232/28000 datapoints
2025-03-07 10:06:32,764 - INFO - training batch 401, loss: 0.373, 12832/28000 datapoints
2025-03-07 10:06:33,032 - INFO - training batch 451, loss: 0.313, 14432/28000 datapoints
2025-03-07 10:06:33,272 - INFO - training batch 501, loss: 0.141, 16032/28000 datapoints
2025-03-07 10:06:33,508 - INFO - training batch 551, loss: 0.210, 17632/28000 datapoints
2025-03-07 10:06:33,750 - INFO - training batch 601, loss: 0.355, 19232/28000 datapoints
2025-03-07 10:06:34,023 - INFO - training batch 651, loss: 0.042, 20832/28000 datapoints
2025-03-07 10:06:34,321 - INFO - training batch 701, loss: 0.310, 22432/28000 datapoints
2025-03-07 10:06:34,562 - INFO - training batch 751, loss: 0.125, 24032/28000 datapoints
2025-03-07 10:06:34,811 - INFO - training batch 801, loss: 0.148, 25632/28000 datapoints
2025-03-07 10:06:35,041 - INFO - training batch 851, loss: 0.228, 27232/28000 datapoints
2025-03-07 10:06:35,167 - INFO - validation batch 1, loss: 0.167, 32/6976 datapoints
2025-03-07 10:06:35,231 - INFO - validation batch 51, loss: 1.355, 1632/6976 datapoints
2025-03-07 10:06:35,294 - INFO - validation batch 101, loss: 0.411, 3232/6976 datapoints
2025-03-07 10:06:35,354 - INFO - validation batch 151, loss: 0.292, 4832/6976 datapoints
2025-03-07 10:06:35,414 - INFO - validation batch 201, loss: 0.863, 6432/6976 datapoints
2025-03-07 10:06:35,435 - INFO - Epoch 130/800 done.
2025-03-07 10:06:35,435 - INFO - Final validation performance:
Loss: 0.618, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:06:35,436 - INFO - Beginning epoch 131/800
2025-03-07 10:06:35,442 - INFO - training batch 1, loss: 0.200, 32/28000 datapoints
2025-03-07 10:06:35,682 - INFO - training batch 51, loss: 0.115, 1632/28000 datapoints
2025-03-07 10:06:35,909 - INFO - training batch 101, loss: 0.166, 3232/28000 datapoints
2025-03-07 10:06:36,177 - INFO - training batch 151, loss: 0.181, 4832/28000 datapoints
2025-03-07 10:06:36,417 - INFO - training batch 201, loss: 0.130, 6432/28000 datapoints
2025-03-07 10:06:36,650 - INFO - training batch 251, loss: 0.275, 8032/28000 datapoints
2025-03-07 10:06:36,883 - INFO - training batch 301, loss: 0.597, 9632/28000 datapoints
2025-03-07 10:06:37,147 - INFO - training batch 351, loss: 0.250, 11232/28000 datapoints
2025-03-07 10:06:37,418 - INFO - training batch 401, loss: 0.368, 12832/28000 datapoints
2025-03-07 10:06:37,680 - INFO - training batch 451, loss: 0.311, 14432/28000 datapoints
2025-03-07 10:06:37,944 - INFO - training batch 501, loss: 0.140, 16032/28000 datapoints
2025-03-07 10:06:38,181 - INFO - training batch 551, loss: 0.207, 17632/28000 datapoints
2025-03-07 10:06:38,403 - INFO - training batch 601, loss: 0.348, 19232/28000 datapoints
2025-03-07 10:06:38,629 - INFO - training batch 651, loss: 0.041, 20832/28000 datapoints
2025-03-07 10:06:38,867 - INFO - training batch 701, loss: 0.309, 22432/28000 datapoints
2025-03-07 10:06:39,102 - INFO - training batch 751, loss: 0.124, 24032/28000 datapoints
2025-03-07 10:06:39,328 - INFO - training batch 801, loss: 0.145, 25632/28000 datapoints
2025-03-07 10:06:39,565 - INFO - training batch 851, loss: 0.223, 27232/28000 datapoints
2025-03-07 10:06:39,673 - INFO - validation batch 1, loss: 0.169, 32/6976 datapoints
2025-03-07 10:06:39,748 - INFO - validation batch 51, loss: 1.359, 1632/6976 datapoints
2025-03-07 10:06:39,810 - INFO - validation batch 101, loss: 0.413, 3232/6976 datapoints
2025-03-07 10:06:39,876 - INFO - validation batch 151, loss: 0.292, 4832/6976 datapoints
2025-03-07 10:06:39,942 - INFO - validation batch 201, loss: 0.864, 6432/6976 datapoints
2025-03-07 10:06:39,962 - INFO - Epoch 131/800 done.
2025-03-07 10:06:39,962 - INFO - Final validation performance:
Loss: 0.619, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:06:39,963 - INFO - Beginning epoch 132/800
2025-03-07 10:06:39,969 - INFO - training batch 1, loss: 0.198, 32/28000 datapoints
2025-03-07 10:06:40,205 - INFO - training batch 51, loss: 0.113, 1632/28000 datapoints
2025-03-07 10:06:40,447 - INFO - training batch 101, loss: 0.165, 3232/28000 datapoints
2025-03-07 10:06:40,671 - INFO - training batch 151, loss: 0.177, 4832/28000 datapoints
2025-03-07 10:06:40,906 - INFO - training batch 201, loss: 0.129, 6432/28000 datapoints
2025-03-07 10:06:41,136 - INFO - training batch 251, loss: 0.272, 8032/28000 datapoints
2025-03-07 10:06:41,375 - INFO - training batch 301, loss: 0.596, 9632/28000 datapoints
2025-03-07 10:06:41,611 - INFO - training batch 351, loss: 0.249, 11232/28000 datapoints
2025-03-07 10:06:41,850 - INFO - training batch 401, loss: 0.365, 12832/28000 datapoints
2025-03-07 10:06:42,141 - INFO - training batch 451, loss: 0.309, 14432/28000 datapoints
2025-03-07 10:06:42,430 - INFO - training batch 501, loss: 0.139, 16032/28000 datapoints
2025-03-07 10:06:42,678 - INFO - training batch 551, loss: 0.205, 17632/28000 datapoints
2025-03-07 10:06:42,920 - INFO - training batch 601, loss: 0.339, 19232/28000 datapoints
2025-03-07 10:06:43,161 - INFO - training batch 651, loss: 0.040, 20832/28000 datapoints
2025-03-07 10:06:43,386 - INFO - training batch 701, loss: 0.308, 22432/28000 datapoints
2025-03-07 10:06:43,606 - INFO - training batch 751, loss: 0.122, 24032/28000 datapoints
2025-03-07 10:06:43,836 - INFO - training batch 801, loss: 0.143, 25632/28000 datapoints
2025-03-07 10:06:44,076 - INFO - training batch 851, loss: 0.219, 27232/28000 datapoints
2025-03-07 10:06:44,183 - INFO - validation batch 1, loss: 0.168, 32/6976 datapoints
2025-03-07 10:06:44,243 - INFO - validation batch 51, loss: 1.361, 1632/6976 datapoints
2025-03-07 10:06:44,304 - INFO - validation batch 101, loss: 0.419, 3232/6976 datapoints
2025-03-07 10:06:44,367 - INFO - validation batch 151, loss: 0.289, 4832/6976 datapoints
2025-03-07 10:06:44,429 - INFO - validation batch 201, loss: 0.869, 6432/6976 datapoints
2025-03-07 10:06:44,451 - INFO - Epoch 132/800 done.
2025-03-07 10:06:44,451 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:06:44,452 - INFO - Beginning epoch 133/800
2025-03-07 10:06:44,458 - INFO - training batch 1, loss: 0.196, 32/28000 datapoints
2025-03-07 10:06:44,684 - INFO - training batch 51, loss: 0.110, 1632/28000 datapoints
2025-03-07 10:06:44,915 - INFO - training batch 101, loss: 0.162, 3232/28000 datapoints
2025-03-07 10:06:45,138 - INFO - training batch 151, loss: 0.174, 4832/28000 datapoints
2025-03-07 10:06:45,388 - INFO - training batch 201, loss: 0.126, 6432/28000 datapoints
2025-03-07 10:06:45,612 - INFO - training batch 251, loss: 0.270, 8032/28000 datapoints
2025-03-07 10:06:45,845 - INFO - training batch 301, loss: 0.593, 9632/28000 datapoints
2025-03-07 10:06:46,082 - INFO - training batch 351, loss: 0.247, 11232/28000 datapoints
2025-03-07 10:06:46,383 - INFO - training batch 401, loss: 0.362, 12832/28000 datapoints
2025-03-07 10:06:46,717 - INFO - training batch 451, loss: 0.308, 14432/28000 datapoints
2025-03-07 10:06:46,950 - INFO - training batch 501, loss: 0.138, 16032/28000 datapoints
2025-03-07 10:06:47,182 - INFO - training batch 551, loss: 0.203, 17632/28000 datapoints
2025-03-07 10:06:47,411 - INFO - training batch 601, loss: 0.334, 19232/28000 datapoints
2025-03-07 10:06:47,639 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-07 10:06:47,875 - INFO - training batch 701, loss: 0.307, 22432/28000 datapoints
2025-03-07 10:06:48,100 - INFO - training batch 751, loss: 0.122, 24032/28000 datapoints
2025-03-07 10:06:48,342 - INFO - training batch 801, loss: 0.141, 25632/28000 datapoints
2025-03-07 10:06:48,580 - INFO - training batch 851, loss: 0.212, 27232/28000 datapoints
2025-03-07 10:06:48,697 - INFO - validation batch 1, loss: 0.168, 32/6976 datapoints
2025-03-07 10:06:48,763 - INFO - validation batch 51, loss: 1.360, 1632/6976 datapoints
2025-03-07 10:06:48,832 - INFO - validation batch 101, loss: 0.422, 3232/6976 datapoints
2025-03-07 10:06:48,899 - INFO - validation batch 151, loss: 0.288, 4832/6976 datapoints
2025-03-07 10:06:48,963 - INFO - validation batch 201, loss: 0.871, 6432/6976 datapoints
2025-03-07 10:06:48,984 - INFO - Epoch 133/800 done.
2025-03-07 10:06:48,984 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:06:48,985 - INFO - Beginning epoch 134/800
2025-03-07 10:06:48,992 - INFO - training batch 1, loss: 0.195, 32/28000 datapoints
2025-03-07 10:06:49,227 - INFO - training batch 51, loss: 0.108, 1632/28000 datapoints
2025-03-07 10:06:49,458 - INFO - training batch 101, loss: 0.158, 3232/28000 datapoints
2025-03-07 10:06:49,683 - INFO - training batch 151, loss: 0.168, 4832/28000 datapoints
2025-03-07 10:06:49,921 - INFO - training batch 201, loss: 0.124, 6432/28000 datapoints
2025-03-07 10:06:50,147 - INFO - training batch 251, loss: 0.268, 8032/28000 datapoints
2025-03-07 10:06:50,373 - INFO - training batch 301, loss: 0.593, 9632/28000 datapoints
2025-03-07 10:06:50,596 - INFO - training batch 351, loss: 0.245, 11232/28000 datapoints
2025-03-07 10:06:50,821 - INFO - training batch 401, loss: 0.358, 12832/28000 datapoints
2025-03-07 10:06:51,045 - INFO - training batch 451, loss: 0.306, 14432/28000 datapoints
2025-03-07 10:06:51,294 - INFO - training batch 501, loss: 0.136, 16032/28000 datapoints
2025-03-07 10:06:51,641 - INFO - training batch 551, loss: 0.201, 17632/28000 datapoints
2025-03-07 10:06:51,896 - INFO - training batch 601, loss: 0.327, 19232/28000 datapoints
2025-03-07 10:06:52,131 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-07 10:06:52,397 - INFO - training batch 701, loss: 0.304, 22432/28000 datapoints
2025-03-07 10:06:52,641 - INFO - training batch 751, loss: 0.123, 24032/28000 datapoints
2025-03-07 10:06:52,895 - INFO - training batch 801, loss: 0.139, 25632/28000 datapoints
2025-03-07 10:06:53,128 - INFO - training batch 851, loss: 0.207, 27232/28000 datapoints
2025-03-07 10:06:53,243 - INFO - validation batch 1, loss: 0.168, 32/6976 datapoints
2025-03-07 10:06:53,311 - INFO - validation batch 51, loss: 1.366, 1632/6976 datapoints
2025-03-07 10:06:53,379 - INFO - validation batch 101, loss: 0.426, 3232/6976 datapoints
2025-03-07 10:06:53,451 - INFO - validation batch 151, loss: 0.290, 4832/6976 datapoints
2025-03-07 10:06:53,521 - INFO - validation batch 201, loss: 0.872, 6432/6976 datapoints
2025-03-07 10:06:53,544 - INFO - Epoch 134/800 done.
2025-03-07 10:06:53,544 - INFO - Final validation performance:
Loss: 0.625, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:06:53,545 - INFO - Beginning epoch 135/800
2025-03-07 10:06:53,552 - INFO - training batch 1, loss: 0.193, 32/28000 datapoints
2025-03-07 10:06:53,805 - INFO - training batch 51, loss: 0.106, 1632/28000 datapoints
2025-03-07 10:06:54,082 - INFO - training batch 101, loss: 0.155, 3232/28000 datapoints
2025-03-07 10:06:54,310 - INFO - training batch 151, loss: 0.165, 4832/28000 datapoints
2025-03-07 10:06:54,549 - INFO - training batch 201, loss: 0.123, 6432/28000 datapoints
2025-03-07 10:06:54,786 - INFO - training batch 251, loss: 0.265, 8032/28000 datapoints
2025-03-07 10:06:55,018 - INFO - training batch 301, loss: 0.590, 9632/28000 datapoints
2025-03-07 10:06:55,248 - INFO - training batch 351, loss: 0.243, 11232/28000 datapoints
2025-03-07 10:06:55,498 - INFO - training batch 401, loss: 0.355, 12832/28000 datapoints
2025-03-07 10:06:55,720 - INFO - training batch 451, loss: 0.305, 14432/28000 datapoints
2025-03-07 10:06:55,957 - INFO - training batch 501, loss: 0.135, 16032/28000 datapoints
2025-03-07 10:06:56,252 - INFO - training batch 551, loss: 0.199, 17632/28000 datapoints
2025-03-07 10:06:56,494 - INFO - training batch 601, loss: 0.325, 19232/28000 datapoints
2025-03-07 10:06:56,728 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-07 10:06:56,953 - INFO - training batch 701, loss: 0.304, 22432/28000 datapoints
2025-03-07 10:06:57,192 - INFO - training batch 751, loss: 0.120, 24032/28000 datapoints
2025-03-07 10:06:57,452 - INFO - training batch 801, loss: 0.137, 25632/28000 datapoints
2025-03-07 10:06:57,684 - INFO - training batch 851, loss: 0.202, 27232/28000 datapoints
2025-03-07 10:06:57,796 - INFO - validation batch 1, loss: 0.169, 32/6976 datapoints
2025-03-07 10:06:57,874 - INFO - validation batch 51, loss: 1.370, 1632/6976 datapoints
2025-03-07 10:06:57,966 - INFO - validation batch 101, loss: 0.427, 3232/6976 datapoints
2025-03-07 10:06:58,056 - INFO - validation batch 151, loss: 0.288, 4832/6976 datapoints
2025-03-07 10:06:58,150 - INFO - validation batch 201, loss: 0.877, 6432/6976 datapoints
2025-03-07 10:06:58,171 - INFO - Epoch 135/800 done.
2025-03-07 10:06:58,172 - INFO - Final validation performance:
Loss: 0.626, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:06:58,172 - INFO - Beginning epoch 136/800
2025-03-07 10:06:58,179 - INFO - training batch 1, loss: 0.192, 32/28000 datapoints
2025-03-07 10:06:58,447 - INFO - training batch 51, loss: 0.104, 1632/28000 datapoints
2025-03-07 10:06:58,713 - INFO - training batch 101, loss: 0.153, 3232/28000 datapoints
2025-03-07 10:06:59,021 - INFO - training batch 151, loss: 0.161, 4832/28000 datapoints
2025-03-07 10:06:59,316 - INFO - training batch 201, loss: 0.121, 6432/28000 datapoints
2025-03-07 10:06:59,597 - INFO - training batch 251, loss: 0.263, 8032/28000 datapoints
2025-03-07 10:06:59,895 - INFO - training batch 301, loss: 0.588, 9632/28000 datapoints
2025-03-07 10:07:00,142 - INFO - training batch 351, loss: 0.242, 11232/28000 datapoints
2025-03-07 10:07:00,390 - INFO - training batch 401, loss: 0.351, 12832/28000 datapoints
2025-03-07 10:07:00,637 - INFO - training batch 451, loss: 0.303, 14432/28000 datapoints
2025-03-07 10:07:00,893 - INFO - training batch 501, loss: 0.133, 16032/28000 datapoints
2025-03-07 10:07:01,197 - INFO - training batch 551, loss: 0.198, 17632/28000 datapoints
2025-03-07 10:07:01,479 - INFO - training batch 601, loss: 0.314, 19232/28000 datapoints
2025-03-07 10:07:01,714 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-07 10:07:01,939 - INFO - training batch 701, loss: 0.303, 22432/28000 datapoints
2025-03-07 10:07:02,261 - INFO - training batch 751, loss: 0.118, 24032/28000 datapoints
2025-03-07 10:07:02,510 - INFO - training batch 801, loss: 0.134, 25632/28000 datapoints
2025-03-07 10:07:02,741 - INFO - training batch 851, loss: 0.199, 27232/28000 datapoints
2025-03-07 10:07:02,853 - INFO - validation batch 1, loss: 0.169, 32/6976 datapoints
2025-03-07 10:07:02,918 - INFO - validation batch 51, loss: 1.375, 1632/6976 datapoints
2025-03-07 10:07:02,987 - INFO - validation batch 101, loss: 0.429, 3232/6976 datapoints
2025-03-07 10:07:03,063 - INFO - validation batch 151, loss: 0.286, 4832/6976 datapoints
2025-03-07 10:07:03,128 - INFO - validation batch 201, loss: 0.878, 6432/6976 datapoints
2025-03-07 10:07:03,154 - INFO - Epoch 136/800 done.
2025-03-07 10:07:03,155 - INFO - Final validation performance:
Loss: 0.627, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:07:03,155 - INFO - Beginning epoch 137/800
2025-03-07 10:07:03,163 - INFO - training batch 1, loss: 0.189, 32/28000 datapoints
2025-03-07 10:07:03,396 - INFO - training batch 51, loss: 0.102, 1632/28000 datapoints
2025-03-07 10:07:03,626 - INFO - training batch 101, loss: 0.150, 3232/28000 datapoints
2025-03-07 10:07:03,860 - INFO - training batch 151, loss: 0.158, 4832/28000 datapoints
2025-03-07 10:07:04,098 - INFO - training batch 201, loss: 0.119, 6432/28000 datapoints
2025-03-07 10:07:04,324 - INFO - training batch 251, loss: 0.261, 8032/28000 datapoints
2025-03-07 10:07:04,550 - INFO - training batch 301, loss: 0.586, 9632/28000 datapoints
2025-03-07 10:07:04,784 - INFO - training batch 351, loss: 0.240, 11232/28000 datapoints
2025-03-07 10:07:05,017 - INFO - training batch 401, loss: 0.347, 12832/28000 datapoints
2025-03-07 10:07:05,252 - INFO - training batch 451, loss: 0.301, 14432/28000 datapoints
2025-03-07 10:07:05,509 - INFO - training batch 501, loss: 0.131, 16032/28000 datapoints
2025-03-07 10:07:05,754 - INFO - training batch 551, loss: 0.197, 17632/28000 datapoints
2025-03-07 10:07:05,998 - INFO - training batch 601, loss: 0.312, 19232/28000 datapoints
2025-03-07 10:07:06,242 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-07 10:07:06,514 - INFO - training batch 701, loss: 0.300, 22432/28000 datapoints
2025-03-07 10:07:06,763 - INFO - training batch 751, loss: 0.118, 24032/28000 datapoints
2025-03-07 10:07:07,006 - INFO - training batch 801, loss: 0.132, 25632/28000 datapoints
2025-03-07 10:07:07,235 - INFO - training batch 851, loss: 0.194, 27232/28000 datapoints
2025-03-07 10:07:07,350 - INFO - validation batch 1, loss: 0.169, 32/6976 datapoints
2025-03-07 10:07:07,417 - INFO - validation batch 51, loss: 1.375, 1632/6976 datapoints
2025-03-07 10:07:07,487 - INFO - validation batch 101, loss: 0.436, 3232/6976 datapoints
2025-03-07 10:07:07,553 - INFO - validation batch 151, loss: 0.285, 4832/6976 datapoints
2025-03-07 10:07:07,620 - INFO - validation batch 201, loss: 0.882, 6432/6976 datapoints
2025-03-07 10:07:07,644 - INFO - Epoch 137/800 done.
2025-03-07 10:07:07,644 - INFO - Final validation performance:
Loss: 0.629, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:07:07,645 - INFO - Beginning epoch 138/800
2025-03-07 10:07:07,652 - INFO - training batch 1, loss: 0.187, 32/28000 datapoints
2025-03-07 10:07:07,877 - INFO - training batch 51, loss: 0.100, 1632/28000 datapoints
2025-03-07 10:07:08,113 - INFO - training batch 101, loss: 0.148, 3232/28000 datapoints
2025-03-07 10:07:08,348 - INFO - training batch 151, loss: 0.154, 4832/28000 datapoints
2025-03-07 10:07:08,569 - INFO - training batch 201, loss: 0.117, 6432/28000 datapoints
2025-03-07 10:07:08,791 - INFO - training batch 251, loss: 0.260, 8032/28000 datapoints
2025-03-07 10:07:09,017 - INFO - training batch 301, loss: 0.582, 9632/28000 datapoints
2025-03-07 10:07:09,256 - INFO - training batch 351, loss: 0.240, 11232/28000 datapoints
2025-03-07 10:07:09,519 - INFO - training batch 401, loss: 0.344, 12832/28000 datapoints
2025-03-07 10:07:09,743 - INFO - training batch 451, loss: 0.300, 14432/28000 datapoints
2025-03-07 10:07:09,970 - INFO - training batch 501, loss: 0.131, 16032/28000 datapoints
2025-03-07 10:07:10,220 - INFO - training batch 551, loss: 0.194, 17632/28000 datapoints
2025-03-07 10:07:10,450 - INFO - training batch 601, loss: 0.303, 19232/28000 datapoints
2025-03-07 10:07:10,684 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-07 10:07:10,918 - INFO - training batch 701, loss: 0.299, 22432/28000 datapoints
2025-03-07 10:07:11,151 - INFO - training batch 751, loss: 0.117, 24032/28000 datapoints
2025-03-07 10:07:11,382 - INFO - training batch 801, loss: 0.130, 25632/28000 datapoints
2025-03-07 10:07:11,609 - INFO - training batch 851, loss: 0.191, 27232/28000 datapoints
2025-03-07 10:07:11,720 - INFO - validation batch 1, loss: 0.168, 32/6976 datapoints
2025-03-07 10:07:11,781 - INFO - validation batch 51, loss: 1.377, 1632/6976 datapoints
2025-03-07 10:07:11,846 - INFO - validation batch 101, loss: 0.439, 3232/6976 datapoints
2025-03-07 10:07:11,909 - INFO - validation batch 151, loss: 0.283, 4832/6976 datapoints
2025-03-07 10:07:11,970 - INFO - validation batch 201, loss: 0.885, 6432/6976 datapoints
2025-03-07 10:07:11,991 - INFO - Epoch 138/800 done.
2025-03-07 10:07:11,991 - INFO - Final validation performance:
Loss: 0.630, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:07:11,992 - INFO - Beginning epoch 139/800
2025-03-07 10:07:11,998 - INFO - training batch 1, loss: 0.186, 32/28000 datapoints
2025-03-07 10:07:12,233 - INFO - training batch 51, loss: 0.098, 1632/28000 datapoints
2025-03-07 10:07:12,463 - INFO - training batch 101, loss: 0.144, 3232/28000 datapoints
2025-03-07 10:07:12,705 - INFO - training batch 151, loss: 0.150, 4832/28000 datapoints
2025-03-07 10:07:12,939 - INFO - training batch 201, loss: 0.116, 6432/28000 datapoints
2025-03-07 10:07:13,361 - INFO - training batch 251, loss: 0.257, 8032/28000 datapoints
2025-03-07 10:07:13,628 - INFO - training batch 301, loss: 0.580, 9632/28000 datapoints
2025-03-07 10:07:13,857 - INFO - training batch 351, loss: 0.238, 11232/28000 datapoints
2025-03-07 10:07:14,107 - INFO - training batch 401, loss: 0.340, 12832/28000 datapoints
2025-03-07 10:07:14,341 - INFO - training batch 451, loss: 0.299, 14432/28000 datapoints
2025-03-07 10:07:14,584 - INFO - training batch 501, loss: 0.129, 16032/28000 datapoints
2025-03-07 10:07:14,820 - INFO - training batch 551, loss: 0.193, 17632/28000 datapoints
2025-03-07 10:07:15,068 - INFO - training batch 601, loss: 0.299, 19232/28000 datapoints
2025-03-07 10:07:15,328 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-07 10:07:15,570 - INFO - training batch 701, loss: 0.298, 22432/28000 datapoints
2025-03-07 10:07:15,826 - INFO - training batch 751, loss: 0.116, 24032/28000 datapoints
2025-03-07 10:07:16,094 - INFO - training batch 801, loss: 0.127, 25632/28000 datapoints
2025-03-07 10:07:16,326 - INFO - training batch 851, loss: 0.187, 27232/28000 datapoints
2025-03-07 10:07:16,449 - INFO - validation batch 1, loss: 0.170, 32/6976 datapoints
2025-03-07 10:07:16,562 - INFO - validation batch 51, loss: 1.381, 1632/6976 datapoints
2025-03-07 10:07:16,654 - INFO - validation batch 101, loss: 0.444, 3232/6976 datapoints
2025-03-07 10:07:16,731 - INFO - validation batch 151, loss: 0.279, 4832/6976 datapoints
2025-03-07 10:07:16,815 - INFO - validation batch 201, loss: 0.888, 6432/6976 datapoints
2025-03-07 10:07:16,835 - INFO - Epoch 139/800 done.
2025-03-07 10:07:16,836 - INFO - Final validation performance:
Loss: 0.632, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:07:16,837 - INFO - Beginning epoch 140/800
2025-03-07 10:07:16,845 - INFO - training batch 1, loss: 0.185, 32/28000 datapoints
2025-03-07 10:07:17,084 - INFO - training batch 51, loss: 0.096, 1632/28000 datapoints
2025-03-07 10:07:17,316 - INFO - training batch 101, loss: 0.142, 3232/28000 datapoints
2025-03-07 10:07:17,548 - INFO - training batch 151, loss: 0.146, 4832/28000 datapoints
2025-03-07 10:07:17,781 - INFO - training batch 201, loss: 0.115, 6432/28000 datapoints
2025-03-07 10:07:18,083 - INFO - training batch 251, loss: 0.256, 8032/28000 datapoints
2025-03-07 10:07:18,420 - INFO - training batch 301, loss: 0.577, 9632/28000 datapoints
2025-03-07 10:07:18,743 - INFO - training batch 351, loss: 0.237, 11232/28000 datapoints
2025-03-07 10:07:19,163 - INFO - training batch 401, loss: 0.337, 12832/28000 datapoints
2025-03-07 10:07:19,469 - INFO - training batch 451, loss: 0.298, 14432/28000 datapoints
2025-03-07 10:07:19,712 - INFO - training batch 501, loss: 0.128, 16032/28000 datapoints
2025-03-07 10:07:19,946 - INFO - training batch 551, loss: 0.191, 17632/28000 datapoints
2025-03-07 10:07:20,178 - INFO - training batch 601, loss: 0.290, 19232/28000 datapoints
2025-03-07 10:07:20,423 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-07 10:07:20,649 - INFO - training batch 701, loss: 0.296, 22432/28000 datapoints
2025-03-07 10:07:20,888 - INFO - training batch 751, loss: 0.116, 24032/28000 datapoints
2025-03-07 10:07:21,125 - INFO - training batch 801, loss: 0.126, 25632/28000 datapoints
2025-03-07 10:07:21,360 - INFO - training batch 851, loss: 0.182, 27232/28000 datapoints
2025-03-07 10:07:21,475 - INFO - validation batch 1, loss: 0.170, 32/6976 datapoints
2025-03-07 10:07:21,536 - INFO - validation batch 51, loss: 1.384, 1632/6976 datapoints
2025-03-07 10:07:21,599 - INFO - validation batch 101, loss: 0.446, 3232/6976 datapoints
2025-03-07 10:07:21,659 - INFO - validation batch 151, loss: 0.280, 4832/6976 datapoints
2025-03-07 10:07:21,723 - INFO - validation batch 201, loss: 0.893, 6432/6976 datapoints
2025-03-07 10:07:21,744 - INFO - Epoch 140/800 done.
2025-03-07 10:07:21,744 - INFO - Final validation performance:
Loss: 0.634, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:07:21,745 - INFO - Beginning epoch 141/800
2025-03-07 10:07:21,752 - INFO - training batch 1, loss: 0.183, 32/28000 datapoints
2025-03-07 10:07:21,979 - INFO - training batch 51, loss: 0.094, 1632/28000 datapoints
2025-03-07 10:07:22,245 - INFO - training batch 101, loss: 0.139, 3232/28000 datapoints
2025-03-07 10:07:22,473 - INFO - training batch 151, loss: 0.143, 4832/28000 datapoints
2025-03-07 10:07:22,695 - INFO - training batch 201, loss: 0.113, 6432/28000 datapoints
2025-03-07 10:07:22,912 - INFO - training batch 251, loss: 0.253, 8032/28000 datapoints
2025-03-07 10:07:23,136 - INFO - training batch 301, loss: 0.573, 9632/28000 datapoints
2025-03-07 10:07:23,359 - INFO - training batch 351, loss: 0.235, 11232/28000 datapoints
2025-03-07 10:07:23,598 - INFO - training batch 401, loss: 0.335, 12832/28000 datapoints
2025-03-07 10:07:23,828 - INFO - training batch 451, loss: 0.296, 14432/28000 datapoints
2025-03-07 10:07:24,062 - INFO - training batch 501, loss: 0.127, 16032/28000 datapoints
2025-03-07 10:07:24,320 - INFO - training batch 551, loss: 0.188, 17632/28000 datapoints
2025-03-07 10:07:24,563 - INFO - training batch 601, loss: 0.282, 19232/28000 datapoints
2025-03-07 10:07:24,786 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-07 10:07:25,019 - INFO - training batch 701, loss: 0.295, 22432/28000 datapoints
2025-03-07 10:07:25,250 - INFO - training batch 751, loss: 0.115, 24032/28000 datapoints
2025-03-07 10:07:25,524 - INFO - training batch 801, loss: 0.123, 25632/28000 datapoints
2025-03-07 10:07:25,752 - INFO - training batch 851, loss: 0.178, 27232/28000 datapoints
2025-03-07 10:07:25,859 - INFO - validation batch 1, loss: 0.170, 32/6976 datapoints
2025-03-07 10:07:25,922 - INFO - validation batch 51, loss: 1.388, 1632/6976 datapoints
2025-03-07 10:07:25,989 - INFO - validation batch 101, loss: 0.452, 3232/6976 datapoints
2025-03-07 10:07:26,048 - INFO - validation batch 151, loss: 0.280, 4832/6976 datapoints
2025-03-07 10:07:26,112 - INFO - validation batch 201, loss: 0.896, 6432/6976 datapoints
2025-03-07 10:07:26,135 - INFO - Epoch 141/800 done.
2025-03-07 10:07:26,135 - INFO - Final validation performance:
Loss: 0.637, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:07:26,136 - INFO - Beginning epoch 142/800
2025-03-07 10:07:26,143 - INFO - training batch 1, loss: 0.181, 32/28000 datapoints
2025-03-07 10:07:26,390 - INFO - training batch 51, loss: 0.092, 1632/28000 datapoints
2025-03-07 10:07:26,723 - INFO - training batch 101, loss: 0.136, 3232/28000 datapoints
2025-03-07 10:07:26,973 - INFO - training batch 151, loss: 0.139, 4832/28000 datapoints
2025-03-07 10:07:27,197 - INFO - training batch 201, loss: 0.112, 6432/28000 datapoints
2025-03-07 10:07:27,452 - INFO - training batch 251, loss: 0.252, 8032/28000 datapoints
2025-03-07 10:07:27,687 - INFO - training batch 301, loss: 0.570, 9632/28000 datapoints
2025-03-07 10:07:27,920 - INFO - training batch 351, loss: 0.234, 11232/28000 datapoints
2025-03-07 10:07:28,151 - INFO - training batch 401, loss: 0.329, 12832/28000 datapoints
2025-03-07 10:07:28,381 - INFO - training batch 451, loss: 0.294, 14432/28000 datapoints
2025-03-07 10:07:28,611 - INFO - training batch 501, loss: 0.126, 16032/28000 datapoints
2025-03-07 10:07:28,840 - INFO - training batch 551, loss: 0.187, 17632/28000 datapoints
2025-03-07 10:07:29,062 - INFO - training batch 601, loss: 0.275, 19232/28000 datapoints
2025-03-07 10:07:29,293 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-07 10:07:29,535 - INFO - training batch 701, loss: 0.293, 22432/28000 datapoints
2025-03-07 10:07:30,023 - INFO - training batch 751, loss: 0.114, 24032/28000 datapoints
2025-03-07 10:07:30,658 - INFO - training batch 801, loss: 0.121, 25632/28000 datapoints
2025-03-07 10:07:31,185 - INFO - training batch 851, loss: 0.174, 27232/28000 datapoints
2025-03-07 10:07:31,315 - INFO - validation batch 1, loss: 0.171, 32/6976 datapoints
2025-03-07 10:07:31,394 - INFO - validation batch 51, loss: 1.392, 1632/6976 datapoints
2025-03-07 10:07:31,469 - INFO - validation batch 101, loss: 0.453, 3232/6976 datapoints
2025-03-07 10:07:31,554 - INFO - validation batch 151, loss: 0.278, 4832/6976 datapoints
2025-03-07 10:07:31,631 - INFO - validation batch 201, loss: 0.899, 6432/6976 datapoints
2025-03-07 10:07:31,660 - INFO - Epoch 142/800 done.
2025-03-07 10:07:31,660 - INFO - Final validation performance:
Loss: 0.639, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:07:31,661 - INFO - Beginning epoch 143/800
2025-03-07 10:07:31,670 - INFO - training batch 1, loss: 0.181, 32/28000 datapoints
2025-03-07 10:07:31,930 - INFO - training batch 51, loss: 0.090, 1632/28000 datapoints
2025-03-07 10:07:32,172 - INFO - training batch 101, loss: 0.134, 3232/28000 datapoints
2025-03-07 10:07:32,425 - INFO - training batch 151, loss: 0.135, 4832/28000 datapoints
2025-03-07 10:07:32,803 - INFO - training batch 201, loss: 0.110, 6432/28000 datapoints
2025-03-07 10:07:33,045 - INFO - training batch 251, loss: 0.250, 8032/28000 datapoints
2025-03-07 10:07:33,279 - INFO - training batch 301, loss: 0.567, 9632/28000 datapoints
2025-03-07 10:07:33,677 - INFO - training batch 351, loss: 0.233, 11232/28000 datapoints
2025-03-07 10:07:33,933 - INFO - training batch 401, loss: 0.324, 12832/28000 datapoints
2025-03-07 10:07:34,296 - INFO - training batch 451, loss: 0.293, 14432/28000 datapoints
2025-03-07 10:07:34,626 - INFO - training batch 501, loss: 0.125, 16032/28000 datapoints
2025-03-07 10:07:35,078 - INFO - training batch 551, loss: 0.185, 17632/28000 datapoints
2025-03-07 10:07:35,502 - INFO - training batch 601, loss: 0.270, 19232/28000 datapoints
2025-03-07 10:07:35,815 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-07 10:07:36,093 - INFO - training batch 701, loss: 0.292, 22432/28000 datapoints
2025-03-07 10:07:36,488 - INFO - training batch 751, loss: 0.114, 24032/28000 datapoints
2025-03-07 10:07:36,880 - INFO - training batch 801, loss: 0.119, 25632/28000 datapoints
2025-03-07 10:07:37,262 - INFO - training batch 851, loss: 0.170, 27232/28000 datapoints
2025-03-07 10:07:37,401 - INFO - validation batch 1, loss: 0.171, 32/6976 datapoints
2025-03-07 10:07:37,482 - INFO - validation batch 51, loss: 1.395, 1632/6976 datapoints
2025-03-07 10:07:37,559 - INFO - validation batch 101, loss: 0.459, 3232/6976 datapoints
2025-03-07 10:07:37,639 - INFO - validation batch 151, loss: 0.275, 4832/6976 datapoints
2025-03-07 10:07:37,714 - INFO - validation batch 201, loss: 0.903, 6432/6976 datapoints
2025-03-07 10:07:37,741 - INFO - Epoch 143/800 done.
2025-03-07 10:07:37,741 - INFO - Final validation performance:
Loss: 0.640, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:07:37,742 - INFO - Beginning epoch 144/800
2025-03-07 10:07:37,750 - INFO - training batch 1, loss: 0.178, 32/28000 datapoints
2025-03-07 10:07:38,106 - INFO - training batch 51, loss: 0.089, 1632/28000 datapoints
2025-03-07 10:07:38,397 - INFO - training batch 101, loss: 0.131, 3232/28000 datapoints
2025-03-07 10:07:38,720 - INFO - training batch 151, loss: 0.133, 4832/28000 datapoints
2025-03-07 10:07:39,045 - INFO - training batch 201, loss: 0.109, 6432/28000 datapoints
2025-03-07 10:07:39,364 - INFO - training batch 251, loss: 0.248, 8032/28000 datapoints
2025-03-07 10:07:39,678 - INFO - training batch 301, loss: 0.562, 9632/28000 datapoints
2025-03-07 10:07:39,961 - INFO - training batch 351, loss: 0.232, 11232/28000 datapoints
2025-03-07 10:07:40,354 - INFO - training batch 401, loss: 0.322, 12832/28000 datapoints
2025-03-07 10:07:40,657 - INFO - training batch 451, loss: 0.288, 14432/28000 datapoints
2025-03-07 10:07:40,911 - INFO - training batch 501, loss: 0.124, 16032/28000 datapoints
2025-03-07 10:07:41,165 - INFO - training batch 551, loss: 0.183, 17632/28000 datapoints
2025-03-07 10:07:41,495 - INFO - training batch 601, loss: 0.258, 19232/28000 datapoints
2025-03-07 10:07:41,736 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-07 10:07:41,967 - INFO - training batch 701, loss: 0.291, 22432/28000 datapoints
2025-03-07 10:07:42,215 - INFO - training batch 751, loss: 0.113, 24032/28000 datapoints
2025-03-07 10:07:42,457 - INFO - training batch 801, loss: 0.117, 25632/28000 datapoints
2025-03-07 10:07:42,715 - INFO - training batch 851, loss: 0.167, 27232/28000 datapoints
2025-03-07 10:07:42,836 - INFO - validation batch 1, loss: 0.172, 32/6976 datapoints
2025-03-07 10:07:42,897 - INFO - validation batch 51, loss: 1.397, 1632/6976 datapoints
2025-03-07 10:07:42,958 - INFO - validation batch 101, loss: 0.461, 3232/6976 datapoints
2025-03-07 10:07:43,029 - INFO - validation batch 151, loss: 0.274, 4832/6976 datapoints
2025-03-07 10:07:43,099 - INFO - validation batch 201, loss: 0.905, 6432/6976 datapoints
2025-03-07 10:07:43,127 - INFO - Epoch 144/800 done.
2025-03-07 10:07:43,127 - INFO - Final validation performance:
Loss: 0.642, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:07:43,128 - INFO - Beginning epoch 145/800
2025-03-07 10:07:43,136 - INFO - training batch 1, loss: 0.177, 32/28000 datapoints
2025-03-07 10:07:43,398 - INFO - training batch 51, loss: 0.085, 1632/28000 datapoints
2025-03-07 10:07:43,677 - INFO - training batch 101, loss: 0.129, 3232/28000 datapoints
2025-03-07 10:07:43,953 - INFO - training batch 151, loss: 0.129, 4832/28000 datapoints
2025-03-07 10:07:44,173 - INFO - training batch 201, loss: 0.107, 6432/28000 datapoints
2025-03-07 10:07:44,397 - INFO - training batch 251, loss: 0.246, 8032/28000 datapoints
2025-03-07 10:07:44,661 - INFO - training batch 301, loss: 0.559, 9632/28000 datapoints
2025-03-07 10:07:44,951 - INFO - training batch 351, loss: 0.231, 11232/28000 datapoints
2025-03-07 10:07:45,207 - INFO - training batch 401, loss: 0.318, 12832/28000 datapoints
2025-03-07 10:07:45,462 - INFO - training batch 451, loss: 0.288, 14432/28000 datapoints
2025-03-07 10:07:45,696 - INFO - training batch 501, loss: 0.124, 16032/28000 datapoints
2025-03-07 10:07:45,921 - INFO - training batch 551, loss: 0.181, 17632/28000 datapoints
2025-03-07 10:07:46,142 - INFO - training batch 601, loss: 0.251, 19232/28000 datapoints
2025-03-07 10:07:46,372 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-07 10:07:46,597 - INFO - training batch 701, loss: 0.288, 22432/28000 datapoints
2025-03-07 10:07:46,823 - INFO - training batch 751, loss: 0.112, 24032/28000 datapoints
2025-03-07 10:07:47,063 - INFO - training batch 801, loss: 0.114, 25632/28000 datapoints
2025-03-07 10:07:47,289 - INFO - training batch 851, loss: 0.164, 27232/28000 datapoints
2025-03-07 10:07:47,417 - INFO - validation batch 1, loss: 0.173, 32/6976 datapoints
2025-03-07 10:07:47,502 - INFO - validation batch 51, loss: 1.403, 1632/6976 datapoints
2025-03-07 10:07:47,591 - INFO - validation batch 101, loss: 0.464, 3232/6976 datapoints
2025-03-07 10:07:47,667 - INFO - validation batch 151, loss: 0.276, 4832/6976 datapoints
2025-03-07 10:07:47,734 - INFO - validation batch 201, loss: 0.907, 6432/6976 datapoints
2025-03-07 10:07:47,755 - INFO - Epoch 145/800 done.
2025-03-07 10:07:47,756 - INFO - Final validation performance:
Loss: 0.645, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:07:47,757 - INFO - Beginning epoch 146/800
2025-03-07 10:07:47,764 - INFO - training batch 1, loss: 0.175, 32/28000 datapoints
2025-03-07 10:07:48,017 - INFO - training batch 51, loss: 0.084, 1632/28000 datapoints
2025-03-07 10:07:48,305 - INFO - training batch 101, loss: 0.127, 3232/28000 datapoints
2025-03-07 10:07:48,585 - INFO - training batch 151, loss: 0.126, 4832/28000 datapoints
2025-03-07 10:07:48,855 - INFO - training batch 201, loss: 0.106, 6432/28000 datapoints
2025-03-07 10:07:49,259 - INFO - training batch 251, loss: 0.245, 8032/28000 datapoints
2025-03-07 10:07:49,570 - INFO - training batch 301, loss: 0.556, 9632/28000 datapoints
2025-03-07 10:07:49,849 - INFO - training batch 351, loss: 0.230, 11232/28000 datapoints
2025-03-07 10:07:50,138 - INFO - training batch 401, loss: 0.314, 12832/28000 datapoints
2025-03-07 10:07:50,495 - INFO - training batch 451, loss: 0.286, 14432/28000 datapoints
2025-03-07 10:07:50,926 - INFO - training batch 501, loss: 0.122, 16032/28000 datapoints
2025-03-07 10:07:51,355 - INFO - training batch 551, loss: 0.179, 17632/28000 datapoints
2025-03-07 10:07:51,960 - INFO - training batch 601, loss: 0.244, 19232/28000 datapoints
2025-03-07 10:07:52,285 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-07 10:07:52,578 - INFO - training batch 701, loss: 0.286, 22432/28000 datapoints
2025-03-07 10:07:52,821 - INFO - training batch 751, loss: 0.112, 24032/28000 datapoints
2025-03-07 10:07:53,071 - INFO - training batch 801, loss: 0.113, 25632/28000 datapoints
2025-03-07 10:07:53,342 - INFO - training batch 851, loss: 0.161, 27232/28000 datapoints
2025-03-07 10:07:53,468 - INFO - validation batch 1, loss: 0.174, 32/6976 datapoints
2025-03-07 10:07:53,535 - INFO - validation batch 51, loss: 1.406, 1632/6976 datapoints
2025-03-07 10:07:53,604 - INFO - validation batch 101, loss: 0.467, 3232/6976 datapoints
2025-03-07 10:07:53,676 - INFO - validation batch 151, loss: 0.272, 4832/6976 datapoints
2025-03-07 10:07:53,756 - INFO - validation batch 201, loss: 0.911, 6432/6976 datapoints
2025-03-07 10:07:53,777 - INFO - Epoch 146/800 done.
2025-03-07 10:07:53,777 - INFO - Final validation performance:
Loss: 0.646, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:07:53,778 - INFO - Beginning epoch 147/800
2025-03-07 10:07:53,785 - INFO - training batch 1, loss: 0.173, 32/28000 datapoints
2025-03-07 10:07:54,058 - INFO - training batch 51, loss: 0.083, 1632/28000 datapoints
2025-03-07 10:07:54,313 - INFO - training batch 101, loss: 0.124, 3232/28000 datapoints
2025-03-07 10:07:54,595 - INFO - training batch 151, loss: 0.122, 4832/28000 datapoints
2025-03-07 10:07:54,855 - INFO - training batch 201, loss: 0.104, 6432/28000 datapoints
2025-03-07 10:07:55,111 - INFO - training batch 251, loss: 0.243, 8032/28000 datapoints
2025-03-07 10:07:55,387 - INFO - training batch 301, loss: 0.551, 9632/28000 datapoints
2025-03-07 10:07:55,644 - INFO - training batch 351, loss: 0.229, 11232/28000 datapoints
2025-03-07 10:07:55,878 - INFO - training batch 401, loss: 0.309, 12832/28000 datapoints
2025-03-07 10:07:56,127 - INFO - training batch 451, loss: 0.285, 14432/28000 datapoints
2025-03-07 10:07:56,391 - INFO - training batch 501, loss: 0.121, 16032/28000 datapoints
2025-03-07 10:07:56,635 - INFO - training batch 551, loss: 0.177, 17632/28000 datapoints
2025-03-07 10:07:56,876 - INFO - training batch 601, loss: 0.240, 19232/28000 datapoints
2025-03-07 10:07:57,140 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-07 10:07:57,395 - INFO - training batch 701, loss: 0.284, 22432/28000 datapoints
2025-03-07 10:07:57,652 - INFO - training batch 751, loss: 0.111, 24032/28000 datapoints
2025-03-07 10:07:57,880 - INFO - training batch 801, loss: 0.111, 25632/28000 datapoints
2025-03-07 10:07:58,114 - INFO - training batch 851, loss: 0.158, 27232/28000 datapoints
2025-03-07 10:07:58,234 - INFO - validation batch 1, loss: 0.176, 32/6976 datapoints
2025-03-07 10:07:58,312 - INFO - validation batch 51, loss: 1.410, 1632/6976 datapoints
2025-03-07 10:07:58,381 - INFO - validation batch 101, loss: 0.467, 3232/6976 datapoints
2025-03-07 10:07:58,447 - INFO - validation batch 151, loss: 0.272, 4832/6976 datapoints
2025-03-07 10:07:58,519 - INFO - validation batch 201, loss: 0.913, 6432/6976 datapoints
2025-03-07 10:07:58,544 - INFO - Epoch 147/800 done.
2025-03-07 10:07:58,545 - INFO - Final validation performance:
Loss: 0.648, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:07:58,546 - INFO - Beginning epoch 148/800
2025-03-07 10:07:58,553 - INFO - training batch 1, loss: 0.173, 32/28000 datapoints
2025-03-07 10:07:58,796 - INFO - training batch 51, loss: 0.081, 1632/28000 datapoints
2025-03-07 10:07:59,041 - INFO - training batch 101, loss: 0.120, 3232/28000 datapoints
2025-03-07 10:07:59,291 - INFO - training batch 151, loss: 0.120, 4832/28000 datapoints
2025-03-07 10:07:59,541 - INFO - training batch 201, loss: 0.103, 6432/28000 datapoints
2025-03-07 10:07:59,783 - INFO - training batch 251, loss: 0.241, 8032/28000 datapoints
2025-03-07 10:08:00,038 - INFO - training batch 301, loss: 0.548, 9632/28000 datapoints
2025-03-07 10:08:00,290 - INFO - training batch 351, loss: 0.228, 11232/28000 datapoints
2025-03-07 10:08:00,549 - INFO - training batch 401, loss: 0.306, 12832/28000 datapoints
2025-03-07 10:08:00,815 - INFO - training batch 451, loss: 0.281, 14432/28000 datapoints
2025-03-07 10:08:01,078 - INFO - training batch 501, loss: 0.120, 16032/28000 datapoints
2025-03-07 10:08:01,326 - INFO - training batch 551, loss: 0.175, 17632/28000 datapoints
2025-03-07 10:08:01,606 - INFO - training batch 601, loss: 0.232, 19232/28000 datapoints
2025-03-07 10:08:01,863 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-07 10:08:02,107 - INFO - training batch 701, loss: 0.283, 22432/28000 datapoints
2025-03-07 10:08:02,334 - INFO - training batch 751, loss: 0.111, 24032/28000 datapoints
2025-03-07 10:08:02,576 - INFO - training batch 801, loss: 0.109, 25632/28000 datapoints
2025-03-07 10:08:02,803 - INFO - training batch 851, loss: 0.153, 27232/28000 datapoints
2025-03-07 10:08:02,917 - INFO - validation batch 1, loss: 0.176, 32/6976 datapoints
2025-03-07 10:08:02,985 - INFO - validation batch 51, loss: 1.413, 1632/6976 datapoints
2025-03-07 10:08:03,062 - INFO - validation batch 101, loss: 0.474, 3232/6976 datapoints
2025-03-07 10:08:03,134 - INFO - validation batch 151, loss: 0.272, 4832/6976 datapoints
2025-03-07 10:08:03,199 - INFO - validation batch 201, loss: 0.919, 6432/6976 datapoints
2025-03-07 10:08:03,224 - INFO - Epoch 148/800 done.
2025-03-07 10:08:03,225 - INFO - Final validation performance:
Loss: 0.651, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:08:03,225 - INFO - Beginning epoch 149/800
2025-03-07 10:08:03,232 - INFO - training batch 1, loss: 0.170, 32/28000 datapoints
2025-03-07 10:08:03,479 - INFO - training batch 51, loss: 0.079, 1632/28000 datapoints
2025-03-07 10:08:03,711 - INFO - training batch 101, loss: 0.118, 3232/28000 datapoints
2025-03-07 10:08:03,945 - INFO - training batch 151, loss: 0.117, 4832/28000 datapoints
2025-03-07 10:08:04,182 - INFO - training batch 201, loss: 0.102, 6432/28000 datapoints
2025-03-07 10:08:04,420 - INFO - training batch 251, loss: 0.240, 8032/28000 datapoints
2025-03-07 10:08:04,662 - INFO - training batch 301, loss: 0.543, 9632/28000 datapoints
2025-03-07 10:08:04,894 - INFO - training batch 351, loss: 0.228, 11232/28000 datapoints
2025-03-07 10:08:05,143 - INFO - training batch 401, loss: 0.304, 12832/28000 datapoints
2025-03-07 10:08:05,395 - INFO - training batch 451, loss: 0.281, 14432/28000 datapoints
2025-03-07 10:08:05,671 - INFO - training batch 501, loss: 0.119, 16032/28000 datapoints
2025-03-07 10:08:05,987 - INFO - training batch 551, loss: 0.174, 17632/28000 datapoints
2025-03-07 10:08:06,290 - INFO - training batch 601, loss: 0.222, 19232/28000 datapoints
2025-03-07 10:08:06,549 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-07 10:08:06,894 - INFO - training batch 701, loss: 0.279, 22432/28000 datapoints
2025-03-07 10:08:07,243 - INFO - training batch 751, loss: 0.110, 24032/28000 datapoints
2025-03-07 10:08:07,828 - INFO - training batch 801, loss: 0.107, 25632/28000 datapoints
2025-03-07 10:08:08,078 - INFO - training batch 851, loss: 0.150, 27232/28000 datapoints
2025-03-07 10:08:08,213 - INFO - validation batch 1, loss: 0.177, 32/6976 datapoints
2025-03-07 10:08:08,289 - INFO - validation batch 51, loss: 1.421, 1632/6976 datapoints
2025-03-07 10:08:08,371 - INFO - validation batch 101, loss: 0.473, 3232/6976 datapoints
2025-03-07 10:08:08,449 - INFO - validation batch 151, loss: 0.271, 4832/6976 datapoints
2025-03-07 10:08:08,516 - INFO - validation batch 201, loss: 0.923, 6432/6976 datapoints
2025-03-07 10:08:08,538 - INFO - Epoch 149/800 done.
2025-03-07 10:08:08,539 - INFO - Final validation performance:
Loss: 0.653, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:08:08,539 - INFO - Beginning epoch 150/800
2025-03-07 10:08:08,547 - INFO - training batch 1, loss: 0.169, 32/28000 datapoints
2025-03-07 10:08:08,783 - INFO - training batch 51, loss: 0.077, 1632/28000 datapoints
2025-03-07 10:08:09,017 - INFO - training batch 101, loss: 0.117, 3232/28000 datapoints
2025-03-07 10:08:09,285 - INFO - training batch 151, loss: 0.114, 4832/28000 datapoints
2025-03-07 10:08:09,544 - INFO - training batch 201, loss: 0.100, 6432/28000 datapoints
2025-03-07 10:08:09,779 - INFO - training batch 251, loss: 0.238, 8032/28000 datapoints
2025-03-07 10:08:10,023 - INFO - training batch 301, loss: 0.542, 9632/28000 datapoints
2025-03-07 10:08:10,273 - INFO - training batch 351, loss: 0.227, 11232/28000 datapoints
2025-03-07 10:08:10,542 - INFO - training batch 401, loss: 0.298, 12832/28000 datapoints
2025-03-07 10:08:10,805 - INFO - training batch 451, loss: 0.280, 14432/28000 datapoints
2025-03-07 10:08:11,081 - INFO - training batch 501, loss: 0.118, 16032/28000 datapoints
2025-03-07 10:08:11,333 - INFO - training batch 551, loss: 0.172, 17632/28000 datapoints
2025-03-07 10:08:11,626 - INFO - training batch 601, loss: 0.218, 19232/28000 datapoints
2025-03-07 10:08:11,873 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-07 10:08:12,149 - INFO - training batch 701, loss: 0.278, 22432/28000 datapoints
2025-03-07 10:08:12,585 - INFO - training batch 751, loss: 0.110, 24032/28000 datapoints
2025-03-07 10:08:12,889 - INFO - training batch 801, loss: 0.105, 25632/28000 datapoints
2025-03-07 10:08:13,189 - INFO - training batch 851, loss: 0.147, 27232/28000 datapoints
2025-03-07 10:08:13,321 - INFO - validation batch 1, loss: 0.178, 32/6976 datapoints
2025-03-07 10:08:13,389 - INFO - validation batch 51, loss: 1.424, 1632/6976 datapoints
2025-03-07 10:08:13,490 - INFO - validation batch 101, loss: 0.476, 3232/6976 datapoints
2025-03-07 10:08:13,567 - INFO - validation batch 151, loss: 0.269, 4832/6976 datapoints
2025-03-07 10:08:13,643 - INFO - validation batch 201, loss: 0.926, 6432/6976 datapoints
2025-03-07 10:08:13,672 - INFO - Epoch 150/800 done.
2025-03-07 10:08:13,673 - INFO - Final validation performance:
Loss: 0.655, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:08:13,673 - INFO - Beginning epoch 151/800
2025-03-07 10:08:13,681 - INFO - training batch 1, loss: 0.167, 32/28000 datapoints
2025-03-07 10:08:13,952 - INFO - training batch 51, loss: 0.077, 1632/28000 datapoints
2025-03-07 10:08:14,236 - INFO - training batch 101, loss: 0.114, 3232/28000 datapoints
2025-03-07 10:08:14,503 - INFO - training batch 151, loss: 0.111, 4832/28000 datapoints
2025-03-07 10:08:14,747 - INFO - training batch 201, loss: 0.098, 6432/28000 datapoints
2025-03-07 10:08:15,016 - INFO - training batch 251, loss: 0.236, 8032/28000 datapoints
2025-03-07 10:08:15,263 - INFO - training batch 301, loss: 0.538, 9632/28000 datapoints
2025-03-07 10:08:15,551 - INFO - training batch 351, loss: 0.225, 11232/28000 datapoints
2025-03-07 10:08:15,788 - INFO - training batch 401, loss: 0.295, 12832/28000 datapoints
2025-03-07 10:08:16,033 - INFO - training batch 451, loss: 0.277, 14432/28000 datapoints
2025-03-07 10:08:16,277 - INFO - training batch 501, loss: 0.116, 16032/28000 datapoints
2025-03-07 10:08:16,523 - INFO - training batch 551, loss: 0.169, 17632/28000 datapoints
2025-03-07 10:08:16,761 - INFO - training batch 601, loss: 0.209, 19232/28000 datapoints
2025-03-07 10:08:16,995 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-07 10:08:17,267 - INFO - training batch 701, loss: 0.276, 22432/28000 datapoints
2025-03-07 10:08:17,524 - INFO - training batch 751, loss: 0.109, 24032/28000 datapoints
2025-03-07 10:08:17,765 - INFO - training batch 801, loss: 0.104, 25632/28000 datapoints
2025-03-07 10:08:17,989 - INFO - training batch 851, loss: 0.144, 27232/28000 datapoints
2025-03-07 10:08:18,106 - INFO - validation batch 1, loss: 0.180, 32/6976 datapoints
2025-03-07 10:08:18,182 - INFO - validation batch 51, loss: 1.425, 1632/6976 datapoints
2025-03-07 10:08:18,257 - INFO - validation batch 101, loss: 0.482, 3232/6976 datapoints
2025-03-07 10:08:18,334 - INFO - validation batch 151, loss: 0.266, 4832/6976 datapoints
2025-03-07 10:08:18,408 - INFO - validation batch 201, loss: 0.931, 6432/6976 datapoints
2025-03-07 10:08:18,430 - INFO - Epoch 151/800 done.
2025-03-07 10:08:18,430 - INFO - Final validation performance:
Loss: 0.657, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:08:18,431 - INFO - Beginning epoch 152/800
2025-03-07 10:08:18,438 - INFO - training batch 1, loss: 0.165, 32/28000 datapoints
2025-03-07 10:08:18,706 - INFO - training batch 51, loss: 0.076, 1632/28000 datapoints
2025-03-07 10:08:18,960 - INFO - training batch 101, loss: 0.111, 3232/28000 datapoints
2025-03-07 10:08:19,303 - INFO - training batch 151, loss: 0.108, 4832/28000 datapoints
2025-03-07 10:08:19,700 - INFO - training batch 201, loss: 0.097, 6432/28000 datapoints
2025-03-07 10:08:19,951 - INFO - training batch 251, loss: 0.235, 8032/28000 datapoints
2025-03-07 10:08:20,243 - INFO - training batch 301, loss: 0.533, 9632/28000 datapoints
2025-03-07 10:08:20,531 - INFO - training batch 351, loss: 0.224, 11232/28000 datapoints
2025-03-07 10:08:20,839 - INFO - training batch 401, loss: 0.291, 12832/28000 datapoints
2025-03-07 10:08:21,113 - INFO - training batch 451, loss: 0.275, 14432/28000 datapoints
2025-03-07 10:08:21,354 - INFO - training batch 501, loss: 0.115, 16032/28000 datapoints
2025-03-07 10:08:21,618 - INFO - training batch 551, loss: 0.169, 17632/28000 datapoints
2025-03-07 10:08:21,865 - INFO - training batch 601, loss: 0.205, 19232/28000 datapoints
2025-03-07 10:08:22,129 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-07 10:08:22,413 - INFO - training batch 701, loss: 0.273, 22432/28000 datapoints
2025-03-07 10:08:22,678 - INFO - training batch 751, loss: 0.109, 24032/28000 datapoints
2025-03-07 10:08:22,923 - INFO - training batch 801, loss: 0.102, 25632/28000 datapoints
2025-03-07 10:08:23,172 - INFO - training batch 851, loss: 0.141, 27232/28000 datapoints
2025-03-07 10:08:23,292 - INFO - validation batch 1, loss: 0.182, 32/6976 datapoints
2025-03-07 10:08:23,365 - INFO - validation batch 51, loss: 1.428, 1632/6976 datapoints
2025-03-07 10:08:23,435 - INFO - validation batch 101, loss: 0.484, 3232/6976 datapoints
2025-03-07 10:08:23,505 - INFO - validation batch 151, loss: 0.266, 4832/6976 datapoints
2025-03-07 10:08:23,573 - INFO - validation batch 201, loss: 0.933, 6432/6976 datapoints
2025-03-07 10:08:23,596 - INFO - Epoch 152/800 done.
2025-03-07 10:08:23,596 - INFO - Final validation performance:
Loss: 0.659, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:08:23,597 - INFO - Beginning epoch 153/800
2025-03-07 10:08:23,605 - INFO - training batch 1, loss: 0.164, 32/28000 datapoints
2025-03-07 10:08:23,866 - INFO - training batch 51, loss: 0.074, 1632/28000 datapoints
2025-03-07 10:08:24,106 - INFO - training batch 101, loss: 0.109, 3232/28000 datapoints
2025-03-07 10:08:24,362 - INFO - training batch 151, loss: 0.103, 4832/28000 datapoints
2025-03-07 10:08:24,604 - INFO - training batch 201, loss: 0.096, 6432/28000 datapoints
2025-03-07 10:08:24,846 - INFO - training batch 251, loss: 0.233, 8032/28000 datapoints
2025-03-07 10:08:25,084 - INFO - training batch 301, loss: 0.528, 9632/28000 datapoints
2025-03-07 10:08:25,339 - INFO - training batch 351, loss: 0.223, 11232/28000 datapoints
2025-03-07 10:08:25,584 - INFO - training batch 401, loss: 0.287, 12832/28000 datapoints
2025-03-07 10:08:25,891 - INFO - training batch 451, loss: 0.272, 14432/28000 datapoints
2025-03-07 10:08:26,175 - INFO - training batch 501, loss: 0.114, 16032/28000 datapoints
2025-03-07 10:08:26,428 - INFO - training batch 551, loss: 0.166, 17632/28000 datapoints
2025-03-07 10:08:26,658 - INFO - training batch 601, loss: 0.192, 19232/28000 datapoints
2025-03-07 10:08:26,887 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-07 10:08:27,140 - INFO - training batch 701, loss: 0.272, 22432/28000 datapoints
2025-03-07 10:08:27,413 - INFO - training batch 751, loss: 0.109, 24032/28000 datapoints
2025-03-07 10:08:27,655 - INFO - training batch 801, loss: 0.100, 25632/28000 datapoints
2025-03-07 10:08:27,894 - INFO - training batch 851, loss: 0.138, 27232/28000 datapoints
2025-03-07 10:08:28,019 - INFO - validation batch 1, loss: 0.182, 32/6976 datapoints
2025-03-07 10:08:28,117 - INFO - validation batch 51, loss: 1.432, 1632/6976 datapoints
2025-03-07 10:08:28,193 - INFO - validation batch 101, loss: 0.489, 3232/6976 datapoints
2025-03-07 10:08:28,259 - INFO - validation batch 151, loss: 0.264, 4832/6976 datapoints
2025-03-07 10:08:28,325 - INFO - validation batch 201, loss: 0.939, 6432/6976 datapoints
2025-03-07 10:08:28,347 - INFO - Epoch 153/800 done.
2025-03-07 10:08:28,347 - INFO - Final validation performance:
Loss: 0.661, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:08:28,348 - INFO - Beginning epoch 154/800
2025-03-07 10:08:28,354 - INFO - training batch 1, loss: 0.163, 32/28000 datapoints
2025-03-07 10:08:28,595 - INFO - training batch 51, loss: 0.073, 1632/28000 datapoints
2025-03-07 10:08:28,839 - INFO - training batch 101, loss: 0.107, 3232/28000 datapoints
2025-03-07 10:08:29,068 - INFO - training batch 151, loss: 0.100, 4832/28000 datapoints
2025-03-07 10:08:29,295 - INFO - training batch 201, loss: 0.094, 6432/28000 datapoints
2025-03-07 10:08:29,519 - INFO - training batch 251, loss: 0.232, 8032/28000 datapoints
2025-03-07 10:08:29,747 - INFO - training batch 301, loss: 0.522, 9632/28000 datapoints
2025-03-07 10:08:29,991 - INFO - training batch 351, loss: 0.222, 11232/28000 datapoints
2025-03-07 10:08:30,376 - INFO - training batch 401, loss: 0.283, 12832/28000 datapoints
2025-03-07 10:08:30,651 - INFO - training batch 451, loss: 0.270, 14432/28000 datapoints
2025-03-07 10:08:30,900 - INFO - training batch 501, loss: 0.113, 16032/28000 datapoints
2025-03-07 10:08:31,136 - INFO - training batch 551, loss: 0.165, 17632/28000 datapoints
2025-03-07 10:08:31,436 - INFO - training batch 601, loss: 0.188, 19232/28000 datapoints
2025-03-07 10:08:31,688 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-07 10:08:31,929 - INFO - training batch 701, loss: 0.269, 22432/28000 datapoints
2025-03-07 10:08:32,163 - INFO - training batch 751, loss: 0.108, 24032/28000 datapoints
2025-03-07 10:08:32,405 - INFO - training batch 801, loss: 0.099, 25632/28000 datapoints
2025-03-07 10:08:32,637 - INFO - training batch 851, loss: 0.135, 27232/28000 datapoints
2025-03-07 10:08:32,752 - INFO - validation batch 1, loss: 0.185, 32/6976 datapoints
2025-03-07 10:08:32,816 - INFO - validation batch 51, loss: 1.440, 1632/6976 datapoints
2025-03-07 10:08:32,881 - INFO - validation batch 101, loss: 0.492, 3232/6976 datapoints
2025-03-07 10:08:32,944 - INFO - validation batch 151, loss: 0.261, 4832/6976 datapoints
2025-03-07 10:08:33,007 - INFO - validation batch 201, loss: 0.941, 6432/6976 datapoints
2025-03-07 10:08:33,031 - INFO - Epoch 154/800 done.
2025-03-07 10:08:33,031 - INFO - Final validation performance:
Loss: 0.664, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:08:33,031 - INFO - Beginning epoch 155/800
2025-03-07 10:08:33,039 - INFO - training batch 1, loss: 0.160, 32/28000 datapoints
2025-03-07 10:08:33,302 - INFO - training batch 51, loss: 0.072, 1632/28000 datapoints
2025-03-07 10:08:33,533 - INFO - training batch 101, loss: 0.104, 3232/28000 datapoints
2025-03-07 10:08:33,757 - INFO - training batch 151, loss: 0.099, 4832/28000 datapoints
2025-03-07 10:08:33,982 - INFO - training batch 201, loss: 0.093, 6432/28000 datapoints
2025-03-07 10:08:34,203 - INFO - training batch 251, loss: 0.230, 8032/28000 datapoints
2025-03-07 10:08:34,429 - INFO - training batch 301, loss: 0.517, 9632/28000 datapoints
2025-03-07 10:08:34,659 - INFO - training batch 351, loss: 0.220, 11232/28000 datapoints
2025-03-07 10:08:34,887 - INFO - training batch 401, loss: 0.279, 12832/28000 datapoints
2025-03-07 10:08:35,122 - INFO - training batch 451, loss: 0.270, 14432/28000 datapoints
2025-03-07 10:08:35,349 - INFO - training batch 501, loss: 0.112, 16032/28000 datapoints
2025-03-07 10:08:35,585 - INFO - training batch 551, loss: 0.162, 17632/28000 datapoints
2025-03-07 10:08:35,810 - INFO - training batch 601, loss: 0.179, 19232/28000 datapoints
2025-03-07 10:08:36,033 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-07 10:08:36,258 - INFO - training batch 701, loss: 0.266, 22432/28000 datapoints
2025-03-07 10:08:36,479 - INFO - training batch 751, loss: 0.108, 24032/28000 datapoints
2025-03-07 10:08:36,700 - INFO - training batch 801, loss: 0.098, 25632/28000 datapoints
2025-03-07 10:08:36,938 - INFO - training batch 851, loss: 0.133, 27232/28000 datapoints
2025-03-07 10:08:37,055 - INFO - validation batch 1, loss: 0.185, 32/6976 datapoints
2025-03-07 10:08:37,124 - INFO - validation batch 51, loss: 1.445, 1632/6976 datapoints
2025-03-07 10:08:37,189 - INFO - validation batch 101, loss: 0.497, 3232/6976 datapoints
2025-03-07 10:08:37,259 - INFO - validation batch 151, loss: 0.261, 4832/6976 datapoints
2025-03-07 10:08:37,335 - INFO - validation batch 201, loss: 0.943, 6432/6976 datapoints
2025-03-07 10:08:37,365 - INFO - Epoch 155/800 done.
2025-03-07 10:08:37,365 - INFO - Final validation performance:
Loss: 0.666, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:08:37,366 - INFO - Beginning epoch 156/800
2025-03-07 10:08:37,374 - INFO - training batch 1, loss: 0.159, 32/28000 datapoints
2025-03-07 10:08:37,661 - INFO - training batch 51, loss: 0.070, 1632/28000 datapoints
2025-03-07 10:08:37,901 - INFO - training batch 101, loss: 0.102, 3232/28000 datapoints
2025-03-07 10:08:38,192 - INFO - training batch 151, loss: 0.097, 4832/28000 datapoints
2025-03-07 10:08:38,479 - INFO - training batch 201, loss: 0.092, 6432/28000 datapoints
2025-03-07 10:08:38,728 - INFO - training batch 251, loss: 0.227, 8032/28000 datapoints
2025-03-07 10:08:38,958 - INFO - training batch 301, loss: 0.513, 9632/28000 datapoints
2025-03-07 10:08:39,192 - INFO - training batch 351, loss: 0.219, 11232/28000 datapoints
2025-03-07 10:08:39,418 - INFO - training batch 401, loss: 0.276, 12832/28000 datapoints
2025-03-07 10:08:39,663 - INFO - training batch 451, loss: 0.269, 14432/28000 datapoints
2025-03-07 10:08:39,900 - INFO - training batch 501, loss: 0.110, 16032/28000 datapoints
2025-03-07 10:08:40,143 - INFO - training batch 551, loss: 0.161, 17632/28000 datapoints
2025-03-07 10:08:40,373 - INFO - training batch 601, loss: 0.178, 19232/28000 datapoints
2025-03-07 10:08:40,601 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-07 10:08:40,823 - INFO - training batch 701, loss: 0.263, 22432/28000 datapoints
2025-03-07 10:08:41,063 - INFO - training batch 751, loss: 0.107, 24032/28000 datapoints
2025-03-07 10:08:41,298 - INFO - training batch 801, loss: 0.096, 25632/28000 datapoints
2025-03-07 10:08:41,526 - INFO - training batch 851, loss: 0.129, 27232/28000 datapoints
2025-03-07 10:08:41,637 - INFO - validation batch 1, loss: 0.187, 32/6976 datapoints
2025-03-07 10:08:41,702 - INFO - validation batch 51, loss: 1.447, 1632/6976 datapoints
2025-03-07 10:08:41,765 - INFO - validation batch 101, loss: 0.499, 3232/6976 datapoints
2025-03-07 10:08:41,829 - INFO - validation batch 151, loss: 0.259, 4832/6976 datapoints
2025-03-07 10:08:41,893 - INFO - validation batch 201, loss: 0.949, 6432/6976 datapoints
2025-03-07 10:08:41,917 - INFO - Epoch 156/800 done.
2025-03-07 10:08:41,918 - INFO - Final validation performance:
Loss: 0.668, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:08:41,918 - INFO - Beginning epoch 157/800
2025-03-07 10:08:41,925 - INFO - training batch 1, loss: 0.158, 32/28000 datapoints
2025-03-07 10:08:42,163 - INFO - training batch 51, loss: 0.069, 1632/28000 datapoints
2025-03-07 10:08:42,390 - INFO - training batch 101, loss: 0.099, 3232/28000 datapoints
2025-03-07 10:08:42,615 - INFO - training batch 151, loss: 0.094, 4832/28000 datapoints
2025-03-07 10:08:42,856 - INFO - training batch 201, loss: 0.091, 6432/28000 datapoints
2025-03-07 10:08:43,111 - INFO - training batch 251, loss: 0.226, 8032/28000 datapoints
2025-03-07 10:08:43,368 - INFO - training batch 301, loss: 0.507, 9632/28000 datapoints
2025-03-07 10:08:43,625 - INFO - training batch 351, loss: 0.218, 11232/28000 datapoints
2025-03-07 10:08:43,872 - INFO - training batch 401, loss: 0.271, 12832/28000 datapoints
2025-03-07 10:08:44,111 - INFO - training batch 451, loss: 0.264, 14432/28000 datapoints
2025-03-07 10:08:44,351 - INFO - training batch 501, loss: 0.109, 16032/28000 datapoints
2025-03-07 10:08:44,598 - INFO - training batch 551, loss: 0.159, 17632/28000 datapoints
2025-03-07 10:08:44,851 - INFO - training batch 601, loss: 0.171, 19232/28000 datapoints
2025-03-07 10:08:45,094 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-07 10:08:45,331 - INFO - training batch 701, loss: 0.261, 22432/28000 datapoints
2025-03-07 10:08:45,562 - INFO - training batch 751, loss: 0.106, 24032/28000 datapoints
2025-03-07 10:08:45,874 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-07 10:08:46,264 - INFO - training batch 851, loss: 0.127, 27232/28000 datapoints
2025-03-07 10:08:46,480 - INFO - validation batch 1, loss: 0.186, 32/6976 datapoints
2025-03-07 10:08:46,590 - INFO - validation batch 51, loss: 1.454, 1632/6976 datapoints
2025-03-07 10:08:46,709 - INFO - validation batch 101, loss: 0.502, 3232/6976 datapoints
2025-03-07 10:08:46,783 - INFO - validation batch 151, loss: 0.259, 4832/6976 datapoints
2025-03-07 10:08:46,873 - INFO - validation batch 201, loss: 0.950, 6432/6976 datapoints
2025-03-07 10:08:46,899 - INFO - Epoch 157/800 done.
2025-03-07 10:08:46,899 - INFO - Final validation performance:
Loss: 0.670, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:08:46,900 - INFO - Beginning epoch 158/800
2025-03-07 10:08:46,908 - INFO - training batch 1, loss: 0.156, 32/28000 datapoints
2025-03-07 10:08:47,166 - INFO - training batch 51, loss: 0.068, 1632/28000 datapoints
2025-03-07 10:08:47,480 - INFO - training batch 101, loss: 0.098, 3232/28000 datapoints
2025-03-07 10:08:47,838 - INFO - training batch 151, loss: 0.092, 4832/28000 datapoints
2025-03-07 10:08:48,158 - INFO - training batch 201, loss: 0.089, 6432/28000 datapoints
2025-03-07 10:08:48,804 - INFO - training batch 251, loss: 0.223, 8032/28000 datapoints
2025-03-07 10:08:49,605 - INFO - training batch 301, loss: 0.502, 9632/28000 datapoints
2025-03-07 10:08:49,907 - INFO - training batch 351, loss: 0.218, 11232/28000 datapoints
2025-03-07 10:08:50,401 - INFO - training batch 401, loss: 0.268, 12832/28000 datapoints
2025-03-07 10:08:51,069 - INFO - training batch 451, loss: 0.264, 14432/28000 datapoints
2025-03-07 10:08:51,616 - INFO - training batch 501, loss: 0.108, 16032/28000 datapoints
2025-03-07 10:08:51,959 - INFO - training batch 551, loss: 0.157, 17632/28000 datapoints
2025-03-07 10:08:52,343 - INFO - training batch 601, loss: 0.164, 19232/28000 datapoints
2025-03-07 10:08:52,857 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-07 10:08:53,281 - INFO - training batch 701, loss: 0.258, 22432/28000 datapoints
2025-03-07 10:08:53,643 - INFO - training batch 751, loss: 0.107, 24032/28000 datapoints
2025-03-07 10:08:54,087 - INFO - training batch 801, loss: 0.093, 25632/28000 datapoints
2025-03-07 10:08:54,516 - INFO - training batch 851, loss: 0.124, 27232/28000 datapoints
2025-03-07 10:08:54,835 - INFO - validation batch 1, loss: 0.189, 32/6976 datapoints
2025-03-07 10:08:54,991 - INFO - validation batch 51, loss: 1.459, 1632/6976 datapoints
2025-03-07 10:08:55,337 - INFO - validation batch 101, loss: 0.505, 3232/6976 datapoints
2025-03-07 10:08:55,783 - INFO - validation batch 151, loss: 0.256, 4832/6976 datapoints
2025-03-07 10:08:56,034 - INFO - validation batch 201, loss: 0.957, 6432/6976 datapoints
2025-03-07 10:08:56,132 - INFO - Epoch 158/800 done.
2025-03-07 10:08:56,133 - INFO - Final validation performance:
Loss: 0.673, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:08:56,137 - INFO - Beginning epoch 159/800
2025-03-07 10:08:56,148 - INFO - training batch 1, loss: 0.155, 32/28000 datapoints
2025-03-07 10:08:56,499 - INFO - training batch 51, loss: 0.067, 1632/28000 datapoints
2025-03-07 10:08:57,007 - INFO - training batch 101, loss: 0.095, 3232/28000 datapoints
2025-03-07 10:08:57,506 - INFO - training batch 151, loss: 0.089, 4832/28000 datapoints
2025-03-07 10:08:58,051 - INFO - training batch 201, loss: 0.088, 6432/28000 datapoints
2025-03-07 10:08:58,434 - INFO - training batch 251, loss: 0.221, 8032/28000 datapoints
2025-03-07 10:08:58,836 - INFO - training batch 301, loss: 0.495, 9632/28000 datapoints
2025-03-07 10:08:59,224 - INFO - training batch 351, loss: 0.217, 11232/28000 datapoints
2025-03-07 10:08:59,548 - INFO - training batch 401, loss: 0.262, 12832/28000 datapoints
2025-03-07 10:08:59,831 - INFO - training batch 451, loss: 0.261, 14432/28000 datapoints
2025-03-07 10:09:00,141 - INFO - training batch 501, loss: 0.107, 16032/28000 datapoints
2025-03-07 10:09:00,521 - INFO - training batch 551, loss: 0.156, 17632/28000 datapoints
2025-03-07 10:09:00,827 - INFO - training batch 601, loss: 0.159, 19232/28000 datapoints
2025-03-07 10:09:01,121 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-07 10:09:01,410 - INFO - training batch 701, loss: 0.256, 22432/28000 datapoints
2025-03-07 10:09:01,676 - INFO - training batch 751, loss: 0.105, 24032/28000 datapoints
2025-03-07 10:09:01,951 - INFO - training batch 801, loss: 0.092, 25632/28000 datapoints
2025-03-07 10:09:02,211 - INFO - training batch 851, loss: 0.123, 27232/28000 datapoints
2025-03-07 10:09:02,362 - INFO - validation batch 1, loss: 0.190, 32/6976 datapoints
2025-03-07 10:09:02,475 - INFO - validation batch 51, loss: 1.462, 1632/6976 datapoints
2025-03-07 10:09:02,558 - INFO - validation batch 101, loss: 0.510, 3232/6976 datapoints
2025-03-07 10:09:02,626 - INFO - validation batch 151, loss: 0.257, 4832/6976 datapoints
2025-03-07 10:09:02,696 - INFO - validation batch 201, loss: 0.959, 6432/6976 datapoints
2025-03-07 10:09:02,732 - INFO - Epoch 159/800 done.
2025-03-07 10:09:02,732 - INFO - Final validation performance:
Loss: 0.676, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:09:02,733 - INFO - Beginning epoch 160/800
2025-03-07 10:09:02,751 - INFO - training batch 1, loss: 0.154, 32/28000 datapoints
2025-03-07 10:09:03,246 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-07 10:09:03,601 - INFO - training batch 101, loss: 0.093, 3232/28000 datapoints
2025-03-07 10:09:03,911 - INFO - training batch 151, loss: 0.088, 4832/28000 datapoints
2025-03-07 10:09:04,254 - INFO - training batch 201, loss: 0.087, 6432/28000 datapoints
2025-03-07 10:09:04,621 - INFO - training batch 251, loss: 0.219, 8032/28000 datapoints
2025-03-07 10:09:04,985 - INFO - training batch 301, loss: 0.492, 9632/28000 datapoints
2025-03-07 10:09:05,246 - INFO - training batch 351, loss: 0.217, 11232/28000 datapoints
2025-03-07 10:09:05,544 - INFO - training batch 401, loss: 0.259, 12832/28000 datapoints
2025-03-07 10:09:05,877 - INFO - training batch 451, loss: 0.259, 14432/28000 datapoints
2025-03-07 10:09:06,206 - INFO - training batch 501, loss: 0.105, 16032/28000 datapoints
2025-03-07 10:09:06,460 - INFO - training batch 551, loss: 0.154, 17632/28000 datapoints
2025-03-07 10:09:06,761 - INFO - training batch 601, loss: 0.156, 19232/28000 datapoints
2025-03-07 10:09:06,998 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-07 10:09:07,223 - INFO - training batch 701, loss: 0.254, 22432/28000 datapoints
2025-03-07 10:09:07,452 - INFO - training batch 751, loss: 0.106, 24032/28000 datapoints
2025-03-07 10:09:07,703 - INFO - training batch 801, loss: 0.091, 25632/28000 datapoints
2025-03-07 10:09:07,954 - INFO - training batch 851, loss: 0.121, 27232/28000 datapoints
2025-03-07 10:09:08,067 - INFO - validation batch 1, loss: 0.189, 32/6976 datapoints
2025-03-07 10:09:08,134 - INFO - validation batch 51, loss: 1.469, 1632/6976 datapoints
2025-03-07 10:09:08,199 - INFO - validation batch 101, loss: 0.512, 3232/6976 datapoints
2025-03-07 10:09:08,266 - INFO - validation batch 151, loss: 0.254, 4832/6976 datapoints
2025-03-07 10:09:08,339 - INFO - validation batch 201, loss: 0.961, 6432/6976 datapoints
2025-03-07 10:09:08,364 - INFO - Epoch 160/800 done.
2025-03-07 10:09:08,364 - INFO - Final validation performance:
Loss: 0.677, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:09:08,365 - INFO - Beginning epoch 161/800
2025-03-07 10:09:08,372 - INFO - training batch 1, loss: 0.152, 32/28000 datapoints
2025-03-07 10:09:08,620 - INFO - training batch 51, loss: 0.064, 1632/28000 datapoints
2025-03-07 10:09:08,869 - INFO - training batch 101, loss: 0.090, 3232/28000 datapoints
2025-03-07 10:09:09,100 - INFO - training batch 151, loss: 0.086, 4832/28000 datapoints
2025-03-07 10:09:09,348 - INFO - training batch 201, loss: 0.085, 6432/28000 datapoints
2025-03-07 10:09:09,584 - INFO - training batch 251, loss: 0.217, 8032/28000 datapoints
2025-03-07 10:09:09,821 - INFO - training batch 301, loss: 0.484, 9632/28000 datapoints
2025-03-07 10:09:10,059 - INFO - training batch 351, loss: 0.215, 11232/28000 datapoints
2025-03-07 10:09:10,299 - INFO - training batch 401, loss: 0.255, 12832/28000 datapoints
2025-03-07 10:09:10,542 - INFO - training batch 451, loss: 0.256, 14432/28000 datapoints
2025-03-07 10:09:10,802 - INFO - training batch 501, loss: 0.104, 16032/28000 datapoints
2025-03-07 10:09:11,078 - INFO - training batch 551, loss: 0.152, 17632/28000 datapoints
2025-03-07 10:09:11,366 - INFO - training batch 601, loss: 0.150, 19232/28000 datapoints
2025-03-07 10:09:11,654 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-07 10:09:11,938 - INFO - training batch 701, loss: 0.251, 22432/28000 datapoints
2025-03-07 10:09:12,199 - INFO - training batch 751, loss: 0.105, 24032/28000 datapoints
2025-03-07 10:09:12,471 - INFO - training batch 801, loss: 0.089, 25632/28000 datapoints
2025-03-07 10:09:12,759 - INFO - training batch 851, loss: 0.119, 27232/28000 datapoints
2025-03-07 10:09:12,887 - INFO - validation batch 1, loss: 0.191, 32/6976 datapoints
2025-03-07 10:09:12,974 - INFO - validation batch 51, loss: 1.475, 1632/6976 datapoints
2025-03-07 10:09:13,057 - INFO - validation batch 101, loss: 0.515, 3232/6976 datapoints
2025-03-07 10:09:13,142 - INFO - validation batch 151, loss: 0.251, 4832/6976 datapoints
2025-03-07 10:09:13,215 - INFO - validation batch 201, loss: 0.966, 6432/6976 datapoints
2025-03-07 10:09:13,241 - INFO - Epoch 161/800 done.
2025-03-07 10:09:13,242 - INFO - Final validation performance:
Loss: 0.679, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:09:13,242 - INFO - Beginning epoch 162/800
2025-03-07 10:09:13,251 - INFO - training batch 1, loss: 0.153, 32/28000 datapoints
2025-03-07 10:09:13,499 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-07 10:09:13,732 - INFO - training batch 101, loss: 0.088, 3232/28000 datapoints
2025-03-07 10:09:13,963 - INFO - training batch 151, loss: 0.084, 4832/28000 datapoints
2025-03-07 10:09:14,192 - INFO - training batch 201, loss: 0.085, 6432/28000 datapoints
2025-03-07 10:09:14,423 - INFO - training batch 251, loss: 0.214, 8032/28000 datapoints
2025-03-07 10:09:14,652 - INFO - training batch 301, loss: 0.478, 9632/28000 datapoints
2025-03-07 10:09:14,881 - INFO - training batch 351, loss: 0.215, 11232/28000 datapoints
2025-03-07 10:09:15,131 - INFO - training batch 401, loss: 0.250, 12832/28000 datapoints
2025-03-07 10:09:15,363 - INFO - training batch 451, loss: 0.255, 14432/28000 datapoints
2025-03-07 10:09:15,608 - INFO - training batch 501, loss: 0.103, 16032/28000 datapoints
2025-03-07 10:09:15,870 - INFO - training batch 551, loss: 0.151, 17632/28000 datapoints
2025-03-07 10:09:16,107 - INFO - training batch 601, loss: 0.147, 19232/28000 datapoints
2025-03-07 10:09:16,344 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-07 10:09:16,605 - INFO - training batch 701, loss: 0.249, 22432/28000 datapoints
2025-03-07 10:09:16,911 - INFO - training batch 751, loss: 0.105, 24032/28000 datapoints
2025-03-07 10:09:17,202 - INFO - training batch 801, loss: 0.087, 25632/28000 datapoints
2025-03-07 10:09:17,489 - INFO - training batch 851, loss: 0.115, 27232/28000 datapoints
2025-03-07 10:09:17,634 - INFO - validation batch 1, loss: 0.192, 32/6976 datapoints
2025-03-07 10:09:17,733 - INFO - validation batch 51, loss: 1.477, 1632/6976 datapoints
2025-03-07 10:09:17,839 - INFO - validation batch 101, loss: 0.519, 3232/6976 datapoints
2025-03-07 10:09:17,985 - INFO - validation batch 151, loss: 0.251, 4832/6976 datapoints
2025-03-07 10:09:18,100 - INFO - validation batch 201, loss: 0.971, 6432/6976 datapoints
2025-03-07 10:09:18,133 - INFO - Epoch 162/800 done.
2025-03-07 10:09:18,134 - INFO - Final validation performance:
Loss: 0.682, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 10:09:18,134 - INFO - Beginning epoch 163/800
2025-03-07 10:09:18,145 - INFO - training batch 1, loss: 0.151, 32/28000 datapoints
2025-03-07 10:09:18,474 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-07 10:09:18,793 - INFO - training batch 101, loss: 0.088, 3232/28000 datapoints
2025-03-07 10:09:19,080 - INFO - training batch 151, loss: 0.082, 4832/28000 datapoints
2025-03-07 10:09:19,358 - INFO - training batch 201, loss: 0.084, 6432/28000 datapoints
2025-03-07 10:09:19,614 - INFO - training batch 251, loss: 0.213, 8032/28000 datapoints
2025-03-07 10:09:19,880 - INFO - training batch 301, loss: 0.473, 9632/28000 datapoints
2025-03-07 10:09:20,226 - INFO - training batch 351, loss: 0.214, 11232/28000 datapoints
2025-03-07 10:09:20,591 - INFO - training batch 401, loss: 0.247, 12832/28000 datapoints
2025-03-07 10:09:21,208 - INFO - training batch 451, loss: 0.252, 14432/28000 datapoints
2025-03-07 10:09:22,075 - INFO - training batch 501, loss: 0.103, 16032/28000 datapoints
2025-03-07 10:09:23,043 - INFO - training batch 551, loss: 0.148, 17632/28000 datapoints
2025-03-07 10:09:23,686 - INFO - training batch 601, loss: 0.139, 19232/28000 datapoints
2025-03-07 10:09:24,049 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-07 10:09:24,465 - INFO - training batch 701, loss: 0.246, 22432/28000 datapoints
2025-03-07 10:09:24,807 - INFO - training batch 751, loss: 0.104, 24032/28000 datapoints
2025-03-07 10:09:25,125 - INFO - training batch 801, loss: 0.086, 25632/28000 datapoints
2025-03-07 10:09:25,463 - INFO - training batch 851, loss: 0.114, 27232/28000 datapoints
2025-03-07 10:09:25,596 - INFO - validation batch 1, loss: 0.194, 32/6976 datapoints
2025-03-07 10:09:25,698 - INFO - validation batch 51, loss: 1.484, 1632/6976 datapoints
2025-03-07 10:09:25,804 - INFO - validation batch 101, loss: 0.521, 3232/6976 datapoints
2025-03-07 10:09:25,914 - INFO - validation batch 151, loss: 0.251, 4832/6976 datapoints
2025-03-07 10:09:26,010 - INFO - validation batch 201, loss: 0.975, 6432/6976 datapoints
2025-03-07 10:09:26,043 - INFO - Epoch 163/800 done.
2025-03-07 10:09:26,044 - INFO - Final validation performance:
Loss: 0.685, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:09:26,046 - INFO - Beginning epoch 164/800
2025-03-07 10:09:26,055 - INFO - training batch 1, loss: 0.148, 32/28000 datapoints
2025-03-07 10:09:26,325 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-07 10:09:26,606 - INFO - training batch 101, loss: 0.086, 3232/28000 datapoints
2025-03-07 10:09:26,847 - INFO - training batch 151, loss: 0.080, 4832/28000 datapoints
2025-03-07 10:09:27,107 - INFO - training batch 201, loss: 0.083, 6432/28000 datapoints
2025-03-07 10:09:27,377 - INFO - training batch 251, loss: 0.210, 8032/28000 datapoints
2025-03-07 10:09:27,631 - INFO - training batch 301, loss: 0.467, 9632/28000 datapoints
2025-03-07 10:09:27,881 - INFO - training batch 351, loss: 0.213, 11232/28000 datapoints
2025-03-07 10:09:28,179 - INFO - training batch 401, loss: 0.243, 12832/28000 datapoints
2025-03-07 10:09:28,447 - INFO - training batch 451, loss: 0.250, 14432/28000 datapoints
2025-03-07 10:09:28,800 - INFO - training batch 501, loss: 0.102, 16032/28000 datapoints
2025-03-07 10:09:29,112 - INFO - training batch 551, loss: 0.148, 17632/28000 datapoints
2025-03-07 10:09:29,398 - INFO - training batch 601, loss: 0.139, 19232/28000 datapoints
2025-03-07 10:09:29,736 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-07 10:09:30,044 - INFO - training batch 701, loss: 0.244, 22432/28000 datapoints
2025-03-07 10:09:30,485 - INFO - training batch 751, loss: 0.104, 24032/28000 datapoints
2025-03-07 10:09:30,765 - INFO - training batch 801, loss: 0.085, 25632/28000 datapoints
2025-03-07 10:09:31,052 - INFO - training batch 851, loss: 0.112, 27232/28000 datapoints
2025-03-07 10:09:31,193 - INFO - validation batch 1, loss: 0.194, 32/6976 datapoints
2025-03-07 10:09:31,300 - INFO - validation batch 51, loss: 1.491, 1632/6976 datapoints
2025-03-07 10:09:31,376 - INFO - validation batch 101, loss: 0.524, 3232/6976 datapoints
2025-03-07 10:09:31,472 - INFO - validation batch 151, loss: 0.248, 4832/6976 datapoints
2025-03-07 10:09:31,579 - INFO - validation batch 201, loss: 0.978, 6432/6976 datapoints
2025-03-07 10:09:31,610 - INFO - Epoch 164/800 done.
2025-03-07 10:09:31,626 - INFO - Final validation performance:
Loss: 0.687, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:09:31,627 - INFO - Beginning epoch 165/800
2025-03-07 10:09:31,641 - INFO - training batch 1, loss: 0.147, 32/28000 datapoints
2025-03-07 10:09:31,963 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-07 10:09:32,238 - INFO - training batch 101, loss: 0.083, 3232/28000 datapoints
2025-03-07 10:09:32,544 - INFO - training batch 151, loss: 0.078, 4832/28000 datapoints
2025-03-07 10:09:32,834 - INFO - training batch 201, loss: 0.081, 6432/28000 datapoints
2025-03-07 10:09:33,110 - INFO - training batch 251, loss: 0.209, 8032/28000 datapoints
2025-03-07 10:09:33,370 - INFO - training batch 301, loss: 0.462, 9632/28000 datapoints
2025-03-07 10:09:33,604 - INFO - training batch 351, loss: 0.213, 11232/28000 datapoints
2025-03-07 10:09:33,837 - INFO - training batch 401, loss: 0.238, 12832/28000 datapoints
2025-03-07 10:09:34,065 - INFO - training batch 451, loss: 0.247, 14432/28000 datapoints
2025-03-07 10:09:34,294 - INFO - training batch 501, loss: 0.100, 16032/28000 datapoints
2025-03-07 10:09:34,536 - INFO - training batch 551, loss: 0.146, 17632/28000 datapoints
2025-03-07 10:09:34,787 - INFO - training batch 601, loss: 0.129, 19232/28000 datapoints
2025-03-07 10:09:35,027 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-07 10:09:35,265 - INFO - training batch 701, loss: 0.242, 22432/28000 datapoints
2025-03-07 10:09:35,507 - INFO - training batch 751, loss: 0.103, 24032/28000 datapoints
2025-03-07 10:09:35,742 - INFO - training batch 801, loss: 0.084, 25632/28000 datapoints
2025-03-07 10:09:35,975 - INFO - training batch 851, loss: 0.108, 27232/28000 datapoints
2025-03-07 10:09:36,103 - INFO - validation batch 1, loss: 0.198, 32/6976 datapoints
2025-03-07 10:09:36,193 - INFO - validation batch 51, loss: 1.491, 1632/6976 datapoints
2025-03-07 10:09:36,285 - INFO - validation batch 101, loss: 0.529, 3232/6976 datapoints
2025-03-07 10:09:36,356 - INFO - validation batch 151, loss: 0.247, 4832/6976 datapoints
2025-03-07 10:09:36,430 - INFO - validation batch 201, loss: 0.985, 6432/6976 datapoints
2025-03-07 10:09:36,458 - INFO - Epoch 165/800 done.
2025-03-07 10:09:36,458 - INFO - Final validation performance:
Loss: 0.690, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:09:36,461 - INFO - Beginning epoch 166/800
2025-03-07 10:09:36,468 - INFO - training batch 1, loss: 0.145, 32/28000 datapoints
2025-03-07 10:09:36,702 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-07 10:09:36,938 - INFO - training batch 101, loss: 0.083, 3232/28000 datapoints
2025-03-07 10:09:37,217 - INFO - training batch 151, loss: 0.076, 4832/28000 datapoints
2025-03-07 10:09:37,489 - INFO - training batch 201, loss: 0.080, 6432/28000 datapoints
2025-03-07 10:09:37,747 - INFO - training batch 251, loss: 0.206, 8032/28000 datapoints
2025-03-07 10:09:38,013 - INFO - training batch 301, loss: 0.454, 9632/28000 datapoints
2025-03-07 10:09:38,284 - INFO - training batch 351, loss: 0.212, 11232/28000 datapoints
2025-03-07 10:09:38,529 - INFO - training batch 401, loss: 0.235, 12832/28000 datapoints
2025-03-07 10:09:38,773 - INFO - training batch 451, loss: 0.247, 14432/28000 datapoints
2025-03-07 10:09:39,023 - INFO - training batch 501, loss: 0.099, 16032/28000 datapoints
2025-03-07 10:09:39,280 - INFO - training batch 551, loss: 0.144, 17632/28000 datapoints
2025-03-07 10:09:39,575 - INFO - training batch 601, loss: 0.128, 19232/28000 datapoints
2025-03-07 10:09:39,846 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-07 10:09:40,120 - INFO - training batch 701, loss: 0.239, 22432/28000 datapoints
2025-03-07 10:09:40,464 - INFO - training batch 751, loss: 0.103, 24032/28000 datapoints
2025-03-07 10:09:40,769 - INFO - training batch 801, loss: 0.083, 25632/28000 datapoints
2025-03-07 10:09:41,079 - INFO - training batch 851, loss: 0.107, 27232/28000 datapoints
2025-03-07 10:09:41,275 - INFO - validation batch 1, loss: 0.196, 32/6976 datapoints
2025-03-07 10:09:41,406 - INFO - validation batch 51, loss: 1.501, 1632/6976 datapoints
2025-03-07 10:09:41,516 - INFO - validation batch 101, loss: 0.534, 3232/6976 datapoints
2025-03-07 10:09:41,629 - INFO - validation batch 151, loss: 0.246, 4832/6976 datapoints
2025-03-07 10:09:41,729 - INFO - validation batch 201, loss: 0.987, 6432/6976 datapoints
2025-03-07 10:09:41,764 - INFO - Epoch 166/800 done.
2025-03-07 10:09:41,765 - INFO - Final validation performance:
Loss: 0.693, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:09:41,765 - INFO - Beginning epoch 167/800
2025-03-07 10:09:41,773 - INFO - training batch 1, loss: 0.143, 32/28000 datapoints
2025-03-07 10:09:42,084 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-07 10:09:42,401 - INFO - training batch 101, loss: 0.081, 3232/28000 datapoints
2025-03-07 10:09:42,788 - INFO - training batch 151, loss: 0.075, 4832/28000 datapoints
2025-03-07 10:09:43,184 - INFO - training batch 201, loss: 0.080, 6432/28000 datapoints
2025-03-07 10:09:43,493 - INFO - training batch 251, loss: 0.204, 8032/28000 datapoints
2025-03-07 10:09:43,774 - INFO - training batch 301, loss: 0.450, 9632/28000 datapoints
2025-03-07 10:09:44,071 - INFO - training batch 351, loss: 0.210, 11232/28000 datapoints
2025-03-07 10:09:44,344 - INFO - training batch 401, loss: 0.232, 12832/28000 datapoints
2025-03-07 10:09:44,591 - INFO - training batch 451, loss: 0.243, 14432/28000 datapoints
2025-03-07 10:09:44,836 - INFO - training batch 501, loss: 0.098, 16032/28000 datapoints
2025-03-07 10:09:45,085 - INFO - training batch 551, loss: 0.142, 17632/28000 datapoints
2025-03-07 10:09:45,390 - INFO - training batch 601, loss: 0.126, 19232/28000 datapoints
2025-03-07 10:09:45,692 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-07 10:09:45,933 - INFO - training batch 701, loss: 0.237, 22432/28000 datapoints
2025-03-07 10:09:46,216 - INFO - training batch 751, loss: 0.103, 24032/28000 datapoints
2025-03-07 10:09:46,477 - INFO - training batch 801, loss: 0.080, 25632/28000 datapoints
2025-03-07 10:09:46,768 - INFO - training batch 851, loss: 0.105, 27232/28000 datapoints
2025-03-07 10:09:46,907 - INFO - validation batch 1, loss: 0.197, 32/6976 datapoints
2025-03-07 10:09:47,005 - INFO - validation batch 51, loss: 1.505, 1632/6976 datapoints
2025-03-07 10:09:47,102 - INFO - validation batch 101, loss: 0.537, 3232/6976 datapoints
2025-03-07 10:09:47,198 - INFO - validation batch 151, loss: 0.248, 4832/6976 datapoints
2025-03-07 10:09:47,306 - INFO - validation batch 201, loss: 0.993, 6432/6976 datapoints
2025-03-07 10:09:47,340 - INFO - Epoch 167/800 done.
2025-03-07 10:09:47,340 - INFO - Final validation performance:
Loss: 0.696, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:09:47,341 - INFO - Beginning epoch 168/800
2025-03-07 10:09:47,352 - INFO - training batch 1, loss: 0.142, 32/28000 datapoints
2025-03-07 10:09:47,666 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-07 10:09:47,975 - INFO - training batch 101, loss: 0.080, 3232/28000 datapoints
2025-03-07 10:09:48,334 - INFO - training batch 151, loss: 0.073, 4832/28000 datapoints
2025-03-07 10:09:48,626 - INFO - training batch 201, loss: 0.079, 6432/28000 datapoints
2025-03-07 10:09:48,892 - INFO - training batch 251, loss: 0.203, 8032/28000 datapoints
2025-03-07 10:09:49,171 - INFO - training batch 301, loss: 0.443, 9632/28000 datapoints
2025-03-07 10:09:49,432 - INFO - training batch 351, loss: 0.211, 11232/28000 datapoints
2025-03-07 10:09:49,667 - INFO - training batch 401, loss: 0.229, 12832/28000 datapoints
2025-03-07 10:09:49,937 - INFO - training batch 451, loss: 0.240, 14432/28000 datapoints
2025-03-07 10:09:50,251 - INFO - training batch 501, loss: 0.098, 16032/28000 datapoints
2025-03-07 10:09:50,497 - INFO - training batch 551, loss: 0.142, 17632/28000 datapoints
2025-03-07 10:09:50,736 - INFO - training batch 601, loss: 0.119, 19232/28000 datapoints
2025-03-07 10:09:50,992 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-07 10:09:51,221 - INFO - training batch 701, loss: 0.233, 22432/28000 datapoints
2025-03-07 10:09:51,631 - INFO - training batch 751, loss: 0.102, 24032/28000 datapoints
2025-03-07 10:09:52,372 - INFO - training batch 801, loss: 0.081, 25632/28000 datapoints
2025-03-07 10:09:52,897 - INFO - training batch 851, loss: 0.103, 27232/28000 datapoints
2025-03-07 10:09:53,039 - INFO - validation batch 1, loss: 0.200, 32/6976 datapoints
2025-03-07 10:09:53,161 - INFO - validation batch 51, loss: 1.512, 1632/6976 datapoints
2025-03-07 10:09:53,296 - INFO - validation batch 101, loss: 0.539, 3232/6976 datapoints
2025-03-07 10:09:53,453 - INFO - validation batch 151, loss: 0.244, 4832/6976 datapoints
2025-03-07 10:09:53,603 - INFO - validation batch 201, loss: 0.998, 6432/6976 datapoints
2025-03-07 10:09:53,661 - INFO - Epoch 168/800 done.
2025-03-07 10:09:53,662 - INFO - Final validation performance:
Loss: 0.698, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:09:53,665 - INFO - Beginning epoch 169/800
2025-03-07 10:09:53,677 - INFO - training batch 1, loss: 0.141, 32/28000 datapoints
2025-03-07 10:09:54,154 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-07 10:09:54,587 - INFO - training batch 101, loss: 0.078, 3232/28000 datapoints
2025-03-07 10:09:54,948 - INFO - training batch 151, loss: 0.072, 4832/28000 datapoints
2025-03-07 10:09:55,268 - INFO - training batch 201, loss: 0.077, 6432/28000 datapoints
2025-03-07 10:09:55,687 - INFO - training batch 251, loss: 0.201, 8032/28000 datapoints
2025-03-07 10:09:56,142 - INFO - training batch 301, loss: 0.436, 9632/28000 datapoints
2025-03-07 10:09:56,525 - INFO - training batch 351, loss: 0.209, 11232/28000 datapoints
2025-03-07 10:09:56,938 - INFO - training batch 401, loss: 0.225, 12832/28000 datapoints
2025-03-07 10:09:57,390 - INFO - training batch 451, loss: 0.237, 14432/28000 datapoints
2025-03-07 10:09:57,810 - INFO - training batch 501, loss: 0.097, 16032/28000 datapoints
2025-03-07 10:09:58,083 - INFO - training batch 551, loss: 0.140, 17632/28000 datapoints
2025-03-07 10:09:58,410 - INFO - training batch 601, loss: 0.116, 19232/28000 datapoints
2025-03-07 10:09:58,788 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-07 10:09:59,137 - INFO - training batch 701, loss: 0.230, 22432/28000 datapoints
2025-03-07 10:09:59,448 - INFO - training batch 751, loss: 0.103, 24032/28000 datapoints
2025-03-07 10:09:59,777 - INFO - training batch 801, loss: 0.079, 25632/28000 datapoints
2025-03-07 10:10:00,072 - INFO - training batch 851, loss: 0.101, 27232/28000 datapoints
2025-03-07 10:10:00,201 - INFO - validation batch 1, loss: 0.199, 32/6976 datapoints
2025-03-07 10:10:00,268 - INFO - validation batch 51, loss: 1.517, 1632/6976 datapoints
2025-03-07 10:10:00,341 - INFO - validation batch 101, loss: 0.544, 3232/6976 datapoints
2025-03-07 10:10:00,420 - INFO - validation batch 151, loss: 0.244, 4832/6976 datapoints
2025-03-07 10:10:00,506 - INFO - validation batch 201, loss: 1.001, 6432/6976 datapoints
2025-03-07 10:10:00,536 - INFO - Epoch 169/800 done.
2025-03-07 10:10:00,540 - INFO - Final validation performance:
Loss: 0.701, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:10:00,541 - INFO - Beginning epoch 170/800
2025-03-07 10:10:00,551 - INFO - training batch 1, loss: 0.138, 32/28000 datapoints
2025-03-07 10:10:00,815 - INFO - training batch 51, loss: 0.053, 1632/28000 datapoints
2025-03-07 10:10:01,065 - INFO - training batch 101, loss: 0.077, 3232/28000 datapoints
2025-03-07 10:10:01,333 - INFO - training batch 151, loss: 0.071, 4832/28000 datapoints
2025-03-07 10:10:01,636 - INFO - training batch 201, loss: 0.078, 6432/28000 datapoints
2025-03-07 10:10:01,902 - INFO - training batch 251, loss: 0.198, 8032/28000 datapoints
2025-03-07 10:10:02,157 - INFO - training batch 301, loss: 0.429, 9632/28000 datapoints
2025-03-07 10:10:02,472 - INFO - training batch 351, loss: 0.209, 11232/28000 datapoints
2025-03-07 10:10:02,766 - INFO - training batch 401, loss: 0.223, 12832/28000 datapoints
2025-03-07 10:10:03,097 - INFO - training batch 451, loss: 0.236, 14432/28000 datapoints
2025-03-07 10:10:03,381 - INFO - training batch 501, loss: 0.095, 16032/28000 datapoints
2025-03-07 10:10:03,658 - INFO - training batch 551, loss: 0.137, 17632/28000 datapoints
2025-03-07 10:10:03,904 - INFO - training batch 601, loss: 0.109, 19232/28000 datapoints
2025-03-07 10:10:04,179 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-07 10:10:04,409 - INFO - training batch 701, loss: 0.228, 22432/28000 datapoints
2025-03-07 10:10:04,657 - INFO - training batch 751, loss: 0.101, 24032/28000 datapoints
2025-03-07 10:10:04,886 - INFO - training batch 801, loss: 0.078, 25632/28000 datapoints
2025-03-07 10:10:05,135 - INFO - training batch 851, loss: 0.099, 27232/28000 datapoints
2025-03-07 10:10:05,251 - INFO - validation batch 1, loss: 0.203, 32/6976 datapoints
2025-03-07 10:10:05,353 - INFO - validation batch 51, loss: 1.520, 1632/6976 datapoints
2025-03-07 10:10:05,436 - INFO - validation batch 101, loss: 0.546, 3232/6976 datapoints
2025-03-07 10:10:05,504 - INFO - validation batch 151, loss: 0.243, 4832/6976 datapoints
2025-03-07 10:10:05,579 - INFO - validation batch 201, loss: 1.011, 6432/6976 datapoints
2025-03-07 10:10:05,608 - INFO - Epoch 170/800 done.
2025-03-07 10:10:05,608 - INFO - Final validation performance:
Loss: 0.704, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:10:05,609 - INFO - Beginning epoch 171/800
2025-03-07 10:10:05,617 - INFO - training batch 1, loss: 0.139, 32/28000 datapoints
2025-03-07 10:10:05,878 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-07 10:10:06,149 - INFO - training batch 101, loss: 0.075, 3232/28000 datapoints
2025-03-07 10:10:06,395 - INFO - training batch 151, loss: 0.069, 4832/28000 datapoints
2025-03-07 10:10:06,666 - INFO - training batch 201, loss: 0.076, 6432/28000 datapoints
2025-03-07 10:10:06,941 - INFO - training batch 251, loss: 0.197, 8032/28000 datapoints
2025-03-07 10:10:07,179 - INFO - training batch 301, loss: 0.424, 9632/28000 datapoints
2025-03-07 10:10:07,410 - INFO - training batch 351, loss: 0.208, 11232/28000 datapoints
2025-03-07 10:10:07,655 - INFO - training batch 401, loss: 0.219, 12832/28000 datapoints
2025-03-07 10:10:07,932 - INFO - training batch 451, loss: 0.234, 14432/28000 datapoints
2025-03-07 10:10:08,189 - INFO - training batch 501, loss: 0.095, 16032/28000 datapoints
2025-03-07 10:10:08,440 - INFO - training batch 551, loss: 0.136, 17632/28000 datapoints
2025-03-07 10:10:08,706 - INFO - training batch 601, loss: 0.111, 19232/28000 datapoints
2025-03-07 10:10:08,939 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-07 10:10:09,171 - INFO - training batch 701, loss: 0.225, 22432/28000 datapoints
2025-03-07 10:10:09,431 - INFO - training batch 751, loss: 0.102, 24032/28000 datapoints
2025-03-07 10:10:09,683 - INFO - training batch 801, loss: 0.076, 25632/28000 datapoints
2025-03-07 10:10:09,914 - INFO - training batch 851, loss: 0.096, 27232/28000 datapoints
2025-03-07 10:10:10,028 - INFO - validation batch 1, loss: 0.204, 32/6976 datapoints
2025-03-07 10:10:10,092 - INFO - validation batch 51, loss: 1.529, 1632/6976 datapoints
2025-03-07 10:10:10,165 - INFO - validation batch 101, loss: 0.551, 3232/6976 datapoints
2025-03-07 10:10:10,233 - INFO - validation batch 151, loss: 0.244, 4832/6976 datapoints
2025-03-07 10:10:10,303 - INFO - validation batch 201, loss: 1.013, 6432/6976 datapoints
2025-03-07 10:10:10,325 - INFO - Epoch 171/800 done.
2025-03-07 10:10:10,325 - INFO - Final validation performance:
Loss: 0.708, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:10:10,327 - INFO - Beginning epoch 172/800
2025-03-07 10:10:10,334 - INFO - training batch 1, loss: 0.137, 32/28000 datapoints
2025-03-07 10:10:10,563 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-07 10:10:10,795 - INFO - training batch 101, loss: 0.073, 3232/28000 datapoints
2025-03-07 10:10:11,032 - INFO - training batch 151, loss: 0.067, 4832/28000 datapoints
2025-03-07 10:10:11,267 - INFO - training batch 201, loss: 0.075, 6432/28000 datapoints
2025-03-07 10:10:11,503 - INFO - training batch 251, loss: 0.194, 8032/28000 datapoints
2025-03-07 10:10:11,744 - INFO - training batch 301, loss: 0.415, 9632/28000 datapoints
2025-03-07 10:10:11,988 - INFO - training batch 351, loss: 0.208, 11232/28000 datapoints
2025-03-07 10:10:12,283 - INFO - training batch 401, loss: 0.216, 12832/28000 datapoints
2025-03-07 10:10:12,517 - INFO - training batch 451, loss: 0.230, 14432/28000 datapoints
2025-03-07 10:10:12,764 - INFO - training batch 501, loss: 0.093, 16032/28000 datapoints
2025-03-07 10:10:12,996 - INFO - training batch 551, loss: 0.134, 17632/28000 datapoints
2025-03-07 10:10:13,252 - INFO - training batch 601, loss: 0.103, 19232/28000 datapoints
2025-03-07 10:10:13,536 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-07 10:10:13,819 - INFO - training batch 701, loss: 0.221, 22432/28000 datapoints
2025-03-07 10:10:14,067 - INFO - training batch 751, loss: 0.101, 24032/28000 datapoints
2025-03-07 10:10:14,308 - INFO - training batch 801, loss: 0.076, 25632/28000 datapoints
2025-03-07 10:10:14,572 - INFO - training batch 851, loss: 0.095, 27232/28000 datapoints
2025-03-07 10:10:14,703 - INFO - validation batch 1, loss: 0.205, 32/6976 datapoints
2025-03-07 10:10:14,771 - INFO - validation batch 51, loss: 1.535, 1632/6976 datapoints
2025-03-07 10:10:14,841 - INFO - validation batch 101, loss: 0.555, 3232/6976 datapoints
2025-03-07 10:10:14,911 - INFO - validation batch 151, loss: 0.245, 4832/6976 datapoints
2025-03-07 10:10:14,977 - INFO - validation batch 201, loss: 1.019, 6432/6976 datapoints
2025-03-07 10:10:15,001 - INFO - Epoch 172/800 done.
2025-03-07 10:10:15,002 - INFO - Final validation performance:
Loss: 0.712, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:10:15,002 - INFO - Beginning epoch 173/800
2025-03-07 10:10:15,009 - INFO - training batch 1, loss: 0.135, 32/28000 datapoints
2025-03-07 10:10:15,296 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-07 10:10:15,534 - INFO - training batch 101, loss: 0.072, 3232/28000 datapoints
2025-03-07 10:10:15,765 - INFO - training batch 151, loss: 0.066, 4832/28000 datapoints
2025-03-07 10:10:15,997 - INFO - training batch 201, loss: 0.074, 6432/28000 datapoints
2025-03-07 10:10:16,223 - INFO - training batch 251, loss: 0.191, 8032/28000 datapoints
2025-03-07 10:10:16,454 - INFO - training batch 301, loss: 0.410, 9632/28000 datapoints
2025-03-07 10:10:16,684 - INFO - training batch 351, loss: 0.207, 11232/28000 datapoints
2025-03-07 10:10:16,908 - INFO - training batch 401, loss: 0.213, 12832/28000 datapoints
2025-03-07 10:10:17,132 - INFO - training batch 451, loss: 0.228, 14432/28000 datapoints
2025-03-07 10:10:17,362 - INFO - training batch 501, loss: 0.093, 16032/28000 datapoints
2025-03-07 10:10:17,606 - INFO - training batch 551, loss: 0.131, 17632/28000 datapoints
2025-03-07 10:10:17,858 - INFO - training batch 601, loss: 0.102, 19232/28000 datapoints
2025-03-07 10:10:18,103 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-07 10:10:18,358 - INFO - training batch 701, loss: 0.219, 22432/28000 datapoints
2025-03-07 10:10:18,644 - INFO - training batch 751, loss: 0.100, 24032/28000 datapoints
2025-03-07 10:10:19,041 - INFO - training batch 801, loss: 0.075, 25632/28000 datapoints
2025-03-07 10:10:19,467 - INFO - training batch 851, loss: 0.093, 27232/28000 datapoints
2025-03-07 10:10:24,592 - INFO - validation batch 1, loss: 0.207, 32/6976 datapoints
2025-03-07 10:10:25,180 - INFO - validation batch 51, loss: 1.546, 1632/6976 datapoints
2025-03-07 10:10:26,075 - INFO - validation batch 101, loss: 0.559, 3232/6976 datapoints
2025-03-07 10:10:26,218 - INFO - validation batch 151, loss: 0.244, 4832/6976 datapoints
2025-03-07 10:10:26,396 - INFO - validation batch 201, loss: 1.021, 6432/6976 datapoints
2025-03-07 10:10:26,441 - INFO - Epoch 173/800 done.
2025-03-07 10:10:26,450 - INFO - Final validation performance:
Loss: 0.715, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:10:26,454 - INFO - Beginning epoch 174/800
2025-03-07 10:10:26,467 - INFO - training batch 1, loss: 0.133, 32/28000 datapoints
2025-03-07 10:10:26,809 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-07 10:10:27,261 - INFO - training batch 101, loss: 0.071, 3232/28000 datapoints
2025-03-07 10:10:27,576 - INFO - training batch 151, loss: 0.065, 4832/28000 datapoints
2025-03-07 10:10:27,922 - INFO - training batch 201, loss: 0.073, 6432/28000 datapoints
2025-03-07 10:10:28,232 - INFO - training batch 251, loss: 0.188, 8032/28000 datapoints
2025-03-07 10:10:28,574 - INFO - training batch 301, loss: 0.403, 9632/28000 datapoints
2025-03-07 10:10:28,921 - INFO - training batch 351, loss: 0.207, 11232/28000 datapoints
2025-03-07 10:10:29,248 - INFO - training batch 401, loss: 0.209, 12832/28000 datapoints
2025-03-07 10:10:29,603 - INFO - training batch 451, loss: 0.227, 14432/28000 datapoints
2025-03-07 10:10:30,263 - INFO - training batch 501, loss: 0.091, 16032/28000 datapoints
2025-03-07 10:10:30,629 - INFO - training batch 551, loss: 0.130, 17632/28000 datapoints
2025-03-07 10:10:30,919 - INFO - training batch 601, loss: 0.100, 19232/28000 datapoints
2025-03-07 10:10:31,202 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-07 10:10:31,487 - INFO - training batch 701, loss: 0.217, 22432/28000 datapoints
2025-03-07 10:10:31,750 - INFO - training batch 751, loss: 0.100, 24032/28000 datapoints
2025-03-07 10:10:32,022 - INFO - training batch 801, loss: 0.074, 25632/28000 datapoints
2025-03-07 10:10:32,312 - INFO - training batch 851, loss: 0.090, 27232/28000 datapoints
2025-03-07 10:10:32,435 - INFO - validation batch 1, loss: 0.208, 32/6976 datapoints
2025-03-07 10:10:32,505 - INFO - validation batch 51, loss: 1.545, 1632/6976 datapoints
2025-03-07 10:10:32,579 - INFO - validation batch 101, loss: 0.565, 3232/6976 datapoints
2025-03-07 10:10:32,650 - INFO - validation batch 151, loss: 0.244, 4832/6976 datapoints
2025-03-07 10:10:32,723 - INFO - validation batch 201, loss: 1.030, 6432/6976 datapoints
2025-03-07 10:10:32,747 - INFO - Epoch 174/800 done.
2025-03-07 10:10:32,747 - INFO - Final validation performance:
Loss: 0.719, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 10:10:32,748 - INFO - Beginning epoch 175/800
2025-03-07 10:10:32,758 - INFO - training batch 1, loss: 0.133, 32/28000 datapoints
2025-03-07 10:10:33,000 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-07 10:10:33,247 - INFO - training batch 101, loss: 0.069, 3232/28000 datapoints
2025-03-07 10:10:33,493 - INFO - training batch 151, loss: 0.063, 4832/28000 datapoints
2025-03-07 10:10:33,732 - INFO - training batch 201, loss: 0.073, 6432/28000 datapoints
2025-03-07 10:10:33,977 - INFO - training batch 251, loss: 0.186, 8032/28000 datapoints
2025-03-07 10:10:34,250 - INFO - training batch 301, loss: 0.396, 9632/28000 datapoints
2025-03-07 10:10:34,500 - INFO - training batch 351, loss: 0.207, 11232/28000 datapoints
2025-03-07 10:10:34,736 - INFO - training batch 401, loss: 0.205, 12832/28000 datapoints
2025-03-07 10:10:34,979 - INFO - training batch 451, loss: 0.223, 14432/28000 datapoints
2025-03-07 10:10:35,233 - INFO - training batch 501, loss: 0.091, 16032/28000 datapoints
2025-03-07 10:10:35,480 - INFO - training batch 551, loss: 0.127, 17632/28000 datapoints
2025-03-07 10:10:35,716 - INFO - training batch 601, loss: 0.094, 19232/28000 datapoints
2025-03-07 10:10:35,965 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-07 10:10:36,221 - INFO - training batch 701, loss: 0.213, 22432/28000 datapoints
2025-03-07 10:10:36,481 - INFO - training batch 751, loss: 0.100, 24032/28000 datapoints
2025-03-07 10:10:36,718 - INFO - training batch 801, loss: 0.073, 25632/28000 datapoints
2025-03-07 10:10:36,958 - INFO - training batch 851, loss: 0.089, 27232/28000 datapoints
2025-03-07 10:10:37,090 - INFO - validation batch 1, loss: 0.210, 32/6976 datapoints
2025-03-07 10:10:37,183 - INFO - validation batch 51, loss: 1.559, 1632/6976 datapoints
2025-03-07 10:10:37,278 - INFO - validation batch 101, loss: 0.564, 3232/6976 datapoints
2025-03-07 10:10:37,384 - INFO - validation batch 151, loss: 0.245, 4832/6976 datapoints
2025-03-07 10:10:37,465 - INFO - validation batch 201, loss: 1.035, 6432/6976 datapoints
2025-03-07 10:10:37,494 - INFO - Epoch 175/800 done.
2025-03-07 10:10:37,497 - INFO - Final validation performance:
Loss: 0.723, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:10:37,498 - INFO - Beginning epoch 176/800
2025-03-07 10:10:37,507 - INFO - training batch 1, loss: 0.131, 32/28000 datapoints
2025-03-07 10:10:37,815 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-07 10:10:38,084 - INFO - training batch 101, loss: 0.068, 3232/28000 datapoints
2025-03-07 10:10:38,342 - INFO - training batch 151, loss: 0.062, 4832/28000 datapoints
2025-03-07 10:10:38,588 - INFO - training batch 201, loss: 0.071, 6432/28000 datapoints
2025-03-07 10:10:38,831 - INFO - training batch 251, loss: 0.185, 8032/28000 datapoints
2025-03-07 10:10:39,122 - INFO - training batch 301, loss: 0.388, 9632/28000 datapoints
2025-03-07 10:10:39,420 - INFO - training batch 351, loss: 0.206, 11232/28000 datapoints
2025-03-07 10:10:39,671 - INFO - training batch 401, loss: 0.203, 12832/28000 datapoints
2025-03-07 10:10:39,934 - INFO - training batch 451, loss: 0.221, 14432/28000 datapoints
2025-03-07 10:10:40,247 - INFO - training batch 501, loss: 0.089, 16032/28000 datapoints
2025-03-07 10:10:40,848 - INFO - training batch 551, loss: 0.127, 17632/28000 datapoints
2025-03-07 10:10:41,140 - INFO - training batch 601, loss: 0.093, 19232/28000 datapoints
2025-03-07 10:10:41,478 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-07 10:10:41,766 - INFO - training batch 701, loss: 0.210, 22432/28000 datapoints
2025-03-07 10:10:42,030 - INFO - training batch 751, loss: 0.099, 24032/28000 datapoints
2025-03-07 10:10:42,374 - INFO - training batch 801, loss: 0.072, 25632/28000 datapoints
2025-03-07 10:10:42,653 - INFO - training batch 851, loss: 0.086, 27232/28000 datapoints
2025-03-07 10:10:42,772 - INFO - validation batch 1, loss: 0.212, 32/6976 datapoints
2025-03-07 10:10:42,873 - INFO - validation batch 51, loss: 1.560, 1632/6976 datapoints
2025-03-07 10:10:42,964 - INFO - validation batch 101, loss: 0.569, 3232/6976 datapoints
2025-03-07 10:10:43,039 - INFO - validation batch 151, loss: 0.242, 4832/6976 datapoints
2025-03-07 10:10:43,113 - INFO - validation batch 201, loss: 1.046, 6432/6976 datapoints
2025-03-07 10:10:43,141 - INFO - Epoch 176/800 done.
2025-03-07 10:10:43,141 - INFO - Final validation performance:
Loss: 0.726, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:10:43,142 - INFO - Beginning epoch 177/800
2025-03-07 10:10:43,150 - INFO - training batch 1, loss: 0.129, 32/28000 datapoints
2025-03-07 10:10:43,419 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-07 10:10:43,659 - INFO - training batch 101, loss: 0.067, 3232/28000 datapoints
2025-03-07 10:10:43,904 - INFO - training batch 151, loss: 0.060, 4832/28000 datapoints
2025-03-07 10:10:44,157 - INFO - training batch 201, loss: 0.069, 6432/28000 datapoints
2025-03-07 10:10:44,436 - INFO - training batch 251, loss: 0.182, 8032/28000 datapoints
2025-03-07 10:10:44,861 - INFO - training batch 301, loss: 0.380, 9632/28000 datapoints
2025-03-07 10:10:45,173 - INFO - training batch 351, loss: 0.206, 11232/28000 datapoints
2025-03-07 10:10:45,525 - INFO - training batch 401, loss: 0.197, 12832/28000 datapoints
2025-03-07 10:10:45,948 - INFO - training batch 451, loss: 0.217, 14432/28000 datapoints
2025-03-07 10:10:47,001 - INFO - training batch 501, loss: 0.088, 16032/28000 datapoints
2025-03-07 10:10:47,938 - INFO - training batch 551, loss: 0.125, 17632/28000 datapoints
2025-03-07 10:10:48,359 - INFO - training batch 601, loss: 0.092, 19232/28000 datapoints
2025-03-07 10:10:49,503 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-07 10:10:50,353 - INFO - training batch 701, loss: 0.206, 22432/28000 datapoints
2025-03-07 10:10:50,840 - INFO - training batch 751, loss: 0.099, 24032/28000 datapoints
2025-03-07 10:10:51,316 - INFO - training batch 801, loss: 0.072, 25632/28000 datapoints
2025-03-07 10:10:52,008 - INFO - training batch 851, loss: 0.084, 27232/28000 datapoints
2025-03-07 10:10:52,343 - INFO - validation batch 1, loss: 0.215, 32/6976 datapoints
2025-03-07 10:10:53,144 - INFO - validation batch 51, loss: 1.572, 1632/6976 datapoints
2025-03-07 10:10:53,331 - INFO - validation batch 101, loss: 0.570, 3232/6976 datapoints
2025-03-07 10:10:53,482 - INFO - validation batch 151, loss: 0.247, 4832/6976 datapoints
2025-03-07 10:10:53,693 - INFO - validation batch 201, loss: 1.047, 6432/6976 datapoints
2025-03-07 10:10:53,758 - INFO - Epoch 177/800 done.
2025-03-07 10:10:53,758 - INFO - Final validation performance:
Loss: 0.730, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:10:53,763 - INFO - Beginning epoch 178/800
2025-03-07 10:10:53,774 - INFO - training batch 1, loss: 0.127, 32/28000 datapoints
2025-03-07 10:10:54,233 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-07 10:10:54,657 - INFO - training batch 101, loss: 0.065, 3232/28000 datapoints
2025-03-07 10:10:55,046 - INFO - training batch 151, loss: 0.059, 4832/28000 datapoints
2025-03-07 10:10:55,427 - INFO - training batch 201, loss: 0.070, 6432/28000 datapoints
2025-03-07 10:10:55,711 - INFO - training batch 251, loss: 0.179, 8032/28000 datapoints
2025-03-07 10:10:55,978 - INFO - training batch 301, loss: 0.371, 9632/28000 datapoints
2025-03-07 10:10:56,253 - INFO - training batch 351, loss: 0.204, 11232/28000 datapoints
2025-03-07 10:10:56,771 - INFO - training batch 401, loss: 0.194, 12832/28000 datapoints
2025-03-07 10:10:57,229 - INFO - training batch 451, loss: 0.216, 14432/28000 datapoints
2025-03-07 10:10:57,622 - INFO - training batch 501, loss: 0.087, 16032/28000 datapoints
2025-03-07 10:10:58,021 - INFO - training batch 551, loss: 0.124, 17632/28000 datapoints
2025-03-07 10:10:58,522 - INFO - training batch 601, loss: 0.086, 19232/28000 datapoints
2025-03-07 10:10:59,188 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-07 10:10:59,741 - INFO - training batch 701, loss: 0.203, 22432/28000 datapoints
2025-03-07 10:11:00,179 - INFO - training batch 751, loss: 0.098, 24032/28000 datapoints
2025-03-07 10:11:00,844 - INFO - training batch 801, loss: 0.071, 25632/28000 datapoints
2025-03-07 10:11:01,311 - INFO - training batch 851, loss: 0.082, 27232/28000 datapoints
2025-03-07 10:11:01,529 - INFO - validation batch 1, loss: 0.216, 32/6976 datapoints
2025-03-07 10:11:01,684 - INFO - validation batch 51, loss: 1.581, 1632/6976 datapoints
2025-03-07 10:11:01,841 - INFO - validation batch 101, loss: 0.573, 3232/6976 datapoints
2025-03-07 10:11:01,976 - INFO - validation batch 151, loss: 0.242, 4832/6976 datapoints
2025-03-07 10:11:02,163 - INFO - validation batch 201, loss: 1.053, 6432/6976 datapoints
2025-03-07 10:11:02,285 - INFO - Epoch 178/800 done.
2025-03-07 10:11:02,293 - INFO - Final validation performance:
Loss: 0.733, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:11:02,298 - INFO - Beginning epoch 179/800
2025-03-07 10:11:02,346 - INFO - training batch 1, loss: 0.126, 32/28000 datapoints
2025-03-07 10:11:03,474 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-07 10:11:04,340 - INFO - training batch 101, loss: 0.063, 3232/28000 datapoints
2025-03-07 10:11:04,951 - INFO - training batch 151, loss: 0.058, 4832/28000 datapoints
2025-03-07 10:11:05,425 - INFO - training batch 201, loss: 0.069, 6432/28000 datapoints
2025-03-07 10:11:05,867 - INFO - training batch 251, loss: 0.179, 8032/28000 datapoints
2025-03-07 10:11:06,402 - INFO - training batch 301, loss: 0.364, 9632/28000 datapoints
2025-03-07 10:11:07,140 - INFO - training batch 351, loss: 0.204, 11232/28000 datapoints
2025-03-07 10:11:09,096 - INFO - training batch 401, loss: 0.192, 12832/28000 datapoints
2025-03-07 10:11:10,167 - INFO - training batch 451, loss: 0.212, 14432/28000 datapoints
2025-03-07 10:11:10,710 - INFO - training batch 501, loss: 0.086, 16032/28000 datapoints
2025-03-07 10:11:11,491 - INFO - training batch 551, loss: 0.121, 17632/28000 datapoints
2025-03-07 10:11:11,980 - INFO - training batch 601, loss: 0.082, 19232/28000 datapoints
2025-03-07 10:11:12,453 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-07 10:11:12,893 - INFO - training batch 701, loss: 0.198, 22432/28000 datapoints
2025-03-07 10:11:13,537 - INFO - training batch 751, loss: 0.097, 24032/28000 datapoints
2025-03-07 10:11:14,001 - INFO - training batch 801, loss: 0.071, 25632/28000 datapoints
2025-03-07 10:11:14,876 - INFO - training batch 851, loss: 0.080, 27232/28000 datapoints
2025-03-07 10:11:15,300 - INFO - validation batch 1, loss: 0.220, 32/6976 datapoints
2025-03-07 10:11:15,564 - INFO - validation batch 51, loss: 1.580, 1632/6976 datapoints
2025-03-07 10:11:16,001 - INFO - validation batch 101, loss: 0.579, 3232/6976 datapoints
2025-03-07 10:11:16,431 - INFO - validation batch 151, loss: 0.245, 4832/6976 datapoints
2025-03-07 10:11:16,950 - INFO - validation batch 201, loss: 1.063, 6432/6976 datapoints
2025-03-07 10:11:17,053 - INFO - Epoch 179/800 done.
2025-03-07 10:11:17,058 - INFO - Final validation performance:
Loss: 0.738, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:11:17,073 - INFO - Beginning epoch 180/800
2025-03-07 10:11:17,129 - INFO - training batch 1, loss: 0.126, 32/28000 datapoints
2025-03-07 10:11:18,321 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-07 10:11:18,909 - INFO - training batch 101, loss: 0.061, 3232/28000 datapoints
2025-03-07 10:11:19,332 - INFO - training batch 151, loss: 0.056, 4832/28000 datapoints
2025-03-07 10:11:19,655 - INFO - training batch 201, loss: 0.066, 6432/28000 datapoints
2025-03-07 10:11:19,957 - INFO - training batch 251, loss: 0.176, 8032/28000 datapoints
2025-03-07 10:11:20,223 - INFO - training batch 301, loss: 0.355, 9632/28000 datapoints
2025-03-07 10:11:20,514 - INFO - training batch 351, loss: 0.203, 11232/28000 datapoints
2025-03-07 10:11:20,803 - INFO - training batch 401, loss: 0.187, 12832/28000 datapoints
2025-03-07 10:11:21,153 - INFO - training batch 451, loss: 0.211, 14432/28000 datapoints
2025-03-07 10:11:21,521 - INFO - training batch 501, loss: 0.085, 16032/28000 datapoints
2025-03-07 10:11:21,848 - INFO - training batch 551, loss: 0.119, 17632/28000 datapoints
2025-03-07 10:11:22,259 - INFO - training batch 601, loss: 0.078, 19232/28000 datapoints
2025-03-07 10:11:22,608 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-07 10:11:22,973 - INFO - training batch 701, loss: 0.195, 22432/28000 datapoints
2025-03-07 10:11:23,274 - INFO - training batch 751, loss: 0.097, 24032/28000 datapoints
2025-03-07 10:11:23,575 - INFO - training batch 801, loss: 0.069, 25632/28000 datapoints
2025-03-07 10:11:23,962 - INFO - training batch 851, loss: 0.078, 27232/28000 datapoints
2025-03-07 10:11:24,224 - INFO - validation batch 1, loss: 0.219, 32/6976 datapoints
2025-03-07 10:11:24,619 - INFO - validation batch 51, loss: 1.594, 1632/6976 datapoints
2025-03-07 10:11:24,917 - INFO - validation batch 101, loss: 0.582, 3232/6976 datapoints
2025-03-07 10:11:25,117 - INFO - validation batch 151, loss: 0.245, 4832/6976 datapoints
2025-03-07 10:11:25,341 - INFO - validation batch 201, loss: 1.068, 6432/6976 datapoints
2025-03-07 10:11:25,392 - INFO - Epoch 180/800 done.
2025-03-07 10:11:25,392 - INFO - Final validation performance:
Loss: 0.742, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:11:25,394 - INFO - Beginning epoch 181/800
2025-03-07 10:11:25,405 - INFO - training batch 1, loss: 0.122, 32/28000 datapoints
2025-03-07 10:11:25,757 - INFO - training batch 51, loss: 0.039, 1632/28000 datapoints
2025-03-07 10:11:26,178 - INFO - training batch 101, loss: 0.061, 3232/28000 datapoints
2025-03-07 10:11:26,488 - INFO - training batch 151, loss: 0.056, 4832/28000 datapoints
2025-03-07 10:11:26,742 - INFO - training batch 201, loss: 0.067, 6432/28000 datapoints
2025-03-07 10:11:27,008 - INFO - training batch 251, loss: 0.174, 8032/28000 datapoints
2025-03-07 10:11:27,258 - INFO - training batch 301, loss: 0.347, 9632/28000 datapoints
2025-03-07 10:11:27,611 - INFO - training batch 351, loss: 0.203, 11232/28000 datapoints
2025-03-07 10:11:27,914 - INFO - training batch 401, loss: 0.183, 12832/28000 datapoints
2025-03-07 10:11:28,170 - INFO - training batch 451, loss: 0.206, 14432/28000 datapoints
2025-03-07 10:11:28,432 - INFO - training batch 501, loss: 0.083, 16032/28000 datapoints
2025-03-07 10:11:28,698 - INFO - training batch 551, loss: 0.119, 17632/28000 datapoints
2025-03-07 10:11:28,937 - INFO - training batch 601, loss: 0.080, 19232/28000 datapoints
2025-03-07 10:11:29,186 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-07 10:11:29,426 - INFO - training batch 701, loss: 0.191, 22432/28000 datapoints
2025-03-07 10:11:29,701 - INFO - training batch 751, loss: 0.096, 24032/28000 datapoints
2025-03-07 10:11:29,997 - INFO - training batch 801, loss: 0.068, 25632/28000 datapoints
2025-03-07 10:11:30,248 - INFO - training batch 851, loss: 0.077, 27232/28000 datapoints
2025-03-07 10:11:30,603 - INFO - validation batch 1, loss: 0.222, 32/6976 datapoints
2025-03-07 10:11:30,749 - INFO - validation batch 51, loss: 1.596, 1632/6976 datapoints
2025-03-07 10:11:30,899 - INFO - validation batch 101, loss: 0.588, 3232/6976 datapoints
2025-03-07 10:11:31,029 - INFO - validation batch 151, loss: 0.247, 4832/6976 datapoints
2025-03-07 10:11:31,197 - INFO - validation batch 201, loss: 1.078, 6432/6976 datapoints
2025-03-07 10:11:31,241 - INFO - Epoch 181/800 done.
2025-03-07 10:11:31,242 - INFO - Final validation performance:
Loss: 0.746, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:11:31,244 - INFO - Beginning epoch 182/800
2025-03-07 10:11:31,255 - INFO - training batch 1, loss: 0.122, 32/28000 datapoints
2025-03-07 10:11:31,722 - INFO - training batch 51, loss: 0.038, 1632/28000 datapoints
2025-03-07 10:11:32,087 - INFO - training batch 101, loss: 0.059, 3232/28000 datapoints
2025-03-07 10:11:32,367 - INFO - training batch 151, loss: 0.055, 4832/28000 datapoints
2025-03-07 10:11:32,674 - INFO - training batch 201, loss: 0.066, 6432/28000 datapoints
2025-03-07 10:11:32,946 - INFO - training batch 251, loss: 0.171, 8032/28000 datapoints
2025-03-07 10:11:33,204 - INFO - training batch 301, loss: 0.338, 9632/28000 datapoints
2025-03-07 10:11:33,467 - INFO - training batch 351, loss: 0.201, 11232/28000 datapoints
2025-03-07 10:11:33,715 - INFO - training batch 401, loss: 0.183, 12832/28000 datapoints
2025-03-07 10:11:33,992 - INFO - training batch 451, loss: 0.202, 14432/28000 datapoints
2025-03-07 10:11:34,290 - INFO - training batch 501, loss: 0.082, 16032/28000 datapoints
2025-03-07 10:11:34,552 - INFO - training batch 551, loss: 0.118, 17632/28000 datapoints
2025-03-07 10:11:34,823 - INFO - training batch 601, loss: 0.076, 19232/28000 datapoints
2025-03-07 10:11:35,101 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-07 10:11:35,364 - INFO - training batch 701, loss: 0.186, 22432/28000 datapoints
2025-03-07 10:11:35,600 - INFO - training batch 751, loss: 0.096, 24032/28000 datapoints
2025-03-07 10:11:35,982 - INFO - training batch 801, loss: 0.067, 25632/28000 datapoints
2025-03-07 10:11:36,229 - INFO - training batch 851, loss: 0.076, 27232/28000 datapoints
2025-03-07 10:11:36,355 - INFO - validation batch 1, loss: 0.222, 32/6976 datapoints
2025-03-07 10:11:36,434 - INFO - validation batch 51, loss: 1.607, 1632/6976 datapoints
2025-03-07 10:11:36,504 - INFO - validation batch 101, loss: 0.591, 3232/6976 datapoints
2025-03-07 10:11:36,577 - INFO - validation batch 151, loss: 0.243, 4832/6976 datapoints
2025-03-07 10:11:36,649 - INFO - validation batch 201, loss: 1.088, 6432/6976 datapoints
2025-03-07 10:11:36,676 - INFO - Epoch 182/800 done.
2025-03-07 10:11:36,676 - INFO - Final validation performance:
Loss: 0.750, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:11:36,677 - INFO - Beginning epoch 183/800
2025-03-07 10:11:36,685 - INFO - training batch 1, loss: 0.121, 32/28000 datapoints
2025-03-07 10:11:36,934 - INFO - training batch 51, loss: 0.037, 1632/28000 datapoints
2025-03-07 10:11:37,183 - INFO - training batch 101, loss: 0.059, 3232/28000 datapoints
2025-03-07 10:11:37,436 - INFO - training batch 151, loss: 0.054, 4832/28000 datapoints
2025-03-07 10:11:37,678 - INFO - training batch 201, loss: 0.065, 6432/28000 datapoints
2025-03-07 10:11:37,912 - INFO - training batch 251, loss: 0.170, 8032/28000 datapoints
2025-03-07 10:11:38,177 - INFO - training batch 301, loss: 0.327, 9632/28000 datapoints
2025-03-07 10:11:38,455 - INFO - training batch 351, loss: 0.203, 11232/28000 datapoints
2025-03-07 10:11:38,702 - INFO - training batch 401, loss: 0.180, 12832/28000 datapoints
2025-03-07 10:11:38,943 - INFO - training batch 451, loss: 0.198, 14432/28000 datapoints
2025-03-07 10:11:39,178 - INFO - training batch 501, loss: 0.080, 16032/28000 datapoints
2025-03-07 10:11:39,442 - INFO - training batch 551, loss: 0.115, 17632/28000 datapoints
2025-03-07 10:11:39,687 - INFO - training batch 601, loss: 0.075, 19232/28000 datapoints
2025-03-07 10:11:39,961 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-07 10:11:40,250 - INFO - training batch 701, loss: 0.184, 22432/28000 datapoints
2025-03-07 10:11:40,487 - INFO - training batch 751, loss: 0.095, 24032/28000 datapoints
2025-03-07 10:11:40,714 - INFO - training batch 801, loss: 0.066, 25632/28000 datapoints
2025-03-07 10:11:40,980 - INFO - training batch 851, loss: 0.074, 27232/28000 datapoints
2025-03-07 10:11:41,140 - INFO - validation batch 1, loss: 0.224, 32/6976 datapoints
2025-03-07 10:11:41,232 - INFO - validation batch 51, loss: 1.617, 1632/6976 datapoints
2025-03-07 10:11:41,329 - INFO - validation batch 101, loss: 0.595, 3232/6976 datapoints
2025-03-07 10:11:41,436 - INFO - validation batch 151, loss: 0.245, 4832/6976 datapoints
2025-03-07 10:11:41,522 - INFO - validation batch 201, loss: 1.092, 6432/6976 datapoints
2025-03-07 10:11:41,554 - INFO - Epoch 183/800 done.
2025-03-07 10:11:41,555 - INFO - Final validation performance:
Loss: 0.755, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:11:41,555 - INFO - Beginning epoch 184/800
2025-03-07 10:11:41,565 - INFO - training batch 1, loss: 0.119, 32/28000 datapoints
2025-03-07 10:11:41,828 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-07 10:11:42,085 - INFO - training batch 101, loss: 0.056, 3232/28000 datapoints
2025-03-07 10:11:42,360 - INFO - training batch 151, loss: 0.052, 4832/28000 datapoints
2025-03-07 10:11:42,633 - INFO - training batch 201, loss: 0.063, 6432/28000 datapoints
2025-03-07 10:11:42,888 - INFO - training batch 251, loss: 0.167, 8032/28000 datapoints
2025-03-07 10:11:43,159 - INFO - training batch 301, loss: 0.319, 9632/28000 datapoints
2025-03-07 10:11:43,423 - INFO - training batch 351, loss: 0.202, 11232/28000 datapoints
2025-03-07 10:11:43,660 - INFO - training batch 401, loss: 0.174, 12832/28000 datapoints
2025-03-07 10:11:43,917 - INFO - training batch 451, loss: 0.197, 14432/28000 datapoints
2025-03-07 10:11:44,170 - INFO - training batch 501, loss: 0.080, 16032/28000 datapoints
2025-03-07 10:11:44,428 - INFO - training batch 551, loss: 0.113, 17632/28000 datapoints
2025-03-07 10:11:44,672 - INFO - training batch 601, loss: 0.074, 19232/28000 datapoints
2025-03-07 10:11:44,906 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-07 10:11:45,139 - INFO - training batch 701, loss: 0.181, 22432/28000 datapoints
2025-03-07 10:11:45,374 - INFO - training batch 751, loss: 0.095, 24032/28000 datapoints
2025-03-07 10:11:45,602 - INFO - training batch 801, loss: 0.067, 25632/28000 datapoints
2025-03-07 10:11:45,830 - INFO - training batch 851, loss: 0.072, 27232/28000 datapoints
2025-03-07 10:11:45,943 - INFO - validation batch 1, loss: 0.225, 32/6976 datapoints
2025-03-07 10:11:46,008 - INFO - validation batch 51, loss: 1.626, 1632/6976 datapoints
2025-03-07 10:11:46,081 - INFO - validation batch 101, loss: 0.598, 3232/6976 datapoints
2025-03-07 10:11:46,147 - INFO - validation batch 151, loss: 0.243, 4832/6976 datapoints
2025-03-07 10:11:46,214 - INFO - validation batch 201, loss: 1.104, 6432/6976 datapoints
2025-03-07 10:11:46,237 - INFO - Epoch 184/800 done.
2025-03-07 10:11:46,238 - INFO - Final validation performance:
Loss: 0.759, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:11:46,238 - INFO - Beginning epoch 185/800
2025-03-07 10:11:46,247 - INFO - training batch 1, loss: 0.116, 32/28000 datapoints
2025-03-07 10:11:46,488 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-07 10:11:46,718 - INFO - training batch 101, loss: 0.055, 3232/28000 datapoints
2025-03-07 10:11:46,951 - INFO - training batch 151, loss: 0.052, 4832/28000 datapoints
2025-03-07 10:11:47,181 - INFO - training batch 201, loss: 0.063, 6432/28000 datapoints
2025-03-07 10:11:47,454 - INFO - training batch 251, loss: 0.165, 8032/28000 datapoints
2025-03-07 10:11:47,692 - INFO - training batch 301, loss: 0.307, 9632/28000 datapoints
2025-03-07 10:11:47,936 - INFO - training batch 351, loss: 0.203, 11232/28000 datapoints
2025-03-07 10:11:48,170 - INFO - training batch 401, loss: 0.172, 12832/28000 datapoints
2025-03-07 10:11:48,437 - INFO - training batch 451, loss: 0.192, 14432/28000 datapoints
2025-03-07 10:11:48,702 - INFO - training batch 501, loss: 0.078, 16032/28000 datapoints
2025-03-07 10:11:48,958 - INFO - training batch 551, loss: 0.112, 17632/28000 datapoints
2025-03-07 10:11:49,208 - INFO - training batch 601, loss: 0.070, 19232/28000 datapoints
2025-03-07 10:11:49,447 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-07 10:11:49,684 - INFO - training batch 701, loss: 0.176, 22432/28000 datapoints
2025-03-07 10:11:49,955 - INFO - training batch 751, loss: 0.094, 24032/28000 datapoints
2025-03-07 10:11:50,323 - INFO - training batch 801, loss: 0.065, 25632/28000 datapoints
2025-03-07 10:11:50,621 - INFO - training batch 851, loss: 0.071, 27232/28000 datapoints
2025-03-07 10:11:50,768 - INFO - validation batch 1, loss: 0.228, 32/6976 datapoints
2025-03-07 10:11:50,858 - INFO - validation batch 51, loss: 1.632, 1632/6976 datapoints
2025-03-07 10:11:50,925 - INFO - validation batch 101, loss: 0.605, 3232/6976 datapoints
2025-03-07 10:11:50,996 - INFO - validation batch 151, loss: 0.248, 4832/6976 datapoints
2025-03-07 10:11:51,085 - INFO - validation batch 201, loss: 1.107, 6432/6976 datapoints
2025-03-07 10:11:51,120 - INFO - Epoch 185/800 done.
2025-03-07 10:11:51,120 - INFO - Final validation performance:
Loss: 0.764, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:11:51,121 - INFO - Beginning epoch 186/800
2025-03-07 10:11:51,130 - INFO - training batch 1, loss: 0.115, 32/28000 datapoints
2025-03-07 10:11:52,042 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-07 10:11:52,325 - INFO - training batch 101, loss: 0.053, 3232/28000 datapoints
2025-03-07 10:11:52,637 - INFO - training batch 151, loss: 0.051, 4832/28000 datapoints
2025-03-07 10:11:52,900 - INFO - training batch 201, loss: 0.062, 6432/28000 datapoints
2025-03-07 10:11:53,159 - INFO - training batch 251, loss: 0.162, 8032/28000 datapoints
2025-03-07 10:11:53,403 - INFO - training batch 301, loss: 0.297, 9632/28000 datapoints
2025-03-07 10:11:53,646 - INFO - training batch 351, loss: 0.202, 11232/28000 datapoints
2025-03-07 10:11:53,948 - INFO - training batch 401, loss: 0.167, 12832/28000 datapoints
2025-03-07 10:11:54,302 - INFO - training batch 451, loss: 0.189, 14432/28000 datapoints
2025-03-07 10:11:54,629 - INFO - training batch 501, loss: 0.076, 16032/28000 datapoints
2025-03-07 10:11:54,895 - INFO - training batch 551, loss: 0.109, 17632/28000 datapoints
2025-03-07 10:11:55,234 - INFO - training batch 601, loss: 0.067, 19232/28000 datapoints
2025-03-07 10:11:55,520 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-07 10:11:55,777 - INFO - training batch 701, loss: 0.172, 22432/28000 datapoints
2025-03-07 10:11:56,032 - INFO - training batch 751, loss: 0.093, 24032/28000 datapoints
2025-03-07 10:11:56,283 - INFO - training batch 801, loss: 0.064, 25632/28000 datapoints
2025-03-07 10:11:56,531 - INFO - training batch 851, loss: 0.069, 27232/28000 datapoints
2025-03-07 10:11:56,651 - INFO - validation batch 1, loss: 0.229, 32/6976 datapoints
2025-03-07 10:11:56,740 - INFO - validation batch 51, loss: 1.642, 1632/6976 datapoints
2025-03-07 10:11:56,809 - INFO - validation batch 101, loss: 0.609, 3232/6976 datapoints
2025-03-07 10:11:56,882 - INFO - validation batch 151, loss: 0.245, 4832/6976 datapoints
2025-03-07 10:11:56,951 - INFO - validation batch 201, loss: 1.114, 6432/6976 datapoints
2025-03-07 10:11:56,975 - INFO - Epoch 186/800 done.
2025-03-07 10:11:56,975 - INFO - Final validation performance:
Loss: 0.768, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:11:56,975 - INFO - Beginning epoch 187/800
2025-03-07 10:11:56,983 - INFO - training batch 1, loss: 0.113, 32/28000 datapoints
2025-03-07 10:11:57,318 - INFO - training batch 51, loss: 0.034, 1632/28000 datapoints
2025-03-07 10:11:57,650 - INFO - training batch 101, loss: 0.052, 3232/28000 datapoints
2025-03-07 10:11:58,003 - INFO - training batch 151, loss: 0.050, 4832/28000 datapoints
2025-03-07 10:11:58,354 - INFO - training batch 201, loss: 0.062, 6432/28000 datapoints
2025-03-07 10:11:58,669 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-07 10:11:59,032 - INFO - training batch 301, loss: 0.288, 9632/28000 datapoints
2025-03-07 10:11:59,340 - INFO - training batch 351, loss: 0.201, 11232/28000 datapoints
2025-03-07 10:11:59,623 - INFO - training batch 401, loss: 0.166, 12832/28000 datapoints
2025-03-07 10:11:59,873 - INFO - training batch 451, loss: 0.185, 14432/28000 datapoints
2025-03-07 10:12:00,134 - INFO - training batch 501, loss: 0.076, 16032/28000 datapoints
2025-03-07 10:12:00,434 - INFO - training batch 551, loss: 0.109, 17632/28000 datapoints
2025-03-07 10:12:00,725 - INFO - training batch 601, loss: 0.067, 19232/28000 datapoints
2025-03-07 10:12:00,996 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-07 10:12:01,377 - INFO - training batch 701, loss: 0.168, 22432/28000 datapoints
2025-03-07 10:12:01,751 - INFO - training batch 751, loss: 0.093, 24032/28000 datapoints
2025-03-07 10:12:02,159 - INFO - training batch 801, loss: 0.064, 25632/28000 datapoints
2025-03-07 10:12:02,522 - INFO - training batch 851, loss: 0.067, 27232/28000 datapoints
2025-03-07 10:12:02,684 - INFO - validation batch 1, loss: 0.232, 32/6976 datapoints
2025-03-07 10:12:02,797 - INFO - validation batch 51, loss: 1.658, 1632/6976 datapoints
2025-03-07 10:12:02,924 - INFO - validation batch 101, loss: 0.609, 3232/6976 datapoints
2025-03-07 10:12:03,035 - INFO - validation batch 151, loss: 0.242, 4832/6976 datapoints
2025-03-07 10:12:03,131 - INFO - validation batch 201, loss: 1.126, 6432/6976 datapoints
2025-03-07 10:12:03,168 - INFO - Epoch 187/800 done.
2025-03-07 10:12:03,168 - INFO - Final validation performance:
Loss: 0.773, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:12:03,169 - INFO - Beginning epoch 188/800
2025-03-07 10:12:03,178 - INFO - training batch 1, loss: 0.113, 32/28000 datapoints
2025-03-07 10:12:03,521 - INFO - training batch 51, loss: 0.033, 1632/28000 datapoints
2025-03-07 10:12:03,849 - INFO - training batch 101, loss: 0.051, 3232/28000 datapoints
2025-03-07 10:12:04,133 - INFO - training batch 151, loss: 0.049, 4832/28000 datapoints
2025-03-07 10:12:04,407 - INFO - training batch 201, loss: 0.061, 6432/28000 datapoints
2025-03-07 10:12:04,699 - INFO - training batch 251, loss: 0.156, 8032/28000 datapoints
2025-03-07 10:12:04,978 - INFO - training batch 301, loss: 0.278, 9632/28000 datapoints
2025-03-07 10:12:05,239 - INFO - training batch 351, loss: 0.198, 11232/28000 datapoints
2025-03-07 10:12:05,541 - INFO - training batch 401, loss: 0.161, 12832/28000 datapoints
2025-03-07 10:12:05,807 - INFO - training batch 451, loss: 0.181, 14432/28000 datapoints
2025-03-07 10:12:06,119 - INFO - training batch 501, loss: 0.074, 16032/28000 datapoints
2025-03-07 10:12:06,414 - INFO - training batch 551, loss: 0.106, 17632/28000 datapoints
2025-03-07 10:12:06,674 - INFO - training batch 601, loss: 0.066, 19232/28000 datapoints
2025-03-07 10:12:06,916 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-07 10:12:07,208 - INFO - training batch 701, loss: 0.165, 22432/28000 datapoints
2025-03-07 10:12:07,481 - INFO - training batch 751, loss: 0.092, 24032/28000 datapoints
2025-03-07 10:12:07,739 - INFO - training batch 801, loss: 0.063, 25632/28000 datapoints
2025-03-07 10:12:07,974 - INFO - training batch 851, loss: 0.066, 27232/28000 datapoints
2025-03-07 10:12:08,098 - INFO - validation batch 1, loss: 0.232, 32/6976 datapoints
2025-03-07 10:12:08,211 - INFO - validation batch 51, loss: 1.663, 1632/6976 datapoints
2025-03-07 10:12:08,352 - INFO - validation batch 101, loss: 0.616, 3232/6976 datapoints
2025-03-07 10:12:08,489 - INFO - validation batch 151, loss: 0.250, 4832/6976 datapoints
2025-03-07 10:12:08,612 - INFO - validation batch 201, loss: 1.131, 6432/6976 datapoints
2025-03-07 10:12:08,651 - INFO - Epoch 188/800 done.
2025-03-07 10:12:08,652 - INFO - Final validation performance:
Loss: 0.779, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:12:08,652 - INFO - Beginning epoch 189/800
2025-03-07 10:12:08,660 - INFO - training batch 1, loss: 0.110, 32/28000 datapoints
2025-03-07 10:12:09,116 - INFO - training batch 51, loss: 0.032, 1632/28000 datapoints
2025-03-07 10:12:09,411 - INFO - training batch 101, loss: 0.049, 3232/28000 datapoints
2025-03-07 10:12:09,686 - INFO - training batch 151, loss: 0.048, 4832/28000 datapoints
2025-03-07 10:12:09,955 - INFO - training batch 201, loss: 0.060, 6432/28000 datapoints
2025-03-07 10:12:10,291 - INFO - training batch 251, loss: 0.153, 8032/28000 datapoints
2025-03-07 10:12:10,602 - INFO - training batch 301, loss: 0.267, 9632/28000 datapoints
2025-03-07 10:12:10,929 - INFO - training batch 351, loss: 0.200, 11232/28000 datapoints
2025-03-07 10:12:11,222 - INFO - training batch 401, loss: 0.158, 12832/28000 datapoints
2025-03-07 10:12:11,599 - INFO - training batch 451, loss: 0.177, 14432/28000 datapoints
2025-03-07 10:12:11,947 - INFO - training batch 501, loss: 0.074, 16032/28000 datapoints
2025-03-07 10:12:12,275 - INFO - training batch 551, loss: 0.106, 17632/28000 datapoints
2025-03-07 10:12:12,651 - INFO - training batch 601, loss: 0.064, 19232/28000 datapoints
2025-03-07 10:12:12,930 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-07 10:12:13,195 - INFO - training batch 701, loss: 0.161, 22432/28000 datapoints
2025-03-07 10:12:13,438 - INFO - training batch 751, loss: 0.091, 24032/28000 datapoints
2025-03-07 10:12:13,706 - INFO - training batch 801, loss: 0.062, 25632/28000 datapoints
2025-03-07 10:12:14,095 - INFO - training batch 851, loss: 0.065, 27232/28000 datapoints
2025-03-07 10:12:14,262 - INFO - validation batch 1, loss: 0.234, 32/6976 datapoints
2025-03-07 10:12:14,362 - INFO - validation batch 51, loss: 1.675, 1632/6976 datapoints
2025-03-07 10:12:14,467 - INFO - validation batch 101, loss: 0.623, 3232/6976 datapoints
2025-03-07 10:12:14,573 - INFO - validation batch 151, loss: 0.246, 4832/6976 datapoints
2025-03-07 10:12:14,666 - INFO - validation batch 201, loss: 1.141, 6432/6976 datapoints
2025-03-07 10:12:14,703 - INFO - Epoch 189/800 done.
2025-03-07 10:12:14,703 - INFO - Final validation performance:
Loss: 0.784, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:12:14,704 - INFO - Beginning epoch 190/800
2025-03-07 10:12:14,712 - INFO - training batch 1, loss: 0.107, 32/28000 datapoints
2025-03-07 10:12:15,007 - INFO - training batch 51, loss: 0.032, 1632/28000 datapoints
2025-03-07 10:12:15,306 - INFO - training batch 101, loss: 0.048, 3232/28000 datapoints
2025-03-07 10:12:15,570 - INFO - training batch 151, loss: 0.047, 4832/28000 datapoints
2025-03-07 10:12:15,805 - INFO - training batch 201, loss: 0.058, 6432/28000 datapoints
2025-03-07 10:12:16,068 - INFO - training batch 251, loss: 0.153, 8032/28000 datapoints
2025-03-07 10:12:16,319 - INFO - training batch 301, loss: 0.255, 9632/28000 datapoints
2025-03-07 10:12:16,652 - INFO - training batch 351, loss: 0.198, 11232/28000 datapoints
2025-03-07 10:12:16,960 - INFO - training batch 401, loss: 0.155, 12832/28000 datapoints
2025-03-07 10:12:17,303 - INFO - training batch 451, loss: 0.173, 14432/28000 datapoints
2025-03-07 10:12:17,717 - INFO - training batch 501, loss: 0.072, 16032/28000 datapoints
2025-03-07 10:12:18,140 - INFO - training batch 551, loss: 0.104, 17632/28000 datapoints
2025-03-07 10:12:18,489 - INFO - training batch 601, loss: 0.063, 19232/28000 datapoints
2025-03-07 10:12:18,825 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-07 10:12:19,117 - INFO - training batch 701, loss: 0.156, 22432/28000 datapoints
2025-03-07 10:12:19,391 - INFO - training batch 751, loss: 0.091, 24032/28000 datapoints
2025-03-07 10:12:19,734 - INFO - training batch 801, loss: 0.062, 25632/28000 datapoints
2025-03-07 10:12:20,077 - INFO - training batch 851, loss: 0.064, 27232/28000 datapoints
2025-03-07 10:12:20,239 - INFO - validation batch 1, loss: 0.238, 32/6976 datapoints
2025-03-07 10:12:20,338 - INFO - validation batch 51, loss: 1.692, 1632/6976 datapoints
2025-03-07 10:12:20,450 - INFO - validation batch 101, loss: 0.624, 3232/6976 datapoints
2025-03-07 10:12:20,614 - INFO - validation batch 151, loss: 0.245, 4832/6976 datapoints
2025-03-07 10:12:20,729 - INFO - validation batch 201, loss: 1.142, 6432/6976 datapoints
2025-03-07 10:12:20,762 - INFO - Epoch 190/800 done.
2025-03-07 10:12:20,762 - INFO - Final validation performance:
Loss: 0.788, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:12:20,763 - INFO - Beginning epoch 191/800
2025-03-07 10:12:20,777 - INFO - training batch 1, loss: 0.106, 32/28000 datapoints
2025-03-07 10:12:21,279 - INFO - training batch 51, loss: 0.032, 1632/28000 datapoints
2025-03-07 10:12:21,647 - INFO - training batch 101, loss: 0.047, 3232/28000 datapoints
2025-03-07 10:12:22,156 - INFO - training batch 151, loss: 0.046, 4832/28000 datapoints
2025-03-07 10:12:22,482 - INFO - training batch 201, loss: 0.057, 6432/28000 datapoints
2025-03-07 10:12:22,784 - INFO - training batch 251, loss: 0.151, 8032/28000 datapoints
2025-03-07 10:12:23,141 - INFO - training batch 301, loss: 0.244, 9632/28000 datapoints
2025-03-07 10:12:23,426 - INFO - training batch 351, loss: 0.196, 11232/28000 datapoints
2025-03-07 10:12:23,696 - INFO - training batch 401, loss: 0.152, 12832/28000 datapoints
2025-03-07 10:12:23,998 - INFO - training batch 451, loss: 0.169, 14432/28000 datapoints
2025-03-07 10:12:24,282 - INFO - training batch 501, loss: 0.071, 16032/28000 datapoints
2025-03-07 10:12:24,576 - INFO - training batch 551, loss: 0.102, 17632/28000 datapoints
2025-03-07 10:12:24,829 - INFO - training batch 601, loss: 0.063, 19232/28000 datapoints
2025-03-07 10:12:25,098 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-07 10:12:25,371 - INFO - training batch 701, loss: 0.154, 22432/28000 datapoints
2025-03-07 10:12:25,614 - INFO - training batch 751, loss: 0.090, 24032/28000 datapoints
2025-03-07 10:12:25,855 - INFO - training batch 801, loss: 0.062, 25632/28000 datapoints
2025-03-07 10:12:26,089 - INFO - training batch 851, loss: 0.062, 27232/28000 datapoints
2025-03-07 10:12:26,206 - INFO - validation batch 1, loss: 0.239, 32/6976 datapoints
2025-03-07 10:12:26,309 - INFO - validation batch 51, loss: 1.695, 1632/6976 datapoints
2025-03-07 10:12:26,420 - INFO - validation batch 101, loss: 0.627, 3232/6976 datapoints
2025-03-07 10:12:26,497 - INFO - validation batch 151, loss: 0.252, 4832/6976 datapoints
2025-03-07 10:12:26,571 - INFO - validation batch 201, loss: 1.156, 6432/6976 datapoints
2025-03-07 10:12:26,615 - INFO - Epoch 191/800 done.
2025-03-07 10:12:26,616 - INFO - Final validation performance:
Loss: 0.794, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:12:26,616 - INFO - Beginning epoch 192/800
2025-03-07 10:12:26,624 - INFO - training batch 1, loss: 0.105, 32/28000 datapoints
2025-03-07 10:12:26,938 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-07 10:12:27,496 - INFO - training batch 101, loss: 0.046, 3232/28000 datapoints
2025-03-07 10:12:27,923 - INFO - training batch 151, loss: 0.045, 4832/28000 datapoints
2025-03-07 10:12:28,191 - INFO - training batch 201, loss: 0.057, 6432/28000 datapoints
2025-03-07 10:12:28,464 - INFO - training batch 251, loss: 0.148, 8032/28000 datapoints
2025-03-07 10:12:28,725 - INFO - training batch 301, loss: 0.235, 9632/28000 datapoints
2025-03-07 10:12:28,982 - INFO - training batch 351, loss: 0.196, 11232/28000 datapoints
2025-03-07 10:12:29,206 - INFO - training batch 401, loss: 0.150, 12832/28000 datapoints
2025-03-07 10:12:29,444 - INFO - training batch 451, loss: 0.164, 14432/28000 datapoints
2025-03-07 10:12:29,673 - INFO - training batch 501, loss: 0.071, 16032/28000 datapoints
2025-03-07 10:12:29,901 - INFO - training batch 551, loss: 0.100, 17632/28000 datapoints
2025-03-07 10:12:30,125 - INFO - training batch 601, loss: 0.059, 19232/28000 datapoints
2025-03-07 10:12:30,506 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-07 10:12:30,767 - INFO - training batch 701, loss: 0.150, 22432/28000 datapoints
2025-03-07 10:12:31,005 - INFO - training batch 751, loss: 0.089, 24032/28000 datapoints
2025-03-07 10:12:31,242 - INFO - training batch 801, loss: 0.061, 25632/28000 datapoints
2025-03-07 10:12:31,481 - INFO - training batch 851, loss: 0.062, 27232/28000 datapoints
2025-03-07 10:12:31,597 - INFO - validation batch 1, loss: 0.241, 32/6976 datapoints
2025-03-07 10:12:31,661 - INFO - validation batch 51, loss: 1.708, 1632/6976 datapoints
2025-03-07 10:12:31,726 - INFO - validation batch 101, loss: 0.631, 3232/6976 datapoints
2025-03-07 10:12:31,796 - INFO - validation batch 151, loss: 0.250, 4832/6976 datapoints
2025-03-07 10:12:31,867 - INFO - validation batch 201, loss: 1.158, 6432/6976 datapoints
2025-03-07 10:12:31,894 - INFO - Epoch 192/800 done.
2025-03-07 10:12:31,894 - INFO - Final validation performance:
Loss: 0.798, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:12:31,895 - INFO - Beginning epoch 193/800
2025-03-07 10:12:31,905 - INFO - training batch 1, loss: 0.101, 32/28000 datapoints
2025-03-07 10:12:32,218 - INFO - training batch 51, loss: 0.032, 1632/28000 datapoints
2025-03-07 10:12:32,539 - INFO - training batch 101, loss: 0.045, 3232/28000 datapoints
2025-03-07 10:12:32,929 - INFO - training batch 151, loss: 0.044, 4832/28000 datapoints
2025-03-07 10:12:33,223 - INFO - training batch 201, loss: 0.056, 6432/28000 datapoints
2025-03-07 10:12:33,524 - INFO - training batch 251, loss: 0.145, 8032/28000 datapoints
2025-03-07 10:12:33,806 - INFO - training batch 301, loss: 0.226, 9632/28000 datapoints
2025-03-07 10:12:34,079 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-07 10:12:34,369 - INFO - training batch 401, loss: 0.148, 12832/28000 datapoints
2025-03-07 10:12:34,660 - INFO - training batch 451, loss: 0.159, 14432/28000 datapoints
2025-03-07 10:12:34,990 - INFO - training batch 501, loss: 0.070, 16032/28000 datapoints
2025-03-07 10:12:35,315 - INFO - training batch 551, loss: 0.100, 17632/28000 datapoints
2025-03-07 10:12:35,577 - INFO - training batch 601, loss: 0.061, 19232/28000 datapoints
2025-03-07 10:12:35,824 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-07 10:12:36,117 - INFO - training batch 701, loss: 0.146, 22432/28000 datapoints
2025-03-07 10:12:36,387 - INFO - training batch 751, loss: 0.089, 24032/28000 datapoints
2025-03-07 10:12:36,680 - INFO - training batch 801, loss: 0.061, 25632/28000 datapoints
2025-03-07 10:12:36,963 - INFO - training batch 851, loss: 0.060, 27232/28000 datapoints
2025-03-07 10:12:37,129 - INFO - validation batch 1, loss: 0.244, 32/6976 datapoints
2025-03-07 10:12:37,222 - INFO - validation batch 51, loss: 1.717, 1632/6976 datapoints
2025-03-07 10:12:37,309 - INFO - validation batch 101, loss: 0.637, 3232/6976 datapoints
2025-03-07 10:12:37,380 - INFO - validation batch 151, loss: 0.252, 4832/6976 datapoints
2025-03-07 10:12:37,461 - INFO - validation batch 201, loss: 1.171, 6432/6976 datapoints
2025-03-07 10:12:37,492 - INFO - Epoch 193/800 done.
2025-03-07 10:12:37,493 - INFO - Final validation performance:
Loss: 0.804, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:12:37,494 - INFO - Beginning epoch 194/800
2025-03-07 10:12:37,506 - INFO - training batch 1, loss: 0.100, 32/28000 datapoints
2025-03-07 10:12:37,767 - INFO - training batch 51, loss: 0.030, 1632/28000 datapoints
2025-03-07 10:12:38,005 - INFO - training batch 101, loss: 0.043, 3232/28000 datapoints
2025-03-07 10:12:38,234 - INFO - training batch 151, loss: 0.043, 4832/28000 datapoints
2025-03-07 10:12:38,481 - INFO - training batch 201, loss: 0.054, 6432/28000 datapoints
2025-03-07 10:12:38,714 - INFO - training batch 251, loss: 0.140, 8032/28000 datapoints
2025-03-07 10:12:38,954 - INFO - training batch 301, loss: 0.217, 9632/28000 datapoints
2025-03-07 10:12:39,207 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-07 10:12:39,452 - INFO - training batch 401, loss: 0.145, 12832/28000 datapoints
2025-03-07 10:12:39,692 - INFO - training batch 451, loss: 0.155, 14432/28000 datapoints
2025-03-07 10:12:39,929 - INFO - training batch 501, loss: 0.069, 16032/28000 datapoints
2025-03-07 10:12:40,157 - INFO - training batch 551, loss: 0.099, 17632/28000 datapoints
2025-03-07 10:12:40,400 - INFO - training batch 601, loss: 0.059, 19232/28000 datapoints
2025-03-07 10:12:40,630 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-07 10:12:40,886 - INFO - training batch 701, loss: 0.143, 22432/28000 datapoints
2025-03-07 10:12:41,138 - INFO - training batch 751, loss: 0.088, 24032/28000 datapoints
2025-03-07 10:12:41,411 - INFO - training batch 801, loss: 0.060, 25632/28000 datapoints
2025-03-07 10:12:41,842 - INFO - training batch 851, loss: 0.060, 27232/28000 datapoints
2025-03-07 10:12:41,973 - INFO - validation batch 1, loss: 0.239, 32/6976 datapoints
2025-03-07 10:12:42,047 - INFO - validation batch 51, loss: 1.745, 1632/6976 datapoints
2025-03-07 10:12:42,116 - INFO - validation batch 101, loss: 0.635, 3232/6976 datapoints
2025-03-07 10:12:42,191 - INFO - validation batch 151, loss: 0.247, 4832/6976 datapoints
2025-03-07 10:12:42,266 - INFO - validation batch 201, loss: 1.175, 6432/6976 datapoints
2025-03-07 10:12:42,295 - INFO - Epoch 194/800 done.
2025-03-07 10:12:42,295 - INFO - Final validation performance:
Loss: 0.808, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:12:42,296 - INFO - Beginning epoch 195/800
2025-03-07 10:12:42,306 - INFO - training batch 1, loss: 0.100, 32/28000 datapoints
2025-03-07 10:12:42,697 - INFO - training batch 51, loss: 0.030, 1632/28000 datapoints
2025-03-07 10:12:43,049 - INFO - training batch 101, loss: 0.042, 3232/28000 datapoints
2025-03-07 10:12:43,374 - INFO - training batch 151, loss: 0.041, 4832/28000 datapoints
2025-03-07 10:12:43,649 - INFO - training batch 201, loss: 0.054, 6432/28000 datapoints
2025-03-07 10:12:43,936 - INFO - training batch 251, loss: 0.139, 8032/28000 datapoints
2025-03-07 10:12:44,212 - INFO - training batch 301, loss: 0.207, 9632/28000 datapoints
2025-03-07 10:12:44,479 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-07 10:12:44,766 - INFO - training batch 401, loss: 0.140, 12832/28000 datapoints
2025-03-07 10:12:45,009 - INFO - training batch 451, loss: 0.151, 14432/28000 datapoints
2025-03-07 10:12:45,262 - INFO - training batch 501, loss: 0.068, 16032/28000 datapoints
2025-03-07 10:12:45,551 - INFO - training batch 551, loss: 0.096, 17632/28000 datapoints
2025-03-07 10:12:45,818 - INFO - training batch 601, loss: 0.058, 19232/28000 datapoints
2025-03-07 10:12:46,114 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-07 10:12:46,349 - INFO - training batch 701, loss: 0.138, 22432/28000 datapoints
2025-03-07 10:12:46,599 - INFO - training batch 751, loss: 0.088, 24032/28000 datapoints
2025-03-07 10:12:46,988 - INFO - training batch 801, loss: 0.060, 25632/28000 datapoints
2025-03-07 10:12:47,351 - INFO - training batch 851, loss: 0.058, 27232/28000 datapoints
2025-03-07 10:12:47,677 - INFO - validation batch 1, loss: 0.245, 32/6976 datapoints
2025-03-07 10:12:48,147 - INFO - validation batch 51, loss: 1.742, 1632/6976 datapoints
2025-03-07 10:12:48,517 - INFO - validation batch 101, loss: 0.642, 3232/6976 datapoints
2025-03-07 10:12:48,721 - INFO - validation batch 151, loss: 0.250, 4832/6976 datapoints
2025-03-07 10:12:48,875 - INFO - validation batch 201, loss: 1.189, 6432/6976 datapoints
2025-03-07 10:12:48,912 - INFO - Epoch 195/800 done.
2025-03-07 10:12:48,913 - INFO - Final validation performance:
Loss: 0.814, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:12:48,914 - INFO - Beginning epoch 196/800
2025-03-07 10:12:48,924 - INFO - training batch 1, loss: 0.097, 32/28000 datapoints
2025-03-07 10:12:49,240 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-07 10:12:49,531 - INFO - training batch 101, loss: 0.041, 3232/28000 datapoints
2025-03-07 10:12:49,806 - INFO - training batch 151, loss: 0.041, 4832/28000 datapoints
2025-03-07 10:12:50,082 - INFO - training batch 201, loss: 0.054, 6432/28000 datapoints
2025-03-07 10:12:50,408 - INFO - training batch 251, loss: 0.136, 8032/28000 datapoints
2025-03-07 10:12:51,022 - INFO - training batch 301, loss: 0.199, 9632/28000 datapoints
2025-03-07 10:12:51,321 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-07 10:12:51,585 - INFO - training batch 401, loss: 0.138, 12832/28000 datapoints
2025-03-07 10:12:51,882 - INFO - training batch 451, loss: 0.147, 14432/28000 datapoints
2025-03-07 10:12:52,183 - INFO - training batch 501, loss: 0.068, 16032/28000 datapoints
2025-03-07 10:12:52,480 - INFO - training batch 551, loss: 0.096, 17632/28000 datapoints
2025-03-07 10:12:52,845 - INFO - training batch 601, loss: 0.058, 19232/28000 datapoints
2025-03-07 10:12:53,173 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-07 10:12:53,480 - INFO - training batch 701, loss: 0.135, 22432/28000 datapoints
2025-03-07 10:12:53,758 - INFO - training batch 751, loss: 0.087, 24032/28000 datapoints
2025-03-07 10:12:54,041 - INFO - training batch 801, loss: 0.059, 25632/28000 datapoints
2025-03-07 10:12:54,345 - INFO - training batch 851, loss: 0.058, 27232/28000 datapoints
2025-03-07 10:12:54,554 - INFO - validation batch 1, loss: 0.245, 32/6976 datapoints
2025-03-07 10:12:54,666 - INFO - validation batch 51, loss: 1.758, 1632/6976 datapoints
2025-03-07 10:12:54,812 - INFO - validation batch 101, loss: 0.647, 3232/6976 datapoints
2025-03-07 10:12:54,915 - INFO - validation batch 151, loss: 0.251, 4832/6976 datapoints
2025-03-07 10:12:55,015 - INFO - validation batch 201, loss: 1.196, 6432/6976 datapoints
2025-03-07 10:12:55,066 - INFO - Epoch 196/800 done.
2025-03-07 10:12:55,066 - INFO - Final validation performance:
Loss: 0.819, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:12:55,067 - INFO - Beginning epoch 197/800
2025-03-07 10:12:55,077 - INFO - training batch 1, loss: 0.095, 32/28000 datapoints
2025-03-07 10:12:55,490 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-07 10:12:55,805 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-07 10:12:56,112 - INFO - training batch 151, loss: 0.040, 4832/28000 datapoints
2025-03-07 10:12:56,471 - INFO - training batch 201, loss: 0.053, 6432/28000 datapoints
2025-03-07 10:12:56,974 - INFO - training batch 251, loss: 0.133, 8032/28000 datapoints
2025-03-07 10:12:57,476 - INFO - training batch 301, loss: 0.189, 9632/28000 datapoints
2025-03-07 10:12:58,097 - INFO - training batch 351, loss: 0.187, 11232/28000 datapoints
2025-03-07 10:12:58,955 - INFO - training batch 401, loss: 0.136, 12832/28000 datapoints
2025-03-07 10:12:59,342 - INFO - training batch 451, loss: 0.142, 14432/28000 datapoints
2025-03-07 10:12:59,706 - INFO - training batch 501, loss: 0.068, 16032/28000 datapoints
2025-03-07 10:13:00,073 - INFO - training batch 551, loss: 0.094, 17632/28000 datapoints
2025-03-07 10:13:00,439 - INFO - training batch 601, loss: 0.056, 19232/28000 datapoints
2025-03-07 10:13:01,067 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-07 10:13:01,506 - INFO - training batch 701, loss: 0.132, 22432/28000 datapoints
2025-03-07 10:13:01,843 - INFO - training batch 751, loss: 0.087, 24032/28000 datapoints
2025-03-07 10:13:02,291 - INFO - training batch 801, loss: 0.058, 25632/28000 datapoints
2025-03-07 10:13:02,688 - INFO - training batch 851, loss: 0.055, 27232/28000 datapoints
2025-03-07 10:13:02,854 - INFO - validation batch 1, loss: 0.249, 32/6976 datapoints
2025-03-07 10:13:03,000 - INFO - validation batch 51, loss: 1.771, 1632/6976 datapoints
2025-03-07 10:13:03,101 - INFO - validation batch 101, loss: 0.650, 3232/6976 datapoints
2025-03-07 10:13:03,214 - INFO - validation batch 151, loss: 0.248, 4832/6976 datapoints
2025-03-07 10:13:03,332 - INFO - validation batch 201, loss: 1.204, 6432/6976 datapoints
2025-03-07 10:13:03,370 - INFO - Epoch 197/800 done.
2025-03-07 10:13:03,371 - INFO - Final validation performance:
Loss: 0.824, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:13:03,372 - INFO - Beginning epoch 198/800
2025-03-07 10:13:03,384 - INFO - training batch 1, loss: 0.094, 32/28000 datapoints
2025-03-07 10:13:03,818 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-07 10:13:04,217 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-07 10:13:04,605 - INFO - training batch 151, loss: 0.039, 4832/28000 datapoints
2025-03-07 10:13:04,983 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-07 10:13:05,329 - INFO - training batch 251, loss: 0.129, 8032/28000 datapoints
2025-03-07 10:13:05,735 - INFO - training batch 301, loss: 0.183, 9632/28000 datapoints
2025-03-07 10:13:06,097 - INFO - training batch 351, loss: 0.188, 11232/28000 datapoints
2025-03-07 10:13:06,400 - INFO - training batch 401, loss: 0.132, 12832/28000 datapoints
2025-03-07 10:13:06,708 - INFO - training batch 451, loss: 0.137, 14432/28000 datapoints
2025-03-07 10:13:06,986 - INFO - training batch 501, loss: 0.065, 16032/28000 datapoints
2025-03-07 10:13:07,300 - INFO - training batch 551, loss: 0.093, 17632/28000 datapoints
2025-03-07 10:13:07,657 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-07 10:13:07,970 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-07 10:13:08,298 - INFO - training batch 701, loss: 0.125, 22432/28000 datapoints
2025-03-07 10:13:08,612 - INFO - training batch 751, loss: 0.086, 24032/28000 datapoints
2025-03-07 10:13:08,972 - INFO - training batch 801, loss: 0.056, 25632/28000 datapoints
2025-03-07 10:13:09,313 - INFO - training batch 851, loss: 0.055, 27232/28000 datapoints
2025-03-07 10:13:09,470 - INFO - validation batch 1, loss: 0.248, 32/6976 datapoints
2025-03-07 10:13:09,594 - INFO - validation batch 51, loss: 1.787, 1632/6976 datapoints
2025-03-07 10:13:09,708 - INFO - validation batch 101, loss: 0.648, 3232/6976 datapoints
2025-03-07 10:13:09,829 - INFO - validation batch 151, loss: 0.248, 4832/6976 datapoints
2025-03-07 10:13:09,925 - INFO - validation batch 201, loss: 1.214, 6432/6976 datapoints
2025-03-07 10:13:09,961 - INFO - Epoch 198/800 done.
2025-03-07 10:13:09,961 - INFO - Final validation performance:
Loss: 0.829, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:13:09,962 - INFO - Beginning epoch 199/800
2025-03-07 10:13:09,970 - INFO - training batch 1, loss: 0.092, 32/28000 datapoints
2025-03-07 10:13:10,250 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-07 10:13:10,520 - INFO - training batch 101, loss: 0.037, 3232/28000 datapoints
2025-03-07 10:13:10,777 - INFO - training batch 151, loss: 0.038, 4832/28000 datapoints
2025-03-07 10:13:11,036 - INFO - training batch 201, loss: 0.050, 6432/28000 datapoints
2025-03-07 10:13:11,325 - INFO - training batch 251, loss: 0.127, 8032/28000 datapoints
2025-03-07 10:13:11,587 - INFO - training batch 301, loss: 0.177, 9632/28000 datapoints
2025-03-07 10:13:11,849 - INFO - training batch 351, loss: 0.182, 11232/28000 datapoints
2025-03-07 10:13:12,114 - INFO - training batch 401, loss: 0.133, 12832/28000 datapoints
2025-03-07 10:13:12,389 - INFO - training batch 451, loss: 0.133, 14432/28000 datapoints
2025-03-07 10:13:12,668 - INFO - training batch 501, loss: 0.063, 16032/28000 datapoints
2025-03-07 10:13:12,968 - INFO - training batch 551, loss: 0.092, 17632/28000 datapoints
2025-03-07 10:13:13,240 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-07 10:13:13,540 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-07 10:13:13,815 - INFO - training batch 701, loss: 0.124, 22432/28000 datapoints
2025-03-07 10:13:14,079 - INFO - training batch 751, loss: 0.084, 24032/28000 datapoints
2025-03-07 10:13:14,360 - INFO - training batch 801, loss: 0.055, 25632/28000 datapoints
2025-03-07 10:13:14,627 - INFO - training batch 851, loss: 0.054, 27232/28000 datapoints
2025-03-07 10:13:14,758 - INFO - validation batch 1, loss: 0.249, 32/6976 datapoints
2025-03-07 10:13:14,830 - INFO - validation batch 51, loss: 1.795, 1632/6976 datapoints
2025-03-07 10:13:14,898 - INFO - validation batch 101, loss: 0.655, 3232/6976 datapoints
2025-03-07 10:13:14,976 - INFO - validation batch 151, loss: 0.253, 4832/6976 datapoints
2025-03-07 10:13:15,047 - INFO - validation batch 201, loss: 1.219, 6432/6976 datapoints
2025-03-07 10:13:15,075 - INFO - Epoch 199/800 done.
2025-03-07 10:13:15,075 - INFO - Final validation performance:
Loss: 0.834, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:13:15,076 - INFO - Beginning epoch 200/800
2025-03-07 10:13:15,083 - INFO - training batch 1, loss: 0.089, 32/28000 datapoints
2025-03-07 10:13:15,346 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-07 10:13:15,605 - INFO - training batch 101, loss: 0.035, 3232/28000 datapoints
2025-03-07 10:13:15,853 - INFO - training batch 151, loss: 0.037, 4832/28000 datapoints
2025-03-07 10:13:16,110 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-07 10:13:16,358 - INFO - training batch 251, loss: 0.126, 8032/28000 datapoints
2025-03-07 10:13:16,612 - INFO - training batch 301, loss: 0.168, 9632/28000 datapoints
2025-03-07 10:13:16,851 - INFO - training batch 351, loss: 0.184, 11232/28000 datapoints
2025-03-07 10:13:17,085 - INFO - training batch 401, loss: 0.130, 12832/28000 datapoints
2025-03-07 10:13:17,399 - INFO - training batch 451, loss: 0.128, 14432/28000 datapoints
2025-03-07 10:13:17,762 - INFO - training batch 501, loss: 0.064, 16032/28000 datapoints
2025-03-07 10:13:18,032 - INFO - training batch 551, loss: 0.091, 17632/28000 datapoints
2025-03-07 10:13:18,263 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-07 10:13:18,496 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-07 10:13:18,728 - INFO - training batch 701, loss: 0.117, 22432/28000 datapoints
2025-03-07 10:13:18,960 - INFO - training batch 751, loss: 0.084, 24032/28000 datapoints
2025-03-07 10:13:19,194 - INFO - training batch 801, loss: 0.054, 25632/28000 datapoints
2025-03-07 10:13:19,430 - INFO - training batch 851, loss: 0.053, 27232/28000 datapoints
2025-03-07 10:13:19,544 - INFO - validation batch 1, loss: 0.253, 32/6976 datapoints
2025-03-07 10:13:19,611 - INFO - validation batch 51, loss: 1.805, 1632/6976 datapoints
2025-03-07 10:13:19,682 - INFO - validation batch 101, loss: 0.658, 3232/6976 datapoints
2025-03-07 10:13:19,751 - INFO - validation batch 151, loss: 0.246, 4832/6976 datapoints
2025-03-07 10:13:19,816 - INFO - validation batch 201, loss: 1.228, 6432/6976 datapoints
2025-03-07 10:13:19,837 - INFO - Epoch 200/800 done.
2025-03-07 10:13:19,837 - INFO - Final validation performance:
Loss: 0.838, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:13:19,839 - INFO - Beginning epoch 201/800
2025-03-07 10:13:19,847 - INFO - training batch 1, loss: 0.087, 32/28000 datapoints
2025-03-07 10:13:20,095 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-07 10:13:20,329 - INFO - training batch 101, loss: 0.034, 3232/28000 datapoints
2025-03-07 10:13:20,562 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-07 10:13:20,790 - INFO - training batch 201, loss: 0.050, 6432/28000 datapoints
2025-03-07 10:13:21,016 - INFO - training batch 251, loss: 0.122, 8032/28000 datapoints
2025-03-07 10:13:21,241 - INFO - training batch 301, loss: 0.164, 9632/28000 datapoints
2025-03-07 10:13:21,510 - INFO - training batch 351, loss: 0.181, 11232/28000 datapoints
2025-03-07 10:13:21,746 - INFO - training batch 401, loss: 0.128, 12832/28000 datapoints
2025-03-07 10:13:21,973 - INFO - training batch 451, loss: 0.124, 14432/28000 datapoints
2025-03-07 10:13:22,220 - INFO - training batch 501, loss: 0.062, 16032/28000 datapoints
2025-03-07 10:13:22,467 - INFO - training batch 551, loss: 0.090, 17632/28000 datapoints
2025-03-07 10:13:22,702 - INFO - training batch 601, loss: 0.052, 19232/28000 datapoints
2025-03-07 10:13:22,940 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-07 10:13:23,223 - INFO - training batch 701, loss: 0.115, 22432/28000 datapoints
2025-03-07 10:13:23,509 - INFO - training batch 751, loss: 0.083, 24032/28000 datapoints
2025-03-07 10:13:23,754 - INFO - training batch 801, loss: 0.052, 25632/28000 datapoints
2025-03-07 10:13:23,995 - INFO - training batch 851, loss: 0.051, 27232/28000 datapoints
2025-03-07 10:13:24,115 - INFO - validation batch 1, loss: 0.252, 32/6976 datapoints
2025-03-07 10:13:24,182 - INFO - validation batch 51, loss: 1.818, 1632/6976 datapoints
2025-03-07 10:13:24,257 - INFO - validation batch 101, loss: 0.662, 3232/6976 datapoints
2025-03-07 10:13:24,338 - INFO - validation batch 151, loss: 0.251, 4832/6976 datapoints
2025-03-07 10:13:24,416 - INFO - validation batch 201, loss: 1.235, 6432/6976 datapoints
2025-03-07 10:13:24,443 - INFO - Epoch 201/800 done.
2025-03-07 10:13:24,443 - INFO - Final validation performance:
Loss: 0.844, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:13:24,444 - INFO - Beginning epoch 202/800
2025-03-07 10:13:24,451 - INFO - training batch 1, loss: 0.086, 32/28000 datapoints
2025-03-07 10:13:24,710 - INFO - training batch 51, loss: 0.026, 1632/28000 datapoints
2025-03-07 10:13:24,949 - INFO - training batch 101, loss: 0.033, 3232/28000 datapoints
2025-03-07 10:13:25,183 - INFO - training batch 151, loss: 0.035, 4832/28000 datapoints
2025-03-07 10:13:25,424 - INFO - training batch 201, loss: 0.049, 6432/28000 datapoints
2025-03-07 10:13:25,657 - INFO - training batch 251, loss: 0.119, 8032/28000 datapoints
2025-03-07 10:13:25,887 - INFO - training batch 301, loss: 0.158, 9632/28000 datapoints
2025-03-07 10:13:26,123 - INFO - training batch 351, loss: 0.178, 11232/28000 datapoints
2025-03-07 10:13:26,379 - INFO - training batch 401, loss: 0.125, 12832/28000 datapoints
2025-03-07 10:13:26,613 - INFO - training batch 451, loss: 0.119, 14432/28000 datapoints
2025-03-07 10:13:26,852 - INFO - training batch 501, loss: 0.062, 16032/28000 datapoints
2025-03-07 10:13:27,086 - INFO - training batch 551, loss: 0.089, 17632/28000 datapoints
2025-03-07 10:13:27,324 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-07 10:13:27,589 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-07 10:13:27,831 - INFO - training batch 701, loss: 0.111, 22432/28000 datapoints
2025-03-07 10:13:28,059 - INFO - training batch 751, loss: 0.082, 24032/28000 datapoints
2025-03-07 10:13:28,295 - INFO - training batch 801, loss: 0.052, 25632/28000 datapoints
2025-03-07 10:13:28,527 - INFO - training batch 851, loss: 0.049, 27232/28000 datapoints
2025-03-07 10:13:28,644 - INFO - validation batch 1, loss: 0.255, 32/6976 datapoints
2025-03-07 10:13:28,713 - INFO - validation batch 51, loss: 1.830, 1632/6976 datapoints
2025-03-07 10:13:28,787 - INFO - validation batch 101, loss: 0.664, 3232/6976 datapoints
2025-03-07 10:13:28,871 - INFO - validation batch 151, loss: 0.245, 4832/6976 datapoints
2025-03-07 10:13:28,968 - INFO - validation batch 201, loss: 1.247, 6432/6976 datapoints
2025-03-07 10:13:28,998 - INFO - Epoch 202/800 done.
2025-03-07 10:13:28,999 - INFO - Final validation performance:
Loss: 0.848, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:13:28,999 - INFO - Beginning epoch 203/800
2025-03-07 10:13:29,008 - INFO - training batch 1, loss: 0.084, 32/28000 datapoints
2025-03-07 10:13:29,333 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-07 10:13:29,615 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-07 10:13:29,974 - INFO - training batch 151, loss: 0.035, 4832/28000 datapoints
2025-03-07 10:13:30,258 - INFO - training batch 201, loss: 0.050, 6432/28000 datapoints
2025-03-07 10:13:30,791 - INFO - training batch 251, loss: 0.115, 8032/28000 datapoints
2025-03-07 10:13:31,097 - INFO - training batch 301, loss: 0.151, 9632/28000 datapoints
2025-03-07 10:13:31,553 - INFO - training batch 351, loss: 0.179, 11232/28000 datapoints
2025-03-07 10:13:31,805 - INFO - training batch 401, loss: 0.124, 12832/28000 datapoints
2025-03-07 10:13:32,105 - INFO - training batch 451, loss: 0.116, 14432/28000 datapoints
2025-03-07 10:13:32,412 - INFO - training batch 501, loss: 0.061, 16032/28000 datapoints
2025-03-07 10:13:32,714 - INFO - training batch 551, loss: 0.088, 17632/28000 datapoints
2025-03-07 10:13:32,995 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-07 10:13:33,262 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-07 10:13:33,547 - INFO - training batch 701, loss: 0.107, 22432/28000 datapoints
2025-03-07 10:13:33,800 - INFO - training batch 751, loss: 0.080, 24032/28000 datapoints
2025-03-07 10:13:34,045 - INFO - training batch 801, loss: 0.052, 25632/28000 datapoints
2025-03-07 10:13:34,285 - INFO - training batch 851, loss: 0.050, 27232/28000 datapoints
2025-03-07 10:13:34,405 - INFO - validation batch 1, loss: 0.253, 32/6976 datapoints
2025-03-07 10:13:34,475 - INFO - validation batch 51, loss: 1.846, 1632/6976 datapoints
2025-03-07 10:13:34,544 - INFO - validation batch 101, loss: 0.672, 3232/6976 datapoints
2025-03-07 10:13:34,608 - INFO - validation batch 151, loss: 0.247, 4832/6976 datapoints
2025-03-07 10:13:34,670 - INFO - validation batch 201, loss: 1.255, 6432/6976 datapoints
2025-03-07 10:13:34,691 - INFO - Epoch 203/800 done.
2025-03-07 10:13:34,692 - INFO - Final validation performance:
Loss: 0.855, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:13:34,692 - INFO - Beginning epoch 204/800
2025-03-07 10:13:34,700 - INFO - training batch 1, loss: 0.082, 32/28000 datapoints
2025-03-07 10:13:34,927 - INFO - training batch 51, loss: 0.026, 1632/28000 datapoints
2025-03-07 10:13:35,203 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-07 10:13:35,524 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-07 10:13:35,798 - INFO - training batch 201, loss: 0.049, 6432/28000 datapoints
2025-03-07 10:13:36,036 - INFO - training batch 251, loss: 0.112, 8032/28000 datapoints
2025-03-07 10:13:36,276 - INFO - training batch 301, loss: 0.145, 9632/28000 datapoints
2025-03-07 10:13:36,539 - INFO - training batch 351, loss: 0.175, 11232/28000 datapoints
2025-03-07 10:13:36,782 - INFO - training batch 401, loss: 0.121, 12832/28000 datapoints
2025-03-07 10:13:37,019 - INFO - training batch 451, loss: 0.110, 14432/28000 datapoints
2025-03-07 10:13:37,264 - INFO - training batch 501, loss: 0.059, 16032/28000 datapoints
2025-03-07 10:13:37,513 - INFO - training batch 551, loss: 0.086, 17632/28000 datapoints
2025-03-07 10:13:37,755 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-07 10:13:38,011 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-07 10:13:38,262 - INFO - training batch 701, loss: 0.103, 22432/28000 datapoints
2025-03-07 10:13:38,506 - INFO - training batch 751, loss: 0.079, 24032/28000 datapoints
2025-03-07 10:13:38,741 - INFO - training batch 801, loss: 0.049, 25632/28000 datapoints
2025-03-07 10:13:38,977 - INFO - training batch 851, loss: 0.047, 27232/28000 datapoints
2025-03-07 10:13:39,109 - INFO - validation batch 1, loss: 0.252, 32/6976 datapoints
2025-03-07 10:13:39,178 - INFO - validation batch 51, loss: 1.852, 1632/6976 datapoints
2025-03-07 10:13:39,252 - INFO - validation batch 101, loss: 0.675, 3232/6976 datapoints
2025-03-07 10:13:39,325 - INFO - validation batch 151, loss: 0.255, 4832/6976 datapoints
2025-03-07 10:13:39,407 - INFO - validation batch 201, loss: 1.263, 6432/6976 datapoints
2025-03-07 10:13:39,430 - INFO - Epoch 204/800 done.
2025-03-07 10:13:39,430 - INFO - Final validation performance:
Loss: 0.860, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:13:39,431 - INFO - Beginning epoch 205/800
2025-03-07 10:13:39,437 - INFO - training batch 1, loss: 0.081, 32/28000 datapoints
2025-03-07 10:13:39,679 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-07 10:13:39,925 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-07 10:13:40,167 - INFO - training batch 151, loss: 0.033, 4832/28000 datapoints
2025-03-07 10:13:40,401 - INFO - training batch 201, loss: 0.047, 6432/28000 datapoints
2025-03-07 10:13:40,639 - INFO - training batch 251, loss: 0.111, 8032/28000 datapoints
2025-03-07 10:13:40,872 - INFO - training batch 301, loss: 0.140, 9632/28000 datapoints
2025-03-07 10:13:41,101 - INFO - training batch 351, loss: 0.172, 11232/28000 datapoints
2025-03-07 10:13:41,343 - INFO - training batch 401, loss: 0.120, 12832/28000 datapoints
2025-03-07 10:13:41,613 - INFO - training batch 451, loss: 0.108, 14432/28000 datapoints
2025-03-07 10:13:41,850 - INFO - training batch 501, loss: 0.058, 16032/28000 datapoints
2025-03-07 10:13:42,079 - INFO - training batch 551, loss: 0.085, 17632/28000 datapoints
2025-03-07 10:13:42,330 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-07 10:13:42,618 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-07 10:13:42,895 - INFO - training batch 701, loss: 0.097, 22432/28000 datapoints
2025-03-07 10:13:43,176 - INFO - training batch 751, loss: 0.079, 24032/28000 datapoints
2025-03-07 10:13:43,568 - INFO - training batch 801, loss: 0.050, 25632/28000 datapoints
2025-03-07 10:13:44,078 - INFO - training batch 851, loss: 0.046, 27232/28000 datapoints
2025-03-07 10:13:44,319 - INFO - validation batch 1, loss: 0.261, 32/6976 datapoints
2025-03-07 10:13:44,452 - INFO - validation batch 51, loss: 1.866, 1632/6976 datapoints
2025-03-07 10:13:44,593 - INFO - validation batch 101, loss: 0.677, 3232/6976 datapoints
2025-03-07 10:13:44,726 - INFO - validation batch 151, loss: 0.250, 4832/6976 datapoints
2025-03-07 10:13:44,899 - INFO - validation batch 201, loss: 1.270, 6432/6976 datapoints
2025-03-07 10:13:44,927 - INFO - Epoch 205/800 done.
2025-03-07 10:13:44,927 - INFO - Final validation performance:
Loss: 0.865, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:13:44,928 - INFO - Beginning epoch 206/800
2025-03-07 10:13:44,937 - INFO - training batch 1, loss: 0.079, 32/28000 datapoints
2025-03-07 10:13:45,234 - INFO - training batch 51, loss: 0.024, 1632/28000 datapoints
2025-03-07 10:13:45,554 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-07 10:13:45,940 - INFO - training batch 151, loss: 0.033, 4832/28000 datapoints
2025-03-07 10:13:46,782 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-07 10:13:48,038 - INFO - training batch 251, loss: 0.105, 8032/28000 datapoints
2025-03-07 10:13:48,489 - INFO - training batch 301, loss: 0.132, 9632/28000 datapoints
2025-03-07 10:13:48,792 - INFO - training batch 351, loss: 0.171, 11232/28000 datapoints
2025-03-07 10:13:49,089 - INFO - training batch 401, loss: 0.117, 12832/28000 datapoints
2025-03-07 10:13:49,490 - INFO - training batch 451, loss: 0.104, 14432/28000 datapoints
2025-03-07 10:13:50,014 - INFO - training batch 501, loss: 0.057, 16032/28000 datapoints
2025-03-07 10:13:50,492 - INFO - training batch 551, loss: 0.084, 17632/28000 datapoints
2025-03-07 10:13:50,805 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-07 10:13:51,081 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-07 10:13:51,384 - INFO - training batch 701, loss: 0.094, 22432/28000 datapoints
2025-03-07 10:13:51,807 - INFO - training batch 751, loss: 0.077, 24032/28000 datapoints
2025-03-07 10:13:52,088 - INFO - training batch 801, loss: 0.049, 25632/28000 datapoints
2025-03-07 10:13:52,382 - INFO - training batch 851, loss: 0.045, 27232/28000 datapoints
2025-03-07 10:13:52,550 - INFO - validation batch 1, loss: 0.262, 32/6976 datapoints
2025-03-07 10:13:52,637 - INFO - validation batch 51, loss: 1.874, 1632/6976 datapoints
2025-03-07 10:13:52,715 - INFO - validation batch 101, loss: 0.683, 3232/6976 datapoints
2025-03-07 10:13:52,798 - INFO - validation batch 151, loss: 0.249, 4832/6976 datapoints
2025-03-07 10:13:52,953 - INFO - validation batch 201, loss: 1.282, 6432/6976 datapoints
2025-03-07 10:13:53,009 - INFO - Epoch 206/800 done.
2025-03-07 10:13:53,010 - INFO - Final validation performance:
Loss: 0.870, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:13:53,011 - INFO - Beginning epoch 207/800
2025-03-07 10:13:53,024 - INFO - training batch 1, loss: 0.076, 32/28000 datapoints
2025-03-07 10:13:53,936 - INFO - training batch 51, loss: 0.024, 1632/28000 datapoints
2025-03-07 10:13:55,582 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-07 10:13:58,032 - INFO - training batch 151, loss: 0.033, 4832/28000 datapoints
2025-03-07 10:13:59,708 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-07 10:14:00,855 - INFO - training batch 251, loss: 0.103, 8032/28000 datapoints
2025-03-07 10:14:02,828 - INFO - training batch 301, loss: 0.129, 9632/28000 datapoints
2025-03-07 10:14:03,800 - INFO - training batch 351, loss: 0.169, 11232/28000 datapoints
2025-03-07 10:14:04,777 - INFO - training batch 401, loss: 0.117, 12832/28000 datapoints
2025-03-07 10:14:05,791 - INFO - training batch 451, loss: 0.101, 14432/28000 datapoints
2025-03-07 10:14:06,486 - INFO - training batch 501, loss: 0.055, 16032/28000 datapoints
2025-03-07 10:14:07,368 - INFO - training batch 551, loss: 0.083, 17632/28000 datapoints
2025-03-07 10:14:09,057 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-07 10:14:10,897 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 10:14:14,882 - INFO - training batch 701, loss: 0.089, 22432/28000 datapoints
2025-03-07 10:14:16,080 - INFO - training batch 751, loss: 0.077, 24032/28000 datapoints
2025-03-07 10:14:17,131 - INFO - training batch 801, loss: 0.047, 25632/28000 datapoints
2025-03-07 10:14:18,240 - INFO - training batch 851, loss: 0.044, 27232/28000 datapoints
2025-03-07 10:14:18,497 - INFO - validation batch 1, loss: 0.262, 32/6976 datapoints
2025-03-07 10:14:18,660 - INFO - validation batch 51, loss: 1.893, 1632/6976 datapoints
2025-03-07 10:14:18,808 - INFO - validation batch 101, loss: 0.688, 3232/6976 datapoints
2025-03-07 10:14:18,943 - INFO - validation batch 151, loss: 0.254, 4832/6976 datapoints
2025-03-07 10:14:19,055 - INFO - validation batch 201, loss: 1.295, 6432/6976 datapoints
2025-03-07 10:14:19,091 - INFO - Epoch 207/800 done.
2025-03-07 10:14:19,091 - INFO - Final validation performance:
Loss: 0.878, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:14:19,094 - INFO - Beginning epoch 208/800
2025-03-07 10:14:19,117 - INFO - training batch 1, loss: 0.074, 32/28000 datapoints
2025-03-07 10:14:19,391 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-07 10:14:19,656 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-07 10:14:19,939 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-07 10:14:20,267 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-07 10:14:20,627 - INFO - training batch 251, loss: 0.098, 8032/28000 datapoints
2025-03-07 10:14:20,940 - INFO - training batch 301, loss: 0.125, 9632/28000 datapoints
2025-03-07 10:14:21,238 - INFO - training batch 351, loss: 0.168, 11232/28000 datapoints
2025-03-07 10:14:21,529 - INFO - training batch 401, loss: 0.115, 12832/28000 datapoints
2025-03-07 10:14:21,786 - INFO - training batch 451, loss: 0.096, 14432/28000 datapoints
2025-03-07 10:14:22,043 - INFO - training batch 501, loss: 0.053, 16032/28000 datapoints
2025-03-07 10:14:22,316 - INFO - training batch 551, loss: 0.081, 17632/28000 datapoints
2025-03-07 10:14:22,627 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-07 10:14:22,903 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 10:14:23,222 - INFO - training batch 701, loss: 0.083, 22432/28000 datapoints
2025-03-07 10:14:23,510 - INFO - training batch 751, loss: 0.076, 24032/28000 datapoints
2025-03-07 10:14:23,768 - INFO - training batch 801, loss: 0.046, 25632/28000 datapoints
2025-03-07 10:14:24,030 - INFO - training batch 851, loss: 0.042, 27232/28000 datapoints
2025-03-07 10:14:24,153 - INFO - validation batch 1, loss: 0.260, 32/6976 datapoints
2025-03-07 10:14:24,217 - INFO - validation batch 51, loss: 1.911, 1632/6976 datapoints
2025-03-07 10:14:24,287 - INFO - validation batch 101, loss: 0.692, 3232/6976 datapoints
2025-03-07 10:14:24,370 - INFO - validation batch 151, loss: 0.247, 4832/6976 datapoints
2025-03-07 10:14:24,448 - INFO - validation batch 201, loss: 1.308, 6432/6976 datapoints
2025-03-07 10:14:24,480 - INFO - Epoch 208/800 done.
2025-03-07 10:14:24,480 - INFO - Final validation performance:
Loss: 0.883, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:14:24,481 - INFO - Beginning epoch 209/800
2025-03-07 10:14:24,488 - INFO - training batch 1, loss: 0.073, 32/28000 datapoints
2025-03-07 10:14:24,775 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-07 10:14:25,283 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-07 10:14:25,944 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-07 10:14:26,249 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-07 10:14:26,535 - INFO - training batch 251, loss: 0.097, 8032/28000 datapoints
2025-03-07 10:14:26,848 - INFO - training batch 301, loss: 0.120, 9632/28000 datapoints
2025-03-07 10:14:27,106 - INFO - training batch 351, loss: 0.166, 11232/28000 datapoints
2025-03-07 10:14:27,358 - INFO - training batch 401, loss: 0.114, 12832/28000 datapoints
2025-03-07 10:14:27,618 - INFO - training batch 451, loss: 0.094, 14432/28000 datapoints
2025-03-07 10:14:27,987 - INFO - training batch 501, loss: 0.052, 16032/28000 datapoints
2025-03-07 10:14:28,460 - INFO - training batch 551, loss: 0.080, 17632/28000 datapoints
2025-03-07 10:14:30,003 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-07 10:14:30,472 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 10:14:30,821 - INFO - training batch 701, loss: 0.081, 22432/28000 datapoints
2025-03-07 10:14:31,187 - INFO - training batch 751, loss: 0.076, 24032/28000 datapoints
2025-03-07 10:14:31,555 - INFO - training batch 801, loss: 0.047, 25632/28000 datapoints
2025-03-07 10:14:31,879 - INFO - training batch 851, loss: 0.042, 27232/28000 datapoints
2025-03-07 10:14:32,042 - INFO - validation batch 1, loss: 0.267, 32/6976 datapoints
2025-03-07 10:14:32,143 - INFO - validation batch 51, loss: 1.927, 1632/6976 datapoints
2025-03-07 10:14:32,223 - INFO - validation batch 101, loss: 0.699, 3232/6976 datapoints
2025-03-07 10:14:32,293 - INFO - validation batch 151, loss: 0.247, 4832/6976 datapoints
2025-03-07 10:14:32,363 - INFO - validation batch 201, loss: 1.313, 6432/6976 datapoints
2025-03-07 10:14:32,389 - INFO - Epoch 209/800 done.
2025-03-07 10:14:32,389 - INFO - Final validation performance:
Loss: 0.891, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:14:32,390 - INFO - Beginning epoch 210/800
2025-03-07 10:14:32,396 - INFO - training batch 1, loss: 0.069, 32/28000 datapoints
2025-03-07 10:14:32,675 - INFO - training batch 51, loss: 0.022, 1632/28000 datapoints
2025-03-07 10:14:32,956 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-07 10:14:33,196 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-07 10:14:33,498 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-07 10:14:33,773 - INFO - training batch 251, loss: 0.093, 8032/28000 datapoints
2025-03-07 10:14:34,273 - INFO - training batch 301, loss: 0.115, 9632/28000 datapoints
2025-03-07 10:14:34,814 - INFO - training batch 351, loss: 0.161, 11232/28000 datapoints
2025-03-07 10:14:35,372 - INFO - training batch 401, loss: 0.110, 12832/28000 datapoints
2025-03-07 10:14:36,077 - INFO - training batch 451, loss: 0.091, 14432/28000 datapoints
2025-03-07 10:14:36,359 - INFO - training batch 501, loss: 0.051, 16032/28000 datapoints
2025-03-07 10:14:36,637 - INFO - training batch 551, loss: 0.079, 17632/28000 datapoints
2025-03-07 10:14:36,892 - INFO - training batch 601, loss: 0.044, 19232/28000 datapoints
2025-03-07 10:14:37,149 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 10:14:37,398 - INFO - training batch 701, loss: 0.075, 22432/28000 datapoints
2025-03-07 10:14:37,640 - INFO - training batch 751, loss: 0.074, 24032/28000 datapoints
2025-03-07 10:14:37,873 - INFO - training batch 801, loss: 0.044, 25632/28000 datapoints
2025-03-07 10:14:38,115 - INFO - training batch 851, loss: 0.040, 27232/28000 datapoints
2025-03-07 10:14:38,233 - INFO - validation batch 1, loss: 0.263, 32/6976 datapoints
2025-03-07 10:14:38,304 - INFO - validation batch 51, loss: 1.941, 1632/6976 datapoints
2025-03-07 10:14:38,376 - INFO - validation batch 101, loss: 0.698, 3232/6976 datapoints
2025-03-07 10:14:38,453 - INFO - validation batch 151, loss: 0.250, 4832/6976 datapoints
2025-03-07 10:14:38,531 - INFO - validation batch 201, loss: 1.329, 6432/6976 datapoints
2025-03-07 10:14:38,556 - INFO - Epoch 210/800 done.
2025-03-07 10:14:38,557 - INFO - Final validation performance:
Loss: 0.896, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:14:38,557 - INFO - Beginning epoch 211/800
2025-03-07 10:14:38,567 - INFO - training batch 1, loss: 0.069, 32/28000 datapoints
2025-03-07 10:14:38,820 - INFO - training batch 51, loss: 0.022, 1632/28000 datapoints
2025-03-07 10:14:39,073 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-07 10:14:39,346 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-07 10:14:39,656 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-07 10:14:39,908 - INFO - training batch 251, loss: 0.091, 8032/28000 datapoints
2025-03-07 10:14:40,162 - INFO - training batch 301, loss: 0.114, 9632/28000 datapoints
2025-03-07 10:14:40,403 - INFO - training batch 351, loss: 0.157, 11232/28000 datapoints
2025-03-07 10:14:41,041 - INFO - training batch 401, loss: 0.108, 12832/28000 datapoints
2025-03-07 10:14:42,292 - INFO - training batch 451, loss: 0.088, 14432/28000 datapoints
2025-03-07 10:14:43,460 - INFO - training batch 501, loss: 0.050, 16032/28000 datapoints
2025-03-07 10:14:43,781 - INFO - training batch 551, loss: 0.078, 17632/28000 datapoints
2025-03-07 10:14:44,187 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-07 10:14:44,464 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 10:14:44,746 - INFO - training batch 701, loss: 0.073, 22432/28000 datapoints
2025-03-07 10:14:45,153 - INFO - training batch 751, loss: 0.073, 24032/28000 datapoints
2025-03-07 10:14:45,596 - INFO - training batch 801, loss: 0.042, 25632/28000 datapoints
2025-03-07 10:14:46,950 - INFO - training batch 851, loss: 0.039, 27232/28000 datapoints
2025-03-07 10:14:47,723 - INFO - validation batch 1, loss: 0.265, 32/6976 datapoints
2025-03-07 10:14:47,873 - INFO - validation batch 51, loss: 1.955, 1632/6976 datapoints
2025-03-07 10:14:47,967 - INFO - validation batch 101, loss: 0.706, 3232/6976 datapoints
2025-03-07 10:14:48,049 - INFO - validation batch 151, loss: 0.241, 4832/6976 datapoints
2025-03-07 10:14:48,134 - INFO - validation batch 201, loss: 1.344, 6432/6976 datapoints
2025-03-07 10:14:48,165 - INFO - Epoch 211/800 done.
2025-03-07 10:14:48,165 - INFO - Final validation performance:
Loss: 0.902, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:14:48,166 - INFO - Beginning epoch 212/800
2025-03-07 10:14:48,177 - INFO - training batch 1, loss: 0.069, 32/28000 datapoints
2025-03-07 10:14:48,521 - INFO - training batch 51, loss: 0.021, 1632/28000 datapoints
2025-03-07 10:14:48,982 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-07 10:14:49,415 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-07 10:14:49,862 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-07 10:14:50,710 - INFO - training batch 251, loss: 0.086, 8032/28000 datapoints
2025-03-07 10:14:51,682 - INFO - training batch 301, loss: 0.108, 9632/28000 datapoints
2025-03-07 10:14:52,422 - INFO - training batch 351, loss: 0.155, 11232/28000 datapoints
2025-03-07 10:14:53,159 - INFO - training batch 401, loss: 0.106, 12832/28000 datapoints
2025-03-07 10:14:53,530 - INFO - training batch 451, loss: 0.084, 14432/28000 datapoints
2025-03-07 10:14:54,266 - INFO - training batch 501, loss: 0.049, 16032/28000 datapoints
2025-03-07 10:14:55,222 - INFO - training batch 551, loss: 0.076, 17632/28000 datapoints
2025-03-07 10:14:55,846 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-07 10:14:56,133 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 10:14:56,417 - INFO - training batch 701, loss: 0.069, 22432/28000 datapoints
2025-03-07 10:14:56,710 - INFO - training batch 751, loss: 0.071, 24032/28000 datapoints
2025-03-07 10:14:57,029 - INFO - training batch 801, loss: 0.044, 25632/28000 datapoints
2025-03-07 10:14:57,270 - INFO - training batch 851, loss: 0.038, 27232/28000 datapoints
2025-03-07 10:14:57,399 - INFO - validation batch 1, loss: 0.264, 32/6976 datapoints
2025-03-07 10:14:57,494 - INFO - validation batch 51, loss: 1.969, 1632/6976 datapoints
2025-03-07 10:14:57,590 - INFO - validation batch 101, loss: 0.712, 3232/6976 datapoints
2025-03-07 10:14:57,674 - INFO - validation batch 151, loss: 0.239, 4832/6976 datapoints
2025-03-07 10:14:57,747 - INFO - validation batch 201, loss: 1.353, 6432/6976 datapoints
2025-03-07 10:14:57,771 - INFO - Epoch 212/800 done.
2025-03-07 10:14:57,771 - INFO - Final validation performance:
Loss: 0.907, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:14:57,772 - INFO - Beginning epoch 213/800
2025-03-07 10:14:57,780 - INFO - training batch 1, loss: 0.065, 32/28000 datapoints
2025-03-07 10:14:58,071 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-07 10:14:58,333 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-07 10:14:58,583 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-07 10:14:58,867 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-07 10:14:59,457 - INFO - training batch 251, loss: 0.084, 8032/28000 datapoints
2025-03-07 10:14:59,954 - INFO - training batch 301, loss: 0.106, 9632/28000 datapoints
2025-03-07 10:15:00,444 - INFO - training batch 351, loss: 0.154, 11232/28000 datapoints
2025-03-07 10:15:00,841 - INFO - training batch 401, loss: 0.104, 12832/28000 datapoints
2025-03-07 10:15:01,164 - INFO - training batch 451, loss: 0.083, 14432/28000 datapoints
2025-03-07 10:15:01,503 - INFO - training batch 501, loss: 0.048, 16032/28000 datapoints
2025-03-07 10:15:01,866 - INFO - training batch 551, loss: 0.075, 17632/28000 datapoints
2025-03-07 10:15:03,009 - INFO - training batch 601, loss: 0.043, 19232/28000 datapoints
2025-03-07 10:15:03,765 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 10:15:04,070 - INFO - training batch 701, loss: 0.063, 22432/28000 datapoints
2025-03-07 10:15:04,363 - INFO - training batch 751, loss: 0.071, 24032/28000 datapoints
2025-03-07 10:15:04,695 - INFO - training batch 801, loss: 0.042, 25632/28000 datapoints
2025-03-07 10:15:05,099 - INFO - training batch 851, loss: 0.037, 27232/28000 datapoints
2025-03-07 10:15:05,326 - INFO - validation batch 1, loss: 0.263, 32/6976 datapoints
2025-03-07 10:15:05,473 - INFO - validation batch 51, loss: 1.985, 1632/6976 datapoints
2025-03-07 10:15:05,789 - INFO - validation batch 101, loss: 0.717, 3232/6976 datapoints
2025-03-07 10:15:06,682 - INFO - validation batch 151, loss: 0.238, 4832/6976 datapoints
2025-03-07 10:15:07,197 - INFO - validation batch 201, loss: 1.360, 6432/6976 datapoints
2025-03-07 10:15:07,484 - INFO - Epoch 213/800 done.
2025-03-07 10:15:07,486 - INFO - Final validation performance:
Loss: 0.913, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:15:07,495 - INFO - Beginning epoch 214/800
2025-03-07 10:15:07,528 - INFO - training batch 1, loss: 0.063, 32/28000 datapoints
2025-03-07 10:15:08,188 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-07 10:15:08,627 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-07 10:15:08,966 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-07 10:15:09,306 - INFO - training batch 201, loss: 0.043, 6432/28000 datapoints
2025-03-07 10:15:09,638 - INFO - training batch 251, loss: 0.081, 8032/28000 datapoints
2025-03-07 10:15:10,077 - INFO - training batch 301, loss: 0.103, 9632/28000 datapoints
2025-03-07 10:15:10,963 - INFO - training batch 351, loss: 0.152, 11232/28000 datapoints
2025-03-07 10:15:11,859 - INFO - training batch 401, loss: 0.101, 12832/28000 datapoints
2025-03-07 10:15:12,179 - INFO - training batch 451, loss: 0.077, 14432/28000 datapoints
2025-03-07 10:15:12,486 - INFO - training batch 501, loss: 0.046, 16032/28000 datapoints
2025-03-07 10:15:12,807 - INFO - training batch 551, loss: 0.073, 17632/28000 datapoints
2025-03-07 10:15:13,202 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-07 10:15:13,534 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 10:15:13,817 - INFO - training batch 701, loss: 0.061, 22432/28000 datapoints
2025-03-07 10:15:14,149 - INFO - training batch 751, loss: 0.071, 24032/28000 datapoints
2025-03-07 10:15:14,446 - INFO - training batch 801, loss: 0.040, 25632/28000 datapoints
2025-03-07 10:15:14,737 - INFO - training batch 851, loss: 0.035, 27232/28000 datapoints
2025-03-07 10:15:14,893 - INFO - validation batch 1, loss: 0.262, 32/6976 datapoints
2025-03-07 10:15:14,985 - INFO - validation batch 51, loss: 2.003, 1632/6976 datapoints
2025-03-07 10:15:15,067 - INFO - validation batch 101, loss: 0.721, 3232/6976 datapoints
2025-03-07 10:15:15,151 - INFO - validation batch 151, loss: 0.238, 4832/6976 datapoints
2025-03-07 10:15:15,308 - INFO - validation batch 201, loss: 1.377, 6432/6976 datapoints
2025-03-07 10:15:15,381 - INFO - Epoch 214/800 done.
2025-03-07 10:15:15,381 - INFO - Final validation performance:
Loss: 0.920, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:15:15,382 - INFO - Beginning epoch 215/800
2025-03-07 10:15:15,413 - INFO - training batch 1, loss: 0.063, 32/28000 datapoints
2025-03-07 10:15:15,925 - INFO - training batch 51, loss: 0.019, 1632/28000 datapoints
2025-03-07 10:15:16,759 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-07 10:15:17,381 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-07 10:15:19,023 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-07 10:15:19,625 - INFO - training batch 251, loss: 0.077, 8032/28000 datapoints
2025-03-07 10:15:21,109 - INFO - training batch 301, loss: 0.099, 9632/28000 datapoints
2025-03-07 10:15:23,191 - INFO - training batch 351, loss: 0.150, 11232/28000 datapoints
2025-03-07 10:15:24,240 - INFO - training batch 401, loss: 0.097, 12832/28000 datapoints
2025-03-07 10:15:27,481 - INFO - training batch 451, loss: 0.074, 14432/28000 datapoints
2025-03-07 10:15:28,374 - INFO - training batch 501, loss: 0.047, 16032/28000 datapoints
2025-03-07 10:15:28,711 - INFO - training batch 551, loss: 0.072, 17632/28000 datapoints
2025-03-07 10:15:29,087 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-07 10:15:29,429 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 10:15:29,771 - INFO - training batch 701, loss: 0.059, 22432/28000 datapoints
2025-03-07 10:15:30,961 - INFO - training batch 751, loss: 0.068, 24032/28000 datapoints
2025-03-07 10:15:32,048 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-07 10:15:32,370 - INFO - training batch 851, loss: 0.034, 27232/28000 datapoints
2025-03-07 10:15:32,534 - INFO - validation batch 1, loss: 0.267, 32/6976 datapoints
2025-03-07 10:15:32,673 - INFO - validation batch 51, loss: 2.016, 1632/6976 datapoints
2025-03-07 10:15:32,804 - INFO - validation batch 101, loss: 0.732, 3232/6976 datapoints
2025-03-07 10:15:32,911 - INFO - validation batch 151, loss: 0.243, 4832/6976 datapoints
2025-03-07 10:15:33,012 - INFO - validation batch 201, loss: 1.386, 6432/6976 datapoints
2025-03-07 10:15:33,049 - INFO - Epoch 215/800 done.
2025-03-07 10:15:33,049 - INFO - Final validation performance:
Loss: 0.929, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:15:33,053 - INFO - Beginning epoch 216/800
2025-03-07 10:15:33,063 - INFO - training batch 1, loss: 0.061, 32/28000 datapoints
2025-03-07 10:15:33,766 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-07 10:15:34,865 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-07 10:15:35,453 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-07 10:15:35,927 - INFO - training batch 201, loss: 0.042, 6432/28000 datapoints
2025-03-07 10:15:36,277 - INFO - training batch 251, loss: 0.076, 8032/28000 datapoints
2025-03-07 10:15:36,617 - INFO - training batch 301, loss: 0.095, 9632/28000 datapoints
2025-03-07 10:15:36,977 - INFO - training batch 351, loss: 0.149, 11232/28000 datapoints
2025-03-07 10:15:37,259 - INFO - training batch 401, loss: 0.096, 12832/28000 datapoints
2025-03-07 10:15:37,607 - INFO - training batch 451, loss: 0.072, 14432/28000 datapoints
2025-03-07 10:15:37,948 - INFO - training batch 501, loss: 0.044, 16032/28000 datapoints
2025-03-07 10:15:38,527 - INFO - training batch 551, loss: 0.070, 17632/28000 datapoints
2025-03-07 10:15:39,056 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-07 10:15:39,545 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 10:15:39,961 - INFO - training batch 701, loss: 0.055, 22432/28000 datapoints
2025-03-07 10:15:40,223 - INFO - training batch 751, loss: 0.067, 24032/28000 datapoints
2025-03-07 10:15:40,472 - INFO - training batch 801, loss: 0.038, 25632/28000 datapoints
2025-03-07 10:15:40,721 - INFO - training batch 851, loss: 0.033, 27232/28000 datapoints
2025-03-07 10:15:40,860 - INFO - validation batch 1, loss: 0.269, 32/6976 datapoints
2025-03-07 10:15:40,929 - INFO - validation batch 51, loss: 2.046, 1632/6976 datapoints
2025-03-07 10:15:41,011 - INFO - validation batch 101, loss: 0.732, 3232/6976 datapoints
2025-03-07 10:15:41,081 - INFO - validation batch 151, loss: 0.236, 4832/6976 datapoints
2025-03-07 10:15:41,169 - INFO - validation batch 201, loss: 1.397, 6432/6976 datapoints
2025-03-07 10:15:41,193 - INFO - Epoch 216/800 done.
2025-03-07 10:15:41,193 - INFO - Final validation performance:
Loss: 0.936, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:15:41,194 - INFO - Beginning epoch 217/800
2025-03-07 10:15:41,205 - INFO - training batch 1, loss: 0.060, 32/28000 datapoints
2025-03-07 10:15:41,472 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-07 10:15:41,726 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-07 10:15:42,008 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-07 10:15:42,270 - INFO - training batch 201, loss: 0.043, 6432/28000 datapoints
2025-03-07 10:15:42,534 - INFO - training batch 251, loss: 0.071, 8032/28000 datapoints
2025-03-07 10:15:42,813 - INFO - training batch 301, loss: 0.093, 9632/28000 datapoints
2025-03-07 10:15:43,126 - INFO - training batch 351, loss: 0.147, 11232/28000 datapoints
2025-03-07 10:15:43,412 - INFO - training batch 401, loss: 0.092, 12832/28000 datapoints
2025-03-07 10:15:43,704 - INFO - training batch 451, loss: 0.069, 14432/28000 datapoints
2025-03-07 10:15:44,413 - INFO - training batch 501, loss: 0.043, 16032/28000 datapoints
2025-03-07 10:15:45,092 - INFO - training batch 551, loss: 0.069, 17632/28000 datapoints
2025-03-07 10:15:45,892 - INFO - training batch 601, loss: 0.040, 19232/28000 datapoints
2025-03-07 10:15:46,219 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 10:15:46,470 - INFO - training batch 701, loss: 0.052, 22432/28000 datapoints
2025-03-07 10:15:46,730 - INFO - training batch 751, loss: 0.065, 24032/28000 datapoints
2025-03-07 10:15:46,981 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-07 10:15:47,241 - INFO - training batch 851, loss: 0.033, 27232/28000 datapoints
2025-03-07 10:15:47,367 - INFO - validation batch 1, loss: 0.271, 32/6976 datapoints
2025-03-07 10:15:47,444 - INFO - validation batch 51, loss: 2.045, 1632/6976 datapoints
2025-03-07 10:15:47,518 - INFO - validation batch 101, loss: 0.743, 3232/6976 datapoints
2025-03-07 10:15:47,592 - INFO - validation batch 151, loss: 0.246, 4832/6976 datapoints
2025-03-07 10:15:47,667 - INFO - validation batch 201, loss: 1.413, 6432/6976 datapoints
2025-03-07 10:15:47,689 - INFO - Epoch 217/800 done.
2025-03-07 10:15:47,690 - INFO - Final validation performance:
Loss: 0.943, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:15:47,690 - INFO - Beginning epoch 218/800
2025-03-07 10:15:47,698 - INFO - training batch 1, loss: 0.058, 32/28000 datapoints
2025-03-07 10:15:47,957 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-07 10:15:48,222 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-07 10:15:48,476 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-07 10:15:48,710 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-07 10:15:48,944 - INFO - training batch 251, loss: 0.068, 8032/28000 datapoints
2025-03-07 10:15:49,181 - INFO - training batch 301, loss: 0.089, 9632/28000 datapoints
2025-03-07 10:15:49,417 - INFO - training batch 351, loss: 0.145, 11232/28000 datapoints
2025-03-07 10:15:49,645 - INFO - training batch 401, loss: 0.090, 12832/28000 datapoints
2025-03-07 10:15:49,896 - INFO - training batch 451, loss: 0.066, 14432/28000 datapoints
2025-03-07 10:15:50,150 - INFO - training batch 501, loss: 0.042, 16032/28000 datapoints
2025-03-07 10:15:50,409 - INFO - training batch 551, loss: 0.068, 17632/28000 datapoints
2025-03-07 10:15:50,641 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-07 10:15:50,981 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 10:15:51,534 - INFO - training batch 701, loss: 0.051, 22432/28000 datapoints
2025-03-07 10:15:51,926 - INFO - training batch 751, loss: 0.062, 24032/28000 datapoints
2025-03-07 10:15:52,178 - INFO - training batch 801, loss: 0.035, 25632/28000 datapoints
2025-03-07 10:15:52,446 - INFO - training batch 851, loss: 0.031, 27232/28000 datapoints
2025-03-07 10:15:52,584 - INFO - validation batch 1, loss: 0.272, 32/6976 datapoints
2025-03-07 10:15:52,683 - INFO - validation batch 51, loss: 2.081, 1632/6976 datapoints
2025-03-07 10:15:52,825 - INFO - validation batch 101, loss: 0.749, 3232/6976 datapoints
2025-03-07 10:15:52,990 - INFO - validation batch 151, loss: 0.246, 4832/6976 datapoints
2025-03-07 10:15:53,097 - INFO - validation batch 201, loss: 1.429, 6432/6976 datapoints
2025-03-07 10:15:53,143 - INFO - Epoch 218/800 done.
2025-03-07 10:15:53,144 - INFO - Final validation performance:
Loss: 0.955, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:15:53,145 - INFO - Beginning epoch 219/800
2025-03-07 10:15:53,160 - INFO - training batch 1, loss: 0.054, 32/28000 datapoints
2025-03-07 10:15:53,569 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-07 10:15:53,935 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-07 10:15:54,566 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-07 10:15:55,203 - INFO - training batch 201, loss: 0.042, 6432/28000 datapoints
2025-03-07 10:15:55,764 - INFO - training batch 251, loss: 0.069, 8032/28000 datapoints
2025-03-07 10:15:56,056 - INFO - training batch 301, loss: 0.088, 9632/28000 datapoints
2025-03-07 10:15:56,324 - INFO - training batch 351, loss: 0.144, 11232/28000 datapoints
2025-03-07 10:15:56,569 - INFO - training batch 401, loss: 0.088, 12832/28000 datapoints
2025-03-07 10:15:56,810 - INFO - training batch 451, loss: 0.064, 14432/28000 datapoints
2025-03-07 10:15:57,054 - INFO - training batch 501, loss: 0.041, 16032/28000 datapoints
2025-03-07 10:15:57,506 - INFO - training batch 551, loss: 0.068, 17632/28000 datapoints
2025-03-07 10:15:57,997 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-07 10:15:58,400 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 10:15:58,685 - INFO - training batch 701, loss: 0.047, 22432/28000 datapoints
2025-03-07 10:15:58,937 - INFO - training batch 751, loss: 0.061, 24032/28000 datapoints
2025-03-07 10:15:59,215 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-07 10:15:59,476 - INFO - training batch 851, loss: 0.030, 27232/28000 datapoints
2025-03-07 10:15:59,596 - INFO - validation batch 1, loss: 0.270, 32/6976 datapoints
2025-03-07 10:15:59,666 - INFO - validation batch 51, loss: 2.105, 1632/6976 datapoints
2025-03-07 10:15:59,735 - INFO - validation batch 101, loss: 0.751, 3232/6976 datapoints
2025-03-07 10:15:59,813 - INFO - validation batch 151, loss: 0.240, 4832/6976 datapoints
2025-03-07 10:15:59,976 - INFO - validation batch 201, loss: 1.442, 6432/6976 datapoints
2025-03-07 10:16:00,024 - INFO - Epoch 219/800 done.
2025-03-07 10:16:00,025 - INFO - Final validation performance:
Loss: 0.962, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:16:00,025 - INFO - Beginning epoch 220/800
2025-03-07 10:16:00,042 - INFO - training batch 1, loss: 0.057, 32/28000 datapoints
2025-03-07 10:16:00,554 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-07 10:16:01,056 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-07 10:16:01,567 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-07 10:16:01,994 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-07 10:16:02,249 - INFO - training batch 251, loss: 0.068, 8032/28000 datapoints
2025-03-07 10:16:02,509 - INFO - training batch 301, loss: 0.083, 9632/28000 datapoints
2025-03-07 10:16:02,750 - INFO - training batch 351, loss: 0.144, 11232/28000 datapoints
2025-03-07 10:16:03,039 - INFO - training batch 401, loss: 0.084, 12832/28000 datapoints
2025-03-07 10:16:03,327 - INFO - training batch 451, loss: 0.060, 14432/28000 datapoints
2025-03-07 10:16:03,662 - INFO - training batch 501, loss: 0.040, 16032/28000 datapoints
2025-03-07 10:16:03,922 - INFO - training batch 551, loss: 0.065, 17632/28000 datapoints
2025-03-07 10:16:04,185 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-07 10:16:04,425 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 10:16:04,660 - INFO - training batch 701, loss: 0.047, 22432/28000 datapoints
2025-03-07 10:16:04,895 - INFO - training batch 751, loss: 0.059, 24032/28000 datapoints
2025-03-07 10:16:05,132 - INFO - training batch 801, loss: 0.035, 25632/28000 datapoints
2025-03-07 10:16:05,374 - INFO - training batch 851, loss: 0.030, 27232/28000 datapoints
2025-03-07 10:16:05,492 - INFO - validation batch 1, loss: 0.269, 32/6976 datapoints
2025-03-07 10:16:05,559 - INFO - validation batch 51, loss: 2.127, 1632/6976 datapoints
2025-03-07 10:16:05,625 - INFO - validation batch 101, loss: 0.762, 3232/6976 datapoints
2025-03-07 10:16:05,691 - INFO - validation batch 151, loss: 0.243, 4832/6976 datapoints
2025-03-07 10:16:05,759 - INFO - validation batch 201, loss: 1.453, 6432/6976 datapoints
2025-03-07 10:16:05,782 - INFO - Epoch 220/800 done.
2025-03-07 10:16:05,782 - INFO - Final validation performance:
Loss: 0.971, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:16:05,783 - INFO - Beginning epoch 221/800
2025-03-07 10:16:05,790 - INFO - training batch 1, loss: 0.051, 32/28000 datapoints
2025-03-07 10:16:06,032 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-07 10:16:06,280 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-07 10:16:06,519 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-07 10:16:06,754 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-07 10:16:07,183 - INFO - training batch 251, loss: 0.062, 8032/28000 datapoints
2025-03-07 10:16:07,651 - INFO - training batch 301, loss: 0.082, 9632/28000 datapoints
2025-03-07 10:16:07,986 - INFO - training batch 351, loss: 0.140, 11232/28000 datapoints
2025-03-07 10:16:08,231 - INFO - training batch 401, loss: 0.083, 12832/28000 datapoints
2025-03-07 10:16:08,473 - INFO - training batch 451, loss: 0.058, 14432/28000 datapoints
2025-03-07 10:16:08,715 - INFO - training batch 501, loss: 0.039, 16032/28000 datapoints
2025-03-07 10:16:08,955 - INFO - training batch 551, loss: 0.064, 17632/28000 datapoints
2025-03-07 10:16:09,196 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-07 10:16:09,431 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 10:16:09,664 - INFO - training batch 701, loss: 0.045, 22432/28000 datapoints
2025-03-07 10:16:09,902 - INFO - training batch 751, loss: 0.057, 24032/28000 datapoints
2025-03-07 10:16:10,137 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-07 10:16:10,376 - INFO - training batch 851, loss: 0.028, 27232/28000 datapoints
2025-03-07 10:16:10,493 - INFO - validation batch 1, loss: 0.267, 32/6976 datapoints
2025-03-07 10:16:10,559 - INFO - validation batch 51, loss: 2.152, 1632/6976 datapoints
2025-03-07 10:16:10,623 - INFO - validation batch 101, loss: 0.764, 3232/6976 datapoints
2025-03-07 10:16:10,688 - INFO - validation batch 151, loss: 0.236, 4832/6976 datapoints
2025-03-07 10:16:10,752 - INFO - validation batch 201, loss: 1.468, 6432/6976 datapoints
2025-03-07 10:16:10,774 - INFO - Epoch 221/800 done.
2025-03-07 10:16:10,774 - INFO - Final validation performance:
Loss: 0.978, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:16:10,775 - INFO - Beginning epoch 222/800
2025-03-07 10:16:10,782 - INFO - training batch 1, loss: 0.054, 32/28000 datapoints
2025-03-07 10:16:11,026 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-07 10:16:11,280 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-07 10:16:11,523 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-07 10:16:11,760 - INFO - training batch 201, loss: 0.040, 6432/28000 datapoints
2025-03-07 10:16:12,165 - INFO - training batch 251, loss: 0.060, 8032/28000 datapoints
2025-03-07 10:16:12,643 - INFO - training batch 301, loss: 0.081, 9632/28000 datapoints
2025-03-07 10:16:12,981 - INFO - training batch 351, loss: 0.137, 11232/28000 datapoints
2025-03-07 10:16:13,217 - INFO - training batch 401, loss: 0.081, 12832/28000 datapoints
2025-03-07 10:16:13,456 - INFO - training batch 451, loss: 0.053, 14432/28000 datapoints
2025-03-07 10:16:13,698 - INFO - training batch 501, loss: 0.038, 16032/28000 datapoints
2025-03-07 10:16:13,935 - INFO - training batch 551, loss: 0.063, 17632/28000 datapoints
2025-03-07 10:16:14,179 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-07 10:16:14,435 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 10:16:14,670 - INFO - training batch 701, loss: 0.043, 22432/28000 datapoints
2025-03-07 10:16:14,912 - INFO - training batch 751, loss: 0.056, 24032/28000 datapoints
2025-03-07 10:16:15,152 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-07 10:16:15,393 - INFO - training batch 851, loss: 0.028, 27232/28000 datapoints
2025-03-07 10:16:15,509 - INFO - validation batch 1, loss: 0.264, 32/6976 datapoints
2025-03-07 10:16:15,576 - INFO - validation batch 51, loss: 2.157, 1632/6976 datapoints
2025-03-07 10:16:15,641 - INFO - validation batch 101, loss: 0.775, 3232/6976 datapoints
2025-03-07 10:16:15,707 - INFO - validation batch 151, loss: 0.250, 4832/6976 datapoints
2025-03-07 10:16:15,772 - INFO - validation batch 201, loss: 1.483, 6432/6976 datapoints
2025-03-07 10:16:15,796 - INFO - Epoch 222/800 done.
2025-03-07 10:16:15,796 - INFO - Final validation performance:
Loss: 0.986, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:16:15,796 - INFO - Beginning epoch 223/800
2025-03-07 10:16:15,804 - INFO - training batch 1, loss: 0.049, 32/28000 datapoints
2025-03-07 10:16:16,038 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-07 10:16:16,276 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-07 10:16:16,510 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-07 10:16:16,751 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-07 10:16:17,132 - INFO - training batch 251, loss: 0.060, 8032/28000 datapoints
2025-03-07 10:16:17,602 - INFO - training batch 301, loss: 0.077, 9632/28000 datapoints
2025-03-07 10:16:17,954 - INFO - training batch 351, loss: 0.138, 11232/28000 datapoints
2025-03-07 10:16:18,184 - INFO - training batch 401, loss: 0.080, 12832/28000 datapoints
2025-03-07 10:16:18,422 - INFO - training batch 451, loss: 0.051, 14432/28000 datapoints
2025-03-07 10:16:18,661 - INFO - training batch 501, loss: 0.037, 16032/28000 datapoints
2025-03-07 10:16:18,903 - INFO - training batch 551, loss: 0.061, 17632/28000 datapoints
2025-03-07 10:16:19,143 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-07 10:16:19,379 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 10:16:19,615 - INFO - training batch 701, loss: 0.042, 22432/28000 datapoints
2025-03-07 10:16:19,861 - INFO - training batch 751, loss: 0.054, 24032/28000 datapoints
2025-03-07 10:16:20,109 - INFO - training batch 801, loss: 0.031, 25632/28000 datapoints
2025-03-07 10:16:20,353 - INFO - training batch 851, loss: 0.026, 27232/28000 datapoints
2025-03-07 10:16:20,470 - INFO - validation batch 1, loss: 0.261, 32/6976 datapoints
2025-03-07 10:16:20,537 - INFO - validation batch 51, loss: 2.206, 1632/6976 datapoints
2025-03-07 10:16:20,603 - INFO - validation batch 101, loss: 0.783, 3232/6976 datapoints
2025-03-07 10:16:20,671 - INFO - validation batch 151, loss: 0.242, 4832/6976 datapoints
2025-03-07 10:16:20,738 - INFO - validation batch 201, loss: 1.491, 6432/6976 datapoints
2025-03-07 10:16:20,763 - INFO - Epoch 223/800 done.
2025-03-07 10:16:20,764 - INFO - Final validation performance:
Loss: 0.997, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:16:20,765 - INFO - Beginning epoch 224/800
2025-03-07 10:16:20,772 - INFO - training batch 1, loss: 0.050, 32/28000 datapoints
2025-03-07 10:16:21,011 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-07 10:16:21,250 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-07 10:16:21,499 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-07 10:16:21,737 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-07 10:16:22,140 - INFO - training batch 251, loss: 0.055, 8032/28000 datapoints
2025-03-07 10:16:22,595 - INFO - training batch 301, loss: 0.072, 9632/28000 datapoints
2025-03-07 10:16:22,956 - INFO - training batch 351, loss: 0.135, 11232/28000 datapoints
2025-03-07 10:16:23,193 - INFO - training batch 401, loss: 0.077, 12832/28000 datapoints
2025-03-07 10:16:23,436 - INFO - training batch 451, loss: 0.049, 14432/28000 datapoints
2025-03-07 10:16:23,677 - INFO - training batch 501, loss: 0.036, 16032/28000 datapoints
2025-03-07 10:16:23,915 - INFO - training batch 551, loss: 0.060, 17632/28000 datapoints
2025-03-07 10:16:24,158 - INFO - training batch 601, loss: 0.035, 19232/28000 datapoints
2025-03-07 10:16:24,421 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 10:16:24,660 - INFO - training batch 701, loss: 0.038, 22432/28000 datapoints
2025-03-07 10:16:24,893 - INFO - training batch 751, loss: 0.053, 24032/28000 datapoints
2025-03-07 10:16:25,133 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-07 10:16:25,377 - INFO - training batch 851, loss: 0.025, 27232/28000 datapoints
2025-03-07 10:16:25,494 - INFO - validation batch 1, loss: 0.258, 32/6976 datapoints
2025-03-07 10:16:25,560 - INFO - validation batch 51, loss: 2.221, 1632/6976 datapoints
2025-03-07 10:16:25,628 - INFO - validation batch 101, loss: 0.787, 3232/6976 datapoints
2025-03-07 10:16:25,694 - INFO - validation batch 151, loss: 0.253, 4832/6976 datapoints
2025-03-07 10:16:25,759 - INFO - validation batch 201, loss: 1.522, 6432/6976 datapoints
2025-03-07 10:16:25,779 - INFO - Epoch 224/800 done.
2025-03-07 10:16:25,780 - INFO - Final validation performance:
Loss: 1.008, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:16:25,780 - INFO - Beginning epoch 225/800
2025-03-07 10:16:25,787 - INFO - training batch 1, loss: 0.049, 32/28000 datapoints
2025-03-07 10:16:26,025 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-07 10:16:26,262 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-07 10:16:26,503 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-07 10:16:26,735 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-07 10:16:27,115 - INFO - training batch 251, loss: 0.054, 8032/28000 datapoints
2025-03-07 10:16:27,592 - INFO - training batch 301, loss: 0.070, 9632/28000 datapoints
2025-03-07 10:16:27,958 - INFO - training batch 351, loss: 0.132, 11232/28000 datapoints
2025-03-07 10:16:28,198 - INFO - training batch 401, loss: 0.075, 12832/28000 datapoints
2025-03-07 10:16:28,445 - INFO - training batch 451, loss: 0.047, 14432/28000 datapoints
2025-03-07 10:16:28,690 - INFO - training batch 501, loss: 0.035, 16032/28000 datapoints
2025-03-07 10:16:28,969 - INFO - training batch 551, loss: 0.058, 17632/28000 datapoints
2025-03-07 10:16:29,244 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-07 10:16:29,544 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 10:16:30,163 - INFO - training batch 701, loss: 0.038, 22432/28000 datapoints
2025-03-07 10:16:31,717 - INFO - training batch 751, loss: 0.050, 24032/28000 datapoints
2025-03-07 10:16:33,807 - INFO - training batch 801, loss: 0.031, 25632/28000 datapoints
2025-03-07 10:16:36,517 - INFO - training batch 851, loss: 0.025, 27232/28000 datapoints
2025-03-07 10:16:36,877 - INFO - validation batch 1, loss: 0.249, 32/6976 datapoints
2025-03-07 10:16:37,019 - INFO - validation batch 51, loss: 2.251, 1632/6976 datapoints
2025-03-07 10:16:37,153 - INFO - validation batch 101, loss: 0.791, 3232/6976 datapoints
2025-03-07 10:16:37,328 - INFO - validation batch 151, loss: 0.251, 4832/6976 datapoints
2025-03-07 10:16:37,615 - INFO - validation batch 201, loss: 1.537, 6432/6976 datapoints
2025-03-07 10:16:37,681 - INFO - Epoch 225/800 done.
2025-03-07 10:16:37,682 - INFO - Final validation performance:
Loss: 1.016, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:16:37,688 - INFO - Beginning epoch 226/800
2025-03-07 10:16:37,707 - INFO - training batch 1, loss: 0.046, 32/28000 datapoints
2025-03-07 10:16:38,185 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-07 10:16:38,714 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-07 10:16:41,131 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-07 10:16:43,321 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-07 10:16:44,055 - INFO - training batch 251, loss: 0.054, 8032/28000 datapoints
2025-03-07 10:16:44,756 - INFO - training batch 301, loss: 0.069, 9632/28000 datapoints
2025-03-07 10:16:45,328 - INFO - training batch 351, loss: 0.130, 11232/28000 datapoints
2025-03-07 10:16:46,592 - INFO - training batch 401, loss: 0.074, 12832/28000 datapoints
2025-03-07 10:16:47,024 - INFO - training batch 451, loss: 0.043, 14432/28000 datapoints
2025-03-07 10:16:47,352 - INFO - training batch 501, loss: 0.034, 16032/28000 datapoints
2025-03-07 10:16:47,691 - INFO - training batch 551, loss: 0.056, 17632/28000 datapoints
2025-03-07 10:16:47,999 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-07 10:16:48,313 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 10:16:48,694 - INFO - training batch 701, loss: 0.035, 22432/28000 datapoints
2025-03-07 10:16:49,119 - INFO - training batch 751, loss: 0.050, 24032/28000 datapoints
2025-03-07 10:16:49,547 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-07 10:16:49,965 - INFO - training batch 851, loss: 0.023, 27232/28000 datapoints
2025-03-07 10:16:50,155 - INFO - validation batch 1, loss: 0.248, 32/6976 datapoints
2025-03-07 10:16:50,270 - INFO - validation batch 51, loss: 2.280, 1632/6976 datapoints
2025-03-07 10:16:50,387 - INFO - validation batch 101, loss: 0.791, 3232/6976 datapoints
2025-03-07 10:16:50,499 - INFO - validation batch 151, loss: 0.255, 4832/6976 datapoints
2025-03-07 10:16:50,606 - INFO - validation batch 201, loss: 1.553, 6432/6976 datapoints
2025-03-07 10:16:50,644 - INFO - Epoch 226/800 done.
2025-03-07 10:16:50,645 - INFO - Final validation performance:
Loss: 1.025, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:16:50,647 - INFO - Beginning epoch 227/800
2025-03-07 10:16:50,657 - INFO - training batch 1, loss: 0.047, 32/28000 datapoints
2025-03-07 10:16:51,004 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-07 10:16:51,341 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-07 10:16:52,154 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-07 10:16:52,485 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-07 10:16:53,071 - INFO - training batch 251, loss: 0.049, 8032/28000 datapoints
2025-03-07 10:16:53,453 - INFO - training batch 301, loss: 0.066, 9632/28000 datapoints
2025-03-07 10:16:53,826 - INFO - training batch 351, loss: 0.129, 11232/28000 datapoints
2025-03-07 10:16:54,123 - INFO - training batch 401, loss: 0.071, 12832/28000 datapoints
2025-03-07 10:16:54,433 - INFO - training batch 451, loss: 0.042, 14432/28000 datapoints
2025-03-07 10:16:54,747 - INFO - training batch 501, loss: 0.033, 16032/28000 datapoints
2025-03-07 10:16:55,086 - INFO - training batch 551, loss: 0.056, 17632/28000 datapoints
2025-03-07 10:16:55,389 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-07 10:16:55,751 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 10:16:57,156 - INFO - training batch 701, loss: 0.035, 22432/28000 datapoints
2025-03-07 10:16:57,779 - INFO - training batch 751, loss: 0.048, 24032/28000 datapoints
2025-03-07 10:16:58,669 - INFO - training batch 801, loss: 0.027, 25632/28000 datapoints
2025-03-07 10:16:59,464 - INFO - training batch 851, loss: 0.023, 27232/28000 datapoints
2025-03-07 10:16:59,675 - INFO - validation batch 1, loss: 0.241, 32/6976 datapoints
2025-03-07 10:16:59,853 - INFO - validation batch 51, loss: 2.299, 1632/6976 datapoints
2025-03-07 10:17:00,027 - INFO - validation batch 101, loss: 0.799, 3232/6976 datapoints
2025-03-07 10:17:00,320 - INFO - validation batch 151, loss: 0.273, 4832/6976 datapoints
2025-03-07 10:17:00,628 - INFO - validation batch 201, loss: 1.581, 6432/6976 datapoints
2025-03-07 10:17:00,687 - INFO - Epoch 227/800 done.
2025-03-07 10:17:00,687 - INFO - Final validation performance:
Loss: 1.039, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:17:00,688 - INFO - Beginning epoch 228/800
2025-03-07 10:17:00,716 - INFO - training batch 1, loss: 0.042, 32/28000 datapoints
2025-03-07 10:17:01,169 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-07 10:17:01,668 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-07 10:17:02,070 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-07 10:17:02,445 - INFO - training batch 201, loss: 0.036, 6432/28000 datapoints
2025-03-07 10:17:02,966 - INFO - training batch 251, loss: 0.049, 8032/28000 datapoints
2025-03-07 10:17:03,385 - INFO - training batch 301, loss: 0.065, 9632/28000 datapoints
2025-03-07 10:17:03,749 - INFO - training batch 351, loss: 0.124, 11232/28000 datapoints
2025-03-07 10:17:04,233 - INFO - training batch 401, loss: 0.070, 12832/28000 datapoints
2025-03-07 10:17:04,668 - INFO - training batch 451, loss: 0.040, 14432/28000 datapoints
2025-03-07 10:17:05,103 - INFO - training batch 501, loss: 0.031, 16032/28000 datapoints
2025-03-07 10:17:05,493 - INFO - training batch 551, loss: 0.053, 17632/28000 datapoints
2025-03-07 10:17:05,864 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-07 10:17:06,263 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 10:17:06,676 - INFO - training batch 701, loss: 0.034, 22432/28000 datapoints
2025-03-07 10:17:07,540 - INFO - training batch 751, loss: 0.045, 24032/28000 datapoints
2025-03-07 10:17:08,281 - INFO - training batch 801, loss: 0.027, 25632/28000 datapoints
2025-03-07 10:17:08,721 - INFO - training batch 851, loss: 0.022, 27232/28000 datapoints
2025-03-07 10:17:08,935 - INFO - validation batch 1, loss: 0.241, 32/6976 datapoints
2025-03-07 10:17:09,132 - INFO - validation batch 51, loss: 2.321, 1632/6976 datapoints
2025-03-07 10:17:09,467 - INFO - validation batch 101, loss: 0.810, 3232/6976 datapoints
2025-03-07 10:17:09,642 - INFO - validation batch 151, loss: 0.268, 4832/6976 datapoints
2025-03-07 10:17:09,814 - INFO - validation batch 201, loss: 1.577, 6432/6976 datapoints
2025-03-07 10:17:09,864 - INFO - Epoch 228/800 done.
2025-03-07 10:17:09,865 - INFO - Final validation performance:
Loss: 1.043, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:17:09,870 - INFO - Beginning epoch 229/800
2025-03-07 10:17:09,883 - INFO - training batch 1, loss: 0.044, 32/28000 datapoints
2025-03-07 10:17:10,305 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-07 10:17:10,989 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-07 10:17:11,478 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-07 10:17:11,766 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-07 10:17:12,036 - INFO - training batch 251, loss: 0.047, 8032/28000 datapoints
2025-03-07 10:17:12,338 - INFO - training batch 301, loss: 0.061, 9632/28000 datapoints
2025-03-07 10:17:12,624 - INFO - training batch 351, loss: 0.124, 11232/28000 datapoints
2025-03-07 10:17:12,898 - INFO - training batch 401, loss: 0.068, 12832/28000 datapoints
2025-03-07 10:17:13,163 - INFO - training batch 451, loss: 0.037, 14432/28000 datapoints
2025-03-07 10:17:13,474 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-07 10:17:13,771 - INFO - training batch 551, loss: 0.052, 17632/28000 datapoints
2025-03-07 10:17:14,098 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-07 10:17:14,510 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 10:17:14,779 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-07 10:17:15,026 - INFO - training batch 751, loss: 0.043, 24032/28000 datapoints
2025-03-07 10:17:15,334 - INFO - training batch 801, loss: 0.026, 25632/28000 datapoints
2025-03-07 10:17:15,646 - INFO - training batch 851, loss: 0.023, 27232/28000 datapoints
2025-03-07 10:17:15,909 - INFO - validation batch 1, loss: 0.239, 32/6976 datapoints
2025-03-07 10:17:16,067 - INFO - validation batch 51, loss: 2.377, 1632/6976 datapoints
2025-03-07 10:17:16,190 - INFO - validation batch 101, loss: 0.809, 3232/6976 datapoints
2025-03-07 10:17:16,435 - INFO - validation batch 151, loss: 0.278, 4832/6976 datapoints
2025-03-07 10:17:16,551 - INFO - validation batch 201, loss: 1.616, 6432/6976 datapoints
2025-03-07 10:17:16,583 - INFO - Epoch 229/800 done.
2025-03-07 10:17:16,584 - INFO - Final validation performance:
Loss: 1.064, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:17:16,585 - INFO - Beginning epoch 230/800
2025-03-07 10:17:16,594 - INFO - training batch 1, loss: 0.040, 32/28000 datapoints
2025-03-07 10:17:17,675 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-07 10:17:18,238 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-07 10:17:18,674 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-07 10:17:19,019 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-07 10:17:19,428 - INFO - training batch 251, loss: 0.044, 8032/28000 datapoints
2025-03-07 10:17:19,766 - INFO - training batch 301, loss: 0.059, 9632/28000 datapoints
2025-03-07 10:17:20,157 - INFO - training batch 351, loss: 0.122, 11232/28000 datapoints
2025-03-07 10:17:20,583 - INFO - training batch 401, loss: 0.065, 12832/28000 datapoints
2025-03-07 10:17:21,870 - INFO - training batch 451, loss: 0.035, 14432/28000 datapoints
2025-03-07 10:17:23,081 - INFO - training batch 501, loss: 0.028, 16032/28000 datapoints
2025-03-07 10:17:23,763 - INFO - training batch 551, loss: 0.051, 17632/28000 datapoints
2025-03-07 10:17:25,116 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-07 10:17:26,166 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-07 10:17:26,589 - INFO - training batch 701, loss: 0.032, 22432/28000 datapoints
2025-03-07 10:17:26,963 - INFO - training batch 751, loss: 0.043, 24032/28000 datapoints
2025-03-07 10:17:27,311 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-07 10:17:27,685 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-07 10:17:27,909 - INFO - validation batch 1, loss: 0.231, 32/6976 datapoints
2025-03-07 10:17:28,053 - INFO - validation batch 51, loss: 2.402, 1632/6976 datapoints
2025-03-07 10:17:28,184 - INFO - validation batch 101, loss: 0.822, 3232/6976 datapoints
2025-03-07 10:17:28,335 - INFO - validation batch 151, loss: 0.267, 4832/6976 datapoints
2025-03-07 10:17:28,487 - INFO - validation batch 201, loss: 1.627, 6432/6976 datapoints
2025-03-07 10:17:28,546 - INFO - Epoch 230/800 done.
2025-03-07 10:17:28,547 - INFO - Final validation performance:
Loss: 1.070, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:17:28,550 - INFO - Beginning epoch 231/800
2025-03-07 10:17:28,562 - INFO - training batch 1, loss: 0.042, 32/28000 datapoints
2025-03-07 10:17:29,021 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-07 10:17:29,385 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-07 10:17:29,712 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-07 10:17:30,021 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-07 10:17:30,522 - INFO - training batch 251, loss: 0.045, 8032/28000 datapoints
2025-03-07 10:17:30,926 - INFO - training batch 301, loss: 0.057, 9632/28000 datapoints
2025-03-07 10:17:31,309 - INFO - training batch 351, loss: 0.123, 11232/28000 datapoints
2025-03-07 10:17:31,687 - INFO - training batch 401, loss: 0.067, 12832/28000 datapoints
2025-03-07 10:17:31,992 - INFO - training batch 451, loss: 0.036, 14432/28000 datapoints
2025-03-07 10:17:32,305 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-07 10:17:32,606 - INFO - training batch 551, loss: 0.049, 17632/28000 datapoints
2025-03-07 10:17:32,891 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-07 10:17:33,193 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-07 10:17:33,523 - INFO - training batch 701, loss: 0.029, 22432/28000 datapoints
2025-03-07 10:17:34,405 - INFO - training batch 751, loss: 0.039, 24032/28000 datapoints
2025-03-07 10:17:35,105 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-07 10:17:35,872 - INFO - training batch 851, loss: 0.021, 27232/28000 datapoints
2025-03-07 10:17:36,216 - INFO - validation batch 1, loss: 0.218, 32/6976 datapoints
2025-03-07 10:17:36,370 - INFO - validation batch 51, loss: 2.429, 1632/6976 datapoints
2025-03-07 10:17:36,491 - INFO - validation batch 101, loss: 0.830, 3232/6976 datapoints
2025-03-07 10:17:36,606 - INFO - validation batch 151, loss: 0.297, 4832/6976 datapoints
2025-03-07 10:17:36,700 - INFO - validation batch 201, loss: 1.650, 6432/6976 datapoints
2025-03-07 10:17:36,734 - INFO - Epoch 231/800 done.
2025-03-07 10:17:36,735 - INFO - Final validation performance:
Loss: 1.085, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:17:36,736 - INFO - Beginning epoch 232/800
2025-03-07 10:17:36,745 - INFO - training batch 1, loss: 0.040, 32/28000 datapoints
2025-03-07 10:17:37,278 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-07 10:17:37,642 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-07 10:17:38,111 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-07 10:17:38,472 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-07 10:17:38,749 - INFO - training batch 251, loss: 0.041, 8032/28000 datapoints
2025-03-07 10:17:39,037 - INFO - training batch 301, loss: 0.053, 9632/28000 datapoints
2025-03-07 10:17:39,343 - INFO - training batch 351, loss: 0.129, 11232/28000 datapoints
2025-03-07 10:17:39,789 - INFO - training batch 401, loss: 0.062, 12832/28000 datapoints
2025-03-07 10:17:40,198 - INFO - training batch 451, loss: 0.037, 14432/28000 datapoints
2025-03-07 10:17:40,691 - INFO - training batch 501, loss: 0.026, 16032/28000 datapoints
2025-03-07 10:17:41,064 - INFO - training batch 551, loss: 0.048, 17632/28000 datapoints
2025-03-07 10:17:41,566 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-07 10:17:41,959 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-07 10:17:42,333 - INFO - training batch 701, loss: 0.028, 22432/28000 datapoints
2025-03-07 10:17:42,614 - INFO - training batch 751, loss: 0.039, 24032/28000 datapoints
2025-03-07 10:17:42,913 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-07 10:17:43,251 - INFO - training batch 851, loss: 0.021, 27232/28000 datapoints
2025-03-07 10:17:43,416 - INFO - validation batch 1, loss: 0.226, 32/6976 datapoints
2025-03-07 10:17:43,512 - INFO - validation batch 51, loss: 2.457, 1632/6976 datapoints
2025-03-07 10:17:43,593 - INFO - validation batch 101, loss: 0.834, 3232/6976 datapoints
2025-03-07 10:17:43,672 - INFO - validation batch 151, loss: 0.287, 4832/6976 datapoints
2025-03-07 10:17:43,752 - INFO - validation batch 201, loss: 1.664, 6432/6976 datapoints
2025-03-07 10:17:43,785 - INFO - Epoch 232/800 done.
2025-03-07 10:17:43,785 - INFO - Final validation performance:
Loss: 1.093, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:17:43,786 - INFO - Beginning epoch 233/800
2025-03-07 10:17:43,802 - INFO - training batch 1, loss: 0.035, 32/28000 datapoints
2025-03-07 10:17:44,107 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-07 10:17:44,427 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-07 10:17:44,735 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-07 10:17:45,064 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-07 10:17:45,530 - INFO - training batch 251, loss: 0.046, 8032/28000 datapoints
2025-03-07 10:17:45,958 - INFO - training batch 301, loss: 0.052, 9632/28000 datapoints
2025-03-07 10:17:46,356 - INFO - training batch 351, loss: 0.105, 11232/28000 datapoints
2025-03-07 10:17:46,688 - INFO - training batch 401, loss: 0.062, 12832/28000 datapoints
2025-03-07 10:17:47,038 - INFO - training batch 451, loss: 0.031, 14432/28000 datapoints
2025-03-07 10:17:47,399 - INFO - training batch 501, loss: 0.026, 16032/28000 datapoints
2025-03-07 10:17:48,092 - INFO - training batch 551, loss: 0.047, 17632/28000 datapoints
2025-03-07 10:17:49,023 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-07 10:17:49,438 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 10:17:50,305 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-07 10:17:50,735 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-07 10:17:51,107 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-07 10:17:51,454 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-07 10:17:51,603 - INFO - validation batch 1, loss: 0.232, 32/6976 datapoints
2025-03-07 10:17:51,689 - INFO - validation batch 51, loss: 2.481, 1632/6976 datapoints
2025-03-07 10:17:51,769 - INFO - validation batch 101, loss: 0.841, 3232/6976 datapoints
2025-03-07 10:17:51,854 - INFO - validation batch 151, loss: 0.266, 4832/6976 datapoints
2025-03-07 10:17:51,937 - INFO - validation batch 201, loss: 1.683, 6432/6976 datapoints
2025-03-07 10:17:51,973 - INFO - Epoch 233/800 done.
2025-03-07 10:17:51,973 - INFO - Final validation performance:
Loss: 1.101, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:17:51,974 - INFO - Beginning epoch 234/800
2025-03-07 10:17:51,983 - INFO - training batch 1, loss: 0.036, 32/28000 datapoints
2025-03-07 10:17:52,303 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-07 10:17:52,596 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-07 10:17:52,887 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-07 10:17:53,166 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-07 10:17:53,469 - INFO - training batch 251, loss: 0.044, 8032/28000 datapoints
2025-03-07 10:17:53,740 - INFO - training batch 301, loss: 0.048, 9632/28000 datapoints
2025-03-07 10:17:54,024 - INFO - training batch 351, loss: 0.112, 11232/28000 datapoints
2025-03-07 10:17:54,314 - INFO - training batch 401, loss: 0.064, 12832/28000 datapoints
2025-03-07 10:17:54,610 - INFO - training batch 451, loss: 0.032, 14432/28000 datapoints
2025-03-07 10:17:54,902 - INFO - training batch 501, loss: 0.025, 16032/28000 datapoints
2025-03-07 10:17:55,224 - INFO - training batch 551, loss: 0.046, 17632/28000 datapoints
2025-03-07 10:17:55,817 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-07 10:17:56,216 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-07 10:17:56,959 - INFO - training batch 701, loss: 0.028, 22432/28000 datapoints
2025-03-07 10:17:57,304 - INFO - training batch 751, loss: 0.035, 24032/28000 datapoints
2025-03-07 10:17:57,719 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-07 10:17:58,104 - INFO - training batch 851, loss: 0.019, 27232/28000 datapoints
2025-03-07 10:17:58,235 - INFO - validation batch 1, loss: 0.223, 32/6976 datapoints
2025-03-07 10:17:58,315 - INFO - validation batch 51, loss: 2.492, 1632/6976 datapoints
2025-03-07 10:17:58,389 - INFO - validation batch 101, loss: 0.848, 3232/6976 datapoints
2025-03-07 10:17:58,467 - INFO - validation batch 151, loss: 0.299, 4832/6976 datapoints
2025-03-07 10:17:58,544 - INFO - validation batch 201, loss: 1.707, 6432/6976 datapoints
2025-03-07 10:17:58,572 - INFO - Epoch 234/800 done.
2025-03-07 10:17:58,572 - INFO - Final validation performance:
Loss: 1.114, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:17:58,573 - INFO - Beginning epoch 235/800
2025-03-07 10:17:58,581 - INFO - training batch 1, loss: 0.036, 32/28000 datapoints
2025-03-07 10:17:58,850 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-07 10:17:59,147 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-07 10:17:59,450 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-07 10:17:59,733 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-07 10:18:00,014 - INFO - training batch 251, loss: 0.039, 8032/28000 datapoints
2025-03-07 10:18:00,285 - INFO - training batch 301, loss: 0.048, 9632/28000 datapoints
2025-03-07 10:18:00,580 - INFO - training batch 351, loss: 0.102, 11232/28000 datapoints
2025-03-07 10:18:00,884 - INFO - training batch 401, loss: 0.055, 12832/28000 datapoints
2025-03-07 10:18:01,187 - INFO - training batch 451, loss: 0.029, 14432/28000 datapoints
2025-03-07 10:18:01,473 - INFO - training batch 501, loss: 0.024, 16032/28000 datapoints
2025-03-07 10:18:01,761 - INFO - training batch 551, loss: 0.044, 17632/28000 datapoints
2025-03-07 10:18:02,042 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-07 10:18:02,312 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-07 10:18:02,586 - INFO - training batch 701, loss: 0.026, 22432/28000 datapoints
2025-03-07 10:18:02,847 - INFO - training batch 751, loss: 0.034, 24032/28000 datapoints
2025-03-07 10:18:03,115 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-07 10:18:03,402 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-07 10:18:03,531 - INFO - validation batch 1, loss: 0.221, 32/6976 datapoints
2025-03-07 10:18:03,608 - INFO - validation batch 51, loss: 2.519, 1632/6976 datapoints
2025-03-07 10:18:03,687 - INFO - validation batch 101, loss: 0.859, 3232/6976 datapoints
2025-03-07 10:18:03,760 - INFO - validation batch 151, loss: 0.298, 4832/6976 datapoints
2025-03-07 10:18:03,835 - INFO - validation batch 201, loss: 1.721, 6432/6976 datapoints
2025-03-07 10:18:03,866 - INFO - Epoch 235/800 done.
2025-03-07 10:18:03,866 - INFO - Final validation performance:
Loss: 1.123, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:18:03,867 - INFO - Beginning epoch 236/800
2025-03-07 10:18:03,875 - INFO - training batch 1, loss: 0.033, 32/28000 datapoints
2025-03-07 10:18:04,138 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-07 10:18:04,420 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-07 10:18:04,684 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-07 10:18:05,032 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-07 10:18:05,318 - INFO - training batch 251, loss: 0.040, 8032/28000 datapoints
2025-03-07 10:18:05,668 - INFO - training batch 301, loss: 0.047, 9632/28000 datapoints
2025-03-07 10:18:05,982 - INFO - training batch 351, loss: 0.106, 11232/28000 datapoints
2025-03-07 10:18:06,261 - INFO - training batch 401, loss: 0.054, 12832/28000 datapoints
2025-03-07 10:18:06,536 - INFO - training batch 451, loss: 0.028, 14432/28000 datapoints
2025-03-07 10:18:06,855 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-07 10:18:07,135 - INFO - training batch 551, loss: 0.042, 17632/28000 datapoints
2025-03-07 10:18:07,619 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-07 10:18:07,948 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-07 10:18:08,353 - INFO - training batch 701, loss: 0.024, 22432/28000 datapoints
2025-03-07 10:18:09,084 - INFO - training batch 751, loss: 0.033, 24032/28000 datapoints
2025-03-07 10:18:09,541 - INFO - training batch 801, loss: 0.020, 25632/28000 datapoints
2025-03-07 10:18:09,961 - INFO - training batch 851, loss: 0.016, 27232/28000 datapoints
2025-03-07 10:18:10,154 - INFO - validation batch 1, loss: 0.213, 32/6976 datapoints
2025-03-07 10:18:10,263 - INFO - validation batch 51, loss: 2.569, 1632/6976 datapoints
2025-03-07 10:18:10,441 - INFO - validation batch 101, loss: 0.871, 3232/6976 datapoints
2025-03-07 10:18:10,550 - INFO - validation batch 151, loss: 0.304, 4832/6976 datapoints
2025-03-07 10:18:10,657 - INFO - validation batch 201, loss: 1.760, 6432/6976 datapoints
2025-03-07 10:18:10,694 - INFO - Epoch 236/800 done.
2025-03-07 10:18:10,694 - INFO - Final validation performance:
Loss: 1.144, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:18:10,695 - INFO - Beginning epoch 237/800
2025-03-07 10:18:10,709 - INFO - training batch 1, loss: 0.034, 32/28000 datapoints
2025-03-07 10:18:11,168 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-07 10:18:11,524 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-07 10:18:11,801 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-07 10:18:12,080 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-07 10:18:12,385 - INFO - training batch 251, loss: 0.041, 8032/28000 datapoints
2025-03-07 10:18:12,667 - INFO - training batch 301, loss: 0.044, 9632/28000 datapoints
2025-03-07 10:18:12,940 - INFO - training batch 351, loss: 0.175, 11232/28000 datapoints
2025-03-07 10:18:13,242 - INFO - training batch 401, loss: 0.067, 12832/28000 datapoints
2025-03-07 10:18:13,547 - INFO - training batch 451, loss: 0.026, 14432/28000 datapoints
2025-03-07 10:18:13,866 - INFO - training batch 501, loss: 0.037, 16032/28000 datapoints
2025-03-07 10:18:14,166 - INFO - training batch 551, loss: 0.049, 17632/28000 datapoints
2025-03-07 10:18:14,727 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-07 10:18:15,143 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-07 10:18:15,553 - INFO - training batch 701, loss: 0.040, 22432/28000 datapoints
2025-03-07 10:18:16,045 - INFO - training batch 751, loss: 0.049, 24032/28000 datapoints
2025-03-07 10:18:16,414 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-07 10:18:16,739 - INFO - training batch 851, loss: 0.042, 27232/28000 datapoints
2025-03-07 10:18:16,875 - INFO - validation batch 1, loss: 0.173, 32/6976 datapoints
2025-03-07 10:18:16,954 - INFO - validation batch 51, loss: 2.631, 1632/6976 datapoints
2025-03-07 10:18:17,034 - INFO - validation batch 101, loss: 0.882, 3232/6976 datapoints
2025-03-07 10:18:17,115 - INFO - validation batch 151, loss: 0.320, 4832/6976 datapoints
2025-03-07 10:18:17,191 - INFO - validation batch 201, loss: 1.801, 6432/6976 datapoints
2025-03-07 10:18:17,227 - INFO - Epoch 237/800 done.
2025-03-07 10:18:17,227 - INFO - Final validation performance:
Loss: 1.161, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:18:17,227 - INFO - Beginning epoch 238/800
2025-03-07 10:18:17,236 - INFO - training batch 1, loss: 0.037, 32/28000 datapoints
2025-03-07 10:18:17,539 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-07 10:18:17,803 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-07 10:18:18,074 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-07 10:18:18,378 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-07 10:18:18,665 - INFO - training batch 251, loss: 0.034, 8032/28000 datapoints
2025-03-07 10:18:18,927 - INFO - training batch 301, loss: 0.034, 9632/28000 datapoints
2025-03-07 10:18:19,183 - INFO - training batch 351, loss: 0.107, 11232/28000 datapoints
2025-03-07 10:18:19,444 - INFO - training batch 401, loss: 0.074, 12832/28000 datapoints
2025-03-07 10:18:19,714 - INFO - training batch 451, loss: 0.048, 14432/28000 datapoints
2025-03-07 10:18:20,005 - INFO - training batch 501, loss: 0.023, 16032/28000 datapoints
2025-03-07 10:18:20,307 - INFO - training batch 551, loss: 0.044, 17632/28000 datapoints
2025-03-07 10:18:20,768 - INFO - training batch 601, loss: 0.028, 19232/28000 datapoints
2025-03-07 10:18:21,158 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-07 10:18:21,607 - INFO - training batch 701, loss: 0.015, 22432/28000 datapoints
2025-03-07 10:18:21,925 - INFO - training batch 751, loss: 0.038, 24032/28000 datapoints
2025-03-07 10:18:22,266 - INFO - training batch 801, loss: 0.031, 25632/28000 datapoints
2025-03-07 10:18:22,596 - INFO - training batch 851, loss: 0.017, 27232/28000 datapoints
2025-03-07 10:18:22,756 - INFO - validation batch 1, loss: 0.177, 32/6976 datapoints
2025-03-07 10:18:22,829 - INFO - validation batch 51, loss: 2.543, 1632/6976 datapoints
2025-03-07 10:18:22,901 - INFO - validation batch 101, loss: 0.902, 3232/6976 datapoints
2025-03-07 10:18:22,973 - INFO - validation batch 151, loss: 0.452, 4832/6976 datapoints
2025-03-07 10:18:23,051 - INFO - validation batch 201, loss: 1.882, 6432/6976 datapoints
2025-03-07 10:18:23,077 - INFO - Epoch 238/800 done.
2025-03-07 10:18:23,077 - INFO - Final validation performance:
Loss: 1.191, top-1 acc: 0.873top-5 acc: 0.873
2025-03-07 10:18:23,078 - INFO - Beginning epoch 239/800
2025-03-07 10:18:23,088 - INFO - training batch 1, loss: 0.044, 32/28000 datapoints
2025-03-07 10:18:23,394 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-07 10:18:23,668 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-07 10:18:23,935 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-07 10:18:24,194 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-07 10:18:24,484 - INFO - training batch 251, loss: 0.044, 8032/28000 datapoints
2025-03-07 10:18:24,748 - INFO - training batch 301, loss: 0.038, 9632/28000 datapoints
2025-03-07 10:18:25,005 - INFO - training batch 351, loss: 0.104, 11232/28000 datapoints
2025-03-07 10:18:25,263 - INFO - training batch 401, loss: 0.075, 12832/28000 datapoints
2025-03-07 10:18:25,567 - INFO - training batch 451, loss: 0.037, 14432/28000 datapoints
2025-03-07 10:18:25,838 - INFO - training batch 501, loss: 0.024, 16032/28000 datapoints
2025-03-07 10:18:26,135 - INFO - training batch 551, loss: 0.043, 17632/28000 datapoints
2025-03-07 10:18:26,503 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-07 10:18:26,948 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-07 10:18:27,336 - INFO - training batch 701, loss: 0.036, 22432/28000 datapoints
2025-03-07 10:18:27,733 - INFO - training batch 751, loss: 0.028, 24032/28000 datapoints
2025-03-07 10:18:28,043 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-07 10:18:28,365 - INFO - training batch 851, loss: 0.017, 27232/28000 datapoints
2025-03-07 10:18:28,533 - INFO - validation batch 1, loss: 0.179, 32/6976 datapoints
2025-03-07 10:18:28,630 - INFO - validation batch 51, loss: 2.607, 1632/6976 datapoints
2025-03-07 10:18:28,727 - INFO - validation batch 101, loss: 0.861, 3232/6976 datapoints
2025-03-07 10:18:28,819 - INFO - validation batch 151, loss: 0.345, 4832/6976 datapoints
2025-03-07 10:18:28,892 - INFO - validation batch 201, loss: 1.870, 6432/6976 datapoints
2025-03-07 10:18:28,924 - INFO - Epoch 239/800 done.
2025-03-07 10:18:28,924 - INFO - Final validation performance:
Loss: 1.172, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:18:28,926 - INFO - Beginning epoch 240/800
2025-03-07 10:18:28,935 - INFO - training batch 1, loss: 0.029, 32/28000 datapoints
2025-03-07 10:18:29,216 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-07 10:18:29,514 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-07 10:18:29,780 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-07 10:18:30,051 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-07 10:18:30,599 - INFO - training batch 251, loss: 0.059, 8032/28000 datapoints
2025-03-07 10:18:30,945 - INFO - training batch 301, loss: 0.034, 9632/28000 datapoints
2025-03-07 10:18:31,299 - INFO - training batch 351, loss: 0.084, 11232/28000 datapoints
2025-03-07 10:18:31,675 - INFO - training batch 401, loss: 0.050, 12832/28000 datapoints
2025-03-07 10:18:31,969 - INFO - training batch 451, loss: 0.066, 14432/28000 datapoints
2025-03-07 10:18:32,263 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-07 10:18:32,562 - INFO - training batch 551, loss: 0.043, 17632/28000 datapoints
2025-03-07 10:18:32,836 - INFO - training batch 601, loss: 0.043, 19232/28000 datapoints
2025-03-07 10:18:33,115 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-07 10:18:33,415 - INFO - training batch 701, loss: 0.020, 22432/28000 datapoints
2025-03-07 10:18:33,695 - INFO - training batch 751, loss: 0.030, 24032/28000 datapoints
2025-03-07 10:18:33,967 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-07 10:18:34,250 - INFO - training batch 851, loss: 0.031, 27232/28000 datapoints
2025-03-07 10:18:34,389 - INFO - validation batch 1, loss: 0.177, 32/6976 datapoints
2025-03-07 10:18:34,475 - INFO - validation batch 51, loss: 2.516, 1632/6976 datapoints
2025-03-07 10:18:34,558 - INFO - validation batch 101, loss: 0.868, 3232/6976 datapoints
2025-03-07 10:18:34,639 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-07 10:18:34,727 - INFO - validation batch 201, loss: 1.851, 6432/6976 datapoints
2025-03-07 10:18:34,754 - INFO - Epoch 240/800 done.
2025-03-07 10:18:34,754 - INFO - Final validation performance:
Loss: 1.164, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:18:34,755 - INFO - Beginning epoch 241/800
2025-03-07 10:18:34,768 - INFO - training batch 1, loss: 0.032, 32/28000 datapoints
2025-03-07 10:18:35,078 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-07 10:18:35,361 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-07 10:18:35,650 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-07 10:18:35,919 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-07 10:18:36,226 - INFO - training batch 251, loss: 0.037, 8032/28000 datapoints
2025-03-07 10:18:36,527 - INFO - training batch 301, loss: 0.038, 9632/28000 datapoints
2025-03-07 10:18:36,813 - INFO - training batch 351, loss: 0.088, 11232/28000 datapoints
2025-03-07 10:18:37,083 - INFO - training batch 401, loss: 0.066, 12832/28000 datapoints
2025-03-07 10:18:37,361 - INFO - training batch 451, loss: 0.045, 14432/28000 datapoints
2025-03-07 10:18:37,640 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-07 10:18:37,920 - INFO - training batch 551, loss: 0.045, 17632/28000 datapoints
2025-03-07 10:18:38,226 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-07 10:18:38,503 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 10:18:38,972 - INFO - training batch 701, loss: 0.017, 22432/28000 datapoints
2025-03-07 10:18:39,491 - INFO - training batch 751, loss: 0.027, 24032/28000 datapoints
2025-03-07 10:18:39,819 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-07 10:18:40,252 - INFO - training batch 851, loss: 0.014, 27232/28000 datapoints
2025-03-07 10:18:40,415 - INFO - validation batch 1, loss: 0.181, 32/6976 datapoints
2025-03-07 10:18:40,513 - INFO - validation batch 51, loss: 2.588, 1632/6976 datapoints
2025-03-07 10:18:40,607 - INFO - validation batch 101, loss: 0.848, 3232/6976 datapoints
2025-03-07 10:18:40,703 - INFO - validation batch 151, loss: 0.326, 4832/6976 datapoints
2025-03-07 10:18:40,808 - INFO - validation batch 201, loss: 1.875, 6432/6976 datapoints
2025-03-07 10:18:40,843 - INFO - Epoch 241/800 done.
2025-03-07 10:18:40,843 - INFO - Final validation performance:
Loss: 1.164, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:18:40,844 - INFO - Beginning epoch 242/800
2025-03-07 10:18:40,854 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-07 10:18:41,186 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-07 10:18:41,532 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-07 10:18:41,799 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-07 10:18:42,060 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-07 10:18:42,396 - INFO - training batch 251, loss: 0.043, 8032/28000 datapoints
2025-03-07 10:18:42,710 - INFO - training batch 301, loss: 0.033, 9632/28000 datapoints
2025-03-07 10:18:42,969 - INFO - training batch 351, loss: 0.089, 11232/28000 datapoints
2025-03-07 10:18:43,232 - INFO - training batch 401, loss: 0.057, 12832/28000 datapoints
2025-03-07 10:18:43,524 - INFO - training batch 451, loss: 0.037, 14432/28000 datapoints
2025-03-07 10:18:43,802 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-07 10:18:44,079 - INFO - training batch 551, loss: 0.037, 17632/28000 datapoints
2025-03-07 10:18:44,535 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-07 10:18:44,982 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-07 10:18:45,340 - INFO - training batch 701, loss: 0.015, 22432/28000 datapoints
2025-03-07 10:18:45,686 - INFO - training batch 751, loss: 0.023, 24032/28000 datapoints
2025-03-07 10:18:46,014 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-07 10:18:46,526 - INFO - training batch 851, loss: 0.013, 27232/28000 datapoints
2025-03-07 10:18:46,686 - INFO - validation batch 1, loss: 0.179, 32/6976 datapoints
2025-03-07 10:18:46,762 - INFO - validation batch 51, loss: 2.623, 1632/6976 datapoints
2025-03-07 10:18:46,834 - INFO - validation batch 101, loss: 0.845, 3232/6976 datapoints
2025-03-07 10:18:46,908 - INFO - validation batch 151, loss: 0.330, 4832/6976 datapoints
2025-03-07 10:18:46,984 - INFO - validation batch 201, loss: 1.887, 6432/6976 datapoints
2025-03-07 10:18:47,016 - INFO - Epoch 242/800 done.
2025-03-07 10:18:47,016 - INFO - Final validation performance:
Loss: 1.173, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:18:47,017 - INFO - Beginning epoch 243/800
2025-03-07 10:18:47,025 - INFO - training batch 1, loss: 0.029, 32/28000 datapoints
2025-03-07 10:18:47,302 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-07 10:18:47,587 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-07 10:18:47,859 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-07 10:18:48,135 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-07 10:18:48,423 - INFO - training batch 251, loss: 0.034, 8032/28000 datapoints
2025-03-07 10:18:48,697 - INFO - training batch 301, loss: 0.037, 9632/28000 datapoints
2025-03-07 10:18:48,964 - INFO - training batch 351, loss: 0.088, 11232/28000 datapoints
2025-03-07 10:18:49,230 - INFO - training batch 401, loss: 0.051, 12832/28000 datapoints
2025-03-07 10:18:49,516 - INFO - training batch 451, loss: 0.030, 14432/28000 datapoints
2025-03-07 10:18:49,796 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-07 10:18:50,110 - INFO - training batch 551, loss: 0.034, 17632/28000 datapoints
2025-03-07 10:18:50,395 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-07 10:18:50,665 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-07 10:18:50,955 - INFO - training batch 701, loss: 0.016, 22432/28000 datapoints
2025-03-07 10:18:51,229 - INFO - training batch 751, loss: 0.023, 24032/28000 datapoints
2025-03-07 10:18:51,515 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-07 10:18:51,781 - INFO - training batch 851, loss: 0.013, 27232/28000 datapoints
2025-03-07 10:18:51,916 - INFO - validation batch 1, loss: 0.193, 32/6976 datapoints
2025-03-07 10:18:51,990 - INFO - validation batch 51, loss: 2.694, 1632/6976 datapoints
2025-03-07 10:18:52,066 - INFO - validation batch 101, loss: 0.845, 3232/6976 datapoints
2025-03-07 10:18:52,143 - INFO - validation batch 151, loss: 0.332, 4832/6976 datapoints
2025-03-07 10:18:52,214 - INFO - validation batch 201, loss: 1.896, 6432/6976 datapoints
2025-03-07 10:18:52,238 - INFO - Epoch 243/800 done.
2025-03-07 10:18:52,238 - INFO - Final validation performance:
Loss: 1.192, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:18:52,239 - INFO - Beginning epoch 244/800
2025-03-07 10:18:52,248 - INFO - training batch 1, loss: 0.026, 32/28000 datapoints
2025-03-07 10:18:52,539 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-07 10:18:52,808 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-07 10:18:53,083 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-07 10:18:53,356 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-07 10:18:53,641 - INFO - training batch 251, loss: 0.032, 8032/28000 datapoints
2025-03-07 10:18:53,916 - INFO - training batch 301, loss: 0.035, 9632/28000 datapoints
2025-03-07 10:18:54,193 - INFO - training batch 351, loss: 0.080, 11232/28000 datapoints
2025-03-07 10:18:54,497 - INFO - training batch 401, loss: 0.049, 12832/28000 datapoints
2025-03-07 10:18:54,842 - INFO - training batch 451, loss: 0.027, 14432/28000 datapoints
2025-03-07 10:18:55,103 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-07 10:18:55,441 - INFO - training batch 551, loss: 0.031, 17632/28000 datapoints
2025-03-07 10:18:55,723 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-07 10:18:56,006 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-07 10:18:56,282 - INFO - training batch 701, loss: 0.017, 22432/28000 datapoints
2025-03-07 10:18:56,700 - INFO - training batch 751, loss: 0.022, 24032/28000 datapoints
2025-03-07 10:18:57,484 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-07 10:18:57,839 - INFO - training batch 851, loss: 0.012, 27232/28000 datapoints
2025-03-07 10:18:58,004 - INFO - validation batch 1, loss: 0.196, 32/6976 datapoints
2025-03-07 10:18:58,102 - INFO - validation batch 51, loss: 2.758, 1632/6976 datapoints
2025-03-07 10:18:58,199 - INFO - validation batch 101, loss: 0.857, 3232/6976 datapoints
2025-03-07 10:18:58,294 - INFO - validation batch 151, loss: 0.345, 4832/6976 datapoints
2025-03-07 10:18:58,383 - INFO - validation batch 201, loss: 1.919, 6432/6976 datapoints
2025-03-07 10:18:58,413 - INFO - Epoch 244/800 done.
2025-03-07 10:18:58,413 - INFO - Final validation performance:
Loss: 1.215, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:18:58,414 - INFO - Beginning epoch 245/800
2025-03-07 10:18:58,424 - INFO - training batch 1, loss: 0.026, 32/28000 datapoints
2025-03-07 10:18:58,770 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-07 10:18:59,069 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-07 10:18:59,332 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-07 10:18:59,596 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-07 10:18:59,869 - INFO - training batch 251, loss: 0.030, 8032/28000 datapoints
2025-03-07 10:19:00,143 - INFO - training batch 301, loss: 0.037, 9632/28000 datapoints
2025-03-07 10:19:00,408 - INFO - training batch 351, loss: 0.077, 11232/28000 datapoints
2025-03-07 10:19:00,697 - INFO - training batch 401, loss: 0.046, 12832/28000 datapoints
2025-03-07 10:19:01,071 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-07 10:19:01,351 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-07 10:19:01,651 - INFO - training batch 551, loss: 0.030, 17632/28000 datapoints
2025-03-07 10:19:01,939 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-07 10:19:02,222 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 10:19:02,512 - INFO - training batch 701, loss: 0.017, 22432/28000 datapoints
2025-03-07 10:19:02,821 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-07 10:19:03,209 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-07 10:19:03,549 - INFO - training batch 851, loss: 0.012, 27232/28000 datapoints
2025-03-07 10:19:03,693 - INFO - validation batch 1, loss: 0.198, 32/6976 datapoints
2025-03-07 10:19:03,774 - INFO - validation batch 51, loss: 2.806, 1632/6976 datapoints
2025-03-07 10:19:03,853 - INFO - validation batch 101, loss: 0.869, 3232/6976 datapoints
2025-03-07 10:19:03,937 - INFO - validation batch 151, loss: 0.363, 4832/6976 datapoints
2025-03-07 10:19:04,039 - INFO - validation batch 201, loss: 1.940, 6432/6976 datapoints
2025-03-07 10:19:04,086 - INFO - Epoch 245/800 done.
2025-03-07 10:19:04,086 - INFO - Final validation performance:
Loss: 1.235, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:19:04,087 - INFO - Beginning epoch 246/800
2025-03-07 10:19:04,097 - INFO - training batch 1, loss: 0.023, 32/28000 datapoints
2025-03-07 10:19:04,528 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-07 10:19:04,879 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-07 10:19:05,164 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-07 10:19:05,446 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-07 10:19:05,752 - INFO - training batch 251, loss: 0.031, 8032/28000 datapoints
2025-03-07 10:19:06,061 - INFO - training batch 301, loss: 0.032, 9632/28000 datapoints
2025-03-07 10:19:06,397 - INFO - training batch 351, loss: 0.238, 11232/28000 datapoints
2025-03-07 10:19:06,721 - INFO - training batch 401, loss: 0.048, 12832/28000 datapoints
2025-03-07 10:19:07,040 - INFO - training batch 451, loss: 0.053, 14432/28000 datapoints
2025-03-07 10:19:07,355 - INFO - training batch 501, loss: 0.023, 16032/28000 datapoints
2025-03-07 10:19:07,672 - INFO - training batch 551, loss: 0.033, 17632/28000 datapoints
2025-03-07 10:19:07,981 - INFO - training batch 601, loss: 0.060, 19232/28000 datapoints
2025-03-07 10:19:08,307 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 10:19:08,624 - INFO - training batch 701, loss: 0.014, 22432/28000 datapoints
2025-03-07 10:19:08,947 - INFO - training batch 751, loss: 0.022, 24032/28000 datapoints
2025-03-07 10:19:09,689 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-07 10:19:10,180 - INFO - training batch 851, loss: 0.013, 27232/28000 datapoints
2025-03-07 10:19:10,558 - INFO - validation batch 1, loss: 0.171, 32/6976 datapoints
2025-03-07 10:19:10,745 - INFO - validation batch 51, loss: 2.871, 1632/6976 datapoints
2025-03-07 10:19:10,887 - INFO - validation batch 101, loss: 0.892, 3232/6976 datapoints
2025-03-07 10:19:11,000 - INFO - validation batch 151, loss: 0.402, 4832/6976 datapoints
2025-03-07 10:19:11,113 - INFO - validation batch 201, loss: 1.986, 6432/6976 datapoints
2025-03-07 10:19:11,152 - INFO - Epoch 246/800 done.
2025-03-07 10:19:11,152 - INFO - Final validation performance:
Loss: 1.265, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:19:11,154 - INFO - Beginning epoch 247/800
2025-03-07 10:19:11,164 - INFO - training batch 1, loss: 0.025, 32/28000 datapoints
2025-03-07 10:19:11,568 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-07 10:19:11,942 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-07 10:19:12,230 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-07 10:19:12,537 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-07 10:19:12,839 - INFO - training batch 251, loss: 0.028, 8032/28000 datapoints
2025-03-07 10:19:13,147 - INFO - training batch 301, loss: 0.032, 9632/28000 datapoints
2025-03-07 10:19:13,480 - INFO - training batch 351, loss: 0.056, 11232/28000 datapoints
2025-03-07 10:19:13,766 - INFO - training batch 401, loss: 0.046, 12832/28000 datapoints
2025-03-07 10:19:14,105 - INFO - training batch 451, loss: 0.031, 14432/28000 datapoints
2025-03-07 10:19:14,429 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-07 10:19:14,731 - INFO - training batch 551, loss: 0.035, 17632/28000 datapoints
2025-03-07 10:19:15,029 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-07 10:19:15,334 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:19:15,671 - INFO - training batch 701, loss: 0.021, 22432/28000 datapoints
2025-03-07 10:19:15,995 - INFO - training batch 751, loss: 0.022, 24032/28000 datapoints
2025-03-07 10:19:16,288 - INFO - training batch 801, loss: 0.038, 25632/28000 datapoints
2025-03-07 10:19:16,573 - INFO - training batch 851, loss: 0.017, 27232/28000 datapoints
2025-03-07 10:19:16,744 - INFO - validation batch 1, loss: 0.208, 32/6976 datapoints
2025-03-07 10:19:16,830 - INFO - validation batch 51, loss: 3.051, 1632/6976 datapoints
2025-03-07 10:19:16,914 - INFO - validation batch 101, loss: 0.859, 3232/6976 datapoints
2025-03-07 10:19:16,988 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-07 10:19:17,064 - INFO - validation batch 201, loss: 1.829, 6432/6976 datapoints
2025-03-07 10:19:17,087 - INFO - Epoch 247/800 done.
2025-03-07 10:19:17,088 - INFO - Final validation performance:
Loss: 1.271, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:19:17,088 - INFO - Beginning epoch 248/800
2025-03-07 10:19:17,101 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-07 10:19:17,418 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-07 10:19:17,928 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-07 10:19:18,217 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-07 10:19:18,531 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-07 10:19:18,825 - INFO - training batch 251, loss: 0.029, 8032/28000 datapoints
2025-03-07 10:19:19,108 - INFO - training batch 301, loss: 0.033, 9632/28000 datapoints
2025-03-07 10:19:19,382 - INFO - training batch 351, loss: 0.068, 11232/28000 datapoints
2025-03-07 10:19:19,674 - INFO - training batch 401, loss: 0.055, 12832/28000 datapoints
2025-03-07 10:19:19,979 - INFO - training batch 451, loss: 0.031, 14432/28000 datapoints
2025-03-07 10:19:20,259 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-07 10:19:20,575 - INFO - training batch 551, loss: 0.035, 17632/28000 datapoints
2025-03-07 10:19:20,886 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-07 10:19:21,392 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:19:21,931 - INFO - training batch 701, loss: 0.022, 22432/28000 datapoints
2025-03-07 10:19:22,384 - INFO - training batch 751, loss: 0.023, 24032/28000 datapoints
2025-03-07 10:19:22,814 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-07 10:19:23,148 - INFO - training batch 851, loss: 0.012, 27232/28000 datapoints
2025-03-07 10:19:23,414 - INFO - validation batch 1, loss: 0.151, 32/6976 datapoints
2025-03-07 10:19:23,529 - INFO - validation batch 51, loss: 2.741, 1632/6976 datapoints
2025-03-07 10:19:23,620 - INFO - validation batch 101, loss: 0.853, 3232/6976 datapoints
2025-03-07 10:19:23,706 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-07 10:19:23,780 - INFO - validation batch 201, loss: 1.980, 6432/6976 datapoints
2025-03-07 10:19:23,814 - INFO - Epoch 248/800 done.
2025-03-07 10:19:23,815 - INFO - Final validation performance:
Loss: 1.227, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:19:23,816 - INFO - Beginning epoch 249/800
2025-03-07 10:19:23,830 - INFO - training batch 1, loss: 0.024, 32/28000 datapoints
2025-03-07 10:19:24,223 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-07 10:19:24,539 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-07 10:19:24,820 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-07 10:19:25,121 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-07 10:19:25,477 - INFO - training batch 251, loss: 0.031, 8032/28000 datapoints
2025-03-07 10:19:25,800 - INFO - training batch 301, loss: 0.029, 9632/28000 datapoints
2025-03-07 10:19:26,104 - INFO - training batch 351, loss: 0.059, 11232/28000 datapoints
2025-03-07 10:19:26,392 - INFO - training batch 401, loss: 0.042, 12832/28000 datapoints
2025-03-07 10:19:26,705 - INFO - training batch 451, loss: 0.026, 14432/28000 datapoints
2025-03-07 10:19:27,052 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-07 10:19:27,360 - INFO - training batch 551, loss: 0.030, 17632/28000 datapoints
2025-03-07 10:19:27,694 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-07 10:19:27,996 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 10:19:28,293 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-07 10:19:28,602 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-07 10:19:28,896 - INFO - training batch 801, loss: 0.018, 25632/28000 datapoints
2025-03-07 10:19:29,177 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-07 10:19:29,339 - INFO - validation batch 1, loss: 0.179, 32/6976 datapoints
2025-03-07 10:19:29,424 - INFO - validation batch 51, loss: 2.820, 1632/6976 datapoints
2025-03-07 10:19:29,503 - INFO - validation batch 101, loss: 0.852, 3232/6976 datapoints
2025-03-07 10:19:29,582 - INFO - validation batch 151, loss: 0.408, 4832/6976 datapoints
2025-03-07 10:19:29,673 - INFO - validation batch 201, loss: 1.987, 6432/6976 datapoints
2025-03-07 10:19:29,708 - INFO - Epoch 249/800 done.
2025-03-07 10:19:29,708 - INFO - Final validation performance:
Loss: 1.249, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:19:29,709 - INFO - Beginning epoch 250/800
2025-03-07 10:19:29,717 - INFO - training batch 1, loss: 0.026, 32/28000 datapoints
2025-03-07 10:19:30,063 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-07 10:19:30,554 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 10:19:30,861 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-07 10:19:31,164 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-07 10:19:31,513 - INFO - training batch 251, loss: 0.031, 8032/28000 datapoints
2025-03-07 10:19:31,838 - INFO - training batch 301, loss: 0.029, 9632/28000 datapoints
2025-03-07 10:19:32,146 - INFO - training batch 351, loss: 0.057, 11232/28000 datapoints
2025-03-07 10:19:32,434 - INFO - training batch 401, loss: 0.045, 12832/28000 datapoints
2025-03-07 10:19:32,785 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-07 10:19:33,072 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-07 10:19:33,414 - INFO - training batch 551, loss: 0.027, 17632/28000 datapoints
2025-03-07 10:19:33,850 - INFO - training batch 601, loss: 0.017, 19232/28000 datapoints
2025-03-07 10:19:34,222 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:19:34,550 - INFO - training batch 701, loss: 0.018, 22432/28000 datapoints
2025-03-07 10:19:34,867 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-07 10:19:35,174 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-07 10:19:35,510 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-07 10:19:35,690 - INFO - validation batch 1, loss: 0.184, 32/6976 datapoints
2025-03-07 10:19:35,804 - INFO - validation batch 51, loss: 2.856, 1632/6976 datapoints
2025-03-07 10:19:35,925 - INFO - validation batch 101, loss: 0.871, 3232/6976 datapoints
2025-03-07 10:19:36,028 - INFO - validation batch 151, loss: 0.387, 4832/6976 datapoints
2025-03-07 10:19:36,142 - INFO - validation batch 201, loss: 2.009, 6432/6976 datapoints
2025-03-07 10:19:36,176 - INFO - Epoch 250/800 done.
2025-03-07 10:19:36,177 - INFO - Final validation performance:
Loss: 1.261, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:19:36,177 - INFO - Beginning epoch 251/800
2025-03-07 10:19:36,186 - INFO - training batch 1, loss: 0.021, 32/28000 datapoints
2025-03-07 10:19:36,567 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-07 10:19:36,868 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-07 10:19:37,194 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-07 10:19:37,461 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-07 10:19:37,745 - INFO - training batch 251, loss: 0.029, 8032/28000 datapoints
2025-03-07 10:19:38,018 - INFO - training batch 301, loss: 0.027, 9632/28000 datapoints
2025-03-07 10:19:38,296 - INFO - training batch 351, loss: 0.126, 11232/28000 datapoints
2025-03-07 10:19:38,562 - INFO - training batch 401, loss: 0.076, 12832/28000 datapoints
2025-03-07 10:19:38,834 - INFO - training batch 451, loss: 0.028, 14432/28000 datapoints
2025-03-07 10:19:39,119 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-07 10:19:39,391 - INFO - training batch 551, loss: 0.024, 17632/28000 datapoints
2025-03-07 10:19:39,665 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-07 10:19:39,931 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-07 10:19:40,260 - INFO - training batch 701, loss: 0.076, 22432/28000 datapoints
2025-03-07 10:19:40,524 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-07 10:19:40,836 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-07 10:19:41,099 - INFO - training batch 851, loss: 0.016, 27232/28000 datapoints
2025-03-07 10:19:41,229 - INFO - validation batch 1, loss: 0.140, 32/6976 datapoints
2025-03-07 10:19:41,314 - INFO - validation batch 51, loss: 2.828, 1632/6976 datapoints
2025-03-07 10:19:41,388 - INFO - validation batch 101, loss: 0.892, 3232/6976 datapoints
2025-03-07 10:19:41,467 - INFO - validation batch 151, loss: 0.437, 4832/6976 datapoints
2025-03-07 10:19:41,540 - INFO - validation batch 201, loss: 2.095, 6432/6976 datapoints
2025-03-07 10:19:41,570 - INFO - Epoch 251/800 done.
2025-03-07 10:19:41,570 - INFO - Final validation performance:
Loss: 1.278, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:19:41,570 - INFO - Beginning epoch 252/800
2025-03-07 10:19:41,578 - INFO - training batch 1, loss: 0.021, 32/28000 datapoints
2025-03-07 10:19:41,842 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-07 10:19:42,103 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 10:19:42,365 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-07 10:19:42,624 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-07 10:19:42,877 - INFO - training batch 251, loss: 0.018, 8032/28000 datapoints
2025-03-07 10:19:43,135 - INFO - training batch 301, loss: 0.028, 9632/28000 datapoints
2025-03-07 10:19:43,398 - INFO - training batch 351, loss: 0.044, 11232/28000 datapoints
2025-03-07 10:19:43,662 - INFO - training batch 401, loss: 0.032, 12832/28000 datapoints
2025-03-07 10:19:43,927 - INFO - training batch 451, loss: 0.054, 14432/28000 datapoints
2025-03-07 10:19:44,185 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-07 10:19:44,455 - INFO - training batch 551, loss: 0.025, 17632/28000 datapoints
2025-03-07 10:19:44,719 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-07 10:19:44,978 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 10:19:45,240 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-07 10:19:45,500 - INFO - training batch 751, loss: 0.029, 24032/28000 datapoints
2025-03-07 10:19:45,759 - INFO - training batch 801, loss: 0.026, 25632/28000 datapoints
2025-03-07 10:19:46,014 - INFO - training batch 851, loss: 0.013, 27232/28000 datapoints
2025-03-07 10:19:46,142 - INFO - validation batch 1, loss: 0.284, 32/6976 datapoints
2025-03-07 10:19:46,212 - INFO - validation batch 51, loss: 2.907, 1632/6976 datapoints
2025-03-07 10:19:46,286 - INFO - validation batch 101, loss: 0.832, 3232/6976 datapoints
2025-03-07 10:19:46,357 - INFO - validation batch 151, loss: 0.249, 4832/6976 datapoints
2025-03-07 10:19:46,429 - INFO - validation batch 201, loss: 2.018, 6432/6976 datapoints
2025-03-07 10:19:46,455 - INFO - Epoch 252/800 done.
2025-03-07 10:19:46,456 - INFO - Final validation performance:
Loss: 1.258, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:19:46,456 - INFO - Beginning epoch 253/800
2025-03-07 10:19:46,463 - INFO - training batch 1, loss: 0.014, 32/28000 datapoints
2025-03-07 10:19:46,720 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-07 10:19:46,983 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 10:19:47,254 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-07 10:19:47,667 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-07 10:19:47,954 - INFO - training batch 251, loss: 0.035, 8032/28000 datapoints
2025-03-07 10:19:48,423 - INFO - training batch 301, loss: 0.036, 9632/28000 datapoints
2025-03-07 10:19:48,723 - INFO - training batch 351, loss: 0.034, 11232/28000 datapoints
2025-03-07 10:19:48,988 - INFO - training batch 401, loss: 0.034, 12832/28000 datapoints
2025-03-07 10:19:49,261 - INFO - training batch 451, loss: 0.030, 14432/28000 datapoints
2025-03-07 10:19:49,526 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-07 10:19:49,801 - INFO - training batch 551, loss: 0.036, 17632/28000 datapoints
2025-03-07 10:19:50,142 - INFO - training batch 601, loss: 0.040, 19232/28000 datapoints
2025-03-07 10:19:50,420 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 10:19:50,705 - INFO - training batch 701, loss: 0.016, 22432/28000 datapoints
2025-03-07 10:19:50,975 - INFO - training batch 751, loss: 0.027, 24032/28000 datapoints
2025-03-07 10:19:51,243 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-07 10:19:51,526 - INFO - training batch 851, loss: 0.014, 27232/28000 datapoints
2025-03-07 10:19:51,660 - INFO - validation batch 1, loss: 0.190, 32/6976 datapoints
2025-03-07 10:19:51,735 - INFO - validation batch 51, loss: 3.070, 1632/6976 datapoints
2025-03-07 10:19:51,806 - INFO - validation batch 101, loss: 0.864, 3232/6976 datapoints
2025-03-07 10:19:51,878 - INFO - validation batch 151, loss: 0.314, 4832/6976 datapoints
2025-03-07 10:19:51,947 - INFO - validation batch 201, loss: 2.042, 6432/6976 datapoints
2025-03-07 10:19:51,972 - INFO - Epoch 253/800 done.
2025-03-07 10:19:51,972 - INFO - Final validation performance:
Loss: 1.296, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:19:51,973 - INFO - Beginning epoch 254/800
2025-03-07 10:19:51,981 - INFO - training batch 1, loss: 0.016, 32/28000 datapoints
2025-03-07 10:19:52,297 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-07 10:19:52,571 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-07 10:19:52,838 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-07 10:19:53,107 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-07 10:19:53,385 - INFO - training batch 251, loss: 0.036, 8032/28000 datapoints
2025-03-07 10:19:53,664 - INFO - training batch 301, loss: 0.025, 9632/28000 datapoints
2025-03-07 10:19:53,964 - INFO - training batch 351, loss: 0.048, 11232/28000 datapoints
2025-03-07 10:19:54,239 - INFO - training batch 401, loss: 0.041, 12832/28000 datapoints
2025-03-07 10:19:54,526 - INFO - training batch 451, loss: 0.083, 14432/28000 datapoints
2025-03-07 10:19:54,796 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-07 10:19:55,076 - INFO - training batch 551, loss: 0.027, 17632/28000 datapoints
2025-03-07 10:19:55,355 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-07 10:19:55,628 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:19:55,908 - INFO - training batch 701, loss: 0.014, 22432/28000 datapoints
2025-03-07 10:19:56,181 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-07 10:19:56,455 - INFO - training batch 801, loss: 0.064, 25632/28000 datapoints
2025-03-07 10:19:56,727 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-07 10:19:56,863 - INFO - validation batch 1, loss: 0.206, 32/6976 datapoints
2025-03-07 10:19:56,939 - INFO - validation batch 51, loss: 2.745, 1632/6976 datapoints
2025-03-07 10:19:57,019 - INFO - validation batch 101, loss: 0.891, 3232/6976 datapoints
2025-03-07 10:19:57,115 - INFO - validation batch 151, loss: 0.749, 4832/6976 datapoints
2025-03-07 10:19:57,217 - INFO - validation batch 201, loss: 2.224, 6432/6976 datapoints
2025-03-07 10:19:57,242 - INFO - Epoch 254/800 done.
2025-03-07 10:19:57,242 - INFO - Final validation performance:
Loss: 1.363, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:19:57,243 - INFO - Beginning epoch 255/800
2025-03-07 10:19:57,254 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-07 10:19:57,569 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-07 10:19:57,880 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-07 10:19:58,202 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-07 10:19:58,486 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-07 10:19:58,762 - INFO - training batch 251, loss: 0.053, 8032/28000 datapoints
2025-03-07 10:19:59,036 - INFO - training batch 301, loss: 0.028, 9632/28000 datapoints
2025-03-07 10:19:59,325 - INFO - training batch 351, loss: 0.046, 11232/28000 datapoints
2025-03-07 10:19:59,596 - INFO - training batch 401, loss: 0.054, 12832/28000 datapoints
2025-03-07 10:19:59,882 - INFO - training batch 451, loss: 0.036, 14432/28000 datapoints
2025-03-07 10:20:00,150 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-07 10:20:00,440 - INFO - training batch 551, loss: 0.032, 17632/28000 datapoints
2025-03-07 10:20:00,718 - INFO - training batch 601, loss: 0.017, 19232/28000 datapoints
2025-03-07 10:20:00,995 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:20:01,269 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-07 10:20:01,548 - INFO - training batch 751, loss: 0.035, 24032/28000 datapoints
2025-03-07 10:20:01,827 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-07 10:20:02,108 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-07 10:20:02,249 - INFO - validation batch 1, loss: 0.196, 32/6976 datapoints
2025-03-07 10:20:02,329 - INFO - validation batch 51, loss: 2.927, 1632/6976 datapoints
2025-03-07 10:20:02,435 - INFO - validation batch 101, loss: 1.079, 3232/6976 datapoints
2025-03-07 10:20:02,513 - INFO - validation batch 151, loss: 0.600, 4832/6976 datapoints
2025-03-07 10:20:02,595 - INFO - validation batch 201, loss: 2.286, 6432/6976 datapoints
2025-03-07 10:20:02,624 - INFO - Epoch 255/800 done.
2025-03-07 10:20:02,625 - INFO - Final validation performance:
Loss: 1.418, top-1 acc: 0.871top-5 acc: 0.871
2025-03-07 10:20:02,625 - INFO - Beginning epoch 256/800
2025-03-07 10:20:02,633 - INFO - training batch 1, loss: 0.036, 32/28000 datapoints
2025-03-07 10:20:02,922 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-07 10:20:03,188 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 10:20:03,466 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-07 10:20:03,736 - INFO - training batch 201, loss: 0.171, 6432/28000 datapoints
2025-03-07 10:20:03,997 - INFO - training batch 251, loss: 0.062, 8032/28000 datapoints
2025-03-07 10:20:04,280 - INFO - training batch 301, loss: 0.025, 9632/28000 datapoints
2025-03-07 10:20:04,568 - INFO - training batch 351, loss: 0.090, 11232/28000 datapoints
2025-03-07 10:20:04,830 - INFO - training batch 401, loss: 0.050, 12832/28000 datapoints
2025-03-07 10:20:05,097 - INFO - training batch 451, loss: 0.038, 14432/28000 datapoints
2025-03-07 10:20:05,374 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-07 10:20:05,633 - INFO - training batch 551, loss: 0.028, 17632/28000 datapoints
2025-03-07 10:20:05,911 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-07 10:20:06,172 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:20:06,448 - INFO - training batch 701, loss: 0.021, 22432/28000 datapoints
2025-03-07 10:20:06,708 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-07 10:20:06,973 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-07 10:20:07,258 - INFO - training batch 851, loss: 0.014, 27232/28000 datapoints
2025-03-07 10:20:07,410 - INFO - validation batch 1, loss: 0.203, 32/6976 datapoints
2025-03-07 10:20:07,485 - INFO - validation batch 51, loss: 3.037, 1632/6976 datapoints
2025-03-07 10:20:07,563 - INFO - validation batch 101, loss: 0.840, 3232/6976 datapoints
2025-03-07 10:20:07,636 - INFO - validation batch 151, loss: 0.335, 4832/6976 datapoints
2025-03-07 10:20:07,706 - INFO - validation batch 201, loss: 2.089, 6432/6976 datapoints
2025-03-07 10:20:07,731 - INFO - Epoch 256/800 done.
2025-03-07 10:20:07,731 - INFO - Final validation performance:
Loss: 1.301, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:20:07,732 - INFO - Beginning epoch 257/800
2025-03-07 10:20:07,740 - INFO - training batch 1, loss: 0.016, 32/28000 datapoints
2025-03-07 10:20:08,014 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-07 10:20:08,277 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-07 10:20:08,529 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-07 10:20:08,806 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-07 10:20:09,070 - INFO - training batch 251, loss: 0.039, 8032/28000 datapoints
2025-03-07 10:20:09,344 - INFO - training batch 301, loss: 0.027, 9632/28000 datapoints
2025-03-07 10:20:09,632 - INFO - training batch 351, loss: 0.051, 11232/28000 datapoints
2025-03-07 10:20:09,910 - INFO - training batch 401, loss: 0.041, 12832/28000 datapoints
2025-03-07 10:20:10,191 - INFO - training batch 451, loss: 0.037, 14432/28000 datapoints
2025-03-07 10:20:10,466 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-07 10:20:10,738 - INFO - training batch 551, loss: 0.030, 17632/28000 datapoints
2025-03-07 10:20:11,037 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-07 10:20:11,323 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:20:11,604 - INFO - training batch 701, loss: 0.020, 22432/28000 datapoints
2025-03-07 10:20:11,881 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-07 10:20:12,157 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:20:12,435 - INFO - training batch 851, loss: 0.019, 27232/28000 datapoints
2025-03-07 10:20:12,569 - INFO - validation batch 1, loss: 0.228, 32/6976 datapoints
2025-03-07 10:20:12,646 - INFO - validation batch 51, loss: 3.172, 1632/6976 datapoints
2025-03-07 10:20:12,723 - INFO - validation batch 101, loss: 0.871, 3232/6976 datapoints
2025-03-07 10:20:12,802 - INFO - validation batch 151, loss: 0.246, 4832/6976 datapoints
2025-03-07 10:20:12,880 - INFO - validation batch 201, loss: 2.071, 6432/6976 datapoints
2025-03-07 10:20:12,911 - INFO - Epoch 257/800 done.
2025-03-07 10:20:12,912 - INFO - Final validation performance:
Loss: 1.317, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:20:12,912 - INFO - Beginning epoch 258/800
2025-03-07 10:20:12,920 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-07 10:20:13,221 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-07 10:20:13,503 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-07 10:20:13,777 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-07 10:20:14,074 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-07 10:20:14,346 - INFO - training batch 251, loss: 0.027, 8032/28000 datapoints
2025-03-07 10:20:14,639 - INFO - training batch 301, loss: 0.021, 9632/28000 datapoints
2025-03-07 10:20:14,925 - INFO - training batch 351, loss: 0.043, 11232/28000 datapoints
2025-03-07 10:20:15,202 - INFO - training batch 401, loss: 0.041, 12832/28000 datapoints
2025-03-07 10:20:15,496 - INFO - training batch 451, loss: 0.029, 14432/28000 datapoints
2025-03-07 10:20:15,775 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-07 10:20:16,073 - INFO - training batch 551, loss: 0.023, 17632/28000 datapoints
2025-03-07 10:20:16,365 - INFO - training batch 601, loss: 0.058, 19232/28000 datapoints
2025-03-07 10:20:16,638 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 10:20:16,915 - INFO - training batch 701, loss: 0.021, 22432/28000 datapoints
2025-03-07 10:20:17,188 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-07 10:20:17,497 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:20:17,774 - INFO - training batch 851, loss: 0.012, 27232/28000 datapoints
2025-03-07 10:20:17,908 - INFO - validation batch 1, loss: 0.221, 32/6976 datapoints
2025-03-07 10:20:17,983 - INFO - validation batch 51, loss: 3.099, 1632/6976 datapoints
2025-03-07 10:20:18,068 - INFO - validation batch 101, loss: 0.888, 3232/6976 datapoints
2025-03-07 10:20:18,161 - INFO - validation batch 151, loss: 0.293, 4832/6976 datapoints
2025-03-07 10:20:18,257 - INFO - validation batch 201, loss: 2.138, 6432/6976 datapoints
2025-03-07 10:20:18,288 - INFO - Epoch 258/800 done.
2025-03-07 10:20:18,288 - INFO - Final validation performance:
Loss: 1.328, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:20:18,289 - INFO - Beginning epoch 259/800
2025-03-07 10:20:18,296 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-07 10:20:18,579 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-07 10:20:18,853 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-07 10:20:19,133 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-07 10:20:19,399 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-07 10:20:19,669 - INFO - training batch 251, loss: 0.035, 8032/28000 datapoints
2025-03-07 10:20:19,943 - INFO - training batch 301, loss: 0.025, 9632/28000 datapoints
2025-03-07 10:20:20,223 - INFO - training batch 351, loss: 0.037, 11232/28000 datapoints
2025-03-07 10:20:20,524 - INFO - training batch 401, loss: 0.035, 12832/28000 datapoints
2025-03-07 10:20:20,859 - INFO - training batch 451, loss: 0.022, 14432/28000 datapoints
2025-03-07 10:20:21,181 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-07 10:20:21,464 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-07 10:20:21,740 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-07 10:20:22,037 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:20:22,345 - INFO - training batch 701, loss: 0.011, 22432/28000 datapoints
2025-03-07 10:20:22,627 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-07 10:20:22,904 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:20:23,172 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-07 10:20:23,310 - INFO - validation batch 1, loss: 0.209, 32/6976 datapoints
2025-03-07 10:20:23,415 - INFO - validation batch 51, loss: 3.098, 1632/6976 datapoints
2025-03-07 10:20:23,556 - INFO - validation batch 101, loss: 0.859, 3232/6976 datapoints
2025-03-07 10:20:23,640 - INFO - validation batch 151, loss: 0.292, 4832/6976 datapoints
2025-03-07 10:20:23,714 - INFO - validation batch 201, loss: 2.128, 6432/6976 datapoints
2025-03-07 10:20:23,738 - INFO - Epoch 259/800 done.
2025-03-07 10:20:23,738 - INFO - Final validation performance:
Loss: 1.317, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:20:23,739 - INFO - Beginning epoch 260/800
2025-03-07 10:20:23,747 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-07 10:20:24,019 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-07 10:20:24,298 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-07 10:20:24,592 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-07 10:20:24,868 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-07 10:20:25,131 - INFO - training batch 251, loss: 0.030, 8032/28000 datapoints
2025-03-07 10:20:25,410 - INFO - training batch 301, loss: 0.023, 9632/28000 datapoints
2025-03-07 10:20:25,682 - INFO - training batch 351, loss: 0.039, 11232/28000 datapoints
2025-03-07 10:20:25,950 - INFO - training batch 401, loss: 0.035, 12832/28000 datapoints
2025-03-07 10:20:26,220 - INFO - training batch 451, loss: 0.020, 14432/28000 datapoints
2025-03-07 10:20:26,480 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-07 10:20:26,747 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-07 10:20:27,016 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-07 10:20:27,280 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:20:27,582 - INFO - training batch 701, loss: 0.014, 22432/28000 datapoints
2025-03-07 10:20:27,846 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-07 10:20:28,103 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:20:28,394 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-07 10:20:28,553 - INFO - validation batch 1, loss: 0.216, 32/6976 datapoints
2025-03-07 10:20:28,651 - INFO - validation batch 51, loss: 3.113, 1632/6976 datapoints
2025-03-07 10:20:28,750 - INFO - validation batch 101, loss: 0.878, 3232/6976 datapoints
2025-03-07 10:20:28,843 - INFO - validation batch 151, loss: 0.320, 4832/6976 datapoints
2025-03-07 10:20:28,939 - INFO - validation batch 201, loss: 2.161, 6432/6976 datapoints
2025-03-07 10:20:29,012 - INFO - Epoch 260/800 done.
2025-03-07 10:20:29,013 - INFO - Final validation performance:
Loss: 1.337, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:20:29,013 - INFO - Beginning epoch 261/800
2025-03-07 10:20:29,022 - INFO - training batch 1, loss: 0.016, 32/28000 datapoints
2025-03-07 10:20:29,333 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-07 10:20:29,651 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-07 10:20:30,013 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-07 10:20:30,317 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-07 10:20:30,625 - INFO - training batch 251, loss: 0.028, 8032/28000 datapoints
2025-03-07 10:20:30,952 - INFO - training batch 301, loss: 0.023, 9632/28000 datapoints
2025-03-07 10:20:31,294 - INFO - training batch 351, loss: 0.036, 11232/28000 datapoints
2025-03-07 10:20:31,576 - INFO - training batch 401, loss: 0.032, 12832/28000 datapoints
2025-03-07 10:20:31,859 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-07 10:20:32,141 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-07 10:20:32,423 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-07 10:20:32,721 - INFO - training batch 601, loss: 0.018, 19232/28000 datapoints
2025-03-07 10:20:32,997 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:20:33,280 - INFO - training batch 701, loss: 0.012, 22432/28000 datapoints
2025-03-07 10:20:33,553 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-07 10:20:33,827 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:20:34,107 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-07 10:20:34,242 - INFO - validation batch 1, loss: 0.219, 32/6976 datapoints
2025-03-07 10:20:34,326 - INFO - validation batch 51, loss: 3.171, 1632/6976 datapoints
2025-03-07 10:20:34,419 - INFO - validation batch 101, loss: 0.913, 3232/6976 datapoints
2025-03-07 10:20:34,505 - INFO - validation batch 151, loss: 0.398, 4832/6976 datapoints
2025-03-07 10:20:34,590 - INFO - validation batch 201, loss: 2.184, 6432/6976 datapoints
2025-03-07 10:20:34,618 - INFO - Epoch 261/800 done.
2025-03-07 10:20:34,619 - INFO - Final validation performance:
Loss: 1.377, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:20:34,619 - INFO - Beginning epoch 262/800
2025-03-07 10:20:34,627 - INFO - training batch 1, loss: 0.018, 32/28000 datapoints
2025-03-07 10:20:34,920 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-07 10:20:35,208 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-07 10:20:35,513 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-07 10:20:35,801 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-07 10:20:36,079 - INFO - training batch 251, loss: 0.025, 8032/28000 datapoints
2025-03-07 10:20:36,375 - INFO - training batch 301, loss: 0.026, 9632/28000 datapoints
2025-03-07 10:20:36,666 - INFO - training batch 351, loss: 0.043, 11232/28000 datapoints
2025-03-07 10:20:36,945 - INFO - training batch 401, loss: 0.037, 12832/28000 datapoints
2025-03-07 10:20:37,236 - INFO - training batch 451, loss: 0.035, 14432/28000 datapoints
2025-03-07 10:20:37,530 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-07 10:20:37,844 - INFO - training batch 551, loss: 0.089, 17632/28000 datapoints
2025-03-07 10:20:38,140 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-07 10:20:38,430 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:20:38,719 - INFO - training batch 701, loss: 0.030, 22432/28000 datapoints
2025-03-07 10:20:38,996 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-07 10:20:39,269 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-07 10:20:39,552 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-07 10:20:39,691 - INFO - validation batch 1, loss: 0.358, 32/6976 datapoints
2025-03-07 10:20:39,765 - INFO - validation batch 51, loss: 3.314, 1632/6976 datapoints
2025-03-07 10:20:39,846 - INFO - validation batch 101, loss: 0.912, 3232/6976 datapoints
2025-03-07 10:20:39,929 - INFO - validation batch 151, loss: 0.220, 4832/6976 datapoints
2025-03-07 10:20:40,007 - INFO - validation batch 201, loss: 2.156, 6432/6976 datapoints
2025-03-07 10:20:40,036 - INFO - Epoch 262/800 done.
2025-03-07 10:20:40,036 - INFO - Final validation performance:
Loss: 1.392, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:20:40,037 - INFO - Beginning epoch 263/800
2025-03-07 10:20:40,059 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-07 10:20:40,401 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-07 10:20:40,687 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-07 10:20:40,963 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-07 10:20:41,229 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-07 10:20:41,503 - INFO - training batch 251, loss: 0.026, 8032/28000 datapoints
2025-03-07 10:20:41,775 - INFO - training batch 301, loss: 0.020, 9632/28000 datapoints
2025-03-07 10:20:42,051 - INFO - training batch 351, loss: 0.028, 11232/28000 datapoints
2025-03-07 10:20:42,310 - INFO - training batch 401, loss: 0.031, 12832/28000 datapoints
2025-03-07 10:20:42,575 - INFO - training batch 451, loss: 0.023, 14432/28000 datapoints
2025-03-07 10:20:42,835 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-07 10:20:43,100 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-07 10:20:43,367 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-07 10:20:43,634 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:20:43,902 - INFO - training batch 701, loss: 0.016, 22432/28000 datapoints
2025-03-07 10:20:44,162 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-07 10:20:44,424 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:20:44,697 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-07 10:20:44,842 - INFO - validation batch 1, loss: 0.291, 32/6976 datapoints
2025-03-07 10:20:44,957 - INFO - validation batch 51, loss: 3.239, 1632/6976 datapoints
2025-03-07 10:20:45,034 - INFO - validation batch 101, loss: 0.855, 3232/6976 datapoints
2025-03-07 10:20:45,110 - INFO - validation batch 151, loss: 0.357, 4832/6976 datapoints
2025-03-07 10:20:45,184 - INFO - validation batch 201, loss: 2.296, 6432/6976 datapoints
2025-03-07 10:20:45,217 - INFO - Epoch 263/800 done.
2025-03-07 10:20:45,217 - INFO - Final validation performance:
Loss: 1.408, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:20:45,218 - INFO - Beginning epoch 264/800
2025-03-07 10:20:45,225 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-07 10:20:45,527 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-07 10:20:45,793 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-07 10:20:46,058 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-07 10:20:46,316 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-07 10:20:46,578 - INFO - training batch 251, loss: 0.044, 8032/28000 datapoints
2025-03-07 10:20:46,849 - INFO - training batch 301, loss: 0.018, 9632/28000 datapoints
2025-03-07 10:20:47,130 - INFO - training batch 351, loss: 0.026, 11232/28000 datapoints
2025-03-07 10:20:47,390 - INFO - training batch 401, loss: 0.024, 12832/28000 datapoints
2025-03-07 10:20:47,674 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-07 10:20:47,952 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-07 10:20:48,215 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-07 10:20:48,485 - INFO - training batch 601, loss: 0.016, 19232/28000 datapoints
2025-03-07 10:20:48,744 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-07 10:20:49,001 - INFO - training batch 701, loss: 0.015, 22432/28000 datapoints
2025-03-07 10:20:49,263 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-07 10:20:49,531 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-07 10:20:49,805 - INFO - training batch 851, loss: 0.013, 27232/28000 datapoints
2025-03-07 10:20:49,939 - INFO - validation batch 1, loss: 0.223, 32/6976 datapoints
2025-03-07 10:20:50,018 - INFO - validation batch 51, loss: 3.262, 1632/6976 datapoints
2025-03-07 10:20:50,090 - INFO - validation batch 101, loss: 0.884, 3232/6976 datapoints
2025-03-07 10:20:50,165 - INFO - validation batch 151, loss: 0.289, 4832/6976 datapoints
2025-03-07 10:20:50,269 - INFO - validation batch 201, loss: 2.190, 6432/6976 datapoints
2025-03-07 10:20:50,322 - INFO - Epoch 264/800 done.
2025-03-07 10:20:50,322 - INFO - Final validation performance:
Loss: 1.370, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:20:50,323 - INFO - Beginning epoch 265/800
2025-03-07 10:20:50,341 - INFO - training batch 1, loss: 0.011, 32/28000 datapoints
2025-03-07 10:20:50,727 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:20:51,023 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 10:20:51,304 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-07 10:20:51,579 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-07 10:20:51,858 - INFO - training batch 251, loss: 0.018, 8032/28000 datapoints
2025-03-07 10:20:52,171 - INFO - training batch 301, loss: 0.029, 9632/28000 datapoints
2025-03-07 10:20:52,471 - INFO - training batch 351, loss: 0.019, 11232/28000 datapoints
2025-03-07 10:20:52,745 - INFO - training batch 401, loss: 0.027, 12832/28000 datapoints
2025-03-07 10:20:53,027 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-07 10:20:53,315 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-07 10:20:53,643 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-07 10:20:53,926 - INFO - training batch 601, loss: 0.013, 19232/28000 datapoints
2025-03-07 10:20:54,228 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:20:54,509 - INFO - training batch 701, loss: 0.013, 22432/28000 datapoints
2025-03-07 10:20:54,790 - INFO - training batch 751, loss: 0.018, 24032/28000 datapoints
2025-03-07 10:20:55,060 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:20:55,354 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-07 10:20:55,494 - INFO - validation batch 1, loss: 0.313, 32/6976 datapoints
2025-03-07 10:20:55,570 - INFO - validation batch 51, loss: 3.245, 1632/6976 datapoints
2025-03-07 10:20:55,656 - INFO - validation batch 101, loss: 0.860, 3232/6976 datapoints
2025-03-07 10:20:55,744 - INFO - validation batch 151, loss: 0.273, 4832/6976 datapoints
2025-03-07 10:20:55,827 - INFO - validation batch 201, loss: 2.164, 6432/6976 datapoints
2025-03-07 10:20:55,862 - INFO - Epoch 265/800 done.
2025-03-07 10:20:55,863 - INFO - Final validation performance:
Loss: 1.371, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:20:55,863 - INFO - Beginning epoch 266/800
2025-03-07 10:20:55,871 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-07 10:20:56,174 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:20:56,459 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 10:20:56,737 - INFO - training batch 151, loss: 0.013, 4832/28000 datapoints
2025-03-07 10:20:57,012 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-07 10:20:57,284 - INFO - training batch 251, loss: 0.014, 8032/28000 datapoints
2025-03-07 10:20:57,584 - INFO - training batch 301, loss: 0.020, 9632/28000 datapoints
2025-03-07 10:20:57,896 - INFO - training batch 351, loss: 0.025, 11232/28000 datapoints
2025-03-07 10:20:58,166 - INFO - training batch 401, loss: 0.022, 12832/28000 datapoints
2025-03-07 10:20:58,449 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-07 10:20:58,725 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-07 10:20:59,006 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-07 10:20:59,292 - INFO - training batch 601, loss: 0.017, 19232/28000 datapoints
2025-03-07 10:20:59,565 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:20:59,841 - INFO - training batch 701, loss: 0.013, 22432/28000 datapoints
2025-03-07 10:21:00,128 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-07 10:21:00,406 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:21:00,694 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-07 10:21:00,832 - INFO - validation batch 1, loss: 0.272, 32/6976 datapoints
2025-03-07 10:21:00,909 - INFO - validation batch 51, loss: 3.359, 1632/6976 datapoints
2025-03-07 10:21:00,986 - INFO - validation batch 101, loss: 0.874, 3232/6976 datapoints
2025-03-07 10:21:01,065 - INFO - validation batch 151, loss: 0.306, 4832/6976 datapoints
2025-03-07 10:21:01,145 - INFO - validation batch 201, loss: 2.243, 6432/6976 datapoints
2025-03-07 10:21:01,176 - INFO - Epoch 266/800 done.
2025-03-07 10:21:01,177 - INFO - Final validation performance:
Loss: 1.411, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:21:01,177 - INFO - Beginning epoch 267/800
2025-03-07 10:21:01,185 - INFO - training batch 1, loss: 0.011, 32/28000 datapoints
2025-03-07 10:21:01,484 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:21:01,761 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 10:21:02,037 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-07 10:21:02,305 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-07 10:21:02,575 - INFO - training batch 251, loss: 0.012, 8032/28000 datapoints
2025-03-07 10:21:02,858 - INFO - training batch 301, loss: 0.015, 9632/28000 datapoints
2025-03-07 10:21:03,133 - INFO - training batch 351, loss: 0.027, 11232/28000 datapoints
2025-03-07 10:21:03,401 - INFO - training batch 401, loss: 0.024, 12832/28000 datapoints
2025-03-07 10:21:03,662 - INFO - training batch 451, loss: 0.013, 14432/28000 datapoints
2025-03-07 10:21:03,927 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-07 10:21:04,197 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-07 10:21:04,471 - INFO - training batch 601, loss: 0.014, 19232/28000 datapoints
2025-03-07 10:21:04,732 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:21:05,000 - INFO - training batch 701, loss: 0.013, 22432/28000 datapoints
2025-03-07 10:21:05,266 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-07 10:21:05,533 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-07 10:21:05,802 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-07 10:21:05,936 - INFO - validation batch 1, loss: 0.252, 32/6976 datapoints
2025-03-07 10:21:06,008 - INFO - validation batch 51, loss: 3.419, 1632/6976 datapoints
2025-03-07 10:21:06,081 - INFO - validation batch 101, loss: 0.899, 3232/6976 datapoints
2025-03-07 10:21:06,153 - INFO - validation batch 151, loss: 0.356, 4832/6976 datapoints
2025-03-07 10:21:06,222 - INFO - validation batch 201, loss: 2.271, 6432/6976 datapoints
2025-03-07 10:21:06,245 - INFO - Epoch 267/800 done.
2025-03-07 10:21:06,245 - INFO - Final validation performance:
Loss: 1.440, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:21:06,246 - INFO - Beginning epoch 268/800
2025-03-07 10:21:06,254 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-07 10:21:06,523 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:21:06,787 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-07 10:21:07,046 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-07 10:21:07,314 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-07 10:21:07,579 - INFO - training batch 251, loss: 0.019, 8032/28000 datapoints
2025-03-07 10:21:07,854 - INFO - training batch 301, loss: 0.016, 9632/28000 datapoints
2025-03-07 10:21:08,150 - INFO - training batch 351, loss: 0.031, 11232/28000 datapoints
2025-03-07 10:21:08,406 - INFO - training batch 401, loss: 0.025, 12832/28000 datapoints
2025-03-07 10:21:08,696 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-07 10:21:08,957 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-07 10:21:09,224 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-07 10:21:09,509 - INFO - training batch 601, loss: 0.014, 19232/28000 datapoints
2025-03-07 10:21:09,764 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:21:10,028 - INFO - training batch 701, loss: 0.012, 22432/28000 datapoints
2025-03-07 10:21:10,293 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-07 10:21:10,554 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:21:10,831 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-07 10:21:10,964 - INFO - validation batch 1, loss: 0.247, 32/6976 datapoints
2025-03-07 10:21:11,032 - INFO - validation batch 51, loss: 3.507, 1632/6976 datapoints
2025-03-07 10:21:11,118 - INFO - validation batch 101, loss: 0.941, 3232/6976 datapoints
2025-03-07 10:21:11,191 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-07 10:21:11,264 - INFO - validation batch 201, loss: 2.280, 6432/6976 datapoints
2025-03-07 10:21:11,293 - INFO - Epoch 268/800 done.
2025-03-07 10:21:11,293 - INFO - Final validation performance:
Loss: 1.472, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:21:11,294 - INFO - Beginning epoch 269/800
2025-03-07 10:21:11,303 - INFO - training batch 1, loss: 0.014, 32/28000 datapoints
2025-03-07 10:21:11,597 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-07 10:21:11,867 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 10:21:12,140 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-07 10:21:12,423 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-07 10:21:12,698 - INFO - training batch 251, loss: 0.017, 8032/28000 datapoints
2025-03-07 10:21:12,978 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-07 10:21:13,253 - INFO - training batch 351, loss: 0.073, 11232/28000 datapoints
2025-03-07 10:21:13,534 - INFO - training batch 401, loss: 0.029, 12832/28000 datapoints
2025-03-07 10:21:13,817 - INFO - training batch 451, loss: 0.211, 14432/28000 datapoints
2025-03-07 10:21:14,100 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:21:14,390 - INFO - training batch 551, loss: 0.157, 17632/28000 datapoints
2025-03-07 10:21:14,675 - INFO - training batch 601, loss: 0.012, 19232/28000 datapoints
2025-03-07 10:21:14,961 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:21:15,250 - INFO - training batch 701, loss: 0.018, 22432/28000 datapoints
2025-03-07 10:21:15,531 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-07 10:21:15,813 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-07 10:21:16,105 - INFO - training batch 851, loss: 0.059, 27232/28000 datapoints
2025-03-07 10:21:16,244 - INFO - validation batch 1, loss: 0.189, 32/6976 datapoints
2025-03-07 10:21:16,321 - INFO - validation batch 51, loss: 3.497, 1632/6976 datapoints
2025-03-07 10:21:16,402 - INFO - validation batch 101, loss: 1.102, 3232/6976 datapoints
2025-03-07 10:21:16,488 - INFO - validation batch 151, loss: 0.701, 4832/6976 datapoints
2025-03-07 10:21:16,567 - INFO - validation batch 201, loss: 2.453, 6432/6976 datapoints
2025-03-07 10:21:16,592 - INFO - Epoch 269/800 done.
2025-03-07 10:21:16,592 - INFO - Final validation performance:
Loss: 1.588, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:21:16,593 - INFO - Beginning epoch 270/800
2025-03-07 10:21:16,603 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-07 10:21:16,914 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-07 10:21:17,195 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 10:21:17,490 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-07 10:21:17,771 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-07 10:21:18,081 - INFO - training batch 251, loss: 0.025, 8032/28000 datapoints
2025-03-07 10:21:18,373 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-07 10:21:18,663 - INFO - training batch 351, loss: 0.024, 11232/28000 datapoints
2025-03-07 10:21:18,930 - INFO - training batch 401, loss: 0.033, 12832/28000 datapoints
2025-03-07 10:21:19,211 - INFO - training batch 451, loss: 0.031, 14432/28000 datapoints
2025-03-07 10:21:19,494 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-07 10:21:19,772 - INFO - training batch 551, loss: 0.017, 17632/28000 datapoints
2025-03-07 10:21:20,066 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-07 10:21:20,349 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:21:20,637 - INFO - training batch 701, loss: 0.017, 22432/28000 datapoints
2025-03-07 10:21:20,914 - INFO - training batch 751, loss: 0.034, 24032/28000 datapoints
2025-03-07 10:21:21,183 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-07 10:21:21,497 - INFO - training batch 851, loss: 0.045, 27232/28000 datapoints
2025-03-07 10:21:21,639 - INFO - validation batch 1, loss: 0.260, 32/6976 datapoints
2025-03-07 10:21:21,712 - INFO - validation batch 51, loss: 3.527, 1632/6976 datapoints
2025-03-07 10:21:21,791 - INFO - validation batch 101, loss: 0.960, 3232/6976 datapoints
2025-03-07 10:21:21,872 - INFO - validation batch 151, loss: 0.248, 4832/6976 datapoints
2025-03-07 10:21:21,950 - INFO - validation batch 201, loss: 2.449, 6432/6976 datapoints
2025-03-07 10:21:21,978 - INFO - Epoch 270/800 done.
2025-03-07 10:21:21,979 - INFO - Final validation performance:
Loss: 1.489, top-1 acc: 0.873top-5 acc: 0.873
2025-03-07 10:21:21,979 - INFO - Beginning epoch 271/800
2025-03-07 10:21:21,987 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-07 10:21:22,292 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-07 10:21:22,568 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-07 10:21:22,846 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-07 10:21:23,115 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-07 10:21:23,386 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-07 10:21:23,662 - INFO - training batch 301, loss: 0.016, 9632/28000 datapoints
2025-03-07 10:21:23,937 - INFO - training batch 351, loss: 0.024, 11232/28000 datapoints
2025-03-07 10:21:24,200 - INFO - training batch 401, loss: 0.029, 12832/28000 datapoints
2025-03-07 10:21:24,463 - INFO - training batch 451, loss: 0.038, 14432/28000 datapoints
2025-03-07 10:21:24,729 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-07 10:21:24,995 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-07 10:21:25,282 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-07 10:21:25,537 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:21:25,802 - INFO - training batch 701, loss: 0.015, 22432/28000 datapoints
2025-03-07 10:21:26,087 - INFO - training batch 751, loss: 0.018, 24032/28000 datapoints
2025-03-07 10:21:26,366 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:21:26,640 - INFO - training batch 851, loss: 0.030, 27232/28000 datapoints
2025-03-07 10:21:26,770 - INFO - validation batch 1, loss: 0.273, 32/6976 datapoints
2025-03-07 10:21:26,842 - INFO - validation batch 51, loss: 3.514, 1632/6976 datapoints
2025-03-07 10:21:26,912 - INFO - validation batch 101, loss: 0.928, 3232/6976 datapoints
2025-03-07 10:21:26,982 - INFO - validation batch 151, loss: 0.232, 4832/6976 datapoints
2025-03-07 10:21:27,056 - INFO - validation batch 201, loss: 2.329, 6432/6976 datapoints
2025-03-07 10:21:27,080 - INFO - Epoch 271/800 done.
2025-03-07 10:21:27,081 - INFO - Final validation performance:
Loss: 1.455, top-1 acc: 0.873top-5 acc: 0.873
2025-03-07 10:21:27,081 - INFO - Beginning epoch 272/800
2025-03-07 10:21:27,089 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-07 10:21:27,389 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:21:27,756 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-07 10:21:28,103 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-07 10:21:28,394 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-07 10:21:28,657 - INFO - training batch 251, loss: 0.017, 8032/28000 datapoints
2025-03-07 10:21:28,929 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-07 10:21:29,200 - INFO - training batch 351, loss: 0.038, 11232/28000 datapoints
2025-03-07 10:21:29,463 - INFO - training batch 401, loss: 0.033, 12832/28000 datapoints
2025-03-07 10:21:29,733 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-07 10:21:30,001 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-07 10:21:30,335 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-07 10:21:30,674 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-07 10:21:30,964 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 10:21:31,314 - INFO - training batch 701, loss: 0.075, 22432/28000 datapoints
2025-03-07 10:21:31,681 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-07 10:21:31,975 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-07 10:21:32,266 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-07 10:21:32,414 - INFO - validation batch 1, loss: 0.274, 32/6976 datapoints
2025-03-07 10:21:32,490 - INFO - validation batch 51, loss: 3.577, 1632/6976 datapoints
2025-03-07 10:21:32,568 - INFO - validation batch 101, loss: 0.884, 3232/6976 datapoints
2025-03-07 10:21:32,649 - INFO - validation batch 151, loss: 0.450, 4832/6976 datapoints
2025-03-07 10:21:32,731 - INFO - validation batch 201, loss: 2.216, 6432/6976 datapoints
2025-03-07 10:21:32,763 - INFO - Epoch 272/800 done.
2025-03-07 10:21:32,763 - INFO - Final validation performance:
Loss: 1.480, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:21:32,764 - INFO - Beginning epoch 273/800
2025-03-07 10:21:32,772 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-07 10:21:33,745 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:21:34,074 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-07 10:21:34,363 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-07 10:21:34,637 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-07 10:21:34,923 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-07 10:21:35,260 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-07 10:21:35,554 - INFO - training batch 351, loss: 0.022, 11232/28000 datapoints
2025-03-07 10:21:35,831 - INFO - training batch 401, loss: 0.022, 12832/28000 datapoints
2025-03-07 10:21:36,115 - INFO - training batch 451, loss: 0.015, 14432/28000 datapoints
2025-03-07 10:21:36,409 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-07 10:21:36,684 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-07 10:21:36,960 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-07 10:21:37,226 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:21:37,513 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-07 10:21:37,790 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-07 10:21:38,062 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:21:38,441 - INFO - training batch 851, loss: 0.017, 27232/28000 datapoints
2025-03-07 10:21:38,604 - INFO - validation batch 1, loss: 0.320, 32/6976 datapoints
2025-03-07 10:21:38,694 - INFO - validation batch 51, loss: 3.628, 1632/6976 datapoints
2025-03-07 10:21:38,783 - INFO - validation batch 101, loss: 0.863, 3232/6976 datapoints
2025-03-07 10:21:38,863 - INFO - validation batch 151, loss: 0.278, 4832/6976 datapoints
2025-03-07 10:21:38,944 - INFO - validation batch 201, loss: 2.240, 6432/6976 datapoints
2025-03-07 10:21:38,976 - INFO - Epoch 273/800 done.
2025-03-07 10:21:38,976 - INFO - Final validation performance:
Loss: 1.466, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:21:38,977 - INFO - Beginning epoch 274/800
2025-03-07 10:21:38,986 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-07 10:21:39,277 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:21:39,554 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-07 10:21:39,854 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-07 10:21:40,150 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-07 10:21:40,474 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-07 10:21:40,783 - INFO - training batch 301, loss: 0.023, 9632/28000 datapoints
2025-03-07 10:21:41,083 - INFO - training batch 351, loss: 0.126, 11232/28000 datapoints
2025-03-07 10:21:41,407 - INFO - training batch 401, loss: 0.033, 12832/28000 datapoints
2025-03-07 10:21:41,705 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-07 10:21:42,078 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-07 10:21:42,409 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-07 10:21:42,693 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-07 10:21:42,955 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:21:43,229 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-07 10:21:43,518 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-07 10:21:43,791 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-07 10:21:44,080 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-07 10:21:44,219 - INFO - validation batch 1, loss: 0.308, 32/6976 datapoints
2025-03-07 10:21:44,300 - INFO - validation batch 51, loss: 3.558, 1632/6976 datapoints
2025-03-07 10:21:44,401 - INFO - validation batch 101, loss: 0.948, 3232/6976 datapoints
2025-03-07 10:21:44,493 - INFO - validation batch 151, loss: 0.312, 4832/6976 datapoints
2025-03-07 10:21:44,589 - INFO - validation batch 201, loss: 2.310, 6432/6976 datapoints
2025-03-07 10:21:44,617 - INFO - Epoch 274/800 done.
2025-03-07 10:21:44,617 - INFO - Final validation performance:
Loss: 1.487, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:21:44,618 - INFO - Beginning epoch 275/800
2025-03-07 10:21:44,626 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-07 10:21:44,923 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:21:45,225 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-07 10:21:45,518 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-07 10:21:45,804 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-07 10:21:46,100 - INFO - training batch 251, loss: 0.039, 8032/28000 datapoints
2025-03-07 10:21:46,406 - INFO - training batch 301, loss: 0.065, 9632/28000 datapoints
2025-03-07 10:21:46,702 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-07 10:21:46,987 - INFO - training batch 401, loss: 0.027, 12832/28000 datapoints
2025-03-07 10:21:47,266 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-07 10:21:47,549 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:21:47,834 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-07 10:21:48,131 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-07 10:21:48,440 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:21:48,726 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-07 10:21:49,028 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-07 10:21:49,335 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-07 10:21:49,645 - INFO - training batch 851, loss: 0.018, 27232/28000 datapoints
2025-03-07 10:21:49,795 - INFO - validation batch 1, loss: 0.287, 32/6976 datapoints
2025-03-07 10:21:49,879 - INFO - validation batch 51, loss: 3.762, 1632/6976 datapoints
2025-03-07 10:21:49,955 - INFO - validation batch 101, loss: 0.901, 3232/6976 datapoints
2025-03-07 10:21:50,050 - INFO - validation batch 151, loss: 0.245, 4832/6976 datapoints
2025-03-07 10:21:50,130 - INFO - validation batch 201, loss: 2.304, 6432/6976 datapoints
2025-03-07 10:21:50,164 - INFO - Epoch 275/800 done.
2025-03-07 10:21:50,164 - INFO - Final validation performance:
Loss: 1.500, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:21:50,165 - INFO - Beginning epoch 276/800
2025-03-07 10:21:50,174 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-07 10:21:50,500 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:21:50,786 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 10:21:51,073 - INFO - training batch 151, loss: 0.013, 4832/28000 datapoints
2025-03-07 10:21:51,357 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-07 10:21:51,685 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-07 10:21:52,039 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-07 10:21:52,384 - INFO - training batch 351, loss: 0.115, 11232/28000 datapoints
2025-03-07 10:21:52,718 - INFO - training batch 401, loss: 0.022, 12832/28000 datapoints
2025-03-07 10:21:53,034 - INFO - training batch 451, loss: 0.015, 14432/28000 datapoints
2025-03-07 10:21:53,357 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-07 10:21:53,665 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-07 10:21:53,965 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-07 10:21:54,255 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:21:54,550 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-07 10:21:54,861 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-07 10:21:55,301 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-07 10:21:55,615 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-07 10:21:55,771 - INFO - validation batch 1, loss: 0.351, 32/6976 datapoints
2025-03-07 10:21:55,855 - INFO - validation batch 51, loss: 3.770, 1632/6976 datapoints
2025-03-07 10:21:55,961 - INFO - validation batch 101, loss: 0.951, 3232/6976 datapoints
2025-03-07 10:21:56,046 - INFO - validation batch 151, loss: 0.306, 4832/6976 datapoints
2025-03-07 10:21:56,128 - INFO - validation batch 201, loss: 2.355, 6432/6976 datapoints
2025-03-07 10:21:56,159 - INFO - Epoch 276/800 done.
2025-03-07 10:21:56,159 - INFO - Final validation performance:
Loss: 1.547, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:21:56,160 - INFO - Beginning epoch 277/800
2025-03-07 10:21:56,168 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-07 10:21:56,547 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:21:56,866 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 10:21:57,186 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-07 10:21:57,567 - INFO - training batch 201, loss: 0.091, 6432/28000 datapoints
2025-03-07 10:21:57,913 - INFO - training batch 251, loss: 0.145, 8032/28000 datapoints
2025-03-07 10:21:58,246 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-07 10:21:58,594 - INFO - training batch 351, loss: 0.022, 11232/28000 datapoints
2025-03-07 10:21:58,896 - INFO - training batch 401, loss: 0.018, 12832/28000 datapoints
2025-03-07 10:21:59,194 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-07 10:21:59,505 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-07 10:21:59,805 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-07 10:22:00,102 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-07 10:22:00,403 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:22:00,704 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-07 10:22:01,019 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-07 10:22:01,342 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:22:01,676 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-07 10:22:01,846 - INFO - validation batch 1, loss: 0.355, 32/6976 datapoints
2025-03-07 10:22:01,922 - INFO - validation batch 51, loss: 3.663, 1632/6976 datapoints
2025-03-07 10:22:02,007 - INFO - validation batch 101, loss: 0.877, 3232/6976 datapoints
2025-03-07 10:22:02,091 - INFO - validation batch 151, loss: 0.199, 4832/6976 datapoints
2025-03-07 10:22:02,179 - INFO - validation batch 201, loss: 2.385, 6432/6976 datapoints
2025-03-07 10:22:02,205 - INFO - Epoch 277/800 done.
2025-03-07 10:22:02,206 - INFO - Final validation performance:
Loss: 1.496, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:22:02,207 - INFO - Beginning epoch 278/800
2025-03-07 10:22:02,215 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-07 10:22:02,539 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:22:02,833 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 10:22:03,141 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-07 10:22:03,464 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-07 10:22:03,780 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-07 10:22:04,083 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-07 10:22:04,417 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-07 10:22:04,703 - INFO - training batch 401, loss: 0.037, 12832/28000 datapoints
2025-03-07 10:22:05,086 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-07 10:22:05,437 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-07 10:22:05,755 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-07 10:22:06,069 - INFO - training batch 601, loss: 0.070, 19232/28000 datapoints
2025-03-07 10:22:06,368 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-07 10:22:06,669 - INFO - training batch 701, loss: 0.023, 22432/28000 datapoints
2025-03-07 10:22:06,965 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-07 10:22:07,249 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:22:07,569 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-07 10:22:07,711 - INFO - validation batch 1, loss: 0.311, 32/6976 datapoints
2025-03-07 10:22:07,783 - INFO - validation batch 51, loss: 3.282, 1632/6976 datapoints
2025-03-07 10:22:07,856 - INFO - validation batch 101, loss: 0.964, 3232/6976 datapoints
2025-03-07 10:22:07,935 - INFO - validation batch 151, loss: 0.293, 4832/6976 datapoints
2025-03-07 10:22:08,013 - INFO - validation batch 201, loss: 2.392, 6432/6976 datapoints
2025-03-07 10:22:08,041 - INFO - Epoch 278/800 done.
2025-03-07 10:22:08,041 - INFO - Final validation performance:
Loss: 1.448, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:22:08,042 - INFO - Beginning epoch 279/800
2025-03-07 10:22:08,054 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 10:22:08,354 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:22:08,728 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 10:22:09,028 - INFO - training batch 151, loss: 0.008, 4832/28000 datapoints
2025-03-07 10:22:09,326 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-07 10:22:09,640 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-07 10:22:09,976 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-07 10:22:10,289 - INFO - training batch 351, loss: 0.016, 11232/28000 datapoints
2025-03-07 10:22:10,599 - INFO - training batch 401, loss: 0.019, 12832/28000 datapoints
2025-03-07 10:22:10,918 - INFO - training batch 451, loss: 0.019, 14432/28000 datapoints
2025-03-07 10:22:11,225 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:22:11,572 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-07 10:22:11,889 - INFO - training batch 601, loss: 0.009, 19232/28000 datapoints
2025-03-07 10:22:12,199 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:22:12,526 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-07 10:22:12,869 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-07 10:22:13,175 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-07 10:22:13,493 - INFO - training batch 851, loss: 0.016, 27232/28000 datapoints
2025-03-07 10:22:13,644 - INFO - validation batch 1, loss: 0.310, 32/6976 datapoints
2025-03-07 10:22:13,726 - INFO - validation batch 51, loss: 3.572, 1632/6976 datapoints
2025-03-07 10:22:13,803 - INFO - validation batch 101, loss: 0.938, 3232/6976 datapoints
2025-03-07 10:22:13,891 - INFO - validation batch 151, loss: 0.361, 4832/6976 datapoints
2025-03-07 10:22:14,011 - INFO - validation batch 201, loss: 2.384, 6432/6976 datapoints
2025-03-07 10:22:14,049 - INFO - Epoch 279/800 done.
2025-03-07 10:22:14,050 - INFO - Final validation performance:
Loss: 1.513, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:22:14,050 - INFO - Beginning epoch 280/800
2025-03-07 10:22:14,068 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-07 10:22:14,413 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:22:14,761 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 10:22:15,063 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-07 10:22:15,363 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-07 10:22:15,647 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-07 10:22:15,957 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-07 10:22:16,316 - INFO - training batch 351, loss: 0.016, 11232/28000 datapoints
2025-03-07 10:22:16,686 - INFO - training batch 401, loss: 0.021, 12832/28000 datapoints
2025-03-07 10:22:17,005 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-07 10:22:17,326 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:22:17,635 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-07 10:22:17,931 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-07 10:22:18,248 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:22:18,604 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-07 10:22:18,932 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-07 10:22:19,258 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-07 10:22:19,633 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-07 10:22:19,787 - INFO - validation batch 1, loss: 0.262, 32/6976 datapoints
2025-03-07 10:22:19,871 - INFO - validation batch 51, loss: 3.610, 1632/6976 datapoints
2025-03-07 10:22:19,945 - INFO - validation batch 101, loss: 0.909, 3232/6976 datapoints
2025-03-07 10:22:20,037 - INFO - validation batch 151, loss: 0.353, 4832/6976 datapoints
2025-03-07 10:22:20,116 - INFO - validation batch 201, loss: 2.338, 6432/6976 datapoints
2025-03-07 10:22:20,141 - INFO - Epoch 280/800 done.
2025-03-07 10:22:20,141 - INFO - Final validation performance:
Loss: 1.494, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:22:20,142 - INFO - Beginning epoch 281/800
2025-03-07 10:22:20,152 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-07 10:22:20,551 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:22:20,847 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-07 10:22:21,173 - INFO - training batch 151, loss: 0.044, 4832/28000 datapoints
2025-03-07 10:22:21,488 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-07 10:22:21,755 - INFO - training batch 251, loss: 0.012, 8032/28000 datapoints
2025-03-07 10:22:22,061 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-07 10:22:22,352 - INFO - training batch 351, loss: 0.015, 11232/28000 datapoints
2025-03-07 10:22:22,641 - INFO - training batch 401, loss: 0.014, 12832/28000 datapoints
2025-03-07 10:22:22,931 - INFO - training batch 451, loss: 0.024, 14432/28000 datapoints
2025-03-07 10:22:23,214 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-07 10:22:23,499 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-07 10:22:23,796 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-07 10:22:24,081 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:22:24,382 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-07 10:22:24,683 - INFO - training batch 751, loss: 0.017, 24032/28000 datapoints
2025-03-07 10:22:24,968 - INFO - training batch 801, loss: 0.020, 25632/28000 datapoints
2025-03-07 10:22:25,262 - INFO - training batch 851, loss: 0.016, 27232/28000 datapoints
2025-03-07 10:22:25,412 - INFO - validation batch 1, loss: 0.262, 32/6976 datapoints
2025-03-07 10:22:25,486 - INFO - validation batch 51, loss: 3.605, 1632/6976 datapoints
2025-03-07 10:22:25,560 - INFO - validation batch 101, loss: 0.902, 3232/6976 datapoints
2025-03-07 10:22:25,638 - INFO - validation batch 151, loss: 0.338, 4832/6976 datapoints
2025-03-07 10:22:25,732 - INFO - validation batch 201, loss: 2.387, 6432/6976 datapoints
2025-03-07 10:22:25,767 - INFO - Epoch 281/800 done.
2025-03-07 10:22:25,767 - INFO - Final validation performance:
Loss: 1.499, top-1 acc: 0.873top-5 acc: 0.873
2025-03-07 10:22:25,768 - INFO - Beginning epoch 282/800
2025-03-07 10:22:25,776 - INFO - training batch 1, loss: 0.011, 32/28000 datapoints
2025-03-07 10:22:26,086 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:22:26,406 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 10:22:26,725 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-07 10:22:27,059 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-07 10:22:27,590 - INFO - training batch 251, loss: 0.012, 8032/28000 datapoints
2025-03-07 10:22:27,896 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-07 10:22:28,190 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-07 10:22:28,466 - INFO - training batch 401, loss: 0.021, 12832/28000 datapoints
2025-03-07 10:22:28,808 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-07 10:22:29,113 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:22:29,400 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-07 10:22:29,697 - INFO - training batch 601, loss: 0.006, 19232/28000 datapoints
2025-03-07 10:22:29,987 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:22:30,287 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-07 10:22:30,787 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-07 10:22:31,119 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-07 10:22:31,432 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-07 10:22:31,588 - INFO - validation batch 1, loss: 0.275, 32/6976 datapoints
2025-03-07 10:22:31,779 - INFO - validation batch 51, loss: 3.651, 1632/6976 datapoints
2025-03-07 10:22:31,912 - INFO - validation batch 101, loss: 0.913, 3232/6976 datapoints
2025-03-07 10:22:32,022 - INFO - validation batch 151, loss: 0.360, 4832/6976 datapoints
2025-03-07 10:22:32,126 - INFO - validation batch 201, loss: 2.364, 6432/6976 datapoints
2025-03-07 10:22:32,161 - INFO - Epoch 282/800 done.
2025-03-07 10:22:32,161 - INFO - Final validation performance:
Loss: 1.513, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:22:32,162 - INFO - Beginning epoch 283/800
2025-03-07 10:22:32,171 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-07 10:22:32,613 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:22:33,127 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 10:22:33,631 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-07 10:22:34,003 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-07 10:22:34,414 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-07 10:22:34,750 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-07 10:22:35,076 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-07 10:22:35,458 - INFO - training batch 401, loss: 0.022, 12832/28000 datapoints
2025-03-07 10:22:35,767 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-07 10:22:36,089 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:22:36,415 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-07 10:22:36,755 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-07 10:22:37,055 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:22:37,385 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-07 10:22:37,780 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-07 10:22:38,131 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-07 10:22:38,478 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-07 10:22:38,648 - INFO - validation batch 1, loss: 0.305, 32/6976 datapoints
2025-03-07 10:22:38,733 - INFO - validation batch 51, loss: 3.657, 1632/6976 datapoints
2025-03-07 10:22:38,823 - INFO - validation batch 101, loss: 0.928, 3232/6976 datapoints
2025-03-07 10:22:38,980 - INFO - validation batch 151, loss: 0.356, 4832/6976 datapoints
2025-03-07 10:22:39,096 - INFO - validation batch 201, loss: 2.335, 6432/6976 datapoints
2025-03-07 10:22:39,137 - INFO - Epoch 283/800 done.
2025-03-07 10:22:39,138 - INFO - Final validation performance:
Loss: 1.516, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:22:39,138 - INFO - Beginning epoch 284/800
2025-03-07 10:22:39,156 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-07 10:22:39,569 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:22:39,896 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 10:22:40,242 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-07 10:22:40,553 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-07 10:22:40,861 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-07 10:22:41,188 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-07 10:22:41,498 - INFO - training batch 351, loss: 0.013, 11232/28000 datapoints
2025-03-07 10:22:41,813 - INFO - training batch 401, loss: 0.017, 12832/28000 datapoints
2025-03-07 10:22:42,123 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-07 10:22:42,420 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:22:42,738 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-07 10:22:43,033 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-07 10:22:43,322 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:22:43,611 - INFO - training batch 701, loss: 0.011, 22432/28000 datapoints
2025-03-07 10:22:43,902 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-07 10:22:44,182 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-07 10:22:44,495 - INFO - training batch 851, loss: 0.026, 27232/28000 datapoints
2025-03-07 10:22:44,668 - INFO - validation batch 1, loss: 0.389, 32/6976 datapoints
2025-03-07 10:22:44,769 - INFO - validation batch 51, loss: 3.864, 1632/6976 datapoints
2025-03-07 10:22:44,864 - INFO - validation batch 101, loss: 0.927, 3232/6976 datapoints
2025-03-07 10:22:44,972 - INFO - validation batch 151, loss: 0.665, 4832/6976 datapoints
2025-03-07 10:22:45,110 - INFO - validation batch 201, loss: 2.169, 6432/6976 datapoints
2025-03-07 10:22:45,135 - INFO - Epoch 284/800 done.
2025-03-07 10:22:45,135 - INFO - Final validation performance:
Loss: 1.603, top-1 acc: 0.864top-5 acc: 0.864
2025-03-07 10:22:45,135 - INFO - Beginning epoch 285/800
2025-03-07 10:22:45,143 - INFO - training batch 1, loss: 0.493, 32/28000 datapoints
2025-03-07 10:22:45,453 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:22:45,721 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-07 10:22:46,011 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-07 10:22:46,289 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-07 10:22:46,596 - INFO - training batch 251, loss: 0.034, 8032/28000 datapoints
2025-03-07 10:22:46,949 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-07 10:22:47,220 - INFO - training batch 351, loss: 0.021, 11232/28000 datapoints
2025-03-07 10:22:47,485 - INFO - training batch 401, loss: 0.016, 12832/28000 datapoints
2025-03-07 10:22:47,754 - INFO - training batch 451, loss: 0.028, 14432/28000 datapoints
2025-03-07 10:22:48,020 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-07 10:22:48,291 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-07 10:22:48,556 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-07 10:22:48,822 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:22:49,115 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-07 10:22:49,382 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-07 10:22:49,644 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-07 10:22:49,925 - INFO - training batch 851, loss: 0.023, 27232/28000 datapoints
2025-03-07 10:22:50,057 - INFO - validation batch 1, loss: 0.302, 32/6976 datapoints
2025-03-07 10:22:50,123 - INFO - validation batch 51, loss: 3.825, 1632/6976 datapoints
2025-03-07 10:22:50,195 - INFO - validation batch 101, loss: 0.925, 3232/6976 datapoints
2025-03-07 10:22:50,271 - INFO - validation batch 151, loss: 0.309, 4832/6976 datapoints
2025-03-07 10:22:50,346 - INFO - validation batch 201, loss: 2.299, 6432/6976 datapoints
2025-03-07 10:22:50,372 - INFO - Epoch 285/800 done.
2025-03-07 10:22:50,372 - INFO - Final validation performance:
Loss: 1.532, top-1 acc: 0.873top-5 acc: 0.873
2025-03-07 10:22:50,372 - INFO - Beginning epoch 286/800
2025-03-07 10:22:50,380 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-07 10:22:50,659 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:22:50,933 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 10:22:51,216 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-07 10:22:51,490 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-07 10:22:51,758 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-07 10:22:52,037 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-07 10:22:52,319 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-07 10:22:52,596 - INFO - training batch 401, loss: 0.024, 12832/28000 datapoints
2025-03-07 10:22:52,879 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-07 10:22:53,152 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-07 10:22:53,430 - INFO - training batch 551, loss: 0.030, 17632/28000 datapoints
2025-03-07 10:22:53,712 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-07 10:22:53,986 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:22:54,268 - INFO - training batch 701, loss: 0.024, 22432/28000 datapoints
2025-03-07 10:22:54,548 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-07 10:22:54,880 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:22:55,236 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-07 10:22:55,403 - INFO - validation batch 1, loss: 0.399, 32/6976 datapoints
2025-03-07 10:22:55,487 - INFO - validation batch 51, loss: 3.641, 1632/6976 datapoints
2025-03-07 10:22:55,598 - INFO - validation batch 101, loss: 0.990, 3232/6976 datapoints
2025-03-07 10:22:55,726 - INFO - validation batch 151, loss: 0.420, 4832/6976 datapoints
2025-03-07 10:22:55,850 - INFO - validation batch 201, loss: 2.280, 6432/6976 datapoints
2025-03-07 10:22:55,890 - INFO - Epoch 286/800 done.
2025-03-07 10:22:55,890 - INFO - Final validation performance:
Loss: 1.546, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:22:55,891 - INFO - Beginning epoch 287/800
2025-03-07 10:22:55,903 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 10:22:56,265 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:22:56,666 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-07 10:22:57,024 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-07 10:22:57,446 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-07 10:22:57,924 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-07 10:22:58,387 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-07 10:22:58,976 - INFO - training batch 351, loss: 0.016, 11232/28000 datapoints
2025-03-07 10:22:59,745 - INFO - training batch 401, loss: 0.023, 12832/28000 datapoints
2025-03-07 10:23:00,186 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-07 10:23:00,579 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:23:01,028 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-07 10:23:01,399 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-07 10:23:01,748 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:23:02,166 - INFO - training batch 701, loss: 0.014, 22432/28000 datapoints
2025-03-07 10:23:02,623 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-07 10:23:03,076 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:23:03,604 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-07 10:23:04,062 - INFO - validation batch 1, loss: 0.261, 32/6976 datapoints
2025-03-07 10:23:04,315 - INFO - validation batch 51, loss: 3.743, 1632/6976 datapoints
2025-03-07 10:23:04,467 - INFO - validation batch 101, loss: 0.906, 3232/6976 datapoints
2025-03-07 10:23:04,614 - INFO - validation batch 151, loss: 0.504, 4832/6976 datapoints
2025-03-07 10:23:04,744 - INFO - validation batch 201, loss: 2.295, 6432/6976 datapoints
2025-03-07 10:23:04,787 - INFO - Epoch 287/800 done.
2025-03-07 10:23:04,788 - INFO - Final validation performance:
Loss: 1.542, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:23:04,791 - INFO - Beginning epoch 288/800
2025-03-07 10:23:04,805 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 10:23:05,251 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:23:05,617 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-07 10:23:05,956 - INFO - training batch 151, loss: 0.070, 4832/28000 datapoints
2025-03-07 10:23:06,345 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-07 10:23:06,718 - INFO - training batch 251, loss: 0.044, 8032/28000 datapoints
2025-03-07 10:23:07,111 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-07 10:23:07,453 - INFO - training batch 351, loss: 0.015, 11232/28000 datapoints
2025-03-07 10:23:07,808 - INFO - training batch 401, loss: 0.058, 12832/28000 datapoints
2025-03-07 10:23:08,153 - INFO - training batch 451, loss: 0.020, 14432/28000 datapoints
2025-03-07 10:23:08,508 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:23:08,830 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-07 10:23:09,155 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-07 10:23:09,571 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:23:09,964 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 10:23:10,344 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-07 10:23:10,920 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-07 10:23:11,225 - INFO - training batch 851, loss: 0.019, 27232/28000 datapoints
2025-03-07 10:23:11,376 - INFO - validation batch 1, loss: 0.317, 32/6976 datapoints
2025-03-07 10:23:11,467 - INFO - validation batch 51, loss: 3.684, 1632/6976 datapoints
2025-03-07 10:23:11,556 - INFO - validation batch 101, loss: 0.947, 3232/6976 datapoints
2025-03-07 10:23:11,630 - INFO - validation batch 151, loss: 0.477, 4832/6976 datapoints
2025-03-07 10:23:11,711 - INFO - validation batch 201, loss: 2.375, 6432/6976 datapoints
2025-03-07 10:23:11,740 - INFO - Epoch 288/800 done.
2025-03-07 10:23:11,740 - INFO - Final validation performance:
Loss: 1.560, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:23:11,741 - INFO - Beginning epoch 289/800
2025-03-07 10:23:11,750 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 10:23:12,136 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:23:12,496 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 10:23:12,846 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-07 10:23:13,138 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-07 10:23:13,459 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-07 10:23:13,759 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:23:14,063 - INFO - training batch 351, loss: 0.025, 11232/28000 datapoints
2025-03-07 10:23:14,343 - INFO - training batch 401, loss: 0.029, 12832/28000 datapoints
2025-03-07 10:23:14,668 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-07 10:23:14,942 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:23:15,258 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-07 10:23:15,561 - INFO - training batch 601, loss: 0.009, 19232/28000 datapoints
2025-03-07 10:23:15,844 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:23:16,132 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 10:23:16,437 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-07 10:23:16,709 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-07 10:23:17,006 - INFO - training batch 851, loss: 0.022, 27232/28000 datapoints
2025-03-07 10:23:17,147 - INFO - validation batch 1, loss: 0.376, 32/6976 datapoints
2025-03-07 10:23:17,217 - INFO - validation batch 51, loss: 3.813, 1632/6976 datapoints
2025-03-07 10:23:17,294 - INFO - validation batch 101, loss: 0.973, 3232/6976 datapoints
2025-03-07 10:23:17,363 - INFO - validation batch 151, loss: 0.419, 4832/6976 datapoints
2025-03-07 10:23:17,433 - INFO - validation batch 201, loss: 2.319, 6432/6976 datapoints
2025-03-07 10:23:17,460 - INFO - Epoch 289/800 done.
2025-03-07 10:23:17,460 - INFO - Final validation performance:
Loss: 1.580, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:23:17,461 - INFO - Beginning epoch 290/800
2025-03-07 10:23:17,470 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 10:23:17,777 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:23:18,067 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-07 10:23:18,361 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-07 10:23:18,646 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-07 10:23:18,924 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-07 10:23:19,215 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:23:19,528 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-07 10:23:19,800 - INFO - training batch 401, loss: 0.025, 12832/28000 datapoints
2025-03-07 10:23:20,085 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-07 10:23:20,367 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:23:20,644 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-07 10:23:20,986 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-07 10:23:21,268 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:23:21,561 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-07 10:23:21,841 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-07 10:23:22,126 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:23:22,420 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-07 10:23:22,560 - INFO - validation batch 1, loss: 0.336, 32/6976 datapoints
2025-03-07 10:23:22,636 - INFO - validation batch 51, loss: 3.851, 1632/6976 datapoints
2025-03-07 10:23:22,709 - INFO - validation batch 101, loss: 0.978, 3232/6976 datapoints
2025-03-07 10:23:22,782 - INFO - validation batch 151, loss: 0.438, 4832/6976 datapoints
2025-03-07 10:23:22,870 - INFO - validation batch 201, loss: 2.290, 6432/6976 datapoints
2025-03-07 10:23:22,912 - INFO - Epoch 290/800 done.
2025-03-07 10:23:22,913 - INFO - Final validation performance:
Loss: 1.579, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:23:22,913 - INFO - Beginning epoch 291/800
2025-03-07 10:23:22,920 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-07 10:23:23,214 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:23:23,511 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-07 10:23:23,805 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-07 10:23:24,093 - INFO - training batch 201, loss: 0.205, 6432/28000 datapoints
2025-03-07 10:23:24,387 - INFO - training batch 251, loss: 0.025, 8032/28000 datapoints
2025-03-07 10:23:24,680 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-07 10:23:24,978 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-07 10:23:25,261 - INFO - training batch 401, loss: 0.026, 12832/28000 datapoints
2025-03-07 10:23:25,555 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-07 10:23:25,836 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:23:26,117 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-07 10:23:26,405 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 10:23:26,690 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:23:26,980 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-07 10:23:27,263 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-07 10:23:27,607 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:23:27,899 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-07 10:23:28,039 - INFO - validation batch 1, loss: 0.349, 32/6976 datapoints
2025-03-07 10:23:28,113 - INFO - validation batch 51, loss: 3.846, 1632/6976 datapoints
2025-03-07 10:23:28,186 - INFO - validation batch 101, loss: 0.980, 3232/6976 datapoints
2025-03-07 10:23:28,262 - INFO - validation batch 151, loss: 0.466, 4832/6976 datapoints
2025-03-07 10:23:28,345 - INFO - validation batch 201, loss: 2.433, 6432/6976 datapoints
2025-03-07 10:23:28,378 - INFO - Epoch 291/800 done.
2025-03-07 10:23:28,379 - INFO - Final validation performance:
Loss: 1.615, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:23:28,379 - INFO - Beginning epoch 292/800
2025-03-07 10:23:28,388 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 10:23:28,688 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-07 10:23:28,976 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-07 10:23:29,268 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-07 10:23:29,580 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-07 10:23:29,866 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-07 10:23:30,165 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:23:30,576 - INFO - training batch 351, loss: 0.016, 11232/28000 datapoints
2025-03-07 10:23:30,865 - INFO - training batch 401, loss: 0.021, 12832/28000 datapoints
2025-03-07 10:23:31,158 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-07 10:23:31,474 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:23:31,762 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-07 10:23:32,061 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-07 10:23:32,350 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:23:32,672 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-07 10:23:32,960 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-07 10:23:33,248 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:23:33,552 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-07 10:23:33,724 - INFO - validation batch 1, loss: 0.411, 32/6976 datapoints
2025-03-07 10:23:33,829 - INFO - validation batch 51, loss: 3.730, 1632/6976 datapoints
2025-03-07 10:23:33,932 - INFO - validation batch 101, loss: 0.926, 3232/6976 datapoints
2025-03-07 10:23:34,015 - INFO - validation batch 151, loss: 0.352, 4832/6976 datapoints
2025-03-07 10:23:34,095 - INFO - validation batch 201, loss: 2.391, 6432/6976 datapoints
2025-03-07 10:23:34,131 - INFO - Epoch 292/800 done.
2025-03-07 10:23:34,132 - INFO - Final validation performance:
Loss: 1.562, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:23:34,132 - INFO - Beginning epoch 293/800
2025-03-07 10:23:34,141 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 10:23:34,444 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:23:34,744 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-07 10:23:35,038 - INFO - training batch 151, loss: 0.008, 4832/28000 datapoints
2025-03-07 10:23:35,393 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-07 10:23:35,685 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-07 10:23:35,979 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:23:36,287 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-07 10:23:36,581 - INFO - training batch 401, loss: 0.016, 12832/28000 datapoints
2025-03-07 10:23:36,871 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-07 10:23:37,187 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:23:37,482 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-07 10:23:37,776 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 10:23:38,058 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:23:38,361 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-07 10:23:38,646 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-07 10:23:38,963 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:23:39,262 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-07 10:23:39,409 - INFO - validation batch 1, loss: 0.375, 32/6976 datapoints
2025-03-07 10:23:39,482 - INFO - validation batch 51, loss: 3.753, 1632/6976 datapoints
2025-03-07 10:23:39,556 - INFO - validation batch 101, loss: 0.928, 3232/6976 datapoints
2025-03-07 10:23:39,645 - INFO - validation batch 151, loss: 0.343, 4832/6976 datapoints
2025-03-07 10:23:39,742 - INFO - validation batch 201, loss: 2.441, 6432/6976 datapoints
2025-03-07 10:23:39,774 - INFO - Epoch 293/800 done.
2025-03-07 10:23:39,775 - INFO - Final validation performance:
Loss: 1.568, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:23:39,776 - INFO - Beginning epoch 294/800
2025-03-07 10:23:39,783 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-07 10:23:40,108 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:23:40,395 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-07 10:23:40,687 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-07 10:23:40,975 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-07 10:23:41,260 - INFO - training batch 251, loss: 0.012, 8032/28000 datapoints
2025-03-07 10:23:41,559 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-07 10:23:41,848 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-07 10:23:42,128 - INFO - training batch 401, loss: 0.015, 12832/28000 datapoints
2025-03-07 10:23:42,422 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-07 10:23:42,707 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:23:42,984 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-07 10:23:43,260 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-07 10:23:43,538 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:23:43,817 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-07 10:23:44,089 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-07 10:23:44,381 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:23:44,706 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-07 10:23:44,863 - INFO - validation batch 1, loss: 0.410, 32/6976 datapoints
2025-03-07 10:23:44,958 - INFO - validation batch 51, loss: 3.801, 1632/6976 datapoints
2025-03-07 10:23:45,030 - INFO - validation batch 101, loss: 0.942, 3232/6976 datapoints
2025-03-07 10:23:45,100 - INFO - validation batch 151, loss: 0.320, 4832/6976 datapoints
2025-03-07 10:23:45,171 - INFO - validation batch 201, loss: 2.463, 6432/6976 datapoints
2025-03-07 10:23:45,195 - INFO - Epoch 294/800 done.
2025-03-07 10:23:45,195 - INFO - Final validation performance:
Loss: 1.587, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:23:45,196 - INFO - Beginning epoch 295/800
2025-03-07 10:23:45,204 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-07 10:23:45,490 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:23:45,782 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 10:23:46,063 - INFO - training batch 151, loss: 0.008, 4832/28000 datapoints
2025-03-07 10:23:46,344 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-07 10:23:46,630 - INFO - training batch 251, loss: 0.015, 8032/28000 datapoints
2025-03-07 10:23:46,908 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-07 10:23:47,189 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-07 10:23:47,469 - INFO - training batch 401, loss: 0.014, 12832/28000 datapoints
2025-03-07 10:23:47,746 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-07 10:23:48,030 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:23:48,312 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-07 10:23:48,602 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-07 10:23:48,882 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:23:49,173 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-07 10:23:49,453 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-07 10:23:49,742 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-07 10:23:50,055 - INFO - training batch 851, loss: 0.115, 27232/28000 datapoints
2025-03-07 10:23:50,209 - INFO - validation batch 1, loss: 0.679, 32/6976 datapoints
2025-03-07 10:23:50,291 - INFO - validation batch 51, loss: 4.092, 1632/6976 datapoints
2025-03-07 10:23:50,368 - INFO - validation batch 101, loss: 1.135, 3232/6976 datapoints
2025-03-07 10:23:50,446 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-07 10:23:50,527 - INFO - validation batch 201, loss: 2.183, 6432/6976 datapoints
2025-03-07 10:23:50,554 - INFO - Epoch 295/800 done.
2025-03-07 10:23:50,555 - INFO - Final validation performance:
Loss: 1.692, top-1 acc: 0.868top-5 acc: 0.868
2025-03-07 10:23:50,555 - INFO - Beginning epoch 296/800
2025-03-07 10:23:50,567 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 10:23:50,904 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-07 10:23:51,193 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-07 10:23:51,504 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-07 10:23:51,790 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-07 10:23:52,073 - INFO - training batch 251, loss: 0.022, 8032/28000 datapoints
2025-03-07 10:23:52,376 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-07 10:23:52,676 - INFO - training batch 351, loss: 0.026, 11232/28000 datapoints
2025-03-07 10:23:52,958 - INFO - training batch 401, loss: 0.018, 12832/28000 datapoints
2025-03-07 10:23:53,249 - INFO - training batch 451, loss: 0.014, 14432/28000 datapoints
2025-03-07 10:23:53,546 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:23:53,832 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-07 10:23:54,123 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-07 10:23:54,417 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:23:54,715 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-07 10:23:55,013 - INFO - training batch 751, loss: 0.017, 24032/28000 datapoints
2025-03-07 10:23:55,305 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-07 10:23:55,646 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-07 10:23:55,811 - INFO - validation batch 1, loss: 0.480, 32/6976 datapoints
2025-03-07 10:23:55,889 - INFO - validation batch 51, loss: 3.584, 1632/6976 datapoints
2025-03-07 10:23:55,970 - INFO - validation batch 101, loss: 1.011, 3232/6976 datapoints
2025-03-07 10:23:56,055 - INFO - validation batch 151, loss: 0.416, 4832/6976 datapoints
2025-03-07 10:23:56,140 - INFO - validation batch 201, loss: 2.419, 6432/6976 datapoints
2025-03-07 10:23:56,168 - INFO - Epoch 296/800 done.
2025-03-07 10:23:56,168 - INFO - Final validation performance:
Loss: 1.582, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:23:56,169 - INFO - Beginning epoch 297/800
2025-03-07 10:23:56,176 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-07 10:23:56,503 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:23:56,814 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-07 10:23:57,135 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-07 10:23:57,436 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-07 10:23:57,766 - INFO - training batch 251, loss: 0.018, 8032/28000 datapoints
2025-03-07 10:23:58,095 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-07 10:23:58,409 - INFO - training batch 351, loss: 0.010, 11232/28000 datapoints
2025-03-07 10:23:58,721 - INFO - training batch 401, loss: 0.010, 12832/28000 datapoints
2025-03-07 10:23:59,034 - INFO - training batch 451, loss: 0.015, 14432/28000 datapoints
2025-03-07 10:23:59,343 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:23:59,655 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-07 10:23:59,969 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-07 10:24:00,273 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:24:00,574 - INFO - training batch 701, loss: 0.023, 22432/28000 datapoints
2025-03-07 10:24:00,854 - INFO - training batch 751, loss: 0.096, 24032/28000 datapoints
2025-03-07 10:24:01,136 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-07 10:24:01,462 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-07 10:24:01,610 - INFO - validation batch 1, loss: 0.345, 32/6976 datapoints
2025-03-07 10:24:01,682 - INFO - validation batch 51, loss: 3.614, 1632/6976 datapoints
2025-03-07 10:24:01,755 - INFO - validation batch 101, loss: 1.001, 3232/6976 datapoints
2025-03-07 10:24:01,835 - INFO - validation batch 151, loss: 0.408, 4832/6976 datapoints
2025-03-07 10:24:01,910 - INFO - validation batch 201, loss: 2.628, 6432/6976 datapoints
2025-03-07 10:24:01,935 - INFO - Epoch 297/800 done.
2025-03-07 10:24:01,935 - INFO - Final validation performance:
Loss: 1.599, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:24:01,935 - INFO - Beginning epoch 298/800
2025-03-07 10:24:01,946 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-07 10:24:02,255 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:24:02,564 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 10:24:02,873 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-07 10:24:03,167 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-07 10:24:03,459 - INFO - training batch 251, loss: 0.024, 8032/28000 datapoints
2025-03-07 10:24:03,766 - INFO - training batch 301, loss: 0.028, 9632/28000 datapoints
2025-03-07 10:24:04,073 - INFO - training batch 351, loss: 0.019, 11232/28000 datapoints
2025-03-07 10:24:04,368 - INFO - training batch 401, loss: 0.016, 12832/28000 datapoints
2025-03-07 10:24:04,655 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-07 10:24:04,973 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:24:05,265 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-07 10:24:05,586 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-07 10:24:05,891 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:24:06,196 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 10:24:06,488 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-07 10:24:06,773 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:24:07,075 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-07 10:24:07,219 - INFO - validation batch 1, loss: 0.299, 32/6976 datapoints
2025-03-07 10:24:07,302 - INFO - validation batch 51, loss: 3.512, 1632/6976 datapoints
2025-03-07 10:24:07,378 - INFO - validation batch 101, loss: 0.991, 3232/6976 datapoints
2025-03-07 10:24:07,454 - INFO - validation batch 151, loss: 0.671, 4832/6976 datapoints
2025-03-07 10:24:07,543 - INFO - validation batch 201, loss: 2.473, 6432/6976 datapoints
2025-03-07 10:24:07,575 - INFO - Epoch 298/800 done.
2025-03-07 10:24:07,575 - INFO - Final validation performance:
Loss: 1.589, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:24:07,576 - INFO - Beginning epoch 299/800
2025-03-07 10:24:07,583 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 10:24:07,896 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-07 10:24:08,205 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 10:24:08,513 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-07 10:24:08,789 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-07 10:24:09,071 - INFO - training batch 251, loss: 0.078, 8032/28000 datapoints
2025-03-07 10:24:09,374 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-07 10:24:09,659 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-07 10:24:09,982 - INFO - training batch 401, loss: 0.015, 12832/28000 datapoints
2025-03-07 10:24:10,314 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-07 10:24:10,640 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:24:10,928 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-07 10:24:11,237 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 10:24:11,538 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:24:11,825 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-07 10:24:12,111 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-07 10:24:12,413 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:24:12,707 - INFO - training batch 851, loss: 0.013, 27232/28000 datapoints
2025-03-07 10:24:12,848 - INFO - validation batch 1, loss: 0.380, 32/6976 datapoints
2025-03-07 10:24:12,921 - INFO - validation batch 51, loss: 3.589, 1632/6976 datapoints
2025-03-07 10:24:13,006 - INFO - validation batch 101, loss: 1.045, 3232/6976 datapoints
2025-03-07 10:24:13,078 - INFO - validation batch 151, loss: 0.467, 4832/6976 datapoints
2025-03-07 10:24:13,154 - INFO - validation batch 201, loss: 2.573, 6432/6976 datapoints
2025-03-07 10:24:13,179 - INFO - Epoch 299/800 done.
2025-03-07 10:24:13,179 - INFO - Final validation performance:
Loss: 1.611, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:24:13,180 - INFO - Beginning epoch 300/800
2025-03-07 10:24:13,187 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 10:24:13,484 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:24:13,771 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 10:24:14,065 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-07 10:24:14,346 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-07 10:24:14,639 - INFO - training batch 251, loss: 0.012, 8032/28000 datapoints
2025-03-07 10:24:14,940 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 10:24:15,233 - INFO - training batch 351, loss: 0.013, 11232/28000 datapoints
2025-03-07 10:24:15,521 - INFO - training batch 401, loss: 0.019, 12832/28000 datapoints
2025-03-07 10:24:15,834 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-07 10:24:16,129 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-07 10:24:16,430 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-07 10:24:16,795 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-07 10:24:17,125 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:24:17,454 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-07 10:24:17,768 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 10:24:18,081 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:24:18,458 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-07 10:24:18,602 - INFO - validation batch 1, loss: 0.367, 32/6976 datapoints
2025-03-07 10:24:18,694 - INFO - validation batch 51, loss: 3.610, 1632/6976 datapoints
2025-03-07 10:24:18,768 - INFO - validation batch 101, loss: 1.043, 3232/6976 datapoints
2025-03-07 10:24:18,843 - INFO - validation batch 151, loss: 0.439, 4832/6976 datapoints
2025-03-07 10:24:18,923 - INFO - validation batch 201, loss: 2.538, 6432/6976 datapoints
2025-03-07 10:24:18,951 - INFO - Epoch 300/800 done.
2025-03-07 10:24:18,952 - INFO - Final validation performance:
Loss: 1.599, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:24:18,952 - INFO - Beginning epoch 301/800
2025-03-07 10:24:18,965 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 10:24:19,283 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:24:19,606 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 10:24:19,933 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-07 10:24:20,261 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-07 10:24:20,600 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-07 10:24:20,926 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:24:21,271 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-07 10:24:21,625 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-07 10:24:21,948 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-07 10:24:22,277 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:24:22,610 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-07 10:24:22,939 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 10:24:23,269 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:24:23,617 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-07 10:24:23,936 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 10:24:24,251 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:24:24,590 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-07 10:24:24,747 - INFO - validation batch 1, loss: 0.442, 32/6976 datapoints
2025-03-07 10:24:24,824 - INFO - validation batch 51, loss: 3.709, 1632/6976 datapoints
2025-03-07 10:24:24,907 - INFO - validation batch 101, loss: 1.041, 3232/6976 datapoints
2025-03-07 10:24:24,991 - INFO - validation batch 151, loss: 0.365, 4832/6976 datapoints
2025-03-07 10:24:25,074 - INFO - validation batch 201, loss: 2.538, 6432/6976 datapoints
2025-03-07 10:24:25,112 - INFO - Epoch 301/800 done.
2025-03-07 10:24:25,113 - INFO - Final validation performance:
Loss: 1.619, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:24:25,113 - INFO - Beginning epoch 302/800
2025-03-07 10:24:25,124 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 10:24:25,475 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:24:25,797 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 10:24:26,137 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-07 10:24:26,449 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-07 10:24:26,784 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-07 10:24:27,121 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:24:27,437 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-07 10:24:27,761 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-07 10:24:28,067 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-07 10:24:28,367 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:24:28,692 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-07 10:24:29,040 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-07 10:24:29,328 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:24:29,622 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-07 10:24:29,905 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 10:24:30,203 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:24:30,568 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 10:24:30,709 - INFO - validation batch 1, loss: 0.419, 32/6976 datapoints
2025-03-07 10:24:30,783 - INFO - validation batch 51, loss: 3.833, 1632/6976 datapoints
2025-03-07 10:24:30,869 - INFO - validation batch 101, loss: 1.058, 3232/6976 datapoints
2025-03-07 10:24:30,945 - INFO - validation batch 151, loss: 0.419, 4832/6976 datapoints
2025-03-07 10:24:31,023 - INFO - validation batch 201, loss: 2.544, 6432/6976 datapoints
2025-03-07 10:24:31,047 - INFO - Epoch 302/800 done.
2025-03-07 10:24:31,047 - INFO - Final validation performance:
Loss: 1.655, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:24:31,048 - INFO - Beginning epoch 303/800
2025-03-07 10:24:31,062 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-07 10:24:31,359 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:24:31,659 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 10:24:31,962 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-07 10:24:32,250 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-07 10:24:32,539 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-07 10:24:32,836 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-07 10:24:33,135 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-07 10:24:33,421 - INFO - training batch 401, loss: 0.010, 12832/28000 datapoints
2025-03-07 10:24:33,713 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-07 10:24:34,007 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:24:34,292 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-07 10:24:34,588 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-07 10:24:34,868 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:24:35,152 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-07 10:24:35,429 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 10:24:35,704 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:24:35,997 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 10:24:36,137 - INFO - validation batch 1, loss: 0.469, 32/6976 datapoints
2025-03-07 10:24:36,207 - INFO - validation batch 51, loss: 3.888, 1632/6976 datapoints
2025-03-07 10:24:36,279 - INFO - validation batch 101, loss: 1.068, 3232/6976 datapoints
2025-03-07 10:24:36,349 - INFO - validation batch 151, loss: 0.386, 4832/6976 datapoints
2025-03-07 10:24:36,420 - INFO - validation batch 201, loss: 2.541, 6432/6976 datapoints
2025-03-07 10:24:36,442 - INFO - Epoch 303/800 done.
2025-03-07 10:24:36,442 - INFO - Final validation performance:
Loss: 1.670, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:24:36,443 - INFO - Beginning epoch 304/800
2025-03-07 10:24:36,456 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 10:24:36,745 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:24:37,025 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-07 10:24:37,320 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-07 10:24:37,602 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-07 10:24:37,880 - INFO - training batch 251, loss: 0.015, 8032/28000 datapoints
2025-03-07 10:24:38,197 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:24:38,510 - INFO - training batch 351, loss: 0.278, 11232/28000 datapoints
2025-03-07 10:24:38,793 - INFO - training batch 401, loss: 0.145, 12832/28000 datapoints
2025-03-07 10:24:39,085 - INFO - training batch 451, loss: 0.054, 14432/28000 datapoints
2025-03-07 10:24:39,376 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-07 10:24:39,660 - INFO - training batch 551, loss: 0.139, 17632/28000 datapoints
2025-03-07 10:24:39,946 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-07 10:24:40,241 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:24:40,557 - INFO - training batch 701, loss: 0.015, 22432/28000 datapoints
2025-03-07 10:24:40,837 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-07 10:24:41,125 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:24:41,432 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 10:24:41,577 - INFO - validation batch 1, loss: 0.329, 32/6976 datapoints
2025-03-07 10:24:41,652 - INFO - validation batch 51, loss: 3.541, 1632/6976 datapoints
2025-03-07 10:24:41,729 - INFO - validation batch 101, loss: 1.104, 3232/6976 datapoints
2025-03-07 10:24:41,805 - INFO - validation batch 151, loss: 0.472, 4832/6976 datapoints
2025-03-07 10:24:41,883 - INFO - validation batch 201, loss: 2.537, 6432/6976 datapoints
2025-03-07 10:24:41,915 - INFO - Epoch 304/800 done.
2025-03-07 10:24:41,916 - INFO - Final validation performance:
Loss: 1.597, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:24:41,916 - INFO - Beginning epoch 305/800
2025-03-07 10:24:41,924 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-07 10:24:42,244 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:24:42,570 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-07 10:24:42,879 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-07 10:24:43,178 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-07 10:24:43,472 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-07 10:24:43,846 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-07 10:24:44,192 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-07 10:24:44,531 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-07 10:24:44,853 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-07 10:24:45,153 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-07 10:24:45,451 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 10:24:45,758 - INFO - training batch 601, loss: 0.094, 19232/28000 datapoints
2025-03-07 10:24:46,066 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:24:46,372 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-07 10:24:46,666 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 10:24:46,968 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:24:47,279 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-07 10:24:47,428 - INFO - validation batch 1, loss: 0.293, 32/6976 datapoints
2025-03-07 10:24:47,522 - INFO - validation batch 51, loss: 3.637, 1632/6976 datapoints
2025-03-07 10:24:47,609 - INFO - validation batch 101, loss: 1.008, 3232/6976 datapoints
2025-03-07 10:24:47,686 - INFO - validation batch 151, loss: 0.449, 4832/6976 datapoints
2025-03-07 10:24:47,765 - INFO - validation batch 201, loss: 2.592, 6432/6976 datapoints
2025-03-07 10:24:47,789 - INFO - Epoch 305/800 done.
2025-03-07 10:24:47,790 - INFO - Final validation performance:
Loss: 1.596, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:24:47,791 - INFO - Beginning epoch 306/800
2025-03-07 10:24:47,801 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 10:24:48,126 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:24:48,427 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-07 10:24:48,741 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-07 10:24:49,034 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-07 10:24:49,335 - INFO - training batch 251, loss: 0.037, 8032/28000 datapoints
2025-03-07 10:24:49,634 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 10:24:49,948 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 10:24:50,257 - INFO - training batch 401, loss: 0.043, 12832/28000 datapoints
2025-03-07 10:24:50,588 - INFO - training batch 451, loss: 0.011, 14432/28000 datapoints
2025-03-07 10:24:50,988 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:24:51,303 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-07 10:24:51,622 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 10:24:51,916 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:24:52,214 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 10:24:52,517 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 10:24:52,818 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:24:53,129 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-07 10:24:53,280 - INFO - validation batch 1, loss: 0.344, 32/6976 datapoints
2025-03-07 10:24:53,356 - INFO - validation batch 51, loss: 3.591, 1632/6976 datapoints
2025-03-07 10:24:53,436 - INFO - validation batch 101, loss: 0.987, 3232/6976 datapoints
2025-03-07 10:24:53,514 - INFO - validation batch 151, loss: 0.416, 4832/6976 datapoints
2025-03-07 10:24:53,592 - INFO - validation batch 201, loss: 2.438, 6432/6976 datapoints
2025-03-07 10:24:53,626 - INFO - Epoch 306/800 done.
2025-03-07 10:24:53,627 - INFO - Final validation performance:
Loss: 1.555, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:24:53,627 - INFO - Beginning epoch 307/800
2025-03-07 10:24:53,635 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 10:24:53,973 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:24:54,256 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-07 10:24:54,563 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-07 10:24:54,854 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-07 10:24:55,175 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-07 10:24:55,471 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:24:55,772 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-07 10:24:56,065 - INFO - training batch 401, loss: 0.010, 12832/28000 datapoints
2025-03-07 10:24:56,360 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-07 10:24:56,650 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:24:56,928 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-07 10:24:57,221 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:24:57,529 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:24:57,818 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 10:24:58,103 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 10:24:58,392 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:24:58,695 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-07 10:24:58,836 - INFO - validation batch 1, loss: 0.354, 32/6976 datapoints
2025-03-07 10:24:58,909 - INFO - validation batch 51, loss: 3.755, 1632/6976 datapoints
2025-03-07 10:24:58,982 - INFO - validation batch 101, loss: 0.959, 3232/6976 datapoints
2025-03-07 10:24:59,092 - INFO - validation batch 151, loss: 0.413, 4832/6976 datapoints
2025-03-07 10:24:59,193 - INFO - validation batch 201, loss: 2.458, 6432/6976 datapoints
2025-03-07 10:24:59,228 - INFO - Epoch 307/800 done.
2025-03-07 10:24:59,228 - INFO - Final validation performance:
Loss: 1.588, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:24:59,229 - INFO - Beginning epoch 308/800
2025-03-07 10:24:59,239 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 10:24:59,587 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:24:59,865 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-07 10:25:00,162 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-07 10:25:00,448 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-07 10:25:00,755 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-07 10:25:01,044 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:25:01,339 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-07 10:25:01,629 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-07 10:25:01,915 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-07 10:25:02,211 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:25:02,504 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 10:25:02,806 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:25:03,106 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:25:03,405 - INFO - training batch 701, loss: 0.018, 22432/28000 datapoints
2025-03-07 10:25:03,689 - INFO - training batch 751, loss: 0.075, 24032/28000 datapoints
2025-03-07 10:25:03,979 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-07 10:25:04,296 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-07 10:25:04,441 - INFO - validation batch 1, loss: 0.296, 32/6976 datapoints
2025-03-07 10:25:04,516 - INFO - validation batch 51, loss: 3.572, 1632/6976 datapoints
2025-03-07 10:25:04,597 - INFO - validation batch 101, loss: 1.004, 3232/6976 datapoints
2025-03-07 10:25:04,676 - INFO - validation batch 151, loss: 0.750, 4832/6976 datapoints
2025-03-07 10:25:04,763 - INFO - validation batch 201, loss: 2.871, 6432/6976 datapoints
2025-03-07 10:25:04,789 - INFO - Epoch 308/800 done.
2025-03-07 10:25:04,789 - INFO - Final validation performance:
Loss: 1.699, top-1 acc: 0.873top-5 acc: 0.873
2025-03-07 10:25:04,790 - INFO - Beginning epoch 309/800
2025-03-07 10:25:04,800 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-07 10:25:05,135 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:25:05,451 - INFO - training batch 101, loss: 0.067, 3232/28000 datapoints
2025-03-07 10:25:05,776 - INFO - training batch 151, loss: 0.013, 4832/28000 datapoints
2025-03-07 10:25:06,084 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-07 10:25:06,389 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-07 10:25:06,702 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 10:25:07,011 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-07 10:25:07,311 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-07 10:25:07,618 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-07 10:25:07,921 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-07 10:25:08,214 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-07 10:25:08,533 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:25:08,833 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:25:09,144 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:25:09,443 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 10:25:09,737 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:25:10,055 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-07 10:25:10,208 - INFO - validation batch 1, loss: 0.605, 32/6976 datapoints
2025-03-07 10:25:10,286 - INFO - validation batch 51, loss: 3.896, 1632/6976 datapoints
2025-03-07 10:25:10,362 - INFO - validation batch 101, loss: 0.956, 3232/6976 datapoints
2025-03-07 10:25:10,443 - INFO - validation batch 151, loss: 0.270, 4832/6976 datapoints
2025-03-07 10:25:10,521 - INFO - validation batch 201, loss: 2.579, 6432/6976 datapoints
2025-03-07 10:25:10,550 - INFO - Epoch 309/800 done.
2025-03-07 10:25:10,551 - INFO - Final validation performance:
Loss: 1.661, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:25:10,552 - INFO - Beginning epoch 310/800
2025-03-07 10:25:10,563 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:25:10,900 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:25:11,205 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 10:25:11,513 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-07 10:25:11,812 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-07 10:25:12,109 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-07 10:25:12,408 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:25:12,706 - INFO - training batch 351, loss: 0.010, 11232/28000 datapoints
2025-03-07 10:25:12,993 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-07 10:25:13,288 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-07 10:25:13,582 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:25:13,862 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-07 10:25:14,164 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:25:14,457 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:25:14,744 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:25:15,020 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:25:15,305 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:25:15,591 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-07 10:25:15,729 - INFO - validation batch 1, loss: 0.467, 32/6976 datapoints
2025-03-07 10:25:15,800 - INFO - validation batch 51, loss: 3.864, 1632/6976 datapoints
2025-03-07 10:25:15,879 - INFO - validation batch 101, loss: 1.012, 3232/6976 datapoints
2025-03-07 10:25:15,948 - INFO - validation batch 151, loss: 0.467, 4832/6976 datapoints
2025-03-07 10:25:16,024 - INFO - validation batch 201, loss: 2.561, 6432/6976 datapoints
2025-03-07 10:25:16,049 - INFO - Epoch 310/800 done.
2025-03-07 10:25:16,049 - INFO - Final validation performance:
Loss: 1.674, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:25:16,050 - INFO - Beginning epoch 311/800
2025-03-07 10:25:16,058 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 10:25:16,362 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:25:16,644 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-07 10:25:16,942 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-07 10:25:17,225 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-07 10:25:17,516 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-07 10:25:17,809 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:25:18,101 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-07 10:25:18,387 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-07 10:25:18,672 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-07 10:25:18,960 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:25:19,240 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-07 10:25:19,532 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:25:19,814 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:25:20,108 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 10:25:20,392 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:25:20,680 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:25:20,993 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-07 10:25:21,132 - INFO - validation batch 1, loss: 0.486, 32/6976 datapoints
2025-03-07 10:25:21,205 - INFO - validation batch 51, loss: 3.964, 1632/6976 datapoints
2025-03-07 10:25:21,275 - INFO - validation batch 101, loss: 1.001, 3232/6976 datapoints
2025-03-07 10:25:21,351 - INFO - validation batch 151, loss: 0.458, 4832/6976 datapoints
2025-03-07 10:25:21,425 - INFO - validation batch 201, loss: 2.589, 6432/6976 datapoints
2025-03-07 10:25:21,450 - INFO - Epoch 311/800 done.
2025-03-07 10:25:21,451 - INFO - Final validation performance:
Loss: 1.700, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:25:21,452 - INFO - Beginning epoch 312/800
2025-03-07 10:25:21,461 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 10:25:21,749 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:25:22,036 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-07 10:25:22,339 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-07 10:25:22,638 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-07 10:25:22,928 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-07 10:25:23,229 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 10:25:23,530 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-07 10:25:23,822 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-07 10:25:24,121 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-07 10:25:24,452 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:25:24,773 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-07 10:25:25,081 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 10:25:25,381 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:25:25,689 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 10:25:25,982 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:25:26,289 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:25:26,604 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 10:25:26,753 - INFO - validation batch 1, loss: 0.487, 32/6976 datapoints
2025-03-07 10:25:26,827 - INFO - validation batch 51, loss: 4.015, 1632/6976 datapoints
2025-03-07 10:25:26,904 - INFO - validation batch 101, loss: 1.024, 3232/6976 datapoints
2025-03-07 10:25:26,983 - INFO - validation batch 151, loss: 0.451, 4832/6976 datapoints
2025-03-07 10:25:27,062 - INFO - validation batch 201, loss: 2.615, 6432/6976 datapoints
2025-03-07 10:25:27,088 - INFO - Epoch 312/800 done.
2025-03-07 10:25:27,089 - INFO - Final validation performance:
Loss: 1.718, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:25:27,089 - INFO - Beginning epoch 313/800
2025-03-07 10:25:27,098 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 10:25:27,425 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:25:27,728 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-07 10:25:28,043 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-07 10:25:28,348 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-07 10:25:28,650 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-07 10:25:28,968 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 10:25:29,281 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-07 10:25:29,593 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-07 10:25:29,897 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-07 10:25:30,212 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:25:30,583 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 10:25:30,917 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 10:25:31,224 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:25:31,551 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 10:25:31,854 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:25:32,148 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:25:32,451 - INFO - training batch 851, loss: 0.905, 27232/28000 datapoints
2025-03-07 10:25:32,603 - INFO - validation batch 1, loss: 0.552, 32/6976 datapoints
2025-03-07 10:25:32,677 - INFO - validation batch 51, loss: 5.494, 1632/6976 datapoints
2025-03-07 10:25:32,753 - INFO - validation batch 101, loss: 1.136, 3232/6976 datapoints
2025-03-07 10:25:32,830 - INFO - validation batch 151, loss: 0.628, 4832/6976 datapoints
2025-03-07 10:25:32,903 - INFO - validation batch 201, loss: 2.289, 6432/6976 datapoints
2025-03-07 10:25:32,929 - INFO - Epoch 313/800 done.
2025-03-07 10:25:32,930 - INFO - Final validation performance:
Loss: 2.020, top-1 acc: 0.863top-5 acc: 0.863
2025-03-07 10:25:32,930 - INFO - Beginning epoch 314/800
2025-03-07 10:25:32,939 - INFO - training batch 1, loss: 0.165, 32/28000 datapoints
2025-03-07 10:25:33,260 - INFO - training batch 51, loss: 0.146, 1632/28000 datapoints
2025-03-07 10:25:33,566 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-07 10:25:33,870 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-07 10:25:34,164 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-07 10:25:34,483 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-07 10:25:34,784 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:25:35,075 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-07 10:25:35,380 - INFO - training batch 401, loss: 0.028, 12832/28000 datapoints
2025-03-07 10:25:35,673 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-07 10:25:35,958 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:25:36,243 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 10:25:36,556 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-07 10:25:36,842 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:25:37,134 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 10:25:37,416 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 10:25:37,700 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:25:37,998 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 10:25:38,137 - INFO - validation batch 1, loss: 0.423, 32/6976 datapoints
2025-03-07 10:25:38,210 - INFO - validation batch 51, loss: 3.557, 1632/6976 datapoints
2025-03-07 10:25:38,283 - INFO - validation batch 101, loss: 0.993, 3232/6976 datapoints
2025-03-07 10:25:38,354 - INFO - validation batch 151, loss: 0.378, 4832/6976 datapoints
2025-03-07 10:25:38,426 - INFO - validation batch 201, loss: 2.728, 6432/6976 datapoints
2025-03-07 10:25:38,450 - INFO - Epoch 314/800 done.
2025-03-07 10:25:38,450 - INFO - Final validation performance:
Loss: 1.616, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:25:38,451 - INFO - Beginning epoch 315/800
2025-03-07 10:25:38,459 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:25:38,745 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:25:39,031 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-07 10:25:39,331 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-07 10:25:39,617 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:25:39,895 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-07 10:25:40,193 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 10:25:40,487 - INFO - training batch 351, loss: 0.021, 11232/28000 datapoints
2025-03-07 10:25:40,788 - INFO - training batch 401, loss: 0.016, 12832/28000 datapoints
2025-03-07 10:25:41,101 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-07 10:25:41,414 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:25:41,689 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 10:25:41,983 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:25:42,271 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:25:42,567 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:25:42,858 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 10:25:43,170 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:25:43,477 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-07 10:25:43,619 - INFO - validation batch 1, loss: 0.349, 32/6976 datapoints
2025-03-07 10:25:43,688 - INFO - validation batch 51, loss: 3.892, 1632/6976 datapoints
2025-03-07 10:25:43,760 - INFO - validation batch 101, loss: 1.008, 3232/6976 datapoints
2025-03-07 10:25:43,830 - INFO - validation batch 151, loss: 0.334, 4832/6976 datapoints
2025-03-07 10:25:43,901 - INFO - validation batch 201, loss: 2.628, 6432/6976 datapoints
2025-03-07 10:25:43,924 - INFO - Epoch 315/800 done.
2025-03-07 10:25:43,924 - INFO - Final validation performance:
Loss: 1.642, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:25:43,925 - INFO - Beginning epoch 316/800
2025-03-07 10:25:43,933 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:25:44,250 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:25:44,546 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 10:25:44,886 - INFO - training batch 151, loss: 0.008, 4832/28000 datapoints
2025-03-07 10:25:45,183 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-07 10:25:45,484 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 10:25:45,791 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 10:25:46,109 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-07 10:25:46,424 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-07 10:25:46,736 - INFO - training batch 451, loss: 0.014, 14432/28000 datapoints
2025-03-07 10:25:47,045 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:25:47,358 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 10:25:47,674 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:25:47,972 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:25:48,282 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:25:48,581 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 10:25:48,896 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:25:49,212 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-07 10:25:49,366 - INFO - validation batch 1, loss: 0.395, 32/6976 datapoints
2025-03-07 10:25:49,444 - INFO - validation batch 51, loss: 4.080, 1632/6976 datapoints
2025-03-07 10:25:49,520 - INFO - validation batch 101, loss: 1.006, 3232/6976 datapoints
2025-03-07 10:25:49,608 - INFO - validation batch 151, loss: 0.426, 4832/6976 datapoints
2025-03-07 10:25:49,686 - INFO - validation batch 201, loss: 2.667, 6432/6976 datapoints
2025-03-07 10:25:49,718 - INFO - Epoch 316/800 done.
2025-03-07 10:25:49,719 - INFO - Final validation performance:
Loss: 1.715, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:25:49,719 - INFO - Beginning epoch 317/800
2025-03-07 10:25:49,727 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:25:50,064 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:25:50,384 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-07 10:25:50,708 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-07 10:25:51,006 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-07 10:25:51,337 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-07 10:25:51,652 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:25:51,968 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-07 10:25:52,271 - INFO - training batch 401, loss: 0.014, 12832/28000 datapoints
2025-03-07 10:25:52,579 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-07 10:25:52,884 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-07 10:25:53,172 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-07 10:25:53,479 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:25:53,772 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:25:54,071 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 10:25:54,363 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 10:25:54,648 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-07 10:25:54,944 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-07 10:25:55,083 - INFO - validation batch 1, loss: 0.327, 32/6976 datapoints
2025-03-07 10:25:55,157 - INFO - validation batch 51, loss: 3.972, 1632/6976 datapoints
2025-03-07 10:25:55,229 - INFO - validation batch 101, loss: 1.054, 3232/6976 datapoints
2025-03-07 10:25:55,304 - INFO - validation batch 151, loss: 0.631, 4832/6976 datapoints
2025-03-07 10:25:55,374 - INFO - validation batch 201, loss: 2.690, 6432/6976 datapoints
2025-03-07 10:25:55,398 - INFO - Epoch 317/800 done.
2025-03-07 10:25:55,398 - INFO - Final validation performance:
Loss: 1.735, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:25:55,399 - INFO - Beginning epoch 318/800
2025-03-07 10:25:55,407 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 10:25:55,699 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:25:55,982 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-07 10:25:56,286 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-07 10:25:56,577 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-07 10:25:56,864 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-07 10:25:57,154 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:25:57,451 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-07 10:25:57,994 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-07 10:25:58,293 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-07 10:25:58,683 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-07 10:25:58,992 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-07 10:25:59,490 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:25:59,813 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:26:00,126 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 10:26:00,456 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 10:26:00,755 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:26:01,082 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-07 10:26:01,272 - INFO - validation batch 1, loss: 0.612, 32/6976 datapoints
2025-03-07 10:26:01,363 - INFO - validation batch 51, loss: 4.180, 1632/6976 datapoints
2025-03-07 10:26:01,444 - INFO - validation batch 101, loss: 0.987, 3232/6976 datapoints
2025-03-07 10:26:01,551 - INFO - validation batch 151, loss: 0.321, 4832/6976 datapoints
2025-03-07 10:26:01,637 - INFO - validation batch 201, loss: 2.706, 6432/6976 datapoints
2025-03-07 10:26:01,672 - INFO - Epoch 318/800 done.
2025-03-07 10:26:01,672 - INFO - Final validation performance:
Loss: 1.761, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:26:01,673 - INFO - Beginning epoch 319/800
2025-03-07 10:26:01,683 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:26:01,999 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:26:02,309 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-07 10:26:02,638 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-07 10:26:02,996 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:26:03,333 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-07 10:26:03,722 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:26:04,142 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-07 10:26:04,481 - INFO - training batch 401, loss: 0.010, 12832/28000 datapoints
2025-03-07 10:26:04,831 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-07 10:26:05,177 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:26:05,503 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 10:26:05,834 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:26:06,142 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:26:06,486 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 10:26:06,832 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 10:26:07,158 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:26:07,504 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-07 10:26:07,679 - INFO - validation batch 1, loss: 0.467, 32/6976 datapoints
2025-03-07 10:26:07,761 - INFO - validation batch 51, loss: 4.142, 1632/6976 datapoints
2025-03-07 10:26:07,858 - INFO - validation batch 101, loss: 1.007, 3232/6976 datapoints
2025-03-07 10:26:07,948 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-07 10:26:08,027 - INFO - validation batch 201, loss: 2.685, 6432/6976 datapoints
2025-03-07 10:26:08,062 - INFO - Epoch 319/800 done.
2025-03-07 10:26:08,062 - INFO - Final validation performance:
Loss: 1.777, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:26:08,063 - INFO - Beginning epoch 320/800
2025-03-07 10:26:08,071 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:26:08,408 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:26:08,731 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 10:26:09,074 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-07 10:26:09,416 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:26:09,730 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-07 10:26:10,045 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 10:26:10,374 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-07 10:26:10,694 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-07 10:26:11,012 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-07 10:26:11,401 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:26:11,739 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-07 10:26:12,062 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:26:12,368 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:26:12,684 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 10:26:12,981 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 10:26:13,289 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:26:13,605 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 10:26:13,753 - INFO - validation batch 1, loss: 0.470, 32/6976 datapoints
2025-03-07 10:26:13,832 - INFO - validation batch 51, loss: 4.185, 1632/6976 datapoints
2025-03-07 10:26:13,903 - INFO - validation batch 101, loss: 1.030, 3232/6976 datapoints
2025-03-07 10:26:13,979 - INFO - validation batch 151, loss: 0.607, 4832/6976 datapoints
2025-03-07 10:26:14,058 - INFO - validation batch 201, loss: 2.699, 6432/6976 datapoints
2025-03-07 10:26:14,082 - INFO - Epoch 320/800 done.
2025-03-07 10:26:14,082 - INFO - Final validation performance:
Loss: 1.798, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:26:14,083 - INFO - Beginning epoch 321/800
2025-03-07 10:26:14,090 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:26:14,389 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:26:14,690 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 10:26:14,995 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-07 10:26:15,313 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:26:15,610 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-07 10:26:15,905 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 10:26:16,211 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-07 10:26:16,508 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-07 10:26:16,829 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-07 10:26:17,140 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:26:17,438 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 10:26:17,745 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:26:18,039 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:26:18,335 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 10:26:18,621 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 10:26:18,917 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:26:19,242 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 10:26:19,394 - INFO - validation batch 1, loss: 0.447, 32/6976 datapoints
2025-03-07 10:26:19,467 - INFO - validation batch 51, loss: 4.232, 1632/6976 datapoints
2025-03-07 10:26:19,549 - INFO - validation batch 101, loss: 1.075, 3232/6976 datapoints
2025-03-07 10:26:19,622 - INFO - validation batch 151, loss: 0.646, 4832/6976 datapoints
2025-03-07 10:26:19,700 - INFO - validation batch 201, loss: 2.677, 6432/6976 datapoints
2025-03-07 10:26:19,728 - INFO - Epoch 321/800 done.
2025-03-07 10:26:19,728 - INFO - Final validation performance:
Loss: 1.815, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:26:19,729 - INFO - Beginning epoch 322/800
2025-03-07 10:26:19,737 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 10:26:20,052 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:26:20,356 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 10:26:20,684 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-07 10:26:21,010 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:26:21,335 - INFO - training batch 251, loss: 0.019, 8032/28000 datapoints
2025-03-07 10:26:21,687 - INFO - training batch 301, loss: 0.282, 9632/28000 datapoints
2025-03-07 10:26:22,032 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-07 10:26:22,350 - INFO - training batch 401, loss: 0.030, 12832/28000 datapoints
2025-03-07 10:26:22,667 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-07 10:26:22,991 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:26:23,294 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-07 10:26:23,611 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-07 10:26:23,919 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:26:24,236 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-07 10:26:24,554 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 10:26:24,883 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:26:25,208 - INFO - training batch 851, loss: 0.014, 27232/28000 datapoints
2025-03-07 10:26:25,370 - INFO - validation batch 1, loss: 0.794, 32/6976 datapoints
2025-03-07 10:26:25,453 - INFO - validation batch 51, loss: 4.209, 1632/6976 datapoints
2025-03-07 10:26:25,534 - INFO - validation batch 101, loss: 1.091, 3232/6976 datapoints
2025-03-07 10:26:25,611 - INFO - validation batch 151, loss: 0.273, 4832/6976 datapoints
2025-03-07 10:26:25,692 - INFO - validation batch 201, loss: 2.909, 6432/6976 datapoints
2025-03-07 10:26:25,723 - INFO - Epoch 322/800 done.
2025-03-07 10:26:25,723 - INFO - Final validation performance:
Loss: 1.855, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:26:25,724 - INFO - Beginning epoch 323/800
2025-03-07 10:26:25,732 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:26:26,078 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:26:26,394 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:26:26,708 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-07 10:26:27,020 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:26:27,339 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 10:26:27,667 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-07 10:26:27,989 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-07 10:26:28,311 - INFO - training batch 401, loss: 0.026, 12832/28000 datapoints
2025-03-07 10:26:28,634 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-07 10:26:28,973 - INFO - training batch 501, loss: 0.031, 16032/28000 datapoints
2025-03-07 10:26:29,298 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-07 10:26:29,627 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 10:26:29,976 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:26:30,325 - INFO - training batch 701, loss: 0.039, 22432/28000 datapoints
2025-03-07 10:26:30,646 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 10:26:30,964 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:26:31,296 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-07 10:26:31,448 - INFO - validation batch 1, loss: 0.342, 32/6976 datapoints
2025-03-07 10:26:31,534 - INFO - validation batch 51, loss: 3.620, 1632/6976 datapoints
2025-03-07 10:26:31,643 - INFO - validation batch 101, loss: 1.250, 3232/6976 datapoints
2025-03-07 10:26:31,719 - INFO - validation batch 151, loss: 1.201, 4832/6976 datapoints
2025-03-07 10:26:31,792 - INFO - validation batch 201, loss: 3.091, 6432/6976 datapoints
2025-03-07 10:26:31,818 - INFO - Epoch 323/800 done.
2025-03-07 10:26:31,819 - INFO - Final validation performance:
Loss: 1.901, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 10:26:31,819 - INFO - Beginning epoch 324/800
2025-03-07 10:26:31,826 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-07 10:26:32,133 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:26:32,434 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-07 10:26:32,734 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-07 10:26:33,039 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-07 10:26:33,345 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-07 10:26:33,659 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-07 10:26:33,987 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-07 10:26:34,291 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-07 10:26:34,589 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-07 10:26:34,892 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-07 10:26:35,185 - INFO - training batch 551, loss: 0.017, 17632/28000 datapoints
2025-03-07 10:26:35,478 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-07 10:26:35,782 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:26:36,081 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 10:26:36,393 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:26:36,689 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-07 10:26:36,993 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 10:26:37,135 - INFO - validation batch 1, loss: 0.378, 32/6976 datapoints
2025-03-07 10:26:37,206 - INFO - validation batch 51, loss: 4.134, 1632/6976 datapoints
2025-03-07 10:26:37,289 - INFO - validation batch 101, loss: 1.052, 3232/6976 datapoints
2025-03-07 10:26:37,397 - INFO - validation batch 151, loss: 0.712, 4832/6976 datapoints
2025-03-07 10:26:37,490 - INFO - validation batch 201, loss: 2.792, 6432/6976 datapoints
2025-03-07 10:26:37,524 - INFO - Epoch 324/800 done.
2025-03-07 10:26:37,524 - INFO - Final validation performance:
Loss: 1.814, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:26:37,525 - INFO - Beginning epoch 325/800
2025-03-07 10:26:37,532 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 10:26:37,840 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:26:38,142 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 10:26:38,496 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-07 10:26:38,842 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:26:39,153 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-07 10:26:39,459 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 10:26:39,772 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-07 10:26:40,127 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-07 10:26:40,486 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-07 10:26:40,805 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:26:41,091 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 10:26:41,423 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 10:26:41,769 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:26:42,094 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:26:42,419 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 10:26:42,741 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:26:43,101 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-07 10:26:43,271 - INFO - validation batch 1, loss: 0.372, 32/6976 datapoints
2025-03-07 10:26:43,352 - INFO - validation batch 51, loss: 4.138, 1632/6976 datapoints
2025-03-07 10:26:43,435 - INFO - validation batch 101, loss: 0.959, 3232/6976 datapoints
2025-03-07 10:26:43,523 - INFO - validation batch 151, loss: 0.616, 4832/6976 datapoints
2025-03-07 10:26:43,606 - INFO - validation batch 201, loss: 2.718, 6432/6976 datapoints
2025-03-07 10:26:43,631 - INFO - Epoch 325/800 done.
2025-03-07 10:26:43,631 - INFO - Final validation performance:
Loss: 1.761, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:26:43,632 - INFO - Beginning epoch 326/800
2025-03-07 10:26:43,640 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:26:43,976 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:26:44,295 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-07 10:26:44,609 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-07 10:26:44,921 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:26:45,236 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 10:26:45,553 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 10:26:45,869 - INFO - training batch 351, loss: 0.013, 11232/28000 datapoints
2025-03-07 10:26:46,211 - INFO - training batch 401, loss: 0.019, 12832/28000 datapoints
2025-03-07 10:26:46,531 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-07 10:26:46,858 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:26:47,167 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 10:26:47,516 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-07 10:26:47,825 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-07 10:26:48,210 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 10:26:48,598 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 10:26:48,901 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-07 10:26:49,239 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-07 10:26:49,401 - INFO - validation batch 1, loss: 0.654, 32/6976 datapoints
2025-03-07 10:26:49,478 - INFO - validation batch 51, loss: 4.378, 1632/6976 datapoints
2025-03-07 10:26:49,574 - INFO - validation batch 101, loss: 1.022, 3232/6976 datapoints
2025-03-07 10:26:49,672 - INFO - validation batch 151, loss: 0.520, 4832/6976 datapoints
2025-03-07 10:26:49,754 - INFO - validation batch 201, loss: 2.353, 6432/6976 datapoints
2025-03-07 10:26:49,789 - INFO - Epoch 326/800 done.
2025-03-07 10:26:49,789 - INFO - Final validation performance:
Loss: 1.785, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:26:49,790 - INFO - Beginning epoch 327/800
2025-03-07 10:26:49,798 - INFO - training batch 1, loss: 0.011, 32/28000 datapoints
2025-03-07 10:26:50,143 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-07 10:26:50,483 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-07 10:26:50,810 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:26:51,122 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:26:51,440 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-07 10:26:51,760 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 10:26:52,091 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-07 10:26:52,408 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-07 10:26:52,730 - INFO - training batch 451, loss: 0.047, 14432/28000 datapoints
2025-03-07 10:26:53,035 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-07 10:26:53,328 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 10:26:53,633 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:26:53,943 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:26:54,258 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 10:26:54,555 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 10:26:54,864 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:26:55,199 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-07 10:26:55,356 - INFO - validation batch 1, loss: 0.449, 32/6976 datapoints
2025-03-07 10:26:55,429 - INFO - validation batch 51, loss: 4.257, 1632/6976 datapoints
2025-03-07 10:26:55,507 - INFO - validation batch 101, loss: 1.039, 3232/6976 datapoints
2025-03-07 10:26:55,586 - INFO - validation batch 151, loss: 0.476, 4832/6976 datapoints
2025-03-07 10:26:55,666 - INFO - validation batch 201, loss: 2.780, 6432/6976 datapoints
2025-03-07 10:26:55,689 - INFO - Epoch 327/800 done.
2025-03-07 10:26:55,689 - INFO - Final validation performance:
Loss: 1.800, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:26:55,690 - INFO - Beginning epoch 328/800
2025-03-07 10:26:55,697 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:26:56,009 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:26:56,321 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 10:26:56,621 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-07 10:26:56,919 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:26:57,256 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-07 10:26:57,579 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 10:26:57,898 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-07 10:26:58,214 - INFO - training batch 401, loss: 0.010, 12832/28000 datapoints
2025-03-07 10:26:58,526 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-07 10:26:58,846 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-07 10:26:59,174 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-07 10:26:59,482 - INFO - training batch 601, loss: 0.108, 19232/28000 datapoints
2025-03-07 10:26:59,789 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:27:00,086 - INFO - training batch 701, loss: 0.013, 22432/28000 datapoints
2025-03-07 10:27:00,407 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-07 10:27:00,700 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:27:01,025 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 10:27:01,192 - INFO - validation batch 1, loss: 0.345, 32/6976 datapoints
2025-03-07 10:27:01,275 - INFO - validation batch 51, loss: 4.285, 1632/6976 datapoints
2025-03-07 10:27:01,356 - INFO - validation batch 101, loss: 0.948, 3232/6976 datapoints
2025-03-07 10:27:01,440 - INFO - validation batch 151, loss: 0.731, 4832/6976 datapoints
2025-03-07 10:27:01,523 - INFO - validation batch 201, loss: 2.710, 6432/6976 datapoints
2025-03-07 10:27:01,553 - INFO - Epoch 328/800 done.
2025-03-07 10:27:01,553 - INFO - Final validation performance:
Loss: 1.804, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:27:01,554 - INFO - Beginning epoch 329/800
2025-03-07 10:27:01,563 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 10:27:01,878 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:27:02,200 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:27:02,521 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 10:27:02,837 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:27:03,150 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-07 10:27:03,471 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-07 10:27:03,793 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-07 10:27:04,106 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-07 10:27:04,429 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-07 10:27:04,743 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:27:05,062 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 10:27:05,417 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-07 10:27:05,719 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:27:06,026 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 10:27:06,355 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 10:27:06,687 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:27:07,031 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 10:27:07,196 - INFO - validation batch 1, loss: 0.332, 32/6976 datapoints
2025-03-07 10:27:07,285 - INFO - validation batch 51, loss: 4.216, 1632/6976 datapoints
2025-03-07 10:27:07,364 - INFO - validation batch 101, loss: 0.971, 3232/6976 datapoints
2025-03-07 10:27:07,456 - INFO - validation batch 151, loss: 0.894, 4832/6976 datapoints
2025-03-07 10:27:07,555 - INFO - validation batch 201, loss: 2.734, 6432/6976 datapoints
2025-03-07 10:27:07,586 - INFO - Epoch 329/800 done.
2025-03-07 10:27:07,586 - INFO - Final validation performance:
Loss: 1.830, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:27:07,587 - INFO - Beginning epoch 330/800
2025-03-07 10:27:07,597 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:27:07,998 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:27:08,357 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:27:08,702 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-07 10:27:09,009 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-07 10:27:09,346 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-07 10:27:09,685 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 10:27:10,003 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-07 10:27:10,325 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-07 10:27:10,653 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-07 10:27:10,989 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:27:11,306 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 10:27:11,635 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:27:11,959 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:27:12,322 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 10:27:12,646 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:27:12,965 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:27:13,298 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-07 10:27:13,459 - INFO - validation batch 1, loss: 0.417, 32/6976 datapoints
2025-03-07 10:27:13,550 - INFO - validation batch 51, loss: 4.318, 1632/6976 datapoints
2025-03-07 10:27:13,641 - INFO - validation batch 101, loss: 0.973, 3232/6976 datapoints
2025-03-07 10:27:13,726 - INFO - validation batch 151, loss: 0.659, 4832/6976 datapoints
2025-03-07 10:27:13,805 - INFO - validation batch 201, loss: 2.768, 6432/6976 datapoints
2025-03-07 10:27:13,833 - INFO - Epoch 330/800 done.
2025-03-07 10:27:13,833 - INFO - Final validation performance:
Loss: 1.827, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:27:13,834 - INFO - Beginning epoch 331/800
2025-03-07 10:27:13,842 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:27:14,168 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:27:14,504 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:27:14,826 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:27:15,155 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:27:15,487 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-07 10:27:15,828 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-07 10:27:16,146 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-07 10:27:16,499 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-07 10:27:16,860 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-07 10:27:17,201 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:27:17,513 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 10:27:17,847 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:27:18,159 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:27:18,477 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 10:27:18,778 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:27:19,078 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:27:19,391 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 10:27:19,545 - INFO - validation batch 1, loss: 0.457, 32/6976 datapoints
2025-03-07 10:27:19,624 - INFO - validation batch 51, loss: 4.357, 1632/6976 datapoints
2025-03-07 10:27:19,702 - INFO - validation batch 101, loss: 1.000, 3232/6976 datapoints
2025-03-07 10:27:19,782 - INFO - validation batch 151, loss: 0.675, 4832/6976 datapoints
2025-03-07 10:27:19,856 - INFO - validation batch 201, loss: 2.796, 6432/6976 datapoints
2025-03-07 10:27:19,882 - INFO - Epoch 331/800 done.
2025-03-07 10:27:19,882 - INFO - Final validation performance:
Loss: 1.857, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:27:19,883 - INFO - Beginning epoch 332/800
2025-03-07 10:27:19,892 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:27:20,213 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:27:20,536 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:27:20,851 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:27:21,162 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:27:21,499 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 10:27:21,824 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 10:27:22,155 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-07 10:27:22,466 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-07 10:27:22,784 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-07 10:27:23,121 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:27:23,423 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 10:27:23,740 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:27:24,052 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:27:24,377 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 10:27:24,703 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:27:25,012 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:27:25,336 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 10:27:25,494 - INFO - validation batch 1, loss: 0.493, 32/6976 datapoints
2025-03-07 10:27:25,577 - INFO - validation batch 51, loss: 4.418, 1632/6976 datapoints
2025-03-07 10:27:25,656 - INFO - validation batch 101, loss: 1.017, 3232/6976 datapoints
2025-03-07 10:27:25,739 - INFO - validation batch 151, loss: 0.673, 4832/6976 datapoints
2025-03-07 10:27:25,820 - INFO - validation batch 201, loss: 2.779, 6432/6976 datapoints
2025-03-07 10:27:25,852 - INFO - Epoch 332/800 done.
2025-03-07 10:27:25,853 - INFO - Final validation performance:
Loss: 1.876, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:27:25,854 - INFO - Beginning epoch 333/800
2025-03-07 10:27:25,863 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:27:26,176 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:27:26,506 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:27:26,816 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-07 10:27:27,130 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:27:27,466 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 10:27:27,786 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 10:27:28,108 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-07 10:27:28,433 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-07 10:27:28,752 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-07 10:27:29,078 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:27:29,384 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 10:27:29,696 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:27:30,001 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:27:30,416 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:27:30,890 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:27:31,282 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:27:31,626 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 10:27:31,780 - INFO - validation batch 1, loss: 0.476, 32/6976 datapoints
2025-03-07 10:27:31,862 - INFO - validation batch 51, loss: 4.478, 1632/6976 datapoints
2025-03-07 10:27:31,942 - INFO - validation batch 101, loss: 1.060, 3232/6976 datapoints
2025-03-07 10:27:32,016 - INFO - validation batch 151, loss: 0.665, 4832/6976 datapoints
2025-03-07 10:27:32,110 - INFO - validation batch 201, loss: 2.817, 6432/6976 datapoints
2025-03-07 10:27:32,140 - INFO - Epoch 333/800 done.
2025-03-07 10:27:32,140 - INFO - Final validation performance:
Loss: 1.899, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:27:32,141 - INFO - Beginning epoch 334/800
2025-03-07 10:27:32,155 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:27:32,577 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:27:32,921 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:27:33,245 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:27:33,585 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:27:33,913 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 10:27:34,241 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 10:27:34,576 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 10:27:34,916 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 10:27:35,242 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-07 10:27:35,575 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:27:35,888 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-07 10:27:36,213 - INFO - training batch 601, loss: 0.439, 19232/28000 datapoints
2025-03-07 10:27:36,581 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:27:36,930 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 10:27:37,263 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 10:27:37,597 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-07 10:27:37,964 - INFO - training batch 851, loss: 0.038, 27232/28000 datapoints
2025-03-07 10:27:38,158 - INFO - validation batch 1, loss: 0.467, 32/6976 datapoints
2025-03-07 10:27:38,242 - INFO - validation batch 51, loss: 4.403, 1632/6976 datapoints
2025-03-07 10:27:38,329 - INFO - validation batch 101, loss: 1.070, 3232/6976 datapoints
2025-03-07 10:27:38,431 - INFO - validation batch 151, loss: 0.976, 4832/6976 datapoints
2025-03-07 10:27:38,530 - INFO - validation batch 201, loss: 2.850, 6432/6976 datapoints
2025-03-07 10:27:38,563 - INFO - Epoch 334/800 done.
2025-03-07 10:27:38,564 - INFO - Final validation performance:
Loss: 1.953, top-1 acc: 0.873top-5 acc: 0.873
2025-03-07 10:27:38,564 - INFO - Beginning epoch 335/800
2025-03-07 10:27:38,572 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-07 10:27:38,908 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-07 10:27:39,246 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-07 10:27:39,585 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-07 10:27:39,925 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:27:40,271 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-07 10:27:40,624 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-07 10:27:40,953 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-07 10:27:41,306 - INFO - training batch 401, loss: 0.038, 12832/28000 datapoints
2025-03-07 10:27:41,677 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-07 10:27:42,029 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:27:42,357 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 10:27:42,795 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 10:27:43,144 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:27:43,482 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 10:27:43,827 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:27:44,148 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:27:44,496 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-07 10:27:44,660 - INFO - validation batch 1, loss: 0.357, 32/6976 datapoints
2025-03-07 10:27:44,736 - INFO - validation batch 51, loss: 4.424, 1632/6976 datapoints
2025-03-07 10:27:44,810 - INFO - validation batch 101, loss: 1.084, 3232/6976 datapoints
2025-03-07 10:27:44,887 - INFO - validation batch 151, loss: 0.903, 4832/6976 datapoints
2025-03-07 10:27:44,986 - INFO - validation batch 201, loss: 2.948, 6432/6976 datapoints
2025-03-07 10:27:45,020 - INFO - Epoch 335/800 done.
2025-03-07 10:27:45,020 - INFO - Final validation performance:
Loss: 1.943, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:27:45,021 - INFO - Beginning epoch 336/800
2025-03-07 10:27:45,030 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 10:27:45,386 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:27:45,764 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-07 10:27:46,090 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:27:46,453 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:27:46,780 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 10:27:47,119 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-07 10:27:47,461 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-07 10:27:47,814 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-07 10:27:48,168 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-07 10:27:48,538 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:27:48,897 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 10:27:49,224 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 10:27:49,558 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:27:49,902 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 10:27:50,245 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:27:50,566 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 10:27:50,905 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 10:27:51,069 - INFO - validation batch 1, loss: 0.460, 32/6976 datapoints
2025-03-07 10:27:51,144 - INFO - validation batch 51, loss: 4.263, 1632/6976 datapoints
2025-03-07 10:27:51,234 - INFO - validation batch 101, loss: 1.105, 3232/6976 datapoints
2025-03-07 10:27:51,315 - INFO - validation batch 151, loss: 0.728, 4832/6976 datapoints
2025-03-07 10:27:51,415 - INFO - validation batch 201, loss: 2.930, 6432/6976 datapoints
2025-03-07 10:27:51,441 - INFO - Epoch 336/800 done.
2025-03-07 10:27:51,441 - INFO - Final validation performance:
Loss: 1.897, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:27:51,442 - INFO - Beginning epoch 337/800
2025-03-07 10:27:51,451 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:27:51,786 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:27:52,121 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 10:27:52,477 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:27:52,869 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-07 10:27:53,202 - INFO - training batch 251, loss: 0.038, 8032/28000 datapoints
2025-03-07 10:27:53,576 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 10:27:53,914 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-07 10:27:54,240 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-07 10:27:54,561 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-07 10:27:54,892 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-07 10:27:55,194 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-07 10:27:55,518 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 10:27:55,842 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:27:56,149 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:27:56,481 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:27:56,809 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:27:57,151 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-07 10:27:57,328 - INFO - validation batch 1, loss: 0.460, 32/6976 datapoints
2025-03-07 10:27:57,403 - INFO - validation batch 51, loss: 3.960, 1632/6976 datapoints
2025-03-07 10:27:57,483 - INFO - validation batch 101, loss: 1.230, 3232/6976 datapoints
2025-03-07 10:27:57,563 - INFO - validation batch 151, loss: 0.643, 4832/6976 datapoints
2025-03-07 10:27:57,684 - INFO - validation batch 201, loss: 2.963, 6432/6976 datapoints
2025-03-07 10:27:57,721 - INFO - Epoch 337/800 done.
2025-03-07 10:27:57,721 - INFO - Final validation performance:
Loss: 1.851, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:27:57,722 - INFO - Beginning epoch 338/800
2025-03-07 10:27:57,732 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:27:58,060 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:27:58,404 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:27:58,737 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:27:59,101 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:27:59,431 - INFO - training batch 251, loss: 0.021, 8032/28000 datapoints
2025-03-07 10:27:59,739 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 10:28:00,074 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-07 10:28:00,419 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-07 10:28:00,755 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-07 10:28:01,105 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-07 10:28:01,442 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 10:28:01,767 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-07 10:28:02,110 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 10:28:02,470 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:28:02,851 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:28:03,167 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:28:03,521 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-07 10:28:03,693 - INFO - validation batch 1, loss: 0.476, 32/6976 datapoints
2025-03-07 10:28:03,775 - INFO - validation batch 51, loss: 4.499, 1632/6976 datapoints
2025-03-07 10:28:03,876 - INFO - validation batch 101, loss: 1.047, 3232/6976 datapoints
2025-03-07 10:28:03,967 - INFO - validation batch 151, loss: 0.569, 4832/6976 datapoints
2025-03-07 10:28:04,057 - INFO - validation batch 201, loss: 2.948, 6432/6976 datapoints
2025-03-07 10:28:04,085 - INFO - Epoch 338/800 done.
2025-03-07 10:28:04,085 - INFO - Final validation performance:
Loss: 1.908, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:28:04,086 - INFO - Beginning epoch 339/800
2025-03-07 10:28:04,094 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:28:04,459 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:28:04,843 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:28:05,183 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 10:28:05,571 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:28:05,934 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 10:28:06,284 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-07 10:28:06,659 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-07 10:28:07,094 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-07 10:28:07,603 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 10:28:08,368 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:28:09,015 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 10:28:09,478 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:28:09,874 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:28:10,272 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:28:10,777 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:28:11,160 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:28:11,754 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-07 10:28:12,083 - INFO - validation batch 1, loss: 0.422, 32/6976 datapoints
2025-03-07 10:28:12,301 - INFO - validation batch 51, loss: 4.507, 1632/6976 datapoints
2025-03-07 10:28:12,485 - INFO - validation batch 101, loss: 1.047, 3232/6976 datapoints
2025-03-07 10:28:12,884 - INFO - validation batch 151, loss: 0.680, 4832/6976 datapoints
2025-03-07 10:28:13,231 - INFO - validation batch 201, loss: 2.837, 6432/6976 datapoints
2025-03-07 10:28:13,363 - INFO - Epoch 339/800 done.
2025-03-07 10:28:13,363 - INFO - Final validation performance:
Loss: 1.899, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:28:13,364 - INFO - Beginning epoch 340/800
2025-03-07 10:28:13,396 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:28:14,360 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:28:15,138 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:28:15,722 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:28:16,369 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:28:17,037 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-07 10:28:17,717 - INFO - training batch 301, loss: 1.029, 9632/28000 datapoints
2025-03-07 10:28:18,283 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-07 10:28:18,974 - INFO - training batch 401, loss: 0.109, 12832/28000 datapoints
2025-03-07 10:28:19,567 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-07 10:28:20,039 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:28:20,507 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-07 10:28:20,914 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:28:21,379 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:28:21,738 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-07 10:28:22,118 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:28:22,452 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:28:22,794 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-07 10:28:22,964 - INFO - validation batch 1, loss: 0.497, 32/6976 datapoints
2025-03-07 10:28:23,077 - INFO - validation batch 51, loss: 3.830, 1632/6976 datapoints
2025-03-07 10:28:23,174 - INFO - validation batch 101, loss: 1.064, 3232/6976 datapoints
2025-03-07 10:28:23,252 - INFO - validation batch 151, loss: 0.578, 4832/6976 datapoints
2025-03-07 10:28:23,339 - INFO - validation batch 201, loss: 3.182, 6432/6976 datapoints
2025-03-07 10:28:23,376 - INFO - Epoch 340/800 done.
2025-03-07 10:28:23,376 - INFO - Final validation performance:
Loss: 1.830, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:28:23,377 - INFO - Beginning epoch 341/800
2025-03-07 10:28:23,385 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-07 10:28:23,770 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:28:24,130 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 10:28:24,509 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-07 10:28:24,835 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:28:25,205 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 10:28:25,578 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 10:28:25,914 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-07 10:28:26,229 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-07 10:28:26,553 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 10:28:26,890 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-07 10:28:27,174 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 10:28:27,486 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:28:27,784 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:28:28,072 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:28:28,375 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:28:28,681 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:28:28,999 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-07 10:28:29,144 - INFO - validation batch 1, loss: 0.439, 32/6976 datapoints
2025-03-07 10:28:29,213 - INFO - validation batch 51, loss: 4.274, 1632/6976 datapoints
2025-03-07 10:28:29,292 - INFO - validation batch 101, loss: 1.027, 3232/6976 datapoints
2025-03-07 10:28:29,378 - INFO - validation batch 151, loss: 0.721, 4832/6976 datapoints
2025-03-07 10:28:29,468 - INFO - validation batch 201, loss: 3.106, 6432/6976 datapoints
2025-03-07 10:28:29,499 - INFO - Epoch 341/800 done.
2025-03-07 10:28:29,500 - INFO - Final validation performance:
Loss: 1.913, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:28:29,501 - INFO - Beginning epoch 342/800
2025-03-07 10:28:29,509 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:28:29,849 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:28:30,182 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:28:30,571 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:28:30,913 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:28:31,216 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 10:28:31,538 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 10:28:31,815 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-07 10:28:32,112 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-07 10:28:32,400 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-07 10:28:32,693 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:28:32,964 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 10:28:33,270 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 10:28:33,570 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:28:33,906 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:28:34,268 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:28:34,878 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:28:35,287 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 10:28:35,823 - INFO - validation batch 1, loss: 0.446, 32/6976 datapoints
2025-03-07 10:28:35,929 - INFO - validation batch 51, loss: 4.433, 1632/6976 datapoints
2025-03-07 10:28:36,027 - INFO - validation batch 101, loss: 1.034, 3232/6976 datapoints
2025-03-07 10:28:36,131 - INFO - validation batch 151, loss: 0.765, 4832/6976 datapoints
2025-03-07 10:28:36,233 - INFO - validation batch 201, loss: 3.033, 6432/6976 datapoints
2025-03-07 10:28:36,272 - INFO - Epoch 342/800 done.
2025-03-07 10:28:36,273 - INFO - Final validation performance:
Loss: 1.942, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:28:36,274 - INFO - Beginning epoch 343/800
2025-03-07 10:28:36,286 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:28:36,685 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:28:37,070 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:28:37,433 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:28:37,768 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:28:38,097 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 10:28:38,494 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 10:28:38,841 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-07 10:28:39,159 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-07 10:28:39,474 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 10:28:39,771 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:28:40,047 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 10:28:40,333 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:28:40,614 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:28:40,889 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:28:41,180 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:28:41,459 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:28:41,744 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 10:28:41,887 - INFO - validation batch 1, loss: 0.450, 32/6976 datapoints
2025-03-07 10:28:41,955 - INFO - validation batch 51, loss: 4.487, 1632/6976 datapoints
2025-03-07 10:28:42,026 - INFO - validation batch 101, loss: 1.037, 3232/6976 datapoints
2025-03-07 10:28:42,091 - INFO - validation batch 151, loss: 0.701, 4832/6976 datapoints
2025-03-07 10:28:42,156 - INFO - validation batch 201, loss: 3.040, 6432/6976 datapoints
2025-03-07 10:28:42,180 - INFO - Epoch 343/800 done.
2025-03-07 10:28:42,180 - INFO - Final validation performance:
Loss: 1.943, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:28:42,181 - INFO - Beginning epoch 344/800
2025-03-07 10:28:42,188 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:28:42,474 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:28:42,765 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:28:43,043 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:28:43,350 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:28:43,646 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 10:28:43,942 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 10:28:44,223 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-07 10:28:44,524 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-07 10:28:44,819 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 10:28:45,113 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:28:45,391 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 10:28:45,676 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:28:45,958 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:28:46,241 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:28:46,536 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:28:46,816 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:28:47,112 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 10:28:47,254 - INFO - validation batch 1, loss: 0.459, 32/6976 datapoints
2025-03-07 10:28:47,325 - INFO - validation batch 51, loss: 4.606, 1632/6976 datapoints
2025-03-07 10:28:47,392 - INFO - validation batch 101, loss: 1.064, 3232/6976 datapoints
2025-03-07 10:28:47,462 - INFO - validation batch 151, loss: 0.711, 4832/6976 datapoints
2025-03-07 10:28:47,535 - INFO - validation batch 201, loss: 3.054, 6432/6976 datapoints
2025-03-07 10:28:47,559 - INFO - Epoch 344/800 done.
2025-03-07 10:28:47,560 - INFO - Final validation performance:
Loss: 1.979, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:28:47,560 - INFO - Beginning epoch 345/800
2025-03-07 10:28:47,567 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:28:47,857 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:28:48,152 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:28:48,435 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:28:48,723 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:28:49,018 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 10:28:49,311 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 10:28:49,595 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-07 10:28:49,897 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 10:28:50,186 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 10:28:50,483 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:28:50,753 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 10:28:51,027 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:28:51,308 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:28:51,586 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:28:51,867 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:28:52,140 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:28:52,422 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 10:28:52,559 - INFO - validation batch 1, loss: 0.448, 32/6976 datapoints
2025-03-07 10:28:52,623 - INFO - validation batch 51, loss: 4.709, 1632/6976 datapoints
2025-03-07 10:28:52,687 - INFO - validation batch 101, loss: 1.101, 3232/6976 datapoints
2025-03-07 10:28:52,749 - INFO - validation batch 151, loss: 0.759, 4832/6976 datapoints
2025-03-07 10:28:52,815 - INFO - validation batch 201, loss: 3.039, 6432/6976 datapoints
2025-03-07 10:28:52,837 - INFO - Epoch 345/800 done.
2025-03-07 10:28:52,837 - INFO - Final validation performance:
Loss: 2.011, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:28:52,838 - INFO - Beginning epoch 346/800
2025-03-07 10:28:52,845 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:28:53,127 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:28:53,442 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:28:53,726 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:28:54,016 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-07 10:28:54,308 - INFO - training batch 251, loss: 0.030, 8032/28000 datapoints
2025-03-07 10:28:54,600 - INFO - training batch 301, loss: 0.054, 9632/28000 datapoints
2025-03-07 10:28:54,892 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 10:28:55,183 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-07 10:28:55,479 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-07 10:28:55,773 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 10:28:56,055 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-07 10:28:56,339 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:28:56,632 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:28:56,919 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 10:28:57,210 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-07 10:28:57,502 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:28:57,805 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-07 10:28:57,976 - INFO - validation batch 1, loss: 0.500, 32/6976 datapoints
2025-03-07 10:28:58,061 - INFO - validation batch 51, loss: 4.482, 1632/6976 datapoints
2025-03-07 10:28:58,150 - INFO - validation batch 101, loss: 1.096, 3232/6976 datapoints
2025-03-07 10:28:58,227 - INFO - validation batch 151, loss: 1.035, 4832/6976 datapoints
2025-03-07 10:28:58,306 - INFO - validation batch 201, loss: 3.171, 6432/6976 datapoints
2025-03-07 10:28:58,330 - INFO - Epoch 346/800 done.
2025-03-07 10:28:58,330 - INFO - Final validation performance:
Loss: 2.057, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 10:28:58,331 - INFO - Beginning epoch 347/800
2025-03-07 10:28:58,338 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-07 10:28:58,639 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:28:58,944 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:28:59,239 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-07 10:28:59,535 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:28:59,828 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 10:29:00,119 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:29:00,416 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-07 10:29:00,708 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-07 10:29:00,996 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-07 10:29:01,302 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-07 10:29:01,589 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-07 10:29:01,879 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:29:02,154 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:29:02,455 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:29:02,745 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:29:03,022 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:29:03,314 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-07 10:29:03,465 - INFO - validation batch 1, loss: 0.487, 32/6976 datapoints
2025-03-07 10:29:03,550 - INFO - validation batch 51, loss: 4.694, 1632/6976 datapoints
2025-03-07 10:29:03,617 - INFO - validation batch 101, loss: 1.178, 3232/6976 datapoints
2025-03-07 10:29:03,685 - INFO - validation batch 151, loss: 0.968, 4832/6976 datapoints
2025-03-07 10:29:03,752 - INFO - validation batch 201, loss: 3.045, 6432/6976 datapoints
2025-03-07 10:29:03,775 - INFO - Epoch 347/800 done.
2025-03-07 10:29:03,775 - INFO - Final validation performance:
Loss: 2.074, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:29:03,776 - INFO - Beginning epoch 348/800
2025-03-07 10:29:03,783 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:29:04,070 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:29:04,373 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:29:04,656 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-07 10:29:04,944 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:29:05,236 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 10:29:05,532 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 10:29:05,828 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 10:29:06,131 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-07 10:29:06,441 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 10:29:06,745 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-07 10:29:07,068 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 10:29:07,383 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:29:07,674 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:29:07,957 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 10:29:08,262 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:29:08,561 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:29:08,862 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-07 10:29:09,017 - INFO - validation batch 1, loss: 0.506, 32/6976 datapoints
2025-03-07 10:29:09,086 - INFO - validation batch 51, loss: 4.725, 1632/6976 datapoints
2025-03-07 10:29:09,155 - INFO - validation batch 101, loss: 1.140, 3232/6976 datapoints
2025-03-07 10:29:09,224 - INFO - validation batch 151, loss: 0.806, 4832/6976 datapoints
2025-03-07 10:29:09,296 - INFO - validation batch 201, loss: 3.037, 6432/6976 datapoints
2025-03-07 10:29:09,330 - INFO - Epoch 348/800 done.
2025-03-07 10:29:09,346 - INFO - Final validation performance:
Loss: 2.043, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:29:09,347 - INFO - Beginning epoch 349/800
2025-03-07 10:29:09,373 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:29:09,663 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:29:09,967 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:29:10,254 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:29:10,547 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:29:10,840 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 10:29:11,134 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 10:29:11,429 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 10:29:11,723 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-07 10:29:12,016 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 10:29:12,312 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:29:12,595 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 10:29:12,875 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 10:29:13,159 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:29:13,450 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 10:29:13,771 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:29:14,073 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:29:14,371 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 10:29:14,521 - INFO - validation batch 1, loss: 0.526, 32/6976 datapoints
2025-03-07 10:29:14,589 - INFO - validation batch 51, loss: 4.764, 1632/6976 datapoints
2025-03-07 10:29:14,658 - INFO - validation batch 101, loss: 1.114, 3232/6976 datapoints
2025-03-07 10:29:14,727 - INFO - validation batch 151, loss: 0.731, 4832/6976 datapoints
2025-03-07 10:29:14,795 - INFO - validation batch 201, loss: 3.019, 6432/6976 datapoints
2025-03-07 10:29:14,821 - INFO - Epoch 349/800 done.
2025-03-07 10:29:14,821 - INFO - Final validation performance:
Loss: 2.031, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:29:14,822 - INFO - Beginning epoch 350/800
2025-03-07 10:29:14,828 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:29:15,123 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:29:15,431 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:29:15,726 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:29:16,017 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:29:16,318 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 10:29:16,625 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 10:29:16,916 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 10:29:17,238 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-07 10:29:17,547 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 10:29:17,848 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:29:18,137 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 10:29:18,428 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:29:18,720 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:29:19,028 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 10:29:19,350 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:29:19,656 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:29:19,972 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 10:29:20,131 - INFO - validation batch 1, loss: 0.569, 32/6976 datapoints
2025-03-07 10:29:20,215 - INFO - validation batch 51, loss: 4.851, 1632/6976 datapoints
2025-03-07 10:29:20,290 - INFO - validation batch 101, loss: 1.100, 3232/6976 datapoints
2025-03-07 10:29:20,371 - INFO - validation batch 151, loss: 0.665, 4832/6976 datapoints
2025-03-07 10:29:20,445 - INFO - validation batch 201, loss: 2.997, 6432/6976 datapoints
2025-03-07 10:29:20,479 - INFO - Epoch 350/800 done.
2025-03-07 10:29:20,479 - INFO - Final validation performance:
Loss: 2.037, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:29:20,480 - INFO - Beginning epoch 351/800
2025-03-07 10:29:20,487 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:29:20,804 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:29:21,113 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:29:21,411 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:29:21,699 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:29:21,994 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 10:29:22,286 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 10:29:22,626 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 10:29:22,926 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 10:29:23,242 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 10:29:23,587 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:29:23,912 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 10:29:24,200 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:29:24,493 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:29:24,782 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 10:29:25,109 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:29:25,403 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:29:25,695 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 10:29:25,841 - INFO - validation batch 1, loss: 0.579, 32/6976 datapoints
2025-03-07 10:29:25,909 - INFO - validation batch 51, loss: 4.918, 1632/6976 datapoints
2025-03-07 10:29:25,978 - INFO - validation batch 101, loss: 1.110, 3232/6976 datapoints
2025-03-07 10:29:26,044 - INFO - validation batch 151, loss: 0.653, 4832/6976 datapoints
2025-03-07 10:29:26,111 - INFO - validation batch 201, loss: 3.026, 6432/6976 datapoints
2025-03-07 10:29:26,133 - INFO - Epoch 351/800 done.
2025-03-07 10:29:26,133 - INFO - Final validation performance:
Loss: 2.057, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:29:26,134 - INFO - Beginning epoch 352/800
2025-03-07 10:29:26,141 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:29:26,483 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:29:26,815 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:29:27,111 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 10:29:27,399 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:29:27,699 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 10:29:27,986 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 10:29:28,266 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 10:29:28,561 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 10:29:28,855 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 10:29:29,154 - INFO - training batch 501, loss: 0.274, 16032/28000 datapoints
2025-03-07 10:29:29,431 - INFO - training batch 551, loss: 0.269, 17632/28000 datapoints
2025-03-07 10:29:29,710 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-07 10:29:30,006 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:29:30,306 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-07 10:29:30,609 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-07 10:29:30,895 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 10:29:31,199 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-07 10:29:31,347 - INFO - validation batch 1, loss: 0.473, 32/6976 datapoints
2025-03-07 10:29:31,417 - INFO - validation batch 51, loss: 3.813, 1632/6976 datapoints
2025-03-07 10:29:31,485 - INFO - validation batch 101, loss: 1.163, 3232/6976 datapoints
2025-03-07 10:29:31,557 - INFO - validation batch 151, loss: 1.093, 4832/6976 datapoints
2025-03-07 10:29:31,631 - INFO - validation batch 201, loss: 3.049, 6432/6976 datapoints
2025-03-07 10:29:31,657 - INFO - Epoch 352/800 done.
2025-03-07 10:29:31,657 - INFO - Final validation performance:
Loss: 1.918, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 10:29:31,658 - INFO - Beginning epoch 353/800
2025-03-07 10:29:31,666 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-07 10:29:31,955 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:29:32,253 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 10:29:32,539 - INFO - training batch 151, loss: 0.092, 4832/28000 datapoints
2025-03-07 10:29:32,825 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-07 10:29:33,175 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 10:29:33,464 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 10:29:33,763 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-07 10:29:34,058 - INFO - training batch 401, loss: 0.028, 12832/28000 datapoints
2025-03-07 10:29:34,349 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-07 10:29:34,632 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 10:29:34,901 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-07 10:29:35,176 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:29:35,464 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:29:35,755 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:29:36,074 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-07 10:29:36,365 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:29:36,661 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-07 10:29:36,807 - INFO - validation batch 1, loss: 0.575, 32/6976 datapoints
2025-03-07 10:29:36,874 - INFO - validation batch 51, loss: 4.734, 1632/6976 datapoints
2025-03-07 10:29:36,942 - INFO - validation batch 101, loss: 1.146, 3232/6976 datapoints
2025-03-07 10:29:37,016 - INFO - validation batch 151, loss: 0.727, 4832/6976 datapoints
2025-03-07 10:29:37,086 - INFO - validation batch 201, loss: 2.972, 6432/6976 datapoints
2025-03-07 10:29:37,113 - INFO - Epoch 353/800 done.
2025-03-07 10:29:37,113 - INFO - Final validation performance:
Loss: 2.031, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:29:37,114 - INFO - Beginning epoch 354/800
2025-03-07 10:29:37,122 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:29:37,415 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:29:37,715 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:29:38,002 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 10:29:38,293 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:29:38,584 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 10:29:38,878 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-07 10:29:39,164 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-07 10:29:39,452 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 10:29:39,747 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-07 10:29:40,036 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 10:29:40,311 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-07 10:29:40,584 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 10:29:40,868 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 10:29:41,144 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:29:41,451 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:29:41,735 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:29:42,018 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 10:29:42,162 - INFO - validation batch 1, loss: 0.410, 32/6976 datapoints
2025-03-07 10:29:42,229 - INFO - validation batch 51, loss: 4.757, 1632/6976 datapoints
2025-03-07 10:29:42,297 - INFO - validation batch 101, loss: 0.998, 3232/6976 datapoints
2025-03-07 10:29:42,361 - INFO - validation batch 151, loss: 0.836, 4832/6976 datapoints
2025-03-07 10:29:42,425 - INFO - validation batch 201, loss: 3.024, 6432/6976 datapoints
2025-03-07 10:29:42,446 - INFO - Epoch 354/800 done.
2025-03-07 10:29:42,446 - INFO - Final validation performance:
Loss: 2.005, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:29:42,447 - INFO - Beginning epoch 355/800
2025-03-07 10:29:42,454 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:29:42,741 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:29:43,024 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-07 10:29:43,311 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 10:29:43,593 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:29:43,909 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 10:29:44,204 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-07 10:29:44,486 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-07 10:29:44,779 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-07 10:29:45,076 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 10:29:45,389 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 10:29:45,660 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 10:29:45,931 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:29:46,217 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:29:46,490 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 10:29:46,824 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 10:29:47,109 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:29:47,397 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 10:29:47,546 - INFO - validation batch 1, loss: 0.456, 32/6976 datapoints
2025-03-07 10:29:47,611 - INFO - validation batch 51, loss: 4.616, 1632/6976 datapoints
2025-03-07 10:29:47,675 - INFO - validation batch 101, loss: 1.057, 3232/6976 datapoints
2025-03-07 10:29:47,742 - INFO - validation batch 151, loss: 0.805, 4832/6976 datapoints
2025-03-07 10:29:47,809 - INFO - validation batch 201, loss: 3.002, 6432/6976 datapoints
2025-03-07 10:29:47,835 - INFO - Epoch 355/800 done.
2025-03-07 10:29:47,835 - INFO - Final validation performance:
Loss: 1.987, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:29:47,836 - INFO - Beginning epoch 356/800
2025-03-07 10:29:47,843 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:29:48,129 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:29:48,426 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:29:48,701 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 10:29:48,979 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:29:49,269 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 10:29:49,561 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 10:29:49,841 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 10:29:50,136 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 10:29:50,436 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 10:29:50,738 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 10:29:51,016 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 10:29:51,307 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 10:29:51,589 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:29:51,863 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 10:29:52,159 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:29:52,439 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:29:52,724 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 10:29:52,867 - INFO - validation batch 1, loss: 0.460, 32/6976 datapoints
2025-03-07 10:29:52,932 - INFO - validation batch 51, loss: 4.669, 1632/6976 datapoints
2025-03-07 10:29:52,997 - INFO - validation batch 101, loss: 1.067, 3232/6976 datapoints
2025-03-07 10:29:53,063 - INFO - validation batch 151, loss: 0.831, 4832/6976 datapoints
2025-03-07 10:29:53,133 - INFO - validation batch 201, loss: 3.000, 6432/6976 datapoints
2025-03-07 10:29:53,160 - INFO - Epoch 356/800 done.
2025-03-07 10:29:53,160 - INFO - Final validation performance:
Loss: 2.005, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:29:53,161 - INFO - Beginning epoch 357/800
2025-03-07 10:29:53,168 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:29:53,458 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:29:53,747 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:29:54,062 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 10:29:54,345 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:29:54,628 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 10:29:54,909 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 10:29:55,186 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 10:29:55,474 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 10:29:55,763 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 10:29:56,074 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 10:29:56,375 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 10:29:56,691 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 10:29:57,019 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:29:57,341 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 10:29:57,639 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:29:57,920 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:29:58,209 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 10:29:58,369 - INFO - validation batch 1, loss: 0.489, 32/6976 datapoints
2025-03-07 10:29:58,438 - INFO - validation batch 51, loss: 4.711, 1632/6976 datapoints
2025-03-07 10:29:58,523 - INFO - validation batch 101, loss: 1.076, 3232/6976 datapoints
2025-03-07 10:29:58,600 - INFO - validation batch 151, loss: 0.759, 4832/6976 datapoints
2025-03-07 10:29:58,675 - INFO - validation batch 201, loss: 3.024, 6432/6976 datapoints
2025-03-07 10:29:58,697 - INFO - Epoch 357/800 done.
2025-03-07 10:29:58,697 - INFO - Final validation performance:
Loss: 2.012, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:29:58,698 - INFO - Beginning epoch 358/800
2025-03-07 10:29:58,707 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:29:59,026 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:29:59,402 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:29:59,771 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 10:30:00,150 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:30:00,544 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 10:30:00,903 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 10:30:01,219 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 10:30:01,601 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 10:30:01,939 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 10:30:02,237 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 10:30:02,524 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 10:30:02,806 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 10:30:03,101 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:30:03,431 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 10:30:03,726 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:30:04,006 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:30:04,314 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 10:30:04,456 - INFO - validation batch 1, loss: 0.518, 32/6976 datapoints
2025-03-07 10:30:04,518 - INFO - validation batch 51, loss: 4.804, 1632/6976 datapoints
2025-03-07 10:30:04,580 - INFO - validation batch 101, loss: 1.092, 3232/6976 datapoints
2025-03-07 10:30:04,641 - INFO - validation batch 151, loss: 0.732, 4832/6976 datapoints
2025-03-07 10:30:04,702 - INFO - validation batch 201, loss: 3.035, 6432/6976 datapoints
2025-03-07 10:30:04,722 - INFO - Epoch 358/800 done.
2025-03-07 10:30:04,723 - INFO - Final validation performance:
Loss: 2.036, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:30:04,723 - INFO - Beginning epoch 359/800
2025-03-07 10:30:04,730 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:30:05,015 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:30:05,308 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:30:05,577 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 10:30:05,850 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:30:06,135 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 10:30:06,422 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 10:30:06,696 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 10:30:06,984 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 10:30:07,269 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 10:30:07,581 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 10:30:07,855 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 10:30:08,153 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 10:30:08,485 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:30:08,802 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 10:30:09,141 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:30:09,459 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:30:09,755 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 10:30:09,905 - INFO - validation batch 1, loss: 0.530, 32/6976 datapoints
2025-03-07 10:30:09,973 - INFO - validation batch 51, loss: 4.876, 1632/6976 datapoints
2025-03-07 10:30:10,040 - INFO - validation batch 101, loss: 1.122, 3232/6976 datapoints
2025-03-07 10:30:10,109 - INFO - validation batch 151, loss: 0.734, 4832/6976 datapoints
2025-03-07 10:30:10,179 - INFO - validation batch 201, loss: 3.088, 6432/6976 datapoints
2025-03-07 10:30:10,202 - INFO - Epoch 359/800 done.
2025-03-07 10:30:10,202 - INFO - Final validation performance:
Loss: 2.070, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 10:30:10,203 - INFO - Beginning epoch 360/800
2025-03-07 10:30:10,212 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:30:10,555 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:30:10,876 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:30:11,181 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 10:30:11,494 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:30:11,827 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 10:30:12,126 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 10:30:12,416 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 10:30:12,724 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 10:30:13,019 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 10:30:13,331 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 10:30:13,700 - INFO - training batch 551, loss: 0.259, 17632/28000 datapoints
2025-03-07 10:30:14,117 - INFO - training batch 601, loss: 0.302, 19232/28000 datapoints
2025-03-07 10:30:14,493 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:30:14,842 - INFO - training batch 701, loss: 0.092, 22432/28000 datapoints
2025-03-07 10:30:15,167 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 10:30:15,503 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-07 10:30:15,845 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-07 10:30:16,041 - INFO - validation batch 1, loss: 0.348, 32/6976 datapoints
2025-03-07 10:30:16,125 - INFO - validation batch 51, loss: 5.318, 1632/6976 datapoints
2025-03-07 10:30:16,196 - INFO - validation batch 101, loss: 1.140, 3232/6976 datapoints
2025-03-07 10:30:16,277 - INFO - validation batch 151, loss: 1.096, 4832/6976 datapoints
2025-03-07 10:30:16,352 - INFO - validation batch 201, loss: 2.829, 6432/6976 datapoints
2025-03-07 10:30:16,383 - INFO - Epoch 360/800 done.
2025-03-07 10:30:16,383 - INFO - Final validation performance:
Loss: 2.146, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 10:30:16,384 - INFO - Beginning epoch 361/800
2025-03-07 10:30:16,394 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 10:30:16,738 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:30:17,096 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-07 10:30:17,463 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 10:30:17,786 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-07 10:30:18,106 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 10:30:18,488 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-07 10:30:18,793 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-07 10:30:19,118 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-07 10:30:19,439 - INFO - training batch 451, loss: 0.098, 14432/28000 datapoints
2025-03-07 10:30:19,757 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 10:30:20,059 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 10:30:20,360 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 10:30:20,665 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:30:20,950 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 10:30:21,256 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 10:30:21,568 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:30:21,857 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 10:30:22,003 - INFO - validation batch 1, loss: 0.367, 32/6976 datapoints
2025-03-07 10:30:22,084 - INFO - validation batch 51, loss: 4.901, 1632/6976 datapoints
2025-03-07 10:30:22,161 - INFO - validation batch 101, loss: 1.088, 3232/6976 datapoints
2025-03-07 10:30:22,229 - INFO - validation batch 151, loss: 0.735, 4832/6976 datapoints
2025-03-07 10:30:22,295 - INFO - validation batch 201, loss: 3.142, 6432/6976 datapoints
2025-03-07 10:30:22,320 - INFO - Epoch 361/800 done.
2025-03-07 10:30:22,321 - INFO - Final validation performance:
Loss: 2.046, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 10:30:22,321 - INFO - Beginning epoch 362/800
2025-03-07 10:30:22,328 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 10:30:22,627 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 10:30:22,940 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:30:23,228 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 10:30:23,543 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 10:30:23,850 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 10:30:24,166 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 10:30:24,523 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-07 10:30:24,848 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 10:30:25,196 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-07 10:30:25,589 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 10:30:25,985 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 10:30:26,283 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 10:30:26,590 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:30:26,889 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 10:30:27,183 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 10:30:27,510 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:30:27,826 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-07 10:30:27,990 - INFO - validation batch 1, loss: 0.488, 32/6976 datapoints
2025-03-07 10:30:28,057 - INFO - validation batch 51, loss: 4.780, 1632/6976 datapoints
2025-03-07 10:30:28,124 - INFO - validation batch 101, loss: 1.122, 3232/6976 datapoints
2025-03-07 10:30:28,206 - INFO - validation batch 151, loss: 0.510, 4832/6976 datapoints
2025-03-07 10:30:28,274 - INFO - validation batch 201, loss: 3.125, 6432/6976 datapoints
2025-03-07 10:30:28,299 - INFO - Epoch 362/800 done.
2025-03-07 10:30:28,299 - INFO - Final validation performance:
Loss: 2.005, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 10:30:28,300 - INFO - Beginning epoch 363/800
2025-03-07 10:30:28,308 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:30:28,623 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:30:28,955 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:30:29,269 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 10:30:29,567 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:30:29,858 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 10:30:30,151 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 10:30:30,470 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 10:30:30,785 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 10:30:31,085 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 10:30:31,387 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 10:30:31,689 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 10:30:31,960 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 10:30:32,272 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:30:32,561 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 10:30:32,890 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 10:30:33,241 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:30:33,581 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 10:30:33,750 - INFO - validation batch 1, loss: 0.420, 32/6976 datapoints
2025-03-07 10:30:33,976 - INFO - validation batch 51, loss: 4.859, 1632/6976 datapoints
2025-03-07 10:30:34,091 - INFO - validation batch 101, loss: 1.152, 3232/6976 datapoints
2025-03-07 10:30:34,236 - INFO - validation batch 151, loss: 0.719, 4832/6976 datapoints
2025-03-07 10:30:34,428 - INFO - validation batch 201, loss: 3.110, 6432/6976 datapoints
2025-03-07 10:30:34,478 - INFO - Epoch 363/800 done.
2025-03-07 10:30:34,478 - INFO - Final validation performance:
Loss: 2.052, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:30:34,480 - INFO - Beginning epoch 364/800
2025-03-07 10:30:34,491 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:30:34,930 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:30:35,404 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:30:35,817 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 10:30:36,202 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:30:36,645 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 10:30:37,095 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 10:30:37,454 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 10:30:37,887 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 10:30:38,261 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 10:30:38,658 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 10:30:39,036 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 10:30:39,444 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 10:30:40,079 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:30:40,735 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 10:30:41,080 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 10:30:41,425 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:30:41,786 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 10:30:41,964 - INFO - validation batch 1, loss: 0.439, 32/6976 datapoints
2025-03-07 10:30:42,071 - INFO - validation batch 51, loss: 4.929, 1632/6976 datapoints
2025-03-07 10:30:42,175 - INFO - validation batch 101, loss: 1.140, 3232/6976 datapoints
2025-03-07 10:30:42,289 - INFO - validation batch 151, loss: 0.715, 4832/6976 datapoints
2025-03-07 10:30:42,395 - INFO - validation batch 201, loss: 3.106, 6432/6976 datapoints
2025-03-07 10:30:42,427 - INFO - Epoch 364/800 done.
2025-03-07 10:30:42,428 - INFO - Final validation performance:
Loss: 2.066, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:30:42,429 - INFO - Beginning epoch 365/800
2025-03-07 10:30:42,437 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:30:42,809 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:30:44,013 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:30:44,458 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 10:30:44,905 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:30:45,381 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 10:30:46,027 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 10:30:47,752 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 10:30:48,726 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 10:30:49,873 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 10:30:50,511 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 10:30:51,159 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 10:30:51,957 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 10:30:52,796 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 10:30:53,225 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 10:30:53,875 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 10:30:55,315 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 10:30:55,813 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 10:30:56,011 - INFO - validation batch 1, loss: 0.443, 32/6976 datapoints
2025-03-07 10:30:56,145 - INFO - validation batch 51, loss: 4.948, 1632/6976 datapoints
2025-03-07 10:30:56,330 - INFO - validation batch 101, loss: 1.130, 3232/6976 datapoints
2025-03-07 10:30:56,447 - INFO - validation batch 151, loss: 0.692, 4832/6976 datapoints
2025-03-07 10:30:56,553 - INFO - validation batch 201, loss: 3.132, 6432/6976 datapoints
2025-03-07 10:30:56,587 - INFO - Epoch 365/800 done.
2025-03-07 10:30:56,587 - INFO - Final validation performance:
Loss: 2.069, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 10:30:56,590 - INFO - Beginning epoch 366/800
2025-03-07 10:30:56,603 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 10:30:56,946 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 10:30:57,298 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 10:30:57,642 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 10:30:57,978 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 10:30:58,319 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 10:30:58,664 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 10:30:58,973 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 10:30:59,315 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:15:14,253 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:15:14,725 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:15:15,089 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:15:15,456 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:15:15,858 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:15:16,232 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:15:16,583 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:15:16,917 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:15:17,284 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:15:17,467 - INFO - validation batch 1, loss: 0.463, 32/6976 datapoints
2025-03-07 11:15:17,585 - INFO - validation batch 51, loss: 4.990, 1632/6976 datapoints
2025-03-07 11:15:17,712 - INFO - validation batch 101, loss: 1.130, 3232/6976 datapoints
2025-03-07 11:15:17,824 - INFO - validation batch 151, loss: 0.693, 4832/6976 datapoints
2025-03-07 11:15:17,929 - INFO - validation batch 201, loss: 3.138, 6432/6976 datapoints
2025-03-07 11:15:17,966 - INFO - Epoch 366/800 done.
2025-03-07 11:15:17,973 - INFO - Final validation performance:
Loss: 2.083, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:15:17,976 - INFO - Beginning epoch 367/800
2025-03-07 11:15:17,985 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:15:18,486 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:15:18,897 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:15:19,288 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:15:20,401 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:15:20,741 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:15:21,107 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:15:21,472 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:15:21,798 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:15:22,114 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:15:22,517 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:15:23,125 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:15:24,060 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:15:24,542 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:15:24,991 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:15:25,482 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:15:25,819 - INFO - validation batch 1, loss: 0.473, 32/6976 datapoints
2025-03-07 11:15:25,960 - INFO - validation batch 51, loss: 5.070, 1632/6976 datapoints
2025-03-07 11:15:26,098 - INFO - validation batch 101, loss: 1.135, 3232/6976 datapoints
2025-03-07 11:15:26,226 - INFO - validation batch 151, loss: 0.680, 4832/6976 datapoints
2025-03-07 11:15:26,331 - INFO - validation batch 201, loss: 3.176, 6432/6976 datapoints
2025-03-07 11:15:26,375 - INFO - Epoch 367/800 done.
2025-03-07 11:15:26,375 - INFO - Final validation performance:
Loss: 2.107, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:15:26,377 - INFO - Beginning epoch 368/800
2025-03-07 11:15:26,386 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:15:26,746 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:15:27,103 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:15:27,442 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:15:27,762 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:15:28,105 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:15:28,429 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:15:28,739 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:15:29,083 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:15:29,417 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:15:29,716 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:15:30,007 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:15:30,298 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:15:30,669 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:15:30,959 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:15:31,265 - INFO - training batch 751, loss: 0.017, 24032/28000 datapoints
2025-03-07 11:15:31,545 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-07 11:15:31,835 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:15:32,021 - INFO - validation batch 1, loss: 0.862, 32/6976 datapoints
2025-03-07 11:15:32,089 - INFO - validation batch 51, loss: 4.465, 1632/6976 datapoints
2025-03-07 11:15:32,156 - INFO - validation batch 101, loss: 1.089, 3232/6976 datapoints
2025-03-07 11:15:32,228 - INFO - validation batch 151, loss: 0.622, 4832/6976 datapoints
2025-03-07 11:15:32,294 - INFO - validation batch 201, loss: 3.564, 6432/6976 datapoints
2025-03-07 11:15:32,320 - INFO - Epoch 368/800 done.
2025-03-07 11:15:32,320 - INFO - Final validation performance:
Loss: 2.120, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:15:32,321 - INFO - Beginning epoch 369/800
2025-03-07 11:15:32,331 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-07 11:15:32,627 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 11:15:32,927 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-07 11:15:33,221 - INFO - training batch 151, loss: 0.148, 4832/28000 datapoints
2025-03-07 11:15:33,504 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-07 11:15:33,794 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-07 11:15:34,095 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-07 11:15:34,428 - INFO - training batch 351, loss: 0.054, 11232/28000 datapoints
2025-03-07 11:15:34,798 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-07 11:15:35,162 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:15:35,484 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 11:15:35,777 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:15:36,069 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:15:36,382 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:15:36,675 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:15:36,981 - INFO - training batch 751, loss: 0.034, 24032/28000 datapoints
2025-03-07 11:15:37,268 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-07 11:15:37,581 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-07 11:15:37,732 - INFO - validation batch 1, loss: 0.294, 32/6976 datapoints
2025-03-07 11:15:37,800 - INFO - validation batch 51, loss: 4.583, 1632/6976 datapoints
2025-03-07 11:15:37,869 - INFO - validation batch 101, loss: 1.194, 3232/6976 datapoints
2025-03-07 11:15:37,937 - INFO - validation batch 151, loss: 1.072, 4832/6976 datapoints
2025-03-07 11:15:38,008 - INFO - validation batch 201, loss: 3.091, 6432/6976 datapoints
2025-03-07 11:15:38,033 - INFO - Epoch 369/800 done.
2025-03-07 11:15:38,034 - INFO - Final validation performance:
Loss: 2.047, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 11:15:38,034 - INFO - Beginning epoch 370/800
2025-03-07 11:15:38,045 - INFO - training batch 1, loss: 0.017, 32/28000 datapoints
2025-03-07 11:15:38,357 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:15:38,666 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:15:38,960 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:15:39,262 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-07 11:15:39,573 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:15:39,926 - INFO - training batch 301, loss: 0.022, 9632/28000 datapoints
2025-03-07 11:15:40,227 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:15:40,542 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-07 11:15:40,843 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:15:41,143 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:15:41,433 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:15:41,735 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:15:42,159 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:15:42,559 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:15:42,930 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:15:43,272 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:15:43,592 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:15:43,754 - INFO - validation batch 1, loss: 0.475, 32/6976 datapoints
2025-03-07 11:15:43,826 - INFO - validation batch 51, loss: 4.791, 1632/6976 datapoints
2025-03-07 11:15:43,896 - INFO - validation batch 101, loss: 1.047, 3232/6976 datapoints
2025-03-07 11:15:43,964 - INFO - validation batch 151, loss: 0.635, 4832/6976 datapoints
2025-03-07 11:15:44,051 - INFO - validation batch 201, loss: 3.231, 6432/6976 datapoints
2025-03-07 11:15:44,077 - INFO - Epoch 370/800 done.
2025-03-07 11:15:44,077 - INFO - Final validation performance:
Loss: 2.036, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:15:44,078 - INFO - Beginning epoch 371/800
2025-03-07 11:15:44,088 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:15:44,483 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:15:44,835 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 11:15:45,135 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:15:45,437 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:15:45,751 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:15:46,056 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 11:15:46,355 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 11:15:46,679 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:15:46,976 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:15:47,270 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:15:47,556 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:15:47,843 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:15:48,163 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:15:48,511 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:15:48,862 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:15:49,168 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:15:49,466 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:15:49,617 - INFO - validation batch 1, loss: 0.459, 32/6976 datapoints
2025-03-07 11:15:49,686 - INFO - validation batch 51, loss: 4.855, 1632/6976 datapoints
2025-03-07 11:15:49,751 - INFO - validation batch 101, loss: 1.057, 3232/6976 datapoints
2025-03-07 11:15:49,819 - INFO - validation batch 151, loss: 0.665, 4832/6976 datapoints
2025-03-07 11:15:49,889 - INFO - validation batch 201, loss: 3.197, 6432/6976 datapoints
2025-03-07 11:15:49,914 - INFO - Epoch 371/800 done.
2025-03-07 11:15:49,914 - INFO - Final validation performance:
Loss: 2.047, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:15:49,915 - INFO - Beginning epoch 372/800
2025-03-07 11:15:49,924 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:15:50,237 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:15:50,550 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:15:50,836 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:15:51,121 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:15:51,421 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:15:51,715 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 11:15:51,996 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:15:52,310 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:15:52,622 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:15:52,932 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:15:53,215 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:15:53,504 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:15:53,807 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:15:54,103 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:15:54,433 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:15:54,725 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:15:55,020 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:15:55,170 - INFO - validation batch 1, loss: 0.465, 32/6976 datapoints
2025-03-07 11:15:55,240 - INFO - validation batch 51, loss: 4.900, 1632/6976 datapoints
2025-03-07 11:15:55,310 - INFO - validation batch 101, loss: 1.054, 3232/6976 datapoints
2025-03-07 11:15:55,384 - INFO - validation batch 151, loss: 0.667, 4832/6976 datapoints
2025-03-07 11:15:55,452 - INFO - validation batch 201, loss: 3.189, 6432/6976 datapoints
2025-03-07 11:15:55,475 - INFO - Epoch 372/800 done.
2025-03-07 11:15:55,475 - INFO - Final validation performance:
Loss: 2.055, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 11:15:55,476 - INFO - Beginning epoch 373/800
2025-03-07 11:15:55,484 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:15:55,783 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:15:56,126 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:15:56,427 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:15:56,744 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:15:57,037 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:15:57,332 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 11:15:57,623 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:15:57,930 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:15:58,231 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:15:58,535 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:15:58,819 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:15:59,104 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:15:59,406 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:15:59,698 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:16:00,016 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:16:00,326 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:16:00,637 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:16:00,793 - INFO - validation batch 1, loss: 0.460, 32/6976 datapoints
2025-03-07 11:16:00,863 - INFO - validation batch 51, loss: 4.933, 1632/6976 datapoints
2025-03-07 11:16:00,932 - INFO - validation batch 101, loss: 1.069, 3232/6976 datapoints
2025-03-07 11:16:01,002 - INFO - validation batch 151, loss: 0.664, 4832/6976 datapoints
2025-03-07 11:16:01,069 - INFO - validation batch 201, loss: 3.186, 6432/6976 datapoints
2025-03-07 11:16:01,094 - INFO - Epoch 373/800 done.
2025-03-07 11:16:01,094 - INFO - Final validation performance:
Loss: 2.062, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:16:01,095 - INFO - Beginning epoch 374/800
2025-03-07 11:16:01,107 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:16:01,420 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:16:01,743 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:16:02,032 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:16:02,317 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:16:02,622 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:16:02,918 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:16:03,204 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:16:03,513 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:16:03,810 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:16:04,113 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:16:04,424 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:16:04,735 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:16:05,042 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:16:05,333 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:16:05,647 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:16:05,944 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:16:06,240 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:16:06,397 - INFO - validation batch 1, loss: 0.466, 32/6976 datapoints
2025-03-07 11:16:06,465 - INFO - validation batch 51, loss: 4.998, 1632/6976 datapoints
2025-03-07 11:16:06,532 - INFO - validation batch 101, loss: 1.080, 3232/6976 datapoints
2025-03-07 11:16:06,598 - INFO - validation batch 151, loss: 0.651, 4832/6976 datapoints
2025-03-07 11:16:06,665 - INFO - validation batch 201, loss: 3.198, 6432/6976 datapoints
2025-03-07 11:16:06,691 - INFO - Epoch 374/800 done.
2025-03-07 11:16:06,691 - INFO - Final validation performance:
Loss: 2.079, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:16:06,692 - INFO - Beginning epoch 375/800
2025-03-07 11:16:06,703 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:16:07,016 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:16:07,328 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:16:07,628 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:16:07,913 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:16:08,213 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:16:08,512 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:16:08,799 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:16:09,109 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:16:09,424 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:16:09,730 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:16:10,024 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:16:10,324 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:16:10,634 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:16:10,931 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:16:11,248 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:16:11,560 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:16:11,859 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:16:12,015 - INFO - validation batch 1, loss: 0.478, 32/6976 datapoints
2025-03-07 11:16:12,084 - INFO - validation batch 51, loss: 5.083, 1632/6976 datapoints
2025-03-07 11:16:12,157 - INFO - validation batch 101, loss: 1.103, 3232/6976 datapoints
2025-03-07 11:16:12,229 - INFO - validation batch 151, loss: 0.637, 4832/6976 datapoints
2025-03-07 11:16:12,300 - INFO - validation batch 201, loss: 3.221, 6432/6976 datapoints
2025-03-07 11:16:12,325 - INFO - Epoch 375/800 done.
2025-03-07 11:16:12,326 - INFO - Final validation performance:
Loss: 2.104, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:16:12,326 - INFO - Beginning epoch 376/800
2025-03-07 11:16:12,336 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:16:12,654 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:16:12,982 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:16:13,306 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:16:13,602 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:16:13,979 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:16:14,318 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:16:14,688 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:16:15,031 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:16:15,346 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:16:15,657 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:16:15,954 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:16:16,276 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:16:16,605 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:16:16,899 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:16:17,209 - INFO - training batch 751, loss: 0.089, 24032/28000 datapoints
2025-03-07 11:16:17,509 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-07 11:16:17,813 - INFO - training batch 851, loss: 0.053, 27232/28000 datapoints
2025-03-07 11:16:17,961 - INFO - validation batch 1, loss: 0.640, 32/6976 datapoints
2025-03-07 11:16:18,028 - INFO - validation batch 51, loss: 5.045, 1632/6976 datapoints
2025-03-07 11:16:18,874 - INFO - validation batch 101, loss: 0.936, 3232/6976 datapoints
2025-03-07 11:16:18,952 - INFO - validation batch 151, loss: 1.044, 4832/6976 datapoints
2025-03-07 11:16:19,029 - INFO - validation batch 201, loss: 3.079, 6432/6976 datapoints
2025-03-07 11:16:19,054 - INFO - Epoch 376/800 done.
2025-03-07 11:16:19,054 - INFO - Final validation performance:
Loss: 2.149, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 11:16:19,055 - INFO - Beginning epoch 377/800
2025-03-07 11:16:19,073 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 11:16:19,421 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:16:19,727 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:16:20,027 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:16:20,325 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:16:20,631 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-07 11:16:20,934 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-07 11:16:21,239 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-07 11:16:21,561 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-07 11:16:21,870 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 11:16:22,171 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 11:16:22,474 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:16:22,766 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-07 11:16:23,062 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 11:16:23,364 - INFO - training batch 701, loss: 0.071, 22432/28000 datapoints
2025-03-07 11:16:23,671 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:16:23,964 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 11:16:24,264 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 11:16:24,429 - INFO - validation batch 1, loss: 0.150, 32/6976 datapoints
2025-03-07 11:16:24,498 - INFO - validation batch 51, loss: 5.104, 1632/6976 datapoints
2025-03-07 11:16:24,565 - INFO - validation batch 101, loss: 1.245, 3232/6976 datapoints
2025-03-07 11:16:24,645 - INFO - validation batch 151, loss: 1.284, 4832/6976 datapoints
2025-03-07 11:16:24,734 - INFO - validation batch 201, loss: 3.335, 6432/6976 datapoints
2025-03-07 11:16:24,763 - INFO - Epoch 377/800 done.
2025-03-07 11:16:24,763 - INFO - Final validation performance:
Loss: 2.224, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 11:16:24,764 - INFO - Beginning epoch 378/800
2025-03-07 11:16:24,771 - INFO - training batch 1, loss: 0.023, 32/28000 datapoints
2025-03-07 11:16:25,093 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:16:25,410 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:16:25,720 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:16:26,013 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:16:26,359 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:16:26,840 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 11:16:27,136 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-07 11:16:27,449 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 11:16:27,756 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 11:16:28,060 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:16:28,376 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:16:28,668 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:16:28,976 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:16:29,507 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:16:29,852 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:16:30,163 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 11:16:30,566 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 11:16:30,727 - INFO - validation batch 1, loss: 0.516, 32/6976 datapoints
2025-03-07 11:16:30,797 - INFO - validation batch 51, loss: 5.097, 1632/6976 datapoints
2025-03-07 11:16:30,869 - INFO - validation batch 101, loss: 1.120, 3232/6976 datapoints
2025-03-07 11:16:30,938 - INFO - validation batch 151, loss: 0.564, 4832/6976 datapoints
2025-03-07 11:16:31,008 - INFO - validation batch 201, loss: 3.286, 6432/6976 datapoints
2025-03-07 11:16:31,034 - INFO - Epoch 378/800 done.
2025-03-07 11:16:31,035 - INFO - Final validation performance:
Loss: 2.116, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:16:31,036 - INFO - Beginning epoch 379/800
2025-03-07 11:16:31,045 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:16:31,357 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:16:31,683 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:16:31,992 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 11:16:32,287 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:16:32,594 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 11:16:32,914 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 11:16:33,214 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 11:16:33,534 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:16:33,836 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:16:34,134 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:16:34,430 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:16:34,722 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:16:35,047 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:16:35,348 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:16:35,706 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:16:35,997 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 11:16:36,290 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 11:16:36,445 - INFO - validation batch 1, loss: 0.453, 32/6976 datapoints
2025-03-07 11:16:36,514 - INFO - validation batch 51, loss: 5.013, 1632/6976 datapoints
2025-03-07 11:16:36,581 - INFO - validation batch 101, loss: 1.054, 3232/6976 datapoints
2025-03-07 11:16:36,653 - INFO - validation batch 151, loss: 0.673, 4832/6976 datapoints
2025-03-07 11:16:36,721 - INFO - validation batch 201, loss: 3.231, 6432/6976 datapoints
2025-03-07 11:16:36,745 - INFO - Epoch 379/800 done.
2025-03-07 11:16:36,746 - INFO - Final validation performance:
Loss: 2.085, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:16:36,746 - INFO - Beginning epoch 380/800
2025-03-07 11:16:36,758 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:16:37,074 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:16:37,396 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 11:16:37,704 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:16:37,991 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:16:38,284 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 11:16:38,588 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 11:16:38,887 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:16:39,197 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:16:39,508 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:16:39,802 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:16:40,092 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:16:40,388 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:16:40,697 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:16:40,996 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:16:41,313 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:16:41,641 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:16:41,969 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:16:42,119 - INFO - validation batch 1, loss: 0.450, 32/6976 datapoints
2025-03-07 11:16:42,186 - INFO - validation batch 51, loss: 5.043, 1632/6976 datapoints
2025-03-07 11:16:42,256 - INFO - validation batch 101, loss: 1.031, 3232/6976 datapoints
2025-03-07 11:16:42,322 - INFO - validation batch 151, loss: 0.685, 4832/6976 datapoints
2025-03-07 11:16:42,392 - INFO - validation batch 201, loss: 3.229, 6432/6976 datapoints
2025-03-07 11:16:42,419 - INFO - Epoch 380/800 done.
2025-03-07 11:16:42,419 - INFO - Final validation performance:
Loss: 2.088, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:16:42,420 - INFO - Beginning epoch 381/800
2025-03-07 11:16:42,428 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:16:42,743 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:16:43,052 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:16:43,357 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:16:43,645 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:16:43,949 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:16:44,246 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 11:16:44,547 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:16:44,861 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:16:45,186 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:16:45,484 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:16:45,782 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:16:46,071 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:16:46,379 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:16:46,685 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:16:47,031 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:16:47,323 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:16:47,648 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:16:47,807 - INFO - validation batch 1, loss: 0.434, 32/6976 datapoints
2025-03-07 11:16:47,874 - INFO - validation batch 51, loss: 5.074, 1632/6976 datapoints
2025-03-07 11:16:47,941 - INFO - validation batch 101, loss: 1.033, 3232/6976 datapoints
2025-03-07 11:16:48,008 - INFO - validation batch 151, loss: 0.707, 4832/6976 datapoints
2025-03-07 11:16:48,075 - INFO - validation batch 201, loss: 3.235, 6432/6976 datapoints
2025-03-07 11:16:48,101 - INFO - Epoch 381/800 done.
2025-03-07 11:16:48,101 - INFO - Final validation performance:
Loss: 2.097, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:16:48,102 - INFO - Beginning epoch 382/800
2025-03-07 11:16:48,120 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:16:48,443 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:16:48,757 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:16:49,060 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:16:49,343 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:16:49,638 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:16:49,937 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:16:50,231 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:16:50,548 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:16:50,857 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:16:51,154 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:16:51,468 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:16:51,778 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:16:52,091 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:16:52,406 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:16:52,732 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:16:53,043 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:16:53,346 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:16:53,503 - INFO - validation batch 1, loss: 0.424, 32/6976 datapoints
2025-03-07 11:16:53,572 - INFO - validation batch 51, loss: 5.117, 1632/6976 datapoints
2025-03-07 11:16:53,638 - INFO - validation batch 101, loss: 1.033, 3232/6976 datapoints
2025-03-07 11:16:53,705 - INFO - validation batch 151, loss: 0.724, 4832/6976 datapoints
2025-03-07 11:16:53,772 - INFO - validation batch 201, loss: 3.256, 6432/6976 datapoints
2025-03-07 11:16:53,795 - INFO - Epoch 382/800 done.
2025-03-07 11:16:53,795 - INFO - Final validation performance:
Loss: 2.111, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:16:53,795 - INFO - Beginning epoch 383/800
2025-03-07 11:16:53,804 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:16:54,114 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:16:54,421 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:16:54,728 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:16:55,035 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:16:55,329 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:16:55,697 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:16:56,031 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:16:56,344 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:16:56,654 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:16:56,962 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:16:57,256 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:16:57,552 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:16:57,865 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:16:58,171 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:16:58,501 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:16:58,806 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:16:59,102 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:16:59,256 - INFO - validation batch 1, loss: 0.445, 32/6976 datapoints
2025-03-07 11:16:59,323 - INFO - validation batch 51, loss: 5.173, 1632/6976 datapoints
2025-03-07 11:16:59,395 - INFO - validation batch 101, loss: 1.040, 3232/6976 datapoints
2025-03-07 11:16:59,463 - INFO - validation batch 151, loss: 0.714, 4832/6976 datapoints
2025-03-07 11:16:59,529 - INFO - validation batch 201, loss: 3.270, 6432/6976 datapoints
2025-03-07 11:16:59,558 - INFO - Epoch 383/800 done.
2025-03-07 11:16:59,558 - INFO - Final validation performance:
Loss: 2.128, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:16:59,558 - INFO - Beginning epoch 384/800
2025-03-07 11:16:59,568 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:16:59,899 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:17:00,204 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:17:00,514 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:17:00,808 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:17:01,106 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:17:01,414 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:17:01,718 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:17:02,029 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:17:02,335 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:17:02,639 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:17:02,940 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:17:03,236 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:17:03,544 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:17:03,837 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:17:04,152 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:17:04,460 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:17:04,759 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:17:04,909 - INFO - validation batch 1, loss: 0.468, 32/6976 datapoints
2025-03-07 11:17:04,979 - INFO - validation batch 51, loss: 5.258, 1632/6976 datapoints
2025-03-07 11:17:05,063 - INFO - validation batch 101, loss: 1.060, 3232/6976 datapoints
2025-03-07 11:17:05,146 - INFO - validation batch 151, loss: 0.704, 4832/6976 datapoints
2025-03-07 11:17:05,217 - INFO - validation batch 201, loss: 3.289, 6432/6976 datapoints
2025-03-07 11:17:05,244 - INFO - Epoch 384/800 done.
2025-03-07 11:17:05,244 - INFO - Final validation performance:
Loss: 2.156, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:17:05,245 - INFO - Beginning epoch 385/800
2025-03-07 11:17:05,253 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:17:05,558 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:17:05,862 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:17:06,169 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:17:06,507 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:17:06,801 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:17:07,104 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:17:07,404 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:17:07,724 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:17:08,027 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:17:08,329 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:17:08,630 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:17:08,930 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:17:09,235 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:17:09,534 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:17:09,844 - INFO - training batch 751, loss: 0.056, 24032/28000 datapoints
2025-03-07 11:17:10,144 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-07 11:17:10,442 - INFO - training batch 851, loss: 0.030, 27232/28000 datapoints
2025-03-07 11:17:10,609 - INFO - validation batch 1, loss: 1.043, 32/6976 datapoints
2025-03-07 11:17:10,683 - INFO - validation batch 51, loss: 5.151, 1632/6976 datapoints
2025-03-07 11:17:10,753 - INFO - validation batch 101, loss: 0.786, 3232/6976 datapoints
2025-03-07 11:17:10,819 - INFO - validation batch 151, loss: 0.589, 4832/6976 datapoints
2025-03-07 11:17:10,887 - INFO - validation batch 201, loss: 3.871, 6432/6976 datapoints
2025-03-07 11:17:10,914 - INFO - Epoch 385/800 done.
2025-03-07 11:17:10,914 - INFO - Final validation performance:
Loss: 2.288, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:17:10,915 - INFO - Beginning epoch 386/800
2025-03-07 11:17:10,926 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:17:11,234 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:17:11,539 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 11:17:11,852 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:17:12,130 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:17:12,433 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:17:12,746 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-07 11:17:13,043 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-07 11:17:13,339 - INFO - training batch 401, loss: 0.120, 12832/28000 datapoints
2025-03-07 11:17:13,645 - INFO - training batch 451, loss: 0.022, 14432/28000 datapoints
2025-03-07 11:17:13,937 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 11:17:14,231 - INFO - training batch 551, loss: 0.022, 17632/28000 datapoints
2025-03-07 11:17:14,530 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:17:14,841 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 11:17:15,140 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:17:15,463 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 11:17:15,763 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:17:16,063 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:17:16,216 - INFO - validation batch 1, loss: 0.429, 32/6976 datapoints
2025-03-07 11:17:16,285 - INFO - validation batch 51, loss: 5.131, 1632/6976 datapoints
2025-03-07 11:17:16,354 - INFO - validation batch 101, loss: 0.953, 3232/6976 datapoints
2025-03-07 11:17:16,423 - INFO - validation batch 151, loss: 1.074, 4832/6976 datapoints
2025-03-07 11:17:16,491 - INFO - validation batch 201, loss: 3.306, 6432/6976 datapoints
2025-03-07 11:17:16,516 - INFO - Epoch 386/800 done.
2025-03-07 11:17:16,516 - INFO - Final validation performance:
Loss: 2.179, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:17:16,517 - INFO - Beginning epoch 387/800
2025-03-07 11:17:16,525 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 11:17:16,871 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 11:17:17,201 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:17:17,510 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:17:17,801 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:17:18,097 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-07 11:17:18,410 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 11:17:18,714 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:17:19,023 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:17:19,337 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:17:19,637 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:17:19,936 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 11:17:20,229 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:17:20,531 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:17:20,826 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:17:21,131 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 11:17:21,426 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:17:21,717 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:17:21,866 - INFO - validation batch 1, loss: 0.467, 32/6976 datapoints
2025-03-07 11:17:21,932 - INFO - validation batch 51, loss: 5.233, 1632/6976 datapoints
2025-03-07 11:17:21,997 - INFO - validation batch 101, loss: 0.848, 3232/6976 datapoints
2025-03-07 11:17:22,061 - INFO - validation batch 151, loss: 0.790, 4832/6976 datapoints
2025-03-07 11:17:22,127 - INFO - validation batch 201, loss: 3.514, 6432/6976 datapoints
2025-03-07 11:17:22,154 - INFO - Epoch 387/800 done.
2025-03-07 11:17:22,154 - INFO - Final validation performance:
Loss: 2.170, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:17:22,155 - INFO - Beginning epoch 388/800
2025-03-07 11:17:22,162 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:17:22,480 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:17:22,792 - INFO - training batch 101, loss: 0.213, 3232/28000 datapoints
2025-03-07 11:17:23,100 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 11:17:23,392 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:17:23,679 - INFO - training batch 251, loss: 0.033, 8032/28000 datapoints
2025-03-07 11:17:23,979 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:17:24,279 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-07 11:17:24,580 - INFO - training batch 401, loss: 0.010, 12832/28000 datapoints
2025-03-07 11:17:24,893 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 11:17:25,197 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:17:25,514 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:17:25,809 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:17:26,162 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:17:26,462 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 11:17:26,765 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 11:17:27,062 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:17:27,356 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:17:27,502 - INFO - validation batch 1, loss: 0.283, 32/6976 datapoints
2025-03-07 11:17:27,574 - INFO - validation batch 51, loss: 5.267, 1632/6976 datapoints
2025-03-07 11:17:27,642 - INFO - validation batch 101, loss: 0.906, 3232/6976 datapoints
2025-03-07 11:17:27,710 - INFO - validation batch 151, loss: 0.784, 4832/6976 datapoints
2025-03-07 11:17:27,778 - INFO - validation batch 201, loss: 3.425, 6432/6976 datapoints
2025-03-07 11:17:27,801 - INFO - Epoch 388/800 done.
2025-03-07 11:17:27,802 - INFO - Final validation performance:
Loss: 2.133, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:17:27,803 - INFO - Beginning epoch 389/800
2025-03-07 11:17:27,813 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:17:28,118 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:17:28,416 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 11:17:28,723 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-07 11:17:29,016 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-07 11:17:29,340 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-07 11:17:29,664 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 11:17:29,969 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:17:30,279 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-07 11:17:30,665 - INFO - training batch 451, loss: 0.029, 14432/28000 datapoints
2025-03-07 11:17:30,968 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 11:17:31,281 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:17:31,579 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:17:31,890 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:17:32,186 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 11:17:32,494 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 11:17:32,800 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 11:17:33,096 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:17:33,248 - INFO - validation batch 1, loss: 0.461, 32/6976 datapoints
2025-03-07 11:17:33,319 - INFO - validation batch 51, loss: 5.081, 1632/6976 datapoints
2025-03-07 11:17:33,389 - INFO - validation batch 101, loss: 1.040, 3232/6976 datapoints
2025-03-07 11:17:33,455 - INFO - validation batch 151, loss: 0.883, 4832/6976 datapoints
2025-03-07 11:17:33,522 - INFO - validation batch 201, loss: 3.548, 6432/6976 datapoints
2025-03-07 11:17:33,548 - INFO - Epoch 389/800 done.
2025-03-07 11:17:33,548 - INFO - Final validation performance:
Loss: 2.203, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:17:33,549 - INFO - Beginning epoch 390/800
2025-03-07 11:17:33,556 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:17:33,869 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:17:34,182 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:17:34,500 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:17:34,781 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 11:17:35,072 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-07 11:17:35,381 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 11:17:35,673 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:17:35,976 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:17:36,280 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:17:36,585 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 11:17:36,878 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:17:37,169 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:17:37,467 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:17:37,770 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:17:38,087 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:17:38,396 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:17:38,696 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 11:17:38,849 - INFO - validation batch 1, loss: 0.269, 32/6976 datapoints
2025-03-07 11:17:38,917 - INFO - validation batch 51, loss: 4.421, 1632/6976 datapoints
2025-03-07 11:17:38,986 - INFO - validation batch 101, loss: 1.114, 3232/6976 datapoints
2025-03-07 11:17:39,056 - INFO - validation batch 151, loss: 0.753, 4832/6976 datapoints
2025-03-07 11:17:39,123 - INFO - validation batch 201, loss: 3.484, 6432/6976 datapoints
2025-03-07 11:17:39,149 - INFO - Epoch 390/800 done.
2025-03-07 11:17:39,150 - INFO - Final validation performance:
Loss: 2.008, top-1 acc: 0.873top-5 acc: 0.873
2025-03-07 11:17:39,151 - INFO - Beginning epoch 391/800
2025-03-07 11:17:39,158 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 11:17:39,473 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:17:39,780 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:17:40,090 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:17:40,381 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:17:40,700 - INFO - training batch 251, loss: 0.014, 8032/28000 datapoints
2025-03-07 11:17:41,022 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 11:17:41,312 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:17:41,626 - INFO - training batch 401, loss: 0.030, 12832/28000 datapoints
2025-03-07 11:17:41,935 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-07 11:17:42,235 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-07 11:17:42,546 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 11:17:42,867 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:17:43,159 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:17:43,447 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 11:17:43,742 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-07 11:17:44,039 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:17:44,332 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:17:44,487 - INFO - validation batch 1, loss: 0.577, 32/6976 datapoints
2025-03-07 11:17:44,553 - INFO - validation batch 51, loss: 5.343, 1632/6976 datapoints
2025-03-07 11:17:44,623 - INFO - validation batch 101, loss: 1.067, 3232/6976 datapoints
2025-03-07 11:17:44,715 - INFO - validation batch 151, loss: 0.785, 4832/6976 datapoints
2025-03-07 11:17:44,783 - INFO - validation batch 201, loss: 3.353, 6432/6976 datapoints
2025-03-07 11:17:44,810 - INFO - Epoch 391/800 done.
2025-03-07 11:17:44,811 - INFO - Final validation performance:
Loss: 2.225, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:17:44,811 - INFO - Beginning epoch 392/800
2025-03-07 11:17:44,819 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:17:45,131 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:17:45,458 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:17:45,807 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:17:46,097 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:17:46,404 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:17:46,704 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-07 11:17:46,994 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-07 11:17:47,300 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-07 11:17:47,616 - INFO - training batch 451, loss: 0.190, 14432/28000 datapoints
2025-03-07 11:17:47,928 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 11:17:48,223 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:17:48,535 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:17:48,843 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:17:49,140 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-07 11:17:49,446 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:17:49,749 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:17:50,047 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:17:50,195 - INFO - validation batch 1, loss: 0.463, 32/6976 datapoints
2025-03-07 11:17:50,263 - INFO - validation batch 51, loss: 5.233, 1632/6976 datapoints
2025-03-07 11:17:50,328 - INFO - validation batch 101, loss: 1.104, 3232/6976 datapoints
2025-03-07 11:17:50,397 - INFO - validation batch 151, loss: 0.864, 4832/6976 datapoints
2025-03-07 11:17:50,464 - INFO - validation batch 201, loss: 3.445, 6432/6976 datapoints
2025-03-07 11:17:50,491 - INFO - Epoch 392/800 done.
2025-03-07 11:17:50,491 - INFO - Final validation performance:
Loss: 2.222, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:17:50,492 - INFO - Beginning epoch 393/800
2025-03-07 11:17:50,500 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:17:50,802 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:17:51,110 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:17:51,416 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:17:51,700 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:17:51,990 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-07 11:17:52,428 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:17:52,745 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 11:17:53,058 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-07 11:17:53,370 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:17:53,672 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:17:53,969 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:17:54,280 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:17:54,587 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:17:54,886 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 11:17:55,201 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:17:55,506 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:17:55,818 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:17:55,970 - INFO - validation batch 1, loss: 0.474, 32/6976 datapoints
2025-03-07 11:17:56,038 - INFO - validation batch 51, loss: 5.351, 1632/6976 datapoints
2025-03-07 11:17:56,105 - INFO - validation batch 101, loss: 1.045, 3232/6976 datapoints
2025-03-07 11:17:56,170 - INFO - validation batch 151, loss: 0.795, 4832/6976 datapoints
2025-03-07 11:17:56,236 - INFO - validation batch 201, loss: 3.358, 6432/6976 datapoints
2025-03-07 11:17:56,261 - INFO - Epoch 393/800 done.
2025-03-07 11:17:56,261 - INFO - Final validation performance:
Loss: 2.205, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:17:56,262 - INFO - Beginning epoch 394/800
2025-03-07 11:17:56,272 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:17:56,582 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:17:56,890 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 11:17:57,193 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:17:57,478 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:17:57,777 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:17:58,074 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:17:58,374 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:17:58,681 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 11:17:58,989 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:17:59,294 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:17:59,594 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:17:59,900 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:18:00,206 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:18:00,506 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:18:00,815 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:18:01,125 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:18:01,418 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:18:01,567 - INFO - validation batch 1, loss: 0.493, 32/6976 datapoints
2025-03-07 11:18:01,637 - INFO - validation batch 51, loss: 5.354, 1632/6976 datapoints
2025-03-07 11:18:01,708 - INFO - validation batch 101, loss: 1.035, 3232/6976 datapoints
2025-03-07 11:18:01,780 - INFO - validation batch 151, loss: 0.787, 4832/6976 datapoints
2025-03-07 11:18:01,847 - INFO - validation batch 201, loss: 3.378, 6432/6976 datapoints
2025-03-07 11:18:01,876 - INFO - Epoch 394/800 done.
2025-03-07 11:18:01,877 - INFO - Final validation performance:
Loss: 2.209, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:18:01,877 - INFO - Beginning epoch 395/800
2025-03-07 11:18:01,884 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:18:02,190 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:18:02,500 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:18:02,804 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:18:03,095 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:18:03,390 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:18:03,690 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:18:03,985 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:18:04,297 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 11:18:04,610 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:18:04,912 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:18:05,215 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:18:05,521 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:18:05,843 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:18:06,142 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:18:06,452 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:18:06,772 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:18:07,109 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:18:07,276 - INFO - validation batch 1, loss: 0.493, 32/6976 datapoints
2025-03-07 11:18:07,361 - INFO - validation batch 51, loss: 5.380, 1632/6976 datapoints
2025-03-07 11:18:07,539 - INFO - validation batch 101, loss: 1.038, 3232/6976 datapoints
2025-03-07 11:18:07,634 - INFO - validation batch 151, loss: 0.785, 4832/6976 datapoints
2025-03-07 11:18:07,734 - INFO - validation batch 201, loss: 3.408, 6432/6976 datapoints
2025-03-07 11:18:07,768 - INFO - Epoch 395/800 done.
2025-03-07 11:18:07,768 - INFO - Final validation performance:
Loss: 2.221, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:18:07,769 - INFO - Beginning epoch 396/800
2025-03-07 11:18:07,778 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:18:08,120 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:18:08,439 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:18:08,757 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:18:09,052 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:18:09,353 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:18:09,660 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:18:09,956 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:18:10,265 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:18:10,577 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:18:10,877 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:18:11,177 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:18:11,481 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:18:11,782 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:18:12,073 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:18:12,377 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:18:12,675 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:18:12,972 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:18:13,122 - INFO - validation batch 1, loss: 0.489, 32/6976 datapoints
2025-03-07 11:18:13,192 - INFO - validation batch 51, loss: 5.412, 1632/6976 datapoints
2025-03-07 11:18:13,259 - INFO - validation batch 101, loss: 1.041, 3232/6976 datapoints
2025-03-07 11:18:13,328 - INFO - validation batch 151, loss: 0.782, 4832/6976 datapoints
2025-03-07 11:18:13,397 - INFO - validation batch 201, loss: 3.417, 6432/6976 datapoints
2025-03-07 11:18:13,422 - INFO - Epoch 396/800 done.
2025-03-07 11:18:13,422 - INFO - Final validation performance:
Loss: 2.228, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:18:13,423 - INFO - Beginning epoch 397/800
2025-03-07 11:18:13,433 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:18:13,730 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:18:14,039 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:18:14,349 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:18:14,642 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:18:14,935 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:18:15,246 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:18:15,545 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:18:15,881 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:18:16,199 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:18:16,502 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:18:16,802 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:18:17,111 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:18:17,422 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:18:17,729 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:18:18,045 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:18:18,349 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:18:18,649 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:18:18,805 - INFO - validation batch 1, loss: 0.503, 32/6976 datapoints
2025-03-07 11:18:18,873 - INFO - validation batch 51, loss: 5.448, 1632/6976 datapoints
2025-03-07 11:18:18,941 - INFO - validation batch 101, loss: 1.039, 3232/6976 datapoints
2025-03-07 11:18:19,010 - INFO - validation batch 151, loss: 0.759, 4832/6976 datapoints
2025-03-07 11:18:19,076 - INFO - validation batch 201, loss: 3.413, 6432/6976 datapoints
2025-03-07 11:18:19,104 - INFO - Epoch 397/800 done.
2025-03-07 11:18:19,104 - INFO - Final validation performance:
Loss: 2.232, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:18:19,105 - INFO - Beginning epoch 398/800
2025-03-07 11:18:19,113 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:18:19,428 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:18:19,738 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:18:20,051 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:18:20,343 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:18:20,639 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:18:20,943 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:18:21,243 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:18:21,550 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:18:21,860 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:18:22,157 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:18:22,457 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:18:22,777 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:18:23,083 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:18:23,392 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:18:23,705 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:18:24,012 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:18:24,311 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:18:24,465 - INFO - validation batch 1, loss: 0.470, 32/6976 datapoints
2025-03-07 11:18:24,534 - INFO - validation batch 51, loss: 5.485, 1632/6976 datapoints
2025-03-07 11:18:24,605 - INFO - validation batch 101, loss: 1.056, 3232/6976 datapoints
2025-03-07 11:18:24,677 - INFO - validation batch 151, loss: 0.759, 4832/6976 datapoints
2025-03-07 11:18:24,752 - INFO - validation batch 201, loss: 3.440, 6432/6976 datapoints
2025-03-07 11:18:24,778 - INFO - Epoch 398/800 done.
2025-03-07 11:18:24,778 - INFO - Final validation performance:
Loss: 2.242, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:18:24,778 - INFO - Beginning epoch 399/800
2025-03-07 11:18:24,786 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:18:25,098 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:18:25,413 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:18:25,728 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:18:26,101 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:18:26,397 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:18:26,703 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:18:27,002 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:18:27,310 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:18:27,630 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:18:27,932 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:18:28,237 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:18:28,546 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:18:28,857 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:18:29,170 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:18:29,487 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:18:29,799 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:18:30,135 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:18:30,290 - INFO - validation batch 1, loss: 0.436, 32/6976 datapoints
2025-03-07 11:18:30,373 - INFO - validation batch 51, loss: 5.519, 1632/6976 datapoints
2025-03-07 11:18:30,440 - INFO - validation batch 101, loss: 1.074, 3232/6976 datapoints
2025-03-07 11:18:30,507 - INFO - validation batch 151, loss: 0.789, 4832/6976 datapoints
2025-03-07 11:18:30,573 - INFO - validation batch 201, loss: 3.452, 6432/6976 datapoints
2025-03-07 11:18:30,597 - INFO - Epoch 399/800 done.
2025-03-07 11:18:30,598 - INFO - Final validation performance:
Loss: 2.254, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:18:30,598 - INFO - Beginning epoch 400/800
2025-03-07 11:18:30,607 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:18:30,930 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:18:31,238 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:18:31,600 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:18:31,958 - INFO - training batch 201, loss: 0.051, 6432/28000 datapoints
2025-03-07 11:18:32,273 - INFO - training batch 251, loss: 0.142, 8032/28000 datapoints
2025-03-07 11:18:32,583 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 11:18:32,885 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:18:33,196 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:18:33,513 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-07 11:18:33,813 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 11:18:34,111 - INFO - training batch 551, loss: 0.062, 17632/28000 datapoints
2025-03-07 11:18:34,419 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:18:34,739 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:18:35,042 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:18:35,342 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-07 11:18:35,654 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:18:35,984 - INFO - training batch 851, loss: 0.271, 27232/28000 datapoints
2025-03-07 11:18:36,185 - INFO - validation batch 1, loss: 1.013, 32/6976 datapoints
2025-03-07 11:18:36,255 - INFO - validation batch 51, loss: 5.778, 1632/6976 datapoints
2025-03-07 11:18:36,324 - INFO - validation batch 101, loss: 1.102, 3232/6976 datapoints
2025-03-07 11:18:36,397 - INFO - validation batch 151, loss: 1.383, 4832/6976 datapoints
2025-03-07 11:18:36,465 - INFO - validation batch 201, loss: 3.075, 6432/6976 datapoints
2025-03-07 11:18:36,491 - INFO - Epoch 400/800 done.
2025-03-07 11:18:36,491 - INFO - Final validation performance:
Loss: 2.470, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:18:36,492 - INFO - Beginning epoch 401/800
2025-03-07 11:18:36,500 - INFO - training batch 1, loss: 0.029, 32/28000 datapoints
2025-03-07 11:18:36,816 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 11:18:37,126 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:18:37,443 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:18:37,741 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:18:38,044 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:18:38,345 - INFO - training batch 301, loss: 0.017, 9632/28000 datapoints
2025-03-07 11:18:38,662 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:18:38,971 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:18:39,297 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:18:39,601 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:18:39,909 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:18:40,212 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:18:40,542 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 11:18:40,846 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:18:41,162 - INFO - training batch 751, loss: 0.070, 24032/28000 datapoints
2025-03-07 11:18:41,475 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:18:41,776 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:18:41,927 - INFO - validation batch 1, loss: 0.422, 32/6976 datapoints
2025-03-07 11:18:41,994 - INFO - validation batch 51, loss: 5.598, 1632/6976 datapoints
2025-03-07 11:18:42,060 - INFO - validation batch 101, loss: 1.247, 3232/6976 datapoints
2025-03-07 11:18:42,127 - INFO - validation batch 151, loss: 0.882, 4832/6976 datapoints
2025-03-07 11:18:42,196 - INFO - validation batch 201, loss: 3.472, 6432/6976 datapoints
2025-03-07 11:18:42,223 - INFO - Epoch 401/800 done.
2025-03-07 11:18:42,223 - INFO - Final validation performance:
Loss: 2.324, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:18:42,224 - INFO - Beginning epoch 402/800
2025-03-07 11:18:42,231 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 11:18:42,549 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:18:42,854 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:18:43,197 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:18:43,494 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-07 11:18:43,791 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 11:18:44,098 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 11:18:44,404 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:18:44,711 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:18:45,039 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:18:45,339 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:18:45,645 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:18:45,954 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:18:46,292 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:18:46,601 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:18:46,911 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-07 11:18:47,226 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:18:47,527 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:18:47,687 - INFO - validation batch 1, loss: 0.353, 32/6976 datapoints
2025-03-07 11:18:47,755 - INFO - validation batch 51, loss: 5.205, 1632/6976 datapoints
2025-03-07 11:18:47,825 - INFO - validation batch 101, loss: 0.945, 3232/6976 datapoints
2025-03-07 11:18:47,894 - INFO - validation batch 151, loss: 0.940, 4832/6976 datapoints
2025-03-07 11:18:47,964 - INFO - validation batch 201, loss: 3.416, 6432/6976 datapoints
2025-03-07 11:18:47,988 - INFO - Epoch 402/800 done.
2025-03-07 11:18:47,989 - INFO - Final validation performance:
Loss: 2.171, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:18:47,989 - INFO - Beginning epoch 403/800
2025-03-07 11:18:47,997 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-07 11:18:48,307 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 11:18:48,619 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 11:18:48,930 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:18:49,218 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:18:49,515 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-07 11:18:49,813 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-07 11:18:50,115 - INFO - training batch 351, loss: 0.024, 11232/28000 datapoints
2025-03-07 11:18:50,419 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:18:50,725 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-07 11:18:51,021 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 11:18:51,323 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:18:51,631 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-07 11:18:51,933 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:18:52,232 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:18:52,542 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 11:18:52,853 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:18:53,157 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-07 11:18:53,311 - INFO - validation batch 1, loss: 0.292, 32/6976 datapoints
2025-03-07 11:18:53,382 - INFO - validation batch 51, loss: 5.079, 1632/6976 datapoints
2025-03-07 11:18:53,458 - INFO - validation batch 101, loss: 1.055, 3232/6976 datapoints
2025-03-07 11:18:53,523 - INFO - validation batch 151, loss: 0.784, 4832/6976 datapoints
2025-03-07 11:18:53,588 - INFO - validation batch 201, loss: 3.705, 6432/6976 datapoints
2025-03-07 11:18:53,614 - INFO - Epoch 403/800 done.
2025-03-07 11:18:53,614 - INFO - Final validation performance:
Loss: 2.183, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:18:53,614 - INFO - Beginning epoch 404/800
2025-03-07 11:18:53,622 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:18:53,949 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-07 11:18:54,247 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:18:54,559 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:18:54,846 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:18:55,141 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:18:55,452 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 11:18:55,761 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-07 11:18:56,067 - INFO - training batch 401, loss: 0.017, 12832/28000 datapoints
2025-03-07 11:18:56,402 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 11:18:56,702 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:18:57,008 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:18:57,318 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:18:57,632 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:18:57,933 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:18:58,237 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:18:58,542 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:18:58,830 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:18:58,980 - INFO - validation batch 1, loss: 0.312, 32/6976 datapoints
2025-03-07 11:18:59,047 - INFO - validation batch 51, loss: 5.246, 1632/6976 datapoints
2025-03-07 11:18:59,116 - INFO - validation batch 101, loss: 1.075, 3232/6976 datapoints
2025-03-07 11:18:59,183 - INFO - validation batch 151, loss: 0.622, 4832/6976 datapoints
2025-03-07 11:18:59,254 - INFO - validation batch 201, loss: 3.522, 6432/6976 datapoints
2025-03-07 11:18:59,278 - INFO - Epoch 404/800 done.
2025-03-07 11:18:59,279 - INFO - Final validation performance:
Loss: 2.155, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:18:59,279 - INFO - Beginning epoch 405/800
2025-03-07 11:18:59,286 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:18:59,615 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:18:59,918 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:19:00,225 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:19:00,520 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:19:00,816 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:19:01,119 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 11:19:01,433 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-07 11:19:01,747 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:19:02,061 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:19:02,362 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:19:02,670 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:19:02,983 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:19:03,306 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:19:03,613 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:19:03,923 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:19:04,236 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:19:04,537 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:19:04,684 - INFO - validation batch 1, loss: 0.402, 32/6976 datapoints
2025-03-07 11:19:04,751 - INFO - validation batch 51, loss: 5.310, 1632/6976 datapoints
2025-03-07 11:19:04,817 - INFO - validation batch 101, loss: 1.062, 3232/6976 datapoints
2025-03-07 11:19:04,886 - INFO - validation batch 151, loss: 0.709, 4832/6976 datapoints
2025-03-07 11:19:04,954 - INFO - validation batch 201, loss: 3.384, 6432/6976 datapoints
2025-03-07 11:19:04,979 - INFO - Epoch 405/800 done.
2025-03-07 11:19:04,979 - INFO - Final validation performance:
Loss: 2.173, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:19:04,980 - INFO - Beginning epoch 406/800
2025-03-07 11:19:04,987 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:19:05,314 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:19:05,616 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:19:05,919 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:19:06,207 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:19:06,519 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:19:06,818 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 11:19:07,120 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:19:07,427 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:19:07,740 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:19:08,041 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:19:08,347 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:19:08,663 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:19:08,981 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:19:09,288 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:19:09,605 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:19:09,911 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:19:10,209 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:19:10,358 - INFO - validation batch 1, loss: 0.392, 32/6976 datapoints
2025-03-07 11:19:10,428 - INFO - validation batch 51, loss: 5.395, 1632/6976 datapoints
2025-03-07 11:19:10,496 - INFO - validation batch 101, loss: 1.067, 3232/6976 datapoints
2025-03-07 11:19:10,561 - INFO - validation batch 151, loss: 0.730, 4832/6976 datapoints
2025-03-07 11:19:10,627 - INFO - validation batch 201, loss: 3.453, 6432/6976 datapoints
2025-03-07 11:19:10,652 - INFO - Epoch 406/800 done.
2025-03-07 11:19:10,652 - INFO - Final validation performance:
Loss: 2.207, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:19:10,653 - INFO - Beginning epoch 407/800
2025-03-07 11:19:10,663 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:19:10,985 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:19:11,300 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:19:11,615 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:19:11,904 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:19:12,200 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:19:12,510 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 11:19:12,815 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:19:13,130 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:19:13,447 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:19:13,742 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:19:14,041 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:19:14,347 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:19:14,669 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:19:14,969 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:19:15,277 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:19:15,582 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:19:15,875 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:19:16,022 - INFO - validation batch 1, loss: 0.386, 32/6976 datapoints
2025-03-07 11:19:16,096 - INFO - validation batch 51, loss: 5.443, 1632/6976 datapoints
2025-03-07 11:19:16,165 - INFO - validation batch 101, loss: 1.087, 3232/6976 datapoints
2025-03-07 11:19:16,240 - INFO - validation batch 151, loss: 0.777, 4832/6976 datapoints
2025-03-07 11:19:16,308 - INFO - validation batch 201, loss: 3.513, 6432/6976 datapoints
2025-03-07 11:19:16,335 - INFO - Epoch 407/800 done.
2025-03-07 11:19:16,335 - INFO - Final validation performance:
Loss: 2.241, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:19:16,336 - INFO - Beginning epoch 408/800
2025-03-07 11:19:16,347 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:19:16,699 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:19:17,008 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:19:17,366 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:19:17,658 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:19:17,953 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:19:18,261 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:19:18,571 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:19:18,884 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:19:19,199 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:19:19,504 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:19:19,807 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:19:20,115 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:19:20,437 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:19:20,745 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:19:21,055 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:19:21,379 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:19:21,683 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:19:21,835 - INFO - validation batch 1, loss: 0.365, 32/6976 datapoints
2025-03-07 11:19:21,902 - INFO - validation batch 51, loss: 5.523, 1632/6976 datapoints
2025-03-07 11:19:21,970 - INFO - validation batch 101, loss: 1.099, 3232/6976 datapoints
2025-03-07 11:19:22,036 - INFO - validation batch 151, loss: 0.830, 4832/6976 datapoints
2025-03-07 11:19:22,105 - INFO - validation batch 201, loss: 3.555, 6432/6976 datapoints
2025-03-07 11:19:22,130 - INFO - Epoch 408/800 done.
2025-03-07 11:19:22,130 - INFO - Final validation performance:
Loss: 2.274, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:19:22,131 - INFO - Beginning epoch 409/800
2025-03-07 11:19:22,141 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:19:22,461 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:19:22,770 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:19:23,089 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:19:23,388 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:19:23,683 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:19:23,990 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:19:24,291 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:19:24,596 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:19:24,908 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:19:25,206 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:19:25,510 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:19:25,817 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:19:26,139 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:19:26,450 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:19:26,781 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:19:27,088 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:19:27,395 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:19:27,547 - INFO - validation batch 1, loss: 0.358, 32/6976 datapoints
2025-03-07 11:19:27,623 - INFO - validation batch 51, loss: 5.594, 1632/6976 datapoints
2025-03-07 11:19:27,691 - INFO - validation batch 101, loss: 1.114, 3232/6976 datapoints
2025-03-07 11:19:27,757 - INFO - validation batch 151, loss: 0.871, 4832/6976 datapoints
2025-03-07 11:19:27,826 - INFO - validation batch 201, loss: 3.586, 6432/6976 datapoints
2025-03-07 11:19:27,853 - INFO - Epoch 409/800 done.
2025-03-07 11:19:27,853 - INFO - Final validation performance:
Loss: 2.305, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:19:27,854 - INFO - Beginning epoch 410/800
2025-03-07 11:19:27,861 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:19:28,180 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:19:28,491 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:19:28,808 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:19:29,099 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:19:29,413 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:19:29,725 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:19:30,033 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:19:30,344 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:19:30,690 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:19:30,995 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:19:31,301 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:19:31,634 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:19:31,952 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:19:32,265 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:19:32,582 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:19:32,903 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:19:33,212 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:19:33,374 - INFO - validation batch 1, loss: 0.361, 32/6976 datapoints
2025-03-07 11:19:33,443 - INFO - validation batch 51, loss: 5.668, 1632/6976 datapoints
2025-03-07 11:19:33,512 - INFO - validation batch 101, loss: 1.134, 3232/6976 datapoints
2025-03-07 11:19:33,578 - INFO - validation batch 151, loss: 0.873, 4832/6976 datapoints
2025-03-07 11:19:33,649 - INFO - validation batch 201, loss: 3.600, 6432/6976 datapoints
2025-03-07 11:19:33,673 - INFO - Epoch 410/800 done.
2025-03-07 11:19:33,674 - INFO - Final validation performance:
Loss: 2.327, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:19:33,674 - INFO - Beginning epoch 411/800
2025-03-07 11:19:33,684 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:19:34,000 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:19:34,309 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:19:34,626 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:19:34,912 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:19:35,206 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:19:35,516 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:19:35,831 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:19:36,170 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:19:36,543 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:19:36,905 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:19:37,221 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:19:37,537 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:19:37,866 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:19:38,178 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:19:38,497 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:19:38,817 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:19:39,129 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:19:39,285 - INFO - validation batch 1, loss: 0.361, 32/6976 datapoints
2025-03-07 11:19:39,356 - INFO - validation batch 51, loss: 5.747, 1632/6976 datapoints
2025-03-07 11:19:39,424 - INFO - validation batch 101, loss: 1.163, 3232/6976 datapoints
2025-03-07 11:19:39,490 - INFO - validation batch 151, loss: 0.861, 4832/6976 datapoints
2025-03-07 11:19:39,556 - INFO - validation batch 201, loss: 3.608, 6432/6976 datapoints
2025-03-07 11:19:39,581 - INFO - Epoch 411/800 done.
2025-03-07 11:19:39,582 - INFO - Final validation performance:
Loss: 2.348, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:19:39,582 - INFO - Beginning epoch 412/800
2025-03-07 11:19:39,591 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:19:39,918 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:19:40,231 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:19:40,569 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:19:40,864 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:19:41,162 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:19:41,517 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:19:41,832 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:19:42,136 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:19:42,458 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:19:42,767 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:19:43,080 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:19:43,396 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:19:43,722 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:19:44,031 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:19:44,345 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:19:44,662 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:19:44,973 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:19:45,130 - INFO - validation batch 1, loss: 0.371, 32/6976 datapoints
2025-03-07 11:19:45,199 - INFO - validation batch 51, loss: 5.782, 1632/6976 datapoints
2025-03-07 11:19:45,267 - INFO - validation batch 101, loss: 1.195, 3232/6976 datapoints
2025-03-07 11:19:45,335 - INFO - validation batch 151, loss: 0.886, 4832/6976 datapoints
2025-03-07 11:19:45,406 - INFO - validation batch 201, loss: 3.634, 6432/6976 datapoints
2025-03-07 11:19:45,431 - INFO - Epoch 412/800 done.
2025-03-07 11:19:45,431 - INFO - Final validation performance:
Loss: 2.374, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:19:45,432 - INFO - Beginning epoch 413/800
2025-03-07 11:19:45,441 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:19:45,763 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:19:46,068 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:19:46,396 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:19:46,696 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:19:47,010 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:19:47,321 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:19:47,638 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:19:47,940 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:19:48,256 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:19:48,564 - INFO - training batch 501, loss: 0.053, 16032/28000 datapoints
2025-03-07 11:19:48,873 - INFO - training batch 551, loss: 0.051, 17632/28000 datapoints
2025-03-07 11:19:49,187 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:19:49,521 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:19:49,831 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:19:50,148 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:19:50,469 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:19:50,781 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-07 11:19:50,941 - INFO - validation batch 1, loss: 0.291, 32/6976 datapoints
2025-03-07 11:19:51,007 - INFO - validation batch 51, loss: 5.023, 1632/6976 datapoints
2025-03-07 11:19:51,074 - INFO - validation batch 101, loss: 1.257, 3232/6976 datapoints
2025-03-07 11:19:51,141 - INFO - validation batch 151, loss: 0.977, 4832/6976 datapoints
2025-03-07 11:19:51,216 - INFO - validation batch 201, loss: 4.052, 6432/6976 datapoints
2025-03-07 11:19:51,243 - INFO - Epoch 413/800 done.
2025-03-07 11:19:51,243 - INFO - Final validation performance:
Loss: 2.320, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:19:51,244 - INFO - Beginning epoch 414/800
2025-03-07 11:19:51,253 - INFO - training batch 1, loss: 0.091, 32/28000 datapoints
2025-03-07 11:19:51,593 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:19:51,911 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:19:52,227 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:19:52,563 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:19:52,880 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:19:53,197 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-07 11:19:53,527 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:19:53,843 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:19:54,166 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:19:54,474 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:19:54,791 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:19:55,102 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:19:55,441 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:19:55,751 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-07 11:19:56,068 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 11:19:56,384 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:19:56,686 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:19:56,865 - INFO - validation batch 1, loss: 0.421, 32/6976 datapoints
2025-03-07 11:19:56,939 - INFO - validation batch 51, loss: 5.611, 1632/6976 datapoints
2025-03-07 11:19:57,007 - INFO - validation batch 101, loss: 1.347, 3232/6976 datapoints
2025-03-07 11:19:57,076 - INFO - validation batch 151, loss: 0.673, 4832/6976 datapoints
2025-03-07 11:19:57,145 - INFO - validation batch 201, loss: 3.647, 6432/6976 datapoints
2025-03-07 11:19:57,173 - INFO - Epoch 414/800 done.
2025-03-07 11:19:57,174 - INFO - Final validation performance:
Loss: 2.340, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 11:19:57,174 - INFO - Beginning epoch 415/800
2025-03-07 11:19:57,182 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:19:57,507 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:19:57,819 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-07 11:19:58,133 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:19:58,441 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:19:58,817 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:19:59,143 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:19:59,463 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:19:59,775 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:20:00,093 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:20:00,402 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:20:00,721 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:20:01,030 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-07 11:20:01,360 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 11:20:01,680 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:20:01,994 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:20:02,313 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:20:02,627 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 11:20:02,777 - INFO - validation batch 1, loss: 0.361, 32/6976 datapoints
2025-03-07 11:20:02,847 - INFO - validation batch 51, loss: 4.937, 1632/6976 datapoints
2025-03-07 11:20:02,912 - INFO - validation batch 101, loss: 1.467, 3232/6976 datapoints
2025-03-07 11:20:02,979 - INFO - validation batch 151, loss: 0.780, 4832/6976 datapoints
2025-03-07 11:20:03,045 - INFO - validation batch 201, loss: 3.996, 6432/6976 datapoints
2025-03-07 11:20:03,072 - INFO - Epoch 415/800 done.
2025-03-07 11:20:03,072 - INFO - Final validation performance:
Loss: 2.308, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 11:20:03,073 - INFO - Beginning epoch 416/800
2025-03-07 11:20:03,085 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:20:03,430 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 11:20:03,745 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:20:04,065 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-07 11:20:04,366 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-07 11:20:04,670 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:20:04,989 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:20:05,296 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:20:05,603 - INFO - training batch 401, loss: 0.022, 12832/28000 datapoints
2025-03-07 11:20:05,913 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-07 11:20:06,217 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:20:06,524 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:20:06,822 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-07 11:20:07,157 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 11:20:07,489 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 11:20:07,800 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:20:08,111 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:20:08,421 - INFO - training batch 851, loss: 0.084, 27232/28000 datapoints
2025-03-07 11:20:08,582 - INFO - validation batch 1, loss: 0.286, 32/6976 datapoints
2025-03-07 11:20:08,650 - INFO - validation batch 51, loss: 5.919, 1632/6976 datapoints
2025-03-07 11:20:08,718 - INFO - validation batch 101, loss: 1.124, 3232/6976 datapoints
2025-03-07 11:20:08,785 - INFO - validation batch 151, loss: 0.545, 4832/6976 datapoints
2025-03-07 11:20:08,853 - INFO - validation batch 201, loss: 3.596, 6432/6976 datapoints
2025-03-07 11:20:08,876 - INFO - Epoch 416/800 done.
2025-03-07 11:20:08,876 - INFO - Final validation performance:
Loss: 2.294, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:20:08,877 - INFO - Beginning epoch 417/800
2025-03-07 11:20:08,885 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:20:09,215 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:20:09,523 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:20:09,840 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:20:10,134 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:20:10,444 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:20:10,764 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:20:11,121 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:20:11,444 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:20:11,768 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:20:12,079 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-07 11:20:12,401 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:20:12,706 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:20:13,034 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:20:13,366 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:20:13,684 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:20:14,005 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:20:14,324 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:20:14,487 - INFO - validation batch 1, loss: 0.270, 32/6976 datapoints
2025-03-07 11:20:14,557 - INFO - validation batch 51, loss: 5.745, 1632/6976 datapoints
2025-03-07 11:20:14,624 - INFO - validation batch 101, loss: 1.111, 3232/6976 datapoints
2025-03-07 11:20:14,689 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-07 11:20:14,756 - INFO - validation batch 201, loss: 4.088, 6432/6976 datapoints
2025-03-07 11:20:14,781 - INFO - Epoch 417/800 done.
2025-03-07 11:20:14,781 - INFO - Final validation performance:
Loss: 2.360, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:20:14,781 - INFO - Beginning epoch 418/800
2025-03-07 11:20:14,791 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:20:15,115 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 11:20:15,426 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:20:15,741 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:20:16,032 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:20:16,339 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:20:16,694 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 11:20:17,085 - INFO - training batch 351, loss: 0.102, 11232/28000 datapoints
2025-03-07 11:20:17,506 - INFO - training batch 401, loss: 0.025, 12832/28000 datapoints
2025-03-07 11:20:17,975 - INFO - training batch 451, loss: 0.013, 14432/28000 datapoints
2025-03-07 11:20:18,480 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:20:18,918 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:20:19,366 - INFO - training batch 601, loss: 0.014, 19232/28000 datapoints
2025-03-07 11:20:19,837 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:20:20,259 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:20:20,675 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:20:21,076 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:20:21,482 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:20:21,692 - INFO - validation batch 1, loss: 0.568, 32/6976 datapoints
2025-03-07 11:20:21,785 - INFO - validation batch 51, loss: 5.520, 1632/6976 datapoints
2025-03-07 11:20:21,879 - INFO - validation batch 101, loss: 1.151, 3232/6976 datapoints
2025-03-07 11:20:21,972 - INFO - validation batch 151, loss: 0.683, 4832/6976 datapoints
2025-03-07 11:20:22,062 - INFO - validation batch 201, loss: 3.908, 6432/6976 datapoints
2025-03-07 11:20:22,094 - INFO - Epoch 418/800 done.
2025-03-07 11:20:22,094 - INFO - Final validation performance:
Loss: 2.366, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:20:22,095 - INFO - Beginning epoch 419/800
2025-03-07 11:20:22,103 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:20:22,513 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:20:22,892 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:20:23,298 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:20:23,666 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:20:24,008 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:20:24,390 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 11:20:24,824 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:20:25,184 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:20:25,537 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-07 11:20:25,893 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:20:26,263 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:20:26,624 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:20:27,036 - INFO - training batch 651, loss: 0.118, 20832/28000 datapoints
2025-03-07 11:20:27,468 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-07 11:20:27,843 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:20:28,234 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:20:28,603 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-07 11:20:28,788 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-07 11:20:28,882 - INFO - validation batch 51, loss: 5.711, 1632/6976 datapoints
2025-03-07 11:20:28,975 - INFO - validation batch 101, loss: 1.421, 3232/6976 datapoints
2025-03-07 11:20:29,067 - INFO - validation batch 151, loss: 0.891, 4832/6976 datapoints
2025-03-07 11:20:29,169 - INFO - validation batch 201, loss: 3.982, 6432/6976 datapoints
2025-03-07 11:20:29,196 - INFO - Epoch 419/800 done.
2025-03-07 11:20:29,197 - INFO - Final validation performance:
Loss: 2.426, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:20:29,198 - INFO - Beginning epoch 420/800
2025-03-07 11:20:29,215 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:20:29,660 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:20:30,038 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:20:30,466 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:20:30,828 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:20:31,231 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:20:31,633 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:20:32,031 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:20:32,410 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-07 11:20:32,782 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-07 11:20:33,137 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:20:33,524 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 11:20:33,893 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:20:34,260 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:20:34,620 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:20:34,972 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:20:35,325 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:20:35,723 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:20:35,906 - INFO - validation batch 1, loss: 0.246, 32/6976 datapoints
2025-03-07 11:20:35,979 - INFO - validation batch 51, loss: 5.396, 1632/6976 datapoints
2025-03-07 11:20:36,055 - INFO - validation batch 101, loss: 1.235, 3232/6976 datapoints
2025-03-07 11:20:36,131 - INFO - validation batch 151, loss: 0.474, 4832/6976 datapoints
2025-03-07 11:20:36,223 - INFO - validation batch 201, loss: 3.748, 6432/6976 datapoints
2025-03-07 11:20:36,259 - INFO - Epoch 420/800 done.
2025-03-07 11:20:36,260 - INFO - Final validation performance:
Loss: 2.220, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:20:36,260 - INFO - Beginning epoch 421/800
2025-03-07 11:20:36,268 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:20:36,649 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:20:37,025 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:20:37,687 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:20:38,054 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:20:38,474 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:20:38,861 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 11:20:39,216 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:20:39,663 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:20:40,022 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:20:40,374 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:20:40,738 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:20:41,161 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:20:41,519 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:20:41,871 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:20:42,207 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:20:42,542 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:20:42,878 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:20:43,041 - INFO - validation batch 1, loss: 0.302, 32/6976 datapoints
2025-03-07 11:20:43,116 - INFO - validation batch 51, loss: 5.620, 1632/6976 datapoints
2025-03-07 11:20:43,191 - INFO - validation batch 101, loss: 1.174, 3232/6976 datapoints
2025-03-07 11:20:43,273 - INFO - validation batch 151, loss: 0.637, 4832/6976 datapoints
2025-03-07 11:20:43,362 - INFO - validation batch 201, loss: 3.866, 6432/6976 datapoints
2025-03-07 11:20:43,387 - INFO - Epoch 421/800 done.
2025-03-07 11:20:43,388 - INFO - Final validation performance:
Loss: 2.320, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:20:43,388 - INFO - Beginning epoch 422/800
2025-03-07 11:20:43,400 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:20:43,769 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:20:44,095 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:20:44,444 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:20:44,765 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:20:45,089 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:20:45,493 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:20:45,885 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:20:46,217 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:20:46,561 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:20:46,892 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:20:47,224 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:20:47,582 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:20:47,932 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:20:48,254 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:20:48,582 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:20:48,912 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:20:49,229 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:20:49,390 - INFO - validation batch 1, loss: 0.366, 32/6976 datapoints
2025-03-07 11:20:49,466 - INFO - validation batch 51, loss: 5.502, 1632/6976 datapoints
2025-03-07 11:20:49,535 - INFO - validation batch 101, loss: 1.144, 3232/6976 datapoints
2025-03-07 11:20:49,613 - INFO - validation batch 151, loss: 0.580, 4832/6976 datapoints
2025-03-07 11:20:49,685 - INFO - validation batch 201, loss: 3.723, 6432/6976 datapoints
2025-03-07 11:20:49,717 - INFO - Epoch 422/800 done.
2025-03-07 11:20:49,717 - INFO - Final validation performance:
Loss: 2.263, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:20:49,718 - INFO - Beginning epoch 423/800
2025-03-07 11:20:49,725 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:20:50,067 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:20:50,444 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:20:50,818 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:20:51,149 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:20:51,478 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:20:51,818 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:20:52,137 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:20:52,467 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:20:52,810 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:20:53,157 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:20:53,489 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:20:53,831 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:20:54,178 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:20:54,508 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:20:54,856 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:20:55,186 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:20:55,515 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:20:55,671 - INFO - validation batch 1, loss: 0.334, 32/6976 datapoints
2025-03-07 11:20:55,746 - INFO - validation batch 51, loss: 5.544, 1632/6976 datapoints
2025-03-07 11:20:55,825 - INFO - validation batch 101, loss: 1.140, 3232/6976 datapoints
2025-03-07 11:20:55,912 - INFO - validation batch 151, loss: 0.645, 4832/6976 datapoints
2025-03-07 11:20:55,985 - INFO - validation batch 201, loss: 3.705, 6432/6976 datapoints
2025-03-07 11:20:56,023 - INFO - Epoch 423/800 done.
2025-03-07 11:20:56,024 - INFO - Final validation performance:
Loss: 2.274, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:20:56,024 - INFO - Beginning epoch 424/800
2025-03-07 11:20:56,031 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:20:56,408 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:20:56,741 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:20:57,119 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:20:57,437 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:20:57,791 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:20:58,136 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:20:58,472 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:20:58,813 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:20:59,169 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:20:59,498 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:20:59,825 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:21:00,147 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:21:00,498 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:21:00,829 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:21:01,157 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:21:01,490 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:21:01,820 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:21:01,978 - INFO - validation batch 1, loss: 0.306, 32/6976 datapoints
2025-03-07 11:21:02,048 - INFO - validation batch 51, loss: 5.581, 1632/6976 datapoints
2025-03-07 11:21:02,120 - INFO - validation batch 101, loss: 1.143, 3232/6976 datapoints
2025-03-07 11:21:02,192 - INFO - validation batch 151, loss: 0.704, 4832/6976 datapoints
2025-03-07 11:21:02,264 - INFO - validation batch 201, loss: 3.708, 6432/6976 datapoints
2025-03-07 11:21:02,287 - INFO - Epoch 424/800 done.
2025-03-07 11:21:02,287 - INFO - Final validation performance:
Loss: 2.288, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:21:02,288 - INFO - Beginning epoch 425/800
2025-03-07 11:21:02,297 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:21:02,656 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:21:02,982 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:21:03,313 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:21:03,624 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:21:03,957 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:21:04,310 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:21:04,644 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:21:04,975 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:21:05,310 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:21:05,635 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:21:05,961 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:21:06,284 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:21:06,623 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:21:06,947 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:21:07,273 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:21:07,623 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:21:07,974 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:21:08,131 - INFO - validation batch 1, loss: 0.286, 32/6976 datapoints
2025-03-07 11:21:08,204 - INFO - validation batch 51, loss: 5.631, 1632/6976 datapoints
2025-03-07 11:21:08,276 - INFO - validation batch 101, loss: 1.147, 3232/6976 datapoints
2025-03-07 11:21:08,346 - INFO - validation batch 151, loss: 0.743, 4832/6976 datapoints
2025-03-07 11:21:08,425 - INFO - validation batch 201, loss: 3.704, 6432/6976 datapoints
2025-03-07 11:21:08,457 - INFO - Epoch 425/800 done.
2025-03-07 11:21:08,458 - INFO - Final validation performance:
Loss: 2.302, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:21:08,458 - INFO - Beginning epoch 426/800
2025-03-07 11:21:08,465 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:21:08,804 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:21:09,128 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:21:09,466 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:21:09,779 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:21:10,104 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:21:10,446 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:21:10,787 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:21:11,128 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:21:11,480 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:21:11,832 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:21:12,173 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:21:12,505 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:21:12,857 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:21:13,222 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:21:13,581 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:21:13,953 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:21:14,305 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:21:14,479 - INFO - validation batch 1, loss: 0.276, 32/6976 datapoints
2025-03-07 11:21:14,556 - INFO - validation batch 51, loss: 5.678, 1632/6976 datapoints
2025-03-07 11:21:14,634 - INFO - validation batch 101, loss: 1.153, 3232/6976 datapoints
2025-03-07 11:21:14,711 - INFO - validation batch 151, loss: 0.766, 4832/6976 datapoints
2025-03-07 11:21:14,802 - INFO - validation batch 201, loss: 3.700, 6432/6976 datapoints
2025-03-07 11:21:14,841 - INFO - Epoch 426/800 done.
2025-03-07 11:21:14,841 - INFO - Final validation performance:
Loss: 2.315, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:21:14,842 - INFO - Beginning epoch 427/800
2025-03-07 11:21:14,870 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:21:15,308 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:21:15,637 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:21:15,985 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:21:16,325 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:21:16,717 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:21:17,083 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:21:17,416 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:21:17,774 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:21:18,147 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:21:18,494 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:21:18,831 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:21:19,182 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:21:19,527 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:21:19,874 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:21:20,201 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:21:20,533 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:21:20,859 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:21:21,019 - INFO - validation batch 1, loss: 0.275, 32/6976 datapoints
2025-03-07 11:21:21,091 - INFO - validation batch 51, loss: 5.759, 1632/6976 datapoints
2025-03-07 11:21:21,166 - INFO - validation batch 101, loss: 1.159, 3232/6976 datapoints
2025-03-07 11:21:21,234 - INFO - validation batch 151, loss: 0.799, 4832/6976 datapoints
2025-03-07 11:21:21,307 - INFO - validation batch 201, loss: 3.703, 6432/6976 datapoints
2025-03-07 11:21:21,333 - INFO - Epoch 427/800 done.
2025-03-07 11:21:21,333 - INFO - Final validation performance:
Loss: 2.339, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:21:21,334 - INFO - Beginning epoch 428/800
2025-03-07 11:21:21,345 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:21:21,704 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:21:22,023 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:21:22,409 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:21:22,723 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:21:23,043 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:21:23,384 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:21:23,706 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:21:24,038 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:21:24,376 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:21:24,690 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:21:25,022 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:21:25,351 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:21:25,689 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:21:26,033 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:21:26,391 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:21:26,724 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:21:27,049 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:21:27,214 - INFO - validation batch 1, loss: 0.283, 32/6976 datapoints
2025-03-07 11:21:27,289 - INFO - validation batch 51, loss: 5.810, 1632/6976 datapoints
2025-03-07 11:21:27,365 - INFO - validation batch 101, loss: 1.190, 3232/6976 datapoints
2025-03-07 11:21:27,438 - INFO - validation batch 151, loss: 0.841, 4832/6976 datapoints
2025-03-07 11:21:27,514 - INFO - validation batch 201, loss: 3.708, 6432/6976 datapoints
2025-03-07 11:21:27,539 - INFO - Epoch 428/800 done.
2025-03-07 11:21:27,539 - INFO - Final validation performance:
Loss: 2.366, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:21:27,540 - INFO - Beginning epoch 429/800
2025-03-07 11:21:27,548 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:21:27,923 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:21:28,255 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:21:28,602 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:21:28,924 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:21:29,260 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:21:29,598 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:21:29,926 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:21:30,268 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:21:30,725 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:21:31,054 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:21:31,438 - INFO - training batch 551, loss: 0.042, 17632/28000 datapoints
2025-03-07 11:21:31,802 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-07 11:21:32,136 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:21:32,495 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-07 11:21:32,844 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 11:21:33,193 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 11:21:33,514 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:21:33,677 - INFO - validation batch 1, loss: 0.542, 32/6976 datapoints
2025-03-07 11:21:33,753 - INFO - validation batch 51, loss: 5.052, 1632/6976 datapoints
2025-03-07 11:21:33,827 - INFO - validation batch 101, loss: 1.562, 3232/6976 datapoints
2025-03-07 11:21:33,897 - INFO - validation batch 151, loss: 1.367, 4832/6976 datapoints
2025-03-07 11:21:33,972 - INFO - validation batch 201, loss: 3.869, 6432/6976 datapoints
2025-03-07 11:21:33,997 - INFO - Epoch 429/800 done.
2025-03-07 11:21:33,998 - INFO - Final validation performance:
Loss: 2.478, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 11:21:33,999 - INFO - Beginning epoch 430/800
2025-03-07 11:21:34,011 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:21:34,370 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 11:21:34,710 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:21:35,042 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:21:35,366 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:21:35,699 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:21:36,033 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-07 11:21:36,358 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:21:36,696 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 11:21:37,034 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:21:37,358 - INFO - training batch 501, loss: 0.142, 16032/28000 datapoints
2025-03-07 11:21:37,692 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 11:21:38,031 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:21:38,374 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:21:38,687 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:21:39,013 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:21:39,346 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:21:39,681 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:21:39,840 - INFO - validation batch 1, loss: 0.292, 32/6976 datapoints
2025-03-07 11:21:39,916 - INFO - validation batch 51, loss: 5.412, 1632/6976 datapoints
2025-03-07 11:21:39,985 - INFO - validation batch 101, loss: 1.199, 3232/6976 datapoints
2025-03-07 11:21:40,056 - INFO - validation batch 151, loss: 1.288, 4832/6976 datapoints
2025-03-07 11:21:40,129 - INFO - validation batch 201, loss: 3.819, 6432/6976 datapoints
2025-03-07 11:21:40,155 - INFO - Epoch 430/800 done.
2025-03-07 11:21:40,155 - INFO - Final validation performance:
Loss: 2.402, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:21:40,156 - INFO - Beginning epoch 431/800
2025-03-07 11:21:40,166 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:21:40,514 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 11:21:40,827 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:21:41,140 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:21:41,441 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:21:41,755 - INFO - training batch 251, loss: 0.014, 8032/28000 datapoints
2025-03-07 11:21:42,080 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:21:42,401 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:21:42,717 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:21:43,044 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:21:43,358 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:21:43,681 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:21:44,012 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-07 11:21:44,349 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:21:44,670 - INFO - training batch 701, loss: 0.467, 22432/28000 datapoints
2025-03-07 11:21:44,994 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 11:21:45,320 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:21:45,639 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-07 11:21:45,795 - INFO - validation batch 1, loss: 0.271, 32/6976 datapoints
2025-03-07 11:21:45,865 - INFO - validation batch 51, loss: 4.674, 1632/6976 datapoints
2025-03-07 11:21:45,933 - INFO - validation batch 101, loss: 1.313, 3232/6976 datapoints
2025-03-07 11:21:45,999 - INFO - validation batch 151, loss: 1.473, 4832/6976 datapoints
2025-03-07 11:21:46,066 - INFO - validation batch 201, loss: 3.771, 6432/6976 datapoints
2025-03-07 11:21:46,090 - INFO - Epoch 431/800 done.
2025-03-07 11:21:46,090 - INFO - Final validation performance:
Loss: 2.300, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 11:21:46,091 - INFO - Beginning epoch 432/800
2025-03-07 11:21:46,099 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 11:21:46,463 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:21:46,788 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:21:47,113 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:21:47,415 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:21:47,740 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:21:48,085 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:21:48,414 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:21:48,724 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:21:49,055 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:21:49,377 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:21:49,700 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:21:50,030 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:21:50,366 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:21:50,693 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:21:51,012 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:21:51,335 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:21:51,646 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:21:51,805 - INFO - validation batch 1, loss: 0.318, 32/6976 datapoints
2025-03-07 11:21:51,874 - INFO - validation batch 51, loss: 5.167, 1632/6976 datapoints
2025-03-07 11:21:51,941 - INFO - validation batch 101, loss: 1.118, 3232/6976 datapoints
2025-03-07 11:21:52,013 - INFO - validation batch 151, loss: 1.206, 4832/6976 datapoints
2025-03-07 11:21:52,083 - INFO - validation batch 201, loss: 4.025, 6432/6976 datapoints
2025-03-07 11:21:52,108 - INFO - Epoch 432/800 done.
2025-03-07 11:21:52,108 - INFO - Final validation performance:
Loss: 2.367, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:21:52,109 - INFO - Beginning epoch 433/800
2025-03-07 11:21:52,116 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:21:52,444 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-07 11:21:52,775 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 11:21:53,095 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:21:53,402 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:21:53,716 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 11:21:54,041 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 11:21:54,356 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:21:54,674 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:21:54,994 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:21:55,295 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:21:55,618 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:21:55,927 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:21:56,255 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:21:56,568 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:21:56,879 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:21:57,198 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:21:57,510 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:21:57,676 - INFO - validation batch 1, loss: 0.541, 32/6976 datapoints
2025-03-07 11:21:57,743 - INFO - validation batch 51, loss: 5.496, 1632/6976 datapoints
2025-03-07 11:21:57,814 - INFO - validation batch 101, loss: 1.165, 3232/6976 datapoints
2025-03-07 11:21:57,880 - INFO - validation batch 151, loss: 1.115, 4832/6976 datapoints
2025-03-07 11:21:57,948 - INFO - validation batch 201, loss: 3.747, 6432/6976 datapoints
2025-03-07 11:21:57,973 - INFO - Epoch 433/800 done.
2025-03-07 11:21:57,973 - INFO - Final validation performance:
Loss: 2.413, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:21:57,973 - INFO - Beginning epoch 434/800
2025-03-07 11:21:57,985 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:21:58,352 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:21:58,660 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:21:58,974 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:21:59,284 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:21:59,602 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:21:59,929 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:22:00,245 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:22:00,561 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:22:00,883 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:22:01,198 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:22:01,518 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:22:01,839 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:22:02,170 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:22:02,482 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:22:02,799 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:22:03,115 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:22:03,425 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:22:03,579 - INFO - validation batch 1, loss: 0.505, 32/6976 datapoints
2025-03-07 11:22:03,647 - INFO - validation batch 51, loss: 5.558, 1632/6976 datapoints
2025-03-07 11:22:03,715 - INFO - validation batch 101, loss: 1.230, 3232/6976 datapoints
2025-03-07 11:22:03,784 - INFO - validation batch 151, loss: 1.091, 4832/6976 datapoints
2025-03-07 11:22:03,853 - INFO - validation batch 201, loss: 3.733, 6432/6976 datapoints
2025-03-07 11:22:03,880 - INFO - Epoch 434/800 done.
2025-03-07 11:22:03,881 - INFO - Final validation performance:
Loss: 2.423, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:22:03,882 - INFO - Beginning epoch 435/800
2025-03-07 11:22:03,892 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:22:04,244 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:22:04,548 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:22:04,863 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:22:05,165 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:22:05,478 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:22:05,800 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:22:06,118 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:22:06,430 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:22:06,749 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:22:07,060 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:22:07,388 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:22:07,705 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:22:08,036 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:22:08,376 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:22:08,692 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:22:09,016 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:22:09,333 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:22:09,493 - INFO - validation batch 1, loss: 0.510, 32/6976 datapoints
2025-03-07 11:22:09,560 - INFO - validation batch 51, loss: 5.565, 1632/6976 datapoints
2025-03-07 11:22:09,627 - INFO - validation batch 101, loss: 1.181, 3232/6976 datapoints
2025-03-07 11:22:09,694 - INFO - validation batch 151, loss: 1.105, 4832/6976 datapoints
2025-03-07 11:22:09,762 - INFO - validation batch 201, loss: 3.798, 6432/6976 datapoints
2025-03-07 11:22:09,788 - INFO - Epoch 435/800 done.
2025-03-07 11:22:09,788 - INFO - Final validation performance:
Loss: 2.432, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:22:09,789 - INFO - Beginning epoch 436/800
2025-03-07 11:22:09,799 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:22:10,126 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:22:10,436 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:22:10,750 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:22:11,061 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:22:11,380 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:22:11,714 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:22:12,033 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:22:12,347 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:22:12,672 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:22:12,978 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:22:13,291 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:22:13,599 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:22:13,924 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:22:14,246 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:22:14,562 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:22:14,877 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:22:15,193 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:22:15,351 - INFO - validation batch 1, loss: 0.496, 32/6976 datapoints
2025-03-07 11:22:15,423 - INFO - validation batch 51, loss: 5.621, 1632/6976 datapoints
2025-03-07 11:22:15,491 - INFO - validation batch 101, loss: 1.172, 3232/6976 datapoints
2025-03-07 11:22:15,559 - INFO - validation batch 151, loss: 1.109, 4832/6976 datapoints
2025-03-07 11:22:15,628 - INFO - validation batch 201, loss: 3.822, 6432/6976 datapoints
2025-03-07 11:22:15,651 - INFO - Epoch 436/800 done.
2025-03-07 11:22:15,651 - INFO - Final validation performance:
Loss: 2.444, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:22:15,652 - INFO - Beginning epoch 437/800
2025-03-07 11:22:15,660 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:22:16,005 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:22:16,312 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:22:16,629 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:22:16,938 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:22:17,252 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:22:17,581 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:22:17,904 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:22:18,217 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:22:18,568 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:22:18,880 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:22:19,197 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:22:19,513 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:22:19,845 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:22:20,160 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:22:20,478 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:22:20,792 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:22:21,103 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:22:21,257 - INFO - validation batch 1, loss: 0.460, 32/6976 datapoints
2025-03-07 11:22:21,332 - INFO - validation batch 51, loss: 5.679, 1632/6976 datapoints
2025-03-07 11:22:21,403 - INFO - validation batch 101, loss: 1.169, 3232/6976 datapoints
2025-03-07 11:22:21,471 - INFO - validation batch 151, loss: 1.119, 4832/6976 datapoints
2025-03-07 11:22:21,540 - INFO - validation batch 201, loss: 3.848, 6432/6976 datapoints
2025-03-07 11:22:21,564 - INFO - Epoch 437/800 done.
2025-03-07 11:22:21,565 - INFO - Final validation performance:
Loss: 2.455, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:22:21,565 - INFO - Beginning epoch 438/800
2025-03-07 11:22:21,572 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:22:21,905 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:22:22,207 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:22:22,525 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:22:22,827 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:22:23,136 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:22:23,465 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:22:23,779 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:22:24,101 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:22:24,431 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:22:24,738 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:22:25,057 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:22:25,381 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:22:25,712 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:22:26,036 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:22:26,351 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:22:26,680 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:22:26,997 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:22:27,152 - INFO - validation batch 1, loss: 0.406, 32/6976 datapoints
2025-03-07 11:22:27,219 - INFO - validation batch 51, loss: 5.739, 1632/6976 datapoints
2025-03-07 11:22:27,288 - INFO - validation batch 101, loss: 1.172, 3232/6976 datapoints
2025-03-07 11:22:27,356 - INFO - validation batch 151, loss: 1.124, 4832/6976 datapoints
2025-03-07 11:22:27,425 - INFO - validation batch 201, loss: 3.866, 6432/6976 datapoints
2025-03-07 11:22:27,451 - INFO - Epoch 438/800 done.
2025-03-07 11:22:27,451 - INFO - Final validation performance:
Loss: 2.461, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:22:27,452 - INFO - Beginning epoch 439/800
2025-03-07 11:22:27,463 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:22:27,802 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:22:28,113 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:22:28,446 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:22:28,767 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:22:29,082 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:22:29,413 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:22:29,723 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:22:30,038 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:22:30,409 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:22:30,769 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:22:31,087 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:22:31,408 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:22:31,775 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:22:32,092 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:22:32,410 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:22:32,732 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:22:33,052 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:22:33,210 - INFO - validation batch 1, loss: 0.348, 32/6976 datapoints
2025-03-07 11:22:33,276 - INFO - validation batch 51, loss: 5.789, 1632/6976 datapoints
2025-03-07 11:22:33,350 - INFO - validation batch 101, loss: 1.182, 3232/6976 datapoints
2025-03-07 11:22:33,423 - INFO - validation batch 151, loss: 1.119, 4832/6976 datapoints
2025-03-07 11:22:33,489 - INFO - validation batch 201, loss: 3.874, 6432/6976 datapoints
2025-03-07 11:22:33,515 - INFO - Epoch 439/800 done.
2025-03-07 11:22:33,515 - INFO - Final validation performance:
Loss: 2.462, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:22:33,516 - INFO - Beginning epoch 440/800
2025-03-07 11:22:33,526 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:22:33,855 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:22:34,174 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:22:34,493 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:22:34,804 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:22:35,121 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:22:35,452 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:22:35,772 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:22:36,090 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:22:36,424 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:22:36,734 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:22:37,056 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:22:37,378 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:22:37,718 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:22:38,032 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:22:38,348 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:22:38,692 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:22:39,008 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:22:39,165 - INFO - validation batch 1, loss: 0.304, 32/6976 datapoints
2025-03-07 11:22:39,234 - INFO - validation batch 51, loss: 5.863, 1632/6976 datapoints
2025-03-07 11:22:39,304 - INFO - validation batch 101, loss: 1.207, 3232/6976 datapoints
2025-03-07 11:22:39,375 - INFO - validation batch 151, loss: 1.107, 4832/6976 datapoints
2025-03-07 11:22:39,444 - INFO - validation batch 201, loss: 3.882, 6432/6976 datapoints
2025-03-07 11:22:39,470 - INFO - Epoch 440/800 done.
2025-03-07 11:22:39,470 - INFO - Final validation performance:
Loss: 2.472, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:22:39,470 - INFO - Beginning epoch 441/800
2025-03-07 11:22:39,480 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:22:39,810 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:22:40,115 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:22:40,428 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:22:40,738 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:22:41,055 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:22:41,380 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:22:41,699 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:22:42,013 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:22:42,347 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:22:42,680 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:22:43,003 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:22:43,322 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:22:43,655 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:22:43,984 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:22:44,309 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:22:44,635 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:22:44,961 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:22:45,130 - INFO - validation batch 1, loss: 0.281, 32/6976 datapoints
2025-03-07 11:22:45,196 - INFO - validation batch 51, loss: 5.928, 1632/6976 datapoints
2025-03-07 11:22:45,263 - INFO - validation batch 101, loss: 1.252, 3232/6976 datapoints
2025-03-07 11:22:45,330 - INFO - validation batch 151, loss: 1.139, 4832/6976 datapoints
2025-03-07 11:22:45,403 - INFO - validation batch 201, loss: 3.913, 6432/6976 datapoints
2025-03-07 11:22:45,427 - INFO - Epoch 441/800 done.
2025-03-07 11:22:45,428 - INFO - Final validation performance:
Loss: 2.503, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:22:45,429 - INFO - Beginning epoch 442/800
2025-03-07 11:22:45,442 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:22:45,782 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:22:46,096 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:22:46,414 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:22:46,729 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:22:47,053 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:22:47,381 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:22:47,711 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:22:48,025 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:22:48,349 - INFO - training batch 451, loss: 0.066, 14432/28000 datapoints
2025-03-07 11:22:48,686 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 11:22:49,017 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:22:49,345 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-07 11:22:49,663 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:22:49,974 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-07 11:22:50,291 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 11:22:50,628 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:22:50,953 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 11:22:51,117 - INFO - validation batch 1, loss: 0.690, 32/6976 datapoints
2025-03-07 11:22:51,185 - INFO - validation batch 51, loss: 5.573, 1632/6976 datapoints
2025-03-07 11:22:51,253 - INFO - validation batch 101, loss: 0.953, 3232/6976 datapoints
2025-03-07 11:22:51,323 - INFO - validation batch 151, loss: 0.619, 4832/6976 datapoints
2025-03-07 11:22:51,398 - INFO - validation batch 201, loss: 4.138, 6432/6976 datapoints
2025-03-07 11:22:51,425 - INFO - Epoch 442/800 done.
2025-03-07 11:22:51,425 - INFO - Final validation performance:
Loss: 2.395, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:22:51,426 - INFO - Beginning epoch 443/800
2025-03-07 11:22:51,433 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:22:51,760 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 11:22:52,071 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:22:52,398 - INFO - training batch 151, loss: 0.062, 4832/28000 datapoints
2025-03-07 11:22:52,717 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:22:53,042 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 11:22:53,363 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:22:53,687 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:22:54,008 - INFO - training batch 401, loss: 0.040, 12832/28000 datapoints
2025-03-07 11:22:54,343 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:22:54,666 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:22:54,990 - INFO - training batch 551, loss: 0.048, 17632/28000 datapoints
2025-03-07 11:22:55,314 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:22:55,632 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:22:55,943 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:22:56,255 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:22:56,586 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:22:56,909 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:22:57,071 - INFO - validation batch 1, loss: 0.668, 32/6976 datapoints
2025-03-07 11:22:57,139 - INFO - validation batch 51, loss: 6.201, 1632/6976 datapoints
2025-03-07 11:22:57,208 - INFO - validation batch 101, loss: 0.976, 3232/6976 datapoints
2025-03-07 11:22:57,275 - INFO - validation batch 151, loss: 0.643, 4832/6976 datapoints
2025-03-07 11:22:57,345 - INFO - validation batch 201, loss: 3.870, 6432/6976 datapoints
2025-03-07 11:22:57,374 - INFO - Epoch 443/800 done.
2025-03-07 11:22:57,375 - INFO - Final validation performance:
Loss: 2.472, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:22:57,375 - INFO - Beginning epoch 444/800
2025-03-07 11:22:57,384 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:22:57,721 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-07 11:22:58,028 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:22:58,351 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:22:58,659 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 11:22:59,005 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 11:22:59,321 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 11:22:59,647 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:22:59,970 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:23:00,291 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-07 11:23:00,610 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:23:00,940 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:23:01,264 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:23:01,597 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:23:01,918 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 11:23:02,240 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:23:02,569 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:23:02,887 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:23:03,047 - INFO - validation batch 1, loss: 0.670, 32/6976 datapoints
2025-03-07 11:23:03,115 - INFO - validation batch 51, loss: 6.420, 1632/6976 datapoints
2025-03-07 11:23:03,182 - INFO - validation batch 101, loss: 1.069, 3232/6976 datapoints
2025-03-07 11:23:03,250 - INFO - validation batch 151, loss: 0.727, 4832/6976 datapoints
2025-03-07 11:23:03,319 - INFO - validation batch 201, loss: 3.917, 6432/6976 datapoints
2025-03-07 11:23:03,344 - INFO - Epoch 444/800 done.
2025-03-07 11:23:03,344 - INFO - Final validation performance:
Loss: 2.560, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:23:03,346 - INFO - Beginning epoch 445/800
2025-03-07 11:23:03,356 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:23:03,686 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-07 11:23:03,990 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:23:04,307 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:23:04,622 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-07 11:23:04,944 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:23:05,264 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:23:05,584 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-07 11:23:05,895 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:23:06,212 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-07 11:23:06,532 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:23:06,853 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:23:07,179 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:23:07,503 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:23:07,829 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:23:08,154 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:23:08,482 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:23:08,802 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:23:08,976 - INFO - validation batch 1, loss: 0.474, 32/6976 datapoints
2025-03-07 11:23:09,041 - INFO - validation batch 51, loss: 6.092, 1632/6976 datapoints
2025-03-07 11:23:09,109 - INFO - validation batch 101, loss: 0.890, 3232/6976 datapoints
2025-03-07 11:23:09,175 - INFO - validation batch 151, loss: 1.185, 4832/6976 datapoints
2025-03-07 11:23:09,242 - INFO - validation batch 201, loss: 4.107, 6432/6976 datapoints
2025-03-07 11:23:09,268 - INFO - Epoch 445/800 done.
2025-03-07 11:23:09,269 - INFO - Final validation performance:
Loss: 2.550, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:23:09,269 - INFO - Beginning epoch 446/800
2025-03-07 11:23:09,277 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:23:09,619 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-07 11:23:09,937 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:23:10,261 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:23:10,578 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:23:10,893 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:23:11,217 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:23:11,538 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:23:11,862 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:23:12,184 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 11:23:12,498 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:23:12,822 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:23:13,147 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:23:13,476 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:23:13,802 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:23:14,124 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:23:14,457 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:23:14,776 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:23:14,936 - INFO - validation batch 1, loss: 0.399, 32/6976 datapoints
2025-03-07 11:23:15,004 - INFO - validation batch 51, loss: 6.196, 1632/6976 datapoints
2025-03-07 11:23:15,075 - INFO - validation batch 101, loss: 1.134, 3232/6976 datapoints
2025-03-07 11:23:15,141 - INFO - validation batch 151, loss: 0.937, 4832/6976 datapoints
2025-03-07 11:23:15,209 - INFO - validation batch 201, loss: 4.030, 6432/6976 datapoints
2025-03-07 11:23:15,234 - INFO - Epoch 446/800 done.
2025-03-07 11:23:15,234 - INFO - Final validation performance:
Loss: 2.539, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:23:15,234 - INFO - Beginning epoch 447/800
2025-03-07 11:23:15,246 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:23:15,583 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:23:15,888 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:23:16,209 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:23:16,518 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:23:16,833 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:23:17,151 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:23:17,478 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:23:17,801 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:23:18,126 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:23:18,436 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:23:18,753 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:23:19,093 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:23:19,420 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:23:19,747 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:23:20,070 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:23:20,399 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:23:20,723 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:23:20,886 - INFO - validation batch 1, loss: 0.514, 32/6976 datapoints
2025-03-07 11:23:20,955 - INFO - validation batch 51, loss: 6.158, 1632/6976 datapoints
2025-03-07 11:23:21,024 - INFO - validation batch 101, loss: 1.071, 3232/6976 datapoints
2025-03-07 11:23:21,090 - INFO - validation batch 151, loss: 0.989, 4832/6976 datapoints
2025-03-07 11:23:21,158 - INFO - validation batch 201, loss: 4.132, 6432/6976 datapoints
2025-03-07 11:23:21,182 - INFO - Epoch 447/800 done.
2025-03-07 11:23:21,182 - INFO - Final validation performance:
Loss: 2.573, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:23:21,183 - INFO - Beginning epoch 448/800
2025-03-07 11:23:21,194 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:23:21,533 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:23:21,842 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:23:22,166 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:23:22,483 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:23:22,802 - INFO - training batch 251, loss: 0.095, 8032/28000 datapoints
2025-03-07 11:23:23,138 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 11:23:23,453 - INFO - training batch 351, loss: 0.010, 11232/28000 datapoints
2025-03-07 11:23:23,769 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:23:24,095 - INFO - training batch 451, loss: 0.347, 14432/28000 datapoints
2025-03-07 11:23:24,426 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 11:23:24,741 - INFO - training batch 551, loss: 0.052, 17632/28000 datapoints
2025-03-07 11:23:25,055 - INFO - training batch 601, loss: 0.014, 19232/28000 datapoints
2025-03-07 11:23:25,380 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:23:25,695 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 11:23:26,026 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:23:26,348 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:23:26,666 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:23:26,830 - INFO - validation batch 1, loss: 0.549, 32/6976 datapoints
2025-03-07 11:23:26,898 - INFO - validation batch 51, loss: 5.994, 1632/6976 datapoints
2025-03-07 11:23:26,968 - INFO - validation batch 101, loss: 1.122, 3232/6976 datapoints
2025-03-07 11:23:27,035 - INFO - validation batch 151, loss: 0.463, 4832/6976 datapoints
2025-03-07 11:23:27,103 - INFO - validation batch 201, loss: 4.150, 6432/6976 datapoints
2025-03-07 11:23:27,127 - INFO - Epoch 448/800 done.
2025-03-07 11:23:27,127 - INFO - Final validation performance:
Loss: 2.456, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:23:27,128 - INFO - Beginning epoch 449/800
2025-03-07 11:23:27,142 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 11:23:27,483 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-07 11:23:27,793 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:23:28,123 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:23:28,442 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:23:28,762 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:23:29,100 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:23:29,425 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:23:29,744 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-07 11:23:30,070 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:23:30,406 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:23:30,727 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:23:31,072 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:23:31,403 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:23:31,734 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:23:32,080 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:23:32,419 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:23:32,748 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:23:32,917 - INFO - validation batch 1, loss: 0.586, 32/6976 datapoints
2025-03-07 11:23:32,986 - INFO - validation batch 51, loss: 6.423, 1632/6976 datapoints
2025-03-07 11:23:33,057 - INFO - validation batch 101, loss: 1.145, 3232/6976 datapoints
2025-03-07 11:23:33,124 - INFO - validation batch 151, loss: 0.631, 4832/6976 datapoints
2025-03-07 11:23:33,190 - INFO - validation batch 201, loss: 3.863, 6432/6976 datapoints
2025-03-07 11:23:33,214 - INFO - Epoch 449/800 done.
2025-03-07 11:23:33,214 - INFO - Final validation performance:
Loss: 2.530, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:23:33,215 - INFO - Beginning epoch 450/800
2025-03-07 11:23:33,226 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:23:33,561 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:23:33,872 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:23:34,200 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:23:34,521 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:23:34,846 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:23:35,169 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:23:35,490 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-07 11:23:35,807 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:23:36,124 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:23:36,437 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:23:36,757 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:23:37,081 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:23:37,407 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:23:37,736 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:23:38,060 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:23:38,387 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:23:38,710 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:23:38,872 - INFO - validation batch 1, loss: 0.672, 32/6976 datapoints
2025-03-07 11:23:38,941 - INFO - validation batch 51, loss: 6.288, 1632/6976 datapoints
2025-03-07 11:23:39,008 - INFO - validation batch 101, loss: 1.144, 3232/6976 datapoints
2025-03-07 11:23:39,089 - INFO - validation batch 151, loss: 0.731, 4832/6976 datapoints
2025-03-07 11:23:39,173 - INFO - validation batch 201, loss: 3.968, 6432/6976 datapoints
2025-03-07 11:23:39,196 - INFO - Epoch 450/800 done.
2025-03-07 11:23:39,196 - INFO - Final validation performance:
Loss: 2.561, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:23:39,197 - INFO - Beginning epoch 451/800
2025-03-07 11:23:39,205 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 11:23:39,543 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:23:39,849 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:23:40,179 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:23:40,495 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:23:40,823 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:23:41,154 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:23:41,490 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:23:41,810 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:23:42,137 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:23:42,447 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:23:42,767 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:23:43,103 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:23:43,434 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:23:43,756 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:23:44,085 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:23:44,440 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:23:44,771 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:23:44,934 - INFO - validation batch 1, loss: 0.717, 32/6976 datapoints
2025-03-07 11:23:45,004 - INFO - validation batch 51, loss: 6.295, 1632/6976 datapoints
2025-03-07 11:23:45,075 - INFO - validation batch 101, loss: 1.048, 3232/6976 datapoints
2025-03-07 11:23:45,146 - INFO - validation batch 151, loss: 0.470, 4832/6976 datapoints
2025-03-07 11:23:45,217 - INFO - validation batch 201, loss: 3.740, 6432/6976 datapoints
2025-03-07 11:23:45,244 - INFO - Epoch 451/800 done.
2025-03-07 11:23:45,245 - INFO - Final validation performance:
Loss: 2.454, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:23:45,245 - INFO - Beginning epoch 452/800
2025-03-07 11:23:45,252 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:23:45,603 - INFO - training batch 51, loss: 0.221, 1632/28000 datapoints
2025-03-07 11:23:45,914 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:23:46,232 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 11:23:46,543 - INFO - training batch 201, loss: 0.062, 6432/28000 datapoints
2025-03-07 11:23:46,865 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:23:47,185 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:23:47,509 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:23:47,828 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:23:48,155 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:23:48,472 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:23:48,784 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 11:23:49,108 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:23:49,468 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:23:49,789 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-07 11:23:50,155 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:23:50,487 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:23:50,815 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:23:50,973 - INFO - validation batch 1, loss: 0.855, 32/6976 datapoints
2025-03-07 11:23:51,039 - INFO - validation batch 51, loss: 6.345, 1632/6976 datapoints
2025-03-07 11:23:51,105 - INFO - validation batch 101, loss: 1.122, 3232/6976 datapoints
2025-03-07 11:23:51,172 - INFO - validation batch 151, loss: 0.397, 4832/6976 datapoints
2025-03-07 11:23:51,239 - INFO - validation batch 201, loss: 3.694, 6432/6976 datapoints
2025-03-07 11:23:51,266 - INFO - Epoch 452/800 done.
2025-03-07 11:23:51,267 - INFO - Final validation performance:
Loss: 2.483, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 11:23:51,267 - INFO - Beginning epoch 453/800
2025-03-07 11:23:51,276 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 11:23:51,612 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:23:51,925 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:23:52,251 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:23:52,564 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:23:52,893 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:23:53,213 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:23:53,536 - INFO - training batch 351, loss: 0.010, 11232/28000 datapoints
2025-03-07 11:23:53,851 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:23:54,179 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:23:54,500 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:23:54,816 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:23:55,141 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:23:55,471 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:23:55,793 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:23:56,117 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:23:56,440 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:23:56,760 - INFO - training batch 851, loss: 0.140, 27232/28000 datapoints
2025-03-07 11:23:56,927 - INFO - validation batch 1, loss: 0.373, 32/6976 datapoints
2025-03-07 11:23:56,996 - INFO - validation batch 51, loss: 6.655, 1632/6976 datapoints
2025-03-07 11:23:57,066 - INFO - validation batch 101, loss: 1.179, 3232/6976 datapoints
2025-03-07 11:23:57,135 - INFO - validation batch 151, loss: 0.592, 4832/6976 datapoints
2025-03-07 11:23:57,203 - INFO - validation batch 201, loss: 3.326, 6432/6976 datapoints
2025-03-07 11:23:57,230 - INFO - Epoch 453/800 done.
2025-03-07 11:23:57,230 - INFO - Final validation performance:
Loss: 2.425, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:23:57,231 - INFO - Beginning epoch 454/800
2025-03-07 11:23:57,240 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:23:57,574 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-07 11:23:57,898 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-07 11:23:58,211 - INFO - training batch 151, loss: 0.382, 4832/28000 datapoints
2025-03-07 11:23:58,519 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:23:58,845 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-07 11:23:59,179 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:23:59,516 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:23:59,831 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:24:00,161 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:24:00,476 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:24:00,791 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 11:24:01,113 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:24:01,447 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:24:01,774 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 11:24:02,100 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:24:02,428 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 11:24:02,751 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:24:02,914 - INFO - validation batch 1, loss: 0.603, 32/6976 datapoints
2025-03-07 11:24:02,984 - INFO - validation batch 51, loss: 6.067, 1632/6976 datapoints
2025-03-07 11:24:03,051 - INFO - validation batch 101, loss: 0.944, 3232/6976 datapoints
2025-03-07 11:24:03,118 - INFO - validation batch 151, loss: 0.738, 4832/6976 datapoints
2025-03-07 11:24:03,189 - INFO - validation batch 201, loss: 3.601, 6432/6976 datapoints
2025-03-07 11:24:03,214 - INFO - Epoch 454/800 done.
2025-03-07 11:24:03,214 - INFO - Final validation performance:
Loss: 2.391, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:24:03,215 - INFO - Beginning epoch 455/800
2025-03-07 11:24:03,227 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-07 11:24:03,578 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:24:03,877 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:24:04,195 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:24:04,513 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:24:04,841 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:24:05,170 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:24:05,478 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:24:05,794 - INFO - training batch 401, loss: 0.012, 12832/28000 datapoints
2025-03-07 11:24:06,124 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:24:06,439 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:24:06,755 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:24:07,070 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:24:07,399 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:24:07,717 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:24:08,037 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:24:08,361 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:24:08,675 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:24:08,838 - INFO - validation batch 1, loss: 0.555, 32/6976 datapoints
2025-03-07 11:24:08,910 - INFO - validation batch 51, loss: 6.000, 1632/6976 datapoints
2025-03-07 11:24:08,985 - INFO - validation batch 101, loss: 1.097, 3232/6976 datapoints
2025-03-07 11:24:09,056 - INFO - validation batch 151, loss: 0.728, 4832/6976 datapoints
2025-03-07 11:24:09,130 - INFO - validation batch 201, loss: 3.659, 6432/6976 datapoints
2025-03-07 11:24:09,153 - INFO - Epoch 455/800 done.
2025-03-07 11:24:09,153 - INFO - Final validation performance:
Loss: 2.408, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:24:09,154 - INFO - Beginning epoch 456/800
2025-03-07 11:24:09,164 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:24:09,563 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:24:09,893 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:24:10,216 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:24:10,536 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:24:10,860 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:24:11,186 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:24:11,508 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:24:11,827 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:24:12,155 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:24:12,467 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:24:12,788 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:24:13,109 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:24:13,440 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:24:13,758 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:24:14,079 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:24:14,411 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:24:14,728 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:24:14,887 - INFO - validation batch 1, loss: 0.557, 32/6976 datapoints
2025-03-07 11:24:14,954 - INFO - validation batch 51, loss: 5.895, 1632/6976 datapoints
2025-03-07 11:24:15,025 - INFO - validation batch 101, loss: 1.095, 3232/6976 datapoints
2025-03-07 11:24:15,093 - INFO - validation batch 151, loss: 0.708, 4832/6976 datapoints
2025-03-07 11:24:15,160 - INFO - validation batch 201, loss: 3.742, 6432/6976 datapoints
2025-03-07 11:24:15,185 - INFO - Epoch 456/800 done.
2025-03-07 11:24:15,186 - INFO - Final validation performance:
Loss: 2.400, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:24:15,186 - INFO - Beginning epoch 457/800
2025-03-07 11:24:15,196 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:24:15,533 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:24:15,836 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:24:16,150 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:24:16,468 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:24:16,785 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:24:17,111 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:24:17,433 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:24:17,758 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:24:18,080 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:24:18,395 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:24:18,707 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:24:19,028 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:24:19,356 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:24:19,695 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:24:20,018 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:24:20,348 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:24:20,672 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:24:20,830 - INFO - validation batch 1, loss: 0.552, 32/6976 datapoints
2025-03-07 11:24:20,900 - INFO - validation batch 51, loss: 5.924, 1632/6976 datapoints
2025-03-07 11:24:20,966 - INFO - validation batch 101, loss: 1.107, 3232/6976 datapoints
2025-03-07 11:24:21,035 - INFO - validation batch 151, loss: 0.686, 4832/6976 datapoints
2025-03-07 11:24:21,108 - INFO - validation batch 201, loss: 3.758, 6432/6976 datapoints
2025-03-07 11:24:21,132 - INFO - Epoch 457/800 done.
2025-03-07 11:24:21,133 - INFO - Final validation performance:
Loss: 2.405, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:24:21,134 - INFO - Beginning epoch 458/800
2025-03-07 11:24:21,144 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:24:21,484 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:24:21,789 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:24:22,109 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:24:22,424 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:24:22,745 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:24:23,072 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:24:23,405 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:24:23,722 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:24:24,049 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:24:24,368 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:24:24,686 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:24:25,015 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:24:25,349 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:24:25,670 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:24:25,993 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:24:26,327 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:24:26,646 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:24:26,805 - INFO - validation batch 1, loss: 0.537, 32/6976 datapoints
2025-03-07 11:24:26,874 - INFO - validation batch 51, loss: 5.945, 1632/6976 datapoints
2025-03-07 11:24:26,944 - INFO - validation batch 101, loss: 1.136, 3232/6976 datapoints
2025-03-07 11:24:27,015 - INFO - validation batch 151, loss: 0.715, 4832/6976 datapoints
2025-03-07 11:24:27,084 - INFO - validation batch 201, loss: 3.782, 6432/6976 datapoints
2025-03-07 11:24:27,111 - INFO - Epoch 458/800 done.
2025-03-07 11:24:27,111 - INFO - Final validation performance:
Loss: 2.423, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:24:27,112 - INFO - Beginning epoch 459/800
2025-03-07 11:24:27,120 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:24:27,458 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:24:27,767 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:24:28,087 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:24:28,406 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:24:28,732 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:24:29,056 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:24:29,384 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:24:29,727 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:24:30,052 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:24:30,386 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:24:30,791 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:24:31,114 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:24:31,467 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:24:31,796 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:24:32,136 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:24:32,503 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:24:32,830 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:24:32,991 - INFO - validation batch 1, loss: 0.509, 32/6976 datapoints
2025-03-07 11:24:33,059 - INFO - validation batch 51, loss: 5.963, 1632/6976 datapoints
2025-03-07 11:24:33,130 - INFO - validation batch 101, loss: 1.166, 3232/6976 datapoints
2025-03-07 11:24:33,198 - INFO - validation batch 151, loss: 0.759, 4832/6976 datapoints
2025-03-07 11:24:33,265 - INFO - validation batch 201, loss: 3.816, 6432/6976 datapoints
2025-03-07 11:24:33,292 - INFO - Epoch 459/800 done.
2025-03-07 11:24:33,293 - INFO - Final validation performance:
Loss: 2.443, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:24:33,295 - INFO - Beginning epoch 460/800
2025-03-07 11:24:33,302 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:24:33,634 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:24:33,941 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:24:34,261 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:24:34,587 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:24:34,913 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:24:35,245 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:24:35,573 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:24:35,896 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:24:36,226 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:24:36,544 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:24:36,861 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:24:37,190 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:24:37,524 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:24:37,857 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:24:38,187 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:24:38,518 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:24:38,843 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:24:39,003 - INFO - validation batch 1, loss: 0.469, 32/6976 datapoints
2025-03-07 11:24:39,071 - INFO - validation batch 51, loss: 5.986, 1632/6976 datapoints
2025-03-07 11:24:39,139 - INFO - validation batch 101, loss: 1.188, 3232/6976 datapoints
2025-03-07 11:24:39,207 - INFO - validation batch 151, loss: 0.810, 4832/6976 datapoints
2025-03-07 11:24:39,278 - INFO - validation batch 201, loss: 3.848, 6432/6976 datapoints
2025-03-07 11:24:39,303 - INFO - Epoch 460/800 done.
2025-03-07 11:24:39,303 - INFO - Final validation performance:
Loss: 2.460, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:24:39,304 - INFO - Beginning epoch 461/800
2025-03-07 11:24:39,312 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:24:39,641 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:24:39,998 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:24:40,312 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:24:40,628 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:24:40,950 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:24:41,276 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:24:41,604 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:24:41,920 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:24:42,246 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:24:42,564 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:24:42,883 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:24:43,211 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:24:43,555 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:24:43,884 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:24:44,214 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:24:44,563 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:24:44,890 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:24:45,052 - INFO - validation batch 1, loss: 0.423, 32/6976 datapoints
2025-03-07 11:24:45,119 - INFO - validation batch 51, loss: 6.020, 1632/6976 datapoints
2025-03-07 11:24:45,186 - INFO - validation batch 101, loss: 1.205, 3232/6976 datapoints
2025-03-07 11:24:45,255 - INFO - validation batch 151, loss: 0.864, 4832/6976 datapoints
2025-03-07 11:24:45,325 - INFO - validation batch 201, loss: 3.866, 6432/6976 datapoints
2025-03-07 11:24:45,351 - INFO - Epoch 461/800 done.
2025-03-07 11:24:45,351 - INFO - Final validation performance:
Loss: 2.476, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:24:45,352 - INFO - Beginning epoch 462/800
2025-03-07 11:24:45,361 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:24:45,700 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:24:46,009 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:24:46,328 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:24:46,645 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:24:46,973 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:24:47,296 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:24:47,628 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:24:47,944 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:24:48,271 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:24:48,583 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:24:48,903 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:24:49,230 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:24:49,568 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:24:49,908 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:24:50,234 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:24:50,570 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:24:50,899 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:24:51,060 - INFO - validation batch 1, loss: 0.384, 32/6976 datapoints
2025-03-07 11:24:51,128 - INFO - validation batch 51, loss: 6.059, 1632/6976 datapoints
2025-03-07 11:24:51,196 - INFO - validation batch 101, loss: 1.221, 3232/6976 datapoints
2025-03-07 11:24:51,266 - INFO - validation batch 151, loss: 0.923, 4832/6976 datapoints
2025-03-07 11:24:51,335 - INFO - validation batch 201, loss: 3.896, 6432/6976 datapoints
2025-03-07 11:24:51,359 - INFO - Epoch 462/800 done.
2025-03-07 11:24:51,359 - INFO - Final validation performance:
Loss: 2.497, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:24:51,360 - INFO - Beginning epoch 463/800
2025-03-07 11:24:51,376 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:24:51,712 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:24:52,025 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:24:52,344 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:24:52,665 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:24:52,998 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:24:53,328 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:24:53,658 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:24:53,984 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:24:54,317 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:24:54,642 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:24:54,967 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:24:55,300 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:24:55,636 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:24:55,960 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:24:56,282 - INFO - training batch 751, loss: 0.276, 24032/28000 datapoints
2025-03-07 11:24:56,618 - INFO - training batch 801, loss: 0.048, 25632/28000 datapoints
2025-03-07 11:24:56,940 - INFO - training batch 851, loss: 0.029, 27232/28000 datapoints
2025-03-07 11:24:57,101 - INFO - validation batch 1, loss: 0.724, 32/6976 datapoints
2025-03-07 11:24:57,168 - INFO - validation batch 51, loss: 5.134, 1632/6976 datapoints
2025-03-07 11:24:57,235 - INFO - validation batch 101, loss: 1.308, 3232/6976 datapoints
2025-03-07 11:24:57,305 - INFO - validation batch 151, loss: 0.897, 4832/6976 datapoints
2025-03-07 11:24:57,376 - INFO - validation batch 201, loss: 3.432, 6432/6976 datapoints
2025-03-07 11:24:57,403 - INFO - Epoch 463/800 done.
2025-03-07 11:24:57,403 - INFO - Final validation performance:
Loss: 2.299, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:24:57,403 - INFO - Beginning epoch 464/800
2025-03-07 11:24:57,411 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:24:57,736 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:24:58,055 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 11:24:58,389 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:24:58,707 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:24:59,034 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:24:59,357 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 11:24:59,689 - INFO - training batch 351, loss: 0.050, 11232/28000 datapoints
2025-03-07 11:25:00,035 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-07 11:25:00,369 - INFO - training batch 451, loss: 0.028, 14432/28000 datapoints
2025-03-07 11:25:00,688 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:25:01,011 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:25:01,333 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:25:01,675 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:25:02,001 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:25:02,327 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:25:02,665 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:25:02,991 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-07 11:25:03,153 - INFO - validation batch 1, loss: 0.616, 32/6976 datapoints
2025-03-07 11:25:03,219 - INFO - validation batch 51, loss: 5.440, 1632/6976 datapoints
2025-03-07 11:25:03,285 - INFO - validation batch 101, loss: 1.059, 3232/6976 datapoints
2025-03-07 11:25:03,355 - INFO - validation batch 151, loss: 1.308, 4832/6976 datapoints
2025-03-07 11:25:03,423 - INFO - validation batch 201, loss: 3.924, 6432/6976 datapoints
2025-03-07 11:25:03,447 - INFO - Epoch 464/800 done.
2025-03-07 11:25:03,447 - INFO - Final validation performance:
Loss: 2.469, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:25:03,448 - INFO - Beginning epoch 465/800
2025-03-07 11:25:03,460 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:25:03,797 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:25:04,112 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:25:04,440 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:25:04,767 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:25:05,096 - INFO - training batch 251, loss: 0.015, 8032/28000 datapoints
2025-03-07 11:25:05,426 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:25:05,744 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:25:06,065 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:25:06,393 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:25:06,706 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:25:07,028 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:25:07,356 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:25:07,714 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:25:08,037 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:25:08,372 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:25:08,709 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:25:09,027 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:25:09,188 - INFO - validation batch 1, loss: 0.529, 32/6976 datapoints
2025-03-07 11:25:09,260 - INFO - validation batch 51, loss: 5.700, 1632/6976 datapoints
2025-03-07 11:25:09,326 - INFO - validation batch 101, loss: 1.107, 3232/6976 datapoints
2025-03-07 11:25:09,400 - INFO - validation batch 151, loss: 1.090, 4832/6976 datapoints
2025-03-07 11:25:09,468 - INFO - validation batch 201, loss: 4.085, 6432/6976 datapoints
2025-03-07 11:25:09,493 - INFO - Epoch 465/800 done.
2025-03-07 11:25:09,493 - INFO - Final validation performance:
Loss: 2.502, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:25:09,494 - INFO - Beginning epoch 466/800
2025-03-07 11:25:09,501 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:25:09,836 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:25:10,168 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:25:10,493 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:25:10,823 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:25:11,148 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:25:11,482 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:25:11,821 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:25:12,150 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:25:12,474 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:25:12,793 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:25:13,114 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:25:13,441 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:25:13,777 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:25:14,097 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:25:14,434 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:25:14,800 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:25:15,118 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:25:15,278 - INFO - validation batch 1, loss: 0.572, 32/6976 datapoints
2025-03-07 11:25:15,348 - INFO - validation batch 51, loss: 5.741, 1632/6976 datapoints
2025-03-07 11:25:15,420 - INFO - validation batch 101, loss: 1.098, 3232/6976 datapoints
2025-03-07 11:25:15,489 - INFO - validation batch 151, loss: 0.913, 4832/6976 datapoints
2025-03-07 11:25:15,557 - INFO - validation batch 201, loss: 4.042, 6432/6976 datapoints
2025-03-07 11:25:15,579 - INFO - Epoch 466/800 done.
2025-03-07 11:25:15,580 - INFO - Final validation performance:
Loss: 2.473, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:25:15,580 - INFO - Beginning epoch 467/800
2025-03-07 11:25:15,590 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:25:15,923 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:25:16,237 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:25:16,575 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:25:16,893 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:25:17,217 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:25:17,548 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:25:17,883 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:25:18,205 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:25:18,538 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:25:18,860 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:25:19,178 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:25:19,510 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:25:19,850 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:25:20,200 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:25:20,541 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:25:20,872 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:25:21,189 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:25:21,362 - INFO - validation batch 1, loss: 0.564, 32/6976 datapoints
2025-03-07 11:25:21,436 - INFO - validation batch 51, loss: 5.879, 1632/6976 datapoints
2025-03-07 11:25:21,508 - INFO - validation batch 101, loss: 1.053, 3232/6976 datapoints
2025-03-07 11:25:21,576 - INFO - validation batch 151, loss: 0.764, 4832/6976 datapoints
2025-03-07 11:25:21,650 - INFO - validation batch 201, loss: 3.700, 6432/6976 datapoints
2025-03-07 11:25:21,676 - INFO - Epoch 467/800 done.
2025-03-07 11:25:21,676 - INFO - Final validation performance:
Loss: 2.392, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:25:21,677 - INFO - Beginning epoch 468/800
2025-03-07 11:25:21,684 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:25:22,013 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:25:22,323 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:25:22,652 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:25:22,974 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:25:23,305 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:25:23,664 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:25:24,005 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:25:24,375 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:25:24,736 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:25:25,087 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:25:25,410 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:25:25,738 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:25:26,093 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:25:26,431 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:25:26,769 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:25:27,106 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:25:27,436 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:25:27,603 - INFO - validation batch 1, loss: 0.545, 32/6976 datapoints
2025-03-07 11:25:27,680 - INFO - validation batch 51, loss: 5.928, 1632/6976 datapoints
2025-03-07 11:25:27,747 - INFO - validation batch 101, loss: 1.053, 3232/6976 datapoints
2025-03-07 11:25:27,816 - INFO - validation batch 151, loss: 0.738, 4832/6976 datapoints
2025-03-07 11:25:27,884 - INFO - validation batch 201, loss: 3.709, 6432/6976 datapoints
2025-03-07 11:25:27,911 - INFO - Epoch 468/800 done.
2025-03-07 11:25:27,911 - INFO - Final validation performance:
Loss: 2.395, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:25:27,913 - INFO - Beginning epoch 469/800
2025-03-07 11:25:27,921 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:25:28,256 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:25:28,600 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:25:28,939 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:25:29,264 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:25:29,607 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:25:29,943 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:25:30,288 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:25:30,675 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:25:31,015 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:25:31,333 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:25:31,664 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:25:32,013 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:25:32,359 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:25:32,692 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:25:33,052 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:25:33,385 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:25:33,706 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:25:33,866 - INFO - validation batch 1, loss: 0.520, 32/6976 datapoints
2025-03-07 11:25:33,938 - INFO - validation batch 51, loss: 5.983, 1632/6976 datapoints
2025-03-07 11:25:34,006 - INFO - validation batch 101, loss: 1.054, 3232/6976 datapoints
2025-03-07 11:25:34,072 - INFO - validation batch 151, loss: 0.735, 4832/6976 datapoints
2025-03-07 11:25:34,142 - INFO - validation batch 201, loss: 3.734, 6432/6976 datapoints
2025-03-07 11:25:34,169 - INFO - Epoch 469/800 done.
2025-03-07 11:25:34,170 - INFO - Final validation performance:
Loss: 2.405, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:25:34,171 - INFO - Beginning epoch 470/800
2025-03-07 11:25:34,178 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:25:34,516 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:25:34,871 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:25:35,223 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:25:35,551 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:25:35,882 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:25:36,218 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:25:36,570 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:25:37,037 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:25:37,369 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:25:37,692 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:25:38,009 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:25:38,336 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:25:38,686 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:25:39,021 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:25:39,353 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:25:39,698 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:25:40,026 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:25:40,188 - INFO - validation batch 1, loss: 0.484, 32/6976 datapoints
2025-03-07 11:25:40,254 - INFO - validation batch 51, loss: 6.035, 1632/6976 datapoints
2025-03-07 11:25:40,341 - INFO - validation batch 101, loss: 1.059, 3232/6976 datapoints
2025-03-07 11:25:40,423 - INFO - validation batch 151, loss: 0.751, 4832/6976 datapoints
2025-03-07 11:25:40,500 - INFO - validation batch 201, loss: 3.771, 6432/6976 datapoints
2025-03-07 11:25:40,526 - INFO - Epoch 470/800 done.
2025-03-07 11:25:40,527 - INFO - Final validation performance:
Loss: 2.420, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:25:40,527 - INFO - Beginning epoch 471/800
2025-03-07 11:25:40,534 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:25:40,868 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:25:41,194 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:25:41,522 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:25:41,842 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:25:42,171 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:25:42,505 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:25:42,838 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:25:43,162 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:25:43,490 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:25:43,811 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:25:44,137 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:25:44,469 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:25:44,821 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:25:45,159 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:25:45,498 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:25:45,839 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:25:46,199 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:25:46,389 - INFO - validation batch 1, loss: 0.438, 32/6976 datapoints
2025-03-07 11:25:46,457 - INFO - validation batch 51, loss: 6.078, 1632/6976 datapoints
2025-03-07 11:25:46,526 - INFO - validation batch 101, loss: 1.066, 3232/6976 datapoints
2025-03-07 11:25:46,593 - INFO - validation batch 151, loss: 0.802, 4832/6976 datapoints
2025-03-07 11:25:46,660 - INFO - validation batch 201, loss: 3.809, 6432/6976 datapoints
2025-03-07 11:25:46,686 - INFO - Epoch 471/800 done.
2025-03-07 11:25:46,687 - INFO - Final validation performance:
Loss: 2.438, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:25:46,687 - INFO - Beginning epoch 472/800
2025-03-07 11:25:46,696 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:25:47,036 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:25:47,390 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:25:47,743 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:25:48,090 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:25:48,438 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:25:48,795 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:25:49,136 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:25:49,474 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:25:49,824 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:25:50,166 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:25:50,537 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:25:50,869 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:25:51,210 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:25:51,549 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:25:51,884 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:25:52,256 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:25:52,644 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:25:52,830 - INFO - validation batch 1, loss: 0.381, 32/6976 datapoints
2025-03-07 11:25:52,911 - INFO - validation batch 51, loss: 6.117, 1632/6976 datapoints
2025-03-07 11:25:52,981 - INFO - validation batch 101, loss: 1.083, 3232/6976 datapoints
2025-03-07 11:25:53,049 - INFO - validation batch 151, loss: 0.870, 4832/6976 datapoints
2025-03-07 11:25:53,117 - INFO - validation batch 201, loss: 3.851, 6432/6976 datapoints
2025-03-07 11:25:53,145 - INFO - Epoch 472/800 done.
2025-03-07 11:25:53,145 - INFO - Final validation performance:
Loss: 2.460, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:25:53,146 - INFO - Beginning epoch 473/800
2025-03-07 11:25:53,154 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:25:53,494 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:25:53,819 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:25:54,148 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:25:54,479 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:25:54,838 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:25:55,175 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:25:55,504 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:25:55,826 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:25:56,162 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:25:56,485 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:25:56,814 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:25:57,139 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:25:57,476 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:25:57,812 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:25:58,145 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:25:58,495 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:25:58,821 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:25:58,989 - INFO - validation batch 1, loss: 0.326, 32/6976 datapoints
2025-03-07 11:25:59,056 - INFO - validation batch 51, loss: 6.164, 1632/6976 datapoints
2025-03-07 11:25:59,123 - INFO - validation batch 101, loss: 1.114, 3232/6976 datapoints
2025-03-07 11:25:59,192 - INFO - validation batch 151, loss: 0.940, 4832/6976 datapoints
2025-03-07 11:25:59,262 - INFO - validation batch 201, loss: 3.900, 6432/6976 datapoints
2025-03-07 11:25:59,286 - INFO - Epoch 473/800 done.
2025-03-07 11:25:59,287 - INFO - Final validation performance:
Loss: 2.489, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:25:59,287 - INFO - Beginning epoch 474/800
2025-03-07 11:25:59,300 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:25:59,640 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:25:59,958 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:26:00,281 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:26:00,624 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:26:00,965 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:26:01,292 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:26:01,621 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:26:01,947 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:26:02,276 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:26:02,597 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:26:02,925 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:26:03,256 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:26:03,597 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:26:03,932 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:26:04,264 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:26:04,613 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:26:04,951 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:26:05,124 - INFO - validation batch 1, loss: 0.296, 32/6976 datapoints
2025-03-07 11:26:05,192 - INFO - validation batch 51, loss: 6.277, 1632/6976 datapoints
2025-03-07 11:26:05,262 - INFO - validation batch 101, loss: 1.155, 3232/6976 datapoints
2025-03-07 11:26:05,331 - INFO - validation batch 151, loss: 0.973, 4832/6976 datapoints
2025-03-07 11:26:05,403 - INFO - validation batch 201, loss: 3.964, 6432/6976 datapoints
2025-03-07 11:26:05,426 - INFO - Epoch 474/800 done.
2025-03-07 11:26:05,427 - INFO - Final validation performance:
Loss: 2.533, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:26:05,427 - INFO - Beginning epoch 475/800
2025-03-07 11:26:05,437 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:26:05,775 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:26:06,103 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:26:06,436 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:26:06,763 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:26:07,103 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:26:07,431 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:26:07,760 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:26:08,082 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:26:08,409 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:26:08,729 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 11:26:09,053 - INFO - training batch 551, loss: 0.045, 17632/28000 datapoints
2025-03-07 11:26:09,380 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:26:09,701 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:26:10,029 - INFO - training batch 701, loss: 0.045, 22432/28000 datapoints
2025-03-07 11:26:10,373 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:26:10,718 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:26:11,052 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:26:11,225 - INFO - validation batch 1, loss: 0.484, 32/6976 datapoints
2025-03-07 11:26:11,294 - INFO - validation batch 51, loss: 6.076, 1632/6976 datapoints
2025-03-07 11:26:11,363 - INFO - validation batch 101, loss: 1.271, 3232/6976 datapoints
2025-03-07 11:26:11,432 - INFO - validation batch 151, loss: 0.777, 4832/6976 datapoints
2025-03-07 11:26:11,500 - INFO - validation batch 201, loss: 4.258, 6432/6976 datapoints
2025-03-07 11:26:11,525 - INFO - Epoch 475/800 done.
2025-03-07 11:26:11,526 - INFO - Final validation performance:
Loss: 2.573, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:26:11,526 - INFO - Beginning epoch 476/800
2025-03-07 11:26:11,539 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:26:11,877 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:26:12,222 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:26:12,559 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:26:12,885 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:26:13,219 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:26:13,612 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:26:13,945 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-07 11:26:14,267 - INFO - training batch 401, loss: 0.012, 12832/28000 datapoints
2025-03-07 11:26:14,597 - INFO - training batch 451, loss: 0.020, 14432/28000 datapoints
2025-03-07 11:26:14,925 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:26:15,260 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:26:15,601 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:26:15,937 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:26:16,278 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:26:16,619 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:26:16,969 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:26:17,298 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-07 11:26:17,468 - INFO - validation batch 1, loss: 0.279, 32/6976 datapoints
2025-03-07 11:26:17,537 - INFO - validation batch 51, loss: 6.362, 1632/6976 datapoints
2025-03-07 11:26:17,605 - INFO - validation batch 101, loss: 1.114, 3232/6976 datapoints
2025-03-07 11:26:17,681 - INFO - validation batch 151, loss: 1.353, 4832/6976 datapoints
2025-03-07 11:26:17,749 - INFO - validation batch 201, loss: 4.299, 6432/6976 datapoints
2025-03-07 11:26:17,775 - INFO - Epoch 476/800 done.
2025-03-07 11:26:17,775 - INFO - Final validation performance:
Loss: 2.681, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:26:17,776 - INFO - Beginning epoch 477/800
2025-03-07 11:26:17,786 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:26:18,123 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-07 11:26:18,451 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:26:18,798 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:26:19,124 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:26:19,462 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:26:19,792 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:26:20,117 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:26:20,442 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:26:20,788 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-07 11:26:21,108 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:26:21,426 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:26:21,753 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:26:22,094 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:26:22,428 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:26:22,761 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:26:23,104 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:26:23,436 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:26:23,602 - INFO - validation batch 1, loss: 0.452, 32/6976 datapoints
2025-03-07 11:26:23,668 - INFO - validation batch 51, loss: 5.994, 1632/6976 datapoints
2025-03-07 11:26:23,734 - INFO - validation batch 101, loss: 1.162, 3232/6976 datapoints
2025-03-07 11:26:23,800 - INFO - validation batch 151, loss: 0.666, 4832/6976 datapoints
2025-03-07 11:26:23,871 - INFO - validation batch 201, loss: 4.123, 6432/6976 datapoints
2025-03-07 11:26:23,896 - INFO - Epoch 477/800 done.
2025-03-07 11:26:23,896 - INFO - Final validation performance:
Loss: 2.479, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:26:23,897 - INFO - Beginning epoch 478/800
2025-03-07 11:26:23,908 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:26:24,241 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:26:24,571 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:26:24,904 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:26:25,244 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:26:25,588 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:26:25,931 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:26:26,276 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:26:26,596 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:26:26,924 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:26:27,247 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:26:27,576 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:26:27,912 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:26:28,241 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:26:28,573 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:26:28,914 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:26:29,249 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:26:29,578 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:26:29,745 - INFO - validation batch 1, loss: 0.496, 32/6976 datapoints
2025-03-07 11:26:29,813 - INFO - validation batch 51, loss: 6.042, 1632/6976 datapoints
2025-03-07 11:26:29,883 - INFO - validation batch 101, loss: 1.206, 3232/6976 datapoints
2025-03-07 11:26:29,950 - INFO - validation batch 151, loss: 0.685, 4832/6976 datapoints
2025-03-07 11:26:30,020 - INFO - validation batch 201, loss: 3.992, 6432/6976 datapoints
2025-03-07 11:26:30,044 - INFO - Epoch 478/800 done.
2025-03-07 11:26:30,044 - INFO - Final validation performance:
Loss: 2.484, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:26:30,045 - INFO - Beginning epoch 479/800
2025-03-07 11:26:30,056 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:26:30,422 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:26:30,819 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-07 11:26:31,160 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:26:31,497 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:26:31,846 - INFO - training batch 251, loss: 0.019, 8032/28000 datapoints
2025-03-07 11:26:32,207 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 11:26:32,549 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:26:32,878 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 11:26:33,211 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:26:33,554 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 11:26:33,880 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:26:34,213 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:26:34,543 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:26:34,874 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:26:35,227 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:26:35,565 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:26:35,896 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:26:36,060 - INFO - validation batch 1, loss: 0.407, 32/6976 datapoints
2025-03-07 11:26:36,127 - INFO - validation batch 51, loss: 6.182, 1632/6976 datapoints
2025-03-07 11:26:36,194 - INFO - validation batch 101, loss: 1.249, 3232/6976 datapoints
2025-03-07 11:26:36,262 - INFO - validation batch 151, loss: 1.009, 4832/6976 datapoints
2025-03-07 11:26:36,328 - INFO - validation batch 201, loss: 4.313, 6432/6976 datapoints
2025-03-07 11:26:36,353 - INFO - Epoch 479/800 done.
2025-03-07 11:26:36,353 - INFO - Final validation performance:
Loss: 2.632, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:26:36,354 - INFO - Beginning epoch 480/800
2025-03-07 11:26:36,365 - INFO - training batch 1, loss: 0.016, 32/28000 datapoints
2025-03-07 11:26:36,694 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:26:37,024 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-07 11:26:37,352 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:26:37,691 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:26:38,016 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:26:38,349 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:26:38,680 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:26:39,003 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:26:39,325 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:26:39,652 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:26:39,971 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:26:40,300 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:26:40,632 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:26:40,985 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:26:41,323 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:26:41,672 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:26:42,004 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:26:42,179 - INFO - validation batch 1, loss: 0.538, 32/6976 datapoints
2025-03-07 11:26:42,247 - INFO - validation batch 51, loss: 5.756, 1632/6976 datapoints
2025-03-07 11:26:42,316 - INFO - validation batch 101, loss: 1.331, 3232/6976 datapoints
2025-03-07 11:26:42,385 - INFO - validation batch 151, loss: 1.196, 4832/6976 datapoints
2025-03-07 11:26:42,451 - INFO - validation batch 201, loss: 4.342, 6432/6976 datapoints
2025-03-07 11:26:42,475 - INFO - Epoch 480/800 done.
2025-03-07 11:26:42,475 - INFO - Final validation performance:
Loss: 2.633, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 11:26:42,476 - INFO - Beginning epoch 481/800
2025-03-07 11:26:42,491 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:26:42,833 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:26:43,159 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:26:43,499 - INFO - training batch 151, loss: 0.066, 4832/28000 datapoints
2025-03-07 11:26:43,817 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:26:44,155 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:26:44,498 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:26:44,840 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 11:26:45,172 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:26:45,502 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:26:45,822 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:26:46,153 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:26:46,484 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:26:46,813 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 11:26:47,136 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:26:47,473 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:26:47,813 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:26:48,145 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-07 11:26:48,311 - INFO - validation batch 1, loss: 0.841, 32/6976 datapoints
2025-03-07 11:26:48,381 - INFO - validation batch 51, loss: 6.211, 1632/6976 datapoints
2025-03-07 11:26:48,448 - INFO - validation batch 101, loss: 1.433, 3232/6976 datapoints
2025-03-07 11:26:48,517 - INFO - validation batch 151, loss: 1.244, 4832/6976 datapoints
2025-03-07 11:26:48,593 - INFO - validation batch 201, loss: 4.100, 6432/6976 datapoints
2025-03-07 11:26:48,620 - INFO - Epoch 481/800 done.
2025-03-07 11:26:48,620 - INFO - Final validation performance:
Loss: 2.766, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:26:48,621 - INFO - Beginning epoch 482/800
2025-03-07 11:26:48,631 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:26:48,978 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:26:49,318 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:26:49,650 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:26:49,978 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:26:50,310 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:26:50,661 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:26:51,032 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:26:51,380 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:26:51,710 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:26:52,048 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:26:52,395 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:26:52,732 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:26:53,074 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:26:53,404 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:26:53,752 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:26:54,089 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:26:54,416 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:26:54,589 - INFO - validation batch 1, loss: 0.625, 32/6976 datapoints
2025-03-07 11:26:54,656 - INFO - validation batch 51, loss: 6.069, 1632/6976 datapoints
2025-03-07 11:26:54,724 - INFO - validation batch 101, loss: 1.228, 3232/6976 datapoints
2025-03-07 11:26:54,794 - INFO - validation batch 151, loss: 0.798, 4832/6976 datapoints
2025-03-07 11:26:54,865 - INFO - validation batch 201, loss: 3.833, 6432/6976 datapoints
2025-03-07 11:26:54,894 - INFO - Epoch 482/800 done.
2025-03-07 11:26:54,894 - INFO - Final validation performance:
Loss: 2.511, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:26:54,895 - INFO - Beginning epoch 483/800
2025-03-07 11:26:54,909 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:26:55,255 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 11:26:55,583 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:26:55,903 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:26:56,230 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:26:56,560 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:26:56,898 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-07 11:26:57,230 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:26:57,556 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:26:57,896 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:26:58,213 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:26:58,535 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:26:58,868 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:26:59,227 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:26:59,579 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:26:59,926 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:27:00,262 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:27:00,599 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:27:00,764 - INFO - validation batch 1, loss: 0.632, 32/6976 datapoints
2025-03-07 11:27:00,832 - INFO - validation batch 51, loss: 5.951, 1632/6976 datapoints
2025-03-07 11:27:00,899 - INFO - validation batch 101, loss: 1.236, 3232/6976 datapoints
2025-03-07 11:27:00,971 - INFO - validation batch 151, loss: 0.884, 4832/6976 datapoints
2025-03-07 11:27:01,041 - INFO - validation batch 201, loss: 3.973, 6432/6976 datapoints
2025-03-07 11:27:01,071 - INFO - Epoch 483/800 done.
2025-03-07 11:27:01,071 - INFO - Final validation performance:
Loss: 2.535, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:27:01,072 - INFO - Beginning epoch 484/800
2025-03-07 11:27:01,081 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:27:01,436 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:27:01,763 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:27:02,119 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:27:02,445 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:27:02,774 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:27:03,111 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-07 11:27:03,446 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:27:03,769 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-07 11:27:04,097 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:27:04,423 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:27:04,754 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:27:05,089 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:27:05,431 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:27:05,765 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:27:06,117 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:27:06,462 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:27:06,788 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:27:06,953 - INFO - validation batch 1, loss: 0.384, 32/6976 datapoints
2025-03-07 11:27:07,027 - INFO - validation batch 51, loss: 5.668, 1632/6976 datapoints
2025-03-07 11:27:07,094 - INFO - validation batch 101, loss: 1.362, 3232/6976 datapoints
2025-03-07 11:27:07,162 - INFO - validation batch 151, loss: 0.752, 4832/6976 datapoints
2025-03-07 11:27:07,232 - INFO - validation batch 201, loss: 4.528, 6432/6976 datapoints
2025-03-07 11:27:07,257 - INFO - Epoch 484/800 done.
2025-03-07 11:27:07,257 - INFO - Final validation performance:
Loss: 2.539, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:27:07,258 - INFO - Beginning epoch 485/800
2025-03-07 11:27:07,270 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:27:07,605 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:27:07,929 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:27:08,253 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:27:08,584 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:27:08,913 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:27:09,237 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:27:09,559 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:27:09,875 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:27:10,203 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:27:10,525 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:27:10,845 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:27:11,187 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:27:11,549 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:27:11,880 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:27:12,213 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:27:12,560 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:27:12,899 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:27:13,072 - INFO - validation batch 1, loss: 0.484, 32/6976 datapoints
2025-03-07 11:27:13,137 - INFO - validation batch 51, loss: 5.785, 1632/6976 datapoints
2025-03-07 11:27:13,206 - INFO - validation batch 101, loss: 1.325, 3232/6976 datapoints
2025-03-07 11:27:13,273 - INFO - validation batch 151, loss: 0.508, 4832/6976 datapoints
2025-03-07 11:27:13,339 - INFO - validation batch 201, loss: 4.407, 6432/6976 datapoints
2025-03-07 11:27:13,367 - INFO - Epoch 485/800 done.
2025-03-07 11:27:13,368 - INFO - Final validation performance:
Loss: 2.502, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:27:13,369 - INFO - Beginning epoch 486/800
2025-03-07 11:27:13,378 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:27:13,721 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-07 11:27:14,047 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:27:14,384 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:27:14,707 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:27:15,037 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:27:15,361 - INFO - training batch 301, loss: 0.046, 9632/28000 datapoints
2025-03-07 11:27:15,691 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:27:16,016 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:27:16,334 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:27:16,671 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:27:16,989 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:27:17,315 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:27:17,647 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:27:17,977 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:27:18,314 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:27:18,643 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:27:18,969 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:27:19,136 - INFO - validation batch 1, loss: 0.332, 32/6976 datapoints
2025-03-07 11:27:19,207 - INFO - validation batch 51, loss: 6.136, 1632/6976 datapoints
2025-03-07 11:27:19,275 - INFO - validation batch 101, loss: 1.270, 3232/6976 datapoints
2025-03-07 11:27:19,344 - INFO - validation batch 151, loss: 0.781, 4832/6976 datapoints
2025-03-07 11:27:19,415 - INFO - validation batch 201, loss: 4.238, 6432/6976 datapoints
2025-03-07 11:27:19,441 - INFO - Epoch 486/800 done.
2025-03-07 11:27:19,442 - INFO - Final validation performance:
Loss: 2.551, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:27:19,442 - INFO - Beginning epoch 487/800
2025-03-07 11:27:19,451 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:27:19,792 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:27:20,117 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:27:20,453 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:27:20,796 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:27:21,132 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:27:21,486 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:27:21,816 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:27:22,139 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:27:22,471 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:27:22,790 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:27:23,113 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:27:23,449 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:27:23,780 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:27:24,112 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:27:24,459 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:27:24,788 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:27:25,122 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:27:25,291 - INFO - validation batch 1, loss: 0.326, 32/6976 datapoints
2025-03-07 11:27:25,364 - INFO - validation batch 51, loss: 6.077, 1632/6976 datapoints
2025-03-07 11:27:25,438 - INFO - validation batch 101, loss: 1.305, 3232/6976 datapoints
2025-03-07 11:27:25,505 - INFO - validation batch 151, loss: 0.764, 4832/6976 datapoints
2025-03-07 11:27:25,574 - INFO - validation batch 201, loss: 4.240, 6432/6976 datapoints
2025-03-07 11:27:25,599 - INFO - Epoch 487/800 done.
2025-03-07 11:27:25,599 - INFO - Final validation performance:
Loss: 2.542, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:27:25,600 - INFO - Beginning epoch 488/800
2025-03-07 11:27:25,611 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:27:25,944 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:27:26,331 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:27:26,673 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:27:27,000 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:27:27,353 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:27:27,689 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:27:28,018 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:27:28,336 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:27:28,667 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:27:28,985 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:27:29,313 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:27:29,649 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:27:29,988 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:27:30,321 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:27:30,772 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:27:31,109 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:27:31,453 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:27:31,631 - INFO - validation batch 1, loss: 0.384, 32/6976 datapoints
2025-03-07 11:27:31,700 - INFO - validation batch 51, loss: 6.136, 1632/6976 datapoints
2025-03-07 11:27:31,776 - INFO - validation batch 101, loss: 1.289, 3232/6976 datapoints
2025-03-07 11:27:31,845 - INFO - validation batch 151, loss: 0.707, 4832/6976 datapoints
2025-03-07 11:27:31,913 - INFO - validation batch 201, loss: 4.230, 6432/6976 datapoints
2025-03-07 11:27:31,937 - INFO - Epoch 488/800 done.
2025-03-07 11:27:31,938 - INFO - Final validation performance:
Loss: 2.549, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:27:31,939 - INFO - Beginning epoch 489/800
2025-03-07 11:27:31,949 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:27:32,290 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:27:32,630 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:27:32,966 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:27:33,299 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:27:33,670 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:27:34,002 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:27:34,335 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:27:34,657 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:27:34,987 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:27:35,314 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:27:35,639 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:27:35,970 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:27:36,305 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:27:36,635 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:27:36,979 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:27:37,313 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:27:37,650 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:27:37,817 - INFO - validation batch 1, loss: 0.401, 32/6976 datapoints
2025-03-07 11:27:37,887 - INFO - validation batch 51, loss: 6.157, 1632/6976 datapoints
2025-03-07 11:27:37,955 - INFO - validation batch 101, loss: 1.285, 3232/6976 datapoints
2025-03-07 11:27:38,025 - INFO - validation batch 151, loss: 0.702, 4832/6976 datapoints
2025-03-07 11:27:38,092 - INFO - validation batch 201, loss: 4.220, 6432/6976 datapoints
2025-03-07 11:27:38,117 - INFO - Epoch 489/800 done.
2025-03-07 11:27:38,117 - INFO - Final validation performance:
Loss: 2.553, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:27:38,117 - INFO - Beginning epoch 490/800
2025-03-07 11:27:38,129 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:27:38,470 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:27:38,788 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:27:39,120 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:27:39,453 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:27:39,786 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:27:40,114 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:27:40,446 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:27:40,769 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:27:41,097 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:27:41,419 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:27:41,765 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:27:42,103 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:27:42,447 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:27:42,783 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:27:43,132 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:27:43,469 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:27:43,803 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:27:43,974 - INFO - validation batch 1, loss: 0.412, 32/6976 datapoints
2025-03-07 11:27:44,043 - INFO - validation batch 51, loss: 6.208, 1632/6976 datapoints
2025-03-07 11:27:44,110 - INFO - validation batch 101, loss: 1.282, 3232/6976 datapoints
2025-03-07 11:27:44,178 - INFO - validation batch 151, loss: 0.711, 4832/6976 datapoints
2025-03-07 11:27:44,245 - INFO - validation batch 201, loss: 4.216, 6432/6976 datapoints
2025-03-07 11:27:44,271 - INFO - Epoch 490/800 done.
2025-03-07 11:27:44,272 - INFO - Final validation performance:
Loss: 2.566, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:27:44,276 - INFO - Beginning epoch 491/800
2025-03-07 11:27:44,285 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:27:44,633 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:27:44,957 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:27:45,295 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:27:45,628 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:27:45,962 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:27:46,299 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:27:46,627 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:27:46,943 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:27:47,274 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:27:47,605 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:27:47,928 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:27:48,262 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:27:48,604 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:27:48,935 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:27:49,277 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:27:49,616 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:27:49,946 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:27:50,116 - INFO - validation batch 1, loss: 0.411, 32/6976 datapoints
2025-03-07 11:27:50,183 - INFO - validation batch 51, loss: 6.264, 1632/6976 datapoints
2025-03-07 11:27:50,250 - INFO - validation batch 101, loss: 1.280, 3232/6976 datapoints
2025-03-07 11:27:50,318 - INFO - validation batch 151, loss: 0.738, 4832/6976 datapoints
2025-03-07 11:27:50,576 - INFO - validation batch 201, loss: 4.222, 6432/6976 datapoints
2025-03-07 11:27:50,602 - INFO - Epoch 491/800 done.
2025-03-07 11:27:50,602 - INFO - Final validation performance:
Loss: 2.583, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:27:50,603 - INFO - Beginning epoch 492/800
2025-03-07 11:27:50,612 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:27:50,944 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:27:51,273 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:27:51,612 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:27:51,957 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:27:52,292 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:27:52,625 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:27:52,954 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:27:53,275 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:27:53,610 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:27:53,929 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:27:54,252 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:27:54,598 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:27:54,935 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:27:55,278 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:27:55,627 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:27:55,965 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:27:56,295 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:27:56,471 - INFO - validation batch 1, loss: 0.397, 32/6976 datapoints
2025-03-07 11:27:56,538 - INFO - validation batch 51, loss: 6.300, 1632/6976 datapoints
2025-03-07 11:27:56,606 - INFO - validation batch 101, loss: 1.284, 3232/6976 datapoints
2025-03-07 11:27:56,674 - INFO - validation batch 151, loss: 0.789, 4832/6976 datapoints
2025-03-07 11:27:56,742 - INFO - validation batch 201, loss: 4.227, 6432/6976 datapoints
2025-03-07 11:27:56,766 - INFO - Epoch 492/800 done.
2025-03-07 11:27:56,766 - INFO - Final validation performance:
Loss: 2.600, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:27:56,767 - INFO - Beginning epoch 493/800
2025-03-07 11:27:56,779 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:27:57,116 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:27:57,462 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:27:57,800 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:27:58,138 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:27:58,494 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:27:58,828 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:27:59,154 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:27:59,481 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:27:59,816 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:28:00,180 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:28:00,549 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:28:00,891 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:28:01,237 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:28:01,573 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:28:01,945 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:28:02,288 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:28:02,630 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:28:02,800 - INFO - validation batch 1, loss: 0.377, 32/6976 datapoints
2025-03-07 11:28:02,867 - INFO - validation batch 51, loss: 6.320, 1632/6976 datapoints
2025-03-07 11:28:02,934 - INFO - validation batch 101, loss: 1.289, 3232/6976 datapoints
2025-03-07 11:28:03,001 - INFO - validation batch 151, loss: 0.860, 4832/6976 datapoints
2025-03-07 11:28:03,068 - INFO - validation batch 201, loss: 4.235, 6432/6976 datapoints
2025-03-07 11:28:03,090 - INFO - Epoch 493/800 done.
2025-03-07 11:28:03,090 - INFO - Final validation performance:
Loss: 2.616, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:28:03,091 - INFO - Beginning epoch 494/800
2025-03-07 11:28:03,101 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:28:03,451 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:28:03,780 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:28:04,105 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:28:04,435 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:28:04,780 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:28:05,111 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:28:05,450 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:28:05,771 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:28:06,102 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:28:06,427 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:28:06,749 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:28:07,090 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:28:07,462 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:28:07,800 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:28:08,144 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:28:08,491 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:28:08,827 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:28:08,995 - INFO - validation batch 1, loss: 0.354, 32/6976 datapoints
2025-03-07 11:28:09,065 - INFO - validation batch 51, loss: 6.336, 1632/6976 datapoints
2025-03-07 11:28:09,136 - INFO - validation batch 101, loss: 1.305, 3232/6976 datapoints
2025-03-07 11:28:09,204 - INFO - validation batch 151, loss: 0.946, 4832/6976 datapoints
2025-03-07 11:28:09,276 - INFO - validation batch 201, loss: 4.250, 6432/6976 datapoints
2025-03-07 11:28:09,303 - INFO - Epoch 494/800 done.
2025-03-07 11:28:09,303 - INFO - Final validation performance:
Loss: 2.638, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:28:09,304 - INFO - Beginning epoch 495/800
2025-03-07 11:28:09,312 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:28:09,658 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:28:09,990 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:28:10,319 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:28:10,661 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:28:11,007 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:28:11,345 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:28:11,681 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:28:12,032 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:28:12,374 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:28:12,704 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:28:13,032 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:28:13,380 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:28:13,719 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:28:14,053 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:28:14,400 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:28:14,746 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:28:15,086 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:28:15,259 - INFO - validation batch 1, loss: 0.337, 32/6976 datapoints
2025-03-07 11:28:15,326 - INFO - validation batch 51, loss: 6.412, 1632/6976 datapoints
2025-03-07 11:28:15,396 - INFO - validation batch 101, loss: 1.321, 3232/6976 datapoints
2025-03-07 11:28:15,466 - INFO - validation batch 151, loss: 1.035, 4832/6976 datapoints
2025-03-07 11:28:15,535 - INFO - validation batch 201, loss: 4.282, 6432/6976 datapoints
2025-03-07 11:28:15,563 - INFO - Epoch 495/800 done.
2025-03-07 11:28:15,563 - INFO - Final validation performance:
Loss: 2.677, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:28:15,565 - INFO - Beginning epoch 496/800
2025-03-07 11:28:15,574 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:28:15,910 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:28:16,242 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:28:16,572 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:28:16,906 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:28:17,250 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:28:17,588 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:28:17,932 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:28:18,258 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:28:18,598 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:28:18,920 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 11:28:19,261 - INFO - training batch 551, loss: 0.143, 17632/28000 datapoints
2025-03-07 11:28:19,609 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-07 11:28:19,944 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:28:20,286 - INFO - training batch 701, loss: 0.167, 22432/28000 datapoints
2025-03-07 11:28:20,636 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:28:20,971 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:28:21,304 - INFO - training batch 851, loss: 0.042, 27232/28000 datapoints
2025-03-07 11:28:21,478 - INFO - validation batch 1, loss: 0.207, 32/6976 datapoints
2025-03-07 11:28:21,546 - INFO - validation batch 51, loss: 5.854, 1632/6976 datapoints
2025-03-07 11:28:21,612 - INFO - validation batch 101, loss: 1.415, 3232/6976 datapoints
2025-03-07 11:28:21,679 - INFO - validation batch 151, loss: 2.582, 4832/6976 datapoints
2025-03-07 11:28:21,747 - INFO - validation batch 201, loss: 3.705, 6432/6976 datapoints
2025-03-07 11:28:21,771 - INFO - Epoch 496/800 done.
2025-03-07 11:28:21,771 - INFO - Final validation performance:
Loss: 2.753, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:28:21,772 - INFO - Beginning epoch 497/800
2025-03-07 11:28:21,780 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-07 11:28:22,140 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:28:22,481 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:28:22,812 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:28:23,142 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:28:23,484 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-07 11:28:23,816 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-07 11:28:24,158 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:28:24,484 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:28:24,815 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:28:25,162 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:28:25,496 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:28:25,832 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:28:26,175 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:28:26,511 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:28:26,847 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:28:27,191 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:28:27,532 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:28:27,703 - INFO - validation batch 1, loss: 0.529, 32/6976 datapoints
2025-03-07 11:28:27,774 - INFO - validation batch 51, loss: 6.075, 1632/6976 datapoints
2025-03-07 11:28:27,843 - INFO - validation batch 101, loss: 1.300, 3232/6976 datapoints
2025-03-07 11:28:27,910 - INFO - validation batch 151, loss: 1.166, 4832/6976 datapoints
2025-03-07 11:28:27,979 - INFO - validation batch 201, loss: 3.779, 6432/6976 datapoints
2025-03-07 11:28:28,007 - INFO - Epoch 497/800 done.
2025-03-07 11:28:28,007 - INFO - Final validation performance:
Loss: 2.570, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:28:28,008 - INFO - Beginning epoch 498/800
2025-03-07 11:28:28,017 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:28:28,346 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-07 11:28:28,679 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:28:29,006 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:28:29,362 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:28:29,719 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 11:28:30,067 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:28:30,429 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:28:30,761 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:28:31,103 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:28:31,439 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:28:31,770 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:28:32,130 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:28:32,467 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:28:32,813 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:28:33,173 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:28:33,523 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:28:33,864 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:28:34,056 - INFO - validation batch 1, loss: 0.522, 32/6976 datapoints
2025-03-07 11:28:34,139 - INFO - validation batch 51, loss: 6.037, 1632/6976 datapoints
2025-03-07 11:28:34,219 - INFO - validation batch 101, loss: 1.309, 3232/6976 datapoints
2025-03-07 11:28:34,291 - INFO - validation batch 151, loss: 1.194, 4832/6976 datapoints
2025-03-07 11:28:34,360 - INFO - validation batch 201, loss: 3.782, 6432/6976 datapoints
2025-03-07 11:28:34,389 - INFO - Epoch 498/800 done.
2025-03-07 11:28:34,389 - INFO - Final validation performance:
Loss: 2.569, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:28:34,390 - INFO - Beginning epoch 499/800
2025-03-07 11:28:34,400 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:28:34,735 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:28:35,073 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:28:35,417 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:28:35,753 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:28:36,103 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:28:36,435 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:28:36,776 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:28:37,103 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:28:37,449 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:28:37,782 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:28:38,099 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:28:38,436 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:28:38,773 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:28:39,105 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:28:39,454 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:28:39,801 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:28:40,137 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:28:40,310 - INFO - validation batch 1, loss: 0.500, 32/6976 datapoints
2025-03-07 11:28:40,380 - INFO - validation batch 51, loss: 6.118, 1632/6976 datapoints
2025-03-07 11:28:40,447 - INFO - validation batch 101, loss: 1.289, 3232/6976 datapoints
2025-03-07 11:28:40,514 - INFO - validation batch 151, loss: 1.199, 4832/6976 datapoints
2025-03-07 11:28:40,583 - INFO - validation batch 201, loss: 3.915, 6432/6976 datapoints
2025-03-07 11:28:40,606 - INFO - Epoch 499/800 done.
2025-03-07 11:28:40,606 - INFO - Final validation performance:
Loss: 2.604, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:28:40,607 - INFO - Beginning epoch 500/800
2025-03-07 11:28:40,618 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:28:40,952 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:28:41,294 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:28:41,636 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:28:41,977 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:28:42,352 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:28:42,687 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:28:43,036 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:28:43,365 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:28:43,705 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:28:44,053 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:28:44,370 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:28:44,710 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:28:45,051 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:28:45,399 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:28:45,740 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:28:46,079 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:28:46,414 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:28:46,586 - INFO - validation batch 1, loss: 0.514, 32/6976 datapoints
2025-03-07 11:28:46,654 - INFO - validation batch 51, loss: 6.134, 1632/6976 datapoints
2025-03-07 11:28:46,721 - INFO - validation batch 101, loss: 1.260, 3232/6976 datapoints
2025-03-07 11:28:46,788 - INFO - validation batch 151, loss: 1.016, 4832/6976 datapoints
2025-03-07 11:28:46,856 - INFO - validation batch 201, loss: 3.978, 6432/6976 datapoints
2025-03-07 11:28:46,881 - INFO - Epoch 500/800 done.
2025-03-07 11:28:46,881 - INFO - Final validation performance:
Loss: 2.580, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:28:46,882 - INFO - Beginning epoch 501/800
2025-03-07 11:28:46,891 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:28:47,214 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:28:47,560 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:28:47,898 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:28:48,236 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:28:48,586 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:28:48,915 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:28:49,257 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:28:49,585 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:28:49,924 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:28:50,254 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:28:50,579 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:28:50,918 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:28:51,255 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:28:51,599 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:28:51,946 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:28:52,309 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:28:52,652 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:28:52,826 - INFO - validation batch 1, loss: 0.500, 32/6976 datapoints
2025-03-07 11:28:52,894 - INFO - validation batch 51, loss: 6.171, 1632/6976 datapoints
2025-03-07 11:28:52,962 - INFO - validation batch 101, loss: 1.258, 3232/6976 datapoints
2025-03-07 11:28:53,031 - INFO - validation batch 151, loss: 1.030, 4832/6976 datapoints
2025-03-07 11:28:53,098 - INFO - validation batch 201, loss: 4.003, 6432/6976 datapoints
2025-03-07 11:28:53,123 - INFO - Epoch 501/800 done.
2025-03-07 11:28:53,123 - INFO - Final validation performance:
Loss: 2.592, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:28:53,124 - INFO - Beginning epoch 502/800
2025-03-07 11:28:53,133 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:28:53,473 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:28:53,810 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:28:54,141 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:28:54,481 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:28:54,829 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:28:55,160 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:28:55,508 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:28:55,832 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:28:56,168 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:28:56,500 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:28:56,816 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:28:57,153 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:28:57,489 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:28:57,829 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:28:58,172 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:28:58,520 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:28:58,857 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:28:59,034 - INFO - validation batch 1, loss: 0.485, 32/6976 datapoints
2025-03-07 11:28:59,101 - INFO - validation batch 51, loss: 6.204, 1632/6976 datapoints
2025-03-07 11:28:59,168 - INFO - validation batch 101, loss: 1.259, 3232/6976 datapoints
2025-03-07 11:28:59,235 - INFO - validation batch 151, loss: 1.027, 4832/6976 datapoints
2025-03-07 11:28:59,303 - INFO - validation batch 201, loss: 4.045, 6432/6976 datapoints
2025-03-07 11:28:59,328 - INFO - Epoch 502/800 done.
2025-03-07 11:28:59,329 - INFO - Final validation performance:
Loss: 2.604, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:28:59,329 - INFO - Beginning epoch 503/800
2025-03-07 11:28:59,339 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:28:59,678 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:29:00,023 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:29:00,359 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:29:00,702 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:29:01,055 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:29:01,393 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:29:01,738 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:29:02,072 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:29:02,433 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:29:02,762 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:29:03,080 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:29:03,425 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:29:03,778 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:29:04,113 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:29:04,459 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:29:04,803 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:29:05,152 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:29:05,327 - INFO - validation batch 1, loss: 0.461, 32/6976 datapoints
2025-03-07 11:29:05,402 - INFO - validation batch 51, loss: 6.248, 1632/6976 datapoints
2025-03-07 11:29:05,472 - INFO - validation batch 101, loss: 1.263, 3232/6976 datapoints
2025-03-07 11:29:05,540 - INFO - validation batch 151, loss: 1.020, 4832/6976 datapoints
2025-03-07 11:29:05,606 - INFO - validation batch 201, loss: 4.098, 6432/6976 datapoints
2025-03-07 11:29:05,633 - INFO - Epoch 503/800 done.
2025-03-07 11:29:05,633 - INFO - Final validation performance:
Loss: 2.618, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:29:05,634 - INFO - Beginning epoch 504/800
2025-03-07 11:29:05,642 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:29:05,975 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:29:06,312 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:29:06,647 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:29:06,980 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:29:07,323 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:29:07,661 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:29:08,002 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:29:08,329 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:29:08,671 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:29:09,002 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:29:09,322 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:29:09,664 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:29:10,004 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:29:10,349 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:29:10,707 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:29:11,054 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:29:11,398 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:29:11,573 - INFO - validation batch 1, loss: 0.430, 32/6976 datapoints
2025-03-07 11:29:11,641 - INFO - validation batch 51, loss: 6.308, 1632/6976 datapoints
2025-03-07 11:29:11,711 - INFO - validation batch 101, loss: 1.275, 3232/6976 datapoints
2025-03-07 11:29:11,780 - INFO - validation batch 151, loss: 1.026, 4832/6976 datapoints
2025-03-07 11:29:11,847 - INFO - validation batch 201, loss: 4.158, 6432/6976 datapoints
2025-03-07 11:29:11,875 - INFO - Epoch 504/800 done.
2025-03-07 11:29:11,875 - INFO - Final validation performance:
Loss: 2.639, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:29:11,876 - INFO - Beginning epoch 505/800
2025-03-07 11:29:11,889 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:29:12,218 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:29:12,578 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:29:12,916 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:29:13,255 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:29:13,606 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:29:13,939 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:29:14,289 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:29:14,621 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:29:14,965 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:29:15,299 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:29:15,631 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:29:15,971 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:29:16,310 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:29:16,651 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:29:17,001 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:29:17,347 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:29:17,696 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:29:17,870 - INFO - validation batch 1, loss: 0.386, 32/6976 datapoints
2025-03-07 11:29:17,940 - INFO - validation batch 51, loss: 6.363, 1632/6976 datapoints
2025-03-07 11:29:18,008 - INFO - validation batch 101, loss: 1.292, 3232/6976 datapoints
2025-03-07 11:29:18,076 - INFO - validation batch 151, loss: 1.047, 4832/6976 datapoints
2025-03-07 11:29:18,145 - INFO - validation batch 201, loss: 4.217, 6432/6976 datapoints
2025-03-07 11:29:18,168 - INFO - Epoch 505/800 done.
2025-03-07 11:29:18,169 - INFO - Final validation performance:
Loss: 2.661, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:29:18,169 - INFO - Beginning epoch 506/800
2025-03-07 11:29:18,181 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:29:18,519 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:29:18,854 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:29:19,190 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:29:19,537 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:29:19,885 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:29:20,217 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:29:20,560 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:29:20,888 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:29:21,227 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:29:21,561 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:29:21,883 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:29:22,226 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:29:22,587 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:29:22,930 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:29:23,276 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:29:23,626 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:29:23,968 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:29:24,141 - INFO - validation batch 1, loss: 0.343, 32/6976 datapoints
2025-03-07 11:29:24,210 - INFO - validation batch 51, loss: 6.414, 1632/6976 datapoints
2025-03-07 11:29:24,279 - INFO - validation batch 101, loss: 1.316, 3232/6976 datapoints
2025-03-07 11:29:24,348 - INFO - validation batch 151, loss: 1.087, 4832/6976 datapoints
2025-03-07 11:29:24,423 - INFO - validation batch 201, loss: 4.271, 6432/6976 datapoints
2025-03-07 11:29:24,448 - INFO - Epoch 506/800 done.
2025-03-07 11:29:24,448 - INFO - Final validation performance:
Loss: 2.686, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:29:24,450 - INFO - Beginning epoch 507/800
2025-03-07 11:29:24,458 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:29:24,786 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:29:25,128 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:29:25,469 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:29:25,814 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:29:26,174 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:29:26,510 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:29:26,847 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:29:27,186 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:29:27,527 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:29:27,865 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:29:28,192 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:29:28,542 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:29:28,877 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:29:29,217 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:29:29,569 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:29:29,922 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:29:30,265 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:29:30,458 - INFO - validation batch 1, loss: 0.334, 32/6976 datapoints
2025-03-07 11:29:30,528 - INFO - validation batch 51, loss: 6.487, 1632/6976 datapoints
2025-03-07 11:29:30,597 - INFO - validation batch 101, loss: 1.342, 3232/6976 datapoints
2025-03-07 11:29:30,664 - INFO - validation batch 151, loss: 1.074, 4832/6976 datapoints
2025-03-07 11:29:30,733 - INFO - validation batch 201, loss: 4.322, 6432/6976 datapoints
2025-03-07 11:29:30,757 - INFO - Epoch 507/800 done.
2025-03-07 11:29:30,757 - INFO - Final validation performance:
Loss: 2.712, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:29:30,758 - INFO - Beginning epoch 508/800
2025-03-07 11:29:30,771 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:29:31,121 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:29:31,464 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:29:31,803 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:29:32,149 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:29:32,508 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:29:32,861 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:29:33,202 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:29:33,573 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:29:33,906 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:29:34,245 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:29:34,585 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:29:34,939 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:29:35,279 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:29:35,641 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:29:35,992 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:29:36,350 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:29:36,692 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:29:36,867 - INFO - validation batch 1, loss: 0.300, 32/6976 datapoints
2025-03-07 11:29:36,933 - INFO - validation batch 51, loss: 6.504, 1632/6976 datapoints
2025-03-07 11:29:36,999 - INFO - validation batch 101, loss: 1.392, 3232/6976 datapoints
2025-03-07 11:29:37,069 - INFO - validation batch 151, loss: 1.142, 4832/6976 datapoints
2025-03-07 11:29:37,136 - INFO - validation batch 201, loss: 4.379, 6432/6976 datapoints
2025-03-07 11:29:37,163 - INFO - Epoch 508/800 done.
2025-03-07 11:29:37,163 - INFO - Final validation performance:
Loss: 2.743, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:29:37,164 - INFO - Beginning epoch 509/800
2025-03-07 11:29:37,173 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:29:37,508 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:29:37,871 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:29:38,205 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:29:38,559 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:29:38,914 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:29:39,251 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:29:39,595 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:29:39,934 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:29:40,271 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:29:40,615 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:29:40,944 - INFO - training batch 551, loss: 0.723, 17632/28000 datapoints
2025-03-07 11:29:41,282 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 11:29:41,621 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:29:41,971 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:29:42,326 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:29:42,680 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-07 11:29:43,044 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 11:29:43,213 - INFO - validation batch 1, loss: 0.649, 32/6976 datapoints
2025-03-07 11:29:43,282 - INFO - validation batch 51, loss: 6.339, 1632/6976 datapoints
2025-03-07 11:29:43,351 - INFO - validation batch 101, loss: 1.348, 3232/6976 datapoints
2025-03-07 11:29:43,424 - INFO - validation batch 151, loss: 0.830, 4832/6976 datapoints
2025-03-07 11:29:43,492 - INFO - validation batch 201, loss: 3.967, 6432/6976 datapoints
2025-03-07 11:29:43,515 - INFO - Epoch 509/800 done.
2025-03-07 11:29:43,515 - INFO - Final validation performance:
Loss: 2.627, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:29:43,516 - INFO - Beginning epoch 510/800
2025-03-07 11:29:43,530 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:29:43,871 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:29:44,213 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:29:44,544 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:29:44,888 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:29:45,236 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:29:45,578 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:29:45,915 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-07 11:29:46,251 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:29:46,597 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:29:46,942 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:29:47,273 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:29:47,616 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:29:47,961 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:29:48,300 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:29:48,658 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:29:49,006 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-07 11:29:49,355 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:29:49,531 - INFO - validation batch 1, loss: 0.414, 32/6976 datapoints
2025-03-07 11:29:49,600 - INFO - validation batch 51, loss: 6.696, 1632/6976 datapoints
2025-03-07 11:29:49,667 - INFO - validation batch 101, loss: 1.607, 3232/6976 datapoints
2025-03-07 11:29:49,735 - INFO - validation batch 151, loss: 1.401, 4832/6976 datapoints
2025-03-07 11:29:49,801 - INFO - validation batch 201, loss: 4.021, 6432/6976 datapoints
2025-03-07 11:29:49,827 - INFO - Epoch 510/800 done.
2025-03-07 11:29:49,827 - INFO - Final validation performance:
Loss: 2.828, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:29:49,828 - INFO - Beginning epoch 511/800
2025-03-07 11:29:49,839 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:29:50,164 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:29:50,510 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:29:50,839 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:29:51,184 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:29:51,558 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:29:51,957 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:29:52,349 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:29:52,724 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:29:53,086 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:29:53,430 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:29:53,764 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:29:54,103 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:29:54,442 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:29:54,779 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:29:55,137 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:29:55,505 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:29:55,845 - INFO - training batch 851, loss: 0.090, 27232/28000 datapoints
2025-03-07 11:29:56,024 - INFO - validation batch 1, loss: 0.331, 32/6976 datapoints
2025-03-07 11:29:56,090 - INFO - validation batch 51, loss: 7.091, 1632/6976 datapoints
2025-03-07 11:29:56,158 - INFO - validation batch 101, loss: 1.664, 3232/6976 datapoints
2025-03-07 11:29:56,225 - INFO - validation batch 151, loss: 1.126, 4832/6976 datapoints
2025-03-07 11:29:56,291 - INFO - validation batch 201, loss: 3.934, 6432/6976 datapoints
2025-03-07 11:29:56,314 - INFO - Epoch 511/800 done.
2025-03-07 11:29:56,314 - INFO - Final validation performance:
Loss: 2.829, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:29:56,315 - INFO - Beginning epoch 512/800
2025-03-07 11:29:56,326 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:29:56,678 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:29:57,017 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:29:57,354 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:29:57,706 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:29:58,064 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:29:58,413 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:29:58,758 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:29:59,093 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:29:59,489 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:29:59,901 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:30:00,276 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:30:00,696 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:30:01,095 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:30:01,508 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:30:01,948 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:30:02,313 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:30:02,671 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:30:02,852 - INFO - validation batch 1, loss: 0.345, 32/6976 datapoints
2025-03-07 11:30:02,933 - INFO - validation batch 51, loss: 6.559, 1632/6976 datapoints
2025-03-07 11:30:03,023 - INFO - validation batch 101, loss: 1.500, 3232/6976 datapoints
2025-03-07 11:30:03,093 - INFO - validation batch 151, loss: 1.259, 4832/6976 datapoints
2025-03-07 11:30:03,162 - INFO - validation batch 201, loss: 4.160, 6432/6976 datapoints
2025-03-07 11:30:03,187 - INFO - Epoch 512/800 done.
2025-03-07 11:30:03,188 - INFO - Final validation performance:
Loss: 2.765, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:30:03,189 - INFO - Beginning epoch 513/800
2025-03-07 11:30:03,199 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:30:03,549 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:30:03,902 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:30:04,242 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:30:04,583 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:30:04,939 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:30:05,280 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:30:05,633 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:30:05,965 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:30:06,292 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:30:06,631 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:30:06,963 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:30:07,301 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:30:07,640 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:30:07,973 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:30:08,322 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:30:08,679 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:30:09,017 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:30:09,191 - INFO - validation batch 1, loss: 0.359, 32/6976 datapoints
2025-03-07 11:30:09,259 - INFO - validation batch 51, loss: 6.430, 1632/6976 datapoints
2025-03-07 11:30:09,328 - INFO - validation batch 101, loss: 1.456, 3232/6976 datapoints
2025-03-07 11:30:09,398 - INFO - validation batch 151, loss: 1.177, 4832/6976 datapoints
2025-03-07 11:30:09,467 - INFO - validation batch 201, loss: 4.210, 6432/6976 datapoints
2025-03-07 11:30:09,492 - INFO - Epoch 513/800 done.
2025-03-07 11:30:09,493 - INFO - Final validation performance:
Loss: 2.726, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:30:09,493 - INFO - Beginning epoch 514/800
2025-03-07 11:30:09,505 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:30:09,834 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:30:10,177 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:30:10,512 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:30:10,848 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:30:11,201 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:30:11,541 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:30:11,885 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:30:12,217 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:30:12,549 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:30:12,890 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:30:13,236 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:30:13,579 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:30:13,918 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:30:14,251 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:30:14,607 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:30:14,960 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:30:15,304 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:30:15,482 - INFO - validation batch 1, loss: 0.377, 32/6976 datapoints
2025-03-07 11:30:15,553 - INFO - validation batch 51, loss: 6.464, 1632/6976 datapoints
2025-03-07 11:30:15,622 - INFO - validation batch 101, loss: 1.440, 3232/6976 datapoints
2025-03-07 11:30:15,695 - INFO - validation batch 151, loss: 1.115, 4832/6976 datapoints
2025-03-07 11:30:15,762 - INFO - validation batch 201, loss: 4.247, 6432/6976 datapoints
2025-03-07 11:30:15,785 - INFO - Epoch 514/800 done.
2025-03-07 11:30:15,785 - INFO - Final validation performance:
Loss: 2.729, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:30:15,786 - INFO - Beginning epoch 515/800
2025-03-07 11:30:15,796 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:30:16,133 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:30:16,480 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:30:16,824 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:30:17,165 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:30:17,523 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:30:17,868 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:30:18,210 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:30:18,544 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:30:18,870 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:30:19,202 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:30:19,531 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:30:19,866 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:30:20,194 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:30:20,528 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:30:20,878 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:30:21,227 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:30:21,574 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:30:21,753 - INFO - validation batch 1, loss: 0.394, 32/6976 datapoints
2025-03-07 11:30:21,823 - INFO - validation batch 51, loss: 6.500, 1632/6976 datapoints
2025-03-07 11:30:21,888 - INFO - validation batch 101, loss: 1.420, 3232/6976 datapoints
2025-03-07 11:30:21,955 - INFO - validation batch 151, loss: 1.087, 4832/6976 datapoints
2025-03-07 11:30:22,024 - INFO - validation batch 201, loss: 4.276, 6432/6976 datapoints
2025-03-07 11:30:22,049 - INFO - Epoch 515/800 done.
2025-03-07 11:30:22,049 - INFO - Final validation performance:
Loss: 2.736, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:30:22,050 - INFO - Beginning epoch 516/800
2025-03-07 11:30:22,061 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:30:22,397 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:30:22,743 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:30:23,078 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:30:23,465 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:30:23,873 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:30:24,214 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:30:24,566 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:30:24,902 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:30:25,233 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:30:25,577 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:30:25,908 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:30:26,255 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:30:26,592 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:30:26,925 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:30:27,282 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:30:27,639 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:30:27,976 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:30:28,150 - INFO - validation batch 1, loss: 0.412, 32/6976 datapoints
2025-03-07 11:30:28,220 - INFO - validation batch 51, loss: 6.546, 1632/6976 datapoints
2025-03-07 11:30:28,288 - INFO - validation batch 101, loss: 1.407, 3232/6976 datapoints
2025-03-07 11:30:28,358 - INFO - validation batch 151, loss: 1.078, 4832/6976 datapoints
2025-03-07 11:30:28,428 - INFO - validation batch 201, loss: 4.306, 6432/6976 datapoints
2025-03-07 11:30:28,455 - INFO - Epoch 516/800 done.
2025-03-07 11:30:28,455 - INFO - Final validation performance:
Loss: 2.750, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:30:28,456 - INFO - Beginning epoch 517/800
2025-03-07 11:30:28,465 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:30:28,794 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:30:29,133 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:30:29,465 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:30:29,805 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:30:30,153 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:30:30,525 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:30:30,865 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:30:31,200 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:30:31,532 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:30:31,873 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:30:32,202 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:30:32,550 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:30:32,888 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:30:33,233 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:30:33,597 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:30:33,974 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:30:34,314 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:30:34,503 - INFO - validation batch 1, loss: 0.429, 32/6976 datapoints
2025-03-07 11:30:34,569 - INFO - validation batch 51, loss: 6.589, 1632/6976 datapoints
2025-03-07 11:30:34,636 - INFO - validation batch 101, loss: 1.402, 3232/6976 datapoints
2025-03-07 11:30:34,705 - INFO - validation batch 151, loss: 1.077, 4832/6976 datapoints
2025-03-07 11:30:34,785 - INFO - validation batch 201, loss: 4.336, 6432/6976 datapoints
2025-03-07 11:30:34,821 - INFO - Epoch 517/800 done.
2025-03-07 11:30:34,824 - INFO - Final validation performance:
Loss: 2.767, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:30:34,826 - INFO - Beginning epoch 518/800
2025-03-07 11:30:34,858 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:30:35,209 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:30:35,563 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:30:35,905 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:30:36,243 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:30:36,617 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:30:36,967 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:30:37,309 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:30:37,669 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:30:38,024 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:30:38,355 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:30:38,689 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:30:39,026 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:30:39,358 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:30:39,690 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:30:40,043 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:30:40,397 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:30:40,732 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:30:40,907 - INFO - validation batch 1, loss: 0.437, 32/6976 datapoints
2025-03-07 11:30:40,975 - INFO - validation batch 51, loss: 6.638, 1632/6976 datapoints
2025-03-07 11:30:41,042 - INFO - validation batch 101, loss: 1.402, 3232/6976 datapoints
2025-03-07 11:30:41,110 - INFO - validation batch 151, loss: 1.083, 4832/6976 datapoints
2025-03-07 11:30:41,178 - INFO - validation batch 201, loss: 4.364, 6432/6976 datapoints
2025-03-07 11:30:41,202 - INFO - Epoch 518/800 done.
2025-03-07 11:30:41,202 - INFO - Final validation performance:
Loss: 2.785, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:30:41,203 - INFO - Beginning epoch 519/800
2025-03-07 11:30:41,217 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:30:41,549 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:30:41,912 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:30:42,248 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:30:42,592 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:30:42,959 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:30:43,306 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:30:43,668 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:30:44,016 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:30:44,346 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:30:44,685 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:30:45,019 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:30:45,362 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:30:45,707 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:30:46,051 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:30:46,417 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:30:46,772 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:30:47,131 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:30:47,314 - INFO - validation batch 1, loss: 0.426, 32/6976 datapoints
2025-03-07 11:30:47,390 - INFO - validation batch 51, loss: 6.699, 1632/6976 datapoints
2025-03-07 11:30:47,459 - INFO - validation batch 101, loss: 1.409, 3232/6976 datapoints
2025-03-07 11:30:47,527 - INFO - validation batch 151, loss: 1.110, 4832/6976 datapoints
2025-03-07 11:30:47,598 - INFO - validation batch 201, loss: 4.389, 6432/6976 datapoints
2025-03-07 11:30:47,623 - INFO - Epoch 519/800 done.
2025-03-07 11:30:47,623 - INFO - Final validation performance:
Loss: 2.807, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:30:47,623 - INFO - Beginning epoch 520/800
2025-03-07 11:30:47,634 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:30:47,963 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:30:48,348 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:30:48,688 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:30:49,028 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:30:49,388 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:30:49,740 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:30:50,089 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:30:50,427 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:30:50,765 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:30:51,101 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:30:51,436 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:30:51,799 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:30:52,146 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:30:52,485 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:30:52,848 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:30:53,208 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:30:53,607 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:30:53,812 - INFO - validation batch 1, loss: 0.404, 32/6976 datapoints
2025-03-07 11:30:53,894 - INFO - validation batch 51, loss: 6.747, 1632/6976 datapoints
2025-03-07 11:30:53,974 - INFO - validation batch 101, loss: 1.426, 3232/6976 datapoints
2025-03-07 11:30:54,059 - INFO - validation batch 151, loss: 1.159, 4832/6976 datapoints
2025-03-07 11:30:54,147 - INFO - validation batch 201, loss: 4.404, 6432/6976 datapoints
2025-03-07 11:30:54,177 - INFO - Epoch 520/800 done.
2025-03-07 11:30:54,177 - INFO - Final validation performance:
Loss: 2.828, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:30:54,178 - INFO - Beginning epoch 521/800
2025-03-07 11:30:54,188 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:30:54,550 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:30:55,000 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:30:55,347 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:30:55,710 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:30:56,082 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:30:56,427 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:30:56,774 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:30:57,112 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:30:57,444 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:30:57,783 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:30:58,114 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:30:58,469 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:30:58,802 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:30:59,138 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:30:59,494 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:30:59,849 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:31:00,186 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:31:00,366 - INFO - validation batch 1, loss: 0.382, 32/6976 datapoints
2025-03-07 11:31:00,440 - INFO - validation batch 51, loss: 6.787, 1632/6976 datapoints
2025-03-07 11:31:00,510 - INFO - validation batch 101, loss: 1.454, 3232/6976 datapoints
2025-03-07 11:31:00,589 - INFO - validation batch 151, loss: 1.213, 4832/6976 datapoints
2025-03-07 11:31:00,657 - INFO - validation batch 201, loss: 4.431, 6432/6976 datapoints
2025-03-07 11:31:00,685 - INFO - Epoch 521/800 done.
2025-03-07 11:31:00,685 - INFO - Final validation performance:
Loss: 2.853, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:31:00,687 - INFO - Beginning epoch 522/800
2025-03-07 11:31:00,697 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:31:01,020 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:31:01,362 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:31:01,699 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:31:02,045 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:31:02,404 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:31:02,746 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:31:03,102 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:31:03,443 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:31:03,796 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:31:04,130 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:31:04,470 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:31:04,832 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:31:05,187 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:31:05,540 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:31:05,902 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:31:06,260 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:31:06,604 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:31:06,782 - INFO - validation batch 1, loss: 0.356, 32/6976 datapoints
2025-03-07 11:31:06,849 - INFO - validation batch 51, loss: 6.827, 1632/6976 datapoints
2025-03-07 11:31:06,918 - INFO - validation batch 101, loss: 1.490, 3232/6976 datapoints
2025-03-07 11:31:06,987 - INFO - validation batch 151, loss: 1.240, 4832/6976 datapoints
2025-03-07 11:31:07,054 - INFO - validation batch 201, loss: 4.456, 6432/6976 datapoints
2025-03-07 11:31:07,077 - INFO - Epoch 522/800 done.
2025-03-07 11:31:07,077 - INFO - Final validation performance:
Loss: 2.874, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:31:07,078 - INFO - Beginning epoch 523/800
2025-03-07 11:31:07,088 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:31:07,417 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:31:07,763 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:31:08,099 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:31:08,439 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:31:08,795 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:31:09,134 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:31:09,489 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:31:09,827 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:31:10,159 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:31:10,494 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:31:10,826 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:31:11,168 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:31:11,498 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:31:11,834 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:31:12,193 - INFO - training batch 751, loss: 0.707, 24032/28000 datapoints
2025-03-07 11:31:12,547 - INFO - training batch 801, loss: 0.110, 25632/28000 datapoints
2025-03-07 11:31:12,898 - INFO - training batch 851, loss: 0.183, 27232/28000 datapoints
2025-03-07 11:31:13,074 - INFO - validation batch 1, loss: 0.659, 32/6976 datapoints
2025-03-07 11:31:13,143 - INFO - validation batch 51, loss: 6.967, 1632/6976 datapoints
2025-03-07 11:31:13,208 - INFO - validation batch 101, loss: 2.091, 3232/6976 datapoints
2025-03-07 11:31:13,277 - INFO - validation batch 151, loss: 2.430, 4832/6976 datapoints
2025-03-07 11:31:13,344 - INFO - validation batch 201, loss: 3.200, 6432/6976 datapoints
2025-03-07 11:31:13,371 - INFO - Epoch 523/800 done.
2025-03-07 11:31:13,371 - INFO - Final validation performance:
Loss: 3.069, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 11:31:13,372 - INFO - Beginning epoch 524/800
2025-03-07 11:31:13,383 - INFO - training batch 1, loss: 0.215, 32/28000 datapoints
2025-03-07 11:31:13,743 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-07 11:31:14,095 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:31:14,446 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:31:14,784 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:31:15,147 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:31:15,493 - INFO - training batch 301, loss: 0.033, 9632/28000 datapoints
2025-03-07 11:31:15,842 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:31:16,176 - INFO - training batch 401, loss: 0.137, 12832/28000 datapoints
2025-03-07 11:31:16,515 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 11:31:16,845 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:31:17,174 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:31:17,513 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:31:17,865 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:31:18,209 - INFO - training batch 701, loss: 0.127, 22432/28000 datapoints
2025-03-07 11:31:18,551 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-07 11:31:18,905 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:31:19,242 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 11:31:19,412 - INFO - validation batch 1, loss: 0.386, 32/6976 datapoints
2025-03-07 11:31:19,483 - INFO - validation batch 51, loss: 7.493, 1632/6976 datapoints
2025-03-07 11:31:19,551 - INFO - validation batch 101, loss: 1.557, 3232/6976 datapoints
2025-03-07 11:31:19,620 - INFO - validation batch 151, loss: 2.731, 4832/6976 datapoints
2025-03-07 11:31:19,691 - INFO - validation batch 201, loss: 4.700, 6432/6976 datapoints
2025-03-07 11:31:19,716 - INFO - Epoch 524/800 done.
2025-03-07 11:31:19,716 - INFO - Final validation performance:
Loss: 3.373, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 11:31:19,717 - INFO - Beginning epoch 525/800
2025-03-07 11:31:19,727 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 11:31:20,065 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:31:20,411 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:31:20,758 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:31:21,087 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:31:21,448 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:31:21,794 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:31:22,139 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:31:22,477 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:31:22,820 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:31:23,164 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:31:23,496 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:31:23,852 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:31:24,204 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:31:24,548 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:31:24,892 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:31:25,243 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 11:31:25,586 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:31:25,765 - INFO - validation batch 1, loss: 0.382, 32/6976 datapoints
2025-03-07 11:31:25,834 - INFO - validation batch 51, loss: 6.968, 1632/6976 datapoints
2025-03-07 11:31:25,902 - INFO - validation batch 101, loss: 1.555, 3232/6976 datapoints
2025-03-07 11:31:25,976 - INFO - validation batch 151, loss: 1.124, 4832/6976 datapoints
2025-03-07 11:31:26,049 - INFO - validation batch 201, loss: 4.428, 6432/6976 datapoints
2025-03-07 11:31:26,079 - INFO - Epoch 525/800 done.
2025-03-07 11:31:26,079 - INFO - Final validation performance:
Loss: 2.892, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:31:26,080 - INFO - Beginning epoch 526/800
2025-03-07 11:31:26,090 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:31:26,421 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:31:26,766 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:31:27,106 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:31:27,444 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:31:27,799 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:31:28,145 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:31:28,492 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:31:28,831 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:31:29,168 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:31:29,503 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:31:29,829 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:31:30,175 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:31:30,539 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:31:30,886 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:31:31,243 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:31:31,607 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:31:31,966 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:31:32,146 - INFO - validation batch 1, loss: 0.506, 32/6976 datapoints
2025-03-07 11:31:32,213 - INFO - validation batch 51, loss: 6.874, 1632/6976 datapoints
2025-03-07 11:31:32,281 - INFO - validation batch 101, loss: 1.606, 3232/6976 datapoints
2025-03-07 11:31:32,352 - INFO - validation batch 151, loss: 1.263, 4832/6976 datapoints
2025-03-07 11:31:32,422 - INFO - validation batch 201, loss: 4.455, 6432/6976 datapoints
2025-03-07 11:31:32,448 - INFO - Epoch 526/800 done.
2025-03-07 11:31:32,449 - INFO - Final validation performance:
Loss: 2.941, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:31:32,450 - INFO - Beginning epoch 527/800
2025-03-07 11:31:32,460 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:31:32,781 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:31:33,130 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:31:33,485 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:31:33,833 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:31:34,220 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:31:34,569 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:31:34,904 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:31:35,274 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:31:35,612 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:31:35,950 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:31:36,270 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:31:36,612 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:31:36,949 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:31:37,287 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:31:37,642 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:31:38,003 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:31:38,348 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:31:38,528 - INFO - validation batch 1, loss: 0.460, 32/6976 datapoints
2025-03-07 11:31:38,598 - INFO - validation batch 51, loss: 6.758, 1632/6976 datapoints
2025-03-07 11:31:38,665 - INFO - validation batch 101, loss: 1.591, 3232/6976 datapoints
2025-03-07 11:31:38,735 - INFO - validation batch 151, loss: 1.319, 4832/6976 datapoints
2025-03-07 11:31:38,806 - INFO - validation batch 201, loss: 4.576, 6432/6976 datapoints
2025-03-07 11:31:38,831 - INFO - Epoch 527/800 done.
2025-03-07 11:31:38,831 - INFO - Final validation performance:
Loss: 2.941, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:31:38,832 - INFO - Beginning epoch 528/800
2025-03-07 11:31:38,843 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:31:39,173 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:31:39,525 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:31:39,870 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:31:40,208 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:31:40,571 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:31:40,922 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:31:41,262 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:31:41,604 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:31:41,946 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:31:42,287 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:31:42,618 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:31:42,959 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:31:43,292 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:31:43,665 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:31:44,045 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:31:44,408 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:31:44,750 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:31:44,927 - INFO - validation batch 1, loss: 0.480, 32/6976 datapoints
2025-03-07 11:31:44,997 - INFO - validation batch 51, loss: 6.801, 1632/6976 datapoints
2025-03-07 11:31:45,067 - INFO - validation batch 101, loss: 1.541, 3232/6976 datapoints
2025-03-07 11:31:45,134 - INFO - validation batch 151, loss: 1.286, 4832/6976 datapoints
2025-03-07 11:31:45,203 - INFO - validation batch 201, loss: 4.455, 6432/6976 datapoints
2025-03-07 11:31:45,227 - INFO - Epoch 528/800 done.
2025-03-07 11:31:45,227 - INFO - Final validation performance:
Loss: 2.913, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:31:45,228 - INFO - Beginning epoch 529/800
2025-03-07 11:31:45,241 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:31:45,565 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:31:45,920 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:31:46,275 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:31:46,621 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:31:46,985 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:31:47,351 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:31:47,698 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:31:48,037 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:31:48,381 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:31:48,723 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:31:49,046 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:31:49,395 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:31:49,739 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:31:50,083 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:31:50,449 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:31:50,828 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:31:51,169 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:31:51,348 - INFO - validation batch 1, loss: 0.482, 32/6976 datapoints
2025-03-07 11:31:51,423 - INFO - validation batch 51, loss: 6.825, 1632/6976 datapoints
2025-03-07 11:31:51,494 - INFO - validation batch 101, loss: 1.517, 3232/6976 datapoints
2025-03-07 11:31:51,565 - INFO - validation batch 151, loss: 1.276, 4832/6976 datapoints
2025-03-07 11:31:51,633 - INFO - validation batch 201, loss: 4.447, 6432/6976 datapoints
2025-03-07 11:31:51,658 - INFO - Epoch 529/800 done.
2025-03-07 11:31:51,658 - INFO - Final validation performance:
Loss: 2.909, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:31:51,659 - INFO - Beginning epoch 530/800
2025-03-07 11:31:51,670 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:31:51,986 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:31:52,335 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:31:52,677 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:31:53,008 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:31:53,367 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:31:53,710 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:31:54,070 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:31:54,405 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:31:54,747 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:31:55,086 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:31:55,412 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:31:55,755 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:31:56,094 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:31:56,435 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:31:56,787 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:31:57,149 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:31:57,501 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:31:57,686 - INFO - validation batch 1, loss: 0.489, 32/6976 datapoints
2025-03-07 11:31:57,752 - INFO - validation batch 51, loss: 6.847, 1632/6976 datapoints
2025-03-07 11:31:57,818 - INFO - validation batch 101, loss: 1.500, 3232/6976 datapoints
2025-03-07 11:31:57,885 - INFO - validation batch 151, loss: 1.243, 4832/6976 datapoints
2025-03-07 11:31:57,950 - INFO - validation batch 201, loss: 4.449, 6432/6976 datapoints
2025-03-07 11:31:57,973 - INFO - Epoch 530/800 done.
2025-03-07 11:31:57,973 - INFO - Final validation performance:
Loss: 2.905, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:31:57,974 - INFO - Beginning epoch 531/800
2025-03-07 11:31:57,984 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:31:58,310 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:31:58,667 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:31:59,010 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:31:59,343 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:31:59,707 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:32:00,049 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:32:00,415 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:32:00,750 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:32:01,088 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:32:01,426 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:32:01,754 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:32:02,098 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:32:02,426 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:32:02,763 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:32:03,112 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:32:03,471 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:32:03,821 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:32:04,004 - INFO - validation batch 1, loss: 0.488, 32/6976 datapoints
2025-03-07 11:32:04,080 - INFO - validation batch 51, loss: 6.863, 1632/6976 datapoints
2025-03-07 11:32:04,166 - INFO - validation batch 101, loss: 1.486, 3232/6976 datapoints
2025-03-07 11:32:04,235 - INFO - validation batch 151, loss: 1.208, 4832/6976 datapoints
2025-03-07 11:32:04,302 - INFO - validation batch 201, loss: 4.468, 6432/6976 datapoints
2025-03-07 11:32:04,327 - INFO - Epoch 531/800 done.
2025-03-07 11:32:04,327 - INFO - Final validation performance:
Loss: 2.903, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:32:04,328 - INFO - Beginning epoch 532/800
2025-03-07 11:32:04,340 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:32:04,668 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:32:05,023 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:32:05,366 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:32:05,705 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:32:06,073 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:32:06,453 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:32:06,801 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:32:07,142 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:32:07,490 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:32:07,832 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:32:08,168 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:32:08,538 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:32:08,901 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:32:09,243 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:32:09,600 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:32:09,973 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:32:10,344 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:32:10,531 - INFO - validation batch 1, loss: 0.478, 32/6976 datapoints
2025-03-07 11:32:10,600 - INFO - validation batch 51, loss: 6.886, 1632/6976 datapoints
2025-03-07 11:32:10,668 - INFO - validation batch 101, loss: 1.476, 3232/6976 datapoints
2025-03-07 11:32:10,736 - INFO - validation batch 151, loss: 1.187, 4832/6976 datapoints
2025-03-07 11:32:10,803 - INFO - validation batch 201, loss: 4.500, 6432/6976 datapoints
2025-03-07 11:32:10,830 - INFO - Epoch 532/800 done.
2025-03-07 11:32:10,831 - INFO - Final validation performance:
Loss: 2.905, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:32:10,831 - INFO - Beginning epoch 533/800
2025-03-07 11:32:10,840 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:32:11,170 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:32:11,529 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:32:11,866 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:32:12,214 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:32:12,584 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:32:12,930 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:32:13,274 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:32:13,616 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:32:13,954 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:32:14,316 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:32:14,653 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:32:15,007 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:32:15,369 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:32:15,715 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:32:16,078 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:32:16,439 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:32:16,785 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:32:16,971 - INFO - validation batch 1, loss: 0.457, 32/6976 datapoints
2025-03-07 11:32:17,039 - INFO - validation batch 51, loss: 6.913, 1632/6976 datapoints
2025-03-07 11:32:17,105 - INFO - validation batch 101, loss: 1.473, 3232/6976 datapoints
2025-03-07 11:32:17,172 - INFO - validation batch 151, loss: 1.183, 4832/6976 datapoints
2025-03-07 11:32:17,240 - INFO - validation batch 201, loss: 4.542, 6432/6976 datapoints
2025-03-07 11:32:17,267 - INFO - Epoch 533/800 done.
2025-03-07 11:32:17,267 - INFO - Final validation performance:
Loss: 2.913, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:32:17,268 - INFO - Beginning epoch 534/800
2025-03-07 11:32:17,278 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:32:17,610 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:32:17,964 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:32:18,312 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:32:18,653 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:32:19,015 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:32:19,357 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:32:19,706 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:32:20,040 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:32:20,375 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:32:20,718 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:32:21,048 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:32:21,394 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:32:21,729 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:32:22,066 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:32:22,421 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:32:22,780 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:32:23,123 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:32:23,305 - INFO - validation batch 1, loss: 0.434, 32/6976 datapoints
2025-03-07 11:32:23,374 - INFO - validation batch 51, loss: 6.941, 1632/6976 datapoints
2025-03-07 11:32:23,446 - INFO - validation batch 101, loss: 1.478, 3232/6976 datapoints
2025-03-07 11:32:23,515 - INFO - validation batch 151, loss: 1.193, 4832/6976 datapoints
2025-03-07 11:32:23,583 - INFO - validation batch 201, loss: 4.583, 6432/6976 datapoints
2025-03-07 11:32:23,612 - INFO - Epoch 534/800 done.
2025-03-07 11:32:23,613 - INFO - Final validation performance:
Loss: 2.926, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:32:23,613 - INFO - Beginning epoch 535/800
2025-03-07 11:32:23,625 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:32:23,948 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:32:24,320 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:32:24,678 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:32:25,020 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:32:25,388 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:32:25,736 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:32:26,098 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:32:26,440 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:32:26,777 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:32:27,119 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:32:27,456 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:32:27,813 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:32:28,147 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:32:28,490 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:32:28,841 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:32:29,201 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:32:29,543 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:32:29,726 - INFO - validation batch 1, loss: 0.415, 32/6976 datapoints
2025-03-07 11:32:29,794 - INFO - validation batch 51, loss: 6.962, 1632/6976 datapoints
2025-03-07 11:32:29,864 - INFO - validation batch 101, loss: 1.489, 3232/6976 datapoints
2025-03-07 11:32:29,932 - INFO - validation batch 151, loss: 1.207, 4832/6976 datapoints
2025-03-07 11:32:30,001 - INFO - validation batch 201, loss: 4.603, 6432/6976 datapoints
2025-03-07 11:32:30,028 - INFO - Epoch 535/800 done.
2025-03-07 11:32:30,028 - INFO - Final validation performance:
Loss: 2.935, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:32:30,029 - INFO - Beginning epoch 536/800
2025-03-07 11:32:30,039 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:32:30,367 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:32:30,760 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:32:31,104 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:32:31,460 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:32:31,873 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:32:32,226 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:32:32,587 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:32:32,931 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:32:33,268 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:32:33,616 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:32:33,952 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:32:34,307 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:32:34,695 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:32:35,042 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:32:35,399 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:32:35,763 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:32:36,109 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:32:36,298 - INFO - validation batch 1, loss: 0.395, 32/6976 datapoints
2025-03-07 11:32:36,365 - INFO - validation batch 51, loss: 6.970, 1632/6976 datapoints
2025-03-07 11:32:36,439 - INFO - validation batch 101, loss: 1.503, 3232/6976 datapoints
2025-03-07 11:32:36,509 - INFO - validation batch 151, loss: 1.199, 4832/6976 datapoints
2025-03-07 11:32:36,576 - INFO - validation batch 201, loss: 4.623, 6432/6976 datapoints
2025-03-07 11:32:36,604 - INFO - Epoch 536/800 done.
2025-03-07 11:32:36,604 - INFO - Final validation performance:
Loss: 2.938, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:32:36,604 - INFO - Beginning epoch 537/800
2025-03-07 11:32:36,613 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:32:36,932 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:32:37,294 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:32:37,644 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:32:37,989 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:32:38,354 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:32:38,711 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:32:39,065 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:32:39,405 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:32:39,742 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:32:40,086 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:32:40,423 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:32:40,772 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:32:41,111 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:32:41,460 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:32:41,815 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:32:42,176 - INFO - training batch 801, loss: 0.090, 25632/28000 datapoints
2025-03-07 11:32:42,534 - INFO - training batch 851, loss: 0.192, 27232/28000 datapoints
2025-03-07 11:32:42,713 - INFO - validation batch 1, loss: 0.749, 32/6976 datapoints
2025-03-07 11:32:42,782 - INFO - validation batch 51, loss: 6.761, 1632/6976 datapoints
2025-03-07 11:32:42,852 - INFO - validation batch 101, loss: 2.035, 3232/6976 datapoints
2025-03-07 11:32:42,919 - INFO - validation batch 151, loss: 1.867, 4832/6976 datapoints
2025-03-07 11:32:42,987 - INFO - validation batch 201, loss: 3.950, 6432/6976 datapoints
2025-03-07 11:32:43,015 - INFO - Epoch 537/800 done.
2025-03-07 11:32:43,015 - INFO - Final validation performance:
Loss: 3.072, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:32:43,016 - INFO - Beginning epoch 538/800
2025-03-07 11:32:43,025 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-07 11:32:43,353 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:32:43,688 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:32:44,036 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:32:44,394 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:32:44,777 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 11:32:45,143 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:32:45,503 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:32:45,846 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:32:46,202 - INFO - training batch 451, loss: 0.243, 14432/28000 datapoints
2025-03-07 11:32:46,544 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:32:46,883 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:32:47,230 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:32:47,577 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:32:47,921 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:32:48,265 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:32:48,624 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:32:48,964 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-07 11:32:49,142 - INFO - validation batch 1, loss: 1.104, 32/6976 datapoints
2025-03-07 11:32:49,211 - INFO - validation batch 51, loss: 7.114, 1632/6976 datapoints
2025-03-07 11:32:49,277 - INFO - validation batch 101, loss: 1.603, 3232/6976 datapoints
2025-03-07 11:32:49,344 - INFO - validation batch 151, loss: 0.883, 4832/6976 datapoints
2025-03-07 11:32:49,416 - INFO - validation batch 201, loss: 4.038, 6432/6976 datapoints
2025-03-07 11:32:49,442 - INFO - Epoch 538/800 done.
2025-03-07 11:32:49,442 - INFO - Final validation performance:
Loss: 2.948, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:32:49,443 - INFO - Beginning epoch 539/800
2025-03-07 11:32:49,451 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:32:49,779 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:32:50,118 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:32:50,456 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:32:50,810 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:32:51,173 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-07 11:32:51,545 - INFO - training batch 301, loss: 0.065, 9632/28000 datapoints
2025-03-07 11:32:51,910 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:32:52,250 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:32:52,603 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:32:52,959 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:32:53,295 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:32:53,654 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:32:54,000 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:32:54,350 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:32:54,727 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:32:55,101 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:32:55,455 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:32:55,640 - INFO - validation batch 1, loss: 0.251, 32/6976 datapoints
2025-03-07 11:32:55,709 - INFO - validation batch 51, loss: 5.637, 1632/6976 datapoints
2025-03-07 11:32:55,775 - INFO - validation batch 101, loss: 1.375, 3232/6976 datapoints
2025-03-07 11:32:55,843 - INFO - validation batch 151, loss: 1.674, 4832/6976 datapoints
2025-03-07 11:32:55,912 - INFO - validation batch 201, loss: 4.786, 6432/6976 datapoints
2025-03-07 11:32:55,937 - INFO - Epoch 539/800 done.
2025-03-07 11:32:55,937 - INFO - Final validation performance:
Loss: 2.745, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:32:55,938 - INFO - Beginning epoch 540/800
2025-03-07 11:32:55,951 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-07 11:32:56,290 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:32:56,657 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:32:56,993 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:32:57,328 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:32:57,698 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:32:58,054 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:32:58,399 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:32:58,736 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:32:59,070 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:32:59,406 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:32:59,747 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:33:00,093 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:33:00,425 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:33:00,766 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:33:01,110 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:33:01,473 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:33:01,820 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:33:02,005 - INFO - validation batch 1, loss: 0.216, 32/6976 datapoints
2025-03-07 11:33:02,072 - INFO - validation batch 51, loss: 6.571, 1632/6976 datapoints
2025-03-07 11:33:02,139 - INFO - validation batch 101, loss: 1.326, 3232/6976 datapoints
2025-03-07 11:33:02,206 - INFO - validation batch 151, loss: 1.428, 4832/6976 datapoints
2025-03-07 11:33:02,272 - INFO - validation batch 201, loss: 4.690, 6432/6976 datapoints
2025-03-07 11:33:02,301 - INFO - Epoch 540/800 done.
2025-03-07 11:33:02,302 - INFO - Final validation performance:
Loss: 2.846, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:33:02,302 - INFO - Beginning epoch 541/800
2025-03-07 11:33:02,312 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:33:02,644 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:33:03,002 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:33:03,340 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:33:03,682 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:33:04,044 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:33:04,412 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:33:04,772 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:33:05,139 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:33:05,487 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:33:05,834 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:33:06,184 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:33:06,531 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:33:06,859 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:33:07,196 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:33:07,541 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:33:07,908 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:33:08,247 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:33:08,431 - INFO - validation batch 1, loss: 0.264, 32/6976 datapoints
2025-03-07 11:33:08,500 - INFO - validation batch 51, loss: 6.710, 1632/6976 datapoints
2025-03-07 11:33:08,570 - INFO - validation batch 101, loss: 1.335, 3232/6976 datapoints
2025-03-07 11:33:08,637 - INFO - validation batch 151, loss: 1.125, 4832/6976 datapoints
2025-03-07 11:33:08,705 - INFO - validation batch 201, loss: 4.431, 6432/6976 datapoints
2025-03-07 11:33:08,731 - INFO - Epoch 541/800 done.
2025-03-07 11:33:08,731 - INFO - Final validation performance:
Loss: 2.773, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:33:08,732 - INFO - Beginning epoch 542/800
2025-03-07 11:33:08,744 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:33:09,058 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:33:09,417 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:33:09,757 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:33:10,093 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:33:10,458 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:33:10,818 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:33:11,167 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:33:11,513 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:33:11,854 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:33:12,199 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:33:12,555 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:33:12,906 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:33:13,239 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:33:13,585 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:33:13,929 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:33:14,291 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:33:14,638 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:33:14,819 - INFO - validation batch 1, loss: 0.315, 32/6976 datapoints
2025-03-07 11:33:14,900 - INFO - validation batch 51, loss: 6.758, 1632/6976 datapoints
2025-03-07 11:33:14,984 - INFO - validation batch 101, loss: 1.332, 3232/6976 datapoints
2025-03-07 11:33:15,057 - INFO - validation batch 151, loss: 1.027, 4832/6976 datapoints
2025-03-07 11:33:15,126 - INFO - validation batch 201, loss: 4.430, 6432/6976 datapoints
2025-03-07 11:33:15,153 - INFO - Epoch 542/800 done.
2025-03-07 11:33:15,153 - INFO - Final validation performance:
Loss: 2.772, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:33:15,154 - INFO - Beginning epoch 543/800
2025-03-07 11:33:15,165 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:33:15,485 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:33:15,836 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:33:16,176 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:33:16,515 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:33:16,876 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:33:17,232 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:33:17,581 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:33:17,925 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:33:18,262 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:33:18,607 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:33:18,950 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:33:19,296 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:33:19,635 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:33:19,978 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:33:20,328 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:33:20,696 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:33:21,044 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:33:21,224 - INFO - validation batch 1, loss: 0.334, 32/6976 datapoints
2025-03-07 11:33:21,292 - INFO - validation batch 51, loss: 6.803, 1632/6976 datapoints
2025-03-07 11:33:21,360 - INFO - validation batch 101, loss: 1.318, 3232/6976 datapoints
2025-03-07 11:33:21,431 - INFO - validation batch 151, loss: 0.962, 4832/6976 datapoints
2025-03-07 11:33:21,502 - INFO - validation batch 201, loss: 4.430, 6432/6976 datapoints
2025-03-07 11:33:21,527 - INFO - Epoch 543/800 done.
2025-03-07 11:33:21,528 - INFO - Final validation performance:
Loss: 2.770, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:33:21,528 - INFO - Beginning epoch 544/800
2025-03-07 11:33:21,541 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:33:21,866 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:33:22,216 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:33:22,561 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:33:22,897 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:33:23,256 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:33:23,617 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:33:23,961 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:33:24,300 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:33:24,636 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:33:24,979 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:33:25,341 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:33:25,692 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:33:26,037 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:33:26,404 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:33:26,755 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:33:27,119 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:33:27,469 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:33:27,655 - INFO - validation batch 1, loss: 0.354, 32/6976 datapoints
2025-03-07 11:33:27,725 - INFO - validation batch 51, loss: 6.841, 1632/6976 datapoints
2025-03-07 11:33:27,793 - INFO - validation batch 101, loss: 1.316, 3232/6976 datapoints
2025-03-07 11:33:27,859 - INFO - validation batch 151, loss: 0.895, 4832/6976 datapoints
2025-03-07 11:33:27,928 - INFO - validation batch 201, loss: 4.422, 6432/6976 datapoints
2025-03-07 11:33:27,953 - INFO - Epoch 544/800 done.
2025-03-07 11:33:27,954 - INFO - Final validation performance:
Loss: 2.766, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:33:27,954 - INFO - Beginning epoch 545/800
2025-03-07 11:33:27,966 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:33:28,291 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:33:28,652 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:33:28,998 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:33:29,336 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:33:29,703 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:33:30,061 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:33:30,427 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:33:30,771 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:33:31,107 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:33:31,444 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:33:31,794 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:33:32,140 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:33:32,477 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:33:32,817 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:33:33,161 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:33:33,519 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:33:33,867 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:33:34,054 - INFO - validation batch 1, loss: 0.377, 32/6976 datapoints
2025-03-07 11:33:34,123 - INFO - validation batch 51, loss: 6.872, 1632/6976 datapoints
2025-03-07 11:33:34,190 - INFO - validation batch 101, loss: 1.315, 3232/6976 datapoints
2025-03-07 11:33:34,259 - INFO - validation batch 151, loss: 0.833, 4832/6976 datapoints
2025-03-07 11:33:34,326 - INFO - validation batch 201, loss: 4.430, 6432/6976 datapoints
2025-03-07 11:33:34,353 - INFO - Epoch 545/800 done.
2025-03-07 11:33:34,353 - INFO - Final validation performance:
Loss: 2.765, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:33:34,355 - INFO - Beginning epoch 546/800
2025-03-07 11:33:34,365 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:33:34,690 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:33:35,057 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:33:35,425 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:33:35,771 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:33:36,183 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:33:36,562 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:33:36,913 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:33:37,256 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:33:37,606 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:33:37,960 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:33:38,300 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:33:38,659 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:33:39,000 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:33:39,341 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:33:39,692 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:33:40,050 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:33:40,396 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:33:40,584 - INFO - validation batch 1, loss: 0.402, 32/6976 datapoints
2025-03-07 11:33:40,651 - INFO - validation batch 51, loss: 6.905, 1632/6976 datapoints
2025-03-07 11:33:40,718 - INFO - validation batch 101, loss: 1.316, 3232/6976 datapoints
2025-03-07 11:33:40,786 - INFO - validation batch 151, loss: 0.784, 4832/6976 datapoints
2025-03-07 11:33:40,853 - INFO - validation batch 201, loss: 4.443, 6432/6976 datapoints
2025-03-07 11:33:40,876 - INFO - Epoch 546/800 done.
2025-03-07 11:33:40,877 - INFO - Final validation performance:
Loss: 2.770, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:33:40,878 - INFO - Beginning epoch 547/800
2025-03-07 11:33:40,891 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:33:41,209 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:33:41,571 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:33:41,907 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:33:42,245 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:33:42,614 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:33:42,972 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:33:43,324 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:33:43,668 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:33:44,002 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:33:44,345 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:33:44,689 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:33:45,055 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:33:45,420 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:33:45,763 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:33:46,108 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:33:46,468 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:33:46,822 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:33:47,007 - INFO - validation batch 1, loss: 0.422, 32/6976 datapoints
2025-03-07 11:33:47,074 - INFO - validation batch 51, loss: 6.946, 1632/6976 datapoints
2025-03-07 11:33:47,143 - INFO - validation batch 101, loss: 1.319, 3232/6976 datapoints
2025-03-07 11:33:47,211 - INFO - validation batch 151, loss: 0.759, 4832/6976 datapoints
2025-03-07 11:33:47,278 - INFO - validation batch 201, loss: 4.463, 6432/6976 datapoints
2025-03-07 11:33:47,300 - INFO - Epoch 547/800 done.
2025-03-07 11:33:47,301 - INFO - Final validation performance:
Loss: 2.782, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:33:47,301 - INFO - Beginning epoch 548/800
2025-03-07 11:33:47,314 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:33:47,642 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:33:47,998 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:33:48,339 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:33:48,686 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:33:49,059 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:33:49,418 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:33:49,771 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:33:50,116 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:33:50,453 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:33:50,804 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:33:51,146 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:33:51,521 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:33:51,898 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:33:52,238 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:33:52,589 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:33:52,946 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:33:53,289 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:33:53,479 - INFO - validation batch 1, loss: 0.422, 32/6976 datapoints
2025-03-07 11:33:53,551 - INFO - validation batch 51, loss: 7.012, 1632/6976 datapoints
2025-03-07 11:33:53,619 - INFO - validation batch 101, loss: 1.324, 3232/6976 datapoints
2025-03-07 11:33:53,688 - INFO - validation batch 151, loss: 0.774, 4832/6976 datapoints
2025-03-07 11:33:53,756 - INFO - validation batch 201, loss: 4.482, 6432/6976 datapoints
2025-03-07 11:33:53,778 - INFO - Epoch 548/800 done.
2025-03-07 11:33:53,778 - INFO - Final validation performance:
Loss: 2.803, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:33:53,779 - INFO - Beginning epoch 549/800
2025-03-07 11:33:53,789 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:33:54,116 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:33:54,477 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:33:54,826 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:33:55,172 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:33:55,553 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:33:55,914 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:33:56,269 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:33:56,618 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:33:56,955 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:33:57,301 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:33:57,645 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:33:58,005 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:33:58,346 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:33:58,695 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:33:59,041 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:33:59,414 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:33:59,758 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:33:59,941 - INFO - validation batch 1, loss: 0.397, 32/6976 datapoints
2025-03-07 11:34:00,010 - INFO - validation batch 51, loss: 7.087, 1632/6976 datapoints
2025-03-07 11:34:00,081 - INFO - validation batch 101, loss: 1.340, 3232/6976 datapoints
2025-03-07 11:34:00,147 - INFO - validation batch 151, loss: 0.827, 4832/6976 datapoints
2025-03-07 11:34:00,215 - INFO - validation batch 201, loss: 4.514, 6432/6976 datapoints
2025-03-07 11:34:00,244 - INFO - Epoch 549/800 done.
2025-03-07 11:34:00,244 - INFO - Final validation performance:
Loss: 2.833, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:34:00,245 - INFO - Beginning epoch 550/800
2025-03-07 11:34:00,254 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:34:00,585 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:34:00,937 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:34:01,278 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:34:01,622 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:34:01,990 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:34:02,350 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:34:02,707 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:34:03,052 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:34:03,393 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:34:03,752 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:34:04,095 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:34:04,448 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:34:04,789 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:34:05,135 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:34:05,495 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:34:05,864 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:34:06,212 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:34:06,402 - INFO - validation batch 1, loss: 0.357, 32/6976 datapoints
2025-03-07 11:34:06,471 - INFO - validation batch 51, loss: 7.122, 1632/6976 datapoints
2025-03-07 11:34:06,539 - INFO - validation batch 101, loss: 1.374, 3232/6976 datapoints
2025-03-07 11:34:06,608 - INFO - validation batch 151, loss: 0.895, 4832/6976 datapoints
2025-03-07 11:34:06,676 - INFO - validation batch 201, loss: 4.554, 6432/6976 datapoints
2025-03-07 11:34:06,706 - INFO - Epoch 550/800 done.
2025-03-07 11:34:06,706 - INFO - Final validation performance:
Loss: 2.860, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:34:06,707 - INFO - Beginning epoch 551/800
2025-03-07 11:34:06,716 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:34:07,049 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:34:07,410 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:34:07,760 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:34:08,108 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:34:08,477 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:34:08,848 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:34:09,204 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:34:09,547 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:34:09,883 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:34:10,229 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:34:10,573 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:34:10,924 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:34:11,261 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:34:11,605 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:34:11,955 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:34:12,313 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:34:12,660 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:34:12,845 - INFO - validation batch 1, loss: 0.331, 32/6976 datapoints
2025-03-07 11:34:12,915 - INFO - validation batch 51, loss: 7.139, 1632/6976 datapoints
2025-03-07 11:34:12,982 - INFO - validation batch 101, loss: 1.433, 3232/6976 datapoints
2025-03-07 11:34:13,050 - INFO - validation batch 151, loss: 0.965, 4832/6976 datapoints
2025-03-07 11:34:13,119 - INFO - validation batch 201, loss: 4.593, 6432/6976 datapoints
2025-03-07 11:34:13,143 - INFO - Epoch 551/800 done.
2025-03-07 11:34:13,143 - INFO - Final validation performance:
Loss: 2.892, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:34:13,144 - INFO - Beginning epoch 552/800
2025-03-07 11:34:13,157 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:34:13,488 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:34:13,841 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:34:14,191 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:34:14,540 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:34:14,907 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:34:15,265 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:34:15,641 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:34:15,985 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:34:16,326 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:34:16,687 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:34:17,024 - INFO - training batch 551, loss: 0.059, 17632/28000 datapoints
2025-03-07 11:34:17,386 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:34:17,741 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 11:34:18,085 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:34:18,435 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:34:18,783 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-07 11:34:19,135 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:34:19,322 - INFO - validation batch 1, loss: 0.707, 32/6976 datapoints
2025-03-07 11:34:19,392 - INFO - validation batch 51, loss: 6.415, 1632/6976 datapoints
2025-03-07 11:34:19,461 - INFO - validation batch 101, loss: 1.688, 3232/6976 datapoints
2025-03-07 11:34:19,529 - INFO - validation batch 151, loss: 0.898, 4832/6976 datapoints
2025-03-07 11:34:19,601 - INFO - validation batch 201, loss: 5.084, 6432/6976 datapoints
2025-03-07 11:34:19,625 - INFO - Epoch 552/800 done.
2025-03-07 11:34:19,625 - INFO - Final validation performance:
Loss: 2.958, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:34:19,626 - INFO - Beginning epoch 553/800
2025-03-07 11:34:19,638 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:34:19,964 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:34:20,307 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:34:20,647 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:34:20,983 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-07 11:34:21,342 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:34:21,701 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 11:34:22,073 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:34:22,420 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:34:22,755 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:34:23,100 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:34:23,446 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:34:23,792 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:34:24,140 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:34:24,499 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:34:24,842 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:34:25,207 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:34:25,563 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:34:25,765 - INFO - validation batch 1, loss: 0.452, 32/6976 datapoints
2025-03-07 11:34:25,835 - INFO - validation batch 51, loss: 6.392, 1632/6976 datapoints
2025-03-07 11:34:25,901 - INFO - validation batch 101, loss: 2.201, 3232/6976 datapoints
2025-03-07 11:34:25,967 - INFO - validation batch 151, loss: 1.313, 4832/6976 datapoints
2025-03-07 11:34:26,090 - INFO - validation batch 201, loss: 4.985, 6432/6976 datapoints
2025-03-07 11:34:26,113 - INFO - Epoch 553/800 done.
2025-03-07 11:34:26,113 - INFO - Final validation performance:
Loss: 3.069, top-1 acc: 0.873top-5 acc: 0.873
2025-03-07 11:34:26,113 - INFO - Beginning epoch 554/800
2025-03-07 11:34:26,133 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 11:34:26,495 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:34:26,857 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-07 11:34:27,202 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 11:34:27,564 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:34:27,918 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-07 11:34:28,263 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:34:28,636 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:34:28,983 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 11:34:29,314 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-07 11:34:29,673 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:34:30,026 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:34:30,359 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:34:30,734 - INFO - training batch 651, loss: 0.070, 20832/28000 datapoints
2025-03-07 11:34:31,092 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:34:31,436 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:34:31,777 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:34:32,137 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:34:32,315 - INFO - validation batch 1, loss: 0.486, 32/6976 datapoints
2025-03-07 11:34:32,388 - INFO - validation batch 51, loss: 7.497, 1632/6976 datapoints
2025-03-07 11:34:32,456 - INFO - validation batch 101, loss: 1.411, 3232/6976 datapoints
2025-03-07 11:34:32,526 - INFO - validation batch 151, loss: 0.666, 4832/6976 datapoints
2025-03-07 11:34:32,596 - INFO - validation batch 201, loss: 4.605, 6432/6976 datapoints
2025-03-07 11:34:32,618 - INFO - Epoch 554/800 done.
2025-03-07 11:34:32,618 - INFO - Final validation performance:
Loss: 2.933, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:34:32,619 - INFO - Beginning epoch 555/800
2025-03-07 11:34:32,628 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:34:32,957 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:34:33,311 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 11:34:33,653 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:34:33,999 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:34:34,360 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:34:34,717 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:34:35,080 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:34:35,446 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:34:35,813 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:34:36,163 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:34:36,556 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:34:36,914 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:34:37,245 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:34:37,600 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:34:37,999 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:34:38,365 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:34:38,712 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:34:38,899 - INFO - validation batch 1, loss: 0.495, 32/6976 datapoints
2025-03-07 11:34:38,967 - INFO - validation batch 51, loss: 6.766, 1632/6976 datapoints
2025-03-07 11:34:39,035 - INFO - validation batch 101, loss: 1.488, 3232/6976 datapoints
2025-03-07 11:34:39,102 - INFO - validation batch 151, loss: 0.517, 4832/6976 datapoints
2025-03-07 11:34:39,172 - INFO - validation batch 201, loss: 4.307, 6432/6976 datapoints
2025-03-07 11:34:39,196 - INFO - Epoch 555/800 done.
2025-03-07 11:34:39,196 - INFO - Final validation performance:
Loss: 2.714, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:34:39,197 - INFO - Beginning epoch 556/800
2025-03-07 11:34:39,208 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:34:39,531 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:34:39,901 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:34:40,247 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:34:40,606 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:34:40,980 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:34:41,338 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:34:41,703 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:34:42,042 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:34:42,386 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:34:42,746 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:34:43,086 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:34:43,436 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:34:43,790 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:34:44,143 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:34:44,497 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:34:44,874 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:34:45,228 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:34:45,430 - INFO - validation batch 1, loss: 0.388, 32/6976 datapoints
2025-03-07 11:34:45,510 - INFO - validation batch 51, loss: 6.957, 1632/6976 datapoints
2025-03-07 11:34:45,580 - INFO - validation batch 101, loss: 1.484, 3232/6976 datapoints
2025-03-07 11:34:45,648 - INFO - validation batch 151, loss: 0.730, 4832/6976 datapoints
2025-03-07 11:34:45,717 - INFO - validation batch 201, loss: 4.367, 6432/6976 datapoints
2025-03-07 11:34:45,742 - INFO - Epoch 556/800 done.
2025-03-07 11:34:45,743 - INFO - Final validation performance:
Loss: 2.785, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:34:45,744 - INFO - Beginning epoch 557/800
2025-03-07 11:34:45,754 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:34:46,101 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:34:46,463 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:34:46,816 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:34:47,162 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:34:47,533 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:34:47,891 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:34:48,242 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:34:48,586 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:34:48,929 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:34:49,275 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:34:49,624 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:34:49,961 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:34:50,296 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:34:50,652 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:34:51,008 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:34:51,375 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:34:51,726 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:34:51,909 - INFO - validation batch 1, loss: 0.370, 32/6976 datapoints
2025-03-07 11:34:51,975 - INFO - validation batch 51, loss: 6.639, 1632/6976 datapoints
2025-03-07 11:34:52,045 - INFO - validation batch 101, loss: 1.506, 3232/6976 datapoints
2025-03-07 11:34:52,112 - INFO - validation batch 151, loss: 0.794, 4832/6976 datapoints
2025-03-07 11:34:52,179 - INFO - validation batch 201, loss: 4.376, 6432/6976 datapoints
2025-03-07 11:34:52,206 - INFO - Epoch 557/800 done.
2025-03-07 11:34:52,206 - INFO - Final validation performance:
Loss: 2.737, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:34:52,207 - INFO - Beginning epoch 558/800
2025-03-07 11:34:52,216 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:34:52,533 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:34:52,898 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:34:53,238 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:34:53,586 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:34:53,951 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:34:54,307 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:34:54,658 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:34:54,994 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:34:55,339 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:34:55,683 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:34:56,046 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:34:56,393 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:34:56,738 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:34:57,098 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:34:57,455 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:34:57,833 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:34:58,176 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:34:58,361 - INFO - validation batch 1, loss: 0.396, 32/6976 datapoints
2025-03-07 11:34:58,437 - INFO - validation batch 51, loss: 6.673, 1632/6976 datapoints
2025-03-07 11:34:58,504 - INFO - validation batch 101, loss: 1.502, 3232/6976 datapoints
2025-03-07 11:34:58,571 - INFO - validation batch 151, loss: 0.788, 4832/6976 datapoints
2025-03-07 11:34:58,639 - INFO - validation batch 201, loss: 4.389, 6432/6976 datapoints
2025-03-07 11:34:58,662 - INFO - Epoch 558/800 done.
2025-03-07 11:34:58,663 - INFO - Final validation performance:
Loss: 2.750, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:34:58,664 - INFO - Beginning epoch 559/800
2025-03-07 11:34:58,674 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:34:59,007 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:34:59,370 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:34:59,723 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:35:00,073 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:35:00,446 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:35:00,809 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:35:01,160 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:35:01,527 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:35:01,915 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:35:02,255 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:35:02,608 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:35:02,951 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:35:03,288 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:35:03,661 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:35:04,028 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:35:04,405 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:35:04,756 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:35:04,948 - INFO - validation batch 1, loss: 0.424, 32/6976 datapoints
2025-03-07 11:35:05,018 - INFO - validation batch 51, loss: 6.700, 1632/6976 datapoints
2025-03-07 11:35:05,107 - INFO - validation batch 101, loss: 1.495, 3232/6976 datapoints
2025-03-07 11:35:05,176 - INFO - validation batch 151, loss: 0.781, 4832/6976 datapoints
2025-03-07 11:35:05,241 - INFO - validation batch 201, loss: 4.402, 6432/6976 datapoints
2025-03-07 11:35:05,265 - INFO - Epoch 559/800 done.
2025-03-07 11:35:05,265 - INFO - Final validation performance:
Loss: 2.760, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:35:05,265 - INFO - Beginning epoch 560/800
2025-03-07 11:35:05,276 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:35:05,624 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:35:05,984 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:35:06,385 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:35:06,744 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:35:07,119 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:35:07,486 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:35:07,850 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:35:08,203 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:35:08,549 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:35:08,895 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:35:09,238 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:35:09,580 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:35:09,915 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:35:10,272 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:35:10,628 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:35:10,997 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:35:11,339 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:35:11,537 - INFO - validation batch 1, loss: 0.443, 32/6976 datapoints
2025-03-07 11:35:11,616 - INFO - validation batch 51, loss: 6.728, 1632/6976 datapoints
2025-03-07 11:35:11,684 - INFO - validation batch 101, loss: 1.490, 3232/6976 datapoints
2025-03-07 11:35:11,755 - INFO - validation batch 151, loss: 0.782, 4832/6976 datapoints
2025-03-07 11:35:11,822 - INFO - validation batch 201, loss: 4.422, 6432/6976 datapoints
2025-03-07 11:35:11,850 - INFO - Epoch 560/800 done.
2025-03-07 11:35:11,850 - INFO - Final validation performance:
Loss: 2.773, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:35:11,851 - INFO - Beginning epoch 561/800
2025-03-07 11:35:11,860 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:35:12,189 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:35:12,549 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:35:12,896 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:35:13,243 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:35:13,611 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:35:13,965 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:35:14,314 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:35:14,660 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:35:15,005 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:35:15,350 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:35:15,701 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:35:16,054 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:35:16,417 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:35:16,778 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:35:17,138 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:35:17,507 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:35:17,857 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:35:18,047 - INFO - validation batch 1, loss: 0.451, 32/6976 datapoints
2025-03-07 11:35:18,113 - INFO - validation batch 51, loss: 6.759, 1632/6976 datapoints
2025-03-07 11:35:18,180 - INFO - validation batch 101, loss: 1.486, 3232/6976 datapoints
2025-03-07 11:35:18,247 - INFO - validation batch 151, loss: 0.799, 4832/6976 datapoints
2025-03-07 11:35:18,313 - INFO - validation batch 201, loss: 4.450, 6432/6976 datapoints
2025-03-07 11:35:18,339 - INFO - Epoch 561/800 done.
2025-03-07 11:35:18,339 - INFO - Final validation performance:
Loss: 2.789, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:35:18,340 - INFO - Beginning epoch 562/800
2025-03-07 11:35:18,352 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:35:18,683 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:35:19,044 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:35:19,388 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:35:19,733 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:35:20,095 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:35:20,453 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:35:20,805 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:35:21,148 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:35:21,490 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:35:21,836 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:35:22,182 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:35:22,528 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:35:22,870 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:35:23,228 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:35:23,587 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:35:23,955 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:35:24,298 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:35:24,490 - INFO - validation batch 1, loss: 0.447, 32/6976 datapoints
2025-03-07 11:35:24,558 - INFO - validation batch 51, loss: 6.802, 1632/6976 datapoints
2025-03-07 11:35:24,624 - INFO - validation batch 101, loss: 1.484, 3232/6976 datapoints
2025-03-07 11:35:24,692 - INFO - validation batch 151, loss: 0.836, 4832/6976 datapoints
2025-03-07 11:35:24,760 - INFO - validation batch 201, loss: 4.479, 6432/6976 datapoints
2025-03-07 11:35:24,786 - INFO - Epoch 562/800 done.
2025-03-07 11:35:24,787 - INFO - Final validation performance:
Loss: 2.810, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:35:24,789 - INFO - Beginning epoch 563/800
2025-03-07 11:35:24,799 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:35:25,133 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:35:25,495 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:35:25,844 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:35:26,243 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:35:26,630 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:35:26,995 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:35:27,353 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:35:27,710 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:35:28,056 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:35:28,409 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:35:28,753 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:35:29,101 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:35:29,441 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:35:29,791 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:35:30,148 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:35:30,541 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:35:30,890 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:35:31,079 - INFO - validation batch 1, loss: 0.430, 32/6976 datapoints
2025-03-07 11:35:31,147 - INFO - validation batch 51, loss: 6.866, 1632/6976 datapoints
2025-03-07 11:35:31,215 - INFO - validation batch 101, loss: 1.486, 3232/6976 datapoints
2025-03-07 11:35:31,284 - INFO - validation batch 151, loss: 0.885, 4832/6976 datapoints
2025-03-07 11:35:31,351 - INFO - validation batch 201, loss: 4.507, 6432/6976 datapoints
2025-03-07 11:35:31,374 - INFO - Epoch 563/800 done.
2025-03-07 11:35:31,375 - INFO - Final validation performance:
Loss: 2.835, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:35:31,375 - INFO - Beginning epoch 564/800
2025-03-07 11:35:31,388 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:35:31,719 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:35:32,108 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:35:32,454 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:35:32,804 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:35:33,166 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:35:33,528 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:35:33,884 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:35:34,236 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:35:34,585 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:35:34,939 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:35:35,290 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:35:35,642 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:35:35,999 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:35:36,353 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:35:36,736 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:35:37,138 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:35:37,491 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:35:37,685 - INFO - validation batch 1, loss: 0.401, 32/6976 datapoints
2025-03-07 11:35:37,757 - INFO - validation batch 51, loss: 6.958, 1632/6976 datapoints
2025-03-07 11:35:37,826 - INFO - validation batch 101, loss: 1.492, 3232/6976 datapoints
2025-03-07 11:35:37,895 - INFO - validation batch 151, loss: 0.942, 4832/6976 datapoints
2025-03-07 11:35:37,963 - INFO - validation batch 201, loss: 4.532, 6432/6976 datapoints
2025-03-07 11:35:37,989 - INFO - Epoch 564/800 done.
2025-03-07 11:35:37,990 - INFO - Final validation performance:
Loss: 2.865, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:35:37,990 - INFO - Beginning epoch 565/800
2025-03-07 11:35:37,999 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:35:38,328 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:35:38,826 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:35:39,177 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:35:39,527 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:35:39,897 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:35:40,260 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:35:40,622 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:35:40,973 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:35:41,319 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:35:41,682 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:35:42,029 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:35:42,395 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:35:42,739 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:35:43,091 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:35:43,450 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:35:43,821 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:35:44,167 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:35:44,353 - INFO - validation batch 1, loss: 0.359, 32/6976 datapoints
2025-03-07 11:35:44,427 - INFO - validation batch 51, loss: 7.054, 1632/6976 datapoints
2025-03-07 11:35:44,493 - INFO - validation batch 101, loss: 1.506, 3232/6976 datapoints
2025-03-07 11:35:44,563 - INFO - validation batch 151, loss: 1.020, 4832/6976 datapoints
2025-03-07 11:35:44,631 - INFO - validation batch 201, loss: 4.547, 6432/6976 datapoints
2025-03-07 11:35:44,655 - INFO - Epoch 565/800 done.
2025-03-07 11:35:44,655 - INFO - Final validation performance:
Loss: 2.897, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:35:44,656 - INFO - Beginning epoch 566/800
2025-03-07 11:35:44,665 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:35:44,997 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:35:45,355 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:35:45,703 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:35:46,085 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:35:46,457 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:35:46,846 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:35:47,207 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:35:47,554 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:35:47,902 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:35:48,256 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:35:48,600 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:35:48,946 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:35:49,295 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:35:49,657 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:35:50,039 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:35:50,416 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:35:50,764 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:35:50,954 - INFO - validation batch 1, loss: 0.312, 32/6976 datapoints
2025-03-07 11:35:51,024 - INFO - validation batch 51, loss: 7.120, 1632/6976 datapoints
2025-03-07 11:35:51,092 - INFO - validation batch 101, loss: 1.530, 3232/6976 datapoints
2025-03-07 11:35:51,161 - INFO - validation batch 151, loss: 1.095, 4832/6976 datapoints
2025-03-07 11:35:51,227 - INFO - validation batch 201, loss: 4.562, 6432/6976 datapoints
2025-03-07 11:35:51,252 - INFO - Epoch 566/800 done.
2025-03-07 11:35:51,252 - INFO - Final validation performance:
Loss: 2.924, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:35:51,253 - INFO - Beginning epoch 567/800
2025-03-07 11:35:51,263 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:35:51,611 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:35:51,968 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:35:52,314 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:35:52,672 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:35:53,049 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:35:53,415 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:35:53,775 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:35:54,120 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:35:54,461 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:35:54,813 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:35:55,160 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:35:55,508 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:35:55,857 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:35:56,269 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:35:56,687 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:35:57,061 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:35:57,471 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:35:57,751 - INFO - validation batch 1, loss: 0.290, 32/6976 datapoints
2025-03-07 11:35:57,838 - INFO - validation batch 51, loss: 7.190, 1632/6976 datapoints
2025-03-07 11:35:57,908 - INFO - validation batch 101, loss: 1.557, 3232/6976 datapoints
2025-03-07 11:35:57,985 - INFO - validation batch 151, loss: 1.117, 4832/6976 datapoints
2025-03-07 11:35:58,057 - INFO - validation batch 201, loss: 4.592, 6432/6976 datapoints
2025-03-07 11:35:58,082 - INFO - Epoch 567/800 done.
2025-03-07 11:35:58,082 - INFO - Final validation performance:
Loss: 2.949, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:35:58,083 - INFO - Beginning epoch 568/800
2025-03-07 11:35:58,095 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:35:58,446 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:35:58,813 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:35:59,183 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:35:59,544 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:35:59,919 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:36:00,288 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:36:00,654 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:36:00,994 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:36:01,332 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:36:01,697 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:36:02,045 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:36:02,393 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:36:02,740 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:36:03,118 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:36:03,613 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:36:04,707 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:36:05,313 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:36:05,547 - INFO - validation batch 1, loss: 0.273, 32/6976 datapoints
2025-03-07 11:36:05,671 - INFO - validation batch 51, loss: 7.285, 1632/6976 datapoints
2025-03-07 11:36:05,878 - INFO - validation batch 101, loss: 1.589, 3232/6976 datapoints
2025-03-07 11:36:06,273 - INFO - validation batch 151, loss: 1.185, 4832/6976 datapoints
2025-03-07 11:36:06,414 - INFO - validation batch 201, loss: 4.630, 6432/6976 datapoints
2025-03-07 11:36:06,561 - INFO - Epoch 568/800 done.
2025-03-07 11:36:06,563 - INFO - Final validation performance:
Loss: 2.992, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:36:06,568 - INFO - Beginning epoch 569/800
2025-03-07 11:36:06,607 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:36:07,686 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:36:08,929 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:36:09,642 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:36:10,034 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:36:10,489 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:36:10,958 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:36:11,401 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:36:11,840 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:36:12,334 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:36:12,818 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:36:13,334 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:36:13,915 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:36:14,445 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:36:15,205 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:36:16,108 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:36:16,969 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:36:17,647 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:36:18,070 - INFO - validation batch 1, loss: 0.229, 32/6976 datapoints
2025-03-07 11:36:18,799 - INFO - validation batch 51, loss: 7.337, 1632/6976 datapoints
2025-03-07 11:36:19,072 - INFO - validation batch 101, loss: 1.636, 3232/6976 datapoints
2025-03-07 11:36:19,232 - INFO - validation batch 151, loss: 1.319, 4832/6976 datapoints
2025-03-07 11:36:19,433 - INFO - validation batch 201, loss: 4.712, 6432/6976 datapoints
2025-03-07 11:36:19,606 - INFO - Epoch 569/800 done.
2025-03-07 11:36:19,614 - INFO - Final validation performance:
Loss: 3.047, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:36:19,618 - INFO - Beginning epoch 570/800
2025-03-07 11:36:19,686 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:36:20,376 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:36:20,952 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:36:21,472 - INFO - training batch 151, loss: 0.259, 4832/28000 datapoints
2025-03-07 11:36:22,193 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 11:36:22,758 - INFO - training batch 251, loss: 0.067, 8032/28000 datapoints
2025-03-07 11:36:23,335 - INFO - training batch 301, loss: 0.016, 9632/28000 datapoints
2025-03-07 11:36:23,799 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:36:24,289 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:36:24,750 - INFO - training batch 451, loss: 0.016, 14432/28000 datapoints
2025-03-07 11:36:25,235 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:36:25,643 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 11:36:26,084 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:36:26,551 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:36:27,321 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:36:28,332 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:36:28,896 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:36:29,468 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:36:29,893 - INFO - validation batch 1, loss: 0.192, 32/6976 datapoints
2025-03-07 11:36:30,069 - INFO - validation batch 51, loss: 6.063, 1632/6976 datapoints
2025-03-07 11:36:30,213 - INFO - validation batch 101, loss: 1.548, 3232/6976 datapoints
2025-03-07 11:36:30,325 - INFO - validation batch 151, loss: 1.400, 4832/6976 datapoints
2025-03-07 11:36:30,494 - INFO - validation batch 201, loss: 4.820, 6432/6976 datapoints
2025-03-07 11:36:30,523 - INFO - Epoch 570/800 done.
2025-03-07 11:36:30,523 - INFO - Final validation performance:
Loss: 2.805, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 11:36:30,524 - INFO - Beginning epoch 571/800
2025-03-07 11:36:30,534 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 11:36:30,996 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:36:31,476 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:36:31,975 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:36:32,419 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:36:32,873 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:36:33,267 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:36:33,658 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:36:34,021 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:36:34,386 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:36:34,784 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:36:35,187 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:36:35,611 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:36:36,000 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:36:36,439 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:36:36,813 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:36:37,208 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:36:37,613 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:36:37,874 - INFO - validation batch 1, loss: 0.636, 32/6976 datapoints
2025-03-07 11:36:37,956 - INFO - validation batch 51, loss: 6.976, 1632/6976 datapoints
2025-03-07 11:36:38,027 - INFO - validation batch 101, loss: 1.613, 3232/6976 datapoints
2025-03-07 11:36:38,098 - INFO - validation batch 151, loss: 0.861, 4832/6976 datapoints
2025-03-07 11:36:38,179 - INFO - validation batch 201, loss: 4.599, 6432/6976 datapoints
2025-03-07 11:36:38,209 - INFO - Epoch 571/800 done.
2025-03-07 11:36:38,209 - INFO - Final validation performance:
Loss: 2.937, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:36:38,209 - INFO - Beginning epoch 572/800
2025-03-07 11:36:38,220 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:36:38,577 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:36:38,974 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:36:39,359 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:36:39,744 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:36:40,138 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:36:40,534 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:36:40,911 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:36:41,276 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:36:41,633 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:36:41,996 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:36:42,357 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:36:42,724 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:36:43,077 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:36:43,459 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:36:43,828 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:36:44,210 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:36:44,573 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:36:44,761 - INFO - validation batch 1, loss: 0.445, 32/6976 datapoints
2025-03-07 11:36:44,831 - INFO - validation batch 51, loss: 7.137, 1632/6976 datapoints
2025-03-07 11:36:44,901 - INFO - validation batch 101, loss: 1.513, 3232/6976 datapoints
2025-03-07 11:36:44,969 - INFO - validation batch 151, loss: 1.053, 4832/6976 datapoints
2025-03-07 11:36:45,039 - INFO - validation batch 201, loss: 4.719, 6432/6976 datapoints
2025-03-07 11:36:45,064 - INFO - Epoch 572/800 done.
2025-03-07 11:36:45,065 - INFO - Final validation performance:
Loss: 2.973, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:36:45,065 - INFO - Beginning epoch 573/800
2025-03-07 11:36:45,074 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:36:45,431 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:36:45,797 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:36:46,156 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:36:46,568 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:36:46,951 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:36:47,344 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:36:47,748 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:36:48,154 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:36:48,542 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:36:49,111 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:36:49,548 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:36:49,978 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:36:50,427 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:36:50,815 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:36:51,187 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:36:51,582 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:36:51,946 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:36:52,131 - INFO - validation batch 1, loss: 0.470, 32/6976 datapoints
2025-03-07 11:36:52,198 - INFO - validation batch 51, loss: 7.073, 1632/6976 datapoints
2025-03-07 11:36:52,265 - INFO - validation batch 101, loss: 1.520, 3232/6976 datapoints
2025-03-07 11:36:52,339 - INFO - validation batch 151, loss: 1.082, 4832/6976 datapoints
2025-03-07 11:36:52,421 - INFO - validation batch 201, loss: 4.685, 6432/6976 datapoints
2025-03-07 11:36:52,447 - INFO - Epoch 573/800 done.
2025-03-07 11:36:52,447 - INFO - Final validation performance:
Loss: 2.966, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:36:52,448 - INFO - Beginning epoch 574/800
2025-03-07 11:36:52,456 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:36:52,795 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:36:53,163 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:36:53,518 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:36:53,886 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:36:54,253 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:36:54,622 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:36:54,981 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:36:55,329 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:36:55,679 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:36:56,032 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:36:56,379 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:36:56,726 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:36:57,062 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:36:57,419 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:36:57,776 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:36:58,164 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:36:58,511 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:36:58,695 - INFO - validation batch 1, loss: 0.497, 32/6976 datapoints
2025-03-07 11:36:58,772 - INFO - validation batch 51, loss: 7.046, 1632/6976 datapoints
2025-03-07 11:36:58,847 - INFO - validation batch 101, loss: 1.531, 3232/6976 datapoints
2025-03-07 11:36:58,914 - INFO - validation batch 151, loss: 1.082, 4832/6976 datapoints
2025-03-07 11:36:58,981 - INFO - validation batch 201, loss: 4.688, 6432/6976 datapoints
2025-03-07 11:36:59,004 - INFO - Epoch 574/800 done.
2025-03-07 11:36:59,004 - INFO - Final validation performance:
Loss: 2.969, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:36:59,005 - INFO - Beginning epoch 575/800
2025-03-07 11:36:59,014 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:36:59,355 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:36:59,715 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:37:00,075 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:37:00,445 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:37:00,817 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:37:01,203 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:37:01,596 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:37:01,948 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:37:02,297 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:37:02,657 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:37:03,012 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:37:03,362 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:37:03,707 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:37:04,064 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:37:04,425 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:37:04,785 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:37:05,133 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:37:05,318 - INFO - validation batch 1, loss: 0.516, 32/6976 datapoints
2025-03-07 11:37:05,389 - INFO - validation batch 51, loss: 7.038, 1632/6976 datapoints
2025-03-07 11:37:05,457 - INFO - validation batch 101, loss: 1.539, 3232/6976 datapoints
2025-03-07 11:37:05,524 - INFO - validation batch 151, loss: 1.046, 4832/6976 datapoints
2025-03-07 11:37:05,589 - INFO - validation batch 201, loss: 4.674, 6432/6976 datapoints
2025-03-07 11:37:05,611 - INFO - Epoch 575/800 done.
2025-03-07 11:37:05,611 - INFO - Final validation performance:
Loss: 2.963, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:37:05,611 - INFO - Beginning epoch 576/800
2025-03-07 11:37:05,620 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:37:05,959 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:37:06,315 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:37:06,674 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:37:07,029 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:37:07,400 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:37:07,776 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:37:08,168 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:37:08,519 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:37:08,867 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:37:09,220 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:37:09,584 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:37:09,918 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:37:10,253 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:37:10,609 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:37:10,962 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:37:11,323 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:37:11,670 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:37:11,862 - INFO - validation batch 1, loss: 0.532, 32/6976 datapoints
2025-03-07 11:37:11,930 - INFO - validation batch 51, loss: 7.042, 1632/6976 datapoints
2025-03-07 11:37:11,995 - INFO - validation batch 101, loss: 1.546, 3232/6976 datapoints
2025-03-07 11:37:12,061 - INFO - validation batch 151, loss: 1.000, 4832/6976 datapoints
2025-03-07 11:37:12,126 - INFO - validation batch 201, loss: 4.664, 6432/6976 datapoints
2025-03-07 11:37:12,151 - INFO - Epoch 576/800 done.
2025-03-07 11:37:12,152 - INFO - Final validation performance:
Loss: 2.957, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:37:12,152 - INFO - Beginning epoch 577/800
2025-03-07 11:37:12,160 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:37:12,496 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:37:12,852 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:37:13,206 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:37:13,559 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:37:13,966 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:37:14,331 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:37:14,693 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:37:15,041 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:37:15,393 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:37:15,746 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:37:16,098 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:37:16,442 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:37:16,776 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:37:17,135 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:37:17,497 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:37:17,867 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:37:18,261 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:37:18,448 - INFO - validation batch 1, loss: 0.541, 32/6976 datapoints
2025-03-07 11:37:18,519 - INFO - validation batch 51, loss: 7.051, 1632/6976 datapoints
2025-03-07 11:37:18,586 - INFO - validation batch 101, loss: 1.548, 3232/6976 datapoints
2025-03-07 11:37:18,654 - INFO - validation batch 151, loss: 0.967, 4832/6976 datapoints
2025-03-07 11:37:18,719 - INFO - validation batch 201, loss: 4.670, 6432/6976 datapoints
2025-03-07 11:37:18,744 - INFO - Epoch 577/800 done.
2025-03-07 11:37:18,744 - INFO - Final validation performance:
Loss: 2.955, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:37:18,745 - INFO - Beginning epoch 578/800
2025-03-07 11:37:18,753 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:37:19,080 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:37:19,435 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:37:19,782 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:37:20,129 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:37:20,498 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:37:20,861 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:37:21,218 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:37:21,563 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:37:21,907 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:37:22,262 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:37:22,620 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:37:22,962 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:37:23,307 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:37:23,668 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:37:24,029 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:37:24,398 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:37:24,745 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:37:24,932 - INFO - validation batch 1, loss: 0.553, 32/6976 datapoints
2025-03-07 11:37:24,997 - INFO - validation batch 51, loss: 7.064, 1632/6976 datapoints
2025-03-07 11:37:25,067 - INFO - validation batch 101, loss: 1.547, 3232/6976 datapoints
2025-03-07 11:37:25,134 - INFO - validation batch 151, loss: 0.948, 4832/6976 datapoints
2025-03-07 11:37:25,200 - INFO - validation batch 201, loss: 4.691, 6432/6976 datapoints
2025-03-07 11:37:25,221 - INFO - Epoch 578/800 done.
2025-03-07 11:37:25,221 - INFO - Final validation performance:
Loss: 2.961, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:37:25,222 - INFO - Beginning epoch 579/800
2025-03-07 11:37:25,233 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:37:25,562 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:37:25,907 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:37:26,283 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:37:26,632 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:37:26,986 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:37:27,354 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:37:27,713 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:37:28,055 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:37:28,421 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:37:28,773 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:37:29,125 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:37:29,468 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:37:29,804 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:37:30,165 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:37:30,570 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:37:30,936 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:37:31,282 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:37:31,472 - INFO - validation batch 1, loss: 0.569, 32/6976 datapoints
2025-03-07 11:37:31,537 - INFO - validation batch 51, loss: 7.093, 1632/6976 datapoints
2025-03-07 11:37:31,601 - INFO - validation batch 101, loss: 1.545, 3232/6976 datapoints
2025-03-07 11:37:31,667 - INFO - validation batch 151, loss: 0.934, 4832/6976 datapoints
2025-03-07 11:37:31,738 - INFO - validation batch 201, loss: 4.720, 6432/6976 datapoints
2025-03-07 11:37:31,762 - INFO - Epoch 579/800 done.
2025-03-07 11:37:31,762 - INFO - Final validation performance:
Loss: 2.972, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:37:31,763 - INFO - Beginning epoch 580/800
2025-03-07 11:37:31,771 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:37:32,110 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:37:32,483 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:37:32,845 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:37:33,212 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:37:33,598 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:37:33,982 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:37:34,357 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:37:34,718 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:37:35,076 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:37:35,468 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:37:35,818 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:37:36,161 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:37:36,501 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:37:36,868 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:37:37,222 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:37:37,596 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:37:37,978 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:37:38,175 - INFO - validation batch 1, loss: 0.571, 32/6976 datapoints
2025-03-07 11:37:38,249 - INFO - validation batch 51, loss: 7.149, 1632/6976 datapoints
2025-03-07 11:37:38,339 - INFO - validation batch 101, loss: 1.543, 3232/6976 datapoints
2025-03-07 11:37:38,413 - INFO - validation batch 151, loss: 0.935, 4832/6976 datapoints
2025-03-07 11:37:38,493 - INFO - validation batch 201, loss: 4.743, 6432/6976 datapoints
2025-03-07 11:37:38,518 - INFO - Epoch 580/800 done.
2025-03-07 11:37:38,519 - INFO - Final validation performance:
Loss: 2.988, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:37:38,519 - INFO - Beginning epoch 581/800
2025-03-07 11:37:38,529 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:37:38,915 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:37:39,275 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:37:39,635 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:37:39,985 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:37:40,356 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:37:40,728 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:37:41,089 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:37:41,441 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:37:41,791 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:37:42,149 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:37:42,509 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:37:42,853 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:37:43,187 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:37:43,544 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:37:43,897 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:37:44,256 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:37:44,602 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:37:44,789 - INFO - validation batch 1, loss: 0.550, 32/6976 datapoints
2025-03-07 11:37:44,854 - INFO - validation batch 51, loss: 7.230, 1632/6976 datapoints
2025-03-07 11:37:44,919 - INFO - validation batch 101, loss: 1.545, 3232/6976 datapoints
2025-03-07 11:37:44,983 - INFO - validation batch 151, loss: 0.953, 4832/6976 datapoints
2025-03-07 11:37:45,052 - INFO - validation batch 201, loss: 4.751, 6432/6976 datapoints
2025-03-07 11:37:45,074 - INFO - Epoch 581/800 done.
2025-03-07 11:37:45,074 - INFO - Final validation performance:
Loss: 3.006, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:37:45,074 - INFO - Beginning epoch 582/800
2025-03-07 11:37:45,083 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:37:45,426 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:37:45,780 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:37:46,126 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:37:46,479 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:37:46,854 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:37:47,224 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:37:47,592 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:37:47,945 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:37:48,293 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:37:48,685 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:37:49,044 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:37:49,396 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:37:49,738 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:37:50,092 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:37:50,445 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:37:50,801 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:37:51,140 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:37:51,332 - INFO - validation batch 1, loss: 0.500, 32/6976 datapoints
2025-03-07 11:37:51,399 - INFO - validation batch 51, loss: 7.298, 1632/6976 datapoints
2025-03-07 11:37:51,464 - INFO - validation batch 101, loss: 1.552, 3232/6976 datapoints
2025-03-07 11:37:51,529 - INFO - validation batch 151, loss: 1.007, 4832/6976 datapoints
2025-03-07 11:37:51,596 - INFO - validation batch 201, loss: 4.750, 6432/6976 datapoints
2025-03-07 11:37:51,616 - INFO - Epoch 582/800 done.
2025-03-07 11:37:51,617 - INFO - Final validation performance:
Loss: 3.021, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:37:51,617 - INFO - Beginning epoch 583/800
2025-03-07 11:37:51,625 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:37:51,957 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:37:52,308 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:37:52,661 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:37:53,010 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:37:53,379 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:37:53,747 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:37:54,107 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:37:54,453 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:37:54,798 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:37:55,162 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:37:55,530 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:37:55,875 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:37:56,219 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:37:56,582 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:37:56,939 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:37:57,298 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:37:57,647 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:37:57,835 - INFO - validation batch 1, loss: 0.455, 32/6976 datapoints
2025-03-07 11:37:57,902 - INFO - validation batch 51, loss: 7.362, 1632/6976 datapoints
2025-03-07 11:37:57,966 - INFO - validation batch 101, loss: 1.564, 3232/6976 datapoints
2025-03-07 11:37:58,032 - INFO - validation batch 151, loss: 1.068, 4832/6976 datapoints
2025-03-07 11:37:58,099 - INFO - validation batch 201, loss: 4.765, 6432/6976 datapoints
2025-03-07 11:37:58,119 - INFO - Epoch 583/800 done.
2025-03-07 11:37:58,120 - INFO - Final validation performance:
Loss: 3.043, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:37:58,120 - INFO - Beginning epoch 584/800
2025-03-07 11:37:58,129 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:37:58,484 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:37:58,847 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:37:59,194 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:37:59,549 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:37:59,911 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:38:00,283 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:38:00,650 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:38:00,992 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:38:01,334 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:38:01,706 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:38:02,065 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:38:02,417 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:38:02,759 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:38:03,120 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:38:03,483 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:38:03,844 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:38:04,187 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:38:04,374 - INFO - validation batch 1, loss: 0.412, 32/6976 datapoints
2025-03-07 11:38:04,439 - INFO - validation batch 51, loss: 7.423, 1632/6976 datapoints
2025-03-07 11:38:04,507 - INFO - validation batch 101, loss: 1.585, 3232/6976 datapoints
2025-03-07 11:38:04,573 - INFO - validation batch 151, loss: 1.086, 4832/6976 datapoints
2025-03-07 11:38:04,639 - INFO - validation batch 201, loss: 4.799, 6432/6976 datapoints
2025-03-07 11:38:04,660 - INFO - Epoch 584/800 done.
2025-03-07 11:38:04,660 - INFO - Final validation performance:
Loss: 3.061, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:38:04,661 - INFO - Beginning epoch 585/800
2025-03-07 11:38:04,669 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:38:05,012 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:38:05,368 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:38:05,723 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:38:06,075 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:38:06,444 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:38:06,828 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:38:07,194 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:38:07,622 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:38:07,993 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:38:08,361 - INFO - training batch 501, loss: 0.259, 16032/28000 datapoints
2025-03-07 11:38:08,743 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-07 11:38:09,133 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-07 11:38:09,491 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:38:09,851 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:38:10,200 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:38:10,613 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:38:10,980 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-07 11:38:11,156 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-07 11:38:11,220 - INFO - validation batch 51, loss: 7.600, 1632/6976 datapoints
2025-03-07 11:38:11,284 - INFO - validation batch 101, loss: 1.597, 3232/6976 datapoints
2025-03-07 11:38:11,352 - INFO - validation batch 151, loss: 1.844, 4832/6976 datapoints
2025-03-07 11:38:11,422 - INFO - validation batch 201, loss: 4.908, 6432/6976 datapoints
2025-03-07 11:38:11,445 - INFO - Epoch 585/800 done.
2025-03-07 11:38:11,445 - INFO - Final validation performance:
Loss: 3.209, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 11:38:11,446 - INFO - Beginning epoch 586/800
2025-03-07 11:38:11,453 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 11:38:11,796 - INFO - training batch 51, loss: 0.127, 1632/28000 datapoints
2025-03-07 11:38:12,159 - INFO - training batch 101, loss: 0.060, 3232/28000 datapoints
2025-03-07 11:38:12,524 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-07 11:38:12,896 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:38:13,256 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:38:13,616 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:38:13,983 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:38:14,319 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:38:14,664 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:38:15,039 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:38:15,391 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:38:15,739 - INFO - training batch 601, loss: 0.006, 19232/28000 datapoints
2025-03-07 11:38:16,084 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:38:16,440 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:38:16,795 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:38:17,160 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:38:17,504 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:38:17,691 - INFO - validation batch 1, loss: 0.234, 32/6976 datapoints
2025-03-07 11:38:17,758 - INFO - validation batch 51, loss: 7.170, 1632/6976 datapoints
2025-03-07 11:38:17,825 - INFO - validation batch 101, loss: 1.608, 3232/6976 datapoints
2025-03-07 11:38:17,890 - INFO - validation batch 151, loss: 1.503, 4832/6976 datapoints
2025-03-07 11:38:17,955 - INFO - validation batch 201, loss: 4.975, 6432/6976 datapoints
2025-03-07 11:38:17,977 - INFO - Epoch 586/800 done.
2025-03-07 11:38:17,977 - INFO - Final validation performance:
Loss: 3.098, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:38:17,978 - INFO - Beginning epoch 587/800
2025-03-07 11:38:17,988 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:38:18,320 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:38:18,695 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:38:19,066 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:38:19,422 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:38:19,795 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:38:20,169 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:38:20,538 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:38:20,878 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:38:21,223 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:38:21,590 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:38:21,944 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:38:22,286 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:38:22,634 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:38:22,993 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:38:23,357 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:38:23,728 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:38:24,076 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:38:24,257 - INFO - validation batch 1, loss: 0.313, 32/6976 datapoints
2025-03-07 11:38:24,323 - INFO - validation batch 51, loss: 7.165, 1632/6976 datapoints
2025-03-07 11:38:24,390 - INFO - validation batch 101, loss: 1.713, 3232/6976 datapoints
2025-03-07 11:38:24,456 - INFO - validation batch 151, loss: 1.198, 4832/6976 datapoints
2025-03-07 11:38:24,520 - INFO - validation batch 201, loss: 4.864, 6432/6976 datapoints
2025-03-07 11:38:24,546 - INFO - Epoch 587/800 done.
2025-03-07 11:38:24,546 - INFO - Final validation performance:
Loss: 3.051, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:38:24,547 - INFO - Beginning epoch 588/800
2025-03-07 11:38:24,555 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:38:24,885 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:38:25,247 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:38:25,592 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:38:25,942 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:38:26,342 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:38:26,720 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:38:27,083 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:38:27,430 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:38:27,781 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:38:28,152 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:38:28,517 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:38:28,888 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:38:29,240 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:38:29,599 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:38:29,956 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:38:30,315 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:38:30,684 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:38:30,863 - INFO - validation batch 1, loss: 0.302, 32/6976 datapoints
2025-03-07 11:38:30,929 - INFO - validation batch 51, loss: 7.443, 1632/6976 datapoints
2025-03-07 11:38:30,995 - INFO - validation batch 101, loss: 1.646, 3232/6976 datapoints
2025-03-07 11:38:31,062 - INFO - validation batch 151, loss: 1.267, 4832/6976 datapoints
2025-03-07 11:38:31,127 - INFO - validation batch 201, loss: 5.110, 6432/6976 datapoints
2025-03-07 11:38:31,152 - INFO - Epoch 588/800 done.
2025-03-07 11:38:31,152 - INFO - Final validation performance:
Loss: 3.154, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:38:31,153 - INFO - Beginning epoch 589/800
2025-03-07 11:38:31,161 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:38:31,494 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:38:31,862 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:38:32,197 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:38:32,547 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:38:32,913 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:38:33,284 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:38:33,649 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:38:33,984 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:38:34,321 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:38:34,689 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:38:35,044 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:38:35,397 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:38:35,758 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:38:36,119 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:38:36,480 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:38:36,851 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:38:37,216 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:38:37,402 - INFO - validation batch 1, loss: 0.320, 32/6976 datapoints
2025-03-07 11:38:37,484 - INFO - validation batch 51, loss: 7.307, 1632/6976 datapoints
2025-03-07 11:38:37,569 - INFO - validation batch 101, loss: 1.645, 3232/6976 datapoints
2025-03-07 11:38:37,658 - INFO - validation batch 151, loss: 1.254, 4832/6976 datapoints
2025-03-07 11:38:37,751 - INFO - validation batch 201, loss: 5.200, 6432/6976 datapoints
2025-03-07 11:38:37,772 - INFO - Epoch 589/800 done.
2025-03-07 11:38:37,772 - INFO - Final validation performance:
Loss: 3.145, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:38:37,773 - INFO - Beginning epoch 590/800
2025-03-07 11:38:37,782 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:38:38,149 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:38:38,523 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:38:38,874 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:38:39,241 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:38:39,621 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:38:39,991 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:38:40,350 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:38:40,687 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:38:41,022 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:38:41,391 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:38:41,742 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:38:42,089 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:38:42,431 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:38:42,790 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:38:43,144 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:38:43,512 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:38:43,860 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:38:44,040 - INFO - validation batch 1, loss: 0.336, 32/6976 datapoints
2025-03-07 11:38:44,108 - INFO - validation batch 51, loss: 7.300, 1632/6976 datapoints
2025-03-07 11:38:44,177 - INFO - validation batch 101, loss: 1.642, 3232/6976 datapoints
2025-03-07 11:38:44,251 - INFO - validation batch 151, loss: 1.217, 4832/6976 datapoints
2025-03-07 11:38:44,319 - INFO - validation batch 201, loss: 5.188, 6432/6976 datapoints
2025-03-07 11:38:44,344 - INFO - Epoch 590/800 done.
2025-03-07 11:38:44,344 - INFO - Final validation performance:
Loss: 3.136, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:38:44,345 - INFO - Beginning epoch 591/800
2025-03-07 11:38:44,352 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:38:44,688 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:38:45,047 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:38:45,390 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:38:45,749 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:38:46,123 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:38:46,499 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:38:46,866 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:38:47,220 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:38:47,569 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:38:47,948 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:38:48,306 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:38:48,659 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:38:49,018 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:38:49,377 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:38:49,736 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:38:50,106 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:38:50,461 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:38:50,643 - INFO - validation batch 1, loss: 0.348, 32/6976 datapoints
2025-03-07 11:38:50,710 - INFO - validation batch 51, loss: 7.316, 1632/6976 datapoints
2025-03-07 11:38:50,776 - INFO - validation batch 101, loss: 1.641, 3232/6976 datapoints
2025-03-07 11:38:50,843 - INFO - validation batch 151, loss: 1.180, 4832/6976 datapoints
2025-03-07 11:38:50,909 - INFO - validation batch 201, loss: 5.170, 6432/6976 datapoints
2025-03-07 11:38:50,932 - INFO - Epoch 591/800 done.
2025-03-07 11:38:50,932 - INFO - Final validation performance:
Loss: 3.131, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:38:50,933 - INFO - Beginning epoch 592/800
2025-03-07 11:38:50,942 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:38:51,273 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:38:51,635 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:38:51,980 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:38:52,331 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:38:52,697 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:38:53,064 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:38:53,428 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:38:53,763 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:38:54,107 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:38:54,678 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:38:55,046 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:38:55,398 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:38:55,749 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:38:56,108 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:38:56,473 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:38:56,847 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:38:57,200 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:38:57,389 - INFO - validation batch 1, loss: 0.359, 32/6976 datapoints
2025-03-07 11:38:57,455 - INFO - validation batch 51, loss: 7.347, 1632/6976 datapoints
2025-03-07 11:38:57,520 - INFO - validation batch 101, loss: 1.643, 3232/6976 datapoints
2025-03-07 11:38:57,588 - INFO - validation batch 151, loss: 1.142, 4832/6976 datapoints
2025-03-07 11:38:57,662 - INFO - validation batch 201, loss: 5.149, 6432/6976 datapoints
2025-03-07 11:38:57,685 - INFO - Epoch 592/800 done.
2025-03-07 11:38:57,685 - INFO - Final validation performance:
Loss: 3.128, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:38:57,686 - INFO - Beginning epoch 593/800
2025-03-07 11:38:57,694 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:38:58,025 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:38:58,384 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:38:58,735 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:38:59,100 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:38:59,471 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:38:59,839 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:39:00,202 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:39:00,544 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:39:00,885 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:39:01,243 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:39:01,598 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:39:01,948 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:39:02,291 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:39:02,651 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:39:03,001 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:39:03,366 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:39:03,720 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:39:03,902 - INFO - validation batch 1, loss: 0.369, 32/6976 datapoints
2025-03-07 11:39:03,968 - INFO - validation batch 51, loss: 7.386, 1632/6976 datapoints
2025-03-07 11:39:04,035 - INFO - validation batch 101, loss: 1.646, 3232/6976 datapoints
2025-03-07 11:39:04,103 - INFO - validation batch 151, loss: 1.106, 4832/6976 datapoints
2025-03-07 11:39:04,172 - INFO - validation batch 201, loss: 5.127, 6432/6976 datapoints
2025-03-07 11:39:04,199 - INFO - Epoch 593/800 done.
2025-03-07 11:39:04,199 - INFO - Final validation performance:
Loss: 3.127, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:39:04,200 - INFO - Beginning epoch 594/800
2025-03-07 11:39:04,210 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:39:04,545 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:39:04,911 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:39:05,261 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:39:05,627 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:39:05,996 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:39:06,369 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:39:06,741 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:39:07,089 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:39:07,430 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:39:07,803 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:39:08,158 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:39:08,511 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:39:08,855 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:39:09,231 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:39:09,587 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:39:09,957 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:39:10,303 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:39:10,488 - INFO - validation batch 1, loss: 0.375, 32/6976 datapoints
2025-03-07 11:39:10,552 - INFO - validation batch 51, loss: 7.427, 1632/6976 datapoints
2025-03-07 11:39:10,618 - INFO - validation batch 101, loss: 1.657, 3232/6976 datapoints
2025-03-07 11:39:10,683 - INFO - validation batch 151, loss: 1.076, 4832/6976 datapoints
2025-03-07 11:39:10,750 - INFO - validation batch 201, loss: 5.112, 6432/6976 datapoints
2025-03-07 11:39:10,772 - INFO - Epoch 594/800 done.
2025-03-07 11:39:10,772 - INFO - Final validation performance:
Loss: 3.130, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:39:10,773 - INFO - Beginning epoch 595/800
2025-03-07 11:39:10,782 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:39:11,118 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:39:11,481 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:39:11,834 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:39:12,189 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:39:12,554 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:39:12,927 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:39:13,291 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:39:13,637 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:39:13,979 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:39:14,381 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:39:14,746 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:39:15,098 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:39:15,452 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:39:15,816 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:39:16,170 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:39:16,547 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:39:16,896 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:39:17,081 - INFO - validation batch 1, loss: 0.381, 32/6976 datapoints
2025-03-07 11:39:17,147 - INFO - validation batch 51, loss: 7.464, 1632/6976 datapoints
2025-03-07 11:39:17,213 - INFO - validation batch 101, loss: 1.671, 3232/6976 datapoints
2025-03-07 11:39:17,279 - INFO - validation batch 151, loss: 1.052, 4832/6976 datapoints
2025-03-07 11:39:17,349 - INFO - validation batch 201, loss: 5.099, 6432/6976 datapoints
2025-03-07 11:39:17,371 - INFO - Epoch 595/800 done.
2025-03-07 11:39:17,371 - INFO - Final validation performance:
Loss: 3.133, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:39:17,372 - INFO - Beginning epoch 596/800
2025-03-07 11:39:17,382 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:39:17,725 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:39:18,082 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:39:18,435 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:39:18,789 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:39:19,151 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:39:19,546 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:39:19,909 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:39:20,245 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:39:20,590 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:39:20,967 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:39:21,319 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:39:21,670 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:39:22,015 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:39:22,369 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:39:22,721 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:39:23,096 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:39:23,469 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:39:23,660 - INFO - validation batch 1, loss: 0.379, 32/6976 datapoints
2025-03-07 11:39:23,726 - INFO - validation batch 51, loss: 7.497, 1632/6976 datapoints
2025-03-07 11:39:23,792 - INFO - validation batch 101, loss: 1.685, 3232/6976 datapoints
2025-03-07 11:39:23,856 - INFO - validation batch 151, loss: 1.047, 4832/6976 datapoints
2025-03-07 11:39:23,922 - INFO - validation batch 201, loss: 5.087, 6432/6976 datapoints
2025-03-07 11:39:23,946 - INFO - Epoch 596/800 done.
2025-03-07 11:39:23,947 - INFO - Final validation performance:
Loss: 3.139, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:39:23,947 - INFO - Beginning epoch 597/800
2025-03-07 11:39:23,955 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:39:24,302 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:39:24,666 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:39:25,023 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:39:25,383 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:39:25,756 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:39:26,140 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:39:26,511 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:39:26,852 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:39:27,195 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:39:27,576 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:39:27,939 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:39:28,285 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:39:28,633 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:39:28,987 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:39:29,339 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:39:29,727 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:39:30,074 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:39:30,256 - INFO - validation batch 1, loss: 0.364, 32/6976 datapoints
2025-03-07 11:39:30,325 - INFO - validation batch 51, loss: 7.533, 1632/6976 datapoints
2025-03-07 11:39:30,409 - INFO - validation batch 101, loss: 1.695, 3232/6976 datapoints
2025-03-07 11:39:30,483 - INFO - validation batch 151, loss: 1.072, 4832/6976 datapoints
2025-03-07 11:39:30,555 - INFO - validation batch 201, loss: 5.068, 6432/6976 datapoints
2025-03-07 11:39:30,578 - INFO - Epoch 597/800 done.
2025-03-07 11:39:30,578 - INFO - Final validation performance:
Loss: 3.146, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:39:30,579 - INFO - Beginning epoch 598/800
2025-03-07 11:39:30,587 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:39:30,928 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:39:31,282 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:39:31,638 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:39:31,992 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:39:32,600 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:39:32,982 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:39:33,353 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:39:33,705 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:39:34,048 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:39:34,427 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:39:34,789 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:39:35,144 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:39:35,494 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:39:35,868 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:39:36,221 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:39:36,595 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:39:36,941 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:39:37,127 - INFO - validation batch 1, loss: 0.332, 32/6976 datapoints
2025-03-07 11:39:37,193 - INFO - validation batch 51, loss: 7.563, 1632/6976 datapoints
2025-03-07 11:39:37,258 - INFO - validation batch 101, loss: 1.713, 3232/6976 datapoints
2025-03-07 11:39:37,339 - INFO - validation batch 151, loss: 1.114, 4832/6976 datapoints
2025-03-07 11:39:37,411 - INFO - validation batch 201, loss: 5.048, 6432/6976 datapoints
2025-03-07 11:39:37,436 - INFO - Epoch 598/800 done.
2025-03-07 11:39:37,436 - INFO - Final validation performance:
Loss: 3.154, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:39:37,437 - INFO - Beginning epoch 599/800
2025-03-07 11:39:37,445 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:39:37,794 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:39:38,161 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:39:38,559 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:39:38,913 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:39:39,273 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:39:39,674 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:39:40,051 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:39:40,391 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:39:40,730 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:39:41,107 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:39:41,469 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:39:41,823 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:39:42,173 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:39:42,548 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:39:42,933 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:39:43,392 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:39:43,762 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:39:43,947 - INFO - validation batch 1, loss: 0.310, 32/6976 datapoints
2025-03-07 11:39:44,015 - INFO - validation batch 51, loss: 7.608, 1632/6976 datapoints
2025-03-07 11:39:44,083 - INFO - validation batch 101, loss: 1.727, 3232/6976 datapoints
2025-03-07 11:39:44,148 - INFO - validation batch 151, loss: 1.168, 4832/6976 datapoints
2025-03-07 11:39:44,214 - INFO - validation batch 201, loss: 5.041, 6432/6976 datapoints
2025-03-07 11:39:44,238 - INFO - Epoch 599/800 done.
2025-03-07 11:39:44,238 - INFO - Final validation performance:
Loss: 3.171, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:39:44,238 - INFO - Beginning epoch 600/800
2025-03-07 11:39:44,248 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:39:44,603 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:39:44,959 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:39:45,316 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:39:45,678 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:39:46,053 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:39:46,440 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:39:46,805 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:39:47,145 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:39:47,500 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:39:47,877 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:39:48,237 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:39:48,599 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:39:48,951 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:39:49,305 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:39:49,686 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:39:50,052 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:39:50,409 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:39:50,599 - INFO - validation batch 1, loss: 0.286, 32/6976 datapoints
2025-03-07 11:39:50,666 - INFO - validation batch 51, loss: 7.636, 1632/6976 datapoints
2025-03-07 11:39:50,730 - INFO - validation batch 101, loss: 1.751, 3232/6976 datapoints
2025-03-07 11:39:50,794 - INFO - validation batch 151, loss: 1.208, 4832/6976 datapoints
2025-03-07 11:39:50,857 - INFO - validation batch 201, loss: 5.074, 6432/6976 datapoints
2025-03-07 11:39:50,881 - INFO - Epoch 600/800 done.
2025-03-07 11:39:50,881 - INFO - Final validation performance:
Loss: 3.191, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:39:50,881 - INFO - Beginning epoch 601/800
2025-03-07 11:39:50,890 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:39:51,242 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:39:51,605 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:39:51,963 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:39:52,319 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:39:52,694 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:39:53,078 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:39:53,464 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:39:53,798 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:39:54,140 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-07 11:39:54,515 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:39:54,857 - INFO - training batch 551, loss: 0.367, 17632/28000 datapoints
2025-03-07 11:39:55,209 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:39:55,557 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:39:55,923 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:39:56,279 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:39:56,642 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:39:56,992 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:39:57,177 - INFO - validation batch 1, loss: 0.167, 32/6976 datapoints
2025-03-07 11:39:57,243 - INFO - validation batch 51, loss: 6.699, 1632/6976 datapoints
2025-03-07 11:39:57,308 - INFO - validation batch 101, loss: 1.698, 3232/6976 datapoints
2025-03-07 11:39:57,374 - INFO - validation batch 151, loss: 1.048, 4832/6976 datapoints
2025-03-07 11:39:57,441 - INFO - validation batch 201, loss: 4.299, 6432/6976 datapoints
2025-03-07 11:39:57,462 - INFO - Epoch 601/800 done.
2025-03-07 11:39:57,462 - INFO - Final validation performance:
Loss: 2.782, top-1 acc: 0.873top-5 acc: 0.873
2025-03-07 11:39:57,463 - INFO - Beginning epoch 602/800
2025-03-07 11:39:57,470 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:39:57,811 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-07 11:39:58,168 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:39:58,523 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:39:58,883 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:39:59,249 - INFO - training batch 251, loss: 0.029, 8032/28000 datapoints
2025-03-07 11:39:59,633 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:40:00,024 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:40:00,377 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:40:00,727 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:40:01,096 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:40:01,451 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:40:01,805 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:40:02,153 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:40:02,531 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:40:02,894 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:40:03,263 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:40:03,614 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:40:03,807 - INFO - validation batch 1, loss: 0.182, 32/6976 datapoints
2025-03-07 11:40:03,877 - INFO - validation batch 51, loss: 7.007, 1632/6976 datapoints
2025-03-07 11:40:03,943 - INFO - validation batch 101, loss: 1.698, 3232/6976 datapoints
2025-03-07 11:40:04,010 - INFO - validation batch 151, loss: 1.201, 4832/6976 datapoints
2025-03-07 11:40:04,075 - INFO - validation batch 201, loss: 5.180, 6432/6976 datapoints
2025-03-07 11:40:04,100 - INFO - Epoch 602/800 done.
2025-03-07 11:40:04,100 - INFO - Final validation performance:
Loss: 3.054, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:40:04,100 - INFO - Beginning epoch 603/800
2025-03-07 11:40:04,107 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:40:04,442 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:40:04,796 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:40:05,150 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:40:05,503 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:40:05,874 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:40:06,231 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:40:06,598 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:40:06,940 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:40:07,282 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:40:07,661 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:40:08,021 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:40:08,369 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 11:40:08,724 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:40:09,091 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:40:09,449 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:40:09,829 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:40:10,167 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:40:10,355 - INFO - validation batch 1, loss: 0.147, 32/6976 datapoints
2025-03-07 11:40:10,422 - INFO - validation batch 51, loss: 7.376, 1632/6976 datapoints
2025-03-07 11:40:10,490 - INFO - validation batch 101, loss: 1.580, 3232/6976 datapoints
2025-03-07 11:40:10,558 - INFO - validation batch 151, loss: 1.185, 4832/6976 datapoints
2025-03-07 11:40:10,625 - INFO - validation batch 201, loss: 4.862, 6432/6976 datapoints
2025-03-07 11:40:10,650 - INFO - Epoch 603/800 done.
2025-03-07 11:40:10,650 - INFO - Final validation performance:
Loss: 3.030, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:40:10,651 - INFO - Beginning epoch 604/800
2025-03-07 11:40:10,659 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:40:10,998 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:40:11,360 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:40:11,724 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:40:12,088 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:40:12,471 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:40:12,885 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:40:13,259 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:40:13,607 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:40:13,951 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:40:14,314 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:40:14,677 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:40:15,028 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 11:40:15,375 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:40:15,741 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:40:16,100 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:40:16,464 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:40:16,806 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:40:16,997 - INFO - validation batch 1, loss: 0.185, 32/6976 datapoints
2025-03-07 11:40:17,065 - INFO - validation batch 51, loss: 7.448, 1632/6976 datapoints
2025-03-07 11:40:17,131 - INFO - validation batch 101, loss: 1.584, 3232/6976 datapoints
2025-03-07 11:40:17,195 - INFO - validation batch 151, loss: 1.236, 4832/6976 datapoints
2025-03-07 11:40:17,262 - INFO - validation batch 201, loss: 4.830, 6432/6976 datapoints
2025-03-07 11:40:17,286 - INFO - Epoch 604/800 done.
2025-03-07 11:40:17,286 - INFO - Final validation performance:
Loss: 3.057, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:40:17,286 - INFO - Beginning epoch 605/800
2025-03-07 11:40:17,294 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:40:17,636 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:40:17,997 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:40:18,354 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:40:18,723 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:40:19,088 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:40:19,451 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:40:19,828 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:40:20,187 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:40:20,538 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:40:20,911 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:40:21,275 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:40:21,634 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:40:21,984 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:40:22,360 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:40:22,728 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:40:23,096 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:40:23,451 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:40:23,641 - INFO - validation batch 1, loss: 0.214, 32/6976 datapoints
2025-03-07 11:40:23,705 - INFO - validation batch 51, loss: 7.460, 1632/6976 datapoints
2025-03-07 11:40:23,770 - INFO - validation batch 101, loss: 1.607, 3232/6976 datapoints
2025-03-07 11:40:23,837 - INFO - validation batch 151, loss: 1.199, 4832/6976 datapoints
2025-03-07 11:40:23,904 - INFO - validation batch 201, loss: 4.835, 6432/6976 datapoints
2025-03-07 11:40:23,929 - INFO - Epoch 605/800 done.
2025-03-07 11:40:23,929 - INFO - Final validation performance:
Loss: 3.063, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:40:23,930 - INFO - Beginning epoch 606/800
2025-03-07 11:40:23,938 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:40:24,262 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:40:24,622 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:40:24,971 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:40:25,327 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:40:25,693 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:40:26,072 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:40:26,469 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:40:26,811 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:40:27,152 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:40:27,518 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:40:27,885 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:40:28,237 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:40:28,587 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:40:28,957 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:40:29,316 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:40:29,681 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:40:30,044 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:40:30,229 - INFO - validation batch 1, loss: 0.235, 32/6976 datapoints
2025-03-07 11:40:30,290 - INFO - validation batch 51, loss: 7.491, 1632/6976 datapoints
2025-03-07 11:40:30,351 - INFO - validation batch 101, loss: 1.606, 3232/6976 datapoints
2025-03-07 11:40:30,433 - INFO - validation batch 151, loss: 1.155, 4832/6976 datapoints
2025-03-07 11:40:30,495 - INFO - validation batch 201, loss: 4.835, 6432/6976 datapoints
2025-03-07 11:40:30,516 - INFO - Epoch 606/800 done.
2025-03-07 11:40:30,517 - INFO - Final validation performance:
Loss: 3.065, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:40:30,517 - INFO - Beginning epoch 607/800
2025-03-07 11:40:30,525 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:40:30,855 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:40:31,717 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:40:32,079 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:40:32,436 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:40:32,817 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:40:33,206 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:40:33,603 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:40:33,948 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:40:34,307 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:40:34,760 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:40:35,257 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:40:36,052 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:40:36,828 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:40:37,356 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:40:37,823 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:40:38,264 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:40:38,764 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:40:39,061 - INFO - validation batch 1, loss: 0.251, 32/6976 datapoints
2025-03-07 11:40:39,158 - INFO - validation batch 51, loss: 7.532, 1632/6976 datapoints
2025-03-07 11:40:39,252 - INFO - validation batch 101, loss: 1.600, 3232/6976 datapoints
2025-03-07 11:40:39,349 - INFO - validation batch 151, loss: 1.110, 4832/6976 datapoints
2025-03-07 11:40:39,453 - INFO - validation batch 201, loss: 4.834, 6432/6976 datapoints
2025-03-07 11:40:39,492 - INFO - Epoch 607/800 done.
2025-03-07 11:40:39,493 - INFO - Final validation performance:
Loss: 3.065, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:40:39,495 - INFO - Beginning epoch 608/800
2025-03-07 11:40:39,505 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:40:39,957 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:40:40,448 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:40:40,838 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:40:41,225 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:40:41,630 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:40:42,040 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:40:42,444 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:40:42,817 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:40:43,192 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:40:43,588 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:40:44,003 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:40:44,452 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:40:44,887 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:40:45,336 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:40:45,759 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:40:46,197 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:40:46,620 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:40:46,847 - INFO - validation batch 1, loss: 0.264, 32/6976 datapoints
2025-03-07 11:40:46,923 - INFO - validation batch 51, loss: 7.573, 1632/6976 datapoints
2025-03-07 11:40:47,007 - INFO - validation batch 101, loss: 1.589, 3232/6976 datapoints
2025-03-07 11:40:47,084 - INFO - validation batch 151, loss: 1.069, 4832/6976 datapoints
2025-03-07 11:40:47,165 - INFO - validation batch 201, loss: 4.836, 6432/6976 datapoints
2025-03-07 11:40:47,196 - INFO - Epoch 608/800 done.
2025-03-07 11:40:47,196 - INFO - Final validation performance:
Loss: 3.066, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:40:47,196 - INFO - Beginning epoch 609/800
2025-03-07 11:40:47,205 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:40:47,595 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:40:48,023 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:40:48,507 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:40:48,899 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:40:49,356 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:40:49,753 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:40:50,152 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:40:50,598 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:40:50,981 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:40:51,367 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:40:51,768 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:40:52,153 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:40:52,535 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:40:52,913 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:40:53,286 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:40:53,661 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:40:54,023 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:40:54,220 - INFO - validation batch 1, loss: 0.277, 32/6976 datapoints
2025-03-07 11:40:54,285 - INFO - validation batch 51, loss: 7.615, 1632/6976 datapoints
2025-03-07 11:40:54,354 - INFO - validation batch 101, loss: 1.577, 3232/6976 datapoints
2025-03-07 11:40:54,427 - INFO - validation batch 151, loss: 1.036, 4832/6976 datapoints
2025-03-07 11:40:54,495 - INFO - validation batch 201, loss: 4.841, 6432/6976 datapoints
2025-03-07 11:40:54,515 - INFO - Epoch 609/800 done.
2025-03-07 11:40:54,515 - INFO - Final validation performance:
Loss: 3.069, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:40:54,516 - INFO - Beginning epoch 610/800
2025-03-07 11:40:54,525 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:40:54,869 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:40:55,234 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:40:55,605 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:40:55,964 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:40:56,329 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:40:56,700 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:40:57,072 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:40:57,412 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:40:57,762 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:40:58,150 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:40:58,541 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:40:58,952 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:40:59,333 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:40:59,712 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:41:00,081 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:41:00,475 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:41:00,835 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:41:01,027 - INFO - validation batch 1, loss: 0.289, 32/6976 datapoints
2025-03-07 11:41:01,093 - INFO - validation batch 51, loss: 7.654, 1632/6976 datapoints
2025-03-07 11:41:01,159 - INFO - validation batch 101, loss: 1.566, 3232/6976 datapoints
2025-03-07 11:41:01,224 - INFO - validation batch 151, loss: 1.021, 4832/6976 datapoints
2025-03-07 11:41:01,288 - INFO - validation batch 201, loss: 4.850, 6432/6976 datapoints
2025-03-07 11:41:01,309 - INFO - Epoch 610/800 done.
2025-03-07 11:41:01,310 - INFO - Final validation performance:
Loss: 3.076, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:41:01,310 - INFO - Beginning epoch 611/800
2025-03-07 11:41:01,318 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:41:01,706 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:41:02,076 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:41:02,437 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:41:02,847 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:41:03,227 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:41:03,600 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:41:03,976 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:41:04,334 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:41:04,675 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:41:05,051 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:41:05,445 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:41:05,804 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:41:06,149 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:41:06,515 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:41:06,879 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:41:07,257 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:41:07,607 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:41:07,794 - INFO - validation batch 1, loss: 0.294, 32/6976 datapoints
2025-03-07 11:41:07,857 - INFO - validation batch 51, loss: 7.692, 1632/6976 datapoints
2025-03-07 11:41:07,922 - INFO - validation batch 101, loss: 1.561, 3232/6976 datapoints
2025-03-07 11:41:07,994 - INFO - validation batch 151, loss: 1.037, 4832/6976 datapoints
2025-03-07 11:41:08,059 - INFO - validation batch 201, loss: 4.862, 6432/6976 datapoints
2025-03-07 11:41:08,084 - INFO - Epoch 611/800 done.
2025-03-07 11:41:08,084 - INFO - Final validation performance:
Loss: 3.089, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:41:08,085 - INFO - Beginning epoch 612/800
2025-03-07 11:41:08,094 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:41:08,446 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:41:08,837 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:41:09,203 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:41:09,564 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:41:09,940 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:41:10,312 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:41:10,706 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:41:11,051 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:41:11,394 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:41:11,769 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:41:12,123 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:41:12,474 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:41:12,819 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:41:13,181 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:41:13,540 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:41:13,905 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:41:14,255 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:41:14,448 - INFO - validation batch 1, loss: 0.286, 32/6976 datapoints
2025-03-07 11:41:14,514 - INFO - validation batch 51, loss: 7.734, 1632/6976 datapoints
2025-03-07 11:41:14,578 - INFO - validation batch 101, loss: 1.566, 3232/6976 datapoints
2025-03-07 11:41:14,644 - INFO - validation batch 151, loss: 1.086, 4832/6976 datapoints
2025-03-07 11:41:14,707 - INFO - validation batch 201, loss: 4.871, 6432/6976 datapoints
2025-03-07 11:41:14,729 - INFO - Epoch 612/800 done.
2025-03-07 11:41:14,729 - INFO - Final validation performance:
Loss: 3.109, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:41:14,730 - INFO - Beginning epoch 613/800
2025-03-07 11:41:14,739 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:41:15,080 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:41:15,443 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:41:15,815 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:41:16,177 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:41:16,550 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:41:16,924 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:41:17,299 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:41:17,651 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:41:17,992 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:41:18,375 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:41:18,735 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:41:19,092 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:41:19,439 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:41:19,804 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:41:20,161 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:41:20,540 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:41:20,889 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:41:21,077 - INFO - validation batch 1, loss: 0.270, 32/6976 datapoints
2025-03-07 11:41:21,143 - INFO - validation batch 51, loss: 7.777, 1632/6976 datapoints
2025-03-07 11:41:21,213 - INFO - validation batch 101, loss: 1.581, 3232/6976 datapoints
2025-03-07 11:41:21,277 - INFO - validation batch 151, loss: 1.148, 4832/6976 datapoints
2025-03-07 11:41:21,343 - INFO - validation batch 201, loss: 4.880, 6432/6976 datapoints
2025-03-07 11:41:21,367 - INFO - Epoch 613/800 done.
2025-03-07 11:41:21,367 - INFO - Final validation performance:
Loss: 3.131, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:41:21,368 - INFO - Beginning epoch 614/800
2025-03-07 11:41:21,375 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:41:21,726 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:41:22,091 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:41:22,450 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:41:22,812 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:41:23,184 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:41:23,567 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:41:23,943 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:41:24,294 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:41:24,634 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:41:25,012 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:41:25,374 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:41:25,725 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:41:26,128 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:41:26,493 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:41:26,846 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:41:27,204 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:41:27,555 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:41:27,746 - INFO - validation batch 1, loss: 0.254, 32/6976 datapoints
2025-03-07 11:41:27,812 - INFO - validation batch 51, loss: 7.821, 1632/6976 datapoints
2025-03-07 11:41:27,879 - INFO - validation batch 101, loss: 1.601, 3232/6976 datapoints
2025-03-07 11:41:27,946 - INFO - validation batch 151, loss: 1.208, 4832/6976 datapoints
2025-03-07 11:41:28,010 - INFO - validation batch 201, loss: 4.892, 6432/6976 datapoints
2025-03-07 11:41:28,034 - INFO - Epoch 614/800 done.
2025-03-07 11:41:28,034 - INFO - Final validation performance:
Loss: 3.155, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:41:28,035 - INFO - Beginning epoch 615/800
2025-03-07 11:41:28,043 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:41:28,388 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:41:28,756 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:41:29,113 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:41:29,480 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:41:29,848 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:41:30,218 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:41:30,650 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:41:31,009 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:41:31,351 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:41:31,735 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:41:32,100 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:41:32,458 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:41:32,811 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:41:33,173 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:41:33,536 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:41:33,896 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:41:34,240 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:41:34,428 - INFO - validation batch 1, loss: 0.240, 32/6976 datapoints
2025-03-07 11:41:34,493 - INFO - validation batch 51, loss: 7.854, 1632/6976 datapoints
2025-03-07 11:41:34,557 - INFO - validation batch 101, loss: 1.631, 3232/6976 datapoints
2025-03-07 11:41:34,622 - INFO - validation batch 151, loss: 1.253, 4832/6976 datapoints
2025-03-07 11:41:34,688 - INFO - validation batch 201, loss: 4.915, 6432/6976 datapoints
2025-03-07 11:41:34,711 - INFO - Epoch 615/800 done.
2025-03-07 11:41:34,711 - INFO - Final validation performance:
Loss: 3.179, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:41:34,712 - INFO - Beginning epoch 616/800
2025-03-07 11:41:34,719 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:41:35,067 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:41:35,432 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:41:35,788 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:41:36,156 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:41:36,536 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:41:36,909 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:41:37,279 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:41:37,622 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:41:37,963 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:41:38,351 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:41:38,724 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:41:39,084 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:41:39,473 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:41:39,844 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:41:40,206 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:41:40,594 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:41:40,967 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:41:41,157 - INFO - validation batch 1, loss: 0.225, 32/6976 datapoints
2025-03-07 11:41:41,221 - INFO - validation batch 51, loss: 7.889, 1632/6976 datapoints
2025-03-07 11:41:41,288 - INFO - validation batch 101, loss: 1.677, 3232/6976 datapoints
2025-03-07 11:41:41,355 - INFO - validation batch 151, loss: 1.279, 4832/6976 datapoints
2025-03-07 11:41:41,423 - INFO - validation batch 201, loss: 4.962, 6432/6976 datapoints
2025-03-07 11:41:41,448 - INFO - Epoch 616/800 done.
2025-03-07 11:41:41,448 - INFO - Final validation performance:
Loss: 3.206, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:41:41,449 - INFO - Beginning epoch 617/800
2025-03-07 11:41:41,456 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:41:41,815 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:41:42,184 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:41:42,550 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:41:42,910 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:41:43,281 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:41:43,655 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:41:44,028 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:41:44,363 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:41:44,706 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:41:45,076 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:41:45,437 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:41:45,790 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:41:46,146 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:41:46,510 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:41:46,870 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:41:47,232 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:41:47,589 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:41:47,777 - INFO - validation batch 1, loss: 0.195, 32/6976 datapoints
2025-03-07 11:41:47,844 - INFO - validation batch 51, loss: 7.945, 1632/6976 datapoints
2025-03-07 11:41:47,911 - INFO - validation batch 101, loss: 1.740, 3232/6976 datapoints
2025-03-07 11:41:47,976 - INFO - validation batch 151, loss: 1.361, 4832/6976 datapoints
2025-03-07 11:41:48,042 - INFO - validation batch 201, loss: 5.056, 6432/6976 datapoints
2025-03-07 11:41:48,065 - INFO - Epoch 617/800 done.
2025-03-07 11:41:48,065 - INFO - Final validation performance:
Loss: 3.259, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:41:48,066 - INFO - Beginning epoch 618/800
2025-03-07 11:41:48,072 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:41:48,479 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:41:48,846 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:41:49,211 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:41:49,581 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:41:49,963 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:41:50,344 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:41:50,727 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:41:51,075 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:41:51,428 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:41:51,801 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 11:41:52,171 - INFO - training batch 551, loss: 0.431, 17632/28000 datapoints
2025-03-07 11:41:52,524 - INFO - training batch 601, loss: 0.471, 19232/28000 datapoints
2025-03-07 11:41:52,888 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:41:53,250 - INFO - training batch 701, loss: 0.018, 22432/28000 datapoints
2025-03-07 11:41:53,654 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:41:54,062 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:41:54,411 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:41:54,596 - INFO - validation batch 1, loss: 0.396, 32/6976 datapoints
2025-03-07 11:41:54,662 - INFO - validation batch 51, loss: 8.565, 1632/6976 datapoints
2025-03-07 11:41:54,727 - INFO - validation batch 101, loss: 1.378, 3232/6976 datapoints
2025-03-07 11:41:54,792 - INFO - validation batch 151, loss: 0.887, 4832/6976 datapoints
2025-03-07 11:41:54,857 - INFO - validation batch 201, loss: 5.129, 6432/6976 datapoints
2025-03-07 11:41:54,879 - INFO - Epoch 618/800 done.
2025-03-07 11:41:54,879 - INFO - Final validation performance:
Loss: 3.271, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 11:41:54,880 - INFO - Beginning epoch 619/800
2025-03-07 11:41:54,888 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:41:55,251 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:41:55,626 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:41:55,998 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:41:56,368 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 11:41:56,745 - INFO - training batch 251, loss: 0.280, 8032/28000 datapoints
2025-03-07 11:41:57,139 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:41:57,517 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-07 11:41:57,901 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:41:58,244 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:41:58,628 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:41:58,997 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:41:59,355 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:41:59,713 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:42:00,078 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-07 11:42:00,447 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:42:00,819 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:42:01,178 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:42:01,355 - INFO - validation batch 1, loss: 0.907, 32/6976 datapoints
2025-03-07 11:42:01,422 - INFO - validation batch 51, loss: 9.603, 1632/6976 datapoints
2025-03-07 11:42:01,491 - INFO - validation batch 101, loss: 1.557, 3232/6976 datapoints
2025-03-07 11:42:01,558 - INFO - validation batch 151, loss: 1.099, 4832/6976 datapoints
2025-03-07 11:42:01,631 - INFO - validation batch 201, loss: 4.392, 6432/6976 datapoints
2025-03-07 11:42:01,659 - INFO - Epoch 619/800 done.
2025-03-07 11:42:01,660 - INFO - Final validation performance:
Loss: 3.512, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:42:01,661 - INFO - Beginning epoch 620/800
2025-03-07 11:42:01,670 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:42:02,035 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:42:02,433 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:42:02,792 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:42:03,136 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:42:03,498 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-07 11:42:03,920 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 11:42:04,304 - INFO - training batch 351, loss: 0.057, 11232/28000 datapoints
2025-03-07 11:42:04,658 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:42:05,001 - INFO - training batch 451, loss: 0.349, 14432/28000 datapoints
2025-03-07 11:42:05,374 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:42:05,748 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:42:06,096 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:42:06,462 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:42:06,827 - INFO - training batch 701, loss: 0.118, 22432/28000 datapoints
2025-03-07 11:42:07,184 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:42:07,554 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-07 11:42:07,903 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:42:08,090 - INFO - validation batch 1, loss: 0.661, 32/6976 datapoints
2025-03-07 11:42:08,162 - INFO - validation batch 51, loss: 7.979, 1632/6976 datapoints
2025-03-07 11:42:08,232 - INFO - validation batch 101, loss: 1.945, 3232/6976 datapoints
2025-03-07 11:42:08,297 - INFO - validation batch 151, loss: 1.347, 4832/6976 datapoints
2025-03-07 11:42:08,362 - INFO - validation batch 201, loss: 4.916, 6432/6976 datapoints
2025-03-07 11:42:08,385 - INFO - Epoch 620/800 done.
2025-03-07 11:42:08,386 - INFO - Final validation performance:
Loss: 3.370, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:42:08,386 - INFO - Beginning epoch 621/800
2025-03-07 11:42:08,397 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:42:08,782 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:42:09,153 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:42:09,508 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:42:09,865 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:42:10,223 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:42:10,607 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:42:10,992 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:42:11,339 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:42:11,696 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:42:12,082 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:42:12,463 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:42:12,821 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:42:13,171 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:42:13,539 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:42:13,908 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:42:14,278 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:42:14,620 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:42:14,808 - INFO - validation batch 1, loss: 0.298, 32/6976 datapoints
2025-03-07 11:42:14,872 - INFO - validation batch 51, loss: 7.778, 1632/6976 datapoints
2025-03-07 11:42:14,937 - INFO - validation batch 101, loss: 1.816, 3232/6976 datapoints
2025-03-07 11:42:15,003 - INFO - validation batch 151, loss: 1.407, 4832/6976 datapoints
2025-03-07 11:42:15,074 - INFO - validation batch 201, loss: 4.833, 6432/6976 datapoints
2025-03-07 11:42:15,098 - INFO - Epoch 621/800 done.
2025-03-07 11:42:15,099 - INFO - Final validation performance:
Loss: 3.227, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:42:15,099 - INFO - Beginning epoch 622/800
2025-03-07 11:42:15,107 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:42:15,460 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:42:15,816 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:42:16,164 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:42:16,512 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:42:16,872 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:42:17,245 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:42:17,609 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:42:17,963 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:42:18,316 - INFO - training batch 451, loss: 0.088, 14432/28000 datapoints
2025-03-07 11:42:18,685 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:42:19,046 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:42:19,402 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:42:19,769 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:42:20,130 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:42:20,542 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:42:20,930 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:42:21,305 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:42:21,502 - INFO - validation batch 1, loss: 0.346, 32/6976 datapoints
2025-03-07 11:42:21,567 - INFO - validation batch 51, loss: 7.452, 1632/6976 datapoints
2025-03-07 11:42:21,632 - INFO - validation batch 101, loss: 2.443, 3232/6976 datapoints
2025-03-07 11:42:21,700 - INFO - validation batch 151, loss: 1.882, 4832/6976 datapoints
2025-03-07 11:42:21,767 - INFO - validation batch 201, loss: 5.965, 6432/6976 datapoints
2025-03-07 11:42:21,792 - INFO - Epoch 622/800 done.
2025-03-07 11:42:21,792 - INFO - Final validation performance:
Loss: 3.618, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 11:42:21,793 - INFO - Beginning epoch 623/800
2025-03-07 11:42:21,799 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 11:42:22,151 - INFO - training batch 51, loss: 0.076, 1632/28000 datapoints
2025-03-07 11:42:22,523 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:42:22,896 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:42:23,258 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:42:23,635 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:42:24,012 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:42:24,388 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:42:24,723 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:42:25,070 - INFO - training batch 451, loss: 0.052, 14432/28000 datapoints
2025-03-07 11:42:25,436 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:42:25,790 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:42:26,150 - INFO - training batch 601, loss: 0.571, 19232/28000 datapoints
2025-03-07 11:42:26,490 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:42:26,844 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:42:27,205 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:42:27,570 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:42:27,924 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:42:28,110 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-07 11:42:28,175 - INFO - validation batch 51, loss: 7.875, 1632/6976 datapoints
2025-03-07 11:42:28,241 - INFO - validation batch 101, loss: 1.720, 3232/6976 datapoints
2025-03-07 11:42:28,309 - INFO - validation batch 151, loss: 1.775, 4832/6976 datapoints
2025-03-07 11:42:28,370 - INFO - validation batch 201, loss: 5.014, 6432/6976 datapoints
2025-03-07 11:42:28,390 - INFO - Epoch 623/800 done.
2025-03-07 11:42:28,391 - INFO - Final validation performance:
Loss: 3.302, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:42:28,391 - INFO - Beginning epoch 624/800
2025-03-07 11:42:28,401 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:42:28,755 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:42:29,118 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:42:29,465 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:42:29,831 - INFO - training batch 201, loss: 0.353, 6432/28000 datapoints
2025-03-07 11:42:30,182 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 11:42:30,613 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:42:30,991 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-07 11:42:31,361 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:42:31,716 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-07 11:42:32,103 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:42:32,460 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:42:32,828 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:42:33,182 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:42:33,539 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 11:42:33,896 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:42:34,259 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:42:34,612 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:42:34,803 - INFO - validation batch 1, loss: 0.307, 32/6976 datapoints
2025-03-07 11:42:34,866 - INFO - validation batch 51, loss: 7.821, 1632/6976 datapoints
2025-03-07 11:42:34,929 - INFO - validation batch 101, loss: 1.716, 3232/6976 datapoints
2025-03-07 11:42:34,988 - INFO - validation batch 151, loss: 1.153, 4832/6976 datapoints
2025-03-07 11:42:35,052 - INFO - validation batch 201, loss: 4.882, 6432/6976 datapoints
2025-03-07 11:42:35,075 - INFO - Epoch 624/800 done.
2025-03-07 11:42:35,075 - INFO - Final validation performance:
Loss: 3.176, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:42:35,075 - INFO - Beginning epoch 625/800
2025-03-07 11:42:35,082 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:42:35,433 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:42:35,782 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:42:36,114 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:42:36,472 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:42:36,827 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-07 11:42:37,186 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:42:37,560 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:42:37,902 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:42:38,246 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:42:38,635 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:42:39,004 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:42:39,367 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:42:39,759 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:42:40,129 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:42:40,496 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:42:40,893 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:42:41,252 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:42:41,460 - INFO - validation batch 1, loss: 0.245, 32/6976 datapoints
2025-03-07 11:42:41,526 - INFO - validation batch 51, loss: 7.790, 1632/6976 datapoints
2025-03-07 11:42:41,591 - INFO - validation batch 101, loss: 1.913, 3232/6976 datapoints
2025-03-07 11:42:41,655 - INFO - validation batch 151, loss: 1.465, 4832/6976 datapoints
2025-03-07 11:42:41,720 - INFO - validation batch 201, loss: 5.322, 6432/6976 datapoints
2025-03-07 11:42:41,745 - INFO - Epoch 625/800 done.
2025-03-07 11:42:41,745 - INFO - Final validation performance:
Loss: 3.347, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:42:41,746 - INFO - Beginning epoch 626/800
2025-03-07 11:42:41,753 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:42:42,101 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:42:42,463 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:42:42,822 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:42:43,177 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:42:43,551 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:42:43,914 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:42:44,286 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:42:44,631 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:42:44,995 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:42:45,371 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:42:45,739 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:42:46,113 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:42:46,462 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:42:46,818 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:42:47,174 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:42:47,545 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:42:47,905 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:42:48,096 - INFO - validation batch 1, loss: 0.197, 32/6976 datapoints
2025-03-07 11:42:48,164 - INFO - validation batch 51, loss: 7.925, 1632/6976 datapoints
2025-03-07 11:42:48,232 - INFO - validation batch 101, loss: 1.854, 3232/6976 datapoints
2025-03-07 11:42:48,297 - INFO - validation batch 151, loss: 1.349, 4832/6976 datapoints
2025-03-07 11:42:48,365 - INFO - validation batch 201, loss: 5.139, 6432/6976 datapoints
2025-03-07 11:42:48,387 - INFO - Epoch 626/800 done.
2025-03-07 11:42:48,387 - INFO - Final validation performance:
Loss: 3.293, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:42:48,388 - INFO - Beginning epoch 627/800
2025-03-07 11:42:48,398 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:42:48,749 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:42:49,097 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:42:49,449 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:42:49,806 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:42:50,173 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:42:50,539 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:42:50,924 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:42:51,259 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:42:51,641 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:42:52,020 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:42:52,397 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:42:52,761 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:42:53,119 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:42:53,486 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:42:53,851 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:42:54,218 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:42:54,572 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:42:54,761 - INFO - validation batch 1, loss: 0.243, 32/6976 datapoints
2025-03-07 11:42:54,830 - INFO - validation batch 51, loss: 7.931, 1632/6976 datapoints
2025-03-07 11:42:54,896 - INFO - validation batch 101, loss: 1.871, 3232/6976 datapoints
2025-03-07 11:42:54,959 - INFO - validation batch 151, loss: 1.325, 4832/6976 datapoints
2025-03-07 11:42:55,025 - INFO - validation batch 201, loss: 5.053, 6432/6976 datapoints
2025-03-07 11:42:55,050 - INFO - Epoch 627/800 done.
2025-03-07 11:42:55,050 - INFO - Final validation performance:
Loss: 3.285, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:42:55,051 - INFO - Beginning epoch 628/800
2025-03-07 11:42:55,057 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:42:55,403 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:42:55,755 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:42:56,108 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:42:56,468 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:42:56,835 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:42:57,207 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:42:57,581 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:42:57,926 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:42:58,282 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:42:58,659 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:42:59,035 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:42:59,411 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:42:59,774 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:43:00,147 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:43:00,522 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:43:00,894 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:43:01,251 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:43:01,443 - INFO - validation batch 1, loss: 0.276, 32/6976 datapoints
2025-03-07 11:43:01,533 - INFO - validation batch 51, loss: 7.870, 1632/6976 datapoints
2025-03-07 11:43:01,605 - INFO - validation batch 101, loss: 1.859, 3232/6976 datapoints
2025-03-07 11:43:01,675 - INFO - validation batch 151, loss: 1.298, 4832/6976 datapoints
2025-03-07 11:43:01,742 - INFO - validation batch 201, loss: 5.122, 6432/6976 datapoints
2025-03-07 11:43:01,763 - INFO - Epoch 628/800 done.
2025-03-07 11:43:01,763 - INFO - Final validation performance:
Loss: 3.285, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:43:01,764 - INFO - Beginning epoch 629/800
2025-03-07 11:43:01,771 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:43:02,119 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:43:02,470 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:43:02,817 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:43:03,169 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:43:03,531 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:43:03,894 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:43:04,264 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:43:04,598 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:43:04,948 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:43:05,335 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:43:05,714 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:43:06,077 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:43:06,440 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:43:06,813 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:43:07,180 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:43:07,551 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:43:07,906 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:43:08,094 - INFO - validation batch 1, loss: 0.283, 32/6976 datapoints
2025-03-07 11:43:08,163 - INFO - validation batch 51, loss: 7.874, 1632/6976 datapoints
2025-03-07 11:43:08,228 - INFO - validation batch 101, loss: 1.853, 3232/6976 datapoints
2025-03-07 11:43:08,295 - INFO - validation batch 151, loss: 1.272, 4832/6976 datapoints
2025-03-07 11:43:08,359 - INFO - validation batch 201, loss: 5.107, 6432/6976 datapoints
2025-03-07 11:43:08,380 - INFO - Epoch 629/800 done.
2025-03-07 11:43:08,380 - INFO - Final validation performance:
Loss: 3.278, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:43:08,381 - INFO - Beginning epoch 630/800
2025-03-07 11:43:08,388 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:43:08,750 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:43:09,094 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:43:09,445 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:43:09,802 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:43:10,166 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:43:10,533 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:43:10,899 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:43:11,228 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:43:11,600 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:43:11,987 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:43:12,362 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:43:12,730 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:43:13,088 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:43:13,456 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:43:13,821 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:43:14,188 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:43:14,543 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:43:14,733 - INFO - validation batch 1, loss: 0.283, 32/6976 datapoints
2025-03-07 11:43:14,798 - INFO - validation batch 51, loss: 7.883, 1632/6976 datapoints
2025-03-07 11:43:14,865 - INFO - validation batch 101, loss: 1.836, 3232/6976 datapoints
2025-03-07 11:43:14,932 - INFO - validation batch 151, loss: 1.239, 4832/6976 datapoints
2025-03-07 11:43:14,998 - INFO - validation batch 201, loss: 5.093, 6432/6976 datapoints
2025-03-07 11:43:15,019 - INFO - Epoch 630/800 done.
2025-03-07 11:43:15,019 - INFO - Final validation performance:
Loss: 3.267, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:43:15,020 - INFO - Beginning epoch 631/800
2025-03-07 11:43:15,026 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:43:15,373 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:43:15,725 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:43:16,073 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:43:16,432 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:43:16,820 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:43:17,183 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:43:17,552 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:43:17,890 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:43:18,244 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:43:18,625 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:43:18,993 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:43:19,352 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:43:19,708 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:43:20,076 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:43:20,442 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:43:20,808 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:43:21,161 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:43:21,351 - INFO - validation batch 1, loss: 0.276, 32/6976 datapoints
2025-03-07 11:43:21,417 - INFO - validation batch 51, loss: 7.891, 1632/6976 datapoints
2025-03-07 11:43:21,482 - INFO - validation batch 101, loss: 1.814, 3232/6976 datapoints
2025-03-07 11:43:21,549 - INFO - validation batch 151, loss: 1.205, 4832/6976 datapoints
2025-03-07 11:43:21,620 - INFO - validation batch 201, loss: 5.082, 6432/6976 datapoints
2025-03-07 11:43:21,651 - INFO - Epoch 631/800 done.
2025-03-07 11:43:21,651 - INFO - Final validation performance:
Loss: 3.254, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:43:21,652 - INFO - Beginning epoch 632/800
2025-03-07 11:43:21,664 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:43:22,040 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:43:22,401 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:43:22,755 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:43:23,115 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:43:23,489 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:43:23,855 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:43:24,220 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:43:24,563 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:43:24,914 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:43:25,297 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:43:25,667 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:43:26,069 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:43:26,427 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:43:26,790 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:43:27,153 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:43:27,514 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:43:27,864 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:43:28,053 - INFO - validation batch 1, loss: 0.264, 32/6976 datapoints
2025-03-07 11:43:28,119 - INFO - validation batch 51, loss: 7.895, 1632/6976 datapoints
2025-03-07 11:43:28,185 - INFO - validation batch 101, loss: 1.794, 3232/6976 datapoints
2025-03-07 11:43:28,253 - INFO - validation batch 151, loss: 1.181, 4832/6976 datapoints
2025-03-07 11:43:28,318 - INFO - validation batch 201, loss: 5.075, 6432/6976 datapoints
2025-03-07 11:43:28,342 - INFO - Epoch 632/800 done.
2025-03-07 11:43:28,342 - INFO - Final validation performance:
Loss: 3.242, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:43:28,343 - INFO - Beginning epoch 633/800
2025-03-07 11:43:28,350 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:43:28,707 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:43:29,053 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:43:29,417 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:43:29,785 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:43:30,155 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:43:30,552 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:43:30,924 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:43:31,259 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:43:31,619 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:43:32,028 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:43:32,405 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:43:32,763 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:43:33,116 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:43:33,480 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:43:33,844 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:43:34,203 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:43:34,551 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:43:34,737 - INFO - validation batch 1, loss: 0.244, 32/6976 datapoints
2025-03-07 11:43:34,804 - INFO - validation batch 51, loss: 7.894, 1632/6976 datapoints
2025-03-07 11:43:34,869 - INFO - validation batch 101, loss: 1.775, 3232/6976 datapoints
2025-03-07 11:43:34,936 - INFO - validation batch 151, loss: 1.174, 4832/6976 datapoints
2025-03-07 11:43:35,003 - INFO - validation batch 201, loss: 5.068, 6432/6976 datapoints
2025-03-07 11:43:35,024 - INFO - Epoch 633/800 done.
2025-03-07 11:43:35,025 - INFO - Final validation performance:
Loss: 3.231, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:43:35,025 - INFO - Beginning epoch 634/800
2025-03-07 11:43:35,034 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:43:35,395 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:43:35,744 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:43:36,096 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:43:36,561 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:43:36,932 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:43:37,306 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:43:37,682 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:43:38,019 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:43:38,382 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:43:38,777 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:43:39,163 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:43:39,530 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:43:39,901 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:43:40,303 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:43:40,666 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:43:41,028 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:43:41,388 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:43:41,575 - INFO - validation batch 1, loss: 0.220, 32/6976 datapoints
2025-03-07 11:43:41,643 - INFO - validation batch 51, loss: 7.891, 1632/6976 datapoints
2025-03-07 11:43:41,710 - INFO - validation batch 101, loss: 1.759, 3232/6976 datapoints
2025-03-07 11:43:41,777 - INFO - validation batch 151, loss: 1.183, 4832/6976 datapoints
2025-03-07 11:43:41,855 - INFO - validation batch 201, loss: 5.072, 6432/6976 datapoints
2025-03-07 11:43:41,889 - INFO - Epoch 634/800 done.
2025-03-07 11:43:41,889 - INFO - Final validation performance:
Loss: 3.225, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:43:41,890 - INFO - Beginning epoch 635/800
2025-03-07 11:43:41,898 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:43:42,261 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:43:42,612 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:43:42,966 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:43:43,324 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:43:43,687 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:43:44,055 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:43:44,431 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:43:44,767 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:43:45,134 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:43:45,521 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:43:45,892 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:43:46,249 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:43:46,616 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:43:46,988 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:43:47,358 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:43:47,736 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:43:48,086 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:43:48,277 - INFO - validation batch 1, loss: 0.200, 32/6976 datapoints
2025-03-07 11:43:48,341 - INFO - validation batch 51, loss: 7.887, 1632/6976 datapoints
2025-03-07 11:43:48,407 - INFO - validation batch 101, loss: 1.748, 3232/6976 datapoints
2025-03-07 11:43:48,471 - INFO - validation batch 151, loss: 1.190, 4832/6976 datapoints
2025-03-07 11:43:48,535 - INFO - validation batch 201, loss: 5.083, 6432/6976 datapoints
2025-03-07 11:43:48,556 - INFO - Epoch 635/800 done.
2025-03-07 11:43:48,556 - INFO - Final validation performance:
Loss: 3.222, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:43:48,557 - INFO - Beginning epoch 636/800
2025-03-07 11:43:48,564 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:43:48,932 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:43:49,310 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:43:49,667 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:43:50,026 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:43:50,395 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:43:50,765 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:43:51,134 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:43:51,470 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:43:51,825 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:43:52,232 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:43:52,608 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:43:52,966 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:43:53,338 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:43:53,718 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:43:54,081 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:43:54,448 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:43:54,797 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:43:54,983 - INFO - validation batch 1, loss: 0.190, 32/6976 datapoints
2025-03-07 11:43:55,054 - INFO - validation batch 51, loss: 7.894, 1632/6976 datapoints
2025-03-07 11:43:55,120 - INFO - validation batch 101, loss: 1.743, 3232/6976 datapoints
2025-03-07 11:43:55,185 - INFO - validation batch 151, loss: 1.192, 4832/6976 datapoints
2025-03-07 11:43:55,256 - INFO - validation batch 201, loss: 5.108, 6432/6976 datapoints
2025-03-07 11:43:55,280 - INFO - Epoch 636/800 done.
2025-03-07 11:43:55,280 - INFO - Final validation performance:
Loss: 3.225, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:43:55,281 - INFO - Beginning epoch 637/800
2025-03-07 11:43:55,289 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:43:55,647 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:43:56,004 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:43:56,362 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:43:56,732 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:43:57,095 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:43:57,472 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:43:57,848 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:43:58,181 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:43:58,536 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:43:58,909 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:43:59,283 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:43:59,644 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:44:00,001 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:44:00,373 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:44:00,740 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:44:01,104 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:44:01,448 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:44:01,632 - INFO - validation batch 1, loss: 0.183, 32/6976 datapoints
2025-03-07 11:44:01,696 - INFO - validation batch 51, loss: 7.903, 1632/6976 datapoints
2025-03-07 11:44:01,761 - INFO - validation batch 101, loss: 1.753, 3232/6976 datapoints
2025-03-07 11:44:01,827 - INFO - validation batch 151, loss: 1.195, 4832/6976 datapoints
2025-03-07 11:44:01,888 - INFO - validation batch 201, loss: 5.143, 6432/6976 datapoints
2025-03-07 11:44:01,910 - INFO - Epoch 637/800 done.
2025-03-07 11:44:01,910 - INFO - Final validation performance:
Loss: 3.235, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:44:01,910 - INFO - Beginning epoch 638/800
2025-03-07 11:44:01,918 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:44:02,293 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:44:02,659 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:44:03,014 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:44:03,375 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:44:03,739 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:44:04,106 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:44:04,481 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:44:04,812 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:44:05,167 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:44:05,547 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:44:05,916 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:44:06,276 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:44:06,641 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:44:07,019 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:44:07,388 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:44:07,749 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:44:08,092 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:44:08,279 - INFO - validation batch 1, loss: 0.184, 32/6976 datapoints
2025-03-07 11:44:08,348 - INFO - validation batch 51, loss: 7.917, 1632/6976 datapoints
2025-03-07 11:44:08,414 - INFO - validation batch 101, loss: 1.789, 3232/6976 datapoints
2025-03-07 11:44:08,476 - INFO - validation batch 151, loss: 1.190, 4832/6976 datapoints
2025-03-07 11:44:08,538 - INFO - validation batch 201, loss: 5.181, 6432/6976 datapoints
2025-03-07 11:44:08,560 - INFO - Epoch 638/800 done.
2025-03-07 11:44:08,560 - INFO - Final validation performance:
Loss: 3.252, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:44:08,561 - INFO - Beginning epoch 639/800
2025-03-07 11:44:08,568 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:44:08,925 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:44:09,282 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:44:09,642 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:44:09,996 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:44:10,364 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:44:10,745 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:44:11,123 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:44:11,464 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:44:11,824 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:44:12,240 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:44:12,632 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:44:13,002 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:44:13,366 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:44:13,731 - INFO - training batch 701, loss: 0.662, 22432/28000 datapoints
2025-03-07 11:44:14,100 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:44:14,468 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-07 11:44:14,809 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:44:14,996 - INFO - validation batch 1, loss: 0.101, 32/6976 datapoints
2025-03-07 11:44:15,064 - INFO - validation batch 51, loss: 6.237, 1632/6976 datapoints
2025-03-07 11:44:15,130 - INFO - validation batch 101, loss: 2.081, 3232/6976 datapoints
2025-03-07 11:44:15,197 - INFO - validation batch 151, loss: 1.510, 4832/6976 datapoints
2025-03-07 11:44:15,265 - INFO - validation batch 201, loss: 5.883, 6432/6976 datapoints
2025-03-07 11:44:15,290 - INFO - Epoch 639/800 done.
2025-03-07 11:44:15,290 - INFO - Final validation performance:
Loss: 3.162, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 11:44:15,291 - INFO - Beginning epoch 640/800
2025-03-07 11:44:15,298 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:44:15,643 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:44:16,005 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:44:16,357 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:44:16,703 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:44:17,061 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:44:17,426 - INFO - training batch 301, loss: 0.178, 9632/28000 datapoints
2025-03-07 11:44:17,807 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:44:18,156 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:44:18,522 - INFO - training batch 451, loss: 0.047, 14432/28000 datapoints
2025-03-07 11:44:18,885 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:44:19,245 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:44:19,602 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:44:19,958 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:44:20,306 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 11:44:20,691 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:44:21,061 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:44:21,426 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:44:21,618 - INFO - validation batch 1, loss: 0.647, 32/6976 datapoints
2025-03-07 11:44:21,685 - INFO - validation batch 51, loss: 6.963, 1632/6976 datapoints
2025-03-07 11:44:21,753 - INFO - validation batch 101, loss: 1.863, 3232/6976 datapoints
2025-03-07 11:44:21,819 - INFO - validation batch 151, loss: 0.782, 4832/6976 datapoints
2025-03-07 11:44:21,884 - INFO - validation batch 201, loss: 5.045, 6432/6976 datapoints
2025-03-07 11:44:21,905 - INFO - Epoch 640/800 done.
2025-03-07 11:44:21,905 - INFO - Final validation performance:
Loss: 3.060, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:44:21,906 - INFO - Beginning epoch 641/800
2025-03-07 11:44:21,914 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:44:22,281 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:44:22,658 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:44:23,025 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:44:23,394 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:44:23,757 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:44:24,138 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:44:24,522 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:44:24,867 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:44:25,232 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:44:25,606 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:44:25,972 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:44:26,370 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:44:26,728 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:44:27,104 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:44:27,461 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:44:27,829 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:44:28,189 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:44:28,378 - INFO - validation batch 1, loss: 1.035, 32/6976 datapoints
2025-03-07 11:44:28,446 - INFO - validation batch 51, loss: 8.036, 1632/6976 datapoints
2025-03-07 11:44:28,511 - INFO - validation batch 101, loss: 2.023, 3232/6976 datapoints
2025-03-07 11:44:28,579 - INFO - validation batch 151, loss: 0.392, 4832/6976 datapoints
2025-03-07 11:44:28,671 - INFO - validation batch 201, loss: 4.793, 6432/6976 datapoints
2025-03-07 11:44:28,704 - INFO - Epoch 641/800 done.
2025-03-07 11:44:28,704 - INFO - Final validation performance:
Loss: 3.256, top-1 acc: 0.873top-5 acc: 0.873
2025-03-07 11:44:28,705 - INFO - Beginning epoch 642/800
2025-03-07 11:44:28,713 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:44:29,089 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:44:29,464 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:44:29,819 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:44:30,197 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:44:30,584 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:44:30,954 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:44:31,328 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:44:31,688 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:44:32,045 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:44:32,459 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:44:32,820 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:44:33,187 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:44:33,547 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:44:33,925 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:44:34,277 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:44:34,629 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:44:34,988 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 11:44:35,172 - INFO - validation batch 1, loss: 1.126, 32/6976 datapoints
2025-03-07 11:44:35,237 - INFO - validation batch 51, loss: 7.447, 1632/6976 datapoints
2025-03-07 11:44:35,304 - INFO - validation batch 101, loss: 2.139, 3232/6976 datapoints
2025-03-07 11:44:35,370 - INFO - validation batch 151, loss: 0.898, 4832/6976 datapoints
2025-03-07 11:44:35,441 - INFO - validation batch 201, loss: 4.547, 6432/6976 datapoints
2025-03-07 11:44:35,465 - INFO - Epoch 642/800 done.
2025-03-07 11:44:35,466 - INFO - Final validation performance:
Loss: 3.231, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 11:44:35,466 - INFO - Beginning epoch 643/800
2025-03-07 11:44:35,475 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:44:35,827 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:44:36,192 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:44:36,548 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:44:36,909 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:44:37,269 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:44:37,659 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:44:38,035 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:44:38,387 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:44:38,754 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:44:39,133 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:44:39,516 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:44:39,905 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:44:40,261 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:44:40,642 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:44:41,014 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:44:41,374 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:44:41,738 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:44:41,930 - INFO - validation batch 1, loss: 0.222, 32/6976 datapoints
2025-03-07 11:44:41,995 - INFO - validation batch 51, loss: 7.268, 1632/6976 datapoints
2025-03-07 11:44:42,067 - INFO - validation batch 101, loss: 1.980, 3232/6976 datapoints
2025-03-07 11:44:42,134 - INFO - validation batch 151, loss: 0.852, 4832/6976 datapoints
2025-03-07 11:44:42,199 - INFO - validation batch 201, loss: 4.975, 6432/6976 datapoints
2025-03-07 11:44:42,221 - INFO - Epoch 643/800 done.
2025-03-07 11:44:42,221 - INFO - Final validation performance:
Loss: 3.059, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:44:42,222 - INFO - Beginning epoch 644/800
2025-03-07 11:44:42,233 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:44:42,600 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:44:42,963 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:44:43,304 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:44:43,677 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:44:44,035 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:44:44,406 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:44:44,777 - INFO - training batch 351, loss: 0.243, 11232/28000 datapoints
2025-03-07 11:44:45,135 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:44:45,497 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:44:45,863 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:44:46,210 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:44:46,583 - INFO - training batch 601, loss: 0.012, 19232/28000 datapoints
2025-03-07 11:44:46,944 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:44:47,313 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 11:44:47,700 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:44:48,047 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:44:48,404 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:44:48,600 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-07 11:44:48,662 - INFO - validation batch 51, loss: 6.178, 1632/6976 datapoints
2025-03-07 11:44:48,724 - INFO - validation batch 101, loss: 1.878, 3232/6976 datapoints
2025-03-07 11:44:48,786 - INFO - validation batch 151, loss: 1.151, 4832/6976 datapoints
2025-03-07 11:44:48,848 - INFO - validation batch 201, loss: 4.954, 6432/6976 datapoints
2025-03-07 11:44:48,868 - INFO - Epoch 644/800 done.
2025-03-07 11:44:48,869 - INFO - Final validation performance:
Loss: 2.858, top-1 acc: 0.872top-5 acc: 0.872
2025-03-07 11:44:48,869 - INFO - Beginning epoch 645/800
2025-03-07 11:44:48,877 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 11:44:49,225 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:44:49,610 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:44:49,974 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:44:50,336 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:44:50,722 - INFO - training batch 251, loss: 0.014, 8032/28000 datapoints
2025-03-07 11:44:51,109 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:44:51,487 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:44:51,831 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:44:52,195 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:44:52,596 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:44:52,969 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:44:53,320 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:44:53,680 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:44:54,045 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:44:54,418 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:44:54,767 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:44:55,126 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:44:55,308 - INFO - validation batch 1, loss: 0.421, 32/6976 datapoints
2025-03-07 11:44:55,374 - INFO - validation batch 51, loss: 7.461, 1632/6976 datapoints
2025-03-07 11:44:55,443 - INFO - validation batch 101, loss: 1.972, 3232/6976 datapoints
2025-03-07 11:44:55,509 - INFO - validation batch 151, loss: 0.453, 4832/6976 datapoints
2025-03-07 11:44:55,574 - INFO - validation batch 201, loss: 5.335, 6432/6976 datapoints
2025-03-07 11:44:55,599 - INFO - Epoch 645/800 done.
2025-03-07 11:44:55,599 - INFO - Final validation performance:
Loss: 3.129, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:44:55,600 - INFO - Beginning epoch 646/800
2025-03-07 11:44:55,607 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:44:55,962 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:44:56,315 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:44:56,673 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:44:57,038 - INFO - training batch 201, loss: 0.091, 6432/28000 datapoints
2025-03-07 11:44:57,406 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 11:44:57,798 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 11:44:58,170 - INFO - training batch 351, loss: 0.045, 11232/28000 datapoints
2025-03-07 11:44:58,531 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:44:58,896 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:44:59,271 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:44:59,635 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 11:44:59,992 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:45:00,351 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:45:00,716 - INFO - training batch 701, loss: 0.066, 22432/28000 datapoints
2025-03-07 11:45:01,074 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:45:01,446 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:45:01,802 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 11:45:01,991 - INFO - validation batch 1, loss: 0.733, 32/6976 datapoints
2025-03-07 11:45:02,055 - INFO - validation batch 51, loss: 8.333, 1632/6976 datapoints
2025-03-07 11:45:02,121 - INFO - validation batch 101, loss: 1.348, 3232/6976 datapoints
2025-03-07 11:45:02,184 - INFO - validation batch 151, loss: 0.659, 4832/6976 datapoints
2025-03-07 11:45:02,248 - INFO - validation batch 201, loss: 5.178, 6432/6976 datapoints
2025-03-07 11:45:02,269 - INFO - Epoch 646/800 done.
2025-03-07 11:45:02,269 - INFO - Final validation performance:
Loss: 3.250, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:45:02,270 - INFO - Beginning epoch 647/800
2025-03-07 11:45:02,279 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:45:02,653 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 11:45:03,040 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:45:03,404 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:45:03,771 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:45:04,129 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:45:04,502 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:45:04,878 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:45:05,225 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:45:05,591 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:45:05,957 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:45:06,325 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:45:06,694 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:45:07,051 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:45:07,417 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:45:07,788 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 11:45:08,156 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:45:08,507 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-07 11:45:08,701 - INFO - validation batch 1, loss: 0.933, 32/6976 datapoints
2025-03-07 11:45:08,763 - INFO - validation batch 51, loss: 7.145, 1632/6976 datapoints
2025-03-07 11:45:08,824 - INFO - validation batch 101, loss: 1.998, 3232/6976 datapoints
2025-03-07 11:45:08,886 - INFO - validation batch 151, loss: 0.881, 4832/6976 datapoints
2025-03-07 11:45:08,950 - INFO - validation batch 201, loss: 5.629, 6432/6976 datapoints
2025-03-07 11:45:08,971 - INFO - Epoch 647/800 done.
2025-03-07 11:45:08,971 - INFO - Final validation performance:
Loss: 3.317, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:45:08,972 - INFO - Beginning epoch 648/800
2025-03-07 11:45:08,978 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:45:09,341 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:45:09,723 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:45:10,079 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:45:10,433 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-07 11:45:10,794 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:45:11,162 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:45:11,530 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 11:45:11,885 - INFO - training batch 401, loss: 0.042, 12832/28000 datapoints
2025-03-07 11:45:12,247 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-07 11:45:12,622 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:45:13,027 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:45:13,380 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 11:45:13,744 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:45:14,117 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:45:14,485 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:45:14,868 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:45:15,228 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:45:15,412 - INFO - validation batch 1, loss: 0.689, 32/6976 datapoints
2025-03-07 11:45:15,478 - INFO - validation batch 51, loss: 6.472, 1632/6976 datapoints
2025-03-07 11:45:15,543 - INFO - validation batch 101, loss: 1.699, 3232/6976 datapoints
2025-03-07 11:45:15,609 - INFO - validation batch 151, loss: 0.569, 4832/6976 datapoints
2025-03-07 11:45:15,674 - INFO - validation batch 201, loss: 5.717, 6432/6976 datapoints
2025-03-07 11:45:15,698 - INFO - Epoch 648/800 done.
2025-03-07 11:45:15,699 - INFO - Final validation performance:
Loss: 3.029, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:45:15,699 - INFO - Beginning epoch 649/800
2025-03-07 11:45:15,706 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:45:16,059 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-07 11:45:16,426 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:45:16,817 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 11:45:17,252 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:45:17,636 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:45:18,019 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:45:18,608 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:45:19,288 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:45:20,069 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:45:20,536 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:45:20,998 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:45:21,465 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-07 11:45:22,149 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:45:22,632 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:45:23,155 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:45:23,827 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:45:24,590 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 11:45:24,793 - INFO - validation batch 1, loss: 0.543, 32/6976 datapoints
2025-03-07 11:45:24,873 - INFO - validation batch 51, loss: 7.536, 1632/6976 datapoints
2025-03-07 11:45:24,942 - INFO - validation batch 101, loss: 1.765, 3232/6976 datapoints
2025-03-07 11:45:25,010 - INFO - validation batch 151, loss: 0.601, 4832/6976 datapoints
2025-03-07 11:45:25,077 - INFO - validation batch 201, loss: 5.038, 6432/6976 datapoints
2025-03-07 11:45:25,100 - INFO - Epoch 649/800 done.
2025-03-07 11:45:25,100 - INFO - Final validation performance:
Loss: 3.096, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:45:25,101 - INFO - Beginning epoch 650/800
2025-03-07 11:45:25,109 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:45:25,486 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:45:25,858 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:45:26,313 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:45:26,696 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:45:27,085 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:45:27,489 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:45:27,865 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:45:28,207 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:45:28,574 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:45:28,960 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:45:29,334 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:45:29,693 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:45:30,077 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:45:30,508 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:45:30,890 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:45:31,259 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:45:31,626 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:45:31,832 - INFO - validation batch 1, loss: 0.564, 32/6976 datapoints
2025-03-07 11:45:31,898 - INFO - validation batch 51, loss: 7.514, 1632/6976 datapoints
2025-03-07 11:45:31,966 - INFO - validation batch 101, loss: 1.702, 3232/6976 datapoints
2025-03-07 11:45:32,032 - INFO - validation batch 151, loss: 0.583, 4832/6976 datapoints
2025-03-07 11:45:32,097 - INFO - validation batch 201, loss: 5.103, 6432/6976 datapoints
2025-03-07 11:45:32,118 - INFO - Epoch 650/800 done.
2025-03-07 11:45:32,118 - INFO - Final validation performance:
Loss: 3.093, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:45:32,119 - INFO - Beginning epoch 651/800
2025-03-07 11:45:32,128 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:45:32,507 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:45:32,865 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:45:33,251 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:45:33,692 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:45:34,098 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:45:34,494 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:45:34,888 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:45:35,239 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:45:35,618 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:45:36,003 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:45:36,401 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:45:36,756 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:45:37,128 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:45:37,511 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:45:37,890 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:45:38,259 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:45:38,657 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:45:38,848 - INFO - validation batch 1, loss: 0.553, 32/6976 datapoints
2025-03-07 11:45:38,913 - INFO - validation batch 51, loss: 7.543, 1632/6976 datapoints
2025-03-07 11:45:38,981 - INFO - validation batch 101, loss: 1.697, 3232/6976 datapoints
2025-03-07 11:45:39,051 - INFO - validation batch 151, loss: 0.572, 4832/6976 datapoints
2025-03-07 11:45:39,122 - INFO - validation batch 201, loss: 5.152, 6432/6976 datapoints
2025-03-07 11:45:39,218 - INFO - Epoch 651/800 done.
2025-03-07 11:45:39,218 - INFO - Final validation performance:
Loss: 3.103, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:45:39,219 - INFO - Beginning epoch 652/800
2025-03-07 11:45:39,234 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:45:39,635 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:45:40,004 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:45:40,387 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:45:40,753 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:45:41,156 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:45:41,540 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:45:41,924 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:45:42,269 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:45:42,643 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:45:43,028 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:45:43,433 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:45:43,812 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:45:44,206 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:45:44,588 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:45:44,979 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:45:45,373 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:45:45,746 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:45:45,932 - INFO - validation batch 1, loss: 0.545, 32/6976 datapoints
2025-03-07 11:45:46,004 - INFO - validation batch 51, loss: 7.570, 1632/6976 datapoints
2025-03-07 11:45:46,071 - INFO - validation batch 101, loss: 1.696, 3232/6976 datapoints
2025-03-07 11:45:46,140 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-07 11:45:46,206 - INFO - validation batch 201, loss: 5.158, 6432/6976 datapoints
2025-03-07 11:45:46,229 - INFO - Epoch 652/800 done.
2025-03-07 11:45:46,229 - INFO - Final validation performance:
Loss: 3.111, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:45:46,230 - INFO - Beginning epoch 653/800
2025-03-07 11:45:46,240 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:45:46,609 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:45:46,970 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:45:47,328 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:45:47,696 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:45:48,059 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:45:48,434 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:45:48,934 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:45:49,299 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:45:49,674 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:45:50,067 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:45:50,457 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:45:50,816 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:45:51,191 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:45:51,582 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:45:51,988 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:45:52,418 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:45:52,785 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:45:52,975 - INFO - validation batch 1, loss: 0.541, 32/6976 datapoints
2025-03-07 11:45:53,041 - INFO - validation batch 51, loss: 7.601, 1632/6976 datapoints
2025-03-07 11:45:53,108 - INFO - validation batch 101, loss: 1.693, 3232/6976 datapoints
2025-03-07 11:45:53,192 - INFO - validation batch 151, loss: 0.604, 4832/6976 datapoints
2025-03-07 11:45:53,269 - INFO - validation batch 201, loss: 5.164, 6432/6976 datapoints
2025-03-07 11:45:53,294 - INFO - Epoch 653/800 done.
2025-03-07 11:45:53,294 - INFO - Final validation performance:
Loss: 3.121, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:45:53,295 - INFO - Beginning epoch 654/800
2025-03-07 11:45:53,303 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:45:53,665 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:45:54,035 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:45:54,413 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:45:54,772 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:45:55,139 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:45:55,524 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:45:55,898 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:45:56,238 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:45:56,629 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:45:57,015 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:45:57,394 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:45:57,757 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:45:58,133 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:45:58,522 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:45:58,905 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:45:59,275 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:45:59,642 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:45:59,827 - INFO - validation batch 1, loss: 0.540, 32/6976 datapoints
2025-03-07 11:45:59,892 - INFO - validation batch 51, loss: 7.644, 1632/6976 datapoints
2025-03-07 11:45:59,965 - INFO - validation batch 101, loss: 1.691, 3232/6976 datapoints
2025-03-07 11:46:00,032 - INFO - validation batch 151, loss: 0.624, 4832/6976 datapoints
2025-03-07 11:46:00,100 - INFO - validation batch 201, loss: 5.173, 6432/6976 datapoints
2025-03-07 11:46:00,124 - INFO - Epoch 654/800 done.
2025-03-07 11:46:00,124 - INFO - Final validation performance:
Loss: 3.134, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:46:00,125 - INFO - Beginning epoch 655/800
2025-03-07 11:46:00,135 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:46:00,579 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:46:01,014 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:46:01,388 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:46:01,771 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:46:02,150 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:46:02,537 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:46:02,915 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:46:03,268 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:46:03,654 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:46:04,041 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:46:04,420 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:46:04,779 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:46:05,154 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:46:05,535 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:46:05,904 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:46:06,272 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:46:06,633 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:46:06,820 - INFO - validation batch 1, loss: 0.540, 32/6976 datapoints
2025-03-07 11:46:06,886 - INFO - validation batch 51, loss: 7.689, 1632/6976 datapoints
2025-03-07 11:46:06,952 - INFO - validation batch 101, loss: 1.688, 3232/6976 datapoints
2025-03-07 11:46:07,016 - INFO - validation batch 151, loss: 0.646, 4832/6976 datapoints
2025-03-07 11:46:07,084 - INFO - validation batch 201, loss: 5.185, 6432/6976 datapoints
2025-03-07 11:46:07,105 - INFO - Epoch 655/800 done.
2025-03-07 11:46:07,105 - INFO - Final validation performance:
Loss: 3.150, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:46:07,106 - INFO - Beginning epoch 656/800
2025-03-07 11:46:07,114 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:46:07,468 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:46:07,831 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:46:08,186 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:46:08,624 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:46:08,996 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:46:09,376 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:46:09,761 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:46:10,118 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:46:10,491 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:46:10,883 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:46:11,264 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:46:11,628 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:46:12,000 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:46:12,379 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:46:12,756 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:46:13,120 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:46:13,500 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:46:13,687 - INFO - validation batch 1, loss: 0.543, 32/6976 datapoints
2025-03-07 11:46:13,752 - INFO - validation batch 51, loss: 7.737, 1632/6976 datapoints
2025-03-07 11:46:13,818 - INFO - validation batch 101, loss: 1.688, 3232/6976 datapoints
2025-03-07 11:46:13,883 - INFO - validation batch 151, loss: 0.664, 4832/6976 datapoints
2025-03-07 11:46:13,950 - INFO - validation batch 201, loss: 5.201, 6432/6976 datapoints
2025-03-07 11:46:13,972 - INFO - Epoch 656/800 done.
2025-03-07 11:46:13,972 - INFO - Final validation performance:
Loss: 3.166, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:46:13,973 - INFO - Beginning epoch 657/800
2025-03-07 11:46:13,985 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:46:14,339 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:46:14,699 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:46:15,062 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:46:15,417 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:46:15,780 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:46:16,162 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:46:16,532 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:46:16,870 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:46:17,229 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:46:17,616 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:46:17,992 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:46:18,348 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:46:18,716 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:46:19,104 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:46:19,494 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:46:19,871 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:46:20,235 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:46:20,427 - INFO - validation batch 1, loss: 0.542, 32/6976 datapoints
2025-03-07 11:46:20,498 - INFO - validation batch 51, loss: 7.784, 1632/6976 datapoints
2025-03-07 11:46:20,564 - INFO - validation batch 101, loss: 1.691, 3232/6976 datapoints
2025-03-07 11:46:20,630 - INFO - validation batch 151, loss: 0.681, 4832/6976 datapoints
2025-03-07 11:46:20,693 - INFO - validation batch 201, loss: 5.214, 6432/6976 datapoints
2025-03-07 11:46:20,716 - INFO - Epoch 657/800 done.
2025-03-07 11:46:20,717 - INFO - Final validation performance:
Loss: 3.183, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:46:20,717 - INFO - Beginning epoch 658/800
2025-03-07 11:46:20,726 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:46:21,090 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:46:21,456 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:46:21,817 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:46:22,174 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:46:22,537 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:46:22,919 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:46:23,283 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:46:23,648 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:46:24,004 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:46:24,407 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:46:24,789 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:46:25,146 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:46:25,515 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:46:25,891 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:46:26,298 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:46:26,673 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:46:27,038 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:46:27,225 - INFO - validation batch 1, loss: 0.530, 32/6976 datapoints
2025-03-07 11:46:27,292 - INFO - validation batch 51, loss: 7.833, 1632/6976 datapoints
2025-03-07 11:46:27,358 - INFO - validation batch 101, loss: 1.697, 3232/6976 datapoints
2025-03-07 11:46:27,425 - INFO - validation batch 151, loss: 0.702, 4832/6976 datapoints
2025-03-07 11:46:27,489 - INFO - validation batch 201, loss: 5.229, 6432/6976 datapoints
2025-03-07 11:46:27,510 - INFO - Epoch 658/800 done.
2025-03-07 11:46:27,510 - INFO - Final validation performance:
Loss: 3.198, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:46:27,511 - INFO - Beginning epoch 659/800
2025-03-07 11:46:27,518 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:46:27,884 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:46:28,250 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:46:28,616 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:46:28,977 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:46:29,354 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:46:29,737 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:46:30,106 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:46:30,477 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:46:30,839 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:46:31,221 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:46:31,593 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:46:31,950 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:46:32,315 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:46:32,703 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:46:33,079 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:46:33,450 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:46:33,832 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:46:34,019 - INFO - validation batch 1, loss: 0.506, 32/6976 datapoints
2025-03-07 11:46:34,083 - INFO - validation batch 51, loss: 7.878, 1632/6976 datapoints
2025-03-07 11:46:34,151 - INFO - validation batch 101, loss: 1.708, 3232/6976 datapoints
2025-03-07 11:46:34,216 - INFO - validation batch 151, loss: 0.743, 4832/6976 datapoints
2025-03-07 11:46:34,281 - INFO - validation batch 201, loss: 5.235, 6432/6976 datapoints
2025-03-07 11:46:34,304 - INFO - Epoch 659/800 done.
2025-03-07 11:46:34,304 - INFO - Final validation performance:
Loss: 3.214, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:46:34,304 - INFO - Beginning epoch 660/800
2025-03-07 11:46:34,312 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:46:34,682 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:46:35,057 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:46:35,437 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:46:35,803 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:46:36,169 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:46:36,552 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:46:36,923 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:46:37,266 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:46:37,626 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:46:38,010 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:46:38,380 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:46:38,767 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:46:39,133 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:46:39,526 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:46:39,897 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:46:40,279 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:46:40,647 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:46:40,839 - INFO - validation batch 1, loss: 0.472, 32/6976 datapoints
2025-03-07 11:46:40,913 - INFO - validation batch 51, loss: 7.925, 1632/6976 datapoints
2025-03-07 11:46:40,980 - INFO - validation batch 101, loss: 1.722, 3232/6976 datapoints
2025-03-07 11:46:41,051 - INFO - validation batch 151, loss: 0.803, 4832/6976 datapoints
2025-03-07 11:46:41,141 - INFO - validation batch 201, loss: 5.230, 6432/6976 datapoints
2025-03-07 11:46:41,173 - INFO - Epoch 660/800 done.
2025-03-07 11:46:41,173 - INFO - Final validation performance:
Loss: 3.230, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:46:41,174 - INFO - Beginning epoch 661/800
2025-03-07 11:46:41,184 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:46:41,558 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:46:41,928 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:46:42,294 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:46:42,672 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:46:43,045 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:46:43,424 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:46:43,812 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:46:44,142 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:46:44,500 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:46:44,878 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:46:45,243 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:46:45,601 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:46:45,971 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:46:46,348 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:46:46,713 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:46:47,079 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:46:47,444 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:46:47,638 - INFO - validation batch 1, loss: 0.427, 32/6976 datapoints
2025-03-07 11:46:47,704 - INFO - validation batch 51, loss: 7.973, 1632/6976 datapoints
2025-03-07 11:46:47,770 - INFO - validation batch 101, loss: 1.749, 3232/6976 datapoints
2025-03-07 11:46:47,835 - INFO - validation batch 151, loss: 0.859, 4832/6976 datapoints
2025-03-07 11:46:47,901 - INFO - validation batch 201, loss: 5.228, 6432/6976 datapoints
2025-03-07 11:46:47,922 - INFO - Epoch 661/800 done.
2025-03-07 11:46:47,922 - INFO - Final validation performance:
Loss: 3.247, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:46:47,923 - INFO - Beginning epoch 662/800
2025-03-07 11:46:47,932 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:46:48,303 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:46:48,675 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:46:49,049 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:46:49,426 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:46:49,797 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:46:50,190 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:46:50,573 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:46:50,913 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:46:51,271 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:46:51,675 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:46:52,060 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:46:52,442 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:46:52,829 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:46:53,228 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:46:53,602 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:46:53,992 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:46:54,356 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:46:54,543 - INFO - validation batch 1, loss: 0.394, 32/6976 datapoints
2025-03-07 11:46:54,608 - INFO - validation batch 51, loss: 8.009, 1632/6976 datapoints
2025-03-07 11:46:54,674 - INFO - validation batch 101, loss: 1.770, 3232/6976 datapoints
2025-03-07 11:46:54,738 - INFO - validation batch 151, loss: 0.871, 4832/6976 datapoints
2025-03-07 11:46:54,808 - INFO - validation batch 201, loss: 5.231, 6432/6976 datapoints
2025-03-07 11:46:54,830 - INFO - Epoch 662/800 done.
2025-03-07 11:46:54,830 - INFO - Final validation performance:
Loss: 3.255, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:46:54,831 - INFO - Beginning epoch 663/800
2025-03-07 11:46:54,839 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:46:55,204 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:46:55,581 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:46:55,955 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:46:56,332 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:46:56,709 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:46:57,100 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:46:57,478 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:46:57,824 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:46:58,190 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:46:58,575 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:46:58,943 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:46:59,302 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:46:59,671 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:47:00,049 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:47:00,421 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:47:00,784 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:47:01,151 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:47:01,335 - INFO - validation batch 1, loss: 0.349, 32/6976 datapoints
2025-03-07 11:47:01,404 - INFO - validation batch 51, loss: 8.052, 1632/6976 datapoints
2025-03-07 11:47:01,470 - INFO - validation batch 101, loss: 1.806, 3232/6976 datapoints
2025-03-07 11:47:01,535 - INFO - validation batch 151, loss: 0.911, 4832/6976 datapoints
2025-03-07 11:47:01,602 - INFO - validation batch 201, loss: 5.241, 6432/6976 datapoints
2025-03-07 11:47:01,623 - INFO - Epoch 663/800 done.
2025-03-07 11:47:01,623 - INFO - Final validation performance:
Loss: 3.272, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:47:01,624 - INFO - Beginning epoch 664/800
2025-03-07 11:47:01,632 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:47:02,004 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:47:02,375 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:47:02,741 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:47:03,146 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:47:03,521 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:47:03,917 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:47:04,312 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:47:04,659 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:47:05,028 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:47:05,421 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:47:05,793 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:47:06,160 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:47:06,571 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:47:06,954 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:47:07,322 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:47:07,685 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:47:08,047 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:47:08,232 - INFO - validation batch 1, loss: 0.301, 32/6976 datapoints
2025-03-07 11:47:08,298 - INFO - validation batch 51, loss: 8.031, 1632/6976 datapoints
2025-03-07 11:47:08,364 - INFO - validation batch 101, loss: 1.863, 3232/6976 datapoints
2025-03-07 11:47:08,435 - INFO - validation batch 151, loss: 1.026, 4832/6976 datapoints
2025-03-07 11:47:08,500 - INFO - validation batch 201, loss: 5.288, 6432/6976 datapoints
2025-03-07 11:47:08,521 - INFO - Epoch 664/800 done.
2025-03-07 11:47:08,521 - INFO - Final validation performance:
Loss: 3.302, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:47:08,522 - INFO - Beginning epoch 665/800
2025-03-07 11:47:08,530 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:47:08,900 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:47:09,269 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:47:09,628 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:47:10,005 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:47:10,373 - INFO - training batch 251, loss: 0.550, 8032/28000 datapoints
2025-03-07 11:47:10,750 - INFO - training batch 301, loss: 0.295, 9632/28000 datapoints
2025-03-07 11:47:11,138 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-07 11:47:11,489 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:47:11,840 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 11:47:12,218 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:47:12,598 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:47:12,979 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:47:13,346 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-07 11:47:13,747 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:47:14,127 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:47:14,506 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:47:14,877 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:47:15,071 - INFO - validation batch 1, loss: 0.641, 32/6976 datapoints
2025-03-07 11:47:15,136 - INFO - validation batch 51, loss: 7.935, 1632/6976 datapoints
2025-03-07 11:47:15,202 - INFO - validation batch 101, loss: 2.008, 3232/6976 datapoints
2025-03-07 11:47:15,268 - INFO - validation batch 151, loss: 0.579, 4832/6976 datapoints
2025-03-07 11:47:15,333 - INFO - validation batch 201, loss: 5.141, 6432/6976 datapoints
2025-03-07 11:47:15,355 - INFO - Epoch 665/800 done.
2025-03-07 11:47:15,355 - INFO - Final validation performance:
Loss: 3.261, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:47:15,356 - INFO - Beginning epoch 666/800
2025-03-07 11:47:15,363 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:47:15,723 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:47:16,091 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:47:16,448 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:47:16,829 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:47:17,196 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:47:17,566 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:47:17,936 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:47:18,297 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-07 11:47:18,657 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-07 11:47:19,045 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:47:19,399 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:47:19,761 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:47:20,114 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 11:47:20,496 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:47:20,864 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 11:47:21,237 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:47:21,607 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:47:21,806 - INFO - validation batch 1, loss: 0.452, 32/6976 datapoints
2025-03-07 11:47:21,871 - INFO - validation batch 51, loss: 8.059, 1632/6976 datapoints
2025-03-07 11:47:21,938 - INFO - validation batch 101, loss: 1.768, 3232/6976 datapoints
2025-03-07 11:47:22,006 - INFO - validation batch 151, loss: 1.203, 4832/6976 datapoints
2025-03-07 11:47:22,071 - INFO - validation batch 201, loss: 5.411, 6432/6976 datapoints
2025-03-07 11:47:22,097 - INFO - Epoch 666/800 done.
2025-03-07 11:47:22,098 - INFO - Final validation performance:
Loss: 3.379, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:47:22,098 - INFO - Beginning epoch 667/800
2025-03-07 11:47:22,106 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:47:22,471 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:47:22,845 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:47:23,217 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:47:23,694 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:47:24,059 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:47:24,463 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:47:24,844 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:47:25,193 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:47:25,560 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:47:25,929 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:47:26,299 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:47:26,658 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:47:27,020 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:47:27,402 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:47:27,775 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:47:28,140 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:47:28,502 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:47:28,692 - INFO - validation batch 1, loss: 0.463, 32/6976 datapoints
2025-03-07 11:47:28,759 - INFO - validation batch 51, loss: 7.838, 1632/6976 datapoints
2025-03-07 11:47:28,825 - INFO - validation batch 101, loss: 1.849, 3232/6976 datapoints
2025-03-07 11:47:28,892 - INFO - validation batch 151, loss: 1.051, 4832/6976 datapoints
2025-03-07 11:47:28,957 - INFO - validation batch 201, loss: 5.215, 6432/6976 datapoints
2025-03-07 11:47:28,979 - INFO - Epoch 667/800 done.
2025-03-07 11:47:28,980 - INFO - Final validation performance:
Loss: 3.283, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:47:28,980 - INFO - Beginning epoch 668/800
2025-03-07 11:47:28,990 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:47:29,346 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:47:29,706 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:47:30,057 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:47:30,476 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:47:30,912 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:47:31,293 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:47:31,680 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:47:32,032 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:47:32,402 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:47:32,780 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:47:33,139 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:47:33,500 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:47:33,858 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:47:34,255 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:47:34,639 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:47:35,005 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:47:35,365 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:47:35,558 - INFO - validation batch 1, loss: 0.502, 32/6976 datapoints
2025-03-07 11:47:35,620 - INFO - validation batch 51, loss: 7.895, 1632/6976 datapoints
2025-03-07 11:47:35,681 - INFO - validation batch 101, loss: 1.834, 3232/6976 datapoints
2025-03-07 11:47:35,744 - INFO - validation batch 151, loss: 1.060, 4832/6976 datapoints
2025-03-07 11:47:35,806 - INFO - validation batch 201, loss: 5.282, 6432/6976 datapoints
2025-03-07 11:47:35,828 - INFO - Epoch 668/800 done.
2025-03-07 11:47:35,829 - INFO - Final validation performance:
Loss: 3.314, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:47:35,829 - INFO - Beginning epoch 669/800
2025-03-07 11:47:35,837 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:47:36,191 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:47:36,554 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:47:36,912 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:47:37,289 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:47:37,659 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:47:38,028 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:47:38,408 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:47:38,758 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:47:39,119 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:47:39,496 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:47:39,853 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:47:40,209 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:47:40,600 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:47:40,992 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:47:41,392 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:47:41,779 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:47:42,147 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:47:42,342 - INFO - validation batch 1, loss: 0.499, 32/6976 datapoints
2025-03-07 11:47:42,408 - INFO - validation batch 51, loss: 7.905, 1632/6976 datapoints
2025-03-07 11:47:42,473 - INFO - validation batch 101, loss: 1.828, 3232/6976 datapoints
2025-03-07 11:47:42,550 - INFO - validation batch 151, loss: 1.065, 4832/6976 datapoints
2025-03-07 11:47:42,620 - INFO - validation batch 201, loss: 5.258, 6432/6976 datapoints
2025-03-07 11:47:42,648 - INFO - Epoch 669/800 done.
2025-03-07 11:47:42,648 - INFO - Final validation performance:
Loss: 3.311, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:47:42,649 - INFO - Beginning epoch 670/800
2025-03-07 11:47:42,657 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:47:43,027 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:47:43,391 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:47:43,753 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:47:44,136 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:47:44,538 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:47:44,919 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:47:45,299 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:47:45,644 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:47:46,004 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:47:46,382 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:47:46,739 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:47:47,100 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:47:47,466 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:47:47,853 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:47:48,224 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:47:48,591 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:47:48,958 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:47:49,149 - INFO - validation batch 1, loss: 0.494, 32/6976 datapoints
2025-03-07 11:47:49,215 - INFO - validation batch 51, loss: 7.907, 1632/6976 datapoints
2025-03-07 11:47:49,281 - INFO - validation batch 101, loss: 1.827, 3232/6976 datapoints
2025-03-07 11:47:49,346 - INFO - validation batch 151, loss: 1.076, 4832/6976 datapoints
2025-03-07 11:47:49,417 - INFO - validation batch 201, loss: 5.235, 6432/6976 datapoints
2025-03-07 11:47:49,443 - INFO - Epoch 670/800 done.
2025-03-07 11:47:49,443 - INFO - Final validation performance:
Loss: 3.308, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:47:49,443 - INFO - Beginning epoch 671/800
2025-03-07 11:47:49,451 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:47:49,803 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:47:50,160 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:47:50,520 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:47:50,872 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:47:51,240 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:47:51,622 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:47:52,002 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:47:52,350 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:47:52,717 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:47:53,104 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:47:53,469 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:47:53,829 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:47:54,190 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:47:54,590 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:47:54,963 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:47:55,340 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:47:55,714 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:47:55,908 - INFO - validation batch 1, loss: 0.490, 32/6976 datapoints
2025-03-07 11:47:55,977 - INFO - validation batch 51, loss: 7.912, 1632/6976 datapoints
2025-03-07 11:47:56,043 - INFO - validation batch 101, loss: 1.829, 3232/6976 datapoints
2025-03-07 11:47:56,108 - INFO - validation batch 151, loss: 1.089, 4832/6976 datapoints
2025-03-07 11:47:56,174 - INFO - validation batch 201, loss: 5.213, 6432/6976 datapoints
2025-03-07 11:47:56,200 - INFO - Epoch 671/800 done.
2025-03-07 11:47:56,200 - INFO - Final validation performance:
Loss: 3.306, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:47:56,200 - INFO - Beginning epoch 672/800
2025-03-07 11:47:56,209 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:47:56,578 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:47:56,938 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:47:57,294 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:47:57,657 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:47:58,032 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:47:58,416 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:47:58,795 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:47:59,141 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:47:59,508 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:47:59,896 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:48:00,252 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:48:00,636 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:48:01,010 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:48:01,398 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:48:01,773 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:48:02,145 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:48:02,510 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:48:02,701 - INFO - validation batch 1, loss: 0.487, 32/6976 datapoints
2025-03-07 11:48:02,767 - INFO - validation batch 51, loss: 7.932, 1632/6976 datapoints
2025-03-07 11:48:02,834 - INFO - validation batch 101, loss: 1.831, 3232/6976 datapoints
2025-03-07 11:48:02,898 - INFO - validation batch 151, loss: 1.098, 4832/6976 datapoints
2025-03-07 11:48:02,966 - INFO - validation batch 201, loss: 5.195, 6432/6976 datapoints
2025-03-07 11:48:02,990 - INFO - Epoch 672/800 done.
2025-03-07 11:48:02,991 - INFO - Final validation performance:
Loss: 3.309, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:48:02,991 - INFO - Beginning epoch 673/800
2025-03-07 11:48:02,999 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:48:03,354 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:48:03,710 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:48:04,065 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:48:04,420 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:48:04,807 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:48:05,184 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:48:05,583 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:48:05,936 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:48:06,307 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:48:06,692 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:48:07,068 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:48:07,521 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:48:07,915 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:48:08,304 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:48:08,687 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:48:09,060 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:48:09,421 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:48:09,611 - INFO - validation batch 1, loss: 0.487, 32/6976 datapoints
2025-03-07 11:48:09,675 - INFO - validation batch 51, loss: 7.957, 1632/6976 datapoints
2025-03-07 11:48:09,741 - INFO - validation batch 101, loss: 1.835, 3232/6976 datapoints
2025-03-07 11:48:09,806 - INFO - validation batch 151, loss: 1.095, 4832/6976 datapoints
2025-03-07 11:48:09,873 - INFO - validation batch 201, loss: 5.182, 6432/6976 datapoints
2025-03-07 11:48:09,898 - INFO - Epoch 673/800 done.
2025-03-07 11:48:09,899 - INFO - Final validation performance:
Loss: 3.311, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:48:09,899 - INFO - Beginning epoch 674/800
2025-03-07 11:48:09,907 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:48:10,258 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:48:10,623 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:48:10,976 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:48:11,363 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:48:11,734 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:48:12,105 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:48:12,483 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:48:12,830 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:48:13,193 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:48:13,569 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:48:13,928 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:48:14,292 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:48:14,671 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:48:15,067 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:48:15,439 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:48:15,811 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:48:16,177 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:48:16,370 - INFO - validation batch 1, loss: 0.490, 32/6976 datapoints
2025-03-07 11:48:16,438 - INFO - validation batch 51, loss: 7.994, 1632/6976 datapoints
2025-03-07 11:48:16,505 - INFO - validation batch 101, loss: 1.841, 3232/6976 datapoints
2025-03-07 11:48:16,573 - INFO - validation batch 151, loss: 1.090, 4832/6976 datapoints
2025-03-07 11:48:16,639 - INFO - validation batch 201, loss: 5.178, 6432/6976 datapoints
2025-03-07 11:48:16,660 - INFO - Epoch 674/800 done.
2025-03-07 11:48:16,660 - INFO - Final validation performance:
Loss: 3.319, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:48:16,661 - INFO - Beginning epoch 675/800
2025-03-07 11:48:16,668 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:48:17,036 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:48:17,407 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:48:17,770 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:48:18,146 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:48:18,517 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:48:18,892 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:48:19,272 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:48:19,617 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:48:19,974 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:48:20,351 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:48:20,715 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:48:21,079 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:48:21,446 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:48:21,834 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:48:22,200 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:48:22,571 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:48:22,934 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:48:23,125 - INFO - validation batch 1, loss: 0.496, 32/6976 datapoints
2025-03-07 11:48:23,191 - INFO - validation batch 51, loss: 8.031, 1632/6976 datapoints
2025-03-07 11:48:23,257 - INFO - validation batch 101, loss: 1.848, 3232/6976 datapoints
2025-03-07 11:48:23,322 - INFO - validation batch 151, loss: 1.079, 4832/6976 datapoints
2025-03-07 11:48:23,387 - INFO - validation batch 201, loss: 5.184, 6432/6976 datapoints
2025-03-07 11:48:23,411 - INFO - Epoch 675/800 done.
2025-03-07 11:48:23,412 - INFO - Final validation performance:
Loss: 3.328, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:48:23,412 - INFO - Beginning epoch 676/800
2025-03-07 11:48:23,419 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:48:23,783 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:48:24,150 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:48:24,506 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:48:24,902 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:48:25,284 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:48:25,666 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:48:26,056 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:48:26,411 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:48:26,775 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:48:27,158 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:48:27,520 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:48:27,891 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:48:28,257 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:48:28,636 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:48:29,006 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:48:29,374 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:48:29,735 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:48:29,923 - INFO - validation batch 1, loss: 0.504, 32/6976 datapoints
2025-03-07 11:48:29,989 - INFO - validation batch 51, loss: 8.068, 1632/6976 datapoints
2025-03-07 11:48:30,055 - INFO - validation batch 101, loss: 1.852, 3232/6976 datapoints
2025-03-07 11:48:30,121 - INFO - validation batch 151, loss: 1.066, 4832/6976 datapoints
2025-03-07 11:48:30,188 - INFO - validation batch 201, loss: 5.202, 6432/6976 datapoints
2025-03-07 11:48:30,210 - INFO - Epoch 676/800 done.
2025-03-07 11:48:30,211 - INFO - Final validation performance:
Loss: 3.338, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:48:30,211 - INFO - Beginning epoch 677/800
2025-03-07 11:48:30,218 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:48:30,600 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:48:30,958 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:48:31,313 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:48:31,697 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:48:32,082 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:48:32,462 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:48:32,842 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:48:33,193 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:48:33,566 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:48:33,951 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:48:34,312 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:48:34,676 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:48:35,070 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:48:35,459 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:48:35,831 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:48:36,201 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:48:36,574 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:48:36,766 - INFO - validation batch 1, loss: 0.517, 32/6976 datapoints
2025-03-07 11:48:36,835 - INFO - validation batch 51, loss: 8.095, 1632/6976 datapoints
2025-03-07 11:48:36,916 - INFO - validation batch 101, loss: 1.856, 3232/6976 datapoints
2025-03-07 11:48:37,005 - INFO - validation batch 151, loss: 1.038, 4832/6976 datapoints
2025-03-07 11:48:37,088 - INFO - validation batch 201, loss: 5.231, 6432/6976 datapoints
2025-03-07 11:48:37,188 - INFO - Epoch 677/800 done.
2025-03-07 11:48:37,189 - INFO - Final validation performance:
Loss: 3.347, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:48:37,189 - INFO - Beginning epoch 678/800
2025-03-07 11:48:37,196 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:48:37,561 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:48:37,937 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:48:38,302 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:48:38,695 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:48:39,067 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:48:39,749 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:48:40,223 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:48:40,600 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:48:40,988 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:48:41,385 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:48:41,782 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:48:42,160 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:48:42,545 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:48:42,937 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:48:43,310 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:48:43,679 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:48:44,041 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:48:44,230 - INFO - validation batch 1, loss: 0.525, 32/6976 datapoints
2025-03-07 11:48:44,293 - INFO - validation batch 51, loss: 8.122, 1632/6976 datapoints
2025-03-07 11:48:44,355 - INFO - validation batch 101, loss: 1.856, 3232/6976 datapoints
2025-03-07 11:48:44,421 - INFO - validation batch 151, loss: 1.021, 4832/6976 datapoints
2025-03-07 11:48:44,484 - INFO - validation batch 201, loss: 5.264, 6432/6976 datapoints
2025-03-07 11:48:44,505 - INFO - Epoch 678/800 done.
2025-03-07 11:48:44,506 - INFO - Final validation performance:
Loss: 3.357, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:48:44,506 - INFO - Beginning epoch 679/800
2025-03-07 11:48:44,514 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:48:44,885 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:48:45,273 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:48:45,666 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:48:46,050 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:48:46,427 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:48:46,805 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:48:47,191 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:48:47,548 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:48:47,916 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:48:48,295 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:48:48,659 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:48:49,024 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:48:49,405 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:48:49,790 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:48:50,164 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:48:50,537 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:48:50,907 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:48:51,094 - INFO - validation batch 1, loss: 0.527, 32/6976 datapoints
2025-03-07 11:48:51,159 - INFO - validation batch 51, loss: 8.165, 1632/6976 datapoints
2025-03-07 11:48:51,227 - INFO - validation batch 101, loss: 1.861, 3232/6976 datapoints
2025-03-07 11:48:51,294 - INFO - validation batch 151, loss: 1.009, 4832/6976 datapoints
2025-03-07 11:48:51,359 - INFO - validation batch 201, loss: 5.297, 6432/6976 datapoints
2025-03-07 11:48:51,382 - INFO - Epoch 679/800 done.
2025-03-07 11:48:51,382 - INFO - Final validation performance:
Loss: 3.372, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:48:51,383 - INFO - Beginning epoch 680/800
2025-03-07 11:48:51,392 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:48:51,760 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:48:52,120 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:48:52,475 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:48:52,876 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:48:53,246 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:48:53,621 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:48:54,001 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:48:54,338 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:48:54,696 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:48:55,096 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:48:55,455 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:48:55,829 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:48:56,199 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:48:56,589 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:48:56,962 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:48:57,328 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:48:57,700 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:48:57,886 - INFO - validation batch 1, loss: 0.519, 32/6976 datapoints
2025-03-07 11:48:57,953 - INFO - validation batch 51, loss: 8.216, 1632/6976 datapoints
2025-03-07 11:48:58,022 - INFO - validation batch 101, loss: 1.869, 3232/6976 datapoints
2025-03-07 11:48:58,087 - INFO - validation batch 151, loss: 1.011, 4832/6976 datapoints
2025-03-07 11:48:58,154 - INFO - validation batch 201, loss: 5.325, 6432/6976 datapoints
2025-03-07 11:48:58,175 - INFO - Epoch 680/800 done.
2025-03-07 11:48:58,175 - INFO - Final validation performance:
Loss: 3.388, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:48:58,176 - INFO - Beginning epoch 681/800
2025-03-07 11:48:58,187 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:48:58,553 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:48:58,914 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:48:59,269 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:48:59,644 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:49:00,013 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:49:00,384 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:49:00,772 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:49:01,115 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:49:01,471 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:49:01,852 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:49:02,210 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:49:02,573 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:49:02,958 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:49:03,338 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:49:03,703 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:49:04,062 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:49:04,428 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:49:04,612 - INFO - validation batch 1, loss: 0.500, 32/6976 datapoints
2025-03-07 11:49:04,672 - INFO - validation batch 51, loss: 8.263, 1632/6976 datapoints
2025-03-07 11:49:04,733 - INFO - validation batch 101, loss: 1.893, 3232/6976 datapoints
2025-03-07 11:49:04,793 - INFO - validation batch 151, loss: 1.027, 4832/6976 datapoints
2025-03-07 11:49:04,853 - INFO - validation batch 201, loss: 5.348, 6432/6976 datapoints
2025-03-07 11:49:04,873 - INFO - Epoch 681/800 done.
2025-03-07 11:49:04,874 - INFO - Final validation performance:
Loss: 3.406, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:49:04,875 - INFO - Beginning epoch 682/800
2025-03-07 11:49:04,882 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:49:05,270 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:49:05,637 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:49:06,007 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:49:06,378 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:49:06,752 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:49:07,131 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:49:07,509 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:49:07,851 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:49:08,213 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:49:08,596 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:49:08,956 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:49:09,326 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:49:09,698 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:49:10,077 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:49:10,448 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:49:10,809 - INFO - training batch 801, loss: 0.146, 25632/28000 datapoints
2025-03-07 11:49:11,180 - INFO - training batch 851, loss: 0.165, 27232/28000 datapoints
2025-03-07 11:49:11,368 - INFO - validation batch 1, loss: 1.708, 32/6976 datapoints
2025-03-07 11:49:11,436 - INFO - validation batch 51, loss: 9.221, 1632/6976 datapoints
2025-03-07 11:49:11,501 - INFO - validation batch 101, loss: 2.269, 3232/6976 datapoints
2025-03-07 11:49:11,570 - INFO - validation batch 151, loss: 0.872, 4832/6976 datapoints
2025-03-07 11:49:11,637 - INFO - validation batch 201, loss: 3.938, 6432/6976 datapoints
2025-03-07 11:49:11,661 - INFO - Epoch 682/800 done.
2025-03-07 11:49:11,661 - INFO - Final validation performance:
Loss: 3.602, top-1 acc: 0.870top-5 acc: 0.870
2025-03-07 11:49:11,661 - INFO - Beginning epoch 683/800
2025-03-07 11:49:11,670 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-07 11:49:12,030 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-07 11:49:12,415 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:49:12,783 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:49:13,187 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:49:13,641 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:49:14,598 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 11:49:15,035 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:49:16,394 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:49:16,880 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:49:17,475 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:49:18,055 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:49:18,612 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:49:19,101 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:49:19,681 - INFO - training batch 701, loss: 0.086, 22432/28000 datapoints
2025-03-07 11:49:20,440 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:49:21,256 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:49:21,913 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:49:22,328 - INFO - validation batch 1, loss: 0.040, 32/6976 datapoints
2025-03-07 11:49:22,493 - INFO - validation batch 51, loss: 8.701, 1632/6976 datapoints
2025-03-07 11:49:22,664 - INFO - validation batch 101, loss: 2.300, 3232/6976 datapoints
2025-03-07 11:49:22,789 - INFO - validation batch 151, loss: 1.713, 4832/6976 datapoints
2025-03-07 11:49:22,885 - INFO - validation batch 201, loss: 5.331, 6432/6976 datapoints
2025-03-07 11:49:22,912 - INFO - Epoch 683/800 done.
2025-03-07 11:49:22,913 - INFO - Final validation performance:
Loss: 3.617, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:49:22,914 - INFO - Beginning epoch 684/800
2025-03-07 11:49:22,921 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:49:23,401 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:49:24,030 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:49:24,472 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:49:24,870 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:49:25,266 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:49:25,710 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:49:26,191 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:49:26,568 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:49:26,926 - INFO - training batch 451, loss: 0.077, 14432/28000 datapoints
2025-03-07 11:49:27,319 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:49:27,714 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:49:28,100 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:49:28,474 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:49:28,879 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:49:29,257 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:49:29,670 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:49:30,042 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:49:30,233 - INFO - validation batch 1, loss: 0.206, 32/6976 datapoints
2025-03-07 11:49:30,303 - INFO - validation batch 51, loss: 8.556, 1632/6976 datapoints
2025-03-07 11:49:30,386 - INFO - validation batch 101, loss: 1.769, 3232/6976 datapoints
2025-03-07 11:49:30,527 - INFO - validation batch 151, loss: 1.263, 4832/6976 datapoints
2025-03-07 11:49:30,640 - INFO - validation batch 201, loss: 5.359, 6432/6976 datapoints
2025-03-07 11:49:30,672 - INFO - Epoch 684/800 done.
2025-03-07 11:49:30,673 - INFO - Final validation performance:
Loss: 3.431, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:49:30,673 - INFO - Beginning epoch 685/800
2025-03-07 11:49:30,684 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:49:31,081 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 11:49:31,468 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:49:31,841 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:49:32,224 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:49:32,761 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:49:33,277 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-07 11:49:33,690 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:49:34,054 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:49:34,414 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:49:34,820 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:49:35,226 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:49:35,630 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:49:36,001 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:49:36,407 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:49:36,782 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:49:37,149 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:49:37,513 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:49:37,711 - INFO - validation batch 1, loss: 0.301, 32/6976 datapoints
2025-03-07 11:49:37,782 - INFO - validation batch 51, loss: 8.344, 1632/6976 datapoints
2025-03-07 11:49:37,856 - INFO - validation batch 101, loss: 1.945, 3232/6976 datapoints
2025-03-07 11:49:37,925 - INFO - validation batch 151, loss: 1.025, 4832/6976 datapoints
2025-03-07 11:49:37,992 - INFO - validation batch 201, loss: 5.000, 6432/6976 datapoints
2025-03-07 11:49:38,014 - INFO - Epoch 685/800 done.
2025-03-07 11:49:38,014 - INFO - Final validation performance:
Loss: 3.323, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:49:38,015 - INFO - Beginning epoch 686/800
2025-03-07 11:49:38,022 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:49:38,407 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:49:38,794 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:49:39,169 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:49:39,564 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:49:39,940 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:49:40,322 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:49:40,713 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:49:41,098 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:49:41,478 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:49:41,867 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:49:42,281 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:49:42,660 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:49:43,025 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:49:43,424 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:49:43,817 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:49:44,201 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:49:44,570 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:49:44,767 - INFO - validation batch 1, loss: 0.171, 32/6976 datapoints
2025-03-07 11:49:44,835 - INFO - validation batch 51, loss: 8.518, 1632/6976 datapoints
2025-03-07 11:49:44,901 - INFO - validation batch 101, loss: 1.913, 3232/6976 datapoints
2025-03-07 11:49:44,966 - INFO - validation batch 151, loss: 1.044, 4832/6976 datapoints
2025-03-07 11:49:45,033 - INFO - validation batch 201, loss: 4.897, 6432/6976 datapoints
2025-03-07 11:49:45,058 - INFO - Epoch 686/800 done.
2025-03-07 11:49:45,058 - INFO - Final validation performance:
Loss: 3.308, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:49:45,059 - INFO - Beginning epoch 687/800
2025-03-07 11:49:45,066 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:49:45,450 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:49:45,860 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:49:46,243 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:49:46,624 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:49:46,984 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:49:47,368 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:49:47,786 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:49:48,153 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:49:48,552 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:49:48,949 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:49:49,458 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:49:49,920 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:49:50,312 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:49:50,766 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:49:51,171 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:49:51,552 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:49:51,930 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:49:52,130 - INFO - validation batch 1, loss: 0.258, 32/6976 datapoints
2025-03-07 11:49:52,197 - INFO - validation batch 51, loss: 8.392, 1632/6976 datapoints
2025-03-07 11:49:52,264 - INFO - validation batch 101, loss: 2.005, 3232/6976 datapoints
2025-03-07 11:49:52,330 - INFO - validation batch 151, loss: 0.900, 4832/6976 datapoints
2025-03-07 11:49:52,398 - INFO - validation batch 201, loss: 5.082, 6432/6976 datapoints
2025-03-07 11:49:52,419 - INFO - Epoch 687/800 done.
2025-03-07 11:49:52,419 - INFO - Final validation performance:
Loss: 3.327, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:49:52,420 - INFO - Beginning epoch 688/800
2025-03-07 11:49:52,427 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:49:52,797 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:49:53,155 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:49:53,521 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:49:53,901 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:49:54,269 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:49:54,676 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:49:55,068 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:49:55,421 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:49:55,803 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:49:56,187 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:49:56,569 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:49:56,938 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:49:57,352 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:49:57,762 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:49:58,141 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:49:58,512 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:49:58,884 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:49:59,079 - INFO - validation batch 1, loss: 0.252, 32/6976 datapoints
2025-03-07 11:49:59,144 - INFO - validation batch 51, loss: 8.398, 1632/6976 datapoints
2025-03-07 11:49:59,208 - INFO - validation batch 101, loss: 1.985, 3232/6976 datapoints
2025-03-07 11:49:59,275 - INFO - validation batch 151, loss: 0.894, 4832/6976 datapoints
2025-03-07 11:49:59,339 - INFO - validation batch 201, loss: 5.068, 6432/6976 datapoints
2025-03-07 11:49:59,360 - INFO - Epoch 688/800 done.
2025-03-07 11:49:59,360 - INFO - Final validation performance:
Loss: 3.319, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:49:59,361 - INFO - Beginning epoch 689/800
2025-03-07 11:49:59,368 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:49:59,771 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:50:00,134 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:50:00,501 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:50:00,892 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:50:01,305 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:50:01,735 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:50:02,171 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:50:02,610 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:50:03,025 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:50:03,428 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:50:03,818 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:50:04,194 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:50:04,561 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:50:04,959 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:50:05,338 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:50:05,701 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:50:06,080 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:50:06,273 - INFO - validation batch 1, loss: 0.248, 32/6976 datapoints
2025-03-07 11:50:06,337 - INFO - validation batch 51, loss: 8.385, 1632/6976 datapoints
2025-03-07 11:50:06,406 - INFO - validation batch 101, loss: 1.972, 3232/6976 datapoints
2025-03-07 11:50:06,472 - INFO - validation batch 151, loss: 0.898, 4832/6976 datapoints
2025-03-07 11:50:06,538 - INFO - validation batch 201, loss: 5.068, 6432/6976 datapoints
2025-03-07 11:50:06,560 - INFO - Epoch 689/800 done.
2025-03-07 11:50:06,561 - INFO - Final validation performance:
Loss: 3.314, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:50:06,561 - INFO - Beginning epoch 690/800
2025-03-07 11:50:06,569 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:50:06,942 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:50:07,323 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:50:07,692 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:50:08,066 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:50:08,447 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:50:08,890 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:50:09,307 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:50:09,705 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:50:10,204 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:50:10,734 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:50:11,224 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:50:11,750 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:50:12,327 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:50:12,898 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:50:13,530 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:50:14,073 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:50:14,612 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:50:14,898 - INFO - validation batch 1, loss: 0.249, 32/6976 datapoints
2025-03-07 11:50:15,002 - INFO - validation batch 51, loss: 8.376, 1632/6976 datapoints
2025-03-07 11:50:15,225 - INFO - validation batch 101, loss: 1.956, 3232/6976 datapoints
2025-03-07 11:50:15,494 - INFO - validation batch 151, loss: 0.893, 4832/6976 datapoints
2025-03-07 11:50:15,633 - INFO - validation batch 201, loss: 5.068, 6432/6976 datapoints
2025-03-07 11:50:15,687 - INFO - Epoch 690/800 done.
2025-03-07 11:50:15,688 - INFO - Final validation performance:
Loss: 3.308, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:50:15,690 - INFO - Beginning epoch 691/800
2025-03-07 11:50:15,755 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:50:16,867 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:50:17,540 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:50:18,044 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:50:18,578 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:50:19,164 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:50:19,678 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:50:20,124 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:50:20,546 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:50:20,948 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:50:21,390 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:50:21,805 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:50:22,216 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:50:22,618 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:50:23,064 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:50:23,477 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:50:23,893 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:50:24,317 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:50:24,541 - INFO - validation batch 1, loss: 0.256, 32/6976 datapoints
2025-03-07 11:50:24,653 - INFO - validation batch 51, loss: 8.374, 1632/6976 datapoints
2025-03-07 11:50:24,762 - INFO - validation batch 101, loss: 1.936, 3232/6976 datapoints
2025-03-07 11:50:24,852 - INFO - validation batch 151, loss: 0.875, 4832/6976 datapoints
2025-03-07 11:50:24,937 - INFO - validation batch 201, loss: 5.064, 6432/6976 datapoints
2025-03-07 11:50:24,969 - INFO - Epoch 691/800 done.
2025-03-07 11:50:24,970 - INFO - Final validation performance:
Loss: 3.301, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:50:24,970 - INFO - Beginning epoch 692/800
2025-03-07 11:50:24,979 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:50:25,469 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:50:25,978 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:50:26,454 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:50:26,891 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:50:27,302 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:50:27,727 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:50:28,168 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:50:28,550 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:50:28,926 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:50:29,326 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:50:29,719 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:50:30,159 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:50:30,668 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:50:31,157 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:50:31,579 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:50:31,998 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:50:32,405 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:50:32,626 - INFO - validation batch 1, loss: 0.265, 32/6976 datapoints
2025-03-07 11:50:32,697 - INFO - validation batch 51, loss: 8.383, 1632/6976 datapoints
2025-03-07 11:50:32,767 - INFO - validation batch 101, loss: 1.913, 3232/6976 datapoints
2025-03-07 11:50:32,840 - INFO - validation batch 151, loss: 0.854, 4832/6976 datapoints
2025-03-07 11:50:32,909 - INFO - validation batch 201, loss: 5.061, 6432/6976 datapoints
2025-03-07 11:50:32,937 - INFO - Epoch 692/800 done.
2025-03-07 11:50:32,937 - INFO - Final validation performance:
Loss: 3.295, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:50:32,938 - INFO - Beginning epoch 693/800
2025-03-07 11:50:32,946 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:50:33,349 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:50:33,738 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:50:34,121 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:50:34,519 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:50:34,924 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:50:35,406 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:50:35,853 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:50:36,271 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:50:36,674 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:50:37,090 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:50:37,486 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:50:37,885 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:50:38,301 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:50:38,750 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:50:39,206 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:50:39,681 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:50:40,173 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:50:40,377 - INFO - validation batch 1, loss: 0.276, 32/6976 datapoints
2025-03-07 11:50:40,451 - INFO - validation batch 51, loss: 8.394, 1632/6976 datapoints
2025-03-07 11:50:40,519 - INFO - validation batch 101, loss: 1.888, 3232/6976 datapoints
2025-03-07 11:50:40,586 - INFO - validation batch 151, loss: 0.839, 4832/6976 datapoints
2025-03-07 11:50:40,651 - INFO - validation batch 201, loss: 5.071, 6432/6976 datapoints
2025-03-07 11:50:40,673 - INFO - Epoch 693/800 done.
2025-03-07 11:50:40,673 - INFO - Final validation performance:
Loss: 3.294, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:50:40,674 - INFO - Beginning epoch 694/800
2025-03-07 11:50:40,682 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:50:41,290 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:50:41,821 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:50:42,501 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:50:43,335 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:50:43,863 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:50:44,414 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:50:44,928 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:50:45,369 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:50:46,008 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:50:46,567 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:50:46,990 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:50:47,405 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:50:47,878 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:50:48,296 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:50:48,762 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:50:49,232 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:50:49,638 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:50:50,120 - INFO - validation batch 1, loss: 0.292, 32/6976 datapoints
2025-03-07 11:50:50,236 - INFO - validation batch 51, loss: 8.403, 1632/6976 datapoints
2025-03-07 11:50:50,357 - INFO - validation batch 101, loss: 1.865, 3232/6976 datapoints
2025-03-07 11:50:50,501 - INFO - validation batch 151, loss: 0.825, 4832/6976 datapoints
2025-03-07 11:50:50,586 - INFO - validation batch 201, loss: 5.099, 6432/6976 datapoints
2025-03-07 11:50:50,616 - INFO - Epoch 694/800 done.
2025-03-07 11:50:50,616 - INFO - Final validation performance:
Loss: 3.297, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:50:50,617 - INFO - Beginning epoch 695/800
2025-03-07 11:50:50,624 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:50:51,066 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:50:51,564 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:50:52,251 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:50:52,853 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:50:53,267 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:50:53,683 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:50:54,089 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:50:54,512 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:50:54,917 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:50:55,329 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:50:55,713 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:50:56,152 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:50:56,590 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:50:57,021 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:50:57,434 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:50:57,833 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:50:58,217 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:50:58,460 - INFO - validation batch 1, loss: 0.313, 32/6976 datapoints
2025-03-07 11:50:58,554 - INFO - validation batch 51, loss: 8.418, 1632/6976 datapoints
2025-03-07 11:50:58,636 - INFO - validation batch 101, loss: 1.845, 3232/6976 datapoints
2025-03-07 11:50:58,708 - INFO - validation batch 151, loss: 0.813, 4832/6976 datapoints
2025-03-07 11:50:58,776 - INFO - validation batch 201, loss: 5.137, 6432/6976 datapoints
2025-03-07 11:50:58,802 - INFO - Epoch 695/800 done.
2025-03-07 11:50:58,802 - INFO - Final validation performance:
Loss: 3.305, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:50:58,803 - INFO - Beginning epoch 696/800
2025-03-07 11:50:58,810 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:50:59,204 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:50:59,589 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:50:59,959 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:51:00,342 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:51:00,732 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:51:01,123 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:51:01,548 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:51:01,951 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:51:02,363 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:51:02,776 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:51:03,169 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:51:03,558 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:51:03,938 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:51:04,342 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:51:04,728 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:51:05,102 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:51:05,471 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:51:05,660 - INFO - validation batch 1, loss: 0.339, 32/6976 datapoints
2025-03-07 11:51:05,727 - INFO - validation batch 51, loss: 8.441, 1632/6976 datapoints
2025-03-07 11:51:05,793 - INFO - validation batch 101, loss: 1.826, 3232/6976 datapoints
2025-03-07 11:51:05,858 - INFO - validation batch 151, loss: 0.806, 4832/6976 datapoints
2025-03-07 11:51:05,923 - INFO - validation batch 201, loss: 5.173, 6432/6976 datapoints
2025-03-07 11:51:05,949 - INFO - Epoch 696/800 done.
2025-03-07 11:51:05,949 - INFO - Final validation performance:
Loss: 3.317, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:51:05,950 - INFO - Beginning epoch 697/800
2025-03-07 11:51:05,957 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:51:06,337 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:51:06,702 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:51:07,084 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:51:07,455 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:51:07,846 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:51:08,244 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:51:08,642 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:51:08,991 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:51:09,351 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:51:09,742 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:51:10,117 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:51:10,494 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:51:10,892 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:51:11,287 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:51:11,685 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:51:12,061 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:51:12,435 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:51:12,627 - INFO - validation batch 1, loss: 0.358, 32/6976 datapoints
2025-03-07 11:51:12,692 - INFO - validation batch 51, loss: 8.468, 1632/6976 datapoints
2025-03-07 11:51:12,758 - INFO - validation batch 101, loss: 1.813, 3232/6976 datapoints
2025-03-07 11:51:12,824 - INFO - validation batch 151, loss: 0.826, 4832/6976 datapoints
2025-03-07 11:51:12,892 - INFO - validation batch 201, loss: 5.204, 6432/6976 datapoints
2025-03-07 11:51:12,914 - INFO - Epoch 697/800 done.
2025-03-07 11:51:12,914 - INFO - Final validation performance:
Loss: 3.334, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:51:12,914 - INFO - Beginning epoch 698/800
2025-03-07 11:51:12,921 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:51:13,311 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:51:13,692 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:51:14,070 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:51:14,520 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:51:14,907 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:51:15,309 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:51:15,745 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:51:16,107 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:51:16,482 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:51:16,862 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:51:17,256 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:51:17,638 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:51:18,010 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:51:18,406 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:51:18,783 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:51:19,147 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:51:19,514 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:51:19,703 - INFO - validation batch 1, loss: 0.366, 32/6976 datapoints
2025-03-07 11:51:19,770 - INFO - validation batch 51, loss: 8.486, 1632/6976 datapoints
2025-03-07 11:51:19,836 - INFO - validation batch 101, loss: 1.809, 3232/6976 datapoints
2025-03-07 11:51:19,901 - INFO - validation batch 151, loss: 0.872, 4832/6976 datapoints
2025-03-07 11:51:19,967 - INFO - validation batch 201, loss: 5.237, 6432/6976 datapoints
2025-03-07 11:51:19,991 - INFO - Epoch 698/800 done.
2025-03-07 11:51:19,991 - INFO - Final validation performance:
Loss: 3.354, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:51:19,992 - INFO - Beginning epoch 699/800
2025-03-07 11:51:20,000 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:51:20,379 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:51:20,760 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:51:21,136 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:51:21,532 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:51:21,931 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:51:22,319 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:51:22,713 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:51:23,071 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:51:23,441 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:51:23,824 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:51:24,197 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:51:24,567 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:51:24,932 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:51:25,319 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:51:25,696 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:51:26,110 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:51:26,494 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:51:26,680 - INFO - validation batch 1, loss: 0.353, 32/6976 datapoints
2025-03-07 11:51:26,747 - INFO - validation batch 51, loss: 8.501, 1632/6976 datapoints
2025-03-07 11:51:26,813 - INFO - validation batch 101, loss: 1.823, 3232/6976 datapoints
2025-03-07 11:51:26,879 - INFO - validation batch 151, loss: 0.931, 4832/6976 datapoints
2025-03-07 11:51:26,944 - INFO - validation batch 201, loss: 5.277, 6432/6976 datapoints
2025-03-07 11:51:26,965 - INFO - Epoch 699/800 done.
2025-03-07 11:51:26,966 - INFO - Final validation performance:
Loss: 3.377, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:51:26,966 - INFO - Beginning epoch 700/800
2025-03-07 11:51:26,973 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:51:27,382 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:51:27,766 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:51:28,139 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:51:28,528 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:51:28,912 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:51:29,293 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:51:29,689 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:51:30,045 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:51:30,459 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:51:30,867 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:51:31,245 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:51:31,623 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:51:32,017 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:51:32,410 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:51:32,793 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:51:33,160 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:51:33,526 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:51:33,716 - INFO - validation batch 1, loss: 0.338, 32/6976 datapoints
2025-03-07 11:51:33,782 - INFO - validation batch 51, loss: 8.505, 1632/6976 datapoints
2025-03-07 11:51:33,848 - INFO - validation batch 101, loss: 1.842, 3232/6976 datapoints
2025-03-07 11:51:33,914 - INFO - validation batch 151, loss: 0.970, 4832/6976 datapoints
2025-03-07 11:51:33,981 - INFO - validation batch 201, loss: 5.289, 6432/6976 datapoints
2025-03-07 11:51:34,006 - INFO - Epoch 700/800 done.
2025-03-07 11:51:34,007 - INFO - Final validation performance:
Loss: 3.389, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:51:34,007 - INFO - Beginning epoch 701/800
2025-03-07 11:51:34,014 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:51:34,383 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:51:34,756 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:51:35,116 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:51:35,505 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:51:35,888 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:51:36,270 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:51:36,668 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:51:37,055 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:51:37,450 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:51:37,883 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:51:38,273 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:51:38,663 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:51:39,048 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:51:39,445 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:51:39,833 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:51:40,208 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:51:40,693 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:51:40,885 - INFO - validation batch 1, loss: 0.314, 32/6976 datapoints
2025-03-07 11:51:40,971 - INFO - validation batch 51, loss: 8.539, 1632/6976 datapoints
2025-03-07 11:51:41,036 - INFO - validation batch 101, loss: 1.870, 3232/6976 datapoints
2025-03-07 11:51:41,101 - INFO - validation batch 151, loss: 0.997, 4832/6976 datapoints
2025-03-07 11:51:41,171 - INFO - validation batch 201, loss: 5.310, 6432/6976 datapoints
2025-03-07 11:51:41,198 - INFO - Epoch 701/800 done.
2025-03-07 11:51:41,198 - INFO - Final validation performance:
Loss: 3.406, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:51:41,199 - INFO - Beginning epoch 702/800
2025-03-07 11:51:41,206 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:51:41,595 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:51:41,969 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:51:42,329 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:51:42,728 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:51:43,106 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:51:43,490 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:51:43,882 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:51:44,237 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:51:44,611 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:51:44,988 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:51:45,378 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:51:45,789 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:51:46,163 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:51:46,549 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:51:46,930 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:51:47,296 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:51:47,702 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:51:47,889 - INFO - validation batch 1, loss: 0.275, 32/6976 datapoints
2025-03-07 11:51:47,954 - INFO - validation batch 51, loss: 8.624, 1632/6976 datapoints
2025-03-07 11:51:48,022 - INFO - validation batch 101, loss: 1.911, 3232/6976 datapoints
2025-03-07 11:51:48,085 - INFO - validation batch 151, loss: 1.015, 4832/6976 datapoints
2025-03-07 11:51:48,151 - INFO - validation batch 201, loss: 5.375, 6432/6976 datapoints
2025-03-07 11:51:48,173 - INFO - Epoch 702/800 done.
2025-03-07 11:51:48,173 - INFO - Final validation performance:
Loss: 3.440, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:51:48,174 - INFO - Beginning epoch 703/800
2025-03-07 11:51:48,181 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:51:48,549 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:51:48,915 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:51:49,270 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:51:49,636 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:51:49,999 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:51:50,380 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:51:50,775 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:51:51,127 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:51:51,488 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:51:51,869 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-07 11:51:52,260 - INFO - training batch 551, loss: 0.455, 17632/28000 datapoints
2025-03-07 11:51:52,628 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:51:52,998 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:51:53,383 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:51:53,770 - INFO - training batch 751, loss: 0.630, 24032/28000 datapoints
2025-03-07 11:51:54,153 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-07 11:51:54,517 - INFO - training batch 851, loss: 0.059, 27232/28000 datapoints
2025-03-07 11:51:54,698 - INFO - validation batch 1, loss: 0.011, 32/6976 datapoints
2025-03-07 11:51:54,763 - INFO - validation batch 51, loss: 6.363, 1632/6976 datapoints
2025-03-07 11:51:54,828 - INFO - validation batch 101, loss: 1.982, 3232/6976 datapoints
2025-03-07 11:51:54,895 - INFO - validation batch 151, loss: 2.245, 4832/6976 datapoints
2025-03-07 11:51:54,961 - INFO - validation batch 201, loss: 5.565, 6432/6976 datapoints
2025-03-07 11:51:54,982 - INFO - Epoch 703/800 done.
2025-03-07 11:51:54,983 - INFO - Final validation performance:
Loss: 3.233, top-1 acc: 0.872top-5 acc: 0.872
2025-03-07 11:51:54,985 - INFO - Beginning epoch 704/800
2025-03-07 11:51:54,994 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:51:55,376 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:51:55,744 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:51:56,111 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:51:56,519 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:51:56,904 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:51:57,278 - INFO - training batch 301, loss: 0.031, 9632/28000 datapoints
2025-03-07 11:51:57,695 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:51:58,073 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:51:58,456 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:51:58,838 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:51:59,223 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:51:59,610 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:51:59,987 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:52:00,384 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:52:00,755 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:52:01,128 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:52:01,489 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-07 11:52:01,683 - INFO - validation batch 1, loss: 0.165, 32/6976 datapoints
2025-03-07 11:52:01,749 - INFO - validation batch 51, loss: 7.184, 1632/6976 datapoints
2025-03-07 11:52:01,812 - INFO - validation batch 101, loss: 2.031, 3232/6976 datapoints
2025-03-07 11:52:01,879 - INFO - validation batch 151, loss: 1.138, 4832/6976 datapoints
2025-03-07 11:52:01,946 - INFO - validation batch 201, loss: 5.088, 6432/6976 datapoints
2025-03-07 11:52:01,967 - INFO - Epoch 704/800 done.
2025-03-07 11:52:01,967 - INFO - Final validation performance:
Loss: 3.121, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:52:01,967 - INFO - Beginning epoch 705/800
2025-03-07 11:52:01,974 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:52:02,342 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-07 11:52:02,704 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:52:03,073 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:52:03,473 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:52:03,847 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:52:04,245 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:52:04,627 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:52:04,975 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:52:05,345 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:52:05,739 - INFO - training batch 501, loss: 0.217, 16032/28000 datapoints
2025-03-07 11:52:06,111 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:52:06,502 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:52:06,878 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 11:52:07,307 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:52:07,720 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:52:08,081 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-07 11:52:08,456 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:52:08,643 - INFO - validation batch 1, loss: 0.384, 32/6976 datapoints
2025-03-07 11:52:08,710 - INFO - validation batch 51, loss: 8.089, 1632/6976 datapoints
2025-03-07 11:52:08,777 - INFO - validation batch 101, loss: 2.041, 3232/6976 datapoints
2025-03-07 11:52:08,868 - INFO - validation batch 151, loss: 0.953, 4832/6976 datapoints
2025-03-07 11:52:08,950 - INFO - validation batch 201, loss: 5.065, 6432/6976 datapoints
2025-03-07 11:52:08,974 - INFO - Epoch 705/800 done.
2025-03-07 11:52:08,974 - INFO - Final validation performance:
Loss: 3.306, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:52:08,974 - INFO - Beginning epoch 706/800
2025-03-07 11:52:08,982 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:52:09,340 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:52:09,711 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:52:10,066 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:52:10,450 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:52:10,818 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:52:11,190 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 11:52:11,587 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:52:11,948 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:52:12,309 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:52:12,702 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:52:13,072 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:52:13,454 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:52:13,830 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:52:14,235 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:52:14,611 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:52:15,016 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:52:15,405 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:52:15,611 - INFO - validation batch 1, loss: 0.490, 32/6976 datapoints
2025-03-07 11:52:15,801 - INFO - validation batch 51, loss: 8.189, 1632/6976 datapoints
2025-03-07 11:52:15,871 - INFO - validation batch 101, loss: 2.001, 3232/6976 datapoints
2025-03-07 11:52:15,942 - INFO - validation batch 151, loss: 1.334, 4832/6976 datapoints
2025-03-07 11:52:16,015 - INFO - validation batch 201, loss: 5.213, 6432/6976 datapoints
2025-03-07 11:52:16,040 - INFO - Epoch 706/800 done.
2025-03-07 11:52:16,041 - INFO - Final validation performance:
Loss: 3.446, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:52:16,044 - INFO - Beginning epoch 707/800
2025-03-07 11:52:16,052 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:52:16,414 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:52:16,781 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:52:17,137 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:52:17,528 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:52:17,932 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:52:18,343 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 11:52:18,718 - INFO - training batch 351, loss: 0.120, 11232/28000 datapoints
2025-03-07 11:52:19,066 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:52:19,422 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:52:19,824 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:52:20,187 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:52:20,557 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:52:20,941 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:52:21,336 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:52:21,718 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:52:22,079 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-07 11:52:22,453 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:52:22,642 - INFO - validation batch 1, loss: 0.831, 32/6976 datapoints
2025-03-07 11:52:22,704 - INFO - validation batch 51, loss: 8.502, 1632/6976 datapoints
2025-03-07 11:52:22,765 - INFO - validation batch 101, loss: 2.125, 3232/6976 datapoints
2025-03-07 11:52:22,827 - INFO - validation batch 151, loss: 1.668, 4832/6976 datapoints
2025-03-07 11:52:22,887 - INFO - validation batch 201, loss: 6.141, 6432/6976 datapoints
2025-03-07 11:52:22,907 - INFO - Epoch 707/800 done.
2025-03-07 11:52:22,907 - INFO - Final validation performance:
Loss: 3.853, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:52:22,908 - INFO - Beginning epoch 708/800
2025-03-07 11:52:22,916 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:52:23,281 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:52:23,651 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:52:24,013 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:52:24,397 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:52:24,771 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:52:25,142 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 11:52:25,562 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:52:25,931 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:52:26,344 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:52:26,742 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:52:27,257 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:52:27,670 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:52:28,079 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 11:52:28,472 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:52:28,868 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:52:29,253 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:52:29,637 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:52:29,833 - INFO - validation batch 1, loss: 0.669, 32/6976 datapoints
2025-03-07 11:52:29,898 - INFO - validation batch 51, loss: 7.997, 1632/6976 datapoints
2025-03-07 11:52:29,963 - INFO - validation batch 101, loss: 2.169, 3232/6976 datapoints
2025-03-07 11:52:30,028 - INFO - validation batch 151, loss: 0.929, 4832/6976 datapoints
2025-03-07 11:52:30,092 - INFO - validation batch 201, loss: 5.131, 6432/6976 datapoints
2025-03-07 11:52:30,116 - INFO - Epoch 708/800 done.
2025-03-07 11:52:30,116 - INFO - Final validation performance:
Loss: 3.379, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:52:30,116 - INFO - Beginning epoch 709/800
2025-03-07 11:52:30,124 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:52:30,536 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:52:30,911 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:52:31,303 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:52:31,766 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:52:32,185 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:52:32,748 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:52:34,013 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:52:34,816 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:52:35,537 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:52:36,118 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:52:36,798 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:52:37,365 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:52:37,910 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:52:38,759 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:52:39,271 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:52:39,805 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:52:40,203 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:52:40,436 - INFO - validation batch 1, loss: 0.405, 32/6976 datapoints
2025-03-07 11:52:40,504 - INFO - validation batch 51, loss: 7.960, 1632/6976 datapoints
2025-03-07 11:52:40,568 - INFO - validation batch 101, loss: 2.048, 3232/6976 datapoints
2025-03-07 11:52:40,635 - INFO - validation batch 151, loss: 0.984, 4832/6976 datapoints
2025-03-07 11:52:40,702 - INFO - validation batch 201, loss: 4.955, 6432/6976 datapoints
2025-03-07 11:52:40,723 - INFO - Epoch 709/800 done.
2025-03-07 11:52:40,723 - INFO - Final validation performance:
Loss: 3.270, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:52:40,724 - INFO - Beginning epoch 710/800
2025-03-07 11:52:40,732 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:52:41,143 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:52:41,524 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:52:42,048 - INFO - training batch 151, loss: 0.038, 4832/28000 datapoints
2025-03-07 11:52:42,454 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 11:52:42,836 - INFO - training batch 251, loss: 0.337, 8032/28000 datapoints
2025-03-07 11:52:43,261 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:52:43,695 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:52:44,135 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:52:44,507 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:52:44,952 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:52:45,353 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-07 11:52:45,979 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:52:46,674 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:52:47,255 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:52:47,805 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:52:48,338 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 11:52:48,744 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:52:48,979 - INFO - validation batch 1, loss: 0.767, 32/6976 datapoints
2025-03-07 11:52:49,055 - INFO - validation batch 51, loss: 8.355, 1632/6976 datapoints
2025-03-07 11:52:49,125 - INFO - validation batch 101, loss: 2.044, 3232/6976 datapoints
2025-03-07 11:52:49,198 - INFO - validation batch 151, loss: 0.512, 4832/6976 datapoints
2025-03-07 11:52:49,287 - INFO - validation batch 201, loss: 4.479, 6432/6976 datapoints
2025-03-07 11:52:49,318 - INFO - Epoch 710/800 done.
2025-03-07 11:52:49,319 - INFO - Final validation performance:
Loss: 3.232, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 11:52:49,319 - INFO - Beginning epoch 711/800
2025-03-07 11:52:49,329 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:52:49,750 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:52:50,120 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:52:50,489 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:52:50,869 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:52:51,243 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-07 11:52:51,631 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:52:52,013 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:52:52,389 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:52:52,785 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 11:52:53,202 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:52:53,616 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 11:52:54,024 - INFO - training batch 601, loss: 0.239, 19232/28000 datapoints
2025-03-07 11:52:54,421 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 11:52:54,841 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:52:55,381 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:52:55,850 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 11:52:56,401 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:52:57,153 - INFO - validation batch 1, loss: 0.200, 32/6976 datapoints
2025-03-07 11:52:57,351 - INFO - validation batch 51, loss: 7.058, 1632/6976 datapoints
2025-03-07 11:52:57,486 - INFO - validation batch 101, loss: 2.058, 3232/6976 datapoints
2025-03-07 11:52:57,665 - INFO - validation batch 151, loss: 2.735, 4832/6976 datapoints
2025-03-07 11:52:58,216 - INFO - validation batch 201, loss: 5.243, 6432/6976 datapoints
2025-03-07 11:52:58,311 - INFO - Epoch 711/800 done.
2025-03-07 11:52:58,312 - INFO - Final validation performance:
Loss: 3.459, top-1 acc: 0.873top-5 acc: 0.873
2025-03-07 11:52:58,314 - INFO - Beginning epoch 712/800
2025-03-07 11:52:58,327 - INFO - training batch 1, loss: 0.030, 32/28000 datapoints
2025-03-07 11:52:58,866 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:52:59,292 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:52:59,774 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-07 11:53:00,391 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:53:00,921 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 11:53:01,403 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 11:53:01,862 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:53:02,264 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:53:02,653 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:53:03,065 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:53:03,448 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:53:03,825 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:53:04,219 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:53:04,640 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:53:05,029 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:53:05,392 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:53:05,768 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:53:05,963 - INFO - validation batch 1, loss: 0.407, 32/6976 datapoints
2025-03-07 11:53:06,032 - INFO - validation batch 51, loss: 8.488, 1632/6976 datapoints
2025-03-07 11:53:06,099 - INFO - validation batch 101, loss: 2.071, 3232/6976 datapoints
2025-03-07 11:53:06,167 - INFO - validation batch 151, loss: 1.254, 4832/6976 datapoints
2025-03-07 11:53:06,234 - INFO - validation batch 201, loss: 4.910, 6432/6976 datapoints
2025-03-07 11:53:06,258 - INFO - Epoch 712/800 done.
2025-03-07 11:53:06,258 - INFO - Final validation performance:
Loss: 3.426, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:53:06,259 - INFO - Beginning epoch 713/800
2025-03-07 11:53:06,266 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:53:06,641 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:53:07,011 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:53:07,380 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:53:07,821 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:53:08,233 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:53:08,666 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:53:09,067 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:53:09,449 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:53:09,818 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:53:10,214 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:53:10,590 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:53:10,978 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:53:11,354 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:53:11,763 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:53:12,153 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:53:12,527 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:53:12,913 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:53:13,122 - INFO - validation batch 1, loss: 0.482, 32/6976 datapoints
2025-03-07 11:53:13,207 - INFO - validation batch 51, loss: 8.464, 1632/6976 datapoints
2025-03-07 11:53:13,280 - INFO - validation batch 101, loss: 2.112, 3232/6976 datapoints
2025-03-07 11:53:13,364 - INFO - validation batch 151, loss: 1.226, 4832/6976 datapoints
2025-03-07 11:53:13,442 - INFO - validation batch 201, loss: 4.904, 6432/6976 datapoints
2025-03-07 11:53:13,468 - INFO - Epoch 713/800 done.
2025-03-07 11:53:13,469 - INFO - Final validation performance:
Loss: 3.437, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:53:13,469 - INFO - Beginning epoch 714/800
2025-03-07 11:53:13,478 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:53:13,902 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:53:14,324 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:53:14,733 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:53:15,123 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:53:15,512 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:53:15,903 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:53:16,321 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:53:16,718 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:53:17,097 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:53:17,493 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:53:17,871 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:53:18,260 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:53:18,658 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:53:19,065 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:53:19,509 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:53:19,911 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:53:20,320 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:53:20,537 - INFO - validation batch 1, loss: 0.471, 32/6976 datapoints
2025-03-07 11:53:20,617 - INFO - validation batch 51, loss: 8.463, 1632/6976 datapoints
2025-03-07 11:53:20,713 - INFO - validation batch 101, loss: 2.112, 3232/6976 datapoints
2025-03-07 11:53:20,797 - INFO - validation batch 151, loss: 1.235, 4832/6976 datapoints
2025-03-07 11:53:21,021 - INFO - validation batch 201, loss: 4.890, 6432/6976 datapoints
2025-03-07 11:53:21,085 - INFO - Epoch 714/800 done.
2025-03-07 11:53:21,085 - INFO - Final validation performance:
Loss: 3.434, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:53:21,087 - INFO - Beginning epoch 715/800
2025-03-07 11:53:21,101 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:53:21,589 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:53:22,027 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:53:22,467 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:53:22,891 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:53:23,362 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:53:24,028 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:53:24,557 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:53:24,981 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:53:25,471 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:53:25,918 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:53:26,526 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:53:26,981 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:53:27,416 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:53:27,865 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:53:28,272 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:53:28,676 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:53:29,074 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:53:29,279 - INFO - validation batch 1, loss: 0.466, 32/6976 datapoints
2025-03-07 11:53:29,361 - INFO - validation batch 51, loss: 8.450, 1632/6976 datapoints
2025-03-07 11:53:29,450 - INFO - validation batch 101, loss: 2.119, 3232/6976 datapoints
2025-03-07 11:53:29,535 - INFO - validation batch 151, loss: 1.243, 4832/6976 datapoints
2025-03-07 11:53:29,613 - INFO - validation batch 201, loss: 4.893, 6432/6976 datapoints
2025-03-07 11:53:29,637 - INFO - Epoch 715/800 done.
2025-03-07 11:53:29,637 - INFO - Final validation performance:
Loss: 3.434, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:53:29,638 - INFO - Beginning epoch 716/800
2025-03-07 11:53:29,647 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:53:30,036 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:53:30,470 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:53:30,875 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:53:31,281 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:53:31,706 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:53:32,138 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:53:32,641 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:53:33,161 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:53:33,590 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:53:34,042 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:53:34,515 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:53:34,972 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:53:35,440 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:53:35,868 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:53:36,316 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:53:36,737 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:53:37,117 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:53:37,315 - INFO - validation batch 1, loss: 0.465, 32/6976 datapoints
2025-03-07 11:53:37,386 - INFO - validation batch 51, loss: 8.431, 1632/6976 datapoints
2025-03-07 11:53:37,461 - INFO - validation batch 101, loss: 2.125, 3232/6976 datapoints
2025-03-07 11:53:37,530 - INFO - validation batch 151, loss: 1.247, 4832/6976 datapoints
2025-03-07 11:53:37,599 - INFO - validation batch 201, loss: 4.903, 6432/6976 datapoints
2025-03-07 11:53:37,628 - INFO - Epoch 716/800 done.
2025-03-07 11:53:37,628 - INFO - Final validation performance:
Loss: 3.434, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:53:37,629 - INFO - Beginning epoch 717/800
2025-03-07 11:53:37,636 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:53:38,012 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:53:38,382 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:53:38,768 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:53:39,147 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:53:39,529 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:53:39,920 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:53:40,315 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:53:40,684 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:53:41,048 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:53:41,524 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:53:41,977 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:53:42,382 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:53:42,774 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:53:43,186 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:53:43,626 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:53:43,999 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:53:44,413 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:53:44,623 - INFO - validation batch 1, loss: 0.472, 32/6976 datapoints
2025-03-07 11:53:44,694 - INFO - validation batch 51, loss: 8.419, 1632/6976 datapoints
2025-03-07 11:53:44,763 - INFO - validation batch 101, loss: 2.128, 3232/6976 datapoints
2025-03-07 11:53:44,833 - INFO - validation batch 151, loss: 1.233, 4832/6976 datapoints
2025-03-07 11:53:44,905 - INFO - validation batch 201, loss: 4.912, 6432/6976 datapoints
2025-03-07 11:53:44,927 - INFO - Epoch 717/800 done.
2025-03-07 11:53:44,928 - INFO - Final validation performance:
Loss: 3.433, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:53:44,928 - INFO - Beginning epoch 718/800
2025-03-07 11:53:44,937 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:53:45,315 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:53:45,700 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:53:46,067 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:53:46,441 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:53:46,822 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:53:47,252 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:53:47,653 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:53:48,014 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:53:48,379 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:53:48,766 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:53:49,155 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:53:49,531 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:53:49,904 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:53:50,291 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:53:50,662 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:53:51,015 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:53:51,387 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:53:51,579 - INFO - validation batch 1, loss: 0.487, 32/6976 datapoints
2025-03-07 11:53:51,646 - INFO - validation batch 51, loss: 8.418, 1632/6976 datapoints
2025-03-07 11:53:51,714 - INFO - validation batch 101, loss: 2.129, 3232/6976 datapoints
2025-03-07 11:53:51,778 - INFO - validation batch 151, loss: 1.196, 4832/6976 datapoints
2025-03-07 11:53:51,845 - INFO - validation batch 201, loss: 4.918, 6432/6976 datapoints
2025-03-07 11:53:51,867 - INFO - Epoch 718/800 done.
2025-03-07 11:53:51,867 - INFO - Final validation performance:
Loss: 3.430, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:53:51,868 - INFO - Beginning epoch 719/800
2025-03-07 11:53:51,875 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:53:52,247 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:53:52,618 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:53:52,979 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:53:53,344 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:53:53,716 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:53:54,099 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:53:54,483 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:53:54,840 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:53:55,199 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:53:55,582 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:53:55,948 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:53:56,330 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:53:56,715 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:53:57,109 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:53:57,483 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:53:57,850 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:53:58,243 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:53:58,437 - INFO - validation batch 1, loss: 0.512, 32/6976 datapoints
2025-03-07 11:53:58,503 - INFO - validation batch 51, loss: 8.424, 1632/6976 datapoints
2025-03-07 11:53:58,578 - INFO - validation batch 101, loss: 2.126, 3232/6976 datapoints
2025-03-07 11:53:58,658 - INFO - validation batch 151, loss: 1.141, 4832/6976 datapoints
2025-03-07 11:53:58,739 - INFO - validation batch 201, loss: 4.925, 6432/6976 datapoints
2025-03-07 11:53:58,769 - INFO - Epoch 719/800 done.
2025-03-07 11:53:58,769 - INFO - Final validation performance:
Loss: 3.425, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:53:58,770 - INFO - Beginning epoch 720/800
2025-03-07 11:53:58,778 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:53:59,301 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:54:00,235 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:54:01,447 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:54:02,131 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:54:02,681 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:54:03,158 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:54:03,636 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:54:04,044 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:54:04,422 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:54:04,839 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:54:05,221 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:54:05,660 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:54:06,052 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:54:06,455 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:54:06,837 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:54:07,192 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:54:07,607 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:54:07,822 - INFO - validation batch 1, loss: 0.536, 32/6976 datapoints
2025-03-07 11:54:07,906 - INFO - validation batch 51, loss: 8.432, 1632/6976 datapoints
2025-03-07 11:54:07,985 - INFO - validation batch 101, loss: 2.121, 3232/6976 datapoints
2025-03-07 11:54:08,062 - INFO - validation batch 151, loss: 1.070, 4832/6976 datapoints
2025-03-07 11:54:08,132 - INFO - validation batch 201, loss: 4.937, 6432/6976 datapoints
2025-03-07 11:54:08,158 - INFO - Epoch 720/800 done.
2025-03-07 11:54:08,158 - INFO - Final validation performance:
Loss: 3.419, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:54:08,159 - INFO - Beginning epoch 721/800
2025-03-07 11:54:08,167 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:54:08,581 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:54:08,999 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:54:09,428 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:54:09,846 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:54:10,236 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:54:10,641 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:54:11,038 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:54:11,420 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:54:11,830 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:54:12,251 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:54:12,625 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:54:13,012 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:54:13,401 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:54:13,826 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:54:14,234 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:54:14,639 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:54:15,124 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:54:15,470 - INFO - validation batch 1, loss: 0.559, 32/6976 datapoints
2025-03-07 11:54:15,576 - INFO - validation batch 51, loss: 8.441, 1632/6976 datapoints
2025-03-07 11:54:15,668 - INFO - validation batch 101, loss: 2.111, 3232/6976 datapoints
2025-03-07 11:54:15,807 - INFO - validation batch 151, loss: 1.000, 4832/6976 datapoints
2025-03-07 11:54:16,042 - INFO - validation batch 201, loss: 4.961, 6432/6976 datapoints
2025-03-07 11:54:16,089 - INFO - Epoch 721/800 done.
2025-03-07 11:54:16,090 - INFO - Final validation performance:
Loss: 3.414, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:54:16,091 - INFO - Beginning epoch 722/800
2025-03-07 11:54:16,100 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:54:16,518 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:54:16,921 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:54:17,313 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:54:17,730 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:54:18,128 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:54:18,521 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:54:18,910 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:54:19,276 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:54:19,683 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:54:20,095 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:54:20,460 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:54:20,891 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:54:21,290 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:54:21,693 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:54:22,081 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:54:22,453 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:54:22,837 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:54:23,034 - INFO - validation batch 1, loss: 0.581, 32/6976 datapoints
2025-03-07 11:54:23,099 - INFO - validation batch 51, loss: 8.453, 1632/6976 datapoints
2025-03-07 11:54:23,162 - INFO - validation batch 101, loss: 2.095, 3232/6976 datapoints
2025-03-07 11:54:23,229 - INFO - validation batch 151, loss: 0.940, 4832/6976 datapoints
2025-03-07 11:54:23,293 - INFO - validation batch 201, loss: 4.995, 6432/6976 datapoints
2025-03-07 11:54:23,315 - INFO - Epoch 722/800 done.
2025-03-07 11:54:23,316 - INFO - Final validation performance:
Loss: 3.413, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:54:23,316 - INFO - Beginning epoch 723/800
2025-03-07 11:54:23,324 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:54:23,729 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:54:24,113 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:54:24,486 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:54:24,862 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:54:25,254 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:54:25,668 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:54:26,143 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:54:26,512 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:54:26,879 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:54:27,275 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:54:27,665 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:54:28,047 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:54:28,426 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:54:28,837 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:54:29,223 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:54:29,591 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:54:30,005 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:54:30,197 - INFO - validation batch 1, loss: 0.589, 32/6976 datapoints
2025-03-07 11:54:30,261 - INFO - validation batch 51, loss: 8.474, 1632/6976 datapoints
2025-03-07 11:54:30,325 - INFO - validation batch 101, loss: 2.079, 3232/6976 datapoints
2025-03-07 11:54:30,391 - INFO - validation batch 151, loss: 0.920, 4832/6976 datapoints
2025-03-07 11:54:30,482 - INFO - validation batch 201, loss: 5.042, 6432/6976 datapoints
2025-03-07 11:54:30,506 - INFO - Epoch 723/800 done.
2025-03-07 11:54:30,506 - INFO - Final validation performance:
Loss: 3.421, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:54:30,507 - INFO - Beginning epoch 724/800
2025-03-07 11:54:30,514 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:54:30,903 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:54:31,284 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:54:31,680 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:54:32,293 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:54:32,804 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:54:33,347 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:54:33,873 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:54:34,355 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:54:34,824 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:54:35,362 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:54:35,853 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:54:36,285 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:54:36,716 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:54:37,117 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:54:37,505 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:54:37,867 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:54:38,242 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:54:38,447 - INFO - validation batch 1, loss: 0.585, 32/6976 datapoints
2025-03-07 11:54:38,532 - INFO - validation batch 51, loss: 8.500, 1632/6976 datapoints
2025-03-07 11:54:38,621 - INFO - validation batch 101, loss: 2.065, 3232/6976 datapoints
2025-03-07 11:54:38,714 - INFO - validation batch 151, loss: 0.933, 4832/6976 datapoints
2025-03-07 11:54:38,805 - INFO - validation batch 201, loss: 5.091, 6432/6976 datapoints
2025-03-07 11:54:38,835 - INFO - Epoch 724/800 done.
2025-03-07 11:54:38,835 - INFO - Final validation performance:
Loss: 3.435, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:54:38,836 - INFO - Beginning epoch 725/800
2025-03-07 11:54:38,845 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:54:39,917 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:54:40,325 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:54:40,717 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:54:41,102 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:54:41,497 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:54:41,912 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:54:42,331 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:54:42,721 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:54:43,117 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:54:43,517 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:54:43,908 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:54:44,307 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:54:44,703 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:54:45,110 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:54:45,578 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:54:45,967 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:54:46,361 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:54:46,562 - INFO - validation batch 1, loss: 0.570, 32/6976 datapoints
2025-03-07 11:54:46,638 - INFO - validation batch 51, loss: 8.527, 1632/6976 datapoints
2025-03-07 11:54:46,706 - INFO - validation batch 101, loss: 2.061, 3232/6976 datapoints
2025-03-07 11:54:46,774 - INFO - validation batch 151, loss: 0.962, 4832/6976 datapoints
2025-03-07 11:54:46,839 - INFO - validation batch 201, loss: 5.143, 6432/6976 datapoints
2025-03-07 11:54:46,867 - INFO - Epoch 725/800 done.
2025-03-07 11:54:46,867 - INFO - Final validation performance:
Loss: 3.453, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:54:46,868 - INFO - Beginning epoch 726/800
2025-03-07 11:54:46,876 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:54:47,344 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:54:47,750 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:54:48,129 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:54:48,514 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:54:48,908 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:54:49,307 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:54:49,715 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:54:50,106 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:54:50,483 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:54:50,887 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:54:51,257 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:54:51,658 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:54:52,055 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:54:52,463 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:54:52,854 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:54:53,226 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:54:53,622 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:54:53,819 - INFO - validation batch 1, loss: 0.544, 32/6976 datapoints
2025-03-07 11:54:53,897 - INFO - validation batch 51, loss: 8.574, 1632/6976 datapoints
2025-03-07 11:54:53,979 - INFO - validation batch 101, loss: 2.066, 3232/6976 datapoints
2025-03-07 11:54:54,052 - INFO - validation batch 151, loss: 0.989, 4832/6976 datapoints
2025-03-07 11:54:54,123 - INFO - validation batch 201, loss: 5.195, 6432/6976 datapoints
2025-03-07 11:54:54,147 - INFO - Epoch 726/800 done.
2025-03-07 11:54:54,147 - INFO - Final validation performance:
Loss: 3.474, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:54:54,148 - INFO - Beginning epoch 727/800
2025-03-07 11:54:54,156 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:54:54,555 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:54:54,979 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:54:55,402 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:54:55,817 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:54:56,219 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:54:56,619 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:54:57,019 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:54:57,384 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:54:57,768 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:54:58,162 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:54:58,534 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:54:58,930 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:54:59,318 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:54:59,718 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:55:00,122 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:55:00,515 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:55:00,910 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:55:01,109 - INFO - validation batch 1, loss: 0.526, 32/6976 datapoints
2025-03-07 11:55:01,171 - INFO - validation batch 51, loss: 8.676, 1632/6976 datapoints
2025-03-07 11:55:01,233 - INFO - validation batch 101, loss: 2.074, 3232/6976 datapoints
2025-03-07 11:55:01,296 - INFO - validation batch 151, loss: 0.977, 4832/6976 datapoints
2025-03-07 11:55:01,358 - INFO - validation batch 201, loss: 5.240, 6432/6976 datapoints
2025-03-07 11:55:01,379 - INFO - Epoch 727/800 done.
2025-03-07 11:55:01,379 - INFO - Final validation performance:
Loss: 3.499, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:55:01,380 - INFO - Beginning epoch 728/800
2025-03-07 11:55:01,387 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:55:01,803 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:55:02,201 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:55:02,590 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:55:02,977 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:55:03,371 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:55:03,780 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:55:04,195 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:55:04,569 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:55:04,946 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:55:05,344 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:55:05,730 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:55:06,163 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:55:06,620 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:55:07,074 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:55:07,604 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:55:08,002 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:55:08,435 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:55:08,637 - INFO - validation batch 1, loss: 0.411, 32/6976 datapoints
2025-03-07 11:55:08,718 - INFO - validation batch 51, loss: 8.720, 1632/6976 datapoints
2025-03-07 11:55:08,796 - INFO - validation batch 101, loss: 2.094, 3232/6976 datapoints
2025-03-07 11:55:08,877 - INFO - validation batch 151, loss: 1.146, 4832/6976 datapoints
2025-03-07 11:55:08,961 - INFO - validation batch 201, loss: 5.333, 6432/6976 datapoints
2025-03-07 11:55:08,988 - INFO - Epoch 728/800 done.
2025-03-07 11:55:08,988 - INFO - Final validation performance:
Loss: 3.541, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:55:08,989 - INFO - Beginning epoch 729/800
2025-03-07 11:55:08,998 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:55:09,443 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:55:09,842 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:55:10,252 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:55:10,769 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:55:11,182 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:55:11,662 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:55:12,161 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:55:12,714 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:55:13,147 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:55:13,917 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:55:14,324 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:55:14,751 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:55:15,171 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:55:15,682 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:55:16,190 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:55:16,613 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:55:17,074 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:55:17,304 - INFO - validation batch 1, loss: 0.495, 32/6976 datapoints
2025-03-07 11:55:17,384 - INFO - validation batch 51, loss: 8.761, 1632/6976 datapoints
2025-03-07 11:55:17,462 - INFO - validation batch 101, loss: 2.079, 3232/6976 datapoints
2025-03-07 11:55:17,545 - INFO - validation batch 151, loss: 1.060, 4832/6976 datapoints
2025-03-07 11:55:17,641 - INFO - validation batch 201, loss: 5.439, 6432/6976 datapoints
2025-03-07 11:55:17,691 - INFO - Epoch 729/800 done.
2025-03-07 11:55:17,691 - INFO - Final validation performance:
Loss: 3.567, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:55:17,692 - INFO - Beginning epoch 730/800
2025-03-07 11:55:17,703 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:55:18,114 - INFO - training batch 51, loss: 0.482, 1632/28000 datapoints
2025-03-07 11:55:18,513 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:55:18,887 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:55:19,282 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:55:19,687 - INFO - training batch 251, loss: 0.106, 8032/28000 datapoints
2025-03-07 11:55:20,108 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:55:20,520 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:55:20,912 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:55:21,328 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:55:21,738 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:55:22,123 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:55:22,515 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:55:22,915 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:55:23,318 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:55:23,713 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:55:24,117 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:55:24,501 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:55:24,688 - INFO - validation batch 1, loss: 0.836, 32/6976 datapoints
2025-03-07 11:55:24,758 - INFO - validation batch 51, loss: 8.691, 1632/6976 datapoints
2025-03-07 11:55:24,825 - INFO - validation batch 101, loss: 1.881, 3232/6976 datapoints
2025-03-07 11:55:24,894 - INFO - validation batch 151, loss: 1.615, 4832/6976 datapoints
2025-03-07 11:55:24,963 - INFO - validation batch 201, loss: 5.582, 6432/6976 datapoints
2025-03-07 11:55:24,987 - INFO - Epoch 730/800 done.
2025-03-07 11:55:24,988 - INFO - Final validation performance:
Loss: 3.721, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:55:24,989 - INFO - Beginning epoch 731/800
2025-03-07 11:55:24,997 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:55:25,376 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:55:25,792 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:55:26,260 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:55:26,674 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:55:27,081 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:55:27,517 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:55:27,953 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:55:28,322 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:55:28,721 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:55:29,111 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:55:29,499 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:55:29,918 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:55:30,316 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:55:30,875 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:55:31,312 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:55:31,752 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:55:32,163 - INFO - training batch 851, loss: 0.082, 27232/28000 datapoints
2025-03-07 11:55:32,372 - INFO - validation batch 1, loss: 0.316, 32/6976 datapoints
2025-03-07 11:55:32,443 - INFO - validation batch 51, loss: 9.492, 1632/6976 datapoints
2025-03-07 11:55:32,512 - INFO - validation batch 101, loss: 2.129, 3232/6976 datapoints
2025-03-07 11:55:32,583 - INFO - validation batch 151, loss: 1.711, 4832/6976 datapoints
2025-03-07 11:55:32,654 - INFO - validation batch 201, loss: 5.603, 6432/6976 datapoints
2025-03-07 11:55:32,677 - INFO - Epoch 731/800 done.
2025-03-07 11:55:32,677 - INFO - Final validation performance:
Loss: 3.850, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:55:32,678 - INFO - Beginning epoch 732/800
2025-03-07 11:55:32,685 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:55:33,069 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:55:33,461 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:55:33,848 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-07 11:55:34,243 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:55:34,636 - INFO - training batch 251, loss: 0.020, 8032/28000 datapoints
2025-03-07 11:55:35,082 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:55:35,507 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:55:35,901 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:55:36,291 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:55:36,719 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:55:37,106 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:55:37,516 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:55:38,047 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 11:55:38,617 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:55:39,158 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:55:39,733 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 11:55:40,211 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:55:40,620 - INFO - validation batch 1, loss: 0.630, 32/6976 datapoints
2025-03-07 11:55:40,714 - INFO - validation batch 51, loss: 7.189, 1632/6976 datapoints
2025-03-07 11:55:40,788 - INFO - validation batch 101, loss: 1.968, 3232/6976 datapoints
2025-03-07 11:55:40,887 - INFO - validation batch 151, loss: 1.496, 4832/6976 datapoints
2025-03-07 11:55:40,976 - INFO - validation batch 201, loss: 6.311, 6432/6976 datapoints
2025-03-07 11:55:41,005 - INFO - Epoch 732/800 done.
2025-03-07 11:55:41,005 - INFO - Final validation performance:
Loss: 3.519, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 11:55:41,006 - INFO - Beginning epoch 733/800
2025-03-07 11:55:41,014 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:55:41,569 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:55:42,124 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:55:42,603 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:55:43,073 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:55:43,539 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:55:44,038 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:55:44,525 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 11:55:44,952 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:55:45,354 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:55:45,764 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:55:46,145 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:55:46,538 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:55:46,950 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:55:47,406 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 11:55:47,828 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:55:48,239 - INFO - training batch 801, loss: 0.146, 25632/28000 datapoints
2025-03-07 11:55:48,700 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:55:48,919 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 11:55:48,986 - INFO - validation batch 51, loss: 7.334, 1632/6976 datapoints
2025-03-07 11:55:49,056 - INFO - validation batch 101, loss: 2.178, 3232/6976 datapoints
2025-03-07 11:55:49,128 - INFO - validation batch 151, loss: 3.142, 4832/6976 datapoints
2025-03-07 11:55:49,197 - INFO - validation batch 201, loss: 6.039, 6432/6976 datapoints
2025-03-07 11:55:49,221 - INFO - Epoch 733/800 done.
2025-03-07 11:55:49,221 - INFO - Final validation performance:
Loss: 3.739, top-1 acc: 0.872top-5 acc: 0.872
2025-03-07 11:55:49,222 - INFO - Beginning epoch 734/800
2025-03-07 11:55:49,230 - INFO - training batch 1, loss: 0.153, 32/28000 datapoints
2025-03-07 11:55:49,615 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:55:50,012 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:55:50,431 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:55:50,896 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:55:51,337 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:55:51,763 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:55:52,180 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 11:55:52,577 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:55:52,982 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-07 11:55:53,509 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:55:53,938 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:55:54,359 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:55:54,791 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:55:55,197 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:55:55,662 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:55:56,079 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:55:56,471 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:55:56,672 - INFO - validation batch 1, loss: 0.398, 32/6976 datapoints
2025-03-07 11:55:56,740 - INFO - validation batch 51, loss: 8.473, 1632/6976 datapoints
2025-03-07 11:55:56,808 - INFO - validation batch 101, loss: 1.884, 3232/6976 datapoints
2025-03-07 11:55:56,877 - INFO - validation batch 151, loss: 1.441, 4832/6976 datapoints
2025-03-07 11:55:56,945 - INFO - validation batch 201, loss: 5.080, 6432/6976 datapoints
2025-03-07 11:55:56,968 - INFO - Epoch 734/800 done.
2025-03-07 11:55:56,968 - INFO - Final validation performance:
Loss: 3.455, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:55:56,969 - INFO - Beginning epoch 735/800
2025-03-07 11:55:56,976 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:55:57,408 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 11:55:57,797 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:55:58,166 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:55:58,558 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:55:58,958 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 11:55:59,361 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 11:55:59,768 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:56:00,144 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:56:00,537 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 11:56:00,958 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:56:01,340 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:56:01,839 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:56:02,232 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:56:02,642 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:56:03,053 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:56:03,448 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:56:03,912 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:56:04,146 - INFO - validation batch 1, loss: 0.223, 32/6976 datapoints
2025-03-07 11:56:04,233 - INFO - validation batch 51, loss: 7.992, 1632/6976 datapoints
2025-03-07 11:56:04,330 - INFO - validation batch 101, loss: 1.874, 3232/6976 datapoints
2025-03-07 11:56:04,426 - INFO - validation batch 151, loss: 1.207, 4832/6976 datapoints
2025-03-07 11:56:04,507 - INFO - validation batch 201, loss: 5.436, 6432/6976 datapoints
2025-03-07 11:56:04,529 - INFO - Epoch 735/800 done.
2025-03-07 11:56:04,530 - INFO - Final validation performance:
Loss: 3.346, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:56:04,530 - INFO - Beginning epoch 736/800
2025-03-07 11:56:04,539 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:56:04,973 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 11:56:05,413 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:56:05,873 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:56:06,344 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:56:06,788 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:56:07,233 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:56:07,689 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:56:08,097 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:56:08,508 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:56:08,933 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:56:09,344 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:56:09,822 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:56:10,266 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:56:10,838 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:56:11,298 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:56:11,707 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:56:12,106 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:56:12,306 - INFO - validation batch 1, loss: 0.283, 32/6976 datapoints
2025-03-07 11:56:12,372 - INFO - validation batch 51, loss: 8.052, 1632/6976 datapoints
2025-03-07 11:56:12,444 - INFO - validation batch 101, loss: 1.847, 3232/6976 datapoints
2025-03-07 11:56:12,513 - INFO - validation batch 151, loss: 1.170, 4832/6976 datapoints
2025-03-07 11:56:12,583 - INFO - validation batch 201, loss: 5.488, 6432/6976 datapoints
2025-03-07 11:56:12,610 - INFO - Epoch 736/800 done.
2025-03-07 11:56:12,610 - INFO - Final validation performance:
Loss: 3.368, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:56:12,611 - INFO - Beginning epoch 737/800
2025-03-07 11:56:12,619 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:56:13,016 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 11:56:13,417 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:56:13,814 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:56:14,261 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:56:14,694 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:56:15,114 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:56:15,533 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:56:15,991 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:56:16,392 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:56:16,880 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:56:17,282 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:56:17,706 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:56:18,131 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:56:18,569 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:56:18,975 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:56:19,397 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:56:19,815 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:56:20,030 - INFO - validation batch 1, loss: 0.245, 32/6976 datapoints
2025-03-07 11:56:20,102 - INFO - validation batch 51, loss: 8.081, 1632/6976 datapoints
2025-03-07 11:56:20,180 - INFO - validation batch 101, loss: 1.801, 3232/6976 datapoints
2025-03-07 11:56:20,254 - INFO - validation batch 151, loss: 1.145, 4832/6976 datapoints
2025-03-07 11:56:20,324 - INFO - validation batch 201, loss: 5.442, 6432/6976 datapoints
2025-03-07 11:56:20,356 - INFO - Epoch 737/800 done.
2025-03-07 11:56:20,356 - INFO - Final validation performance:
Loss: 3.343, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 11:56:20,357 - INFO - Beginning epoch 738/800
2025-03-07 11:56:20,366 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:56:20,801 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 11:56:21,218 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:56:21,604 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:56:21,992 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:56:22,395 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:56:22,800 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:56:23,213 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:56:23,600 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:56:23,993 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:56:24,395 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:56:24,783 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:56:25,230 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:56:25,713 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:56:26,196 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:56:26,671 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:56:27,074 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:56:27,476 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:56:27,689 - INFO - validation batch 1, loss: 0.242, 32/6976 datapoints
2025-03-07 11:56:27,762 - INFO - validation batch 51, loss: 8.091, 1632/6976 datapoints
2025-03-07 11:56:27,840 - INFO - validation batch 101, loss: 1.800, 3232/6976 datapoints
2025-03-07 11:56:27,911 - INFO - validation batch 151, loss: 1.157, 4832/6976 datapoints
2025-03-07 11:56:27,987 - INFO - validation batch 201, loss: 5.455, 6432/6976 datapoints
2025-03-07 11:56:28,013 - INFO - Epoch 738/800 done.
2025-03-07 11:56:28,013 - INFO - Final validation performance:
Loss: 3.349, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 11:56:28,014 - INFO - Beginning epoch 739/800
2025-03-07 11:56:28,022 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:56:28,407 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 11:56:28,795 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:56:29,177 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:56:29,591 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:56:30,013 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:56:30,441 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:56:30,868 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:56:31,304 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:56:31,706 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:56:32,113 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:56:32,496 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:56:32,899 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:56:33,290 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:56:33,702 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:56:34,124 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:56:34,536 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:56:34,929 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:56:35,128 - INFO - validation batch 1, loss: 0.247, 32/6976 datapoints
2025-03-07 11:56:35,199 - INFO - validation batch 51, loss: 8.103, 1632/6976 datapoints
2025-03-07 11:56:35,267 - INFO - validation batch 101, loss: 1.800, 3232/6976 datapoints
2025-03-07 11:56:35,338 - INFO - validation batch 151, loss: 1.134, 4832/6976 datapoints
2025-03-07 11:56:35,420 - INFO - validation batch 201, loss: 5.467, 6432/6976 datapoints
2025-03-07 11:56:35,447 - INFO - Epoch 739/800 done.
2025-03-07 11:56:35,447 - INFO - Final validation performance:
Loss: 3.350, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 11:56:35,448 - INFO - Beginning epoch 740/800
2025-03-07 11:56:35,458 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:56:35,879 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 11:56:36,275 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:56:36,669 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:56:37,082 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:56:37,507 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:56:37,950 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:56:38,373 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:56:38,779 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:56:39,179 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:56:39,589 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:56:39,961 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:56:40,359 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:56:40,747 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:56:41,182 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:56:41,623 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:56:42,054 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:56:42,455 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:56:42,660 - INFO - validation batch 1, loss: 0.257, 32/6976 datapoints
2025-03-07 11:56:42,754 - INFO - validation batch 51, loss: 8.119, 1632/6976 datapoints
2025-03-07 11:56:42,852 - INFO - validation batch 101, loss: 1.802, 3232/6976 datapoints
2025-03-07 11:56:42,921 - INFO - validation batch 151, loss: 1.097, 4832/6976 datapoints
2025-03-07 11:56:42,987 - INFO - validation batch 201, loss: 5.479, 6432/6976 datapoints
2025-03-07 11:56:43,012 - INFO - Epoch 740/800 done.
2025-03-07 11:56:43,012 - INFO - Final validation performance:
Loss: 3.351, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:56:43,013 - INFO - Beginning epoch 741/800
2025-03-07 11:56:43,021 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:56:43,396 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 11:56:43,779 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:56:44,159 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:56:44,549 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:56:44,940 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:56:45,334 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:56:45,756 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:56:46,142 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:56:46,539 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:56:46,958 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:56:47,333 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:56:47,725 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:56:48,101 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:56:48,483 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:56:48,868 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:56:49,248 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:56:49,631 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:56:49,824 - INFO - validation batch 1, loss: 0.272, 32/6976 datapoints
2025-03-07 11:56:50,035 - INFO - validation batch 51, loss: 8.141, 1632/6976 datapoints
2025-03-07 11:56:50,121 - INFO - validation batch 101, loss: 1.804, 3232/6976 datapoints
2025-03-07 11:56:50,206 - INFO - validation batch 151, loss: 1.055, 4832/6976 datapoints
2025-03-07 11:56:50,299 - INFO - validation batch 201, loss: 5.491, 6432/6976 datapoints
2025-03-07 11:56:50,322 - INFO - Epoch 741/800 done.
2025-03-07 11:56:50,322 - INFO - Final validation performance:
Loss: 3.353, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:56:50,323 - INFO - Beginning epoch 742/800
2025-03-07 11:56:50,331 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:56:50,728 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 11:56:51,142 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:56:51,613 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:56:52,023 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:56:52,454 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:56:52,860 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:56:53,269 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:56:53,644 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:56:54,019 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:56:54,411 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:56:54,787 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:56:55,189 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:56:55,572 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:56:55,960 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:56:56,351 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:56:56,732 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:56:57,107 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:56:57,296 - INFO - validation batch 1, loss: 0.286, 32/6976 datapoints
2025-03-07 11:56:57,370 - INFO - validation batch 51, loss: 8.166, 1632/6976 datapoints
2025-03-07 11:56:57,442 - INFO - validation batch 101, loss: 1.806, 3232/6976 datapoints
2025-03-07 11:56:57,510 - INFO - validation batch 151, loss: 1.017, 4832/6976 datapoints
2025-03-07 11:56:57,576 - INFO - validation batch 201, loss: 5.505, 6432/6976 datapoints
2025-03-07 11:56:57,606 - INFO - Epoch 742/800 done.
2025-03-07 11:56:57,606 - INFO - Final validation performance:
Loss: 3.356, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:56:57,607 - INFO - Beginning epoch 743/800
2025-03-07 11:56:57,615 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:56:57,997 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 11:56:58,372 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:56:58,741 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:56:59,121 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:56:59,511 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:56:59,914 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:57:00,316 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:57:00,690 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:57:01,070 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:57:01,491 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:57:01,897 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:57:02,310 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:57:02,708 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:57:03,106 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:57:03,512 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:57:03,894 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:57:04,280 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:57:04,479 - INFO - validation batch 1, loss: 0.294, 32/6976 datapoints
2025-03-07 11:57:04,545 - INFO - validation batch 51, loss: 8.198, 1632/6976 datapoints
2025-03-07 11:57:04,611 - INFO - validation batch 101, loss: 1.806, 3232/6976 datapoints
2025-03-07 11:57:04,677 - INFO - validation batch 151, loss: 0.989, 4832/6976 datapoints
2025-03-07 11:57:04,744 - INFO - validation batch 201, loss: 5.517, 6432/6976 datapoints
2025-03-07 11:57:04,768 - INFO - Epoch 743/800 done.
2025-03-07 11:57:04,768 - INFO - Final validation performance:
Loss: 3.361, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:57:04,769 - INFO - Beginning epoch 744/800
2025-03-07 11:57:04,777 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:57:05,164 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 11:57:05,542 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:57:05,904 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:57:06,282 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:57:06,668 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:57:07,228 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:57:07,621 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:57:07,994 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:57:08,370 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:57:08,761 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:57:09,129 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:57:09,527 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:57:09,907 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:57:10,303 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:57:10,695 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:57:11,082 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:57:11,475 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:57:11,744 - INFO - validation batch 1, loss: 0.308, 32/6976 datapoints
2025-03-07 11:57:11,854 - INFO - validation batch 51, loss: 8.234, 1632/6976 datapoints
2025-03-07 11:57:11,952 - INFO - validation batch 101, loss: 1.806, 3232/6976 datapoints
2025-03-07 11:57:12,042 - INFO - validation batch 151, loss: 0.967, 4832/6976 datapoints
2025-03-07 11:57:12,129 - INFO - validation batch 201, loss: 5.530, 6432/6976 datapoints
2025-03-07 11:57:12,160 - INFO - Epoch 744/800 done.
2025-03-07 11:57:12,161 - INFO - Final validation performance:
Loss: 3.369, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:57:12,161 - INFO - Beginning epoch 745/800
2025-03-07 11:57:12,170 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:57:12,596 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 11:57:13,010 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:57:13,411 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:57:13,813 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:57:14,211 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:57:14,605 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:57:15,005 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:57:15,369 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:57:15,739 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:57:16,121 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:57:16,507 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:57:16,891 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:57:17,278 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:57:17,678 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:57:18,127 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:57:18,638 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:57:19,086 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:57:19,295 - INFO - validation batch 1, loss: 0.328, 32/6976 datapoints
2025-03-07 11:57:19,367 - INFO - validation batch 51, loss: 8.270, 1632/6976 datapoints
2025-03-07 11:57:19,440 - INFO - validation batch 101, loss: 1.807, 3232/6976 datapoints
2025-03-07 11:57:19,509 - INFO - validation batch 151, loss: 0.951, 4832/6976 datapoints
2025-03-07 11:57:19,581 - INFO - validation batch 201, loss: 5.543, 6432/6976 datapoints
2025-03-07 11:57:19,608 - INFO - Epoch 745/800 done.
2025-03-07 11:57:19,608 - INFO - Final validation performance:
Loss: 3.380, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:57:19,609 - INFO - Beginning epoch 746/800
2025-03-07 11:57:19,617 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:57:20,027 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:57:20,446 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:57:20,835 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:57:21,223 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:57:21,654 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:57:22,122 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:57:22,546 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:57:22,923 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:57:23,367 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:57:24,225 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:57:25,147 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:57:25,642 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:57:26,126 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:57:27,032 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:57:27,639 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:57:28,206 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:57:28,665 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:57:28,876 - INFO - validation batch 1, loss: 0.346, 32/6976 datapoints
2025-03-07 11:57:28,950 - INFO - validation batch 51, loss: 8.311, 1632/6976 datapoints
2025-03-07 11:57:29,056 - INFO - validation batch 101, loss: 1.812, 3232/6976 datapoints
2025-03-07 11:57:29,127 - INFO - validation batch 151, loss: 0.954, 4832/6976 datapoints
2025-03-07 11:57:29,200 - INFO - validation batch 201, loss: 5.560, 6432/6976 datapoints
2025-03-07 11:57:29,223 - INFO - Epoch 746/800 done.
2025-03-07 11:57:29,224 - INFO - Final validation performance:
Loss: 3.397, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:57:29,228 - INFO - Beginning epoch 747/800
2025-03-07 11:57:29,236 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:57:29,838 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:57:30,313 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:57:30,939 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:57:31,384 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:57:31,851 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:57:33,097 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:57:33,730 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:57:34,326 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:57:35,059 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:57:35,537 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:57:35,970 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:57:36,643 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:57:37,058 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:57:37,464 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:57:37,885 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:57:38,313 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:57:38,820 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:57:39,062 - INFO - validation batch 1, loss: 0.360, 32/6976 datapoints
2025-03-07 11:57:39,140 - INFO - validation batch 51, loss: 8.357, 1632/6976 datapoints
2025-03-07 11:57:39,209 - INFO - validation batch 101, loss: 1.827, 3232/6976 datapoints
2025-03-07 11:57:39,306 - INFO - validation batch 151, loss: 0.980, 4832/6976 datapoints
2025-03-07 11:57:39,395 - INFO - validation batch 201, loss: 5.578, 6432/6976 datapoints
2025-03-07 11:57:39,422 - INFO - Epoch 747/800 done.
2025-03-07 11:57:39,422 - INFO - Final validation performance:
Loss: 3.420, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:57:39,423 - INFO - Beginning epoch 748/800
2025-03-07 11:57:39,431 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:57:39,878 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:57:40,485 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:57:40,910 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:57:41,359 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:57:41,906 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:57:42,382 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:57:42,874 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:57:43,348 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:57:43,768 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:57:44,228 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:57:44,687 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:57:45,109 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:57:45,531 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:57:45,974 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:57:46,440 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:57:46,850 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:57:47,251 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:57:47,458 - INFO - validation batch 1, loss: 0.372, 32/6976 datapoints
2025-03-07 11:57:47,537 - INFO - validation batch 51, loss: 8.409, 1632/6976 datapoints
2025-03-07 11:57:47,669 - INFO - validation batch 101, loss: 1.849, 3232/6976 datapoints
2025-03-07 11:57:47,875 - INFO - validation batch 151, loss: 1.025, 4832/6976 datapoints
2025-03-07 11:57:47,966 - INFO - validation batch 201, loss: 5.595, 6432/6976 datapoints
2025-03-07 11:57:47,987 - INFO - Epoch 748/800 done.
2025-03-07 11:57:47,988 - INFO - Final validation performance:
Loss: 3.450, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:57:47,988 - INFO - Beginning epoch 749/800
2025-03-07 11:57:47,997 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:57:48,393 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:57:48,825 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:57:49,347 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:57:49,797 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:57:50,221 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:57:50,682 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:57:51,141 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:57:51,524 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:57:51,916 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:57:52,348 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:57:52,731 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:57:53,130 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:57:53,527 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:57:53,928 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:57:54,355 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:57:54,755 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:57:55,157 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:57:55,352 - INFO - validation batch 1, loss: 0.391, 32/6976 datapoints
2025-03-07 11:57:55,423 - INFO - validation batch 51, loss: 8.476, 1632/6976 datapoints
2025-03-07 11:57:55,493 - INFO - validation batch 101, loss: 1.880, 3232/6976 datapoints
2025-03-07 11:57:55,560 - INFO - validation batch 151, loss: 1.075, 4832/6976 datapoints
2025-03-07 11:57:55,626 - INFO - validation batch 201, loss: 5.600, 6432/6976 datapoints
2025-03-07 11:57:55,653 - INFO - Epoch 749/800 done.
2025-03-07 11:57:55,653 - INFO - Final validation performance:
Loss: 3.484, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:57:55,654 - INFO - Beginning epoch 750/800
2025-03-07 11:57:55,663 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:57:56,060 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:57:56,449 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:57:56,814 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:57:57,191 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:57:57,573 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:57:57,966 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:57:58,358 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:57:58,731 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:57:59,110 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:57:59,501 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:57:59,874 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:58:00,266 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:58:00,644 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:58:01,044 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:58:01,429 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:58:01,812 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:58:02,207 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:58:02,420 - INFO - validation batch 1, loss: 0.401, 32/6976 datapoints
2025-03-07 11:58:02,488 - INFO - validation batch 51, loss: 8.570, 1632/6976 datapoints
2025-03-07 11:58:02,554 - INFO - validation batch 101, loss: 1.925, 3232/6976 datapoints
2025-03-07 11:58:02,623 - INFO - validation batch 151, loss: 1.104, 4832/6976 datapoints
2025-03-07 11:58:02,690 - INFO - validation batch 201, loss: 5.587, 6432/6976 datapoints
2025-03-07 11:58:02,717 - INFO - Epoch 750/800 done.
2025-03-07 11:58:02,718 - INFO - Final validation performance:
Loss: 3.517, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 11:58:02,718 - INFO - Beginning epoch 751/800
2025-03-07 11:58:02,725 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:58:03,112 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:58:03,501 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:58:03,869 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:58:04,249 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:58:04,629 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:58:05,007 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:58:05,417 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:58:05,848 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:58:06,251 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:58:06,714 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:58:07,107 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:58:07,551 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:58:07,932 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:58:08,329 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:58:08,726 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:58:09,105 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:58:09,503 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:58:09,698 - INFO - validation batch 1, loss: 0.374, 32/6976 datapoints
2025-03-07 11:58:09,766 - INFO - validation batch 51, loss: 8.690, 1632/6976 datapoints
2025-03-07 11:58:09,833 - INFO - validation batch 101, loss: 1.963, 3232/6976 datapoints
2025-03-07 11:58:09,899 - INFO - validation batch 151, loss: 1.166, 4832/6976 datapoints
2025-03-07 11:58:09,967 - INFO - validation batch 201, loss: 5.588, 6432/6976 datapoints
2025-03-07 11:58:09,990 - INFO - Epoch 751/800 done.
2025-03-07 11:58:09,990 - INFO - Final validation performance:
Loss: 3.556, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:58:09,991 - INFO - Beginning epoch 752/800
2025-03-07 11:58:09,999 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:58:10,385 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:58:10,768 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:58:11,147 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:58:11,538 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:58:11,920 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:58:12,302 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:58:12,713 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:58:13,078 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:58:13,455 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:58:13,844 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:58:14,212 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:58:14,602 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:58:14,975 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:58:15,363 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:58:15,764 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:58:16,139 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:58:16,535 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:58:16,721 - INFO - validation batch 1, loss: 0.320, 32/6976 datapoints
2025-03-07 11:58:16,786 - INFO - validation batch 51, loss: 8.819, 1632/6976 datapoints
2025-03-07 11:58:16,853 - INFO - validation batch 101, loss: 2.025, 3232/6976 datapoints
2025-03-07 11:58:16,920 - INFO - validation batch 151, loss: 1.257, 4832/6976 datapoints
2025-03-07 11:58:16,987 - INFO - validation batch 201, loss: 5.622, 6432/6976 datapoints
2025-03-07 11:58:17,011 - INFO - Epoch 752/800 done.
2025-03-07 11:58:17,012 - INFO - Final validation performance:
Loss: 3.609, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:58:17,012 - INFO - Beginning epoch 753/800
2025-03-07 11:58:17,021 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:58:17,404 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:58:17,791 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:58:18,164 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:58:18,567 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:58:18,952 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:58:19,339 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:58:19,737 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:58:20,109 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:58:20,493 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:58:20,887 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:58:21,260 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:58:21,643 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:58:22,024 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:58:22,412 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:58:22,814 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:58:23,212 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:58:23,651 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:58:23,841 - INFO - validation batch 1, loss: 0.335, 32/6976 datapoints
2025-03-07 11:58:23,912 - INFO - validation batch 51, loss: 8.882, 1632/6976 datapoints
2025-03-07 11:58:23,980 - INFO - validation batch 101, loss: 2.079, 3232/6976 datapoints
2025-03-07 11:58:24,050 - INFO - validation batch 151, loss: 1.241, 4832/6976 datapoints
2025-03-07 11:58:24,119 - INFO - validation batch 201, loss: 5.605, 6432/6976 datapoints
2025-03-07 11:58:24,141 - INFO - Epoch 753/800 done.
2025-03-07 11:58:24,142 - INFO - Final validation performance:
Loss: 3.628, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:58:24,143 - INFO - Beginning epoch 754/800
2025-03-07 11:58:24,153 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:58:24,564 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:58:24,961 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:58:25,346 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:58:25,744 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:58:26,132 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:58:26,531 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:58:26,924 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:58:27,293 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:58:27,679 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:58:28,053 - INFO - training batch 501, loss: 0.279, 16032/28000 datapoints
2025-03-07 11:58:28,418 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 11:58:28,789 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:58:29,145 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:58:29,513 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:58:29,905 - INFO - training batch 751, loss: 0.135, 24032/28000 datapoints
2025-03-07 11:58:30,285 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 11:58:30,739 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:58:30,953 - INFO - validation batch 1, loss: 0.041, 32/6976 datapoints
2025-03-07 11:58:31,019 - INFO - validation batch 51, loss: 9.209, 1632/6976 datapoints
2025-03-07 11:58:31,083 - INFO - validation batch 101, loss: 1.698, 3232/6976 datapoints
2025-03-07 11:58:31,150 - INFO - validation batch 151, loss: 2.044, 4832/6976 datapoints
2025-03-07 11:58:31,215 - INFO - validation batch 201, loss: 5.926, 6432/6976 datapoints
2025-03-07 11:58:31,237 - INFO - Epoch 754/800 done.
2025-03-07 11:58:31,237 - INFO - Final validation performance:
Loss: 3.784, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:58:31,238 - INFO - Beginning epoch 755/800
2025-03-07 11:58:31,246 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:58:31,609 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:58:32,000 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:58:32,388 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:58:32,829 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:58:33,211 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:58:33,625 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:58:34,021 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:58:34,411 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-07 11:58:34,793 - INFO - training batch 451, loss: 0.051, 14432/28000 datapoints
2025-03-07 11:58:35,191 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:58:35,603 - INFO - training batch 551, loss: 0.085, 17632/28000 datapoints
2025-03-07 11:58:35,976 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:58:36,343 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:58:36,755 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:58:37,140 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:58:37,535 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:58:37,934 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 11:58:38,120 - INFO - validation batch 1, loss: 0.227, 32/6976 datapoints
2025-03-07 11:58:38,185 - INFO - validation batch 51, loss: 8.317, 1632/6976 datapoints
2025-03-07 11:58:38,252 - INFO - validation batch 101, loss: 1.764, 3232/6976 datapoints
2025-03-07 11:58:38,320 - INFO - validation batch 151, loss: 1.299, 4832/6976 datapoints
2025-03-07 11:58:38,387 - INFO - validation batch 201, loss: 4.837, 6432/6976 datapoints
2025-03-07 11:58:38,422 - INFO - Epoch 755/800 done.
2025-03-07 11:58:38,423 - INFO - Final validation performance:
Loss: 3.289, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:58:38,423 - INFO - Beginning epoch 756/800
2025-03-07 11:58:38,430 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:58:38,829 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:58:39,197 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 11:58:39,585 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:58:39,992 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:58:40,384 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:58:40,878 - INFO - training batch 301, loss: 0.249, 9632/28000 datapoints
2025-03-07 11:58:41,282 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:58:41,660 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:58:42,040 - INFO - training batch 451, loss: 0.024, 14432/28000 datapoints
2025-03-07 11:58:42,445 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:58:42,860 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:58:43,231 - INFO - training batch 601, loss: 0.009, 19232/28000 datapoints
2025-03-07 11:58:43,607 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:58:44,019 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:58:44,398 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:58:44,770 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:58:45,163 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:58:45,354 - INFO - validation batch 1, loss: 0.111, 32/6976 datapoints
2025-03-07 11:58:45,426 - INFO - validation batch 51, loss: 8.988, 1632/6976 datapoints
2025-03-07 11:58:45,514 - INFO - validation batch 101, loss: 1.730, 3232/6976 datapoints
2025-03-07 11:58:45,580 - INFO - validation batch 151, loss: 1.465, 4832/6976 datapoints
2025-03-07 11:58:45,645 - INFO - validation batch 201, loss: 5.332, 6432/6976 datapoints
2025-03-07 11:58:45,670 - INFO - Epoch 756/800 done.
2025-03-07 11:58:45,671 - INFO - Final validation performance:
Loss: 3.525, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 11:58:45,671 - INFO - Beginning epoch 757/800
2025-03-07 11:58:45,678 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:58:46,069 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:58:46,455 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-07 11:58:46,847 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:58:47,263 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:58:47,646 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:58:48,021 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:58:48,404 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:58:48,775 - INFO - training batch 401, loss: 0.020, 12832/28000 datapoints
2025-03-07 11:58:49,137 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:58:49,507 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:58:49,880 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:58:50,261 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:58:50,630 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:58:51,020 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:58:51,402 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:58:51,781 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:58:52,166 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:58:52,351 - INFO - validation batch 1, loss: 0.951, 32/6976 datapoints
2025-03-07 11:58:52,418 - INFO - validation batch 51, loss: 8.553, 1632/6976 datapoints
2025-03-07 11:58:52,482 - INFO - validation batch 101, loss: 2.135, 3232/6976 datapoints
2025-03-07 11:58:52,549 - INFO - validation batch 151, loss: 0.632, 4832/6976 datapoints
2025-03-07 11:58:52,612 - INFO - validation batch 201, loss: 5.598, 6432/6976 datapoints
2025-03-07 11:58:52,634 - INFO - Epoch 757/800 done.
2025-03-07 11:58:52,634 - INFO - Final validation performance:
Loss: 3.574, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:58:52,635 - INFO - Beginning epoch 758/800
2025-03-07 11:58:52,642 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:58:53,059 - INFO - training batch 51, loss: 0.303, 1632/28000 datapoints
2025-03-07 11:58:53,439 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 11:58:53,879 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:58:54,275 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:58:54,656 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 11:58:55,064 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:58:55,453 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:58:55,828 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 11:58:56,193 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:58:56,574 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:58:56,941 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:58:57,319 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:58:57,705 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:58:58,082 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:58:58,462 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:58:58,839 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:58:59,225 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:58:59,413 - INFO - validation batch 1, loss: 0.654, 32/6976 datapoints
2025-03-07 11:58:59,479 - INFO - validation batch 51, loss: 9.198, 1632/6976 datapoints
2025-03-07 11:58:59,544 - INFO - validation batch 101, loss: 1.815, 3232/6976 datapoints
2025-03-07 11:58:59,608 - INFO - validation batch 151, loss: 1.132, 4832/6976 datapoints
2025-03-07 11:58:59,674 - INFO - validation batch 201, loss: 5.374, 6432/6976 datapoints
2025-03-07 11:58:59,696 - INFO - Epoch 758/800 done.
2025-03-07 11:58:59,696 - INFO - Final validation performance:
Loss: 3.634, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:58:59,696 - INFO - Beginning epoch 759/800
2025-03-07 11:58:59,705 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:59:00,102 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:59:00,482 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:59:00,862 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:59:01,264 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:59:01,653 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:59:02,053 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:59:02,448 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:59:02,837 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:59:03,238 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:59:03,630 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:59:04,009 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:59:04,391 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:59:04,761 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:59:05,138 - INFO - training batch 701, loss: 0.122, 22432/28000 datapoints
2025-03-07 11:59:05,525 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:59:05,895 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:59:06,283 - INFO - training batch 851, loss: 0.084, 27232/28000 datapoints
2025-03-07 11:59:06,482 - INFO - validation batch 1, loss: 0.543, 32/6976 datapoints
2025-03-07 11:59:06,546 - INFO - validation batch 51, loss: 8.739, 1632/6976 datapoints
2025-03-07 11:59:06,612 - INFO - validation batch 101, loss: 1.888, 3232/6976 datapoints
2025-03-07 11:59:06,679 - INFO - validation batch 151, loss: 1.433, 4832/6976 datapoints
2025-03-07 11:59:06,745 - INFO - validation batch 201, loss: 4.957, 6432/6976 datapoints
2025-03-07 11:59:06,769 - INFO - Epoch 759/800 done.
2025-03-07 11:59:06,769 - INFO - Final validation performance:
Loss: 3.512, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 11:59:06,769 - INFO - Beginning epoch 760/800
2025-03-07 11:59:06,779 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:59:07,157 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:59:07,532 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:59:07,920 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 11:59:08,327 - INFO - training batch 201, loss: 0.117, 6432/28000 datapoints
2025-03-07 11:59:08,702 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:59:09,106 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:59:09,557 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-07 11:59:09,916 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:59:10,273 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 11:59:10,680 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:59:11,060 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 11:59:11,450 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:59:11,817 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:59:12,217 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:59:12,603 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:59:12,999 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:59:13,380 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:59:13,561 - INFO - validation batch 1, loss: 0.543, 32/6976 datapoints
2025-03-07 11:59:13,631 - INFO - validation batch 51, loss: 8.631, 1632/6976 datapoints
2025-03-07 11:59:13,696 - INFO - validation batch 101, loss: 1.810, 3232/6976 datapoints
2025-03-07 11:59:13,764 - INFO - validation batch 151, loss: 1.364, 4832/6976 datapoints
2025-03-07 11:59:13,829 - INFO - validation batch 201, loss: 5.490, 6432/6976 datapoints
2025-03-07 11:59:13,853 - INFO - Epoch 760/800 done.
2025-03-07 11:59:13,853 - INFO - Final validation performance:
Loss: 3.568, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 11:59:13,855 - INFO - Beginning epoch 761/800
2025-03-07 11:59:13,863 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:59:14,245 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:59:14,615 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:59:15,006 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:59:15,408 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:59:15,865 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:59:16,269 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:59:16,659 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:59:17,033 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:59:17,402 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:59:17,803 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:59:18,186 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:59:18,583 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:59:18,951 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:59:19,317 - INFO - training batch 701, loss: 0.014, 22432/28000 datapoints
2025-03-07 11:59:19,701 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:59:20,096 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 11:59:20,486 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-07 11:59:20,669 - INFO - validation batch 1, loss: 1.148, 32/6976 datapoints
2025-03-07 11:59:20,736 - INFO - validation batch 51, loss: 7.052, 1632/6976 datapoints
2025-03-07 11:59:20,801 - INFO - validation batch 101, loss: 2.265, 3232/6976 datapoints
2025-03-07 11:59:20,867 - INFO - validation batch 151, loss: 1.383, 4832/6976 datapoints
2025-03-07 11:59:20,934 - INFO - validation batch 201, loss: 5.417, 6432/6976 datapoints
2025-03-07 11:59:20,958 - INFO - Epoch 761/800 done.
2025-03-07 11:59:20,958 - INFO - Final validation performance:
Loss: 3.453, top-1 acc: 0.878top-5 acc: 0.878
2025-03-07 11:59:20,959 - INFO - Beginning epoch 762/800
2025-03-07 11:59:20,965 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:59:21,353 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:59:21,723 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:59:22,102 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:59:22,481 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:59:22,875 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:59:23,292 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:59:23,733 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:59:24,119 - INFO - training batch 401, loss: 0.079, 12832/28000 datapoints
2025-03-07 11:59:24,512 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:59:24,934 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:59:25,338 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:59:25,742 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:59:26,188 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:59:26,651 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:59:27,052 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:59:27,443 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:59:27,836 - INFO - training batch 851, loss: 0.026, 27232/28000 datapoints
2025-03-07 11:59:28,026 - INFO - validation batch 1, loss: 0.426, 32/6976 datapoints
2025-03-07 11:59:28,104 - INFO - validation batch 51, loss: 8.111, 1632/6976 datapoints
2025-03-07 11:59:28,168 - INFO - validation batch 101, loss: 2.202, 3232/6976 datapoints
2025-03-07 11:59:28,238 - INFO - validation batch 151, loss: 2.701, 4832/6976 datapoints
2025-03-07 11:59:28,303 - INFO - validation batch 201, loss: 5.039, 6432/6976 datapoints
2025-03-07 11:59:28,326 - INFO - Epoch 762/800 done.
2025-03-07 11:59:28,326 - INFO - Final validation performance:
Loss: 3.696, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 11:59:28,326 - INFO - Beginning epoch 763/800
2025-03-07 11:59:28,334 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 11:59:28,745 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:59:29,134 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:59:29,545 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:59:29,964 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:59:30,337 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:59:30,776 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:59:31,161 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 11:59:31,549 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:59:31,990 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:59:33,570 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:59:34,422 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:59:35,436 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:59:35,961 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:59:36,482 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:59:37,136 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:59:37,754 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:59:38,146 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:59:38,343 - INFO - validation batch 1, loss: 0.543, 32/6976 datapoints
2025-03-07 11:59:38,417 - INFO - validation batch 51, loss: 8.996, 1632/6976 datapoints
2025-03-07 11:59:38,485 - INFO - validation batch 101, loss: 1.900, 3232/6976 datapoints
2025-03-07 11:59:38,554 - INFO - validation batch 151, loss: 1.203, 4832/6976 datapoints
2025-03-07 11:59:38,622 - INFO - validation batch 201, loss: 4.870, 6432/6976 datapoints
2025-03-07 11:59:38,645 - INFO - Epoch 763/800 done.
2025-03-07 11:59:38,645 - INFO - Final validation performance:
Loss: 3.503, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 11:59:38,646 - INFO - Beginning epoch 764/800
2025-03-07 11:59:38,655 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:59:39,057 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:59:39,452 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:59:39,850 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:59:40,226 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:59:40,595 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:59:40,986 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:59:41,373 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:59:41,749 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:59:42,123 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:59:42,513 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:59:42,919 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:59:43,343 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:59:43,719 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:59:44,114 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:59:44,503 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:59:44,910 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:59:45,295 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:59:45,489 - INFO - validation batch 1, loss: 0.649, 32/6976 datapoints
2025-03-07 11:59:45,553 - INFO - validation batch 51, loss: 9.005, 1632/6976 datapoints
2025-03-07 11:59:45,619 - INFO - validation batch 101, loss: 1.880, 3232/6976 datapoints
2025-03-07 11:59:45,685 - INFO - validation batch 151, loss: 1.232, 4832/6976 datapoints
2025-03-07 11:59:45,752 - INFO - validation batch 201, loss: 4.936, 6432/6976 datapoints
2025-03-07 11:59:45,775 - INFO - Epoch 764/800 done.
2025-03-07 11:59:45,775 - INFO - Final validation performance:
Loss: 3.541, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 11:59:45,776 - INFO - Beginning epoch 765/800
2025-03-07 11:59:45,783 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:59:46,177 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:59:46,565 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:59:46,955 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:59:47,350 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:59:47,735 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:59:48,133 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:59:48,536 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:59:48,955 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:59:49,844 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:59:50,514 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:59:51,044 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 11:59:51,572 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 11:59:52,067 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 11:59:52,734 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 11:59:53,227 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 11:59:53,651 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 11:59:54,042 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 11:59:54,235 - INFO - validation batch 1, loss: 0.631, 32/6976 datapoints
2025-03-07 11:59:54,301 - INFO - validation batch 51, loss: 9.037, 1632/6976 datapoints
2025-03-07 11:59:54,367 - INFO - validation batch 101, loss: 1.865, 3232/6976 datapoints
2025-03-07 11:59:54,441 - INFO - validation batch 151, loss: 1.240, 4832/6976 datapoints
2025-03-07 11:59:54,506 - INFO - validation batch 201, loss: 4.896, 6432/6976 datapoints
2025-03-07 11:59:54,527 - INFO - Epoch 765/800 done.
2025-03-07 11:59:54,528 - INFO - Final validation performance:
Loss: 3.534, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 11:59:54,528 - INFO - Beginning epoch 766/800
2025-03-07 11:59:54,538 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 11:59:54,980 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 11:59:55,392 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 11:59:55,777 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 11:59:56,154 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 11:59:56,526 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 11:59:56,929 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 11:59:57,330 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 11:59:57,976 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 11:59:58,461 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 11:59:59,042 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 11:59:59,698 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:00:00,388 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:00:00,863 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:00:01,283 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:00:01,818 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:00:02,260 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:00:02,755 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:00:02,970 - INFO - validation batch 1, loss: 0.617, 32/6976 datapoints
2025-03-07 12:00:03,036 - INFO - validation batch 51, loss: 9.027, 1632/6976 datapoints
2025-03-07 12:00:03,102 - INFO - validation batch 101, loss: 1.854, 3232/6976 datapoints
2025-03-07 12:00:03,171 - INFO - validation batch 151, loss: 1.257, 4832/6976 datapoints
2025-03-07 12:00:03,245 - INFO - validation batch 201, loss: 4.886, 6432/6976 datapoints
2025-03-07 12:00:03,271 - INFO - Epoch 766/800 done.
2025-03-07 12:00:03,271 - INFO - Final validation performance:
Loss: 3.528, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:00:03,272 - INFO - Beginning epoch 767/800
2025-03-07 12:00:03,280 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:00:03,702 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:00:04,106 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:00:04,487 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:00:04,953 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:00:05,352 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:00:05,800 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:00:06,244 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:00:06,669 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:00:07,067 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:00:07,470 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:00:07,858 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:00:08,249 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:00:08,620 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:00:09,013 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:00:09,395 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:00:09,779 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:00:10,149 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:00:10,338 - INFO - validation batch 1, loss: 0.618, 32/6976 datapoints
2025-03-07 12:00:10,403 - INFO - validation batch 51, loss: 9.016, 1632/6976 datapoints
2025-03-07 12:00:10,472 - INFO - validation batch 101, loss: 1.841, 3232/6976 datapoints
2025-03-07 12:00:10,538 - INFO - validation batch 151, loss: 1.256, 4832/6976 datapoints
2025-03-07 12:00:10,603 - INFO - validation batch 201, loss: 4.880, 6432/6976 datapoints
2025-03-07 12:00:10,627 - INFO - Epoch 767/800 done.
2025-03-07 12:00:10,627 - INFO - Final validation performance:
Loss: 3.522, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:00:10,627 - INFO - Beginning epoch 768/800
2025-03-07 12:00:10,635 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:00:11,017 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:00:11,405 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:00:11,787 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:00:12,191 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:00:12,602 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:00:12,997 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:00:13,388 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:00:13,800 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:00:14,215 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:00:14,618 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:00:15,049 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:00:15,468 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:00:15,852 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:00:16,240 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:00:16,638 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:00:17,033 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:00:17,415 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:00:17,604 - INFO - validation batch 1, loss: 0.625, 32/6976 datapoints
2025-03-07 12:00:17,680 - INFO - validation batch 51, loss: 9.010, 1632/6976 datapoints
2025-03-07 12:00:17,746 - INFO - validation batch 101, loss: 1.827, 3232/6976 datapoints
2025-03-07 12:00:17,812 - INFO - validation batch 151, loss: 1.239, 4832/6976 datapoints
2025-03-07 12:00:17,878 - INFO - validation batch 201, loss: 4.875, 6432/6976 datapoints
2025-03-07 12:00:17,900 - INFO - Epoch 768/800 done.
2025-03-07 12:00:17,900 - INFO - Final validation performance:
Loss: 3.515, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:00:17,901 - INFO - Beginning epoch 769/800
2025-03-07 12:00:17,910 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:00:18,296 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:00:18,677 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:00:19,069 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:00:19,456 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:00:19,833 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:00:20,233 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:00:20,644 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:00:21,016 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:00:21,394 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:00:21,794 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:00:22,184 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:00:22,580 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:00:22,958 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:00:23,340 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:00:23,739 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:00:24,117 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:00:24,498 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:00:24,685 - INFO - validation batch 1, loss: 0.638, 32/6976 datapoints
2025-03-07 12:00:24,755 - INFO - validation batch 51, loss: 9.008, 1632/6976 datapoints
2025-03-07 12:00:24,820 - INFO - validation batch 101, loss: 1.813, 3232/6976 datapoints
2025-03-07 12:00:24,885 - INFO - validation batch 151, loss: 1.203, 4832/6976 datapoints
2025-03-07 12:00:24,952 - INFO - validation batch 201, loss: 4.869, 6432/6976 datapoints
2025-03-07 12:00:24,975 - INFO - Epoch 769/800 done.
2025-03-07 12:00:24,975 - INFO - Final validation performance:
Loss: 3.506, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:00:24,976 - INFO - Beginning epoch 770/800
2025-03-07 12:00:24,983 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:00:25,464 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:00:25,933 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:00:26,334 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:00:26,740 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:00:27,129 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:00:27,522 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:00:27,938 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:00:28,372 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:00:28,803 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:00:29,997 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:00:30,716 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:00:31,475 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:00:32,196 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:00:32,691 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:00:33,102 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:00:33,509 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:00:33,942 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:00:34,154 - INFO - validation batch 1, loss: 0.653, 32/6976 datapoints
2025-03-07 12:00:34,234 - INFO - validation batch 51, loss: 9.020, 1632/6976 datapoints
2025-03-07 12:00:34,311 - INFO - validation batch 101, loss: 1.804, 3232/6976 datapoints
2025-03-07 12:00:34,396 - INFO - validation batch 151, loss: 1.156, 4832/6976 datapoints
2025-03-07 12:00:34,488 - INFO - validation batch 201, loss: 4.868, 6432/6976 datapoints
2025-03-07 12:00:34,531 - INFO - Epoch 770/800 done.
2025-03-07 12:00:34,531 - INFO - Final validation performance:
Loss: 3.500, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:00:34,532 - INFO - Beginning epoch 771/800
2025-03-07 12:00:34,541 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:00:34,956 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:00:35,362 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:00:35,754 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:00:36,158 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:00:36,571 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:00:36,961 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:00:37,345 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:00:37,721 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:00:38,118 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:00:39,001 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:00:39,541 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:00:40,092 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:00:40,687 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:00:41,144 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:00:41,583 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:00:41,993 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:00:42,386 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:00:42,584 - INFO - validation batch 1, loss: 0.668, 32/6976 datapoints
2025-03-07 12:00:42,650 - INFO - validation batch 51, loss: 9.046, 1632/6976 datapoints
2025-03-07 12:00:42,716 - INFO - validation batch 101, loss: 1.796, 3232/6976 datapoints
2025-03-07 12:00:42,788 - INFO - validation batch 151, loss: 1.098, 4832/6976 datapoints
2025-03-07 12:00:42,854 - INFO - validation batch 201, loss: 4.878, 6432/6976 datapoints
2025-03-07 12:00:42,876 - INFO - Epoch 771/800 done.
2025-03-07 12:00:42,877 - INFO - Final validation performance:
Loss: 3.497, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:00:42,877 - INFO - Beginning epoch 772/800
2025-03-07 12:00:42,886 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:00:43,279 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:00:43,670 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:00:44,080 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:00:44,472 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:00:44,882 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:00:45,296 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:00:45,729 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:00:46,122 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:00:46,993 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:00:47,618 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:00:48,118 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:00:48,625 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:00:49,028 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:00:49,433 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:00:49,820 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:00:50,204 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:00:50,594 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:00:50,783 - INFO - validation batch 1, loss: 0.688, 32/6976 datapoints
2025-03-07 12:00:50,849 - INFO - validation batch 51, loss: 9.078, 1632/6976 datapoints
2025-03-07 12:00:50,914 - INFO - validation batch 101, loss: 1.786, 3232/6976 datapoints
2025-03-07 12:00:50,979 - INFO - validation batch 151, loss: 1.045, 4832/6976 datapoints
2025-03-07 12:00:51,046 - INFO - validation batch 201, loss: 4.904, 6432/6976 datapoints
2025-03-07 12:00:51,071 - INFO - Epoch 772/800 done.
2025-03-07 12:00:51,071 - INFO - Final validation performance:
Loss: 3.500, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:00:51,072 - INFO - Beginning epoch 773/800
2025-03-07 12:00:51,080 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:00:51,487 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:00:51,888 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:00:52,259 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:00:52,648 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:00:53,043 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:00:53,424 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:00:53,818 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:00:54,199 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:00:54,589 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:00:54,986 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:00:55,376 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:00:55,770 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:00:56,149 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:00:56,556 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:00:56,948 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:00:57,335 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:00:57,757 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:00:57,946 - INFO - validation batch 1, loss: 0.702, 32/6976 datapoints
2025-03-07 12:00:58,013 - INFO - validation batch 51, loss: 9.103, 1632/6976 datapoints
2025-03-07 12:00:58,081 - INFO - validation batch 101, loss: 1.773, 3232/6976 datapoints
2025-03-07 12:00:58,146 - INFO - validation batch 151, loss: 1.005, 4832/6976 datapoints
2025-03-07 12:00:58,213 - INFO - validation batch 201, loss: 4.936, 6432/6976 datapoints
2025-03-07 12:00:58,236 - INFO - Epoch 773/800 done.
2025-03-07 12:00:58,236 - INFO - Final validation performance:
Loss: 3.504, top-1 acc: 0.884top-5 acc: 0.884
2025-03-07 12:00:58,237 - INFO - Beginning epoch 774/800
2025-03-07 12:00:58,246 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:00:58,640 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:00:59,030 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:00:59,415 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:00:59,799 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:01:00,176 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:01:00,564 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:01:00,975 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:01:01,375 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:01:02,211 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:01:02,760 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:01:03,382 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:01:03,921 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:01:04,511 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:01:05,035 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:01:05,500 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:01:05,967 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:01:06,379 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:01:06,593 - INFO - validation batch 1, loss: 0.713, 32/6976 datapoints
2025-03-07 12:01:06,660 - INFO - validation batch 51, loss: 9.123, 1632/6976 datapoints
2025-03-07 12:01:06,732 - INFO - validation batch 101, loss: 1.764, 3232/6976 datapoints
2025-03-07 12:01:06,798 - INFO - validation batch 151, loss: 0.989, 4832/6976 datapoints
2025-03-07 12:01:06,868 - INFO - validation batch 201, loss: 4.974, 6432/6976 datapoints
2025-03-07 12:01:06,890 - INFO - Epoch 774/800 done.
2025-03-07 12:01:06,890 - INFO - Final validation performance:
Loss: 3.512, top-1 acc: 0.884top-5 acc: 0.884
2025-03-07 12:01:06,891 - INFO - Beginning epoch 775/800
2025-03-07 12:01:06,900 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:01:07,313 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:01:07,715 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:01:08,102 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:01:08,483 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:01:08,867 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:01:09,255 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:01:09,651 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:01:10,016 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:01:10,390 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:01:10,785 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:01:11,167 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:01:11,567 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:01:11,962 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:01:12,356 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:01:12,747 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:01:13,133 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:01:13,542 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:01:13,730 - INFO - validation batch 1, loss: 0.713, 32/6976 datapoints
2025-03-07 12:01:13,796 - INFO - validation batch 51, loss: 9.136, 1632/6976 datapoints
2025-03-07 12:01:13,863 - INFO - validation batch 101, loss: 1.763, 3232/6976 datapoints
2025-03-07 12:01:13,932 - INFO - validation batch 151, loss: 0.991, 4832/6976 datapoints
2025-03-07 12:01:13,997 - INFO - validation batch 201, loss: 5.027, 6432/6976 datapoints
2025-03-07 12:01:14,023 - INFO - Epoch 775/800 done.
2025-03-07 12:01:14,023 - INFO - Final validation performance:
Loss: 3.526, top-1 acc: 0.884top-5 acc: 0.884
2025-03-07 12:01:14,023 - INFO - Beginning epoch 776/800
2025-03-07 12:01:14,032 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:01:14,455 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:01:14,847 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:01:15,233 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:01:15,646 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:01:16,027 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:01:16,414 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:01:16,836 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:01:17,206 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:01:17,587 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:01:17,974 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:01:18,384 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:01:18,779 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:01:19,160 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:01:19,554 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:01:19,943 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:01:20,327 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:01:20,733 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:01:20,918 - INFO - validation batch 1, loss: 0.705, 32/6976 datapoints
2025-03-07 12:01:20,983 - INFO - validation batch 51, loss: 9.160, 1632/6976 datapoints
2025-03-07 12:01:21,049 - INFO - validation batch 101, loss: 1.768, 3232/6976 datapoints
2025-03-07 12:01:21,115 - INFO - validation batch 151, loss: 1.011, 4832/6976 datapoints
2025-03-07 12:01:21,180 - INFO - validation batch 201, loss: 5.089, 6432/6976 datapoints
2025-03-07 12:01:21,208 - INFO - Epoch 776/800 done.
2025-03-07 12:01:21,208 - INFO - Final validation performance:
Loss: 3.547, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:01:21,209 - INFO - Beginning epoch 777/800
2025-03-07 12:01:21,218 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:01:21,621 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:01:22,005 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:01:22,389 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:01:22,777 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:01:23,158 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:01:23,544 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:01:23,968 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:01:24,622 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:01:25,199 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:01:25,850 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:01:26,401 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:01:26,983 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:01:27,450 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:01:27,991 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:01:28,382 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:01:28,770 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:01:29,173 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:01:29,356 - INFO - validation batch 1, loss: 0.686, 32/6976 datapoints
2025-03-07 12:01:29,483 - INFO - validation batch 51, loss: 9.178, 1632/6976 datapoints
2025-03-07 12:01:29,587 - INFO - validation batch 101, loss: 1.786, 3232/6976 datapoints
2025-03-07 12:01:29,683 - INFO - validation batch 151, loss: 1.050, 4832/6976 datapoints
2025-03-07 12:01:29,871 - INFO - validation batch 201, loss: 5.154, 6432/6976 datapoints
2025-03-07 12:01:29,969 - INFO - Epoch 777/800 done.
2025-03-07 12:01:29,970 - INFO - Final validation performance:
Loss: 3.571, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:01:29,972 - INFO - Beginning epoch 778/800
2025-03-07 12:01:29,985 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:01:31,567 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:01:32,038 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:01:32,482 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:01:32,943 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:01:33,368 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:01:33,788 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:01:34,344 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:01:34,852 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:01:35,264 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:01:35,679 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:01:36,086 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:01:36,511 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:01:36,980 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:01:37,389 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:01:37,875 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:01:38,497 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:01:39,017 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:01:39,230 - INFO - validation batch 1, loss: 0.648, 32/6976 datapoints
2025-03-07 12:01:39,345 - INFO - validation batch 51, loss: 9.199, 1632/6976 datapoints
2025-03-07 12:01:39,468 - INFO - validation batch 101, loss: 1.818, 3232/6976 datapoints
2025-03-07 12:01:39,545 - INFO - validation batch 151, loss: 1.095, 4832/6976 datapoints
2025-03-07 12:01:39,622 - INFO - validation batch 201, loss: 5.214, 6432/6976 datapoints
2025-03-07 12:01:39,656 - INFO - Epoch 778/800 done.
2025-03-07 12:01:39,656 - INFO - Final validation performance:
Loss: 3.595, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 12:01:39,657 - INFO - Beginning epoch 779/800
2025-03-07 12:01:39,667 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:01:40,105 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:01:40,514 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:01:40,905 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:01:41,309 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:01:41,697 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:01:42,086 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:01:42,488 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:01:42,926 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:01:43,307 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:01:43,730 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:01:44,192 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:01:44,769 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:01:45,181 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:01:45,687 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:01:46,099 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:01:46,502 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:01:46,921 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:01:47,115 - INFO - validation batch 1, loss: 0.596, 32/6976 datapoints
2025-03-07 12:01:47,186 - INFO - validation batch 51, loss: 9.225, 1632/6976 datapoints
2025-03-07 12:01:47,253 - INFO - validation batch 101, loss: 1.867, 3232/6976 datapoints
2025-03-07 12:01:47,320 - INFO - validation batch 151, loss: 1.137, 4832/6976 datapoints
2025-03-07 12:01:47,387 - INFO - validation batch 201, loss: 5.266, 6432/6976 datapoints
2025-03-07 12:01:47,414 - INFO - Epoch 779/800 done.
2025-03-07 12:01:47,415 - INFO - Final validation performance:
Loss: 3.618, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 12:01:47,415 - INFO - Beginning epoch 780/800
2025-03-07 12:01:47,425 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:01:47,839 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:01:48,227 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:01:48,605 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:01:48,995 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:01:49,374 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:01:49,756 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:01:50,154 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:01:50,620 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:01:51,257 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:01:51,803 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:01:52,303 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:01:52,849 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:01:53,369 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:01:53,880 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:01:54,393 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:01:54,852 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:01:55,307 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:01:55,536 - INFO - validation batch 1, loss: 0.526, 32/6976 datapoints
2025-03-07 12:01:55,607 - INFO - validation batch 51, loss: 9.293, 1632/6976 datapoints
2025-03-07 12:01:55,680 - INFO - validation batch 101, loss: 1.921, 3232/6976 datapoints
2025-03-07 12:01:55,750 - INFO - validation batch 151, loss: 1.151, 4832/6976 datapoints
2025-03-07 12:01:55,827 - INFO - validation batch 201, loss: 5.343, 6432/6976 datapoints
2025-03-07 12:01:55,853 - INFO - Epoch 780/800 done.
2025-03-07 12:01:55,853 - INFO - Final validation performance:
Loss: 3.647, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 12:01:55,855 - INFO - Beginning epoch 781/800
2025-03-07 12:01:55,869 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:01:56,335 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:01:56,772 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:01:57,181 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:01:57,597 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:01:58,010 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:01:58,428 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:01:58,864 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:01:59,268 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:01:59,681 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:02:05,823 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:02:07,612 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:02:08,290 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:02:09,185 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:02:15,429 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:02:16,557 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:02:20,186 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:02:22,121 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:02:22,484 - INFO - validation batch 1, loss: 0.520, 32/6976 datapoints
2025-03-07 12:02:22,666 - INFO - validation batch 51, loss: 9.365, 1632/6976 datapoints
2025-03-07 12:02:22,983 - INFO - validation batch 101, loss: 1.962, 3232/6976 datapoints
2025-03-07 12:02:23,113 - INFO - validation batch 151, loss: 1.094, 4832/6976 datapoints
2025-03-07 12:02:23,256 - INFO - validation batch 201, loss: 5.480, 6432/6976 datapoints
2025-03-07 12:02:23,302 - INFO - Epoch 781/800 done.
2025-03-07 12:02:23,303 - INFO - Final validation performance:
Loss: 3.684, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 12:02:23,307 - INFO - Beginning epoch 782/800
2025-03-07 12:02:23,321 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:02:24,216 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:02:25,571 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:02:26,723 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:02:27,342 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:02:27,800 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:02:28,271 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:02:28,721 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:02:29,139 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:02:29,565 - INFO - training batch 451, loss: 0.632, 14432/28000 datapoints
2025-03-07 12:02:30,009 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:02:30,437 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:02:31,100 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:02:31,528 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:02:32,147 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:02:32,579 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:02:32,991 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:02:33,405 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:02:33,617 - INFO - validation batch 1, loss: 0.861, 32/6976 datapoints
2025-03-07 12:02:33,687 - INFO - validation batch 51, loss: 8.851, 1632/6976 datapoints
2025-03-07 12:02:33,763 - INFO - validation batch 101, loss: 1.701, 3232/6976 datapoints
2025-03-07 12:02:33,849 - INFO - validation batch 151, loss: 1.184, 4832/6976 datapoints
2025-03-07 12:02:33,939 - INFO - validation batch 201, loss: 5.938, 6432/6976 datapoints
2025-03-07 12:02:33,999 - INFO - Epoch 782/800 done.
2025-03-07 12:02:33,999 - INFO - Final validation performance:
Loss: 3.707, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 12:02:34,000 - INFO - Beginning epoch 783/800
2025-03-07 12:02:34,009 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:02:34,448 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:02:34,956 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:02:35,485 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:02:36,072 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:02:36,550 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 12:02:36,981 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:02:37,382 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:02:37,780 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:02:38,168 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:02:38,592 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:02:39,001 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:02:39,445 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:02:39,972 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:02:41,566 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:02:44,332 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:02:44,887 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:02:45,441 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:02:45,751 - INFO - validation batch 1, loss: 0.824, 32/6976 datapoints
2025-03-07 12:02:45,871 - INFO - validation batch 51, loss: 9.019, 1632/6976 datapoints
2025-03-07 12:02:46,029 - INFO - validation batch 101, loss: 1.746, 3232/6976 datapoints
2025-03-07 12:02:46,156 - INFO - validation batch 151, loss: 1.213, 4832/6976 datapoints
2025-03-07 12:02:46,378 - INFO - validation batch 201, loss: 5.783, 6432/6976 datapoints
2025-03-07 12:02:46,470 - INFO - Epoch 783/800 done.
2025-03-07 12:02:46,471 - INFO - Final validation performance:
Loss: 3.717, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:02:46,476 - INFO - Beginning epoch 784/800
2025-03-07 12:02:46,489 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:02:48,192 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 12:02:49,571 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:02:53,377 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:02:54,895 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:02:55,963 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:02:57,088 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:02:57,936 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:02:58,729 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:02:59,388 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:03:00,035 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:03:00,652 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:03:01,370 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:03:01,923 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:03:02,768 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:03:03,512 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:03:04,121 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:03:05,257 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:03:05,599 - INFO - validation batch 1, loss: 0.709, 32/6976 datapoints
2025-03-07 12:03:06,131 - INFO - validation batch 51, loss: 9.171, 1632/6976 datapoints
2025-03-07 12:03:06,292 - INFO - validation batch 101, loss: 1.774, 3232/6976 datapoints
2025-03-07 12:03:06,450 - INFO - validation batch 151, loss: 1.250, 4832/6976 datapoints
2025-03-07 12:03:06,695 - INFO - validation batch 201, loss: 5.730, 6432/6976 datapoints
2025-03-07 12:03:06,833 - INFO - Epoch 784/800 done.
2025-03-07 12:03:06,838 - INFO - Final validation performance:
Loss: 3.727, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 12:03:06,856 - INFO - Beginning epoch 785/800
2025-03-07 12:03:07,003 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:03:09,536 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 12:03:10,857 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:03:12,940 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:03:13,981 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:03:14,525 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:03:15,158 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:03:15,636 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:03:16,093 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:03:16,605 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:03:17,136 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:03:17,697 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:03:18,297 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:03:18,846 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:03:19,392 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:03:20,194 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:03:20,767 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:03:21,241 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:03:21,461 - INFO - validation batch 1, loss: 0.784, 32/6976 datapoints
2025-03-07 12:03:21,555 - INFO - validation batch 51, loss: 9.015, 1632/6976 datapoints
2025-03-07 12:03:21,649 - INFO - validation batch 101, loss: 1.808, 3232/6976 datapoints
2025-03-07 12:03:21,745 - INFO - validation batch 151, loss: 1.210, 4832/6976 datapoints
2025-03-07 12:03:21,843 - INFO - validation batch 201, loss: 5.792, 6432/6976 datapoints
2025-03-07 12:03:21,879 - INFO - Epoch 785/800 done.
2025-03-07 12:03:21,880 - INFO - Final validation performance:
Loss: 3.722, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:03:21,882 - INFO - Beginning epoch 786/800
2025-03-07 12:03:21,890 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:03:22,445 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 12:03:22,873 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:03:23,274 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:03:23,683 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:03:24,081 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:03:24,475 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:03:24,870 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:03:25,243 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:03:25,646 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:03:26,092 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:03:26,567 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:03:27,013 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:03:27,418 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:03:27,837 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:03:28,270 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:03:28,673 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:03:29,110 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:03:29,309 - INFO - validation batch 1, loss: 0.770, 32/6976 datapoints
2025-03-07 12:03:29,378 - INFO - validation batch 51, loss: 9.025, 1632/6976 datapoints
2025-03-07 12:03:29,453 - INFO - validation batch 101, loss: 1.827, 3232/6976 datapoints
2025-03-07 12:03:29,526 - INFO - validation batch 151, loss: 1.212, 4832/6976 datapoints
2025-03-07 12:03:29,603 - INFO - validation batch 201, loss: 5.746, 6432/6976 datapoints
2025-03-07 12:03:29,628 - INFO - Epoch 786/800 done.
2025-03-07 12:03:29,628 - INFO - Final validation performance:
Loss: 3.716, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:03:29,629 - INFO - Beginning epoch 787/800
2025-03-07 12:03:29,638 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:03:30,073 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 12:03:30,661 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:03:31,113 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:03:31,538 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:03:31,954 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:03:32,360 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:03:32,776 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:03:33,191 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:03:33,611 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:03:34,043 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:03:34,459 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:03:34,878 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:03:35,301 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:03:35,714 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:03:36,130 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:03:36,551 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:03:37,033 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:03:37,271 - INFO - validation batch 1, loss: 0.773, 32/6976 datapoints
2025-03-07 12:03:37,374 - INFO - validation batch 51, loss: 9.017, 1632/6976 datapoints
2025-03-07 12:03:37,512 - INFO - validation batch 101, loss: 1.843, 3232/6976 datapoints
2025-03-07 12:03:37,589 - INFO - validation batch 151, loss: 1.207, 4832/6976 datapoints
2025-03-07 12:03:37,657 - INFO - validation batch 201, loss: 5.724, 6432/6976 datapoints
2025-03-07 12:03:37,682 - INFO - Epoch 787/800 done.
2025-03-07 12:03:37,682 - INFO - Final validation performance:
Loss: 3.713, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:03:37,683 - INFO - Beginning epoch 788/800
2025-03-07 12:03:37,692 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:03:38,147 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 12:03:39,197 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:03:40,034 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:03:40,631 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:03:41,674 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:03:42,174 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:03:43,110 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:03:43,576 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:03:44,017 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:03:44,442 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:03:44,853 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:03:45,263 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:03:45,661 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:03:46,055 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:03:46,484 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:03:46,860 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:03:47,267 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:03:47,464 - INFO - validation batch 1, loss: 0.781, 32/6976 datapoints
2025-03-07 12:03:47,532 - INFO - validation batch 51, loss: 9.016, 1632/6976 datapoints
2025-03-07 12:03:47,603 - INFO - validation batch 101, loss: 1.860, 3232/6976 datapoints
2025-03-07 12:03:47,672 - INFO - validation batch 151, loss: 1.195, 4832/6976 datapoints
2025-03-07 12:03:47,741 - INFO - validation batch 201, loss: 5.700, 6432/6976 datapoints
2025-03-07 12:03:47,767 - INFO - Epoch 788/800 done.
2025-03-07 12:03:47,767 - INFO - Final validation performance:
Loss: 3.710, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:03:47,768 - INFO - Beginning epoch 789/800
2025-03-07 12:03:47,777 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:03:48,207 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 12:03:48,602 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:03:49,006 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:03:49,409 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:03:49,814 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:03:50,233 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:03:50,667 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:03:51,052 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:03:51,448 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:03:51,865 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:03:52,302 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:03:52,756 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:03:53,247 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:03:53,712 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:03:54,533 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:03:54,953 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:03:55,449 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:03:56,285 - INFO - validation batch 1, loss: 0.791, 32/6976 datapoints
2025-03-07 12:03:56,660 - INFO - validation batch 51, loss: 9.021, 1632/6976 datapoints
2025-03-07 12:03:56,847 - INFO - validation batch 101, loss: 1.876, 3232/6976 datapoints
2025-03-07 12:03:56,931 - INFO - validation batch 151, loss: 1.177, 4832/6976 datapoints
2025-03-07 12:03:57,116 - INFO - validation batch 201, loss: 5.674, 6432/6976 datapoints
2025-03-07 12:03:57,164 - INFO - Epoch 789/800 done.
2025-03-07 12:03:57,164 - INFO - Final validation performance:
Loss: 3.708, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:03:57,165 - INFO - Beginning epoch 790/800
2025-03-07 12:03:57,187 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:03:57,793 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 12:03:58,305 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:03:59,030 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:03:59,605 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:04:00,119 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:04:00,704 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:04:01,159 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:04:01,675 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:04:02,091 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:04:02,538 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:04:02,951 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:04:03,351 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:04:03,787 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:04:04,192 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:04:04,633 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:04:05,020 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:04:05,440 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:04:05,643 - INFO - validation batch 1, loss: 0.805, 32/6976 datapoints
2025-03-07 12:04:05,715 - INFO - validation batch 51, loss: 9.030, 1632/6976 datapoints
2025-03-07 12:04:05,903 - INFO - validation batch 101, loss: 1.891, 3232/6976 datapoints
2025-03-07 12:04:06,003 - INFO - validation batch 151, loss: 1.154, 4832/6976 datapoints
2025-03-07 12:04:06,069 - INFO - validation batch 201, loss: 5.643, 6432/6976 datapoints
2025-03-07 12:04:06,092 - INFO - Epoch 790/800 done.
2025-03-07 12:04:06,092 - INFO - Final validation performance:
Loss: 3.705, top-1 acc: 0.884top-5 acc: 0.884
2025-03-07 12:04:06,093 - INFO - Beginning epoch 791/800
2025-03-07 12:04:06,104 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:04:06,896 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 12:04:07,386 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:04:07,848 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:04:08,362 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:04:08,845 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:04:09,389 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:04:09,934 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:04:10,380 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:04:10,866 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:04:11,378 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:04:11,840 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:04:12,307 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:04:12,816 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:04:13,309 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:04:13,768 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:04:14,212 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:04:14,675 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:04:14,892 - INFO - validation batch 1, loss: 0.818, 32/6976 datapoints
2025-03-07 12:04:14,973 - INFO - validation batch 51, loss: 9.045, 1632/6976 datapoints
2025-03-07 12:04:15,052 - INFO - validation batch 101, loss: 1.901, 3232/6976 datapoints
2025-03-07 12:04:15,135 - INFO - validation batch 151, loss: 1.130, 4832/6976 datapoints
2025-03-07 12:04:15,215 - INFO - validation batch 201, loss: 5.606, 6432/6976 datapoints
2025-03-07 12:04:15,242 - INFO - Epoch 791/800 done.
2025-03-07 12:04:15,243 - INFO - Final validation performance:
Loss: 3.700, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:04:15,243 - INFO - Beginning epoch 792/800
2025-03-07 12:04:15,254 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:04:15,743 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 12:04:16,176 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:04:16,703 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:04:17,235 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:04:17,669 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:04:18,080 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:04:18,508 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:04:18,925 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:04:19,333 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:04:19,756 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:04:20,160 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:04:20,563 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:04:20,961 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:04:21,362 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:04:21,776 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:04:22,205 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:04:22,646 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:04:22,855 - INFO - validation batch 1, loss: 0.830, 32/6976 datapoints
2025-03-07 12:04:22,937 - INFO - validation batch 51, loss: 9.072, 1632/6976 datapoints
2025-03-07 12:04:23,016 - INFO - validation batch 101, loss: 1.907, 3232/6976 datapoints
2025-03-07 12:04:23,085 - INFO - validation batch 151, loss: 1.105, 4832/6976 datapoints
2025-03-07 12:04:23,160 - INFO - validation batch 201, loss: 5.566, 6432/6976 datapoints
2025-03-07 12:04:23,191 - INFO - Epoch 792/800 done.
2025-03-07 12:04:23,191 - INFO - Final validation performance:
Loss: 3.696, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 12:04:23,192 - INFO - Beginning epoch 793/800
2025-03-07 12:04:23,203 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:04:23,738 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:04:24,176 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:04:24,607 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:04:25,080 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:04:25,550 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:04:25,999 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:04:26,463 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:04:26,855 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:04:27,285 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:04:27,727 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:04:28,134 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:04:28,530 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:04:28,942 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:04:29,369 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:04:29,795 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:04:30,218 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:04:30,785 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:04:31,056 - INFO - validation batch 1, loss: 0.837, 32/6976 datapoints
2025-03-07 12:04:31,136 - INFO - validation batch 51, loss: 9.114, 1632/6976 datapoints
2025-03-07 12:04:31,217 - INFO - validation batch 101, loss: 1.907, 3232/6976 datapoints
2025-03-07 12:04:31,294 - INFO - validation batch 151, loss: 1.085, 4832/6976 datapoints
2025-03-07 12:04:31,363 - INFO - validation batch 201, loss: 5.530, 6432/6976 datapoints
2025-03-07 12:04:31,387 - INFO - Epoch 793/800 done.
2025-03-07 12:04:31,387 - INFO - Final validation performance:
Loss: 3.694, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 12:04:31,388 - INFO - Beginning epoch 794/800
2025-03-07 12:04:31,398 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:04:31,834 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:04:32,237 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:04:32,666 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:04:33,076 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:04:33,491 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:04:33,926 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:04:34,342 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:04:34,763 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:04:35,165 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:04:35,617 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:04:36,054 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:04:36,498 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:04:36,936 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:04:37,428 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:04:37,904 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:04:38,356 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:04:38,851 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:04:39,070 - INFO - validation batch 1, loss: 0.838, 32/6976 datapoints
2025-03-07 12:04:39,147 - INFO - validation batch 51, loss: 9.152, 1632/6976 datapoints
2025-03-07 12:04:39,224 - INFO - validation batch 101, loss: 1.909, 3232/6976 datapoints
2025-03-07 12:04:39,305 - INFO - validation batch 151, loss: 1.067, 4832/6976 datapoints
2025-03-07 12:04:39,387 - INFO - validation batch 201, loss: 5.498, 6432/6976 datapoints
2025-03-07 12:04:39,428 - INFO - Epoch 794/800 done.
2025-03-07 12:04:39,428 - INFO - Final validation performance:
Loss: 3.693, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 12:04:39,429 - INFO - Beginning epoch 795/800
2025-03-07 12:04:39,443 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:04:39,926 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:04:40,358 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:04:40,799 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:04:41,247 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:04:41,708 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:04:42,186 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:04:42,674 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:04:43,198 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:04:43,656 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:04:44,114 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:04:44,559 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:04:45,032 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:04:45,512 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:04:45,998 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:04:46,490 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:04:46,964 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:04:47,554 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:04:47,869 - INFO - validation batch 1, loss: 0.840, 32/6976 datapoints
2025-03-07 12:04:47,979 - INFO - validation batch 51, loss: 9.202, 1632/6976 datapoints
2025-03-07 12:04:48,084 - INFO - validation batch 101, loss: 1.905, 3232/6976 datapoints
2025-03-07 12:04:48,190 - INFO - validation batch 151, loss: 1.051, 4832/6976 datapoints
2025-03-07 12:04:48,287 - INFO - validation batch 201, loss: 5.476, 6432/6976 datapoints
2025-03-07 12:04:48,323 - INFO - Epoch 795/800 done.
2025-03-07 12:04:48,323 - INFO - Final validation performance:
Loss: 3.695, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 12:04:48,324 - INFO - Beginning epoch 796/800
2025-03-07 12:04:48,335 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:04:48,862 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:04:49,383 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:04:49,883 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:04:50,327 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:04:50,757 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:04:51,178 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:04:51,609 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:04:52,004 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:04:52,427 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:04:52,874 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:04:53,310 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:04:53,725 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:04:54,138 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:04:54,584 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:04:54,993 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:04:55,399 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:04:55,849 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:04:56,050 - INFO - validation batch 1, loss: 0.843, 32/6976 datapoints
2025-03-07 12:04:56,121 - INFO - validation batch 51, loss: 9.252, 1632/6976 datapoints
2025-03-07 12:04:56,187 - INFO - validation batch 101, loss: 1.907, 3232/6976 datapoints
2025-03-07 12:04:56,258 - INFO - validation batch 151, loss: 1.033, 4832/6976 datapoints
2025-03-07 12:04:56,328 - INFO - validation batch 201, loss: 5.467, 6432/6976 datapoints
2025-03-07 12:04:56,353 - INFO - Epoch 796/800 done.
2025-03-07 12:04:56,354 - INFO - Final validation performance:
Loss: 3.701, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 12:04:56,354 - INFO - Beginning epoch 797/800
2025-03-07 12:04:56,364 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:04:56,772 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:04:57,257 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:04:57,717 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:04:58,121 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:04:58,512 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:04:58,905 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:04:59,302 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:04:59,677 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:05:00,051 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:05:00,512 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:05:00,939 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:05:01,335 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:05:01,736 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:05:02,145 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:05:02,567 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:05:02,978 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:05:03,377 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:05:03,570 - INFO - validation batch 1, loss: 0.840, 32/6976 datapoints
2025-03-07 12:05:03,632 - INFO - validation batch 51, loss: 9.303, 1632/6976 datapoints
2025-03-07 12:05:03,693 - INFO - validation batch 101, loss: 1.914, 3232/6976 datapoints
2025-03-07 12:05:03,755 - INFO - validation batch 151, loss: 1.027, 4832/6976 datapoints
2025-03-07 12:05:03,815 - INFO - validation batch 201, loss: 5.475, 6432/6976 datapoints
2025-03-07 12:05:03,836 - INFO - Epoch 797/800 done.
2025-03-07 12:05:03,836 - INFO - Final validation performance:
Loss: 3.712, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 12:05:03,836 - INFO - Beginning epoch 798/800
2025-03-07 12:05:03,846 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:05:04,271 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:05:04,672 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:05:05,053 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:05:05,479 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:05:05,882 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:05:06,301 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:05:06,740 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:05:07,135 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:05:07,570 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:05:07,986 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:05:08,423 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:05:08,850 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:05:09,256 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:05:09,683 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:05:10,096 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:05:10,515 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:05:10,952 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:05:11,164 - INFO - validation batch 1, loss: 0.824, 32/6976 datapoints
2025-03-07 12:05:11,237 - INFO - validation batch 51, loss: 9.356, 1632/6976 datapoints
2025-03-07 12:05:11,308 - INFO - validation batch 101, loss: 1.926, 3232/6976 datapoints
2025-03-07 12:05:11,375 - INFO - validation batch 151, loss: 1.048, 4832/6976 datapoints
2025-03-07 12:05:11,448 - INFO - validation batch 201, loss: 5.490, 6432/6976 datapoints
2025-03-07 12:05:11,475 - INFO - Epoch 798/800 done.
2025-03-07 12:05:11,475 - INFO - Final validation performance:
Loss: 3.729, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 12:05:11,476 - INFO - Beginning epoch 799/800
2025-03-07 12:05:11,487 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:05:11,947 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:05:12,368 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:05:12,813 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:05:13,249 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:05:13,706 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:05:14,150 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:05:14,574 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:05:14,976 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:05:15,361 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:05:15,782 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:05:16,174 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:05:16,587 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:05:16,970 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:05:17,373 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:05:17,820 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:05:18,249 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:05:18,672 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:05:18,864 - INFO - validation batch 1, loss: 0.791, 32/6976 datapoints
2025-03-07 12:05:18,934 - INFO - validation batch 51, loss: 9.409, 1632/6976 datapoints
2025-03-07 12:05:19,004 - INFO - validation batch 101, loss: 1.949, 3232/6976 datapoints
2025-03-07 12:05:19,071 - INFO - validation batch 151, loss: 1.091, 4832/6976 datapoints
2025-03-07 12:05:19,139 - INFO - validation batch 201, loss: 5.505, 6432/6976 datapoints
2025-03-07 12:05:19,166 - INFO - Epoch 799/800 done.
2025-03-07 12:05:19,167 - INFO - Final validation performance:
Loss: 3.749, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 12:05:19,167 - INFO - Beginning epoch 800/800
2025-03-07 12:05:19,175 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:05:19,594 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:05:20,024 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:05:20,442 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:05:20,900 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:05:21,345 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:05:21,775 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:05:22,215 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:05:22,620 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:05:23,022 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:05:23,439 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:05:23,955 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:05:24,433 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:05:24,885 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:05:25,345 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:05:26,141 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:05:26,611 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:05:27,062 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:05:27,268 - INFO - validation batch 1, loss: 0.734, 32/6976 datapoints
2025-03-07 12:05:27,345 - INFO - validation batch 51, loss: 9.468, 1632/6976 datapoints
2025-03-07 12:05:27,424 - INFO - validation batch 101, loss: 1.977, 3232/6976 datapoints
2025-03-07 12:05:27,496 - INFO - validation batch 151, loss: 1.154, 4832/6976 datapoints
2025-03-07 12:05:27,599 - INFO - validation batch 201, loss: 5.534, 6432/6976 datapoints
2025-03-07 12:05:27,628 - INFO - Epoch 800/800 done.
2025-03-07 12:05:27,628 - INFO - Final validation performance:
Loss: 3.773, top-1 acc: 0.883top-5 acc: 0.883
2025-03-07 12:05:27,629 - INFO - Finished training in 8169.95 seconds.
2025-03-07 12:05:27,632 - INFO - Model trained in 8169.95 s
2025-03-07 12:05:27,632 - INFO - Evaluating model...
2025-03-07 12:05:27,637 - INFO - validation batch 1, loss: 0.734, 32/6976 datapoints
2025-03-07 12:05:27,713 - INFO - validation batch 51, loss: 9.468, 1632/6976 datapoints
2025-03-07 12:05:27,787 - INFO - validation batch 101, loss: 1.977, 3232/6976 datapoints
2025-03-07 12:05:27,872 - INFO - validation batch 151, loss: 1.154, 4832/6976 datapoints
2025-03-07 12:05:27,960 - INFO - validation batch 201, loss: 5.534, 6432/6976 datapoints
2025-03-07 12:05:27,986 - INFO - Done evaluating.
2025-03-07 12:05:27,986 - INFO - Average final validation loss: 3.773
2025-03-07 12:05:27,986 - INFO - Saving...
2025-03-07 12:06:07,679 - INFO - Done saving.
2025-03-07 12:06:07,685 - INFO - Successfully completed hyperparameter combination 1 of 1