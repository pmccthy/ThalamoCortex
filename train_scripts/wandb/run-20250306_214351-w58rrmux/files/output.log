2025-03-06 21:43:57,007 - INFO - Running hyperparameter combination 3 of 4
2025-03-06 21:43:57,008 - INFO - 2_CTCNet_TC_multi_pre_activation_reciprocal
2025-03-06 21:43:57,009 - INFO - Loading data...
2025-03-06 21:43:58,314 - INFO - Done loading.
2025-03-06 21:43:58,314 - INFO - Building model and optimiser...
2025-03-06 21:43:58,318 - INFO - =================================================================
Layer (type:depth-idx)                   Param #
=================================================================
├─Sequential: 1-1                        --
|    └─Linear: 2-1                       4,112
|    └─ReLU: 2-2                         --
├─Linear: 1-2                            2,176
├─Linear: 1-3                            2,176
├─CortexWithThalamicMultiPreAct: 1-4     --
|    └─Linear: 2-3                       200,832
|    └─ReLU: 2-4                         --
├─CortexWithThalamicMultiPreAct: 1-5     --
|    └─Linear: 2-5                       16,512
|    └─ReLU: 2-6                         --
├─Sequential: 1-6                        --
|    └─Linear: 2-7                       1,290
=================================================================
Total params: 227,098
Trainable params: 227,098
Non-trainable params: 0
=================================================================
2025-03-06 21:43:58,319 - INFO - Done.
2025-03-06 21:43:58,319 - INFO - Training...
2025-03-06 21:43:58,319 - INFO - Beginning epoch 1/800
2025-03-06 21:43:58,327 - INFO - training batch 1, loss: 2.304, 32/28000 datapoints
2025-03-06 21:43:58,495 - INFO - training batch 51, loss: 2.298, 1632/28000 datapoints
2025-03-06 21:43:58,669 - INFO - training batch 101, loss: 2.311, 3232/28000 datapoints
2025-03-06 21:43:58,819 - INFO - training batch 151, loss: 2.310, 4832/28000 datapoints
2025-03-06 21:43:58,978 - INFO - training batch 201, loss: 2.297, 6432/28000 datapoints
2025-03-06 21:43:59,282 - INFO - training batch 251, loss: 2.303, 8032/28000 datapoints
2025-03-06 21:43:59,430 - INFO - training batch 301, loss: 2.295, 9632/28000 datapoints
2025-03-06 21:43:59,580 - INFO - training batch 351, loss: 2.320, 11232/28000 datapoints
2025-03-06 21:43:59,729 - INFO - training batch 401, loss: 2.302, 12832/28000 datapoints
2025-03-06 21:43:59,879 - INFO - training batch 451, loss: 2.303, 14432/28000 datapoints
2025-03-06 21:44:00,030 - INFO - training batch 501, loss: 2.308, 16032/28000 datapoints
2025-03-06 21:44:00,178 - INFO - training batch 551, loss: 2.308, 17632/28000 datapoints
2025-03-06 21:44:00,327 - INFO - training batch 601, loss: 2.288, 19232/28000 datapoints
2025-03-06 21:44:00,472 - INFO - training batch 651, loss: 2.308, 20832/28000 datapoints
2025-03-06 21:44:00,621 - INFO - training batch 701, loss: 2.308, 22432/28000 datapoints
2025-03-06 21:44:00,771 - INFO - training batch 751, loss: 2.305, 24032/28000 datapoints
2025-03-06 21:44:00,927 - INFO - training batch 801, loss: 2.294, 25632/28000 datapoints
2025-03-06 21:44:01,080 - INFO - training batch 851, loss: 2.307, 27232/28000 datapoints
2025-03-06 21:44:01,156 - INFO - validation batch 1, loss: 2.291, 32/6976 datapoints
2025-03-06 21:44:01,211 - INFO - validation batch 51, loss: 2.306, 1632/6976 datapoints
2025-03-06 21:44:01,269 - INFO - validation batch 101, loss: 2.309, 3232/6976 datapoints
2025-03-06 21:44:01,324 - INFO - validation batch 151, loss: 2.309, 4832/6976 datapoints
2025-03-06 21:44:01,376 - INFO - validation batch 201, loss: 2.297, 6432/6976 datapoints
2025-03-06 21:44:01,393 - INFO - Epoch 1/800 done.
2025-03-06 21:44:01,394 - INFO - Final validation performance:
Loss: 2.303, top-1 acc: 0.101top-5 acc: 0.101
2025-03-06 21:44:01,394 - INFO - Beginning epoch 2/800
2025-03-06 21:44:01,398 - INFO - training batch 1, loss: 2.304, 32/28000 datapoints
2025-03-06 21:44:01,557 - INFO - training batch 51, loss: 2.297, 1632/28000 datapoints
2025-03-06 21:44:01,708 - INFO - training batch 101, loss: 2.310, 3232/28000 datapoints
2025-03-06 21:44:01,863 - INFO - training batch 151, loss: 2.309, 4832/28000 datapoints
2025-03-06 21:44:02,012 - INFO - training batch 201, loss: 2.295, 6432/28000 datapoints
2025-03-06 21:44:02,164 - INFO - training batch 251, loss: 2.302, 8032/28000 datapoints
2025-03-06 21:44:02,312 - INFO - training batch 301, loss: 2.294, 9632/28000 datapoints
2025-03-06 21:44:02,459 - INFO - training batch 351, loss: 2.319, 11232/28000 datapoints
2025-03-06 21:44:02,615 - INFO - training batch 401, loss: 2.301, 12832/28000 datapoints
2025-03-06 21:44:02,790 - INFO - training batch 451, loss: 2.302, 14432/28000 datapoints
2025-03-06 21:44:02,944 - INFO - training batch 501, loss: 2.306, 16032/28000 datapoints
2025-03-06 21:44:03,099 - INFO - training batch 551, loss: 2.306, 17632/28000 datapoints
2025-03-06 21:44:03,251 - INFO - training batch 601, loss: 2.287, 19232/28000 datapoints
2025-03-06 21:44:03,401 - INFO - training batch 651, loss: 2.306, 20832/28000 datapoints
2025-03-06 21:44:03,548 - INFO - training batch 701, loss: 2.305, 22432/28000 datapoints
2025-03-06 21:44:03,700 - INFO - training batch 751, loss: 2.303, 24032/28000 datapoints
2025-03-06 21:44:03,856 - INFO - training batch 801, loss: 2.292, 25632/28000 datapoints
2025-03-06 21:44:04,007 - INFO - training batch 851, loss: 2.304, 27232/28000 datapoints
2025-03-06 21:44:04,085 - INFO - validation batch 1, loss: 2.290, 32/6976 datapoints
2025-03-06 21:44:04,137 - INFO - validation batch 51, loss: 2.304, 1632/6976 datapoints
2025-03-06 21:44:04,191 - INFO - validation batch 101, loss: 2.307, 3232/6976 datapoints
2025-03-06 21:44:04,245 - INFO - validation batch 151, loss: 2.308, 4832/6976 datapoints
2025-03-06 21:44:04,298 - INFO - validation batch 201, loss: 2.294, 6432/6976 datapoints
2025-03-06 21:44:04,317 - INFO - Epoch 2/800 done.
2025-03-06 21:44:04,317 - INFO - Final validation performance:
Loss: 2.301, top-1 acc: 0.101top-5 acc: 0.101
2025-03-06 21:44:04,317 - INFO - Beginning epoch 3/800
2025-03-06 21:44:04,322 - INFO - training batch 1, loss: 2.303, 32/28000 datapoints
2025-03-06 21:44:04,479 - INFO - training batch 51, loss: 2.295, 1632/28000 datapoints
2025-03-06 21:44:04,630 - INFO - training batch 101, loss: 2.306, 3232/28000 datapoints
2025-03-06 21:44:04,780 - INFO - training batch 151, loss: 2.307, 4832/28000 datapoints
2025-03-06 21:44:04,938 - INFO - training batch 201, loss: 2.293, 6432/28000 datapoints
2025-03-06 21:44:05,100 - INFO - training batch 251, loss: 2.300, 8032/28000 datapoints
2025-03-06 21:44:05,252 - INFO - training batch 301, loss: 2.293, 9632/28000 datapoints
2025-03-06 21:44:05,403 - INFO - training batch 351, loss: 2.315, 11232/28000 datapoints
2025-03-06 21:44:05,552 - INFO - training batch 401, loss: 2.297, 12832/28000 datapoints
2025-03-06 21:44:05,705 - INFO - training batch 451, loss: 2.299, 14432/28000 datapoints
2025-03-06 21:44:05,859 - INFO - training batch 501, loss: 2.301, 16032/28000 datapoints
2025-03-06 21:44:06,012 - INFO - training batch 551, loss: 2.302, 17632/28000 datapoints
2025-03-06 21:44:06,165 - INFO - training batch 601, loss: 2.284, 19232/28000 datapoints
2025-03-06 21:44:06,317 - INFO - training batch 651, loss: 2.301, 20832/28000 datapoints
2025-03-06 21:44:06,466 - INFO - training batch 701, loss: 2.299, 22432/28000 datapoints
2025-03-06 21:44:06,618 - INFO - training batch 751, loss: 2.297, 24032/28000 datapoints
2025-03-06 21:44:06,768 - INFO - training batch 801, loss: 2.288, 25632/28000 datapoints
2025-03-06 21:44:06,921 - INFO - training batch 851, loss: 2.296, 27232/28000 datapoints
2025-03-06 21:44:06,997 - INFO - validation batch 1, loss: 2.284, 32/6976 datapoints
2025-03-06 21:44:07,054 - INFO - validation batch 51, loss: 2.298, 1632/6976 datapoints
2025-03-06 21:44:07,110 - INFO - validation batch 101, loss: 2.300, 3232/6976 datapoints
2025-03-06 21:44:07,163 - INFO - validation batch 151, loss: 2.304, 4832/6976 datapoints
2025-03-06 21:44:07,219 - INFO - validation batch 201, loss: 2.287, 6432/6976 datapoints
2025-03-06 21:44:07,240 - INFO - Epoch 3/800 done.
2025-03-06 21:44:07,240 - INFO - Final validation performance:
Loss: 2.295, top-1 acc: 0.102top-5 acc: 0.102
2025-03-06 21:44:07,240 - INFO - Beginning epoch 4/800
2025-03-06 21:44:07,244 - INFO - training batch 1, loss: 2.300, 32/28000 datapoints
2025-03-06 21:44:07,401 - INFO - training batch 51, loss: 2.290, 1632/28000 datapoints
2025-03-06 21:44:07,548 - INFO - training batch 101, loss: 2.298, 3232/28000 datapoints
2025-03-06 21:44:07,709 - INFO - training batch 151, loss: 2.301, 4832/28000 datapoints
2025-03-06 21:44:07,869 - INFO - training batch 201, loss: 2.281, 6432/28000 datapoints
2025-03-06 21:44:08,017 - INFO - training batch 251, loss: 2.295, 8032/28000 datapoints
2025-03-06 21:44:08,169 - INFO - training batch 301, loss: 2.283, 9632/28000 datapoints
2025-03-06 21:44:08,322 - INFO - training batch 351, loss: 2.297, 11232/28000 datapoints
2025-03-06 21:44:08,473 - INFO - training batch 401, loss: 2.280, 12832/28000 datapoints
2025-03-06 21:44:08,623 - INFO - training batch 451, loss: 2.287, 14432/28000 datapoints
2025-03-06 21:44:08,775 - INFO - training batch 501, loss: 2.269, 16032/28000 datapoints
2025-03-06 21:44:08,930 - INFO - training batch 551, loss: 2.280, 17632/28000 datapoints
2025-03-06 21:44:09,089 - INFO - training batch 601, loss: 2.259, 19232/28000 datapoints
2025-03-06 21:44:09,245 - INFO - training batch 651, loss: 2.270, 20832/28000 datapoints
2025-03-06 21:44:09,396 - INFO - training batch 701, loss: 2.251, 22432/28000 datapoints
2025-03-06 21:44:09,544 - INFO - training batch 751, loss: 2.252, 24032/28000 datapoints
2025-03-06 21:44:09,708 - INFO - training batch 801, loss: 2.254, 25632/28000 datapoints
2025-03-06 21:44:09,863 - INFO - training batch 851, loss: 2.226, 27232/28000 datapoints
2025-03-06 21:44:09,938 - INFO - validation batch 1, loss: 2.229, 32/6976 datapoints
2025-03-06 21:44:09,991 - INFO - validation batch 51, loss: 2.255, 1632/6976 datapoints
2025-03-06 21:44:10,045 - INFO - validation batch 101, loss: 2.249, 3232/6976 datapoints
2025-03-06 21:44:10,100 - INFO - validation batch 151, loss: 2.292, 4832/6976 datapoints
2025-03-06 21:44:10,155 - INFO - validation batch 201, loss: 2.234, 6432/6976 datapoints
2025-03-06 21:44:10,176 - INFO - Epoch 4/800 done.
2025-03-06 21:44:10,176 - INFO - Final validation performance:
Loss: 2.252, top-1 acc: 0.237top-5 acc: 0.237
2025-03-06 21:44:10,177 - INFO - Beginning epoch 5/800
2025-03-06 21:44:10,182 - INFO - training batch 1, loss: 2.289, 32/28000 datapoints
2025-03-06 21:44:10,343 - INFO - training batch 51, loss: 2.281, 1632/28000 datapoints
2025-03-06 21:44:10,492 - INFO - training batch 101, loss: 2.249, 3232/28000 datapoints
2025-03-06 21:44:10,648 - INFO - training batch 151, loss: 2.257, 4832/28000 datapoints
2025-03-06 21:44:10,840 - INFO - training batch 201, loss: 2.168, 6432/28000 datapoints
2025-03-06 21:44:10,992 - INFO - training batch 251, loss: 2.281, 8032/28000 datapoints
2025-03-06 21:44:11,144 - INFO - training batch 301, loss: 2.204, 9632/28000 datapoints
2025-03-06 21:44:11,298 - INFO - training batch 351, loss: 2.190, 11232/28000 datapoints
2025-03-06 21:44:11,447 - INFO - training batch 401, loss: 2.157, 12832/28000 datapoints
2025-03-06 21:44:11,599 - INFO - training batch 451, loss: 2.221, 14432/28000 datapoints
2025-03-06 21:44:11,750 - INFO - training batch 501, loss: 2.089, 16032/28000 datapoints
2025-03-06 21:44:11,902 - INFO - training batch 551, loss: 2.147, 17632/28000 datapoints
2025-03-06 21:44:12,052 - INFO - training batch 601, loss: 2.128, 19232/28000 datapoints
2025-03-06 21:44:12,205 - INFO - training batch 651, loss: 2.133, 20832/28000 datapoints
2025-03-06 21:44:12,359 - INFO - training batch 701, loss: 2.052, 22432/28000 datapoints
2025-03-06 21:44:12,509 - INFO - training batch 751, loss: 2.086, 24032/28000 datapoints
2025-03-06 21:44:12,662 - INFO - training batch 801, loss: 2.113, 25632/28000 datapoints
2025-03-06 21:44:12,836 - INFO - training batch 851, loss: 2.011, 27232/28000 datapoints
2025-03-06 21:44:12,910 - INFO - validation batch 1, loss: 2.052, 32/6976 datapoints
2025-03-06 21:44:12,958 - INFO - validation batch 51, loss: 2.173, 1632/6976 datapoints
2025-03-06 21:44:13,009 - INFO - validation batch 101, loss: 2.089, 3232/6976 datapoints
2025-03-06 21:44:13,058 - INFO - validation batch 151, loss: 2.246, 4832/6976 datapoints
2025-03-06 21:44:13,111 - INFO - validation batch 201, loss: 2.012, 6432/6976 datapoints
2025-03-06 21:44:13,127 - INFO - Epoch 5/800 done.
2025-03-06 21:44:13,127 - INFO - Final validation performance:
Loss: 2.114, top-1 acc: 0.341top-5 acc: 0.341
2025-03-06 21:44:13,128 - INFO - Beginning epoch 6/800
2025-03-06 21:44:13,132 - INFO - training batch 1, loss: 2.213, 32/28000 datapoints
2025-03-06 21:44:13,294 - INFO - training batch 51, loss: 2.166, 1632/28000 datapoints
2025-03-06 21:44:13,447 - INFO - training batch 101, loss: 2.044, 3232/28000 datapoints
2025-03-06 21:44:13,600 - INFO - training batch 151, loss: 2.143, 4832/28000 datapoints
2025-03-06 21:44:13,755 - INFO - training batch 201, loss: 2.006, 6432/28000 datapoints
2025-03-06 21:44:13,910 - INFO - training batch 251, loss: 2.145, 8032/28000 datapoints
2025-03-06 21:44:14,061 - INFO - training batch 301, loss: 2.095, 9632/28000 datapoints
2025-03-06 21:44:14,213 - INFO - training batch 351, loss: 2.056, 11232/28000 datapoints
2025-03-06 21:44:14,364 - INFO - training batch 401, loss: 1.941, 12832/28000 datapoints
2025-03-06 21:44:14,516 - INFO - training batch 451, loss: 2.055, 14432/28000 datapoints
2025-03-06 21:44:14,668 - INFO - training batch 501, loss: 1.797, 16032/28000 datapoints
2025-03-06 21:44:14,821 - INFO - training batch 551, loss: 1.920, 17632/28000 datapoints
2025-03-06 21:44:14,984 - INFO - training batch 601, loss: 1.903, 19232/28000 datapoints
2025-03-06 21:44:15,152 - INFO - training batch 651, loss: 1.871, 20832/28000 datapoints
2025-03-06 21:44:15,306 - INFO - training batch 701, loss: 1.750, 22432/28000 datapoints
2025-03-06 21:44:15,456 - INFO - training batch 751, loss: 1.864, 24032/28000 datapoints
2025-03-06 21:44:15,606 - INFO - training batch 801, loss: 1.864, 25632/28000 datapoints
2025-03-06 21:44:15,758 - INFO - training batch 851, loss: 1.778, 27232/28000 datapoints
2025-03-06 21:44:15,835 - INFO - validation batch 1, loss: 1.771, 32/6976 datapoints
2025-03-06 21:44:15,891 - INFO - validation batch 51, loss: 2.099, 1632/6976 datapoints
2025-03-06 21:44:15,940 - INFO - validation batch 101, loss: 1.881, 3232/6976 datapoints
2025-03-06 21:44:15,993 - INFO - validation batch 151, loss: 2.141, 4832/6976 datapoints
2025-03-06 21:44:16,041 - INFO - validation batch 201, loss: 1.674, 6432/6976 datapoints
2025-03-06 21:44:16,058 - INFO - Epoch 6/800 done.
2025-03-06 21:44:16,058 - INFO - Final validation performance:
Loss: 1.913, top-1 acc: 0.389top-5 acc: 0.389
2025-03-06 21:44:16,059 - INFO - Beginning epoch 7/800
2025-03-06 21:44:16,063 - INFO - training batch 1, loss: 2.103, 32/28000 datapoints
2025-03-06 21:44:16,217 - INFO - training batch 51, loss: 1.957, 1632/28000 datapoints
2025-03-06 21:44:16,369 - INFO - training batch 101, loss: 1.805, 3232/28000 datapoints
2025-03-06 21:44:16,523 - INFO - training batch 151, loss: 2.003, 4832/28000 datapoints
2025-03-06 21:44:16,709 - INFO - training batch 201, loss: 1.876, 6432/28000 datapoints
2025-03-06 21:44:16,866 - INFO - training batch 251, loss: 1.980, 8032/28000 datapoints
2025-03-06 21:44:17,017 - INFO - training batch 301, loss: 1.989, 9632/28000 datapoints
2025-03-06 21:44:17,171 - INFO - training batch 351, loss: 1.963, 11232/28000 datapoints
2025-03-06 21:44:17,323 - INFO - training batch 401, loss: 1.768, 12832/28000 datapoints
2025-03-06 21:44:17,475 - INFO - training batch 451, loss: 1.869, 14432/28000 datapoints
2025-03-06 21:44:17,628 - INFO - training batch 501, loss: 1.541, 16032/28000 datapoints
2025-03-06 21:44:17,780 - INFO - training batch 551, loss: 1.769, 17632/28000 datapoints
2025-03-06 21:44:17,933 - INFO - training batch 601, loss: 1.733, 19232/28000 datapoints
2025-03-06 21:44:18,087 - INFO - training batch 651, loss: 1.619, 20832/28000 datapoints
2025-03-06 21:44:18,238 - INFO - training batch 701, loss: 1.540, 22432/28000 datapoints
2025-03-06 21:44:18,392 - INFO - training batch 751, loss: 1.748, 24032/28000 datapoints
2025-03-06 21:44:18,543 - INFO - training batch 801, loss: 1.680, 25632/28000 datapoints
2025-03-06 21:44:18,722 - INFO - training batch 851, loss: 1.656, 27232/28000 datapoints
2025-03-06 21:44:18,810 - INFO - validation batch 1, loss: 1.551, 32/6976 datapoints
2025-03-06 21:44:18,877 - INFO - validation batch 51, loss: 2.057, 1632/6976 datapoints
2025-03-06 21:44:18,942 - INFO - validation batch 101, loss: 1.762, 3232/6976 datapoints
2025-03-06 21:44:19,019 - INFO - validation batch 151, loss: 2.090, 4832/6976 datapoints
2025-03-06 21:44:19,071 - INFO - validation batch 201, loss: 1.466, 6432/6976 datapoints
2025-03-06 21:44:19,090 - INFO - Epoch 7/800 done.
2025-03-06 21:44:19,091 - INFO - Final validation performance:
Loss: 1.785, top-1 acc: 0.412top-5 acc: 0.412
2025-03-06 21:44:19,091 - INFO - Beginning epoch 8/800
2025-03-06 21:44:19,095 - INFO - training batch 1, loss: 2.072, 32/28000 datapoints
2025-03-06 21:44:19,252 - INFO - training batch 51, loss: 1.861, 1632/28000 datapoints
2025-03-06 21:44:19,400 - INFO - training batch 101, loss: 1.665, 3232/28000 datapoints
2025-03-06 21:44:19,550 - INFO - training batch 151, loss: 1.924, 4832/28000 datapoints
2025-03-06 21:44:19,702 - INFO - training batch 201, loss: 1.830, 6432/28000 datapoints
2025-03-06 21:44:19,857 - INFO - training batch 251, loss: 1.888, 8032/28000 datapoints
2025-03-06 21:44:20,007 - INFO - training batch 301, loss: 1.931, 9632/28000 datapoints
2025-03-06 21:44:20,157 - INFO - training batch 351, loss: 1.917, 11232/28000 datapoints
2025-03-06 21:44:20,309 - INFO - training batch 401, loss: 1.692, 12832/28000 datapoints
2025-03-06 21:44:20,458 - INFO - training batch 451, loss: 1.759, 14432/28000 datapoints
2025-03-06 21:44:20,609 - INFO - training batch 501, loss: 1.410, 16032/28000 datapoints
2025-03-06 21:44:20,765 - INFO - training batch 551, loss: 1.708, 17632/28000 datapoints
2025-03-06 21:44:20,920 - INFO - training batch 601, loss: 1.676, 19232/28000 datapoints
2025-03-06 21:44:21,097 - INFO - training batch 651, loss: 1.482, 20832/28000 datapoints
2025-03-06 21:44:21,247 - INFO - training batch 701, loss: 1.432, 22432/28000 datapoints
2025-03-06 21:44:21,400 - INFO - training batch 751, loss: 1.715, 24032/28000 datapoints
2025-03-06 21:44:21,551 - INFO - training batch 801, loss: 1.589, 25632/28000 datapoints
2025-03-06 21:44:21,701 - INFO - training batch 851, loss: 1.601, 27232/28000 datapoints
2025-03-06 21:44:21,777 - INFO - validation batch 1, loss: 1.432, 32/6976 datapoints
2025-03-06 21:44:21,826 - INFO - validation batch 51, loss: 2.020, 1632/6976 datapoints
2025-03-06 21:44:21,878 - INFO - validation batch 101, loss: 1.700, 3232/6976 datapoints
2025-03-06 21:44:21,927 - INFO - validation batch 151, loss: 2.077, 4832/6976 datapoints
2025-03-06 21:44:21,977 - INFO - validation batch 201, loss: 1.356, 6432/6976 datapoints
2025-03-06 21:44:21,994 - INFO - Epoch 8/800 done.
2025-03-06 21:44:21,994 - INFO - Final validation performance:
Loss: 1.717, top-1 acc: 0.424top-5 acc: 0.424
2025-03-06 21:44:21,995 - INFO - Beginning epoch 9/800
2025-03-06 21:44:21,999 - INFO - training batch 1, loss: 2.065, 32/28000 datapoints
2025-03-06 21:44:22,150 - INFO - training batch 51, loss: 1.838, 1632/28000 datapoints
2025-03-06 21:44:22,302 - INFO - training batch 101, loss: 1.577, 3232/28000 datapoints
2025-03-06 21:44:22,457 - INFO - training batch 151, loss: 1.888, 4832/28000 datapoints
2025-03-06 21:44:22,607 - INFO - training batch 201, loss: 1.803, 6432/28000 datapoints
2025-03-06 21:44:22,762 - INFO - training batch 251, loss: 1.824, 8032/28000 datapoints
2025-03-06 21:44:22,942 - INFO - training batch 301, loss: 1.885, 9632/28000 datapoints
2025-03-06 21:44:23,097 - INFO - training batch 351, loss: 1.875, 11232/28000 datapoints
2025-03-06 21:44:23,246 - INFO - training batch 401, loss: 1.654, 12832/28000 datapoints
2025-03-06 21:44:23,403 - INFO - training batch 451, loss: 1.688, 14432/28000 datapoints
2025-03-06 21:44:23,556 - INFO - training batch 501, loss: 1.340, 16032/28000 datapoints
2025-03-06 21:44:23,713 - INFO - training batch 551, loss: 1.675, 17632/28000 datapoints
2025-03-06 21:44:23,873 - INFO - training batch 601, loss: 1.651, 19232/28000 datapoints
2025-03-06 21:44:24,032 - INFO - training batch 651, loss: 1.398, 20832/28000 datapoints
2025-03-06 21:44:24,185 - INFO - training batch 701, loss: 1.367, 22432/28000 datapoints
2025-03-06 21:44:24,336 - INFO - training batch 751, loss: 1.702, 24032/28000 datapoints
2025-03-06 21:44:24,488 - INFO - training batch 801, loss: 1.536, 25632/28000 datapoints
2025-03-06 21:44:24,641 - INFO - training batch 851, loss: 1.567, 27232/28000 datapoints
2025-03-06 21:44:24,724 - INFO - validation batch 1, loss: 1.356, 32/6976 datapoints
2025-03-06 21:44:24,776 - INFO - validation batch 51, loss: 1.982, 1632/6976 datapoints
2025-03-06 21:44:24,836 - INFO - validation batch 101, loss: 1.658, 3232/6976 datapoints
2025-03-06 21:44:24,891 - INFO - validation batch 151, loss: 2.062, 4832/6976 datapoints
2025-03-06 21:44:24,944 - INFO - validation batch 201, loss: 1.286, 6432/6976 datapoints
2025-03-06 21:44:24,963 - INFO - Epoch 9/800 done.
2025-03-06 21:44:24,964 - INFO - Final validation performance:
Loss: 1.669, top-1 acc: 0.436top-5 acc: 0.436
2025-03-06 21:44:24,964 - INFO - Beginning epoch 10/800
2025-03-06 21:44:24,969 - INFO - training batch 1, loss: 2.047, 32/28000 datapoints
2025-03-06 21:44:25,136 - INFO - training batch 51, loss: 1.830, 1632/28000 datapoints
2025-03-06 21:44:25,293 - INFO - training batch 101, loss: 1.517, 3232/28000 datapoints
2025-03-06 21:44:25,452 - INFO - training batch 151, loss: 1.862, 4832/28000 datapoints
2025-03-06 21:44:25,605 - INFO - training batch 201, loss: 1.782, 6432/28000 datapoints
2025-03-06 21:44:25,767 - INFO - training batch 251, loss: 1.770, 8032/28000 datapoints
2025-03-06 21:44:25,956 - INFO - training batch 301, loss: 1.842, 9632/28000 datapoints
2025-03-06 21:44:26,163 - INFO - training batch 351, loss: 1.833, 11232/28000 datapoints
2025-03-06 21:44:26,383 - INFO - training batch 401, loss: 1.630, 12832/28000 datapoints
2025-03-06 21:44:26,558 - INFO - training batch 451, loss: 1.639, 14432/28000 datapoints
2025-03-06 21:44:26,734 - INFO - training batch 501, loss: 1.297, 16032/28000 datapoints
2025-03-06 21:44:26,919 - INFO - training batch 551, loss: 1.649, 17632/28000 datapoints
2025-03-06 21:44:27,112 - INFO - training batch 601, loss: 1.634, 19232/28000 datapoints
2025-03-06 21:44:27,323 - INFO - training batch 651, loss: 1.337, 20832/28000 datapoints
2025-03-06 21:44:27,540 - INFO - training batch 701, loss: 1.323, 22432/28000 datapoints
2025-03-06 21:44:27,757 - INFO - training batch 751, loss: 1.694, 24032/28000 datapoints
2025-03-06 21:44:27,982 - INFO - training batch 801, loss: 1.498, 25632/28000 datapoints
2025-03-06 21:44:28,215 - INFO - training batch 851, loss: 1.541, 27232/28000 datapoints
2025-03-06 21:44:28,335 - INFO - validation batch 1, loss: 1.302, 32/6976 datapoints
2025-03-06 21:44:28,417 - INFO - validation batch 51, loss: 1.946, 1632/6976 datapoints
2025-03-06 21:44:28,505 - INFO - validation batch 101, loss: 1.627, 3232/6976 datapoints
2025-03-06 21:44:28,585 - INFO - validation batch 151, loss: 2.043, 4832/6976 datapoints
2025-03-06 21:44:28,668 - INFO - validation batch 201, loss: 1.237, 6432/6976 datapoints
2025-03-06 21:44:28,697 - INFO - Epoch 10/800 done.
2025-03-06 21:44:28,697 - INFO - Final validation performance:
Loss: 1.631, top-1 acc: 0.442top-5 acc: 0.442
2025-03-06 21:44:28,698 - INFO - Beginning epoch 11/800
2025-03-06 21:44:28,704 - INFO - training batch 1, loss: 2.022, 32/28000 datapoints
2025-03-06 21:44:28,955 - INFO - training batch 51, loss: 1.822, 1632/28000 datapoints
2025-03-06 21:44:29,211 - INFO - training batch 101, loss: 1.471, 3232/28000 datapoints
2025-03-06 21:44:29,459 - INFO - training batch 151, loss: 1.839, 4832/28000 datapoints
2025-03-06 21:44:29,756 - INFO - training batch 201, loss: 1.762, 6432/28000 datapoints
2025-03-06 21:44:30,036 - INFO - training batch 251, loss: 1.722, 8032/28000 datapoints
2025-03-06 21:44:30,311 - INFO - training batch 301, loss: 1.804, 9632/28000 datapoints
2025-03-06 21:44:30,573 - INFO - training batch 351, loss: 1.794, 11232/28000 datapoints
2025-03-06 21:44:30,847 - INFO - training batch 401, loss: 1.611, 12832/28000 datapoints
2025-03-06 21:44:31,129 - INFO - training batch 451, loss: 1.602, 14432/28000 datapoints
2025-03-06 21:44:31,429 - INFO - training batch 501, loss: 1.270, 16032/28000 datapoints
2025-03-06 21:44:31,710 - INFO - training batch 551, loss: 1.626, 17632/28000 datapoints
2025-03-06 21:44:32,005 - INFO - training batch 601, loss: 1.619, 19232/28000 datapoints
2025-03-06 21:44:32,315 - INFO - training batch 651, loss: 1.290, 20832/28000 datapoints
2025-03-06 21:44:32,625 - INFO - training batch 701, loss: 1.289, 22432/28000 datapoints
2025-03-06 21:44:32,958 - INFO - training batch 751, loss: 1.690, 24032/28000 datapoints
2025-03-06 21:44:33,319 - INFO - training batch 801, loss: 1.467, 25632/28000 datapoints
2025-03-06 21:44:33,644 - INFO - training batch 851, loss: 1.520, 27232/28000 datapoints
2025-03-06 21:44:33,808 - INFO - validation batch 1, loss: 1.260, 32/6976 datapoints
2025-03-06 21:44:33,934 - INFO - validation batch 51, loss: 1.914, 1632/6976 datapoints
2025-03-06 21:44:34,062 - INFO - validation batch 101, loss: 1.601, 3232/6976 datapoints
2025-03-06 21:44:34,187 - INFO - validation batch 151, loss: 2.020, 4832/6976 datapoints
2025-03-06 21:44:34,317 - INFO - validation batch 201, loss: 1.197, 6432/6976 datapoints
2025-03-06 21:44:34,360 - INFO - Epoch 11/800 done.
2025-03-06 21:44:34,361 - INFO - Final validation performance:
Loss: 1.598, top-1 acc: 0.451top-5 acc: 0.451
2025-03-06 21:44:34,362 - INFO - Beginning epoch 12/800
2025-03-06 21:44:34,383 - INFO - training batch 1, loss: 1.994, 32/28000 datapoints
2025-03-06 21:44:34,735 - INFO - training batch 51, loss: 1.811, 1632/28000 datapoints
2025-03-06 21:44:35,133 - INFO - training batch 101, loss: 1.433, 3232/28000 datapoints
2025-03-06 21:44:35,515 - INFO - training batch 151, loss: 1.819, 4832/28000 datapoints
2025-03-06 21:44:35,886 - INFO - training batch 201, loss: 1.744, 6432/28000 datapoints
2025-03-06 21:44:36,258 - INFO - training batch 251, loss: 1.677, 8032/28000 datapoints
2025-03-06 21:44:36,624 - INFO - training batch 301, loss: 1.768, 9632/28000 datapoints
2025-03-06 21:44:36,997 - INFO - training batch 351, loss: 1.758, 11232/28000 datapoints
2025-03-06 21:44:37,363 - INFO - training batch 401, loss: 1.593, 12832/28000 datapoints
2025-03-06 21:44:37,741 - INFO - training batch 451, loss: 1.572, 14432/28000 datapoints
2025-03-06 21:44:38,177 - INFO - training batch 501, loss: 1.252, 16032/28000 datapoints
2025-03-06 21:44:38,543 - INFO - training batch 551, loss: 1.605, 17632/28000 datapoints
2025-03-06 21:44:38,925 - INFO - training batch 601, loss: 1.606, 19232/28000 datapoints
2025-03-06 21:44:39,324 - INFO - training batch 651, loss: 1.251, 20832/28000 datapoints
2025-03-06 21:44:39,709 - INFO - training batch 701, loss: 1.261, 22432/28000 datapoints
2025-03-06 21:44:40,095 - INFO - training batch 751, loss: 1.685, 24032/28000 datapoints
2025-03-06 21:44:40,472 - INFO - training batch 801, loss: 1.439, 25632/28000 datapoints
2025-03-06 21:44:40,847 - INFO - training batch 851, loss: 1.503, 27232/28000 datapoints
2025-03-06 21:44:41,062 - INFO - validation batch 1, loss: 1.224, 32/6976 datapoints
2025-03-06 21:44:41,264 - INFO - validation batch 51, loss: 1.886, 1632/6976 datapoints
2025-03-06 21:44:41,457 - INFO - validation batch 101, loss: 1.578, 3232/6976 datapoints
2025-03-06 21:44:41,588 - INFO - validation batch 151, loss: 1.995, 4832/6976 datapoints
2025-03-06 21:44:41,722 - INFO - validation batch 201, loss: 1.163, 6432/6976 datapoints
2025-03-06 21:44:41,766 - INFO - Epoch 12/800 done.
2025-03-06 21:44:41,766 - INFO - Final validation performance:
Loss: 1.569, top-1 acc: 0.457top-5 acc: 0.457
2025-03-06 21:44:41,767 - INFO - Beginning epoch 13/800
2025-03-06 21:44:41,779 - INFO - training batch 1, loss: 1.964, 32/28000 datapoints
2025-03-06 21:44:42,184 - INFO - training batch 51, loss: 1.798, 1632/28000 datapoints
2025-03-06 21:44:42,552 - INFO - training batch 101, loss: 1.399, 3232/28000 datapoints
2025-03-06 21:44:42,906 - INFO - training batch 151, loss: 1.801, 4832/28000 datapoints
2025-03-06 21:44:43,306 - INFO - training batch 201, loss: 1.727, 6432/28000 datapoints
2025-03-06 21:44:43,652 - INFO - training batch 251, loss: 1.636, 8032/28000 datapoints
2025-03-06 21:44:43,994 - INFO - training batch 301, loss: 1.737, 9632/28000 datapoints
2025-03-06 21:44:44,328 - INFO - training batch 351, loss: 1.725, 11232/28000 datapoints
2025-03-06 21:44:44,640 - INFO - training batch 401, loss: 1.578, 12832/28000 datapoints
2025-03-06 21:44:44,946 - INFO - training batch 451, loss: 1.547, 14432/28000 datapoints
2025-03-06 21:44:45,276 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:44:45,578 - INFO - training batch 551, loss: 1.586, 17632/28000 datapoints
2025-03-06 21:44:45,876 - INFO - training batch 601, loss: 1.594, 19232/28000 datapoints
2025-03-06 21:44:46,199 - INFO - training batch 651, loss: 1.219, 20832/28000 datapoints
2025-03-06 21:44:46,512 - INFO - training batch 701, loss: 1.238, 22432/28000 datapoints
2025-03-06 21:44:46,797 - INFO - training batch 751, loss: 1.679, 24032/28000 datapoints
2025-03-06 21:44:47,069 - INFO - training batch 801, loss: 1.415, 25632/28000 datapoints
2025-03-06 21:44:47,332 - INFO - training batch 851, loss: 1.491, 27232/28000 datapoints
2025-03-06 21:44:47,473 - INFO - validation batch 1, loss: 1.195, 32/6976 datapoints
2025-03-06 21:44:47,572 - INFO - validation batch 51, loss: 1.865, 1632/6976 datapoints
2025-03-06 21:44:47,667 - INFO - validation batch 101, loss: 1.557, 3232/6976 datapoints
2025-03-06 21:44:47,764 - INFO - validation batch 151, loss: 1.969, 4832/6976 datapoints
2025-03-06 21:44:47,856 - INFO - validation batch 201, loss: 1.136, 6432/6976 datapoints
2025-03-06 21:44:47,896 - INFO - Epoch 13/800 done.
2025-03-06 21:44:47,896 - INFO - Final validation performance:
Loss: 1.545, top-1 acc: 0.464top-5 acc: 0.464
2025-03-06 21:44:47,897 - INFO - Beginning epoch 14/800
2025-03-06 21:44:47,904 - INFO - training batch 1, loss: 1.932, 32/28000 datapoints
2025-03-06 21:44:48,164 - INFO - training batch 51, loss: 1.784, 1632/28000 datapoints
2025-03-06 21:44:48,420 - INFO - training batch 101, loss: 1.370, 3232/28000 datapoints
2025-03-06 21:44:48,666 - INFO - training batch 151, loss: 1.784, 4832/28000 datapoints
2025-03-06 21:44:48,912 - INFO - training batch 201, loss: 1.711, 6432/28000 datapoints
2025-03-06 21:44:49,150 - INFO - training batch 251, loss: 1.598, 8032/28000 datapoints
2025-03-06 21:44:49,385 - INFO - training batch 301, loss: 1.710, 9632/28000 datapoints
2025-03-06 21:44:49,617 - INFO - training batch 351, loss: 1.696, 11232/28000 datapoints
2025-03-06 21:44:49,855 - INFO - training batch 401, loss: 1.565, 12832/28000 datapoints
2025-03-06 21:44:50,085 - INFO - training batch 451, loss: 1.526, 14432/28000 datapoints
2025-03-06 21:44:50,315 - INFO - training batch 501, loss: 1.229, 16032/28000 datapoints
2025-03-06 21:44:50,546 - INFO - training batch 551, loss: 1.568, 17632/28000 datapoints
2025-03-06 21:44:50,761 - INFO - training batch 601, loss: 1.583, 19232/28000 datapoints
2025-03-06 21:44:50,979 - INFO - training batch 651, loss: 1.192, 20832/28000 datapoints
2025-03-06 21:44:51,191 - INFO - training batch 701, loss: 1.219, 22432/28000 datapoints
2025-03-06 21:44:51,405 - INFO - training batch 751, loss: 1.674, 24032/28000 datapoints
2025-03-06 21:44:51,616 - INFO - training batch 801, loss: 1.392, 25632/28000 datapoints
2025-03-06 21:44:51,820 - INFO - training batch 851, loss: 1.479, 27232/28000 datapoints
2025-03-06 21:44:51,926 - INFO - validation batch 1, loss: 1.170, 32/6976 datapoints
2025-03-06 21:44:51,995 - INFO - validation batch 51, loss: 1.848, 1632/6976 datapoints
2025-03-06 21:44:52,069 - INFO - validation batch 101, loss: 1.538, 3232/6976 datapoints
2025-03-06 21:44:52,140 - INFO - validation batch 151, loss: 1.944, 4832/6976 datapoints
2025-03-06 21:44:52,211 - INFO - validation batch 201, loss: 1.112, 6432/6976 datapoints
2025-03-06 21:44:52,240 - INFO - Epoch 14/800 done.
2025-03-06 21:44:52,240 - INFO - Final validation performance:
Loss: 1.522, top-1 acc: 0.469top-5 acc: 0.469
2025-03-06 21:44:52,241 - INFO - Beginning epoch 15/800
2025-03-06 21:44:52,246 - INFO - training batch 1, loss: 1.901, 32/28000 datapoints
2025-03-06 21:44:52,449 - INFO - training batch 51, loss: 1.769, 1632/28000 datapoints
2025-03-06 21:44:52,650 - INFO - training batch 101, loss: 1.344, 3232/28000 datapoints
2025-03-06 21:44:52,853 - INFO - training batch 151, loss: 1.768, 4832/28000 datapoints
2025-03-06 21:44:53,052 - INFO - training batch 201, loss: 1.696, 6432/28000 datapoints
2025-03-06 21:44:53,256 - INFO - training batch 251, loss: 1.562, 8032/28000 datapoints
2025-03-06 21:44:53,485 - INFO - training batch 301, loss: 1.685, 9632/28000 datapoints
2025-03-06 21:44:53,676 - INFO - training batch 351, loss: 1.672, 11232/28000 datapoints
2025-03-06 21:44:53,889 - INFO - training batch 401, loss: 1.553, 12832/28000 datapoints
2025-03-06 21:44:54,083 - INFO - training batch 451, loss: 1.508, 14432/28000 datapoints
2025-03-06 21:44:54,251 - INFO - training batch 501, loss: 1.222, 16032/28000 datapoints
2025-03-06 21:44:54,418 - INFO - training batch 551, loss: 1.552, 17632/28000 datapoints
2025-03-06 21:44:54,587 - INFO - training batch 601, loss: 1.572, 19232/28000 datapoints
2025-03-06 21:44:54,756 - INFO - training batch 651, loss: 1.168, 20832/28000 datapoints
2025-03-06 21:44:54,928 - INFO - training batch 701, loss: 1.202, 22432/28000 datapoints
2025-03-06 21:44:55,099 - INFO - training batch 751, loss: 1.668, 24032/28000 datapoints
2025-03-06 21:44:55,278 - INFO - training batch 801, loss: 1.370, 25632/28000 datapoints
2025-03-06 21:44:55,447 - INFO - training batch 851, loss: 1.469, 27232/28000 datapoints
2025-03-06 21:44:55,528 - INFO - validation batch 1, loss: 1.149, 32/6976 datapoints
2025-03-06 21:44:55,586 - INFO - validation batch 51, loss: 1.832, 1632/6976 datapoints
2025-03-06 21:44:55,644 - INFO - validation batch 101, loss: 1.519, 3232/6976 datapoints
2025-03-06 21:44:55,702 - INFO - validation batch 151, loss: 1.917, 4832/6976 datapoints
2025-03-06 21:44:55,761 - INFO - validation batch 201, loss: 1.091, 6432/6976 datapoints
2025-03-06 21:44:55,783 - INFO - Epoch 15/800 done.
2025-03-06 21:44:55,783 - INFO - Final validation performance:
Loss: 1.502, top-1 acc: 0.475top-5 acc: 0.475
2025-03-06 21:44:55,784 - INFO - Beginning epoch 16/800
2025-03-06 21:44:55,788 - INFO - training batch 1, loss: 1.869, 32/28000 datapoints
2025-03-06 21:44:55,958 - INFO - training batch 51, loss: 1.754, 1632/28000 datapoints
2025-03-06 21:44:56,131 - INFO - training batch 101, loss: 1.320, 3232/28000 datapoints
2025-03-06 21:44:56,301 - INFO - training batch 151, loss: 1.753, 4832/28000 datapoints
2025-03-06 21:44:56,465 - INFO - training batch 201, loss: 1.682, 6432/28000 datapoints
2025-03-06 21:44:56,634 - INFO - training batch 251, loss: 1.528, 8032/28000 datapoints
2025-03-06 21:44:56,800 - INFO - training batch 301, loss: 1.662, 9632/28000 datapoints
2025-03-06 21:44:56,965 - INFO - training batch 351, loss: 1.650, 11232/28000 datapoints
2025-03-06 21:44:57,135 - INFO - training batch 401, loss: 1.542, 12832/28000 datapoints
2025-03-06 21:44:57,304 - INFO - training batch 451, loss: 1.491, 14432/28000 datapoints
2025-03-06 21:44:57,471 - INFO - training batch 501, loss: 1.216, 16032/28000 datapoints
2025-03-06 21:44:57,633 - INFO - training batch 551, loss: 1.538, 17632/28000 datapoints
2025-03-06 21:44:57,795 - INFO - training batch 601, loss: 1.560, 19232/28000 datapoints
2025-03-06 21:44:57,969 - INFO - training batch 651, loss: 1.147, 20832/28000 datapoints
2025-03-06 21:44:58,135 - INFO - training batch 701, loss: 1.189, 22432/28000 datapoints
2025-03-06 21:44:58,296 - INFO - training batch 751, loss: 1.662, 24032/28000 datapoints
2025-03-06 21:44:58,464 - INFO - training batch 801, loss: 1.349, 25632/28000 datapoints
2025-03-06 21:44:58,630 - INFO - training batch 851, loss: 1.461, 27232/28000 datapoints
2025-03-06 21:44:58,711 - INFO - validation batch 1, loss: 1.129, 32/6976 datapoints
2025-03-06 21:44:58,773 - INFO - validation batch 51, loss: 1.819, 1632/6976 datapoints
2025-03-06 21:44:58,836 - INFO - validation batch 101, loss: 1.502, 3232/6976 datapoints
2025-03-06 21:44:58,893 - INFO - validation batch 151, loss: 1.891, 4832/6976 datapoints
2025-03-06 21:44:58,950 - INFO - validation batch 201, loss: 1.072, 6432/6976 datapoints
2025-03-06 21:44:58,971 - INFO - Epoch 16/800 done.
2025-03-06 21:44:58,971 - INFO - Final validation performance:
Loss: 1.483, top-1 acc: 0.480top-5 acc: 0.480
2025-03-06 21:44:58,972 - INFO - Beginning epoch 17/800
2025-03-06 21:44:58,977 - INFO - training batch 1, loss: 1.837, 32/28000 datapoints
2025-03-06 21:44:59,154 - INFO - training batch 51, loss: 1.739, 1632/28000 datapoints
2025-03-06 21:44:59,326 - INFO - training batch 101, loss: 1.298, 3232/28000 datapoints
2025-03-06 21:44:59,490 - INFO - training batch 151, loss: 1.739, 4832/28000 datapoints
2025-03-06 21:44:59,657 - INFO - training batch 201, loss: 1.669, 6432/28000 datapoints
2025-03-06 21:44:59,817 - INFO - training batch 251, loss: 1.497, 8032/28000 datapoints
2025-03-06 21:44:59,982 - INFO - training batch 301, loss: 1.641, 9632/28000 datapoints
2025-03-06 21:45:00,154 - INFO - training batch 351, loss: 1.630, 11232/28000 datapoints
2025-03-06 21:45:00,327 - INFO - training batch 401, loss: 1.532, 12832/28000 datapoints
2025-03-06 21:45:00,495 - INFO - training batch 451, loss: 1.476, 14432/28000 datapoints
2025-03-06 21:45:00,672 - INFO - training batch 501, loss: 1.213, 16032/28000 datapoints
2025-03-06 21:45:00,846 - INFO - training batch 551, loss: 1.524, 17632/28000 datapoints
2025-03-06 21:45:01,017 - INFO - training batch 601, loss: 1.549, 19232/28000 datapoints
2025-03-06 21:45:01,198 - INFO - training batch 651, loss: 1.129, 20832/28000 datapoints
2025-03-06 21:45:01,378 - INFO - training batch 701, loss: 1.177, 22432/28000 datapoints
2025-03-06 21:45:01,557 - INFO - training batch 751, loss: 1.655, 24032/28000 datapoints
2025-03-06 21:45:01,737 - INFO - training batch 801, loss: 1.329, 25632/28000 datapoints
2025-03-06 21:45:01,912 - INFO - training batch 851, loss: 1.454, 27232/28000 datapoints
2025-03-06 21:45:02,000 - INFO - validation batch 1, loss: 1.112, 32/6976 datapoints
2025-03-06 21:45:02,062 - INFO - validation batch 51, loss: 1.809, 1632/6976 datapoints
2025-03-06 21:45:02,124 - INFO - validation batch 101, loss: 1.486, 3232/6976 datapoints
2025-03-06 21:45:02,195 - INFO - validation batch 151, loss: 1.864, 4832/6976 datapoints
2025-03-06 21:45:02,258 - INFO - validation batch 201, loss: 1.054, 6432/6976 datapoints
2025-03-06 21:45:02,286 - INFO - Epoch 17/800 done.
2025-03-06 21:45:02,286 - INFO - Final validation performance:
Loss: 1.465, top-1 acc: 0.483top-5 acc: 0.483
2025-03-06 21:45:02,287 - INFO - Beginning epoch 18/800
2025-03-06 21:45:02,292 - INFO - training batch 1, loss: 1.806, 32/28000 datapoints
2025-03-06 21:45:02,490 - INFO - training batch 51, loss: 1.724, 1632/28000 datapoints
2025-03-06 21:45:02,685 - INFO - training batch 101, loss: 1.278, 3232/28000 datapoints
2025-03-06 21:45:02,885 - INFO - training batch 151, loss: 1.725, 4832/28000 datapoints
2025-03-06 21:45:03,080 - INFO - training batch 201, loss: 1.658, 6432/28000 datapoints
2025-03-06 21:45:03,286 - INFO - training batch 251, loss: 1.467, 8032/28000 datapoints
2025-03-06 21:45:03,520 - INFO - training batch 301, loss: 1.622, 9632/28000 datapoints
2025-03-06 21:45:03,721 - INFO - training batch 351, loss: 1.610, 11232/28000 datapoints
2025-03-06 21:45:03,921 - INFO - training batch 401, loss: 1.522, 12832/28000 datapoints
2025-03-06 21:45:04,124 - INFO - training batch 451, loss: 1.462, 14432/28000 datapoints
2025-03-06 21:45:04,322 - INFO - training batch 501, loss: 1.211, 16032/28000 datapoints
2025-03-06 21:45:04,517 - INFO - training batch 551, loss: 1.512, 17632/28000 datapoints
2025-03-06 21:45:04,717 - INFO - training batch 601, loss: 1.538, 19232/28000 datapoints
2025-03-06 21:45:04,916 - INFO - training batch 651, loss: 1.114, 20832/28000 datapoints
2025-03-06 21:45:05,128 - INFO - training batch 701, loss: 1.168, 22432/28000 datapoints
2025-03-06 21:45:05,339 - INFO - training batch 751, loss: 1.647, 24032/28000 datapoints
2025-03-06 21:45:05,546 - INFO - training batch 801, loss: 1.310, 25632/28000 datapoints
2025-03-06 21:45:05,748 - INFO - training batch 851, loss: 1.449, 27232/28000 datapoints
2025-03-06 21:45:05,853 - INFO - validation batch 1, loss: 1.096, 32/6976 datapoints
2025-03-06 21:45:05,928 - INFO - validation batch 51, loss: 1.799, 1632/6976 datapoints
2025-03-06 21:45:05,995 - INFO - validation batch 101, loss: 1.471, 3232/6976 datapoints
2025-03-06 21:45:06,065 - INFO - validation batch 151, loss: 1.838, 4832/6976 datapoints
2025-03-06 21:45:06,143 - INFO - validation batch 201, loss: 1.037, 6432/6976 datapoints
2025-03-06 21:45:06,170 - INFO - Epoch 18/800 done.
2025-03-06 21:45:06,171 - INFO - Final validation performance:
Loss: 1.448, top-1 acc: 0.486top-5 acc: 0.486
2025-03-06 21:45:06,171 - INFO - Beginning epoch 19/800
2025-03-06 21:45:06,177 - INFO - training batch 1, loss: 1.777, 32/28000 datapoints
2025-03-06 21:45:06,388 - INFO - training batch 51, loss: 1.709, 1632/28000 datapoints
2025-03-06 21:45:06,584 - INFO - training batch 101, loss: 1.259, 3232/28000 datapoints
2025-03-06 21:45:06,778 - INFO - training batch 151, loss: 1.712, 4832/28000 datapoints
2025-03-06 21:45:06,976 - INFO - training batch 201, loss: 1.647, 6432/28000 datapoints
2025-03-06 21:45:07,177 - INFO - training batch 251, loss: 1.439, 8032/28000 datapoints
2025-03-06 21:45:07,372 - INFO - training batch 301, loss: 1.604, 9632/28000 datapoints
2025-03-06 21:45:07,568 - INFO - training batch 351, loss: 1.590, 11232/28000 datapoints
2025-03-06 21:45:07,763 - INFO - training batch 401, loss: 1.512, 12832/28000 datapoints
2025-03-06 21:45:07,963 - INFO - training batch 451, loss: 1.448, 14432/28000 datapoints
2025-03-06 21:45:08,156 - INFO - training batch 501, loss: 1.209, 16032/28000 datapoints
2025-03-06 21:45:08,356 - INFO - training batch 551, loss: 1.500, 17632/28000 datapoints
2025-03-06 21:45:08,550 - INFO - training batch 601, loss: 1.528, 19232/28000 datapoints
2025-03-06 21:45:08,751 - INFO - training batch 651, loss: 1.100, 20832/28000 datapoints
2025-03-06 21:45:08,950 - INFO - training batch 701, loss: 1.160, 22432/28000 datapoints
2025-03-06 21:45:09,144 - INFO - training batch 751, loss: 1.640, 24032/28000 datapoints
2025-03-06 21:45:09,350 - INFO - training batch 801, loss: 1.292, 25632/28000 datapoints
2025-03-06 21:45:09,551 - INFO - training batch 851, loss: 1.443, 27232/28000 datapoints
2025-03-06 21:45:09,647 - INFO - validation batch 1, loss: 1.082, 32/6976 datapoints
2025-03-06 21:45:09,712 - INFO - validation batch 51, loss: 1.791, 1632/6976 datapoints
2025-03-06 21:45:09,777 - INFO - validation batch 101, loss: 1.456, 3232/6976 datapoints
2025-03-06 21:45:09,848 - INFO - validation batch 151, loss: 1.811, 4832/6976 datapoints
2025-03-06 21:45:09,909 - INFO - validation batch 201, loss: 1.021, 6432/6976 datapoints
2025-03-06 21:45:09,930 - INFO - Epoch 19/800 done.
2025-03-06 21:45:09,930 - INFO - Final validation performance:
Loss: 1.432, top-1 acc: 0.490top-5 acc: 0.490
2025-03-06 21:45:09,930 - INFO - Beginning epoch 20/800
2025-03-06 21:45:09,936 - INFO - training batch 1, loss: 1.749, 32/28000 datapoints
2025-03-06 21:45:10,146 - INFO - training batch 51, loss: 1.693, 1632/28000 datapoints
2025-03-06 21:45:10,347 - INFO - training batch 101, loss: 1.241, 3232/28000 datapoints
2025-03-06 21:45:10,539 - INFO - training batch 151, loss: 1.700, 4832/28000 datapoints
2025-03-06 21:45:10,751 - INFO - training batch 201, loss: 1.637, 6432/28000 datapoints
2025-03-06 21:45:10,950 - INFO - training batch 251, loss: 1.412, 8032/28000 datapoints
2025-03-06 21:45:11,189 - INFO - training batch 301, loss: 1.587, 9632/28000 datapoints
2025-03-06 21:45:11,406 - INFO - training batch 351, loss: 1.571, 11232/28000 datapoints
2025-03-06 21:45:11,608 - INFO - training batch 401, loss: 1.502, 12832/28000 datapoints
2025-03-06 21:45:11,801 - INFO - training batch 451, loss: 1.435, 14432/28000 datapoints
2025-03-06 21:45:11,999 - INFO - training batch 501, loss: 1.208, 16032/28000 datapoints
2025-03-06 21:45:12,204 - INFO - training batch 551, loss: 1.490, 17632/28000 datapoints
2025-03-06 21:45:12,402 - INFO - training batch 601, loss: 1.518, 19232/28000 datapoints
2025-03-06 21:45:12,594 - INFO - training batch 651, loss: 1.087, 20832/28000 datapoints
2025-03-06 21:45:12,793 - INFO - training batch 701, loss: 1.152, 22432/28000 datapoints
2025-03-06 21:45:12,993 - INFO - training batch 751, loss: 1.631, 24032/28000 datapoints
2025-03-06 21:45:13,191 - INFO - training batch 801, loss: 1.274, 25632/28000 datapoints
2025-03-06 21:45:13,391 - INFO - training batch 851, loss: 1.436, 27232/28000 datapoints
2025-03-06 21:45:13,487 - INFO - validation batch 1, loss: 1.069, 32/6976 datapoints
2025-03-06 21:45:13,577 - INFO - validation batch 51, loss: 1.784, 1632/6976 datapoints
2025-03-06 21:45:13,650 - INFO - validation batch 101, loss: 1.441, 3232/6976 datapoints
2025-03-06 21:45:13,718 - INFO - validation batch 151, loss: 1.785, 4832/6976 datapoints
2025-03-06 21:45:13,782 - INFO - validation batch 201, loss: 1.006, 6432/6976 datapoints
2025-03-06 21:45:13,804 - INFO - Epoch 20/800 done.
2025-03-06 21:45:13,804 - INFO - Final validation performance:
Loss: 1.417, top-1 acc: 0.494top-5 acc: 0.494
2025-03-06 21:45:13,805 - INFO - Beginning epoch 21/800
2025-03-06 21:45:13,810 - INFO - training batch 1, loss: 1.722, 32/28000 datapoints
2025-03-06 21:45:14,011 - INFO - training batch 51, loss: 1.678, 1632/28000 datapoints
2025-03-06 21:45:14,212 - INFO - training batch 101, loss: 1.224, 3232/28000 datapoints
2025-03-06 21:45:14,406 - INFO - training batch 151, loss: 1.688, 4832/28000 datapoints
2025-03-06 21:45:14,608 - INFO - training batch 201, loss: 1.627, 6432/28000 datapoints
2025-03-06 21:45:14,795 - INFO - training batch 251, loss: 1.386, 8032/28000 datapoints
2025-03-06 21:45:14,992 - INFO - training batch 301, loss: 1.571, 9632/28000 datapoints
2025-03-06 21:45:15,190 - INFO - training batch 351, loss: 1.553, 11232/28000 datapoints
2025-03-06 21:45:15,386 - INFO - training batch 401, loss: 1.493, 12832/28000 datapoints
2025-03-06 21:45:15,570 - INFO - training batch 451, loss: 1.422, 14432/28000 datapoints
2025-03-06 21:45:15,765 - INFO - training batch 501, loss: 1.207, 16032/28000 datapoints
2025-03-06 21:45:15,953 - INFO - training batch 551, loss: 1.480, 17632/28000 datapoints
2025-03-06 21:45:16,145 - INFO - training batch 601, loss: 1.509, 19232/28000 datapoints
2025-03-06 21:45:16,334 - INFO - training batch 651, loss: 1.075, 20832/28000 datapoints
2025-03-06 21:45:16,523 - INFO - training batch 701, loss: 1.145, 22432/28000 datapoints
2025-03-06 21:45:16,712 - INFO - training batch 751, loss: 1.622, 24032/28000 datapoints
2025-03-06 21:45:16,903 - INFO - training batch 801, loss: 1.256, 25632/28000 datapoints
2025-03-06 21:45:17,090 - INFO - training batch 851, loss: 1.430, 27232/28000 datapoints
2025-03-06 21:45:17,181 - INFO - validation batch 1, loss: 1.057, 32/6976 datapoints
2025-03-06 21:45:17,239 - INFO - validation batch 51, loss: 1.778, 1632/6976 datapoints
2025-03-06 21:45:17,296 - INFO - validation batch 101, loss: 1.426, 3232/6976 datapoints
2025-03-06 21:45:17,357 - INFO - validation batch 151, loss: 1.759, 4832/6976 datapoints
2025-03-06 21:45:17,414 - INFO - validation batch 201, loss: 0.991, 6432/6976 datapoints
2025-03-06 21:45:17,434 - INFO - Epoch 21/800 done.
2025-03-06 21:45:17,434 - INFO - Final validation performance:
Loss: 1.402, top-1 acc: 0.497top-5 acc: 0.497
2025-03-06 21:45:17,435 - INFO - Beginning epoch 22/800
2025-03-06 21:45:17,440 - INFO - training batch 1, loss: 1.696, 32/28000 datapoints
2025-03-06 21:45:17,629 - INFO - training batch 51, loss: 1.662, 1632/28000 datapoints
2025-03-06 21:45:17,818 - INFO - training batch 101, loss: 1.207, 3232/28000 datapoints
2025-03-06 21:45:18,004 - INFO - training batch 151, loss: 1.676, 4832/28000 datapoints
2025-03-06 21:45:18,185 - INFO - training batch 201, loss: 1.617, 6432/28000 datapoints
2025-03-06 21:45:18,367 - INFO - training batch 251, loss: 1.361, 8032/28000 datapoints
2025-03-06 21:45:18,547 - INFO - training batch 301, loss: 1.556, 9632/28000 datapoints
2025-03-06 21:45:18,729 - INFO - training batch 351, loss: 1.534, 11232/28000 datapoints
2025-03-06 21:45:18,927 - INFO - training batch 401, loss: 1.483, 12832/28000 datapoints
2025-03-06 21:45:19,150 - INFO - training batch 451, loss: 1.409, 14432/28000 datapoints
2025-03-06 21:45:19,326 - INFO - training batch 501, loss: 1.205, 16032/28000 datapoints
2025-03-06 21:45:19,492 - INFO - training batch 551, loss: 1.470, 17632/28000 datapoints
2025-03-06 21:45:19,654 - INFO - training batch 601, loss: 1.500, 19232/28000 datapoints
2025-03-06 21:45:19,819 - INFO - training batch 651, loss: 1.063, 20832/28000 datapoints
2025-03-06 21:45:19,987 - INFO - training batch 701, loss: 1.138, 22432/28000 datapoints
2025-03-06 21:45:20,157 - INFO - training batch 751, loss: 1.613, 24032/28000 datapoints
2025-03-06 21:45:20,325 - INFO - training batch 801, loss: 1.238, 25632/28000 datapoints
2025-03-06 21:45:20,494 - INFO - training batch 851, loss: 1.424, 27232/28000 datapoints
2025-03-06 21:45:20,575 - INFO - validation batch 1, loss: 1.045, 32/6976 datapoints
2025-03-06 21:45:20,630 - INFO - validation batch 51, loss: 1.772, 1632/6976 datapoints
2025-03-06 21:45:20,686 - INFO - validation batch 101, loss: 1.410, 3232/6976 datapoints
2025-03-06 21:45:20,746 - INFO - validation batch 151, loss: 1.733, 4832/6976 datapoints
2025-03-06 21:45:20,802 - INFO - validation batch 201, loss: 0.976, 6432/6976 datapoints
2025-03-06 21:45:20,824 - INFO - Epoch 22/800 done.
2025-03-06 21:45:20,825 - INFO - Final validation performance:
Loss: 1.387, top-1 acc: 0.501top-5 acc: 0.501
2025-03-06 21:45:20,825 - INFO - Beginning epoch 23/800
2025-03-06 21:45:20,832 - INFO - training batch 1, loss: 1.672, 32/28000 datapoints
2025-03-06 21:45:21,017 - INFO - training batch 51, loss: 1.646, 1632/28000 datapoints
2025-03-06 21:45:21,193 - INFO - training batch 101, loss: 1.190, 3232/28000 datapoints
2025-03-06 21:45:21,380 - INFO - training batch 151, loss: 1.664, 4832/28000 datapoints
2025-03-06 21:45:21,555 - INFO - training batch 201, loss: 1.607, 6432/28000 datapoints
2025-03-06 21:45:21,729 - INFO - training batch 251, loss: 1.337, 8032/28000 datapoints
2025-03-06 21:45:21,913 - INFO - training batch 301, loss: 1.542, 9632/28000 datapoints
2025-03-06 21:45:22,088 - INFO - training batch 351, loss: 1.517, 11232/28000 datapoints
2025-03-06 21:45:22,264 - INFO - training batch 401, loss: 1.473, 12832/28000 datapoints
2025-03-06 21:45:22,441 - INFO - training batch 451, loss: 1.396, 14432/28000 datapoints
2025-03-06 21:45:22,615 - INFO - training batch 501, loss: 1.203, 16032/28000 datapoints
2025-03-06 21:45:22,794 - INFO - training batch 551, loss: 1.461, 17632/28000 datapoints
2025-03-06 21:45:22,974 - INFO - training batch 601, loss: 1.492, 19232/28000 datapoints
2025-03-06 21:45:23,152 - INFO - training batch 651, loss: 1.052, 20832/28000 datapoints
2025-03-06 21:45:23,327 - INFO - training batch 701, loss: 1.132, 22432/28000 datapoints
2025-03-06 21:45:23,506 - INFO - training batch 751, loss: 1.602, 24032/28000 datapoints
2025-03-06 21:45:23,707 - INFO - training batch 801, loss: 1.220, 25632/28000 datapoints
2025-03-06 21:45:23,880 - INFO - training batch 851, loss: 1.419, 27232/28000 datapoints
2025-03-06 21:45:23,962 - INFO - validation batch 1, loss: 1.034, 32/6976 datapoints
2025-03-06 21:45:24,024 - INFO - validation batch 51, loss: 1.767, 1632/6976 datapoints
2025-03-06 21:45:24,080 - INFO - validation batch 101, loss: 1.393, 3232/6976 datapoints
2025-03-06 21:45:24,143 - INFO - validation batch 151, loss: 1.707, 4832/6976 datapoints
2025-03-06 21:45:24,205 - INFO - validation batch 201, loss: 0.960, 6432/6976 datapoints
2025-03-06 21:45:24,228 - INFO - Epoch 23/800 done.
2025-03-06 21:45:24,228 - INFO - Final validation performance:
Loss: 1.372, top-1 acc: 0.505top-5 acc: 0.505
2025-03-06 21:45:24,229 - INFO - Beginning epoch 24/800
2025-03-06 21:45:24,233 - INFO - training batch 1, loss: 1.648, 32/28000 datapoints
2025-03-06 21:45:24,425 - INFO - training batch 51, loss: 1.630, 1632/28000 datapoints
2025-03-06 21:45:24,610 - INFO - training batch 101, loss: 1.173, 3232/28000 datapoints
2025-03-06 21:45:24,791 - INFO - training batch 151, loss: 1.653, 4832/28000 datapoints
2025-03-06 21:45:24,968 - INFO - training batch 201, loss: 1.597, 6432/28000 datapoints
2025-03-06 21:45:25,136 - INFO - training batch 251, loss: 1.313, 8032/28000 datapoints
2025-03-06 21:45:25,302 - INFO - training batch 301, loss: 1.527, 9632/28000 datapoints
2025-03-06 21:45:25,471 - INFO - training batch 351, loss: 1.499, 11232/28000 datapoints
2025-03-06 21:45:25,633 - INFO - training batch 401, loss: 1.462, 12832/28000 datapoints
2025-03-06 21:45:25,798 - INFO - training batch 451, loss: 1.384, 14432/28000 datapoints
2025-03-06 21:45:25,966 - INFO - training batch 501, loss: 1.201, 16032/28000 datapoints
2025-03-06 21:45:26,135 - INFO - training batch 551, loss: 1.452, 17632/28000 datapoints
2025-03-06 21:45:26,309 - INFO - training batch 601, loss: 1.483, 19232/28000 datapoints
2025-03-06 21:45:26,476 - INFO - training batch 651, loss: 1.040, 20832/28000 datapoints
2025-03-06 21:45:26,642 - INFO - training batch 701, loss: 1.125, 22432/28000 datapoints
2025-03-06 21:45:26,808 - INFO - training batch 751, loss: 1.590, 24032/28000 datapoints
2025-03-06 21:45:26,975 - INFO - training batch 801, loss: 1.203, 25632/28000 datapoints
2025-03-06 21:45:27,141 - INFO - training batch 851, loss: 1.412, 27232/28000 datapoints
2025-03-06 21:45:27,228 - INFO - validation batch 1, loss: 1.023, 32/6976 datapoints
2025-03-06 21:45:27,284 - INFO - validation batch 51, loss: 1.763, 1632/6976 datapoints
2025-03-06 21:45:27,342 - INFO - validation batch 101, loss: 1.376, 3232/6976 datapoints
2025-03-06 21:45:27,404 - INFO - validation batch 151, loss: 1.681, 4832/6976 datapoints
2025-03-06 21:45:27,463 - INFO - validation batch 201, loss: 0.947, 6432/6976 datapoints
2025-03-06 21:45:27,488 - INFO - Epoch 24/800 done.
2025-03-06 21:45:27,488 - INFO - Final validation performance:
Loss: 1.358, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:45:27,489 - INFO - Beginning epoch 25/800
2025-03-06 21:45:27,493 - INFO - training batch 1, loss: 1.625, 32/28000 datapoints
2025-03-06 21:45:27,669 - INFO - training batch 51, loss: 1.613, 1632/28000 datapoints
2025-03-06 21:45:27,836 - INFO - training batch 101, loss: 1.156, 3232/28000 datapoints
2025-03-06 21:45:28,011 - INFO - training batch 151, loss: 1.641, 4832/28000 datapoints
2025-03-06 21:45:28,183 - INFO - training batch 201, loss: 1.587, 6432/28000 datapoints
2025-03-06 21:45:28,351 - INFO - training batch 251, loss: 1.289, 8032/28000 datapoints
2025-03-06 21:45:28,527 - INFO - training batch 301, loss: 1.513, 9632/28000 datapoints
2025-03-06 21:45:28,694 - INFO - training batch 351, loss: 1.480, 11232/28000 datapoints
2025-03-06 21:45:28,869 - INFO - training batch 401, loss: 1.451, 12832/28000 datapoints
2025-03-06 21:45:29,048 - INFO - training batch 451, loss: 1.371, 14432/28000 datapoints
2025-03-06 21:45:29,219 - INFO - training batch 501, loss: 1.199, 16032/28000 datapoints
2025-03-06 21:45:29,404 - INFO - training batch 551, loss: 1.442, 17632/28000 datapoints
2025-03-06 21:45:29,583 - INFO - training batch 601, loss: 1.474, 19232/28000 datapoints
2025-03-06 21:45:29,759 - INFO - training batch 651, loss: 1.028, 20832/28000 datapoints
2025-03-06 21:45:29,936 - INFO - training batch 701, loss: 1.118, 22432/28000 datapoints
2025-03-06 21:45:30,113 - INFO - training batch 751, loss: 1.577, 24032/28000 datapoints
2025-03-06 21:45:30,293 - INFO - training batch 801, loss: 1.185, 25632/28000 datapoints
2025-03-06 21:45:30,467 - INFO - training batch 851, loss: 1.406, 27232/28000 datapoints
2025-03-06 21:45:30,558 - INFO - validation batch 1, loss: 1.013, 32/6976 datapoints
2025-03-06 21:45:30,620 - INFO - validation batch 51, loss: 1.758, 1632/6976 datapoints
2025-03-06 21:45:30,681 - INFO - validation batch 101, loss: 1.358, 3232/6976 datapoints
2025-03-06 21:45:30,745 - INFO - validation batch 151, loss: 1.655, 4832/6976 datapoints
2025-03-06 21:45:30,813 - INFO - validation batch 201, loss: 0.933, 6432/6976 datapoints
2025-03-06 21:45:30,844 - INFO - Epoch 25/800 done.
2025-03-06 21:45:30,844 - INFO - Final validation performance:
Loss: 1.343, top-1 acc: 0.513top-5 acc: 0.513
2025-03-06 21:45:30,845 - INFO - Beginning epoch 26/800
2025-03-06 21:45:30,850 - INFO - training batch 1, loss: 1.602, 32/28000 datapoints
2025-03-06 21:45:31,053 - INFO - training batch 51, loss: 1.596, 1632/28000 datapoints
2025-03-06 21:45:31,259 - INFO - training batch 101, loss: 1.139, 3232/28000 datapoints
2025-03-06 21:45:31,463 - INFO - training batch 151, loss: 1.628, 4832/28000 datapoints
2025-03-06 21:45:31,667 - INFO - training batch 201, loss: 1.576, 6432/28000 datapoints
2025-03-06 21:45:31,869 - INFO - training batch 251, loss: 1.266, 8032/28000 datapoints
2025-03-06 21:45:32,066 - INFO - training batch 301, loss: 1.498, 9632/28000 datapoints
2025-03-06 21:45:32,265 - INFO - training batch 351, loss: 1.460, 11232/28000 datapoints
2025-03-06 21:45:32,464 - INFO - training batch 401, loss: 1.439, 12832/28000 datapoints
2025-03-06 21:45:32,658 - INFO - training batch 451, loss: 1.357, 14432/28000 datapoints
2025-03-06 21:45:32,860 - INFO - training batch 501, loss: 1.197, 16032/28000 datapoints
2025-03-06 21:45:33,058 - INFO - training batch 551, loss: 1.433, 17632/28000 datapoints
2025-03-06 21:45:33,261 - INFO - training batch 601, loss: 1.464, 19232/28000 datapoints
2025-03-06 21:45:33,462 - INFO - training batch 651, loss: 1.016, 20832/28000 datapoints
2025-03-06 21:45:33,659 - INFO - training batch 701, loss: 1.110, 22432/28000 datapoints
2025-03-06 21:45:33,892 - INFO - training batch 751, loss: 1.563, 24032/28000 datapoints
2025-03-06 21:45:34,085 - INFO - training batch 801, loss: 1.166, 25632/28000 datapoints
2025-03-06 21:45:34,289 - INFO - training batch 851, loss: 1.398, 27232/28000 datapoints
2025-03-06 21:45:34,387 - INFO - validation batch 1, loss: 1.002, 32/6976 datapoints
2025-03-06 21:45:34,455 - INFO - validation batch 51, loss: 1.755, 1632/6976 datapoints
2025-03-06 21:45:34,523 - INFO - validation batch 101, loss: 1.340, 3232/6976 datapoints
2025-03-06 21:45:34,589 - INFO - validation batch 151, loss: 1.629, 4832/6976 datapoints
2025-03-06 21:45:34,659 - INFO - validation batch 201, loss: 0.918, 6432/6976 datapoints
2025-03-06 21:45:34,690 - INFO - Epoch 26/800 done.
2025-03-06 21:45:34,690 - INFO - Final validation performance:
Loss: 1.329, top-1 acc: 0.519top-5 acc: 0.519
2025-03-06 21:45:34,691 - INFO - Beginning epoch 27/800
2025-03-06 21:45:34,696 - INFO - training batch 1, loss: 1.580, 32/28000 datapoints
2025-03-06 21:45:34,909 - INFO - training batch 51, loss: 1.578, 1632/28000 datapoints
2025-03-06 21:45:35,125 - INFO - training batch 101, loss: 1.123, 3232/28000 datapoints
2025-03-06 21:45:35,330 - INFO - training batch 151, loss: 1.616, 4832/28000 datapoints
2025-03-06 21:45:35,533 - INFO - training batch 201, loss: 1.565, 6432/28000 datapoints
2025-03-06 21:45:35,735 - INFO - training batch 251, loss: 1.242, 8032/28000 datapoints
2025-03-06 21:45:35,938 - INFO - training batch 301, loss: 1.484, 9632/28000 datapoints
2025-03-06 21:45:36,141 - INFO - training batch 351, loss: 1.440, 11232/28000 datapoints
2025-03-06 21:45:36,342 - INFO - training batch 401, loss: 1.426, 12832/28000 datapoints
2025-03-06 21:45:36,539 - INFO - training batch 451, loss: 1.342, 14432/28000 datapoints
2025-03-06 21:45:36,739 - INFO - training batch 501, loss: 1.193, 16032/28000 datapoints
2025-03-06 21:45:36,938 - INFO - training batch 551, loss: 1.424, 17632/28000 datapoints
2025-03-06 21:45:37,137 - INFO - training batch 601, loss: 1.454, 19232/28000 datapoints
2025-03-06 21:45:37,335 - INFO - training batch 651, loss: 1.002, 20832/28000 datapoints
2025-03-06 21:45:37,538 - INFO - training batch 701, loss: 1.101, 22432/28000 datapoints
2025-03-06 21:45:37,737 - INFO - training batch 751, loss: 1.548, 24032/28000 datapoints
2025-03-06 21:45:37,957 - INFO - training batch 801, loss: 1.148, 25632/28000 datapoints
2025-03-06 21:45:38,154 - INFO - training batch 851, loss: 1.391, 27232/28000 datapoints
2025-03-06 21:45:38,254 - INFO - validation batch 1, loss: 0.991, 32/6976 datapoints
2025-03-06 21:45:38,324 - INFO - validation batch 51, loss: 1.752, 1632/6976 datapoints
2025-03-06 21:45:38,392 - INFO - validation batch 101, loss: 1.322, 3232/6976 datapoints
2025-03-06 21:45:38,461 - INFO - validation batch 151, loss: 1.602, 4832/6976 datapoints
2025-03-06 21:45:38,527 - INFO - validation batch 201, loss: 0.903, 6432/6976 datapoints
2025-03-06 21:45:38,553 - INFO - Epoch 27/800 done.
2025-03-06 21:45:38,553 - INFO - Final validation performance:
Loss: 1.314, top-1 acc: 0.522top-5 acc: 0.522
2025-03-06 21:45:38,554 - INFO - Beginning epoch 28/800
2025-03-06 21:45:38,560 - INFO - training batch 1, loss: 1.557, 32/28000 datapoints
2025-03-06 21:45:38,766 - INFO - training batch 51, loss: 1.559, 1632/28000 datapoints
2025-03-06 21:45:38,959 - INFO - training batch 101, loss: 1.106, 3232/28000 datapoints
2025-03-06 21:45:39,155 - INFO - training batch 151, loss: 1.603, 4832/28000 datapoints
2025-03-06 21:45:39,362 - INFO - training batch 201, loss: 1.554, 6432/28000 datapoints
2025-03-06 21:45:39,571 - INFO - training batch 251, loss: 1.219, 8032/28000 datapoints
2025-03-06 21:45:39,769 - INFO - training batch 301, loss: 1.468, 9632/28000 datapoints
2025-03-06 21:45:39,976 - INFO - training batch 351, loss: 1.419, 11232/28000 datapoints
2025-03-06 21:45:40,200 - INFO - training batch 401, loss: 1.413, 12832/28000 datapoints
2025-03-06 21:45:40,416 - INFO - training batch 451, loss: 1.327, 14432/28000 datapoints
2025-03-06 21:45:40,616 - INFO - training batch 501, loss: 1.189, 16032/28000 datapoints
2025-03-06 21:45:40,819 - INFO - training batch 551, loss: 1.415, 17632/28000 datapoints
2025-03-06 21:45:41,025 - INFO - training batch 601, loss: 1.443, 19232/28000 datapoints
2025-03-06 21:45:41,225 - INFO - training batch 651, loss: 0.989, 20832/28000 datapoints
2025-03-06 21:45:41,447 - INFO - training batch 701, loss: 1.092, 22432/28000 datapoints
2025-03-06 21:45:41,649 - INFO - training batch 751, loss: 1.532, 24032/28000 datapoints
2025-03-06 21:45:41,848 - INFO - training batch 801, loss: 1.129, 25632/28000 datapoints
2025-03-06 21:45:42,038 - INFO - training batch 851, loss: 1.384, 27232/28000 datapoints
2025-03-06 21:45:42,144 - INFO - validation batch 1, loss: 0.979, 32/6976 datapoints
2025-03-06 21:45:42,226 - INFO - validation batch 51, loss: 1.750, 1632/6976 datapoints
2025-03-06 21:45:42,308 - INFO - validation batch 101, loss: 1.303, 3232/6976 datapoints
2025-03-06 21:45:42,373 - INFO - validation batch 151, loss: 1.575, 4832/6976 datapoints
2025-03-06 21:45:42,438 - INFO - validation batch 201, loss: 0.888, 6432/6976 datapoints
2025-03-06 21:45:42,458 - INFO - Epoch 28/800 done.
2025-03-06 21:45:42,459 - INFO - Final validation performance:
Loss: 1.299, top-1 acc: 0.528top-5 acc: 0.528
2025-03-06 21:45:42,459 - INFO - Beginning epoch 29/800
2025-03-06 21:45:42,464 - INFO - training batch 1, loss: 1.536, 32/28000 datapoints
2025-03-06 21:45:42,656 - INFO - training batch 51, loss: 1.540, 1632/28000 datapoints
2025-03-06 21:45:42,855 - INFO - training batch 101, loss: 1.088, 3232/28000 datapoints
2025-03-06 21:45:43,051 - INFO - training batch 151, loss: 1.590, 4832/28000 datapoints
2025-03-06 21:45:43,238 - INFO - training batch 201, loss: 1.541, 6432/28000 datapoints
2025-03-06 21:45:43,422 - INFO - training batch 251, loss: 1.195, 8032/28000 datapoints
2025-03-06 21:45:43,611 - INFO - training batch 301, loss: 1.453, 9632/28000 datapoints
2025-03-06 21:45:43,801 - INFO - training batch 351, loss: 1.397, 11232/28000 datapoints
2025-03-06 21:45:44,015 - INFO - training batch 401, loss: 1.399, 12832/28000 datapoints
2025-03-06 21:45:44,189 - INFO - training batch 451, loss: 1.310, 14432/28000 datapoints
2025-03-06 21:45:44,371 - INFO - training batch 501, loss: 1.183, 16032/28000 datapoints
2025-03-06 21:45:44,545 - INFO - training batch 551, loss: 1.406, 17632/28000 datapoints
2025-03-06 21:45:44,718 - INFO - training batch 601, loss: 1.430, 19232/28000 datapoints
2025-03-06 21:45:44,894 - INFO - training batch 651, loss: 0.976, 20832/28000 datapoints
2025-03-06 21:45:45,070 - INFO - training batch 701, loss: 1.083, 22432/28000 datapoints
2025-03-06 21:45:45,232 - INFO - training batch 751, loss: 1.515, 24032/28000 datapoints
2025-03-06 21:45:45,392 - INFO - training batch 801, loss: 1.108, 25632/28000 datapoints
2025-03-06 21:45:45,543 - INFO - training batch 851, loss: 1.375, 27232/28000 datapoints
2025-03-06 21:45:45,619 - INFO - validation batch 1, loss: 0.968, 32/6976 datapoints
2025-03-06 21:45:45,673 - INFO - validation batch 51, loss: 1.747, 1632/6976 datapoints
2025-03-06 21:45:45,726 - INFO - validation batch 101, loss: 1.283, 3232/6976 datapoints
2025-03-06 21:45:45,777 - INFO - validation batch 151, loss: 1.547, 4832/6976 datapoints
2025-03-06 21:45:45,826 - INFO - validation batch 201, loss: 0.874, 6432/6976 datapoints
2025-03-06 21:45:45,846 - INFO - Epoch 29/800 done.
2025-03-06 21:45:45,847 - INFO - Final validation performance:
Loss: 1.284, top-1 acc: 0.532top-5 acc: 0.532
2025-03-06 21:45:45,847 - INFO - Beginning epoch 30/800
2025-03-06 21:45:45,852 - INFO - training batch 1, loss: 1.515, 32/28000 datapoints
2025-03-06 21:45:46,000 - INFO - training batch 51, loss: 1.520, 1632/28000 datapoints
2025-03-06 21:45:46,143 - INFO - training batch 101, loss: 1.071, 3232/28000 datapoints
2025-03-06 21:45:46,283 - INFO - training batch 151, loss: 1.577, 4832/28000 datapoints
2025-03-06 21:45:46,424 - INFO - training batch 201, loss: 1.528, 6432/28000 datapoints
2025-03-06 21:45:46,563 - INFO - training batch 251, loss: 1.172, 8032/28000 datapoints
2025-03-06 21:45:46,706 - INFO - training batch 301, loss: 1.437, 9632/28000 datapoints
2025-03-06 21:45:46,847 - INFO - training batch 351, loss: 1.373, 11232/28000 datapoints
2025-03-06 21:45:46,987 - INFO - training batch 401, loss: 1.384, 12832/28000 datapoints
2025-03-06 21:45:47,132 - INFO - training batch 451, loss: 1.293, 14432/28000 datapoints
2025-03-06 21:45:47,276 - INFO - training batch 501, loss: 1.177, 16032/28000 datapoints
2025-03-06 21:45:47,441 - INFO - training batch 551, loss: 1.397, 17632/28000 datapoints
2025-03-06 21:45:47,593 - INFO - training batch 601, loss: 1.417, 19232/28000 datapoints
2025-03-06 21:45:47,739 - INFO - training batch 651, loss: 0.963, 20832/28000 datapoints
2025-03-06 21:45:47,886 - INFO - training batch 701, loss: 1.073, 22432/28000 datapoints
2025-03-06 21:45:48,035 - INFO - training batch 751, loss: 1.497, 24032/28000 datapoints
2025-03-06 21:45:48,183 - INFO - training batch 801, loss: 1.087, 25632/28000 datapoints
2025-03-06 21:45:48,330 - INFO - training batch 851, loss: 1.366, 27232/28000 datapoints
2025-03-06 21:45:48,401 - INFO - validation batch 1, loss: 0.955, 32/6976 datapoints
2025-03-06 21:45:48,452 - INFO - validation batch 51, loss: 1.745, 1632/6976 datapoints
2025-03-06 21:45:48,499 - INFO - validation batch 101, loss: 1.262, 3232/6976 datapoints
2025-03-06 21:45:48,545 - INFO - validation batch 151, loss: 1.519, 4832/6976 datapoints
2025-03-06 21:45:48,592 - INFO - validation batch 201, loss: 0.859, 6432/6976 datapoints
2025-03-06 21:45:48,612 - INFO - Epoch 30/800 done.
2025-03-06 21:45:48,612 - INFO - Final validation performance:
Loss: 1.268, top-1 acc: 0.538top-5 acc: 0.538
2025-03-06 21:45:48,613 - INFO - Beginning epoch 31/800
2025-03-06 21:45:48,618 - INFO - training batch 1, loss: 1.494, 32/28000 datapoints
2025-03-06 21:45:48,770 - INFO - training batch 51, loss: 1.501, 1632/28000 datapoints
2025-03-06 21:45:48,918 - INFO - training batch 101, loss: 1.053, 3232/28000 datapoints
2025-03-06 21:45:49,063 - INFO - training batch 151, loss: 1.564, 4832/28000 datapoints
2025-03-06 21:45:49,208 - INFO - training batch 201, loss: 1.514, 6432/28000 datapoints
2025-03-06 21:45:49,353 - INFO - training batch 251, loss: 1.148, 8032/28000 datapoints
2025-03-06 21:45:49,500 - INFO - training batch 301, loss: 1.420, 9632/28000 datapoints
2025-03-06 21:45:49,643 - INFO - training batch 351, loss: 1.349, 11232/28000 datapoints
2025-03-06 21:45:49,788 - INFO - training batch 401, loss: 1.369, 12832/28000 datapoints
2025-03-06 21:45:49,934 - INFO - training batch 451, loss: 1.275, 14432/28000 datapoints
2025-03-06 21:45:50,081 - INFO - training batch 501, loss: 1.170, 16032/28000 datapoints
2025-03-06 21:45:50,228 - INFO - training batch 551, loss: 1.387, 17632/28000 datapoints
2025-03-06 21:45:50,374 - INFO - training batch 601, loss: 1.403, 19232/28000 datapoints
2025-03-06 21:45:50,520 - INFO - training batch 651, loss: 0.949, 20832/28000 datapoints
2025-03-06 21:45:50,665 - INFO - training batch 701, loss: 1.062, 22432/28000 datapoints
2025-03-06 21:45:50,809 - INFO - training batch 751, loss: 1.476, 24032/28000 datapoints
2025-03-06 21:45:50,954 - INFO - training batch 801, loss: 1.065, 25632/28000 datapoints
2025-03-06 21:45:51,099 - INFO - training batch 851, loss: 1.357, 27232/28000 datapoints
2025-03-06 21:45:51,172 - INFO - validation batch 1, loss: 0.942, 32/6976 datapoints
2025-03-06 21:45:51,219 - INFO - validation batch 51, loss: 1.742, 1632/6976 datapoints
2025-03-06 21:45:51,266 - INFO - validation batch 101, loss: 1.239, 3232/6976 datapoints
2025-03-06 21:45:51,314 - INFO - validation batch 151, loss: 1.490, 4832/6976 datapoints
2025-03-06 21:45:51,360 - INFO - validation batch 201, loss: 0.844, 6432/6976 datapoints
2025-03-06 21:45:51,376 - INFO - Epoch 31/800 done.
2025-03-06 21:45:51,377 - INFO - Final validation performance:
Loss: 1.251, top-1 acc: 0.544top-5 acc: 0.544
2025-03-06 21:45:51,377 - INFO - Beginning epoch 32/800
2025-03-06 21:45:51,381 - INFO - training batch 1, loss: 1.473, 32/28000 datapoints
2025-03-06 21:45:51,531 - INFO - training batch 51, loss: 1.481, 1632/28000 datapoints
2025-03-06 21:45:51,681 - INFO - training batch 101, loss: 1.034, 3232/28000 datapoints
2025-03-06 21:45:51,826 - INFO - training batch 151, loss: 1.551, 4832/28000 datapoints
2025-03-06 21:45:51,974 - INFO - training batch 201, loss: 1.499, 6432/28000 datapoints
2025-03-06 21:45:52,118 - INFO - training batch 251, loss: 1.123, 8032/28000 datapoints
2025-03-06 21:45:52,268 - INFO - training batch 301, loss: 1.404, 9632/28000 datapoints
2025-03-06 21:45:52,414 - INFO - training batch 351, loss: 1.324, 11232/28000 datapoints
2025-03-06 21:45:52,558 - INFO - training batch 401, loss: 1.352, 12832/28000 datapoints
2025-03-06 21:45:52,703 - INFO - training batch 451, loss: 1.256, 14432/28000 datapoints
2025-03-06 21:45:52,851 - INFO - training batch 501, loss: 1.162, 16032/28000 datapoints
2025-03-06 21:45:52,996 - INFO - training batch 551, loss: 1.376, 17632/28000 datapoints
2025-03-06 21:45:53,141 - INFO - training batch 601, loss: 1.388, 19232/28000 datapoints
2025-03-06 21:45:53,287 - INFO - training batch 651, loss: 0.933, 20832/28000 datapoints
2025-03-06 21:45:53,430 - INFO - training batch 701, loss: 1.051, 22432/28000 datapoints
2025-03-06 21:45:53,593 - INFO - training batch 751, loss: 1.453, 24032/28000 datapoints
2025-03-06 21:45:53,739 - INFO - training batch 801, loss: 1.043, 25632/28000 datapoints
2025-03-06 21:45:53,885 - INFO - training batch 851, loss: 1.347, 27232/28000 datapoints
2025-03-06 21:45:53,970 - INFO - validation batch 1, loss: 0.929, 32/6976 datapoints
2025-03-06 21:45:54,035 - INFO - validation batch 51, loss: 1.740, 1632/6976 datapoints
2025-03-06 21:45:54,083 - INFO - validation batch 101, loss: 1.216, 3232/6976 datapoints
2025-03-06 21:45:54,133 - INFO - validation batch 151, loss: 1.461, 4832/6976 datapoints
2025-03-06 21:45:54,180 - INFO - validation batch 201, loss: 0.829, 6432/6976 datapoints
2025-03-06 21:45:54,198 - INFO - Epoch 32/800 done.
2025-03-06 21:45:54,198 - INFO - Final validation performance:
Loss: 1.235, top-1 acc: 0.551top-5 acc: 0.551
2025-03-06 21:45:54,199 - INFO - Beginning epoch 33/800
2025-03-06 21:45:54,203 - INFO - training batch 1, loss: 1.452, 32/28000 datapoints
2025-03-06 21:45:54,352 - INFO - training batch 51, loss: 1.460, 1632/28000 datapoints
2025-03-06 21:45:54,497 - INFO - training batch 101, loss: 1.014, 3232/28000 datapoints
2025-03-06 21:45:54,643 - INFO - training batch 151, loss: 1.537, 4832/28000 datapoints
2025-03-06 21:45:54,791 - INFO - training batch 201, loss: 1.483, 6432/28000 datapoints
2025-03-06 21:45:54,937 - INFO - training batch 251, loss: 1.098, 8032/28000 datapoints
2025-03-06 21:45:55,084 - INFO - training batch 301, loss: 1.385, 9632/28000 datapoints
2025-03-06 21:45:55,239 - INFO - training batch 351, loss: 1.298, 11232/28000 datapoints
2025-03-06 21:45:55,384 - INFO - training batch 401, loss: 1.335, 12832/28000 datapoints
2025-03-06 21:45:55,532 - INFO - training batch 451, loss: 1.237, 14432/28000 datapoints
2025-03-06 21:45:55,677 - INFO - training batch 501, loss: 1.154, 16032/28000 datapoints
2025-03-06 21:45:55,822 - INFO - training batch 551, loss: 1.365, 17632/28000 datapoints
2025-03-06 21:45:55,972 - INFO - training batch 601, loss: 1.374, 19232/28000 datapoints
2025-03-06 21:45:56,120 - INFO - training batch 651, loss: 0.916, 20832/28000 datapoints
2025-03-06 21:45:56,266 - INFO - training batch 701, loss: 1.038, 22432/28000 datapoints
2025-03-06 21:45:56,410 - INFO - training batch 751, loss: 1.428, 24032/28000 datapoints
2025-03-06 21:45:56,554 - INFO - training batch 801, loss: 1.020, 25632/28000 datapoints
2025-03-06 21:45:56,698 - INFO - training batch 851, loss: 1.336, 27232/28000 datapoints
2025-03-06 21:45:56,770 - INFO - validation batch 1, loss: 0.915, 32/6976 datapoints
2025-03-06 21:45:56,817 - INFO - validation batch 51, loss: 1.738, 1632/6976 datapoints
2025-03-06 21:45:56,866 - INFO - validation batch 101, loss: 1.191, 3232/6976 datapoints
2025-03-06 21:45:56,913 - INFO - validation batch 151, loss: 1.432, 4832/6976 datapoints
2025-03-06 21:45:56,960 - INFO - validation batch 201, loss: 0.813, 6432/6976 datapoints
2025-03-06 21:45:56,977 - INFO - Epoch 33/800 done.
2025-03-06 21:45:56,977 - INFO - Final validation performance:
Loss: 1.218, top-1 acc: 0.560top-5 acc: 0.560
2025-03-06 21:45:56,977 - INFO - Beginning epoch 34/800
2025-03-06 21:45:56,981 - INFO - training batch 1, loss: 1.430, 32/28000 datapoints
2025-03-06 21:45:57,126 - INFO - training batch 51, loss: 1.439, 1632/28000 datapoints
2025-03-06 21:45:57,275 - INFO - training batch 101, loss: 0.994, 3232/28000 datapoints
2025-03-06 21:45:57,424 - INFO - training batch 151, loss: 1.523, 4832/28000 datapoints
2025-03-06 21:45:57,573 - INFO - training batch 201, loss: 1.467, 6432/28000 datapoints
2025-03-06 21:45:57,720 - INFO - training batch 251, loss: 1.073, 8032/28000 datapoints
2025-03-06 21:45:57,868 - INFO - training batch 301, loss: 1.367, 9632/28000 datapoints
2025-03-06 21:45:58,012 - INFO - training batch 351, loss: 1.271, 11232/28000 datapoints
2025-03-06 21:45:58,157 - INFO - training batch 401, loss: 1.317, 12832/28000 datapoints
2025-03-06 21:45:58,303 - INFO - training batch 451, loss: 1.217, 14432/28000 datapoints
2025-03-06 21:45:58,448 - INFO - training batch 501, loss: 1.145, 16032/28000 datapoints
2025-03-06 21:45:58,592 - INFO - training batch 551, loss: 1.355, 17632/28000 datapoints
2025-03-06 21:45:58,739 - INFO - training batch 601, loss: 1.358, 19232/28000 datapoints
2025-03-06 21:45:58,886 - INFO - training batch 651, loss: 0.898, 20832/28000 datapoints
2025-03-06 21:45:59,035 - INFO - training batch 701, loss: 1.026, 22432/28000 datapoints
2025-03-06 21:45:59,182 - INFO - training batch 751, loss: 1.401, 24032/28000 datapoints
2025-03-06 21:45:59,331 - INFO - training batch 801, loss: 0.997, 25632/28000 datapoints
2025-03-06 21:45:59,480 - INFO - training batch 851, loss: 1.324, 27232/28000 datapoints
2025-03-06 21:45:59,551 - INFO - validation batch 1, loss: 0.900, 32/6976 datapoints
2025-03-06 21:45:59,597 - INFO - validation batch 51, loss: 1.737, 1632/6976 datapoints
2025-03-06 21:45:59,647 - INFO - validation batch 101, loss: 1.166, 3232/6976 datapoints
2025-03-06 21:45:59,704 - INFO - validation batch 151, loss: 1.403, 4832/6976 datapoints
2025-03-06 21:45:59,755 - INFO - validation batch 201, loss: 0.797, 6432/6976 datapoints
2025-03-06 21:45:59,773 - INFO - Epoch 34/800 done.
2025-03-06 21:45:59,773 - INFO - Final validation performance:
Loss: 1.201, top-1 acc: 0.569top-5 acc: 0.569
2025-03-06 21:45:59,774 - INFO - Beginning epoch 35/800
2025-03-06 21:45:59,778 - INFO - training batch 1, loss: 1.409, 32/28000 datapoints
2025-03-06 21:45:59,928 - INFO - training batch 51, loss: 1.415, 1632/28000 datapoints
2025-03-06 21:46:00,081 - INFO - training batch 101, loss: 0.973, 3232/28000 datapoints
2025-03-06 21:46:00,227 - INFO - training batch 151, loss: 1.508, 4832/28000 datapoints
2025-03-06 21:46:00,375 - INFO - training batch 201, loss: 1.450, 6432/28000 datapoints
2025-03-06 21:46:00,521 - INFO - training batch 251, loss: 1.046, 8032/28000 datapoints
2025-03-06 21:46:00,665 - INFO - training batch 301, loss: 1.346, 9632/28000 datapoints
2025-03-06 21:46:00,812 - INFO - training batch 351, loss: 1.244, 11232/28000 datapoints
2025-03-06 21:46:00,959 - INFO - training batch 401, loss: 1.298, 12832/28000 datapoints
2025-03-06 21:46:01,104 - INFO - training batch 451, loss: 1.195, 14432/28000 datapoints
2025-03-06 21:46:01,249 - INFO - training batch 501, loss: 1.135, 16032/28000 datapoints
2025-03-06 21:46:01,396 - INFO - training batch 551, loss: 1.344, 17632/28000 datapoints
2025-03-06 21:46:01,545 - INFO - training batch 601, loss: 1.342, 19232/28000 datapoints
2025-03-06 21:46:01,695 - INFO - training batch 651, loss: 0.879, 20832/28000 datapoints
2025-03-06 21:46:01,844 - INFO - training batch 701, loss: 1.013, 22432/28000 datapoints
2025-03-06 21:46:02,005 - INFO - training batch 751, loss: 1.372, 24032/28000 datapoints
2025-03-06 21:46:02,149 - INFO - training batch 801, loss: 0.973, 25632/28000 datapoints
2025-03-06 21:46:02,294 - INFO - training batch 851, loss: 1.312, 27232/28000 datapoints
2025-03-06 21:46:02,367 - INFO - validation batch 1, loss: 0.885, 32/6976 datapoints
2025-03-06 21:46:02,416 - INFO - validation batch 51, loss: 1.736, 1632/6976 datapoints
2025-03-06 21:46:02,462 - INFO - validation batch 101, loss: 1.140, 3232/6976 datapoints
2025-03-06 21:46:02,509 - INFO - validation batch 151, loss: 1.374, 4832/6976 datapoints
2025-03-06 21:46:02,555 - INFO - validation batch 201, loss: 0.781, 6432/6976 datapoints
2025-03-06 21:46:02,571 - INFO - Epoch 35/800 done.
2025-03-06 21:46:02,572 - INFO - Final validation performance:
Loss: 1.183, top-1 acc: 0.578top-5 acc: 0.578
2025-03-06 21:46:02,572 - INFO - Beginning epoch 36/800
2025-03-06 21:46:02,576 - INFO - training batch 1, loss: 1.387, 32/28000 datapoints
2025-03-06 21:46:02,725 - INFO - training batch 51, loss: 1.391, 1632/28000 datapoints
2025-03-06 21:46:02,874 - INFO - training batch 101, loss: 0.951, 3232/28000 datapoints
2025-03-06 21:46:03,019 - INFO - training batch 151, loss: 1.493, 4832/28000 datapoints
2025-03-06 21:46:03,163 - INFO - training batch 201, loss: 1.433, 6432/28000 datapoints
2025-03-06 21:46:03,309 - INFO - training batch 251, loss: 1.019, 8032/28000 datapoints
2025-03-06 21:46:03,457 - INFO - training batch 301, loss: 1.325, 9632/28000 datapoints
2025-03-06 21:46:03,605 - INFO - training batch 351, loss: 1.216, 11232/28000 datapoints
2025-03-06 21:46:03,751 - INFO - training batch 401, loss: 1.279, 12832/28000 datapoints
2025-03-06 21:46:03,905 - INFO - training batch 451, loss: 1.172, 14432/28000 datapoints
2025-03-06 21:46:04,064 - INFO - training batch 501, loss: 1.124, 16032/28000 datapoints
2025-03-06 21:46:04,224 - INFO - training batch 551, loss: 1.333, 17632/28000 datapoints
2025-03-06 21:46:04,378 - INFO - training batch 601, loss: 1.325, 19232/28000 datapoints
2025-03-06 21:46:04,528 - INFO - training batch 651, loss: 0.859, 20832/28000 datapoints
2025-03-06 21:46:04,676 - INFO - training batch 701, loss: 0.999, 22432/28000 datapoints
2025-03-06 21:46:04,823 - INFO - training batch 751, loss: 1.342, 24032/28000 datapoints
2025-03-06 21:46:04,974 - INFO - training batch 801, loss: 0.948, 25632/28000 datapoints
2025-03-06 21:46:05,127 - INFO - training batch 851, loss: 1.300, 27232/28000 datapoints
2025-03-06 21:46:05,203 - INFO - validation batch 1, loss: 0.870, 32/6976 datapoints
2025-03-06 21:46:05,253 - INFO - validation batch 51, loss: 1.736, 1632/6976 datapoints
2025-03-06 21:46:05,305 - INFO - validation batch 101, loss: 1.113, 3232/6976 datapoints
2025-03-06 21:46:05,359 - INFO - validation batch 151, loss: 1.345, 4832/6976 datapoints
2025-03-06 21:46:05,411 - INFO - validation batch 201, loss: 0.765, 6432/6976 datapoints
2025-03-06 21:46:05,430 - INFO - Epoch 36/800 done.
2025-03-06 21:46:05,430 - INFO - Final validation performance:
Loss: 1.166, top-1 acc: 0.588top-5 acc: 0.588
2025-03-06 21:46:05,431 - INFO - Beginning epoch 37/800
2025-03-06 21:46:05,435 - INFO - training batch 1, loss: 1.364, 32/28000 datapoints
2025-03-06 21:46:05,590 - INFO - training batch 51, loss: 1.366, 1632/28000 datapoints
2025-03-06 21:46:05,750 - INFO - training batch 101, loss: 0.928, 3232/28000 datapoints
2025-03-06 21:46:05,903 - INFO - training batch 151, loss: 1.477, 4832/28000 datapoints
2025-03-06 21:46:06,053 - INFO - training batch 201, loss: 1.414, 6432/28000 datapoints
2025-03-06 21:46:06,202 - INFO - training batch 251, loss: 0.992, 8032/28000 datapoints
2025-03-06 21:46:06,366 - INFO - training batch 301, loss: 1.303, 9632/28000 datapoints
2025-03-06 21:46:06,515 - INFO - training batch 351, loss: 1.187, 11232/28000 datapoints
2025-03-06 21:46:06,666 - INFO - training batch 401, loss: 1.259, 12832/28000 datapoints
2025-03-06 21:46:06,819 - INFO - training batch 451, loss: 1.149, 14432/28000 datapoints
2025-03-06 21:46:06,973 - INFO - training batch 501, loss: 1.112, 16032/28000 datapoints
2025-03-06 21:46:07,123 - INFO - training batch 551, loss: 1.321, 17632/28000 datapoints
2025-03-06 21:46:07,271 - INFO - training batch 601, loss: 1.309, 19232/28000 datapoints
2025-03-06 21:46:07,422 - INFO - training batch 651, loss: 0.838, 20832/28000 datapoints
2025-03-06 21:46:07,574 - INFO - training batch 701, loss: 0.985, 22432/28000 datapoints
2025-03-06 21:46:07,721 - INFO - training batch 751, loss: 1.310, 24032/28000 datapoints
2025-03-06 21:46:07,875 - INFO - training batch 801, loss: 0.923, 25632/28000 datapoints
2025-03-06 21:46:08,023 - INFO - training batch 851, loss: 1.287, 27232/28000 datapoints
2025-03-06 21:46:08,100 - INFO - validation batch 1, loss: 0.854, 32/6976 datapoints
2025-03-06 21:46:08,158 - INFO - validation batch 51, loss: 1.737, 1632/6976 datapoints
2025-03-06 21:46:08,211 - INFO - validation batch 101, loss: 1.085, 3232/6976 datapoints
2025-03-06 21:46:08,265 - INFO - validation batch 151, loss: 1.316, 4832/6976 datapoints
2025-03-06 21:46:08,316 - INFO - validation batch 201, loss: 0.748, 6432/6976 datapoints
2025-03-06 21:46:08,337 - INFO - Epoch 37/800 done.
2025-03-06 21:46:08,337 - INFO - Final validation performance:
Loss: 1.148, top-1 acc: 0.598top-5 acc: 0.598
2025-03-06 21:46:08,337 - INFO - Beginning epoch 38/800
2025-03-06 21:46:08,341 - INFO - training batch 1, loss: 1.341, 32/28000 datapoints
2025-03-06 21:46:08,496 - INFO - training batch 51, loss: 1.340, 1632/28000 datapoints
2025-03-06 21:46:08,645 - INFO - training batch 101, loss: 0.905, 3232/28000 datapoints
2025-03-06 21:46:08,795 - INFO - training batch 151, loss: 1.461, 4832/28000 datapoints
2025-03-06 21:46:08,947 - INFO - training batch 201, loss: 1.393, 6432/28000 datapoints
2025-03-06 21:46:09,096 - INFO - training batch 251, loss: 0.964, 8032/28000 datapoints
2025-03-06 21:46:09,246 - INFO - training batch 301, loss: 1.279, 9632/28000 datapoints
2025-03-06 21:46:09,397 - INFO - training batch 351, loss: 1.157, 11232/28000 datapoints
2025-03-06 21:46:09,550 - INFO - training batch 401, loss: 1.238, 12832/28000 datapoints
2025-03-06 21:46:09,698 - INFO - training batch 451, loss: 1.125, 14432/28000 datapoints
2025-03-06 21:46:09,850 - INFO - training batch 501, loss: 1.100, 16032/28000 datapoints
2025-03-06 21:46:10,000 - INFO - training batch 551, loss: 1.310, 17632/28000 datapoints
2025-03-06 21:46:10,155 - INFO - training batch 601, loss: 1.292, 19232/28000 datapoints
2025-03-06 21:46:10,305 - INFO - training batch 651, loss: 0.817, 20832/28000 datapoints
2025-03-06 21:46:10,461 - INFO - training batch 701, loss: 0.971, 22432/28000 datapoints
2025-03-06 21:46:10,609 - INFO - training batch 751, loss: 1.276, 24032/28000 datapoints
2025-03-06 21:46:10,756 - INFO - training batch 801, loss: 0.897, 25632/28000 datapoints
2025-03-06 21:46:10,906 - INFO - training batch 851, loss: 1.274, 27232/28000 datapoints
2025-03-06 21:46:10,982 - INFO - validation batch 1, loss: 0.837, 32/6976 datapoints
2025-03-06 21:46:11,032 - INFO - validation batch 51, loss: 1.738, 1632/6976 datapoints
2025-03-06 21:46:11,084 - INFO - validation batch 101, loss: 1.056, 3232/6976 datapoints
2025-03-06 21:46:11,134 - INFO - validation batch 151, loss: 1.288, 4832/6976 datapoints
2025-03-06 21:46:11,186 - INFO - validation batch 201, loss: 0.732, 6432/6976 datapoints
2025-03-06 21:46:11,203 - INFO - Epoch 38/800 done.
2025-03-06 21:46:11,203 - INFO - Final validation performance:
Loss: 1.130, top-1 acc: 0.608top-5 acc: 0.608
2025-03-06 21:46:11,204 - INFO - Beginning epoch 39/800
2025-03-06 21:46:11,208 - INFO - training batch 1, loss: 1.317, 32/28000 datapoints
2025-03-06 21:46:11,358 - INFO - training batch 51, loss: 1.312, 1632/28000 datapoints
2025-03-06 21:46:11,531 - INFO - training batch 101, loss: 0.881, 3232/28000 datapoints
2025-03-06 21:46:11,707 - INFO - training batch 151, loss: 1.444, 4832/28000 datapoints
2025-03-06 21:46:11,860 - INFO - training batch 201, loss: 1.372, 6432/28000 datapoints
2025-03-06 21:46:12,011 - INFO - training batch 251, loss: 0.937, 8032/28000 datapoints
2025-03-06 21:46:12,160 - INFO - training batch 301, loss: 1.256, 9632/28000 datapoints
2025-03-06 21:46:12,314 - INFO - training batch 351, loss: 1.126, 11232/28000 datapoints
2025-03-06 21:46:12,465 - INFO - training batch 401, loss: 1.218, 12832/28000 datapoints
2025-03-06 21:46:12,613 - INFO - training batch 451, loss: 1.100, 14432/28000 datapoints
2025-03-06 21:46:12,764 - INFO - training batch 501, loss: 1.087, 16032/28000 datapoints
2025-03-06 21:46:12,925 - INFO - training batch 551, loss: 1.298, 17632/28000 datapoints
2025-03-06 21:46:13,075 - INFO - training batch 601, loss: 1.277, 19232/28000 datapoints
2025-03-06 21:46:13,222 - INFO - training batch 651, loss: 0.797, 20832/28000 datapoints
2025-03-06 21:46:13,370 - INFO - training batch 701, loss: 0.956, 22432/28000 datapoints
2025-03-06 21:46:13,523 - INFO - training batch 751, loss: 1.240, 24032/28000 datapoints
2025-03-06 21:46:13,670 - INFO - training batch 801, loss: 0.871, 25632/28000 datapoints
2025-03-06 21:46:13,818 - INFO - training batch 851, loss: 1.260, 27232/28000 datapoints
2025-03-06 21:46:13,897 - INFO - validation batch 1, loss: 0.819, 32/6976 datapoints
2025-03-06 21:46:13,949 - INFO - validation batch 51, loss: 1.740, 1632/6976 datapoints
2025-03-06 21:46:14,001 - INFO - validation batch 101, loss: 1.025, 3232/6976 datapoints
2025-03-06 21:46:14,054 - INFO - validation batch 151, loss: 1.259, 4832/6976 datapoints
2025-03-06 21:46:14,105 - INFO - validation batch 201, loss: 0.715, 6432/6976 datapoints
2025-03-06 21:46:14,127 - INFO - Epoch 39/800 done.
2025-03-06 21:46:14,127 - INFO - Final validation performance:
Loss: 1.112, top-1 acc: 0.617top-5 acc: 0.617
2025-03-06 21:46:14,128 - INFO - Beginning epoch 40/800
2025-03-06 21:46:14,134 - INFO - training batch 1, loss: 1.292, 32/28000 datapoints
2025-03-06 21:46:14,306 - INFO - training batch 51, loss: 1.284, 1632/28000 datapoints
2025-03-06 21:46:14,452 - INFO - training batch 101, loss: 0.855, 3232/28000 datapoints
2025-03-06 21:46:14,601 - INFO - training batch 151, loss: 1.427, 4832/28000 datapoints
2025-03-06 21:46:14,744 - INFO - training batch 201, loss: 1.351, 6432/28000 datapoints
2025-03-06 21:46:14,890 - INFO - training batch 251, loss: 0.910, 8032/28000 datapoints
2025-03-06 21:46:15,037 - INFO - training batch 301, loss: 1.233, 9632/28000 datapoints
2025-03-06 21:46:15,185 - INFO - training batch 351, loss: 1.094, 11232/28000 datapoints
2025-03-06 21:46:15,329 - INFO - training batch 401, loss: 1.197, 12832/28000 datapoints
2025-03-06 21:46:15,475 - INFO - training batch 451, loss: 1.076, 14432/28000 datapoints
2025-03-06 21:46:15,624 - INFO - training batch 501, loss: 1.074, 16032/28000 datapoints
2025-03-06 21:46:15,769 - INFO - training batch 551, loss: 1.286, 17632/28000 datapoints
2025-03-06 21:46:15,915 - INFO - training batch 601, loss: 1.263, 19232/28000 datapoints
2025-03-06 21:46:16,063 - INFO - training batch 651, loss: 0.776, 20832/28000 datapoints
2025-03-06 21:46:16,207 - INFO - training batch 701, loss: 0.941, 22432/28000 datapoints
2025-03-06 21:46:16,350 - INFO - training batch 751, loss: 1.202, 24032/28000 datapoints
2025-03-06 21:46:16,494 - INFO - training batch 801, loss: 0.845, 25632/28000 datapoints
2025-03-06 21:46:16,639 - INFO - training batch 851, loss: 1.246, 27232/28000 datapoints
2025-03-06 21:46:16,710 - INFO - validation batch 1, loss: 0.801, 32/6976 datapoints
2025-03-06 21:46:16,758 - INFO - validation batch 51, loss: 1.744, 1632/6976 datapoints
2025-03-06 21:46:16,805 - INFO - validation batch 101, loss: 0.995, 3232/6976 datapoints
2025-03-06 21:46:16,855 - INFO - validation batch 151, loss: 1.229, 4832/6976 datapoints
2025-03-06 21:46:16,902 - INFO - validation batch 201, loss: 0.698, 6432/6976 datapoints
2025-03-06 21:46:16,918 - INFO - Epoch 40/800 done.
2025-03-06 21:46:16,919 - INFO - Final validation performance:
Loss: 1.094, top-1 acc: 0.627top-5 acc: 0.627
2025-03-06 21:46:16,919 - INFO - Beginning epoch 41/800
2025-03-06 21:46:16,923 - INFO - training batch 1, loss: 1.268, 32/28000 datapoints
2025-03-06 21:46:17,073 - INFO - training batch 51, loss: 1.255, 1632/28000 datapoints
2025-03-06 21:46:17,220 - INFO - training batch 101, loss: 0.831, 3232/28000 datapoints
2025-03-06 21:46:17,363 - INFO - training batch 151, loss: 1.409, 4832/28000 datapoints
2025-03-06 21:46:17,508 - INFO - training batch 201, loss: 1.330, 6432/28000 datapoints
2025-03-06 21:46:17,665 - INFO - training batch 251, loss: 0.883, 8032/28000 datapoints
2025-03-06 21:46:17,821 - INFO - training batch 301, loss: 1.210, 9632/28000 datapoints
2025-03-06 21:46:17,975 - INFO - training batch 351, loss: 1.064, 11232/28000 datapoints
2025-03-06 21:46:18,121 - INFO - training batch 401, loss: 1.177, 12832/28000 datapoints
2025-03-06 21:46:18,271 - INFO - training batch 451, loss: 1.052, 14432/28000 datapoints
2025-03-06 21:46:18,426 - INFO - training batch 501, loss: 1.060, 16032/28000 datapoints
2025-03-06 21:46:18,577 - INFO - training batch 551, loss: 1.277, 17632/28000 datapoints
2025-03-06 21:46:18,726 - INFO - training batch 601, loss: 1.249, 19232/28000 datapoints
2025-03-06 21:46:18,873 - INFO - training batch 651, loss: 0.755, 20832/28000 datapoints
2025-03-06 21:46:19,017 - INFO - training batch 701, loss: 0.927, 22432/28000 datapoints
2025-03-06 21:46:19,162 - INFO - training batch 751, loss: 1.164, 24032/28000 datapoints
2025-03-06 21:46:19,304 - INFO - training batch 801, loss: 0.820, 25632/28000 datapoints
2025-03-06 21:46:19,449 - INFO - training batch 851, loss: 1.232, 27232/28000 datapoints
2025-03-06 21:46:19,522 - INFO - validation batch 1, loss: 0.781, 32/6976 datapoints
2025-03-06 21:46:19,573 - INFO - validation batch 51, loss: 1.749, 1632/6976 datapoints
2025-03-06 21:46:19,620 - INFO - validation batch 101, loss: 0.965, 3232/6976 datapoints
2025-03-06 21:46:19,667 - INFO - validation batch 151, loss: 1.201, 4832/6976 datapoints
2025-03-06 21:46:19,713 - INFO - validation batch 201, loss: 0.682, 6432/6976 datapoints
2025-03-06 21:46:19,729 - INFO - Epoch 41/800 done.
2025-03-06 21:46:19,729 - INFO - Final validation performance:
Loss: 1.076, top-1 acc: 0.638top-5 acc: 0.638
2025-03-06 21:46:19,730 - INFO - Beginning epoch 42/800
2025-03-06 21:46:19,734 - INFO - training batch 1, loss: 1.241, 32/28000 datapoints
2025-03-06 21:46:19,886 - INFO - training batch 51, loss: 1.225, 1632/28000 datapoints
2025-03-06 21:46:20,031 - INFO - training batch 101, loss: 0.806, 3232/28000 datapoints
2025-03-06 21:46:20,179 - INFO - training batch 151, loss: 1.391, 4832/28000 datapoints
2025-03-06 21:46:20,325 - INFO - training batch 201, loss: 1.306, 6432/28000 datapoints
2025-03-06 21:46:20,470 - INFO - training batch 251, loss: 0.858, 8032/28000 datapoints
2025-03-06 21:46:20,615 - INFO - training batch 301, loss: 1.189, 9632/28000 datapoints
2025-03-06 21:46:20,758 - INFO - training batch 351, loss: 1.035, 11232/28000 datapoints
2025-03-06 21:46:20,905 - INFO - training batch 401, loss: 1.159, 12832/28000 datapoints
2025-03-06 21:46:21,636 - INFO - training batch 651, loss: 0.735, 20832/28000 datapoints
2025-03-06 21:46:21,785 - INFO - training batch 701, loss: 0.912, 22432/28000 datapoints
2025-03-06 21:46:21,932 - INFO - training batch 751, loss: 1.127, 24032/28000 datapoints
2025-03-06 21:46:22,076 - INFO - training batch 801, loss: 0.795, 25632/28000 datapoints
2025-03-06 21:46:22,220 - INFO - training batch 851, loss: 1.217, 27232/28000 datapoints
2025-03-06 21:46:22,291 - INFO - validation batch 1, loss: 0.763, 32/6976 datapoints
2025-03-06 21:46:22,338 - INFO - validation batch 51, loss: 1.753, 1632/6976 datapoints
2025-03-06 21:46:22,385 - INFO - validation batch 101, loss: 0.934, 3232/6976 datapoints
2025-03-06 21:46:22,431 - INFO - validation batch 151, loss: 1.175, 4832/6976 datapoints
2025-03-06 21:46:22,478 - INFO - validation batch 201, loss: 0.665, 6432/6976 datapoints
2025-03-06 21:46:22,494 - INFO - Epoch 42/800 done.
2025-03-06 21:46:22,494 - INFO - Final validation performance:
Loss: 1.058, top-1 acc: 0.649top-5 acc: 0.649
2025-03-06 21:46:22,494 - INFO - Beginning epoch 43/800
2025-03-06 21:46:22,498 - INFO - training batch 1, loss: 1.215, 32/28000 datapoints
2025-03-06 21:46:22,647 - INFO - training batch 51, loss: 1.195, 1632/28000 datapoints
2025-03-06 21:46:22,790 - INFO - training batch 101, loss: 0.780, 3232/28000 datapoints
2025-03-06 21:46:22,939 - INFO - training batch 151, loss: 1.375, 4832/28000 datapoints
2025-03-06 21:46:23,085 - INFO - training batch 201, loss: 1.279, 6432/28000 datapoints
2025-03-06 21:46:23,229 - INFO - training batch 251, loss: 0.833, 8032/28000 datapoints
2025-03-06 21:46:23,373 - INFO - training batch 301, loss: 1.167, 9632/28000 datapoints
2025-03-06 21:46:23,519 - INFO - training batch 351, loss: 1.005, 11232/28000 datapoints
2025-03-06 21:46:23,668 - INFO - training batch 401, loss: 1.142, 12832/28000 datapoints
2025-03-06 21:46:23,817 - INFO - training batch 451, loss: 1.004, 14432/28000 datapoints
2025-03-06 21:46:23,982 - INFO - training batch 501, loss: 1.029, 16032/28000 datapoints
2025-03-06 21:46:24,132 - INFO - training batch 551, loss: 1.258, 17632/28000 datapoints
2025-03-06 21:46:24,304 - INFO - training batch 601, loss: 1.225, 19232/28000 datapoints
2025-03-06 21:46:24,456 - INFO - training batch 651, loss: 0.716, 20832/28000 datapoints
2025-03-06 21:46:24,614 - INFO - training batch 701, loss: 0.897, 22432/28000 datapoints
2025-03-06 21:46:24,767 - INFO - training batch 751, loss: 1.088, 24032/28000 datapoints
2025-03-06 21:46:24,914 - INFO - training batch 801, loss: 0.771, 25632/28000 datapoints
2025-03-06 21:46:25,066 - INFO - training batch 851, loss: 1.204, 27232/28000 datapoints
2025-03-06 21:46:25,146 - INFO - validation batch 1, loss: 0.745, 32/6976 datapoints
2025-03-06 21:46:25,197 - INFO - validation batch 51, loss: 1.758, 1632/6976 datapoints
2025-03-06 21:46:25,247 - INFO - validation batch 101, loss: 0.905, 3232/6976 datapoints
2025-03-06 21:46:25,307 - INFO - validation batch 151, loss: 1.149, 4832/6976 datapoints
2025-03-06 21:46:25,359 - INFO - validation batch 201, loss: 0.649, 6432/6976 datapoints
2025-03-06 21:46:25,377 - INFO - Epoch 43/800 done.
2025-03-06 21:46:25,377 - INFO - Final validation performance:
Loss: 1.041, top-1 acc: 0.659top-5 acc: 0.659
2025-03-06 21:46:25,459 - INFO - Beginning epoch 44/800
2025-03-06 21:46:25,463 - INFO - training batch 1, loss: 1.188, 32/28000 datapoints
2025-03-06 21:46:25,612 - INFO - training batch 51, loss: 1.166, 1632/28000 datapoints
2025-03-06 21:46:25,760 - INFO - training batch 101, loss: 0.755, 3232/28000 datapoints
2025-03-06 21:46:25,910 - INFO - training batch 151, loss: 1.358, 4832/28000 datapoints
2025-03-06 21:46:26,059 - INFO - training batch 201, loss: 1.249, 6432/28000 datapoints
2025-03-06 21:46:26,205 - INFO - training batch 251, loss: 0.811, 8032/28000 datapoints
2025-03-06 21:46:26,353 - INFO - training batch 301, loss: 1.146, 9632/28000 datapoints
2025-03-06 21:46:26,500 - INFO - training batch 351, loss: 0.975, 11232/28000 datapoints
2025-03-06 21:46:26,645 - INFO - training batch 401, loss: 1.127, 12832/28000 datapoints
2025-03-06 21:46:26,787 - INFO - training batch 451, loss: 0.983, 14432/28000 datapoints
2025-03-06 21:46:26,932 - INFO - training batch 501, loss: 1.013, 16032/28000 datapoints
2025-03-06 21:46:27,076 - INFO - training batch 551, loss: 1.251, 17632/28000 datapoints
2025-03-06 21:46:27,221 - INFO - training batch 601, loss: 1.214, 19232/28000 datapoints
2025-03-06 21:46:27,365 - INFO - training batch 651, loss: 0.697, 20832/28000 datapoints
2025-03-06 21:46:27,511 - INFO - training batch 701, loss: 0.883, 22432/28000 datapoints
2025-03-06 21:46:27,659 - INFO - training batch 751, loss: 1.049, 24032/28000 datapoints
2025-03-06 21:46:27,801 - INFO - training batch 801, loss: 0.748, 25632/28000 datapoints
2025-03-06 21:46:27,948 - INFO - training batch 851, loss: 1.192, 27232/28000 datapoints
2025-03-06 21:46:28,019 - INFO - validation batch 1, loss: 0.728, 32/6976 datapoints
2025-03-06 21:46:28,066 - INFO - validation batch 51, loss: 1.762, 1632/6976 datapoints
2025-03-06 21:46:28,113 - INFO - validation batch 101, loss: 0.876, 3232/6976 datapoints
2025-03-06 21:46:28,161 - INFO - validation batch 151, loss: 1.124, 4832/6976 datapoints
2025-03-06 21:46:28,208 - INFO - validation batch 201, loss: 0.634, 6432/6976 datapoints
2025-03-06 21:46:28,224 - INFO - Epoch 44/800 done.
2025-03-06 21:46:28,225 - INFO - Final validation performance:
Loss: 1.025, top-1 acc: 0.668top-5 acc: 0.668
2025-03-06 21:46:28,225 - INFO - Beginning epoch 45/800
2025-03-06 21:46:28,229 - INFO - training batch 1, loss: 1.162, 32/28000 datapoints
2025-03-06 21:46:28,395 - INFO - training batch 51, loss: 1.139, 1632/28000 datapoints
2025-03-06 21:46:28,548 - INFO - training batch 101, loss: 0.731, 3232/28000 datapoints
2025-03-06 21:46:28,696 - INFO - training batch 151, loss: 1.341, 4832/28000 datapoints
2025-03-06 21:46:28,843 - INFO - training batch 201, loss: 1.218, 6432/28000 datapoints
2025-03-06 21:46:28,986 - INFO - training batch 251, loss: 0.789, 8032/28000 datapoints
2025-03-06 21:46:29,154 - INFO - training batch 301, loss: 1.125, 9632/28000 datapoints
2025-03-06 21:46:29,300 - INFO - training batch 351, loss: 0.944, 11232/28000 datapoints
2025-03-06 21:46:29,444 - INFO - training batch 401, loss: 1.114, 12832/28000 datapoints
2025-03-06 21:46:29,598 - INFO - training batch 451, loss: 0.964, 14432/28000 datapoints
2025-03-06 21:46:29,744 - INFO - training batch 501, loss: 0.998, 16032/28000 datapoints
2025-03-06 21:46:29,891 - INFO - training batch 551, loss: 1.244, 17632/28000 datapoints
2025-03-06 21:46:30,050 - INFO - training batch 601, loss: 1.205, 19232/28000 datapoints
2025-03-06 21:46:30,196 - INFO - training batch 651, loss: 0.679, 20832/28000 datapoints
2025-03-06 21:46:30,340 - INFO - training batch 701, loss: 0.868, 22432/28000 datapoints
2025-03-06 21:46:30,485 - INFO - training batch 751, loss: 1.011, 24032/28000 datapoints
2025-03-06 21:46:30,635 - INFO - training batch 801, loss: 0.725, 25632/28000 datapoints
2025-03-06 21:46:30,784 - INFO - training batch 851, loss: 1.179, 27232/28000 datapoints
2025-03-06 21:46:30,859 - INFO - validation batch 1, loss: 0.712, 32/6976 datapoints
2025-03-06 21:46:30,906 - INFO - validation batch 51, loss: 1.765, 1632/6976 datapoints
2025-03-06 21:46:30,952 - INFO - validation batch 101, loss: 0.849, 3232/6976 datapoints
2025-03-06 21:46:31,000 - INFO - validation batch 151, loss: 1.100, 4832/6976 datapoints
2025-03-06 21:46:31,053 - INFO - validation batch 201, loss: 0.619, 6432/6976 datapoints
2025-03-06 21:46:31,070 - INFO - Epoch 45/800 done.
2025-03-06 21:46:31,070 - INFO - Final validation performance:
Loss: 1.009, top-1 acc: 0.678top-5 acc: 0.678
2025-03-06 21:46:31,070 - INFO - Beginning epoch 46/800
2025-03-06 21:46:31,074 - INFO - training batch 1, loss: 1.135, 32/28000 datapoints
2025-03-06 21:46:31,223 - INFO - training batch 51, loss: 1.111, 1632/28000 datapoints
2025-03-06 21:46:31,369 - INFO - training batch 101, loss: 0.707, 3232/28000 datapoints
2025-03-06 21:46:31,515 - INFO - training batch 151, loss: 1.325, 4832/28000 datapoints
2025-03-06 21:46:31,665 - INFO - training batch 201, loss: 1.185, 6432/28000 datapoints
2025-03-06 21:46:31,815 - INFO - training batch 251, loss: 0.769, 8032/28000 datapoints
2025-03-06 21:46:31,962 - INFO - training batch 301, loss: 1.105, 9632/28000 datapoints
2025-03-06 21:46:32,107 - INFO - training batch 351, loss: 0.914, 11232/28000 datapoints
2025-03-06 21:46:32,253 - INFO - training batch 401, loss: 1.104, 12832/28000 datapoints
2025-03-06 21:46:32,396 - INFO - training batch 451, loss: 0.946, 14432/28000 datapoints
2025-03-06 21:46:32,539 - INFO - training batch 501, loss: 0.981, 16032/28000 datapoints
2025-03-06 21:46:32,685 - INFO - training batch 551, loss: 1.239, 17632/28000 datapoints
2025-03-06 21:46:32,831 - INFO - training batch 601, loss: 1.198, 19232/28000 datapoints
2025-03-06 21:46:32,979 - INFO - training batch 651, loss: 0.661, 20832/28000 datapoints
2025-03-06 21:46:33,122 - INFO - training batch 701, loss: 0.853, 22432/28000 datapoints
2025-03-06 21:46:33,267 - INFO - training batch 751, loss: 0.974, 24032/28000 datapoints
2025-03-06 21:46:33,411 - INFO - training batch 801, loss: 0.704, 25632/28000 datapoints
2025-03-06 21:46:33,556 - INFO - training batch 851, loss: 1.167, 27232/28000 datapoints
2025-03-06 21:46:33,631 - INFO - validation batch 1, loss: 0.696, 32/6976 datapoints
2025-03-06 21:46:33,679 - INFO - validation batch 51, loss: 1.768, 1632/6976 datapoints
2025-03-06 21:46:33,728 - INFO - validation batch 101, loss: 0.824, 3232/6976 datapoints
2025-03-06 21:46:33,775 - INFO - validation batch 151, loss: 1.077, 4832/6976 datapoints
2025-03-06 21:46:33,823 - INFO - validation batch 201, loss: 0.607, 6432/6976 datapoints
2025-03-06 21:46:33,842 - INFO - Epoch 46/800 done.
2025-03-06 21:46:33,842 - INFO - Final validation performance:
Loss: 0.994, top-1 acc: 0.686top-5 acc: 0.686
2025-03-06 21:46:33,843 - INFO - Beginning epoch 47/800
2025-03-06 21:46:33,847 - INFO - training batch 1, loss: 1.109, 32/28000 datapoints
2025-03-06 21:46:33,998 - INFO - training batch 51, loss: 1.085, 1632/28000 datapoints
2025-03-06 21:46:34,145 - INFO - training batch 101, loss: 0.683, 3232/28000 datapoints
2025-03-06 21:46:34,295 - INFO - training batch 151, loss: 1.309, 4832/28000 datapoints
2025-03-06 21:46:34,460 - INFO - training batch 201, loss: 1.151, 6432/28000 datapoints
2025-03-06 21:46:34,606 - INFO - training batch 251, loss: 0.751, 8032/28000 datapoints
2025-03-06 21:46:34,751 - INFO - training batch 301, loss: 1.086, 9632/28000 datapoints
2025-03-06 21:46:34,897 - INFO - training batch 351, loss: 0.885, 11232/28000 datapoints
2025-03-06 21:46:35,043 - INFO - training batch 401, loss: 1.097, 12832/28000 datapoints
2025-03-06 21:46:35,193 - INFO - training batch 451, loss: 0.931, 14432/28000 datapoints
2025-03-06 21:46:35,339 - INFO - training batch 501, loss: 0.965, 16032/28000 datapoints
2025-03-06 21:46:35,484 - INFO - training batch 551, loss: 1.236, 17632/28000 datapoints
2025-03-06 21:46:35,632 - INFO - training batch 601, loss: 1.192, 19232/28000 datapoints
2025-03-06 21:46:35,778 - INFO - training batch 651, loss: 0.643, 20832/28000 datapoints
2025-03-06 21:46:35,925 - INFO - training batch 701, loss: 0.839, 22432/28000 datapoints
2025-03-06 21:46:36,081 - INFO - training batch 751, loss: 0.938, 24032/28000 datapoints
2025-03-06 21:46:36,234 - INFO - training batch 801, loss: 0.684, 25632/28000 datapoints
2025-03-06 21:46:36,380 - INFO - training batch 851, loss: 1.155, 27232/28000 datapoints
2025-03-06 21:46:36,451 - INFO - validation batch 1, loss: 0.681, 32/6976 datapoints
2025-03-06 21:46:36,498 - INFO - validation batch 51, loss: 1.770, 1632/6976 datapoints
2025-03-06 21:46:36,546 - INFO - validation batch 101, loss: 0.801, 3232/6976 datapoints
2025-03-06 21:46:36,599 - INFO - validation batch 151, loss: 1.055, 4832/6976 datapoints
2025-03-06 21:46:36,649 - INFO - validation batch 201, loss: 0.596, 6432/6976 datapoints
2025-03-06 21:46:36,665 - INFO - Epoch 47/800 done.
2025-03-06 21:46:36,665 - INFO - Final validation performance:
Loss: 0.981, top-1 acc: 0.693top-5 acc: 0.693
2025-03-06 21:46:36,666 - INFO - Beginning epoch 48/800
2025-03-06 21:46:36,670 - INFO - training batch 1, loss: 1.083, 32/28000 datapoints
2025-03-06 21:46:36,822 - INFO - training batch 51, loss: 1.060, 1632/28000 datapoints
2025-03-06 21:46:36,967 - INFO - training batch 101, loss: 0.660, 3232/28000 datapoints
2025-03-06 21:46:37,112 - INFO - training batch 151, loss: 1.293, 4832/28000 datapoints
2025-03-06 21:46:37,254 - INFO - training batch 201, loss: 1.115, 6432/28000 datapoints
2025-03-06 21:46:37,399 - INFO - training batch 251, loss: 0.733, 8032/28000 datapoints
2025-03-06 21:46:37,543 - INFO - training batch 301, loss: 1.068, 9632/28000 datapoints
2025-03-06 21:46:37,690 - INFO - training batch 351, loss: 0.858, 11232/28000 datapoints
2025-03-06 21:46:37,849 - INFO - training batch 401, loss: 1.093, 12832/28000 datapoints
2025-03-06 21:46:37,995 - INFO - training batch 451, loss: 0.917, 14432/28000 datapoints
2025-03-06 21:46:38,139 - INFO - training batch 501, loss: 0.949, 16032/28000 datapoints
2025-03-06 21:46:38,287 - INFO - training batch 551, loss: 1.233, 17632/28000 datapoints
2025-03-06 21:46:38,432 - INFO - training batch 601, loss: 1.186, 19232/28000 datapoints
2025-03-06 21:46:38,576 - INFO - training batch 651, loss: 0.628, 20832/28000 datapoints
2025-03-06 21:46:38,721 - INFO - training batch 701, loss: 0.824, 22432/28000 datapoints
2025-03-06 21:46:38,868 - INFO - training batch 751, loss: 0.904, 24032/28000 datapoints
2025-03-06 21:46:39,011 - INFO - training batch 801, loss: 0.666, 25632/28000 datapoints
2025-03-06 21:46:39,155 - INFO - training batch 851, loss: 1.143, 27232/28000 datapoints
2025-03-06 21:46:39,228 - INFO - validation batch 1, loss: 0.667, 32/6976 datapoints
2025-03-06 21:46:39,279 - INFO - validation batch 51, loss: 1.771, 1632/6976 datapoints
2025-03-06 21:46:39,329 - INFO - validation batch 101, loss: 0.779, 3232/6976 datapoints
2025-03-06 21:46:39,376 - INFO - validation batch 151, loss: 1.035, 4832/6976 datapoints
2025-03-06 21:46:39,423 - INFO - validation batch 201, loss: 0.587, 6432/6976 datapoints
2025-03-06 21:46:39,439 - INFO - Epoch 48/800 done.
2025-03-06 21:46:39,439 - INFO - Final validation performance:
Loss: 0.968, top-1 acc: 0.701top-5 acc: 0.701
2025-03-06 21:46:39,440 - INFO - Beginning epoch 49/800
2025-03-06 21:46:39,444 - INFO - training batch 1, loss: 1.058, 32/28000 datapoints
2025-03-06 21:46:39,592 - INFO - training batch 51, loss: 1.036, 1632/28000 datapoints
2025-03-06 21:46:39,740 - INFO - training batch 101, loss: 0.637, 3232/28000 datapoints
2025-03-06 21:46:39,889 - INFO - training batch 151, loss: 1.278, 4832/28000 datapoints
2025-03-06 21:46:40,033 - INFO - training batch 201, loss: 1.076, 6432/28000 datapoints
2025-03-06 21:46:40,182 - INFO - training batch 251, loss: 0.717, 8032/28000 datapoints
2025-03-06 21:46:40,333 - INFO - training batch 301, loss: 1.051, 9632/28000 datapoints
2025-03-06 21:46:40,486 - INFO - training batch 351, loss: 0.833, 11232/28000 datapoints
2025-03-06 21:46:40,636 - INFO - training batch 401, loss: 1.090, 12832/28000 datapoints
2025-03-06 21:46:40,782 - INFO - training batch 451, loss: 0.905, 14432/28000 datapoints
2025-03-06 21:46:40,930 - INFO - training batch 501, loss: 0.933, 16032/28000 datapoints
2025-03-06 21:46:41,073 - INFO - training batch 551, loss: 1.229, 17632/28000 datapoints
2025-03-06 21:46:41,217 - INFO - training batch 601, loss: 1.182, 19232/28000 datapoints
2025-03-06 21:46:41,362 - INFO - training batch 651, loss: 0.613, 20832/28000 datapoints
2025-03-06 21:46:41,507 - INFO - training batch 701, loss: 0.810, 22432/28000 datapoints
2025-03-06 21:46:41,657 - INFO - training batch 751, loss: 0.872, 24032/28000 datapoints
2025-03-06 21:46:41,806 - INFO - training batch 801, loss: 0.649, 25632/28000 datapoints
2025-03-06 21:46:41,953 - INFO - training batch 851, loss: 1.131, 27232/28000 datapoints
2025-03-06 21:46:42,023 - INFO - validation batch 1, loss: 0.653, 32/6976 datapoints
2025-03-06 21:46:42,070 - INFO - validation batch 51, loss: 1.773, 1632/6976 datapoints
2025-03-06 21:46:42,117 - INFO - validation batch 101, loss: 0.759, 3232/6976 datapoints
2025-03-06 21:46:42,164 - INFO - validation batch 151, loss: 1.014, 4832/6976 datapoints
2025-03-06 21:46:42,212 - INFO - validation batch 201, loss: 0.580, 6432/6976 datapoints
2025-03-06 21:46:42,228 - INFO - Epoch 49/800 done.
2025-03-06 21:46:42,228 - INFO - Final validation performance:
Loss: 0.956, top-1 acc: 0.707top-5 acc: 0.707
2025-03-06 21:46:42,228 - INFO - Beginning epoch 50/800
2025-03-06 21:46:42,233 - INFO - training batch 1, loss: 1.033, 32/28000 datapoints
2025-03-06 21:46:42,393 - INFO - training batch 51, loss: 1.012, 1632/28000 datapoints
2025-03-06 21:46:42,538 - INFO - training batch 101, loss: 0.617, 3232/28000 datapoints
2025-03-06 21:46:42,684 - INFO - training batch 151, loss: 1.263, 4832/28000 datapoints
2025-03-06 21:46:42,839 - INFO - training batch 201, loss: 1.037, 6432/28000 datapoints
2025-03-06 21:46:42,986 - INFO - training batch 251, loss: 0.702, 8032/28000 datapoints
2025-03-06 21:46:43,134 - INFO - training batch 301, loss: 1.035, 9632/28000 datapoints
2025-03-06 21:46:43,283 - INFO - training batch 351, loss: 0.807, 11232/28000 datapoints
2025-03-06 21:46:43,426 - INFO - training batch 401, loss: 1.090, 12832/28000 datapoints
2025-03-06 21:46:43,569 - INFO - training batch 451, loss: 0.895, 14432/28000 datapoints
2025-03-06 21:46:43,716 - INFO - training batch 501, loss: 0.917, 16032/28000 datapoints
2025-03-06 21:46:43,864 - INFO - training batch 551, loss: 1.224, 17632/28000 datapoints
2025-03-06 21:46:44,015 - INFO - training batch 601, loss: 1.179, 19232/28000 datapoints
2025-03-06 21:46:44,163 - INFO - training batch 651, loss: 0.599, 20832/28000 datapoints
2025-03-06 21:46:44,310 - INFO - training batch 701, loss: 0.796, 22432/28000 datapoints
2025-03-06 21:46:44,486 - INFO - training batch 751, loss: 0.844, 24032/28000 datapoints
2025-03-06 21:46:44,636 - INFO - training batch 801, loss: 0.633, 25632/28000 datapoints
2025-03-06 21:46:44,800 - INFO - training batch 851, loss: 1.119, 27232/28000 datapoints
2025-03-06 21:46:44,879 - INFO - validation batch 1, loss: 0.640, 32/6976 datapoints
2025-03-06 21:46:44,931 - INFO - validation batch 51, loss: 1.774, 1632/6976 datapoints
2025-03-06 21:46:44,985 - INFO - validation batch 101, loss: 0.740, 3232/6976 datapoints
2025-03-06 21:46:45,039 - INFO - validation batch 151, loss: 0.994, 4832/6976 datapoints
2025-03-06 21:46:45,092 - INFO - validation batch 201, loss: 0.574, 6432/6976 datapoints
2025-03-06 21:46:45,115 - INFO - Epoch 50/800 done.
2025-03-06 21:46:45,116 - INFO - Final validation performance:
Loss: 0.944, top-1 acc: 0.712top-5 acc: 0.712
2025-03-06 21:46:45,116 - INFO - Beginning epoch 51/800
2025-03-06 21:46:45,122 - INFO - training batch 1, loss: 1.009, 32/28000 datapoints
2025-03-06 21:46:45,272 - INFO - training batch 51, loss: 0.990, 1632/28000 datapoints
2025-03-06 21:46:45,420 - INFO - training batch 101, loss: 0.596, 3232/28000 datapoints
2025-03-06 21:46:45,565 - INFO - training batch 151, loss: 1.248, 4832/28000 datapoints
2025-03-06 21:46:45,715 - INFO - training batch 201, loss: 0.999, 6432/28000 datapoints
2025-03-06 21:46:45,863 - INFO - training batch 251, loss: 0.687, 8032/28000 datapoints
2025-03-06 21:46:46,009 - INFO - training batch 301, loss: 1.021, 9632/28000 datapoints
2025-03-06 21:46:46,152 - INFO - training batch 351, loss: 0.783, 11232/28000 datapoints
2025-03-06 21:46:46,299 - INFO - training batch 401, loss: 1.090, 12832/28000 datapoints
2025-03-06 21:46:46,444 - INFO - training batch 451, loss: 0.884, 14432/28000 datapoints
2025-03-06 21:46:46,589 - INFO - training batch 501, loss: 0.901, 16032/28000 datapoints
2025-03-06 21:46:46,735 - INFO - training batch 551, loss: 1.222, 17632/28000 datapoints
2025-03-06 21:46:46,883 - INFO - training batch 601, loss: 1.175, 19232/28000 datapoints
2025-03-06 21:46:47,028 - INFO - training batch 651, loss: 0.587, 20832/28000 datapoints
2025-03-06 21:46:47,172 - INFO - training batch 701, loss: 0.782, 22432/28000 datapoints
2025-03-06 21:46:47,317 - INFO - training batch 751, loss: 0.819, 24032/28000 datapoints
2025-03-06 21:46:47,462 - INFO - training batch 801, loss: 0.618, 25632/28000 datapoints
2025-03-06 21:46:47,607 - INFO - training batch 851, loss: 1.109, 27232/28000 datapoints
2025-03-06 21:46:47,681 - INFO - validation batch 1, loss: 0.626, 32/6976 datapoints
2025-03-06 21:46:47,728 - INFO - validation batch 51, loss: 1.774, 1632/6976 datapoints
2025-03-06 21:46:47,775 - INFO - validation batch 101, loss: 0.722, 3232/6976 datapoints
2025-03-06 21:46:47,823 - INFO - validation batch 151, loss: 0.975, 4832/6976 datapoints
2025-03-06 21:46:47,873 - INFO - validation batch 201, loss: 0.569, 6432/6976 datapoints
2025-03-06 21:46:47,889 - INFO - Epoch 51/800 done.
2025-03-06 21:46:47,889 - INFO - Final validation performance:
Loss: 0.933, top-1 acc: 0.720top-5 acc: 0.720
2025-03-06 21:46:47,890 - INFO - Beginning epoch 52/800
2025-03-06 21:46:47,894 - INFO - training batch 1, loss: 0.986, 32/28000 datapoints
2025-03-06 21:46:48,042 - INFO - training batch 51, loss: 0.970, 1632/28000 datapoints
2025-03-06 21:46:48,187 - INFO - training batch 101, loss: 0.578, 3232/28000 datapoints
2025-03-06 21:46:48,342 - INFO - training batch 151, loss: 1.234, 4832/28000 datapoints
2025-03-06 21:46:48,495 - INFO - training batch 201, loss: 0.963, 6432/28000 datapoints
2025-03-06 21:46:48,640 - INFO - training batch 251, loss: 0.674, 8032/28000 datapoints
2025-03-06 21:46:48,791 - INFO - training batch 301, loss: 1.008, 9632/28000 datapoints
2025-03-06 21:46:48,945 - INFO - training batch 351, loss: 0.758, 11232/28000 datapoints
2025-03-06 21:46:49,089 - INFO - training batch 401, loss: 1.089, 12832/28000 datapoints
2025-03-06 21:46:49,237 - INFO - training batch 451, loss: 0.874, 14432/28000 datapoints
2025-03-06 21:46:49,380 - INFO - training batch 501, loss: 0.884, 16032/28000 datapoints
2025-03-06 21:46:49,527 - INFO - training batch 551, loss: 1.218, 17632/28000 datapoints
2025-03-06 21:46:49,678 - INFO - training batch 601, loss: 1.172, 19232/28000 datapoints
2025-03-06 21:46:49,830 - INFO - training batch 651, loss: 0.575, 20832/28000 datapoints
2025-03-06 21:46:49,985 - INFO - training batch 701, loss: 0.770, 22432/28000 datapoints
2025-03-06 21:46:50,132 - INFO - training batch 751, loss: 0.796, 24032/28000 datapoints
2025-03-06 21:46:50,280 - INFO - training batch 801, loss: 0.605, 25632/28000 datapoints
2025-03-06 21:46:50,424 - INFO - training batch 851, loss: 1.098, 27232/28000 datapoints
2025-03-06 21:46:50,495 - INFO - validation batch 1, loss: 0.614, 32/6976 datapoints
2025-03-06 21:46:50,543 - INFO - validation batch 51, loss: 1.771, 1632/6976 datapoints
2025-03-06 21:46:50,589 - INFO - validation batch 101, loss: 0.705, 3232/6976 datapoints
2025-03-06 21:46:50,636 - INFO - validation batch 151, loss: 0.958, 4832/6976 datapoints
2025-03-06 21:46:50,685 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:46:50,701 - INFO - Epoch 52/800 done.
2025-03-06 21:46:50,702 - INFO - Final validation performance:
Loss: 0.923, top-1 acc: 0.725top-5 acc: 0.725
2025-03-06 21:46:50,702 - INFO - Beginning epoch 53/800
2025-03-06 21:46:50,706 - INFO - training batch 1, loss: 0.965, 32/28000 datapoints
2025-03-06 21:46:50,857 - INFO - training batch 51, loss: 0.952, 1632/28000 datapoints
2025-03-06 21:46:51,004 - INFO - training batch 101, loss: 0.560, 3232/28000 datapoints
2025-03-06 21:46:51,149 - INFO - training batch 151, loss: 1.220, 4832/28000 datapoints
2025-03-06 21:46:51,295 - INFO - training batch 201, loss: 0.927, 6432/28000 datapoints
2025-03-06 21:46:51,441 - INFO - training batch 251, loss: 0.662, 8032/28000 datapoints
2025-03-06 21:46:51,586 - INFO - training batch 301, loss: 0.995, 9632/28000 datapoints
2025-03-06 21:46:51,737 - INFO - training batch 351, loss: 0.736, 11232/28000 datapoints
2025-03-06 21:46:51,891 - INFO - training batch 401, loss: 1.089, 12832/28000 datapoints
2025-03-06 21:46:52,037 - INFO - training batch 451, loss: 0.864, 14432/28000 datapoints
2025-03-06 21:46:52,182 - INFO - training batch 501, loss: 0.867, 16032/28000 datapoints
2025-03-06 21:46:52,327 - INFO - training batch 551, loss: 1.214, 17632/28000 datapoints
2025-03-06 21:46:52,473 - INFO - training batch 601, loss: 1.170, 19232/28000 datapoints
2025-03-06 21:46:52,617 - INFO - training batch 651, loss: 0.565, 20832/28000 datapoints
2025-03-06 21:46:52,761 - INFO - training batch 701, loss: 0.759, 22432/28000 datapoints
2025-03-06 21:46:52,908 - INFO - training batch 751, loss: 0.775, 24032/28000 datapoints
2025-03-06 21:46:53,057 - INFO - training batch 801, loss: 0.592, 25632/28000 datapoints
2025-03-06 21:46:53,202 - INFO - training batch 851, loss: 1.088, 27232/28000 datapoints
2025-03-06 21:46:53,274 - INFO - validation batch 1, loss: 0.603, 32/6976 datapoints
2025-03-06 21:46:53,321 - INFO - validation batch 51, loss: 1.767, 1632/6976 datapoints
2025-03-06 21:46:53,368 - INFO - validation batch 101, loss: 0.689, 3232/6976 datapoints
2025-03-06 21:46:53,415 - INFO - validation batch 151, loss: 0.942, 4832/6976 datapoints
2025-03-06 21:46:53,464 - INFO - validation batch 201, loss: 0.563, 6432/6976 datapoints
2025-03-06 21:46:53,482 - INFO - Epoch 53/800 done.
2025-03-06 21:46:53,482 - INFO - Final validation performance:
Loss: 0.913, top-1 acc: 0.729top-5 acc: 0.729
2025-03-06 21:46:53,483 - INFO - Beginning epoch 54/800
2025-03-06 21:46:53,487 - INFO - training batch 1, loss: 0.945, 32/28000 datapoints
2025-03-06 21:46:53,634 - INFO - training batch 51, loss: 0.933, 1632/28000 datapoints
2025-03-06 21:46:53,783 - INFO - training batch 101, loss: 0.544, 3232/28000 datapoints
2025-03-06 21:46:53,931 - INFO - training batch 151, loss: 1.207, 4832/28000 datapoints
2025-03-06 21:46:54,078 - INFO - training batch 201, loss: 0.896, 6432/28000 datapoints
2025-03-06 21:46:54,224 - INFO - training batch 251, loss: 0.651, 8032/28000 datapoints
2025-03-06 21:46:54,368 - INFO - training batch 301, loss: 0.983, 9632/28000 datapoints
2025-03-06 21:46:54,546 - INFO - training batch 351, loss: 0.715, 11232/28000 datapoints
2025-03-06 21:46:54,698 - INFO - training batch 401, loss: 1.090, 12832/28000 datapoints
2025-03-06 21:46:54,846 - INFO - training batch 451, loss: 0.855, 14432/28000 datapoints
2025-03-06 21:46:55,006 - INFO - training batch 501, loss: 0.851, 16032/28000 datapoints
2025-03-06 21:46:55,162 - INFO - training batch 551, loss: 1.210, 17632/28000 datapoints
2025-03-06 21:46:55,312 - INFO - training batch 601, loss: 1.169, 19232/28000 datapoints
2025-03-06 21:46:55,457 - INFO - training batch 651, loss: 0.555, 20832/28000 datapoints
2025-03-06 21:46:55,603 - INFO - training batch 701, loss: 0.748, 22432/28000 datapoints
2025-03-06 21:46:55,754 - INFO - training batch 751, loss: 0.754, 24032/28000 datapoints
2025-03-06 21:46:55,902 - INFO - training batch 801, loss: 0.581, 25632/28000 datapoints
2025-03-06 21:46:56,049 - INFO - training batch 851, loss: 1.078, 27232/28000 datapoints
2025-03-06 21:46:56,120 - INFO - validation batch 1, loss: 0.591, 32/6976 datapoints
2025-03-06 21:46:56,167 - INFO - validation batch 51, loss: 1.765, 1632/6976 datapoints
2025-03-06 21:46:56,216 - INFO - validation batch 101, loss: 0.673, 3232/6976 datapoints
2025-03-06 21:46:56,268 - INFO - validation batch 151, loss: 0.927, 4832/6976 datapoints
2025-03-06 21:46:56,316 - INFO - validation batch 201, loss: 0.561, 6432/6976 datapoints
2025-03-06 21:46:56,332 - INFO - Epoch 54/800 done.
2025-03-06 21:46:56,332 - INFO - Final validation performance:
Loss: 0.903, top-1 acc: 0.735top-5 acc: 0.735
2025-03-06 21:46:56,332 - INFO - Beginning epoch 55/800
2025-03-06 21:46:56,336 - INFO - training batch 1, loss: 0.926, 32/28000 datapoints
2025-03-06 21:46:56,483 - INFO - training batch 51, loss: 0.917, 1632/28000 datapoints
2025-03-06 21:46:56,630 - INFO - training batch 101, loss: 0.529, 3232/28000 datapoints
2025-03-06 21:46:56,777 - INFO - training batch 151, loss: 1.194, 4832/28000 datapoints
2025-03-06 21:46:56,925 - INFO - training batch 201, loss: 0.870, 6432/28000 datapoints
2025-03-06 21:46:57,070 - INFO - training batch 251, loss: 0.640, 8032/28000 datapoints
2025-03-06 21:46:57,213 - INFO - training batch 301, loss: 0.972, 9632/28000 datapoints
2025-03-06 21:46:57,357 - INFO - training batch 351, loss: 0.694, 11232/28000 datapoints
2025-03-06 21:46:57,501 - INFO - training batch 401, loss: 1.092, 12832/28000 datapoints
2025-03-06 21:46:57,649 - INFO - training batch 451, loss: 0.846, 14432/28000 datapoints
2025-03-06 21:46:57,801 - INFO - training batch 501, loss: 0.835, 16032/28000 datapoints
2025-03-06 21:46:57,948 - INFO - training batch 551, loss: 1.204, 17632/28000 datapoints
2025-03-06 21:46:58,094 - INFO - training batch 601, loss: 1.167, 19232/28000 datapoints
2025-03-06 21:46:58,240 - INFO - training batch 651, loss: 0.546, 20832/28000 datapoints
2025-03-06 21:46:58,383 - INFO - training batch 701, loss: 0.736, 22432/28000 datapoints
2025-03-06 21:46:58,527 - INFO - training batch 751, loss: 0.735, 24032/28000 datapoints
2025-03-06 21:46:58,674 - INFO - training batch 801, loss: 0.570, 25632/28000 datapoints
2025-03-06 21:46:58,820 - INFO - training batch 851, loss: 1.067, 27232/28000 datapoints
2025-03-06 21:46:58,893 - INFO - validation batch 1, loss: 0.578, 32/6976 datapoints
2025-03-06 21:46:58,940 - INFO - validation batch 51, loss: 1.761, 1632/6976 datapoints
2025-03-06 21:46:58,990 - INFO - validation batch 101, loss: 0.658, 3232/6976 datapoints
2025-03-06 21:46:59,039 - INFO - validation batch 151, loss: 0.912, 4832/6976 datapoints
2025-03-06 21:46:59,088 - INFO - validation batch 201, loss: 0.560, 6432/6976 datapoints
2025-03-06 21:46:59,104 - INFO - Epoch 55/800 done.
2025-03-06 21:46:59,104 - INFO - Final validation performance:
Loss: 0.894, top-1 acc: 0.741top-5 acc: 0.741
2025-03-06 21:46:59,105 - INFO - Beginning epoch 56/800
2025-03-06 21:46:59,109 - INFO - training batch 1, loss: 0.907, 32/28000 datapoints
2025-03-06 21:46:59,257 - INFO - training batch 51, loss: 0.900, 1632/28000 datapoints
2025-03-06 21:46:59,403 - INFO - training batch 101, loss: 0.515, 3232/28000 datapoints
2025-03-06 21:46:59,549 - INFO - training batch 151, loss: 1.181, 4832/28000 datapoints
2025-03-06 21:46:59,697 - INFO - training batch 201, loss: 0.847, 6432/28000 datapoints
2025-03-06 21:46:59,851 - INFO - training batch 251, loss: 0.630, 8032/28000 datapoints
2025-03-06 21:46:59,997 - INFO - training batch 301, loss: 0.961, 9632/28000 datapoints
2025-03-06 21:47:00,146 - INFO - training batch 351, loss: 0.675, 11232/28000 datapoints
2025-03-06 21:47:00,295 - INFO - training batch 401, loss: 1.093, 12832/28000 datapoints
2025-03-06 21:47:00,443 - INFO - training batch 451, loss: 0.839, 14432/28000 datapoints
2025-03-06 21:47:00,602 - INFO - training batch 501, loss: 0.818, 16032/28000 datapoints
2025-03-06 21:47:00,747 - INFO - training batch 551, loss: 1.197, 17632/28000 datapoints
2025-03-06 21:47:00,893 - INFO - training batch 601, loss: 1.165, 19232/28000 datapoints
2025-03-06 21:47:01,046 - INFO - training batch 651, loss: 0.536, 20832/28000 datapoints
2025-03-06 21:47:01,195 - INFO - training batch 701, loss: 0.726, 22432/28000 datapoints
2025-03-06 21:47:01,344 - INFO - training batch 751, loss: 0.718, 24032/28000 datapoints
2025-03-06 21:47:01,494 - INFO - training batch 801, loss: 0.559, 25632/28000 datapoints
2025-03-06 21:47:01,639 - INFO - training batch 851, loss: 1.056, 27232/28000 datapoints
2025-03-06 21:47:01,711 - INFO - validation batch 1, loss: 0.565, 32/6976 datapoints
2025-03-06 21:47:01,761 - INFO - validation batch 51, loss: 1.758, 1632/6976 datapoints
2025-03-06 21:47:01,809 - INFO - validation batch 101, loss: 0.644, 3232/6976 datapoints
2025-03-06 21:47:01,866 - INFO - validation batch 151, loss: 0.899, 4832/6976 datapoints
2025-03-06 21:47:01,913 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 21:47:01,930 - INFO - Epoch 56/800 done.
2025-03-06 21:47:01,930 - INFO - Final validation performance:
Loss: 0.885, top-1 acc: 0.745top-5 acc: 0.745
2025-03-06 21:47:01,930 - INFO - Beginning epoch 57/800
2025-03-06 21:47:01,935 - INFO - training batch 1, loss: 0.891, 32/28000 datapoints
2025-03-06 21:47:02,081 - INFO - training batch 51, loss: 0.885, 1632/28000 datapoints
2025-03-06 21:47:02,228 - INFO - training batch 101, loss: 0.502, 3232/28000 datapoints
2025-03-06 21:47:02,374 - INFO - training batch 151, loss: 1.168, 4832/28000 datapoints
2025-03-06 21:47:02,519 - INFO - training batch 201, loss: 0.826, 6432/28000 datapoints
2025-03-06 21:47:02,664 - INFO - training batch 251, loss: 0.621, 8032/28000 datapoints
2025-03-06 21:47:02,809 - INFO - training batch 301, loss: 0.952, 9632/28000 datapoints
2025-03-06 21:47:02,957 - INFO - training batch 351, loss: 0.657, 11232/28000 datapoints
2025-03-06 21:47:03,103 - INFO - training batch 401, loss: 1.094, 12832/28000 datapoints
2025-03-06 21:47:03,250 - INFO - training batch 451, loss: 0.832, 14432/28000 datapoints
2025-03-06 21:47:03,396 - INFO - training batch 501, loss: 0.801, 16032/28000 datapoints
2025-03-06 21:47:03,541 - INFO - training batch 551, loss: 1.191, 17632/28000 datapoints
2025-03-06 21:47:03,688 - INFO - training batch 601, loss: 1.164, 19232/28000 datapoints
2025-03-06 21:47:03,861 - INFO - training batch 651, loss: 0.528, 20832/28000 datapoints
2025-03-06 21:47:04,004 - INFO - training batch 701, loss: 0.715, 22432/28000 datapoints
2025-03-06 21:47:04,149 - INFO - training batch 751, loss: 0.702, 24032/28000 datapoints
2025-03-06 21:47:04,298 - INFO - training batch 801, loss: 0.550, 25632/28000 datapoints
2025-03-06 21:47:04,446 - INFO - training batch 851, loss: 1.046, 27232/28000 datapoints
2025-03-06 21:47:04,522 - INFO - validation batch 1, loss: 0.554, 32/6976 datapoints
2025-03-06 21:47:04,572 - INFO - validation batch 51, loss: 1.754, 1632/6976 datapoints
2025-03-06 21:47:04,652 - INFO - validation batch 101, loss: 0.630, 3232/6976 datapoints
2025-03-06 21:47:04,708 - INFO - validation batch 151, loss: 0.885, 4832/6976 datapoints
2025-03-06 21:47:04,758 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 21:47:04,779 - INFO - Epoch 57/800 done.
2025-03-06 21:47:04,780 - INFO - Final validation performance:
Loss: 0.876, top-1 acc: 0.749top-5 acc: 0.749
2025-03-06 21:47:04,780 - INFO - Beginning epoch 58/800
2025-03-06 21:47:04,785 - INFO - training batch 1, loss: 0.875, 32/28000 datapoints
2025-03-06 21:47:04,942 - INFO - training batch 51, loss: 0.870, 1632/28000 datapoints
2025-03-06 21:47:05,097 - INFO - training batch 101, loss: 0.489, 3232/28000 datapoints
2025-03-06 21:47:05,249 - INFO - training batch 151, loss: 1.157, 4832/28000 datapoints
2025-03-06 21:47:05,398 - INFO - training batch 201, loss: 0.808, 6432/28000 datapoints
2025-03-06 21:47:05,546 - INFO - training batch 251, loss: 0.612, 8032/28000 datapoints
2025-03-06 21:47:05,694 - INFO - training batch 301, loss: 0.943, 9632/28000 datapoints
2025-03-06 21:47:05,849 - INFO - training batch 351, loss: 0.639, 11232/28000 datapoints
2025-03-06 21:47:05,999 - INFO - training batch 401, loss: 1.096, 12832/28000 datapoints
2025-03-06 21:47:06,148 - INFO - training batch 451, loss: 0.827, 14432/28000 datapoints
2025-03-06 21:47:06,300 - INFO - training batch 501, loss: 0.785, 16032/28000 datapoints
2025-03-06 21:47:06,450 - INFO - training batch 551, loss: 1.186, 17632/28000 datapoints
2025-03-06 21:47:06,597 - INFO - training batch 601, loss: 1.164, 19232/28000 datapoints
2025-03-06 21:47:06,762 - INFO - training batch 651, loss: 0.520, 20832/28000 datapoints
2025-03-06 21:47:06,913 - INFO - training batch 701, loss: 0.705, 22432/28000 datapoints
2025-03-06 21:47:07,059 - INFO - training batch 751, loss: 0.687, 24032/28000 datapoints
2025-03-06 21:47:07,215 - INFO - training batch 801, loss: 0.542, 25632/28000 datapoints
2025-03-06 21:47:07,367 - INFO - training batch 851, loss: 1.035, 27232/28000 datapoints
2025-03-06 21:47:07,442 - INFO - validation batch 1, loss: 0.542, 32/6976 datapoints
2025-03-06 21:47:07,493 - INFO - validation batch 51, loss: 1.749, 1632/6976 datapoints
2025-03-06 21:47:07,544 - INFO - validation batch 101, loss: 0.618, 3232/6976 datapoints
2025-03-06 21:47:07,599 - INFO - validation batch 151, loss: 0.871, 4832/6976 datapoints
2025-03-06 21:47:07,652 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 21:47:07,672 - INFO - Epoch 58/800 done.
2025-03-06 21:47:07,672 - INFO - Final validation performance:
Loss: 0.868, top-1 acc: 0.752top-5 acc: 0.752
2025-03-06 21:47:07,673 - INFO - Beginning epoch 59/800
2025-03-06 21:47:07,677 - INFO - training batch 1, loss: 0.862, 32/28000 datapoints
2025-03-06 21:47:07,827 - INFO - training batch 51, loss: 0.856, 1632/28000 datapoints
2025-03-06 21:47:07,974 - INFO - training batch 101, loss: 0.478, 3232/28000 datapoints
2025-03-06 21:47:08,121 - INFO - training batch 151, loss: 1.145, 4832/28000 datapoints
2025-03-06 21:47:08,269 - INFO - training batch 201, loss: 0.791, 6432/28000 datapoints
2025-03-06 21:47:08,412 - INFO - training batch 251, loss: 0.603, 8032/28000 datapoints
2025-03-06 21:47:08,557 - INFO - training batch 301, loss: 0.935, 9632/28000 datapoints
2025-03-06 21:47:08,702 - INFO - training batch 351, loss: 0.624, 11232/28000 datapoints
2025-03-06 21:47:08,851 - INFO - training batch 401, loss: 1.100, 12832/28000 datapoints
2025-03-06 21:47:08,995 - INFO - training batch 451, loss: 0.821, 14432/28000 datapoints
2025-03-06 21:47:09,142 - INFO - training batch 501, loss: 0.769, 16032/28000 datapoints
2025-03-06 21:47:09,292 - INFO - training batch 551, loss: 1.180, 17632/28000 datapoints
2025-03-06 21:47:09,436 - INFO - training batch 601, loss: 1.162, 19232/28000 datapoints
2025-03-06 21:47:09,582 - INFO - training batch 651, loss: 0.511, 20832/28000 datapoints
2025-03-06 21:47:09,729 - INFO - training batch 701, loss: 0.695, 22432/28000 datapoints
2025-03-06 21:47:09,880 - INFO - training batch 751, loss: 0.673, 24032/28000 datapoints
2025-03-06 21:47:10,024 - INFO - training batch 801, loss: 0.534, 25632/28000 datapoints
2025-03-06 21:47:10,174 - INFO - training batch 851, loss: 1.024, 27232/28000 datapoints
2025-03-06 21:47:10,249 - INFO - validation batch 1, loss: 0.531, 32/6976 datapoints
2025-03-06 21:47:10,302 - INFO - validation batch 51, loss: 1.744, 1632/6976 datapoints
2025-03-06 21:47:10,349 - INFO - validation batch 101, loss: 0.605, 3232/6976 datapoints
2025-03-06 21:47:10,396 - INFO - validation batch 151, loss: 0.858, 4832/6976 datapoints
2025-03-06 21:47:10,443 - INFO - validation batch 201, loss: 0.560, 6432/6976 datapoints
2025-03-06 21:47:10,459 - INFO - Epoch 59/800 done.
2025-03-06 21:47:10,459 - INFO - Final validation performance:
Loss: 0.860, top-1 acc: 0.758top-5 acc: 0.758
2025-03-06 21:47:10,460 - INFO - Beginning epoch 60/800
2025-03-06 21:47:10,463 - INFO - training batch 1, loss: 0.848, 32/28000 datapoints
2025-03-06 21:47:10,610 - INFO - training batch 51, loss: 0.843, 1632/28000 datapoints
2025-03-06 21:47:10,757 - INFO - training batch 101, loss: 0.468, 3232/28000 datapoints
2025-03-06 21:47:10,911 - INFO - training batch 151, loss: 1.133, 4832/28000 datapoints
2025-03-06 21:47:11,056 - INFO - training batch 201, loss: 0.774, 6432/28000 datapoints
2025-03-06 21:47:11,200 - INFO - training batch 251, loss: 0.595, 8032/28000 datapoints
2025-03-06 21:47:11,347 - INFO - training batch 301, loss: 0.927, 9632/28000 datapoints
2025-03-06 21:47:11,496 - INFO - training batch 351, loss: 0.609, 11232/28000 datapoints
2025-03-06 21:47:11,639 - INFO - training batch 401, loss: 1.102, 12832/28000 datapoints
2025-03-06 21:47:11,789 - INFO - training batch 451, loss: 0.816, 14432/28000 datapoints
2025-03-06 21:47:11,968 - INFO - training batch 501, loss: 0.754, 16032/28000 datapoints
2025-03-06 21:47:12,135 - INFO - training batch 551, loss: 1.173, 17632/28000 datapoints
2025-03-06 21:47:12,283 - INFO - training batch 601, loss: 1.161, 19232/28000 datapoints
2025-03-06 21:47:12,434 - INFO - training batch 651, loss: 0.503, 20832/28000 datapoints
2025-03-06 21:47:12,582 - INFO - training batch 701, loss: 0.685, 22432/28000 datapoints
2025-03-06 21:47:12,731 - INFO - training batch 751, loss: 0.660, 24032/28000 datapoints
2025-03-06 21:47:12,888 - INFO - training batch 801, loss: 0.527, 25632/28000 datapoints
2025-03-06 21:47:13,043 - INFO - training batch 851, loss: 1.014, 27232/28000 datapoints
2025-03-06 21:47:13,114 - INFO - validation batch 1, loss: 0.521, 32/6976 datapoints
2025-03-06 21:47:13,160 - INFO - validation batch 51, loss: 1.737, 1632/6976 datapoints
2025-03-06 21:47:13,207 - INFO - validation batch 101, loss: 0.593, 3232/6976 datapoints
2025-03-06 21:47:13,255 - INFO - validation batch 151, loss: 0.846, 4832/6976 datapoints
2025-03-06 21:47:13,302 - INFO - validation batch 201, loss: 0.560, 6432/6976 datapoints
2025-03-06 21:47:13,322 - INFO - Epoch 60/800 done.
2025-03-06 21:47:13,322 - INFO - Final validation performance:
Loss: 0.851, top-1 acc: 0.760top-5 acc: 0.760
2025-03-06 21:47:13,323 - INFO - Beginning epoch 61/800
2025-03-06 21:47:13,328 - INFO - training batch 1, loss: 0.835, 32/28000 datapoints
2025-03-06 21:47:13,479 - INFO - training batch 51, loss: 0.831, 1632/28000 datapoints
2025-03-06 21:47:13,624 - INFO - training batch 101, loss: 0.458, 3232/28000 datapoints
2025-03-06 21:47:13,772 - INFO - training batch 151, loss: 1.122, 4832/28000 datapoints
2025-03-06 21:47:13,926 - INFO - training batch 201, loss: 0.759, 6432/28000 datapoints
2025-03-06 21:47:14,070 - INFO - training batch 251, loss: 0.586, 8032/28000 datapoints
2025-03-06 21:47:14,213 - INFO - training batch 301, loss: 0.918, 9632/28000 datapoints
2025-03-06 21:47:14,358 - INFO - training batch 351, loss: 0.596, 11232/28000 datapoints
2025-03-06 21:47:14,504 - INFO - training batch 401, loss: 1.105, 12832/28000 datapoints
2025-03-06 21:47:14,648 - INFO - training batch 451, loss: 0.812, 14432/28000 datapoints
2025-03-06 21:47:14,824 - INFO - training batch 501, loss: 0.740, 16032/28000 datapoints
2025-03-06 21:47:14,971 - INFO - training batch 551, loss: 1.165, 17632/28000 datapoints
2025-03-06 21:47:15,128 - INFO - training batch 601, loss: 1.161, 19232/28000 datapoints
2025-03-06 21:47:15,281 - INFO - training batch 651, loss: 0.496, 20832/28000 datapoints
2025-03-06 21:47:15,425 - INFO - training batch 701, loss: 0.676, 22432/28000 datapoints
2025-03-06 21:47:15,569 - INFO - training batch 751, loss: 0.647, 24032/28000 datapoints
2025-03-06 21:47:15,721 - INFO - training batch 801, loss: 0.520, 25632/28000 datapoints
2025-03-06 21:47:15,873 - INFO - training batch 851, loss: 1.003, 27232/28000 datapoints
2025-03-06 21:47:15,945 - INFO - validation batch 1, loss: 0.511, 32/6976 datapoints
2025-03-06 21:47:15,994 - INFO - validation batch 51, loss: 1.730, 1632/6976 datapoints
2025-03-06 21:47:16,042 - INFO - validation batch 101, loss: 0.580, 3232/6976 datapoints
2025-03-06 21:47:16,090 - INFO - validation batch 151, loss: 0.835, 4832/6976 datapoints
2025-03-06 21:47:16,138 - INFO - validation batch 201, loss: 0.561, 6432/6976 datapoints
2025-03-06 21:47:16,155 - INFO - Epoch 61/800 done.
2025-03-06 21:47:16,155 - INFO - Final validation performance:
Loss: 0.843, top-1 acc: 0.763top-5 acc: 0.763
2025-03-06 21:47:16,155 - INFO - Beginning epoch 62/800
2025-03-06 21:47:16,159 - INFO - training batch 1, loss: 0.823, 32/28000 datapoints
2025-03-06 21:47:16,310 - INFO - training batch 51, loss: 0.819, 1632/28000 datapoints
2025-03-06 21:47:16,460 - INFO - training batch 101, loss: 0.448, 3232/28000 datapoints
2025-03-06 21:47:16,607 - INFO - training batch 151, loss: 1.111, 4832/28000 datapoints
2025-03-06 21:47:16,754 - INFO - training batch 201, loss: 0.745, 6432/28000 datapoints
2025-03-06 21:47:16,903 - INFO - training batch 251, loss: 0.579, 8032/28000 datapoints
2025-03-06 21:47:17,048 - INFO - training batch 301, loss: 0.911, 9632/28000 datapoints
2025-03-06 21:47:17,192 - INFO - training batch 351, loss: 0.584, 11232/28000 datapoints
2025-03-06 21:47:17,339 - INFO - training batch 401, loss: 1.100, 12832/28000 datapoints
2025-03-06 21:47:17,484 - INFO - training batch 451, loss: 0.808, 14432/28000 datapoints
2025-03-06 21:47:17,628 - INFO - training batch 501, loss: 0.725, 16032/28000 datapoints
2025-03-06 21:47:17,772 - INFO - training batch 551, loss: 1.156, 17632/28000 datapoints
2025-03-06 21:47:17,925 - INFO - training batch 601, loss: 1.161, 19232/28000 datapoints
2025-03-06 21:47:18,071 - INFO - training batch 651, loss: 0.488, 20832/28000 datapoints
2025-03-06 21:47:18,216 - INFO - training batch 701, loss: 0.666, 22432/28000 datapoints
2025-03-06 21:47:18,361 - INFO - training batch 751, loss: 0.636, 24032/28000 datapoints
2025-03-06 21:47:18,505 - INFO - training batch 801, loss: 0.513, 25632/28000 datapoints
2025-03-06 21:47:18,652 - INFO - training batch 851, loss: 0.994, 27232/28000 datapoints
2025-03-06 21:47:18,723 - INFO - validation batch 1, loss: 0.502, 32/6976 datapoints
2025-03-06 21:47:18,771 - INFO - validation batch 51, loss: 1.725, 1632/6976 datapoints
2025-03-06 21:47:18,819 - INFO - validation batch 101, loss: 0.569, 3232/6976 datapoints
2025-03-06 21:47:18,868 - INFO - validation batch 151, loss: 0.823, 4832/6976 datapoints
2025-03-06 21:47:18,915 - INFO - validation batch 201, loss: 0.561, 6432/6976 datapoints
2025-03-06 21:47:18,930 - INFO - Epoch 62/800 done.
2025-03-06 21:47:18,931 - INFO - Final validation performance:
Loss: 0.836, top-1 acc: 0.764top-5 acc: 0.764
2025-03-06 21:47:18,931 - INFO - Beginning epoch 63/800
2025-03-06 21:47:18,935 - INFO - training batch 1, loss: 0.811, 32/28000 datapoints
2025-03-06 21:47:19,087 - INFO - training batch 51, loss: 0.807, 1632/28000 datapoints
2025-03-06 21:47:19,240 - INFO - training batch 101, loss: 0.440, 3232/28000 datapoints
2025-03-06 21:47:19,388 - INFO - training batch 151, loss: 1.102, 4832/28000 datapoints
2025-03-06 21:47:19,533 - INFO - training batch 201, loss: 0.731, 6432/28000 datapoints
2025-03-06 21:47:19,686 - INFO - training batch 251, loss: 0.572, 8032/28000 datapoints
2025-03-06 21:47:19,842 - INFO - training batch 301, loss: 0.904, 9632/28000 datapoints
2025-03-06 21:47:19,990 - INFO - training batch 351, loss: 0.573, 11232/28000 datapoints
2025-03-06 21:47:20,135 - INFO - training batch 401, loss: 1.088, 12832/28000 datapoints
2025-03-06 21:47:20,282 - INFO - training batch 451, loss: 0.804, 14432/28000 datapoints
2025-03-06 21:47:20,430 - INFO - training batch 501, loss: 0.712, 16032/28000 datapoints
2025-03-06 21:47:20,589 - INFO - training batch 551, loss: 1.148, 17632/28000 datapoints
2025-03-06 21:47:20,735 - INFO - training batch 601, loss: 1.161, 19232/28000 datapoints
2025-03-06 21:47:20,885 - INFO - training batch 651, loss: 0.481, 20832/28000 datapoints
2025-03-06 21:47:21,031 - INFO - training batch 701, loss: 0.656, 22432/28000 datapoints
2025-03-06 21:47:21,179 - INFO - training batch 751, loss: 0.626, 24032/28000 datapoints
2025-03-06 21:47:21,325 - INFO - training batch 801, loss: 0.507, 25632/28000 datapoints
2025-03-06 21:47:21,472 - INFO - training batch 851, loss: 0.984, 27232/28000 datapoints
2025-03-06 21:47:21,543 - INFO - validation batch 1, loss: 0.493, 32/6976 datapoints
2025-03-06 21:47:21,591 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:47:21,638 - INFO - validation batch 101, loss: 0.557, 3232/6976 datapoints
2025-03-06 21:47:21,687 - INFO - validation batch 151, loss: 0.812, 4832/6976 datapoints
2025-03-06 21:47:21,734 - INFO - validation batch 201, loss: 0.561, 6432/6976 datapoints
2025-03-06 21:47:21,750 - INFO - Epoch 63/800 done.
2025-03-06 21:47:21,750 - INFO - Final validation performance:
Loss: 0.828, top-1 acc: 0.767top-5 acc: 0.767
2025-03-06 21:47:21,751 - INFO - Beginning epoch 64/800
2025-03-06 21:47:21,755 - INFO - training batch 1, loss: 0.800, 32/28000 datapoints
2025-03-06 21:47:21,913 - INFO - training batch 51, loss: 0.794, 1632/28000 datapoints
2025-03-06 21:47:22,059 - INFO - training batch 101, loss: 0.432, 3232/28000 datapoints
2025-03-06 21:47:22,206 - INFO - training batch 151, loss: 1.092, 4832/28000 datapoints
2025-03-06 21:47:22,353 - INFO - training batch 201, loss: 0.718, 6432/28000 datapoints
2025-03-06 21:47:22,499 - INFO - training batch 251, loss: 0.565, 8032/28000 datapoints
2025-03-06 21:47:22,643 - INFO - training batch 301, loss: 0.897, 9632/28000 datapoints
2025-03-06 21:47:22,786 - INFO - training batch 351, loss: 0.565, 11232/28000 datapoints
2025-03-06 21:47:22,935 - INFO - training batch 401, loss: 1.075, 12832/28000 datapoints
2025-03-06 21:47:23,081 - INFO - training batch 451, loss: 0.800, 14432/28000 datapoints
2025-03-06 21:47:23,227 - INFO - training batch 501, loss: 0.699, 16032/28000 datapoints
2025-03-06 21:47:23,374 - INFO - training batch 551, loss: 1.137, 17632/28000 datapoints
2025-03-06 21:47:23,519 - INFO - training batch 601, loss: 1.162, 19232/28000 datapoints
2025-03-06 21:47:23,664 - INFO - training batch 651, loss: 0.474, 20832/28000 datapoints
2025-03-06 21:47:23,810 - INFO - training batch 701, loss: 0.647, 22432/28000 datapoints
2025-03-06 21:47:23,961 - INFO - training batch 751, loss: 0.616, 24032/28000 datapoints
2025-03-06 21:47:24,106 - INFO - training batch 801, loss: 0.502, 25632/28000 datapoints
2025-03-06 21:47:24,250 - INFO - training batch 851, loss: 0.974, 27232/28000 datapoints
2025-03-06 21:47:24,323 - INFO - validation batch 1, loss: 0.485, 32/6976 datapoints
2025-03-06 21:47:24,378 - INFO - validation batch 51, loss: 1.713, 1632/6976 datapoints
2025-03-06 21:47:24,430 - INFO - validation batch 101, loss: 0.547, 3232/6976 datapoints
2025-03-06 21:47:24,481 - INFO - validation batch 151, loss: 0.800, 4832/6976 datapoints
2025-03-06 21:47:24,531 - INFO - validation batch 201, loss: 0.562, 6432/6976 datapoints
2025-03-06 21:47:24,547 - INFO - Epoch 64/800 done.
2025-03-06 21:47:24,547 - INFO - Final validation performance:
Loss: 0.821, top-1 acc: 0.771top-5 acc: 0.771
2025-03-06 21:47:24,548 - INFO - Beginning epoch 65/800
2025-03-06 21:47:24,552 - INFO - training batch 1, loss: 0.789, 32/28000 datapoints
2025-03-06 21:47:24,698 - INFO - training batch 51, loss: 0.783, 1632/28000 datapoints
2025-03-06 21:47:24,870 - INFO - training batch 101, loss: 0.424, 3232/28000 datapoints
2025-03-06 21:47:25,023 - INFO - training batch 151, loss: 1.083, 4832/28000 datapoints
2025-03-06 21:47:25,191 - INFO - training batch 201, loss: 0.705, 6432/28000 datapoints
2025-03-06 21:47:25,337 - INFO - training batch 251, loss: 0.557, 8032/28000 datapoints
2025-03-06 21:47:25,484 - INFO - training batch 301, loss: 0.890, 9632/28000 datapoints
2025-03-06 21:47:25,635 - INFO - training batch 351, loss: 0.557, 11232/28000 datapoints
2025-03-06 21:47:25,792 - INFO - training batch 401, loss: 1.062, 12832/28000 datapoints
2025-03-06 21:47:25,947 - INFO - training batch 451, loss: 0.796, 14432/28000 datapoints
2025-03-06 21:47:26,094 - INFO - training batch 501, loss: 0.687, 16032/28000 datapoints
2025-03-06 21:47:26,239 - INFO - training batch 551, loss: 1.127, 17632/28000 datapoints
2025-03-06 21:47:26,385 - INFO - training batch 601, loss: 1.162, 19232/28000 datapoints
2025-03-06 21:47:26,533 - INFO - training batch 651, loss: 0.467, 20832/28000 datapoints
2025-03-06 21:47:26,680 - INFO - training batch 701, loss: 0.638, 22432/28000 datapoints
2025-03-06 21:47:26,824 - INFO - training batch 751, loss: 0.607, 24032/28000 datapoints
2025-03-06 21:47:26,974 - INFO - training batch 801, loss: 0.496, 25632/28000 datapoints
2025-03-06 21:47:27,119 - INFO - training batch 851, loss: 0.965, 27232/28000 datapoints
2025-03-06 21:47:27,193 - INFO - validation batch 1, loss: 0.478, 32/6976 datapoints
2025-03-06 21:47:27,240 - INFO - validation batch 51, loss: 1.706, 1632/6976 datapoints
2025-03-06 21:47:27,288 - INFO - validation batch 101, loss: 0.536, 3232/6976 datapoints
2025-03-06 21:47:27,334 - INFO - validation batch 151, loss: 0.789, 4832/6976 datapoints
2025-03-06 21:47:27,381 - INFO - validation batch 201, loss: 0.562, 6432/6976 datapoints
2025-03-06 21:47:27,397 - INFO - Epoch 65/800 done.
2025-03-06 21:47:27,398 - INFO - Final validation performance:
Loss: 0.814, top-1 acc: 0.773top-5 acc: 0.773
2025-03-06 21:47:27,398 - INFO - Beginning epoch 66/800
2025-03-06 21:47:27,402 - INFO - training batch 1, loss: 0.779, 32/28000 datapoints
2025-03-06 21:47:27,550 - INFO - training batch 51, loss: 0.771, 1632/28000 datapoints
2025-03-06 21:47:27,697 - INFO - training batch 101, loss: 0.416, 3232/28000 datapoints
2025-03-06 21:47:27,847 - INFO - training batch 151, loss: 1.074, 4832/28000 datapoints
2025-03-06 21:47:28,001 - INFO - training batch 201, loss: 0.692, 6432/28000 datapoints
2025-03-06 21:47:28,146 - INFO - training batch 251, loss: 0.550, 8032/28000 datapoints
2025-03-06 21:47:28,291 - INFO - training batch 301, loss: 0.883, 9632/28000 datapoints
2025-03-06 21:47:28,436 - INFO - training batch 351, loss: 0.551, 11232/28000 datapoints
2025-03-06 21:47:28,581 - INFO - training batch 401, loss: 1.050, 12832/28000 datapoints
2025-03-06 21:47:28,726 - INFO - training batch 451, loss: 0.793, 14432/28000 datapoints
2025-03-06 21:47:28,875 - INFO - training batch 501, loss: 0.675, 16032/28000 datapoints
2025-03-06 21:47:29,028 - INFO - training batch 551, loss: 1.117, 17632/28000 datapoints
2025-03-06 21:47:29,175 - INFO - training batch 601, loss: 1.163, 19232/28000 datapoints
2025-03-06 21:47:29,321 - INFO - training batch 651, loss: 0.460, 20832/28000 datapoints
2025-03-06 21:47:29,467 - INFO - training batch 701, loss: 0.629, 22432/28000 datapoints
2025-03-06 21:47:29,612 - INFO - training batch 751, loss: 0.599, 24032/28000 datapoints
2025-03-06 21:47:29,757 - INFO - training batch 801, loss: 0.490, 25632/28000 datapoints
2025-03-06 21:47:29,909 - INFO - training batch 851, loss: 0.956, 27232/28000 datapoints
2025-03-06 21:47:29,982 - INFO - validation batch 1, loss: 0.470, 32/6976 datapoints
2025-03-06 21:47:30,029 - INFO - validation batch 51, loss: 1.700, 1632/6976 datapoints
2025-03-06 21:47:30,081 - INFO - validation batch 101, loss: 0.526, 3232/6976 datapoints
2025-03-06 21:47:30,136 - INFO - validation batch 151, loss: 0.777, 4832/6976 datapoints
2025-03-06 21:47:30,183 - INFO - validation batch 201, loss: 0.563, 6432/6976 datapoints
2025-03-06 21:47:30,199 - INFO - Epoch 66/800 done.
2025-03-06 21:47:30,199 - INFO - Final validation performance:
Loss: 0.807, top-1 acc: 0.775top-5 acc: 0.775
2025-03-06 21:47:30,200 - INFO - Beginning epoch 67/800
2025-03-06 21:47:30,204 - INFO - training batch 1, loss: 0.770, 32/28000 datapoints
2025-03-06 21:47:30,359 - INFO - training batch 51, loss: 0.760, 1632/28000 datapoints
2025-03-06 21:47:30,508 - INFO - training batch 101, loss: 0.409, 3232/28000 datapoints
2025-03-06 21:47:30,655 - INFO - training batch 151, loss: 1.065, 4832/28000 datapoints
2025-03-06 21:47:30,805 - INFO - training batch 201, loss: 0.678, 6432/28000 datapoints
2025-03-06 21:47:30,957 - INFO - training batch 251, loss: 0.543, 8032/28000 datapoints
2025-03-06 21:47:31,109 - INFO - training batch 301, loss: 0.876, 9632/28000 datapoints
2025-03-06 21:47:31,268 - INFO - training batch 351, loss: 0.545, 11232/28000 datapoints
2025-03-06 21:47:31,416 - INFO - training batch 401, loss: 1.037, 12832/28000 datapoints
2025-03-06 21:47:31,566 - INFO - training batch 451, loss: 0.789, 14432/28000 datapoints
2025-03-06 21:47:31,722 - INFO - training batch 501, loss: 0.663, 16032/28000 datapoints
2025-03-06 21:47:31,881 - INFO - training batch 551, loss: 1.106, 17632/28000 datapoints
2025-03-06 21:47:32,031 - INFO - training batch 601, loss: 1.162, 19232/28000 datapoints
2025-03-06 21:47:32,183 - INFO - training batch 651, loss: 0.454, 20832/28000 datapoints
2025-03-06 21:47:32,329 - INFO - training batch 701, loss: 0.621, 22432/28000 datapoints
2025-03-06 21:47:32,475 - INFO - training batch 751, loss: 0.592, 24032/28000 datapoints
2025-03-06 21:47:32,620 - INFO - training batch 801, loss: 0.485, 25632/28000 datapoints
2025-03-06 21:47:32,766 - INFO - training batch 851, loss: 0.948, 27232/28000 datapoints
2025-03-06 21:47:32,841 - INFO - validation batch 1, loss: 0.462, 32/6976 datapoints
2025-03-06 21:47:32,888 - INFO - validation batch 51, loss: 1.693, 1632/6976 datapoints
2025-03-06 21:47:32,936 - INFO - validation batch 101, loss: 0.516, 3232/6976 datapoints
2025-03-06 21:47:32,985 - INFO - validation batch 151, loss: 0.766, 4832/6976 datapoints
2025-03-06 21:47:33,032 - INFO - validation batch 201, loss: 0.563, 6432/6976 datapoints
2025-03-06 21:47:33,049 - INFO - Epoch 67/800 done.
2025-03-06 21:47:33,049 - INFO - Final validation performance:
Loss: 0.800, top-1 acc: 0.777top-5 acc: 0.777
2025-03-06 21:47:33,049 - INFO - Beginning epoch 68/800
2025-03-06 21:47:33,053 - INFO - training batch 1, loss: 0.760, 32/28000 datapoints
2025-03-06 21:47:33,201 - INFO - training batch 51, loss: 0.748, 1632/28000 datapoints
2025-03-06 21:47:33,348 - INFO - training batch 101, loss: 0.403, 3232/28000 datapoints
2025-03-06 21:47:33,499 - INFO - training batch 151, loss: 1.057, 4832/28000 datapoints
2025-03-06 21:47:33,645 - INFO - training batch 201, loss: 0.665, 6432/28000 datapoints
2025-03-06 21:47:33,793 - INFO - training batch 251, loss: 0.536, 8032/28000 datapoints
2025-03-06 21:47:33,959 - INFO - training batch 301, loss: 0.869, 9632/28000 datapoints
2025-03-06 21:47:34,105 - INFO - training batch 351, loss: 0.541, 11232/28000 datapoints
2025-03-06 21:47:34,251 - INFO - training batch 401, loss: 1.026, 12832/28000 datapoints
2025-03-06 21:47:34,397 - INFO - training batch 451, loss: 0.785, 14432/28000 datapoints
2025-03-06 21:47:34,544 - INFO - training batch 501, loss: 0.651, 16032/28000 datapoints
2025-03-06 21:47:34,690 - INFO - training batch 551, loss: 1.096, 17632/28000 datapoints
2025-03-06 21:47:34,841 - INFO - training batch 601, loss: 1.161, 19232/28000 datapoints
2025-03-06 21:47:35,015 - INFO - training batch 651, loss: 0.447, 20832/28000 datapoints
2025-03-06 21:47:35,167 - INFO - training batch 701, loss: 0.614, 22432/28000 datapoints
2025-03-06 21:47:35,317 - INFO - training batch 751, loss: 0.585, 24032/28000 datapoints
2025-03-06 21:47:35,464 - INFO - training batch 801, loss: 0.479, 25632/28000 datapoints
2025-03-06 21:47:35,610 - INFO - training batch 851, loss: 0.940, 27232/28000 datapoints
2025-03-06 21:47:35,682 - INFO - validation batch 1, loss: 0.454, 32/6976 datapoints
2025-03-06 21:47:35,730 - INFO - validation batch 51, loss: 1.686, 1632/6976 datapoints
2025-03-06 21:47:35,778 - INFO - validation batch 101, loss: 0.507, 3232/6976 datapoints
2025-03-06 21:47:35,825 - INFO - validation batch 151, loss: 0.754, 4832/6976 datapoints
2025-03-06 21:47:35,878 - INFO - validation batch 201, loss: 0.564, 6432/6976 datapoints
2025-03-06 21:47:35,897 - INFO - Epoch 68/800 done.
2025-03-06 21:47:35,897 - INFO - Final validation performance:
Loss: 0.793, top-1 acc: 0.778top-5 acc: 0.778
2025-03-06 21:47:35,898 - INFO - Beginning epoch 69/800
2025-03-06 21:47:35,902 - INFO - training batch 1, loss: 0.752, 32/28000 datapoints
2025-03-06 21:47:36,053 - INFO - training batch 51, loss: 0.736, 1632/28000 datapoints
2025-03-06 21:47:36,199 - INFO - training batch 101, loss: 0.396, 3232/28000 datapoints
2025-03-06 21:47:36,346 - INFO - training batch 151, loss: 1.048, 4832/28000 datapoints
2025-03-06 21:47:36,493 - INFO - training batch 201, loss: 0.653, 6432/28000 datapoints
2025-03-06 21:47:36,640 - INFO - training batch 251, loss: 0.530, 8032/28000 datapoints
2025-03-06 21:47:36,787 - INFO - training batch 301, loss: 0.863, 9632/28000 datapoints
2025-03-06 21:47:36,936 - INFO - training batch 351, loss: 0.538, 11232/28000 datapoints
2025-03-06 21:47:37,085 - INFO - training batch 401, loss: 1.014, 12832/28000 datapoints
2025-03-06 21:47:37,241 - INFO - training batch 451, loss: 0.782, 14432/28000 datapoints
2025-03-06 21:47:37,392 - INFO - training batch 501, loss: 0.640, 16032/28000 datapoints
2025-03-06 21:47:37,540 - INFO - training batch 551, loss: 1.084, 17632/28000 datapoints
2025-03-06 21:47:37,695 - INFO - training batch 601, loss: 1.161, 19232/28000 datapoints
2025-03-06 21:47:37,860 - INFO - training batch 651, loss: 0.440, 20832/28000 datapoints
2025-03-06 21:47:38,015 - INFO - training batch 701, loss: 0.606, 22432/28000 datapoints
2025-03-06 21:47:38,166 - INFO - training batch 751, loss: 0.578, 24032/28000 datapoints
2025-03-06 21:47:38,314 - INFO - training batch 801, loss: 0.473, 25632/28000 datapoints
2025-03-06 21:47:38,461 - INFO - training batch 851, loss: 0.931, 27232/28000 datapoints
2025-03-06 21:47:38,533 - INFO - validation batch 1, loss: 0.446, 32/6976 datapoints
2025-03-06 21:47:38,582 - INFO - validation batch 51, loss: 1.679, 1632/6976 datapoints
2025-03-06 21:47:38,629 - INFO - validation batch 101, loss: 0.497, 3232/6976 datapoints
2025-03-06 21:47:38,676 - INFO - validation batch 151, loss: 0.744, 4832/6976 datapoints
2025-03-06 21:47:38,724 - INFO - validation batch 201, loss: 0.565, 6432/6976 datapoints
2025-03-06 21:47:38,740 - INFO - Epoch 69/800 done.
2025-03-06 21:47:38,740 - INFO - Final validation performance:
Loss: 0.786, top-1 acc: 0.780top-5 acc: 0.780
2025-03-06 21:47:38,741 - INFO - Beginning epoch 70/800
2025-03-06 21:47:38,745 - INFO - training batch 1, loss: 0.743, 32/28000 datapoints
2025-03-06 21:47:38,897 - INFO - training batch 51, loss: 0.726, 1632/28000 datapoints
2025-03-06 21:47:39,046 - INFO - training batch 101, loss: 0.391, 3232/28000 datapoints
2025-03-06 21:47:39,195 - INFO - training batch 151, loss: 1.039, 4832/28000 datapoints
2025-03-06 21:47:39,353 - INFO - training batch 201, loss: 0.641, 6432/28000 datapoints
2025-03-06 21:47:39,501 - INFO - training batch 251, loss: 0.523, 8032/28000 datapoints
2025-03-06 21:47:39,649 - INFO - training batch 301, loss: 0.857, 9632/28000 datapoints
2025-03-06 21:47:39,794 - INFO - training batch 351, loss: 0.536, 11232/28000 datapoints
2025-03-06 21:47:39,949 - INFO - training batch 401, loss: 1.002, 12832/28000 datapoints
2025-03-06 21:47:40,098 - INFO - training batch 451, loss: 0.778, 14432/28000 datapoints
2025-03-06 21:47:40,249 - INFO - training batch 501, loss: 0.629, 16032/28000 datapoints
2025-03-06 21:47:40,396 - INFO - training batch 551, loss: 1.071, 17632/28000 datapoints
2025-03-06 21:47:40,544 - INFO - training batch 601, loss: 1.159, 19232/28000 datapoints
2025-03-06 21:47:40,694 - INFO - training batch 651, loss: 0.434, 20832/28000 datapoints
2025-03-06 21:47:40,845 - INFO - training batch 701, loss: 0.598, 22432/28000 datapoints
2025-03-06 21:47:40,998 - INFO - training batch 751, loss: 0.572, 24032/28000 datapoints
2025-03-06 21:47:41,147 - INFO - training batch 801, loss: 0.468, 25632/28000 datapoints
2025-03-06 21:47:41,294 - INFO - training batch 851, loss: 0.923, 27232/28000 datapoints
2025-03-06 21:47:41,366 - INFO - validation batch 1, loss: 0.438, 32/6976 datapoints
2025-03-06 21:47:41,413 - INFO - validation batch 51, loss: 1.674, 1632/6976 datapoints
2025-03-06 21:47:41,463 - INFO - validation batch 101, loss: 0.489, 3232/6976 datapoints
2025-03-06 21:47:41,510 - INFO - validation batch 151, loss: 0.734, 4832/6976 datapoints
2025-03-06 21:47:41,557 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:47:41,573 - INFO - Epoch 70/800 done.
2025-03-06 21:47:41,573 - INFO - Final validation performance:
Loss: 0.780, top-1 acc: 0.782top-5 acc: 0.782
2025-03-06 21:47:41,574 - INFO - Beginning epoch 71/800
2025-03-06 21:47:41,578 - INFO - training batch 1, loss: 0.735, 32/28000 datapoints
2025-03-06 21:47:41,730 - INFO - training batch 51, loss: 0.714, 1632/28000 datapoints
2025-03-06 21:47:41,880 - INFO - training batch 101, loss: 0.386, 3232/28000 datapoints
2025-03-06 21:47:42,040 - INFO - training batch 151, loss: 1.031, 4832/28000 datapoints
2025-03-06 21:47:42,190 - INFO - training batch 201, loss: 0.629, 6432/28000 datapoints
2025-03-06 21:47:42,337 - INFO - training batch 251, loss: 0.517, 8032/28000 datapoints
2025-03-06 21:47:42,483 - INFO - training batch 301, loss: 0.851, 9632/28000 datapoints
2025-03-06 21:47:42,629 - INFO - training batch 351, loss: 0.534, 11232/28000 datapoints
2025-03-06 21:47:42,775 - INFO - training batch 401, loss: 0.991, 12832/28000 datapoints
2025-03-06 21:47:42,922 - INFO - training batch 451, loss: 0.775, 14432/28000 datapoints
2025-03-06 21:47:43,069 - INFO - training batch 501, loss: 0.618, 16032/28000 datapoints
2025-03-06 21:47:43,219 - INFO - training batch 551, loss: 1.058, 17632/28000 datapoints
2025-03-06 21:47:43,387 - INFO - training batch 601, loss: 1.157, 19232/28000 datapoints
2025-03-06 21:47:43,534 - INFO - training batch 651, loss: 0.428, 20832/28000 datapoints
2025-03-06 21:47:43,683 - INFO - training batch 701, loss: 0.591, 22432/28000 datapoints
2025-03-06 21:47:43,840 - INFO - training batch 751, loss: 0.567, 24032/28000 datapoints
2025-03-06 21:47:43,992 - INFO - training batch 801, loss: 0.464, 25632/28000 datapoints
2025-03-06 21:47:44,144 - INFO - training batch 851, loss: 0.915, 27232/28000 datapoints
2025-03-06 21:47:44,216 - INFO - validation batch 1, loss: 0.430, 32/6976 datapoints
2025-03-06 21:47:44,264 - INFO - validation batch 51, loss: 1.667, 1632/6976 datapoints
2025-03-06 21:47:44,312 - INFO - validation batch 101, loss: 0.480, 3232/6976 datapoints
2025-03-06 21:47:44,359 - INFO - validation batch 151, loss: 0.723, 4832/6976 datapoints
2025-03-06 21:47:44,406 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:47:44,423 - INFO - Epoch 71/800 done.
2025-03-06 21:47:44,423 - INFO - Final validation performance:
Loss: 0.773, top-1 acc: 0.783top-5 acc: 0.783
2025-03-06 21:47:44,423 - INFO - Beginning epoch 72/800
2025-03-06 21:47:44,427 - INFO - training batch 1, loss: 0.728, 32/28000 datapoints
2025-03-06 21:47:44,580 - INFO - training batch 51, loss: 0.703, 1632/28000 datapoints
2025-03-06 21:47:44,735 - INFO - training batch 101, loss: 0.381, 3232/28000 datapoints
2025-03-06 21:47:44,890 - INFO - training batch 151, loss: 1.023, 4832/28000 datapoints
2025-03-06 21:47:45,073 - INFO - training batch 201, loss: 0.617, 6432/28000 datapoints
2025-03-06 21:47:45,234 - INFO - training batch 251, loss: 0.511, 8032/28000 datapoints
2025-03-06 21:47:45,387 - INFO - training batch 301, loss: 0.846, 9632/28000 datapoints
2025-03-06 21:47:45,537 - INFO - training batch 351, loss: 0.533, 11232/28000 datapoints
2025-03-06 21:47:45,689 - INFO - training batch 401, loss: 0.980, 12832/28000 datapoints
2025-03-06 21:47:45,846 - INFO - training batch 451, loss: 0.772, 14432/28000 datapoints
2025-03-06 21:47:46,004 - INFO - training batch 501, loss: 0.608, 16032/28000 datapoints
2025-03-06 21:47:46,158 - INFO - training batch 551, loss: 1.046, 17632/28000 datapoints
2025-03-06 21:47:46,310 - INFO - training batch 601, loss: 1.156, 19232/28000 datapoints
2025-03-06 21:47:46,461 - INFO - training batch 651, loss: 0.422, 20832/28000 datapoints
2025-03-06 21:47:46,620 - INFO - training batch 701, loss: 0.584, 22432/28000 datapoints
2025-03-06 21:47:46,770 - INFO - training batch 751, loss: 0.561, 24032/28000 datapoints
2025-03-06 21:47:46,922 - INFO - training batch 801, loss: 0.459, 25632/28000 datapoints
2025-03-06 21:47:47,074 - INFO - training batch 851, loss: 0.908, 27232/28000 datapoints
2025-03-06 21:47:47,148 - INFO - validation batch 1, loss: 0.423, 32/6976 datapoints
2025-03-06 21:47:47,201 - INFO - validation batch 51, loss: 1.661, 1632/6976 datapoints
2025-03-06 21:47:47,254 - INFO - validation batch 101, loss: 0.471, 3232/6976 datapoints
2025-03-06 21:47:47,304 - INFO - validation batch 151, loss: 0.714, 4832/6976 datapoints
2025-03-06 21:47:47,355 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:47:47,374 - INFO - Epoch 72/800 done.
2025-03-06 21:47:47,374 - INFO - Final validation performance:
Loss: 0.767, top-1 acc: 0.784top-5 acc: 0.784
2025-03-06 21:47:47,375 - INFO - Beginning epoch 73/800
2025-03-06 21:47:47,379 - INFO - training batch 1, loss: 0.721, 32/28000 datapoints
2025-03-06 21:47:47,529 - INFO - training batch 51, loss: 0.692, 1632/28000 datapoints
2025-03-06 21:47:47,678 - INFO - training batch 101, loss: 0.376, 3232/28000 datapoints
2025-03-06 21:47:47,825 - INFO - training batch 151, loss: 1.015, 4832/28000 datapoints
2025-03-06 21:47:47,977 - INFO - training batch 201, loss: 0.606, 6432/28000 datapoints
2025-03-06 21:47:48,124 - INFO - training batch 251, loss: 0.505, 8032/28000 datapoints
2025-03-06 21:47:48,272 - INFO - training batch 301, loss: 0.841, 9632/28000 datapoints
2025-03-06 21:47:48,418 - INFO - training batch 351, loss: 0.532, 11232/28000 datapoints
2025-03-06 21:47:48,565 - INFO - training batch 401, loss: 0.970, 12832/28000 datapoints
2025-03-06 21:47:48,713 - INFO - training batch 451, loss: 0.769, 14432/28000 datapoints
2025-03-06 21:47:48,863 - INFO - training batch 501, loss: 0.598, 16032/28000 datapoints
2025-03-06 21:47:49,011 - INFO - training batch 551, loss: 1.033, 17632/28000 datapoints
2025-03-06 21:47:49,158 - INFO - training batch 601, loss: 1.154, 19232/28000 datapoints
2025-03-06 21:47:49,307 - INFO - training batch 651, loss: 0.416, 20832/28000 datapoints
2025-03-06 21:47:49,463 - INFO - training batch 701, loss: 0.577, 22432/28000 datapoints
2025-03-06 21:47:49,614 - INFO - training batch 751, loss: 0.555, 24032/28000 datapoints
2025-03-06 21:47:49,762 - INFO - training batch 801, loss: 0.454, 25632/28000 datapoints
2025-03-06 21:47:49,912 - INFO - training batch 851, loss: 0.903, 27232/28000 datapoints
2025-03-06 21:47:49,993 - INFO - validation batch 1, loss: 0.415, 32/6976 datapoints
2025-03-06 21:47:50,041 - INFO - validation batch 51, loss: 1.656, 1632/6976 datapoints
2025-03-06 21:47:50,088 - INFO - validation batch 101, loss: 0.463, 3232/6976 datapoints
2025-03-06 21:47:50,141 - INFO - validation batch 151, loss: 0.705, 4832/6976 datapoints
2025-03-06 21:47:50,188 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:47:50,207 - INFO - Epoch 73/800 done.
2025-03-06 21:47:50,207 - INFO - Final validation performance:
Loss: 0.761, top-1 acc: 0.787top-5 acc: 0.787
2025-03-06 21:47:50,208 - INFO - Beginning epoch 74/800
2025-03-06 21:47:50,212 - INFO - training batch 1, loss: 0.714, 32/28000 datapoints
2025-03-06 21:47:50,363 - INFO - training batch 51, loss: 0.681, 1632/28000 datapoints
2025-03-06 21:47:50,513 - INFO - training batch 101, loss: 0.372, 3232/28000 datapoints
2025-03-06 21:47:50,661 - INFO - training batch 151, loss: 1.008, 4832/28000 datapoints
2025-03-06 21:47:50,809 - INFO - training batch 201, loss: 0.596, 6432/28000 datapoints
2025-03-06 21:47:50,959 - INFO - training batch 251, loss: 0.498, 8032/28000 datapoints
2025-03-06 21:47:51,106 - INFO - training batch 301, loss: 0.836, 9632/28000 datapoints
2025-03-06 21:47:51,255 - INFO - training batch 351, loss: 0.531, 11232/28000 datapoints
2025-03-06 21:47:51,402 - INFO - training batch 401, loss: 0.960, 12832/28000 datapoints
2025-03-06 21:47:51,550 - INFO - training batch 451, loss: 0.766, 14432/28000 datapoints
2025-03-06 21:47:51,697 - INFO - training batch 501, loss: 0.588, 16032/28000 datapoints
2025-03-06 21:47:51,847 - INFO - training batch 551, loss: 1.020, 17632/28000 datapoints
2025-03-06 21:47:52,005 - INFO - training batch 601, loss: 1.153, 19232/28000 datapoints
2025-03-06 21:47:52,156 - INFO - training batch 651, loss: 0.409, 20832/28000 datapoints
2025-03-06 21:47:52,304 - INFO - training batch 701, loss: 0.571, 22432/28000 datapoints
2025-03-06 21:47:52,451 - INFO - training batch 751, loss: 0.550, 24032/28000 datapoints
2025-03-06 21:47:52,597 - INFO - training batch 801, loss: 0.449, 25632/28000 datapoints
2025-03-06 21:47:52,745 - INFO - training batch 851, loss: 0.897, 27232/28000 datapoints
2025-03-06 21:47:52,817 - INFO - validation batch 1, loss: 0.409, 32/6976 datapoints
2025-03-06 21:47:52,867 - INFO - validation batch 51, loss: 1.650, 1632/6976 datapoints
2025-03-06 21:47:52,914 - INFO - validation batch 101, loss: 0.455, 3232/6976 datapoints
2025-03-06 21:47:52,961 - INFO - validation batch 151, loss: 0.696, 4832/6976 datapoints
2025-03-06 21:47:53,008 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:47:53,024 - INFO - Epoch 74/800 done.
2025-03-06 21:47:53,024 - INFO - Final validation performance:
Loss: 0.755, top-1 acc: 0.788top-5 acc: 0.788
2025-03-06 21:47:53,025 - INFO - Beginning epoch 75/800
2025-03-06 21:47:53,029 - INFO - training batch 1, loss: 0.706, 32/28000 datapoints
2025-03-06 21:47:53,178 - INFO - training batch 51, loss: 0.671, 1632/28000 datapoints
2025-03-06 21:47:53,329 - INFO - training batch 101, loss: 0.368, 3232/28000 datapoints
2025-03-06 21:47:53,478 - INFO - training batch 151, loss: 1.001, 4832/28000 datapoints
2025-03-06 21:47:53,627 - INFO - training batch 201, loss: 0.585, 6432/28000 datapoints
2025-03-06 21:47:53,774 - INFO - training batch 251, loss: 0.492, 8032/28000 datapoints
2025-03-06 21:47:53,923 - INFO - training batch 301, loss: 0.832, 9632/28000 datapoints
2025-03-06 21:47:54,074 - INFO - training batch 351, loss: 0.531, 11232/28000 datapoints
2025-03-06 21:47:54,221 - INFO - training batch 401, loss: 0.951, 12832/28000 datapoints
2025-03-06 21:47:54,368 - INFO - training batch 451, loss: 0.762, 14432/28000 datapoints
2025-03-06 21:47:54,515 - INFO - training batch 501, loss: 0.578, 16032/28000 datapoints
2025-03-06 21:47:54,666 - INFO - training batch 551, loss: 1.007, 17632/28000 datapoints
2025-03-06 21:47:54,814 - INFO - training batch 601, loss: 1.150, 19232/28000 datapoints
2025-03-06 21:47:54,964 - INFO - training batch 651, loss: 0.403, 20832/28000 datapoints
2025-03-06 21:47:55,144 - INFO - training batch 701, loss: 0.565, 22432/28000 datapoints
2025-03-06 21:47:55,298 - INFO - training batch 751, loss: 0.545, 24032/28000 datapoints
2025-03-06 21:47:55,445 - INFO - training batch 801, loss: 0.444, 25632/28000 datapoints
2025-03-06 21:47:55,600 - INFO - training batch 851, loss: 0.890, 27232/28000 datapoints
2025-03-06 21:47:55,678 - INFO - validation batch 1, loss: 0.403, 32/6976 datapoints
2025-03-06 21:47:55,725 - INFO - validation batch 51, loss: 1.643, 1632/6976 datapoints
2025-03-06 21:47:55,773 - INFO - validation batch 101, loss: 0.448, 3232/6976 datapoints
2025-03-06 21:47:55,820 - INFO - validation batch 151, loss: 0.686, 4832/6976 datapoints
2025-03-06 21:47:55,870 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:47:55,887 - INFO - Epoch 75/800 done.
2025-03-06 21:47:55,887 - INFO - Final validation performance:
Loss: 0.749, top-1 acc: 0.791top-5 acc: 0.791
2025-03-06 21:47:55,887 - INFO - Beginning epoch 76/800
2025-03-06 21:47:55,891 - INFO - training batch 1, loss: 0.699, 32/28000 datapoints
2025-03-06 21:47:56,046 - INFO - training batch 51, loss: 0.661, 1632/28000 datapoints
2025-03-06 21:47:56,197 - INFO - training batch 101, loss: 0.364, 3232/28000 datapoints
2025-03-06 21:47:56,348 - INFO - training batch 151, loss: 0.994, 4832/28000 datapoints
2025-03-06 21:47:56,494 - INFO - training batch 201, loss: 0.576, 6432/28000 datapoints
2025-03-06 21:47:56,643 - INFO - training batch 251, loss: 0.486, 8032/28000 datapoints
2025-03-06 21:47:56,792 - INFO - training batch 301, loss: 0.827, 9632/28000 datapoints
2025-03-06 21:47:56,941 - INFO - training batch 351, loss: 0.530, 11232/28000 datapoints
2025-03-06 21:47:57,089 - INFO - training batch 401, loss: 0.942, 12832/28000 datapoints
2025-03-06 21:47:57,236 - INFO - training batch 451, loss: 0.759, 14432/28000 datapoints
2025-03-06 21:47:57,383 - INFO - training batch 501, loss: 0.568, 16032/28000 datapoints
2025-03-06 21:47:57,531 - INFO - training batch 551, loss: 0.994, 17632/28000 datapoints
2025-03-06 21:47:57,679 - INFO - training batch 601, loss: 1.148, 19232/28000 datapoints
2025-03-06 21:47:57,828 - INFO - training batch 651, loss: 0.396, 20832/28000 datapoints
2025-03-06 21:47:57,978 - INFO - training batch 701, loss: 0.559, 22432/28000 datapoints
2025-03-06 21:47:58,133 - INFO - training batch 751, loss: 0.540, 24032/28000 datapoints
2025-03-06 21:47:58,282 - INFO - training batch 801, loss: 0.440, 25632/28000 datapoints
2025-03-06 21:47:58,427 - INFO - training batch 851, loss: 0.884, 27232/28000 datapoints
2025-03-06 21:47:58,500 - INFO - validation batch 1, loss: 0.396, 32/6976 datapoints
2025-03-06 21:47:58,547 - INFO - validation batch 51, loss: 1.638, 1632/6976 datapoints
2025-03-06 21:47:58,595 - INFO - validation batch 101, loss: 0.440, 3232/6976 datapoints
2025-03-06 21:47:58,642 - INFO - validation batch 151, loss: 0.677, 4832/6976 datapoints
2025-03-06 21:47:58,689 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:47:58,705 - INFO - Epoch 76/800 done.
2025-03-06 21:47:58,705 - INFO - Final validation performance:
Loss: 0.744, top-1 acc: 0.791top-5 acc: 0.791
2025-03-06 21:47:58,706 - INFO - Beginning epoch 77/800
2025-03-06 21:47:58,710 - INFO - training batch 1, loss: 0.692, 32/28000 datapoints
2025-03-06 21:47:58,867 - INFO - training batch 51, loss: 0.651, 1632/28000 datapoints
2025-03-06 21:47:59,014 - INFO - training batch 101, loss: 0.360, 3232/28000 datapoints
2025-03-06 21:47:59,164 - INFO - training batch 151, loss: 0.988, 4832/28000 datapoints
2025-03-06 21:47:59,311 - INFO - training batch 201, loss: 0.566, 6432/28000 datapoints
2025-03-06 21:47:59,458 - INFO - training batch 251, loss: 0.480, 8032/28000 datapoints
2025-03-06 21:47:59,605 - INFO - training batch 301, loss: 0.822, 9632/28000 datapoints
2025-03-06 21:47:59,751 - INFO - training batch 351, loss: 0.530, 11232/28000 datapoints
2025-03-06 21:47:59,902 - INFO - training batch 401, loss: 0.933, 12832/28000 datapoints
2025-03-06 21:48:00,055 - INFO - training batch 451, loss: 0.755, 14432/28000 datapoints
2025-03-06 21:48:00,214 - INFO - training batch 501, loss: 0.559, 16032/28000 datapoints
2025-03-06 21:48:00,390 - INFO - training batch 551, loss: 0.982, 17632/28000 datapoints
2025-03-06 21:48:00,576 - INFO - training batch 601, loss: 1.145, 19232/28000 datapoints
2025-03-06 21:48:00,744 - INFO - training batch 651, loss: 0.390, 20832/28000 datapoints
2025-03-06 21:48:00,916 - INFO - training batch 701, loss: 0.553, 22432/28000 datapoints
2025-03-06 21:48:01,068 - INFO - training batch 751, loss: 0.535, 24032/28000 datapoints
2025-03-06 21:48:01,223 - INFO - training batch 801, loss: 0.435, 25632/28000 datapoints
2025-03-06 21:48:01,372 - INFO - training batch 851, loss: 0.879, 27232/28000 datapoints
2025-03-06 21:48:01,446 - INFO - validation batch 1, loss: 0.390, 32/6976 datapoints
2025-03-06 21:48:01,493 - INFO - validation batch 51, loss: 1.631, 1632/6976 datapoints
2025-03-06 21:48:01,542 - INFO - validation batch 101, loss: 0.433, 3232/6976 datapoints
2025-03-06 21:48:01,592 - INFO - validation batch 151, loss: 0.669, 4832/6976 datapoints
2025-03-06 21:48:01,640 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:48:01,656 - INFO - Epoch 77/800 done.
2025-03-06 21:48:01,656 - INFO - Final validation performance:
Loss: 0.738, top-1 acc: 0.794top-5 acc: 0.794
2025-03-06 21:48:01,656 - INFO - Beginning epoch 78/800
2025-03-06 21:48:01,660 - INFO - training batch 1, loss: 0.686, 32/28000 datapoints
2025-03-06 21:48:01,864 - INFO - training batch 51, loss: 0.641, 1632/28000 datapoints
2025-03-06 21:48:02,020 - INFO - training batch 101, loss: 0.357, 3232/28000 datapoints
2025-03-06 21:48:02,176 - INFO - training batch 151, loss: 0.981, 4832/28000 datapoints
2025-03-06 21:48:02,326 - INFO - training batch 201, loss: 0.556, 6432/28000 datapoints
2025-03-06 21:48:02,479 - INFO - training batch 251, loss: 0.475, 8032/28000 datapoints
2025-03-06 21:48:02,631 - INFO - training batch 301, loss: 0.818, 9632/28000 datapoints
2025-03-06 21:48:02,779 - INFO - training batch 351, loss: 0.529, 11232/28000 datapoints
2025-03-06 21:48:02,930 - INFO - training batch 401, loss: 0.924, 12832/28000 datapoints
2025-03-06 21:48:03,078 - INFO - training batch 451, loss: 0.751, 14432/28000 datapoints
2025-03-06 21:48:03,227 - INFO - training batch 501, loss: 0.548, 16032/28000 datapoints
2025-03-06 21:48:03,376 - INFO - training batch 551, loss: 0.968, 17632/28000 datapoints
2025-03-06 21:48:03,524 - INFO - training batch 601, loss: 1.142, 19232/28000 datapoints
2025-03-06 21:48:03,670 - INFO - training batch 651, loss: 0.384, 20832/28000 datapoints
2025-03-06 21:48:03,817 - INFO - training batch 701, loss: 0.548, 22432/28000 datapoints
2025-03-06 21:48:03,972 - INFO - training batch 751, loss: 0.531, 24032/28000 datapoints
2025-03-06 21:48:04,123 - INFO - training batch 801, loss: 0.431, 25632/28000 datapoints
2025-03-06 21:48:04,271 - INFO - training batch 851, loss: 0.874, 27232/28000 datapoints
2025-03-06 21:48:04,344 - INFO - validation batch 1, loss: 0.384, 32/6976 datapoints
2025-03-06 21:48:04,392 - INFO - validation batch 51, loss: 1.625, 1632/6976 datapoints
2025-03-06 21:48:04,440 - INFO - validation batch 101, loss: 0.426, 3232/6976 datapoints
2025-03-06 21:48:04,488 - INFO - validation batch 151, loss: 0.660, 4832/6976 datapoints
2025-03-06 21:48:04,535 - INFO - validation batch 201, loss: 0.565, 6432/6976 datapoints
2025-03-06 21:48:04,551 - INFO - Epoch 78/800 done.
2025-03-06 21:48:04,551 - INFO - Final validation performance:
Loss: 0.732, top-1 acc: 0.795top-5 acc: 0.795
2025-03-06 21:48:04,552 - INFO - Beginning epoch 79/800
2025-03-06 21:48:04,556 - INFO - training batch 1, loss: 0.680, 32/28000 datapoints
2025-03-06 21:48:04,713 - INFO - training batch 51, loss: 0.631, 1632/28000 datapoints
2025-03-06 21:48:04,872 - INFO - training batch 101, loss: 0.353, 3232/28000 datapoints
2025-03-06 21:48:05,026 - INFO - training batch 151, loss: 0.974, 4832/28000 datapoints
2025-03-06 21:48:05,204 - INFO - training batch 201, loss: 0.546, 6432/28000 datapoints
2025-03-06 21:48:05,370 - INFO - training batch 251, loss: 0.469, 8032/28000 datapoints
2025-03-06 21:48:05,522 - INFO - training batch 301, loss: 0.814, 9632/28000 datapoints
2025-03-06 21:48:05,675 - INFO - training batch 351, loss: 0.530, 11232/28000 datapoints
2025-03-06 21:48:05,826 - INFO - training batch 401, loss: 0.917, 12832/28000 datapoints
2025-03-06 21:48:05,981 - INFO - training batch 451, loss: 0.747, 14432/28000 datapoints
2025-03-06 21:48:06,136 - INFO - training batch 501, loss: 0.539, 16032/28000 datapoints
2025-03-06 21:48:06,290 - INFO - training batch 551, loss: 0.956, 17632/28000 datapoints
2025-03-06 21:48:06,441 - INFO - training batch 601, loss: 1.139, 19232/28000 datapoints
2025-03-06 21:48:06,602 - INFO - training batch 651, loss: 0.378, 20832/28000 datapoints
2025-03-06 21:48:06,756 - INFO - training batch 701, loss: 0.543, 22432/28000 datapoints
2025-03-06 21:48:06,914 - INFO - training batch 751, loss: 0.526, 24032/28000 datapoints
2025-03-06 21:48:07,064 - INFO - training batch 801, loss: 0.427, 25632/28000 datapoints
2025-03-06 21:48:07,216 - INFO - training batch 851, loss: 0.868, 27232/28000 datapoints
2025-03-06 21:48:07,292 - INFO - validation batch 1, loss: 0.377, 32/6976 datapoints
2025-03-06 21:48:07,344 - INFO - validation batch 51, loss: 1.619, 1632/6976 datapoints
2025-03-06 21:48:07,398 - INFO - validation batch 101, loss: 0.419, 3232/6976 datapoints
2025-03-06 21:48:07,450 - INFO - validation batch 151, loss: 0.652, 4832/6976 datapoints
2025-03-06 21:48:07,501 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:48:07,518 - INFO - Epoch 79/800 done.
2025-03-06 21:48:07,518 - INFO - Final validation performance:
Loss: 0.727, top-1 acc: 0.797top-5 acc: 0.797
2025-03-06 21:48:07,519 - INFO - Beginning epoch 80/800
2025-03-06 21:48:07,524 - INFO - training batch 1, loss: 0.673, 32/28000 datapoints
2025-03-06 21:48:07,677 - INFO - training batch 51, loss: 0.622, 1632/28000 datapoints
2025-03-06 21:48:07,847 - INFO - training batch 101, loss: 0.349, 3232/28000 datapoints
2025-03-06 21:48:07,997 - INFO - training batch 151, loss: 0.966, 4832/28000 datapoints
2025-03-06 21:48:08,154 - INFO - training batch 201, loss: 0.537, 6432/28000 datapoints
2025-03-06 21:48:08,309 - INFO - training batch 251, loss: 0.464, 8032/28000 datapoints
2025-03-06 21:48:08,457 - INFO - training batch 301, loss: 0.810, 9632/28000 datapoints
2025-03-06 21:48:08,608 - INFO - training batch 351, loss: 0.530, 11232/28000 datapoints
2025-03-06 21:48:08,755 - INFO - training batch 401, loss: 0.911, 12832/28000 datapoints
2025-03-06 21:48:08,906 - INFO - training batch 451, loss: 0.743, 14432/28000 datapoints
2025-03-06 21:48:09,056 - INFO - training batch 501, loss: 0.529, 16032/28000 datapoints
2025-03-06 21:48:09,207 - INFO - training batch 551, loss: 0.944, 17632/28000 datapoints
2025-03-06 21:48:09,361 - INFO - training batch 601, loss: 1.137, 19232/28000 datapoints
2025-03-06 21:48:09,510 - INFO - training batch 651, loss: 0.372, 20832/28000 datapoints
2025-03-06 21:48:09,658 - INFO - training batch 701, loss: 0.538, 22432/28000 datapoints
2025-03-06 21:48:09,805 - INFO - training batch 751, loss: 0.521, 24032/28000 datapoints
2025-03-06 21:48:09,956 - INFO - training batch 801, loss: 0.423, 25632/28000 datapoints
2025-03-06 21:48:10,110 - INFO - training batch 851, loss: 0.862, 27232/28000 datapoints
2025-03-06 21:48:10,183 - INFO - validation batch 1, loss: 0.371, 32/6976 datapoints
2025-03-06 21:48:10,232 - INFO - validation batch 51, loss: 1.612, 1632/6976 datapoints
2025-03-06 21:48:10,282 - INFO - validation batch 101, loss: 0.413, 3232/6976 datapoints
2025-03-06 21:48:10,329 - INFO - validation batch 151, loss: 0.644, 4832/6976 datapoints
2025-03-06 21:48:10,379 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:48:10,395 - INFO - Epoch 80/800 done.
2025-03-06 21:48:10,395 - INFO - Final validation performance:
Loss: 0.721, top-1 acc: 0.799top-5 acc: 0.799
2025-03-06 21:48:10,395 - INFO - Beginning epoch 81/800
2025-03-06 21:48:10,400 - INFO - training batch 1, loss: 0.667, 32/28000 datapoints
2025-03-06 21:48:10,552 - INFO - training batch 51, loss: 0.612, 1632/28000 datapoints
2025-03-06 21:48:10,702 - INFO - training batch 101, loss: 0.346, 3232/28000 datapoints
2025-03-06 21:48:10,855 - INFO - training batch 151, loss: 0.959, 4832/28000 datapoints
2025-03-06 21:48:11,005 - INFO - training batch 201, loss: 0.528, 6432/28000 datapoints
2025-03-06 21:48:11,153 - INFO - training batch 251, loss: 0.459, 8032/28000 datapoints
2025-03-06 21:48:11,310 - INFO - training batch 301, loss: 0.807, 9632/28000 datapoints
2025-03-06 21:48:11,459 - INFO - training batch 351, loss: 0.529, 11232/28000 datapoints
2025-03-06 21:48:11,609 - INFO - training batch 401, loss: 0.904, 12832/28000 datapoints
2025-03-06 21:48:11,757 - INFO - training batch 451, loss: 0.739, 14432/28000 datapoints
2025-03-06 21:48:11,910 - INFO - training batch 501, loss: 0.520, 16032/28000 datapoints
2025-03-06 21:48:12,070 - INFO - training batch 551, loss: 0.934, 17632/28000 datapoints
2025-03-06 21:48:12,219 - INFO - training batch 601, loss: 1.136, 19232/28000 datapoints
2025-03-06 21:48:12,402 - INFO - training batch 651, loss: 0.367, 20832/28000 datapoints
2025-03-06 21:48:12,562 - INFO - training batch 701, loss: 0.533, 22432/28000 datapoints
2025-03-06 21:48:12,711 - INFO - training batch 751, loss: 0.517, 24032/28000 datapoints
2025-03-06 21:48:12,861 - INFO - training batch 801, loss: 0.419, 25632/28000 datapoints
2025-03-06 21:48:13,009 - INFO - training batch 851, loss: 0.856, 27232/28000 datapoints
2025-03-06 21:48:13,081 - INFO - validation batch 1, loss: 0.364, 32/6976 datapoints
2025-03-06 21:48:13,129 - INFO - validation batch 51, loss: 1.606, 1632/6976 datapoints
2025-03-06 21:48:13,176 - INFO - validation batch 101, loss: 0.407, 3232/6976 datapoints
2025-03-06 21:48:13,225 - INFO - validation batch 151, loss: 0.637, 4832/6976 datapoints
2025-03-06 21:48:13,273 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:48:13,290 - INFO - Epoch 81/800 done.
2025-03-06 21:48:13,290 - INFO - Final validation performance:
Loss: 0.716, top-1 acc: 0.801top-5 acc: 0.801
2025-03-06 21:48:13,290 - INFO - Beginning epoch 82/800
2025-03-06 21:48:13,294 - INFO - training batch 1, loss: 0.661, 32/28000 datapoints
2025-03-06 21:48:13,443 - INFO - training batch 51, loss: 0.602, 1632/28000 datapoints
2025-03-06 21:48:13,607 - INFO - training batch 101, loss: 0.343, 3232/28000 datapoints
2025-03-06 21:48:13,775 - INFO - training batch 151, loss: 0.952, 4832/28000 datapoints
2025-03-06 21:48:13,937 - INFO - training batch 201, loss: 0.519, 6432/28000 datapoints
2025-03-06 21:48:14,090 - INFO - training batch 251, loss: 0.454, 8032/28000 datapoints
2025-03-06 21:48:14,237 - INFO - training batch 301, loss: 0.804, 9632/28000 datapoints
2025-03-06 21:48:14,392 - INFO - training batch 351, loss: 0.530, 11232/28000 datapoints
2025-03-06 21:48:14,543 - INFO - training batch 401, loss: 0.898, 12832/28000 datapoints
2025-03-06 21:48:14,695 - INFO - training batch 451, loss: 0.735, 14432/28000 datapoints
2025-03-06 21:48:14,846 - INFO - training batch 501, loss: 0.511, 16032/28000 datapoints
2025-03-06 21:48:14,995 - INFO - training batch 551, loss: 0.921, 17632/28000 datapoints
2025-03-06 21:48:15,153 - INFO - training batch 601, loss: 1.134, 19232/28000 datapoints
2025-03-06 21:48:15,324 - INFO - training batch 651, loss: 0.361, 20832/28000 datapoints
2025-03-06 21:48:15,480 - INFO - training batch 701, loss: 0.528, 22432/28000 datapoints
2025-03-06 21:48:15,629 - INFO - training batch 751, loss: 0.513, 24032/28000 datapoints
2025-03-06 21:48:15,777 - INFO - training batch 801, loss: 0.415, 25632/28000 datapoints
2025-03-06 21:48:15,926 - INFO - training batch 851, loss: 0.850, 27232/28000 datapoints
2025-03-06 21:48:15,999 - INFO - validation batch 1, loss: 0.358, 32/6976 datapoints
2025-03-06 21:48:16,046 - INFO - validation batch 51, loss: 1.600, 1632/6976 datapoints
2025-03-06 21:48:16,097 - INFO - validation batch 101, loss: 0.401, 3232/6976 datapoints
2025-03-06 21:48:16,144 - INFO - validation batch 151, loss: 0.629, 4832/6976 datapoints
2025-03-06 21:48:16,190 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:48:16,207 - INFO - Epoch 82/800 done.
2025-03-06 21:48:16,207 - INFO - Final validation performance:
Loss: 0.711, top-1 acc: 0.802top-5 acc: 0.802
2025-03-06 21:48:16,208 - INFO - Beginning epoch 83/800
2025-03-06 21:48:16,212 - INFO - training batch 1, loss: 0.655, 32/28000 datapoints
2025-03-06 21:48:16,364 - INFO - training batch 51, loss: 0.593, 1632/28000 datapoints
2025-03-06 21:48:16,520 - INFO - training batch 101, loss: 0.339, 3232/28000 datapoints
2025-03-06 21:48:16,670 - INFO - training batch 151, loss: 0.945, 4832/28000 datapoints
2025-03-06 21:48:16,820 - INFO - training batch 201, loss: 0.511, 6432/28000 datapoints
2025-03-06 21:48:16,971 - INFO - training batch 251, loss: 0.449, 8032/28000 datapoints
2025-03-06 21:48:17,120 - INFO - training batch 301, loss: 0.801, 9632/28000 datapoints
2025-03-06 21:48:17,269 - INFO - training batch 351, loss: 0.530, 11232/28000 datapoints
2025-03-06 21:48:17,418 - INFO - training batch 401, loss: 0.892, 12832/28000 datapoints
2025-03-06 21:48:17,573 - INFO - training batch 451, loss: 0.731, 14432/28000 datapoints
2025-03-06 21:48:17,722 - INFO - training batch 501, loss: 0.501, 16032/28000 datapoints
2025-03-06 21:48:17,874 - INFO - training batch 551, loss: 0.909, 17632/28000 datapoints
2025-03-06 21:48:18,023 - INFO - training batch 601, loss: 1.131, 19232/28000 datapoints
2025-03-06 21:48:18,174 - INFO - training batch 651, loss: 0.354, 20832/28000 datapoints
2025-03-06 21:48:18,323 - INFO - training batch 701, loss: 0.524, 22432/28000 datapoints
2025-03-06 21:48:18,470 - INFO - training batch 751, loss: 0.508, 24032/28000 datapoints
2025-03-06 21:48:18,620 - INFO - training batch 801, loss: 0.411, 25632/28000 datapoints
2025-03-06 21:48:18,768 - INFO - training batch 851, loss: 0.844, 27232/28000 datapoints
2025-03-06 21:48:18,846 - INFO - validation batch 1, loss: 0.352, 32/6976 datapoints
2025-03-06 21:48:18,892 - INFO - validation batch 51, loss: 1.594, 1632/6976 datapoints
2025-03-06 21:48:18,940 - INFO - validation batch 101, loss: 0.395, 3232/6976 datapoints
2025-03-06 21:48:18,987 - INFO - validation batch 151, loss: 0.622, 4832/6976 datapoints
2025-03-06 21:48:19,035 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:48:19,052 - INFO - Epoch 83/800 done.
2025-03-06 21:48:19,052 - INFO - Final validation performance:
Loss: 0.706, top-1 acc: 0.803top-5 acc: 0.803
2025-03-06 21:48:19,053 - INFO - Beginning epoch 84/800
2025-03-06 21:48:19,057 - INFO - training batch 1, loss: 0.649, 32/28000 datapoints
2025-03-06 21:48:19,204 - INFO - training batch 51, loss: 0.583, 1632/28000 datapoints
2025-03-06 21:48:19,354 - INFO - training batch 101, loss: 0.336, 3232/28000 datapoints
2025-03-06 21:48:19,502 - INFO - training batch 151, loss: 0.937, 4832/28000 datapoints
2025-03-06 21:48:19,651 - INFO - training batch 201, loss: 0.503, 6432/28000 datapoints
2025-03-06 21:48:19,806 - INFO - training batch 251, loss: 0.444, 8032/28000 datapoints
2025-03-06 21:48:19,963 - INFO - training batch 301, loss: 0.797, 9632/28000 datapoints
2025-03-06 21:48:20,115 - INFO - training batch 351, loss: 0.531, 11232/28000 datapoints
2025-03-06 21:48:20,265 - INFO - training batch 401, loss: 0.885, 12832/28000 datapoints
2025-03-06 21:48:20,422 - INFO - training batch 451, loss: 0.727, 14432/28000 datapoints
2025-03-06 21:48:20,575 - INFO - training batch 501, loss: 0.492, 16032/28000 datapoints
2025-03-06 21:48:20,729 - INFO - training batch 551, loss: 0.898, 17632/28000 datapoints
2025-03-06 21:48:20,881 - INFO - training batch 601, loss: 1.128, 19232/28000 datapoints
2025-03-06 21:48:21,029 - INFO - training batch 651, loss: 0.349, 20832/28000 datapoints
2025-03-06 21:48:21,177 - INFO - training batch 701, loss: 0.519, 22432/28000 datapoints
2025-03-06 21:48:21,327 - INFO - training batch 751, loss: 0.504, 24032/28000 datapoints
2025-03-06 21:48:21,475 - INFO - training batch 801, loss: 0.407, 25632/28000 datapoints
2025-03-06 21:48:21,624 - INFO - training batch 851, loss: 0.838, 27232/28000 datapoints
2025-03-06 21:48:21,697 - INFO - validation batch 1, loss: 0.347, 32/6976 datapoints
2025-03-06 21:48:21,744 - INFO - validation batch 51, loss: 1.588, 1632/6976 datapoints
2025-03-06 21:48:21,792 - INFO - validation batch 101, loss: 0.390, 3232/6976 datapoints
2025-03-06 21:48:21,843 - INFO - validation batch 151, loss: 0.614, 4832/6976 datapoints
2025-03-06 21:48:21,891 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:48:21,907 - INFO - Epoch 84/800 done.
2025-03-06 21:48:21,908 - INFO - Final validation performance:
Loss: 0.701, top-1 acc: 0.805top-5 acc: 0.805
2025-03-06 21:48:21,908 - INFO - Beginning epoch 85/800
2025-03-06 21:48:21,912 - INFO - training batch 1, loss: 0.643, 32/28000 datapoints
2025-03-06 21:48:22,067 - INFO - training batch 51, loss: 0.574, 1632/28000 datapoints
2025-03-06 21:48:22,224 - INFO - training batch 101, loss: 0.333, 3232/28000 datapoints
2025-03-06 21:48:22,374 - INFO - training batch 151, loss: 0.929, 4832/28000 datapoints
2025-03-06 21:48:22,522 - INFO - training batch 201, loss: 0.496, 6432/28000 datapoints
2025-03-06 21:48:22,673 - INFO - training batch 251, loss: 0.439, 8032/28000 datapoints
2025-03-06 21:48:22,822 - INFO - training batch 301, loss: 0.794, 9632/28000 datapoints
2025-03-06 21:48:22,973 - INFO - training batch 351, loss: 0.531, 11232/28000 datapoints
2025-03-06 21:48:23,121 - INFO - training batch 401, loss: 0.881, 12832/28000 datapoints
2025-03-06 21:48:23,270 - INFO - training batch 451, loss: 0.724, 14432/28000 datapoints
2025-03-06 21:48:23,420 - INFO - training batch 501, loss: 0.483, 16032/28000 datapoints
2025-03-06 21:48:23,569 - INFO - training batch 551, loss: 0.886, 17632/28000 datapoints
2025-03-06 21:48:23,718 - INFO - training batch 601, loss: 1.124, 19232/28000 datapoints
2025-03-06 21:48:23,870 - INFO - training batch 651, loss: 0.343, 20832/28000 datapoints
2025-03-06 21:48:24,017 - INFO - training batch 701, loss: 0.514, 22432/28000 datapoints
2025-03-06 21:48:24,169 - INFO - training batch 751, loss: 0.499, 24032/28000 datapoints
2025-03-06 21:48:24,317 - INFO - training batch 801, loss: 0.403, 25632/28000 datapoints
2025-03-06 21:48:24,467 - INFO - training batch 851, loss: 0.832, 27232/28000 datapoints
2025-03-06 21:48:24,540 - INFO - validation batch 1, loss: 0.342, 32/6976 datapoints
2025-03-06 21:48:24,587 - INFO - validation batch 51, loss: 1.582, 1632/6976 datapoints
2025-03-06 21:48:24,635 - INFO - validation batch 101, loss: 0.385, 3232/6976 datapoints
2025-03-06 21:48:24,683 - INFO - validation batch 151, loss: 0.606, 4832/6976 datapoints
2025-03-06 21:48:24,737 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:48:24,754 - INFO - Epoch 85/800 done.
2025-03-06 21:48:24,754 - INFO - Final validation performance:
Loss: 0.696, top-1 acc: 0.807top-5 acc: 0.807
2025-03-06 21:48:24,755 - INFO - Beginning epoch 86/800
2025-03-06 21:48:24,759 - INFO - training batch 1, loss: 0.637, 32/28000 datapoints
2025-03-06 21:48:24,914 - INFO - training batch 51, loss: 0.565, 1632/28000 datapoints
2025-03-06 21:48:25,074 - INFO - training batch 101, loss: 0.329, 3232/28000 datapoints
2025-03-06 21:48:25,234 - INFO - training batch 151, loss: 0.923, 4832/28000 datapoints
2025-03-06 21:48:25,406 - INFO - training batch 201, loss: 0.488, 6432/28000 datapoints
2025-03-06 21:48:25,568 - INFO - training batch 251, loss: 0.434, 8032/28000 datapoints
2025-03-06 21:48:25,720 - INFO - training batch 301, loss: 0.791, 9632/28000 datapoints
2025-03-06 21:48:25,886 - INFO - training batch 351, loss: 0.531, 11232/28000 datapoints
2025-03-06 21:48:26,044 - INFO - training batch 401, loss: 0.876, 12832/28000 datapoints
2025-03-06 21:48:26,200 - INFO - training batch 451, loss: 0.719, 14432/28000 datapoints
2025-03-06 21:48:26,361 - INFO - training batch 501, loss: 0.475, 16032/28000 datapoints
2025-03-06 21:48:26,519 - INFO - training batch 551, loss: 0.875, 17632/28000 datapoints
2025-03-06 21:48:26,682 - INFO - training batch 601, loss: 1.122, 19232/28000 datapoints
2025-03-06 21:48:26,843 - INFO - training batch 651, loss: 0.338, 20832/28000 datapoints
2025-03-06 21:48:26,995 - INFO - training batch 701, loss: 0.509, 22432/28000 datapoints
2025-03-06 21:48:27,151 - INFO - training batch 751, loss: 0.495, 24032/28000 datapoints
2025-03-06 21:48:27,304 - INFO - training batch 801, loss: 0.400, 25632/28000 datapoints
2025-03-06 21:48:27,455 - INFO - training batch 851, loss: 0.827, 27232/28000 datapoints
2025-03-06 21:48:27,532 - INFO - validation batch 1, loss: 0.336, 32/6976 datapoints
2025-03-06 21:48:27,582 - INFO - validation batch 51, loss: 1.575, 1632/6976 datapoints
2025-03-06 21:48:27,635 - INFO - validation batch 101, loss: 0.380, 3232/6976 datapoints
2025-03-06 21:48:27,689 - INFO - validation batch 151, loss: 0.599, 4832/6976 datapoints
2025-03-06 21:48:27,741 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:48:27,757 - INFO - Epoch 86/800 done.
2025-03-06 21:48:27,758 - INFO - Final validation performance:
Loss: 0.691, top-1 acc: 0.809top-5 acc: 0.809
2025-03-06 21:48:27,758 - INFO - Beginning epoch 87/800
2025-03-06 21:48:27,763 - INFO - training batch 1, loss: 0.631, 32/28000 datapoints
2025-03-06 21:48:27,918 - INFO - training batch 51, loss: 0.557, 1632/28000 datapoints
2025-03-06 21:48:28,073 - INFO - training batch 101, loss: 0.326, 3232/28000 datapoints
2025-03-06 21:48:28,232 - INFO - training batch 151, loss: 0.916, 4832/28000 datapoints
2025-03-06 21:48:28,386 - INFO - training batch 201, loss: 0.481, 6432/28000 datapoints
2025-03-06 21:48:28,538 - INFO - training batch 251, loss: 0.429, 8032/28000 datapoints
2025-03-06 21:48:28,692 - INFO - training batch 301, loss: 0.788, 9632/28000 datapoints
2025-03-06 21:48:28,848 - INFO - training batch 351, loss: 0.532, 11232/28000 datapoints
2025-03-06 21:48:28,999 - INFO - training batch 401, loss: 0.871, 12832/28000 datapoints
2025-03-06 21:48:29,151 - INFO - training batch 451, loss: 0.716, 14432/28000 datapoints
2025-03-06 21:48:29,307 - INFO - training batch 501, loss: 0.466, 16032/28000 datapoints
2025-03-06 21:48:29,461 - INFO - training batch 551, loss: 0.863, 17632/28000 datapoints
2025-03-06 21:48:29,612 - INFO - training batch 601, loss: 1.119, 19232/28000 datapoints
2025-03-06 21:48:29,765 - INFO - training batch 651, loss: 0.332, 20832/28000 datapoints
2025-03-06 21:48:29,920 - INFO - training batch 701, loss: 0.505, 22432/28000 datapoints
2025-03-06 21:48:30,071 - INFO - training batch 751, loss: 0.491, 24032/28000 datapoints
2025-03-06 21:48:30,228 - INFO - training batch 801, loss: 0.396, 25632/28000 datapoints
2025-03-06 21:48:30,381 - INFO - training batch 851, loss: 0.823, 27232/28000 datapoints
2025-03-06 21:48:30,458 - INFO - validation batch 1, loss: 0.331, 32/6976 datapoints
2025-03-06 21:48:30,515 - INFO - validation batch 51, loss: 1.568, 1632/6976 datapoints
2025-03-06 21:48:30,567 - INFO - validation batch 101, loss: 0.375, 3232/6976 datapoints
2025-03-06 21:48:30,625 - INFO - validation batch 151, loss: 0.591, 4832/6976 datapoints
2025-03-06 21:48:30,690 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:48:30,707 - INFO - Epoch 87/800 done.
2025-03-06 21:48:30,707 - INFO - Final validation performance:
Loss: 0.686, top-1 acc: 0.810top-5 acc: 0.810
2025-03-06 21:48:30,708 - INFO - Beginning epoch 88/800
2025-03-06 21:48:30,712 - INFO - training batch 1, loss: 0.626, 32/28000 datapoints
2025-03-06 21:48:30,884 - INFO - training batch 51, loss: 0.548, 1632/28000 datapoints
2025-03-06 21:48:31,062 - INFO - training batch 101, loss: 0.324, 3232/28000 datapoints
2025-03-06 21:48:31,239 - INFO - training batch 151, loss: 0.909, 4832/28000 datapoints
2025-03-06 21:48:31,432 - INFO - training batch 201, loss: 0.475, 6432/28000 datapoints
2025-03-06 21:48:31,610 - INFO - training batch 251, loss: 0.425, 8032/28000 datapoints
2025-03-06 21:48:31,775 - INFO - training batch 301, loss: 0.785, 9632/28000 datapoints
2025-03-06 21:48:31,957 - INFO - training batch 351, loss: 0.531, 11232/28000 datapoints
2025-03-06 21:48:32,125 - INFO - training batch 401, loss: 0.867, 12832/28000 datapoints
2025-03-06 21:48:32,284 - INFO - training batch 451, loss: 0.711, 14432/28000 datapoints
2025-03-06 21:48:32,446 - INFO - training batch 501, loss: 0.458, 16032/28000 datapoints
2025-03-06 21:48:32,605 - INFO - training batch 551, loss: 0.852, 17632/28000 datapoints
2025-03-06 21:48:32,765 - INFO - training batch 601, loss: 1.116, 19232/28000 datapoints
2025-03-06 21:48:32,922 - INFO - training batch 651, loss: 0.327, 20832/28000 datapoints
2025-03-06 21:48:33,075 - INFO - training batch 701, loss: 0.501, 22432/28000 datapoints
2025-03-06 21:48:33,229 - INFO - training batch 751, loss: 0.487, 24032/28000 datapoints
2025-03-06 21:48:33,385 - INFO - training batch 801, loss: 0.392, 25632/28000 datapoints
2025-03-06 21:48:33,538 - INFO - training batch 851, loss: 0.819, 27232/28000 datapoints
2025-03-06 21:48:33,614 - INFO - validation batch 1, loss: 0.326, 32/6976 datapoints
2025-03-06 21:48:33,666 - INFO - validation batch 51, loss: 1.561, 1632/6976 datapoints
2025-03-06 21:48:33,718 - INFO - validation batch 101, loss: 0.370, 3232/6976 datapoints
2025-03-06 21:48:33,768 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 21:48:33,820 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:48:33,845 - INFO - Epoch 88/800 done.
2025-03-06 21:48:33,845 - INFO - Final validation performance:
Loss: 0.682, top-1 acc: 0.811top-5 acc: 0.811
2025-03-06 21:48:33,846 - INFO - Beginning epoch 89/800
2025-03-06 21:48:33,851 - INFO - training batch 1, loss: 0.620, 32/28000 datapoints
2025-03-06 21:48:34,007 - INFO - training batch 51, loss: 0.539, 1632/28000 datapoints
2025-03-06 21:48:34,162 - INFO - training batch 101, loss: 0.321, 3232/28000 datapoints
2025-03-06 21:48:34,317 - INFO - training batch 151, loss: 0.901, 4832/28000 datapoints
2025-03-06 21:48:34,471 - INFO - training batch 201, loss: 0.468, 6432/28000 datapoints
2025-03-06 21:48:34,623 - INFO - training batch 251, loss: 0.421, 8032/28000 datapoints
2025-03-06 21:48:34,774 - INFO - training batch 301, loss: 0.782, 9632/28000 datapoints
2025-03-06 21:48:34,931 - INFO - training batch 351, loss: 0.531, 11232/28000 datapoints
2025-03-06 21:48:35,085 - INFO - training batch 401, loss: 0.863, 12832/28000 datapoints
2025-03-06 21:48:35,242 - INFO - training batch 451, loss: 0.707, 14432/28000 datapoints
2025-03-06 21:48:35,397 - INFO - training batch 501, loss: 0.450, 16032/28000 datapoints
2025-03-06 21:48:35,573 - INFO - training batch 551, loss: 0.842, 17632/28000 datapoints
2025-03-06 21:48:35,726 - INFO - training batch 601, loss: 1.113, 19232/28000 datapoints
2025-03-06 21:48:35,884 - INFO - training batch 651, loss: 0.322, 20832/28000 datapoints
2025-03-06 21:48:36,037 - INFO - training batch 701, loss: 0.496, 22432/28000 datapoints
2025-03-06 21:48:36,194 - INFO - training batch 751, loss: 0.483, 24032/28000 datapoints
2025-03-06 21:48:36,347 - INFO - training batch 801, loss: 0.389, 25632/28000 datapoints
2025-03-06 21:48:36,499 - INFO - training batch 851, loss: 0.814, 27232/28000 datapoints
2025-03-06 21:48:36,574 - INFO - validation batch 1, loss: 0.321, 32/6976 datapoints
2025-03-06 21:48:36,626 - INFO - validation batch 51, loss: 1.553, 1632/6976 datapoints
2025-03-06 21:48:36,681 - INFO - validation batch 101, loss: 0.366, 3232/6976 datapoints
2025-03-06 21:48:36,729 - INFO - validation batch 151, loss: 0.579, 4832/6976 datapoints
2025-03-06 21:48:36,778 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:48:36,794 - INFO - Epoch 89/800 done.
2025-03-06 21:48:36,794 - INFO - Final validation performance:
Loss: 0.677, top-1 acc: 0.812top-5 acc: 0.812
2025-03-06 21:48:36,795 - INFO - Beginning epoch 90/800
2025-03-06 21:48:36,799 - INFO - training batch 1, loss: 0.614, 32/28000 datapoints
2025-03-06 21:48:36,951 - INFO - training batch 51, loss: 0.531, 1632/28000 datapoints
2025-03-06 21:48:37,100 - INFO - training batch 101, loss: 0.318, 3232/28000 datapoints
2025-03-06 21:48:37,251 - INFO - training batch 151, loss: 0.894, 4832/28000 datapoints
2025-03-06 21:48:37,399 - INFO - training batch 201, loss: 0.462, 6432/28000 datapoints
2025-03-06 21:48:37,546 - INFO - training batch 251, loss: 0.417, 8032/28000 datapoints
2025-03-06 21:48:37,694 - INFO - training batch 301, loss: 0.779, 9632/28000 datapoints
2025-03-06 21:48:37,857 - INFO - training batch 351, loss: 0.531, 11232/28000 datapoints
2025-03-06 21:48:38,021 - INFO - training batch 401, loss: 0.859, 12832/28000 datapoints
2025-03-06 21:48:38,172 - INFO - training batch 451, loss: 0.703, 14432/28000 datapoints
2025-03-06 21:48:38,325 - INFO - training batch 501, loss: 0.443, 16032/28000 datapoints
2025-03-06 21:48:38,479 - INFO - training batch 551, loss: 0.831, 17632/28000 datapoints
2025-03-06 21:48:38,629 - INFO - training batch 601, loss: 1.111, 19232/28000 datapoints
2025-03-06 21:48:38,783 - INFO - training batch 651, loss: 0.316, 20832/28000 datapoints
2025-03-06 21:48:38,933 - INFO - training batch 701, loss: 0.492, 22432/28000 datapoints
2025-03-06 21:48:39,081 - INFO - training batch 751, loss: 0.479, 24032/28000 datapoints
2025-03-06 21:48:39,230 - INFO - training batch 801, loss: 0.385, 25632/28000 datapoints
2025-03-06 21:48:39,386 - INFO - training batch 851, loss: 0.809, 27232/28000 datapoints
2025-03-06 21:48:39,460 - INFO - validation batch 1, loss: 0.316, 32/6976 datapoints
2025-03-06 21:48:39,507 - INFO - validation batch 51, loss: 1.547, 1632/6976 datapoints
2025-03-06 21:48:39,553 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 21:48:39,600 - INFO - validation batch 151, loss: 0.572, 4832/6976 datapoints
2025-03-06 21:48:39,646 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:48:39,664 - INFO - Epoch 90/800 done.
2025-03-06 21:48:39,664 - INFO - Final validation performance:
Loss: 0.673, top-1 acc: 0.813top-5 acc: 0.813
2025-03-06 21:48:39,664 - INFO - Beginning epoch 91/800
2025-03-06 21:48:39,668 - INFO - training batch 1, loss: 0.609, 32/28000 datapoints
2025-03-06 21:48:39,822 - INFO - training batch 51, loss: 0.522, 1632/28000 datapoints
2025-03-06 21:48:39,973 - INFO - training batch 101, loss: 0.316, 3232/28000 datapoints
2025-03-06 21:48:40,122 - INFO - training batch 151, loss: 0.887, 4832/28000 datapoints
2025-03-06 21:48:40,277 - INFO - training batch 201, loss: 0.455, 6432/28000 datapoints
2025-03-06 21:48:40,429 - INFO - training batch 251, loss: 0.413, 8032/28000 datapoints
2025-03-06 21:48:40,578 - INFO - training batch 301, loss: 0.778, 9632/28000 datapoints
2025-03-06 21:48:40,728 - INFO - training batch 351, loss: 0.532, 11232/28000 datapoints
2025-03-06 21:48:40,888 - INFO - training batch 401, loss: 0.855, 12832/28000 datapoints
2025-03-06 21:48:41,041 - INFO - training batch 451, loss: 0.699, 14432/28000 datapoints
2025-03-06 21:48:41,190 - INFO - training batch 501, loss: 0.435, 16032/28000 datapoints
2025-03-06 21:48:41,349 - INFO - training batch 551, loss: 0.821, 17632/28000 datapoints
2025-03-06 21:48:41,502 - INFO - training batch 601, loss: 1.108, 19232/28000 datapoints
2025-03-06 21:48:41,653 - INFO - training batch 651, loss: 0.311, 20832/28000 datapoints
2025-03-06 21:48:41,802 - INFO - training batch 701, loss: 0.488, 22432/28000 datapoints
2025-03-06 21:48:41,954 - INFO - training batch 751, loss: 0.476, 24032/28000 datapoints
2025-03-06 21:48:42,104 - INFO - training batch 801, loss: 0.382, 25632/28000 datapoints
2025-03-06 21:48:42,272 - INFO - training batch 851, loss: 0.804, 27232/28000 datapoints
2025-03-06 21:48:42,349 - INFO - validation batch 1, loss: 0.310, 32/6976 datapoints
2025-03-06 21:48:42,397 - INFO - validation batch 51, loss: 1.541, 1632/6976 datapoints
2025-03-06 21:48:42,445 - INFO - validation batch 101, loss: 0.358, 3232/6976 datapoints
2025-03-06 21:48:42,493 - INFO - validation batch 151, loss: 0.568, 4832/6976 datapoints
2025-03-06 21:48:42,540 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:48:42,556 - INFO - Epoch 91/800 done.
2025-03-06 21:48:42,556 - INFO - Final validation performance:
Loss: 0.669, top-1 acc: 0.815top-5 acc: 0.815
2025-03-06 21:48:42,557 - INFO - Beginning epoch 92/800
2025-03-06 21:48:42,561 - INFO - training batch 1, loss: 0.603, 32/28000 datapoints
2025-03-06 21:48:42,712 - INFO - training batch 51, loss: 0.514, 1632/28000 datapoints
2025-03-06 21:48:42,867 - INFO - training batch 101, loss: 0.314, 3232/28000 datapoints
2025-03-06 21:48:43,016 - INFO - training batch 151, loss: 0.880, 4832/28000 datapoints
2025-03-06 21:48:43,164 - INFO - training batch 201, loss: 0.448, 6432/28000 datapoints
2025-03-06 21:48:43,314 - INFO - training batch 251, loss: 0.409, 8032/28000 datapoints
2025-03-06 21:48:43,466 - INFO - training batch 301, loss: 0.776, 9632/28000 datapoints
2025-03-06 21:48:43,615 - INFO - training batch 351, loss: 0.532, 11232/28000 datapoints
2025-03-06 21:48:43,765 - INFO - training batch 401, loss: 0.850, 12832/28000 datapoints
2025-03-06 21:48:43,918 - INFO - training batch 451, loss: 0.695, 14432/28000 datapoints
2025-03-06 21:48:44,078 - INFO - training batch 501, loss: 0.427, 16032/28000 datapoints
2025-03-06 21:48:44,232 - INFO - training batch 551, loss: 0.813, 17632/28000 datapoints
2025-03-06 21:48:44,382 - INFO - training batch 601, loss: 1.106, 19232/28000 datapoints
2025-03-06 21:48:44,538 - INFO - training batch 651, loss: 0.305, 20832/28000 datapoints
2025-03-06 21:48:44,690 - INFO - training batch 701, loss: 0.483, 22432/28000 datapoints
2025-03-06 21:48:44,843 - INFO - training batch 751, loss: 0.473, 24032/28000 datapoints
2025-03-06 21:48:45,007 - INFO - training batch 801, loss: 0.379, 25632/28000 datapoints
2025-03-06 21:48:45,165 - INFO - training batch 851, loss: 0.799, 27232/28000 datapoints
2025-03-06 21:48:45,242 - INFO - validation batch 1, loss: 0.306, 32/6976 datapoints
2025-03-06 21:48:45,294 - INFO - validation batch 51, loss: 1.535, 1632/6976 datapoints
2025-03-06 21:48:45,346 - INFO - validation batch 101, loss: 0.354, 3232/6976 datapoints
2025-03-06 21:48:45,401 - INFO - validation batch 151, loss: 0.562, 4832/6976 datapoints
2025-03-06 21:48:45,459 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:48:45,481 - INFO - Epoch 92/800 done.
2025-03-06 21:48:45,481 - INFO - Final validation performance:
Loss: 0.665, top-1 acc: 0.816top-5 acc: 0.816
2025-03-06 21:48:45,482 - INFO - Beginning epoch 93/800
2025-03-06 21:48:45,487 - INFO - training batch 1, loss: 0.597, 32/28000 datapoints
2025-03-06 21:48:45,670 - INFO - training batch 51, loss: 0.505, 1632/28000 datapoints
2025-03-06 21:48:45,819 - INFO - training batch 101, loss: 0.312, 3232/28000 datapoints
2025-03-06 21:48:45,979 - INFO - training batch 151, loss: 0.872, 4832/28000 datapoints
2025-03-06 21:48:46,139 - INFO - training batch 201, loss: 0.442, 6432/28000 datapoints
2025-03-06 21:48:46,292 - INFO - training batch 251, loss: 0.406, 8032/28000 datapoints
2025-03-06 21:48:46,442 - INFO - training batch 301, loss: 0.773, 9632/28000 datapoints
2025-03-06 21:48:46,593 - INFO - training batch 351, loss: 0.532, 11232/28000 datapoints
2025-03-06 21:48:46,748 - INFO - training batch 401, loss: 0.846, 12832/28000 datapoints
2025-03-06 21:48:46,901 - INFO - training batch 451, loss: 0.691, 14432/28000 datapoints
2025-03-06 21:48:47,053 - INFO - training batch 501, loss: 0.419, 16032/28000 datapoints
2025-03-06 21:48:47,201 - INFO - training batch 551, loss: 0.803, 17632/28000 datapoints
2025-03-06 21:48:47,350 - INFO - training batch 601, loss: 1.104, 19232/28000 datapoints
2025-03-06 21:48:47,500 - INFO - training batch 651, loss: 0.300, 20832/28000 datapoints
2025-03-06 21:48:47,649 - INFO - training batch 701, loss: 0.479, 22432/28000 datapoints
2025-03-06 21:48:47,796 - INFO - training batch 751, loss: 0.468, 24032/28000 datapoints
2025-03-06 21:48:47,946 - INFO - training batch 801, loss: 0.375, 25632/28000 datapoints
2025-03-06 21:48:48,095 - INFO - training batch 851, loss: 0.796, 27232/28000 datapoints
2025-03-06 21:48:48,167 - INFO - validation batch 1, loss: 0.300, 32/6976 datapoints
2025-03-06 21:48:48,218 - INFO - validation batch 51, loss: 1.527, 1632/6976 datapoints
2025-03-06 21:48:48,265 - INFO - validation batch 101, loss: 0.350, 3232/6976 datapoints
2025-03-06 21:48:48,313 - INFO - validation batch 151, loss: 0.558, 4832/6976 datapoints
2025-03-06 21:48:48,363 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:48:48,379 - INFO - Epoch 93/800 done.
2025-03-06 21:48:48,379 - INFO - Final validation performance:
Loss: 0.661, top-1 acc: 0.816top-5 acc: 0.816
2025-03-06 21:48:48,380 - INFO - Beginning epoch 94/800
2025-03-06 21:48:48,384 - INFO - training batch 1, loss: 0.592, 32/28000 datapoints
2025-03-06 21:48:48,536 - INFO - training batch 51, loss: 0.496, 1632/28000 datapoints
2025-03-06 21:48:48,686 - INFO - training batch 101, loss: 0.310, 3232/28000 datapoints
2025-03-06 21:48:48,835 - INFO - training batch 151, loss: 0.866, 4832/28000 datapoints
2025-03-06 21:48:48,988 - INFO - training batch 201, loss: 0.436, 6432/28000 datapoints
2025-03-06 21:48:49,136 - INFO - training batch 251, loss: 0.403, 8032/28000 datapoints
2025-03-06 21:48:49,284 - INFO - training batch 301, loss: 0.771, 9632/28000 datapoints
2025-03-06 21:48:49,435 - INFO - training batch 351, loss: 0.532, 11232/28000 datapoints
2025-03-06 21:48:49,584 - INFO - training batch 401, loss: 0.842, 12832/28000 datapoints
2025-03-06 21:48:49,731 - INFO - training batch 451, loss: 0.686, 14432/28000 datapoints
2025-03-06 21:48:49,883 - INFO - training batch 501, loss: 0.412, 16032/28000 datapoints
2025-03-06 21:48:50,032 - INFO - training batch 551, loss: 0.794, 17632/28000 datapoints
2025-03-06 21:48:50,196 - INFO - training batch 601, loss: 1.103, 19232/28000 datapoints
2025-03-06 21:48:50,350 - INFO - training batch 651, loss: 0.296, 20832/28000 datapoints
2025-03-06 21:48:50,502 - INFO - training batch 701, loss: 0.475, 22432/28000 datapoints
2025-03-06 21:48:50,653 - INFO - training batch 751, loss: 0.463, 24032/28000 datapoints
2025-03-06 21:48:50,808 - INFO - training batch 801, loss: 0.372, 25632/28000 datapoints
2025-03-06 21:48:50,962 - INFO - training batch 851, loss: 0.792, 27232/28000 datapoints
2025-03-06 21:48:51,035 - INFO - validation batch 1, loss: 0.296, 32/6976 datapoints
2025-03-06 21:48:51,083 - INFO - validation batch 51, loss: 1.520, 1632/6976 datapoints
2025-03-06 21:48:51,134 - INFO - validation batch 101, loss: 0.346, 3232/6976 datapoints
2025-03-06 21:48:51,182 - INFO - validation batch 151, loss: 0.553, 4832/6976 datapoints
2025-03-06 21:48:51,230 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:48:51,246 - INFO - Epoch 94/800 done.
2025-03-06 21:48:51,246 - INFO - Final validation performance:
Loss: 0.657, top-1 acc: 0.816top-5 acc: 0.816
2025-03-06 21:48:51,246 - INFO - Beginning epoch 95/800
2025-03-06 21:48:51,251 - INFO - training batch 1, loss: 0.586, 32/28000 datapoints
2025-03-06 21:48:51,402 - INFO - training batch 51, loss: 0.487, 1632/28000 datapoints
2025-03-06 21:48:51,554 - INFO - training batch 101, loss: 0.308, 3232/28000 datapoints
2025-03-06 21:48:51,707 - INFO - training batch 151, loss: 0.860, 4832/28000 datapoints
2025-03-06 21:48:51,857 - INFO - training batch 201, loss: 0.430, 6432/28000 datapoints
2025-03-06 21:48:52,006 - INFO - training batch 251, loss: 0.400, 8032/28000 datapoints
2025-03-06 21:48:52,157 - INFO - training batch 301, loss: 0.768, 9632/28000 datapoints
2025-03-06 21:48:52,313 - INFO - training batch 351, loss: 0.531, 11232/28000 datapoints
2025-03-06 21:48:52,463 - INFO - training batch 401, loss: 0.838, 12832/28000 datapoints
2025-03-06 21:48:52,612 - INFO - training batch 451, loss: 0.682, 14432/28000 datapoints
2025-03-06 21:48:52,762 - INFO - training batch 501, loss: 0.405, 16032/28000 datapoints
2025-03-06 21:48:52,916 - INFO - training batch 551, loss: 0.785, 17632/28000 datapoints
2025-03-06 21:48:53,067 - INFO - training batch 601, loss: 1.102, 19232/28000 datapoints
2025-03-06 21:48:53,218 - INFO - training batch 651, loss: 0.291, 20832/28000 datapoints
2025-03-06 21:48:53,367 - INFO - training batch 701, loss: 0.471, 22432/28000 datapoints
2025-03-06 21:48:53,517 - INFO - training batch 751, loss: 0.458, 24032/28000 datapoints
2025-03-06 21:48:53,668 - INFO - training batch 801, loss: 0.369, 25632/28000 datapoints
2025-03-06 21:48:53,815 - INFO - training batch 851, loss: 0.788, 27232/28000 datapoints
2025-03-06 21:48:53,892 - INFO - validation batch 1, loss: 0.291, 32/6976 datapoints
2025-03-06 21:48:53,940 - INFO - validation batch 51, loss: 1.514, 1632/6976 datapoints
2025-03-06 21:48:53,990 - INFO - validation batch 101, loss: 0.343, 3232/6976 datapoints
2025-03-06 21:48:54,037 - INFO - validation batch 151, loss: 0.549, 4832/6976 datapoints
2025-03-06 21:48:54,084 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:48:54,100 - INFO - Epoch 95/800 done.
2025-03-06 21:48:54,100 - INFO - Final validation performance:
Loss: 0.653, top-1 acc: 0.816top-5 acc: 0.816
2025-03-06 21:48:54,102 - INFO - Beginning epoch 96/800
2025-03-06 21:48:54,106 - INFO - training batch 1, loss: 0.580, 32/28000 datapoints
2025-03-06 21:48:54,258 - INFO - training batch 51, loss: 0.479, 1632/28000 datapoints
2025-03-06 21:48:54,407 - INFO - training batch 101, loss: 0.305, 3232/28000 datapoints
2025-03-06 21:48:54,616 - INFO - training batch 151, loss: 0.853, 4832/28000 datapoints
2025-03-06 21:48:54,765 - INFO - training batch 201, loss: 0.423, 6432/28000 datapoints
2025-03-06 21:48:54,914 - INFO - training batch 251, loss: 0.396, 8032/28000 datapoints
2025-03-06 21:48:55,065 - INFO - training batch 301, loss: 0.767, 9632/28000 datapoints
2025-03-06 21:48:55,215 - INFO - training batch 351, loss: 0.529, 11232/28000 datapoints
2025-03-06 21:48:55,366 - INFO - training batch 401, loss: 0.835, 12832/28000 datapoints
2025-03-06 21:48:55,517 - INFO - training batch 451, loss: 0.678, 14432/28000 datapoints
2025-03-06 21:48:55,684 - INFO - training batch 501, loss: 0.398, 16032/28000 datapoints
2025-03-06 21:48:55,846 - INFO - training batch 551, loss: 0.777, 17632/28000 datapoints
2025-03-06 21:48:55,996 - INFO - training batch 601, loss: 1.099, 19232/28000 datapoints
2025-03-06 21:48:56,146 - INFO - training batch 651, loss: 0.286, 20832/28000 datapoints
2025-03-06 21:48:56,313 - INFO - training batch 701, loss: 0.467, 22432/28000 datapoints
2025-03-06 21:48:56,464 - INFO - training batch 751, loss: 0.455, 24032/28000 datapoints
2025-03-06 21:48:56,613 - INFO - training batch 801, loss: 0.366, 25632/28000 datapoints
2025-03-06 21:48:56,769 - INFO - training batch 851, loss: 0.784, 27232/28000 datapoints
2025-03-06 21:48:56,844 - INFO - validation batch 1, loss: 0.286, 32/6976 datapoints
2025-03-06 21:48:56,893 - INFO - validation batch 51, loss: 1.508, 1632/6976 datapoints
2025-03-06 21:48:56,940 - INFO - validation batch 101, loss: 0.340, 3232/6976 datapoints
2025-03-06 21:48:56,987 - INFO - validation batch 151, loss: 0.546, 4832/6976 datapoints
2025-03-06 21:48:57,036 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:48:57,054 - INFO - Epoch 96/800 done.
2025-03-06 21:48:57,054 - INFO - Final validation performance:
Loss: 0.650, top-1 acc: 0.817top-5 acc: 0.817
2025-03-06 21:48:57,055 - INFO - Beginning epoch 97/800
2025-03-06 21:48:57,059 - INFO - training batch 1, loss: 0.575, 32/28000 datapoints
2025-03-06 21:48:57,212 - INFO - training batch 51, loss: 0.472, 1632/28000 datapoints
2025-03-06 21:48:57,362 - INFO - training batch 101, loss: 0.303, 3232/28000 datapoints
2025-03-06 21:48:57,513 - INFO - training batch 151, loss: 0.846, 4832/28000 datapoints
2025-03-06 21:48:57,664 - INFO - training batch 201, loss: 0.416, 6432/28000 datapoints
2025-03-06 21:48:57,811 - INFO - training batch 251, loss: 0.393, 8032/28000 datapoints
2025-03-06 21:48:57,963 - INFO - training batch 301, loss: 0.765, 9632/28000 datapoints
2025-03-06 21:48:58,114 - INFO - training batch 351, loss: 0.526, 11232/28000 datapoints
2025-03-06 21:48:58,267 - INFO - training batch 401, loss: 0.831, 12832/28000 datapoints
2025-03-06 21:48:58,418 - INFO - training batch 451, loss: 0.673, 14432/28000 datapoints
2025-03-06 21:48:58,570 - INFO - training batch 501, loss: 0.391, 16032/28000 datapoints
2025-03-06 21:48:58,725 - INFO - training batch 551, loss: 0.768, 17632/28000 datapoints
2025-03-06 21:48:58,877 - INFO - training batch 601, loss: 1.098, 19232/28000 datapoints
2025-03-06 21:48:59,025 - INFO - training batch 651, loss: 0.281, 20832/28000 datapoints
2025-03-06 21:48:59,175 - INFO - training batch 701, loss: 0.464, 22432/28000 datapoints
2025-03-06 21:48:59,325 - INFO - training batch 751, loss: 0.451, 24032/28000 datapoints
2025-03-06 21:48:59,472 - INFO - training batch 801, loss: 0.363, 25632/28000 datapoints
2025-03-06 21:48:59,621 - INFO - training batch 851, loss: 0.781, 27232/28000 datapoints
2025-03-06 21:48:59,693 - INFO - validation batch 1, loss: 0.282, 32/6976 datapoints
2025-03-06 21:48:59,741 - INFO - validation batch 51, loss: 1.502, 1632/6976 datapoints
2025-03-06 21:48:59,787 - INFO - validation batch 101, loss: 0.337, 3232/6976 datapoints
2025-03-06 21:48:59,834 - INFO - validation batch 151, loss: 0.542, 4832/6976 datapoints
2025-03-06 21:48:59,893 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:48:59,910 - INFO - Epoch 97/800 done.
2025-03-06 21:48:59,910 - INFO - Final validation performance:
Loss: 0.646, top-1 acc: 0.819top-5 acc: 0.819
2025-03-06 21:48:59,911 - INFO - Beginning epoch 98/800
2025-03-06 21:48:59,916 - INFO - training batch 1, loss: 0.569, 32/28000 datapoints
2025-03-06 21:49:00,099 - INFO - training batch 51, loss: 0.465, 1632/28000 datapoints
2025-03-06 21:49:00,252 - INFO - training batch 101, loss: 0.301, 3232/28000 datapoints
2025-03-06 21:49:00,401 - INFO - training batch 151, loss: 0.840, 4832/28000 datapoints
2025-03-06 21:49:00,553 - INFO - training batch 201, loss: 0.409, 6432/28000 datapoints
2025-03-06 21:49:00,702 - INFO - training batch 251, loss: 0.391, 8032/28000 datapoints
2025-03-06 21:49:00,910 - INFO - training batch 301, loss: 0.764, 9632/28000 datapoints
2025-03-06 21:49:01,057 - INFO - training batch 351, loss: 0.523, 11232/28000 datapoints
2025-03-06 21:49:01,206 - INFO - training batch 401, loss: 0.827, 12832/28000 datapoints
2025-03-06 21:49:01,358 - INFO - training batch 451, loss: 0.669, 14432/28000 datapoints
2025-03-06 21:49:01,509 - INFO - training batch 501, loss: 0.384, 16032/28000 datapoints
2025-03-06 21:49:01,662 - INFO - training batch 551, loss: 0.760, 17632/28000 datapoints
2025-03-06 21:49:01,811 - INFO - training batch 601, loss: 1.096, 19232/28000 datapoints
2025-03-06 21:49:01,964 - INFO - training batch 651, loss: 0.276, 20832/28000 datapoints
2025-03-06 21:49:02,114 - INFO - training batch 701, loss: 0.460, 22432/28000 datapoints
2025-03-06 21:49:02,275 - INFO - training batch 751, loss: 0.446, 24032/28000 datapoints
2025-03-06 21:49:02,435 - INFO - training batch 801, loss: 0.361, 25632/28000 datapoints
2025-03-06 21:49:02,590 - INFO - training batch 851, loss: 0.777, 27232/28000 datapoints
2025-03-06 21:49:02,664 - INFO - validation batch 1, loss: 0.277, 32/6976 datapoints
2025-03-06 21:49:02,712 - INFO - validation batch 51, loss: 1.496, 1632/6976 datapoints
2025-03-06 21:49:02,758 - INFO - validation batch 101, loss: 0.334, 3232/6976 datapoints
2025-03-06 21:49:02,814 - INFO - validation batch 151, loss: 0.537, 4832/6976 datapoints
2025-03-06 21:49:02,865 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:49:02,882 - INFO - Epoch 98/800 done.
2025-03-06 21:49:02,882 - INFO - Final validation performance:
Loss: 0.643, top-1 acc: 0.820top-5 acc: 0.820
2025-03-06 21:49:02,883 - INFO - Beginning epoch 99/800
2025-03-06 21:49:02,887 - INFO - training batch 1, loss: 0.563, 32/28000 datapoints
2025-03-06 21:49:03,044 - INFO - training batch 51, loss: 0.457, 1632/28000 datapoints
2025-03-06 21:49:03,195 - INFO - training batch 101, loss: 0.298, 3232/28000 datapoints
2025-03-06 21:49:03,344 - INFO - training batch 151, loss: 0.834, 4832/28000 datapoints
2025-03-06 21:49:03,495 - INFO - training batch 201, loss: 0.403, 6432/28000 datapoints
2025-03-06 21:49:03,645 - INFO - training batch 251, loss: 0.387, 8032/28000 datapoints
2025-03-06 21:49:03,793 - INFO - training batch 301, loss: 0.763, 9632/28000 datapoints
2025-03-06 21:49:03,944 - INFO - training batch 351, loss: 0.521, 11232/28000 datapoints
2025-03-06 21:49:04,092 - INFO - training batch 401, loss: 0.823, 12832/28000 datapoints
2025-03-06 21:49:04,242 - INFO - training batch 451, loss: 0.664, 14432/28000 datapoints
2025-03-06 21:49:04,393 - INFO - training batch 501, loss: 0.377, 16032/28000 datapoints
2025-03-06 21:49:04,542 - INFO - training batch 551, loss: 0.753, 17632/28000 datapoints
2025-03-06 21:49:04,694 - INFO - training batch 601, loss: 1.092, 19232/28000 datapoints
2025-03-06 21:49:04,848 - INFO - training batch 651, loss: 0.271, 20832/28000 datapoints
2025-03-06 21:49:05,010 - INFO - training batch 701, loss: 0.456, 22432/28000 datapoints
2025-03-06 21:49:05,167 - INFO - training batch 751, loss: 0.443, 24032/28000 datapoints
2025-03-06 21:49:05,318 - INFO - training batch 801, loss: 0.359, 25632/28000 datapoints
2025-03-06 21:49:05,474 - INFO - training batch 851, loss: 0.773, 27232/28000 datapoints
2025-03-06 21:49:05,554 - INFO - validation batch 1, loss: 0.273, 32/6976 datapoints
2025-03-06 21:49:05,607 - INFO - validation batch 51, loss: 1.490, 1632/6976 datapoints
2025-03-06 21:49:05,660 - INFO - validation batch 101, loss: 0.331, 3232/6976 datapoints
2025-03-06 21:49:05,715 - INFO - validation batch 151, loss: 0.533, 4832/6976 datapoints
2025-03-06 21:49:05,785 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:49:05,807 - INFO - Epoch 99/800 done.
2025-03-06 21:49:05,807 - INFO - Final validation performance:
Loss: 0.639, top-1 acc: 0.820top-5 acc: 0.820
2025-03-06 21:49:05,808 - INFO - Beginning epoch 100/800
2025-03-06 21:49:05,813 - INFO - training batch 1, loss: 0.558, 32/28000 datapoints
2025-03-06 21:49:05,979 - INFO - training batch 51, loss: 0.450, 1632/28000 datapoints
2025-03-06 21:49:06,130 - INFO - training batch 101, loss: 0.296, 3232/28000 datapoints
2025-03-06 21:49:06,288 - INFO - training batch 151, loss: 0.827, 4832/28000 datapoints
2025-03-06 21:49:06,441 - INFO - training batch 201, loss: 0.396, 6432/28000 datapoints
2025-03-06 21:49:06,594 - INFO - training batch 251, loss: 0.384, 8032/28000 datapoints
2025-03-06 21:49:06,746 - INFO - training batch 301, loss: 0.761, 9632/28000 datapoints
2025-03-06 21:49:06,900 - INFO - training batch 351, loss: 0.518, 11232/28000 datapoints
2025-03-06 21:49:07,055 - INFO - training batch 401, loss: 0.820, 12832/28000 datapoints
2025-03-06 21:49:07,209 - INFO - training batch 451, loss: 0.659, 14432/28000 datapoints
2025-03-06 21:49:07,362 - INFO - training batch 501, loss: 0.371, 16032/28000 datapoints
2025-03-06 21:49:07,515 - INFO - training batch 551, loss: 0.745, 17632/28000 datapoints
2025-03-06 21:49:07,668 - INFO - training batch 601, loss: 1.089, 19232/28000 datapoints
2025-03-06 21:49:07,822 - INFO - training batch 651, loss: 0.266, 20832/28000 datapoints
2025-03-06 21:49:07,978 - INFO - training batch 701, loss: 0.451, 22432/28000 datapoints
2025-03-06 21:49:08,134 - INFO - training batch 751, loss: 0.439, 24032/28000 datapoints
2025-03-06 21:49:08,291 - INFO - training batch 801, loss: 0.356, 25632/28000 datapoints
2025-03-06 21:49:08,443 - INFO - training batch 851, loss: 0.769, 27232/28000 datapoints
2025-03-06 21:49:08,519 - INFO - validation batch 1, loss: 0.269, 32/6976 datapoints
2025-03-06 21:49:08,572 - INFO - validation batch 51, loss: 1.484, 1632/6976 datapoints
2025-03-06 21:49:08,627 - INFO - validation batch 101, loss: 0.328, 3232/6976 datapoints
2025-03-06 21:49:08,687 - INFO - validation batch 151, loss: 0.529, 4832/6976 datapoints
2025-03-06 21:49:08,748 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:49:08,767 - INFO - Epoch 100/800 done.
2025-03-06 21:49:08,767 - INFO - Final validation performance:
Loss: 0.636, top-1 acc: 0.822top-5 acc: 0.822
2025-03-06 21:49:08,768 - INFO - Beginning epoch 101/800
2025-03-06 21:49:08,773 - INFO - training batch 1, loss: 0.553, 32/28000 datapoints
2025-03-06 21:49:08,932 - INFO - training batch 51, loss: 0.443, 1632/28000 datapoints
2025-03-06 21:49:09,085 - INFO - training batch 101, loss: 0.294, 3232/28000 datapoints
2025-03-06 21:49:09,242 - INFO - training batch 151, loss: 0.822, 4832/28000 datapoints
2025-03-06 21:49:09,397 - INFO - training batch 201, loss: 0.390, 6432/28000 datapoints
2025-03-06 21:49:09,548 - INFO - training batch 251, loss: 0.381, 8032/28000 datapoints
2025-03-06 21:49:09,701 - INFO - training batch 301, loss: 0.760, 9632/28000 datapoints
2025-03-06 21:49:09,855 - INFO - training batch 351, loss: 0.516, 11232/28000 datapoints
2025-03-06 21:49:10,011 - INFO - training batch 401, loss: 0.816, 12832/28000 datapoints
2025-03-06 21:49:10,165 - INFO - training batch 451, loss: 0.655, 14432/28000 datapoints
2025-03-06 21:49:10,321 - INFO - training batch 501, loss: 0.365, 16032/28000 datapoints
2025-03-06 21:49:10,473 - INFO - training batch 551, loss: 0.738, 17632/28000 datapoints
2025-03-06 21:49:10,629 - INFO - training batch 601, loss: 1.085, 19232/28000 datapoints
2025-03-06 21:49:10,782 - INFO - training batch 651, loss: 0.260, 20832/28000 datapoints
2025-03-06 21:49:10,938 - INFO - training batch 701, loss: 0.448, 22432/28000 datapoints
2025-03-06 21:49:11,092 - INFO - training batch 751, loss: 0.436, 24032/28000 datapoints
2025-03-06 21:49:11,250 - INFO - training batch 801, loss: 0.353, 25632/28000 datapoints
2025-03-06 21:49:11,403 - INFO - training batch 851, loss: 0.765, 27232/28000 datapoints
2025-03-06 21:49:11,480 - INFO - validation batch 1, loss: 0.265, 32/6976 datapoints
2025-03-06 21:49:11,532 - INFO - validation batch 51, loss: 1.476, 1632/6976 datapoints
2025-03-06 21:49:11,585 - INFO - validation batch 101, loss: 0.326, 3232/6976 datapoints
2025-03-06 21:49:11,634 - INFO - validation batch 151, loss: 0.526, 4832/6976 datapoints
2025-03-06 21:49:11,690 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:49:11,705 - INFO - Epoch 101/800 done.
2025-03-06 21:49:11,706 - INFO - Final validation performance:
Loss: 0.632, top-1 acc: 0.823top-5 acc: 0.823
2025-03-06 21:49:11,706 - INFO - Beginning epoch 102/800
2025-03-06 21:49:11,711 - INFO - training batch 1, loss: 0.548, 32/28000 datapoints
2025-03-06 21:49:11,866 - INFO - training batch 51, loss: 0.436, 1632/28000 datapoints
2025-03-06 21:49:12,015 - INFO - training batch 101, loss: 0.291, 3232/28000 datapoints
2025-03-06 21:49:12,165 - INFO - training batch 151, loss: 0.816, 4832/28000 datapoints
2025-03-06 21:49:12,323 - INFO - training batch 201, loss: 0.383, 6432/28000 datapoints
2025-03-06 21:49:12,471 - INFO - training batch 251, loss: 0.379, 8032/28000 datapoints
2025-03-06 21:49:12,621 - INFO - training batch 301, loss: 0.759, 9632/28000 datapoints
2025-03-06 21:49:12,805 - INFO - training batch 351, loss: 0.513, 11232/28000 datapoints
2025-03-06 21:49:12,969 - INFO - training batch 401, loss: 0.813, 12832/28000 datapoints
2025-03-06 21:49:13,125 - INFO - training batch 451, loss: 0.650, 14432/28000 datapoints
2025-03-06 21:49:13,274 - INFO - training batch 501, loss: 0.359, 16032/28000 datapoints
2025-03-06 21:49:13,424 - INFO - training batch 551, loss: 0.731, 17632/28000 datapoints
2025-03-06 21:49:13,576 - INFO - training batch 601, loss: 1.080, 19232/28000 datapoints
2025-03-06 21:49:13,727 - INFO - training batch 651, loss: 0.256, 20832/28000 datapoints
2025-03-06 21:49:13,886 - INFO - training batch 701, loss: 0.445, 22432/28000 datapoints
2025-03-06 21:49:14,064 - INFO - training batch 751, loss: 0.431, 24032/28000 datapoints
2025-03-06 21:49:14,236 - INFO - training batch 801, loss: 0.351, 25632/28000 datapoints
2025-03-06 21:49:14,388 - INFO - training batch 851, loss: 0.762, 27232/28000 datapoints
2025-03-06 21:49:14,461 - INFO - validation batch 1, loss: 0.261, 32/6976 datapoints
2025-03-06 21:49:14,508 - INFO - validation batch 51, loss: 1.472, 1632/6976 datapoints
2025-03-06 21:49:14,556 - INFO - validation batch 101, loss: 0.323, 3232/6976 datapoints
2025-03-06 21:49:14,603 - INFO - validation batch 151, loss: 0.524, 4832/6976 datapoints
2025-03-06 21:49:14,650 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:49:14,667 - INFO - Epoch 102/800 done.
2025-03-06 21:49:14,667 - INFO - Final validation performance:
Loss: 0.629, top-1 acc: 0.824top-5 acc: 0.824
2025-03-06 21:49:14,668 - INFO - Beginning epoch 103/800
2025-03-06 21:49:14,672 - INFO - training batch 1, loss: 0.542, 32/28000 datapoints
2025-03-06 21:49:14,843 - INFO - training batch 51, loss: 0.429, 1632/28000 datapoints
2025-03-06 21:49:14,991 - INFO - training batch 101, loss: 0.288, 3232/28000 datapoints
2025-03-06 21:49:15,147 - INFO - training batch 151, loss: 0.810, 4832/28000 datapoints
2025-03-06 21:49:15,306 - INFO - training batch 201, loss: 0.376, 6432/28000 datapoints
2025-03-06 21:49:15,457 - INFO - training batch 251, loss: 0.376, 8032/28000 datapoints
2025-03-06 21:49:15,611 - INFO - training batch 301, loss: 0.757, 9632/28000 datapoints
2025-03-06 21:49:15,761 - INFO - training batch 351, loss: 0.510, 11232/28000 datapoints
2025-03-06 21:49:15,939 - INFO - training batch 401, loss: 0.808, 12832/28000 datapoints
2025-03-06 21:49:16,088 - INFO - training batch 451, loss: 0.645, 14432/28000 datapoints
2025-03-06 21:49:16,236 - INFO - training batch 501, loss: 0.352, 16032/28000 datapoints
2025-03-06 21:49:16,388 - INFO - training batch 551, loss: 0.724, 17632/28000 datapoints
2025-03-06 21:49:16,538 - INFO - training batch 601, loss: 1.076, 19232/28000 datapoints
2025-03-06 21:49:16,689 - INFO - training batch 651, loss: 0.251, 20832/28000 datapoints
2025-03-06 21:49:16,841 - INFO - training batch 701, loss: 0.441, 22432/28000 datapoints
2025-03-06 21:49:16,990 - INFO - training batch 751, loss: 0.427, 24032/28000 datapoints
2025-03-06 21:49:17,138 - INFO - training batch 801, loss: 0.348, 25632/28000 datapoints
2025-03-06 21:49:17,287 - INFO - training batch 851, loss: 0.759, 27232/28000 datapoints
2025-03-06 21:49:17,361 - INFO - validation batch 1, loss: 0.257, 32/6976 datapoints
2025-03-06 21:49:17,408 - INFO - validation batch 51, loss: 1.466, 1632/6976 datapoints
2025-03-06 21:49:17,456 - INFO - validation batch 101, loss: 0.321, 3232/6976 datapoints
2025-03-06 21:49:17,503 - INFO - validation batch 151, loss: 0.520, 4832/6976 datapoints
2025-03-06 21:49:17,555 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:49:17,572 - INFO - Epoch 103/800 done.
2025-03-06 21:49:17,572 - INFO - Final validation performance:
Loss: 0.626, top-1 acc: 0.825top-5 acc: 0.825
2025-03-06 21:49:17,573 - INFO - Beginning epoch 104/800
2025-03-06 21:49:17,577 - INFO - training batch 1, loss: 0.538, 32/28000 datapoints
2025-03-06 21:49:17,727 - INFO - training batch 51, loss: 0.422, 1632/28000 datapoints
2025-03-06 21:49:17,883 - INFO - training batch 101, loss: 0.286, 3232/28000 datapoints
2025-03-06 21:49:18,033 - INFO - training batch 151, loss: 0.805, 4832/28000 datapoints
2025-03-06 21:49:18,181 - INFO - training batch 201, loss: 0.370, 6432/28000 datapoints
2025-03-06 21:49:18,335 - INFO - training batch 251, loss: 0.374, 8032/28000 datapoints
2025-03-06 21:49:18,484 - INFO - training batch 301, loss: 0.757, 9632/28000 datapoints
2025-03-06 21:49:18,633 - INFO - training batch 351, loss: 0.508, 11232/28000 datapoints
2025-03-06 21:49:18,782 - INFO - training batch 401, loss: 0.803, 12832/28000 datapoints
2025-03-06 21:49:18,934 - INFO - training batch 451, loss: 0.640, 14432/28000 datapoints
2025-03-06 21:49:19,083 - INFO - training batch 501, loss: 0.347, 16032/28000 datapoints
2025-03-06 21:49:19,233 - INFO - training batch 551, loss: 0.718, 17632/28000 datapoints
2025-03-06 21:49:19,392 - INFO - training batch 601, loss: 1.072, 19232/28000 datapoints
2025-03-06 21:49:19,541 - INFO - training batch 651, loss: 0.246, 20832/28000 datapoints
2025-03-06 21:49:19,690 - INFO - training batch 701, loss: 0.438, 22432/28000 datapoints
2025-03-06 21:49:19,843 - INFO - training batch 751, loss: 0.422, 24032/28000 datapoints
2025-03-06 21:49:19,992 - INFO - training batch 801, loss: 0.346, 25632/28000 datapoints
2025-03-06 21:49:20,141 - INFO - training batch 851, loss: 0.755, 27232/28000 datapoints
2025-03-06 21:49:20,214 - INFO - validation batch 1, loss: 0.253, 32/6976 datapoints
2025-03-06 21:49:20,262 - INFO - validation batch 51, loss: 1.459, 1632/6976 datapoints
2025-03-06 21:49:20,309 - INFO - validation batch 101, loss: 0.319, 3232/6976 datapoints
2025-03-06 21:49:20,360 - INFO - validation batch 151, loss: 0.518, 4832/6976 datapoints
2025-03-06 21:49:20,407 - INFO - validation batch 201, loss: 0.565, 6432/6976 datapoints
2025-03-06 21:49:20,423 - INFO - Epoch 104/800 done.
2025-03-06 21:49:20,423 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.827top-5 acc: 0.827
2025-03-06 21:49:20,424 - INFO - Beginning epoch 105/800
2025-03-06 21:49:20,428 - INFO - training batch 1, loss: 0.533, 32/28000 datapoints
2025-03-06 21:49:20,577 - INFO - training batch 51, loss: 0.415, 1632/28000 datapoints
2025-03-06 21:49:20,729 - INFO - training batch 101, loss: 0.284, 3232/28000 datapoints
2025-03-06 21:49:20,886 - INFO - training batch 151, loss: 0.800, 4832/28000 datapoints
2025-03-06 21:49:21,044 - INFO - training batch 201, loss: 0.364, 6432/28000 datapoints
2025-03-06 21:49:21,192 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-06 21:49:21,351 - INFO - training batch 301, loss: 0.756, 9632/28000 datapoints
2025-03-06 21:49:21,505 - INFO - training batch 351, loss: 0.505, 11232/28000 datapoints
2025-03-06 21:49:21,655 - INFO - training batch 401, loss: 0.798, 12832/28000 datapoints
2025-03-06 21:49:21,807 - INFO - training batch 451, loss: 0.635, 14432/28000 datapoints
2025-03-06 21:49:21,959 - INFO - training batch 501, loss: 0.341, 16032/28000 datapoints
2025-03-06 21:49:22,110 - INFO - training batch 551, loss: 0.711, 17632/28000 datapoints
2025-03-06 21:49:22,261 - INFO - training batch 601, loss: 1.068, 19232/28000 datapoints
2025-03-06 21:49:22,414 - INFO - training batch 651, loss: 0.241, 20832/28000 datapoints
2025-03-06 21:49:22,563 - INFO - training batch 701, loss: 0.435, 22432/28000 datapoints
2025-03-06 21:49:22,712 - INFO - training batch 751, loss: 0.418, 24032/28000 datapoints
2025-03-06 21:49:22,867 - INFO - training batch 801, loss: 0.343, 25632/28000 datapoints
2025-03-06 21:49:23,015 - INFO - training batch 851, loss: 0.751, 27232/28000 datapoints
2025-03-06 21:49:23,088 - INFO - validation batch 1, loss: 0.249, 32/6976 datapoints
2025-03-06 21:49:23,135 - INFO - validation batch 51, loss: 1.453, 1632/6976 datapoints
2025-03-06 21:49:23,182 - INFO - validation batch 101, loss: 0.316, 3232/6976 datapoints
2025-03-06 21:49:23,231 - INFO - validation batch 151, loss: 0.515, 4832/6976 datapoints
2025-03-06 21:49:23,278 - INFO - validation batch 201, loss: 0.564, 6432/6976 datapoints
2025-03-06 21:49:23,294 - INFO - Epoch 105/800 done.
2025-03-06 21:49:23,294 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.828top-5 acc: 0.828
2025-03-06 21:49:23,295 - INFO - Beginning epoch 106/800
2025-03-06 21:49:23,299 - INFO - training batch 1, loss: 0.528, 32/28000 datapoints
2025-03-06 21:49:23,453 - INFO - training batch 51, loss: 0.408, 1632/28000 datapoints
2025-03-06 21:49:23,606 - INFO - training batch 101, loss: 0.281, 3232/28000 datapoints
2025-03-06 21:49:23,756 - INFO - training batch 151, loss: 0.794, 4832/28000 datapoints
2025-03-06 21:49:23,910 - INFO - training batch 201, loss: 0.357, 6432/28000 datapoints
2025-03-06 21:49:24,059 - INFO - training batch 251, loss: 0.369, 8032/28000 datapoints
2025-03-06 21:49:24,206 - INFO - training batch 301, loss: 0.756, 9632/28000 datapoints
2025-03-06 21:49:24,357 - INFO - training batch 351, loss: 0.503, 11232/28000 datapoints
2025-03-06 21:49:24,506 - INFO - training batch 401, loss: 0.793, 12832/28000 datapoints
2025-03-06 21:49:24,654 - INFO - training batch 451, loss: 0.629, 14432/28000 datapoints
2025-03-06 21:49:24,804 - INFO - training batch 501, loss: 0.336, 16032/28000 datapoints
2025-03-06 21:49:24,955 - INFO - training batch 551, loss: 0.706, 17632/28000 datapoints
2025-03-06 21:49:25,113 - INFO - training batch 601, loss: 1.064, 19232/28000 datapoints
2025-03-06 21:49:25,270 - INFO - training batch 651, loss: 0.236, 20832/28000 datapoints
2025-03-06 21:49:25,422 - INFO - training batch 701, loss: 0.432, 22432/28000 datapoints
2025-03-06 21:49:25,574 - INFO - training batch 751, loss: 0.415, 24032/28000 datapoints
2025-03-06 21:49:25,729 - INFO - training batch 801, loss: 0.341, 25632/28000 datapoints
2025-03-06 21:49:25,888 - INFO - training batch 851, loss: 0.748, 27232/28000 datapoints
2025-03-06 21:49:25,974 - INFO - validation batch 1, loss: 0.245, 32/6976 datapoints
2025-03-06 21:49:26,045 - INFO - validation batch 51, loss: 1.447, 1632/6976 datapoints
2025-03-06 21:49:26,097 - INFO - validation batch 101, loss: 0.314, 3232/6976 datapoints
2025-03-06 21:49:26,148 - INFO - validation batch 151, loss: 0.513, 4832/6976 datapoints
2025-03-06 21:49:26,201 - INFO - validation batch 201, loss: 0.564, 6432/6976 datapoints
2025-03-06 21:49:26,217 - INFO - Epoch 106/800 done.
2025-03-06 21:49:26,217 - INFO - Final validation performance:
Loss: 0.617, top-1 acc: 0.829top-5 acc: 0.829
2025-03-06 21:49:26,218 - INFO - Beginning epoch 107/800
2025-03-06 21:49:26,222 - INFO - training batch 1, loss: 0.524, 32/28000 datapoints
2025-03-06 21:49:26,377 - INFO - training batch 51, loss: 0.401, 1632/28000 datapoints
2025-03-06 21:49:26,533 - INFO - training batch 101, loss: 0.278, 3232/28000 datapoints
2025-03-06 21:49:26,686 - INFO - training batch 151, loss: 0.790, 4832/28000 datapoints
2025-03-06 21:49:26,852 - INFO - training batch 201, loss: 0.352, 6432/28000 datapoints
2025-03-06 21:49:27,019 - INFO - training batch 251, loss: 0.367, 8032/28000 datapoints
2025-03-06 21:49:27,171 - INFO - training batch 301, loss: 0.754, 9632/28000 datapoints
2025-03-06 21:49:27,323 - INFO - training batch 351, loss: 0.500, 11232/28000 datapoints
2025-03-06 21:49:27,483 - INFO - training batch 401, loss: 0.788, 12832/28000 datapoints
2025-03-06 21:49:27,638 - INFO - training batch 451, loss: 0.625, 14432/28000 datapoints
2025-03-06 21:49:27,797 - INFO - training batch 501, loss: 0.331, 16032/28000 datapoints
2025-03-06 21:49:27,953 - INFO - training batch 551, loss: 0.699, 17632/28000 datapoints
2025-03-06 21:49:28,105 - INFO - training batch 601, loss: 1.061, 19232/28000 datapoints
2025-03-06 21:49:28,258 - INFO - training batch 651, loss: 0.231, 20832/28000 datapoints
2025-03-06 21:49:28,413 - INFO - training batch 701, loss: 0.429, 22432/28000 datapoints
2025-03-06 21:49:28,568 - INFO - training batch 751, loss: 0.412, 24032/28000 datapoints
2025-03-06 21:49:28,721 - INFO - training batch 801, loss: 0.339, 25632/28000 datapoints
2025-03-06 21:49:28,876 - INFO - training batch 851, loss: 0.746, 27232/28000 datapoints
2025-03-06 21:49:28,953 - INFO - validation batch 1, loss: 0.241, 32/6976 datapoints
2025-03-06 21:49:29,005 - INFO - validation batch 51, loss: 1.442, 1632/6976 datapoints
2025-03-06 21:49:29,057 - INFO - validation batch 101, loss: 0.312, 3232/6976 datapoints
2025-03-06 21:49:29,108 - INFO - validation batch 151, loss: 0.511, 4832/6976 datapoints
2025-03-06 21:49:29,159 - INFO - validation batch 201, loss: 0.564, 6432/6976 datapoints
2025-03-06 21:49:29,177 - INFO - Epoch 107/800 done.
2025-03-06 21:49:29,177 - INFO - Final validation performance:
Loss: 0.614, top-1 acc: 0.830top-5 acc: 0.830
2025-03-06 21:49:29,178 - INFO - Beginning epoch 108/800
2025-03-06 21:49:29,183 - INFO - training batch 1, loss: 0.519, 32/28000 datapoints
2025-03-06 21:49:29,337 - INFO - training batch 51, loss: 0.395, 1632/28000 datapoints
2025-03-06 21:49:29,489 - INFO - training batch 101, loss: 0.276, 3232/28000 datapoints
2025-03-06 21:49:29,640 - INFO - training batch 151, loss: 0.786, 4832/28000 datapoints
2025-03-06 21:49:29,791 - INFO - training batch 201, loss: 0.346, 6432/28000 datapoints
2025-03-06 21:49:29,942 - INFO - training batch 251, loss: 0.365, 8032/28000 datapoints
2025-03-06 21:49:30,090 - INFO - training batch 301, loss: 0.753, 9632/28000 datapoints
2025-03-06 21:49:30,237 - INFO - training batch 351, loss: 0.498, 11232/28000 datapoints
2025-03-06 21:49:30,389 - INFO - training batch 401, loss: 0.783, 12832/28000 datapoints
2025-03-06 21:49:30,538 - INFO - training batch 451, loss: 0.621, 14432/28000 datapoints
2025-03-06 21:49:30,686 - INFO - training batch 501, loss: 0.325, 16032/28000 datapoints
2025-03-06 21:49:30,840 - INFO - training batch 551, loss: 0.693, 17632/28000 datapoints
2025-03-06 21:49:30,989 - INFO - training batch 601, loss: 1.056, 19232/28000 datapoints
2025-03-06 21:49:31,139 - INFO - training batch 651, loss: 0.228, 20832/28000 datapoints
2025-03-06 21:49:31,288 - INFO - training batch 701, loss: 0.425, 22432/28000 datapoints
2025-03-06 21:49:31,438 - INFO - training batch 751, loss: 0.409, 24032/28000 datapoints
2025-03-06 21:49:31,589 - INFO - training batch 801, loss: 0.336, 25632/28000 datapoints
2025-03-06 21:49:31,739 - INFO - training batch 851, loss: 0.743, 27232/28000 datapoints
2025-03-06 21:49:31,813 - INFO - validation batch 1, loss: 0.238, 32/6976 datapoints
2025-03-06 21:49:31,863 - INFO - validation batch 51, loss: 1.436, 1632/6976 datapoints
2025-03-06 21:49:31,909 - INFO - validation batch 101, loss: 0.310, 3232/6976 datapoints
2025-03-06 21:49:31,956 - INFO - validation batch 151, loss: 0.510, 4832/6976 datapoints
2025-03-06 21:49:32,004 - INFO - validation batch 201, loss: 0.564, 6432/6976 datapoints
2025-03-06 21:49:32,020 - INFO - Epoch 108/800 done.
2025-03-06 21:49:32,020 - INFO - Final validation performance:
Loss: 0.612, top-1 acc: 0.831top-5 acc: 0.831
2025-03-06 21:49:32,021 - INFO - Beginning epoch 109/800
2025-03-06 21:49:32,025 - INFO - training batch 1, loss: 0.514, 32/28000 datapoints
2025-03-06 21:49:32,175 - INFO - training batch 51, loss: 0.388, 1632/28000 datapoints
2025-03-06 21:49:32,328 - INFO - training batch 101, loss: 0.273, 3232/28000 datapoints
2025-03-06 21:49:32,482 - INFO - training batch 151, loss: 0.782, 4832/28000 datapoints
2025-03-06 21:49:32,632 - INFO - training batch 201, loss: 0.340, 6432/28000 datapoints
2025-03-06 21:49:32,783 - INFO - training batch 251, loss: 0.363, 8032/28000 datapoints
2025-03-06 21:49:32,936 - INFO - training batch 301, loss: 0.751, 9632/28000 datapoints
2025-03-06 21:49:33,101 - INFO - training batch 351, loss: 0.495, 11232/28000 datapoints
2025-03-06 21:49:33,252 - INFO - training batch 401, loss: 0.779, 12832/28000 datapoints
2025-03-06 21:49:33,400 - INFO - training batch 451, loss: 0.615, 14432/28000 datapoints
2025-03-06 21:49:33,555 - INFO - training batch 501, loss: 0.320, 16032/28000 datapoints
2025-03-06 21:49:33,711 - INFO - training batch 551, loss: 0.687, 17632/28000 datapoints
2025-03-06 21:49:33,865 - INFO - training batch 601, loss: 1.051, 19232/28000 datapoints
2025-03-06 21:49:34,026 - INFO - training batch 651, loss: 0.223, 20832/28000 datapoints
2025-03-06 21:49:34,175 - INFO - training batch 701, loss: 0.423, 22432/28000 datapoints
2025-03-06 21:49:34,325 - INFO - training batch 751, loss: 0.406, 24032/28000 datapoints
2025-03-06 21:49:34,476 - INFO - training batch 801, loss: 0.334, 25632/28000 datapoints
2025-03-06 21:49:34,624 - INFO - training batch 851, loss: 0.740, 27232/28000 datapoints
2025-03-06 21:49:34,700 - INFO - validation batch 1, loss: 0.234, 32/6976 datapoints
2025-03-06 21:49:34,747 - INFO - validation batch 51, loss: 1.431, 1632/6976 datapoints
2025-03-06 21:49:34,794 - INFO - validation batch 101, loss: 0.308, 3232/6976 datapoints
2025-03-06 21:49:34,846 - INFO - validation batch 151, loss: 0.509, 4832/6976 datapoints
2025-03-06 21:49:34,893 - INFO - validation batch 201, loss: 0.563, 6432/6976 datapoints
2025-03-06 21:49:34,909 - INFO - Epoch 109/800 done.
2025-03-06 21:49:34,909 - INFO - Final validation performance:
Loss: 0.609, top-1 acc: 0.832top-5 acc: 0.832
2025-03-06 21:49:34,910 - INFO - Beginning epoch 110/800
2025-03-06 21:49:34,914 - INFO - training batch 1, loss: 0.510, 32/28000 datapoints
2025-03-06 21:49:35,069 - INFO - training batch 51, loss: 0.381, 1632/28000 datapoints
2025-03-06 21:49:35,225 - INFO - training batch 101, loss: 0.270, 3232/28000 datapoints
2025-03-06 21:49:35,374 - INFO - training batch 151, loss: 0.777, 4832/28000 datapoints
2025-03-06 21:49:35,526 - INFO - training batch 201, loss: 0.334, 6432/28000 datapoints
2025-03-06 21:49:35,675 - INFO - training batch 251, loss: 0.360, 8032/28000 datapoints
2025-03-06 21:49:35,827 - INFO - training batch 301, loss: 0.749, 9632/28000 datapoints
2025-03-06 21:49:35,977 - INFO - training batch 351, loss: 0.492, 11232/28000 datapoints
2025-03-06 21:49:36,152 - INFO - training batch 401, loss: 0.776, 12832/28000 datapoints
2025-03-06 21:49:36,301 - INFO - training batch 451, loss: 0.611, 14432/28000 datapoints
2025-03-06 21:49:36,455 - INFO - training batch 501, loss: 0.315, 16032/28000 datapoints
2025-03-06 21:49:36,613 - INFO - training batch 551, loss: 0.681, 17632/28000 datapoints
2025-03-06 21:49:36,763 - INFO - training batch 601, loss: 1.047, 19232/28000 datapoints
2025-03-06 21:49:36,915 - INFO - training batch 651, loss: 0.219, 20832/28000 datapoints
2025-03-06 21:49:37,066 - INFO - training batch 701, loss: 0.420, 22432/28000 datapoints
2025-03-06 21:49:37,213 - INFO - training batch 751, loss: 0.402, 24032/28000 datapoints
2025-03-06 21:49:37,361 - INFO - training batch 801, loss: 0.332, 25632/28000 datapoints
2025-03-06 21:49:37,508 - INFO - training batch 851, loss: 0.736, 27232/28000 datapoints
2025-03-06 21:49:37,583 - INFO - validation batch 1, loss: 0.230, 32/6976 datapoints
2025-03-06 21:49:37,630 - INFO - validation batch 51, loss: 1.427, 1632/6976 datapoints
2025-03-06 21:49:37,678 - INFO - validation batch 101, loss: 0.306, 3232/6976 datapoints
2025-03-06 21:49:37,724 - INFO - validation batch 151, loss: 0.507, 4832/6976 datapoints
2025-03-06 21:49:37,772 - INFO - validation batch 201, loss: 0.562, 6432/6976 datapoints
2025-03-06 21:49:37,788 - INFO - Epoch 110/800 done.
2025-03-06 21:49:37,788 - INFO - Final validation performance:
Loss: 0.607, top-1 acc: 0.833top-5 acc: 0.833
2025-03-06 21:49:37,789 - INFO - Beginning epoch 111/800
2025-03-06 21:49:37,793 - INFO - training batch 1, loss: 0.505, 32/28000 datapoints
2025-03-06 21:49:37,957 - INFO - training batch 51, loss: 0.375, 1632/28000 datapoints
2025-03-06 21:49:38,110 - INFO - training batch 101, loss: 0.268, 3232/28000 datapoints
2025-03-06 21:49:38,259 - INFO - training batch 151, loss: 0.774, 4832/28000 datapoints
2025-03-06 21:49:38,409 - INFO - training batch 201, loss: 0.329, 6432/28000 datapoints
2025-03-06 21:49:38,565 - INFO - training batch 251, loss: 0.358, 8032/28000 datapoints
2025-03-06 21:49:38,718 - INFO - training batch 301, loss: 0.748, 9632/28000 datapoints
2025-03-06 21:49:38,871 - INFO - training batch 351, loss: 0.490, 11232/28000 datapoints
2025-03-06 21:49:39,024 - INFO - training batch 401, loss: 0.774, 12832/28000 datapoints
2025-03-06 21:49:39,182 - INFO - training batch 451, loss: 0.607, 14432/28000 datapoints
2025-03-06 21:49:39,335 - INFO - training batch 501, loss: 0.311, 16032/28000 datapoints
2025-03-06 21:49:39,489 - INFO - training batch 551, loss: 0.674, 17632/28000 datapoints
2025-03-06 21:49:39,643 - INFO - training batch 601, loss: 1.046, 19232/28000 datapoints
2025-03-06 21:49:39,793 - INFO - training batch 651, loss: 0.215, 20832/28000 datapoints
2025-03-06 21:49:39,947 - INFO - training batch 701, loss: 0.417, 22432/28000 datapoints
2025-03-06 21:49:40,098 - INFO - training batch 751, loss: 0.397, 24032/28000 datapoints
2025-03-06 21:49:40,246 - INFO - training batch 801, loss: 0.330, 25632/28000 datapoints
2025-03-06 21:49:40,394 - INFO - training batch 851, loss: 0.734, 27232/28000 datapoints
2025-03-06 21:49:40,469 - INFO - validation batch 1, loss: 0.227, 32/6976 datapoints
2025-03-06 21:49:40,515 - INFO - validation batch 51, loss: 1.426, 1632/6976 datapoints
2025-03-06 21:49:40,563 - INFO - validation batch 101, loss: 0.304, 3232/6976 datapoints
2025-03-06 21:49:40,612 - INFO - validation batch 151, loss: 0.505, 4832/6976 datapoints
2025-03-06 21:49:40,659 - INFO - validation batch 201, loss: 0.562, 6432/6976 datapoints
2025-03-06 21:49:40,676 - INFO - Epoch 111/800 done.
2025-03-06 21:49:40,676 - INFO - Final validation performance:
Loss: 0.605, top-1 acc: 0.835top-5 acc: 0.835
2025-03-06 21:49:40,676 - INFO - Beginning epoch 112/800
2025-03-06 21:49:40,680 - INFO - training batch 1, loss: 0.500, 32/28000 datapoints
2025-03-06 21:49:40,840 - INFO - training batch 51, loss: 0.370, 1632/28000 datapoints
2025-03-06 21:49:40,990 - INFO - training batch 101, loss: 0.265, 3232/28000 datapoints
2025-03-06 21:49:41,144 - INFO - training batch 151, loss: 0.770, 4832/28000 datapoints
2025-03-06 21:49:41,296 - INFO - training batch 201, loss: 0.325, 6432/28000 datapoints
2025-03-06 21:49:41,450 - INFO - training batch 251, loss: 0.357, 8032/28000 datapoints
2025-03-06 21:49:41,601 - INFO - training batch 301, loss: 0.747, 9632/28000 datapoints
2025-03-06 21:49:41,755 - INFO - training batch 351, loss: 0.488, 11232/28000 datapoints
2025-03-06 21:49:41,910 - INFO - training batch 401, loss: 0.771, 12832/28000 datapoints
2025-03-06 21:49:42,058 - INFO - training batch 451, loss: 0.603, 14432/28000 datapoints
2025-03-06 21:49:42,208 - INFO - training batch 501, loss: 0.307, 16032/28000 datapoints
2025-03-06 21:49:42,363 - INFO - training batch 551, loss: 0.668, 17632/28000 datapoints
2025-03-06 21:49:42,515 - INFO - training batch 601, loss: 1.040, 19232/28000 datapoints
2025-03-06 21:49:42,664 - INFO - training batch 651, loss: 0.211, 20832/28000 datapoints
2025-03-06 21:49:42,814 - INFO - training batch 701, loss: 0.414, 22432/28000 datapoints
2025-03-06 21:49:42,967 - INFO - training batch 751, loss: 0.393, 24032/28000 datapoints
2025-03-06 21:49:43,115 - INFO - training batch 801, loss: 0.327, 25632/28000 datapoints
2025-03-06 21:49:43,262 - INFO - training batch 851, loss: 0.730, 27232/28000 datapoints
2025-03-06 21:49:43,335 - INFO - validation batch 1, loss: 0.224, 32/6976 datapoints
2025-03-06 21:49:43,382 - INFO - validation batch 51, loss: 1.424, 1632/6976 datapoints
2025-03-06 21:49:43,429 - INFO - validation batch 101, loss: 0.303, 3232/6976 datapoints
2025-03-06 21:49:43,479 - INFO - validation batch 151, loss: 0.502, 4832/6976 datapoints
2025-03-06 21:49:43,538 - INFO - validation batch 201, loss: 0.562, 6432/6976 datapoints
2025-03-06 21:49:43,555 - INFO - Epoch 112/800 done.
2025-03-06 21:49:43,555 - INFO - Final validation performance:
Loss: 0.603, top-1 acc: 0.836top-5 acc: 0.836
2025-03-06 21:49:43,555 - INFO - Beginning epoch 113/800
2025-03-06 21:49:43,560 - INFO - training batch 1, loss: 0.496, 32/28000 datapoints
2025-03-06 21:49:43,713 - INFO - training batch 51, loss: 0.364, 1632/28000 datapoints
2025-03-06 21:49:43,865 - INFO - training batch 101, loss: 0.262, 3232/28000 datapoints
2025-03-06 21:49:44,015 - INFO - training batch 151, loss: 0.768, 4832/28000 datapoints
2025-03-06 21:49:44,164 - INFO - training batch 201, loss: 0.319, 6432/28000 datapoints
2025-03-06 21:49:44,311 - INFO - training batch 251, loss: 0.355, 8032/28000 datapoints
2025-03-06 21:49:44,462 - INFO - training batch 301, loss: 0.745, 9632/28000 datapoints
2025-03-06 21:49:44,610 - INFO - training batch 351, loss: 0.486, 11232/28000 datapoints
2025-03-06 21:49:44,759 - INFO - training batch 401, loss: 0.767, 12832/28000 datapoints
2025-03-06 21:49:44,910 - INFO - training batch 451, loss: 0.598, 14432/28000 datapoints
2025-03-06 21:49:45,062 - INFO - training batch 501, loss: 0.303, 16032/28000 datapoints
2025-03-06 21:49:45,231 - INFO - training batch 551, loss: 0.662, 17632/28000 datapoints
2025-03-06 21:49:45,385 - INFO - training batch 601, loss: 1.036, 19232/28000 datapoints
2025-03-06 21:49:45,535 - INFO - training batch 651, loss: 0.207, 20832/28000 datapoints
2025-03-06 21:49:45,693 - INFO - training batch 701, loss: 0.410, 22432/28000 datapoints
2025-03-06 21:49:45,848 - INFO - training batch 751, loss: 0.389, 24032/28000 datapoints
2025-03-06 21:49:46,014 - INFO - training batch 801, loss: 0.324, 25632/28000 datapoints
2025-03-06 21:49:46,183 - INFO - training batch 851, loss: 0.727, 27232/28000 datapoints
2025-03-06 21:49:46,269 - INFO - validation batch 1, loss: 0.220, 32/6976 datapoints
2025-03-06 21:49:46,317 - INFO - validation batch 51, loss: 1.421, 1632/6976 datapoints
2025-03-06 21:49:46,364 - INFO - validation batch 101, loss: 0.301, 3232/6976 datapoints
2025-03-06 21:49:46,410 - INFO - validation batch 151, loss: 0.501, 4832/6976 datapoints
2025-03-06 21:49:46,461 - INFO - validation batch 201, loss: 0.563, 6432/6976 datapoints
2025-03-06 21:49:46,477 - INFO - Epoch 113/800 done.
2025-03-06 21:49:46,478 - INFO - Final validation performance:
Loss: 0.601, top-1 acc: 0.837top-5 acc: 0.837
2025-03-06 21:49:46,478 - INFO - Beginning epoch 114/800
2025-03-06 21:49:46,482 - INFO - training batch 1, loss: 0.491, 32/28000 datapoints
2025-03-06 21:49:46,637 - INFO - training batch 51, loss: 0.359, 1632/28000 datapoints
2025-03-06 21:49:46,786 - INFO - training batch 101, loss: 0.260, 3232/28000 datapoints
2025-03-06 21:49:46,943 - INFO - training batch 151, loss: 0.765, 4832/28000 datapoints
2025-03-06 21:49:47,092 - INFO - training batch 201, loss: 0.313, 6432/28000 datapoints
2025-03-06 21:49:47,241 - INFO - training batch 251, loss: 0.354, 8032/28000 datapoints
2025-03-06 21:49:47,389 - INFO - training batch 301, loss: 0.744, 9632/28000 datapoints
2025-03-06 21:49:47,539 - INFO - training batch 351, loss: 0.484, 11232/28000 datapoints
2025-03-06 21:49:47,691 - INFO - training batch 401, loss: 0.763, 12832/28000 datapoints
2025-03-06 21:49:47,842 - INFO - training batch 451, loss: 0.591, 14432/28000 datapoints
2025-03-06 21:49:47,994 - INFO - training batch 501, loss: 0.299, 16032/28000 datapoints
2025-03-06 21:49:48,146 - INFO - training batch 551, loss: 0.658, 17632/28000 datapoints
2025-03-06 21:49:48,294 - INFO - training batch 601, loss: 1.031, 19232/28000 datapoints
2025-03-06 21:49:48,442 - INFO - training batch 651, loss: 0.203, 20832/28000 datapoints
2025-03-06 21:49:48,594 - INFO - training batch 701, loss: 0.408, 22432/28000 datapoints
2025-03-06 21:49:48,745 - INFO - training batch 751, loss: 0.384, 24032/28000 datapoints
2025-03-06 21:49:48,895 - INFO - training batch 801, loss: 0.322, 25632/28000 datapoints
2025-03-06 21:49:49,046 - INFO - training batch 851, loss: 0.724, 27232/28000 datapoints
2025-03-06 21:49:49,120 - INFO - validation batch 1, loss: 0.216, 32/6976 datapoints
2025-03-06 21:49:49,168 - INFO - validation batch 51, loss: 1.418, 1632/6976 datapoints
2025-03-06 21:49:49,215 - INFO - validation batch 101, loss: 0.299, 3232/6976 datapoints
2025-03-06 21:49:49,262 - INFO - validation batch 151, loss: 0.501, 4832/6976 datapoints
2025-03-06 21:49:49,312 - INFO - validation batch 201, loss: 0.564, 6432/6976 datapoints
2025-03-06 21:49:49,328 - INFO - Epoch 114/800 done.
2025-03-06 21:49:49,328 - INFO - Final validation performance:
Loss: 0.600, top-1 acc: 0.838top-5 acc: 0.838
2025-03-06 21:49:49,329 - INFO - Beginning epoch 115/800
2025-03-06 21:49:49,333 - INFO - training batch 1, loss: 0.486, 32/28000 datapoints
2025-03-06 21:49:49,481 - INFO - training batch 51, loss: 0.353, 1632/28000 datapoints
2025-03-06 21:49:49,630 - INFO - training batch 101, loss: 0.258, 3232/28000 datapoints
2025-03-06 21:49:49,782 - INFO - training batch 151, loss: 0.761, 4832/28000 datapoints
2025-03-06 21:49:49,934 - INFO - training batch 201, loss: 0.308, 6432/28000 datapoints
2025-03-06 21:49:50,082 - INFO - training batch 251, loss: 0.352, 8032/28000 datapoints
2025-03-06 21:49:50,233 - INFO - training batch 301, loss: 0.743, 9632/28000 datapoints
2025-03-06 21:49:50,380 - INFO - training batch 351, loss: 0.482, 11232/28000 datapoints
2025-03-06 21:49:50,533 - INFO - training batch 401, loss: 0.760, 12832/28000 datapoints
2025-03-06 21:49:50,683 - INFO - training batch 451, loss: 0.587, 14432/28000 datapoints
2025-03-06 21:49:50,831 - INFO - training batch 501, loss: 0.295, 16032/28000 datapoints
2025-03-06 21:49:50,984 - INFO - training batch 551, loss: 0.653, 17632/28000 datapoints
2025-03-06 21:49:51,132 - INFO - training batch 601, loss: 1.027, 19232/28000 datapoints
2025-03-06 21:49:51,290 - INFO - training batch 651, loss: 0.199, 20832/28000 datapoints
2025-03-06 21:49:51,447 - INFO - training batch 701, loss: 0.405, 22432/28000 datapoints
2025-03-06 21:49:51,597 - INFO - training batch 751, loss: 0.380, 24032/28000 datapoints
2025-03-06 21:49:51,747 - INFO - training batch 801, loss: 0.319, 25632/28000 datapoints
2025-03-06 21:49:51,902 - INFO - training batch 851, loss: 0.720, 27232/28000 datapoints
2025-03-06 21:49:51,977 - INFO - validation batch 1, loss: 0.213, 32/6976 datapoints
2025-03-06 21:49:52,027 - INFO - validation batch 51, loss: 1.417, 1632/6976 datapoints
2025-03-06 21:49:52,078 - INFO - validation batch 101, loss: 0.298, 3232/6976 datapoints
2025-03-06 21:49:52,127 - INFO - validation batch 151, loss: 0.499, 4832/6976 datapoints
2025-03-06 21:49:52,174 - INFO - validation batch 201, loss: 0.565, 6432/6976 datapoints
2025-03-06 21:49:52,190 - INFO - Epoch 115/800 done.
2025-03-06 21:49:52,190 - INFO - Final validation performance:
Loss: 0.598, top-1 acc: 0.838top-5 acc: 0.838
2025-03-06 21:49:52,191 - INFO - Beginning epoch 116/800
2025-03-06 21:49:52,197 - INFO - training batch 1, loss: 0.481, 32/28000 datapoints
2025-03-06 21:49:52,352 - INFO - training batch 51, loss: 0.349, 1632/28000 datapoints
2025-03-06 21:49:52,508 - INFO - training batch 101, loss: 0.255, 3232/28000 datapoints
2025-03-06 21:49:52,656 - INFO - training batch 151, loss: 0.758, 4832/28000 datapoints
2025-03-06 21:49:52,807 - INFO - training batch 201, loss: 0.304, 6432/28000 datapoints
2025-03-06 21:49:52,957 - INFO - training batch 251, loss: 0.351, 8032/28000 datapoints
2025-03-06 21:49:53,106 - INFO - training batch 301, loss: 0.740, 9632/28000 datapoints
2025-03-06 21:49:53,257 - INFO - training batch 351, loss: 0.479, 11232/28000 datapoints
2025-03-06 21:49:53,404 - INFO - training batch 401, loss: 0.757, 12832/28000 datapoints
2025-03-06 21:49:53,554 - INFO - training batch 451, loss: 0.583, 14432/28000 datapoints
2025-03-06 21:49:53,704 - INFO - training batch 501, loss: 0.290, 16032/28000 datapoints
2025-03-06 21:49:53,858 - INFO - training batch 551, loss: 0.647, 17632/28000 datapoints
2025-03-06 21:49:54,008 - INFO - training batch 601, loss: 1.022, 19232/28000 datapoints
2025-03-06 21:49:54,158 - INFO - training batch 651, loss: 0.195, 20832/28000 datapoints
2025-03-06 21:49:54,308 - INFO - training batch 701, loss: 0.403, 22432/28000 datapoints
2025-03-06 21:49:54,455 - INFO - training batch 751, loss: 0.375, 24032/28000 datapoints
2025-03-06 21:49:54,606 - INFO - training batch 801, loss: 0.317, 25632/28000 datapoints
2025-03-06 21:49:54,754 - INFO - training batch 851, loss: 0.717, 27232/28000 datapoints
2025-03-06 21:49:54,827 - INFO - validation batch 1, loss: 0.210, 32/6976 datapoints
2025-03-06 21:49:54,876 - INFO - validation batch 51, loss: 1.416, 1632/6976 datapoints
2025-03-06 21:49:54,922 - INFO - validation batch 101, loss: 0.298, 3232/6976 datapoints
2025-03-06 21:49:54,969 - INFO - validation batch 151, loss: 0.498, 4832/6976 datapoints
2025-03-06 21:49:55,018 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:49:55,034 - INFO - Epoch 116/800 done.
2025-03-06 21:49:55,035 - INFO - Final validation performance:
Loss: 0.597, top-1 acc: 0.839top-5 acc: 0.839
2025-03-06 21:49:55,035 - INFO - Beginning epoch 117/800
2025-03-06 21:49:55,039 - INFO - training batch 1, loss: 0.476, 32/28000 datapoints
2025-03-06 21:49:55,196 - INFO - training batch 51, loss: 0.345, 1632/28000 datapoints
2025-03-06 21:49:55,348 - INFO - training batch 101, loss: 0.253, 3232/28000 datapoints
2025-03-06 21:49:55,496 - INFO - training batch 151, loss: 0.754, 4832/28000 datapoints
2025-03-06 21:49:55,645 - INFO - training batch 201, loss: 0.298, 6432/28000 datapoints
2025-03-06 21:49:55,795 - INFO - training batch 251, loss: 0.351, 8032/28000 datapoints
2025-03-06 21:49:55,947 - INFO - training batch 301, loss: 0.739, 9632/28000 datapoints
2025-03-06 21:49:56,096 - INFO - training batch 351, loss: 0.477, 11232/28000 datapoints
2025-03-06 21:49:56,253 - INFO - training batch 401, loss: 0.755, 12832/28000 datapoints
2025-03-06 21:49:56,419 - INFO - training batch 451, loss: 0.578, 14432/28000 datapoints
2025-03-06 21:49:56,572 - INFO - training batch 501, loss: 0.286, 16032/28000 datapoints
2025-03-06 21:49:56,722 - INFO - training batch 551, loss: 0.642, 17632/28000 datapoints
2025-03-06 21:49:56,872 - INFO - training batch 601, loss: 1.017, 19232/28000 datapoints
2025-03-06 21:49:57,021 - INFO - training batch 651, loss: 0.192, 20832/28000 datapoints
2025-03-06 21:49:57,169 - INFO - training batch 701, loss: 0.400, 22432/28000 datapoints
2025-03-06 21:49:57,319 - INFO - training batch 751, loss: 0.371, 24032/28000 datapoints
2025-03-06 21:49:57,481 - INFO - training batch 801, loss: 0.314, 25632/28000 datapoints
2025-03-06 21:49:57,633 - INFO - training batch 851, loss: 0.713, 27232/28000 datapoints
2025-03-06 21:49:57,707 - INFO - validation batch 1, loss: 0.206, 32/6976 datapoints
2025-03-06 21:49:57,755 - INFO - validation batch 51, loss: 1.413, 1632/6976 datapoints
2025-03-06 21:49:57,801 - INFO - validation batch 101, loss: 0.297, 3232/6976 datapoints
2025-03-06 21:49:57,858 - INFO - validation batch 151, loss: 0.497, 4832/6976 datapoints
2025-03-06 21:49:57,908 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:49:57,925 - INFO - Epoch 117/800 done.
2025-03-06 21:49:57,925 - INFO - Final validation performance:
Loss: 0.596, top-1 acc: 0.839top-5 acc: 0.839
2025-03-06 21:49:57,925 - INFO - Beginning epoch 118/800
2025-03-06 21:49:57,930 - INFO - training batch 1, loss: 0.471, 32/28000 datapoints
2025-03-06 21:49:58,084 - INFO - training batch 51, loss: 0.341, 1632/28000 datapoints
2025-03-06 21:49:58,233 - INFO - training batch 101, loss: 0.250, 3232/28000 datapoints
2025-03-06 21:49:58,383 - INFO - training batch 151, loss: 0.751, 4832/28000 datapoints
2025-03-06 21:49:58,534 - INFO - training batch 201, loss: 0.293, 6432/28000 datapoints
2025-03-06 21:49:58,686 - INFO - training batch 251, loss: 0.350, 8032/28000 datapoints
2025-03-06 21:49:58,841 - INFO - training batch 301, loss: 0.738, 9632/28000 datapoints
2025-03-06 21:49:58,993 - INFO - training batch 351, loss: 0.475, 11232/28000 datapoints
2025-03-06 21:49:59,140 - INFO - training batch 401, loss: 0.753, 12832/28000 datapoints
2025-03-06 21:49:59,292 - INFO - training batch 451, loss: 0.575, 14432/28000 datapoints
2025-03-06 21:49:59,440 - INFO - training batch 501, loss: 0.282, 16032/28000 datapoints
2025-03-06 21:49:59,589 - INFO - training batch 551, loss: 0.637, 17632/28000 datapoints
2025-03-06 21:49:59,738 - INFO - training batch 601, loss: 1.014, 19232/28000 datapoints
2025-03-06 21:49:59,891 - INFO - training batch 651, loss: 0.188, 20832/28000 datapoints
2025-03-06 21:50:00,041 - INFO - training batch 701, loss: 0.397, 22432/28000 datapoints
2025-03-06 21:50:00,190 - INFO - training batch 751, loss: 0.367, 24032/28000 datapoints
2025-03-06 21:50:00,340 - INFO - training batch 801, loss: 0.312, 25632/28000 datapoints
2025-03-06 21:50:00,489 - INFO - training batch 851, loss: 0.710, 27232/28000 datapoints
2025-03-06 21:50:00,564 - INFO - validation batch 1, loss: 0.203, 32/6976 datapoints
2025-03-06 21:50:00,612 - INFO - validation batch 51, loss: 1.410, 1632/6976 datapoints
2025-03-06 21:50:00,659 - INFO - validation batch 101, loss: 0.296, 3232/6976 datapoints
2025-03-06 21:50:00,706 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 21:50:00,754 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:50:00,771 - INFO - Epoch 118/800 done.
2025-03-06 21:50:00,771 - INFO - Final validation performance:
Loss: 0.594, top-1 acc: 0.840top-5 acc: 0.840
2025-03-06 21:50:00,771 - INFO - Beginning epoch 119/800
2025-03-06 21:50:00,775 - INFO - training batch 1, loss: 0.467, 32/28000 datapoints
2025-03-06 21:50:00,929 - INFO - training batch 51, loss: 0.337, 1632/28000 datapoints
2025-03-06 21:50:01,078 - INFO - training batch 101, loss: 0.248, 3232/28000 datapoints
2025-03-06 21:50:01,227 - INFO - training batch 151, loss: 0.748, 4832/28000 datapoints
2025-03-06 21:50:01,376 - INFO - training batch 201, loss: 0.287, 6432/28000 datapoints
2025-03-06 21:50:01,524 - INFO - training batch 251, loss: 0.349, 8032/28000 datapoints
2025-03-06 21:50:01,671 - INFO - training batch 301, loss: 0.737, 9632/28000 datapoints
2025-03-06 21:50:01,821 - INFO - training batch 351, loss: 0.472, 11232/28000 datapoints
2025-03-06 21:50:01,972 - INFO - training batch 401, loss: 0.750, 12832/28000 datapoints
2025-03-06 21:50:02,122 - INFO - training batch 451, loss: 0.571, 14432/28000 datapoints
2025-03-06 21:50:02,270 - INFO - training batch 501, loss: 0.279, 16032/28000 datapoints
2025-03-06 21:50:02,423 - INFO - training batch 551, loss: 0.633, 17632/28000 datapoints
2025-03-06 21:50:02,574 - INFO - training batch 601, loss: 1.009, 19232/28000 datapoints
2025-03-06 21:50:02,724 - INFO - training batch 651, loss: 0.185, 20832/28000 datapoints
2025-03-06 21:50:02,875 - INFO - training batch 701, loss: 0.395, 22432/28000 datapoints
2025-03-06 21:50:03,025 - INFO - training batch 751, loss: 0.362, 24032/28000 datapoints
2025-03-06 21:50:03,176 - INFO - training batch 801, loss: 0.310, 25632/28000 datapoints
2025-03-06 21:50:03,326 - INFO - training batch 851, loss: 0.706, 27232/28000 datapoints
2025-03-06 21:50:03,399 - INFO - validation batch 1, loss: 0.200, 32/6976 datapoints
2025-03-06 21:50:03,447 - INFO - validation batch 51, loss: 1.408, 1632/6976 datapoints
2025-03-06 21:50:03,494 - INFO - validation batch 101, loss: 0.295, 3232/6976 datapoints
2025-03-06 21:50:03,543 - INFO - validation batch 151, loss: 0.495, 4832/6976 datapoints
2025-03-06 21:50:03,590 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:50:03,608 - INFO - Epoch 119/800 done.
2025-03-06 21:50:03,608 - INFO - Final validation performance:
Loss: 0.593, top-1 acc: 0.841top-5 acc: 0.841
2025-03-06 21:50:03,609 - INFO - Beginning epoch 120/800
2025-03-06 21:50:03,613 - INFO - training batch 1, loss: 0.462, 32/28000 datapoints
2025-03-06 21:50:03,784 - INFO - training batch 51, loss: 0.333, 1632/28000 datapoints
2025-03-06 21:50:03,937 - INFO - training batch 101, loss: 0.245, 3232/28000 datapoints
2025-03-06 21:50:04,088 - INFO - training batch 151, loss: 0.745, 4832/28000 datapoints
2025-03-06 21:50:04,239 - INFO - training batch 201, loss: 0.282, 6432/28000 datapoints
2025-03-06 21:50:04,388 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:50:04,539 - INFO - training batch 301, loss: 0.736, 9632/28000 datapoints
2025-03-06 21:50:04,686 - INFO - training batch 351, loss: 0.470, 11232/28000 datapoints
2025-03-06 21:50:04,834 - INFO - training batch 401, loss: 0.747, 12832/28000 datapoints
2025-03-06 21:50:04,986 - INFO - training batch 451, loss: 0.567, 14432/28000 datapoints
2025-03-06 21:50:05,142 - INFO - training batch 501, loss: 0.275, 16032/28000 datapoints
2025-03-06 21:50:05,292 - INFO - training batch 551, loss: 0.628, 17632/28000 datapoints
2025-03-06 21:50:05,446 - INFO - training batch 601, loss: 1.004, 19232/28000 datapoints
2025-03-06 21:50:05,599 - INFO - training batch 651, loss: 0.182, 20832/28000 datapoints
2025-03-06 21:50:05,752 - INFO - training batch 701, loss: 0.392, 22432/28000 datapoints
2025-03-06 21:50:05,910 - INFO - training batch 751, loss: 0.358, 24032/28000 datapoints
2025-03-06 21:50:06,065 - INFO - training batch 801, loss: 0.307, 25632/28000 datapoints
2025-03-06 21:50:06,219 - INFO - training batch 851, loss: 0.702, 27232/28000 datapoints
2025-03-06 21:50:06,296 - INFO - validation batch 1, loss: 0.197, 32/6976 datapoints
2025-03-06 21:50:06,361 - INFO - validation batch 51, loss: 1.404, 1632/6976 datapoints
2025-03-06 21:50:06,429 - INFO - validation batch 101, loss: 0.294, 3232/6976 datapoints
2025-03-06 21:50:06,482 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 21:50:06,536 - INFO - validation batch 201, loss: 0.570, 6432/6976 datapoints
2025-03-06 21:50:06,571 - INFO - Epoch 120/800 done.
2025-03-06 21:50:06,574 - INFO - Final validation performance:
Loss: 0.592, top-1 acc: 0.842top-5 acc: 0.842
2025-03-06 21:50:06,574 - INFO - Beginning epoch 121/800
2025-03-06 21:50:06,579 - INFO - training batch 1, loss: 0.458, 32/28000 datapoints
2025-03-06 21:50:06,735 - INFO - training batch 51, loss: 0.328, 1632/28000 datapoints
2025-03-06 21:50:06,891 - INFO - training batch 101, loss: 0.243, 3232/28000 datapoints
2025-03-06 21:50:07,044 - INFO - training batch 151, loss: 0.741, 4832/28000 datapoints
2025-03-06 21:50:07,198 - INFO - training batch 201, loss: 0.277, 6432/28000 datapoints
2025-03-06 21:50:07,350 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:50:07,504 - INFO - training batch 301, loss: 0.736, 9632/28000 datapoints
2025-03-06 21:50:07,658 - INFO - training batch 351, loss: 0.466, 11232/28000 datapoints
2025-03-06 21:50:07,811 - INFO - training batch 401, loss: 0.745, 12832/28000 datapoints
2025-03-06 21:50:07,966 - INFO - training batch 451, loss: 0.563, 14432/28000 datapoints
2025-03-06 21:50:08,118 - INFO - training batch 501, loss: 0.272, 16032/28000 datapoints
2025-03-06 21:50:08,271 - INFO - training batch 551, loss: 0.624, 17632/28000 datapoints
2025-03-06 21:50:08,423 - INFO - training batch 601, loss: 1.000, 19232/28000 datapoints
2025-03-06 21:50:08,578 - INFO - training batch 651, loss: 0.179, 20832/28000 datapoints
2025-03-06 21:50:08,731 - INFO - training batch 701, loss: 0.390, 22432/28000 datapoints
2025-03-06 21:50:08,886 - INFO - training batch 751, loss: 0.354, 24032/28000 datapoints
2025-03-06 21:50:09,039 - INFO - training batch 801, loss: 0.305, 25632/28000 datapoints
2025-03-06 21:50:09,189 - INFO - training batch 851, loss: 0.697, 27232/28000 datapoints
2025-03-06 21:50:09,269 - INFO - validation batch 1, loss: 0.194, 32/6976 datapoints
2025-03-06 21:50:09,336 - INFO - validation batch 51, loss: 1.402, 1632/6976 datapoints
2025-03-06 21:50:09,384 - INFO - validation batch 101, loss: 0.293, 3232/6976 datapoints
2025-03-06 21:50:09,432 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 21:50:09,479 - INFO - validation batch 201, loss: 0.571, 6432/6976 datapoints
2025-03-06 21:50:09,495 - INFO - Epoch 121/800 done.
2025-03-06 21:50:09,495 - INFO - Final validation performance:
Loss: 0.591, top-1 acc: 0.843top-5 acc: 0.843
2025-03-06 21:50:09,496 - INFO - Beginning epoch 122/800
2025-03-06 21:50:09,500 - INFO - training batch 1, loss: 0.453, 32/28000 datapoints
2025-03-06 21:50:09,660 - INFO - training batch 51, loss: 0.325, 1632/28000 datapoints
2025-03-06 21:50:09,815 - INFO - training batch 101, loss: 0.241, 3232/28000 datapoints
2025-03-06 21:50:09,969 - INFO - training batch 151, loss: 0.738, 4832/28000 datapoints
2025-03-06 21:50:10,124 - INFO - training batch 201, loss: 0.272, 6432/28000 datapoints
2025-03-06 21:50:10,277 - INFO - training batch 251, loss: 0.349, 8032/28000 datapoints
2025-03-06 21:50:10,426 - INFO - training batch 301, loss: 0.734, 9632/28000 datapoints
2025-03-06 21:50:10,581 - INFO - training batch 351, loss: 0.464, 11232/28000 datapoints
2025-03-06 21:50:10,728 - INFO - training batch 401, loss: 0.743, 12832/28000 datapoints
2025-03-06 21:50:10,880 - INFO - training batch 451, loss: 0.560, 14432/28000 datapoints
2025-03-06 21:50:11,030 - INFO - training batch 501, loss: 0.268, 16032/28000 datapoints
2025-03-06 21:50:11,179 - INFO - training batch 551, loss: 0.619, 17632/28000 datapoints
2025-03-06 21:50:11,330 - INFO - training batch 601, loss: 0.996, 19232/28000 datapoints
2025-03-06 21:50:11,480 - INFO - training batch 651, loss: 0.175, 20832/28000 datapoints
2025-03-06 21:50:11,629 - INFO - training batch 701, loss: 0.388, 22432/28000 datapoints
2025-03-06 21:50:11,781 - INFO - training batch 751, loss: 0.350, 24032/28000 datapoints
2025-03-06 21:50:11,933 - INFO - training batch 801, loss: 0.303, 25632/28000 datapoints
2025-03-06 21:50:12,089 - INFO - training batch 851, loss: 0.693, 27232/28000 datapoints
2025-03-06 21:50:12,163 - INFO - validation batch 1, loss: 0.191, 32/6976 datapoints
2025-03-06 21:50:12,209 - INFO - validation batch 51, loss: 1.399, 1632/6976 datapoints
2025-03-06 21:50:12,259 - INFO - validation batch 101, loss: 0.292, 3232/6976 datapoints
2025-03-06 21:50:12,307 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 21:50:12,354 - INFO - validation batch 201, loss: 0.571, 6432/6976 datapoints
2025-03-06 21:50:12,370 - INFO - Epoch 122/800 done.
2025-03-06 21:50:12,370 - INFO - Final validation performance:
Loss: 0.590, top-1 acc: 0.842top-5 acc: 0.842
2025-03-06 21:50:12,371 - INFO - Beginning epoch 123/800
2025-03-06 21:50:12,375 - INFO - training batch 1, loss: 0.449, 32/28000 datapoints
2025-03-06 21:50:12,534 - INFO - training batch 51, loss: 0.320, 1632/28000 datapoints
2025-03-06 21:50:12,685 - INFO - training batch 101, loss: 0.239, 3232/28000 datapoints
2025-03-06 21:50:12,836 - INFO - training batch 151, loss: 0.736, 4832/28000 datapoints
2025-03-06 21:50:12,986 - INFO - training batch 201, loss: 0.268, 6432/28000 datapoints
2025-03-06 21:50:13,197 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:50:13,368 - INFO - training batch 301, loss: 0.734, 9632/28000 datapoints
2025-03-06 21:50:13,519 - INFO - training batch 351, loss: 0.461, 11232/28000 datapoints
2025-03-06 21:50:13,670 - INFO - training batch 401, loss: 0.741, 12832/28000 datapoints
2025-03-06 21:50:13,819 - INFO - training batch 451, loss: 0.556, 14432/28000 datapoints
2025-03-06 21:50:13,971 - INFO - training batch 501, loss: 0.265, 16032/28000 datapoints
2025-03-06 21:50:14,121 - INFO - training batch 551, loss: 0.614, 17632/28000 datapoints
2025-03-06 21:50:14,271 - INFO - training batch 601, loss: 0.989, 19232/28000 datapoints
2025-03-06 21:50:14,422 - INFO - training batch 651, loss: 0.173, 20832/28000 datapoints
2025-03-06 21:50:14,575 - INFO - training batch 701, loss: 0.385, 22432/28000 datapoints
2025-03-06 21:50:14,724 - INFO - training batch 751, loss: 0.346, 24032/28000 datapoints
2025-03-06 21:50:14,874 - INFO - training batch 801, loss: 0.301, 25632/28000 datapoints
2025-03-06 21:50:15,025 - INFO - training batch 851, loss: 0.689, 27232/28000 datapoints
2025-03-06 21:50:15,103 - INFO - validation batch 1, loss: 0.188, 32/6976 datapoints
2025-03-06 21:50:15,150 - INFO - validation batch 51, loss: 1.398, 1632/6976 datapoints
2025-03-06 21:50:15,197 - INFO - validation batch 101, loss: 0.292, 3232/6976 datapoints
2025-03-06 21:50:15,246 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 21:50:15,293 - INFO - validation batch 201, loss: 0.573, 6432/6976 datapoints
2025-03-06 21:50:15,309 - INFO - Epoch 123/800 done.
2025-03-06 21:50:15,309 - INFO - Final validation performance:
Loss: 0.589, top-1 acc: 0.843top-5 acc: 0.843
2025-03-06 21:50:15,310 - INFO - Beginning epoch 124/800
2025-03-06 21:50:15,315 - INFO - training batch 1, loss: 0.445, 32/28000 datapoints
2025-03-06 21:50:15,465 - INFO - training batch 51, loss: 0.317, 1632/28000 datapoints
2025-03-06 21:50:15,615 - INFO - training batch 101, loss: 0.236, 3232/28000 datapoints
2025-03-06 21:50:15,776 - INFO - training batch 151, loss: 0.733, 4832/28000 datapoints
2025-03-06 21:50:15,929 - INFO - training batch 201, loss: 0.264, 6432/28000 datapoints
2025-03-06 21:50:16,086 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:50:16,240 - INFO - training batch 301, loss: 0.732, 9632/28000 datapoints
2025-03-06 21:50:16,389 - INFO - training batch 351, loss: 0.458, 11232/28000 datapoints
2025-03-06 21:50:16,568 - INFO - training batch 401, loss: 0.739, 12832/28000 datapoints
2025-03-06 21:50:16,721 - INFO - training batch 451, loss: 0.553, 14432/28000 datapoints
2025-03-06 21:50:16,872 - INFO - training batch 501, loss: 0.261, 16032/28000 datapoints
2025-03-06 21:50:17,021 - INFO - training batch 551, loss: 0.610, 17632/28000 datapoints
2025-03-06 21:50:17,170 - INFO - training batch 601, loss: 0.984, 19232/28000 datapoints
2025-03-06 21:50:17,320 - INFO - training batch 651, loss: 0.170, 20832/28000 datapoints
2025-03-06 21:50:17,470 - INFO - training batch 701, loss: 0.382, 22432/28000 datapoints
2025-03-06 21:50:17,619 - INFO - training batch 751, loss: 0.342, 24032/28000 datapoints
2025-03-06 21:50:17,766 - INFO - training batch 801, loss: 0.299, 25632/28000 datapoints
2025-03-06 21:50:17,918 - INFO - training batch 851, loss: 0.685, 27232/28000 datapoints
2025-03-06 21:50:17,993 - INFO - validation batch 1, loss: 0.185, 32/6976 datapoints
2025-03-06 21:50:18,040 - INFO - validation batch 51, loss: 1.396, 1632/6976 datapoints
2025-03-06 21:50:18,089 - INFO - validation batch 101, loss: 0.291, 3232/6976 datapoints
2025-03-06 21:50:18,136 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 21:50:18,183 - INFO - validation batch 201, loss: 0.574, 6432/6976 datapoints
2025-03-06 21:50:18,199 - INFO - Epoch 124/800 done.
2025-03-06 21:50:18,199 - INFO - Final validation performance:
Loss: 0.589, top-1 acc: 0.844top-5 acc: 0.844
2025-03-06 21:50:18,200 - INFO - Beginning epoch 125/800
2025-03-06 21:50:18,204 - INFO - training batch 1, loss: 0.441, 32/28000 datapoints
2025-03-06 21:50:18,360 - INFO - training batch 51, loss: 0.313, 1632/28000 datapoints
2025-03-06 21:50:18,511 - INFO - training batch 101, loss: 0.234, 3232/28000 datapoints
2025-03-06 21:50:18,666 - INFO - training batch 151, loss: 0.730, 4832/28000 datapoints
2025-03-06 21:50:18,816 - INFO - training batch 201, loss: 0.259, 6432/28000 datapoints
2025-03-06 21:50:18,967 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:50:19,119 - INFO - training batch 301, loss: 0.731, 9632/28000 datapoints
2025-03-06 21:50:19,272 - INFO - training batch 351, loss: 0.454, 11232/28000 datapoints
2025-03-06 21:50:19,423 - INFO - training batch 401, loss: 0.737, 12832/28000 datapoints
2025-03-06 21:50:19,575 - INFO - training batch 451, loss: 0.549, 14432/28000 datapoints
2025-03-06 21:50:19,723 - INFO - training batch 501, loss: 0.258, 16032/28000 datapoints
2025-03-06 21:50:19,875 - INFO - training batch 551, loss: 0.605, 17632/28000 datapoints
2025-03-06 21:50:20,025 - INFO - training batch 601, loss: 0.978, 19232/28000 datapoints
2025-03-06 21:50:20,174 - INFO - training batch 651, loss: 0.167, 20832/28000 datapoints
2025-03-06 21:50:20,324 - INFO - training batch 701, loss: 0.380, 22432/28000 datapoints
2025-03-06 21:50:20,471 - INFO - training batch 751, loss: 0.339, 24032/28000 datapoints
2025-03-06 21:50:20,622 - INFO - training batch 801, loss: 0.296, 25632/28000 datapoints
2025-03-06 21:50:20,771 - INFO - training batch 851, loss: 0.680, 27232/28000 datapoints
2025-03-06 21:50:20,846 - INFO - validation batch 1, loss: 0.182, 32/6976 datapoints
2025-03-06 21:50:20,893 - INFO - validation batch 51, loss: 1.394, 1632/6976 datapoints
2025-03-06 21:50:20,945 - INFO - validation batch 101, loss: 0.291, 3232/6976 datapoints
2025-03-06 21:50:20,993 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 21:50:21,044 - INFO - validation batch 201, loss: 0.575, 6432/6976 datapoints
2025-03-06 21:50:21,064 - INFO - Epoch 125/800 done.
2025-03-06 21:50:21,064 - INFO - Final validation performance:
Loss: 0.588, top-1 acc: 0.845top-5 acc: 0.845
2025-03-06 21:50:21,064 - INFO - Beginning epoch 126/800
2025-03-06 21:50:21,069 - INFO - training batch 1, loss: 0.438, 32/28000 datapoints
2025-03-06 21:50:21,222 - INFO - training batch 51, loss: 0.309, 1632/28000 datapoints
2025-03-06 21:50:21,371 - INFO - training batch 101, loss: 0.232, 3232/28000 datapoints
2025-03-06 21:50:21,521 - INFO - training batch 151, loss: 0.727, 4832/28000 datapoints
2025-03-06 21:50:21,675 - INFO - training batch 201, loss: 0.255, 6432/28000 datapoints
2025-03-06 21:50:21,839 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:50:21,989 - INFO - training batch 301, loss: 0.731, 9632/28000 datapoints
2025-03-06 21:50:22,140 - INFO - training batch 351, loss: 0.452, 11232/28000 datapoints
2025-03-06 21:50:22,298 - INFO - training batch 401, loss: 0.736, 12832/28000 datapoints
2025-03-06 21:50:22,455 - INFO - training batch 451, loss: 0.545, 14432/28000 datapoints
2025-03-06 21:50:22,610 - INFO - training batch 501, loss: 0.254, 16032/28000 datapoints
2025-03-06 21:50:22,759 - INFO - training batch 551, loss: 0.601, 17632/28000 datapoints
2025-03-06 21:50:22,912 - INFO - training batch 601, loss: 0.972, 19232/28000 datapoints
2025-03-06 21:50:23,061 - INFO - training batch 651, loss: 0.164, 20832/28000 datapoints
2025-03-06 21:50:23,210 - INFO - training batch 701, loss: 0.378, 22432/28000 datapoints
2025-03-06 21:50:23,358 - INFO - training batch 751, loss: 0.334, 24032/28000 datapoints
2025-03-06 21:50:23,506 - INFO - training batch 801, loss: 0.294, 25632/28000 datapoints
2025-03-06 21:50:23,655 - INFO - training batch 851, loss: 0.676, 27232/28000 datapoints
2025-03-06 21:50:23,728 - INFO - validation batch 1, loss: 0.180, 32/6976 datapoints
2025-03-06 21:50:23,774 - INFO - validation batch 51, loss: 1.393, 1632/6976 datapoints
2025-03-06 21:50:23,822 - INFO - validation batch 101, loss: 0.290, 3232/6976 datapoints
2025-03-06 21:50:23,873 - INFO - validation batch 151, loss: 0.497, 4832/6976 datapoints
2025-03-06 21:50:23,921 - INFO - validation batch 201, loss: 0.576, 6432/6976 datapoints
2025-03-06 21:50:23,937 - INFO - Epoch 126/800 done.
2025-03-06 21:50:23,937 - INFO - Final validation performance:
Loss: 0.587, top-1 acc: 0.846top-5 acc: 0.846
2025-03-06 21:50:23,937 - INFO - Beginning epoch 127/800
2025-03-06 21:50:23,941 - INFO - training batch 1, loss: 0.434, 32/28000 datapoints
2025-03-06 21:50:24,095 - INFO - training batch 51, loss: 0.306, 1632/28000 datapoints
2025-03-06 21:50:24,244 - INFO - training batch 101, loss: 0.230, 3232/28000 datapoints
2025-03-06 21:50:24,393 - INFO - training batch 151, loss: 0.723, 4832/28000 datapoints
2025-03-06 21:50:24,541 - INFO - training batch 201, loss: 0.251, 6432/28000 datapoints
2025-03-06 21:50:24,692 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:50:24,840 - INFO - training batch 301, loss: 0.729, 9632/28000 datapoints
2025-03-06 21:50:24,989 - INFO - training batch 351, loss: 0.448, 11232/28000 datapoints
2025-03-06 21:50:25,148 - INFO - training batch 401, loss: 0.733, 12832/28000 datapoints
2025-03-06 21:50:25,297 - INFO - training batch 451, loss: 0.541, 14432/28000 datapoints
2025-03-06 21:50:25,445 - INFO - training batch 501, loss: 0.251, 16032/28000 datapoints
2025-03-06 21:50:25,598 - INFO - training batch 551, loss: 0.597, 17632/28000 datapoints
2025-03-06 21:50:25,752 - INFO - training batch 601, loss: 0.967, 19232/28000 datapoints
2025-03-06 21:50:25,908 - INFO - training batch 651, loss: 0.161, 20832/28000 datapoints
2025-03-06 21:50:26,060 - INFO - training batch 701, loss: 0.375, 22432/28000 datapoints
2025-03-06 21:50:26,217 - INFO - training batch 751, loss: 0.331, 24032/28000 datapoints
2025-03-06 21:50:26,372 - INFO - training batch 801, loss: 0.291, 25632/28000 datapoints
2025-03-06 21:50:26,535 - INFO - training batch 851, loss: 0.671, 27232/28000 datapoints
2025-03-06 21:50:26,632 - INFO - validation batch 1, loss: 0.178, 32/6976 datapoints
2025-03-06 21:50:26,685 - INFO - validation batch 51, loss: 1.390, 1632/6976 datapoints
2025-03-06 21:50:26,733 - INFO - validation batch 101, loss: 0.290, 3232/6976 datapoints
2025-03-06 21:50:26,782 - INFO - validation batch 151, loss: 0.497, 4832/6976 datapoints
2025-03-06 21:50:26,829 - INFO - validation batch 201, loss: 0.577, 6432/6976 datapoints
2025-03-06 21:50:26,848 - INFO - Epoch 127/800 done.
2025-03-06 21:50:26,848 - INFO - Final validation performance:
Loss: 0.586, top-1 acc: 0.847top-5 acc: 0.847
2025-03-06 21:50:26,848 - INFO - Beginning epoch 128/800
2025-03-06 21:50:26,853 - INFO - training batch 1, loss: 0.431, 32/28000 datapoints
2025-03-06 21:50:27,005 - INFO - training batch 51, loss: 0.302, 1632/28000 datapoints
2025-03-06 21:50:27,158 - INFO - training batch 101, loss: 0.228, 3232/28000 datapoints
2025-03-06 21:50:27,306 - INFO - training batch 151, loss: 0.721, 4832/28000 datapoints
2025-03-06 21:50:27,455 - INFO - training batch 201, loss: 0.247, 6432/28000 datapoints
2025-03-06 21:50:27,603 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:50:27,761 - INFO - training batch 301, loss: 0.728, 9632/28000 datapoints
2025-03-06 21:50:27,916 - INFO - training batch 351, loss: 0.445, 11232/28000 datapoints
2025-03-06 21:50:28,063 - INFO - training batch 401, loss: 0.731, 12832/28000 datapoints
2025-03-06 21:50:28,211 - INFO - training batch 451, loss: 0.538, 14432/28000 datapoints
2025-03-06 21:50:28,366 - INFO - training batch 501, loss: 0.248, 16032/28000 datapoints
2025-03-06 21:50:28,517 - INFO - training batch 551, loss: 0.593, 17632/28000 datapoints
2025-03-06 21:50:28,670 - INFO - training batch 601, loss: 0.960, 19232/28000 datapoints
2025-03-06 21:50:28,824 - INFO - training batch 651, loss: 0.159, 20832/28000 datapoints
2025-03-06 21:50:28,977 - INFO - training batch 701, loss: 0.373, 22432/28000 datapoints
2025-03-06 21:50:29,126 - INFO - training batch 751, loss: 0.327, 24032/28000 datapoints
2025-03-06 21:50:29,277 - INFO - training batch 801, loss: 0.289, 25632/28000 datapoints
2025-03-06 21:50:29,426 - INFO - training batch 851, loss: 0.668, 27232/28000 datapoints
2025-03-06 21:50:29,499 - INFO - validation batch 1, loss: 0.175, 32/6976 datapoints
2025-03-06 21:50:29,547 - INFO - validation batch 51, loss: 1.390, 1632/6976 datapoints
2025-03-06 21:50:29,593 - INFO - validation batch 101, loss: 0.289, 3232/6976 datapoints
2025-03-06 21:50:29,641 - INFO - validation batch 151, loss: 0.495, 4832/6976 datapoints
2025-03-06 21:50:29,688 - INFO - validation batch 201, loss: 0.579, 6432/6976 datapoints
2025-03-06 21:50:29,704 - INFO - Epoch 128/800 done.
2025-03-06 21:50:29,705 - INFO - Final validation performance:
Loss: 0.586, top-1 acc: 0.847top-5 acc: 0.847
2025-03-06 21:50:29,705 - INFO - Beginning epoch 129/800
2025-03-06 21:50:29,709 - INFO - training batch 1, loss: 0.427, 32/28000 datapoints
2025-03-06 21:50:29,861 - INFO - training batch 51, loss: 0.299, 1632/28000 datapoints
2025-03-06 21:50:30,012 - INFO - training batch 101, loss: 0.226, 3232/28000 datapoints
2025-03-06 21:50:30,166 - INFO - training batch 151, loss: 0.718, 4832/28000 datapoints
2025-03-06 21:50:30,316 - INFO - training batch 201, loss: 0.243, 6432/28000 datapoints
2025-03-06 21:50:30,464 - INFO - training batch 251, loss: 0.349, 8032/28000 datapoints
2025-03-06 21:50:30,611 - INFO - training batch 301, loss: 0.727, 9632/28000 datapoints
2025-03-06 21:50:30,764 - INFO - training batch 351, loss: 0.441, 11232/28000 datapoints
2025-03-06 21:50:30,915 - INFO - training batch 401, loss: 0.729, 12832/28000 datapoints
2025-03-06 21:50:31,064 - INFO - training batch 451, loss: 0.535, 14432/28000 datapoints
2025-03-06 21:50:31,215 - INFO - training batch 501, loss: 0.245, 16032/28000 datapoints
2025-03-06 21:50:31,364 - INFO - training batch 551, loss: 0.589, 17632/28000 datapoints
2025-03-06 21:50:31,516 - INFO - training batch 601, loss: 0.954, 19232/28000 datapoints
2025-03-06 21:50:31,667 - INFO - training batch 651, loss: 0.156, 20832/28000 datapoints
2025-03-06 21:50:31,816 - INFO - training batch 701, loss: 0.371, 22432/28000 datapoints
2025-03-06 21:50:31,969 - INFO - training batch 751, loss: 0.322, 24032/28000 datapoints
2025-03-06 21:50:32,117 - INFO - training batch 801, loss: 0.287, 25632/28000 datapoints
2025-03-06 21:50:32,267 - INFO - training batch 851, loss: 0.663, 27232/28000 datapoints
2025-03-06 21:50:32,340 - INFO - validation batch 1, loss: 0.172, 32/6976 datapoints
2025-03-06 21:50:32,387 - INFO - validation batch 51, loss: 1.389, 1632/6976 datapoints
2025-03-06 21:50:32,433 - INFO - validation batch 101, loss: 0.289, 3232/6976 datapoints
2025-03-06 21:50:32,484 - INFO - validation batch 151, loss: 0.493, 4832/6976 datapoints
2025-03-06 21:50:32,530 - INFO - validation batch 201, loss: 0.579, 6432/6976 datapoints
2025-03-06 21:50:32,546 - INFO - Epoch 129/800 done.
2025-03-06 21:50:32,547 - INFO - Final validation performance:
Loss: 0.584, top-1 acc: 0.847top-5 acc: 0.847
2025-03-06 21:50:32,547 - INFO - Beginning epoch 130/800
2025-03-06 21:50:32,552 - INFO - training batch 1, loss: 0.423, 32/28000 datapoints
2025-03-06 21:50:32,706 - INFO - training batch 51, loss: 0.296, 1632/28000 datapoints
2025-03-06 21:50:32,855 - INFO - training batch 101, loss: 0.225, 3232/28000 datapoints
2025-03-06 21:50:33,005 - INFO - training batch 151, loss: 0.715, 4832/28000 datapoints
2025-03-06 21:50:33,153 - INFO - training batch 201, loss: 0.239, 6432/28000 datapoints
2025-03-06 21:50:33,302 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:50:33,451 - INFO - training batch 301, loss: 0.726, 9632/28000 datapoints
2025-03-06 21:50:33,599 - INFO - training batch 351, loss: 0.438, 11232/28000 datapoints
2025-03-06 21:50:33,748 - INFO - training batch 401, loss: 0.727, 12832/28000 datapoints
2025-03-06 21:50:33,919 - INFO - training batch 451, loss: 0.532, 14432/28000 datapoints
2025-03-06 21:50:34,068 - INFO - training batch 501, loss: 0.242, 16032/28000 datapoints
2025-03-06 21:50:34,224 - INFO - training batch 551, loss: 0.585, 17632/28000 datapoints
2025-03-06 21:50:34,377 - INFO - training batch 601, loss: 0.947, 19232/28000 datapoints
2025-03-06 21:50:34,529 - INFO - training batch 651, loss: 0.153, 20832/28000 datapoints
2025-03-06 21:50:34,686 - INFO - training batch 701, loss: 0.368, 22432/28000 datapoints
2025-03-06 21:50:34,834 - INFO - training batch 751, loss: 0.319, 24032/28000 datapoints
2025-03-06 21:50:34,984 - INFO - training batch 801, loss: 0.285, 25632/28000 datapoints
2025-03-06 21:50:35,140 - INFO - training batch 851, loss: 0.660, 27232/28000 datapoints
2025-03-06 21:50:35,215 - INFO - validation batch 1, loss: 0.170, 32/6976 datapoints
2025-03-06 21:50:35,262 - INFO - validation batch 51, loss: 1.388, 1632/6976 datapoints
2025-03-06 21:50:35,310 - INFO - validation batch 101, loss: 0.289, 3232/6976 datapoints
2025-03-06 21:50:35,357 - INFO - validation batch 151, loss: 0.493, 4832/6976 datapoints
2025-03-06 21:50:35,405 - INFO - validation batch 201, loss: 0.580, 6432/6976 datapoints
2025-03-06 21:50:35,421 - INFO - Epoch 130/800 done.
2025-03-06 21:50:35,421 - INFO - Final validation performance:
Loss: 0.584, top-1 acc: 0.848top-5 acc: 0.848
2025-03-06 21:50:35,422 - INFO - Beginning epoch 131/800
2025-03-06 21:50:35,426 - INFO - training batch 1, loss: 0.420, 32/28000 datapoints
2025-03-06 21:50:35,576 - INFO - training batch 51, loss: 0.293, 1632/28000 datapoints
2025-03-06 21:50:35,726 - INFO - training batch 101, loss: 0.223, 3232/28000 datapoints
2025-03-06 21:50:35,880 - INFO - training batch 151, loss: 0.712, 4832/28000 datapoints
2025-03-06 21:50:36,028 - INFO - training batch 201, loss: 0.236, 6432/28000 datapoints
2025-03-06 21:50:36,175 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:50:36,327 - INFO - training batch 301, loss: 0.725, 9632/28000 datapoints
2025-03-06 21:50:36,476 - INFO - training batch 351, loss: 0.435, 11232/28000 datapoints
2025-03-06 21:50:36,632 - INFO - training batch 401, loss: 0.725, 12832/28000 datapoints
2025-03-06 21:50:36,803 - INFO - training batch 451, loss: 0.530, 14432/28000 datapoints
2025-03-06 21:50:36,956 - INFO - training batch 501, loss: 0.240, 16032/28000 datapoints
2025-03-06 21:50:37,106 - INFO - training batch 551, loss: 0.581, 17632/28000 datapoints
2025-03-06 21:50:37,255 - INFO - training batch 601, loss: 0.941, 19232/28000 datapoints
2025-03-06 21:50:37,403 - INFO - training batch 651, loss: 0.151, 20832/28000 datapoints
2025-03-06 21:50:37,551 - INFO - training batch 701, loss: 0.366, 22432/28000 datapoints
2025-03-06 21:50:37,699 - INFO - training batch 751, loss: 0.315, 24032/28000 datapoints
2025-03-06 21:50:37,862 - INFO - training batch 801, loss: 0.283, 25632/28000 datapoints
2025-03-06 21:50:38,010 - INFO - training batch 851, loss: 0.655, 27232/28000 datapoints
2025-03-06 21:50:38,083 - INFO - validation batch 1, loss: 0.168, 32/6976 datapoints
2025-03-06 21:50:38,130 - INFO - validation batch 51, loss: 1.387, 1632/6976 datapoints
2025-03-06 21:50:38,176 - INFO - validation batch 101, loss: 0.289, 3232/6976 datapoints
2025-03-06 21:50:38,223 - INFO - validation batch 151, loss: 0.492, 4832/6976 datapoints
2025-03-06 21:50:38,273 - INFO - validation batch 201, loss: 0.582, 6432/6976 datapoints
2025-03-06 21:50:38,289 - INFO - Epoch 131/800 done.
2025-03-06 21:50:38,289 - INFO - Final validation performance:
Loss: 0.583, top-1 acc: 0.848top-5 acc: 0.848
2025-03-06 21:50:38,290 - INFO - Beginning epoch 132/800
2025-03-06 21:50:38,294 - INFO - training batch 1, loss: 0.417, 32/28000 datapoints
2025-03-06 21:50:38,445 - INFO - training batch 51, loss: 0.290, 1632/28000 datapoints
2025-03-06 21:50:38,592 - INFO - training batch 101, loss: 0.221, 3232/28000 datapoints
2025-03-06 21:50:38,744 - INFO - training batch 151, loss: 0.710, 4832/28000 datapoints
2025-03-06 21:50:38,899 - INFO - training batch 201, loss: 0.231, 6432/28000 datapoints
2025-03-06 21:50:39,050 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:50:39,198 - INFO - training batch 301, loss: 0.723, 9632/28000 datapoints
2025-03-06 21:50:39,351 - INFO - training batch 351, loss: 0.431, 11232/28000 datapoints
2025-03-06 21:50:39,501 - INFO - training batch 401, loss: 0.723, 12832/28000 datapoints
2025-03-06 21:50:39,649 - INFO - training batch 451, loss: 0.526, 14432/28000 datapoints
2025-03-06 21:50:39,801 - INFO - training batch 501, loss: 0.238, 16032/28000 datapoints
2025-03-06 21:50:39,966 - INFO - training batch 551, loss: 0.577, 17632/28000 datapoints
2025-03-06 21:50:40,117 - INFO - training batch 601, loss: 0.935, 19232/28000 datapoints
2025-03-06 21:50:40,274 - INFO - training batch 651, loss: 0.149, 20832/28000 datapoints
2025-03-06 21:50:40,428 - INFO - training batch 701, loss: 0.363, 22432/28000 datapoints
2025-03-06 21:50:40,576 - INFO - training batch 751, loss: 0.312, 24032/28000 datapoints
2025-03-06 21:50:40,731 - INFO - training batch 801, loss: 0.281, 25632/28000 datapoints
2025-03-06 21:50:40,885 - INFO - training batch 851, loss: 0.651, 27232/28000 datapoints
2025-03-06 21:50:40,959 - INFO - validation batch 1, loss: 0.166, 32/6976 datapoints
2025-03-06 21:50:41,006 - INFO - validation batch 51, loss: 1.386, 1632/6976 datapoints
2025-03-06 21:50:41,052 - INFO - validation batch 101, loss: 0.289, 3232/6976 datapoints
2025-03-06 21:50:41,100 - INFO - validation batch 151, loss: 0.492, 4832/6976 datapoints
2025-03-06 21:50:41,146 - INFO - validation batch 201, loss: 0.584, 6432/6976 datapoints
2025-03-06 21:50:41,163 - INFO - Epoch 132/800 done.
2025-03-06 21:50:41,163 - INFO - Final validation performance:
Loss: 0.583, top-1 acc: 0.848top-5 acc: 0.848
2025-03-06 21:50:41,163 - INFO - Beginning epoch 133/800
2025-03-06 21:50:41,168 - INFO - training batch 1, loss: 0.413, 32/28000 datapoints
2025-03-06 21:50:41,321 - INFO - training batch 51, loss: 0.287, 1632/28000 datapoints
2025-03-06 21:50:41,470 - INFO - training batch 101, loss: 0.219, 3232/28000 datapoints
2025-03-06 21:50:41,619 - INFO - training batch 151, loss: 0.707, 4832/28000 datapoints
2025-03-06 21:50:41,768 - INFO - training batch 201, loss: 0.228, 6432/28000 datapoints
2025-03-06 21:50:41,926 - INFO - training batch 251, loss: 0.347, 8032/28000 datapoints
2025-03-06 21:50:42,076 - INFO - training batch 301, loss: 0.721, 9632/28000 datapoints
2025-03-06 21:50:42,235 - INFO - training batch 351, loss: 0.428, 11232/28000 datapoints
2025-03-06 21:50:42,386 - INFO - training batch 401, loss: 0.721, 12832/28000 datapoints
2025-03-06 21:50:42,538 - INFO - training batch 451, loss: 0.524, 14432/28000 datapoints
2025-03-06 21:50:42,691 - INFO - training batch 501, loss: 0.235, 16032/28000 datapoints
2025-03-06 21:50:42,843 - INFO - training batch 551, loss: 0.573, 17632/28000 datapoints
2025-03-06 21:50:42,991 - INFO - training batch 601, loss: 0.929, 19232/28000 datapoints
2025-03-06 21:50:43,139 - INFO - training batch 651, loss: 0.146, 20832/28000 datapoints
2025-03-06 21:50:43,289 - INFO - training batch 701, loss: 0.360, 22432/28000 datapoints
2025-03-06 21:50:43,437 - INFO - training batch 751, loss: 0.309, 24032/28000 datapoints
2025-03-06 21:50:43,586 - INFO - training batch 801, loss: 0.279, 25632/28000 datapoints
2025-03-06 21:50:43,735 - INFO - training batch 851, loss: 0.648, 27232/28000 datapoints
2025-03-06 21:50:43,808 - INFO - validation batch 1, loss: 0.163, 32/6976 datapoints
2025-03-06 21:50:43,859 - INFO - validation batch 51, loss: 1.385, 1632/6976 datapoints
2025-03-06 21:50:43,907 - INFO - validation batch 101, loss: 0.288, 3232/6976 datapoints
2025-03-06 21:50:43,954 - INFO - validation batch 151, loss: 0.492, 4832/6976 datapoints
2025-03-06 21:50:44,001 - INFO - validation batch 201, loss: 0.585, 6432/6976 datapoints
2025-03-06 21:50:44,017 - INFO - Epoch 133/800 done.
2025-03-06 21:50:44,017 - INFO - Final validation performance:
Loss: 0.583, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 21:50:44,017 - INFO - Beginning epoch 134/800
2025-03-06 21:50:44,022 - INFO - training batch 1, loss: 0.410, 32/28000 datapoints
2025-03-06 21:50:44,173 - INFO - training batch 51, loss: 0.284, 1632/28000 datapoints
2025-03-06 21:50:44,328 - INFO - training batch 101, loss: 0.218, 3232/28000 datapoints
2025-03-06 21:50:44,478 - INFO - training batch 151, loss: 0.704, 4832/28000 datapoints
2025-03-06 21:50:44,626 - INFO - training batch 201, loss: 0.225, 6432/28000 datapoints
2025-03-06 21:50:44,777 - INFO - training batch 251, loss: 0.347, 8032/28000 datapoints
2025-03-06 21:50:44,930 - INFO - training batch 301, loss: 0.721, 9632/28000 datapoints
2025-03-06 21:50:45,085 - INFO - training batch 351, loss: 0.425, 11232/28000 datapoints
2025-03-06 21:50:45,234 - INFO - training batch 401, loss: 0.719, 12832/28000 datapoints
2025-03-06 21:50:45,384 - INFO - training batch 451, loss: 0.521, 14432/28000 datapoints
2025-03-06 21:50:45,531 - INFO - training batch 501, loss: 0.232, 16032/28000 datapoints
2025-03-06 21:50:45,680 - INFO - training batch 551, loss: 0.569, 17632/28000 datapoints
2025-03-06 21:50:45,840 - INFO - training batch 601, loss: 0.922, 19232/28000 datapoints
2025-03-06 21:50:46,006 - INFO - training batch 651, loss: 0.144, 20832/28000 datapoints
2025-03-06 21:50:46,162 - INFO - training batch 701, loss: 0.358, 22432/28000 datapoints
2025-03-06 21:50:46,327 - INFO - training batch 751, loss: 0.305, 24032/28000 datapoints
2025-03-06 21:50:46,491 - INFO - training batch 801, loss: 0.276, 25632/28000 datapoints
2025-03-06 21:50:46,649 - INFO - training batch 851, loss: 0.645, 27232/28000 datapoints
2025-03-06 21:50:46,734 - INFO - validation batch 1, loss: 0.161, 32/6976 datapoints
2025-03-06 21:50:46,807 - INFO - validation batch 51, loss: 1.385, 1632/6976 datapoints
2025-03-06 21:50:46,864 - INFO - validation batch 101, loss: 0.288, 3232/6976 datapoints
2025-03-06 21:50:46,916 - INFO - validation batch 151, loss: 0.491, 4832/6976 datapoints
2025-03-06 21:50:46,972 - INFO - validation batch 201, loss: 0.586, 6432/6976 datapoints
2025-03-06 21:50:46,995 - INFO - Epoch 134/800 done.
2025-03-06 21:50:46,995 - INFO - Final validation performance:
Loss: 0.582, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:50:46,996 - INFO - Beginning epoch 135/800
2025-03-06 21:50:47,000 - INFO - training batch 1, loss: 0.407, 32/28000 datapoints
2025-03-06 21:50:47,155 - INFO - training batch 51, loss: 0.282, 1632/28000 datapoints
2025-03-06 21:50:47,310 - INFO - training batch 101, loss: 0.216, 3232/28000 datapoints
2025-03-06 21:50:47,464 - INFO - training batch 151, loss: 0.701, 4832/28000 datapoints
2025-03-06 21:50:47,615 - INFO - training batch 201, loss: 0.222, 6432/28000 datapoints
2025-03-06 21:50:47,766 - INFO - training batch 251, loss: 0.347, 8032/28000 datapoints
2025-03-06 21:50:47,928 - INFO - training batch 301, loss: 0.720, 9632/28000 datapoints
2025-03-06 21:50:48,083 - INFO - training batch 351, loss: 0.422, 11232/28000 datapoints
2025-03-06 21:50:48,239 - INFO - training batch 401, loss: 0.717, 12832/28000 datapoints
2025-03-06 21:50:48,393 - INFO - training batch 451, loss: 0.518, 14432/28000 datapoints
2025-03-06 21:50:48,545 - INFO - training batch 501, loss: 0.229, 16032/28000 datapoints
2025-03-06 21:50:48,698 - INFO - training batch 551, loss: 0.564, 17632/28000 datapoints
2025-03-06 21:50:48,857 - INFO - training batch 601, loss: 0.916, 19232/28000 datapoints
2025-03-06 21:50:49,009 - INFO - training batch 651, loss: 0.142, 20832/28000 datapoints
2025-03-06 21:50:49,164 - INFO - training batch 701, loss: 0.356, 22432/28000 datapoints
2025-03-06 21:50:49,318 - INFO - training batch 751, loss: 0.302, 24032/28000 datapoints
2025-03-06 21:50:49,471 - INFO - training batch 801, loss: 0.274, 25632/28000 datapoints
2025-03-06 21:50:49,621 - INFO - training batch 851, loss: 0.641, 27232/28000 datapoints
2025-03-06 21:50:49,701 - INFO - validation batch 1, loss: 0.159, 32/6976 datapoints
2025-03-06 21:50:49,753 - INFO - validation batch 51, loss: 1.384, 1632/6976 datapoints
2025-03-06 21:50:49,805 - INFO - validation batch 101, loss: 0.288, 3232/6976 datapoints
2025-03-06 21:50:49,860 - INFO - validation batch 151, loss: 0.491, 4832/6976 datapoints
2025-03-06 21:50:49,913 - INFO - validation batch 201, loss: 0.587, 6432/6976 datapoints
2025-03-06 21:50:49,931 - INFO - Epoch 135/800 done.
2025-03-06 21:50:49,931 - INFO - Final validation performance:
Loss: 0.582, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:50:49,931 - INFO - Beginning epoch 136/800
2025-03-06 21:50:49,936 - INFO - training batch 1, loss: 0.404, 32/28000 datapoints
2025-03-06 21:50:50,096 - INFO - training batch 51, loss: 0.280, 1632/28000 datapoints
2025-03-06 21:50:50,249 - INFO - training batch 101, loss: 0.214, 3232/28000 datapoints
2025-03-06 21:50:50,405 - INFO - training batch 151, loss: 0.698, 4832/28000 datapoints
2025-03-06 21:50:50,555 - INFO - training batch 201, loss: 0.218, 6432/28000 datapoints
2025-03-06 21:50:50,706 - INFO - training batch 251, loss: 0.347, 8032/28000 datapoints
2025-03-06 21:50:50,865 - INFO - training batch 301, loss: 0.719, 9632/28000 datapoints
2025-03-06 21:50:51,017 - INFO - training batch 351, loss: 0.418, 11232/28000 datapoints
2025-03-06 21:50:51,169 - INFO - training batch 401, loss: 0.715, 12832/28000 datapoints
2025-03-06 21:50:51,323 - INFO - training batch 451, loss: 0.515, 14432/28000 datapoints
2025-03-06 21:50:51,477 - INFO - training batch 501, loss: 0.227, 16032/28000 datapoints
2025-03-06 21:50:51,630 - INFO - training batch 551, loss: 0.561, 17632/28000 datapoints
2025-03-06 21:50:51,784 - INFO - training batch 601, loss: 0.910, 19232/28000 datapoints
2025-03-06 21:50:51,939 - INFO - training batch 651, loss: 0.139, 20832/28000 datapoints
2025-03-06 21:50:52,101 - INFO - training batch 701, loss: 0.354, 22432/28000 datapoints
2025-03-06 21:50:52,269 - INFO - training batch 751, loss: 0.299, 24032/28000 datapoints
2025-03-06 21:50:52,423 - INFO - training batch 801, loss: 0.272, 25632/28000 datapoints
2025-03-06 21:50:52,584 - INFO - training batch 851, loss: 0.637, 27232/28000 datapoints
2025-03-06 21:50:52,661 - INFO - validation batch 1, loss: 0.157, 32/6976 datapoints
2025-03-06 21:50:52,718 - INFO - validation batch 51, loss: 1.383, 1632/6976 datapoints
2025-03-06 21:50:52,769 - INFO - validation batch 101, loss: 0.288, 3232/6976 datapoints
2025-03-06 21:50:52,821 - INFO - validation batch 151, loss: 0.491, 4832/6976 datapoints
2025-03-06 21:50:52,875 - INFO - validation batch 201, loss: 0.587, 6432/6976 datapoints
2025-03-06 21:50:52,896 - INFO - Epoch 136/800 done.
2025-03-06 21:50:52,896 - INFO - Final validation performance:
Loss: 0.581, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:50:52,896 - INFO - Beginning epoch 137/800
2025-03-06 21:50:52,903 - INFO - training batch 1, loss: 0.401, 32/28000 datapoints
2025-03-06 21:50:53,062 - INFO - training batch 51, loss: 0.277, 1632/28000 datapoints
2025-03-06 21:50:53,215 - INFO - training batch 101, loss: 0.213, 3232/28000 datapoints
2025-03-06 21:50:53,368 - INFO - training batch 151, loss: 0.694, 4832/28000 datapoints
2025-03-06 21:50:53,522 - INFO - training batch 201, loss: 0.215, 6432/28000 datapoints
2025-03-06 21:50:53,674 - INFO - training batch 251, loss: 0.347, 8032/28000 datapoints
2025-03-06 21:50:53,826 - INFO - training batch 301, loss: 0.719, 9632/28000 datapoints
2025-03-06 21:50:53,982 - INFO - training batch 351, loss: 0.415, 11232/28000 datapoints
2025-03-06 21:50:54,135 - INFO - training batch 401, loss: 0.714, 12832/28000 datapoints
2025-03-06 21:50:54,290 - INFO - training batch 451, loss: 0.513, 14432/28000 datapoints
2025-03-06 21:50:54,446 - INFO - training batch 501, loss: 0.224, 16032/28000 datapoints
2025-03-06 21:50:54,598 - INFO - training batch 551, loss: 0.557, 17632/28000 datapoints
2025-03-06 21:50:54,756 - INFO - training batch 601, loss: 0.904, 19232/28000 datapoints
2025-03-06 21:50:54,911 - INFO - training batch 651, loss: 0.137, 20832/28000 datapoints
2025-03-06 21:50:55,067 - INFO - training batch 701, loss: 0.352, 22432/28000 datapoints
2025-03-06 21:50:55,223 - INFO - training batch 751, loss: 0.296, 24032/28000 datapoints
2025-03-06 21:50:55,376 - INFO - training batch 801, loss: 0.270, 25632/28000 datapoints
2025-03-06 21:50:55,528 - INFO - training batch 851, loss: 0.634, 27232/28000 datapoints
2025-03-06 21:50:55,604 - INFO - validation batch 1, loss: 0.155, 32/6976 datapoints
2025-03-06 21:50:55,655 - INFO - validation batch 51, loss: 1.383, 1632/6976 datapoints
2025-03-06 21:50:55,706 - INFO - validation batch 101, loss: 0.287, 3232/6976 datapoints
2025-03-06 21:50:55,757 - INFO - validation batch 151, loss: 0.491, 4832/6976 datapoints
2025-03-06 21:50:55,807 - INFO - validation batch 201, loss: 0.588, 6432/6976 datapoints
2025-03-06 21:50:55,823 - INFO - Epoch 137/800 done.
2025-03-06 21:50:55,824 - INFO - Final validation performance:
Loss: 0.581, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:50:55,824 - INFO - Beginning epoch 138/800
2025-03-06 21:50:55,829 - INFO - training batch 1, loss: 0.398, 32/28000 datapoints
2025-03-06 21:50:55,990 - INFO - training batch 51, loss: 0.275, 1632/28000 datapoints
2025-03-06 21:50:56,142 - INFO - training batch 101, loss: 0.211, 3232/28000 datapoints
2025-03-06 21:50:56,298 - INFO - training batch 151, loss: 0.692, 4832/28000 datapoints
2025-03-06 21:50:56,452 - INFO - training batch 201, loss: 0.212, 6432/28000 datapoints
2025-03-06 21:50:56,603 - INFO - training batch 251, loss: 0.347, 8032/28000 datapoints
2025-03-06 21:50:56,758 - INFO - training batch 301, loss: 0.718, 9632/28000 datapoints
2025-03-06 21:50:56,937 - INFO - training batch 351, loss: 0.412, 11232/28000 datapoints
2025-03-06 21:50:57,089 - INFO - training batch 401, loss: 0.712, 12832/28000 datapoints
2025-03-06 21:50:57,241 - INFO - training batch 451, loss: 0.510, 14432/28000 datapoints
2025-03-06 21:50:57,394 - INFO - training batch 501, loss: 0.222, 16032/28000 datapoints
2025-03-06 21:50:57,546 - INFO - training batch 551, loss: 0.554, 17632/28000 datapoints
2025-03-06 21:50:57,700 - INFO - training batch 601, loss: 0.897, 19232/28000 datapoints
2025-03-06 21:50:57,855 - INFO - training batch 651, loss: 0.135, 20832/28000 datapoints
2025-03-06 21:50:58,007 - INFO - training batch 701, loss: 0.350, 22432/28000 datapoints
2025-03-06 21:50:58,158 - INFO - training batch 751, loss: 0.292, 24032/28000 datapoints
2025-03-06 21:50:58,315 - INFO - training batch 801, loss: 0.268, 25632/28000 datapoints
2025-03-06 21:50:58,477 - INFO - training batch 851, loss: 0.630, 27232/28000 datapoints
2025-03-06 21:50:58,552 - INFO - validation batch 1, loss: 0.153, 32/6976 datapoints
2025-03-06 21:50:58,603 - INFO - validation batch 51, loss: 1.382, 1632/6976 datapoints
2025-03-06 21:50:58,656 - INFO - validation batch 101, loss: 0.287, 3232/6976 datapoints
2025-03-06 21:50:58,710 - INFO - validation batch 151, loss: 0.491, 4832/6976 datapoints
2025-03-06 21:50:58,767 - INFO - validation batch 201, loss: 0.590, 6432/6976 datapoints
2025-03-06 21:50:58,788 - INFO - Epoch 138/800 done.
2025-03-06 21:50:58,788 - INFO - Final validation performance:
Loss: 0.581, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:50:58,788 - INFO - Beginning epoch 139/800
2025-03-06 21:50:58,793 - INFO - training batch 1, loss: 0.395, 32/28000 datapoints
2025-03-06 21:50:58,957 - INFO - training batch 51, loss: 0.273, 1632/28000 datapoints
2025-03-06 21:50:59,116 - INFO - training batch 101, loss: 0.209, 3232/28000 datapoints
2025-03-06 21:50:59,272 - INFO - training batch 151, loss: 0.689, 4832/28000 datapoints
2025-03-06 21:50:59,435 - INFO - training batch 201, loss: 0.209, 6432/28000 datapoints
2025-03-06 21:50:59,593 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:50:59,748 - INFO - training batch 301, loss: 0.718, 9632/28000 datapoints
2025-03-06 21:50:59,904 - INFO - training batch 351, loss: 0.409, 11232/28000 datapoints
2025-03-06 21:51:00,063 - INFO - training batch 401, loss: 0.710, 12832/28000 datapoints
2025-03-06 21:51:00,215 - INFO - training batch 451, loss: 0.507, 14432/28000 datapoints
2025-03-06 21:51:00,370 - INFO - training batch 501, loss: 0.220, 16032/28000 datapoints
2025-03-06 21:51:00,520 - INFO - training batch 551, loss: 0.550, 17632/28000 datapoints
2025-03-06 21:51:00,669 - INFO - training batch 601, loss: 0.892, 19232/28000 datapoints
2025-03-06 21:51:00,822 - INFO - training batch 651, loss: 0.133, 20832/28000 datapoints
2025-03-06 21:51:00,972 - INFO - training batch 701, loss: 0.348, 22432/28000 datapoints
2025-03-06 21:51:01,121 - INFO - training batch 751, loss: 0.290, 24032/28000 datapoints
2025-03-06 21:51:01,268 - INFO - training batch 801, loss: 0.266, 25632/28000 datapoints
2025-03-06 21:51:01,416 - INFO - training batch 851, loss: 0.625, 27232/28000 datapoints
2025-03-06 21:51:01,490 - INFO - validation batch 1, loss: 0.152, 32/6976 datapoints
2025-03-06 21:51:01,538 - INFO - validation batch 51, loss: 1.381, 1632/6976 datapoints
2025-03-06 21:51:01,586 - INFO - validation batch 101, loss: 0.286, 3232/6976 datapoints
2025-03-06 21:51:01,632 - INFO - validation batch 151, loss: 0.491, 4832/6976 datapoints
2025-03-06 21:51:01,681 - INFO - validation batch 201, loss: 0.591, 6432/6976 datapoints
2025-03-06 21:51:01,697 - INFO - Epoch 139/800 done.
2025-03-06 21:51:01,697 - INFO - Final validation performance:
Loss: 0.580, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:51:01,698 - INFO - Beginning epoch 140/800
2025-03-06 21:51:01,702 - INFO - training batch 1, loss: 0.393, 32/28000 datapoints
2025-03-06 21:51:01,854 - INFO - training batch 51, loss: 0.270, 1632/28000 datapoints
2025-03-06 21:51:02,002 - INFO - training batch 101, loss: 0.208, 3232/28000 datapoints
2025-03-06 21:51:02,154 - INFO - training batch 151, loss: 0.686, 4832/28000 datapoints
2025-03-06 21:51:02,303 - INFO - training batch 201, loss: 0.206, 6432/28000 datapoints
2025-03-06 21:51:02,452 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:51:02,610 - INFO - training batch 301, loss: 0.717, 9632/28000 datapoints
2025-03-06 21:51:02,764 - INFO - training batch 351, loss: 0.405, 11232/28000 datapoints
2025-03-06 21:51:02,918 - INFO - training batch 401, loss: 0.708, 12832/28000 datapoints
2025-03-06 21:51:03,069 - INFO - training batch 451, loss: 0.505, 14432/28000 datapoints
2025-03-06 21:51:03,219 - INFO - training batch 501, loss: 0.218, 16032/28000 datapoints
2025-03-06 21:51:03,368 - INFO - training batch 551, loss: 0.547, 17632/28000 datapoints
2025-03-06 21:51:03,518 - INFO - training batch 601, loss: 0.885, 19232/28000 datapoints
2025-03-06 21:51:03,667 - INFO - training batch 651, loss: 0.131, 20832/28000 datapoints
2025-03-06 21:51:03,814 - INFO - training batch 701, loss: 0.346, 22432/28000 datapoints
2025-03-06 21:51:03,965 - INFO - training batch 751, loss: 0.286, 24032/28000 datapoints
2025-03-06 21:51:04,115 - INFO - training batch 801, loss: 0.264, 25632/28000 datapoints
2025-03-06 21:51:04,263 - INFO - training batch 851, loss: 0.622, 27232/28000 datapoints
2025-03-06 21:51:04,339 - INFO - validation batch 1, loss: 0.150, 32/6976 datapoints
2025-03-06 21:51:04,386 - INFO - validation batch 51, loss: 1.379, 1632/6976 datapoints
2025-03-06 21:51:04,433 - INFO - validation batch 101, loss: 0.286, 3232/6976 datapoints
2025-03-06 21:51:04,483 - INFO - validation batch 151, loss: 0.491, 4832/6976 datapoints
2025-03-06 21:51:04,542 - INFO - validation batch 201, loss: 0.591, 6432/6976 datapoints
2025-03-06 21:51:04,565 - INFO - Epoch 140/800 done.
2025-03-06 21:51:04,566 - INFO - Final validation performance:
Loss: 0.579, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:51:04,566 - INFO - Beginning epoch 141/800
2025-03-06 21:51:04,570 - INFO - training batch 1, loss: 0.391, 32/28000 datapoints
2025-03-06 21:51:04,721 - INFO - training batch 51, loss: 0.268, 1632/28000 datapoints
2025-03-06 21:51:04,875 - INFO - training batch 101, loss: 0.206, 3232/28000 datapoints
2025-03-06 21:51:05,033 - INFO - training batch 151, loss: 0.684, 4832/28000 datapoints
2025-03-06 21:51:05,192 - INFO - training batch 201, loss: 0.203, 6432/28000 datapoints
2025-03-06 21:51:05,341 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:51:05,488 - INFO - training batch 301, loss: 0.717, 9632/28000 datapoints
2025-03-06 21:51:05,638 - INFO - training batch 351, loss: 0.402, 11232/28000 datapoints
2025-03-06 21:51:05,792 - INFO - training batch 401, loss: 0.706, 12832/28000 datapoints
2025-03-06 21:51:05,948 - INFO - training batch 451, loss: 0.503, 14432/28000 datapoints
2025-03-06 21:51:06,102 - INFO - training batch 501, loss: 0.216, 16032/28000 datapoints
2025-03-06 21:51:06,258 - INFO - training batch 551, loss: 0.543, 17632/28000 datapoints
2025-03-06 21:51:06,414 - INFO - training batch 601, loss: 0.878, 19232/28000 datapoints
2025-03-06 21:51:06,568 - INFO - training batch 651, loss: 0.128, 20832/28000 datapoints
2025-03-06 21:51:06,721 - INFO - training batch 701, loss: 0.344, 22432/28000 datapoints
2025-03-06 21:51:06,877 - INFO - training batch 751, loss: 0.284, 24032/28000 datapoints
2025-03-06 21:51:07,053 - INFO - training batch 801, loss: 0.262, 25632/28000 datapoints
2025-03-06 21:51:07,207 - INFO - training batch 851, loss: 0.618, 27232/28000 datapoints
2025-03-06 21:51:07,283 - INFO - validation batch 1, loss: 0.148, 32/6976 datapoints
2025-03-06 21:51:07,334 - INFO - validation batch 51, loss: 1.379, 1632/6976 datapoints
2025-03-06 21:51:07,385 - INFO - validation batch 101, loss: 0.285, 3232/6976 datapoints
2025-03-06 21:51:07,438 - INFO - validation batch 151, loss: 0.490, 4832/6976 datapoints
2025-03-06 21:51:07,486 - INFO - validation batch 201, loss: 0.592, 6432/6976 datapoints
2025-03-06 21:51:07,503 - INFO - Epoch 141/800 done.
2025-03-06 21:51:07,503 - INFO - Final validation performance:
Loss: 0.579, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:51:07,503 - INFO - Beginning epoch 142/800
2025-03-06 21:51:07,508 - INFO - training batch 1, loss: 0.388, 32/28000 datapoints
2025-03-06 21:51:07,661 - INFO - training batch 51, loss: 0.266, 1632/28000 datapoints
2025-03-06 21:51:07,811 - INFO - training batch 101, loss: 0.204, 3232/28000 datapoints
2025-03-06 21:51:07,965 - INFO - training batch 151, loss: 0.680, 4832/28000 datapoints
2025-03-06 21:51:08,115 - INFO - training batch 201, loss: 0.200, 6432/28000 datapoints
2025-03-06 21:51:08,263 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:51:08,410 - INFO - training batch 301, loss: 0.716, 9632/28000 datapoints
2025-03-06 21:51:08,559 - INFO - training batch 351, loss: 0.398, 11232/28000 datapoints
2025-03-06 21:51:08,708 - INFO - training batch 401, loss: 0.703, 12832/28000 datapoints
2025-03-06 21:51:08,862 - INFO - training batch 451, loss: 0.500, 14432/28000 datapoints
2025-03-06 21:51:09,011 - INFO - training batch 501, loss: 0.214, 16032/28000 datapoints
2025-03-06 21:51:09,163 - INFO - training batch 551, loss: 0.540, 17632/28000 datapoints
2025-03-06 21:51:09,314 - INFO - training batch 601, loss: 0.872, 19232/28000 datapoints
2025-03-06 21:51:09,465 - INFO - training batch 651, loss: 0.127, 20832/28000 datapoints
2025-03-06 21:51:09,615 - INFO - training batch 701, loss: 0.342, 22432/28000 datapoints
2025-03-06 21:51:09,763 - INFO - training batch 751, loss: 0.280, 24032/28000 datapoints
2025-03-06 21:51:09,913 - INFO - training batch 801, loss: 0.260, 25632/28000 datapoints
2025-03-06 21:51:10,062 - INFO - training batch 851, loss: 0.614, 27232/28000 datapoints
2025-03-06 21:51:10,136 - INFO - validation batch 1, loss: 0.147, 32/6976 datapoints
2025-03-06 21:51:10,183 - INFO - validation batch 51, loss: 1.378, 1632/6976 datapoints
2025-03-06 21:51:10,231 - INFO - validation batch 101, loss: 0.285, 3232/6976 datapoints
2025-03-06 21:51:10,279 - INFO - validation batch 151, loss: 0.490, 4832/6976 datapoints
2025-03-06 21:51:10,328 - INFO - validation batch 201, loss: 0.592, 6432/6976 datapoints
2025-03-06 21:51:10,344 - INFO - Epoch 142/800 done.
2025-03-06 21:51:10,344 - INFO - Final validation performance:
Loss: 0.578, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:51:10,345 - INFO - Beginning epoch 143/800
2025-03-06 21:51:10,349 - INFO - training batch 1, loss: 0.386, 32/28000 datapoints
2025-03-06 21:51:10,501 - INFO - training batch 51, loss: 0.264, 1632/28000 datapoints
2025-03-06 21:51:10,653 - INFO - training batch 101, loss: 0.202, 3232/28000 datapoints
2025-03-06 21:51:10,804 - INFO - training batch 151, loss: 0.679, 4832/28000 datapoints
2025-03-06 21:51:10,955 - INFO - training batch 201, loss: 0.198, 6432/28000 datapoints
2025-03-06 21:51:11,103 - INFO - training batch 251, loss: 0.347, 8032/28000 datapoints
2025-03-06 21:51:11,253 - INFO - training batch 301, loss: 0.716, 9632/28000 datapoints
2025-03-06 21:51:11,402 - INFO - training batch 351, loss: 0.395, 11232/28000 datapoints
2025-03-06 21:51:11,552 - INFO - training batch 401, loss: 0.702, 12832/28000 datapoints
2025-03-06 21:51:11,703 - INFO - training batch 451, loss: 0.498, 14432/28000 datapoints
2025-03-06 21:51:11,853 - INFO - training batch 501, loss: 0.212, 16032/28000 datapoints
2025-03-06 21:51:12,003 - INFO - training batch 551, loss: 0.538, 17632/28000 datapoints
2025-03-06 21:51:12,156 - INFO - training batch 601, loss: 0.864, 19232/28000 datapoints
2025-03-06 21:51:12,309 - INFO - training batch 651, loss: 0.124, 20832/28000 datapoints
2025-03-06 21:51:12,457 - INFO - training batch 701, loss: 0.341, 22432/28000 datapoints
2025-03-06 21:51:12,620 - INFO - training batch 751, loss: 0.278, 24032/28000 datapoints
2025-03-06 21:51:12,770 - INFO - training batch 801, loss: 0.257, 25632/28000 datapoints
2025-03-06 21:51:12,923 - INFO - training batch 851, loss: 0.611, 27232/28000 datapoints
2025-03-06 21:51:12,996 - INFO - validation batch 1, loss: 0.146, 32/6976 datapoints
2025-03-06 21:51:13,050 - INFO - validation batch 51, loss: 1.379, 1632/6976 datapoints
2025-03-06 21:51:13,097 - INFO - validation batch 101, loss: 0.284, 3232/6976 datapoints
2025-03-06 21:51:13,146 - INFO - validation batch 151, loss: 0.489, 4832/6976 datapoints
2025-03-06 21:51:13,196 - INFO - validation batch 201, loss: 0.593, 6432/6976 datapoints
2025-03-06 21:51:13,212 - INFO - Epoch 143/800 done.
2025-03-06 21:51:13,212 - INFO - Final validation performance:
Loss: 0.578, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:51:13,212 - INFO - Beginning epoch 144/800
2025-03-06 21:51:13,217 - INFO - training batch 1, loss: 0.384, 32/28000 datapoints
2025-03-06 21:51:13,369 - INFO - training batch 51, loss: 0.263, 1632/28000 datapoints
2025-03-06 21:51:13,521 - INFO - training batch 101, loss: 0.201, 3232/28000 datapoints
2025-03-06 21:51:13,708 - INFO - training batch 151, loss: 0.676, 4832/28000 datapoints
2025-03-06 21:51:13,859 - INFO - training batch 201, loss: 0.196, 6432/28000 datapoints
2025-03-06 21:51:14,007 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:51:14,155 - INFO - training batch 301, loss: 0.715, 9632/28000 datapoints
2025-03-06 21:51:14,304 - INFO - training batch 351, loss: 0.391, 11232/28000 datapoints
2025-03-06 21:51:14,453 - INFO - training batch 401, loss: 0.699, 12832/28000 datapoints
2025-03-06 21:51:14,603 - INFO - training batch 451, loss: 0.496, 14432/28000 datapoints
2025-03-06 21:51:14,753 - INFO - training batch 501, loss: 0.210, 16032/28000 datapoints
2025-03-06 21:51:14,909 - INFO - training batch 551, loss: 0.536, 17632/28000 datapoints
2025-03-06 21:51:15,063 - INFO - training batch 601, loss: 0.858, 19232/28000 datapoints
2025-03-06 21:51:15,227 - INFO - training batch 651, loss: 0.122, 20832/28000 datapoints
2025-03-06 21:51:15,375 - INFO - training batch 701, loss: 0.339, 22432/28000 datapoints
2025-03-06 21:51:15,524 - INFO - training batch 751, loss: 0.275, 24032/28000 datapoints
2025-03-06 21:51:15,672 - INFO - training batch 801, loss: 0.256, 25632/28000 datapoints
2025-03-06 21:51:15,820 - INFO - training batch 851, loss: 0.607, 27232/28000 datapoints
2025-03-06 21:51:15,894 - INFO - validation batch 1, loss: 0.145, 32/6976 datapoints
2025-03-06 21:51:15,941 - INFO - validation batch 51, loss: 1.379, 1632/6976 datapoints
2025-03-06 21:51:15,989 - INFO - validation batch 101, loss: 0.284, 3232/6976 datapoints
2025-03-06 21:51:16,036 - INFO - validation batch 151, loss: 0.490, 4832/6976 datapoints
2025-03-06 21:51:16,083 - INFO - validation batch 201, loss: 0.593, 6432/6976 datapoints
2025-03-06 21:51:16,099 - INFO - Epoch 144/800 done.
2025-03-06 21:51:16,099 - INFO - Final validation performance:
Loss: 0.578, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:51:16,100 - INFO - Beginning epoch 145/800
2025-03-06 21:51:16,104 - INFO - training batch 1, loss: 0.382, 32/28000 datapoints
2025-03-06 21:51:16,257 - INFO - training batch 51, loss: 0.261, 1632/28000 datapoints
2025-03-06 21:51:16,406 - INFO - training batch 101, loss: 0.199, 3232/28000 datapoints
2025-03-06 21:51:16,561 - INFO - training batch 151, loss: 0.673, 4832/28000 datapoints
2025-03-06 21:51:16,714 - INFO - training batch 201, loss: 0.194, 6432/28000 datapoints
2025-03-06 21:51:16,867 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 21:51:17,023 - INFO - training batch 301, loss: 0.715, 9632/28000 datapoints
2025-03-06 21:51:17,190 - INFO - training batch 351, loss: 0.387, 11232/28000 datapoints
2025-03-06 21:51:17,338 - INFO - training batch 401, loss: 0.697, 12832/28000 datapoints
2025-03-06 21:51:17,485 - INFO - training batch 451, loss: 0.495, 14432/28000 datapoints
2025-03-06 21:51:17,636 - INFO - training batch 501, loss: 0.208, 16032/28000 datapoints
2025-03-06 21:51:17,788 - INFO - training batch 551, loss: 0.533, 17632/28000 datapoints
2025-03-06 21:51:17,940 - INFO - training batch 601, loss: 0.852, 19232/28000 datapoints
2025-03-06 21:51:18,107 - INFO - training batch 651, loss: 0.120, 20832/28000 datapoints
2025-03-06 21:51:18,256 - INFO - training batch 701, loss: 0.337, 22432/28000 datapoints
2025-03-06 21:51:18,404 - INFO - training batch 751, loss: 0.272, 24032/28000 datapoints
2025-03-06 21:51:18,552 - INFO - training batch 801, loss: 0.254, 25632/28000 datapoints
2025-03-06 21:51:18,708 - INFO - training batch 851, loss: 0.603, 27232/28000 datapoints
2025-03-06 21:51:18,782 - INFO - validation batch 1, loss: 0.143, 32/6976 datapoints
2025-03-06 21:51:18,832 - INFO - validation batch 51, loss: 1.379, 1632/6976 datapoints
2025-03-06 21:51:18,882 - INFO - validation batch 101, loss: 0.284, 3232/6976 datapoints
2025-03-06 21:51:18,928 - INFO - validation batch 151, loss: 0.489, 4832/6976 datapoints
2025-03-06 21:51:18,977 - INFO - validation batch 201, loss: 0.592, 6432/6976 datapoints
2025-03-06 21:51:18,993 - INFO - Epoch 145/800 done.
2025-03-06 21:51:18,993 - INFO - Final validation performance:
Loss: 0.578, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:51:18,994 - INFO - Beginning epoch 146/800
2025-03-06 21:51:18,998 - INFO - training batch 1, loss: 0.380, 32/28000 datapoints
2025-03-06 21:51:19,150 - INFO - training batch 51, loss: 0.259, 1632/28000 datapoints
2025-03-06 21:51:19,307 - INFO - training batch 101, loss: 0.198, 3232/28000 datapoints
2025-03-06 21:51:19,462 - INFO - training batch 151, loss: 0.670, 4832/28000 datapoints
2025-03-06 21:51:19,617 - INFO - training batch 201, loss: 0.192, 6432/28000 datapoints
2025-03-06 21:51:19,766 - INFO - training batch 251, loss: 0.349, 8032/28000 datapoints
2025-03-06 21:51:19,918 - INFO - training batch 301, loss: 0.714, 9632/28000 datapoints
2025-03-06 21:51:20,065 - INFO - training batch 351, loss: 0.383, 11232/28000 datapoints
2025-03-06 21:51:20,215 - INFO - training batch 401, loss: 0.695, 12832/28000 datapoints
2025-03-06 21:51:20,363 - INFO - training batch 451, loss: 0.493, 14432/28000 datapoints
2025-03-06 21:51:20,514 - INFO - training batch 501, loss: 0.206, 16032/28000 datapoints
2025-03-06 21:51:20,664 - INFO - training batch 551, loss: 0.530, 17632/28000 datapoints
2025-03-06 21:51:20,813 - INFO - training batch 601, loss: 0.845, 19232/28000 datapoints
2025-03-06 21:51:20,967 - INFO - training batch 651, loss: 0.119, 20832/28000 datapoints
2025-03-06 21:51:21,117 - INFO - training batch 701, loss: 0.336, 22432/28000 datapoints
2025-03-06 21:51:21,266 - INFO - training batch 751, loss: 0.269, 24032/28000 datapoints
2025-03-06 21:51:21,413 - INFO - training batch 801, loss: 0.252, 25632/28000 datapoints
2025-03-06 21:51:21,563 - INFO - training batch 851, loss: 0.599, 27232/28000 datapoints
2025-03-06 21:51:21,637 - INFO - validation batch 1, loss: 0.142, 32/6976 datapoints
2025-03-06 21:51:21,684 - INFO - validation batch 51, loss: 1.379, 1632/6976 datapoints
2025-03-06 21:51:21,732 - INFO - validation batch 101, loss: 0.284, 3232/6976 datapoints
2025-03-06 21:51:21,780 - INFO - validation batch 151, loss: 0.489, 4832/6976 datapoints
2025-03-06 21:51:21,827 - INFO - validation batch 201, loss: 0.591, 6432/6976 datapoints
2025-03-06 21:51:21,846 - INFO - Epoch 146/800 done.
2025-03-06 21:51:21,846 - INFO - Final validation performance:
Loss: 0.577, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:51:21,846 - INFO - Beginning epoch 147/800
2025-03-06 21:51:21,850 - INFO - training batch 1, loss: 0.378, 32/28000 datapoints
2025-03-06 21:51:22,002 - INFO - training batch 51, loss: 0.258, 1632/28000 datapoints
2025-03-06 21:51:22,152 - INFO - training batch 101, loss: 0.196, 3232/28000 datapoints
2025-03-06 21:51:22,303 - INFO - training batch 151, loss: 0.666, 4832/28000 datapoints
2025-03-06 21:51:22,452 - INFO - training batch 201, loss: 0.190, 6432/28000 datapoints
2025-03-06 21:51:22,603 - INFO - training batch 251, loss: 0.349, 8032/28000 datapoints
2025-03-06 21:51:22,752 - INFO - training batch 301, loss: 0.714, 9632/28000 datapoints
2025-03-06 21:51:22,915 - INFO - training batch 351, loss: 0.379, 11232/28000 datapoints
2025-03-06 21:51:23,072 - INFO - training batch 401, loss: 0.694, 12832/28000 datapoints
2025-03-06 21:51:23,245 - INFO - training batch 451, loss: 0.492, 14432/28000 datapoints
2025-03-06 21:51:23,394 - INFO - training batch 501, loss: 0.205, 16032/28000 datapoints
2025-03-06 21:51:23,546 - INFO - training batch 551, loss: 0.527, 17632/28000 datapoints
2025-03-06 21:51:23,694 - INFO - training batch 601, loss: 0.838, 19232/28000 datapoints
2025-03-06 21:51:23,846 - INFO - training batch 651, loss: 0.117, 20832/28000 datapoints
2025-03-06 21:51:23,994 - INFO - training batch 701, loss: 0.334, 22432/28000 datapoints
2025-03-06 21:51:24,143 - INFO - training batch 751, loss: 0.267, 24032/28000 datapoints
2025-03-06 21:51:24,290 - INFO - training batch 801, loss: 0.250, 25632/28000 datapoints
2025-03-06 21:51:24,441 - INFO - training batch 851, loss: 0.596, 27232/28000 datapoints
2025-03-06 21:51:24,514 - INFO - validation batch 1, loss: 0.141, 32/6976 datapoints
2025-03-06 21:51:24,561 - INFO - validation batch 51, loss: 1.381, 1632/6976 datapoints
2025-03-06 21:51:24,610 - INFO - validation batch 101, loss: 0.284, 3232/6976 datapoints
2025-03-06 21:51:24,656 - INFO - validation batch 151, loss: 0.490, 4832/6976 datapoints
2025-03-06 21:51:24,703 - INFO - validation batch 201, loss: 0.590, 6432/6976 datapoints
2025-03-06 21:51:24,719 - INFO - Epoch 147/800 done.
2025-03-06 21:51:24,720 - INFO - Final validation performance:
Loss: 0.577, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:51:24,720 - INFO - Beginning epoch 148/800
2025-03-06 21:51:24,724 - INFO - training batch 1, loss: 0.377, 32/28000 datapoints
2025-03-06 21:51:24,881 - INFO - training batch 51, loss: 0.257, 1632/28000 datapoints
2025-03-06 21:51:25,032 - INFO - training batch 101, loss: 0.195, 3232/28000 datapoints
2025-03-06 21:51:25,196 - INFO - training batch 151, loss: 0.662, 4832/28000 datapoints
2025-03-06 21:51:25,349 - INFO - training batch 201, loss: 0.189, 6432/28000 datapoints
2025-03-06 21:51:25,497 - INFO - training batch 251, loss: 0.349, 8032/28000 datapoints
2025-03-06 21:51:25,646 - INFO - training batch 301, loss: 0.713, 9632/28000 datapoints
2025-03-06 21:51:25,795 - INFO - training batch 351, loss: 0.375, 11232/28000 datapoints
2025-03-06 21:51:25,952 - INFO - training batch 401, loss: 0.692, 12832/28000 datapoints
2025-03-06 21:51:26,103 - INFO - training batch 451, loss: 0.490, 14432/28000 datapoints
2025-03-06 21:51:26,261 - INFO - training batch 501, loss: 0.203, 16032/28000 datapoints
2025-03-06 21:51:26,416 - INFO - training batch 551, loss: 0.524, 17632/28000 datapoints
2025-03-06 21:51:26,569 - INFO - training batch 601, loss: 0.830, 19232/28000 datapoints
2025-03-06 21:51:26,723 - INFO - training batch 651, loss: 0.115, 20832/28000 datapoints
2025-03-06 21:51:26,880 - INFO - training batch 701, loss: 0.332, 22432/28000 datapoints
2025-03-06 21:51:27,034 - INFO - training batch 751, loss: 0.264, 24032/28000 datapoints
2025-03-06 21:51:27,213 - INFO - training batch 801, loss: 0.248, 25632/28000 datapoints
2025-03-06 21:51:27,369 - INFO - training batch 851, loss: 0.593, 27232/28000 datapoints
2025-03-06 21:51:27,446 - INFO - validation batch 1, loss: 0.139, 32/6976 datapoints
2025-03-06 21:51:27,499 - INFO - validation batch 51, loss: 1.383, 1632/6976 datapoints
2025-03-06 21:51:27,553 - INFO - validation batch 101, loss: 0.284, 3232/6976 datapoints
2025-03-06 21:51:27,606 - INFO - validation batch 151, loss: 0.490, 4832/6976 datapoints
2025-03-06 21:51:27,657 - INFO - validation batch 201, loss: 0.589, 6432/6976 datapoints
2025-03-06 21:51:27,674 - INFO - Epoch 148/800 done.
2025-03-06 21:51:27,674 - INFO - Final validation performance:
Loss: 0.577, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:51:27,674 - INFO - Beginning epoch 149/800
2025-03-06 21:51:27,680 - INFO - training batch 1, loss: 0.375, 32/28000 datapoints
2025-03-06 21:51:27,836 - INFO - training batch 51, loss: 0.257, 1632/28000 datapoints
2025-03-06 21:51:28,054 - INFO - training batch 101, loss: 0.194, 3232/28000 datapoints
2025-03-06 21:51:28,215 - INFO - training batch 151, loss: 0.657, 4832/28000 datapoints
2025-03-06 21:51:28,370 - INFO - training batch 201, loss: 0.187, 6432/28000 datapoints
2025-03-06 21:51:28,529 - INFO - training batch 251, loss: 0.351, 8032/28000 datapoints
2025-03-06 21:51:28,684 - INFO - training batch 301, loss: 0.712, 9632/28000 datapoints
2025-03-06 21:51:28,835 - INFO - training batch 351, loss: 0.371, 11232/28000 datapoints
2025-03-06 21:51:28,994 - INFO - training batch 401, loss: 0.690, 12832/28000 datapoints
2025-03-06 21:51:29,151 - INFO - training batch 451, loss: 0.488, 14432/28000 datapoints
2025-03-06 21:51:29,313 - INFO - training batch 501, loss: 0.201, 16032/28000 datapoints
2025-03-06 21:51:29,482 - INFO - training batch 551, loss: 0.521, 17632/28000 datapoints
2025-03-06 21:51:29,635 - INFO - training batch 601, loss: 0.823, 19232/28000 datapoints
2025-03-06 21:51:29,788 - INFO - training batch 651, loss: 0.114, 20832/28000 datapoints
2025-03-06 21:51:29,943 - INFO - training batch 701, loss: 0.330, 22432/28000 datapoints
2025-03-06 21:51:30,093 - INFO - training batch 751, loss: 0.262, 24032/28000 datapoints
2025-03-06 21:51:30,245 - INFO - training batch 801, loss: 0.247, 25632/28000 datapoints
2025-03-06 21:51:30,396 - INFO - training batch 851, loss: 0.591, 27232/28000 datapoints
2025-03-06 21:51:30,473 - INFO - validation batch 1, loss: 0.138, 32/6976 datapoints
2025-03-06 21:51:30,528 - INFO - validation batch 51, loss: 1.386, 1632/6976 datapoints
2025-03-06 21:51:30,585 - INFO - validation batch 101, loss: 0.284, 3232/6976 datapoints
2025-03-06 21:51:30,640 - INFO - validation batch 151, loss: 0.491, 4832/6976 datapoints
2025-03-06 21:51:30,689 - INFO - validation batch 201, loss: 0.587, 6432/6976 datapoints
2025-03-06 21:51:30,705 - INFO - Epoch 149/800 done.
2025-03-06 21:51:30,706 - INFO - Final validation performance:
Loss: 0.577, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:51:30,706 - INFO - Beginning epoch 150/800
2025-03-06 21:51:30,710 - INFO - training batch 1, loss: 0.374, 32/28000 datapoints
2025-03-06 21:51:30,861 - INFO - training batch 51, loss: 0.256, 1632/28000 datapoints
2025-03-06 21:51:31,016 - INFO - training batch 101, loss: 0.193, 3232/28000 datapoints
2025-03-06 21:51:31,166 - INFO - training batch 151, loss: 0.653, 4832/28000 datapoints
2025-03-06 21:51:31,319 - INFO - training batch 201, loss: 0.186, 6432/28000 datapoints
2025-03-06 21:51:31,467 - INFO - training batch 251, loss: 0.351, 8032/28000 datapoints
2025-03-06 21:51:31,617 - INFO - training batch 301, loss: 0.711, 9632/28000 datapoints
2025-03-06 21:51:31,765 - INFO - training batch 351, loss: 0.367, 11232/28000 datapoints
2025-03-06 21:51:31,915 - INFO - training batch 401, loss: 0.687, 12832/28000 datapoints
2025-03-06 21:51:32,064 - INFO - training batch 451, loss: 0.487, 14432/28000 datapoints
2025-03-06 21:51:32,216 - INFO - training batch 501, loss: 0.199, 16032/28000 datapoints
2025-03-06 21:51:32,363 - INFO - training batch 551, loss: 0.517, 17632/28000 datapoints
2025-03-06 21:51:32,515 - INFO - training batch 601, loss: 0.817, 19232/28000 datapoints
2025-03-06 21:51:32,668 - INFO - training batch 651, loss: 0.112, 20832/28000 datapoints
2025-03-06 21:51:32,821 - INFO - training batch 701, loss: 0.328, 22432/28000 datapoints
2025-03-06 21:51:32,978 - INFO - training batch 751, loss: 0.260, 24032/28000 datapoints
2025-03-06 21:51:33,129 - INFO - training batch 801, loss: 0.245, 25632/28000 datapoints
2025-03-06 21:51:33,278 - INFO - training batch 851, loss: 0.587, 27232/28000 datapoints
2025-03-06 21:51:33,352 - INFO - validation batch 1, loss: 0.137, 32/6976 datapoints
2025-03-06 21:51:33,399 - INFO - validation batch 51, loss: 1.387, 1632/6976 datapoints
2025-03-06 21:51:33,445 - INFO - validation batch 101, loss: 0.284, 3232/6976 datapoints
2025-03-06 21:51:33,495 - INFO - validation batch 151, loss: 0.490, 4832/6976 datapoints
2025-03-06 21:51:33,542 - INFO - validation batch 201, loss: 0.586, 6432/6976 datapoints
2025-03-06 21:51:33,558 - INFO - Epoch 150/800 done.
2025-03-06 21:51:33,558 - INFO - Final validation performance:
Loss: 0.577, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:51:33,559 - INFO - Beginning epoch 151/800
2025-03-06 21:51:33,563 - INFO - training batch 1, loss: 0.373, 32/28000 datapoints
2025-03-06 21:51:33,713 - INFO - training batch 51, loss: 0.255, 1632/28000 datapoints
2025-03-06 21:51:33,868 - INFO - training batch 101, loss: 0.192, 3232/28000 datapoints
2025-03-06 21:51:34,018 - INFO - training batch 151, loss: 0.650, 4832/28000 datapoints
2025-03-06 21:51:34,167 - INFO - training batch 201, loss: 0.183, 6432/28000 datapoints
2025-03-06 21:51:34,315 - INFO - training batch 251, loss: 0.350, 8032/28000 datapoints
2025-03-06 21:51:34,463 - INFO - training batch 301, loss: 0.710, 9632/28000 datapoints
2025-03-06 21:51:34,615 - INFO - training batch 351, loss: 0.363, 11232/28000 datapoints
2025-03-06 21:51:34,764 - INFO - training batch 401, loss: 0.686, 12832/28000 datapoints
2025-03-06 21:51:34,924 - INFO - training batch 451, loss: 0.485, 14432/28000 datapoints
2025-03-06 21:51:35,077 - INFO - training batch 501, loss: 0.198, 16032/28000 datapoints
2025-03-06 21:51:35,236 - INFO - training batch 551, loss: 0.515, 17632/28000 datapoints
2025-03-06 21:51:35,385 - INFO - training batch 601, loss: 0.810, 19232/28000 datapoints
2025-03-06 21:51:35,535 - INFO - training batch 651, loss: 0.110, 20832/28000 datapoints
2025-03-06 21:51:35,684 - INFO - training batch 701, loss: 0.326, 22432/28000 datapoints
2025-03-06 21:51:35,832 - INFO - training batch 751, loss: 0.257, 24032/28000 datapoints
2025-03-06 21:51:35,983 - INFO - training batch 801, loss: 0.243, 25632/28000 datapoints
2025-03-06 21:51:36,131 - INFO - training batch 851, loss: 0.583, 27232/28000 datapoints
2025-03-06 21:51:36,204 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 21:51:36,252 - INFO - validation batch 51, loss: 1.389, 1632/6976 datapoints
2025-03-06 21:51:36,299 - INFO - validation batch 101, loss: 0.283, 3232/6976 datapoints
2025-03-06 21:51:36,346 - INFO - validation batch 151, loss: 0.489, 4832/6976 datapoints
2025-03-06 21:51:36,392 - INFO - validation batch 201, loss: 0.586, 6432/6976 datapoints
2025-03-06 21:51:36,408 - INFO - Epoch 151/800 done.
2025-03-06 21:51:36,408 - INFO - Final validation performance:
Loss: 0.577, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:51:36,409 - INFO - Beginning epoch 152/800
2025-03-06 21:51:36,413 - INFO - training batch 1, loss: 0.371, 32/28000 datapoints
2025-03-06 21:51:36,567 - INFO - training batch 51, loss: 0.255, 1632/28000 datapoints
2025-03-06 21:51:36,723 - INFO - training batch 101, loss: 0.190, 3232/28000 datapoints
2025-03-06 21:51:36,875 - INFO - training batch 151, loss: 0.645, 4832/28000 datapoints
2025-03-06 21:51:37,027 - INFO - training batch 201, loss: 0.181, 6432/28000 datapoints
2025-03-06 21:51:37,176 - INFO - training batch 251, loss: 0.350, 8032/28000 datapoints
2025-03-06 21:51:37,351 - INFO - training batch 301, loss: 0.708, 9632/28000 datapoints
2025-03-06 21:51:37,499 - INFO - training batch 351, loss: 0.360, 11232/28000 datapoints
2025-03-06 21:51:37,649 - INFO - training batch 401, loss: 0.683, 12832/28000 datapoints
2025-03-06 21:51:37,797 - INFO - training batch 451, loss: 0.484, 14432/28000 datapoints
2025-03-06 21:51:37,962 - INFO - training batch 501, loss: 0.196, 16032/28000 datapoints
2025-03-06 21:51:38,112 - INFO - training batch 551, loss: 0.511, 17632/28000 datapoints
2025-03-06 21:51:38,262 - INFO - training batch 601, loss: 0.803, 19232/28000 datapoints
2025-03-06 21:51:38,412 - INFO - training batch 651, loss: 0.109, 20832/28000 datapoints
2025-03-06 21:51:38,562 - INFO - training batch 701, loss: 0.324, 22432/28000 datapoints
2025-03-06 21:51:38,712 - INFO - training batch 751, loss: 0.256, 24032/28000 datapoints
2025-03-06 21:51:38,863 - INFO - training batch 801, loss: 0.242, 25632/28000 datapoints
2025-03-06 21:51:39,024 - INFO - training batch 851, loss: 0.579, 27232/28000 datapoints
2025-03-06 21:51:39,099 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 21:51:39,146 - INFO - validation batch 51, loss: 1.391, 1632/6976 datapoints
2025-03-06 21:51:39,193 - INFO - validation batch 101, loss: 0.283, 3232/6976 datapoints
2025-03-06 21:51:39,244 - INFO - validation batch 151, loss: 0.488, 4832/6976 datapoints
2025-03-06 21:51:39,293 - INFO - validation batch 201, loss: 0.585, 6432/6976 datapoints
2025-03-06 21:51:39,309 - INFO - Epoch 152/800 done.
2025-03-06 21:51:39,309 - INFO - Final validation performance:
Loss: 0.576, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:51:39,310 - INFO - Beginning epoch 153/800
2025-03-06 21:51:39,314 - INFO - training batch 1, loss: 0.369, 32/28000 datapoints
2025-03-06 21:51:39,463 - INFO - training batch 51, loss: 0.253, 1632/28000 datapoints
2025-03-06 21:51:39,616 - INFO - training batch 101, loss: 0.189, 3232/28000 datapoints
2025-03-06 21:51:39,765 - INFO - training batch 151, loss: 0.641, 4832/28000 datapoints
2025-03-06 21:51:39,916 - INFO - training batch 201, loss: 0.180, 6432/28000 datapoints
2025-03-06 21:51:40,065 - INFO - training batch 251, loss: 0.352, 8032/28000 datapoints
2025-03-06 21:51:40,214 - INFO - training batch 301, loss: 0.707, 9632/28000 datapoints
2025-03-06 21:51:40,362 - INFO - training batch 351, loss: 0.356, 11232/28000 datapoints
2025-03-06 21:51:40,511 - INFO - training batch 401, loss: 0.680, 12832/28000 datapoints
2025-03-06 21:51:40,661 - INFO - training batch 451, loss: 0.483, 14432/28000 datapoints
2025-03-06 21:51:40,814 - INFO - training batch 501, loss: 0.195, 16032/28000 datapoints
2025-03-06 21:51:40,969 - INFO - training batch 551, loss: 0.507, 17632/28000 datapoints
2025-03-06 21:51:41,121 - INFO - training batch 601, loss: 0.795, 19232/28000 datapoints
2025-03-06 21:51:41,276 - INFO - training batch 651, loss: 0.107, 20832/28000 datapoints
2025-03-06 21:51:41,424 - INFO - training batch 701, loss: 0.322, 22432/28000 datapoints
2025-03-06 21:51:41,574 - INFO - training batch 751, loss: 0.253, 24032/28000 datapoints
2025-03-06 21:51:41,725 - INFO - training batch 801, loss: 0.240, 25632/28000 datapoints
2025-03-06 21:51:41,875 - INFO - training batch 851, loss: 0.577, 27232/28000 datapoints
2025-03-06 21:51:41,948 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 21:51:41,995 - INFO - validation batch 51, loss: 1.393, 1632/6976 datapoints
2025-03-06 21:51:42,042 - INFO - validation batch 101, loss: 0.283, 3232/6976 datapoints
2025-03-06 21:51:42,092 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 21:51:42,140 - INFO - validation batch 201, loss: 0.583, 6432/6976 datapoints
2025-03-06 21:51:42,156 - INFO - Epoch 153/800 done.
2025-03-06 21:51:42,156 - INFO - Final validation performance:
Loss: 0.576, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:51:42,157 - INFO - Beginning epoch 154/800
2025-03-06 21:51:42,161 - INFO - training batch 1, loss: 0.368, 32/28000 datapoints
2025-03-06 21:51:42,314 - INFO - training batch 51, loss: 0.252, 1632/28000 datapoints
2025-03-06 21:51:42,465 - INFO - training batch 101, loss: 0.188, 3232/28000 datapoints
2025-03-06 21:51:42,620 - INFO - training batch 151, loss: 0.636, 4832/28000 datapoints
2025-03-06 21:51:42,776 - INFO - training batch 201, loss: 0.179, 6432/28000 datapoints
2025-03-06 21:51:42,926 - INFO - training batch 251, loss: 0.352, 8032/28000 datapoints
2025-03-06 21:51:43,078 - INFO - training batch 301, loss: 0.706, 9632/28000 datapoints
2025-03-06 21:51:43,226 - INFO - training batch 351, loss: 0.352, 11232/28000 datapoints
2025-03-06 21:51:43,374 - INFO - training batch 401, loss: 0.678, 12832/28000 datapoints
2025-03-06 21:51:43,523 - INFO - training batch 451, loss: 0.482, 14432/28000 datapoints
2025-03-06 21:51:43,674 - INFO - training batch 501, loss: 0.194, 16032/28000 datapoints
2025-03-06 21:51:43,824 - INFO - training batch 551, loss: 0.503, 17632/28000 datapoints
2025-03-06 21:51:43,978 - INFO - training batch 601, loss: 0.790, 19232/28000 datapoints
2025-03-06 21:51:44,128 - INFO - training batch 651, loss: 0.106, 20832/28000 datapoints
2025-03-06 21:51:44,280 - INFO - training batch 701, loss: 0.320, 22432/28000 datapoints
2025-03-06 21:51:44,428 - INFO - training batch 751, loss: 0.251, 24032/28000 datapoints
2025-03-06 21:51:44,578 - INFO - training batch 801, loss: 0.239, 25632/28000 datapoints
2025-03-06 21:51:44,728 - INFO - training batch 851, loss: 0.573, 27232/28000 datapoints
2025-03-06 21:51:44,800 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 21:51:44,850 - INFO - validation batch 51, loss: 1.395, 1632/6976 datapoints
2025-03-06 21:51:44,896 - INFO - validation batch 101, loss: 0.283, 3232/6976 datapoints
2025-03-06 21:51:44,945 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 21:51:44,992 - INFO - validation batch 201, loss: 0.581, 6432/6976 datapoints
2025-03-06 21:51:45,010 - INFO - Epoch 154/800 done.
2025-03-06 21:51:45,010 - INFO - Final validation performance:
Loss: 0.576, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:51:45,011 - INFO - Beginning epoch 155/800
2025-03-06 21:51:45,015 - INFO - training batch 1, loss: 0.367, 32/28000 datapoints
2025-03-06 21:51:45,174 - INFO - training batch 51, loss: 0.252, 1632/28000 datapoints
2025-03-06 21:51:45,326 - INFO - training batch 101, loss: 0.187, 3232/28000 datapoints
2025-03-06 21:51:45,474 - INFO - training batch 151, loss: 0.632, 4832/28000 datapoints
2025-03-06 21:51:45,624 - INFO - training batch 201, loss: 0.177, 6432/28000 datapoints
2025-03-06 21:51:45,773 - INFO - training batch 251, loss: 0.353, 8032/28000 datapoints
2025-03-06 21:51:45,930 - INFO - training batch 301, loss: 0.705, 9632/28000 datapoints
2025-03-06 21:51:46,079 - INFO - training batch 351, loss: 0.349, 11232/28000 datapoints
2025-03-06 21:51:46,232 - INFO - training batch 401, loss: 0.676, 12832/28000 datapoints
2025-03-06 21:51:46,382 - INFO - training batch 451, loss: 0.481, 14432/28000 datapoints
2025-03-06 21:51:46,534 - INFO - training batch 501, loss: 0.192, 16032/28000 datapoints
2025-03-06 21:51:46,704 - INFO - training batch 551, loss: 0.498, 17632/28000 datapoints
2025-03-06 21:51:46,863 - INFO - training batch 601, loss: 0.782, 19232/28000 datapoints
2025-03-06 21:51:47,020 - INFO - training batch 651, loss: 0.104, 20832/28000 datapoints
2025-03-06 21:51:47,174 - INFO - training batch 701, loss: 0.318, 22432/28000 datapoints
2025-03-06 21:51:47,331 - INFO - training batch 751, loss: 0.249, 24032/28000 datapoints
2025-03-06 21:51:47,500 - INFO - training batch 801, loss: 0.237, 25632/28000 datapoints
2025-03-06 21:51:47,652 - INFO - training batch 851, loss: 0.570, 27232/28000 datapoints
2025-03-06 21:51:47,727 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 21:51:47,779 - INFO - validation batch 51, loss: 1.397, 1632/6976 datapoints
2025-03-06 21:51:47,832 - INFO - validation batch 101, loss: 0.283, 3232/6976 datapoints
2025-03-06 21:51:47,885 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 21:51:47,937 - INFO - validation batch 201, loss: 0.579, 6432/6976 datapoints
2025-03-06 21:51:47,954 - INFO - Epoch 155/800 done.
2025-03-06 21:51:47,954 - INFO - Final validation performance:
Loss: 0.576, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:51:47,954 - INFO - Beginning epoch 156/800
2025-03-06 21:51:47,958 - INFO - training batch 1, loss: 0.366, 32/28000 datapoints
2025-03-06 21:51:48,111 - INFO - training batch 51, loss: 0.251, 1632/28000 datapoints
2025-03-06 21:51:48,262 - INFO - training batch 101, loss: 0.186, 3232/28000 datapoints
2025-03-06 21:51:48,412 - INFO - training batch 151, loss: 0.627, 4832/28000 datapoints
2025-03-06 21:51:48,559 - INFO - training batch 201, loss: 0.175, 6432/28000 datapoints
2025-03-06 21:51:48,709 - INFO - training batch 251, loss: 0.353, 8032/28000 datapoints
2025-03-06 21:51:48,858 - INFO - training batch 301, loss: 0.705, 9632/28000 datapoints
2025-03-06 21:51:49,010 - INFO - training batch 351, loss: 0.345, 11232/28000 datapoints
2025-03-06 21:51:49,161 - INFO - training batch 401, loss: 0.673, 12832/28000 datapoints
2025-03-06 21:51:49,313 - INFO - training batch 451, loss: 0.480, 14432/28000 datapoints
2025-03-06 21:51:49,466 - INFO - training batch 501, loss: 0.191, 16032/28000 datapoints
2025-03-06 21:51:49,615 - INFO - training batch 551, loss: 0.495, 17632/28000 datapoints
2025-03-06 21:51:49,766 - INFO - training batch 601, loss: 0.775, 19232/28000 datapoints
2025-03-06 21:51:49,925 - INFO - training batch 651, loss: 0.103, 20832/28000 datapoints
2025-03-06 21:51:50,074 - INFO - training batch 701, loss: 0.316, 22432/28000 datapoints
2025-03-06 21:51:50,231 - INFO - training batch 751, loss: 0.247, 24032/28000 datapoints
2025-03-06 21:51:50,380 - INFO - training batch 801, loss: 0.235, 25632/28000 datapoints
2025-03-06 21:51:50,530 - INFO - training batch 851, loss: 0.567, 27232/28000 datapoints
2025-03-06 21:51:50,603 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 21:51:50,650 - INFO - validation batch 51, loss: 1.400, 1632/6976 datapoints
2025-03-06 21:51:50,699 - INFO - validation batch 101, loss: 0.284, 3232/6976 datapoints
2025-03-06 21:51:50,747 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 21:51:50,795 - INFO - validation batch 201, loss: 0.576, 6432/6976 datapoints
2025-03-06 21:51:50,811 - INFO - Epoch 156/800 done.
2025-03-06 21:51:50,812 - INFO - Final validation performance:
Loss: 0.576, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:51:50,812 - INFO - Beginning epoch 157/800
2025-03-06 21:51:50,816 - INFO - training batch 1, loss: 0.364, 32/28000 datapoints
2025-03-06 21:51:50,973 - INFO - training batch 51, loss: 0.250, 1632/28000 datapoints
2025-03-06 21:51:51,121 - INFO - training batch 101, loss: 0.185, 3232/28000 datapoints
2025-03-06 21:51:51,274 - INFO - training batch 151, loss: 0.622, 4832/28000 datapoints
2025-03-06 21:51:51,422 - INFO - training batch 201, loss: 0.174, 6432/28000 datapoints
2025-03-06 21:51:51,571 - INFO - training batch 251, loss: 0.354, 8032/28000 datapoints
2025-03-06 21:51:51,723 - INFO - training batch 301, loss: 0.705, 9632/28000 datapoints
2025-03-06 21:51:51,873 - INFO - training batch 351, loss: 0.341, 11232/28000 datapoints
2025-03-06 21:51:52,020 - INFO - training batch 401, loss: 0.671, 12832/28000 datapoints
2025-03-06 21:51:52,169 - INFO - training batch 451, loss: 0.480, 14432/28000 datapoints
2025-03-06 21:51:52,319 - INFO - training batch 501, loss: 0.189, 16032/28000 datapoints
2025-03-06 21:51:52,471 - INFO - training batch 551, loss: 0.489, 17632/28000 datapoints
2025-03-06 21:51:52,621 - INFO - training batch 601, loss: 0.768, 19232/28000 datapoints
2025-03-06 21:51:52,774 - INFO - training batch 651, loss: 0.102, 20832/28000 datapoints
2025-03-06 21:51:52,925 - INFO - training batch 701, loss: 0.315, 22432/28000 datapoints
2025-03-06 21:51:53,078 - INFO - training batch 751, loss: 0.245, 24032/28000 datapoints
2025-03-06 21:51:53,228 - INFO - training batch 801, loss: 0.233, 25632/28000 datapoints
2025-03-06 21:51:53,378 - INFO - training batch 851, loss: 0.563, 27232/28000 datapoints
2025-03-06 21:51:53,452 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 21:51:53,499 - INFO - validation batch 51, loss: 1.404, 1632/6976 datapoints
2025-03-06 21:51:53,545 - INFO - validation batch 101, loss: 0.285, 3232/6976 datapoints
2025-03-06 21:51:53,593 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 21:51:53,640 - INFO - validation batch 201, loss: 0.574, 6432/6976 datapoints
2025-03-06 21:51:53,657 - INFO - Epoch 157/800 done.
2025-03-06 21:51:53,657 - INFO - Final validation performance:
Loss: 0.576, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:51:53,658 - INFO - Beginning epoch 158/800
2025-03-06 21:51:53,662 - INFO - training batch 1, loss: 0.363, 32/28000 datapoints
2025-03-06 21:51:53,820 - INFO - training batch 51, loss: 0.251, 1632/28000 datapoints
2025-03-06 21:51:53,972 - INFO - training batch 101, loss: 0.184, 3232/28000 datapoints
2025-03-06 21:51:54,123 - INFO - training batch 151, loss: 0.618, 4832/28000 datapoints
2025-03-06 21:51:54,275 - INFO - training batch 201, loss: 0.172, 6432/28000 datapoints
2025-03-06 21:51:54,424 - INFO - training batch 251, loss: 0.355, 8032/28000 datapoints
2025-03-06 21:51:54,572 - INFO - training batch 301, loss: 0.705, 9632/28000 datapoints
2025-03-06 21:51:54,724 - INFO - training batch 351, loss: 0.338, 11232/28000 datapoints
2025-03-06 21:51:54,874 - INFO - training batch 401, loss: 0.669, 12832/28000 datapoints
2025-03-06 21:51:55,028 - INFO - training batch 451, loss: 0.479, 14432/28000 datapoints
2025-03-06 21:51:55,182 - INFO - training batch 501, loss: 0.188, 16032/28000 datapoints
2025-03-06 21:51:55,333 - INFO - training batch 551, loss: 0.485, 17632/28000 datapoints
2025-03-06 21:51:55,482 - INFO - training batch 601, loss: 0.759, 19232/28000 datapoints
2025-03-06 21:51:55,631 - INFO - training batch 651, loss: 0.100, 20832/28000 datapoints
2025-03-06 21:51:55,782 - INFO - training batch 701, loss: 0.313, 22432/28000 datapoints
2025-03-06 21:51:55,934 - INFO - training batch 751, loss: 0.244, 24032/28000 datapoints
2025-03-06 21:51:56,082 - INFO - training batch 801, loss: 0.232, 25632/28000 datapoints
2025-03-06 21:51:56,231 - INFO - training batch 851, loss: 0.559, 27232/28000 datapoints
2025-03-06 21:51:56,304 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 21:51:56,351 - INFO - validation batch 51, loss: 1.407, 1632/6976 datapoints
2025-03-06 21:51:56,401 - INFO - validation batch 101, loss: 0.285, 3232/6976 datapoints
2025-03-06 21:51:56,449 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 21:51:56,496 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:51:56,512 - INFO - Epoch 158/800 done.
2025-03-06 21:51:56,513 - INFO - Final validation performance:
Loss: 0.576, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:51:56,513 - INFO - Beginning epoch 159/800
2025-03-06 21:51:56,517 - INFO - training batch 1, loss: 0.362, 32/28000 datapoints
2025-03-06 21:51:56,671 - INFO - training batch 51, loss: 0.249, 1632/28000 datapoints
2025-03-06 21:51:56,826 - INFO - training batch 101, loss: 0.182, 3232/28000 datapoints
2025-03-06 21:51:56,978 - INFO - training batch 151, loss: 0.612, 4832/28000 datapoints
2025-03-06 21:51:57,131 - INFO - training batch 201, loss: 0.171, 6432/28000 datapoints
2025-03-06 21:51:57,281 - INFO - training batch 251, loss: 0.355, 8032/28000 datapoints
2025-03-06 21:51:57,437 - INFO - training batch 301, loss: 0.704, 9632/28000 datapoints
2025-03-06 21:51:57,606 - INFO - training batch 351, loss: 0.334, 11232/28000 datapoints
2025-03-06 21:51:57,756 - INFO - training batch 401, loss: 0.666, 12832/28000 datapoints
2025-03-06 21:51:57,907 - INFO - training batch 451, loss: 0.479, 14432/28000 datapoints
2025-03-06 21:51:58,057 - INFO - training batch 501, loss: 0.187, 16032/28000 datapoints
2025-03-06 21:51:58,206 - INFO - training batch 551, loss: 0.481, 17632/28000 datapoints
2025-03-06 21:51:58,355 - INFO - training batch 601, loss: 0.753, 19232/28000 datapoints
2025-03-06 21:51:58,505 - INFO - training batch 651, loss: 0.099, 20832/28000 datapoints
2025-03-06 21:51:58,653 - INFO - training batch 701, loss: 0.311, 22432/28000 datapoints
2025-03-06 21:51:58,804 - INFO - training batch 751, loss: 0.242, 24032/28000 datapoints
2025-03-06 21:51:58,954 - INFO - training batch 801, loss: 0.231, 25632/28000 datapoints
2025-03-06 21:51:59,105 - INFO - training batch 851, loss: 0.556, 27232/28000 datapoints
2025-03-06 21:51:59,178 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 21:51:59,226 - INFO - validation batch 51, loss: 1.409, 1632/6976 datapoints
2025-03-06 21:51:59,280 - INFO - validation batch 101, loss: 0.285, 3232/6976 datapoints
2025-03-06 21:51:59,328 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 21:51:59,375 - INFO - validation batch 201, loss: 0.569, 6432/6976 datapoints
2025-03-06 21:51:59,391 - INFO - Epoch 159/800 done.
2025-03-06 21:51:59,391 - INFO - Final validation performance:
Loss: 0.576, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:51:59,392 - INFO - Beginning epoch 160/800
2025-03-06 21:51:59,396 - INFO - training batch 1, loss: 0.361, 32/28000 datapoints
2025-03-06 21:51:59,546 - INFO - training batch 51, loss: 0.249, 1632/28000 datapoints
2025-03-06 21:51:59,696 - INFO - training batch 101, loss: 0.182, 3232/28000 datapoints
2025-03-06 21:51:59,851 - INFO - training batch 151, loss: 0.608, 4832/28000 datapoints
2025-03-06 21:52:00,000 - INFO - training batch 201, loss: 0.170, 6432/28000 datapoints
2025-03-06 21:52:00,149 - INFO - training batch 251, loss: 0.356, 8032/28000 datapoints
2025-03-06 21:52:00,300 - INFO - training batch 301, loss: 0.703, 9632/28000 datapoints
2025-03-06 21:52:00,448 - INFO - training batch 351, loss: 0.330, 11232/28000 datapoints
2025-03-06 21:52:00,597 - INFO - training batch 401, loss: 0.663, 12832/28000 datapoints
2025-03-06 21:52:00,746 - INFO - training batch 451, loss: 0.477, 14432/28000 datapoints
2025-03-06 21:52:00,906 - INFO - training batch 501, loss: 0.186, 16032/28000 datapoints
2025-03-06 21:52:01,058 - INFO - training batch 551, loss: 0.477, 17632/28000 datapoints
2025-03-06 21:52:01,217 - INFO - training batch 601, loss: 0.746, 19232/28000 datapoints
2025-03-06 21:52:01,367 - INFO - training batch 651, loss: 0.098, 20832/28000 datapoints
2025-03-06 21:52:01,516 - INFO - training batch 701, loss: 0.309, 22432/28000 datapoints
2025-03-06 21:52:01,664 - INFO - training batch 751, loss: 0.240, 24032/28000 datapoints
2025-03-06 21:52:01,815 - INFO - training batch 801, loss: 0.229, 25632/28000 datapoints
2025-03-06 21:52:01,966 - INFO - training batch 851, loss: 0.552, 27232/28000 datapoints
2025-03-06 21:52:02,039 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 21:52:02,086 - INFO - validation batch 51, loss: 1.412, 1632/6976 datapoints
2025-03-06 21:52:02,133 - INFO - validation batch 101, loss: 0.286, 3232/6976 datapoints
2025-03-06 21:52:02,179 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 21:52:02,227 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:52:02,244 - INFO - Epoch 160/800 done.
2025-03-06 21:52:02,244 - INFO - Final validation performance:
Loss: 0.577, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:52:02,244 - INFO - Beginning epoch 161/800
2025-03-06 21:52:02,249 - INFO - training batch 1, loss: 0.360, 32/28000 datapoints
2025-03-06 21:52:02,402 - INFO - training batch 51, loss: 0.249, 1632/28000 datapoints
2025-03-06 21:52:02,550 - INFO - training batch 101, loss: 0.181, 3232/28000 datapoints
2025-03-06 21:52:02,698 - INFO - training batch 151, loss: 0.602, 4832/28000 datapoints
2025-03-06 21:52:02,853 - INFO - training batch 201, loss: 0.168, 6432/28000 datapoints
2025-03-06 21:52:03,000 - INFO - training batch 251, loss: 0.357, 8032/28000 datapoints
2025-03-06 21:52:03,151 - INFO - training batch 301, loss: 0.702, 9632/28000 datapoints
2025-03-06 21:52:03,303 - INFO - training batch 351, loss: 0.327, 11232/28000 datapoints
2025-03-06 21:52:03,450 - INFO - training batch 401, loss: 0.661, 12832/28000 datapoints
2025-03-06 21:52:03,599 - INFO - training batch 451, loss: 0.476, 14432/28000 datapoints
2025-03-06 21:52:03,748 - INFO - training batch 501, loss: 0.185, 16032/28000 datapoints
2025-03-06 21:52:03,900 - INFO - training batch 551, loss: 0.473, 17632/28000 datapoints
2025-03-06 21:52:04,049 - INFO - training batch 601, loss: 0.739, 19232/28000 datapoints
2025-03-06 21:52:04,198 - INFO - training batch 651, loss: 0.096, 20832/28000 datapoints
2025-03-06 21:52:04,348 - INFO - training batch 701, loss: 0.308, 22432/28000 datapoints
2025-03-06 21:52:04,495 - INFO - training batch 751, loss: 0.239, 24032/28000 datapoints
2025-03-06 21:52:04,644 - INFO - training batch 801, loss: 0.228, 25632/28000 datapoints
2025-03-06 21:52:04,792 - INFO - training batch 851, loss: 0.549, 27232/28000 datapoints
2025-03-06 21:52:04,870 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 21:52:04,917 - INFO - validation batch 51, loss: 1.416, 1632/6976 datapoints
2025-03-06 21:52:04,964 - INFO - validation batch 101, loss: 0.286, 3232/6976 datapoints
2025-03-06 21:52:05,013 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 21:52:05,063 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:52:05,083 - INFO - Epoch 161/800 done.
2025-03-06 21:52:05,083 - INFO - Final validation performance:
Loss: 0.577, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:52:05,084 - INFO - Beginning epoch 162/800
2025-03-06 21:52:05,089 - INFO - training batch 1, loss: 0.359, 32/28000 datapoints
2025-03-06 21:52:05,241 - INFO - training batch 51, loss: 0.248, 1632/28000 datapoints
2025-03-06 21:52:05,416 - INFO - training batch 101, loss: 0.180, 3232/28000 datapoints
2025-03-06 21:52:05,566 - INFO - training batch 151, loss: 0.598, 4832/28000 datapoints
2025-03-06 21:52:05,716 - INFO - training batch 201, loss: 0.167, 6432/28000 datapoints
2025-03-06 21:52:05,869 - INFO - training batch 251, loss: 0.358, 8032/28000 datapoints
2025-03-06 21:52:06,035 - INFO - training batch 301, loss: 0.702, 9632/28000 datapoints
2025-03-06 21:52:06,195 - INFO - training batch 351, loss: 0.322, 11232/28000 datapoints
2025-03-06 21:52:06,359 - INFO - training batch 401, loss: 0.659, 12832/28000 datapoints
2025-03-06 21:52:06,515 - INFO - training batch 451, loss: 0.475, 14432/28000 datapoints
2025-03-06 21:52:06,670 - INFO - training batch 501, loss: 0.185, 16032/28000 datapoints
2025-03-06 21:52:06,827 - INFO - training batch 551, loss: 0.469, 17632/28000 datapoints
2025-03-06 21:52:06,982 - INFO - training batch 601, loss: 0.733, 19232/28000 datapoints
2025-03-06 21:52:07,139 - INFO - training batch 651, loss: 0.095, 20832/28000 datapoints
2025-03-06 21:52:07,301 - INFO - training batch 701, loss: 0.306, 22432/28000 datapoints
2025-03-06 21:52:07,453 - INFO - training batch 751, loss: 0.237, 24032/28000 datapoints
2025-03-06 21:52:07,627 - INFO - training batch 801, loss: 0.226, 25632/28000 datapoints
2025-03-06 21:52:07,780 - INFO - training batch 851, loss: 0.544, 27232/28000 datapoints
2025-03-06 21:52:07,861 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 21:52:07,912 - INFO - validation batch 51, loss: 1.418, 1632/6976 datapoints
2025-03-06 21:52:07,963 - INFO - validation batch 101, loss: 0.287, 3232/6976 datapoints
2025-03-06 21:52:08,016 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 21:52:08,069 - INFO - validation batch 201, loss: 0.564, 6432/6976 datapoints
2025-03-06 21:52:08,089 - INFO - Epoch 162/800 done.
2025-03-06 21:52:08,089 - INFO - Final validation performance:
Loss: 0.577, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:52:08,090 - INFO - Beginning epoch 163/800
2025-03-06 21:52:08,094 - INFO - training batch 1, loss: 0.357, 32/28000 datapoints
2025-03-06 21:52:08,246 - INFO - training batch 51, loss: 0.248, 1632/28000 datapoints
2025-03-06 21:52:08,399 - INFO - training batch 101, loss: 0.179, 3232/28000 datapoints
2025-03-06 21:52:08,547 - INFO - training batch 151, loss: 0.593, 4832/28000 datapoints
2025-03-06 21:52:08,695 - INFO - training batch 201, loss: 0.167, 6432/28000 datapoints
2025-03-06 21:52:08,844 - INFO - training batch 251, loss: 0.358, 8032/28000 datapoints
2025-03-06 21:52:08,994 - INFO - training batch 301, loss: 0.701, 9632/28000 datapoints
2025-03-06 21:52:09,146 - INFO - training batch 351, loss: 0.319, 11232/28000 datapoints
2025-03-06 21:52:09,318 - INFO - training batch 401, loss: 0.656, 12832/28000 datapoints
2025-03-06 21:52:09,467 - INFO - training batch 451, loss: 0.473, 14432/28000 datapoints
2025-03-06 21:52:09,614 - INFO - training batch 501, loss: 0.183, 16032/28000 datapoints
2025-03-06 21:52:09,767 - INFO - training batch 551, loss: 0.464, 17632/28000 datapoints
2025-03-06 21:52:09,921 - INFO - training batch 601, loss: 0.725, 19232/28000 datapoints
2025-03-06 21:52:10,069 - INFO - training batch 651, loss: 0.094, 20832/28000 datapoints
2025-03-06 21:52:10,228 - INFO - training batch 701, loss: 0.304, 22432/28000 datapoints
2025-03-06 21:52:10,381 - INFO - training batch 751, loss: 0.236, 24032/28000 datapoints
2025-03-06 21:52:10,535 - INFO - training batch 801, loss: 0.225, 25632/28000 datapoints
2025-03-06 21:52:10,688 - INFO - training batch 851, loss: 0.540, 27232/28000 datapoints
2025-03-06 21:52:10,767 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 21:52:10,818 - INFO - validation batch 51, loss: 1.421, 1632/6976 datapoints
2025-03-06 21:52:10,871 - INFO - validation batch 101, loss: 0.287, 3232/6976 datapoints
2025-03-06 21:52:10,925 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 21:52:10,977 - INFO - validation batch 201, loss: 0.563, 6432/6976 datapoints
2025-03-06 21:52:10,997 - INFO - Epoch 163/800 done.
2025-03-06 21:52:10,998 - INFO - Final validation performance:
Loss: 0.578, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:52:10,998 - INFO - Beginning epoch 164/800
2025-03-06 21:52:11,002 - INFO - training batch 1, loss: 0.356, 32/28000 datapoints
2025-03-06 21:52:11,158 - INFO - training batch 51, loss: 0.248, 1632/28000 datapoints
2025-03-06 21:52:11,320 - INFO - training batch 101, loss: 0.178, 3232/28000 datapoints
2025-03-06 21:52:11,480 - INFO - training batch 151, loss: 0.588, 4832/28000 datapoints
2025-03-06 21:52:11,634 - INFO - training batch 201, loss: 0.165, 6432/28000 datapoints
2025-03-06 21:52:11,792 - INFO - training batch 251, loss: 0.358, 8032/28000 datapoints
2025-03-06 21:52:11,951 - INFO - training batch 301, loss: 0.700, 9632/28000 datapoints
2025-03-06 21:52:12,104 - INFO - training batch 351, loss: 0.316, 11232/28000 datapoints
2025-03-06 21:52:12,259 - INFO - training batch 401, loss: 0.654, 12832/28000 datapoints
2025-03-06 21:52:12,414 - INFO - training batch 451, loss: 0.472, 14432/28000 datapoints
2025-03-06 21:52:12,568 - INFO - training batch 501, loss: 0.183, 16032/28000 datapoints
2025-03-06 21:52:12,722 - INFO - training batch 551, loss: 0.460, 17632/28000 datapoints
2025-03-06 21:52:12,893 - INFO - training batch 601, loss: 0.717, 19232/28000 datapoints
2025-03-06 21:52:13,053 - INFO - training batch 651, loss: 0.092, 20832/28000 datapoints
2025-03-06 21:52:13,207 - INFO - training batch 701, loss: 0.302, 22432/28000 datapoints
2025-03-06 21:52:13,360 - INFO - training batch 751, loss: 0.233, 24032/28000 datapoints
2025-03-06 21:52:13,517 - INFO - training batch 801, loss: 0.224, 25632/28000 datapoints
2025-03-06 21:52:13,668 - INFO - training batch 851, loss: 0.535, 27232/28000 datapoints
2025-03-06 21:52:13,746 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 21:52:13,797 - INFO - validation batch 51, loss: 1.424, 1632/6976 datapoints
2025-03-06 21:52:13,855 - INFO - validation batch 101, loss: 0.288, 3232/6976 datapoints
2025-03-06 21:52:13,921 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 21:52:13,994 - INFO - validation batch 201, loss: 0.562, 6432/6976 datapoints
2025-03-06 21:52:14,016 - INFO - Epoch 164/800 done.
2025-03-06 21:52:14,017 - INFO - Final validation performance:
Loss: 0.578, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:52:14,017 - INFO - Beginning epoch 165/800
2025-03-06 21:52:14,023 - INFO - training batch 1, loss: 0.355, 32/28000 datapoints
2025-03-06 21:52:14,179 - INFO - training batch 51, loss: 0.247, 1632/28000 datapoints
2025-03-06 21:52:14,333 - INFO - training batch 101, loss: 0.176, 3232/28000 datapoints
2025-03-06 21:52:14,489 - INFO - training batch 151, loss: 0.583, 4832/28000 datapoints
2025-03-06 21:52:14,641 - INFO - training batch 201, loss: 0.164, 6432/28000 datapoints
2025-03-06 21:52:14,793 - INFO - training batch 251, loss: 0.359, 8032/28000 datapoints
2025-03-06 21:52:14,950 - INFO - training batch 301, loss: 0.700, 9632/28000 datapoints
2025-03-06 21:52:15,106 - INFO - training batch 351, loss: 0.313, 11232/28000 datapoints
2025-03-06 21:52:15,263 - INFO - training batch 401, loss: 0.653, 12832/28000 datapoints
2025-03-06 21:52:15,416 - INFO - training batch 451, loss: 0.472, 14432/28000 datapoints
2025-03-06 21:52:15,570 - INFO - training batch 501, loss: 0.181, 16032/28000 datapoints
2025-03-06 21:52:15,724 - INFO - training batch 551, loss: 0.455, 17632/28000 datapoints
2025-03-06 21:52:15,880 - INFO - training batch 601, loss: 0.708, 19232/28000 datapoints
2025-03-06 21:52:16,035 - INFO - training batch 651, loss: 0.091, 20832/28000 datapoints
2025-03-06 21:52:16,186 - INFO - training batch 701, loss: 0.301, 22432/28000 datapoints
2025-03-06 21:52:16,338 - INFO - training batch 751, loss: 0.232, 24032/28000 datapoints
2025-03-06 21:52:16,490 - INFO - training batch 801, loss: 0.224, 25632/28000 datapoints
2025-03-06 21:52:16,644 - INFO - training batch 851, loss: 0.532, 27232/28000 datapoints
2025-03-06 21:52:16,721 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 21:52:16,774 - INFO - validation batch 51, loss: 1.428, 1632/6976 datapoints
2025-03-06 21:52:16,827 - INFO - validation batch 101, loss: 0.288, 3232/6976 datapoints
2025-03-06 21:52:16,883 - INFO - validation batch 151, loss: 0.488, 4832/6976 datapoints
2025-03-06 21:52:16,935 - INFO - validation batch 201, loss: 0.562, 6432/6976 datapoints
2025-03-06 21:52:16,954 - INFO - Epoch 165/800 done.
2025-03-06 21:52:16,955 - INFO - Final validation performance:
Loss: 0.579, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:52:16,955 - INFO - Beginning epoch 166/800
2025-03-06 21:52:16,960 - INFO - training batch 1, loss: 0.354, 32/28000 datapoints
2025-03-06 21:52:17,117 - INFO - training batch 51, loss: 0.247, 1632/28000 datapoints
2025-03-06 21:52:17,269 - INFO - training batch 101, loss: 0.175, 3232/28000 datapoints
2025-03-06 21:52:17,435 - INFO - training batch 151, loss: 0.579, 4832/28000 datapoints
2025-03-06 21:52:17,589 - INFO - training batch 201, loss: 0.163, 6432/28000 datapoints
2025-03-06 21:52:17,774 - INFO - training batch 251, loss: 0.359, 8032/28000 datapoints
2025-03-06 21:52:17,933 - INFO - training batch 301, loss: 0.699, 9632/28000 datapoints
2025-03-06 21:52:18,088 - INFO - training batch 351, loss: 0.310, 11232/28000 datapoints
2025-03-06 21:52:18,244 - INFO - training batch 401, loss: 0.649, 12832/28000 datapoints
2025-03-06 21:52:18,397 - INFO - training batch 451, loss: 0.470, 14432/28000 datapoints
2025-03-06 21:52:18,549 - INFO - training batch 501, loss: 0.180, 16032/28000 datapoints
2025-03-06 21:52:18,702 - INFO - training batch 551, loss: 0.452, 17632/28000 datapoints
2025-03-06 21:52:18,858 - INFO - training batch 601, loss: 0.702, 19232/28000 datapoints
2025-03-06 21:52:19,011 - INFO - training batch 651, loss: 0.090, 20832/28000 datapoints
2025-03-06 21:52:19,165 - INFO - training batch 701, loss: 0.299, 22432/28000 datapoints
2025-03-06 21:52:19,316 - INFO - training batch 751, loss: 0.231, 24032/28000 datapoints
2025-03-06 21:52:19,471 - INFO - training batch 801, loss: 0.221, 25632/28000 datapoints
2025-03-06 21:52:19,628 - INFO - training batch 851, loss: 0.526, 27232/28000 datapoints
2025-03-06 21:52:19,705 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 21:52:19,757 - INFO - validation batch 51, loss: 1.429, 1632/6976 datapoints
2025-03-06 21:52:19,809 - INFO - validation batch 101, loss: 0.288, 3232/6976 datapoints
2025-03-06 21:52:19,863 - INFO - validation batch 151, loss: 0.488, 4832/6976 datapoints
2025-03-06 21:52:19,916 - INFO - validation batch 201, loss: 0.561, 6432/6976 datapoints
2025-03-06 21:52:19,935 - INFO - Epoch 166/800 done.
2025-03-06 21:52:19,935 - INFO - Final validation performance:
Loss: 0.579, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:52:19,935 - INFO - Beginning epoch 167/800
2025-03-06 21:52:19,940 - INFO - training batch 1, loss: 0.353, 32/28000 datapoints
2025-03-06 21:52:20,095 - INFO - training batch 51, loss: 0.247, 1632/28000 datapoints
2025-03-06 21:52:20,244 - INFO - training batch 101, loss: 0.174, 3232/28000 datapoints
2025-03-06 21:52:20,393 - INFO - training batch 151, loss: 0.574, 4832/28000 datapoints
2025-03-06 21:52:20,543 - INFO - training batch 201, loss: 0.162, 6432/28000 datapoints
2025-03-06 21:52:20,694 - INFO - training batch 251, loss: 0.359, 8032/28000 datapoints
2025-03-06 21:52:20,846 - INFO - training batch 301, loss: 0.699, 9632/28000 datapoints
2025-03-06 21:52:20,994 - INFO - training batch 351, loss: 0.307, 11232/28000 datapoints
2025-03-06 21:52:21,147 - INFO - training batch 401, loss: 0.647, 12832/28000 datapoints
2025-03-06 21:52:21,296 - INFO - training batch 451, loss: 0.470, 14432/28000 datapoints
2025-03-06 21:52:21,444 - INFO - training batch 501, loss: 0.179, 16032/28000 datapoints
2025-03-06 21:52:21,594 - INFO - training batch 551, loss: 0.447, 17632/28000 datapoints
2025-03-06 21:52:21,744 - INFO - training batch 601, loss: 0.693, 19232/28000 datapoints
2025-03-06 21:52:21,900 - INFO - training batch 651, loss: 0.089, 20832/28000 datapoints
2025-03-06 21:52:22,050 - INFO - training batch 701, loss: 0.297, 22432/28000 datapoints
2025-03-06 21:52:22,200 - INFO - training batch 751, loss: 0.229, 24032/28000 datapoints
2025-03-06 21:52:22,349 - INFO - training batch 801, loss: 0.220, 25632/28000 datapoints
2025-03-06 21:52:22,499 - INFO - training batch 851, loss: 0.522, 27232/28000 datapoints
2025-03-06 21:52:22,576 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 21:52:22,623 - INFO - validation batch 51, loss: 1.432, 1632/6976 datapoints
2025-03-06 21:52:22,670 - INFO - validation batch 101, loss: 0.289, 3232/6976 datapoints
2025-03-06 21:52:22,717 - INFO - validation batch 151, loss: 0.488, 4832/6976 datapoints
2025-03-06 21:52:22,764 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 21:52:22,785 - INFO - Epoch 167/800 done.
2025-03-06 21:52:22,785 - INFO - Final validation performance:
Loss: 0.579, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:52:22,785 - INFO - Beginning epoch 168/800
2025-03-06 21:52:22,789 - INFO - training batch 1, loss: 0.352, 32/28000 datapoints
2025-03-06 21:52:22,944 - INFO - training batch 51, loss: 0.246, 1632/28000 datapoints
2025-03-06 21:52:23,095 - INFO - training batch 101, loss: 0.173, 3232/28000 datapoints
2025-03-06 21:52:23,246 - INFO - training batch 151, loss: 0.569, 4832/28000 datapoints
2025-03-06 21:52:23,410 - INFO - training batch 201, loss: 0.161, 6432/28000 datapoints
2025-03-06 21:52:23,561 - INFO - training batch 251, loss: 0.359, 8032/28000 datapoints
2025-03-06 21:52:23,709 - INFO - training batch 301, loss: 0.698, 9632/28000 datapoints
2025-03-06 21:52:23,873 - INFO - training batch 351, loss: 0.304, 11232/28000 datapoints
2025-03-06 21:52:24,029 - INFO - training batch 401, loss: 0.645, 12832/28000 datapoints
2025-03-06 21:52:24,179 - INFO - training batch 451, loss: 0.470, 14432/28000 datapoints
2025-03-06 21:52:24,331 - INFO - training batch 501, loss: 0.179, 16032/28000 datapoints
2025-03-06 21:52:24,481 - INFO - training batch 551, loss: 0.443, 17632/28000 datapoints
2025-03-06 21:52:24,631 - INFO - training batch 601, loss: 0.687, 19232/28000 datapoints
2025-03-06 21:52:24,782 - INFO - training batch 651, loss: 0.087, 20832/28000 datapoints
2025-03-06 21:52:24,936 - INFO - training batch 701, loss: 0.296, 22432/28000 datapoints
2025-03-06 21:52:25,085 - INFO - training batch 751, loss: 0.228, 24032/28000 datapoints
2025-03-06 21:52:25,240 - INFO - training batch 801, loss: 0.220, 25632/28000 datapoints
2025-03-06 21:52:25,389 - INFO - training batch 851, loss: 0.518, 27232/28000 datapoints
2025-03-06 21:52:25,462 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 21:52:25,510 - INFO - validation batch 51, loss: 1.436, 1632/6976 datapoints
2025-03-06 21:52:25,559 - INFO - validation batch 101, loss: 0.289, 3232/6976 datapoints
2025-03-06 21:52:25,606 - INFO - validation batch 151, loss: 0.489, 4832/6976 datapoints
2025-03-06 21:52:25,653 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 21:52:25,669 - INFO - Epoch 168/800 done.
2025-03-06 21:52:25,669 - INFO - Final validation performance:
Loss: 0.580, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:52:25,670 - INFO - Beginning epoch 169/800
2025-03-06 21:52:25,673 - INFO - training batch 1, loss: 0.351, 32/28000 datapoints
2025-03-06 21:52:25,822 - INFO - training batch 51, loss: 0.246, 1632/28000 datapoints
2025-03-06 21:52:25,976 - INFO - training batch 101, loss: 0.172, 3232/28000 datapoints
2025-03-06 21:52:26,128 - INFO - training batch 151, loss: 0.564, 4832/28000 datapoints
2025-03-06 21:52:26,278 - INFO - training batch 201, loss: 0.160, 6432/28000 datapoints
2025-03-06 21:52:26,427 - INFO - training batch 251, loss: 0.359, 8032/28000 datapoints
2025-03-06 21:52:26,576 - INFO - training batch 301, loss: 0.698, 9632/28000 datapoints
2025-03-06 21:52:26,725 - INFO - training batch 351, loss: 0.301, 11232/28000 datapoints
2025-03-06 21:52:26,878 - INFO - training batch 401, loss: 0.642, 12832/28000 datapoints
2025-03-06 21:52:27,028 - INFO - training batch 451, loss: 0.467, 14432/28000 datapoints
2025-03-06 21:52:27,181 - INFO - training batch 501, loss: 0.178, 16032/28000 datapoints
2025-03-06 21:52:27,336 - INFO - training batch 551, loss: 0.439, 17632/28000 datapoints
2025-03-06 21:52:27,486 - INFO - training batch 601, loss: 0.679, 19232/28000 datapoints
2025-03-06 21:52:27,635 - INFO - training batch 651, loss: 0.086, 20832/28000 datapoints
2025-03-06 21:52:27,809 - INFO - training batch 701, loss: 0.294, 22432/28000 datapoints
2025-03-06 21:52:27,960 - INFO - training batch 751, loss: 0.227, 24032/28000 datapoints
2025-03-06 21:52:28,108 - INFO - training batch 801, loss: 0.218, 25632/28000 datapoints
2025-03-06 21:52:28,256 - INFO - training batch 851, loss: 0.513, 27232/28000 datapoints
2025-03-06 21:52:28,329 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:52:28,377 - INFO - validation batch 51, loss: 1.438, 1632/6976 datapoints
2025-03-06 21:52:28,424 - INFO - validation batch 101, loss: 0.290, 3232/6976 datapoints
2025-03-06 21:52:28,471 - INFO - validation batch 151, loss: 0.489, 4832/6976 datapoints
2025-03-06 21:52:28,517 - INFO - validation batch 201, loss: 0.558, 6432/6976 datapoints
2025-03-06 21:52:28,534 - INFO - Epoch 169/800 done.
2025-03-06 21:52:28,534 - INFO - Final validation performance:
Loss: 0.581, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:52:28,534 - INFO - Beginning epoch 170/800
2025-03-06 21:52:28,538 - INFO - training batch 1, loss: 0.350, 32/28000 datapoints
2025-03-06 21:52:28,690 - INFO - training batch 51, loss: 0.245, 1632/28000 datapoints
2025-03-06 21:52:28,841 - INFO - training batch 101, loss: 0.171, 3232/28000 datapoints
2025-03-06 21:52:28,997 - INFO - training batch 151, loss: 0.560, 4832/28000 datapoints
2025-03-06 21:52:29,152 - INFO - training batch 201, loss: 0.159, 6432/28000 datapoints
2025-03-06 21:52:29,301 - INFO - training batch 251, loss: 0.359, 8032/28000 datapoints
2025-03-06 21:52:29,464 - INFO - training batch 301, loss: 0.696, 9632/28000 datapoints
2025-03-06 21:52:29,612 - INFO - training batch 351, loss: 0.298, 11232/28000 datapoints
2025-03-06 21:52:29,761 - INFO - training batch 401, loss: 0.640, 12832/28000 datapoints
2025-03-06 21:52:29,921 - INFO - training batch 451, loss: 0.467, 14432/28000 datapoints
2025-03-06 21:52:30,071 - INFO - training batch 501, loss: 0.177, 16032/28000 datapoints
2025-03-06 21:52:30,225 - INFO - training batch 551, loss: 0.435, 17632/28000 datapoints
2025-03-06 21:52:30,378 - INFO - training batch 601, loss: 0.673, 19232/28000 datapoints
2025-03-06 21:52:30,533 - INFO - training batch 651, loss: 0.085, 20832/28000 datapoints
2025-03-06 21:52:30,685 - INFO - training batch 701, loss: 0.292, 22432/28000 datapoints
2025-03-06 21:52:30,852 - INFO - training batch 751, loss: 0.225, 24032/28000 datapoints
2025-03-06 21:52:31,043 - INFO - training batch 801, loss: 0.217, 25632/28000 datapoints
2025-03-06 21:52:31,208 - INFO - training batch 851, loss: 0.509, 27232/28000 datapoints
2025-03-06 21:52:31,289 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:52:31,341 - INFO - validation batch 51, loss: 1.443, 1632/6976 datapoints
2025-03-06 21:52:31,390 - INFO - validation batch 101, loss: 0.290, 3232/6976 datapoints
2025-03-06 21:52:31,440 - INFO - validation batch 151, loss: 0.490, 4832/6976 datapoints
2025-03-06 21:52:31,492 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 21:52:31,508 - INFO - Epoch 170/800 done.
2025-03-06 21:52:31,509 - INFO - Final validation performance:
Loss: 0.581, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:52:31,509 - INFO - Beginning epoch 171/800
2025-03-06 21:52:31,513 - INFO - training batch 1, loss: 0.350, 32/28000 datapoints
2025-03-06 21:52:31,666 - INFO - training batch 51, loss: 0.244, 1632/28000 datapoints
2025-03-06 21:52:31,817 - INFO - training batch 101, loss: 0.171, 3232/28000 datapoints
2025-03-06 21:52:31,972 - INFO - training batch 151, loss: 0.554, 4832/28000 datapoints
2025-03-06 21:52:32,122 - INFO - training batch 201, loss: 0.158, 6432/28000 datapoints
2025-03-06 21:52:32,270 - INFO - training batch 251, loss: 0.359, 8032/28000 datapoints
2025-03-06 21:52:32,417 - INFO - training batch 301, loss: 0.696, 9632/28000 datapoints
2025-03-06 21:52:32,564 - INFO - training batch 351, loss: 0.296, 11232/28000 datapoints
2025-03-06 21:52:32,713 - INFO - training batch 401, loss: 0.638, 12832/28000 datapoints
2025-03-06 21:52:32,865 - INFO - training batch 451, loss: 0.467, 14432/28000 datapoints
2025-03-06 21:52:33,014 - INFO - training batch 501, loss: 0.176, 16032/28000 datapoints
2025-03-06 21:52:33,167 - INFO - training batch 551, loss: 0.432, 17632/28000 datapoints
2025-03-06 21:52:33,316 - INFO - training batch 601, loss: 0.664, 19232/28000 datapoints
2025-03-06 21:52:33,465 - INFO - training batch 651, loss: 0.084, 20832/28000 datapoints
2025-03-06 21:52:33,614 - INFO - training batch 701, loss: 0.291, 22432/28000 datapoints
2025-03-06 21:52:33,762 - INFO - training batch 751, loss: 0.224, 24032/28000 datapoints
2025-03-06 21:52:33,920 - INFO - training batch 801, loss: 0.216, 25632/28000 datapoints
2025-03-06 21:52:34,072 - INFO - training batch 851, loss: 0.505, 27232/28000 datapoints
2025-03-06 21:52:34,146 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:52:34,198 - INFO - validation batch 51, loss: 1.448, 1632/6976 datapoints
2025-03-06 21:52:34,251 - INFO - validation batch 101, loss: 0.291, 3232/6976 datapoints
2025-03-06 21:52:34,311 - INFO - validation batch 151, loss: 0.491, 4832/6976 datapoints
2025-03-06 21:52:34,372 - INFO - validation batch 201, loss: 0.555, 6432/6976 datapoints
2025-03-06 21:52:34,390 - INFO - Epoch 171/800 done.
2025-03-06 21:52:34,391 - INFO - Final validation performance:
Loss: 0.583, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:52:34,391 - INFO - Beginning epoch 172/800
2025-03-06 21:52:34,397 - INFO - training batch 1, loss: 0.349, 32/28000 datapoints
2025-03-06 21:52:34,561 - INFO - training batch 51, loss: 0.244, 1632/28000 datapoints
2025-03-06 21:52:34,713 - INFO - training batch 101, loss: 0.170, 3232/28000 datapoints
2025-03-06 21:52:34,866 - INFO - training batch 151, loss: 0.548, 4832/28000 datapoints
2025-03-06 21:52:35,016 - INFO - training batch 201, loss: 0.157, 6432/28000 datapoints
2025-03-06 21:52:35,175 - INFO - training batch 251, loss: 0.361, 8032/28000 datapoints
2025-03-06 21:52:35,324 - INFO - training batch 301, loss: 0.695, 9632/28000 datapoints
2025-03-06 21:52:35,486 - INFO - training batch 351, loss: 0.293, 11232/28000 datapoints
2025-03-06 21:52:35,635 - INFO - training batch 401, loss: 0.635, 12832/28000 datapoints
2025-03-06 21:52:35,783 - INFO - training batch 451, loss: 0.465, 14432/28000 datapoints
2025-03-06 21:52:35,947 - INFO - training batch 501, loss: 0.175, 16032/28000 datapoints
2025-03-06 21:52:36,102 - INFO - training batch 551, loss: 0.428, 17632/28000 datapoints
2025-03-06 21:52:36,252 - INFO - training batch 601, loss: 0.656, 19232/28000 datapoints
2025-03-06 21:52:36,405 - INFO - training batch 651, loss: 0.083, 20832/28000 datapoints
2025-03-06 21:52:36,554 - INFO - training batch 701, loss: 0.290, 22432/28000 datapoints
2025-03-06 21:52:36,703 - INFO - training batch 751, loss: 0.223, 24032/28000 datapoints
2025-03-06 21:52:36,853 - INFO - training batch 801, loss: 0.214, 25632/28000 datapoints
2025-03-06 21:52:37,003 - INFO - training batch 851, loss: 0.500, 27232/28000 datapoints
2025-03-06 21:52:37,076 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:52:37,123 - INFO - validation batch 51, loss: 1.450, 1632/6976 datapoints
2025-03-06 21:52:37,176 - INFO - validation batch 101, loss: 0.292, 3232/6976 datapoints
2025-03-06 21:52:37,223 - INFO - validation batch 151, loss: 0.491, 4832/6976 datapoints
2025-03-06 21:52:37,272 - INFO - validation batch 201, loss: 0.554, 6432/6976 datapoints
2025-03-06 21:52:37,288 - INFO - Epoch 172/800 done.
2025-03-06 21:52:37,289 - INFO - Final validation performance:
Loss: 0.583, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:52:37,289 - INFO - Beginning epoch 173/800
2025-03-06 21:52:37,293 - INFO - training batch 1, loss: 0.350, 32/28000 datapoints
2025-03-06 21:52:37,446 - INFO - training batch 51, loss: 0.242, 1632/28000 datapoints
2025-03-06 21:52:37,595 - INFO - training batch 101, loss: 0.169, 3232/28000 datapoints
2025-03-06 21:52:37,747 - INFO - training batch 151, loss: 0.543, 4832/28000 datapoints
2025-03-06 21:52:37,936 - INFO - training batch 201, loss: 0.157, 6432/28000 datapoints
2025-03-06 21:52:38,088 - INFO - training batch 251, loss: 0.361, 8032/28000 datapoints
2025-03-06 21:52:38,237 - INFO - training batch 301, loss: 0.694, 9632/28000 datapoints
2025-03-06 21:52:38,389 - INFO - training batch 351, loss: 0.291, 11232/28000 datapoints
2025-03-06 21:52:38,538 - INFO - training batch 401, loss: 0.633, 12832/28000 datapoints
2025-03-06 21:52:38,687 - INFO - training batch 451, loss: 0.464, 14432/28000 datapoints
2025-03-06 21:52:38,835 - INFO - training batch 501, loss: 0.174, 16032/28000 datapoints
2025-03-06 21:52:38,988 - INFO - training batch 551, loss: 0.423, 17632/28000 datapoints
2025-03-06 21:52:39,141 - INFO - training batch 601, loss: 0.648, 19232/28000 datapoints
2025-03-06 21:52:39,297 - INFO - training batch 651, loss: 0.082, 20832/28000 datapoints
2025-03-06 21:52:39,445 - INFO - training batch 701, loss: 0.289, 22432/28000 datapoints
2025-03-06 21:52:39,594 - INFO - training batch 751, loss: 0.221, 24032/28000 datapoints
2025-03-06 21:52:39,743 - INFO - training batch 801, loss: 0.213, 25632/28000 datapoints
2025-03-06 21:52:39,896 - INFO - training batch 851, loss: 0.497, 27232/28000 datapoints
2025-03-06 21:52:39,969 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:52:40,016 - INFO - validation batch 51, loss: 1.454, 1632/6976 datapoints
2025-03-06 21:52:40,064 - INFO - validation batch 101, loss: 0.294, 3232/6976 datapoints
2025-03-06 21:52:40,112 - INFO - validation batch 151, loss: 0.492, 4832/6976 datapoints
2025-03-06 21:52:40,160 - INFO - validation batch 201, loss: 0.552, 6432/6976 datapoints
2025-03-06 21:52:40,176 - INFO - Epoch 173/800 done.
2025-03-06 21:52:40,176 - INFO - Final validation performance:
Loss: 0.584, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:52:40,177 - INFO - Beginning epoch 174/800
2025-03-06 21:52:40,181 - INFO - training batch 1, loss: 0.349, 32/28000 datapoints
2025-03-06 21:52:40,335 - INFO - training batch 51, loss: 0.240, 1632/28000 datapoints
2025-03-06 21:52:40,483 - INFO - training batch 101, loss: 0.168, 3232/28000 datapoints
2025-03-06 21:52:40,633 - INFO - training batch 151, loss: 0.537, 4832/28000 datapoints
2025-03-06 21:52:40,783 - INFO - training batch 201, loss: 0.156, 6432/28000 datapoints
2025-03-06 21:52:40,934 - INFO - training batch 251, loss: 0.362, 8032/28000 datapoints
2025-03-06 21:52:41,083 - INFO - training batch 301, loss: 0.694, 9632/28000 datapoints
2025-03-06 21:52:41,244 - INFO - training batch 351, loss: 0.288, 11232/28000 datapoints
2025-03-06 21:52:41,411 - INFO - training batch 401, loss: 0.630, 12832/28000 datapoints
2025-03-06 21:52:41,586 - INFO - training batch 451, loss: 0.464, 14432/28000 datapoints
2025-03-06 21:52:41,746 - INFO - training batch 501, loss: 0.173, 16032/28000 datapoints
2025-03-06 21:52:41,914 - INFO - training batch 551, loss: 0.419, 17632/28000 datapoints
2025-03-06 21:52:42,074 - INFO - training batch 601, loss: 0.639, 19232/28000 datapoints
2025-03-06 21:52:42,239 - INFO - training batch 651, loss: 0.081, 20832/28000 datapoints
2025-03-06 21:52:42,402 - INFO - training batch 701, loss: 0.287, 22432/28000 datapoints
2025-03-06 21:52:42,559 - INFO - training batch 751, loss: 0.220, 24032/28000 datapoints
2025-03-06 21:52:42,716 - INFO - training batch 801, loss: 0.211, 25632/28000 datapoints
2025-03-06 21:52:42,875 - INFO - training batch 851, loss: 0.492, 27232/28000 datapoints
2025-03-06 21:52:42,952 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:52:43,003 - INFO - validation batch 51, loss: 1.457, 1632/6976 datapoints
2025-03-06 21:52:43,054 - INFO - validation batch 101, loss: 0.295, 3232/6976 datapoints
2025-03-06 21:52:43,104 - INFO - validation batch 151, loss: 0.493, 4832/6976 datapoints
2025-03-06 21:52:43,152 - INFO - validation batch 201, loss: 0.551, 6432/6976 datapoints
2025-03-06 21:52:43,168 - INFO - Epoch 174/800 done.
2025-03-06 21:52:43,168 - INFO - Final validation performance:
Loss: 0.585, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:52:43,169 - INFO - Beginning epoch 175/800
2025-03-06 21:52:43,173 - INFO - training batch 1, loss: 0.349, 32/28000 datapoints
2025-03-06 21:52:43,339 - INFO - training batch 51, loss: 0.239, 1632/28000 datapoints
2025-03-06 21:52:43,687 - INFO - training batch 101, loss: 0.168, 3232/28000 datapoints
2025-03-06 21:52:43,909 - INFO - training batch 151, loss: 0.532, 4832/28000 datapoints
2025-03-06 21:52:44,100 - INFO - training batch 201, loss: 0.155, 6432/28000 datapoints
2025-03-06 21:52:44,284 - INFO - training batch 251, loss: 0.362, 8032/28000 datapoints
2025-03-06 21:52:44,499 - INFO - training batch 301, loss: 0.693, 9632/28000 datapoints
2025-03-06 21:52:44,907 - INFO - training batch 351, loss: 0.286, 11232/28000 datapoints
2025-03-06 21:52:45,083 - INFO - training batch 401, loss: 0.628, 12832/28000 datapoints
2025-03-06 21:52:45,239 - INFO - training batch 451, loss: 0.464, 14432/28000 datapoints
2025-03-06 21:52:45,395 - INFO - training batch 501, loss: 0.173, 16032/28000 datapoints
2025-03-06 21:52:45,549 - INFO - training batch 551, loss: 0.416, 17632/28000 datapoints
2025-03-06 21:52:45,701 - INFO - training batch 601, loss: 0.631, 19232/28000 datapoints
2025-03-06 21:52:45,858 - INFO - training batch 651, loss: 0.079, 20832/28000 datapoints
2025-03-06 21:52:46,012 - INFO - training batch 701, loss: 0.285, 22432/28000 datapoints
2025-03-06 21:52:46,165 - INFO - training batch 751, loss: 0.219, 24032/28000 datapoints
2025-03-06 21:52:46,321 - INFO - training batch 801, loss: 0.209, 25632/28000 datapoints
2025-03-06 21:52:46,471 - INFO - training batch 851, loss: 0.487, 27232/28000 datapoints
2025-03-06 21:52:46,549 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:52:46,598 - INFO - validation batch 51, loss: 1.461, 1632/6976 datapoints
2025-03-06 21:52:46,657 - INFO - validation batch 101, loss: 0.296, 3232/6976 datapoints
2025-03-06 21:52:46,709 - INFO - validation batch 151, loss: 0.494, 4832/6976 datapoints
2025-03-06 21:52:46,763 - INFO - validation batch 201, loss: 0.549, 6432/6976 datapoints
2025-03-06 21:52:46,782 - INFO - Epoch 175/800 done.
2025-03-06 21:52:46,783 - INFO - Final validation performance:
Loss: 0.586, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:52:46,783 - INFO - Beginning epoch 176/800
2025-03-06 21:52:46,790 - INFO - training batch 1, loss: 0.349, 32/28000 datapoints
2025-03-06 21:52:47,006 - INFO - training batch 51, loss: 0.237, 1632/28000 datapoints
2025-03-06 21:52:47,189 - INFO - training batch 101, loss: 0.167, 3232/28000 datapoints
2025-03-06 21:52:47,386 - INFO - training batch 151, loss: 0.526, 4832/28000 datapoints
2025-03-06 21:52:47,559 - INFO - training batch 201, loss: 0.154, 6432/28000 datapoints
2025-03-06 21:52:47,721 - INFO - training batch 251, loss: 0.361, 8032/28000 datapoints
2025-03-06 21:52:47,884 - INFO - training batch 301, loss: 0.692, 9632/28000 datapoints
2025-03-06 21:52:48,076 - INFO - training batch 351, loss: 0.284, 11232/28000 datapoints
2025-03-06 21:52:48,250 - INFO - training batch 401, loss: 0.625, 12832/28000 datapoints
2025-03-06 21:52:48,421 - INFO - training batch 451, loss: 0.464, 14432/28000 datapoints
2025-03-06 21:52:48,592 - INFO - training batch 501, loss: 0.172, 16032/28000 datapoints
2025-03-06 21:52:48,761 - INFO - training batch 551, loss: 0.412, 17632/28000 datapoints
2025-03-06 21:52:48,927 - INFO - training batch 601, loss: 0.620, 19232/28000 datapoints
2025-03-06 21:52:49,097 - INFO - training batch 651, loss: 0.078, 20832/28000 datapoints
2025-03-06 21:52:49,262 - INFO - training batch 701, loss: 0.284, 22432/28000 datapoints
2025-03-06 21:52:49,421 - INFO - training batch 751, loss: 0.217, 24032/28000 datapoints
2025-03-06 21:52:49,582 - INFO - training batch 801, loss: 0.209, 25632/28000 datapoints
2025-03-06 21:52:49,749 - INFO - training batch 851, loss: 0.483, 27232/28000 datapoints
2025-03-06 21:52:49,831 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:52:49,894 - INFO - validation batch 51, loss: 1.466, 1632/6976 datapoints
2025-03-06 21:52:49,949 - INFO - validation batch 101, loss: 0.297, 3232/6976 datapoints
2025-03-06 21:52:50,006 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 21:52:50,062 - INFO - validation batch 201, loss: 0.548, 6432/6976 datapoints
2025-03-06 21:52:50,083 - INFO - Epoch 176/800 done.
2025-03-06 21:52:50,083 - INFO - Final validation performance:
Loss: 0.587, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:52:50,084 - INFO - Beginning epoch 177/800
2025-03-06 21:52:50,089 - INFO - training batch 1, loss: 0.349, 32/28000 datapoints
2025-03-06 21:52:50,259 - INFO - training batch 51, loss: 0.235, 1632/28000 datapoints
2025-03-06 21:52:50,427 - INFO - training batch 101, loss: 0.167, 3232/28000 datapoints
2025-03-06 21:52:50,592 - INFO - training batch 151, loss: 0.520, 4832/28000 datapoints
2025-03-06 21:52:50,754 - INFO - training batch 201, loss: 0.153, 6432/28000 datapoints
2025-03-06 21:52:50,915 - INFO - training batch 251, loss: 0.359, 8032/28000 datapoints
2025-03-06 21:52:51,076 - INFO - training batch 301, loss: 0.691, 9632/28000 datapoints
2025-03-06 21:52:51,242 - INFO - training batch 351, loss: 0.282, 11232/28000 datapoints
2025-03-06 21:52:51,400 - INFO - training batch 401, loss: 0.623, 12832/28000 datapoints
2025-03-06 21:52:51,557 - INFO - training batch 451, loss: 0.463, 14432/28000 datapoints
2025-03-06 21:52:51,711 - INFO - training batch 501, loss: 0.171, 16032/28000 datapoints
2025-03-06 21:52:51,874 - INFO - training batch 551, loss: 0.408, 17632/28000 datapoints
2025-03-06 21:52:52,030 - INFO - training batch 601, loss: 0.612, 19232/28000 datapoints
2025-03-06 21:52:52,191 - INFO - training batch 651, loss: 0.078, 20832/28000 datapoints
2025-03-06 21:52:52,353 - INFO - training batch 701, loss: 0.282, 22432/28000 datapoints
2025-03-06 21:52:52,511 - INFO - training batch 751, loss: 0.216, 24032/28000 datapoints
2025-03-06 21:52:52,674 - INFO - training batch 801, loss: 0.207, 25632/28000 datapoints
2025-03-06 21:52:52,832 - INFO - training batch 851, loss: 0.478, 27232/28000 datapoints
2025-03-06 21:52:52,917 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:52:52,971 - INFO - validation batch 51, loss: 1.470, 1632/6976 datapoints
2025-03-06 21:52:53,024 - INFO - validation batch 101, loss: 0.299, 3232/6976 datapoints
2025-03-06 21:52:53,078 - INFO - validation batch 151, loss: 0.495, 4832/6976 datapoints
2025-03-06 21:52:53,132 - INFO - validation batch 201, loss: 0.547, 6432/6976 datapoints
2025-03-06 21:52:53,155 - INFO - Epoch 177/800 done.
2025-03-06 21:52:53,156 - INFO - Final validation performance:
Loss: 0.588, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:52:53,156 - INFO - Beginning epoch 178/800
2025-03-06 21:52:53,161 - INFO - training batch 1, loss: 0.350, 32/28000 datapoints
2025-03-06 21:52:53,321 - INFO - training batch 51, loss: 0.234, 1632/28000 datapoints
2025-03-06 21:52:53,474 - INFO - training batch 101, loss: 0.167, 3232/28000 datapoints
2025-03-06 21:52:53,640 - INFO - training batch 151, loss: 0.514, 4832/28000 datapoints
2025-03-06 21:52:53,791 - INFO - training batch 201, loss: 0.153, 6432/28000 datapoints
2025-03-06 21:52:53,951 - INFO - training batch 251, loss: 0.355, 8032/28000 datapoints
2025-03-06 21:52:54,105 - INFO - training batch 301, loss: 0.689, 9632/28000 datapoints
2025-03-06 21:52:54,259 - INFO - training batch 351, loss: 0.280, 11232/28000 datapoints
2025-03-06 21:52:54,415 - INFO - training batch 401, loss: 0.621, 12832/28000 datapoints
2025-03-06 21:52:54,566 - INFO - training batch 451, loss: 0.462, 14432/28000 datapoints
2025-03-06 21:52:54,720 - INFO - training batch 501, loss: 0.171, 16032/28000 datapoints
2025-03-06 21:52:54,878 - INFO - training batch 551, loss: 0.405, 17632/28000 datapoints
2025-03-06 21:52:55,029 - INFO - training batch 601, loss: 0.605, 19232/28000 datapoints
2025-03-06 21:52:55,187 - INFO - training batch 651, loss: 0.076, 20832/28000 datapoints
2025-03-06 21:52:55,342 - INFO - training batch 701, loss: 0.281, 22432/28000 datapoints
2025-03-06 21:52:55,492 - INFO - training batch 751, loss: 0.214, 24032/28000 datapoints
2025-03-06 21:52:55,642 - INFO - training batch 801, loss: 0.206, 25632/28000 datapoints
2025-03-06 21:52:55,791 - INFO - training batch 851, loss: 0.473, 27232/28000 datapoints
2025-03-06 21:52:55,869 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:52:55,920 - INFO - validation batch 51, loss: 1.475, 1632/6976 datapoints
2025-03-06 21:52:55,971 - INFO - validation batch 101, loss: 0.300, 3232/6976 datapoints
2025-03-06 21:52:56,023 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 21:52:56,075 - INFO - validation batch 201, loss: 0.546, 6432/6976 datapoints
2025-03-06 21:52:56,096 - INFO - Epoch 178/800 done.
2025-03-06 21:52:56,096 - INFO - Final validation performance:
Loss: 0.589, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:52:56,096 - INFO - Beginning epoch 179/800
2025-03-06 21:52:56,101 - INFO - training batch 1, loss: 0.349, 32/28000 datapoints
2025-03-06 21:52:56,255 - INFO - training batch 51, loss: 0.233, 1632/28000 datapoints
2025-03-06 21:52:56,406 - INFO - training batch 101, loss: 0.166, 3232/28000 datapoints
2025-03-06 21:52:56,556 - INFO - training batch 151, loss: 0.508, 4832/28000 datapoints
2025-03-06 21:52:56,705 - INFO - training batch 201, loss: 0.152, 6432/28000 datapoints
2025-03-06 21:52:56,857 - INFO - training batch 251, loss: 0.353, 8032/28000 datapoints
2025-03-06 21:52:57,007 - INFO - training batch 301, loss: 0.689, 9632/28000 datapoints
2025-03-06 21:52:57,155 - INFO - training batch 351, loss: 0.278, 11232/28000 datapoints
2025-03-06 21:52:57,307 - INFO - training batch 401, loss: 0.619, 12832/28000 datapoints
2025-03-06 21:52:57,454 - INFO - training batch 451, loss: 0.462, 14432/28000 datapoints
2025-03-06 21:52:57,605 - INFO - training batch 501, loss: 0.170, 16032/28000 datapoints
2025-03-06 21:52:57,753 - INFO - training batch 551, loss: 0.401, 17632/28000 datapoints
2025-03-06 21:52:57,906 - INFO - training batch 601, loss: 0.595, 19232/28000 datapoints
2025-03-06 21:52:58,067 - INFO - training batch 651, loss: 0.076, 20832/28000 datapoints
2025-03-06 21:52:58,221 - INFO - training batch 701, loss: 0.279, 22432/28000 datapoints
2025-03-06 21:52:58,366 - INFO - training batch 751, loss: 0.213, 24032/28000 datapoints
2025-03-06 21:52:58,532 - INFO - training batch 801, loss: 0.204, 25632/28000 datapoints
2025-03-06 21:52:58,679 - INFO - training batch 851, loss: 0.468, 27232/28000 datapoints
2025-03-06 21:52:58,755 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:52:58,806 - INFO - validation batch 51, loss: 1.480, 1632/6976 datapoints
2025-03-06 21:52:58,859 - INFO - validation batch 101, loss: 0.302, 3232/6976 datapoints
2025-03-06 21:52:58,911 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 21:52:59,015 - INFO - validation batch 201, loss: 0.544, 6432/6976 datapoints
2025-03-06 21:52:59,037 - INFO - Epoch 179/800 done.
2025-03-06 21:52:59,037 - INFO - Final validation performance:
Loss: 0.590, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:52:59,038 - INFO - Beginning epoch 180/800
2025-03-06 21:52:59,043 - INFO - training batch 1, loss: 0.349, 32/28000 datapoints
2025-03-06 21:52:59,223 - INFO - training batch 51, loss: 0.231, 1632/28000 datapoints
2025-03-06 21:52:59,369 - INFO - training batch 101, loss: 0.166, 3232/28000 datapoints
2025-03-06 21:52:59,516 - INFO - training batch 151, loss: 0.502, 4832/28000 datapoints
2025-03-06 21:52:59,673 - INFO - training batch 201, loss: 0.151, 6432/28000 datapoints
2025-03-06 21:52:59,815 - INFO - training batch 251, loss: 0.350, 8032/28000 datapoints
2025-03-06 21:52:59,975 - INFO - training batch 301, loss: 0.687, 9632/28000 datapoints
2025-03-06 21:53:00,135 - INFO - training batch 351, loss: 0.276, 11232/28000 datapoints
2025-03-06 21:53:00,286 - INFO - training batch 401, loss: 0.617, 12832/28000 datapoints
2025-03-06 21:53:00,432 - INFO - training batch 451, loss: 0.461, 14432/28000 datapoints
2025-03-06 21:53:00,584 - INFO - training batch 501, loss: 0.170, 16032/28000 datapoints
2025-03-06 21:53:00,733 - INFO - training batch 551, loss: 0.398, 17632/28000 datapoints
2025-03-06 21:53:00,882 - INFO - training batch 601, loss: 0.587, 19232/28000 datapoints
2025-03-06 21:53:01,030 - INFO - training batch 651, loss: 0.075, 20832/28000 datapoints
2025-03-06 21:53:01,178 - INFO - training batch 701, loss: 0.277, 22432/28000 datapoints
2025-03-06 21:53:01,333 - INFO - training batch 751, loss: 0.212, 24032/28000 datapoints
2025-03-06 21:53:01,496 - INFO - training batch 801, loss: 0.203, 25632/28000 datapoints
2025-03-06 21:53:01,666 - INFO - training batch 851, loss: 0.464, 27232/28000 datapoints
2025-03-06 21:53:01,755 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:53:01,812 - INFO - validation batch 51, loss: 1.486, 1632/6976 datapoints
2025-03-06 21:53:01,876 - INFO - validation batch 101, loss: 0.303, 3232/6976 datapoints
2025-03-06 21:53:01,937 - INFO - validation batch 151, loss: 0.497, 4832/6976 datapoints
2025-03-06 21:53:01,991 - INFO - validation batch 201, loss: 0.542, 6432/6976 datapoints
2025-03-06 21:53:02,011 - INFO - Epoch 180/800 done.
2025-03-06 21:53:02,012 - INFO - Final validation performance:
Loss: 0.591, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:53:02,012 - INFO - Beginning epoch 181/800
2025-03-06 21:53:02,017 - INFO - training batch 1, loss: 0.349, 32/28000 datapoints
2025-03-06 21:53:02,183 - INFO - training batch 51, loss: 0.229, 1632/28000 datapoints
2025-03-06 21:53:02,332 - INFO - training batch 101, loss: 0.166, 3232/28000 datapoints
2025-03-06 21:53:02,482 - INFO - training batch 151, loss: 0.496, 4832/28000 datapoints
2025-03-06 21:53:02,630 - INFO - training batch 201, loss: 0.150, 6432/28000 datapoints
2025-03-06 21:53:02,774 - INFO - training batch 251, loss: 0.347, 8032/28000 datapoints
2025-03-06 21:53:02,934 - INFO - training batch 301, loss: 0.685, 9632/28000 datapoints
2025-03-06 21:53:03,079 - INFO - training batch 351, loss: 0.274, 11232/28000 datapoints
2025-03-06 21:53:03,223 - INFO - training batch 401, loss: 0.614, 12832/28000 datapoints
2025-03-06 21:53:03,368 - INFO - training batch 451, loss: 0.461, 14432/28000 datapoints
2025-03-06 21:53:03,516 - INFO - training batch 501, loss: 0.170, 16032/28000 datapoints
2025-03-06 21:53:03,661 - INFO - training batch 551, loss: 0.396, 17632/28000 datapoints
2025-03-06 21:53:03,810 - INFO - training batch 601, loss: 0.578, 19232/28000 datapoints
2025-03-06 21:53:03,966 - INFO - training batch 651, loss: 0.074, 20832/28000 datapoints
2025-03-06 21:53:04,115 - INFO - training batch 701, loss: 0.276, 22432/28000 datapoints
2025-03-06 21:53:04,263 - INFO - training batch 751, loss: 0.210, 24032/28000 datapoints
2025-03-06 21:53:04,408 - INFO - training batch 801, loss: 0.202, 25632/28000 datapoints
2025-03-06 21:53:04,557 - INFO - training batch 851, loss: 0.459, 27232/28000 datapoints
2025-03-06 21:53:04,631 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:04,681 - INFO - validation batch 51, loss: 1.491, 1632/6976 datapoints
2025-03-06 21:53:04,732 - INFO - validation batch 101, loss: 0.304, 3232/6976 datapoints
2025-03-06 21:53:04,784 - INFO - validation batch 151, loss: 0.498, 4832/6976 datapoints
2025-03-06 21:53:04,830 - INFO - validation batch 201, loss: 0.541, 6432/6976 datapoints
2025-03-06 21:53:04,849 - INFO - Epoch 181/800 done.
2025-03-06 21:53:04,849 - INFO - Final validation performance:
Loss: 0.592, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:53:04,849 - INFO - Beginning epoch 182/800
2025-03-06 21:53:04,853 - INFO - training batch 1, loss: 0.348, 32/28000 datapoints
2025-03-06 21:53:05,004 - INFO - training batch 51, loss: 0.228, 1632/28000 datapoints
2025-03-06 21:53:05,155 - INFO - training batch 101, loss: 0.165, 3232/28000 datapoints
2025-03-06 21:53:05,303 - INFO - training batch 151, loss: 0.489, 4832/28000 datapoints
2025-03-06 21:53:05,448 - INFO - training batch 201, loss: 0.149, 6432/28000 datapoints
2025-03-06 21:53:05,596 - INFO - training batch 251, loss: 0.347, 8032/28000 datapoints
2025-03-06 21:53:05,746 - INFO - training batch 301, loss: 0.684, 9632/28000 datapoints
2025-03-06 21:53:05,890 - INFO - training batch 351, loss: 0.272, 11232/28000 datapoints
2025-03-06 21:53:06,042 - INFO - training batch 401, loss: 0.612, 12832/28000 datapoints
2025-03-06 21:53:06,187 - INFO - training batch 451, loss: 0.460, 14432/28000 datapoints
2025-03-06 21:53:06,335 - INFO - training batch 501, loss: 0.169, 16032/28000 datapoints
2025-03-06 21:53:06,488 - INFO - training batch 551, loss: 0.392, 17632/28000 datapoints
2025-03-06 21:53:06,633 - INFO - training batch 601, loss: 0.569, 19232/28000 datapoints
2025-03-06 21:53:06,778 - INFO - training batch 651, loss: 0.073, 20832/28000 datapoints
2025-03-06 21:53:06,922 - INFO - training batch 701, loss: 0.275, 22432/28000 datapoints
2025-03-06 21:53:07,065 - INFO - training batch 751, loss: 0.209, 24032/28000 datapoints
2025-03-06 21:53:07,211 - INFO - training batch 801, loss: 0.200, 25632/28000 datapoints
2025-03-06 21:53:07,358 - INFO - training batch 851, loss: 0.455, 27232/28000 datapoints
2025-03-06 21:53:07,428 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:07,474 - INFO - validation batch 51, loss: 1.496, 1632/6976 datapoints
2025-03-06 21:53:07,521 - INFO - validation batch 101, loss: 0.305, 3232/6976 datapoints
2025-03-06 21:53:07,567 - INFO - validation batch 151, loss: 0.497, 4832/6976 datapoints
2025-03-06 21:53:07,614 - INFO - validation batch 201, loss: 0.540, 6432/6976 datapoints
2025-03-06 21:53:07,630 - INFO - Epoch 182/800 done.
2025-03-06 21:53:07,630 - INFO - Final validation performance:
Loss: 0.593, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:53:07,631 - INFO - Beginning epoch 183/800
2025-03-06 21:53:07,635 - INFO - training batch 1, loss: 0.348, 32/28000 datapoints
2025-03-06 21:53:07,780 - INFO - training batch 51, loss: 0.225, 1632/28000 datapoints
2025-03-06 21:53:07,926 - INFO - training batch 101, loss: 0.163, 3232/28000 datapoints
2025-03-06 21:53:08,072 - INFO - training batch 151, loss: 0.485, 4832/28000 datapoints
2025-03-06 21:53:08,238 - INFO - training batch 201, loss: 0.149, 6432/28000 datapoints
2025-03-06 21:53:08,380 - INFO - training batch 251, loss: 0.344, 8032/28000 datapoints
2025-03-06 21:53:08,524 - INFO - training batch 301, loss: 0.682, 9632/28000 datapoints
2025-03-06 21:53:08,666 - INFO - training batch 351, loss: 0.270, 11232/28000 datapoints
2025-03-06 21:53:08,809 - INFO - training batch 401, loss: 0.610, 12832/28000 datapoints
2025-03-06 21:53:08,953 - INFO - training batch 451, loss: 0.459, 14432/28000 datapoints
2025-03-06 21:53:09,104 - INFO - training batch 501, loss: 0.168, 16032/28000 datapoints
2025-03-06 21:53:09,254 - INFO - training batch 551, loss: 0.389, 17632/28000 datapoints
2025-03-06 21:53:09,402 - INFO - training batch 601, loss: 0.561, 19232/28000 datapoints
2025-03-06 21:53:09,546 - INFO - training batch 651, loss: 0.072, 20832/28000 datapoints
2025-03-06 21:53:09,690 - INFO - training batch 701, loss: 0.274, 22432/28000 datapoints
2025-03-06 21:53:09,832 - INFO - training batch 751, loss: 0.207, 24032/28000 datapoints
2025-03-06 21:53:09,979 - INFO - training batch 801, loss: 0.200, 25632/28000 datapoints
2025-03-06 21:53:10,126 - INFO - training batch 851, loss: 0.451, 27232/28000 datapoints
2025-03-06 21:53:10,197 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:10,243 - INFO - validation batch 51, loss: 1.502, 1632/6976 datapoints
2025-03-06 21:53:10,289 - INFO - validation batch 101, loss: 0.306, 3232/6976 datapoints
2025-03-06 21:53:10,336 - INFO - validation batch 151, loss: 0.499, 4832/6976 datapoints
2025-03-06 21:53:10,382 - INFO - validation batch 201, loss: 0.538, 6432/6976 datapoints
2025-03-06 21:53:10,398 - INFO - Epoch 183/800 done.
2025-03-06 21:53:10,399 - INFO - Final validation performance:
Loss: 0.595, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:53:10,399 - INFO - Beginning epoch 184/800
2025-03-06 21:53:10,403 - INFO - training batch 1, loss: 0.346, 32/28000 datapoints
2025-03-06 21:53:10,552 - INFO - training batch 51, loss: 0.223, 1632/28000 datapoints
2025-03-06 21:53:10,697 - INFO - training batch 101, loss: 0.161, 3232/28000 datapoints
2025-03-06 21:53:10,840 - INFO - training batch 151, loss: 0.477, 4832/28000 datapoints
2025-03-06 21:53:10,989 - INFO - training batch 201, loss: 0.148, 6432/28000 datapoints
2025-03-06 21:53:11,133 - INFO - training batch 251, loss: 0.343, 8032/28000 datapoints
2025-03-06 21:53:11,275 - INFO - training batch 301, loss: 0.682, 9632/28000 datapoints
2025-03-06 21:53:11,422 - INFO - training batch 351, loss: 0.269, 11232/28000 datapoints
2025-03-06 21:53:11,568 - INFO - training batch 401, loss: 0.607, 12832/28000 datapoints
2025-03-06 21:53:11,725 - INFO - training batch 451, loss: 0.458, 14432/28000 datapoints
2025-03-06 21:53:11,873 - INFO - training batch 501, loss: 0.168, 16032/28000 datapoints
2025-03-06 21:53:12,016 - INFO - training batch 551, loss: 0.385, 17632/28000 datapoints
2025-03-06 21:53:12,168 - INFO - training batch 601, loss: 0.551, 19232/28000 datapoints
2025-03-06 21:53:12,318 - INFO - training batch 651, loss: 0.071, 20832/28000 datapoints
2025-03-06 21:53:12,465 - INFO - training batch 701, loss: 0.273, 22432/28000 datapoints
2025-03-06 21:53:12,613 - INFO - training batch 751, loss: 0.206, 24032/28000 datapoints
2025-03-06 21:53:12,758 - INFO - training batch 801, loss: 0.197, 25632/28000 datapoints
2025-03-06 21:53:12,908 - INFO - training batch 851, loss: 0.446, 27232/28000 datapoints
2025-03-06 21:53:12,983 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:13,038 - INFO - validation batch 51, loss: 1.507, 1632/6976 datapoints
2025-03-06 21:53:13,088 - INFO - validation batch 101, loss: 0.308, 3232/6976 datapoints
2025-03-06 21:53:13,137 - INFO - validation batch 151, loss: 0.498, 4832/6976 datapoints
2025-03-06 21:53:13,185 - INFO - validation batch 201, loss: 0.538, 6432/6976 datapoints
2025-03-06 21:53:13,203 - INFO - Epoch 184/800 done.
2025-03-06 21:53:13,203 - INFO - Final validation performance:
Loss: 0.596, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:53:13,204 - INFO - Beginning epoch 185/800
2025-03-06 21:53:13,208 - INFO - training batch 1, loss: 0.346, 32/28000 datapoints
2025-03-06 21:53:13,369 - INFO - training batch 51, loss: 0.222, 1632/28000 datapoints
2025-03-06 21:53:13,517 - INFO - training batch 101, loss: 0.159, 3232/28000 datapoints
2025-03-06 21:53:13,671 - INFO - training batch 151, loss: 0.472, 4832/28000 datapoints
2025-03-06 21:53:13,817 - INFO - training batch 201, loss: 0.147, 6432/28000 datapoints
2025-03-06 21:53:14,000 - INFO - training batch 251, loss: 0.341, 8032/28000 datapoints
2025-03-06 21:53:14,177 - INFO - training batch 301, loss: 0.680, 9632/28000 datapoints
2025-03-06 21:53:14,372 - INFO - training batch 351, loss: 0.267, 11232/28000 datapoints
2025-03-06 21:53:14,544 - INFO - training batch 401, loss: 0.604, 12832/28000 datapoints
2025-03-06 21:53:14,692 - INFO - training batch 451, loss: 0.457, 14432/28000 datapoints
2025-03-06 21:53:14,839 - INFO - training batch 501, loss: 0.168, 16032/28000 datapoints
2025-03-06 21:53:14,988 - INFO - training batch 551, loss: 0.384, 17632/28000 datapoints
2025-03-06 21:53:15,148 - INFO - training batch 601, loss: 0.539, 19232/28000 datapoints
2025-03-06 21:53:15,305 - INFO - training batch 651, loss: 0.070, 20832/28000 datapoints
2025-03-06 21:53:15,457 - INFO - training batch 701, loss: 0.271, 22432/28000 datapoints
2025-03-06 21:53:15,608 - INFO - training batch 751, loss: 0.205, 24032/28000 datapoints
2025-03-06 21:53:15,758 - INFO - training batch 801, loss: 0.196, 25632/28000 datapoints
2025-03-06 21:53:15,909 - INFO - training batch 851, loss: 0.440, 27232/28000 datapoints
2025-03-06 21:53:15,981 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:16,026 - INFO - validation batch 51, loss: 1.513, 1632/6976 datapoints
2025-03-06 21:53:16,074 - INFO - validation batch 101, loss: 0.310, 3232/6976 datapoints
2025-03-06 21:53:16,122 - INFO - validation batch 151, loss: 0.498, 4832/6976 datapoints
2025-03-06 21:53:16,169 - INFO - validation batch 201, loss: 0.536, 6432/6976 datapoints
2025-03-06 21:53:16,185 - INFO - Epoch 185/800 done.
2025-03-06 21:53:16,185 - INFO - Final validation performance:
Loss: 0.597, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:53:16,186 - INFO - Beginning epoch 186/800
2025-03-06 21:53:16,190 - INFO - training batch 1, loss: 0.346, 32/28000 datapoints
2025-03-06 21:53:16,334 - INFO - training batch 51, loss: 0.220, 1632/28000 datapoints
2025-03-06 21:53:16,476 - INFO - training batch 101, loss: 0.158, 3232/28000 datapoints
2025-03-06 21:53:16,622 - INFO - training batch 151, loss: 0.466, 4832/28000 datapoints
2025-03-06 21:53:16,770 - INFO - training batch 201, loss: 0.146, 6432/28000 datapoints
2025-03-06 21:53:16,916 - INFO - training batch 251, loss: 0.339, 8032/28000 datapoints
2025-03-06 21:53:17,057 - INFO - training batch 301, loss: 0.679, 9632/28000 datapoints
2025-03-06 21:53:17,207 - INFO - training batch 351, loss: 0.265, 11232/28000 datapoints
2025-03-06 21:53:17,356 - INFO - training batch 401, loss: 0.603, 12832/28000 datapoints
2025-03-06 21:53:17,498 - INFO - training batch 451, loss: 0.457, 14432/28000 datapoints
2025-03-06 21:53:17,642 - INFO - training batch 501, loss: 0.167, 16032/28000 datapoints
2025-03-06 21:53:17,789 - INFO - training batch 551, loss: 0.380, 17632/28000 datapoints
2025-03-06 21:53:17,946 - INFO - training batch 601, loss: 0.530, 19232/28000 datapoints
2025-03-06 21:53:18,093 - INFO - training batch 651, loss: 0.070, 20832/28000 datapoints
2025-03-06 21:53:18,256 - INFO - training batch 701, loss: 0.270, 22432/28000 datapoints
2025-03-06 21:53:18,412 - INFO - training batch 751, loss: 0.204, 24032/28000 datapoints
2025-03-06 21:53:18,558 - INFO - training batch 801, loss: 0.195, 25632/28000 datapoints
2025-03-06 21:53:18,702 - INFO - training batch 851, loss: 0.436, 27232/28000 datapoints
2025-03-06 21:53:18,774 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:18,824 - INFO - validation batch 51, loss: 1.515, 1632/6976 datapoints
2025-03-06 21:53:18,872 - INFO - validation batch 101, loss: 0.311, 3232/6976 datapoints
2025-03-06 21:53:18,919 - INFO - validation batch 151, loss: 0.499, 4832/6976 datapoints
2025-03-06 21:53:18,966 - INFO - validation batch 201, loss: 0.534, 6432/6976 datapoints
2025-03-06 21:53:18,982 - INFO - Epoch 186/800 done.
2025-03-06 21:53:18,982 - INFO - Final validation performance:
Loss: 0.597, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:53:18,982 - INFO - Beginning epoch 187/800
2025-03-06 21:53:18,986 - INFO - training batch 1, loss: 0.345, 32/28000 datapoints
2025-03-06 21:53:19,133 - INFO - training batch 51, loss: 0.218, 1632/28000 datapoints
2025-03-06 21:53:19,280 - INFO - training batch 101, loss: 0.156, 3232/28000 datapoints
2025-03-06 21:53:19,430 - INFO - training batch 151, loss: 0.460, 4832/28000 datapoints
2025-03-06 21:53:19,574 - INFO - training batch 201, loss: 0.145, 6432/28000 datapoints
2025-03-06 21:53:19,719 - INFO - training batch 251, loss: 0.338, 8032/28000 datapoints
2025-03-06 21:53:19,865 - INFO - training batch 301, loss: 0.678, 9632/28000 datapoints
2025-03-06 21:53:20,007 - INFO - training batch 351, loss: 0.263, 11232/28000 datapoints
2025-03-06 21:53:20,151 - INFO - training batch 401, loss: 0.601, 12832/28000 datapoints
2025-03-06 21:53:20,295 - INFO - training batch 451, loss: 0.456, 14432/28000 datapoints
2025-03-06 21:53:20,439 - INFO - training batch 501, loss: 0.167, 16032/28000 datapoints
2025-03-06 21:53:20,584 - INFO - training batch 551, loss: 0.376, 17632/28000 datapoints
2025-03-06 21:53:20,731 - INFO - training batch 601, loss: 0.519, 19232/28000 datapoints
2025-03-06 21:53:20,875 - INFO - training batch 651, loss: 0.069, 20832/28000 datapoints
2025-03-06 21:53:21,021 - INFO - training batch 701, loss: 0.269, 22432/28000 datapoints
2025-03-06 21:53:21,164 - INFO - training batch 751, loss: 0.203, 24032/28000 datapoints
2025-03-06 21:53:21,306 - INFO - training batch 801, loss: 0.192, 25632/28000 datapoints
2025-03-06 21:53:21,462 - INFO - training batch 851, loss: 0.432, 27232/28000 datapoints
2025-03-06 21:53:21,533 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:21,579 - INFO - validation batch 51, loss: 1.519, 1632/6976 datapoints
2025-03-06 21:53:21,625 - INFO - validation batch 101, loss: 0.313, 3232/6976 datapoints
2025-03-06 21:53:21,674 - INFO - validation batch 151, loss: 0.499, 4832/6976 datapoints
2025-03-06 21:53:21,722 - INFO - validation batch 201, loss: 0.533, 6432/6976 datapoints
2025-03-06 21:53:21,741 - INFO - Epoch 187/800 done.
2025-03-06 21:53:21,741 - INFO - Final validation performance:
Loss: 0.598, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:53:21,742 - INFO - Beginning epoch 188/800
2025-03-06 21:53:21,746 - INFO - training batch 1, loss: 0.345, 32/28000 datapoints
2025-03-06 21:53:21,893 - INFO - training batch 51, loss: 0.217, 1632/28000 datapoints
2025-03-06 21:53:22,039 - INFO - training batch 101, loss: 0.155, 3232/28000 datapoints
2025-03-06 21:53:22,184 - INFO - training batch 151, loss: 0.456, 4832/28000 datapoints
2025-03-06 21:53:22,329 - INFO - training batch 201, loss: 0.144, 6432/28000 datapoints
2025-03-06 21:53:22,472 - INFO - training batch 251, loss: 0.336, 8032/28000 datapoints
2025-03-06 21:53:22,614 - INFO - training batch 301, loss: 0.677, 9632/28000 datapoints
2025-03-06 21:53:22,758 - INFO - training batch 351, loss: 0.262, 11232/28000 datapoints
2025-03-06 21:53:22,905 - INFO - training batch 401, loss: 0.599, 12832/28000 datapoints
2025-03-06 21:53:23,053 - INFO - training batch 451, loss: 0.455, 14432/28000 datapoints
2025-03-06 21:53:23,197 - INFO - training batch 501, loss: 0.167, 16032/28000 datapoints
2025-03-06 21:53:23,344 - INFO - training batch 551, loss: 0.374, 17632/28000 datapoints
2025-03-06 21:53:23,491 - INFO - training batch 601, loss: 0.510, 19232/28000 datapoints
2025-03-06 21:53:23,634 - INFO - training batch 651, loss: 0.068, 20832/28000 datapoints
2025-03-06 21:53:23,782 - INFO - training batch 701, loss: 0.267, 22432/28000 datapoints
2025-03-06 21:53:23,940 - INFO - training batch 751, loss: 0.202, 24032/28000 datapoints
2025-03-06 21:53:24,097 - INFO - training batch 801, loss: 0.191, 25632/28000 datapoints
2025-03-06 21:53:24,249 - INFO - training batch 851, loss: 0.427, 27232/28000 datapoints
2025-03-06 21:53:24,325 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:24,375 - INFO - validation batch 51, loss: 1.524, 1632/6976 datapoints
2025-03-06 21:53:24,427 - INFO - validation batch 101, loss: 0.315, 3232/6976 datapoints
2025-03-06 21:53:24,481 - INFO - validation batch 151, loss: 0.500, 4832/6976 datapoints
2025-03-06 21:53:24,532 - INFO - validation batch 201, loss: 0.532, 6432/6976 datapoints
2025-03-06 21:53:24,550 - INFO - Epoch 188/800 done.
2025-03-06 21:53:24,550 - INFO - Final validation performance:
Loss: 0.600, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:53:24,551 - INFO - Beginning epoch 189/800
2025-03-06 21:53:24,555 - INFO - training batch 1, loss: 0.345, 32/28000 datapoints
2025-03-06 21:53:24,713 - INFO - training batch 51, loss: 0.216, 1632/28000 datapoints
2025-03-06 21:53:24,862 - INFO - training batch 101, loss: 0.154, 3232/28000 datapoints
2025-03-06 21:53:25,013 - INFO - training batch 151, loss: 0.451, 4832/28000 datapoints
2025-03-06 21:53:25,167 - INFO - training batch 201, loss: 0.144, 6432/28000 datapoints
2025-03-06 21:53:25,318 - INFO - training batch 251, loss: 0.333, 8032/28000 datapoints
2025-03-06 21:53:25,468 - INFO - training batch 301, loss: 0.676, 9632/28000 datapoints
2025-03-06 21:53:25,614 - INFO - training batch 351, loss: 0.260, 11232/28000 datapoints
2025-03-06 21:53:25,763 - INFO - training batch 401, loss: 0.596, 12832/28000 datapoints
2025-03-06 21:53:25,913 - INFO - training batch 451, loss: 0.454, 14432/28000 datapoints
2025-03-06 21:53:26,062 - INFO - training batch 501, loss: 0.166, 16032/28000 datapoints
2025-03-06 21:53:26,210 - INFO - training batch 551, loss: 0.371, 17632/28000 datapoints
2025-03-06 21:53:26,359 - INFO - training batch 601, loss: 0.499, 19232/28000 datapoints
2025-03-06 21:53:26,510 - INFO - training batch 651, loss: 0.067, 20832/28000 datapoints
2025-03-06 21:53:26,663 - INFO - training batch 701, loss: 0.265, 22432/28000 datapoints
2025-03-06 21:53:26,816 - INFO - training batch 751, loss: 0.201, 24032/28000 datapoints
2025-03-06 21:53:26,969 - INFO - training batch 801, loss: 0.190, 25632/28000 datapoints
2025-03-06 21:53:27,117 - INFO - training batch 851, loss: 0.423, 27232/28000 datapoints
2025-03-06 21:53:27,194 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:27,249 - INFO - validation batch 51, loss: 1.529, 1632/6976 datapoints
2025-03-06 21:53:27,302 - INFO - validation batch 101, loss: 0.316, 3232/6976 datapoints
2025-03-06 21:53:27,353 - INFO - validation batch 151, loss: 0.500, 4832/6976 datapoints
2025-03-06 21:53:27,411 - INFO - validation batch 201, loss: 0.530, 6432/6976 datapoints
2025-03-06 21:53:27,428 - INFO - Epoch 189/800 done.
2025-03-06 21:53:27,428 - INFO - Final validation performance:
Loss: 0.601, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:53:27,429 - INFO - Beginning epoch 190/800
2025-03-06 21:53:27,434 - INFO - training batch 1, loss: 0.344, 32/28000 datapoints
2025-03-06 21:53:27,587 - INFO - training batch 51, loss: 0.215, 1632/28000 datapoints
2025-03-06 21:53:27,738 - INFO - training batch 101, loss: 0.152, 3232/28000 datapoints
2025-03-06 21:53:27,891 - INFO - training batch 151, loss: 0.446, 4832/28000 datapoints
2025-03-06 21:53:28,037 - INFO - training batch 201, loss: 0.143, 6432/28000 datapoints
2025-03-06 21:53:28,185 - INFO - training batch 251, loss: 0.331, 8032/28000 datapoints
2025-03-06 21:53:28,356 - INFO - training batch 301, loss: 0.675, 9632/28000 datapoints
2025-03-06 21:53:28,506 - INFO - training batch 351, loss: 0.258, 11232/28000 datapoints
2025-03-06 21:53:28,649 - INFO - training batch 401, loss: 0.594, 12832/28000 datapoints
2025-03-06 21:53:28,795 - INFO - training batch 451, loss: 0.453, 14432/28000 datapoints
2025-03-06 21:53:28,946 - INFO - training batch 501, loss: 0.166, 16032/28000 datapoints
2025-03-06 21:53:29,090 - INFO - training batch 551, loss: 0.367, 17632/28000 datapoints
2025-03-06 21:53:29,234 - INFO - training batch 601, loss: 0.488, 19232/28000 datapoints
2025-03-06 21:53:29,380 - INFO - training batch 651, loss: 0.067, 20832/28000 datapoints
2025-03-06 21:53:29,523 - INFO - training batch 701, loss: 0.264, 22432/28000 datapoints
2025-03-06 21:53:29,666 - INFO - training batch 751, loss: 0.200, 24032/28000 datapoints
2025-03-06 21:53:29,811 - INFO - training batch 801, loss: 0.190, 25632/28000 datapoints
2025-03-06 21:53:29,956 - INFO - training batch 851, loss: 0.421, 27232/28000 datapoints
2025-03-06 21:53:30,028 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:30,074 - INFO - validation batch 51, loss: 1.535, 1632/6976 datapoints
2025-03-06 21:53:30,120 - INFO - validation batch 101, loss: 0.318, 3232/6976 datapoints
2025-03-06 21:53:30,166 - INFO - validation batch 151, loss: 0.501, 4832/6976 datapoints
2025-03-06 21:53:30,223 - INFO - validation batch 201, loss: 0.528, 6432/6976 datapoints
2025-03-06 21:53:30,239 - INFO - Epoch 190/800 done.
2025-03-06 21:53:30,240 - INFO - Final validation performance:
Loss: 0.602, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 21:53:30,241 - INFO - Beginning epoch 191/800
2025-03-06 21:53:30,245 - INFO - training batch 1, loss: 0.344, 32/28000 datapoints
2025-03-06 21:53:30,401 - INFO - training batch 51, loss: 0.213, 1632/28000 datapoints
2025-03-06 21:53:30,543 - INFO - training batch 101, loss: 0.151, 3232/28000 datapoints
2025-03-06 21:53:30,687 - INFO - training batch 151, loss: 0.442, 4832/28000 datapoints
2025-03-06 21:53:30,833 - INFO - training batch 201, loss: 0.142, 6432/28000 datapoints
2025-03-06 21:53:30,976 - INFO - training batch 251, loss: 0.331, 8032/28000 datapoints
2025-03-06 21:53:31,119 - INFO - training batch 301, loss: 0.674, 9632/28000 datapoints
2025-03-06 21:53:31,262 - INFO - training batch 351, loss: 0.258, 11232/28000 datapoints
2025-03-06 21:53:31,410 - INFO - training batch 401, loss: 0.592, 12832/28000 datapoints
2025-03-06 21:53:31,553 - INFO - training batch 451, loss: 0.452, 14432/28000 datapoints
2025-03-06 21:53:31,697 - INFO - training batch 501, loss: 0.167, 16032/28000 datapoints
2025-03-06 21:53:31,847 - INFO - training batch 551, loss: 0.364, 17632/28000 datapoints
2025-03-06 21:53:31,994 - INFO - training batch 601, loss: 0.481, 19232/28000 datapoints
2025-03-06 21:53:32,148 - INFO - training batch 651, loss: 0.066, 20832/28000 datapoints
2025-03-06 21:53:32,297 - INFO - training batch 701, loss: 0.263, 22432/28000 datapoints
2025-03-06 21:53:32,444 - INFO - training batch 751, loss: 0.199, 24032/28000 datapoints
2025-03-06 21:53:32,591 - INFO - training batch 801, loss: 0.187, 25632/28000 datapoints
2025-03-06 21:53:32,741 - INFO - training batch 851, loss: 0.416, 27232/28000 datapoints
2025-03-06 21:53:32,815 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:32,866 - INFO - validation batch 51, loss: 1.539, 1632/6976 datapoints
2025-03-06 21:53:32,914 - INFO - validation batch 101, loss: 0.319, 3232/6976 datapoints
2025-03-06 21:53:32,967 - INFO - validation batch 151, loss: 0.502, 4832/6976 datapoints
2025-03-06 21:53:33,015 - INFO - validation batch 201, loss: 0.528, 6432/6976 datapoints
2025-03-06 21:53:33,033 - INFO - Epoch 191/800 done.
2025-03-06 21:53:33,033 - INFO - Final validation performance:
Loss: 0.603, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 21:53:33,034 - INFO - Beginning epoch 192/800
2025-03-06 21:53:33,038 - INFO - training batch 1, loss: 0.342, 32/28000 datapoints
2025-03-06 21:53:33,188 - INFO - training batch 51, loss: 0.212, 1632/28000 datapoints
2025-03-06 21:53:33,341 - INFO - training batch 101, loss: 0.149, 3232/28000 datapoints
2025-03-06 21:53:33,496 - INFO - training batch 151, loss: 0.437, 4832/28000 datapoints
2025-03-06 21:53:33,647 - INFO - training batch 201, loss: 0.142, 6432/28000 datapoints
2025-03-06 21:53:33,797 - INFO - training batch 251, loss: 0.329, 8032/28000 datapoints
2025-03-06 21:53:33,947 - INFO - training batch 301, loss: 0.672, 9632/28000 datapoints
2025-03-06 21:53:34,097 - INFO - training batch 351, loss: 0.256, 11232/28000 datapoints
2025-03-06 21:53:34,247 - INFO - training batch 401, loss: 0.590, 12832/28000 datapoints
2025-03-06 21:53:34,405 - INFO - training batch 451, loss: 0.452, 14432/28000 datapoints
2025-03-06 21:53:34,555 - INFO - training batch 501, loss: 0.166, 16032/28000 datapoints
2025-03-06 21:53:34,707 - INFO - training batch 551, loss: 0.362, 17632/28000 datapoints
2025-03-06 21:53:34,862 - INFO - training batch 601, loss: 0.472, 19232/28000 datapoints
2025-03-06 21:53:35,007 - INFO - training batch 651, loss: 0.065, 20832/28000 datapoints
2025-03-06 21:53:35,158 - INFO - training batch 701, loss: 0.261, 22432/28000 datapoints
2025-03-06 21:53:35,303 - INFO - training batch 751, loss: 0.198, 24032/28000 datapoints
2025-03-06 21:53:35,449 - INFO - training batch 801, loss: 0.186, 25632/28000 datapoints
2025-03-06 21:53:35,592 - INFO - training batch 851, loss: 0.411, 27232/28000 datapoints
2025-03-06 21:53:35,662 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:35,708 - INFO - validation batch 51, loss: 1.543, 1632/6976 datapoints
2025-03-06 21:53:35,755 - INFO - validation batch 101, loss: 0.320, 3232/6976 datapoints
2025-03-06 21:53:35,801 - INFO - validation batch 151, loss: 0.503, 4832/6976 datapoints
2025-03-06 21:53:35,850 - INFO - validation batch 201, loss: 0.525, 6432/6976 datapoints
2025-03-06 21:53:35,867 - INFO - Epoch 192/800 done.
2025-03-06 21:53:35,867 - INFO - Final validation performance:
Loss: 0.604, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 21:53:35,867 - INFO - Beginning epoch 193/800
2025-03-06 21:53:35,872 - INFO - training batch 1, loss: 0.342, 32/28000 datapoints
2025-03-06 21:53:36,020 - INFO - training batch 51, loss: 0.209, 1632/28000 datapoints
2025-03-06 21:53:36,166 - INFO - training batch 101, loss: 0.148, 3232/28000 datapoints
2025-03-06 21:53:36,322 - INFO - training batch 151, loss: 0.431, 4832/28000 datapoints
2025-03-06 21:53:36,476 - INFO - training batch 201, loss: 0.141, 6432/28000 datapoints
2025-03-06 21:53:36,621 - INFO - training batch 251, loss: 0.327, 8032/28000 datapoints
2025-03-06 21:53:36,775 - INFO - training batch 301, loss: 0.671, 9632/28000 datapoints
2025-03-06 21:53:36,930 - INFO - training batch 351, loss: 0.254, 11232/28000 datapoints
2025-03-06 21:53:37,084 - INFO - training batch 401, loss: 0.588, 12832/28000 datapoints
2025-03-06 21:53:37,232 - INFO - training batch 451, loss: 0.451, 14432/28000 datapoints
2025-03-06 21:53:37,382 - INFO - training batch 501, loss: 0.166, 16032/28000 datapoints
2025-03-06 21:53:37,533 - INFO - training batch 551, loss: 0.358, 17632/28000 datapoints
2025-03-06 21:53:37,681 - INFO - training batch 601, loss: 0.464, 19232/28000 datapoints
2025-03-06 21:53:37,829 - INFO - training batch 651, loss: 0.065, 20832/28000 datapoints
2025-03-06 21:53:37,988 - INFO - training batch 701, loss: 0.260, 22432/28000 datapoints
2025-03-06 21:53:38,133 - INFO - training batch 751, loss: 0.197, 24032/28000 datapoints
2025-03-06 21:53:38,279 - INFO - training batch 801, loss: 0.186, 25632/28000 datapoints
2025-03-06 21:53:38,444 - INFO - training batch 851, loss: 0.409, 27232/28000 datapoints
2025-03-06 21:53:38,518 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:38,567 - INFO - validation batch 51, loss: 1.549, 1632/6976 datapoints
2025-03-06 21:53:38,615 - INFO - validation batch 101, loss: 0.322, 3232/6976 datapoints
2025-03-06 21:53:38,661 - INFO - validation batch 151, loss: 0.504, 4832/6976 datapoints
2025-03-06 21:53:38,708 - INFO - validation batch 201, loss: 0.525, 6432/6976 datapoints
2025-03-06 21:53:38,724 - INFO - Epoch 193/800 done.
2025-03-06 21:53:38,724 - INFO - Final validation performance:
Loss: 0.606, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 21:53:38,724 - INFO - Beginning epoch 194/800
2025-03-06 21:53:38,728 - INFO - training batch 1, loss: 0.340, 32/28000 datapoints
2025-03-06 21:53:38,878 - INFO - training batch 51, loss: 0.207, 1632/28000 datapoints
2025-03-06 21:53:39,022 - INFO - training batch 101, loss: 0.146, 3232/28000 datapoints
2025-03-06 21:53:39,166 - INFO - training batch 151, loss: 0.426, 4832/28000 datapoints
2025-03-06 21:53:39,320 - INFO - training batch 201, loss: 0.140, 6432/28000 datapoints
2025-03-06 21:53:39,469 - INFO - training batch 251, loss: 0.326, 8032/28000 datapoints
2025-03-06 21:53:39,612 - INFO - training batch 301, loss: 0.670, 9632/28000 datapoints
2025-03-06 21:53:39,755 - INFO - training batch 351, loss: 0.253, 11232/28000 datapoints
2025-03-06 21:53:39,903 - INFO - training batch 401, loss: 0.586, 12832/28000 datapoints
2025-03-06 21:53:40,047 - INFO - training batch 451, loss: 0.449, 14432/28000 datapoints
2025-03-06 21:53:40,190 - INFO - training batch 501, loss: 0.165, 16032/28000 datapoints
2025-03-06 21:53:40,337 - INFO - training batch 551, loss: 0.356, 17632/28000 datapoints
2025-03-06 21:53:40,481 - INFO - training batch 601, loss: 0.454, 19232/28000 datapoints
2025-03-06 21:53:40,625 - INFO - training batch 651, loss: 0.064, 20832/28000 datapoints
2025-03-06 21:53:40,770 - INFO - training batch 701, loss: 0.259, 22432/28000 datapoints
2025-03-06 21:53:40,918 - INFO - training batch 751, loss: 0.196, 24032/28000 datapoints
2025-03-06 21:53:41,070 - INFO - training batch 801, loss: 0.183, 25632/28000 datapoints
2025-03-06 21:53:41,213 - INFO - training batch 851, loss: 0.405, 27232/28000 datapoints
2025-03-06 21:53:41,284 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:41,330 - INFO - validation batch 51, loss: 1.554, 1632/6976 datapoints
2025-03-06 21:53:41,377 - INFO - validation batch 101, loss: 0.324, 3232/6976 datapoints
2025-03-06 21:53:41,428 - INFO - validation batch 151, loss: 0.505, 4832/6976 datapoints
2025-03-06 21:53:41,481 - INFO - validation batch 201, loss: 0.524, 6432/6976 datapoints
2025-03-06 21:53:41,496 - INFO - Epoch 194/800 done.
2025-03-06 21:53:41,497 - INFO - Final validation performance:
Loss: 0.607, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 21:53:41,497 - INFO - Beginning epoch 195/800
2025-03-06 21:53:41,501 - INFO - training batch 1, loss: 0.339, 32/28000 datapoints
2025-03-06 21:53:41,647 - INFO - training batch 51, loss: 0.206, 1632/28000 datapoints
2025-03-06 21:53:41,797 - INFO - training batch 101, loss: 0.144, 3232/28000 datapoints
2025-03-06 21:53:41,951 - INFO - training batch 151, loss: 0.421, 4832/28000 datapoints
2025-03-06 21:53:42,093 - INFO - training batch 201, loss: 0.139, 6432/28000 datapoints
2025-03-06 21:53:42,238 - INFO - training batch 251, loss: 0.324, 8032/28000 datapoints
2025-03-06 21:53:42,391 - INFO - training batch 301, loss: 0.668, 9632/28000 datapoints
2025-03-06 21:53:42,541 - INFO - training batch 351, loss: 0.251, 11232/28000 datapoints
2025-03-06 21:53:42,687 - INFO - training batch 401, loss: 0.584, 12832/28000 datapoints
2025-03-06 21:53:42,844 - INFO - training batch 451, loss: 0.448, 14432/28000 datapoints
2025-03-06 21:53:43,001 - INFO - training batch 501, loss: 0.165, 16032/28000 datapoints
2025-03-06 21:53:43,155 - INFO - training batch 551, loss: 0.352, 17632/28000 datapoints
2025-03-06 21:53:43,304 - INFO - training batch 601, loss: 0.445, 19232/28000 datapoints
2025-03-06 21:53:43,457 - INFO - training batch 651, loss: 0.064, 20832/28000 datapoints
2025-03-06 21:53:43,602 - INFO - training batch 701, loss: 0.258, 22432/28000 datapoints
2025-03-06 21:53:43,744 - INFO - training batch 751, loss: 0.194, 24032/28000 datapoints
2025-03-06 21:53:43,899 - INFO - training batch 801, loss: 0.183, 25632/28000 datapoints
2025-03-06 21:53:44,047 - INFO - training batch 851, loss: 0.401, 27232/28000 datapoints
2025-03-06 21:53:44,121 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:44,172 - INFO - validation batch 51, loss: 1.557, 1632/6976 datapoints
2025-03-06 21:53:44,224 - INFO - validation batch 101, loss: 0.326, 3232/6976 datapoints
2025-03-06 21:53:44,274 - INFO - validation batch 151, loss: 0.505, 4832/6976 datapoints
2025-03-06 21:53:44,326 - INFO - validation batch 201, loss: 0.523, 6432/6976 datapoints
2025-03-06 21:53:44,343 - INFO - Epoch 195/800 done.
2025-03-06 21:53:44,344 - INFO - Final validation performance:
Loss: 0.608, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 21:53:44,344 - INFO - Beginning epoch 196/800
2025-03-06 21:53:44,348 - INFO - training batch 1, loss: 0.339, 32/28000 datapoints
2025-03-06 21:53:44,502 - INFO - training batch 51, loss: 0.205, 1632/28000 datapoints
2025-03-06 21:53:44,649 - INFO - training batch 101, loss: 0.143, 3232/28000 datapoints
2025-03-06 21:53:44,797 - INFO - training batch 151, loss: 0.414, 4832/28000 datapoints
2025-03-06 21:53:44,948 - INFO - training batch 201, loss: 0.138, 6432/28000 datapoints
2025-03-06 21:53:45,099 - INFO - training batch 251, loss: 0.322, 8032/28000 datapoints
2025-03-06 21:53:45,249 - INFO - training batch 301, loss: 0.668, 9632/28000 datapoints
2025-03-06 21:53:45,396 - INFO - training batch 351, loss: 0.250, 11232/28000 datapoints
2025-03-06 21:53:45,546 - INFO - training batch 401, loss: 0.582, 12832/28000 datapoints
2025-03-06 21:53:45,693 - INFO - training batch 451, loss: 0.447, 14432/28000 datapoints
2025-03-06 21:53:45,843 - INFO - training batch 501, loss: 0.164, 16032/28000 datapoints
2025-03-06 21:53:45,993 - INFO - training batch 551, loss: 0.349, 17632/28000 datapoints
2025-03-06 21:53:46,143 - INFO - training batch 601, loss: 0.439, 19232/28000 datapoints
2025-03-06 21:53:46,292 - INFO - training batch 651, loss: 0.063, 20832/28000 datapoints
2025-03-06 21:53:46,439 - INFO - training batch 701, loss: 0.256, 22432/28000 datapoints
2025-03-06 21:53:46,586 - INFO - training batch 751, loss: 0.194, 24032/28000 datapoints
2025-03-06 21:53:46,735 - INFO - training batch 801, loss: 0.182, 25632/28000 datapoints
2025-03-06 21:53:46,889 - INFO - training batch 851, loss: 0.397, 27232/28000 datapoints
2025-03-06 21:53:46,966 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:47,019 - INFO - validation batch 51, loss: 1.561, 1632/6976 datapoints
2025-03-06 21:53:47,070 - INFO - validation batch 101, loss: 0.327, 3232/6976 datapoints
2025-03-06 21:53:47,121 - INFO - validation batch 151, loss: 0.506, 4832/6976 datapoints
2025-03-06 21:53:47,174 - INFO - validation batch 201, loss: 0.522, 6432/6976 datapoints
2025-03-06 21:53:47,193 - INFO - Epoch 196/800 done.
2025-03-06 21:53:47,194 - INFO - Final validation performance:
Loss: 0.609, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 21:53:47,194 - INFO - Beginning epoch 197/800
2025-03-06 21:53:47,199 - INFO - training batch 1, loss: 0.338, 32/28000 datapoints
2025-03-06 21:53:47,360 - INFO - training batch 51, loss: 0.203, 1632/28000 datapoints
2025-03-06 21:53:47,521 - INFO - training batch 101, loss: 0.142, 3232/28000 datapoints
2025-03-06 21:53:47,673 - INFO - training batch 151, loss: 0.410, 4832/28000 datapoints
2025-03-06 21:53:47,824 - INFO - training batch 201, loss: 0.138, 6432/28000 datapoints
2025-03-06 21:53:47,976 - INFO - training batch 251, loss: 0.321, 8032/28000 datapoints
2025-03-06 21:53:48,126 - INFO - training batch 301, loss: 0.666, 9632/28000 datapoints
2025-03-06 21:53:48,278 - INFO - training batch 351, loss: 0.249, 11232/28000 datapoints
2025-03-06 21:53:48,454 - INFO - training batch 401, loss: 0.580, 12832/28000 datapoints
2025-03-06 21:53:48,628 - INFO - training batch 451, loss: 0.446, 14432/28000 datapoints
2025-03-06 21:53:48,778 - INFO - training batch 501, loss: 0.164, 16032/28000 datapoints
2025-03-06 21:53:48,938 - INFO - training batch 551, loss: 0.346, 17632/28000 datapoints
2025-03-06 21:53:49,097 - INFO - training batch 601, loss: 0.429, 19232/28000 datapoints
2025-03-06 21:53:49,245 - INFO - training batch 651, loss: 0.062, 20832/28000 datapoints
2025-03-06 21:53:49,395 - INFO - training batch 701, loss: 0.255, 22432/28000 datapoints
2025-03-06 21:53:49,549 - INFO - training batch 751, loss: 0.192, 24032/28000 datapoints
2025-03-06 21:53:49,696 - INFO - training batch 801, loss: 0.181, 25632/28000 datapoints
2025-03-06 21:53:49,846 - INFO - training batch 851, loss: 0.394, 27232/28000 datapoints
2025-03-06 21:53:49,921 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:49,971 - INFO - validation batch 51, loss: 1.564, 1632/6976 datapoints
2025-03-06 21:53:50,023 - INFO - validation batch 101, loss: 0.329, 3232/6976 datapoints
2025-03-06 21:53:50,076 - INFO - validation batch 151, loss: 0.508, 4832/6976 datapoints
2025-03-06 21:53:50,126 - INFO - validation batch 201, loss: 0.520, 6432/6976 datapoints
2025-03-06 21:53:50,142 - INFO - Epoch 197/800 done.
2025-03-06 21:53:50,143 - INFO - Final validation performance:
Loss: 0.610, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 21:53:50,143 - INFO - Beginning epoch 198/800
2025-03-06 21:53:50,147 - INFO - training batch 1, loss: 0.338, 32/28000 datapoints
2025-03-06 21:53:50,296 - INFO - training batch 51, loss: 0.201, 1632/28000 datapoints
2025-03-06 21:53:50,439 - INFO - training batch 101, loss: 0.141, 3232/28000 datapoints
2025-03-06 21:53:50,587 - INFO - training batch 151, loss: 0.403, 4832/28000 datapoints
2025-03-06 21:53:50,731 - INFO - training batch 201, loss: 0.137, 6432/28000 datapoints
2025-03-06 21:53:50,876 - INFO - training batch 251, loss: 0.320, 8032/28000 datapoints
2025-03-06 21:53:51,020 - INFO - training batch 301, loss: 0.664, 9632/28000 datapoints
2025-03-06 21:53:51,164 - INFO - training batch 351, loss: 0.248, 11232/28000 datapoints
2025-03-06 21:53:51,307 - INFO - training batch 401, loss: 0.577, 12832/28000 datapoints
2025-03-06 21:53:51,450 - INFO - training batch 451, loss: 0.445, 14432/28000 datapoints
2025-03-06 21:53:51,597 - INFO - training batch 501, loss: 0.164, 16032/28000 datapoints
2025-03-06 21:53:51,741 - INFO - training batch 551, loss: 0.343, 17632/28000 datapoints
2025-03-06 21:53:51,890 - INFO - training batch 601, loss: 0.422, 19232/28000 datapoints
2025-03-06 21:53:52,032 - INFO - training batch 651, loss: 0.062, 20832/28000 datapoints
2025-03-06 21:53:52,176 - INFO - training batch 701, loss: 0.253, 22432/28000 datapoints
2025-03-06 21:53:52,322 - INFO - training batch 751, loss: 0.192, 24032/28000 datapoints
2025-03-06 21:53:52,466 - INFO - training batch 801, loss: 0.179, 25632/28000 datapoints
2025-03-06 21:53:52,610 - INFO - training batch 851, loss: 0.391, 27232/28000 datapoints
2025-03-06 21:53:52,681 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:52,727 - INFO - validation batch 51, loss: 1.568, 1632/6976 datapoints
2025-03-06 21:53:52,774 - INFO - validation batch 101, loss: 0.331, 3232/6976 datapoints
2025-03-06 21:53:52,819 - INFO - validation batch 151, loss: 0.508, 4832/6976 datapoints
2025-03-06 21:53:52,869 - INFO - validation batch 201, loss: 0.520, 6432/6976 datapoints
2025-03-06 21:53:52,886 - INFO - Epoch 198/800 done.
2025-03-06 21:53:52,886 - INFO - Final validation performance:
Loss: 0.611, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 21:53:52,887 - INFO - Beginning epoch 199/800
2025-03-06 21:53:52,891 - INFO - training batch 1, loss: 0.337, 32/28000 datapoints
2025-03-06 21:53:53,041 - INFO - training batch 51, loss: 0.200, 1632/28000 datapoints
2025-03-06 21:53:53,187 - INFO - training batch 101, loss: 0.140, 3232/28000 datapoints
2025-03-06 21:53:53,331 - INFO - training batch 151, loss: 0.399, 4832/28000 datapoints
2025-03-06 21:53:53,474 - INFO - training batch 201, loss: 0.137, 6432/28000 datapoints
2025-03-06 21:53:53,620 - INFO - training batch 251, loss: 0.318, 8032/28000 datapoints
2025-03-06 21:53:53,762 - INFO - training batch 301, loss: 0.664, 9632/28000 datapoints
2025-03-06 21:53:53,908 - INFO - training batch 351, loss: 0.246, 11232/28000 datapoints
2025-03-06 21:53:54,053 - INFO - training batch 401, loss: 0.574, 12832/28000 datapoints
2025-03-06 21:53:54,196 - INFO - training batch 451, loss: 0.444, 14432/28000 datapoints
2025-03-06 21:53:54,342 - INFO - training batch 501, loss: 0.163, 16032/28000 datapoints
2025-03-06 21:53:54,485 - INFO - training batch 551, loss: 0.340, 17632/28000 datapoints
2025-03-06 21:53:54,645 - INFO - training batch 601, loss: 0.414, 19232/28000 datapoints
2025-03-06 21:53:54,789 - INFO - training batch 651, loss: 0.061, 20832/28000 datapoints
2025-03-06 21:53:54,939 - INFO - training batch 701, loss: 0.252, 22432/28000 datapoints
2025-03-06 21:53:55,091 - INFO - training batch 751, loss: 0.191, 24032/28000 datapoints
2025-03-06 21:53:55,241 - INFO - training batch 801, loss: 0.178, 25632/28000 datapoints
2025-03-06 21:53:55,390 - INFO - training batch 851, loss: 0.387, 27232/28000 datapoints
2025-03-06 21:53:55,462 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:55,512 - INFO - validation batch 51, loss: 1.572, 1632/6976 datapoints
2025-03-06 21:53:55,557 - INFO - validation batch 101, loss: 0.332, 3232/6976 datapoints
2025-03-06 21:53:55,607 - INFO - validation batch 151, loss: 0.509, 4832/6976 datapoints
2025-03-06 21:53:55,655 - INFO - validation batch 201, loss: 0.519, 6432/6976 datapoints
2025-03-06 21:53:55,671 - INFO - Epoch 199/800 done.
2025-03-06 21:53:55,671 - INFO - Final validation performance:
Loss: 0.612, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 21:53:55,672 - INFO - Beginning epoch 200/800
2025-03-06 21:53:55,675 - INFO - training batch 1, loss: 0.335, 32/28000 datapoints
2025-03-06 21:53:55,819 - INFO - training batch 51, loss: 0.198, 1632/28000 datapoints
2025-03-06 21:53:55,966 - INFO - training batch 101, loss: 0.138, 3232/28000 datapoints
2025-03-06 21:53:56,177 - INFO - training batch 151, loss: 0.393, 4832/28000 datapoints
2025-03-06 21:53:56,319 - INFO - training batch 201, loss: 0.136, 6432/28000 datapoints
2025-03-06 21:53:56,461 - INFO - training batch 251, loss: 0.317, 8032/28000 datapoints
2025-03-06 21:53:56,603 - INFO - training batch 301, loss: 0.663, 9632/28000 datapoints
2025-03-06 21:53:56,747 - INFO - training batch 351, loss: 0.245, 11232/28000 datapoints
2025-03-06 21:53:56,893 - INFO - training batch 401, loss: 0.572, 12832/28000 datapoints
2025-03-06 21:53:57,035 - INFO - training batch 451, loss: 0.443, 14432/28000 datapoints
2025-03-06 21:53:57,182 - INFO - training batch 501, loss: 0.163, 16032/28000 datapoints
2025-03-06 21:53:57,329 - INFO - training batch 551, loss: 0.337, 17632/28000 datapoints
2025-03-06 21:53:57,475 - INFO - training batch 601, loss: 0.408, 19232/28000 datapoints
2025-03-06 21:53:57,623 - INFO - training batch 651, loss: 0.060, 20832/28000 datapoints
2025-03-06 21:53:57,767 - INFO - training batch 701, loss: 0.251, 22432/28000 datapoints
2025-03-06 21:53:57,913 - INFO - training batch 751, loss: 0.189, 24032/28000 datapoints
2025-03-06 21:53:58,055 - INFO - training batch 801, loss: 0.178, 25632/28000 datapoints
2025-03-06 21:53:58,197 - INFO - training batch 851, loss: 0.383, 27232/28000 datapoints
2025-03-06 21:53:58,268 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:53:58,315 - INFO - validation batch 51, loss: 1.576, 1632/6976 datapoints
2025-03-06 21:53:58,360 - INFO - validation batch 101, loss: 0.334, 3232/6976 datapoints
2025-03-06 21:53:58,407 - INFO - validation batch 151, loss: 0.511, 4832/6976 datapoints
2025-03-06 21:53:58,453 - INFO - validation batch 201, loss: 0.517, 6432/6976 datapoints
2025-03-06 21:53:58,468 - INFO - Epoch 200/800 done.
2025-03-06 21:53:58,469 - INFO - Final validation performance:
Loss: 0.613, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 21:53:58,469 - INFO - Beginning epoch 201/800
2025-03-06 21:53:58,473 - INFO - training batch 1, loss: 0.335, 32/28000 datapoints
2025-03-06 21:53:58,642 - INFO - training batch 51, loss: 0.196, 1632/28000 datapoints
2025-03-06 21:53:58,790 - INFO - training batch 101, loss: 0.138, 3232/28000 datapoints
2025-03-06 21:53:58,937 - INFO - training batch 151, loss: 0.388, 4832/28000 datapoints
2025-03-06 21:53:59,092 - INFO - training batch 201, loss: 0.135, 6432/28000 datapoints
2025-03-06 21:53:59,238 - INFO - training batch 251, loss: 0.316, 8032/28000 datapoints
2025-03-06 21:53:59,381 - INFO - training batch 301, loss: 0.662, 9632/28000 datapoints
2025-03-06 21:53:59,528 - INFO - training batch 351, loss: 0.244, 11232/28000 datapoints
2025-03-06 21:53:59,672 - INFO - training batch 401, loss: 0.570, 12832/28000 datapoints
2025-03-06 21:53:59,815 - INFO - training batch 451, loss: 0.442, 14432/28000 datapoints
2025-03-06 21:53:59,965 - INFO - training batch 501, loss: 0.163, 16032/28000 datapoints
2025-03-06 21:54:00,110 - INFO - training batch 551, loss: 0.334, 17632/28000 datapoints
2025-03-06 21:54:00,255 - INFO - training batch 601, loss: 0.400, 19232/28000 datapoints
2025-03-06 21:54:00,409 - INFO - training batch 651, loss: 0.060, 20832/28000 datapoints
2025-03-06 21:54:00,552 - INFO - training batch 701, loss: 0.250, 22432/28000 datapoints
2025-03-06 21:54:00,705 - INFO - training batch 751, loss: 0.188, 24032/28000 datapoints
2025-03-06 21:54:00,857 - INFO - training batch 801, loss: 0.176, 25632/28000 datapoints
2025-03-06 21:54:01,089 - INFO - training batch 851, loss: 0.380, 27232/28000 datapoints
2025-03-06 21:54:01,163 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:54:01,211 - INFO - validation batch 51, loss: 1.579, 1632/6976 datapoints
2025-03-06 21:54:01,261 - INFO - validation batch 101, loss: 0.335, 3232/6976 datapoints
2025-03-06 21:54:01,309 - INFO - validation batch 151, loss: 0.511, 4832/6976 datapoints
2025-03-06 21:54:01,356 - INFO - validation batch 201, loss: 0.516, 6432/6976 datapoints
2025-03-06 21:54:01,372 - INFO - Epoch 201/800 done.
2025-03-06 21:54:01,372 - INFO - Final validation performance:
Loss: 0.614, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 21:54:01,373 - INFO - Beginning epoch 202/800
2025-03-06 21:54:01,377 - INFO - training batch 1, loss: 0.335, 32/28000 datapoints
2025-03-06 21:54:01,542 - INFO - training batch 51, loss: 0.194, 1632/28000 datapoints
2025-03-06 21:54:01,693 - INFO - training batch 101, loss: 0.136, 3232/28000 datapoints
2025-03-06 21:54:01,844 - INFO - training batch 151, loss: 0.382, 4832/28000 datapoints
2025-03-06 21:54:01,991 - INFO - training batch 201, loss: 0.135, 6432/28000 datapoints
2025-03-06 21:54:02,137 - INFO - training batch 251, loss: 0.315, 8032/28000 datapoints
2025-03-06 21:54:02,286 - INFO - training batch 301, loss: 0.659, 9632/28000 datapoints
2025-03-06 21:54:02,434 - INFO - training batch 351, loss: 0.243, 11232/28000 datapoints
2025-03-06 21:54:02,582 - INFO - training batch 401, loss: 0.568, 12832/28000 datapoints
2025-03-06 21:54:02,728 - INFO - training batch 451, loss: 0.441, 14432/28000 datapoints
2025-03-06 21:54:02,877 - INFO - training batch 501, loss: 0.162, 16032/28000 datapoints
2025-03-06 21:54:03,026 - INFO - training batch 551, loss: 0.331, 17632/28000 datapoints
2025-03-06 21:54:03,176 - INFO - training batch 601, loss: 0.393, 19232/28000 datapoints
2025-03-06 21:54:03,319 - INFO - training batch 651, loss: 0.059, 20832/28000 datapoints
2025-03-06 21:54:03,463 - INFO - training batch 701, loss: 0.248, 22432/28000 datapoints
2025-03-06 21:54:03,611 - INFO - training batch 751, loss: 0.186, 24032/28000 datapoints
2025-03-06 21:54:03,755 - INFO - training batch 801, loss: 0.175, 25632/28000 datapoints
2025-03-06 21:54:03,900 - INFO - training batch 851, loss: 0.376, 27232/28000 datapoints
2025-03-06 21:54:03,972 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:54:04,018 - INFO - validation batch 51, loss: 1.584, 1632/6976 datapoints
2025-03-06 21:54:04,064 - INFO - validation batch 101, loss: 0.337, 3232/6976 datapoints
2025-03-06 21:54:04,115 - INFO - validation batch 151, loss: 0.511, 4832/6976 datapoints
2025-03-06 21:54:04,165 - INFO - validation batch 201, loss: 0.515, 6432/6976 datapoints
2025-03-06 21:54:04,182 - INFO - Epoch 202/800 done.
2025-03-06 21:54:04,182 - INFO - Final validation performance:
Loss: 0.615, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 21:54:04,183 - INFO - Beginning epoch 203/800
2025-03-06 21:54:04,188 - INFO - training batch 1, loss: 0.333, 32/28000 datapoints
2025-03-06 21:54:04,337 - INFO - training batch 51, loss: 0.193, 1632/28000 datapoints
2025-03-06 21:54:04,481 - INFO - training batch 101, loss: 0.135, 3232/28000 datapoints
2025-03-06 21:54:04,623 - INFO - training batch 151, loss: 0.376, 4832/28000 datapoints
2025-03-06 21:54:04,766 - INFO - training batch 201, loss: 0.134, 6432/28000 datapoints
2025-03-06 21:54:04,912 - INFO - training batch 251, loss: 0.313, 8032/28000 datapoints
2025-03-06 21:54:05,057 - INFO - training batch 301, loss: 0.658, 9632/28000 datapoints
2025-03-06 21:54:05,206 - INFO - training batch 351, loss: 0.241, 11232/28000 datapoints
2025-03-06 21:54:05,351 - INFO - training batch 401, loss: 0.565, 12832/28000 datapoints
2025-03-06 21:54:05,494 - INFO - training batch 451, loss: 0.440, 14432/28000 datapoints
2025-03-06 21:54:05,640 - INFO - training batch 501, loss: 0.162, 16032/28000 datapoints
2025-03-06 21:54:05,784 - INFO - training batch 551, loss: 0.328, 17632/28000 datapoints
2025-03-06 21:54:05,931 - INFO - training batch 601, loss: 0.386, 19232/28000 datapoints
2025-03-06 21:54:06,075 - INFO - training batch 651, loss: 0.059, 20832/28000 datapoints
2025-03-06 21:54:06,219 - INFO - training batch 701, loss: 0.247, 22432/28000 datapoints
2025-03-06 21:54:06,362 - INFO - training batch 751, loss: 0.186, 24032/28000 datapoints
2025-03-06 21:54:06,506 - INFO - training batch 801, loss: 0.173, 25632/28000 datapoints
2025-03-06 21:54:06,649 - INFO - training batch 851, loss: 0.372, 27232/28000 datapoints
2025-03-06 21:54:06,719 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:54:06,766 - INFO - validation batch 51, loss: 1.589, 1632/6976 datapoints
2025-03-06 21:54:06,813 - INFO - validation batch 101, loss: 0.339, 3232/6976 datapoints
2025-03-06 21:54:06,865 - INFO - validation batch 151, loss: 0.512, 4832/6976 datapoints
2025-03-06 21:54:06,918 - INFO - validation batch 201, loss: 0.515, 6432/6976 datapoints
2025-03-06 21:54:06,937 - INFO - Epoch 203/800 done.
2025-03-06 21:54:06,937 - INFO - Final validation performance:
Loss: 0.616, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 21:54:06,938 - INFO - Beginning epoch 204/800
2025-03-06 21:54:06,942 - INFO - training batch 1, loss: 0.332, 32/28000 datapoints
2025-03-06 21:54:07,086 - INFO - training batch 51, loss: 0.192, 1632/28000 datapoints
2025-03-06 21:54:07,229 - INFO - training batch 101, loss: 0.134, 3232/28000 datapoints
2025-03-06 21:54:07,380 - INFO - training batch 151, loss: 0.369, 4832/28000 datapoints
2025-03-06 21:54:07,529 - INFO - training batch 201, loss: 0.133, 6432/28000 datapoints
2025-03-06 21:54:07,675 - INFO - training batch 251, loss: 0.311, 8032/28000 datapoints
2025-03-06 21:54:07,819 - INFO - training batch 301, loss: 0.656, 9632/28000 datapoints
2025-03-06 21:54:07,965 - INFO - training batch 351, loss: 0.241, 11232/28000 datapoints
2025-03-06 21:54:08,108 - INFO - training batch 401, loss: 0.563, 12832/28000 datapoints
2025-03-06 21:54:08,251 - INFO - training batch 451, loss: 0.439, 14432/28000 datapoints
2025-03-06 21:54:08,395 - INFO - training batch 501, loss: 0.162, 16032/28000 datapoints
2025-03-06 21:54:08,540 - INFO - training batch 551, loss: 0.325, 17632/28000 datapoints
2025-03-06 21:54:08,704 - INFO - training batch 601, loss: 0.379, 19232/28000 datapoints
2025-03-06 21:54:08,856 - INFO - training batch 651, loss: 0.058, 20832/28000 datapoints
2025-03-06 21:54:08,999 - INFO - training batch 701, loss: 0.246, 22432/28000 datapoints
2025-03-06 21:54:09,143 - INFO - training batch 751, loss: 0.185, 24032/28000 datapoints
2025-03-06 21:54:09,291 - INFO - training batch 801, loss: 0.172, 25632/28000 datapoints
2025-03-06 21:54:09,433 - INFO - training batch 851, loss: 0.367, 27232/28000 datapoints
2025-03-06 21:54:09,504 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:54:09,553 - INFO - validation batch 51, loss: 1.593, 1632/6976 datapoints
2025-03-06 21:54:09,598 - INFO - validation batch 101, loss: 0.341, 3232/6976 datapoints
2025-03-06 21:54:09,644 - INFO - validation batch 151, loss: 0.511, 4832/6976 datapoints
2025-03-06 21:54:09,690 - INFO - validation batch 201, loss: 0.513, 6432/6976 datapoints
2025-03-06 21:54:09,705 - INFO - Epoch 204/800 done.
2025-03-06 21:54:09,705 - INFO - Final validation performance:
Loss: 0.617, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 21:54:09,706 - INFO - Beginning epoch 205/800
2025-03-06 21:54:09,710 - INFO - training batch 1, loss: 0.331, 32/28000 datapoints
2025-03-06 21:54:09,861 - INFO - training batch 51, loss: 0.190, 1632/28000 datapoints
2025-03-06 21:54:10,004 - INFO - training batch 101, loss: 0.132, 3232/28000 datapoints
2025-03-06 21:54:10,148 - INFO - training batch 151, loss: 0.363, 4832/28000 datapoints
2025-03-06 21:54:10,293 - INFO - training batch 201, loss: 0.132, 6432/28000 datapoints
2025-03-06 21:54:10,436 - INFO - training batch 251, loss: 0.310, 8032/28000 datapoints
2025-03-06 21:54:10,581 - INFO - training batch 301, loss: 0.654, 9632/28000 datapoints
2025-03-06 21:54:10,723 - INFO - training batch 351, loss: 0.239, 11232/28000 datapoints
2025-03-06 21:54:10,871 - INFO - training batch 401, loss: 0.561, 12832/28000 datapoints
2025-03-06 21:54:11,014 - INFO - training batch 451, loss: 0.438, 14432/28000 datapoints
2025-03-06 21:54:11,157 - INFO - training batch 501, loss: 0.162, 16032/28000 datapoints
2025-03-06 21:54:11,301 - INFO - training batch 551, loss: 0.322, 17632/28000 datapoints
2025-03-06 21:54:11,445 - INFO - training batch 601, loss: 0.372, 19232/28000 datapoints
2025-03-06 21:54:11,592 - INFO - training batch 651, loss: 0.058, 20832/28000 datapoints
2025-03-06 21:54:11,736 - INFO - training batch 701, loss: 0.245, 22432/28000 datapoints
2025-03-06 21:54:11,885 - INFO - training batch 751, loss: 0.184, 24032/28000 datapoints
2025-03-06 21:54:12,031 - INFO - training batch 801, loss: 0.172, 25632/28000 datapoints
2025-03-06 21:54:12,174 - INFO - training batch 851, loss: 0.365, 27232/28000 datapoints
2025-03-06 21:54:12,245 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:54:12,291 - INFO - validation batch 51, loss: 1.596, 1632/6976 datapoints
2025-03-06 21:54:12,338 - INFO - validation batch 101, loss: 0.343, 3232/6976 datapoints
2025-03-06 21:54:12,386 - INFO - validation batch 151, loss: 0.512, 4832/6976 datapoints
2025-03-06 21:54:12,433 - INFO - validation batch 201, loss: 0.511, 6432/6976 datapoints
2025-03-06 21:54:12,449 - INFO - Epoch 205/800 done.
2025-03-06 21:54:12,449 - INFO - Final validation performance:
Loss: 0.618, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 21:54:12,450 - INFO - Beginning epoch 206/800
2025-03-06 21:54:12,454 - INFO - training batch 1, loss: 0.330, 32/28000 datapoints
2025-03-06 21:54:12,597 - INFO - training batch 51, loss: 0.187, 1632/28000 datapoints
2025-03-06 21:54:12,743 - INFO - training batch 101, loss: 0.131, 3232/28000 datapoints
2025-03-06 21:54:12,892 - INFO - training batch 151, loss: 0.356, 4832/28000 datapoints
2025-03-06 21:54:13,074 - INFO - training batch 201, loss: 0.132, 6432/28000 datapoints
2025-03-06 21:54:13,224 - INFO - training batch 251, loss: 0.310, 8032/28000 datapoints
2025-03-06 21:54:13,373 - INFO - training batch 301, loss: 0.653, 9632/28000 datapoints
2025-03-06 21:54:13,525 - INFO - training batch 351, loss: 0.238, 11232/28000 datapoints
2025-03-06 21:54:13,677 - INFO - training batch 401, loss: 0.559, 12832/28000 datapoints
2025-03-06 21:54:13,824 - INFO - training batch 451, loss: 0.437, 14432/28000 datapoints
2025-03-06 21:54:13,975 - INFO - training batch 501, loss: 0.162, 16032/28000 datapoints
2025-03-06 21:54:14,118 - INFO - training batch 551, loss: 0.320, 17632/28000 datapoints
2025-03-06 21:54:14,261 - INFO - training batch 601, loss: 0.366, 19232/28000 datapoints
2025-03-06 21:54:14,409 - INFO - training batch 651, loss: 0.057, 20832/28000 datapoints
2025-03-06 21:54:14,551 - INFO - training batch 701, loss: 0.244, 22432/28000 datapoints
2025-03-06 21:54:14,695 - INFO - training batch 751, loss: 0.184, 24032/28000 datapoints
2025-03-06 21:54:14,880 - INFO - training batch 801, loss: 0.169, 25632/28000 datapoints
2025-03-06 21:54:15,029 - INFO - training batch 851, loss: 0.361, 27232/28000 datapoints
2025-03-06 21:54:15,104 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:54:15,154 - INFO - validation batch 51, loss: 1.602, 1632/6976 datapoints
2025-03-06 21:54:15,200 - INFO - validation batch 101, loss: 0.345, 3232/6976 datapoints
2025-03-06 21:54:15,247 - INFO - validation batch 151, loss: 0.512, 4832/6976 datapoints
2025-03-06 21:54:15,296 - INFO - validation batch 201, loss: 0.512, 6432/6976 datapoints
2025-03-06 21:54:15,311 - INFO - Epoch 206/800 done.
2025-03-06 21:54:15,312 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 21:54:15,312 - INFO - Beginning epoch 207/800
2025-03-06 21:54:15,316 - INFO - training batch 1, loss: 0.330, 32/28000 datapoints
2025-03-06 21:54:15,467 - INFO - training batch 51, loss: 0.186, 1632/28000 datapoints
2025-03-06 21:54:15,621 - INFO - training batch 101, loss: 0.130, 3232/28000 datapoints
2025-03-06 21:54:15,773 - INFO - training batch 151, loss: 0.351, 4832/28000 datapoints
2025-03-06 21:54:15,923 - INFO - training batch 201, loss: 0.130, 6432/28000 datapoints
2025-03-06 21:54:16,070 - INFO - training batch 251, loss: 0.307, 8032/28000 datapoints
2025-03-06 21:54:16,216 - INFO - training batch 301, loss: 0.651, 9632/28000 datapoints
2025-03-06 21:54:16,362 - INFO - training batch 351, loss: 0.237, 11232/28000 datapoints
2025-03-06 21:54:16,509 - INFO - training batch 401, loss: 0.557, 12832/28000 datapoints
2025-03-06 21:54:16,656 - INFO - training batch 451, loss: 0.436, 14432/28000 datapoints
2025-03-06 21:54:16,802 - INFO - training batch 501, loss: 0.161, 16032/28000 datapoints
2025-03-06 21:54:16,950 - INFO - training batch 551, loss: 0.316, 17632/28000 datapoints
2025-03-06 21:54:17,093 - INFO - training batch 601, loss: 0.358, 19232/28000 datapoints
2025-03-06 21:54:17,237 - INFO - training batch 651, loss: 0.057, 20832/28000 datapoints
2025-03-06 21:54:17,379 - INFO - training batch 701, loss: 0.242, 22432/28000 datapoints
2025-03-06 21:54:17,525 - INFO - training batch 751, loss: 0.183, 24032/28000 datapoints
2025-03-06 21:54:17,672 - INFO - training batch 801, loss: 0.169, 25632/28000 datapoints
2025-03-06 21:54:17,816 - INFO - training batch 851, loss: 0.357, 27232/28000 datapoints
2025-03-06 21:54:17,890 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:54:17,936 - INFO - validation batch 51, loss: 1.606, 1632/6976 datapoints
2025-03-06 21:54:17,983 - INFO - validation batch 101, loss: 0.346, 3232/6976 datapoints
2025-03-06 21:54:18,030 - INFO - validation batch 151, loss: 0.513, 4832/6976 datapoints
2025-03-06 21:54:18,076 - INFO - validation batch 201, loss: 0.511, 6432/6976 datapoints
2025-03-06 21:54:18,092 - INFO - Epoch 207/800 done.
2025-03-06 21:54:18,092 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 21:54:18,093 - INFO - Beginning epoch 208/800
2025-03-06 21:54:18,097 - INFO - training batch 1, loss: 0.328, 32/28000 datapoints
2025-03-06 21:54:18,242 - INFO - training batch 51, loss: 0.184, 1632/28000 datapoints
2025-03-06 21:54:18,383 - INFO - training batch 101, loss: 0.129, 3232/28000 datapoints
2025-03-06 21:54:18,529 - INFO - training batch 151, loss: 0.346, 4832/28000 datapoints
2025-03-06 21:54:18,671 - INFO - training batch 201, loss: 0.130, 6432/28000 datapoints
2025-03-06 21:54:18,842 - INFO - training batch 251, loss: 0.306, 8032/28000 datapoints
2025-03-06 21:54:19,010 - INFO - training batch 301, loss: 0.650, 9632/28000 datapoints
2025-03-06 21:54:19,183 - INFO - training batch 351, loss: 0.236, 11232/28000 datapoints
2025-03-06 21:54:19,327 - INFO - training batch 401, loss: 0.555, 12832/28000 datapoints
2025-03-06 21:54:19,471 - INFO - training batch 451, loss: 0.436, 14432/28000 datapoints
2025-03-06 21:54:19,624 - INFO - training batch 501, loss: 0.161, 16032/28000 datapoints
2025-03-06 21:54:19,771 - INFO - training batch 551, loss: 0.313, 17632/28000 datapoints
2025-03-06 21:54:19,927 - INFO - training batch 601, loss: 0.353, 19232/28000 datapoints
2025-03-06 21:54:20,074 - INFO - training batch 651, loss: 0.056, 20832/28000 datapoints
2025-03-06 21:54:20,220 - INFO - training batch 701, loss: 0.240, 22432/28000 datapoints
2025-03-06 21:54:20,361 - INFO - training batch 751, loss: 0.182, 24032/28000 datapoints
2025-03-06 21:54:20,507 - INFO - training batch 801, loss: 0.167, 25632/28000 datapoints
2025-03-06 21:54:20,650 - INFO - training batch 851, loss: 0.352, 27232/28000 datapoints
2025-03-06 21:54:20,720 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:54:20,766 - INFO - validation batch 51, loss: 1.611, 1632/6976 datapoints
2025-03-06 21:54:20,812 - INFO - validation batch 101, loss: 0.348, 3232/6976 datapoints
2025-03-06 21:54:20,860 - INFO - validation batch 151, loss: 0.513, 4832/6976 datapoints
2025-03-06 21:54:20,909 - INFO - validation batch 201, loss: 0.510, 6432/6976 datapoints
2025-03-06 21:54:20,926 - INFO - Epoch 208/800 done.
2025-03-06 21:54:20,926 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 21:54:20,927 - INFO - Beginning epoch 209/800
2025-03-06 21:54:20,931 - INFO - training batch 1, loss: 0.327, 32/28000 datapoints
2025-03-06 21:54:21,076 - INFO - training batch 51, loss: 0.183, 1632/28000 datapoints
2025-03-06 21:54:21,221 - INFO - training batch 101, loss: 0.127, 3232/28000 datapoints
2025-03-06 21:54:21,366 - INFO - training batch 151, loss: 0.339, 4832/28000 datapoints
2025-03-06 21:54:21,512 - INFO - training batch 201, loss: 0.128, 6432/28000 datapoints
2025-03-06 21:54:21,659 - INFO - training batch 251, loss: 0.305, 8032/28000 datapoints
2025-03-06 21:54:21,805 - INFO - training batch 301, loss: 0.648, 9632/28000 datapoints
2025-03-06 21:54:21,953 - INFO - training batch 351, loss: 0.234, 11232/28000 datapoints
2025-03-06 21:54:22,098 - INFO - training batch 401, loss: 0.552, 12832/28000 datapoints
2025-03-06 21:54:22,241 - INFO - training batch 451, loss: 0.435, 14432/28000 datapoints
2025-03-06 21:54:22,387 - INFO - training batch 501, loss: 0.161, 16032/28000 datapoints
2025-03-06 21:54:22,532 - INFO - training batch 551, loss: 0.311, 17632/28000 datapoints
2025-03-06 21:54:22,675 - INFO - training batch 601, loss: 0.346, 19232/28000 datapoints
2025-03-06 21:54:22,823 - INFO - training batch 651, loss: 0.056, 20832/28000 datapoints
2025-03-06 21:54:22,971 - INFO - training batch 701, loss: 0.239, 22432/28000 datapoints
2025-03-06 21:54:23,119 - INFO - training batch 751, loss: 0.181, 24032/28000 datapoints
2025-03-06 21:54:23,261 - INFO - training batch 801, loss: 0.167, 25632/28000 datapoints
2025-03-06 21:54:23,403 - INFO - training batch 851, loss: 0.349, 27232/28000 datapoints
2025-03-06 21:54:23,476 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:54:23,522 - INFO - validation batch 51, loss: 1.614, 1632/6976 datapoints
2025-03-06 21:54:23,568 - INFO - validation batch 101, loss: 0.350, 3232/6976 datapoints
2025-03-06 21:54:23,616 - INFO - validation batch 151, loss: 0.514, 4832/6976 datapoints
2025-03-06 21:54:23,663 - INFO - validation batch 201, loss: 0.509, 6432/6976 datapoints
2025-03-06 21:54:23,679 - INFO - Epoch 209/800 done.
2025-03-06 21:54:23,679 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 21:54:23,680 - INFO - Beginning epoch 210/800
2025-03-06 21:54:23,684 - INFO - training batch 1, loss: 0.326, 32/28000 datapoints
2025-03-06 21:54:23,830 - INFO - training batch 51, loss: 0.181, 1632/28000 datapoints
2025-03-06 21:54:23,983 - INFO - training batch 101, loss: 0.127, 3232/28000 datapoints
2025-03-06 21:54:24,131 - INFO - training batch 151, loss: 0.335, 4832/28000 datapoints
2025-03-06 21:54:24,276 - INFO - training batch 201, loss: 0.128, 6432/28000 datapoints
2025-03-06 21:54:24,420 - INFO - training batch 251, loss: 0.305, 8032/28000 datapoints
2025-03-06 21:54:24,564 - INFO - training batch 301, loss: 0.648, 9632/28000 datapoints
2025-03-06 21:54:24,708 - INFO - training batch 351, loss: 0.233, 11232/28000 datapoints
2025-03-06 21:54:24,852 - INFO - training batch 401, loss: 0.550, 12832/28000 datapoints
2025-03-06 21:54:24,996 - INFO - training batch 451, loss: 0.434, 14432/28000 datapoints
2025-03-06 21:54:25,147 - INFO - training batch 501, loss: 0.160, 16032/28000 datapoints
2025-03-06 21:54:25,304 - INFO - training batch 551, loss: 0.308, 17632/28000 datapoints
2025-03-06 21:54:25,446 - INFO - training batch 601, loss: 0.339, 19232/28000 datapoints
2025-03-06 21:54:25,592 - INFO - training batch 651, loss: 0.055, 20832/28000 datapoints
2025-03-06 21:54:25,750 - INFO - training batch 701, loss: 0.238, 22432/28000 datapoints
2025-03-06 21:54:25,904 - INFO - training batch 751, loss: 0.180, 24032/28000 datapoints
2025-03-06 21:54:26,053 - INFO - training batch 801, loss: 0.166, 25632/28000 datapoints
2025-03-06 21:54:26,204 - INFO - training batch 851, loss: 0.347, 27232/28000 datapoints
2025-03-06 21:54:26,276 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:54:26,324 - INFO - validation batch 51, loss: 1.620, 1632/6976 datapoints
2025-03-06 21:54:26,371 - INFO - validation batch 101, loss: 0.353, 3232/6976 datapoints
2025-03-06 21:54:26,418 - INFO - validation batch 151, loss: 0.515, 4832/6976 datapoints
2025-03-06 21:54:26,465 - INFO - validation batch 201, loss: 0.509, 6432/6976 datapoints
2025-03-06 21:54:26,482 - INFO - Epoch 210/800 done.
2025-03-06 21:54:26,482 - INFO - Final validation performance:
Loss: 0.625, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 21:54:26,483 - INFO - Beginning epoch 211/800
2025-03-06 21:54:26,487 - INFO - training batch 1, loss: 0.324, 32/28000 datapoints
2025-03-06 21:54:26,639 - INFO - training batch 51, loss: 0.179, 1632/28000 datapoints
2025-03-06 21:54:26,785 - INFO - training batch 101, loss: 0.126, 3232/28000 datapoints
2025-03-06 21:54:26,936 - INFO - training batch 151, loss: 0.330, 4832/28000 datapoints
2025-03-06 21:54:27,086 - INFO - training batch 201, loss: 0.127, 6432/28000 datapoints
2025-03-06 21:54:27,232 - INFO - training batch 251, loss: 0.303, 8032/28000 datapoints
2025-03-06 21:54:27,378 - INFO - training batch 301, loss: 0.645, 9632/28000 datapoints
2025-03-06 21:54:27,522 - INFO - training batch 351, loss: 0.231, 11232/28000 datapoints
2025-03-06 21:54:27,670 - INFO - training batch 401, loss: 0.548, 12832/28000 datapoints
2025-03-06 21:54:27,813 - INFO - training batch 451, loss: 0.433, 14432/28000 datapoints
2025-03-06 21:54:27,959 - INFO - training batch 501, loss: 0.161, 16032/28000 datapoints
2025-03-06 21:54:28,105 - INFO - training batch 551, loss: 0.305, 17632/28000 datapoints
2025-03-06 21:54:28,249 - INFO - training batch 601, loss: 0.333, 19232/28000 datapoints
2025-03-06 21:54:28,397 - INFO - training batch 651, loss: 0.055, 20832/28000 datapoints
2025-03-06 21:54:28,541 - INFO - training batch 701, loss: 0.236, 22432/28000 datapoints
2025-03-06 21:54:28,683 - INFO - training batch 751, loss: 0.180, 24032/28000 datapoints
2025-03-06 21:54:28,839 - INFO - training batch 801, loss: 0.165, 25632/28000 datapoints
2025-03-06 21:54:28,996 - INFO - training batch 851, loss: 0.342, 27232/28000 datapoints
2025-03-06 21:54:29,069 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:54:29,114 - INFO - validation batch 51, loss: 1.625, 1632/6976 datapoints
2025-03-06 21:54:29,161 - INFO - validation batch 101, loss: 0.355, 3232/6976 datapoints
2025-03-06 21:54:29,209 - INFO - validation batch 151, loss: 0.514, 4832/6976 datapoints
2025-03-06 21:54:29,255 - INFO - validation batch 201, loss: 0.507, 6432/6976 datapoints
2025-03-06 21:54:29,271 - INFO - Epoch 211/800 done.
2025-03-06 21:54:29,271 - INFO - Final validation performance:
Loss: 0.626, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 21:54:29,272 - INFO - Beginning epoch 212/800
2025-03-06 21:54:29,275 - INFO - training batch 1, loss: 0.323, 32/28000 datapoints
2025-03-06 21:54:29,423 - INFO - training batch 51, loss: 0.177, 1632/28000 datapoints
2025-03-06 21:54:29,568 - INFO - training batch 101, loss: 0.124, 3232/28000 datapoints
2025-03-06 21:54:29,717 - INFO - training batch 151, loss: 0.324, 4832/28000 datapoints
2025-03-06 21:54:29,862 - INFO - training batch 201, loss: 0.126, 6432/28000 datapoints
2025-03-06 21:54:30,005 - INFO - training batch 251, loss: 0.303, 8032/28000 datapoints
2025-03-06 21:54:30,150 - INFO - training batch 301, loss: 0.644, 9632/28000 datapoints
2025-03-06 21:54:30,294 - INFO - training batch 351, loss: 0.230, 11232/28000 datapoints
2025-03-06 21:54:30,436 - INFO - training batch 401, loss: 0.545, 12832/28000 datapoints
2025-03-06 21:54:30,581 - INFO - training batch 451, loss: 0.431, 14432/28000 datapoints
2025-03-06 21:54:30,726 - INFO - training batch 501, loss: 0.160, 16032/28000 datapoints
2025-03-06 21:54:30,872 - INFO - training batch 551, loss: 0.303, 17632/28000 datapoints
2025-03-06 21:54:31,016 - INFO - training batch 601, loss: 0.327, 19232/28000 datapoints
2025-03-06 21:54:31,164 - INFO - training batch 651, loss: 0.054, 20832/28000 datapoints
2025-03-06 21:54:31,306 - INFO - training batch 701, loss: 0.235, 22432/28000 datapoints
2025-03-06 21:54:31,462 - INFO - training batch 751, loss: 0.179, 24032/28000 datapoints
2025-03-06 21:54:31,605 - INFO - training batch 801, loss: 0.164, 25632/28000 datapoints
2025-03-06 21:54:31,758 - INFO - training batch 851, loss: 0.340, 27232/28000 datapoints
2025-03-06 21:54:31,834 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:54:31,887 - INFO - validation batch 51, loss: 1.628, 1632/6976 datapoints
2025-03-06 21:54:31,934 - INFO - validation batch 101, loss: 0.357, 3232/6976 datapoints
2025-03-06 21:54:31,982 - INFO - validation batch 151, loss: 0.516, 4832/6976 datapoints
2025-03-06 21:54:32,028 - INFO - validation batch 201, loss: 0.507, 6432/6976 datapoints
2025-03-06 21:54:32,045 - INFO - Epoch 212/800 done.
2025-03-06 21:54:32,045 - INFO - Final validation performance:
Loss: 0.627, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 21:54:32,046 - INFO - Beginning epoch 213/800
2025-03-06 21:54:32,050 - INFO - training batch 1, loss: 0.322, 32/28000 datapoints
2025-03-06 21:54:32,202 - INFO - training batch 51, loss: 0.175, 1632/28000 datapoints
2025-03-06 21:54:32,345 - INFO - training batch 101, loss: 0.124, 3232/28000 datapoints
2025-03-06 21:54:32,491 - INFO - training batch 151, loss: 0.318, 4832/28000 datapoints
2025-03-06 21:54:32,635 - INFO - training batch 201, loss: 0.126, 6432/28000 datapoints
2025-03-06 21:54:32,778 - INFO - training batch 251, loss: 0.301, 8032/28000 datapoints
2025-03-06 21:54:32,924 - INFO - training batch 301, loss: 0.643, 9632/28000 datapoints
2025-03-06 21:54:33,072 - INFO - training batch 351, loss: 0.229, 11232/28000 datapoints
2025-03-06 21:54:33,224 - INFO - training batch 401, loss: 0.543, 12832/28000 datapoints
2025-03-06 21:54:33,366 - INFO - training batch 451, loss: 0.430, 14432/28000 datapoints
2025-03-06 21:54:33,509 - INFO - training batch 501, loss: 0.160, 16032/28000 datapoints
2025-03-06 21:54:33,659 - INFO - training batch 551, loss: 0.300, 17632/28000 datapoints
2025-03-06 21:54:33,801 - INFO - training batch 601, loss: 0.320, 19232/28000 datapoints
2025-03-06 21:54:33,948 - INFO - training batch 651, loss: 0.054, 20832/28000 datapoints
2025-03-06 21:54:34,091 - INFO - training batch 701, loss: 0.234, 22432/28000 datapoints
2025-03-06 21:54:34,234 - INFO - training batch 751, loss: 0.179, 24032/28000 datapoints
2025-03-06 21:54:34,379 - INFO - training batch 801, loss: 0.162, 25632/28000 datapoints
2025-03-06 21:54:34,521 - INFO - training batch 851, loss: 0.336, 27232/28000 datapoints
2025-03-06 21:54:34,591 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:54:34,638 - INFO - validation batch 51, loss: 1.632, 1632/6976 datapoints
2025-03-06 21:54:34,685 - INFO - validation batch 101, loss: 0.359, 3232/6976 datapoints
2025-03-06 21:54:34,730 - INFO - validation batch 151, loss: 0.514, 4832/6976 datapoints
2025-03-06 21:54:34,776 - INFO - validation batch 201, loss: 0.505, 6432/6976 datapoints
2025-03-06 21:54:34,792 - INFO - Epoch 213/800 done.
2025-03-06 21:54:34,792 - INFO - Final validation performance:
Loss: 0.627, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 21:54:34,792 - INFO - Beginning epoch 214/800
2025-03-06 21:54:34,796 - INFO - training batch 1, loss: 0.321, 32/28000 datapoints
2025-03-06 21:54:34,944 - INFO - training batch 51, loss: 0.172, 1632/28000 datapoints
2025-03-06 21:54:35,094 - INFO - training batch 101, loss: 0.122, 3232/28000 datapoints
2025-03-06 21:54:35,247 - INFO - training batch 151, loss: 0.312, 4832/28000 datapoints
2025-03-06 21:54:35,392 - INFO - training batch 201, loss: 0.125, 6432/28000 datapoints
2025-03-06 21:54:35,535 - INFO - training batch 251, loss: 0.300, 8032/28000 datapoints
2025-03-06 21:54:35,690 - INFO - training batch 301, loss: 0.641, 9632/28000 datapoints
2025-03-06 21:54:35,832 - INFO - training batch 351, loss: 0.228, 11232/28000 datapoints
2025-03-06 21:54:35,978 - INFO - training batch 401, loss: 0.540, 12832/28000 datapoints
2025-03-06 21:54:36,122 - INFO - training batch 451, loss: 0.429, 14432/28000 datapoints
2025-03-06 21:54:36,266 - INFO - training batch 501, loss: 0.159, 16032/28000 datapoints
2025-03-06 21:54:36,411 - INFO - training batch 551, loss: 0.298, 17632/28000 datapoints
2025-03-06 21:54:36,554 - INFO - training batch 601, loss: 0.316, 19232/28000 datapoints
2025-03-06 21:54:36,701 - INFO - training batch 651, loss: 0.053, 20832/28000 datapoints
2025-03-06 21:54:36,846 - INFO - training batch 701, loss: 0.233, 22432/28000 datapoints
2025-03-06 21:54:36,988 - INFO - training batch 751, loss: 0.178, 24032/28000 datapoints
2025-03-06 21:54:37,138 - INFO - training batch 801, loss: 0.162, 25632/28000 datapoints
2025-03-06 21:54:37,281 - INFO - training batch 851, loss: 0.333, 27232/28000 datapoints
2025-03-06 21:54:37,352 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:54:37,399 - INFO - validation batch 51, loss: 1.637, 1632/6976 datapoints
2025-03-06 21:54:37,445 - INFO - validation batch 101, loss: 0.361, 3232/6976 datapoints
2025-03-06 21:54:37,491 - INFO - validation batch 151, loss: 0.517, 4832/6976 datapoints
2025-03-06 21:54:37,548 - INFO - validation batch 201, loss: 0.505, 6432/6976 datapoints
2025-03-06 21:54:37,564 - INFO - Epoch 214/800 done.
2025-03-06 21:54:37,565 - INFO - Final validation performance:
Loss: 0.629, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:54:37,565 - INFO - Beginning epoch 215/800
2025-03-06 21:54:37,569 - INFO - training batch 1, loss: 0.319, 32/28000 datapoints
2025-03-06 21:54:37,724 - INFO - training batch 51, loss: 0.170, 1632/28000 datapoints
2025-03-06 21:54:37,878 - INFO - training batch 101, loss: 0.122, 3232/28000 datapoints
2025-03-06 21:54:38,028 - INFO - training batch 151, loss: 0.306, 4832/28000 datapoints
2025-03-06 21:54:38,178 - INFO - training batch 201, loss: 0.124, 6432/28000 datapoints
2025-03-06 21:54:38,323 - INFO - training batch 251, loss: 0.300, 8032/28000 datapoints
2025-03-06 21:54:38,469 - INFO - training batch 301, loss: 0.639, 9632/28000 datapoints
2025-03-06 21:54:38,615 - INFO - training batch 351, loss: 0.227, 11232/28000 datapoints
2025-03-06 21:54:38,761 - INFO - training batch 401, loss: 0.539, 12832/28000 datapoints
2025-03-06 21:54:38,918 - INFO - training batch 451, loss: 0.428, 14432/28000 datapoints
2025-03-06 21:54:39,080 - INFO - training batch 501, loss: 0.159, 16032/28000 datapoints
2025-03-06 21:54:39,230 - INFO - training batch 551, loss: 0.295, 17632/28000 datapoints
2025-03-06 21:54:39,382 - INFO - training batch 601, loss: 0.308, 19232/28000 datapoints
2025-03-06 21:54:39,530 - INFO - training batch 651, loss: 0.052, 20832/28000 datapoints
2025-03-06 21:54:39,683 - INFO - training batch 701, loss: 0.231, 22432/28000 datapoints
2025-03-06 21:54:39,830 - INFO - training batch 751, loss: 0.178, 24032/28000 datapoints
2025-03-06 21:54:39,982 - INFO - training batch 801, loss: 0.160, 25632/28000 datapoints
2025-03-06 21:54:40,129 - INFO - training batch 851, loss: 0.329, 27232/28000 datapoints
2025-03-06 21:54:40,202 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:54:40,248 - INFO - validation batch 51, loss: 1.642, 1632/6976 datapoints
2025-03-06 21:54:40,295 - INFO - validation batch 101, loss: 0.363, 3232/6976 datapoints
2025-03-06 21:54:40,340 - INFO - validation batch 151, loss: 0.518, 4832/6976 datapoints
2025-03-06 21:54:40,386 - INFO - validation batch 201, loss: 0.504, 6432/6976 datapoints
2025-03-06 21:54:40,402 - INFO - Epoch 215/800 done.
2025-03-06 21:54:40,402 - INFO - Final validation performance:
Loss: 0.631, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:54:40,403 - INFO - Beginning epoch 216/800
2025-03-06 21:54:40,407 - INFO - training batch 1, loss: 0.318, 32/28000 datapoints
2025-03-06 21:54:40,551 - INFO - training batch 51, loss: 0.167, 1632/28000 datapoints
2025-03-06 21:54:40,695 - INFO - training batch 101, loss: 0.122, 3232/28000 datapoints
2025-03-06 21:54:40,843 - INFO - training batch 151, loss: 0.300, 4832/28000 datapoints
2025-03-06 21:54:40,986 - INFO - training batch 201, loss: 0.124, 6432/28000 datapoints
2025-03-06 21:54:41,128 - INFO - training batch 251, loss: 0.299, 8032/28000 datapoints
2025-03-06 21:54:41,272 - INFO - training batch 301, loss: 0.638, 9632/28000 datapoints
2025-03-06 21:54:41,414 - INFO - training batch 351, loss: 0.225, 11232/28000 datapoints
2025-03-06 21:54:41,558 - INFO - training batch 401, loss: 0.536, 12832/28000 datapoints
2025-03-06 21:54:41,705 - INFO - training batch 451, loss: 0.426, 14432/28000 datapoints
2025-03-06 21:54:41,852 - INFO - training batch 501, loss: 0.159, 16032/28000 datapoints
2025-03-06 21:54:42,003 - INFO - training batch 551, loss: 0.292, 17632/28000 datapoints
2025-03-06 21:54:42,146 - INFO - training batch 601, loss: 0.302, 19232/28000 datapoints
2025-03-06 21:54:42,291 - INFO - training batch 651, loss: 0.052, 20832/28000 datapoints
2025-03-06 21:54:42,436 - INFO - training batch 701, loss: 0.230, 22432/28000 datapoints
2025-03-06 21:54:42,579 - INFO - training batch 751, loss: 0.177, 24032/28000 datapoints
2025-03-06 21:54:42,723 - INFO - training batch 801, loss: 0.160, 25632/28000 datapoints
2025-03-06 21:54:42,867 - INFO - training batch 851, loss: 0.325, 27232/28000 datapoints
2025-03-06 21:54:42,938 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 21:54:42,984 - INFO - validation batch 51, loss: 1.644, 1632/6976 datapoints
2025-03-06 21:54:43,029 - INFO - validation batch 101, loss: 0.365, 3232/6976 datapoints
2025-03-06 21:54:43,075 - INFO - validation batch 151, loss: 0.519, 4832/6976 datapoints
2025-03-06 21:54:43,122 - INFO - validation batch 201, loss: 0.503, 6432/6976 datapoints
2025-03-06 21:54:43,141 - INFO - Epoch 216/800 done.
2025-03-06 21:54:43,141 - INFO - Final validation performance:
Loss: 0.631, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:54:43,142 - INFO - Beginning epoch 217/800
2025-03-06 21:54:43,146 - INFO - training batch 1, loss: 0.316, 32/28000 datapoints
2025-03-06 21:54:43,296 - INFO - training batch 51, loss: 0.164, 1632/28000 datapoints
2025-03-06 21:54:43,443 - INFO - training batch 101, loss: 0.120, 3232/28000 datapoints
2025-03-06 21:54:43,586 - INFO - training batch 151, loss: 0.293, 4832/28000 datapoints
2025-03-06 21:54:43,750 - INFO - training batch 201, loss: 0.123, 6432/28000 datapoints
2025-03-06 21:54:43,899 - INFO - training batch 251, loss: 0.298, 8032/28000 datapoints
2025-03-06 21:54:44,054 - INFO - training batch 301, loss: 0.636, 9632/28000 datapoints
2025-03-06 21:54:44,218 - INFO - training batch 351, loss: 0.224, 11232/28000 datapoints
2025-03-06 21:54:44,369 - INFO - training batch 401, loss: 0.533, 12832/28000 datapoints
2025-03-06 21:54:44,522 - INFO - training batch 451, loss: 0.425, 14432/28000 datapoints
2025-03-06 21:54:44,670 - INFO - training batch 501, loss: 0.158, 16032/28000 datapoints
2025-03-06 21:54:44,822 - INFO - training batch 551, loss: 0.290, 17632/28000 datapoints
2025-03-06 21:54:44,975 - INFO - training batch 601, loss: 0.298, 19232/28000 datapoints
2025-03-06 21:54:45,126 - INFO - training batch 651, loss: 0.051, 20832/28000 datapoints
2025-03-06 21:54:45,279 - INFO - training batch 701, loss: 0.229, 22432/28000 datapoints
2025-03-06 21:54:45,427 - INFO - training batch 751, loss: 0.176, 24032/28000 datapoints
2025-03-06 21:54:45,576 - INFO - training batch 801, loss: 0.159, 25632/28000 datapoints
2025-03-06 21:54:45,726 - INFO - training batch 851, loss: 0.322, 27232/28000 datapoints
2025-03-06 21:54:45,801 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 21:54:45,854 - INFO - validation batch 51, loss: 1.650, 1632/6976 datapoints
2025-03-06 21:54:45,903 - INFO - validation batch 101, loss: 0.368, 3232/6976 datapoints
2025-03-06 21:54:45,953 - INFO - validation batch 151, loss: 0.520, 4832/6976 datapoints
2025-03-06 21:54:46,005 - INFO - validation batch 201, loss: 0.502, 6432/6976 datapoints
2025-03-06 21:54:46,022 - INFO - Epoch 217/800 done.
2025-03-06 21:54:46,022 - INFO - Final validation performance:
Loss: 0.633, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:54:46,022 - INFO - Beginning epoch 218/800
2025-03-06 21:54:46,027 - INFO - training batch 1, loss: 0.315, 32/28000 datapoints
2025-03-06 21:54:46,177 - INFO - training batch 51, loss: 0.163, 1632/28000 datapoints
2025-03-06 21:54:46,323 - INFO - training batch 101, loss: 0.120, 3232/28000 datapoints
2025-03-06 21:54:46,469 - INFO - training batch 151, loss: 0.288, 4832/28000 datapoints
2025-03-06 21:54:46,614 - INFO - training batch 201, loss: 0.122, 6432/28000 datapoints
2025-03-06 21:54:46,758 - INFO - training batch 251, loss: 0.298, 8032/28000 datapoints
2025-03-06 21:54:46,906 - INFO - training batch 301, loss: 0.635, 9632/28000 datapoints
2025-03-06 21:54:47,049 - INFO - training batch 351, loss: 0.223, 11232/28000 datapoints
2025-03-06 21:54:47,193 - INFO - training batch 401, loss: 0.530, 12832/28000 datapoints
2025-03-06 21:54:47,337 - INFO - training batch 451, loss: 0.423, 14432/28000 datapoints
2025-03-06 21:54:47,479 - INFO - training batch 501, loss: 0.157, 16032/28000 datapoints
2025-03-06 21:54:47,623 - INFO - training batch 551, loss: 0.288, 17632/28000 datapoints
2025-03-06 21:54:47,781 - INFO - training batch 601, loss: 0.293, 19232/28000 datapoints
2025-03-06 21:54:47,936 - INFO - training batch 651, loss: 0.050, 20832/28000 datapoints
2025-03-06 21:54:48,084 - INFO - training batch 701, loss: 0.228, 22432/28000 datapoints
2025-03-06 21:54:48,231 - INFO - training batch 751, loss: 0.176, 24032/28000 datapoints
2025-03-06 21:54:48,377 - INFO - training batch 801, loss: 0.158, 25632/28000 datapoints
2025-03-06 21:54:48,523 - INFO - training batch 851, loss: 0.319, 27232/28000 datapoints
2025-03-06 21:54:48,595 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 21:54:48,642 - INFO - validation batch 51, loss: 1.652, 1632/6976 datapoints
2025-03-06 21:54:48,689 - INFO - validation batch 101, loss: 0.369, 3232/6976 datapoints
2025-03-06 21:54:48,739 - INFO - validation batch 151, loss: 0.521, 4832/6976 datapoints
2025-03-06 21:54:48,785 - INFO - validation batch 201, loss: 0.502, 6432/6976 datapoints
2025-03-06 21:54:48,801 - INFO - Epoch 218/800 done.
2025-03-06 21:54:48,802 - INFO - Final validation performance:
Loss: 0.634, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:54:48,802 - INFO - Beginning epoch 219/800
2025-03-06 21:54:48,806 - INFO - training batch 1, loss: 0.313, 32/28000 datapoints
2025-03-06 21:54:48,959 - INFO - training batch 51, loss: 0.162, 1632/28000 datapoints
2025-03-06 21:54:49,132 - INFO - training batch 101, loss: 0.119, 3232/28000 datapoints
2025-03-06 21:54:49,280 - INFO - training batch 151, loss: 0.282, 4832/28000 datapoints
2025-03-06 21:54:49,428 - INFO - training batch 201, loss: 0.122, 6432/28000 datapoints
2025-03-06 21:54:49,574 - INFO - training batch 251, loss: 0.296, 8032/28000 datapoints
2025-03-06 21:54:49,729 - INFO - training batch 301, loss: 0.633, 9632/28000 datapoints
2025-03-06 21:54:49,889 - INFO - training batch 351, loss: 0.222, 11232/28000 datapoints
2025-03-06 21:54:50,076 - INFO - training batch 401, loss: 0.528, 12832/28000 datapoints
2025-03-06 21:54:50,229 - INFO - training batch 451, loss: 0.422, 14432/28000 datapoints
2025-03-06 21:54:50,377 - INFO - training batch 501, loss: 0.157, 16032/28000 datapoints
2025-03-06 21:54:50,526 - INFO - training batch 551, loss: 0.285, 17632/28000 datapoints
2025-03-06 21:54:50,670 - INFO - training batch 601, loss: 0.286, 19232/28000 datapoints
2025-03-06 21:54:50,813 - INFO - training batch 651, loss: 0.050, 20832/28000 datapoints
2025-03-06 21:54:50,960 - INFO - training batch 701, loss: 0.227, 22432/28000 datapoints
2025-03-06 21:54:51,104 - INFO - training batch 751, loss: 0.174, 24032/28000 datapoints
2025-03-06 21:54:51,246 - INFO - training batch 801, loss: 0.157, 25632/28000 datapoints
2025-03-06 21:54:51,389 - INFO - training batch 851, loss: 0.314, 27232/28000 datapoints
2025-03-06 21:54:51,459 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 21:54:51,505 - INFO - validation batch 51, loss: 1.658, 1632/6976 datapoints
2025-03-06 21:54:51,551 - INFO - validation batch 101, loss: 0.372, 3232/6976 datapoints
2025-03-06 21:54:51,597 - INFO - validation batch 151, loss: 0.521, 4832/6976 datapoints
2025-03-06 21:54:51,644 - INFO - validation batch 201, loss: 0.501, 6432/6976 datapoints
2025-03-06 21:54:51,660 - INFO - Epoch 219/800 done.
2025-03-06 21:54:51,660 - INFO - Final validation performance:
Loss: 0.635, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:54:51,660 - INFO - Beginning epoch 220/800
2025-03-06 21:54:51,664 - INFO - training batch 1, loss: 0.313, 32/28000 datapoints
2025-03-06 21:54:51,812 - INFO - training batch 51, loss: 0.159, 1632/28000 datapoints
2025-03-06 21:54:51,963 - INFO - training batch 101, loss: 0.118, 3232/28000 datapoints
2025-03-06 21:54:52,109 - INFO - training batch 151, loss: 0.276, 4832/28000 datapoints
2025-03-06 21:54:52,256 - INFO - training batch 201, loss: 0.121, 6432/28000 datapoints
2025-03-06 21:54:52,399 - INFO - training batch 251, loss: 0.295, 8032/28000 datapoints
2025-03-06 21:54:52,541 - INFO - training batch 301, loss: 0.632, 9632/28000 datapoints
2025-03-06 21:54:52,686 - INFO - training batch 351, loss: 0.221, 11232/28000 datapoints
2025-03-06 21:54:52,827 - INFO - training batch 401, loss: 0.526, 12832/28000 datapoints
2025-03-06 21:54:52,981 - INFO - training batch 451, loss: 0.420, 14432/28000 datapoints
2025-03-06 21:54:53,125 - INFO - training batch 501, loss: 0.157, 16032/28000 datapoints
2025-03-06 21:54:53,274 - INFO - training batch 551, loss: 0.283, 17632/28000 datapoints
2025-03-06 21:54:53,420 - INFO - training batch 601, loss: 0.281, 19232/28000 datapoints
2025-03-06 21:54:53,565 - INFO - training batch 651, loss: 0.049, 20832/28000 datapoints
2025-03-06 21:54:53,707 - INFO - training batch 701, loss: 0.225, 22432/28000 datapoints
2025-03-06 21:54:53,856 - INFO - training batch 751, loss: 0.174, 24032/28000 datapoints
2025-03-06 21:54:54,000 - INFO - training batch 801, loss: 0.156, 25632/28000 datapoints
2025-03-06 21:54:54,146 - INFO - training batch 851, loss: 0.312, 27232/28000 datapoints
2025-03-06 21:54:54,217 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 21:54:54,265 - INFO - validation batch 51, loss: 1.661, 1632/6976 datapoints
2025-03-06 21:54:54,312 - INFO - validation batch 101, loss: 0.374, 3232/6976 datapoints
2025-03-06 21:54:54,361 - INFO - validation batch 151, loss: 0.525, 4832/6976 datapoints
2025-03-06 21:54:54,409 - INFO - validation batch 201, loss: 0.501, 6432/6976 datapoints
2025-03-06 21:54:54,427 - INFO - Epoch 220/800 done.
2025-03-06 21:54:54,427 - INFO - Final validation performance:
Loss: 0.637, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:54:54,428 - INFO - Beginning epoch 221/800
2025-03-06 21:54:54,432 - INFO - training batch 1, loss: 0.312, 32/28000 datapoints
2025-03-06 21:54:54,576 - INFO - training batch 51, loss: 0.157, 1632/28000 datapoints
2025-03-06 21:54:54,720 - INFO - training batch 101, loss: 0.118, 3232/28000 datapoints
2025-03-06 21:54:54,866 - INFO - training batch 151, loss: 0.271, 4832/28000 datapoints
2025-03-06 21:54:55,016 - INFO - training batch 201, loss: 0.120, 6432/28000 datapoints
2025-03-06 21:54:55,168 - INFO - training batch 251, loss: 0.294, 8032/28000 datapoints
2025-03-06 21:54:55,318 - INFO - training batch 301, loss: 0.629, 9632/28000 datapoints
2025-03-06 21:54:55,461 - INFO - training batch 351, loss: 0.220, 11232/28000 datapoints
2025-03-06 21:54:55,604 - INFO - training batch 401, loss: 0.523, 12832/28000 datapoints
2025-03-06 21:54:55,758 - INFO - training batch 451, loss: 0.420, 14432/28000 datapoints
2025-03-06 21:54:55,913 - INFO - training batch 501, loss: 0.157, 16032/28000 datapoints
2025-03-06 21:54:56,058 - INFO - training batch 551, loss: 0.281, 17632/28000 datapoints
2025-03-06 21:54:56,207 - INFO - training batch 601, loss: 0.277, 19232/28000 datapoints
2025-03-06 21:54:56,354 - INFO - training batch 651, loss: 0.049, 20832/28000 datapoints
2025-03-06 21:54:56,500 - INFO - training batch 701, loss: 0.224, 22432/28000 datapoints
2025-03-06 21:54:56,649 - INFO - training batch 751, loss: 0.173, 24032/28000 datapoints
2025-03-06 21:54:56,791 - INFO - training batch 801, loss: 0.155, 25632/28000 datapoints
2025-03-06 21:54:56,938 - INFO - training batch 851, loss: 0.307, 27232/28000 datapoints
2025-03-06 21:54:57,009 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 21:54:57,057 - INFO - validation batch 51, loss: 1.668, 1632/6976 datapoints
2025-03-06 21:54:57,103 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-06 21:54:57,150 - INFO - validation batch 151, loss: 0.522, 4832/6976 datapoints
2025-03-06 21:54:57,196 - INFO - validation batch 201, loss: 0.499, 6432/6976 datapoints
2025-03-06 21:54:57,212 - INFO - Epoch 221/800 done.
2025-03-06 21:54:57,212 - INFO - Final validation performance:
Loss: 0.638, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:54:57,212 - INFO - Beginning epoch 222/800
2025-03-06 21:54:57,216 - INFO - training batch 1, loss: 0.311, 32/28000 datapoints
2025-03-06 21:54:57,363 - INFO - training batch 51, loss: 0.156, 1632/28000 datapoints
2025-03-06 21:54:57,513 - INFO - training batch 101, loss: 0.116, 3232/28000 datapoints
2025-03-06 21:54:57,661 - INFO - training batch 151, loss: 0.265, 4832/28000 datapoints
2025-03-06 21:54:57,814 - INFO - training batch 201, loss: 0.120, 6432/28000 datapoints
2025-03-06 21:54:57,964 - INFO - training batch 251, loss: 0.292, 8032/28000 datapoints
2025-03-06 21:54:58,114 - INFO - training batch 301, loss: 0.629, 9632/28000 datapoints
2025-03-06 21:54:58,260 - INFO - training batch 351, loss: 0.220, 11232/28000 datapoints
2025-03-06 21:54:58,407 - INFO - training batch 401, loss: 0.520, 12832/28000 datapoints
2025-03-06 21:54:58,555 - INFO - training batch 451, loss: 0.419, 14432/28000 datapoints
2025-03-06 21:54:58,700 - INFO - training batch 501, loss: 0.157, 16032/28000 datapoints
2025-03-06 21:54:58,849 - INFO - training batch 551, loss: 0.278, 17632/28000 datapoints
2025-03-06 21:54:58,995 - INFO - training batch 601, loss: 0.272, 19232/28000 datapoints
2025-03-06 21:54:59,164 - INFO - training batch 651, loss: 0.049, 20832/28000 datapoints
2025-03-06 21:54:59,308 - INFO - training batch 701, loss: 0.223, 22432/28000 datapoints
2025-03-06 21:54:59,451 - INFO - training batch 751, loss: 0.173, 24032/28000 datapoints
2025-03-06 21:54:59,593 - INFO - training batch 801, loss: 0.155, 25632/28000 datapoints
2025-03-06 21:54:59,737 - INFO - training batch 851, loss: 0.305, 27232/28000 datapoints
2025-03-06 21:54:59,810 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:54:59,859 - INFO - validation batch 51, loss: 1.671, 1632/6976 datapoints
2025-03-06 21:54:59,904 - INFO - validation batch 101, loss: 0.379, 3232/6976 datapoints
2025-03-06 21:54:59,952 - INFO - validation batch 151, loss: 0.526, 4832/6976 datapoints
2025-03-06 21:54:59,997 - INFO - validation batch 201, loss: 0.499, 6432/6976 datapoints
2025-03-06 21:55:00,013 - INFO - Epoch 222/800 done.
2025-03-06 21:55:00,014 - INFO - Final validation performance:
Loss: 0.640, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:00,014 - INFO - Beginning epoch 223/800
2025-03-06 21:55:00,018 - INFO - training batch 1, loss: 0.309, 32/28000 datapoints
2025-03-06 21:55:00,162 - INFO - training batch 51, loss: 0.154, 1632/28000 datapoints
2025-03-06 21:55:00,311 - INFO - training batch 101, loss: 0.115, 3232/28000 datapoints
2025-03-06 21:55:00,459 - INFO - training batch 151, loss: 0.260, 4832/28000 datapoints
2025-03-06 21:55:00,602 - INFO - training batch 201, loss: 0.118, 6432/28000 datapoints
2025-03-06 21:55:00,746 - INFO - training batch 251, loss: 0.293, 8032/28000 datapoints
2025-03-06 21:55:00,891 - INFO - training batch 301, loss: 0.626, 9632/28000 datapoints
2025-03-06 21:55:01,036 - INFO - training batch 351, loss: 0.218, 11232/28000 datapoints
2025-03-06 21:55:01,178 - INFO - training batch 401, loss: 0.518, 12832/28000 datapoints
2025-03-06 21:55:01,323 - INFO - training batch 451, loss: 0.418, 14432/28000 datapoints
2025-03-06 21:55:01,466 - INFO - training batch 501, loss: 0.156, 16032/28000 datapoints
2025-03-06 21:55:01,609 - INFO - training batch 551, loss: 0.277, 17632/28000 datapoints
2025-03-06 21:55:01,763 - INFO - training batch 601, loss: 0.267, 19232/28000 datapoints
2025-03-06 21:55:01,924 - INFO - training batch 651, loss: 0.048, 20832/28000 datapoints
2025-03-06 21:55:02,071 - INFO - training batch 701, loss: 0.221, 22432/28000 datapoints
2025-03-06 21:55:02,218 - INFO - training batch 751, loss: 0.172, 24032/28000 datapoints
2025-03-06 21:55:02,368 - INFO - training batch 801, loss: 0.152, 25632/28000 datapoints
2025-03-06 21:55:02,513 - INFO - training batch 851, loss: 0.301, 27232/28000 datapoints
2025-03-06 21:55:02,583 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:55:02,630 - INFO - validation batch 51, loss: 1.675, 1632/6976 datapoints
2025-03-06 21:55:02,680 - INFO - validation batch 101, loss: 0.381, 3232/6976 datapoints
2025-03-06 21:55:02,726 - INFO - validation batch 151, loss: 0.526, 4832/6976 datapoints
2025-03-06 21:55:02,773 - INFO - validation batch 201, loss: 0.498, 6432/6976 datapoints
2025-03-06 21:55:02,788 - INFO - Epoch 223/800 done.
2025-03-06 21:55:02,789 - INFO - Final validation performance:
Loss: 0.641, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:02,789 - INFO - Beginning epoch 224/800
2025-03-06 21:55:02,793 - INFO - training batch 1, loss: 0.308, 32/28000 datapoints
2025-03-06 21:55:02,939 - INFO - training batch 51, loss: 0.152, 1632/28000 datapoints
2025-03-06 21:55:03,084 - INFO - training batch 101, loss: 0.115, 3232/28000 datapoints
2025-03-06 21:55:03,234 - INFO - training batch 151, loss: 0.255, 4832/28000 datapoints
2025-03-06 21:55:03,377 - INFO - training batch 201, loss: 0.118, 6432/28000 datapoints
2025-03-06 21:55:03,522 - INFO - training batch 251, loss: 0.291, 8032/28000 datapoints
2025-03-06 21:55:03,664 - INFO - training batch 301, loss: 0.625, 9632/28000 datapoints
2025-03-06 21:55:03,810 - INFO - training batch 351, loss: 0.218, 11232/28000 datapoints
2025-03-06 21:55:03,956 - INFO - training batch 401, loss: 0.515, 12832/28000 datapoints
2025-03-06 21:55:04,103 - INFO - training batch 451, loss: 0.417, 14432/28000 datapoints
2025-03-06 21:55:04,248 - INFO - training batch 501, loss: 0.156, 16032/28000 datapoints
2025-03-06 21:55:04,399 - INFO - training batch 551, loss: 0.274, 17632/28000 datapoints
2025-03-06 21:55:04,548 - INFO - training batch 601, loss: 0.265, 19232/28000 datapoints
2025-03-06 21:55:04,694 - INFO - training batch 651, loss: 0.048, 20832/28000 datapoints
2025-03-06 21:55:04,845 - INFO - training batch 701, loss: 0.220, 22432/28000 datapoints
2025-03-06 21:55:04,994 - INFO - training batch 751, loss: 0.171, 24032/28000 datapoints
2025-03-06 21:55:05,153 - INFO - training batch 801, loss: 0.152, 25632/28000 datapoints
2025-03-06 21:55:05,300 - INFO - training batch 851, loss: 0.298, 27232/28000 datapoints
2025-03-06 21:55:05,374 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:55:05,425 - INFO - validation batch 51, loss: 1.680, 1632/6976 datapoints
2025-03-06 21:55:05,477 - INFO - validation batch 101, loss: 0.383, 3232/6976 datapoints
2025-03-06 21:55:05,531 - INFO - validation batch 151, loss: 0.528, 4832/6976 datapoints
2025-03-06 21:55:05,579 - INFO - validation batch 201, loss: 0.499, 6432/6976 datapoints
2025-03-06 21:55:05,597 - INFO - Epoch 224/800 done.
2025-03-06 21:55:05,598 - INFO - Final validation performance:
Loss: 0.643, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:05,598 - INFO - Beginning epoch 225/800
2025-03-06 21:55:05,602 - INFO - training batch 1, loss: 0.308, 32/28000 datapoints
2025-03-06 21:55:05,753 - INFO - training batch 51, loss: 0.152, 1632/28000 datapoints
2025-03-06 21:55:05,906 - INFO - training batch 101, loss: 0.114, 3232/28000 datapoints
2025-03-06 21:55:06,056 - INFO - training batch 151, loss: 0.250, 4832/28000 datapoints
2025-03-06 21:55:06,203 - INFO - training batch 201, loss: 0.116, 6432/28000 datapoints
2025-03-06 21:55:06,347 - INFO - training batch 251, loss: 0.290, 8032/28000 datapoints
2025-03-06 21:55:06,495 - INFO - training batch 301, loss: 0.623, 9632/28000 datapoints
2025-03-06 21:55:06,640 - INFO - training batch 351, loss: 0.217, 11232/28000 datapoints
2025-03-06 21:55:06,786 - INFO - training batch 401, loss: 0.512, 12832/28000 datapoints
2025-03-06 21:55:06,935 - INFO - training batch 451, loss: 0.416, 14432/28000 datapoints
2025-03-06 21:55:07,086 - INFO - training batch 501, loss: 0.156, 16032/28000 datapoints
2025-03-06 21:55:07,237 - INFO - training batch 551, loss: 0.271, 17632/28000 datapoints
2025-03-06 21:55:07,387 - INFO - training batch 601, loss: 0.262, 19232/28000 datapoints
2025-03-06 21:55:07,538 - INFO - training batch 651, loss: 0.047, 20832/28000 datapoints
2025-03-06 21:55:07,692 - INFO - training batch 701, loss: 0.219, 22432/28000 datapoints
2025-03-06 21:55:07,848 - INFO - training batch 751, loss: 0.170, 24032/28000 datapoints
2025-03-06 21:55:08,000 - INFO - training batch 801, loss: 0.150, 25632/28000 datapoints
2025-03-06 21:55:08,163 - INFO - training batch 851, loss: 0.294, 27232/28000 datapoints
2025-03-06 21:55:08,237 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:55:08,290 - INFO - validation batch 51, loss: 1.686, 1632/6976 datapoints
2025-03-06 21:55:08,341 - INFO - validation batch 101, loss: 0.386, 3232/6976 datapoints
2025-03-06 21:55:08,391 - INFO - validation batch 151, loss: 0.527, 4832/6976 datapoints
2025-03-06 21:55:08,442 - INFO - validation batch 201, loss: 0.496, 6432/6976 datapoints
2025-03-06 21:55:08,462 - INFO - Epoch 225/800 done.
2025-03-06 21:55:08,462 - INFO - Final validation performance:
Loss: 0.644, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:08,463 - INFO - Beginning epoch 226/800
2025-03-06 21:55:08,468 - INFO - training batch 1, loss: 0.307, 32/28000 datapoints
2025-03-06 21:55:08,634 - INFO - training batch 51, loss: 0.149, 1632/28000 datapoints
2025-03-06 21:55:08,784 - INFO - training batch 101, loss: 0.113, 3232/28000 datapoints
2025-03-06 21:55:08,937 - INFO - training batch 151, loss: 0.244, 4832/28000 datapoints
2025-03-06 21:55:09,088 - INFO - training batch 201, loss: 0.116, 6432/28000 datapoints
2025-03-06 21:55:09,264 - INFO - training batch 251, loss: 0.289, 8032/28000 datapoints
2025-03-06 21:55:09,418 - INFO - training batch 301, loss: 0.622, 9632/28000 datapoints
2025-03-06 21:55:09,571 - INFO - training batch 351, loss: 0.217, 11232/28000 datapoints
2025-03-06 21:55:09,719 - INFO - training batch 401, loss: 0.509, 12832/28000 datapoints
2025-03-06 21:55:09,874 - INFO - training batch 451, loss: 0.416, 14432/28000 datapoints
2025-03-06 21:55:10,020 - INFO - training batch 501, loss: 0.156, 16032/28000 datapoints
2025-03-06 21:55:10,168 - INFO - training batch 551, loss: 0.269, 17632/28000 datapoints
2025-03-06 21:55:10,317 - INFO - training batch 601, loss: 0.259, 19232/28000 datapoints
2025-03-06 21:55:10,466 - INFO - training batch 651, loss: 0.047, 20832/28000 datapoints
2025-03-06 21:55:10,612 - INFO - training batch 701, loss: 0.217, 22432/28000 datapoints
2025-03-06 21:55:10,759 - INFO - training batch 751, loss: 0.169, 24032/28000 datapoints
2025-03-06 21:55:10,908 - INFO - training batch 801, loss: 0.149, 25632/28000 datapoints
2025-03-06 21:55:11,055 - INFO - training batch 851, loss: 0.292, 27232/28000 datapoints
2025-03-06 21:55:11,130 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:55:11,180 - INFO - validation batch 51, loss: 1.689, 1632/6976 datapoints
2025-03-06 21:55:11,226 - INFO - validation batch 101, loss: 0.388, 3232/6976 datapoints
2025-03-06 21:55:11,273 - INFO - validation batch 151, loss: 0.529, 4832/6976 datapoints
2025-03-06 21:55:11,319 - INFO - validation batch 201, loss: 0.497, 6432/6976 datapoints
2025-03-06 21:55:11,335 - INFO - Epoch 226/800 done.
2025-03-06 21:55:11,335 - INFO - Final validation performance:
Loss: 0.645, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:11,336 - INFO - Beginning epoch 227/800
2025-03-06 21:55:11,340 - INFO - training batch 1, loss: 0.306, 32/28000 datapoints
2025-03-06 21:55:11,485 - INFO - training batch 51, loss: 0.149, 1632/28000 datapoints
2025-03-06 21:55:11,631 - INFO - training batch 101, loss: 0.113, 3232/28000 datapoints
2025-03-06 21:55:11,776 - INFO - training batch 151, loss: 0.239, 4832/28000 datapoints
2025-03-06 21:55:11,926 - INFO - training batch 201, loss: 0.115, 6432/28000 datapoints
2025-03-06 21:55:12,072 - INFO - training batch 251, loss: 0.288, 8032/28000 datapoints
2025-03-06 21:55:12,218 - INFO - training batch 301, loss: 0.618, 9632/28000 datapoints
2025-03-06 21:55:12,362 - INFO - training batch 351, loss: 0.216, 11232/28000 datapoints
2025-03-06 21:55:12,504 - INFO - training batch 401, loss: 0.507, 12832/28000 datapoints
2025-03-06 21:55:12,650 - INFO - training batch 451, loss: 0.416, 14432/28000 datapoints
2025-03-06 21:55:12,794 - INFO - training batch 501, loss: 0.155, 16032/28000 datapoints
2025-03-06 21:55:12,942 - INFO - training batch 551, loss: 0.267, 17632/28000 datapoints
2025-03-06 21:55:13,100 - INFO - training batch 601, loss: 0.253, 19232/28000 datapoints
2025-03-06 21:55:13,251 - INFO - training batch 651, loss: 0.046, 20832/28000 datapoints
2025-03-06 21:55:13,394 - INFO - training batch 701, loss: 0.216, 22432/28000 datapoints
2025-03-06 21:55:13,537 - INFO - training batch 751, loss: 0.168, 24032/28000 datapoints
2025-03-06 21:55:13,683 - INFO - training batch 801, loss: 0.149, 25632/28000 datapoints
2025-03-06 21:55:13,830 - INFO - training batch 851, loss: 0.289, 27232/28000 datapoints
2025-03-06 21:55:13,904 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:55:13,951 - INFO - validation batch 51, loss: 1.692, 1632/6976 datapoints
2025-03-06 21:55:13,997 - INFO - validation batch 101, loss: 0.391, 3232/6976 datapoints
2025-03-06 21:55:14,043 - INFO - validation batch 151, loss: 0.530, 4832/6976 datapoints
2025-03-06 21:55:14,090 - INFO - validation batch 201, loss: 0.493, 6432/6976 datapoints
2025-03-06 21:55:14,106 - INFO - Epoch 227/800 done.
2025-03-06 21:55:14,106 - INFO - Final validation performance:
Loss: 0.646, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:14,107 - INFO - Beginning epoch 228/800
2025-03-06 21:55:14,111 - INFO - training batch 1, loss: 0.305, 32/28000 datapoints
2025-03-06 21:55:14,276 - INFO - training batch 51, loss: 0.146, 1632/28000 datapoints
2025-03-06 21:55:14,421 - INFO - training batch 101, loss: 0.113, 3232/28000 datapoints
2025-03-06 21:55:14,564 - INFO - training batch 151, loss: 0.234, 4832/28000 datapoints
2025-03-06 21:55:14,714 - INFO - training batch 201, loss: 0.114, 6432/28000 datapoints
2025-03-06 21:55:14,861 - INFO - training batch 251, loss: 0.289, 8032/28000 datapoints
2025-03-06 21:55:15,010 - INFO - training batch 301, loss: 0.617, 9632/28000 datapoints
2025-03-06 21:55:15,170 - INFO - training batch 351, loss: 0.215, 11232/28000 datapoints
2025-03-06 21:55:15,349 - INFO - training batch 401, loss: 0.504, 12832/28000 datapoints
2025-03-06 21:55:15,493 - INFO - training batch 451, loss: 0.415, 14432/28000 datapoints
2025-03-06 21:55:15,635 - INFO - training batch 501, loss: 0.155, 16032/28000 datapoints
2025-03-06 21:55:15,793 - INFO - training batch 551, loss: 0.265, 17632/28000 datapoints
2025-03-06 21:55:15,943 - INFO - training batch 601, loss: 0.252, 19232/28000 datapoints
2025-03-06 21:55:16,087 - INFO - training batch 651, loss: 0.046, 20832/28000 datapoints
2025-03-06 21:55:16,231 - INFO - training batch 701, loss: 0.214, 22432/28000 datapoints
2025-03-06 21:55:16,373 - INFO - training batch 751, loss: 0.168, 24032/28000 datapoints
2025-03-06 21:55:16,516 - INFO - training batch 801, loss: 0.147, 25632/28000 datapoints
2025-03-06 21:55:16,659 - INFO - training batch 851, loss: 0.287, 27232/28000 datapoints
2025-03-06 21:55:16,732 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:55:16,779 - INFO - validation batch 51, loss: 1.695, 1632/6976 datapoints
2025-03-06 21:55:16,824 - INFO - validation batch 101, loss: 0.393, 3232/6976 datapoints
2025-03-06 21:55:16,874 - INFO - validation batch 151, loss: 0.533, 4832/6976 datapoints
2025-03-06 21:55:16,919 - INFO - validation batch 201, loss: 0.494, 6432/6976 datapoints
2025-03-06 21:55:16,935 - INFO - Epoch 228/800 done.
2025-03-06 21:55:16,935 - INFO - Final validation performance:
Loss: 0.648, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:16,936 - INFO - Beginning epoch 229/800
2025-03-06 21:55:16,940 - INFO - training batch 1, loss: 0.304, 32/28000 datapoints
2025-03-06 21:55:17,084 - INFO - training batch 51, loss: 0.145, 1632/28000 datapoints
2025-03-06 21:55:17,232 - INFO - training batch 101, loss: 0.112, 3232/28000 datapoints
2025-03-06 21:55:17,376 - INFO - training batch 151, loss: 0.230, 4832/28000 datapoints
2025-03-06 21:55:17,525 - INFO - training batch 201, loss: 0.114, 6432/28000 datapoints
2025-03-06 21:55:17,667 - INFO - training batch 251, loss: 0.287, 8032/28000 datapoints
2025-03-06 21:55:17,816 - INFO - training batch 301, loss: 0.617, 9632/28000 datapoints
2025-03-06 21:55:17,966 - INFO - training batch 351, loss: 0.214, 11232/28000 datapoints
2025-03-06 21:55:18,111 - INFO - training batch 401, loss: 0.502, 12832/28000 datapoints
2025-03-06 21:55:18,258 - INFO - training batch 451, loss: 0.415, 14432/28000 datapoints
2025-03-06 21:55:18,402 - INFO - training batch 501, loss: 0.155, 16032/28000 datapoints
2025-03-06 21:55:18,551 - INFO - training batch 551, loss: 0.263, 17632/28000 datapoints
2025-03-06 21:55:18,699 - INFO - training batch 601, loss: 0.247, 19232/28000 datapoints
2025-03-06 21:55:18,848 - INFO - training batch 651, loss: 0.045, 20832/28000 datapoints
2025-03-06 21:55:18,995 - INFO - training batch 701, loss: 0.212, 22432/28000 datapoints
2025-03-06 21:55:19,142 - INFO - training batch 751, loss: 0.167, 24032/28000 datapoints
2025-03-06 21:55:19,303 - INFO - training batch 801, loss: 0.146, 25632/28000 datapoints
2025-03-06 21:55:19,469 - INFO - training batch 851, loss: 0.283, 27232/28000 datapoints
2025-03-06 21:55:19,542 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:55:19,588 - INFO - validation batch 51, loss: 1.700, 1632/6976 datapoints
2025-03-06 21:55:19,635 - INFO - validation batch 101, loss: 0.394, 3232/6976 datapoints
2025-03-06 21:55:19,685 - INFO - validation batch 151, loss: 0.535, 4832/6976 datapoints
2025-03-06 21:55:19,734 - INFO - validation batch 201, loss: 0.493, 6432/6976 datapoints
2025-03-06 21:55:19,750 - INFO - Epoch 229/800 done.
2025-03-06 21:55:19,750 - INFO - Final validation performance:
Loss: 0.650, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:19,751 - INFO - Beginning epoch 230/800
2025-03-06 21:55:19,755 - INFO - training batch 1, loss: 0.303, 32/28000 datapoints
2025-03-06 21:55:19,916 - INFO - training batch 51, loss: 0.143, 1632/28000 datapoints
2025-03-06 21:55:20,063 - INFO - training batch 101, loss: 0.111, 3232/28000 datapoints
2025-03-06 21:55:20,208 - INFO - training batch 151, loss: 0.226, 4832/28000 datapoints
2025-03-06 21:55:20,369 - INFO - training batch 201, loss: 0.113, 6432/28000 datapoints
2025-03-06 21:55:20,512 - INFO - training batch 251, loss: 0.287, 8032/28000 datapoints
2025-03-06 21:55:20,654 - INFO - training batch 301, loss: 0.615, 9632/28000 datapoints
2025-03-06 21:55:20,804 - INFO - training batch 351, loss: 0.213, 11232/28000 datapoints
2025-03-06 21:55:20,953 - INFO - training batch 401, loss: 0.499, 12832/28000 datapoints
2025-03-06 21:55:21,097 - INFO - training batch 451, loss: 0.414, 14432/28000 datapoints
2025-03-06 21:55:21,246 - INFO - training batch 501, loss: 0.155, 16032/28000 datapoints
2025-03-06 21:55:21,391 - INFO - training batch 551, loss: 0.261, 17632/28000 datapoints
2025-03-06 21:55:21,534 - INFO - training batch 601, loss: 0.242, 19232/28000 datapoints
2025-03-06 21:55:21,676 - INFO - training batch 651, loss: 0.045, 20832/28000 datapoints
2025-03-06 21:55:21,820 - INFO - training batch 701, loss: 0.211, 22432/28000 datapoints
2025-03-06 21:55:21,969 - INFO - training batch 751, loss: 0.165, 24032/28000 datapoints
2025-03-06 21:55:22,114 - INFO - training batch 801, loss: 0.146, 25632/28000 datapoints
2025-03-06 21:55:22,259 - INFO - training batch 851, loss: 0.279, 27232/28000 datapoints
2025-03-06 21:55:22,329 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:55:22,376 - INFO - validation batch 51, loss: 1.703, 1632/6976 datapoints
2025-03-06 21:55:22,422 - INFO - validation batch 101, loss: 0.397, 3232/6976 datapoints
2025-03-06 21:55:22,468 - INFO - validation batch 151, loss: 0.536, 4832/6976 datapoints
2025-03-06 21:55:22,515 - INFO - validation batch 201, loss: 0.490, 6432/6976 datapoints
2025-03-06 21:55:22,532 - INFO - Epoch 230/800 done.
2025-03-06 21:55:22,532 - INFO - Final validation performance:
Loss: 0.650, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:22,532 - INFO - Beginning epoch 231/800
2025-03-06 21:55:22,536 - INFO - training batch 1, loss: 0.302, 32/28000 datapoints
2025-03-06 21:55:22,681 - INFO - training batch 51, loss: 0.142, 1632/28000 datapoints
2025-03-06 21:55:22,828 - INFO - training batch 101, loss: 0.111, 3232/28000 datapoints
2025-03-06 21:55:22,976 - INFO - training batch 151, loss: 0.221, 4832/28000 datapoints
2025-03-06 21:55:23,121 - INFO - training batch 201, loss: 0.112, 6432/28000 datapoints
2025-03-06 21:55:23,270 - INFO - training batch 251, loss: 0.286, 8032/28000 datapoints
2025-03-06 21:55:23,413 - INFO - training batch 301, loss: 0.613, 9632/28000 datapoints
2025-03-06 21:55:23,556 - INFO - training batch 351, loss: 0.213, 11232/28000 datapoints
2025-03-06 21:55:23,700 - INFO - training batch 401, loss: 0.497, 12832/28000 datapoints
2025-03-06 21:55:23,850 - INFO - training batch 451, loss: 0.413, 14432/28000 datapoints
2025-03-06 21:55:23,996 - INFO - training batch 501, loss: 0.154, 16032/28000 datapoints
2025-03-06 21:55:24,141 - INFO - training batch 551, loss: 0.259, 17632/28000 datapoints
2025-03-06 21:55:24,287 - INFO - training batch 601, loss: 0.242, 19232/28000 datapoints
2025-03-06 21:55:24,437 - INFO - training batch 651, loss: 0.045, 20832/28000 datapoints
2025-03-06 21:55:24,584 - INFO - training batch 701, loss: 0.209, 22432/28000 datapoints
2025-03-06 21:55:24,729 - INFO - training batch 751, loss: 0.165, 24032/28000 datapoints
2025-03-06 21:55:24,882 - INFO - training batch 801, loss: 0.143, 25632/28000 datapoints
2025-03-06 21:55:25,031 - INFO - training batch 851, loss: 0.275, 27232/28000 datapoints
2025-03-06 21:55:25,112 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:55:25,167 - INFO - validation batch 51, loss: 1.709, 1632/6976 datapoints
2025-03-06 21:55:25,217 - INFO - validation batch 101, loss: 0.399, 3232/6976 datapoints
2025-03-06 21:55:25,267 - INFO - validation batch 151, loss: 0.534, 4832/6976 datapoints
2025-03-06 21:55:25,320 - INFO - validation batch 201, loss: 0.491, 6432/6976 datapoints
2025-03-06 21:55:25,338 - INFO - Epoch 231/800 done.
2025-03-06 21:55:25,339 - INFO - Final validation performance:
Loss: 0.652, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:25,339 - INFO - Beginning epoch 232/800
2025-03-06 21:55:25,343 - INFO - training batch 1, loss: 0.301, 32/28000 datapoints
2025-03-06 21:55:25,495 - INFO - training batch 51, loss: 0.140, 1632/28000 datapoints
2025-03-06 21:55:25,643 - INFO - training batch 101, loss: 0.110, 3232/28000 datapoints
2025-03-06 21:55:25,792 - INFO - training batch 151, loss: 0.217, 4832/28000 datapoints
2025-03-06 21:55:25,945 - INFO - training batch 201, loss: 0.111, 6432/28000 datapoints
2025-03-06 21:55:26,091 - INFO - training batch 251, loss: 0.285, 8032/28000 datapoints
2025-03-06 21:55:26,238 - INFO - training batch 301, loss: 0.612, 9632/28000 datapoints
2025-03-06 21:55:26,397 - INFO - training batch 351, loss: 0.212, 11232/28000 datapoints
2025-03-06 21:55:26,544 - INFO - training batch 401, loss: 0.495, 12832/28000 datapoints
2025-03-06 21:55:26,690 - INFO - training batch 451, loss: 0.412, 14432/28000 datapoints
2025-03-06 21:55:26,845 - INFO - training batch 501, loss: 0.154, 16032/28000 datapoints
2025-03-06 21:55:26,998 - INFO - training batch 551, loss: 0.257, 17632/28000 datapoints
2025-03-06 21:55:27,147 - INFO - training batch 601, loss: 0.238, 19232/28000 datapoints
2025-03-06 21:55:27,300 - INFO - training batch 651, loss: 0.044, 20832/28000 datapoints
2025-03-06 21:55:27,450 - INFO - training batch 701, loss: 0.208, 22432/28000 datapoints
2025-03-06 21:55:27,596 - INFO - training batch 751, loss: 0.164, 24032/28000 datapoints
2025-03-06 21:55:27,750 - INFO - training batch 801, loss: 0.142, 25632/28000 datapoints
2025-03-06 21:55:27,909 - INFO - training batch 851, loss: 0.272, 27232/28000 datapoints
2025-03-06 21:55:27,984 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:55:28,035 - INFO - validation batch 51, loss: 1.712, 1632/6976 datapoints
2025-03-06 21:55:28,084 - INFO - validation batch 101, loss: 0.402, 3232/6976 datapoints
2025-03-06 21:55:28,132 - INFO - validation batch 151, loss: 0.536, 4832/6976 datapoints
2025-03-06 21:55:28,180 - INFO - validation batch 201, loss: 0.491, 6432/6976 datapoints
2025-03-06 21:55:28,198 - INFO - Epoch 232/800 done.
2025-03-06 21:55:28,198 - INFO - Final validation performance:
Loss: 0.653, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:55:28,198 - INFO - Beginning epoch 233/800
2025-03-06 21:55:28,203 - INFO - training batch 1, loss: 0.300, 32/28000 datapoints
2025-03-06 21:55:28,357 - INFO - training batch 51, loss: 0.139, 1632/28000 datapoints
2025-03-06 21:55:28,506 - INFO - training batch 101, loss: 0.109, 3232/28000 datapoints
2025-03-06 21:55:28,654 - INFO - training batch 151, loss: 0.213, 4832/28000 datapoints
2025-03-06 21:55:28,800 - INFO - training batch 201, loss: 0.110, 6432/28000 datapoints
2025-03-06 21:55:28,951 - INFO - training batch 251, loss: 0.283, 8032/28000 datapoints
2025-03-06 21:55:29,098 - INFO - training batch 301, loss: 0.610, 9632/28000 datapoints
2025-03-06 21:55:29,246 - INFO - training batch 351, loss: 0.212, 11232/28000 datapoints
2025-03-06 21:55:29,401 - INFO - training batch 401, loss: 0.492, 12832/28000 datapoints
2025-03-06 21:55:29,565 - INFO - training batch 451, loss: 0.412, 14432/28000 datapoints
2025-03-06 21:55:29,712 - INFO - training batch 501, loss: 0.154, 16032/28000 datapoints
2025-03-06 21:55:29,859 - INFO - training batch 551, loss: 0.255, 17632/28000 datapoints
2025-03-06 21:55:30,006 - INFO - training batch 601, loss: 0.233, 19232/28000 datapoints
2025-03-06 21:55:30,155 - INFO - training batch 651, loss: 0.044, 20832/28000 datapoints
2025-03-06 21:55:30,301 - INFO - training batch 701, loss: 0.206, 22432/28000 datapoints
2025-03-06 21:55:30,446 - INFO - training batch 751, loss: 0.163, 24032/28000 datapoints
2025-03-06 21:55:30,589 - INFO - training batch 801, loss: 0.141, 25632/28000 datapoints
2025-03-06 21:55:30,732 - INFO - training batch 851, loss: 0.269, 27232/28000 datapoints
2025-03-06 21:55:30,802 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:55:30,851 - INFO - validation batch 51, loss: 1.718, 1632/6976 datapoints
2025-03-06 21:55:30,897 - INFO - validation batch 101, loss: 0.404, 3232/6976 datapoints
2025-03-06 21:55:30,946 - INFO - validation batch 151, loss: 0.539, 4832/6976 datapoints
2025-03-06 21:55:30,992 - INFO - validation batch 201, loss: 0.490, 6432/6976 datapoints
2025-03-06 21:55:31,008 - INFO - Epoch 233/800 done.
2025-03-06 21:55:31,008 - INFO - Final validation performance:
Loss: 0.655, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:31,009 - INFO - Beginning epoch 234/800
2025-03-06 21:55:31,013 - INFO - training batch 1, loss: 0.298, 32/28000 datapoints
2025-03-06 21:55:31,157 - INFO - training batch 51, loss: 0.137, 1632/28000 datapoints
2025-03-06 21:55:31,301 - INFO - training batch 101, loss: 0.109, 3232/28000 datapoints
2025-03-06 21:55:31,449 - INFO - training batch 151, loss: 0.209, 4832/28000 datapoints
2025-03-06 21:55:31,593 - INFO - training batch 201, loss: 0.109, 6432/28000 datapoints
2025-03-06 21:55:31,737 - INFO - training batch 251, loss: 0.283, 8032/28000 datapoints
2025-03-06 21:55:31,890 - INFO - training batch 301, loss: 0.607, 9632/28000 datapoints
2025-03-06 21:55:32,035 - INFO - training batch 351, loss: 0.211, 11232/28000 datapoints
2025-03-06 21:55:32,180 - INFO - training batch 401, loss: 0.490, 12832/28000 datapoints
2025-03-06 21:55:32,324 - INFO - training batch 451, loss: 0.411, 14432/28000 datapoints
2025-03-06 21:55:32,482 - INFO - training batch 501, loss: 0.153, 16032/28000 datapoints
2025-03-06 21:55:32,630 - INFO - training batch 551, loss: 0.253, 17632/28000 datapoints
2025-03-06 21:55:32,772 - INFO - training batch 601, loss: 0.229, 19232/28000 datapoints
2025-03-06 21:55:32,921 - INFO - training batch 651, loss: 0.044, 20832/28000 datapoints
2025-03-06 21:55:33,071 - INFO - training batch 701, loss: 0.205, 22432/28000 datapoints
2025-03-06 21:55:33,216 - INFO - training batch 751, loss: 0.162, 24032/28000 datapoints
2025-03-06 21:55:33,363 - INFO - training batch 801, loss: 0.141, 25632/28000 datapoints
2025-03-06 21:55:33,508 - INFO - training batch 851, loss: 0.267, 27232/28000 datapoints
2025-03-06 21:55:33,579 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:55:33,625 - INFO - validation batch 51, loss: 1.722, 1632/6976 datapoints
2025-03-06 21:55:33,674 - INFO - validation batch 101, loss: 0.407, 3232/6976 datapoints
2025-03-06 21:55:33,724 - INFO - validation batch 151, loss: 0.539, 4832/6976 datapoints
2025-03-06 21:55:33,771 - INFO - validation batch 201, loss: 0.489, 6432/6976 datapoints
2025-03-06 21:55:33,786 - INFO - Epoch 234/800 done.
2025-03-06 21:55:33,786 - INFO - Final validation performance:
Loss: 0.656, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:33,787 - INFO - Beginning epoch 235/800
2025-03-06 21:55:33,791 - INFO - training batch 1, loss: 0.297, 32/28000 datapoints
2025-03-06 21:55:33,947 - INFO - training batch 51, loss: 0.134, 1632/28000 datapoints
2025-03-06 21:55:34,091 - INFO - training batch 101, loss: 0.108, 3232/28000 datapoints
2025-03-06 21:55:34,236 - INFO - training batch 151, loss: 0.205, 4832/28000 datapoints
2025-03-06 21:55:34,378 - INFO - training batch 201, loss: 0.109, 6432/28000 datapoints
2025-03-06 21:55:34,522 - INFO - training batch 251, loss: 0.282, 8032/28000 datapoints
2025-03-06 21:55:34,664 - INFO - training batch 301, loss: 0.605, 9632/28000 datapoints
2025-03-06 21:55:34,806 - INFO - training batch 351, loss: 0.211, 11232/28000 datapoints
2025-03-06 21:55:34,954 - INFO - training batch 401, loss: 0.488, 12832/28000 datapoints
2025-03-06 21:55:35,104 - INFO - training batch 451, loss: 0.410, 14432/28000 datapoints
2025-03-06 21:55:35,252 - INFO - training batch 501, loss: 0.153, 16032/28000 datapoints
2025-03-06 21:55:35,397 - INFO - training batch 551, loss: 0.251, 17632/28000 datapoints
2025-03-06 21:55:35,543 - INFO - training batch 601, loss: 0.225, 19232/28000 datapoints
2025-03-06 21:55:35,689 - INFO - training batch 651, loss: 0.043, 20832/28000 datapoints
2025-03-06 21:55:35,831 - INFO - training batch 701, loss: 0.203, 22432/28000 datapoints
2025-03-06 21:55:35,982 - INFO - training batch 751, loss: 0.162, 24032/28000 datapoints
2025-03-06 21:55:36,124 - INFO - training batch 801, loss: 0.139, 25632/28000 datapoints
2025-03-06 21:55:36,268 - INFO - training batch 851, loss: 0.264, 27232/28000 datapoints
2025-03-06 21:55:36,341 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:55:36,387 - INFO - validation batch 51, loss: 1.729, 1632/6976 datapoints
2025-03-06 21:55:36,435 - INFO - validation batch 101, loss: 0.409, 3232/6976 datapoints
2025-03-06 21:55:36,481 - INFO - validation batch 151, loss: 0.541, 4832/6976 datapoints
2025-03-06 21:55:36,527 - INFO - validation batch 201, loss: 0.490, 6432/6976 datapoints
2025-03-06 21:55:36,544 - INFO - Epoch 235/800 done.
2025-03-06 21:55:36,544 - INFO - Final validation performance:
Loss: 0.659, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:36,544 - INFO - Beginning epoch 236/800
2025-03-06 21:55:36,548 - INFO - training batch 1, loss: 0.296, 32/28000 datapoints
2025-03-06 21:55:36,692 - INFO - training batch 51, loss: 0.133, 1632/28000 datapoints
2025-03-06 21:55:36,835 - INFO - training batch 101, loss: 0.107, 3232/28000 datapoints
2025-03-06 21:55:36,983 - INFO - training batch 151, loss: 0.202, 4832/28000 datapoints
2025-03-06 21:55:37,127 - INFO - training batch 201, loss: 0.107, 6432/28000 datapoints
2025-03-06 21:55:37,269 - INFO - training batch 251, loss: 0.282, 8032/28000 datapoints
2025-03-06 21:55:37,412 - INFO - training batch 301, loss: 0.602, 9632/28000 datapoints
2025-03-06 21:55:37,556 - INFO - training batch 351, loss: 0.210, 11232/28000 datapoints
2025-03-06 21:55:37,698 - INFO - training batch 401, loss: 0.484, 12832/28000 datapoints
2025-03-06 21:55:37,855 - INFO - training batch 451, loss: 0.409, 14432/28000 datapoints
2025-03-06 21:55:38,004 - INFO - training batch 501, loss: 0.152, 16032/28000 datapoints
2025-03-06 21:55:38,149 - INFO - training batch 551, loss: 0.249, 17632/28000 datapoints
2025-03-06 21:55:38,294 - INFO - training batch 601, loss: 0.224, 19232/28000 datapoints
2025-03-06 21:55:38,437 - INFO - training batch 651, loss: 0.043, 20832/28000 datapoints
2025-03-06 21:55:38,596 - INFO - training batch 701, loss: 0.202, 22432/28000 datapoints
2025-03-06 21:55:38,738 - INFO - training batch 751, loss: 0.160, 24032/28000 datapoints
2025-03-06 21:55:38,885 - INFO - training batch 801, loss: 0.138, 25632/28000 datapoints
2025-03-06 21:55:39,037 - INFO - training batch 851, loss: 0.259, 27232/28000 datapoints
2025-03-06 21:55:39,111 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:55:39,162 - INFO - validation batch 51, loss: 1.732, 1632/6976 datapoints
2025-03-06 21:55:39,211 - INFO - validation batch 101, loss: 0.412, 3232/6976 datapoints
2025-03-06 21:55:39,258 - INFO - validation batch 151, loss: 0.540, 4832/6976 datapoints
2025-03-06 21:55:39,307 - INFO - validation batch 201, loss: 0.486, 6432/6976 datapoints
2025-03-06 21:55:39,327 - INFO - Epoch 236/800 done.
2025-03-06 21:55:39,327 - INFO - Final validation performance:
Loss: 0.659, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:39,328 - INFO - Beginning epoch 237/800
2025-03-06 21:55:39,333 - INFO - training batch 1, loss: 0.294, 32/28000 datapoints
2025-03-06 21:55:39,487 - INFO - training batch 51, loss: 0.131, 1632/28000 datapoints
2025-03-06 21:55:39,651 - INFO - training batch 101, loss: 0.106, 3232/28000 datapoints
2025-03-06 21:55:39,795 - INFO - training batch 151, loss: 0.198, 4832/28000 datapoints
2025-03-06 21:55:39,944 - INFO - training batch 201, loss: 0.106, 6432/28000 datapoints
2025-03-06 21:55:40,090 - INFO - training batch 251, loss: 0.281, 8032/28000 datapoints
2025-03-06 21:55:40,232 - INFO - training batch 301, loss: 0.601, 9632/28000 datapoints
2025-03-06 21:55:40,375 - INFO - training batch 351, loss: 0.209, 11232/28000 datapoints
2025-03-06 21:55:40,523 - INFO - training batch 401, loss: 0.481, 12832/28000 datapoints
2025-03-06 21:55:40,665 - INFO - training batch 451, loss: 0.407, 14432/28000 datapoints
2025-03-06 21:55:40,809 - INFO - training batch 501, loss: 0.152, 16032/28000 datapoints
2025-03-06 21:55:40,958 - INFO - training batch 551, loss: 0.247, 17632/28000 datapoints
2025-03-06 21:55:41,106 - INFO - training batch 601, loss: 0.220, 19232/28000 datapoints
2025-03-06 21:55:41,255 - INFO - training batch 651, loss: 0.043, 20832/28000 datapoints
2025-03-06 21:55:41,401 - INFO - training batch 701, loss: 0.200, 22432/28000 datapoints
2025-03-06 21:55:41,549 - INFO - training batch 751, loss: 0.161, 24032/28000 datapoints
2025-03-06 21:55:41,702 - INFO - training batch 801, loss: 0.137, 25632/28000 datapoints
2025-03-06 21:55:41,850 - INFO - training batch 851, loss: 0.258, 27232/28000 datapoints
2025-03-06 21:55:41,928 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:55:41,976 - INFO - validation batch 51, loss: 1.736, 1632/6976 datapoints
2025-03-06 21:55:42,024 - INFO - validation batch 101, loss: 0.414, 3232/6976 datapoints
2025-03-06 21:55:42,078 - INFO - validation batch 151, loss: 0.544, 4832/6976 datapoints
2025-03-06 21:55:42,132 - INFO - validation batch 201, loss: 0.488, 6432/6976 datapoints
2025-03-06 21:55:42,148 - INFO - Epoch 237/800 done.
2025-03-06 21:55:42,148 - INFO - Final validation performance:
Loss: 0.661, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:42,149 - INFO - Beginning epoch 238/800
2025-03-06 21:55:42,153 - INFO - training batch 1, loss: 0.293, 32/28000 datapoints
2025-03-06 21:55:42,300 - INFO - training batch 51, loss: 0.130, 1632/28000 datapoints
2025-03-06 21:55:42,447 - INFO - training batch 101, loss: 0.106, 3232/28000 datapoints
2025-03-06 21:55:42,599 - INFO - training batch 151, loss: 0.194, 4832/28000 datapoints
2025-03-06 21:55:42,745 - INFO - training batch 201, loss: 0.106, 6432/28000 datapoints
2025-03-06 21:55:42,893 - INFO - training batch 251, loss: 0.280, 8032/28000 datapoints
2025-03-06 21:55:43,051 - INFO - training batch 301, loss: 0.598, 9632/28000 datapoints
2025-03-06 21:55:43,194 - INFO - training batch 351, loss: 0.208, 11232/28000 datapoints
2025-03-06 21:55:43,340 - INFO - training batch 401, loss: 0.478, 12832/28000 datapoints
2025-03-06 21:55:43,484 - INFO - training batch 451, loss: 0.406, 14432/28000 datapoints
2025-03-06 21:55:43,633 - INFO - training batch 501, loss: 0.152, 16032/28000 datapoints
2025-03-06 21:55:43,776 - INFO - training batch 551, loss: 0.245, 17632/28000 datapoints
2025-03-06 21:55:43,925 - INFO - training batch 601, loss: 0.217, 19232/28000 datapoints
2025-03-06 21:55:44,073 - INFO - training batch 651, loss: 0.042, 20832/28000 datapoints
2025-03-06 21:55:44,217 - INFO - training batch 701, loss: 0.199, 22432/28000 datapoints
2025-03-06 21:55:44,367 - INFO - training batch 751, loss: 0.159, 24032/28000 datapoints
2025-03-06 21:55:44,512 - INFO - training batch 801, loss: 0.136, 25632/28000 datapoints
2025-03-06 21:55:44,661 - INFO - training batch 851, loss: 0.254, 27232/28000 datapoints
2025-03-06 21:55:44,743 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:55:44,805 - INFO - validation batch 51, loss: 1.741, 1632/6976 datapoints
2025-03-06 21:55:44,863 - INFO - validation batch 101, loss: 0.416, 3232/6976 datapoints
2025-03-06 21:55:44,913 - INFO - validation batch 151, loss: 0.542, 4832/6976 datapoints
2025-03-06 21:55:44,963 - INFO - validation batch 201, loss: 0.486, 6432/6976 datapoints
2025-03-06 21:55:44,980 - INFO - Epoch 238/800 done.
2025-03-06 21:55:44,981 - INFO - Final validation performance:
Loss: 0.662, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:44,981 - INFO - Beginning epoch 239/800
2025-03-06 21:55:44,987 - INFO - training batch 1, loss: 0.291, 32/28000 datapoints
2025-03-06 21:55:45,156 - INFO - training batch 51, loss: 0.129, 1632/28000 datapoints
2025-03-06 21:55:45,304 - INFO - training batch 101, loss: 0.105, 3232/28000 datapoints
2025-03-06 21:55:45,453 - INFO - training batch 151, loss: 0.191, 4832/28000 datapoints
2025-03-06 21:55:45,601 - INFO - training batch 201, loss: 0.105, 6432/28000 datapoints
2025-03-06 21:55:45,747 - INFO - training batch 251, loss: 0.279, 8032/28000 datapoints
2025-03-06 21:55:45,911 - INFO - training batch 301, loss: 0.597, 9632/28000 datapoints
2025-03-06 21:55:46,088 - INFO - training batch 351, loss: 0.208, 11232/28000 datapoints
2025-03-06 21:55:46,270 - INFO - training batch 401, loss: 0.476, 12832/28000 datapoints
2025-03-06 21:55:46,418 - INFO - training batch 451, loss: 0.404, 14432/28000 datapoints
2025-03-06 21:55:46,565 - INFO - training batch 501, loss: 0.151, 16032/28000 datapoints
2025-03-06 21:55:46,715 - INFO - training batch 551, loss: 0.243, 17632/28000 datapoints
2025-03-06 21:55:46,864 - INFO - training batch 601, loss: 0.216, 19232/28000 datapoints
2025-03-06 21:55:47,015 - INFO - training batch 651, loss: 0.042, 20832/28000 datapoints
2025-03-06 21:55:47,163 - INFO - training batch 701, loss: 0.197, 22432/28000 datapoints
2025-03-06 21:55:47,311 - INFO - training batch 751, loss: 0.159, 24032/28000 datapoints
2025-03-06 21:55:47,457 - INFO - training batch 801, loss: 0.135, 25632/28000 datapoints
2025-03-06 21:55:47,605 - INFO - training batch 851, loss: 0.251, 27232/28000 datapoints
2025-03-06 21:55:47,679 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:55:47,734 - INFO - validation batch 51, loss: 1.745, 1632/6976 datapoints
2025-03-06 21:55:47,788 - INFO - validation batch 101, loss: 0.418, 3232/6976 datapoints
2025-03-06 21:55:47,839 - INFO - validation batch 151, loss: 0.546, 4832/6976 datapoints
2025-03-06 21:55:47,892 - INFO - validation batch 201, loss: 0.486, 6432/6976 datapoints
2025-03-06 21:55:47,908 - INFO - Epoch 239/800 done.
2025-03-06 21:55:47,908 - INFO - Final validation performance:
Loss: 0.664, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:47,909 - INFO - Beginning epoch 240/800
2025-03-06 21:55:47,913 - INFO - training batch 1, loss: 0.290, 32/28000 datapoints
2025-03-06 21:55:48,082 - INFO - training batch 51, loss: 0.127, 1632/28000 datapoints
2025-03-06 21:55:48,234 - INFO - training batch 101, loss: 0.105, 3232/28000 datapoints
2025-03-06 21:55:48,384 - INFO - training batch 151, loss: 0.187, 4832/28000 datapoints
2025-03-06 21:55:48,537 - INFO - training batch 201, loss: 0.104, 6432/28000 datapoints
2025-03-06 21:55:48,690 - INFO - training batch 251, loss: 0.279, 8032/28000 datapoints
2025-03-06 21:55:48,841 - INFO - training batch 301, loss: 0.595, 9632/28000 datapoints
2025-03-06 21:55:48,994 - INFO - training batch 351, loss: 0.207, 11232/28000 datapoints
2025-03-06 21:55:49,146 - INFO - training batch 401, loss: 0.473, 12832/28000 datapoints
2025-03-06 21:55:49,298 - INFO - training batch 451, loss: 0.403, 14432/28000 datapoints
2025-03-06 21:55:49,450 - INFO - training batch 501, loss: 0.150, 16032/28000 datapoints
2025-03-06 21:55:49,615 - INFO - training batch 551, loss: 0.242, 17632/28000 datapoints
2025-03-06 21:55:49,781 - INFO - training batch 601, loss: 0.212, 19232/28000 datapoints
2025-03-06 21:55:49,936 - INFO - training batch 651, loss: 0.042, 20832/28000 datapoints
2025-03-06 21:55:50,091 - INFO - training batch 701, loss: 0.197, 22432/28000 datapoints
2025-03-06 21:55:50,239 - INFO - training batch 751, loss: 0.157, 24032/28000 datapoints
2025-03-06 21:55:50,386 - INFO - training batch 801, loss: 0.134, 25632/28000 datapoints
2025-03-06 21:55:50,533 - INFO - training batch 851, loss: 0.250, 27232/28000 datapoints
2025-03-06 21:55:50,608 - INFO - validation batch 1, loss: 0.123, 32/6976 datapoints
2025-03-06 21:55:50,659 - INFO - validation batch 51, loss: 1.750, 1632/6976 datapoints
2025-03-06 21:55:50,710 - INFO - validation batch 101, loss: 0.421, 3232/6976 datapoints
2025-03-06 21:55:50,759 - INFO - validation batch 151, loss: 0.549, 4832/6976 datapoints
2025-03-06 21:55:50,809 - INFO - validation batch 201, loss: 0.486, 6432/6976 datapoints
2025-03-06 21:55:50,828 - INFO - Epoch 240/800 done.
2025-03-06 21:55:50,828 - INFO - Final validation performance:
Loss: 0.666, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:50,829 - INFO - Beginning epoch 241/800
2025-03-06 21:55:50,833 - INFO - training batch 1, loss: 0.288, 32/28000 datapoints
2025-03-06 21:55:50,994 - INFO - training batch 51, loss: 0.126, 1632/28000 datapoints
2025-03-06 21:55:51,140 - INFO - training batch 101, loss: 0.104, 3232/28000 datapoints
2025-03-06 21:55:51,285 - INFO - training batch 151, loss: 0.184, 4832/28000 datapoints
2025-03-06 21:55:51,436 - INFO - training batch 201, loss: 0.103, 6432/28000 datapoints
2025-03-06 21:55:51,583 - INFO - training batch 251, loss: 0.279, 8032/28000 datapoints
2025-03-06 21:55:51,730 - INFO - training batch 301, loss: 0.593, 9632/28000 datapoints
2025-03-06 21:55:51,875 - INFO - training batch 351, loss: 0.207, 11232/28000 datapoints
2025-03-06 21:55:52,022 - INFO - training batch 401, loss: 0.471, 12832/28000 datapoints
2025-03-06 21:55:52,168 - INFO - training batch 451, loss: 0.402, 14432/28000 datapoints
2025-03-06 21:55:52,314 - INFO - training batch 501, loss: 0.150, 16032/28000 datapoints
2025-03-06 21:55:52,461 - INFO - training batch 551, loss: 0.239, 17632/28000 datapoints
2025-03-06 21:55:52,609 - INFO - training batch 601, loss: 0.210, 19232/28000 datapoints
2025-03-06 21:55:52,753 - INFO - training batch 651, loss: 0.041, 20832/28000 datapoints
2025-03-06 21:55:52,900 - INFO - training batch 701, loss: 0.195, 22432/28000 datapoints
2025-03-06 21:55:53,042 - INFO - training batch 751, loss: 0.158, 24032/28000 datapoints
2025-03-06 21:55:53,185 - INFO - training batch 801, loss: 0.133, 25632/28000 datapoints
2025-03-06 21:55:53,332 - INFO - training batch 851, loss: 0.247, 27232/28000 datapoints
2025-03-06 21:55:53,404 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:55:53,451 - INFO - validation batch 51, loss: 1.757, 1632/6976 datapoints
2025-03-06 21:55:53,496 - INFO - validation batch 101, loss: 0.422, 3232/6976 datapoints
2025-03-06 21:55:53,543 - INFO - validation batch 151, loss: 0.548, 4832/6976 datapoints
2025-03-06 21:55:53,589 - INFO - validation batch 201, loss: 0.486, 6432/6976 datapoints
2025-03-06 21:55:53,605 - INFO - Epoch 241/800 done.
2025-03-06 21:55:53,605 - INFO - Final validation performance:
Loss: 0.667, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:53,606 - INFO - Beginning epoch 242/800
2025-03-06 21:55:53,610 - INFO - training batch 1, loss: 0.288, 32/28000 datapoints
2025-03-06 21:55:53,757 - INFO - training batch 51, loss: 0.125, 1632/28000 datapoints
2025-03-06 21:55:53,905 - INFO - training batch 101, loss: 0.104, 3232/28000 datapoints
2025-03-06 21:55:54,052 - INFO - training batch 151, loss: 0.183, 4832/28000 datapoints
2025-03-06 21:55:54,196 - INFO - training batch 201, loss: 0.102, 6432/28000 datapoints
2025-03-06 21:55:54,341 - INFO - training batch 251, loss: 0.278, 8032/28000 datapoints
2025-03-06 21:55:54,486 - INFO - training batch 301, loss: 0.590, 9632/28000 datapoints
2025-03-06 21:55:54,631 - INFO - training batch 351, loss: 0.206, 11232/28000 datapoints
2025-03-06 21:55:54,775 - INFO - training batch 401, loss: 0.468, 12832/28000 datapoints
2025-03-06 21:55:54,920 - INFO - training batch 451, loss: 0.401, 14432/28000 datapoints
2025-03-06 21:55:55,067 - INFO - training batch 501, loss: 0.150, 16032/28000 datapoints
2025-03-06 21:55:55,218 - INFO - training batch 551, loss: 0.238, 17632/28000 datapoints
2025-03-06 21:55:55,364 - INFO - training batch 601, loss: 0.205, 19232/28000 datapoints
2025-03-06 21:55:55,509 - INFO - training batch 651, loss: 0.041, 20832/28000 datapoints
2025-03-06 21:55:55,654 - INFO - training batch 701, loss: 0.193, 22432/28000 datapoints
2025-03-06 21:55:55,798 - INFO - training batch 751, loss: 0.155, 24032/28000 datapoints
2025-03-06 21:55:55,944 - INFO - training batch 801, loss: 0.131, 25632/28000 datapoints
2025-03-06 21:55:56,089 - INFO - training batch 851, loss: 0.244, 27232/28000 datapoints
2025-03-06 21:55:56,161 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:55:56,207 - INFO - validation batch 51, loss: 1.759, 1632/6976 datapoints
2025-03-06 21:55:56,253 - INFO - validation batch 101, loss: 0.425, 3232/6976 datapoints
2025-03-06 21:55:56,299 - INFO - validation batch 151, loss: 0.552, 4832/6976 datapoints
2025-03-06 21:55:56,346 - INFO - validation batch 201, loss: 0.484, 6432/6976 datapoints
2025-03-06 21:55:56,361 - INFO - Epoch 242/800 done.
2025-03-06 21:55:56,361 - INFO - Final validation performance:
Loss: 0.669, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:56,362 - INFO - Beginning epoch 243/800
2025-03-06 21:55:56,366 - INFO - training batch 1, loss: 0.285, 32/28000 datapoints
2025-03-06 21:55:56,510 - INFO - training batch 51, loss: 0.123, 1632/28000 datapoints
2025-03-06 21:55:56,656 - INFO - training batch 101, loss: 0.103, 3232/28000 datapoints
2025-03-06 21:55:56,799 - INFO - training batch 151, loss: 0.179, 4832/28000 datapoints
2025-03-06 21:55:56,956 - INFO - training batch 201, loss: 0.101, 6432/28000 datapoints
2025-03-06 21:55:57,106 - INFO - training batch 251, loss: 0.277, 8032/28000 datapoints
2025-03-06 21:55:57,249 - INFO - training batch 301, loss: 0.588, 9632/28000 datapoints
2025-03-06 21:55:57,392 - INFO - training batch 351, loss: 0.206, 11232/28000 datapoints
2025-03-06 21:55:57,541 - INFO - training batch 401, loss: 0.465, 12832/28000 datapoints
2025-03-06 21:55:57,687 - INFO - training batch 451, loss: 0.400, 14432/28000 datapoints
2025-03-06 21:55:57,833 - INFO - training batch 501, loss: 0.149, 16032/28000 datapoints
2025-03-06 21:55:57,980 - INFO - training batch 551, loss: 0.235, 17632/28000 datapoints
2025-03-06 21:55:58,128 - INFO - training batch 601, loss: 0.206, 19232/28000 datapoints
2025-03-06 21:55:58,273 - INFO - training batch 651, loss: 0.040, 20832/28000 datapoints
2025-03-06 21:55:58,416 - INFO - training batch 701, loss: 0.192, 22432/28000 datapoints
2025-03-06 21:55:58,558 - INFO - training batch 751, loss: 0.155, 24032/28000 datapoints
2025-03-06 21:55:58,702 - INFO - training batch 801, loss: 0.130, 25632/28000 datapoints
2025-03-06 21:55:58,848 - INFO - training batch 851, loss: 0.242, 27232/28000 datapoints
2025-03-06 21:55:58,918 - INFO - validation batch 1, loss: 0.123, 32/6976 datapoints
2025-03-06 21:55:58,965 - INFO - validation batch 51, loss: 1.764, 1632/6976 datapoints
2025-03-06 21:55:59,011 - INFO - validation batch 101, loss: 0.427, 3232/6976 datapoints
2025-03-06 21:55:59,057 - INFO - validation batch 151, loss: 0.552, 4832/6976 datapoints
2025-03-06 21:55:59,103 - INFO - validation batch 201, loss: 0.484, 6432/6976 datapoints
2025-03-06 21:55:59,119 - INFO - Epoch 243/800 done.
2025-03-06 21:55:59,119 - INFO - Final validation performance:
Loss: 0.670, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:55:59,119 - INFO - Beginning epoch 244/800
2025-03-06 21:55:59,123 - INFO - training batch 1, loss: 0.284, 32/28000 datapoints
2025-03-06 21:55:59,273 - INFO - training batch 51, loss: 0.121, 1632/28000 datapoints
2025-03-06 21:55:59,420 - INFO - training batch 101, loss: 0.102, 3232/28000 datapoints
2025-03-06 21:55:59,568 - INFO - training batch 151, loss: 0.177, 4832/28000 datapoints
2025-03-06 21:55:59,734 - INFO - training batch 201, loss: 0.100, 6432/28000 datapoints
2025-03-06 21:55:59,893 - INFO - training batch 251, loss: 0.276, 8032/28000 datapoints
2025-03-06 21:56:00,044 - INFO - training batch 301, loss: 0.586, 9632/28000 datapoints
2025-03-06 21:56:00,191 - INFO - training batch 351, loss: 0.205, 11232/28000 datapoints
2025-03-06 21:56:00,339 - INFO - training batch 401, loss: 0.463, 12832/28000 datapoints
2025-03-06 21:56:00,484 - INFO - training batch 451, loss: 0.399, 14432/28000 datapoints
2025-03-06 21:56:00,633 - INFO - training batch 501, loss: 0.149, 16032/28000 datapoints
2025-03-06 21:56:00,783 - INFO - training batch 551, loss: 0.234, 17632/28000 datapoints
2025-03-06 21:56:00,935 - INFO - training batch 601, loss: 0.200, 19232/28000 datapoints
2025-03-06 21:56:01,083 - INFO - training batch 651, loss: 0.040, 20832/28000 datapoints
2025-03-06 21:56:01,230 - INFO - training batch 701, loss: 0.190, 22432/28000 datapoints
2025-03-06 21:56:01,373 - INFO - training batch 751, loss: 0.155, 24032/28000 datapoints
2025-03-06 21:56:01,518 - INFO - training batch 801, loss: 0.129, 25632/28000 datapoints
2025-03-06 21:56:01,663 - INFO - training batch 851, loss: 0.240, 27232/28000 datapoints
2025-03-06 21:56:01,734 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:56:01,781 - INFO - validation batch 51, loss: 1.769, 1632/6976 datapoints
2025-03-06 21:56:01,827 - INFO - validation batch 101, loss: 0.428, 3232/6976 datapoints
2025-03-06 21:56:01,876 - INFO - validation batch 151, loss: 0.555, 4832/6976 datapoints
2025-03-06 21:56:01,921 - INFO - validation batch 201, loss: 0.485, 6432/6976 datapoints
2025-03-06 21:56:01,938 - INFO - Epoch 244/800 done.
2025-03-06 21:56:01,938 - INFO - Final validation performance:
Loss: 0.672, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:56:01,938 - INFO - Beginning epoch 245/800
2025-03-06 21:56:01,942 - INFO - training batch 1, loss: 0.282, 32/28000 datapoints
2025-03-06 21:56:02,091 - INFO - training batch 51, loss: 0.121, 1632/28000 datapoints
2025-03-06 21:56:02,237 - INFO - training batch 101, loss: 0.102, 3232/28000 datapoints
2025-03-06 21:56:02,380 - INFO - training batch 151, loss: 0.175, 4832/28000 datapoints
2025-03-06 21:56:02,525 - INFO - training batch 201, loss: 0.099, 6432/28000 datapoints
2025-03-06 21:56:02,669 - INFO - training batch 251, loss: 0.276, 8032/28000 datapoints
2025-03-06 21:56:02,816 - INFO - training batch 301, loss: 0.582, 9632/28000 datapoints
2025-03-06 21:56:02,970 - INFO - training batch 351, loss: 0.204, 11232/28000 datapoints
2025-03-06 21:56:03,121 - INFO - training batch 401, loss: 0.459, 12832/28000 datapoints
2025-03-06 21:56:03,267 - INFO - training batch 451, loss: 0.399, 14432/28000 datapoints
2025-03-06 21:56:03,412 - INFO - training batch 501, loss: 0.148, 16032/28000 datapoints
2025-03-06 21:56:03,562 - INFO - training batch 551, loss: 0.232, 17632/28000 datapoints
2025-03-06 21:56:03,710 - INFO - training batch 601, loss: 0.198, 19232/28000 datapoints
2025-03-06 21:56:03,858 - INFO - training batch 651, loss: 0.040, 20832/28000 datapoints
2025-03-06 21:56:04,009 - INFO - training batch 701, loss: 0.188, 22432/28000 datapoints
2025-03-06 21:56:04,151 - INFO - training batch 751, loss: 0.153, 24032/28000 datapoints
2025-03-06 21:56:04,295 - INFO - training batch 801, loss: 0.127, 25632/28000 datapoints
2025-03-06 21:56:04,440 - INFO - training batch 851, loss: 0.237, 27232/28000 datapoints
2025-03-06 21:56:04,514 - INFO - validation batch 1, loss: 0.123, 32/6976 datapoints
2025-03-06 21:56:04,559 - INFO - validation batch 51, loss: 1.772, 1632/6976 datapoints
2025-03-06 21:56:04,606 - INFO - validation batch 101, loss: 0.431, 3232/6976 datapoints
2025-03-06 21:56:04,652 - INFO - validation batch 151, loss: 0.558, 4832/6976 datapoints
2025-03-06 21:56:04,698 - INFO - validation batch 201, loss: 0.484, 6432/6976 datapoints
2025-03-06 21:56:04,714 - INFO - Epoch 245/800 done.
2025-03-06 21:56:04,714 - INFO - Final validation performance:
Loss: 0.674, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:56:04,714 - INFO - Beginning epoch 246/800
2025-03-06 21:56:04,718 - INFO - training batch 1, loss: 0.281, 32/28000 datapoints
2025-03-06 21:56:04,873 - INFO - training batch 51, loss: 0.119, 1632/28000 datapoints
2025-03-06 21:56:05,025 - INFO - training batch 101, loss: 0.101, 3232/28000 datapoints
2025-03-06 21:56:05,177 - INFO - training batch 151, loss: 0.172, 4832/28000 datapoints
2025-03-06 21:56:05,327 - INFO - training batch 201, loss: 0.098, 6432/28000 datapoints
2025-03-06 21:56:05,479 - INFO - training batch 251, loss: 0.274, 8032/28000 datapoints
2025-03-06 21:56:05,628 - INFO - training batch 301, loss: 0.581, 9632/28000 datapoints
2025-03-06 21:56:05,777 - INFO - training batch 351, loss: 0.204, 11232/28000 datapoints
2025-03-06 21:56:05,926 - INFO - training batch 401, loss: 0.456, 12832/28000 datapoints
2025-03-06 21:56:06,075 - INFO - training batch 451, loss: 0.398, 14432/28000 datapoints
2025-03-06 21:56:06,224 - INFO - training batch 501, loss: 0.147, 16032/28000 datapoints
2025-03-06 21:56:06,374 - INFO - training batch 551, loss: 0.230, 17632/28000 datapoints
2025-03-06 21:56:06,524 - INFO - training batch 601, loss: 0.196, 19232/28000 datapoints
2025-03-06 21:56:06,671 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 21:56:06,819 - INFO - training batch 701, loss: 0.187, 22432/28000 datapoints
2025-03-06 21:56:06,969 - INFO - training batch 751, loss: 0.153, 24032/28000 datapoints
2025-03-06 21:56:07,116 - INFO - training batch 801, loss: 0.126, 25632/28000 datapoints
2025-03-06 21:56:07,263 - INFO - training batch 851, loss: 0.236, 27232/28000 datapoints
2025-03-06 21:56:07,337 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:56:07,386 - INFO - validation batch 51, loss: 1.781, 1632/6976 datapoints
2025-03-06 21:56:07,439 - INFO - validation batch 101, loss: 0.431, 3232/6976 datapoints
2025-03-06 21:56:07,488 - INFO - validation batch 151, loss: 0.553, 4832/6976 datapoints
2025-03-06 21:56:07,536 - INFO - validation batch 201, loss: 0.483, 6432/6976 datapoints
2025-03-06 21:56:07,552 - INFO - Epoch 246/800 done.
2025-03-06 21:56:07,552 - INFO - Final validation performance:
Loss: 0.674, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:56:07,552 - INFO - Beginning epoch 247/800
2025-03-06 21:56:07,557 - INFO - training batch 1, loss: 0.279, 32/28000 datapoints
2025-03-06 21:56:07,701 - INFO - training batch 51, loss: 0.118, 1632/28000 datapoints
2025-03-06 21:56:07,858 - INFO - training batch 101, loss: 0.101, 3232/28000 datapoints
2025-03-06 21:56:08,002 - INFO - training batch 151, loss: 0.171, 4832/28000 datapoints
2025-03-06 21:56:08,150 - INFO - training batch 201, loss: 0.098, 6432/28000 datapoints
2025-03-06 21:56:08,294 - INFO - training batch 251, loss: 0.274, 8032/28000 datapoints
2025-03-06 21:56:08,436 - INFO - training batch 301, loss: 0.577, 9632/28000 datapoints
2025-03-06 21:56:08,580 - INFO - training batch 351, loss: 0.203, 11232/28000 datapoints
2025-03-06 21:56:08,722 - INFO - training batch 401, loss: 0.453, 12832/28000 datapoints
2025-03-06 21:56:08,868 - INFO - training batch 451, loss: 0.398, 14432/28000 datapoints
2025-03-06 21:56:09,021 - INFO - training batch 501, loss: 0.148, 16032/28000 datapoints
2025-03-06 21:56:09,168 - INFO - training batch 551, loss: 0.229, 17632/28000 datapoints
2025-03-06 21:56:09,321 - INFO - training batch 601, loss: 0.191, 19232/28000 datapoints
2025-03-06 21:56:09,465 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 21:56:09,614 - INFO - training batch 701, loss: 0.186, 22432/28000 datapoints
2025-03-06 21:56:09,765 - INFO - training batch 751, loss: 0.151, 24032/28000 datapoints
2025-03-06 21:56:09,942 - INFO - training batch 801, loss: 0.125, 25632/28000 datapoints
2025-03-06 21:56:10,089 - INFO - training batch 851, loss: 0.233, 27232/28000 datapoints
2025-03-06 21:56:10,160 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:56:10,207 - INFO - validation batch 51, loss: 1.783, 1632/6976 datapoints
2025-03-06 21:56:10,253 - INFO - validation batch 101, loss: 0.435, 3232/6976 datapoints
2025-03-06 21:56:10,302 - INFO - validation batch 151, loss: 0.560, 4832/6976 datapoints
2025-03-06 21:56:10,350 - INFO - validation batch 201, loss: 0.483, 6432/6976 datapoints
2025-03-06 21:56:10,365 - INFO - Epoch 247/800 done.
2025-03-06 21:56:10,365 - INFO - Final validation performance:
Loss: 0.677, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:56:10,366 - INFO - Beginning epoch 248/800
2025-03-06 21:56:10,370 - INFO - training batch 1, loss: 0.277, 32/28000 datapoints
2025-03-06 21:56:10,515 - INFO - training batch 51, loss: 0.117, 1632/28000 datapoints
2025-03-06 21:56:10,659 - INFO - training batch 101, loss: 0.100, 3232/28000 datapoints
2025-03-06 21:56:10,806 - INFO - training batch 151, loss: 0.168, 4832/28000 datapoints
2025-03-06 21:56:10,957 - INFO - training batch 201, loss: 0.097, 6432/28000 datapoints
2025-03-06 21:56:11,100 - INFO - training batch 251, loss: 0.273, 8032/28000 datapoints
2025-03-06 21:56:11,244 - INFO - training batch 301, loss: 0.577, 9632/28000 datapoints
2025-03-06 21:56:11,392 - INFO - training batch 351, loss: 0.203, 11232/28000 datapoints
2025-03-06 21:56:11,543 - INFO - training batch 401, loss: 0.450, 12832/28000 datapoints
2025-03-06 21:56:11,690 - INFO - training batch 451, loss: 0.397, 14432/28000 datapoints
2025-03-06 21:56:11,839 - INFO - training batch 501, loss: 0.147, 16032/28000 datapoints
2025-03-06 21:56:12,023 - INFO - training batch 551, loss: 0.227, 17632/28000 datapoints
2025-03-06 21:56:12,177 - INFO - training batch 601, loss: 0.193, 19232/28000 datapoints
2025-03-06 21:56:12,325 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 21:56:12,472 - INFO - training batch 701, loss: 0.184, 22432/28000 datapoints
2025-03-06 21:56:12,618 - INFO - training batch 751, loss: 0.151, 24032/28000 datapoints
2025-03-06 21:56:12,767 - INFO - training batch 801, loss: 0.123, 25632/28000 datapoints
2025-03-06 21:56:12,917 - INFO - training batch 851, loss: 0.231, 27232/28000 datapoints
2025-03-06 21:56:12,991 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:56:13,049 - INFO - validation batch 51, loss: 1.788, 1632/6976 datapoints
2025-03-06 21:56:13,106 - INFO - validation batch 101, loss: 0.437, 3232/6976 datapoints
2025-03-06 21:56:13,152 - INFO - validation batch 151, loss: 0.561, 4832/6976 datapoints
2025-03-06 21:56:13,198 - INFO - validation batch 201, loss: 0.483, 6432/6976 datapoints
2025-03-06 21:56:13,214 - INFO - Epoch 248/800 done.
2025-03-06 21:56:13,214 - INFO - Final validation performance:
Loss: 0.679, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:56:13,215 - INFO - Beginning epoch 249/800
2025-03-06 21:56:13,219 - INFO - training batch 1, loss: 0.275, 32/28000 datapoints
2025-03-06 21:56:13,373 - INFO - training batch 51, loss: 0.117, 1632/28000 datapoints
2025-03-06 21:56:13,516 - INFO - training batch 101, loss: 0.099, 3232/28000 datapoints
2025-03-06 21:56:13,677 - INFO - training batch 151, loss: 0.167, 4832/28000 datapoints
2025-03-06 21:56:13,838 - INFO - training batch 201, loss: 0.096, 6432/28000 datapoints
2025-03-06 21:56:13,985 - INFO - training batch 251, loss: 0.272, 8032/28000 datapoints
2025-03-06 21:56:14,134 - INFO - training batch 301, loss: 0.574, 9632/28000 datapoints
2025-03-06 21:56:14,281 - INFO - training batch 351, loss: 0.202, 11232/28000 datapoints
2025-03-06 21:56:14,425 - INFO - training batch 401, loss: 0.447, 12832/28000 datapoints
2025-03-06 21:56:14,577 - INFO - training batch 451, loss: 0.396, 14432/28000 datapoints
2025-03-06 21:56:14,722 - INFO - training batch 501, loss: 0.146, 16032/28000 datapoints
2025-03-06 21:56:14,871 - INFO - training batch 551, loss: 0.226, 17632/28000 datapoints
2025-03-06 21:56:15,018 - INFO - training batch 601, loss: 0.189, 19232/28000 datapoints
2025-03-06 21:56:15,179 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 21:56:15,326 - INFO - training batch 701, loss: 0.183, 22432/28000 datapoints
2025-03-06 21:56:15,470 - INFO - training batch 751, loss: 0.149, 24032/28000 datapoints
2025-03-06 21:56:15,621 - INFO - training batch 801, loss: 0.122, 25632/28000 datapoints
2025-03-06 21:56:15,805 - INFO - training batch 851, loss: 0.229, 27232/28000 datapoints
2025-03-06 21:56:15,881 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:56:15,928 - INFO - validation batch 51, loss: 1.792, 1632/6976 datapoints
2025-03-06 21:56:15,974 - INFO - validation batch 101, loss: 0.440, 3232/6976 datapoints
2025-03-06 21:56:16,020 - INFO - validation batch 151, loss: 0.563, 4832/6976 datapoints
2025-03-06 21:56:16,074 - INFO - validation batch 201, loss: 0.482, 6432/6976 datapoints
2025-03-06 21:56:16,089 - INFO - Epoch 249/800 done.
2025-03-06 21:56:16,089 - INFO - Final validation performance:
Loss: 0.680, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:56:16,090 - INFO - Beginning epoch 250/800
2025-03-06 21:56:16,094 - INFO - training batch 1, loss: 0.273, 32/28000 datapoints
2025-03-06 21:56:16,241 - INFO - training batch 51, loss: 0.115, 1632/28000 datapoints
2025-03-06 21:56:16,386 - INFO - training batch 101, loss: 0.099, 3232/28000 datapoints
2025-03-06 21:56:16,531 - INFO - training batch 151, loss: 0.165, 4832/28000 datapoints
2025-03-06 21:56:16,674 - INFO - training batch 201, loss: 0.095, 6432/28000 datapoints
2025-03-06 21:56:16,818 - INFO - training batch 251, loss: 0.271, 8032/28000 datapoints
2025-03-06 21:56:16,969 - INFO - training batch 301, loss: 0.572, 9632/28000 datapoints
2025-03-06 21:56:17,112 - INFO - training batch 351, loss: 0.201, 11232/28000 datapoints
2025-03-06 21:56:17,255 - INFO - training batch 401, loss: 0.444, 12832/28000 datapoints
2025-03-06 21:56:17,401 - INFO - training batch 451, loss: 0.395, 14432/28000 datapoints
2025-03-06 21:56:17,544 - INFO - training batch 501, loss: 0.146, 16032/28000 datapoints
2025-03-06 21:56:17,689 - INFO - training batch 551, loss: 0.223, 17632/28000 datapoints
2025-03-06 21:56:17,833 - INFO - training batch 601, loss: 0.184, 19232/28000 datapoints
2025-03-06 21:56:17,980 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 21:56:18,128 - INFO - training batch 701, loss: 0.181, 22432/28000 datapoints
2025-03-06 21:56:18,276 - INFO - training batch 751, loss: 0.149, 24032/28000 datapoints
2025-03-06 21:56:18,419 - INFO - training batch 801, loss: 0.121, 25632/28000 datapoints
2025-03-06 21:56:18,563 - INFO - training batch 851, loss: 0.227, 27232/28000 datapoints
2025-03-06 21:56:18,633 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:56:18,678 - INFO - validation batch 51, loss: 1.799, 1632/6976 datapoints
2025-03-06 21:56:18,726 - INFO - validation batch 101, loss: 0.442, 3232/6976 datapoints
2025-03-06 21:56:18,773 - INFO - validation batch 151, loss: 0.563, 4832/6976 datapoints
2025-03-06 21:56:18,819 - INFO - validation batch 201, loss: 0.482, 6432/6976 datapoints
2025-03-06 21:56:18,834 - INFO - Epoch 250/800 done.
2025-03-06 21:56:18,835 - INFO - Final validation performance:
Loss: 0.682, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:56:18,835 - INFO - Beginning epoch 251/800
2025-03-06 21:56:18,841 - INFO - training batch 1, loss: 0.271, 32/28000 datapoints
2025-03-06 21:56:18,988 - INFO - training batch 51, loss: 0.114, 1632/28000 datapoints
2025-03-06 21:56:19,134 - INFO - training batch 101, loss: 0.098, 3232/28000 datapoints
2025-03-06 21:56:19,281 - INFO - training batch 151, loss: 0.163, 4832/28000 datapoints
2025-03-06 21:56:19,442 - INFO - training batch 201, loss: 0.094, 6432/28000 datapoints
2025-03-06 21:56:19,594 - INFO - training batch 251, loss: 0.272, 8032/28000 datapoints
2025-03-06 21:56:19,742 - INFO - training batch 301, loss: 0.569, 9632/28000 datapoints
2025-03-06 21:56:19,901 - INFO - training batch 351, loss: 0.201, 11232/28000 datapoints
2025-03-06 21:56:20,080 - INFO - training batch 401, loss: 0.440, 12832/28000 datapoints
2025-03-06 21:56:20,234 - INFO - training batch 451, loss: 0.394, 14432/28000 datapoints
2025-03-06 21:56:20,381 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-06 21:56:20,531 - INFO - training batch 551, loss: 0.221, 17632/28000 datapoints
2025-03-06 21:56:20,680 - INFO - training batch 601, loss: 0.183, 19232/28000 datapoints
2025-03-06 21:56:20,828 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 21:56:20,979 - INFO - training batch 701, loss: 0.180, 22432/28000 datapoints
2025-03-06 21:56:21,122 - INFO - training batch 751, loss: 0.148, 24032/28000 datapoints
2025-03-06 21:56:21,264 - INFO - training batch 801, loss: 0.119, 25632/28000 datapoints
2025-03-06 21:56:21,422 - INFO - training batch 851, loss: 0.225, 27232/28000 datapoints
2025-03-06 21:56:21,495 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:56:21,541 - INFO - validation batch 51, loss: 1.802, 1632/6976 datapoints
2025-03-06 21:56:21,587 - INFO - validation batch 101, loss: 0.444, 3232/6976 datapoints
2025-03-06 21:56:21,633 - INFO - validation batch 151, loss: 0.563, 4832/6976 datapoints
2025-03-06 21:56:21,679 - INFO - validation batch 201, loss: 0.483, 6432/6976 datapoints
2025-03-06 21:56:21,694 - INFO - Epoch 251/800 done.
2025-03-06 21:56:21,695 - INFO - Final validation performance:
Loss: 0.683, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:56:21,695 - INFO - Beginning epoch 252/800
2025-03-06 21:56:21,699 - INFO - training batch 1, loss: 0.269, 32/28000 datapoints
2025-03-06 21:56:21,849 - INFO - training batch 51, loss: 0.112, 1632/28000 datapoints
2025-03-06 21:56:22,000 - INFO - training batch 101, loss: 0.097, 3232/28000 datapoints
2025-03-06 21:56:22,148 - INFO - training batch 151, loss: 0.161, 4832/28000 datapoints
2025-03-06 21:56:22,292 - INFO - training batch 201, loss: 0.093, 6432/28000 datapoints
2025-03-06 21:56:22,435 - INFO - training batch 251, loss: 0.270, 8032/28000 datapoints
2025-03-06 21:56:22,579 - INFO - training batch 301, loss: 0.567, 9632/28000 datapoints
2025-03-06 21:56:22,724 - INFO - training batch 351, loss: 0.201, 11232/28000 datapoints
2025-03-06 21:56:22,870 - INFO - training batch 401, loss: 0.438, 12832/28000 datapoints
2025-03-06 21:56:23,014 - INFO - training batch 451, loss: 0.392, 14432/28000 datapoints
2025-03-06 21:56:23,158 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-06 21:56:23,303 - INFO - training batch 551, loss: 0.219, 17632/28000 datapoints
2025-03-06 21:56:23,453 - INFO - training batch 601, loss: 0.181, 19232/28000 datapoints
2025-03-06 21:56:23,598 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 21:56:23,743 - INFO - training batch 701, loss: 0.178, 22432/28000 datapoints
2025-03-06 21:56:23,888 - INFO - training batch 751, loss: 0.147, 24032/28000 datapoints
2025-03-06 21:56:24,031 - INFO - training batch 801, loss: 0.118, 25632/28000 datapoints
2025-03-06 21:56:24,179 - INFO - training batch 851, loss: 0.222, 27232/28000 datapoints
2025-03-06 21:56:24,250 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:56:24,296 - INFO - validation batch 51, loss: 1.808, 1632/6976 datapoints
2025-03-06 21:56:24,342 - INFO - validation batch 101, loss: 0.446, 3232/6976 datapoints
2025-03-06 21:56:24,386 - INFO - validation batch 151, loss: 0.566, 4832/6976 datapoints
2025-03-06 21:56:24,432 - INFO - validation batch 201, loss: 0.483, 6432/6976 datapoints
2025-03-06 21:56:24,448 - INFO - Epoch 252/800 done.
2025-03-06 21:56:24,448 - INFO - Final validation performance:
Loss: 0.686, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:56:24,448 - INFO - Beginning epoch 253/800
2025-03-06 21:56:24,455 - INFO - training batch 1, loss: 0.268, 32/28000 datapoints
2025-03-06 21:56:24,600 - INFO - training batch 51, loss: 0.112, 1632/28000 datapoints
2025-03-06 21:56:24,746 - INFO - training batch 101, loss: 0.098, 3232/28000 datapoints
2025-03-06 21:56:24,904 - INFO - training batch 151, loss: 0.160, 4832/28000 datapoints
2025-03-06 21:56:25,054 - INFO - training batch 201, loss: 0.093, 6432/28000 datapoints
2025-03-06 21:56:25,206 - INFO - training batch 251, loss: 0.270, 8032/28000 datapoints
2025-03-06 21:56:25,353 - INFO - training batch 301, loss: 0.565, 9632/28000 datapoints
2025-03-06 21:56:25,502 - INFO - training batch 351, loss: 0.200, 11232/28000 datapoints
2025-03-06 21:56:25,650 - INFO - training batch 401, loss: 0.434, 12832/28000 datapoints
2025-03-06 21:56:25,798 - INFO - training batch 451, loss: 0.392, 14432/28000 datapoints
2025-03-06 21:56:25,949 - INFO - training batch 501, loss: 0.144, 16032/28000 datapoints
2025-03-06 21:56:26,102 - INFO - training batch 551, loss: 0.217, 17632/28000 datapoints
2025-03-06 21:56:26,267 - INFO - training batch 601, loss: 0.179, 19232/28000 datapoints
2025-03-06 21:56:26,439 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-06 21:56:26,588 - INFO - training batch 701, loss: 0.176, 22432/28000 datapoints
2025-03-06 21:56:26,738 - INFO - training batch 751, loss: 0.145, 24032/28000 datapoints
2025-03-06 21:56:26,884 - INFO - training batch 801, loss: 0.117, 25632/28000 datapoints
2025-03-06 21:56:27,033 - INFO - training batch 851, loss: 0.220, 27232/28000 datapoints
2025-03-06 21:56:27,108 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:56:27,158 - INFO - validation batch 51, loss: 1.813, 1632/6976 datapoints
2025-03-06 21:56:27,208 - INFO - validation batch 101, loss: 0.449, 3232/6976 datapoints
2025-03-06 21:56:27,258 - INFO - validation batch 151, loss: 0.566, 4832/6976 datapoints
2025-03-06 21:56:27,307 - INFO - validation batch 201, loss: 0.481, 6432/6976 datapoints
2025-03-06 21:56:27,324 - INFO - Epoch 253/800 done.
2025-03-06 21:56:27,324 - INFO - Final validation performance:
Loss: 0.687, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:56:27,324 - INFO - Beginning epoch 254/800
2025-03-06 21:56:27,329 - INFO - training batch 1, loss: 0.266, 32/28000 datapoints
2025-03-06 21:56:27,479 - INFO - training batch 51, loss: 0.111, 1632/28000 datapoints
2025-03-06 21:56:27,638 - INFO - training batch 101, loss: 0.096, 3232/28000 datapoints
2025-03-06 21:56:27,789 - INFO - training batch 151, loss: 0.158, 4832/28000 datapoints
2025-03-06 21:56:27,942 - INFO - training batch 201, loss: 0.092, 6432/28000 datapoints
2025-03-06 21:56:28,099 - INFO - training batch 251, loss: 0.269, 8032/28000 datapoints
2025-03-06 21:56:28,249 - INFO - training batch 301, loss: 0.563, 9632/28000 datapoints
2025-03-06 21:56:28,395 - INFO - training batch 351, loss: 0.200, 11232/28000 datapoints
2025-03-06 21:56:28,547 - INFO - training batch 401, loss: 0.431, 12832/28000 datapoints
2025-03-06 21:56:28,693 - INFO - training batch 451, loss: 0.391, 14432/28000 datapoints
2025-03-06 21:56:28,844 - INFO - training batch 501, loss: 0.144, 16032/28000 datapoints
2025-03-06 21:56:28,992 - INFO - training batch 551, loss: 0.217, 17632/28000 datapoints
2025-03-06 21:56:29,143 - INFO - training batch 601, loss: 0.179, 19232/28000 datapoints
2025-03-06 21:56:29,293 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-06 21:56:29,440 - INFO - training batch 701, loss: 0.175, 22432/28000 datapoints
2025-03-06 21:56:29,654 - INFO - training batch 751, loss: 0.145, 24032/28000 datapoints
2025-03-06 21:56:29,801 - INFO - training batch 801, loss: 0.115, 25632/28000 datapoints
2025-03-06 21:56:29,947 - INFO - training batch 851, loss: 0.219, 27232/28000 datapoints
2025-03-06 21:56:30,034 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:56:30,111 - INFO - validation batch 51, loss: 1.817, 1632/6976 datapoints
2025-03-06 21:56:30,171 - INFO - validation batch 101, loss: 0.452, 3232/6976 datapoints
2025-03-06 21:56:30,223 - INFO - validation batch 151, loss: 0.568, 4832/6976 datapoints
2025-03-06 21:56:30,269 - INFO - validation batch 201, loss: 0.481, 6432/6976 datapoints
2025-03-06 21:56:30,285 - INFO - Epoch 254/800 done.
2025-03-06 21:56:30,285 - INFO - Final validation performance:
Loss: 0.689, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:56:30,286 - INFO - Beginning epoch 255/800
2025-03-06 21:56:30,290 - INFO - training batch 1, loss: 0.264, 32/28000 datapoints
2025-03-06 21:56:30,436 - INFO - training batch 51, loss: 0.110, 1632/28000 datapoints
2025-03-06 21:56:30,581 - INFO - training batch 101, loss: 0.096, 3232/28000 datapoints
2025-03-06 21:56:30,728 - INFO - training batch 151, loss: 0.156, 4832/28000 datapoints
2025-03-06 21:56:30,877 - INFO - training batch 201, loss: 0.091, 6432/28000 datapoints
2025-03-06 21:56:31,022 - INFO - training batch 251, loss: 0.268, 8032/28000 datapoints
2025-03-06 21:56:31,167 - INFO - training batch 301, loss: 0.559, 9632/28000 datapoints
2025-03-06 21:56:31,311 - INFO - training batch 351, loss: 0.200, 11232/28000 datapoints
2025-03-06 21:56:31,452 - INFO - training batch 401, loss: 0.428, 12832/28000 datapoints
2025-03-06 21:56:31,596 - INFO - training batch 451, loss: 0.390, 14432/28000 datapoints
2025-03-06 21:56:31,741 - INFO - training batch 501, loss: 0.144, 16032/28000 datapoints
2025-03-06 21:56:31,893 - INFO - training batch 551, loss: 0.214, 17632/28000 datapoints
2025-03-06 21:56:32,040 - INFO - training batch 601, loss: 0.174, 19232/28000 datapoints
2025-03-06 21:56:32,190 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-06 21:56:32,331 - INFO - training batch 701, loss: 0.173, 22432/28000 datapoints
2025-03-06 21:56:32,475 - INFO - training batch 751, loss: 0.144, 24032/28000 datapoints
2025-03-06 21:56:32,617 - INFO - training batch 801, loss: 0.114, 25632/28000 datapoints
2025-03-06 21:56:32,760 - INFO - training batch 851, loss: 0.218, 27232/28000 datapoints
2025-03-06 21:56:32,832 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 21:56:32,880 - INFO - validation batch 51, loss: 1.823, 1632/6976 datapoints
2025-03-06 21:56:32,926 - INFO - validation batch 101, loss: 0.453, 3232/6976 datapoints
2025-03-06 21:56:32,972 - INFO - validation batch 151, loss: 0.570, 4832/6976 datapoints
2025-03-06 21:56:33,018 - INFO - validation batch 201, loss: 0.483, 6432/6976 datapoints
2025-03-06 21:56:33,034 - INFO - Epoch 255/800 done.
2025-03-06 21:56:33,034 - INFO - Final validation performance:
Loss: 0.691, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:56:33,035 - INFO - Beginning epoch 256/800
2025-03-06 21:56:33,039 - INFO - training batch 1, loss: 0.262, 32/28000 datapoints
2025-03-06 21:56:33,190 - INFO - training batch 51, loss: 0.110, 1632/28000 datapoints
2025-03-06 21:56:33,334 - INFO - training batch 101, loss: 0.096, 3232/28000 datapoints
2025-03-06 21:56:33,486 - INFO - training batch 151, loss: 0.155, 4832/28000 datapoints
2025-03-06 21:56:33,640 - INFO - training batch 201, loss: 0.090, 6432/28000 datapoints
2025-03-06 21:56:33,791 - INFO - training batch 251, loss: 0.268, 8032/28000 datapoints
2025-03-06 21:56:33,938 - INFO - training batch 301, loss: 0.556, 9632/28000 datapoints
2025-03-06 21:56:34,090 - INFO - training batch 351, loss: 0.199, 11232/28000 datapoints
2025-03-06 21:56:34,241 - INFO - training batch 401, loss: 0.425, 12832/28000 datapoints
2025-03-06 21:56:34,389 - INFO - training batch 451, loss: 0.390, 14432/28000 datapoints
2025-03-06 21:56:34,540 - INFO - training batch 501, loss: 0.143, 16032/28000 datapoints
2025-03-06 21:56:34,686 - INFO - training batch 551, loss: 0.212, 17632/28000 datapoints
2025-03-06 21:56:34,830 - INFO - training batch 601, loss: 0.172, 19232/28000 datapoints
2025-03-06 21:56:34,975 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 21:56:35,126 - INFO - training batch 701, loss: 0.171, 22432/28000 datapoints
2025-03-06 21:56:35,272 - INFO - training batch 751, loss: 0.142, 24032/28000 datapoints
2025-03-06 21:56:35,416 - INFO - training batch 801, loss: 0.114, 25632/28000 datapoints
2025-03-06 21:56:35,563 - INFO - training batch 851, loss: 0.214, 27232/28000 datapoints
2025-03-06 21:56:35,637 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 21:56:35,684 - INFO - validation batch 51, loss: 1.828, 1632/6976 datapoints
2025-03-06 21:56:35,733 - INFO - validation batch 101, loss: 0.456, 3232/6976 datapoints
2025-03-06 21:56:35,780 - INFO - validation batch 151, loss: 0.573, 4832/6976 datapoints
2025-03-06 21:56:35,825 - INFO - validation batch 201, loss: 0.480, 6432/6976 datapoints
2025-03-06 21:56:35,843 - INFO - Epoch 256/800 done.
2025-03-06 21:56:35,844 - INFO - Final validation performance:
Loss: 0.693, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:56:35,844 - INFO - Beginning epoch 257/800
2025-03-06 21:56:35,848 - INFO - training batch 1, loss: 0.260, 32/28000 datapoints
2025-03-06 21:56:35,993 - INFO - training batch 51, loss: 0.108, 1632/28000 datapoints
2025-03-06 21:56:36,141 - INFO - training batch 101, loss: 0.096, 3232/28000 datapoints
2025-03-06 21:56:36,289 - INFO - training batch 151, loss: 0.154, 4832/28000 datapoints
2025-03-06 21:56:36,433 - INFO - training batch 201, loss: 0.089, 6432/28000 datapoints
2025-03-06 21:56:36,577 - INFO - training batch 251, loss: 0.267, 8032/28000 datapoints
2025-03-06 21:56:36,727 - INFO - training batch 301, loss: 0.554, 9632/28000 datapoints
2025-03-06 21:56:36,873 - INFO - training batch 351, loss: 0.198, 11232/28000 datapoints
2025-03-06 21:56:37,019 - INFO - training batch 401, loss: 0.421, 12832/28000 datapoints
2025-03-06 21:56:37,165 - INFO - training batch 451, loss: 0.389, 14432/28000 datapoints
2025-03-06 21:56:37,310 - INFO - training batch 501, loss: 0.142, 16032/28000 datapoints
2025-03-06 21:56:37,455 - INFO - training batch 551, loss: 0.211, 17632/28000 datapoints
2025-03-06 21:56:37,600 - INFO - training batch 601, loss: 0.172, 19232/28000 datapoints
2025-03-06 21:56:37,747 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 21:56:37,903 - INFO - training batch 701, loss: 0.170, 22432/28000 datapoints
2025-03-06 21:56:38,047 - INFO - training batch 751, loss: 0.142, 24032/28000 datapoints
2025-03-06 21:56:38,207 - INFO - training batch 801, loss: 0.112, 25632/28000 datapoints
2025-03-06 21:56:38,355 - INFO - training batch 851, loss: 0.213, 27232/28000 datapoints
2025-03-06 21:56:38,426 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 21:56:38,472 - INFO - validation batch 51, loss: 1.831, 1632/6976 datapoints
2025-03-06 21:56:38,519 - INFO - validation batch 101, loss: 0.458, 3232/6976 datapoints
2025-03-06 21:56:38,566 - INFO - validation batch 151, loss: 0.575, 4832/6976 datapoints
2025-03-06 21:56:38,613 - INFO - validation batch 201, loss: 0.481, 6432/6976 datapoints
2025-03-06 21:56:38,629 - INFO - Epoch 257/800 done.
2025-03-06 21:56:38,629 - INFO - Final validation performance:
Loss: 0.694, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:56:38,629 - INFO - Beginning epoch 258/800
2025-03-06 21:56:38,633 - INFO - training batch 1, loss: 0.257, 32/28000 datapoints
2025-03-06 21:56:38,781 - INFO - training batch 51, loss: 0.108, 1632/28000 datapoints
2025-03-06 21:56:38,927 - INFO - training batch 101, loss: 0.094, 3232/28000 datapoints
2025-03-06 21:56:39,071 - INFO - training batch 151, loss: 0.153, 4832/28000 datapoints
2025-03-06 21:56:39,220 - INFO - training batch 201, loss: 0.089, 6432/28000 datapoints
2025-03-06 21:56:39,373 - INFO - training batch 251, loss: 0.265, 8032/28000 datapoints
2025-03-06 21:56:39,521 - INFO - training batch 301, loss: 0.552, 9632/28000 datapoints
2025-03-06 21:56:39,677 - INFO - training batch 351, loss: 0.198, 11232/28000 datapoints
2025-03-06 21:56:39,829 - INFO - training batch 401, loss: 0.418, 12832/28000 datapoints
2025-03-06 21:56:39,979 - INFO - training batch 451, loss: 0.387, 14432/28000 datapoints
2025-03-06 21:56:40,158 - INFO - training batch 501, loss: 0.142, 16032/28000 datapoints
2025-03-06 21:56:40,319 - INFO - training batch 551, loss: 0.209, 17632/28000 datapoints
2025-03-06 21:56:40,466 - INFO - training batch 601, loss: 0.166, 19232/28000 datapoints
2025-03-06 21:56:40,618 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 21:56:40,768 - INFO - training batch 701, loss: 0.169, 22432/28000 datapoints
2025-03-06 21:56:40,918 - INFO - training batch 751, loss: 0.141, 24032/28000 datapoints
2025-03-06 21:56:41,063 - INFO - training batch 801, loss: 0.110, 25632/28000 datapoints
2025-03-06 21:56:41,212 - INFO - training batch 851, loss: 0.211, 27232/28000 datapoints
2025-03-06 21:56:41,285 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 21:56:41,332 - INFO - validation batch 51, loss: 1.838, 1632/6976 datapoints
2025-03-06 21:56:41,378 - INFO - validation batch 101, loss: 0.462, 3232/6976 datapoints
2025-03-06 21:56:41,423 - INFO - validation batch 151, loss: 0.575, 4832/6976 datapoints
2025-03-06 21:56:41,468 - INFO - validation batch 201, loss: 0.481, 6432/6976 datapoints
2025-03-06 21:56:41,484 - INFO - Epoch 258/800 done.
2025-03-06 21:56:41,484 - INFO - Final validation performance:
Loss: 0.696, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:56:41,484 - INFO - Beginning epoch 259/800
2025-03-06 21:56:41,489 - INFO - training batch 1, loss: 0.255, 32/28000 datapoints
2025-03-06 21:56:41,634 - INFO - training batch 51, loss: 0.107, 1632/28000 datapoints
2025-03-06 21:56:41,782 - INFO - training batch 101, loss: 0.094, 3232/28000 datapoints
2025-03-06 21:56:41,928 - INFO - training batch 151, loss: 0.152, 4832/28000 datapoints
2025-03-06 21:56:42,072 - INFO - training batch 201, loss: 0.088, 6432/28000 datapoints
2025-03-06 21:56:42,221 - INFO - training batch 251, loss: 0.265, 8032/28000 datapoints
2025-03-06 21:56:42,364 - INFO - training batch 301, loss: 0.550, 9632/28000 datapoints
2025-03-06 21:56:42,508 - INFO - training batch 351, loss: 0.197, 11232/28000 datapoints
2025-03-06 21:56:42,651 - INFO - training batch 401, loss: 0.415, 12832/28000 datapoints
2025-03-06 21:56:42,796 - INFO - training batch 451, loss: 0.387, 14432/28000 datapoints
2025-03-06 21:56:42,941 - INFO - training batch 501, loss: 0.142, 16032/28000 datapoints
2025-03-06 21:56:43,085 - INFO - training batch 551, loss: 0.207, 17632/28000 datapoints
2025-03-06 21:56:43,231 - INFO - training batch 601, loss: 0.165, 19232/28000 datapoints
2025-03-06 21:56:43,379 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 21:56:43,526 - INFO - training batch 701, loss: 0.167, 22432/28000 datapoints
2025-03-06 21:56:43,668 - INFO - training batch 751, loss: 0.140, 24032/28000 datapoints
2025-03-06 21:56:43,814 - INFO - training batch 801, loss: 0.109, 25632/28000 datapoints
2025-03-06 21:56:43,960 - INFO - training batch 851, loss: 0.209, 27232/28000 datapoints
2025-03-06 21:56:44,030 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 21:56:44,076 - INFO - validation batch 51, loss: 1.840, 1632/6976 datapoints
2025-03-06 21:56:44,122 - INFO - validation batch 101, loss: 0.465, 3232/6976 datapoints
2025-03-06 21:56:44,172 - INFO - validation batch 151, loss: 0.577, 4832/6976 datapoints
2025-03-06 21:56:44,223 - INFO - validation batch 201, loss: 0.479, 6432/6976 datapoints
2025-03-06 21:56:44,243 - INFO - Epoch 259/800 done.
2025-03-06 21:56:44,243 - INFO - Final validation performance:
Loss: 0.697, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:56:44,244 - INFO - Beginning epoch 260/800
2025-03-06 21:56:44,248 - INFO - training batch 1, loss: 0.253, 32/28000 datapoints
2025-03-06 21:56:44,393 - INFO - training batch 51, loss: 0.106, 1632/28000 datapoints
2025-03-06 21:56:44,541 - INFO - training batch 101, loss: 0.094, 3232/28000 datapoints
2025-03-06 21:56:44,688 - INFO - training batch 151, loss: 0.150, 4832/28000 datapoints
2025-03-06 21:56:44,840 - INFO - training batch 201, loss: 0.087, 6432/28000 datapoints
2025-03-06 21:56:44,988 - INFO - training batch 251, loss: 0.264, 8032/28000 datapoints
2025-03-06 21:56:45,142 - INFO - training batch 301, loss: 0.548, 9632/28000 datapoints
2025-03-06 21:56:45,290 - INFO - training batch 351, loss: 0.197, 11232/28000 datapoints
2025-03-06 21:56:45,439 - INFO - training batch 401, loss: 0.411, 12832/28000 datapoints
2025-03-06 21:56:45,587 - INFO - training batch 451, loss: 0.386, 14432/28000 datapoints
2025-03-06 21:56:45,740 - INFO - training batch 501, loss: 0.141, 16032/28000 datapoints
2025-03-06 21:56:45,903 - INFO - training batch 551, loss: 0.206, 17632/28000 datapoints
2025-03-06 21:56:46,052 - INFO - training batch 601, loss: 0.165, 19232/28000 datapoints
2025-03-06 21:56:46,205 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 21:56:46,361 - INFO - training batch 701, loss: 0.165, 22432/28000 datapoints
2025-03-06 21:56:46,511 - INFO - training batch 751, loss: 0.139, 24032/28000 datapoints
2025-03-06 21:56:46,659 - INFO - training batch 801, loss: 0.109, 25632/28000 datapoints
2025-03-06 21:56:46,813 - INFO - training batch 851, loss: 0.207, 27232/28000 datapoints
2025-03-06 21:56:46,889 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:56:46,939 - INFO - validation batch 51, loss: 1.847, 1632/6976 datapoints
2025-03-06 21:56:46,987 - INFO - validation batch 101, loss: 0.468, 3232/6976 datapoints
2025-03-06 21:56:47,034 - INFO - validation batch 151, loss: 0.578, 4832/6976 datapoints
2025-03-06 21:56:47,080 - INFO - validation batch 201, loss: 0.480, 6432/6976 datapoints
2025-03-06 21:56:47,096 - INFO - Epoch 260/800 done.
2025-03-06 21:56:47,096 - INFO - Final validation performance:
Loss: 0.700, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:56:47,096 - INFO - Beginning epoch 261/800
2025-03-06 21:56:47,101 - INFO - training batch 1, loss: 0.251, 32/28000 datapoints
2025-03-06 21:56:47,249 - INFO - training batch 51, loss: 0.104, 1632/28000 datapoints
2025-03-06 21:56:47,396 - INFO - training batch 101, loss: 0.092, 3232/28000 datapoints
2025-03-06 21:56:47,540 - INFO - training batch 151, loss: 0.149, 4832/28000 datapoints
2025-03-06 21:56:47,684 - INFO - training batch 201, loss: 0.087, 6432/28000 datapoints
2025-03-06 21:56:47,828 - INFO - training batch 251, loss: 0.263, 8032/28000 datapoints
2025-03-06 21:56:47,982 - INFO - training batch 301, loss: 0.547, 9632/28000 datapoints
2025-03-06 21:56:48,127 - INFO - training batch 351, loss: 0.197, 11232/28000 datapoints
2025-03-06 21:56:48,274 - INFO - training batch 401, loss: 0.407, 12832/28000 datapoints
2025-03-06 21:56:48,427 - INFO - training batch 451, loss: 0.385, 14432/28000 datapoints
2025-03-06 21:56:48,574 - INFO - training batch 501, loss: 0.141, 16032/28000 datapoints
2025-03-06 21:56:48,720 - INFO - training batch 551, loss: 0.205, 17632/28000 datapoints
2025-03-06 21:56:48,868 - INFO - training batch 601, loss: 0.159, 19232/28000 datapoints
2025-03-06 21:56:49,014 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 21:56:49,157 - INFO - training batch 701, loss: 0.164, 22432/28000 datapoints
2025-03-06 21:56:49,300 - INFO - training batch 751, loss: 0.139, 24032/28000 datapoints
2025-03-06 21:56:49,445 - INFO - training batch 801, loss: 0.107, 25632/28000 datapoints
2025-03-06 21:56:49,590 - INFO - training batch 851, loss: 0.206, 27232/28000 datapoints
2025-03-06 21:56:49,660 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:56:49,706 - INFO - validation batch 51, loss: 1.852, 1632/6976 datapoints
2025-03-06 21:56:49,752 - INFO - validation batch 101, loss: 0.470, 3232/6976 datapoints
2025-03-06 21:56:49,799 - INFO - validation batch 151, loss: 0.582, 4832/6976 datapoints
2025-03-06 21:56:49,851 - INFO - validation batch 201, loss: 0.481, 6432/6976 datapoints
2025-03-06 21:56:49,867 - INFO - Epoch 261/800 done.
2025-03-06 21:56:49,868 - INFO - Final validation performance:
Loss: 0.702, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:56:49,868 - INFO - Beginning epoch 262/800
2025-03-06 21:56:49,873 - INFO - training batch 1, loss: 0.250, 32/28000 datapoints
2025-03-06 21:56:50,017 - INFO - training batch 51, loss: 0.105, 1632/28000 datapoints
2025-03-06 21:56:50,162 - INFO - training batch 101, loss: 0.093, 3232/28000 datapoints
2025-03-06 21:56:50,339 - INFO - training batch 151, loss: 0.148, 4832/28000 datapoints
2025-03-06 21:56:50,485 - INFO - training batch 201, loss: 0.086, 6432/28000 datapoints
2025-03-06 21:56:50,630 - INFO - training batch 251, loss: 0.262, 8032/28000 datapoints
2025-03-06 21:56:50,777 - INFO - training batch 301, loss: 0.544, 9632/28000 datapoints
2025-03-06 21:56:50,927 - INFO - training batch 351, loss: 0.196, 11232/28000 datapoints
2025-03-06 21:56:51,075 - INFO - training batch 401, loss: 0.404, 12832/28000 datapoints
2025-03-06 21:56:51,222 - INFO - training batch 451, loss: 0.384, 14432/28000 datapoints
2025-03-06 21:56:51,370 - INFO - training batch 501, loss: 0.140, 16032/28000 datapoints
2025-03-06 21:56:51,517 - INFO - training batch 551, loss: 0.203, 17632/28000 datapoints
2025-03-06 21:56:51,665 - INFO - training batch 601, loss: 0.160, 19232/28000 datapoints
2025-03-06 21:56:51,813 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 21:56:51,976 - INFO - training batch 701, loss: 0.162, 22432/28000 datapoints
2025-03-06 21:56:52,125 - INFO - training batch 751, loss: 0.137, 24032/28000 datapoints
2025-03-06 21:56:52,276 - INFO - training batch 801, loss: 0.106, 25632/28000 datapoints
2025-03-06 21:56:52,430 - INFO - training batch 851, loss: 0.204, 27232/28000 datapoints
2025-03-06 21:56:52,504 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:56:52,551 - INFO - validation batch 51, loss: 1.854, 1632/6976 datapoints
2025-03-06 21:56:52,601 - INFO - validation batch 101, loss: 0.475, 3232/6976 datapoints
2025-03-06 21:56:52,648 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 21:56:52,695 - INFO - validation batch 201, loss: 0.480, 6432/6976 datapoints
2025-03-06 21:56:52,711 - INFO - Epoch 262/800 done.
2025-03-06 21:56:52,711 - INFO - Final validation performance:
Loss: 0.704, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:56:52,712 - INFO - Beginning epoch 263/800
2025-03-06 21:56:52,716 - INFO - training batch 1, loss: 0.249, 32/28000 datapoints
2025-03-06 21:56:52,870 - INFO - training batch 51, loss: 0.103, 1632/28000 datapoints
2025-03-06 21:56:53,016 - INFO - training batch 101, loss: 0.091, 3232/28000 datapoints
2025-03-06 21:56:53,160 - INFO - training batch 151, loss: 0.147, 4832/28000 datapoints
2025-03-06 21:56:53,304 - INFO - training batch 201, loss: 0.085, 6432/28000 datapoints
2025-03-06 21:56:53,450 - INFO - training batch 251, loss: 0.261, 8032/28000 datapoints
2025-03-06 21:56:53,600 - INFO - training batch 301, loss: 0.543, 9632/28000 datapoints
2025-03-06 21:56:53,742 - INFO - training batch 351, loss: 0.195, 11232/28000 datapoints
2025-03-06 21:56:53,890 - INFO - training batch 401, loss: 0.400, 12832/28000 datapoints
2025-03-06 21:56:54,033 - INFO - training batch 451, loss: 0.383, 14432/28000 datapoints
2025-03-06 21:56:54,181 - INFO - training batch 501, loss: 0.140, 16032/28000 datapoints
2025-03-06 21:56:54,333 - INFO - training batch 551, loss: 0.201, 17632/28000 datapoints
2025-03-06 21:56:54,478 - INFO - training batch 601, loss: 0.158, 19232/28000 datapoints
2025-03-06 21:56:54,622 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 21:56:54,765 - INFO - training batch 701, loss: 0.161, 22432/28000 datapoints
2025-03-06 21:56:54,912 - INFO - training batch 751, loss: 0.136, 24032/28000 datapoints
2025-03-06 21:56:55,057 - INFO - training batch 801, loss: 0.104, 25632/28000 datapoints
2025-03-06 21:56:55,205 - INFO - training batch 851, loss: 0.202, 27232/28000 datapoints
2025-03-06 21:56:55,277 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:56:55,326 - INFO - validation batch 51, loss: 1.861, 1632/6976 datapoints
2025-03-06 21:56:55,371 - INFO - validation batch 101, loss: 0.477, 3232/6976 datapoints
2025-03-06 21:56:55,418 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-06 21:56:55,463 - INFO - validation batch 201, loss: 0.480, 6432/6976 datapoints
2025-03-06 21:56:55,479 - INFO - Epoch 263/800 done.
2025-03-06 21:56:55,479 - INFO - Final validation performance:
Loss: 0.706, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 21:56:55,480 - INFO - Beginning epoch 264/800
2025-03-06 21:56:55,484 - INFO - training batch 1, loss: 0.246, 32/28000 datapoints
2025-03-06 21:56:55,629 - INFO - training batch 51, loss: 0.103, 1632/28000 datapoints
2025-03-06 21:56:55,774 - INFO - training batch 101, loss: 0.091, 3232/28000 datapoints
2025-03-06 21:56:55,927 - INFO - training batch 151, loss: 0.146, 4832/28000 datapoints
2025-03-06 21:56:56,071 - INFO - training batch 201, loss: 0.085, 6432/28000 datapoints
2025-03-06 21:56:56,214 - INFO - training batch 251, loss: 0.260, 8032/28000 datapoints
2025-03-06 21:56:56,361 - INFO - training batch 301, loss: 0.541, 9632/28000 datapoints
2025-03-06 21:56:56,506 - INFO - training batch 351, loss: 0.195, 11232/28000 datapoints
2025-03-06 21:56:56,653 - INFO - training batch 401, loss: 0.396, 12832/28000 datapoints
2025-03-06 21:56:56,796 - INFO - training batch 451, loss: 0.382, 14432/28000 datapoints
2025-03-06 21:56:56,942 - INFO - training batch 501, loss: 0.139, 16032/28000 datapoints
2025-03-06 21:56:57,087 - INFO - training batch 551, loss: 0.200, 17632/28000 datapoints
2025-03-06 21:56:57,233 - INFO - training batch 601, loss: 0.158, 19232/28000 datapoints
2025-03-06 21:56:57,377 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 21:56:57,522 - INFO - training batch 701, loss: 0.159, 22432/28000 datapoints
2025-03-06 21:56:57,666 - INFO - training batch 751, loss: 0.136, 24032/28000 datapoints
2025-03-06 21:56:57,810 - INFO - training batch 801, loss: 0.104, 25632/28000 datapoints
2025-03-06 21:56:57,957 - INFO - training batch 851, loss: 0.199, 27232/28000 datapoints
2025-03-06 21:56:58,037 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:56:58,087 - INFO - validation batch 51, loss: 1.869, 1632/6976 datapoints
2025-03-06 21:56:58,133 - INFO - validation batch 101, loss: 0.479, 3232/6976 datapoints
2025-03-06 21:56:58,181 - INFO - validation batch 151, loss: 0.589, 4832/6976 datapoints
2025-03-06 21:56:58,227 - INFO - validation batch 201, loss: 0.479, 6432/6976 datapoints
2025-03-06 21:56:58,246 - INFO - Epoch 264/800 done.
2025-03-06 21:56:58,246 - INFO - Final validation performance:
Loss: 0.709, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 21:56:58,247 - INFO - Beginning epoch 265/800
2025-03-06 21:56:58,251 - INFO - training batch 1, loss: 0.245, 32/28000 datapoints
2025-03-06 21:56:58,399 - INFO - training batch 51, loss: 0.101, 1632/28000 datapoints
2025-03-06 21:56:58,545 - INFO - training batch 101, loss: 0.091, 3232/28000 datapoints
2025-03-06 21:56:58,688 - INFO - training batch 151, loss: 0.145, 4832/28000 datapoints
2025-03-06 21:56:58,833 - INFO - training batch 201, loss: 0.084, 6432/28000 datapoints
2025-03-06 21:56:58,979 - INFO - training batch 251, loss: 0.260, 8032/28000 datapoints
2025-03-06 21:56:59,123 - INFO - training batch 301, loss: 0.539, 9632/28000 datapoints
2025-03-06 21:56:59,268 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 21:56:59,410 - INFO - training batch 401, loss: 0.394, 12832/28000 datapoints
2025-03-06 21:56:59,556 - INFO - training batch 451, loss: 0.381, 14432/28000 datapoints
2025-03-06 21:56:59,700 - INFO - training batch 501, loss: 0.139, 16032/28000 datapoints
2025-03-06 21:56:59,848 - INFO - training batch 551, loss: 0.199, 17632/28000 datapoints
2025-03-06 21:56:59,992 - INFO - training batch 601, loss: 0.154, 19232/28000 datapoints
2025-03-06 21:57:00,136 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 21:57:00,285 - INFO - training batch 701, loss: 0.158, 22432/28000 datapoints
2025-03-06 21:57:00,455 - INFO - training batch 751, loss: 0.135, 24032/28000 datapoints
2025-03-06 21:57:00,599 - INFO - training batch 801, loss: 0.102, 25632/28000 datapoints
2025-03-06 21:57:00,743 - INFO - training batch 851, loss: 0.198, 27232/28000 datapoints
2025-03-06 21:57:00,814 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:57:00,863 - INFO - validation batch 51, loss: 1.871, 1632/6976 datapoints
2025-03-06 21:57:00,910 - INFO - validation batch 101, loss: 0.483, 3232/6976 datapoints
2025-03-06 21:57:00,957 - INFO - validation batch 151, loss: 0.591, 4832/6976 datapoints
2025-03-06 21:57:01,005 - INFO - validation batch 201, loss: 0.479, 6432/6976 datapoints
2025-03-06 21:57:01,021 - INFO - Epoch 265/800 done.
2025-03-06 21:57:01,021 - INFO - Final validation performance:
Loss: 0.710, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 21:57:01,021 - INFO - Beginning epoch 266/800
2025-03-06 21:57:01,025 - INFO - training batch 1, loss: 0.243, 32/28000 datapoints
2025-03-06 21:57:01,171 - INFO - training batch 51, loss: 0.101, 1632/28000 datapoints
2025-03-06 21:57:01,316 - INFO - training batch 101, loss: 0.090, 3232/28000 datapoints
2025-03-06 21:57:01,462 - INFO - training batch 151, loss: 0.144, 4832/28000 datapoints
2025-03-06 21:57:01,607 - INFO - training batch 201, loss: 0.084, 6432/28000 datapoints
2025-03-06 21:57:01,753 - INFO - training batch 251, loss: 0.258, 8032/28000 datapoints
2025-03-06 21:57:01,901 - INFO - training batch 301, loss: 0.535, 9632/28000 datapoints
2025-03-06 21:57:02,048 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 21:57:02,193 - INFO - training batch 401, loss: 0.390, 12832/28000 datapoints
2025-03-06 21:57:02,339 - INFO - training batch 451, loss: 0.380, 14432/28000 datapoints
2025-03-06 21:57:02,483 - INFO - training batch 501, loss: 0.139, 16032/28000 datapoints
2025-03-06 21:57:02,628 - INFO - training batch 551, loss: 0.198, 17632/28000 datapoints
2025-03-06 21:57:02,775 - INFO - training batch 601, loss: 0.152, 19232/28000 datapoints
2025-03-06 21:57:02,921 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 21:57:03,065 - INFO - training batch 701, loss: 0.157, 22432/28000 datapoints
2025-03-06 21:57:03,208 - INFO - training batch 751, loss: 0.135, 24032/28000 datapoints
2025-03-06 21:57:03,351 - INFO - training batch 801, loss: 0.100, 25632/28000 datapoints
2025-03-06 21:57:03,496 - INFO - training batch 851, loss: 0.197, 27232/28000 datapoints
2025-03-06 21:57:03,570 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:57:03,617 - INFO - validation batch 51, loss: 1.876, 1632/6976 datapoints
2025-03-06 21:57:03,664 - INFO - validation batch 101, loss: 0.487, 3232/6976 datapoints
2025-03-06 21:57:03,710 - INFO - validation batch 151, loss: 0.594, 4832/6976 datapoints
2025-03-06 21:57:03,755 - INFO - validation batch 201, loss: 0.480, 6432/6976 datapoints
2025-03-06 21:57:03,771 - INFO - Epoch 266/800 done.
2025-03-06 21:57:03,771 - INFO - Final validation performance:
Loss: 0.713, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:03,772 - INFO - Beginning epoch 267/800
2025-03-06 21:57:03,776 - INFO - training batch 1, loss: 0.241, 32/28000 datapoints
2025-03-06 21:57:03,924 - INFO - training batch 51, loss: 0.100, 1632/28000 datapoints
2025-03-06 21:57:04,082 - INFO - training batch 101, loss: 0.089, 3232/28000 datapoints
2025-03-06 21:57:04,228 - INFO - training batch 151, loss: 0.143, 4832/28000 datapoints
2025-03-06 21:57:04,377 - INFO - training batch 201, loss: 0.083, 6432/28000 datapoints
2025-03-06 21:57:04,530 - INFO - training batch 251, loss: 0.257, 8032/28000 datapoints
2025-03-06 21:57:04,678 - INFO - training batch 301, loss: 0.534, 9632/28000 datapoints
2025-03-06 21:57:04,825 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 21:57:04,980 - INFO - training batch 401, loss: 0.386, 12832/28000 datapoints
2025-03-06 21:57:05,138 - INFO - training batch 451, loss: 0.379, 14432/28000 datapoints
2025-03-06 21:57:05,290 - INFO - training batch 501, loss: 0.138, 16032/28000 datapoints
2025-03-06 21:57:05,443 - INFO - training batch 551, loss: 0.196, 17632/28000 datapoints
2025-03-06 21:57:05,596 - INFO - training batch 601, loss: 0.149, 19232/28000 datapoints
2025-03-06 21:57:05,749 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 21:57:05,901 - INFO - training batch 701, loss: 0.155, 22432/28000 datapoints
2025-03-06 21:57:06,056 - INFO - training batch 751, loss: 0.135, 24032/28000 datapoints
2025-03-06 21:57:06,205 - INFO - training batch 801, loss: 0.099, 25632/28000 datapoints
2025-03-06 21:57:06,359 - INFO - training batch 851, loss: 0.195, 27232/28000 datapoints
2025-03-06 21:57:06,434 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 21:57:06,485 - INFO - validation batch 51, loss: 1.879, 1632/6976 datapoints
2025-03-06 21:57:06,537 - INFO - validation batch 101, loss: 0.490, 3232/6976 datapoints
2025-03-06 21:57:06,585 - INFO - validation batch 151, loss: 0.596, 4832/6976 datapoints
2025-03-06 21:57:06,631 - INFO - validation batch 201, loss: 0.480, 6432/6976 datapoints
2025-03-06 21:57:06,648 - INFO - Epoch 267/800 done.
2025-03-06 21:57:06,649 - INFO - Final validation performance:
Loss: 0.715, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:06,649 - INFO - Beginning epoch 268/800
2025-03-06 21:57:06,653 - INFO - training batch 1, loss: 0.241, 32/28000 datapoints
2025-03-06 21:57:06,808 - INFO - training batch 51, loss: 0.100, 1632/28000 datapoints
2025-03-06 21:57:06,957 - INFO - training batch 101, loss: 0.090, 3232/28000 datapoints
2025-03-06 21:57:07,107 - INFO - training batch 151, loss: 0.142, 4832/28000 datapoints
2025-03-06 21:57:07,252 - INFO - training batch 201, loss: 0.082, 6432/28000 datapoints
2025-03-06 21:57:07,394 - INFO - training batch 251, loss: 0.257, 8032/28000 datapoints
2025-03-06 21:57:07,536 - INFO - training batch 301, loss: 0.530, 9632/28000 datapoints
2025-03-06 21:57:07,681 - INFO - training batch 351, loss: 0.192, 11232/28000 datapoints
2025-03-06 21:57:07,825 - INFO - training batch 401, loss: 0.383, 12832/28000 datapoints
2025-03-06 21:57:07,980 - INFO - training batch 451, loss: 0.378, 14432/28000 datapoints
2025-03-06 21:57:08,127 - INFO - training batch 501, loss: 0.137, 16032/28000 datapoints
2025-03-06 21:57:08,271 - INFO - training batch 551, loss: 0.195, 17632/28000 datapoints
2025-03-06 21:57:08,418 - INFO - training batch 601, loss: 0.148, 19232/28000 datapoints
2025-03-06 21:57:08,562 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 21:57:08,705 - INFO - training batch 701, loss: 0.154, 22432/28000 datapoints
2025-03-06 21:57:08,850 - INFO - training batch 751, loss: 0.133, 24032/28000 datapoints
2025-03-06 21:57:08,993 - INFO - training batch 801, loss: 0.099, 25632/28000 datapoints
2025-03-06 21:57:09,137 - INFO - training batch 851, loss: 0.193, 27232/28000 datapoints
2025-03-06 21:57:09,207 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 21:57:09,256 - INFO - validation batch 51, loss: 1.885, 1632/6976 datapoints
2025-03-06 21:57:09,306 - INFO - validation batch 101, loss: 0.492, 3232/6976 datapoints
2025-03-06 21:57:09,353 - INFO - validation batch 151, loss: 0.600, 4832/6976 datapoints
2025-03-06 21:57:09,399 - INFO - validation batch 201, loss: 0.480, 6432/6976 datapoints
2025-03-06 21:57:09,414 - INFO - Epoch 268/800 done.
2025-03-06 21:57:09,415 - INFO - Final validation performance:
Loss: 0.717, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 21:57:09,415 - INFO - Beginning epoch 269/800
2025-03-06 21:57:09,420 - INFO - training batch 1, loss: 0.237, 32/28000 datapoints
2025-03-06 21:57:09,564 - INFO - training batch 51, loss: 0.099, 1632/28000 datapoints
2025-03-06 21:57:09,713 - INFO - training batch 101, loss: 0.089, 3232/28000 datapoints
2025-03-06 21:57:09,859 - INFO - training batch 151, loss: 0.141, 4832/28000 datapoints
2025-03-06 21:57:10,013 - INFO - training batch 201, loss: 0.082, 6432/28000 datapoints
2025-03-06 21:57:10,166 - INFO - training batch 251, loss: 0.256, 8032/28000 datapoints
2025-03-06 21:57:10,315 - INFO - training batch 301, loss: 0.530, 9632/28000 datapoints
2025-03-06 21:57:10,482 - INFO - training batch 351, loss: 0.192, 11232/28000 datapoints
2025-03-06 21:57:10,639 - INFO - training batch 401, loss: 0.379, 12832/28000 datapoints
2025-03-06 21:57:10,791 - INFO - training batch 451, loss: 0.377, 14432/28000 datapoints
2025-03-06 21:57:10,941 - INFO - training batch 501, loss: 0.137, 16032/28000 datapoints
2025-03-06 21:57:11,085 - INFO - training batch 551, loss: 0.194, 17632/28000 datapoints
2025-03-06 21:57:11,230 - INFO - training batch 601, loss: 0.148, 19232/28000 datapoints
2025-03-06 21:57:11,373 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 21:57:11,517 - INFO - training batch 701, loss: 0.152, 22432/28000 datapoints
2025-03-06 21:57:11,662 - INFO - training batch 751, loss: 0.133, 24032/28000 datapoints
2025-03-06 21:57:11,806 - INFO - training batch 801, loss: 0.096, 25632/28000 datapoints
2025-03-06 21:57:11,954 - INFO - training batch 851, loss: 0.190, 27232/28000 datapoints
2025-03-06 21:57:12,025 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 21:57:12,072 - INFO - validation batch 51, loss: 1.887, 1632/6976 datapoints
2025-03-06 21:57:12,121 - INFO - validation batch 101, loss: 0.495, 3232/6976 datapoints
2025-03-06 21:57:12,167 - INFO - validation batch 151, loss: 0.598, 4832/6976 datapoints
2025-03-06 21:57:12,213 - INFO - validation batch 201, loss: 0.478, 6432/6976 datapoints
2025-03-06 21:57:12,229 - INFO - Epoch 269/800 done.
2025-03-06 21:57:12,229 - INFO - Final validation performance:
Loss: 0.718, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:12,230 - INFO - Beginning epoch 270/800
2025-03-06 21:57:12,234 - INFO - training batch 1, loss: 0.236, 32/28000 datapoints
2025-03-06 21:57:12,382 - INFO - training batch 51, loss: 0.098, 1632/28000 datapoints
2025-03-06 21:57:12,528 - INFO - training batch 101, loss: 0.089, 3232/28000 datapoints
2025-03-06 21:57:12,675 - INFO - training batch 151, loss: 0.140, 4832/28000 datapoints
2025-03-06 21:57:12,820 - INFO - training batch 201, loss: 0.081, 6432/28000 datapoints
2025-03-06 21:57:12,967 - INFO - training batch 251, loss: 0.255, 8032/28000 datapoints
2025-03-06 21:57:13,154 - INFO - training batch 301, loss: 0.524, 9632/28000 datapoints
2025-03-06 21:57:13,312 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 21:57:13,459 - INFO - training batch 401, loss: 0.375, 12832/28000 datapoints
2025-03-06 21:57:13,604 - INFO - training batch 451, loss: 0.376, 14432/28000 datapoints
2025-03-06 21:57:13,750 - INFO - training batch 501, loss: 0.137, 16032/28000 datapoints
2025-03-06 21:57:13,897 - INFO - training batch 551, loss: 0.192, 17632/28000 datapoints
2025-03-06 21:57:14,041 - INFO - training batch 601, loss: 0.146, 19232/28000 datapoints
2025-03-06 21:57:14,185 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 21:57:14,335 - INFO - training batch 701, loss: 0.151, 22432/28000 datapoints
2025-03-06 21:57:14,479 - INFO - training batch 751, loss: 0.133, 24032/28000 datapoints
2025-03-06 21:57:14,625 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-06 21:57:14,773 - INFO - training batch 851, loss: 0.189, 27232/28000 datapoints
2025-03-06 21:57:14,846 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 21:57:14,892 - INFO - validation batch 51, loss: 1.893, 1632/6976 datapoints
2025-03-06 21:57:14,938 - INFO - validation batch 101, loss: 0.496, 3232/6976 datapoints
2025-03-06 21:57:14,991 - INFO - validation batch 151, loss: 0.603, 4832/6976 datapoints
2025-03-06 21:57:15,043 - INFO - validation batch 201, loss: 0.481, 6432/6976 datapoints
2025-03-06 21:57:15,059 - INFO - Epoch 270/800 done.
2025-03-06 21:57:15,059 - INFO - Final validation performance:
Loss: 0.721, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:15,060 - INFO - Beginning epoch 271/800
2025-03-06 21:57:15,064 - INFO - training batch 1, loss: 0.233, 32/28000 datapoints
2025-03-06 21:57:15,219 - INFO - training batch 51, loss: 0.097, 1632/28000 datapoints
2025-03-06 21:57:15,364 - INFO - training batch 101, loss: 0.087, 3232/28000 datapoints
2025-03-06 21:57:15,508 - INFO - training batch 151, loss: 0.139, 4832/28000 datapoints
2025-03-06 21:57:15,659 - INFO - training batch 201, loss: 0.080, 6432/28000 datapoints
2025-03-06 21:57:15,807 - INFO - training batch 251, loss: 0.253, 8032/28000 datapoints
2025-03-06 21:57:15,958 - INFO - training batch 301, loss: 0.521, 9632/28000 datapoints
2025-03-06 21:57:16,151 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 21:57:16,312 - INFO - training batch 401, loss: 0.372, 12832/28000 datapoints
2025-03-06 21:57:16,460 - INFO - training batch 451, loss: 0.375, 14432/28000 datapoints
2025-03-06 21:57:16,615 - INFO - training batch 501, loss: 0.136, 16032/28000 datapoints
2025-03-06 21:57:16,770 - INFO - training batch 551, loss: 0.191, 17632/28000 datapoints
2025-03-06 21:57:16,921 - INFO - training batch 601, loss: 0.143, 19232/28000 datapoints
2025-03-06 21:57:17,073 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 21:57:17,220 - INFO - training batch 701, loss: 0.149, 22432/28000 datapoints
2025-03-06 21:57:17,369 - INFO - training batch 751, loss: 0.131, 24032/28000 datapoints
2025-03-06 21:57:17,515 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-06 21:57:17,660 - INFO - training batch 851, loss: 0.186, 27232/28000 datapoints
2025-03-06 21:57:17,735 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 21:57:17,782 - INFO - validation batch 51, loss: 1.895, 1632/6976 datapoints
2025-03-06 21:57:17,828 - INFO - validation batch 101, loss: 0.501, 3232/6976 datapoints
2025-03-06 21:57:17,876 - INFO - validation batch 151, loss: 0.605, 4832/6976 datapoints
2025-03-06 21:57:17,922 - INFO - validation batch 201, loss: 0.477, 6432/6976 datapoints
2025-03-06 21:57:17,938 - INFO - Epoch 271/800 done.
2025-03-06 21:57:17,938 - INFO - Final validation performance:
Loss: 0.722, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:17,939 - INFO - Beginning epoch 272/800
2025-03-06 21:57:17,943 - INFO - training batch 1, loss: 0.231, 32/28000 datapoints
2025-03-06 21:57:18,089 - INFO - training batch 51, loss: 0.097, 1632/28000 datapoints
2025-03-06 21:57:18,235 - INFO - training batch 101, loss: 0.088, 3232/28000 datapoints
2025-03-06 21:57:18,387 - INFO - training batch 151, loss: 0.138, 4832/28000 datapoints
2025-03-06 21:57:18,531 - INFO - training batch 201, loss: 0.079, 6432/28000 datapoints
2025-03-06 21:57:18,676 - INFO - training batch 251, loss: 0.254, 8032/28000 datapoints
2025-03-06 21:57:18,821 - INFO - training batch 301, loss: 0.518, 9632/28000 datapoints
2025-03-06 21:57:18,965 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 21:57:19,109 - INFO - training batch 401, loss: 0.369, 12832/28000 datapoints
2025-03-06 21:57:19,255 - INFO - training batch 451, loss: 0.374, 14432/28000 datapoints
2025-03-06 21:57:19,398 - INFO - training batch 501, loss: 0.136, 16032/28000 datapoints
2025-03-06 21:57:19,544 - INFO - training batch 551, loss: 0.190, 17632/28000 datapoints
2025-03-06 21:57:19,689 - INFO - training batch 601, loss: 0.143, 19232/28000 datapoints
2025-03-06 21:57:19,832 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 21:57:19,978 - INFO - training batch 701, loss: 0.147, 22432/28000 datapoints
2025-03-06 21:57:20,121 - INFO - training batch 751, loss: 0.131, 24032/28000 datapoints
2025-03-06 21:57:20,265 - INFO - training batch 801, loss: 0.091, 25632/28000 datapoints
2025-03-06 21:57:20,412 - INFO - training batch 851, loss: 0.184, 27232/28000 datapoints
2025-03-06 21:57:20,487 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 21:57:20,554 - INFO - validation batch 51, loss: 1.897, 1632/6976 datapoints
2025-03-06 21:57:20,605 - INFO - validation batch 101, loss: 0.503, 3232/6976 datapoints
2025-03-06 21:57:20,651 - INFO - validation batch 151, loss: 0.607, 4832/6976 datapoints
2025-03-06 21:57:20,700 - INFO - validation batch 201, loss: 0.477, 6432/6976 datapoints
2025-03-06 21:57:20,715 - INFO - Epoch 272/800 done.
2025-03-06 21:57:20,715 - INFO - Final validation performance:
Loss: 0.723, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:20,716 - INFO - Beginning epoch 273/800
2025-03-06 21:57:20,720 - INFO - training batch 1, loss: 0.229, 32/28000 datapoints
2025-03-06 21:57:20,869 - INFO - training batch 51, loss: 0.096, 1632/28000 datapoints
2025-03-06 21:57:21,012 - INFO - training batch 101, loss: 0.087, 3232/28000 datapoints
2025-03-06 21:57:21,155 - INFO - training batch 151, loss: 0.138, 4832/28000 datapoints
2025-03-06 21:57:21,301 - INFO - training batch 201, loss: 0.079, 6432/28000 datapoints
2025-03-06 21:57:21,444 - INFO - training batch 251, loss: 0.251, 8032/28000 datapoints
2025-03-06 21:57:21,588 - INFO - training batch 301, loss: 0.516, 9632/28000 datapoints
2025-03-06 21:57:21,732 - INFO - training batch 351, loss: 0.190, 11232/28000 datapoints
2025-03-06 21:57:21,879 - INFO - training batch 401, loss: 0.365, 12832/28000 datapoints
2025-03-06 21:57:22,022 - INFO - training batch 451, loss: 0.372, 14432/28000 datapoints
2025-03-06 21:57:22,169 - INFO - training batch 501, loss: 0.135, 16032/28000 datapoints
2025-03-06 21:57:22,327 - INFO - training batch 551, loss: 0.188, 17632/28000 datapoints
2025-03-06 21:57:22,474 - INFO - training batch 601, loss: 0.140, 19232/28000 datapoints
2025-03-06 21:57:22,620 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:57:22,769 - INFO - training batch 701, loss: 0.145, 22432/28000 datapoints
2025-03-06 21:57:22,917 - INFO - training batch 751, loss: 0.129, 24032/28000 datapoints
2025-03-06 21:57:23,064 - INFO - training batch 801, loss: 0.092, 25632/28000 datapoints
2025-03-06 21:57:23,207 - INFO - training batch 851, loss: 0.183, 27232/28000 datapoints
2025-03-06 21:57:23,282 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 21:57:23,334 - INFO - validation batch 51, loss: 1.904, 1632/6976 datapoints
2025-03-06 21:57:23,380 - INFO - validation batch 101, loss: 0.506, 3232/6976 datapoints
2025-03-06 21:57:23,427 - INFO - validation batch 151, loss: 0.611, 4832/6976 datapoints
2025-03-06 21:57:23,474 - INFO - validation batch 201, loss: 0.480, 6432/6976 datapoints
2025-03-06 21:57:23,489 - INFO - Epoch 273/800 done.
2025-03-06 21:57:23,489 - INFO - Final validation performance:
Loss: 0.727, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:23,490 - INFO - Beginning epoch 274/800
2025-03-06 21:57:23,494 - INFO - training batch 1, loss: 0.227, 32/28000 datapoints
2025-03-06 21:57:23,640 - INFO - training batch 51, loss: 0.094, 1632/28000 datapoints
2025-03-06 21:57:23,789 - INFO - training batch 101, loss: 0.086, 3232/28000 datapoints
2025-03-06 21:57:23,934 - INFO - training batch 151, loss: 0.137, 4832/28000 datapoints
2025-03-06 21:57:24,079 - INFO - training batch 201, loss: 0.079, 6432/28000 datapoints
2025-03-06 21:57:24,222 - INFO - training batch 251, loss: 0.251, 8032/28000 datapoints
2025-03-06 21:57:24,374 - INFO - training batch 301, loss: 0.513, 9632/28000 datapoints
2025-03-06 21:57:24,517 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 21:57:24,659 - INFO - training batch 401, loss: 0.362, 12832/28000 datapoints
2025-03-06 21:57:24,803 - INFO - training batch 451, loss: 0.372, 14432/28000 datapoints
2025-03-06 21:57:24,950 - INFO - training batch 501, loss: 0.135, 16032/28000 datapoints
2025-03-06 21:57:25,100 - INFO - training batch 551, loss: 0.187, 17632/28000 datapoints
2025-03-06 21:57:25,254 - INFO - training batch 601, loss: 0.140, 19232/28000 datapoints
2025-03-06 21:57:25,400 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:57:25,546 - INFO - training batch 701, loss: 0.144, 22432/28000 datapoints
2025-03-06 21:57:25,691 - INFO - training batch 751, loss: 0.130, 24032/28000 datapoints
2025-03-06 21:57:25,847 - INFO - training batch 801, loss: 0.089, 25632/28000 datapoints
2025-03-06 21:57:25,995 - INFO - training batch 851, loss: 0.180, 27232/28000 datapoints
2025-03-06 21:57:26,072 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 21:57:26,123 - INFO - validation batch 51, loss: 1.904, 1632/6976 datapoints
2025-03-06 21:57:26,175 - INFO - validation batch 101, loss: 0.508, 3232/6976 datapoints
2025-03-06 21:57:26,226 - INFO - validation batch 151, loss: 0.611, 4832/6976 datapoints
2025-03-06 21:57:26,275 - INFO - validation batch 201, loss: 0.477, 6432/6976 datapoints
2025-03-06 21:57:26,291 - INFO - Epoch 274/800 done.
2025-03-06 21:57:26,291 - INFO - Final validation performance:
Loss: 0.727, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:26,292 - INFO - Beginning epoch 275/800
2025-03-06 21:57:26,296 - INFO - training batch 1, loss: 0.226, 32/28000 datapoints
2025-03-06 21:57:26,445 - INFO - training batch 51, loss: 0.094, 1632/28000 datapoints
2025-03-06 21:57:26,588 - INFO - training batch 101, loss: 0.087, 3232/28000 datapoints
2025-03-06 21:57:26,736 - INFO - training batch 151, loss: 0.136, 4832/28000 datapoints
2025-03-06 21:57:26,886 - INFO - training batch 201, loss: 0.078, 6432/28000 datapoints
2025-03-06 21:57:27,030 - INFO - training batch 251, loss: 0.251, 8032/28000 datapoints
2025-03-06 21:57:27,176 - INFO - training batch 301, loss: 0.511, 9632/28000 datapoints
2025-03-06 21:57:27,322 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 21:57:27,466 - INFO - training batch 401, loss: 0.360, 12832/28000 datapoints
2025-03-06 21:57:27,608 - INFO - training batch 451, loss: 0.371, 14432/28000 datapoints
2025-03-06 21:57:27,755 - INFO - training batch 501, loss: 0.135, 16032/28000 datapoints
2025-03-06 21:57:27,903 - INFO - training batch 551, loss: 0.186, 17632/28000 datapoints
2025-03-06 21:57:28,052 - INFO - training batch 601, loss: 0.137, 19232/28000 datapoints
2025-03-06 21:57:28,196 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:57:28,352 - INFO - training batch 701, loss: 0.142, 22432/28000 datapoints
2025-03-06 21:57:28,508 - INFO - training batch 751, loss: 0.128, 24032/28000 datapoints
2025-03-06 21:57:28,654 - INFO - training batch 801, loss: 0.090, 25632/28000 datapoints
2025-03-06 21:57:28,809 - INFO - training batch 851, loss: 0.179, 27232/28000 datapoints
2025-03-06 21:57:28,886 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 21:57:28,937 - INFO - validation batch 51, loss: 1.912, 1632/6976 datapoints
2025-03-06 21:57:28,983 - INFO - validation batch 101, loss: 0.512, 3232/6976 datapoints
2025-03-06 21:57:29,031 - INFO - validation batch 151, loss: 0.617, 4832/6976 datapoints
2025-03-06 21:57:29,078 - INFO - validation batch 201, loss: 0.478, 6432/6976 datapoints
2025-03-06 21:57:29,094 - INFO - Epoch 275/800 done.
2025-03-06 21:57:29,094 - INFO - Final validation performance:
Loss: 0.731, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:29,095 - INFO - Beginning epoch 276/800
2025-03-06 21:57:29,099 - INFO - training batch 1, loss: 0.223, 32/28000 datapoints
2025-03-06 21:57:29,247 - INFO - training batch 51, loss: 0.094, 1632/28000 datapoints
2025-03-06 21:57:29,399 - INFO - training batch 101, loss: 0.086, 3232/28000 datapoints
2025-03-06 21:57:29,547 - INFO - training batch 151, loss: 0.135, 4832/28000 datapoints
2025-03-06 21:57:29,694 - INFO - training batch 201, loss: 0.077, 6432/28000 datapoints
2025-03-06 21:57:29,847 - INFO - training batch 251, loss: 0.250, 8032/28000 datapoints
2025-03-06 21:57:29,992 - INFO - training batch 301, loss: 0.507, 9632/28000 datapoints
2025-03-06 21:57:30,139 - INFO - training batch 351, loss: 0.188, 11232/28000 datapoints
2025-03-06 21:57:30,283 - INFO - training batch 401, loss: 0.355, 12832/28000 datapoints
2025-03-06 21:57:30,432 - INFO - training batch 451, loss: 0.370, 14432/28000 datapoints
2025-03-06 21:57:30,583 - INFO - training batch 501, loss: 0.134, 16032/28000 datapoints
2025-03-06 21:57:30,749 - INFO - training batch 551, loss: 0.185, 17632/28000 datapoints
2025-03-06 21:57:30,896 - INFO - training batch 601, loss: 0.135, 19232/28000 datapoints
2025-03-06 21:57:31,042 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:57:31,189 - INFO - training batch 701, loss: 0.141, 22432/28000 datapoints
2025-03-06 21:57:31,333 - INFO - training batch 751, loss: 0.127, 24032/28000 datapoints
2025-03-06 21:57:31,474 - INFO - training batch 801, loss: 0.087, 25632/28000 datapoints
2025-03-06 21:57:31,618 - INFO - training batch 851, loss: 0.177, 27232/28000 datapoints
2025-03-06 21:57:31,689 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 21:57:31,735 - INFO - validation batch 51, loss: 1.914, 1632/6976 datapoints
2025-03-06 21:57:31,780 - INFO - validation batch 101, loss: 0.514, 3232/6976 datapoints
2025-03-06 21:57:31,828 - INFO - validation batch 151, loss: 0.616, 4832/6976 datapoints
2025-03-06 21:57:31,877 - INFO - validation batch 201, loss: 0.476, 6432/6976 datapoints
2025-03-06 21:57:31,893 - INFO - Epoch 276/800 done.
2025-03-06 21:57:31,893 - INFO - Final validation performance:
Loss: 0.731, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:31,894 - INFO - Beginning epoch 277/800
2025-03-06 21:57:31,898 - INFO - training batch 1, loss: 0.222, 32/28000 datapoints
2025-03-06 21:57:32,042 - INFO - training batch 51, loss: 0.093, 1632/28000 datapoints
2025-03-06 21:57:32,188 - INFO - training batch 101, loss: 0.085, 3232/28000 datapoints
2025-03-06 21:57:32,333 - INFO - training batch 151, loss: 0.134, 4832/28000 datapoints
2025-03-06 21:57:32,480 - INFO - training batch 201, loss: 0.077, 6432/28000 datapoints
2025-03-06 21:57:32,623 - INFO - training batch 251, loss: 0.248, 8032/28000 datapoints
2025-03-06 21:57:32,767 - INFO - training batch 301, loss: 0.504, 9632/28000 datapoints
2025-03-06 21:57:32,913 - INFO - training batch 351, loss: 0.188, 11232/28000 datapoints
2025-03-06 21:57:33,055 - INFO - training batch 401, loss: 0.352, 12832/28000 datapoints
2025-03-06 21:57:33,199 - INFO - training batch 451, loss: 0.368, 14432/28000 datapoints
2025-03-06 21:57:33,344 - INFO - training batch 501, loss: 0.134, 16032/28000 datapoints
2025-03-06 21:57:33,489 - INFO - training batch 551, loss: 0.183, 17632/28000 datapoints
2025-03-06 21:57:33,636 - INFO - training batch 601, loss: 0.131, 19232/28000 datapoints
2025-03-06 21:57:33,786 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 21:57:33,932 - INFO - training batch 701, loss: 0.139, 22432/28000 datapoints
2025-03-06 21:57:34,076 - INFO - training batch 751, loss: 0.127, 24032/28000 datapoints
2025-03-06 21:57:34,228 - INFO - training batch 801, loss: 0.086, 25632/28000 datapoints
2025-03-06 21:57:34,385 - INFO - training batch 851, loss: 0.176, 27232/28000 datapoints
2025-03-06 21:57:34,461 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 21:57:34,506 - INFO - validation batch 51, loss: 1.916, 1632/6976 datapoints
2025-03-06 21:57:34,553 - INFO - validation batch 101, loss: 0.517, 3232/6976 datapoints
2025-03-06 21:57:34,599 - INFO - validation batch 151, loss: 0.623, 4832/6976 datapoints
2025-03-06 21:57:34,646 - INFO - validation batch 201, loss: 0.477, 6432/6976 datapoints
2025-03-06 21:57:34,661 - INFO - Epoch 277/800 done.
2025-03-06 21:57:34,662 - INFO - Final validation performance:
Loss: 0.734, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:34,662 - INFO - Beginning epoch 278/800
2025-03-06 21:57:34,666 - INFO - training batch 1, loss: 0.220, 32/28000 datapoints
2025-03-06 21:57:34,816 - INFO - training batch 51, loss: 0.093, 1632/28000 datapoints
2025-03-06 21:57:34,966 - INFO - training batch 101, loss: 0.085, 3232/28000 datapoints
2025-03-06 21:57:35,114 - INFO - training batch 151, loss: 0.133, 4832/28000 datapoints
2025-03-06 21:57:35,262 - INFO - training batch 201, loss: 0.077, 6432/28000 datapoints
2025-03-06 21:57:35,406 - INFO - training batch 251, loss: 0.247, 8032/28000 datapoints
2025-03-06 21:57:35,550 - INFO - training batch 301, loss: 0.502, 9632/28000 datapoints
2025-03-06 21:57:35,693 - INFO - training batch 351, loss: 0.188, 11232/28000 datapoints
2025-03-06 21:57:35,836 - INFO - training batch 401, loss: 0.348, 12832/28000 datapoints
2025-03-06 21:57:35,984 - INFO - training batch 451, loss: 0.367, 14432/28000 datapoints
2025-03-06 21:57:36,129 - INFO - training batch 501, loss: 0.133, 16032/28000 datapoints
2025-03-06 21:57:36,276 - INFO - training batch 551, loss: 0.182, 17632/28000 datapoints
2025-03-06 21:57:36,424 - INFO - training batch 601, loss: 0.131, 19232/28000 datapoints
2025-03-06 21:57:36,569 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 21:57:36,714 - INFO - training batch 701, loss: 0.137, 22432/28000 datapoints
2025-03-06 21:57:36,863 - INFO - training batch 751, loss: 0.125, 24032/28000 datapoints
2025-03-06 21:57:37,012 - INFO - training batch 801, loss: 0.086, 25632/28000 datapoints
2025-03-06 21:57:37,158 - INFO - training batch 851, loss: 0.174, 27232/28000 datapoints
2025-03-06 21:57:37,228 - INFO - validation batch 1, loss: 0.137, 32/6976 datapoints
2025-03-06 21:57:37,274 - INFO - validation batch 51, loss: 1.921, 1632/6976 datapoints
2025-03-06 21:57:37,320 - INFO - validation batch 101, loss: 0.521, 3232/6976 datapoints
2025-03-06 21:57:37,367 - INFO - validation batch 151, loss: 0.625, 4832/6976 datapoints
2025-03-06 21:57:37,414 - INFO - validation batch 201, loss: 0.477, 6432/6976 datapoints
2025-03-06 21:57:37,430 - INFO - Epoch 278/800 done.
2025-03-06 21:57:37,430 - INFO - Final validation performance:
Loss: 0.736, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 21:57:37,431 - INFO - Beginning epoch 279/800
2025-03-06 21:57:37,435 - INFO - training batch 1, loss: 0.218, 32/28000 datapoints
2025-03-06 21:57:37,579 - INFO - training batch 51, loss: 0.092, 1632/28000 datapoints
2025-03-06 21:57:37,723 - INFO - training batch 101, loss: 0.084, 3232/28000 datapoints
2025-03-06 21:57:37,884 - INFO - training batch 151, loss: 0.132, 4832/28000 datapoints
2025-03-06 21:57:38,028 - INFO - training batch 201, loss: 0.076, 6432/28000 datapoints
2025-03-06 21:57:38,175 - INFO - training batch 251, loss: 0.247, 8032/28000 datapoints
2025-03-06 21:57:38,318 - INFO - training batch 301, loss: 0.498, 9632/28000 datapoints
2025-03-06 21:57:38,469 - INFO - training batch 351, loss: 0.187, 11232/28000 datapoints
2025-03-06 21:57:38,611 - INFO - training batch 401, loss: 0.344, 12832/28000 datapoints
2025-03-06 21:57:38,755 - INFO - training batch 451, loss: 0.366, 14432/28000 datapoints
2025-03-06 21:57:38,901 - INFO - training batch 501, loss: 0.133, 16032/28000 datapoints
2025-03-06 21:57:39,047 - INFO - training batch 551, loss: 0.181, 17632/28000 datapoints
2025-03-06 21:57:39,194 - INFO - training batch 601, loss: 0.132, 19232/28000 datapoints
2025-03-06 21:57:39,342 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 21:57:39,491 - INFO - training batch 701, loss: 0.136, 22432/28000 datapoints
2025-03-06 21:57:39,638 - INFO - training batch 751, loss: 0.125, 24032/28000 datapoints
2025-03-06 21:57:39,786 - INFO - training batch 801, loss: 0.084, 25632/28000 datapoints
2025-03-06 21:57:39,937 - INFO - training batch 851, loss: 0.174, 27232/28000 datapoints
2025-03-06 21:57:40,009 - INFO - validation batch 1, loss: 0.137, 32/6976 datapoints
2025-03-06 21:57:40,056 - INFO - validation batch 51, loss: 1.923, 1632/6976 datapoints
2025-03-06 21:57:40,103 - INFO - validation batch 101, loss: 0.523, 3232/6976 datapoints
2025-03-06 21:57:40,151 - INFO - validation batch 151, loss: 0.626, 4832/6976 datapoints
2025-03-06 21:57:40,198 - INFO - validation batch 201, loss: 0.478, 6432/6976 datapoints
2025-03-06 21:57:40,214 - INFO - Epoch 279/800 done.
2025-03-06 21:57:40,214 - INFO - Final validation performance:
Loss: 0.738, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:40,215 - INFO - Beginning epoch 280/800
2025-03-06 21:57:40,219 - INFO - training batch 1, loss: 0.217, 32/28000 datapoints
2025-03-06 21:57:40,367 - INFO - training batch 51, loss: 0.091, 1632/28000 datapoints
2025-03-06 21:57:40,520 - INFO - training batch 101, loss: 0.084, 3232/28000 datapoints
2025-03-06 21:57:40,671 - INFO - training batch 151, loss: 0.132, 4832/28000 datapoints
2025-03-06 21:57:40,848 - INFO - training batch 201, loss: 0.076, 6432/28000 datapoints
2025-03-06 21:57:40,999 - INFO - training batch 251, loss: 0.246, 8032/28000 datapoints
2025-03-06 21:57:41,149 - INFO - training batch 301, loss: 0.495, 9632/28000 datapoints
2025-03-06 21:57:41,293 - INFO - training batch 351, loss: 0.187, 11232/28000 datapoints
2025-03-06 21:57:41,439 - INFO - training batch 401, loss: 0.341, 12832/28000 datapoints
2025-03-06 21:57:41,588 - INFO - training batch 451, loss: 0.366, 14432/28000 datapoints
2025-03-06 21:57:41,732 - INFO - training batch 501, loss: 0.132, 16032/28000 datapoints
2025-03-06 21:57:41,881 - INFO - training batch 551, loss: 0.179, 17632/28000 datapoints
2025-03-06 21:57:42,025 - INFO - training batch 601, loss: 0.129, 19232/28000 datapoints
2025-03-06 21:57:42,170 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 21:57:42,313 - INFO - training batch 701, loss: 0.135, 22432/28000 datapoints
2025-03-06 21:57:42,461 - INFO - training batch 751, loss: 0.124, 24032/28000 datapoints
2025-03-06 21:57:42,608 - INFO - training batch 801, loss: 0.083, 25632/28000 datapoints
2025-03-06 21:57:42,752 - INFO - training batch 851, loss: 0.172, 27232/28000 datapoints
2025-03-06 21:57:42,823 - INFO - validation batch 1, loss: 0.139, 32/6976 datapoints
2025-03-06 21:57:42,871 - INFO - validation batch 51, loss: 1.930, 1632/6976 datapoints
2025-03-06 21:57:42,917 - INFO - validation batch 101, loss: 0.527, 3232/6976 datapoints
2025-03-06 21:57:42,962 - INFO - validation batch 151, loss: 0.631, 4832/6976 datapoints
2025-03-06 21:57:43,010 - INFO - validation batch 201, loss: 0.477, 6432/6976 datapoints
2025-03-06 21:57:43,026 - INFO - Epoch 280/800 done.
2025-03-06 21:57:43,026 - INFO - Final validation performance:
Loss: 0.741, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 21:57:43,026 - INFO - Beginning epoch 281/800
2025-03-06 21:57:43,030 - INFO - training batch 1, loss: 0.214, 32/28000 datapoints
2025-03-06 21:57:43,175 - INFO - training batch 51, loss: 0.089, 1632/28000 datapoints
2025-03-06 21:57:43,318 - INFO - training batch 101, loss: 0.083, 3232/28000 datapoints
2025-03-06 21:57:43,465 - INFO - training batch 151, loss: 0.131, 4832/28000 datapoints
2025-03-06 21:57:43,613 - INFO - training batch 201, loss: 0.075, 6432/28000 datapoints
2025-03-06 21:57:43,758 - INFO - training batch 251, loss: 0.245, 8032/28000 datapoints
2025-03-06 21:57:43,906 - INFO - training batch 301, loss: 0.490, 9632/28000 datapoints
2025-03-06 21:57:44,051 - INFO - training batch 351, loss: 0.186, 11232/28000 datapoints
2025-03-06 21:57:44,195 - INFO - training batch 401, loss: 0.337, 12832/28000 datapoints
2025-03-06 21:57:44,339 - INFO - training batch 451, loss: 0.366, 14432/28000 datapoints
2025-03-06 21:57:44,487 - INFO - training batch 501, loss: 0.132, 16032/28000 datapoints
2025-03-06 21:57:44,636 - INFO - training batch 551, loss: 0.178, 17632/28000 datapoints
2025-03-06 21:57:44,781 - INFO - training batch 601, loss: 0.124, 19232/28000 datapoints
2025-03-06 21:57:44,929 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 21:57:45,080 - INFO - training batch 701, loss: 0.133, 22432/28000 datapoints
2025-03-06 21:57:45,233 - INFO - training batch 751, loss: 0.123, 24032/28000 datapoints
2025-03-06 21:57:45,385 - INFO - training batch 801, loss: 0.082, 25632/28000 datapoints
2025-03-06 21:57:45,539 - INFO - training batch 851, loss: 0.170, 27232/28000 datapoints
2025-03-06 21:57:45,613 - INFO - validation batch 1, loss: 0.140, 32/6976 datapoints
2025-03-06 21:57:45,661 - INFO - validation batch 51, loss: 1.933, 1632/6976 datapoints
2025-03-06 21:57:45,713 - INFO - validation batch 101, loss: 0.530, 3232/6976 datapoints
2025-03-06 21:57:45,764 - INFO - validation batch 151, loss: 0.631, 4832/6976 datapoints
2025-03-06 21:57:45,813 - INFO - validation batch 201, loss: 0.475, 6432/6976 datapoints
2025-03-06 21:57:45,830 - INFO - Epoch 281/800 done.
2025-03-06 21:57:45,830 - INFO - Final validation performance:
Loss: 0.742, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:45,831 - INFO - Beginning epoch 282/800
2025-03-06 21:57:45,836 - INFO - training batch 1, loss: 0.212, 32/28000 datapoints
2025-03-06 21:57:45,992 - INFO - training batch 51, loss: 0.089, 1632/28000 datapoints
2025-03-06 21:57:46,147 - INFO - training batch 101, loss: 0.083, 3232/28000 datapoints
2025-03-06 21:57:46,297 - INFO - training batch 151, loss: 0.131, 4832/28000 datapoints
2025-03-06 21:57:46,447 - INFO - training batch 201, loss: 0.074, 6432/28000 datapoints
2025-03-06 21:57:46,598 - INFO - training batch 251, loss: 0.245, 8032/28000 datapoints
2025-03-06 21:57:46,749 - INFO - training batch 301, loss: 0.491, 9632/28000 datapoints
2025-03-06 21:57:46,898 - INFO - training batch 351, loss: 0.185, 11232/28000 datapoints
2025-03-06 21:57:47,047 - INFO - training batch 401, loss: 0.335, 12832/28000 datapoints
2025-03-06 21:57:47,195 - INFO - training batch 451, loss: 0.364, 14432/28000 datapoints
2025-03-06 21:57:47,344 - INFO - training batch 501, loss: 0.131, 16032/28000 datapoints
2025-03-06 21:57:47,494 - INFO - training batch 551, loss: 0.178, 17632/28000 datapoints
2025-03-06 21:57:47,648 - INFO - training batch 601, loss: 0.125, 19232/28000 datapoints
2025-03-06 21:57:47,798 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 21:57:47,947 - INFO - training batch 701, loss: 0.131, 22432/28000 datapoints
2025-03-06 21:57:48,104 - INFO - training batch 751, loss: 0.124, 24032/28000 datapoints
2025-03-06 21:57:48,254 - INFO - training batch 801, loss: 0.080, 25632/28000 datapoints
2025-03-06 21:57:48,403 - INFO - training batch 851, loss: 0.170, 27232/28000 datapoints
2025-03-06 21:57:48,482 - INFO - validation batch 1, loss: 0.141, 32/6976 datapoints
2025-03-06 21:57:48,528 - INFO - validation batch 51, loss: 1.939, 1632/6976 datapoints
2025-03-06 21:57:48,575 - INFO - validation batch 101, loss: 0.532, 3232/6976 datapoints
2025-03-06 21:57:48,625 - INFO - validation batch 151, loss: 0.635, 4832/6976 datapoints
2025-03-06 21:57:48,675 - INFO - validation batch 201, loss: 0.477, 6432/6976 datapoints
2025-03-06 21:57:48,693 - INFO - Epoch 282/800 done.
2025-03-06 21:57:48,694 - INFO - Final validation performance:
Loss: 0.745, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 21:57:48,694 - INFO - Beginning epoch 283/800
2025-03-06 21:57:48,698 - INFO - training batch 1, loss: 0.211, 32/28000 datapoints
2025-03-06 21:57:48,851 - INFO - training batch 51, loss: 0.089, 1632/28000 datapoints
2025-03-06 21:57:48,994 - INFO - training batch 101, loss: 0.083, 3232/28000 datapoints
2025-03-06 21:57:49,143 - INFO - training batch 151, loss: 0.130, 4832/28000 datapoints
2025-03-06 21:57:49,287 - INFO - training batch 201, loss: 0.074, 6432/28000 datapoints
2025-03-06 21:57:49,430 - INFO - training batch 251, loss: 0.244, 8032/28000 datapoints
2025-03-06 21:57:49,574 - INFO - training batch 301, loss: 0.486, 9632/28000 datapoints
2025-03-06 21:57:49,718 - INFO - training batch 351, loss: 0.185, 11232/28000 datapoints
2025-03-06 21:57:49,864 - INFO - training batch 401, loss: 0.331, 12832/28000 datapoints
2025-03-06 21:57:50,007 - INFO - training batch 451, loss: 0.363, 14432/28000 datapoints
2025-03-06 21:57:50,152 - INFO - training batch 501, loss: 0.130, 16032/28000 datapoints
2025-03-06 21:57:50,299 - INFO - training batch 551, loss: 0.176, 17632/28000 datapoints
2025-03-06 21:57:50,442 - INFO - training batch 601, loss: 0.121, 19232/28000 datapoints
2025-03-06 21:57:50,593 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 21:57:50,736 - INFO - training batch 701, loss: 0.130, 22432/28000 datapoints
2025-03-06 21:57:50,908 - INFO - training batch 751, loss: 0.122, 24032/28000 datapoints
2025-03-06 21:57:51,056 - INFO - training batch 801, loss: 0.080, 25632/28000 datapoints
2025-03-06 21:57:51,204 - INFO - training batch 851, loss: 0.167, 27232/28000 datapoints
2025-03-06 21:57:51,278 - INFO - validation batch 1, loss: 0.141, 32/6976 datapoints
2025-03-06 21:57:51,325 - INFO - validation batch 51, loss: 1.940, 1632/6976 datapoints
2025-03-06 21:57:51,372 - INFO - validation batch 101, loss: 0.536, 3232/6976 datapoints
2025-03-06 21:57:51,419 - INFO - validation batch 151, loss: 0.638, 4832/6976 datapoints
2025-03-06 21:57:51,466 - INFO - validation batch 201, loss: 0.475, 6432/6976 datapoints
2025-03-06 21:57:51,482 - INFO - Epoch 283/800 done.
2025-03-06 21:57:51,482 - INFO - Final validation performance:
Loss: 0.746, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:51,483 - INFO - Beginning epoch 284/800
2025-03-06 21:57:51,487 - INFO - training batch 1, loss: 0.209, 32/28000 datapoints
2025-03-06 21:57:51,638 - INFO - training batch 51, loss: 0.088, 1632/28000 datapoints
2025-03-06 21:57:51,784 - INFO - training batch 101, loss: 0.082, 3232/28000 datapoints
2025-03-06 21:57:51,935 - INFO - training batch 151, loss: 0.129, 4832/28000 datapoints
2025-03-06 21:57:52,084 - INFO - training batch 201, loss: 0.074, 6432/28000 datapoints
2025-03-06 21:57:52,233 - INFO - training batch 251, loss: 0.244, 8032/28000 datapoints
2025-03-06 21:57:52,380 - INFO - training batch 301, loss: 0.484, 9632/28000 datapoints
2025-03-06 21:57:52,535 - INFO - training batch 351, loss: 0.184, 11232/28000 datapoints
2025-03-06 21:57:52,683 - INFO - training batch 401, loss: 0.327, 12832/28000 datapoints
2025-03-06 21:57:52,828 - INFO - training batch 451, loss: 0.361, 14432/28000 datapoints
2025-03-06 21:57:52,976 - INFO - training batch 501, loss: 0.130, 16032/28000 datapoints
2025-03-06 21:57:53,121 - INFO - training batch 551, loss: 0.175, 17632/28000 datapoints
2025-03-06 21:57:53,267 - INFO - training batch 601, loss: 0.122, 19232/28000 datapoints
2025-03-06 21:57:53,409 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 21:57:53,553 - INFO - training batch 701, loss: 0.128, 22432/28000 datapoints
2025-03-06 21:57:53,701 - INFO - training batch 751, loss: 0.121, 24032/28000 datapoints
2025-03-06 21:57:53,847 - INFO - training batch 801, loss: 0.079, 25632/28000 datapoints
2025-03-06 21:57:53,990 - INFO - training batch 851, loss: 0.166, 27232/28000 datapoints
2025-03-06 21:57:54,061 - INFO - validation batch 1, loss: 0.143, 32/6976 datapoints
2025-03-06 21:57:54,109 - INFO - validation batch 51, loss: 1.948, 1632/6976 datapoints
2025-03-06 21:57:54,154 - INFO - validation batch 101, loss: 0.539, 3232/6976 datapoints
2025-03-06 21:57:54,203 - INFO - validation batch 151, loss: 0.641, 4832/6976 datapoints
2025-03-06 21:57:54,249 - INFO - validation batch 201, loss: 0.476, 6432/6976 datapoints
2025-03-06 21:57:54,265 - INFO - Epoch 284/800 done.
2025-03-06 21:57:54,265 - INFO - Final validation performance:
Loss: 0.749, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:54,266 - INFO - Beginning epoch 285/800
2025-03-06 21:57:54,270 - INFO - training batch 1, loss: 0.207, 32/28000 datapoints
2025-03-06 21:57:54,415 - INFO - training batch 51, loss: 0.087, 1632/28000 datapoints
2025-03-06 21:57:54,563 - INFO - training batch 101, loss: 0.082, 3232/28000 datapoints
2025-03-06 21:57:54,712 - INFO - training batch 151, loss: 0.128, 4832/28000 datapoints
2025-03-06 21:57:54,856 - INFO - training batch 201, loss: 0.073, 6432/28000 datapoints
2025-03-06 21:57:54,999 - INFO - training batch 251, loss: 0.242, 8032/28000 datapoints
2025-03-06 21:57:55,151 - INFO - training batch 301, loss: 0.481, 9632/28000 datapoints
2025-03-06 21:57:55,298 - INFO - training batch 351, loss: 0.184, 11232/28000 datapoints
2025-03-06 21:57:55,442 - INFO - training batch 401, loss: 0.323, 12832/28000 datapoints
2025-03-06 21:57:55,585 - INFO - training batch 451, loss: 0.360, 14432/28000 datapoints
2025-03-06 21:57:55,730 - INFO - training batch 501, loss: 0.129, 16032/28000 datapoints
2025-03-06 21:57:55,881 - INFO - training batch 551, loss: 0.174, 17632/28000 datapoints
2025-03-06 21:57:56,025 - INFO - training batch 601, loss: 0.119, 19232/28000 datapoints
2025-03-06 21:57:56,171 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 21:57:56,318 - INFO - training batch 701, loss: 0.127, 22432/28000 datapoints
2025-03-06 21:57:56,462 - INFO - training batch 751, loss: 0.121, 24032/28000 datapoints
2025-03-06 21:57:56,610 - INFO - training batch 801, loss: 0.077, 25632/28000 datapoints
2025-03-06 21:57:56,756 - INFO - training batch 851, loss: 0.164, 27232/28000 datapoints
2025-03-06 21:57:56,827 - INFO - validation batch 1, loss: 0.143, 32/6976 datapoints
2025-03-06 21:57:56,877 - INFO - validation batch 51, loss: 1.950, 1632/6976 datapoints
2025-03-06 21:57:56,923 - INFO - validation batch 101, loss: 0.543, 3232/6976 datapoints
2025-03-06 21:57:56,968 - INFO - validation batch 151, loss: 0.645, 4832/6976 datapoints
2025-03-06 21:57:57,014 - INFO - validation batch 201, loss: 0.475, 6432/6976 datapoints
2025-03-06 21:57:57,030 - INFO - Epoch 285/800 done.
2025-03-06 21:57:57,030 - INFO - Final validation performance:
Loss: 0.751, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:57,031 - INFO - Beginning epoch 286/800
2025-03-06 21:57:57,034 - INFO - training batch 1, loss: 0.206, 32/28000 datapoints
2025-03-06 21:57:57,184 - INFO - training batch 51, loss: 0.087, 1632/28000 datapoints
2025-03-06 21:57:57,327 - INFO - training batch 101, loss: 0.082, 3232/28000 datapoints
2025-03-06 21:57:57,470 - INFO - training batch 151, loss: 0.127, 4832/28000 datapoints
2025-03-06 21:57:57,614 - INFO - training batch 201, loss: 0.073, 6432/28000 datapoints
2025-03-06 21:57:57,759 - INFO - training batch 251, loss: 0.240, 8032/28000 datapoints
2025-03-06 21:57:57,909 - INFO - training batch 301, loss: 0.477, 9632/28000 datapoints
2025-03-06 21:57:58,055 - INFO - training batch 351, loss: 0.183, 11232/28000 datapoints
2025-03-06 21:57:58,202 - INFO - training batch 401, loss: 0.319, 12832/28000 datapoints
2025-03-06 21:57:58,350 - INFO - training batch 451, loss: 0.359, 14432/28000 datapoints
2025-03-06 21:57:58,505 - INFO - training batch 501, loss: 0.129, 16032/28000 datapoints
2025-03-06 21:57:58,653 - INFO - training batch 551, loss: 0.173, 17632/28000 datapoints
2025-03-06 21:57:58,807 - INFO - training batch 601, loss: 0.119, 19232/28000 datapoints
2025-03-06 21:57:58,954 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 21:57:59,098 - INFO - training batch 701, loss: 0.126, 22432/28000 datapoints
2025-03-06 21:57:59,242 - INFO - training batch 751, loss: 0.120, 24032/28000 datapoints
2025-03-06 21:57:59,390 - INFO - training batch 801, loss: 0.076, 25632/28000 datapoints
2025-03-06 21:57:59,538 - INFO - training batch 851, loss: 0.164, 27232/28000 datapoints
2025-03-06 21:57:59,609 - INFO - validation batch 1, loss: 0.146, 32/6976 datapoints
2025-03-06 21:57:59,654 - INFO - validation batch 51, loss: 1.956, 1632/6976 datapoints
2025-03-06 21:57:59,702 - INFO - validation batch 101, loss: 0.546, 3232/6976 datapoints
2025-03-06 21:57:59,749 - INFO - validation batch 151, loss: 0.649, 4832/6976 datapoints
2025-03-06 21:57:59,794 - INFO - validation batch 201, loss: 0.477, 6432/6976 datapoints
2025-03-06 21:57:59,810 - INFO - Epoch 286/800 done.
2025-03-06 21:57:59,811 - INFO - Final validation performance:
Loss: 0.755, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:57:59,811 - INFO - Beginning epoch 287/800
2025-03-06 21:57:59,815 - INFO - training batch 1, loss: 0.205, 32/28000 datapoints
2025-03-06 21:57:59,965 - INFO - training batch 51, loss: 0.086, 1632/28000 datapoints
2025-03-06 21:58:00,110 - INFO - training batch 101, loss: 0.081, 3232/28000 datapoints
2025-03-06 21:58:00,258 - INFO - training batch 151, loss: 0.126, 4832/28000 datapoints
2025-03-06 21:58:00,407 - INFO - training batch 201, loss: 0.073, 6432/28000 datapoints
2025-03-06 21:58:00,556 - INFO - training batch 251, loss: 0.240, 8032/28000 datapoints
2025-03-06 21:58:00,700 - INFO - training batch 301, loss: 0.475, 9632/28000 datapoints
2025-03-06 21:58:00,848 - INFO - training batch 351, loss: 0.182, 11232/28000 datapoints
2025-03-06 21:58:01,012 - INFO - training batch 401, loss: 0.316, 12832/28000 datapoints
2025-03-06 21:58:01,159 - INFO - training batch 451, loss: 0.357, 14432/28000 datapoints
2025-03-06 21:58:01,316 - INFO - training batch 501, loss: 0.129, 16032/28000 datapoints
2025-03-06 21:58:01,463 - INFO - training batch 551, loss: 0.171, 17632/28000 datapoints
2025-03-06 21:58:01,611 - INFO - training batch 601, loss: 0.115, 19232/28000 datapoints
2025-03-06 21:58:01,757 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 21:58:01,914 - INFO - training batch 701, loss: 0.124, 22432/28000 datapoints
2025-03-06 21:58:02,057 - INFO - training batch 751, loss: 0.121, 24032/28000 datapoints
2025-03-06 21:58:02,202 - INFO - training batch 801, loss: 0.075, 25632/28000 datapoints
2025-03-06 21:58:02,347 - INFO - training batch 851, loss: 0.162, 27232/28000 datapoints
2025-03-06 21:58:02,418 - INFO - validation batch 1, loss: 0.149, 32/6976 datapoints
2025-03-06 21:58:02,464 - INFO - validation batch 51, loss: 1.961, 1632/6976 datapoints
2025-03-06 21:58:02,513 - INFO - validation batch 101, loss: 0.549, 3232/6976 datapoints
2025-03-06 21:58:02,561 - INFO - validation batch 151, loss: 0.655, 4832/6976 datapoints
2025-03-06 21:58:02,623 - INFO - validation batch 201, loss: 0.477, 6432/6976 datapoints
2025-03-06 21:58:02,645 - INFO - Epoch 287/800 done.
2025-03-06 21:58:02,646 - INFO - Final validation performance:
Loss: 0.758, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:58:02,646 - INFO - Beginning epoch 288/800
2025-03-06 21:58:02,651 - INFO - training batch 1, loss: 0.204, 32/28000 datapoints
2025-03-06 21:58:02,827 - INFO - training batch 51, loss: 0.085, 1632/28000 datapoints
2025-03-06 21:58:03,011 - INFO - training batch 101, loss: 0.081, 3232/28000 datapoints
2025-03-06 21:58:03,189 - INFO - training batch 151, loss: 0.126, 4832/28000 datapoints
2025-03-06 21:58:03,362 - INFO - training batch 201, loss: 0.072, 6432/28000 datapoints
2025-03-06 21:58:03,517 - INFO - training batch 251, loss: 0.240, 8032/28000 datapoints
2025-03-06 21:58:03,674 - INFO - training batch 301, loss: 0.470, 9632/28000 datapoints
2025-03-06 21:58:03,850 - INFO - training batch 351, loss: 0.182, 11232/28000 datapoints
2025-03-06 21:58:04,053 - INFO - training batch 401, loss: 0.312, 12832/28000 datapoints
2025-03-06 21:58:04,218 - INFO - training batch 451, loss: 0.356, 14432/28000 datapoints
2025-03-06 21:58:04,374 - INFO - training batch 501, loss: 0.128, 16032/28000 datapoints
2025-03-06 21:58:04,538 - INFO - training batch 551, loss: 0.170, 17632/28000 datapoints
2025-03-06 21:58:04,702 - INFO - training batch 601, loss: 0.116, 19232/28000 datapoints
2025-03-06 21:58:04,858 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 21:58:05,008 - INFO - training batch 701, loss: 0.123, 22432/28000 datapoints
2025-03-06 21:58:05,165 - INFO - training batch 751, loss: 0.119, 24032/28000 datapoints
2025-03-06 21:58:05,318 - INFO - training batch 801, loss: 0.075, 25632/28000 datapoints
2025-03-06 21:58:05,473 - INFO - training batch 851, loss: 0.160, 27232/28000 datapoints
2025-03-06 21:58:05,551 - INFO - validation batch 1, loss: 0.149, 32/6976 datapoints
2025-03-06 21:58:05,602 - INFO - validation batch 51, loss: 1.964, 1632/6976 datapoints
2025-03-06 21:58:05,651 - INFO - validation batch 101, loss: 0.552, 3232/6976 datapoints
2025-03-06 21:58:05,702 - INFO - validation batch 151, loss: 0.655, 4832/6976 datapoints
2025-03-06 21:58:05,757 - INFO - validation batch 201, loss: 0.475, 6432/6976 datapoints
2025-03-06 21:58:05,773 - INFO - Epoch 288/800 done.
2025-03-06 21:58:05,774 - INFO - Final validation performance:
Loss: 0.759, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:58:05,774 - INFO - Beginning epoch 289/800
2025-03-06 21:58:05,779 - INFO - training batch 1, loss: 0.201, 32/28000 datapoints
2025-03-06 21:58:05,936 - INFO - training batch 51, loss: 0.085, 1632/28000 datapoints
2025-03-06 21:58:06,089 - INFO - training batch 101, loss: 0.081, 3232/28000 datapoints
2025-03-06 21:58:06,241 - INFO - training batch 151, loss: 0.125, 4832/28000 datapoints
2025-03-06 21:58:06,395 - INFO - training batch 201, loss: 0.072, 6432/28000 datapoints
2025-03-06 21:58:06,550 - INFO - training batch 251, loss: 0.238, 8032/28000 datapoints
2025-03-06 21:58:06,704 - INFO - training batch 301, loss: 0.468, 9632/28000 datapoints
2025-03-06 21:58:06,859 - INFO - training batch 351, loss: 0.181, 11232/28000 datapoints
2025-03-06 21:58:07,008 - INFO - training batch 401, loss: 0.309, 12832/28000 datapoints
2025-03-06 21:58:07,156 - INFO - training batch 451, loss: 0.355, 14432/28000 datapoints
2025-03-06 21:58:07,308 - INFO - training batch 501, loss: 0.127, 16032/28000 datapoints
2025-03-06 21:58:07,458 - INFO - training batch 551, loss: 0.170, 17632/28000 datapoints
2025-03-06 21:58:07,607 - INFO - training batch 601, loss: 0.113, 19232/28000 datapoints
2025-03-06 21:58:07,756 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 21:58:07,909 - INFO - training batch 701, loss: 0.121, 22432/28000 datapoints
2025-03-06 21:58:08,059 - INFO - training batch 751, loss: 0.119, 24032/28000 datapoints
2025-03-06 21:58:08,214 - INFO - training batch 801, loss: 0.073, 25632/28000 datapoints
2025-03-06 21:58:08,362 - INFO - training batch 851, loss: 0.159, 27232/28000 datapoints
2025-03-06 21:58:08,437 - INFO - validation batch 1, loss: 0.151, 32/6976 datapoints
2025-03-06 21:58:08,485 - INFO - validation batch 51, loss: 1.969, 1632/6976 datapoints
2025-03-06 21:58:08,537 - INFO - validation batch 101, loss: 0.555, 3232/6976 datapoints
2025-03-06 21:58:08,585 - INFO - validation batch 151, loss: 0.657, 4832/6976 datapoints
2025-03-06 21:58:08,631 - INFO - validation batch 201, loss: 0.476, 6432/6976 datapoints
2025-03-06 21:58:08,647 - INFO - Epoch 289/800 done.
2025-03-06 21:58:08,648 - INFO - Final validation performance:
Loss: 0.762, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:58:08,648 - INFO - Beginning epoch 290/800
2025-03-06 21:58:08,652 - INFO - training batch 1, loss: 0.201, 32/28000 datapoints
2025-03-06 21:58:08,800 - INFO - training batch 51, loss: 0.084, 1632/28000 datapoints
2025-03-06 21:58:08,947 - INFO - training batch 101, loss: 0.081, 3232/28000 datapoints
2025-03-06 21:58:09,089 - INFO - training batch 151, loss: 0.123, 4832/28000 datapoints
2025-03-06 21:58:09,234 - INFO - training batch 201, loss: 0.072, 6432/28000 datapoints
2025-03-06 21:58:09,383 - INFO - training batch 251, loss: 0.236, 8032/28000 datapoints
2025-03-06 21:58:09,527 - INFO - training batch 301, loss: 0.462, 9632/28000 datapoints
2025-03-06 21:58:09,673 - INFO - training batch 351, loss: 0.181, 11232/28000 datapoints
2025-03-06 21:58:09,816 - INFO - training batch 401, loss: 0.307, 12832/28000 datapoints
2025-03-06 21:58:09,962 - INFO - training batch 451, loss: 0.353, 14432/28000 datapoints
2025-03-06 21:58:10,105 - INFO - training batch 501, loss: 0.126, 16032/28000 datapoints
2025-03-06 21:58:10,250 - INFO - training batch 551, loss: 0.169, 17632/28000 datapoints
2025-03-06 21:58:10,395 - INFO - training batch 601, loss: 0.111, 19232/28000 datapoints
2025-03-06 21:58:10,543 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 21:58:10,688 - INFO - training batch 701, loss: 0.120, 22432/28000 datapoints
2025-03-06 21:58:10,831 - INFO - training batch 751, loss: 0.117, 24032/28000 datapoints
2025-03-06 21:58:10,985 - INFO - training batch 801, loss: 0.072, 25632/28000 datapoints
2025-03-06 21:58:11,149 - INFO - training batch 851, loss: 0.159, 27232/28000 datapoints
2025-03-06 21:58:11,220 - INFO - validation batch 1, loss: 0.153, 32/6976 datapoints
2025-03-06 21:58:11,267 - INFO - validation batch 51, loss: 1.976, 1632/6976 datapoints
2025-03-06 21:58:11,317 - INFO - validation batch 101, loss: 0.558, 3232/6976 datapoints
2025-03-06 21:58:11,363 - INFO - validation batch 151, loss: 0.662, 4832/6976 datapoints
2025-03-06 21:58:11,410 - INFO - validation batch 201, loss: 0.476, 6432/6976 datapoints
2025-03-06 21:58:11,426 - INFO - Epoch 290/800 done.
2025-03-06 21:58:11,426 - INFO - Final validation performance:
Loss: 0.765, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:58:11,426 - INFO - Beginning epoch 291/800
2025-03-06 21:58:11,430 - INFO - training batch 1, loss: 0.198, 32/28000 datapoints
2025-03-06 21:58:11,579 - INFO - training batch 51, loss: 0.085, 1632/28000 datapoints
2025-03-06 21:58:11,722 - INFO - training batch 101, loss: 0.081, 3232/28000 datapoints
2025-03-06 21:58:11,871 - INFO - training batch 151, loss: 0.123, 4832/28000 datapoints
2025-03-06 21:58:12,013 - INFO - training batch 201, loss: 0.071, 6432/28000 datapoints
2025-03-06 21:58:12,157 - INFO - training batch 251, loss: 0.236, 8032/28000 datapoints
2025-03-06 21:58:12,300 - INFO - training batch 301, loss: 0.458, 9632/28000 datapoints
2025-03-06 21:58:12,444 - INFO - training batch 351, loss: 0.181, 11232/28000 datapoints
2025-03-06 21:58:12,591 - INFO - training batch 401, loss: 0.302, 12832/28000 datapoints
2025-03-06 21:58:12,734 - INFO - training batch 451, loss: 0.352, 14432/28000 datapoints
2025-03-06 21:58:12,884 - INFO - training batch 501, loss: 0.126, 16032/28000 datapoints
2025-03-06 21:58:13,034 - INFO - training batch 551, loss: 0.166, 17632/28000 datapoints
2025-03-06 21:58:13,190 - INFO - training batch 601, loss: 0.113, 19232/28000 datapoints
2025-03-06 21:58:13,335 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 21:58:13,482 - INFO - training batch 701, loss: 0.117, 22432/28000 datapoints
2025-03-06 21:58:13,625 - INFO - training batch 751, loss: 0.116, 24032/28000 datapoints
2025-03-06 21:58:13,770 - INFO - training batch 801, loss: 0.072, 25632/28000 datapoints
2025-03-06 21:58:13,919 - INFO - training batch 851, loss: 0.156, 27232/28000 datapoints
2025-03-06 21:58:13,990 - INFO - validation batch 1, loss: 0.154, 32/6976 datapoints
2025-03-06 21:58:14,036 - INFO - validation batch 51, loss: 1.975, 1632/6976 datapoints
2025-03-06 21:58:14,085 - INFO - validation batch 101, loss: 0.559, 3232/6976 datapoints
2025-03-06 21:58:14,131 - INFO - validation batch 151, loss: 0.665, 4832/6976 datapoints
2025-03-06 21:58:14,177 - INFO - validation batch 201, loss: 0.473, 6432/6976 datapoints
2025-03-06 21:58:14,193 - INFO - Epoch 291/800 done.
2025-03-06 21:58:14,193 - INFO - Final validation performance:
Loss: 0.765, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:58:14,194 - INFO - Beginning epoch 292/800
2025-03-06 21:58:14,198 - INFO - training batch 1, loss: 0.197, 32/28000 datapoints
2025-03-06 21:58:14,345 - INFO - training batch 51, loss: 0.083, 1632/28000 datapoints
2025-03-06 21:58:14,491 - INFO - training batch 101, loss: 0.080, 3232/28000 datapoints
2025-03-06 21:58:14,640 - INFO - training batch 151, loss: 0.122, 4832/28000 datapoints
2025-03-06 21:58:14,784 - INFO - training batch 201, loss: 0.071, 6432/28000 datapoints
2025-03-06 21:58:14,931 - INFO - training batch 251, loss: 0.236, 8032/28000 datapoints
2025-03-06 21:58:15,083 - INFO - training batch 301, loss: 0.454, 9632/28000 datapoints
2025-03-06 21:58:15,229 - INFO - training batch 351, loss: 0.180, 11232/28000 datapoints
2025-03-06 21:58:15,384 - INFO - training batch 401, loss: 0.299, 12832/28000 datapoints
2025-03-06 21:58:15,528 - INFO - training batch 451, loss: 0.351, 14432/28000 datapoints
2025-03-06 21:58:15,673 - INFO - training batch 501, loss: 0.126, 16032/28000 datapoints
2025-03-06 21:58:15,816 - INFO - training batch 551, loss: 0.166, 17632/28000 datapoints
2025-03-06 21:58:15,969 - INFO - training batch 601, loss: 0.107, 19232/28000 datapoints
2025-03-06 21:58:16,115 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 21:58:16,261 - INFO - training batch 701, loss: 0.116, 22432/28000 datapoints
2025-03-06 21:58:16,414 - INFO - training batch 751, loss: 0.115, 24032/28000 datapoints
2025-03-06 21:58:16,593 - INFO - training batch 801, loss: 0.070, 25632/28000 datapoints
2025-03-06 21:58:16,745 - INFO - training batch 851, loss: 0.155, 27232/28000 datapoints
2025-03-06 21:58:16,818 - INFO - validation batch 1, loss: 0.157, 32/6976 datapoints
2025-03-06 21:58:16,868 - INFO - validation batch 51, loss: 1.982, 1632/6976 datapoints
2025-03-06 21:58:16,917 - INFO - validation batch 101, loss: 0.562, 3232/6976 datapoints
2025-03-06 21:58:16,964 - INFO - validation batch 151, loss: 0.668, 4832/6976 datapoints
2025-03-06 21:58:17,011 - INFO - validation batch 201, loss: 0.475, 6432/6976 datapoints
2025-03-06 21:58:17,027 - INFO - Epoch 292/800 done.
2025-03-06 21:58:17,027 - INFO - Final validation performance:
Loss: 0.769, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:58:17,028 - INFO - Beginning epoch 293/800
2025-03-06 21:58:17,033 - INFO - training batch 1, loss: 0.196, 32/28000 datapoints
2025-03-06 21:58:17,186 - INFO - training batch 51, loss: 0.082, 1632/28000 datapoints
2025-03-06 21:58:17,334 - INFO - training batch 101, loss: 0.079, 3232/28000 datapoints
2025-03-06 21:58:17,484 - INFO - training batch 151, loss: 0.122, 4832/28000 datapoints
2025-03-06 21:58:17,633 - INFO - training batch 201, loss: 0.071, 6432/28000 datapoints
2025-03-06 21:58:17,778 - INFO - training batch 251, loss: 0.235, 8032/28000 datapoints
2025-03-06 21:58:17,932 - INFO - training batch 301, loss: 0.447, 9632/28000 datapoints
2025-03-06 21:58:18,079 - INFO - training batch 351, loss: 0.179, 11232/28000 datapoints
2025-03-06 21:58:18,226 - INFO - training batch 401, loss: 0.296, 12832/28000 datapoints
2025-03-06 21:58:18,372 - INFO - training batch 451, loss: 0.349, 14432/28000 datapoints
2025-03-06 21:58:18,516 - INFO - training batch 501, loss: 0.125, 16032/28000 datapoints
2025-03-06 21:58:18,666 - INFO - training batch 551, loss: 0.165, 17632/28000 datapoints
2025-03-06 21:58:18,812 - INFO - training batch 601, loss: 0.105, 19232/28000 datapoints
2025-03-06 21:58:18,960 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 21:58:19,103 - INFO - training batch 701, loss: 0.115, 22432/28000 datapoints
2025-03-06 21:58:19,245 - INFO - training batch 751, loss: 0.115, 24032/28000 datapoints
2025-03-06 21:58:19,390 - INFO - training batch 801, loss: 0.069, 25632/28000 datapoints
2025-03-06 21:58:19,536 - INFO - training batch 851, loss: 0.154, 27232/28000 datapoints
2025-03-06 21:58:19,606 - INFO - validation batch 1, loss: 0.158, 32/6976 datapoints
2025-03-06 21:58:19,654 - INFO - validation batch 51, loss: 1.986, 1632/6976 datapoints
2025-03-06 21:58:19,700 - INFO - validation batch 101, loss: 0.565, 3232/6976 datapoints
2025-03-06 21:58:19,747 - INFO - validation batch 151, loss: 0.671, 4832/6976 datapoints
2025-03-06 21:58:19,793 - INFO - validation batch 201, loss: 0.475, 6432/6976 datapoints
2025-03-06 21:58:19,809 - INFO - Epoch 293/800 done.
2025-03-06 21:58:19,809 - INFO - Final validation performance:
Loss: 0.771, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:58:19,809 - INFO - Beginning epoch 294/800
2025-03-06 21:58:19,813 - INFO - training batch 1, loss: 0.194, 32/28000 datapoints
2025-03-06 21:58:19,963 - INFO - training batch 51, loss: 0.082, 1632/28000 datapoints
2025-03-06 21:58:20,106 - INFO - training batch 101, loss: 0.079, 3232/28000 datapoints
2025-03-06 21:58:20,249 - INFO - training batch 151, loss: 0.121, 4832/28000 datapoints
2025-03-06 21:58:20,394 - INFO - training batch 201, loss: 0.070, 6432/28000 datapoints
2025-03-06 21:58:20,538 - INFO - training batch 251, loss: 0.233, 8032/28000 datapoints
2025-03-06 21:58:20,685 - INFO - training batch 301, loss: 0.445, 9632/28000 datapoints
2025-03-06 21:58:20,827 - INFO - training batch 351, loss: 0.178, 11232/28000 datapoints
2025-03-06 21:58:20,977 - INFO - training batch 401, loss: 0.291, 12832/28000 datapoints
2025-03-06 21:58:21,151 - INFO - training batch 451, loss: 0.348, 14432/28000 datapoints
2025-03-06 21:58:21,298 - INFO - training batch 501, loss: 0.124, 16032/28000 datapoints
2025-03-06 21:58:21,445 - INFO - training batch 551, loss: 0.164, 17632/28000 datapoints
2025-03-06 21:58:21,589 - INFO - training batch 601, loss: 0.105, 19232/28000 datapoints
2025-03-06 21:58:21,734 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 21:58:21,878 - INFO - training batch 701, loss: 0.113, 22432/28000 datapoints
2025-03-06 21:58:22,022 - INFO - training batch 751, loss: 0.115, 24032/28000 datapoints
2025-03-06 21:58:22,173 - INFO - training batch 801, loss: 0.068, 25632/28000 datapoints
2025-03-06 21:58:22,317 - INFO - training batch 851, loss: 0.153, 27232/28000 datapoints
2025-03-06 21:58:22,388 - INFO - validation batch 1, loss: 0.164, 32/6976 datapoints
2025-03-06 21:58:22,437 - INFO - validation batch 51, loss: 1.992, 1632/6976 datapoints
2025-03-06 21:58:22,484 - INFO - validation batch 101, loss: 0.566, 3232/6976 datapoints
2025-03-06 21:58:22,530 - INFO - validation batch 151, loss: 0.678, 4832/6976 datapoints
2025-03-06 21:58:22,579 - INFO - validation batch 201, loss: 0.478, 6432/6976 datapoints
2025-03-06 21:58:22,594 - INFO - Epoch 294/800 done.
2025-03-06 21:58:22,595 - INFO - Final validation performance:
Loss: 0.775, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:58:22,595 - INFO - Beginning epoch 295/800
2025-03-06 21:58:22,599 - INFO - training batch 1, loss: 0.193, 32/28000 datapoints
2025-03-06 21:58:22,747 - INFO - training batch 51, loss: 0.081, 1632/28000 datapoints
2025-03-06 21:58:22,893 - INFO - training batch 101, loss: 0.079, 3232/28000 datapoints
2025-03-06 21:58:23,038 - INFO - training batch 151, loss: 0.120, 4832/28000 datapoints
2025-03-06 21:58:23,183 - INFO - training batch 201, loss: 0.070, 6432/28000 datapoints
2025-03-06 21:58:23,326 - INFO - training batch 251, loss: 0.234, 8032/28000 datapoints
2025-03-06 21:58:23,470 - INFO - training batch 301, loss: 0.439, 9632/28000 datapoints
2025-03-06 21:58:23,614 - INFO - training batch 351, loss: 0.179, 11232/28000 datapoints
2025-03-06 21:58:23,757 - INFO - training batch 401, loss: 0.287, 12832/28000 datapoints
2025-03-06 21:58:23,908 - INFO - training batch 451, loss: 0.347, 14432/28000 datapoints
2025-03-06 21:58:24,052 - INFO - training batch 501, loss: 0.123, 16032/28000 datapoints
2025-03-06 21:58:24,197 - INFO - training batch 551, loss: 0.163, 17632/28000 datapoints
2025-03-06 21:58:24,340 - INFO - training batch 601, loss: 0.108, 19232/28000 datapoints
2025-03-06 21:58:24,484 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 21:58:24,632 - INFO - training batch 701, loss: 0.111, 22432/28000 datapoints
2025-03-06 21:58:24,775 - INFO - training batch 751, loss: 0.113, 24032/28000 datapoints
2025-03-06 21:58:24,919 - INFO - training batch 801, loss: 0.068, 25632/28000 datapoints
2025-03-06 21:58:25,066 - INFO - training batch 851, loss: 0.152, 27232/28000 datapoints
2025-03-06 21:58:25,142 - INFO - validation batch 1, loss: 0.162, 32/6976 datapoints
2025-03-06 21:58:25,188 - INFO - validation batch 51, loss: 1.995, 1632/6976 datapoints
2025-03-06 21:58:25,234 - INFO - validation batch 101, loss: 0.571, 3232/6976 datapoints
2025-03-06 21:58:25,280 - INFO - validation batch 151, loss: 0.679, 4832/6976 datapoints
2025-03-06 21:58:25,326 - INFO - validation batch 201, loss: 0.475, 6432/6976 datapoints
2025-03-06 21:58:25,341 - INFO - Epoch 295/800 done.
2025-03-06 21:58:25,341 - INFO - Final validation performance:
Loss: 0.776, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:58:25,342 - INFO - Beginning epoch 296/800
2025-03-06 21:58:25,346 - INFO - training batch 1, loss: 0.191, 32/28000 datapoints
2025-03-06 21:58:25,495 - INFO - training batch 51, loss: 0.081, 1632/28000 datapoints
2025-03-06 21:58:25,643 - INFO - training batch 101, loss: 0.079, 3232/28000 datapoints
2025-03-06 21:58:25,791 - INFO - training batch 151, loss: 0.120, 4832/28000 datapoints
2025-03-06 21:58:25,939 - INFO - training batch 201, loss: 0.070, 6432/28000 datapoints
2025-03-06 21:58:26,090 - INFO - training batch 251, loss: 0.232, 8032/28000 datapoints
2025-03-06 21:58:26,239 - INFO - training batch 301, loss: 0.437, 9632/28000 datapoints
2025-03-06 21:58:26,386 - INFO - training batch 351, loss: 0.178, 11232/28000 datapoints
2025-03-06 21:58:26,533 - INFO - training batch 401, loss: 0.285, 12832/28000 datapoints
2025-03-06 21:58:26,684 - INFO - training batch 451, loss: 0.345, 14432/28000 datapoints
2025-03-06 21:58:26,838 - INFO - training batch 501, loss: 0.124, 16032/28000 datapoints
2025-03-06 21:58:26,986 - INFO - training batch 551, loss: 0.162, 17632/28000 datapoints
2025-03-06 21:58:27,141 - INFO - training batch 601, loss: 0.101, 19232/28000 datapoints
2025-03-06 21:58:27,290 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 21:58:27,442 - INFO - training batch 701, loss: 0.109, 22432/28000 datapoints
2025-03-06 21:58:27,590 - INFO - training batch 751, loss: 0.113, 24032/28000 datapoints
2025-03-06 21:58:27,736 - INFO - training batch 801, loss: 0.066, 25632/28000 datapoints
2025-03-06 21:58:27,888 - INFO - training batch 851, loss: 0.151, 27232/28000 datapoints
2025-03-06 21:58:27,966 - INFO - validation batch 1, loss: 0.165, 32/6976 datapoints
2025-03-06 21:58:28,017 - INFO - validation batch 51, loss: 2.001, 1632/6976 datapoints
2025-03-06 21:58:28,069 - INFO - validation batch 101, loss: 0.574, 3232/6976 datapoints
2025-03-06 21:58:28,121 - INFO - validation batch 151, loss: 0.687, 4832/6976 datapoints
2025-03-06 21:58:28,174 - INFO - validation batch 201, loss: 0.477, 6432/6976 datapoints
2025-03-06 21:58:28,193 - INFO - Epoch 296/800 done.
2025-03-06 21:58:28,193 - INFO - Final validation performance:
Loss: 0.781, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:58:28,194 - INFO - Beginning epoch 297/800
2025-03-06 21:58:28,198 - INFO - training batch 1, loss: 0.189, 32/28000 datapoints
2025-03-06 21:58:28,349 - INFO - training batch 51, loss: 0.080, 1632/28000 datapoints
2025-03-06 21:58:28,504 - INFO - training batch 101, loss: 0.077, 3232/28000 datapoints
2025-03-06 21:58:28,665 - INFO - training batch 151, loss: 0.119, 4832/28000 datapoints
2025-03-06 21:58:28,818 - INFO - training batch 201, loss: 0.069, 6432/28000 datapoints
2025-03-06 21:58:28,973 - INFO - training batch 251, loss: 0.231, 8032/28000 datapoints
2025-03-06 21:58:29,126 - INFO - training batch 301, loss: 0.430, 9632/28000 datapoints
2025-03-06 21:58:29,280 - INFO - training batch 351, loss: 0.178, 11232/28000 datapoints
2025-03-06 21:58:29,430 - INFO - training batch 401, loss: 0.280, 12832/28000 datapoints
2025-03-06 21:58:29,580 - INFO - training batch 451, loss: 0.345, 14432/28000 datapoints
2025-03-06 21:58:29,732 - INFO - training batch 501, loss: 0.124, 16032/28000 datapoints
2025-03-06 21:58:29,884 - INFO - training batch 551, loss: 0.160, 17632/28000 datapoints
2025-03-06 21:58:30,031 - INFO - training batch 601, loss: 0.103, 19232/28000 datapoints
2025-03-06 21:58:30,181 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 21:58:30,326 - INFO - training batch 701, loss: 0.108, 22432/28000 datapoints
2025-03-06 21:58:30,472 - INFO - training batch 751, loss: 0.112, 24032/28000 datapoints
2025-03-06 21:58:30,623 - INFO - training batch 801, loss: 0.066, 25632/28000 datapoints
2025-03-06 21:58:30,770 - INFO - training batch 851, loss: 0.150, 27232/28000 datapoints
2025-03-06 21:58:30,846 - INFO - validation batch 1, loss: 0.166, 32/6976 datapoints
2025-03-06 21:58:30,896 - INFO - validation batch 51, loss: 2.006, 1632/6976 datapoints
2025-03-06 21:58:30,946 - INFO - validation batch 101, loss: 0.576, 3232/6976 datapoints
2025-03-06 21:58:30,997 - INFO - validation batch 151, loss: 0.685, 4832/6976 datapoints
2025-03-06 21:58:31,047 - INFO - validation batch 201, loss: 0.476, 6432/6976 datapoints
2025-03-06 21:58:31,065 - INFO - Epoch 297/800 done.
2025-03-06 21:58:31,065 - INFO - Final validation performance:
Loss: 0.782, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:58:31,066 - INFO - Beginning epoch 298/800
2025-03-06 21:58:31,070 - INFO - training batch 1, loss: 0.186, 32/28000 datapoints
2025-03-06 21:58:31,243 - INFO - training batch 51, loss: 0.080, 1632/28000 datapoints
2025-03-06 21:58:31,390 - INFO - training batch 101, loss: 0.078, 3232/28000 datapoints
2025-03-06 21:58:31,540 - INFO - training batch 151, loss: 0.118, 4832/28000 datapoints
2025-03-06 21:58:31,689 - INFO - training batch 201, loss: 0.068, 6432/28000 datapoints
2025-03-06 21:58:31,837 - INFO - training batch 251, loss: 0.231, 8032/28000 datapoints
2025-03-06 21:58:31,986 - INFO - training batch 301, loss: 0.424, 9632/28000 datapoints
2025-03-06 21:58:32,134 - INFO - training batch 351, loss: 0.178, 11232/28000 datapoints
2025-03-06 21:58:32,282 - INFO - training batch 401, loss: 0.276, 12832/28000 datapoints
2025-03-06 21:58:32,432 - INFO - training batch 451, loss: 0.344, 14432/28000 datapoints
2025-03-06 21:58:32,580 - INFO - training batch 501, loss: 0.123, 16032/28000 datapoints
2025-03-06 21:58:32,732 - INFO - training batch 551, loss: 0.159, 17632/28000 datapoints
2025-03-06 21:58:32,880 - INFO - training batch 601, loss: 0.101, 19232/28000 datapoints
2025-03-06 21:58:33,027 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 21:58:33,174 - INFO - training batch 701, loss: 0.106, 22432/28000 datapoints
2025-03-06 21:58:33,321 - INFO - training batch 751, loss: 0.113, 24032/28000 datapoints
2025-03-06 21:58:33,469 - INFO - training batch 801, loss: 0.065, 25632/28000 datapoints
2025-03-06 21:58:33,617 - INFO - training batch 851, loss: 0.150, 27232/28000 datapoints
2025-03-06 21:58:33,693 - INFO - validation batch 1, loss: 0.173, 32/6976 datapoints
2025-03-06 21:58:33,743 - INFO - validation batch 51, loss: 2.014, 1632/6976 datapoints
2025-03-06 21:58:33,793 - INFO - validation batch 101, loss: 0.579, 3232/6976 datapoints
2025-03-06 21:58:33,850 - INFO - validation batch 151, loss: 0.692, 4832/6976 datapoints
2025-03-06 21:58:33,900 - INFO - validation batch 201, loss: 0.481, 6432/6976 datapoints
2025-03-06 21:58:33,916 - INFO - Epoch 298/800 done.
2025-03-06 21:58:33,916 - INFO - Final validation performance:
Loss: 0.788, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:58:33,917 - INFO - Beginning epoch 299/800
2025-03-06 21:58:33,921 - INFO - training batch 1, loss: 0.185, 32/28000 datapoints
2025-03-06 21:58:34,070 - INFO - training batch 51, loss: 0.079, 1632/28000 datapoints
2025-03-06 21:58:34,221 - INFO - training batch 101, loss: 0.077, 3232/28000 datapoints
2025-03-06 21:58:34,369 - INFO - training batch 151, loss: 0.117, 4832/28000 datapoints
2025-03-06 21:58:34,516 - INFO - training batch 201, loss: 0.068, 6432/28000 datapoints
2025-03-06 21:58:34,670 - INFO - training batch 251, loss: 0.230, 8032/28000 datapoints
2025-03-06 21:58:34,818 - INFO - training batch 301, loss: 0.420, 9632/28000 datapoints
2025-03-06 21:58:34,967 - INFO - training batch 351, loss: 0.178, 11232/28000 datapoints
2025-03-06 21:58:35,123 - INFO - training batch 401, loss: 0.272, 12832/28000 datapoints
2025-03-06 21:58:35,271 - INFO - training batch 451, loss: 0.342, 14432/28000 datapoints
2025-03-06 21:58:35,420 - INFO - training batch 501, loss: 0.122, 16032/28000 datapoints
2025-03-06 21:58:35,573 - INFO - training batch 551, loss: 0.158, 17632/28000 datapoints
2025-03-06 21:58:35,724 - INFO - training batch 601, loss: 0.098, 19232/28000 datapoints
2025-03-06 21:58:35,874 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 21:58:36,023 - INFO - training batch 701, loss: 0.104, 22432/28000 datapoints
2025-03-06 21:58:36,172 - INFO - training batch 751, loss: 0.111, 24032/28000 datapoints
2025-03-06 21:58:36,322 - INFO - training batch 801, loss: 0.064, 25632/28000 datapoints
2025-03-06 21:58:36,475 - INFO - training batch 851, loss: 0.146, 27232/28000 datapoints
2025-03-06 21:58:36,553 - INFO - validation batch 1, loss: 0.172, 32/6976 datapoints
2025-03-06 21:58:36,606 - INFO - validation batch 51, loss: 2.018, 1632/6976 datapoints
2025-03-06 21:58:36,662 - INFO - validation batch 101, loss: 0.582, 3232/6976 datapoints
2025-03-06 21:58:36,714 - INFO - validation batch 151, loss: 0.693, 4832/6976 datapoints
2025-03-06 21:58:36,765 - INFO - validation batch 201, loss: 0.476, 6432/6976 datapoints
2025-03-06 21:58:36,785 - INFO - Epoch 299/800 done.
2025-03-06 21:58:36,785 - INFO - Final validation performance:
Loss: 0.788, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:58:36,786 - INFO - Beginning epoch 300/800
2025-03-06 21:58:36,790 - INFO - training batch 1, loss: 0.183, 32/28000 datapoints
2025-03-06 21:58:36,941 - INFO - training batch 51, loss: 0.078, 1632/28000 datapoints
2025-03-06 21:58:37,089 - INFO - training batch 101, loss: 0.077, 3232/28000 datapoints
2025-03-06 21:58:37,241 - INFO - training batch 151, loss: 0.117, 4832/28000 datapoints
2025-03-06 21:58:37,389 - INFO - training batch 201, loss: 0.068, 6432/28000 datapoints
2025-03-06 21:58:37,537 - INFO - training batch 251, loss: 0.230, 8032/28000 datapoints
2025-03-06 21:58:37,684 - INFO - training batch 301, loss: 0.416, 9632/28000 datapoints
2025-03-06 21:58:37,830 - INFO - training batch 351, loss: 0.177, 11232/28000 datapoints
2025-03-06 21:58:37,994 - INFO - training batch 401, loss: 0.268, 12832/28000 datapoints
2025-03-06 21:58:38,139 - INFO - training batch 451, loss: 0.342, 14432/28000 datapoints
2025-03-06 21:58:38,288 - INFO - training batch 501, loss: 0.122, 16032/28000 datapoints
2025-03-06 21:58:38,433 - INFO - training batch 551, loss: 0.156, 17632/28000 datapoints
2025-03-06 21:58:38,581 - INFO - training batch 601, loss: 0.100, 19232/28000 datapoints
2025-03-06 21:58:38,731 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 21:58:38,877 - INFO - training batch 701, loss: 0.103, 22432/28000 datapoints
2025-03-06 21:58:39,021 - INFO - training batch 751, loss: 0.110, 24032/28000 datapoints
2025-03-06 21:58:39,167 - INFO - training batch 801, loss: 0.063, 25632/28000 datapoints
2025-03-06 21:58:39,319 - INFO - training batch 851, loss: 0.146, 27232/28000 datapoints
2025-03-06 21:58:39,389 - INFO - validation batch 1, loss: 0.173, 32/6976 datapoints
2025-03-06 21:58:39,436 - INFO - validation batch 51, loss: 2.020, 1632/6976 datapoints
2025-03-06 21:58:39,482 - INFO - validation batch 101, loss: 0.584, 3232/6976 datapoints
2025-03-06 21:58:39,529 - INFO - validation batch 151, loss: 0.696, 4832/6976 datapoints
2025-03-06 21:58:39,575 - INFO - validation batch 201, loss: 0.477, 6432/6976 datapoints
2025-03-06 21:58:39,591 - INFO - Epoch 300/800 done.
2025-03-06 21:58:39,591 - INFO - Final validation performance:
Loss: 0.790, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:58:39,592 - INFO - Beginning epoch 301/800
2025-03-06 21:58:39,596 - INFO - training batch 1, loss: 0.182, 32/28000 datapoints
2025-03-06 21:58:39,743 - INFO - training batch 51, loss: 0.078, 1632/28000 datapoints
2025-03-06 21:58:39,888 - INFO - training batch 101, loss: 0.076, 3232/28000 datapoints
2025-03-06 21:58:40,032 - INFO - training batch 151, loss: 0.117, 4832/28000 datapoints
2025-03-06 21:58:40,179 - INFO - training batch 201, loss: 0.067, 6432/28000 datapoints
2025-03-06 21:58:40,323 - INFO - training batch 251, loss: 0.229, 8032/28000 datapoints
2025-03-06 21:58:40,467 - INFO - training batch 301, loss: 0.410, 9632/28000 datapoints
2025-03-06 21:58:40,611 - INFO - training batch 351, loss: 0.177, 11232/28000 datapoints
2025-03-06 21:58:40,759 - INFO - training batch 401, loss: 0.264, 12832/28000 datapoints
2025-03-06 21:58:40,905 - INFO - training batch 451, loss: 0.341, 14432/28000 datapoints
2025-03-06 21:58:41,050 - INFO - training batch 501, loss: 0.121, 16032/28000 datapoints
2025-03-06 21:58:41,196 - INFO - training batch 551, loss: 0.155, 17632/28000 datapoints
2025-03-06 21:58:41,367 - INFO - training batch 601, loss: 0.096, 19232/28000 datapoints
2025-03-06 21:58:41,517 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 21:58:41,660 - INFO - training batch 701, loss: 0.101, 22432/28000 datapoints
2025-03-06 21:58:41,807 - INFO - training batch 751, loss: 0.109, 24032/28000 datapoints
2025-03-06 21:58:41,956 - INFO - training batch 801, loss: 0.062, 25632/28000 datapoints
2025-03-06 21:58:42,114 - INFO - training batch 851, loss: 0.145, 27232/28000 datapoints
2025-03-06 21:58:42,186 - INFO - validation batch 1, loss: 0.177, 32/6976 datapoints
2025-03-06 21:58:42,234 - INFO - validation batch 51, loss: 2.030, 1632/6976 datapoints
2025-03-06 21:58:42,280 - INFO - validation batch 101, loss: 0.587, 3232/6976 datapoints
2025-03-06 21:58:42,328 - INFO - validation batch 151, loss: 0.701, 4832/6976 datapoints
2025-03-06 21:58:42,373 - INFO - validation batch 201, loss: 0.480, 6432/6976 datapoints
2025-03-06 21:58:42,390 - INFO - Epoch 301/800 done.
2025-03-06 21:58:42,390 - INFO - Final validation performance:
Loss: 0.795, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:58:42,390 - INFO - Beginning epoch 302/800
2025-03-06 21:58:42,394 - INFO - training batch 1, loss: 0.180, 32/28000 datapoints
2025-03-06 21:58:42,539 - INFO - training batch 51, loss: 0.078, 1632/28000 datapoints
2025-03-06 21:58:42,686 - INFO - training batch 101, loss: 0.075, 3232/28000 datapoints
2025-03-06 21:58:42,832 - INFO - training batch 151, loss: 0.117, 4832/28000 datapoints
2025-03-06 21:58:42,978 - INFO - training batch 201, loss: 0.067, 6432/28000 datapoints
2025-03-06 21:58:43,120 - INFO - training batch 251, loss: 0.227, 8032/28000 datapoints
2025-03-06 21:58:43,264 - INFO - training batch 301, loss: 0.405, 9632/28000 datapoints
2025-03-06 21:58:43,411 - INFO - training batch 351, loss: 0.177, 11232/28000 datapoints
2025-03-06 21:58:43,554 - INFO - training batch 401, loss: 0.262, 12832/28000 datapoints
2025-03-06 21:58:43,699 - INFO - training batch 451, loss: 0.339, 14432/28000 datapoints
2025-03-06 21:58:43,849 - INFO - training batch 501, loss: 0.121, 16032/28000 datapoints
2025-03-06 21:58:43,996 - INFO - training batch 551, loss: 0.155, 17632/28000 datapoints
2025-03-06 21:58:44,140 - INFO - training batch 601, loss: 0.094, 19232/28000 datapoints
2025-03-06 21:58:44,284 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 21:58:44,426 - INFO - training batch 701, loss: 0.100, 22432/28000 datapoints
2025-03-06 21:58:44,570 - INFO - training batch 751, loss: 0.109, 24032/28000 datapoints
2025-03-06 21:58:44,719 - INFO - training batch 801, loss: 0.061, 25632/28000 datapoints
2025-03-06 21:58:44,865 - INFO - training batch 851, loss: 0.144, 27232/28000 datapoints
2025-03-06 21:58:44,935 - INFO - validation batch 1, loss: 0.179, 32/6976 datapoints
2025-03-06 21:58:44,981 - INFO - validation batch 51, loss: 2.036, 1632/6976 datapoints
2025-03-06 21:58:45,029 - INFO - validation batch 101, loss: 0.589, 3232/6976 datapoints
2025-03-06 21:58:45,076 - INFO - validation batch 151, loss: 0.704, 4832/6976 datapoints
2025-03-06 21:58:45,128 - INFO - validation batch 201, loss: 0.478, 6432/6976 datapoints
2025-03-06 21:58:45,147 - INFO - Epoch 302/800 done.
2025-03-06 21:58:45,147 - INFO - Final validation performance:
Loss: 0.797, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 21:58:45,147 - INFO - Beginning epoch 303/800
2025-03-06 21:58:45,151 - INFO - training batch 1, loss: 0.179, 32/28000 datapoints
2025-03-06 21:58:45,299 - INFO - training batch 51, loss: 0.077, 1632/28000 datapoints
2025-03-06 21:58:45,449 - INFO - training batch 101, loss: 0.075, 3232/28000 datapoints
2025-03-06 21:58:45,595 - INFO - training batch 151, loss: 0.116, 4832/28000 datapoints
2025-03-06 21:58:45,744 - INFO - training batch 201, loss: 0.066, 6432/28000 datapoints
2025-03-06 21:58:45,899 - INFO - training batch 251, loss: 0.226, 8032/28000 datapoints
2025-03-06 21:58:46,048 - INFO - training batch 301, loss: 0.400, 9632/28000 datapoints
2025-03-06 21:58:46,193 - INFO - training batch 351, loss: 0.176, 11232/28000 datapoints
2025-03-06 21:58:46,344 - INFO - training batch 401, loss: 0.257, 12832/28000 datapoints
2025-03-06 21:58:46,491 - INFO - training batch 451, loss: 0.339, 14432/28000 datapoints
2025-03-06 21:58:46,639 - INFO - training batch 501, loss: 0.120, 16032/28000 datapoints
2025-03-06 21:58:46,794 - INFO - training batch 551, loss: 0.153, 17632/28000 datapoints
2025-03-06 21:58:46,945 - INFO - training batch 601, loss: 0.096, 19232/28000 datapoints
2025-03-06 21:58:47,094 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 21:58:47,243 - INFO - training batch 701, loss: 0.098, 22432/28000 datapoints
2025-03-06 21:58:47,397 - INFO - training batch 751, loss: 0.109, 24032/28000 datapoints
2025-03-06 21:58:47,547 - INFO - training batch 801, loss: 0.060, 25632/28000 datapoints
2025-03-06 21:58:47,694 - INFO - training batch 851, loss: 0.145, 27232/28000 datapoints
2025-03-06 21:58:47,770 - INFO - validation batch 1, loss: 0.181, 32/6976 datapoints
2025-03-06 21:58:47,822 - INFO - validation batch 51, loss: 2.044, 1632/6976 datapoints
2025-03-06 21:58:47,877 - INFO - validation batch 101, loss: 0.591, 3232/6976 datapoints
2025-03-06 21:58:47,928 - INFO - validation batch 151, loss: 0.708, 4832/6976 datapoints
2025-03-06 21:58:47,977 - INFO - validation batch 201, loss: 0.481, 6432/6976 datapoints
2025-03-06 21:58:47,996 - INFO - Epoch 303/800 done.
2025-03-06 21:58:47,997 - INFO - Final validation performance:
Loss: 0.801, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:58:47,997 - INFO - Beginning epoch 304/800
2025-03-06 21:58:48,002 - INFO - training batch 1, loss: 0.178, 32/28000 datapoints
2025-03-06 21:58:48,155 - INFO - training batch 51, loss: 0.077, 1632/28000 datapoints
2025-03-06 21:58:48,311 - INFO - training batch 101, loss: 0.075, 3232/28000 datapoints
2025-03-06 21:58:48,459 - INFO - training batch 151, loss: 0.116, 4832/28000 datapoints
2025-03-06 21:58:48,605 - INFO - training batch 201, loss: 0.066, 6432/28000 datapoints
2025-03-06 21:58:48,761 - INFO - training batch 251, loss: 0.226, 8032/28000 datapoints
2025-03-06 21:58:48,912 - INFO - training batch 301, loss: 0.395, 9632/28000 datapoints
2025-03-06 21:58:49,066 - INFO - training batch 351, loss: 0.176, 11232/28000 datapoints
2025-03-06 21:58:49,215 - INFO - training batch 401, loss: 0.252, 12832/28000 datapoints
2025-03-06 21:58:49,363 - INFO - training batch 451, loss: 0.338, 14432/28000 datapoints
2025-03-06 21:58:49,510 - INFO - training batch 501, loss: 0.120, 16032/28000 datapoints
2025-03-06 21:58:49,659 - INFO - training batch 551, loss: 0.152, 17632/28000 datapoints
2025-03-06 21:58:49,808 - INFO - training batch 601, loss: 0.093, 19232/28000 datapoints
2025-03-06 21:58:49,959 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 21:58:50,116 - INFO - training batch 701, loss: 0.097, 22432/28000 datapoints
2025-03-06 21:58:50,271 - INFO - training batch 751, loss: 0.107, 24032/28000 datapoints
2025-03-06 21:58:50,424 - INFO - training batch 801, loss: 0.059, 25632/28000 datapoints
2025-03-06 21:58:50,574 - INFO - training batch 851, loss: 0.140, 27232/28000 datapoints
2025-03-06 21:58:50,651 - INFO - validation batch 1, loss: 0.184, 32/6976 datapoints
2025-03-06 21:58:50,708 - INFO - validation batch 51, loss: 2.046, 1632/6976 datapoints
2025-03-06 21:58:50,762 - INFO - validation batch 101, loss: 0.596, 3232/6976 datapoints
2025-03-06 21:58:50,814 - INFO - validation batch 151, loss: 0.716, 4832/6976 datapoints
2025-03-06 21:58:50,868 - INFO - validation batch 201, loss: 0.479, 6432/6976 datapoints
2025-03-06 21:58:50,887 - INFO - Epoch 304/800 done.
2025-03-06 21:58:50,887 - INFO - Final validation performance:
Loss: 0.804, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:58:50,888 - INFO - Beginning epoch 305/800
2025-03-06 21:58:50,892 - INFO - training batch 1, loss: 0.175, 32/28000 datapoints
2025-03-06 21:58:51,041 - INFO - training batch 51, loss: 0.076, 1632/28000 datapoints
2025-03-06 21:58:51,188 - INFO - training batch 101, loss: 0.073, 3232/28000 datapoints
2025-03-06 21:58:51,337 - INFO - training batch 151, loss: 0.115, 4832/28000 datapoints
2025-03-06 21:58:51,509 - INFO - training batch 201, loss: 0.066, 6432/28000 datapoints
2025-03-06 21:58:51,656 - INFO - training batch 251, loss: 0.224, 8032/28000 datapoints
2025-03-06 21:58:51,805 - INFO - training batch 301, loss: 0.391, 9632/28000 datapoints
2025-03-06 21:58:51,952 - INFO - training batch 351, loss: 0.176, 11232/28000 datapoints
2025-03-06 21:58:52,100 - INFO - training batch 401, loss: 0.249, 12832/28000 datapoints
2025-03-06 21:58:52,244 - INFO - training batch 451, loss: 0.336, 14432/28000 datapoints
2025-03-06 21:58:52,390 - INFO - training batch 501, loss: 0.119, 16032/28000 datapoints
2025-03-06 21:58:52,534 - INFO - training batch 551, loss: 0.151, 17632/28000 datapoints
2025-03-06 21:58:52,678 - INFO - training batch 601, loss: 0.095, 19232/28000 datapoints
2025-03-06 21:58:52,831 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 21:58:52,977 - INFO - training batch 701, loss: 0.096, 22432/28000 datapoints
2025-03-06 21:58:53,120 - INFO - training batch 751, loss: 0.107, 24032/28000 datapoints
2025-03-06 21:58:53,263 - INFO - training batch 801, loss: 0.058, 25632/28000 datapoints
2025-03-06 21:58:53,406 - INFO - training batch 851, loss: 0.140, 27232/28000 datapoints
2025-03-06 21:58:53,476 - INFO - validation batch 1, loss: 0.183, 32/6976 datapoints
2025-03-06 21:58:53,522 - INFO - validation batch 51, loss: 2.052, 1632/6976 datapoints
2025-03-06 21:58:53,568 - INFO - validation batch 101, loss: 0.599, 3232/6976 datapoints
2025-03-06 21:58:53,614 - INFO - validation batch 151, loss: 0.715, 4832/6976 datapoints
2025-03-06 21:58:53,663 - INFO - validation batch 201, loss: 0.479, 6432/6976 datapoints
2025-03-06 21:58:53,681 - INFO - Epoch 305/800 done.
2025-03-06 21:58:53,681 - INFO - Final validation performance:
Loss: 0.806, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:58:53,682 - INFO - Beginning epoch 306/800
2025-03-06 21:58:53,686 - INFO - training batch 1, loss: 0.174, 32/28000 datapoints
2025-03-06 21:58:53,832 - INFO - training batch 51, loss: 0.076, 1632/28000 datapoints
2025-03-06 21:58:53,986 - INFO - training batch 101, loss: 0.073, 3232/28000 datapoints
2025-03-06 21:58:54,131 - INFO - training batch 151, loss: 0.115, 4832/28000 datapoints
2025-03-06 21:58:54,274 - INFO - training batch 201, loss: 0.065, 6432/28000 datapoints
2025-03-06 21:58:54,417 - INFO - training batch 251, loss: 0.224, 8032/28000 datapoints
2025-03-06 21:58:54,561 - INFO - training batch 301, loss: 0.385, 9632/28000 datapoints
2025-03-06 21:58:54,709 - INFO - training batch 351, loss: 0.175, 11232/28000 datapoints
2025-03-06 21:58:54,861 - INFO - training batch 401, loss: 0.245, 12832/28000 datapoints
2025-03-06 21:58:55,011 - INFO - training batch 451, loss: 0.336, 14432/28000 datapoints
2025-03-06 21:58:55,167 - INFO - training batch 501, loss: 0.119, 16032/28000 datapoints
2025-03-06 21:58:55,311 - INFO - training batch 551, loss: 0.150, 17632/28000 datapoints
2025-03-06 21:58:55,456 - INFO - training batch 601, loss: 0.089, 19232/28000 datapoints
2025-03-06 21:58:55,601 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 21:58:55,743 - INFO - training batch 701, loss: 0.094, 22432/28000 datapoints
2025-03-06 21:58:55,956 - INFO - training batch 751, loss: 0.106, 24032/28000 datapoints
2025-03-06 21:58:56,102 - INFO - training batch 801, loss: 0.057, 25632/28000 datapoints
2025-03-06 21:58:56,251 - INFO - training batch 851, loss: 0.139, 27232/28000 datapoints
2025-03-06 21:58:56,324 - INFO - validation batch 1, loss: 0.188, 32/6976 datapoints
2025-03-06 21:58:56,370 - INFO - validation batch 51, loss: 2.059, 1632/6976 datapoints
2025-03-06 21:58:56,420 - INFO - validation batch 101, loss: 0.603, 3232/6976 datapoints
2025-03-06 21:58:56,469 - INFO - validation batch 151, loss: 0.724, 4832/6976 datapoints
2025-03-06 21:58:56,516 - INFO - validation batch 201, loss: 0.481, 6432/6976 datapoints
2025-03-06 21:58:56,531 - INFO - Epoch 306/800 done.
2025-03-06 21:58:56,532 - INFO - Final validation performance:
Loss: 0.811, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:58:56,532 - INFO - Beginning epoch 307/800
2025-03-06 21:58:56,536 - INFO - training batch 1, loss: 0.171, 32/28000 datapoints
2025-03-06 21:58:56,681 - INFO - training batch 51, loss: 0.076, 1632/28000 datapoints
2025-03-06 21:58:56,829 - INFO - training batch 101, loss: 0.072, 3232/28000 datapoints
2025-03-06 21:58:56,977 - INFO - training batch 151, loss: 0.115, 4832/28000 datapoints
2025-03-06 21:58:57,121 - INFO - training batch 201, loss: 0.065, 6432/28000 datapoints
2025-03-06 21:58:57,264 - INFO - training batch 251, loss: 0.223, 8032/28000 datapoints
2025-03-06 21:58:57,409 - INFO - training batch 301, loss: 0.379, 9632/28000 datapoints
2025-03-06 21:58:57,552 - INFO - training batch 351, loss: 0.175, 11232/28000 datapoints
2025-03-06 21:58:57,696 - INFO - training batch 401, loss: 0.241, 12832/28000 datapoints
2025-03-06 21:58:57,855 - INFO - training batch 451, loss: 0.334, 14432/28000 datapoints
2025-03-06 21:58:58,001 - INFO - training batch 501, loss: 0.118, 16032/28000 datapoints
2025-03-06 21:58:58,144 - INFO - training batch 551, loss: 0.149, 17632/28000 datapoints
2025-03-06 21:58:58,288 - INFO - training batch 601, loss: 0.092, 19232/28000 datapoints
2025-03-06 21:58:58,432 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 21:58:58,580 - INFO - training batch 701, loss: 0.092, 22432/28000 datapoints
2025-03-06 21:58:58,728 - INFO - training batch 751, loss: 0.106, 24032/28000 datapoints
2025-03-06 21:58:58,876 - INFO - training batch 801, loss: 0.057, 25632/28000 datapoints
2025-03-06 21:58:59,021 - INFO - training batch 851, loss: 0.138, 27232/28000 datapoints
2025-03-06 21:58:59,093 - INFO - validation batch 1, loss: 0.189, 32/6976 datapoints
2025-03-06 21:58:59,139 - INFO - validation batch 51, loss: 2.067, 1632/6976 datapoints
2025-03-06 21:58:59,185 - INFO - validation batch 101, loss: 0.606, 3232/6976 datapoints
2025-03-06 21:58:59,231 - INFO - validation batch 151, loss: 0.726, 4832/6976 datapoints
2025-03-06 21:58:59,278 - INFO - validation batch 201, loss: 0.480, 6432/6976 datapoints
2025-03-06 21:58:59,293 - INFO - Epoch 307/800 done.
2025-03-06 21:58:59,294 - INFO - Final validation performance:
Loss: 0.813, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:58:59,294 - INFO - Beginning epoch 308/800
2025-03-06 21:58:59,298 - INFO - training batch 1, loss: 0.170, 32/28000 datapoints
2025-03-06 21:58:59,444 - INFO - training batch 51, loss: 0.075, 1632/28000 datapoints
2025-03-06 21:58:59,592 - INFO - training batch 101, loss: 0.072, 3232/28000 datapoints
2025-03-06 21:58:59,735 - INFO - training batch 151, loss: 0.114, 4832/28000 datapoints
2025-03-06 21:58:59,885 - INFO - training batch 201, loss: 0.065, 6432/28000 datapoints
2025-03-06 21:59:00,030 - INFO - training batch 251, loss: 0.223, 8032/28000 datapoints
2025-03-06 21:59:00,174 - INFO - training batch 301, loss: 0.376, 9632/28000 datapoints
2025-03-06 21:59:00,317 - INFO - training batch 351, loss: 0.174, 11232/28000 datapoints
2025-03-06 21:59:00,462 - INFO - training batch 401, loss: 0.237, 12832/28000 datapoints
2025-03-06 21:59:00,606 - INFO - training batch 451, loss: 0.333, 14432/28000 datapoints
2025-03-06 21:59:00,755 - INFO - training batch 501, loss: 0.118, 16032/28000 datapoints
2025-03-06 21:59:00,904 - INFO - training batch 551, loss: 0.147, 17632/28000 datapoints
2025-03-06 21:59:01,047 - INFO - training batch 601, loss: 0.092, 19232/28000 datapoints
2025-03-06 21:59:01,191 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 21:59:01,333 - INFO - training batch 701, loss: 0.091, 22432/28000 datapoints
2025-03-06 21:59:01,485 - INFO - training batch 751, loss: 0.106, 24032/28000 datapoints
2025-03-06 21:59:01,650 - INFO - training batch 801, loss: 0.055, 25632/28000 datapoints
2025-03-06 21:59:01,798 - INFO - training batch 851, loss: 0.137, 27232/28000 datapoints
2025-03-06 21:59:01,875 - INFO - validation batch 1, loss: 0.195, 32/6976 datapoints
2025-03-06 21:59:01,922 - INFO - validation batch 51, loss: 2.078, 1632/6976 datapoints
2025-03-06 21:59:01,977 - INFO - validation batch 101, loss: 0.607, 3232/6976 datapoints
2025-03-06 21:59:02,095 - INFO - validation batch 151, loss: 0.729, 4832/6976 datapoints
2025-03-06 21:59:02,143 - INFO - validation batch 201, loss: 0.483, 6432/6976 datapoints
2025-03-06 21:59:02,159 - INFO - Epoch 308/800 done.
2025-03-06 21:59:02,159 - INFO - Final validation performance:
Loss: 0.818, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:59:02,159 - INFO - Beginning epoch 309/800
2025-03-06 21:59:02,163 - INFO - training batch 1, loss: 0.170, 32/28000 datapoints
2025-03-06 21:59:02,310 - INFO - training batch 51, loss: 0.075, 1632/28000 datapoints
2025-03-06 21:59:02,454 - INFO - training batch 101, loss: 0.071, 3232/28000 datapoints
2025-03-06 21:59:02,603 - INFO - training batch 151, loss: 0.114, 4832/28000 datapoints
2025-03-06 21:59:02,750 - INFO - training batch 201, loss: 0.065, 6432/28000 datapoints
2025-03-06 21:59:02,897 - INFO - training batch 251, loss: 0.222, 8032/28000 datapoints
2025-03-06 21:59:03,040 - INFO - training batch 301, loss: 0.368, 9632/28000 datapoints
2025-03-06 21:59:03,183 - INFO - training batch 351, loss: 0.173, 11232/28000 datapoints
2025-03-06 21:59:03,326 - INFO - training batch 401, loss: 0.234, 12832/28000 datapoints
2025-03-06 21:59:03,469 - INFO - training batch 451, loss: 0.331, 14432/28000 datapoints
2025-03-06 21:59:03,616 - INFO - training batch 501, loss: 0.117, 16032/28000 datapoints
2025-03-06 21:59:03,762 - INFO - training batch 551, loss: 0.146, 17632/28000 datapoints
2025-03-06 21:59:03,911 - INFO - training batch 601, loss: 0.091, 19232/28000 datapoints
2025-03-06 21:59:04,059 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 21:59:04,202 - INFO - training batch 701, loss: 0.090, 22432/28000 datapoints
2025-03-06 21:59:04,346 - INFO - training batch 751, loss: 0.104, 24032/28000 datapoints
2025-03-06 21:59:04,489 - INFO - training batch 801, loss: 0.055, 25632/28000 datapoints
2025-03-06 21:59:04,633 - INFO - training batch 851, loss: 0.136, 27232/28000 datapoints
2025-03-06 21:59:04,705 - INFO - validation batch 1, loss: 0.193, 32/6976 datapoints
2025-03-06 21:59:04,755 - INFO - validation batch 51, loss: 2.085, 1632/6976 datapoints
2025-03-06 21:59:04,802 - INFO - validation batch 101, loss: 0.612, 3232/6976 datapoints
2025-03-06 21:59:04,851 - INFO - validation batch 151, loss: 0.730, 4832/6976 datapoints
2025-03-06 21:59:04,898 - INFO - validation batch 201, loss: 0.481, 6432/6976 datapoints
2025-03-06 21:59:04,914 - INFO - Epoch 309/800 done.
2025-03-06 21:59:04,914 - INFO - Final validation performance:
Loss: 0.820, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:59:04,915 - INFO - Beginning epoch 310/800
2025-03-06 21:59:04,919 - INFO - training batch 1, loss: 0.167, 32/28000 datapoints
2025-03-06 21:59:05,071 - INFO - training batch 51, loss: 0.075, 1632/28000 datapoints
2025-03-06 21:59:05,226 - INFO - training batch 101, loss: 0.071, 3232/28000 datapoints
2025-03-06 21:59:05,370 - INFO - training batch 151, loss: 0.113, 4832/28000 datapoints
2025-03-06 21:59:05,514 - INFO - training batch 201, loss: 0.064, 6432/28000 datapoints
2025-03-06 21:59:05,659 - INFO - training batch 251, loss: 0.222, 8032/28000 datapoints
2025-03-06 21:59:05,813 - INFO - training batch 301, loss: 0.364, 9632/28000 datapoints
2025-03-06 21:59:05,967 - INFO - training batch 351, loss: 0.173, 11232/28000 datapoints
2025-03-06 21:59:06,118 - INFO - training batch 401, loss: 0.230, 12832/28000 datapoints
2025-03-06 21:59:06,270 - INFO - training batch 451, loss: 0.331, 14432/28000 datapoints
2025-03-06 21:59:06,424 - INFO - training batch 501, loss: 0.116, 16032/28000 datapoints
2025-03-06 21:59:06,578 - INFO - training batch 551, loss: 0.146, 17632/28000 datapoints
2025-03-06 21:59:06,730 - INFO - training batch 601, loss: 0.087, 19232/28000 datapoints
2025-03-06 21:59:06,889 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 21:59:07,040 - INFO - training batch 701, loss: 0.089, 22432/28000 datapoints
2025-03-06 21:59:07,193 - INFO - training batch 751, loss: 0.104, 24032/28000 datapoints
2025-03-06 21:59:07,344 - INFO - training batch 801, loss: 0.054, 25632/28000 datapoints
2025-03-06 21:59:07,495 - INFO - training batch 851, loss: 0.136, 27232/28000 datapoints
2025-03-06 21:59:07,569 - INFO - validation batch 1, loss: 0.198, 32/6976 datapoints
2025-03-06 21:59:07,622 - INFO - validation batch 51, loss: 2.091, 1632/6976 datapoints
2025-03-06 21:59:07,676 - INFO - validation batch 101, loss: 0.615, 3232/6976 datapoints
2025-03-06 21:59:07,728 - INFO - validation batch 151, loss: 0.739, 4832/6976 datapoints
2025-03-06 21:59:07,780 - INFO - validation batch 201, loss: 0.483, 6432/6976 datapoints
2025-03-06 21:59:07,799 - INFO - Epoch 310/800 done.
2025-03-06 21:59:07,799 - INFO - Final validation performance:
Loss: 0.825, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:59:07,800 - INFO - Beginning epoch 311/800
2025-03-06 21:59:07,804 - INFO - training batch 1, loss: 0.166, 32/28000 datapoints
2025-03-06 21:59:07,958 - INFO - training batch 51, loss: 0.075, 1632/28000 datapoints
2025-03-06 21:59:08,110 - INFO - training batch 101, loss: 0.071, 3232/28000 datapoints
2025-03-06 21:59:08,268 - INFO - training batch 151, loss: 0.113, 4832/28000 datapoints
2025-03-06 21:59:08,417 - INFO - training batch 201, loss: 0.064, 6432/28000 datapoints
2025-03-06 21:59:08,566 - INFO - training batch 251, loss: 0.221, 8032/28000 datapoints
2025-03-06 21:59:08,717 - INFO - training batch 301, loss: 0.358, 9632/28000 datapoints
2025-03-06 21:59:08,873 - INFO - training batch 351, loss: 0.172, 11232/28000 datapoints
2025-03-06 21:59:09,018 - INFO - training batch 401, loss: 0.226, 12832/28000 datapoints
2025-03-06 21:59:09,167 - INFO - training batch 451, loss: 0.329, 14432/28000 datapoints
2025-03-06 21:59:09,319 - INFO - training batch 501, loss: 0.115, 16032/28000 datapoints
2025-03-06 21:59:09,465 - INFO - training batch 551, loss: 0.144, 17632/28000 datapoints
2025-03-06 21:59:09,613 - INFO - training batch 601, loss: 0.090, 19232/28000 datapoints
2025-03-06 21:59:09,766 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 21:59:09,918 - INFO - training batch 701, loss: 0.088, 22432/28000 datapoints
2025-03-06 21:59:10,065 - INFO - training batch 751, loss: 0.103, 24032/28000 datapoints
2025-03-06 21:59:10,216 - INFO - training batch 801, loss: 0.053, 25632/28000 datapoints
2025-03-06 21:59:10,364 - INFO - training batch 851, loss: 0.133, 27232/28000 datapoints
2025-03-06 21:59:10,440 - INFO - validation batch 1, loss: 0.201, 32/6976 datapoints
2025-03-06 21:59:10,487 - INFO - validation batch 51, loss: 2.100, 1632/6976 datapoints
2025-03-06 21:59:10,537 - INFO - validation batch 101, loss: 0.619, 3232/6976 datapoints
2025-03-06 21:59:10,587 - INFO - validation batch 151, loss: 0.742, 4832/6976 datapoints
2025-03-06 21:59:10,632 - INFO - validation batch 201, loss: 0.483, 6432/6976 datapoints
2025-03-06 21:59:10,650 - INFO - Epoch 311/800 done.
2025-03-06 21:59:10,650 - INFO - Final validation performance:
Loss: 0.829, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:59:10,651 - INFO - Beginning epoch 312/800
2025-03-06 21:59:10,655 - INFO - training batch 1, loss: 0.163, 32/28000 datapoints
2025-03-06 21:59:10,805 - INFO - training batch 51, loss: 0.074, 1632/28000 datapoints
2025-03-06 21:59:10,952 - INFO - training batch 101, loss: 0.070, 3232/28000 datapoints
2025-03-06 21:59:11,095 - INFO - training batch 151, loss: 0.112, 4832/28000 datapoints
2025-03-06 21:59:11,241 - INFO - training batch 201, loss: 0.063, 6432/28000 datapoints
2025-03-06 21:59:11,386 - INFO - training batch 251, loss: 0.221, 8032/28000 datapoints
2025-03-06 21:59:11,533 - INFO - training batch 301, loss: 0.353, 9632/28000 datapoints
2025-03-06 21:59:11,706 - INFO - training batch 351, loss: 0.172, 11232/28000 datapoints
2025-03-06 21:59:11,850 - INFO - training batch 401, loss: 0.221, 12832/28000 datapoints
2025-03-06 21:59:11,999 - INFO - training batch 451, loss: 0.328, 14432/28000 datapoints
2025-03-06 21:59:12,146 - INFO - training batch 501, loss: 0.115, 16032/28000 datapoints
2025-03-06 21:59:12,293 - INFO - training batch 551, loss: 0.143, 17632/28000 datapoints
2025-03-06 21:59:12,439 - INFO - training batch 601, loss: 0.087, 19232/28000 datapoints
2025-03-06 21:59:12,584 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 21:59:12,731 - INFO - training batch 701, loss: 0.086, 22432/28000 datapoints
2025-03-06 21:59:12,881 - INFO - training batch 751, loss: 0.102, 24032/28000 datapoints
2025-03-06 21:59:13,030 - INFO - training batch 801, loss: 0.052, 25632/28000 datapoints
2025-03-06 21:59:13,177 - INFO - training batch 851, loss: 0.133, 27232/28000 datapoints
2025-03-06 21:59:13,247 - INFO - validation batch 1, loss: 0.201, 32/6976 datapoints
2025-03-06 21:59:13,293 - INFO - validation batch 51, loss: 2.106, 1632/6976 datapoints
2025-03-06 21:59:13,339 - INFO - validation batch 101, loss: 0.622, 3232/6976 datapoints
2025-03-06 21:59:13,386 - INFO - validation batch 151, loss: 0.742, 4832/6976 datapoints
2025-03-06 21:59:13,432 - INFO - validation batch 201, loss: 0.483, 6432/6976 datapoints
2025-03-06 21:59:13,447 - INFO - Epoch 312/800 done.
2025-03-06 21:59:13,448 - INFO - Final validation performance:
Loss: 0.831, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:59:13,448 - INFO - Beginning epoch 313/800
2025-03-06 21:59:13,452 - INFO - training batch 1, loss: 0.164, 32/28000 datapoints
2025-03-06 21:59:13,596 - INFO - training batch 51, loss: 0.073, 1632/28000 datapoints
2025-03-06 21:59:13,743 - INFO - training batch 101, loss: 0.070, 3232/28000 datapoints
2025-03-06 21:59:13,892 - INFO - training batch 151, loss: 0.112, 4832/28000 datapoints
2025-03-06 21:59:14,038 - INFO - training batch 201, loss: 0.063, 6432/28000 datapoints
2025-03-06 21:59:14,183 - INFO - training batch 251, loss: 0.219, 8032/28000 datapoints
2025-03-06 21:59:14,325 - INFO - training batch 301, loss: 0.350, 9632/28000 datapoints
2025-03-06 21:59:14,468 - INFO - training batch 351, loss: 0.171, 11232/28000 datapoints
2025-03-06 21:59:14,611 - INFO - training batch 401, loss: 0.217, 12832/28000 datapoints
2025-03-06 21:59:14,756 - INFO - training batch 451, loss: 0.326, 14432/28000 datapoints
2025-03-06 21:59:14,906 - INFO - training batch 501, loss: 0.113, 16032/28000 datapoints
2025-03-06 21:59:15,052 - INFO - training batch 551, loss: 0.143, 17632/28000 datapoints
2025-03-06 21:59:15,204 - INFO - training batch 601, loss: 0.085, 19232/28000 datapoints
2025-03-06 21:59:15,350 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:59:15,493 - INFO - training batch 701, loss: 0.085, 22432/28000 datapoints
2025-03-06 21:59:15,635 - INFO - training batch 751, loss: 0.103, 24032/28000 datapoints
2025-03-06 21:59:15,781 - INFO - training batch 801, loss: 0.051, 25632/28000 datapoints
2025-03-06 21:59:15,935 - INFO - training batch 851, loss: 0.132, 27232/28000 datapoints
2025-03-06 21:59:16,006 - INFO - validation batch 1, loss: 0.206, 32/6976 datapoints
2025-03-06 21:59:16,052 - INFO - validation batch 51, loss: 2.113, 1632/6976 datapoints
2025-03-06 21:59:16,100 - INFO - validation batch 101, loss: 0.625, 3232/6976 datapoints
2025-03-06 21:59:16,148 - INFO - validation batch 151, loss: 0.751, 4832/6976 datapoints
2025-03-06 21:59:16,196 - INFO - validation batch 201, loss: 0.486, 6432/6976 datapoints
2025-03-06 21:59:16,212 - INFO - Epoch 313/800 done.
2025-03-06 21:59:16,212 - INFO - Final validation performance:
Loss: 0.836, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:59:16,213 - INFO - Beginning epoch 314/800
2025-03-06 21:59:16,217 - INFO - training batch 1, loss: 0.162, 32/28000 datapoints
2025-03-06 21:59:16,362 - INFO - training batch 51, loss: 0.073, 1632/28000 datapoints
2025-03-06 21:59:16,506 - INFO - training batch 101, loss: 0.069, 3232/28000 datapoints
2025-03-06 21:59:16,651 - INFO - training batch 151, loss: 0.111, 4832/28000 datapoints
2025-03-06 21:59:16,803 - INFO - training batch 201, loss: 0.063, 6432/28000 datapoints
2025-03-06 21:59:16,992 - INFO - training batch 251, loss: 0.219, 8032/28000 datapoints
2025-03-06 21:59:17,143 - INFO - training batch 301, loss: 0.342, 9632/28000 datapoints
2025-03-06 21:59:17,295 - INFO - training batch 351, loss: 0.170, 11232/28000 datapoints
2025-03-06 21:59:17,442 - INFO - training batch 401, loss: 0.214, 12832/28000 datapoints
2025-03-06 21:59:17,589 - INFO - training batch 451, loss: 0.324, 14432/28000 datapoints
2025-03-06 21:59:17,741 - INFO - training batch 501, loss: 0.113, 16032/28000 datapoints
2025-03-06 21:59:17,892 - INFO - training batch 551, loss: 0.141, 17632/28000 datapoints
2025-03-06 21:59:18,042 - INFO - training batch 601, loss: 0.085, 19232/28000 datapoints
2025-03-06 21:59:18,193 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:59:18,341 - INFO - training batch 701, loss: 0.084, 22432/28000 datapoints
2025-03-06 21:59:18,489 - INFO - training batch 751, loss: 0.101, 24032/28000 datapoints
2025-03-06 21:59:18,637 - INFO - training batch 801, loss: 0.050, 25632/28000 datapoints
2025-03-06 21:59:18,798 - INFO - training batch 851, loss: 0.131, 27232/28000 datapoints
2025-03-06 21:59:18,876 - INFO - validation batch 1, loss: 0.204, 32/6976 datapoints
2025-03-06 21:59:18,923 - INFO - validation batch 51, loss: 2.121, 1632/6976 datapoints
2025-03-06 21:59:18,970 - INFO - validation batch 101, loss: 0.629, 3232/6976 datapoints
2025-03-06 21:59:19,016 - INFO - validation batch 151, loss: 0.752, 4832/6976 datapoints
2025-03-06 21:59:19,064 - INFO - validation batch 201, loss: 0.483, 6432/6976 datapoints
2025-03-06 21:59:19,080 - INFO - Epoch 314/800 done.
2025-03-06 21:59:19,080 - INFO - Final validation performance:
Loss: 0.838, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:59:19,081 - INFO - Beginning epoch 315/800
2025-03-06 21:59:19,085 - INFO - training batch 1, loss: 0.160, 32/28000 datapoints
2025-03-06 21:59:19,234 - INFO - training batch 51, loss: 0.073, 1632/28000 datapoints
2025-03-06 21:59:19,378 - INFO - training batch 101, loss: 0.070, 3232/28000 datapoints
2025-03-06 21:59:19,521 - INFO - training batch 151, loss: 0.110, 4832/28000 datapoints
2025-03-06 21:59:19,669 - INFO - training batch 201, loss: 0.062, 6432/28000 datapoints
2025-03-06 21:59:19,816 - INFO - training batch 251, loss: 0.217, 8032/28000 datapoints
2025-03-06 21:59:19,966 - INFO - training batch 301, loss: 0.339, 9632/28000 datapoints
2025-03-06 21:59:20,108 - INFO - training batch 351, loss: 0.170, 11232/28000 datapoints
2025-03-06 21:59:20,253 - INFO - training batch 401, loss: 0.209, 12832/28000 datapoints
2025-03-06 21:59:20,396 - INFO - training batch 451, loss: 0.323, 14432/28000 datapoints
2025-03-06 21:59:20,540 - INFO - training batch 501, loss: 0.113, 16032/28000 datapoints
2025-03-06 21:59:20,685 - INFO - training batch 551, loss: 0.140, 17632/28000 datapoints
2025-03-06 21:59:20,835 - INFO - training batch 601, loss: 0.084, 19232/28000 datapoints
2025-03-06 21:59:20,981 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:59:21,128 - INFO - training batch 701, loss: 0.083, 22432/28000 datapoints
2025-03-06 21:59:21,273 - INFO - training batch 751, loss: 0.101, 24032/28000 datapoints
2025-03-06 21:59:21,417 - INFO - training batch 801, loss: 0.050, 25632/28000 datapoints
2025-03-06 21:59:21,561 - INFO - training batch 851, loss: 0.130, 27232/28000 datapoints
2025-03-06 21:59:21,638 - INFO - validation batch 1, loss: 0.208, 32/6976 datapoints
2025-03-06 21:59:21,707 - INFO - validation batch 51, loss: 2.127, 1632/6976 datapoints
2025-03-06 21:59:21,761 - INFO - validation batch 101, loss: 0.633, 3232/6976 datapoints
2025-03-06 21:59:21,809 - INFO - validation batch 151, loss: 0.761, 4832/6976 datapoints
2025-03-06 21:59:21,857 - INFO - validation batch 201, loss: 0.485, 6432/6976 datapoints
2025-03-06 21:59:21,873 - INFO - Epoch 315/800 done.
2025-03-06 21:59:21,873 - INFO - Final validation performance:
Loss: 0.843, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:59:21,874 - INFO - Beginning epoch 316/800
2025-03-06 21:59:21,878 - INFO - training batch 1, loss: 0.158, 32/28000 datapoints
2025-03-06 21:59:22,025 - INFO - training batch 51, loss: 0.072, 1632/28000 datapoints
2025-03-06 21:59:22,168 - INFO - training batch 101, loss: 0.068, 3232/28000 datapoints
2025-03-06 21:59:22,316 - INFO - training batch 151, loss: 0.110, 4832/28000 datapoints
2025-03-06 21:59:22,462 - INFO - training batch 201, loss: 0.062, 6432/28000 datapoints
2025-03-06 21:59:22,605 - INFO - training batch 251, loss: 0.216, 8032/28000 datapoints
2025-03-06 21:59:22,750 - INFO - training batch 301, loss: 0.333, 9632/28000 datapoints
2025-03-06 21:59:22,902 - INFO - training batch 351, loss: 0.169, 11232/28000 datapoints
2025-03-06 21:59:23,047 - INFO - training batch 401, loss: 0.206, 12832/28000 datapoints
2025-03-06 21:59:23,191 - INFO - training batch 451, loss: 0.321, 14432/28000 datapoints
2025-03-06 21:59:23,338 - INFO - training batch 501, loss: 0.111, 16032/28000 datapoints
2025-03-06 21:59:23,483 - INFO - training batch 551, loss: 0.139, 17632/28000 datapoints
2025-03-06 21:59:23,626 - INFO - training batch 601, loss: 0.082, 19232/28000 datapoints
2025-03-06 21:59:23,773 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:59:23,922 - INFO - training batch 701, loss: 0.082, 22432/28000 datapoints
2025-03-06 21:59:24,070 - INFO - training batch 751, loss: 0.100, 24032/28000 datapoints
2025-03-06 21:59:24,217 - INFO - training batch 801, loss: 0.049, 25632/28000 datapoints
2025-03-06 21:59:24,364 - INFO - training batch 851, loss: 0.128, 27232/28000 datapoints
2025-03-06 21:59:24,435 - INFO - validation batch 1, loss: 0.211, 32/6976 datapoints
2025-03-06 21:59:24,482 - INFO - validation batch 51, loss: 2.135, 1632/6976 datapoints
2025-03-06 21:59:24,530 - INFO - validation batch 101, loss: 0.638, 3232/6976 datapoints
2025-03-06 21:59:24,576 - INFO - validation batch 151, loss: 0.765, 4832/6976 datapoints
2025-03-06 21:59:24,622 - INFO - validation batch 201, loss: 0.486, 6432/6976 datapoints
2025-03-06 21:59:24,638 - INFO - Epoch 316/800 done.
2025-03-06 21:59:24,638 - INFO - Final validation performance:
Loss: 0.847, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:59:24,638 - INFO - Beginning epoch 317/800
2025-03-06 21:59:24,643 - INFO - training batch 1, loss: 0.157, 32/28000 datapoints
2025-03-06 21:59:24,790 - INFO - training batch 51, loss: 0.072, 1632/28000 datapoints
2025-03-06 21:59:24,944 - INFO - training batch 101, loss: 0.069, 3232/28000 datapoints
2025-03-06 21:59:25,097 - INFO - training batch 151, loss: 0.109, 4832/28000 datapoints
2025-03-06 21:59:25,241 - INFO - training batch 201, loss: 0.062, 6432/28000 datapoints
2025-03-06 21:59:25,386 - INFO - training batch 251, loss: 0.216, 8032/28000 datapoints
2025-03-06 21:59:25,530 - INFO - training batch 301, loss: 0.329, 9632/28000 datapoints
2025-03-06 21:59:25,673 - INFO - training batch 351, loss: 0.169, 11232/28000 datapoints
2025-03-06 21:59:25,819 - INFO - training batch 401, loss: 0.201, 12832/28000 datapoints
2025-03-06 21:59:25,973 - INFO - training batch 451, loss: 0.320, 14432/28000 datapoints
2025-03-06 21:59:26,122 - INFO - training batch 501, loss: 0.111, 16032/28000 datapoints
2025-03-06 21:59:26,270 - INFO - training batch 551, loss: 0.137, 17632/28000 datapoints
2025-03-06 21:59:26,421 - INFO - training batch 601, loss: 0.084, 19232/28000 datapoints
2025-03-06 21:59:26,571 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:59:26,719 - INFO - training batch 701, loss: 0.080, 22432/28000 datapoints
2025-03-06 21:59:26,873 - INFO - training batch 751, loss: 0.100, 24032/28000 datapoints
2025-03-06 21:59:27,021 - INFO - training batch 801, loss: 0.049, 25632/28000 datapoints
2025-03-06 21:59:27,169 - INFO - training batch 851, loss: 0.127, 27232/28000 datapoints
2025-03-06 21:59:27,244 - INFO - validation batch 1, loss: 0.214, 32/6976 datapoints
2025-03-06 21:59:27,292 - INFO - validation batch 51, loss: 2.144, 1632/6976 datapoints
2025-03-06 21:59:27,342 - INFO - validation batch 101, loss: 0.640, 3232/6976 datapoints
2025-03-06 21:59:27,388 - INFO - validation batch 151, loss: 0.769, 4832/6976 datapoints
2025-03-06 21:59:27,435 - INFO - validation batch 201, loss: 0.486, 6432/6976 datapoints
2025-03-06 21:59:27,451 - INFO - Epoch 317/800 done.
2025-03-06 21:59:27,451 - INFO - Final validation performance:
Loss: 0.851, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:59:27,452 - INFO - Beginning epoch 318/800
2025-03-06 21:59:27,456 - INFO - training batch 1, loss: 0.156, 32/28000 datapoints
2025-03-06 21:59:27,600 - INFO - training batch 51, loss: 0.071, 1632/28000 datapoints
2025-03-06 21:59:27,745 - INFO - training batch 101, loss: 0.067, 3232/28000 datapoints
2025-03-06 21:59:27,899 - INFO - training batch 151, loss: 0.109, 4832/28000 datapoints
2025-03-06 21:59:28,043 - INFO - training batch 201, loss: 0.061, 6432/28000 datapoints
2025-03-06 21:59:28,186 - INFO - training batch 251, loss: 0.215, 8032/28000 datapoints
2025-03-06 21:59:28,330 - INFO - training batch 301, loss: 0.325, 9632/28000 datapoints
2025-03-06 21:59:28,474 - INFO - training batch 351, loss: 0.168, 11232/28000 datapoints
2025-03-06 21:59:28,615 - INFO - training batch 401, loss: 0.199, 12832/28000 datapoints
2025-03-06 21:59:28,759 - INFO - training batch 451, loss: 0.319, 14432/28000 datapoints
2025-03-06 21:59:28,911 - INFO - training batch 501, loss: 0.110, 16032/28000 datapoints
2025-03-06 21:59:29,055 - INFO - training batch 551, loss: 0.136, 17632/28000 datapoints
2025-03-06 21:59:29,201 - INFO - training batch 601, loss: 0.082, 19232/28000 datapoints
2025-03-06 21:59:29,348 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:59:29,493 - INFO - training batch 701, loss: 0.079, 22432/28000 datapoints
2025-03-06 21:59:29,637 - INFO - training batch 751, loss: 0.099, 24032/28000 datapoints
2025-03-06 21:59:29,782 - INFO - training batch 801, loss: 0.047, 25632/28000 datapoints
2025-03-06 21:59:29,929 - INFO - training batch 851, loss: 0.127, 27232/28000 datapoints
2025-03-06 21:59:30,002 - INFO - validation batch 1, loss: 0.212, 32/6976 datapoints
2025-03-06 21:59:30,048 - INFO - validation batch 51, loss: 2.151, 1632/6976 datapoints
2025-03-06 21:59:30,093 - INFO - validation batch 101, loss: 0.644, 3232/6976 datapoints
2025-03-06 21:59:30,138 - INFO - validation batch 151, loss: 0.770, 4832/6976 datapoints
2025-03-06 21:59:30,184 - INFO - validation batch 201, loss: 0.487, 6432/6976 datapoints
2025-03-06 21:59:30,199 - INFO - Epoch 318/800 done.
2025-03-06 21:59:30,200 - INFO - Final validation performance:
Loss: 0.853, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:59:30,200 - INFO - Beginning epoch 319/800
2025-03-06 21:59:30,204 - INFO - training batch 1, loss: 0.156, 32/28000 datapoints
2025-03-06 21:59:30,352 - INFO - training batch 51, loss: 0.072, 1632/28000 datapoints
2025-03-06 21:59:30,502 - INFO - training batch 101, loss: 0.067, 3232/28000 datapoints
2025-03-06 21:59:30,646 - INFO - training batch 151, loss: 0.109, 4832/28000 datapoints
2025-03-06 21:59:30,789 - INFO - training batch 201, loss: 0.061, 6432/28000 datapoints
2025-03-06 21:59:30,939 - INFO - training batch 251, loss: 0.214, 8032/28000 datapoints
2025-03-06 21:59:31,082 - INFO - training batch 301, loss: 0.320, 9632/28000 datapoints
2025-03-06 21:59:31,225 - INFO - training batch 351, loss: 0.167, 11232/28000 datapoints
2025-03-06 21:59:31,370 - INFO - training batch 401, loss: 0.194, 12832/28000 datapoints
2025-03-06 21:59:31,517 - INFO - training batch 451, loss: 0.317, 14432/28000 datapoints
2025-03-06 21:59:31,665 - INFO - training batch 501, loss: 0.109, 16032/28000 datapoints
2025-03-06 21:59:31,838 - INFO - training batch 551, loss: 0.136, 17632/28000 datapoints
2025-03-06 21:59:31,991 - INFO - training batch 601, loss: 0.081, 19232/28000 datapoints
2025-03-06 21:59:32,138 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:59:32,286 - INFO - training batch 701, loss: 0.079, 22432/28000 datapoints
2025-03-06 21:59:32,435 - INFO - training batch 751, loss: 0.100, 24032/28000 datapoints
2025-03-06 21:59:32,581 - INFO - training batch 801, loss: 0.047, 25632/28000 datapoints
2025-03-06 21:59:32,728 - INFO - training batch 851, loss: 0.125, 27232/28000 datapoints
2025-03-06 21:59:32,801 - INFO - validation batch 1, loss: 0.217, 32/6976 datapoints
2025-03-06 21:59:32,850 - INFO - validation batch 51, loss: 2.159, 1632/6976 datapoints
2025-03-06 21:59:32,900 - INFO - validation batch 101, loss: 0.647, 3232/6976 datapoints
2025-03-06 21:59:32,948 - INFO - validation batch 151, loss: 0.776, 4832/6976 datapoints
2025-03-06 21:59:32,995 - INFO - validation batch 201, loss: 0.487, 6432/6976 datapoints
2025-03-06 21:59:33,011 - INFO - Epoch 319/800 done.
2025-03-06 21:59:33,011 - INFO - Final validation performance:
Loss: 0.857, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:59:33,012 - INFO - Beginning epoch 320/800
2025-03-06 21:59:33,015 - INFO - training batch 1, loss: 0.152, 32/28000 datapoints
2025-03-06 21:59:33,166 - INFO - training batch 51, loss: 0.070, 1632/28000 datapoints
2025-03-06 21:59:33,309 - INFO - training batch 101, loss: 0.067, 3232/28000 datapoints
2025-03-06 21:59:33,455 - INFO - training batch 151, loss: 0.108, 4832/28000 datapoints
2025-03-06 21:59:33,598 - INFO - training batch 201, loss: 0.061, 6432/28000 datapoints
2025-03-06 21:59:33,741 - INFO - training batch 251, loss: 0.214, 8032/28000 datapoints
2025-03-06 21:59:33,886 - INFO - training batch 301, loss: 0.315, 9632/28000 datapoints
2025-03-06 21:59:34,038 - INFO - training batch 351, loss: 0.167, 11232/28000 datapoints
2025-03-06 21:59:34,182 - INFO - training batch 401, loss: 0.190, 12832/28000 datapoints
2025-03-06 21:59:34,330 - INFO - training batch 451, loss: 0.315, 14432/28000 datapoints
2025-03-06 21:59:34,476 - INFO - training batch 501, loss: 0.109, 16032/28000 datapoints
2025-03-06 21:59:34,622 - INFO - training batch 551, loss: 0.134, 17632/28000 datapoints
2025-03-06 21:59:34,766 - INFO - training batch 601, loss: 0.080, 19232/28000 datapoints
2025-03-06 21:59:34,917 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:59:35,066 - INFO - training batch 701, loss: 0.077, 22432/28000 datapoints
2025-03-06 21:59:35,216 - INFO - training batch 751, loss: 0.098, 24032/28000 datapoints
2025-03-06 21:59:35,361 - INFO - training batch 801, loss: 0.046, 25632/28000 datapoints
2025-03-06 21:59:35,506 - INFO - training batch 851, loss: 0.125, 27232/28000 datapoints
2025-03-06 21:59:35,577 - INFO - validation batch 1, loss: 0.217, 32/6976 datapoints
2025-03-06 21:59:35,622 - INFO - validation batch 51, loss: 2.168, 1632/6976 datapoints
2025-03-06 21:59:35,667 - INFO - validation batch 101, loss: 0.652, 3232/6976 datapoints
2025-03-06 21:59:35,713 - INFO - validation batch 151, loss: 0.778, 4832/6976 datapoints
2025-03-06 21:59:35,760 - INFO - validation batch 201, loss: 0.488, 6432/6976 datapoints
2025-03-06 21:59:35,776 - INFO - Epoch 320/800 done.
2025-03-06 21:59:35,776 - INFO - Final validation performance:
Loss: 0.861, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:59:35,777 - INFO - Beginning epoch 321/800
2025-03-06 21:59:35,781 - INFO - training batch 1, loss: 0.152, 32/28000 datapoints
2025-03-06 21:59:35,928 - INFO - training batch 51, loss: 0.070, 1632/28000 datapoints
2025-03-06 21:59:36,074 - INFO - training batch 101, loss: 0.066, 3232/28000 datapoints
2025-03-06 21:59:36,217 - INFO - training batch 151, loss: 0.107, 4832/28000 datapoints
2025-03-06 21:59:36,382 - INFO - training batch 201, loss: 0.061, 6432/28000 datapoints
2025-03-06 21:59:36,530 - INFO - training batch 251, loss: 0.212, 8032/28000 datapoints
2025-03-06 21:59:36,672 - INFO - training batch 301, loss: 0.309, 9632/28000 datapoints
2025-03-06 21:59:36,818 - INFO - training batch 351, loss: 0.166, 11232/28000 datapoints
2025-03-06 21:59:36,975 - INFO - training batch 401, loss: 0.188, 12832/28000 datapoints
2025-03-06 21:59:37,121 - INFO - training batch 451, loss: 0.314, 14432/28000 datapoints
2025-03-06 21:59:37,275 - INFO - training batch 501, loss: 0.107, 16032/28000 datapoints
2025-03-06 21:59:37,421 - INFO - training batch 551, loss: 0.134, 17632/28000 datapoints
2025-03-06 21:59:37,570 - INFO - training batch 601, loss: 0.081, 19232/28000 datapoints
2025-03-06 21:59:37,713 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:59:37,869 - INFO - training batch 701, loss: 0.076, 22432/28000 datapoints
2025-03-06 21:59:38,014 - INFO - training batch 751, loss: 0.098, 24032/28000 datapoints
2025-03-06 21:59:38,160 - INFO - training batch 801, loss: 0.046, 25632/28000 datapoints
2025-03-06 21:59:38,305 - INFO - training batch 851, loss: 0.124, 27232/28000 datapoints
2025-03-06 21:59:38,376 - INFO - validation batch 1, loss: 0.221, 32/6976 datapoints
2025-03-06 21:59:38,425 - INFO - validation batch 51, loss: 2.175, 1632/6976 datapoints
2025-03-06 21:59:38,476 - INFO - validation batch 101, loss: 0.656, 3232/6976 datapoints
2025-03-06 21:59:38,523 - INFO - validation batch 151, loss: 0.784, 4832/6976 datapoints
2025-03-06 21:59:38,570 - INFO - validation batch 201, loss: 0.488, 6432/6976 datapoints
2025-03-06 21:59:38,586 - INFO - Epoch 321/800 done.
2025-03-06 21:59:38,586 - INFO - Final validation performance:
Loss: 0.865, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:59:38,586 - INFO - Beginning epoch 322/800
2025-03-06 21:59:38,590 - INFO - training batch 1, loss: 0.149, 32/28000 datapoints
2025-03-06 21:59:38,736 - INFO - training batch 51, loss: 0.070, 1632/28000 datapoints
2025-03-06 21:59:38,881 - INFO - training batch 101, loss: 0.066, 3232/28000 datapoints
2025-03-06 21:59:39,033 - INFO - training batch 151, loss: 0.107, 4832/28000 datapoints
2025-03-06 21:59:39,186 - INFO - training batch 201, loss: 0.060, 6432/28000 datapoints
2025-03-06 21:59:39,337 - INFO - training batch 251, loss: 0.212, 8032/28000 datapoints
2025-03-06 21:59:39,484 - INFO - training batch 301, loss: 0.305, 9632/28000 datapoints
2025-03-06 21:59:39,630 - INFO - training batch 351, loss: 0.166, 11232/28000 datapoints
2025-03-06 21:59:39,773 - INFO - training batch 401, loss: 0.184, 12832/28000 datapoints
2025-03-06 21:59:39,920 - INFO - training batch 451, loss: 0.312, 14432/28000 datapoints
2025-03-06 21:59:40,070 - INFO - training batch 501, loss: 0.107, 16032/28000 datapoints
2025-03-06 21:59:40,216 - INFO - training batch 551, loss: 0.132, 17632/28000 datapoints
2025-03-06 21:59:40,361 - INFO - training batch 601, loss: 0.075, 19232/28000 datapoints
2025-03-06 21:59:40,506 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 21:59:40,650 - INFO - training batch 701, loss: 0.076, 22432/28000 datapoints
2025-03-06 21:59:40,793 - INFO - training batch 751, loss: 0.097, 24032/28000 datapoints
2025-03-06 21:59:40,944 - INFO - training batch 801, loss: 0.044, 25632/28000 datapoints
2025-03-06 21:59:41,090 - INFO - training batch 851, loss: 0.123, 27232/28000 datapoints
2025-03-06 21:59:41,161 - INFO - validation batch 1, loss: 0.224, 32/6976 datapoints
2025-03-06 21:59:41,208 - INFO - validation batch 51, loss: 2.179, 1632/6976 datapoints
2025-03-06 21:59:41,254 - INFO - validation batch 101, loss: 0.661, 3232/6976 datapoints
2025-03-06 21:59:41,299 - INFO - validation batch 151, loss: 0.794, 4832/6976 datapoints
2025-03-06 21:59:41,345 - INFO - validation batch 201, loss: 0.490, 6432/6976 datapoints
2025-03-06 21:59:41,361 - INFO - Epoch 322/800 done.
2025-03-06 21:59:41,361 - INFO - Final validation performance:
Loss: 0.869, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:59:41,362 - INFO - Beginning epoch 323/800
2025-03-06 21:59:41,366 - INFO - training batch 1, loss: 0.149, 32/28000 datapoints
2025-03-06 21:59:41,511 - INFO - training batch 51, loss: 0.070, 1632/28000 datapoints
2025-03-06 21:59:41,656 - INFO - training batch 101, loss: 0.065, 3232/28000 datapoints
2025-03-06 21:59:41,801 - INFO - training batch 151, loss: 0.107, 4832/28000 datapoints
2025-03-06 21:59:41,978 - INFO - training batch 201, loss: 0.059, 6432/28000 datapoints
2025-03-06 21:59:42,124 - INFO - training batch 251, loss: 0.211, 8032/28000 datapoints
2025-03-06 21:59:42,267 - INFO - training batch 301, loss: 0.299, 9632/28000 datapoints
2025-03-06 21:59:42,423 - INFO - training batch 351, loss: 0.164, 11232/28000 datapoints
2025-03-06 21:59:42,567 - INFO - training batch 401, loss: 0.182, 12832/28000 datapoints
2025-03-06 21:59:42,709 - INFO - training batch 451, loss: 0.309, 14432/28000 datapoints
2025-03-06 21:59:42,865 - INFO - training batch 501, loss: 0.106, 16032/28000 datapoints
2025-03-06 21:59:43,018 - INFO - training batch 551, loss: 0.131, 17632/28000 datapoints
2025-03-06 21:59:43,170 - INFO - training batch 601, loss: 0.080, 19232/28000 datapoints
2025-03-06 21:59:43,321 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 21:59:43,464 - INFO - training batch 701, loss: 0.074, 22432/28000 datapoints
2025-03-06 21:59:43,608 - INFO - training batch 751, loss: 0.096, 24032/28000 datapoints
2025-03-06 21:59:43,753 - INFO - training batch 801, loss: 0.043, 25632/28000 datapoints
2025-03-06 21:59:43,904 - INFO - training batch 851, loss: 0.122, 27232/28000 datapoints
2025-03-06 21:59:43,978 - INFO - validation batch 1, loss: 0.222, 32/6976 datapoints
2025-03-06 21:59:44,030 - INFO - validation batch 51, loss: 2.188, 1632/6976 datapoints
2025-03-06 21:59:44,078 - INFO - validation batch 101, loss: 0.664, 3232/6976 datapoints
2025-03-06 21:59:44,125 - INFO - validation batch 151, loss: 0.796, 4832/6976 datapoints
2025-03-06 21:59:44,173 - INFO - validation batch 201, loss: 0.489, 6432/6976 datapoints
2025-03-06 21:59:44,189 - INFO - Epoch 323/800 done.
2025-03-06 21:59:44,189 - INFO - Final validation performance:
Loss: 0.872, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:59:44,189 - INFO - Beginning epoch 324/800
2025-03-06 21:59:44,194 - INFO - training batch 1, loss: 0.148, 32/28000 datapoints
2025-03-06 21:59:44,347 - INFO - training batch 51, loss: 0.069, 1632/28000 datapoints
2025-03-06 21:59:44,495 - INFO - training batch 101, loss: 0.065, 3232/28000 datapoints
2025-03-06 21:59:44,645 - INFO - training batch 151, loss: 0.107, 4832/28000 datapoints
2025-03-06 21:59:44,795 - INFO - training batch 201, loss: 0.059, 6432/28000 datapoints
2025-03-06 21:59:44,950 - INFO - training batch 251, loss: 0.209, 8032/28000 datapoints
2025-03-06 21:59:45,103 - INFO - training batch 301, loss: 0.295, 9632/28000 datapoints
2025-03-06 21:59:45,253 - INFO - training batch 351, loss: 0.164, 11232/28000 datapoints
2025-03-06 21:59:45,409 - INFO - training batch 401, loss: 0.178, 12832/28000 datapoints
2025-03-06 21:59:45,556 - INFO - training batch 451, loss: 0.308, 14432/28000 datapoints
2025-03-06 21:59:45,704 - INFO - training batch 501, loss: 0.106, 16032/28000 datapoints
2025-03-06 21:59:45,858 - INFO - training batch 551, loss: 0.130, 17632/28000 datapoints
2025-03-06 21:59:46,013 - INFO - training batch 601, loss: 0.078, 19232/28000 datapoints
2025-03-06 21:59:46,162 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 21:59:46,310 - INFO - training batch 701, loss: 0.073, 22432/28000 datapoints
2025-03-06 21:59:46,458 - INFO - training batch 751, loss: 0.097, 24032/28000 datapoints
2025-03-06 21:59:46,611 - INFO - training batch 801, loss: 0.043, 25632/28000 datapoints
2025-03-06 21:59:46,764 - INFO - training batch 851, loss: 0.120, 27232/28000 datapoints
2025-03-06 21:59:46,837 - INFO - validation batch 1, loss: 0.230, 32/6976 datapoints
2025-03-06 21:59:46,888 - INFO - validation batch 51, loss: 2.197, 1632/6976 datapoints
2025-03-06 21:59:46,939 - INFO - validation batch 101, loss: 0.667, 3232/6976 datapoints
2025-03-06 21:59:46,986 - INFO - validation batch 151, loss: 0.803, 4832/6976 datapoints
2025-03-06 21:59:47,033 - INFO - validation batch 201, loss: 0.492, 6432/6976 datapoints
2025-03-06 21:59:47,049 - INFO - Epoch 324/800 done.
2025-03-06 21:59:47,049 - INFO - Final validation performance:
Loss: 0.878, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:59:47,049 - INFO - Beginning epoch 325/800
2025-03-06 21:59:47,053 - INFO - training batch 1, loss: 0.145, 32/28000 datapoints
2025-03-06 21:59:47,200 - INFO - training batch 51, loss: 0.069, 1632/28000 datapoints
2025-03-06 21:59:47,348 - INFO - training batch 101, loss: 0.064, 3232/28000 datapoints
2025-03-06 21:59:47,494 - INFO - training batch 151, loss: 0.107, 4832/28000 datapoints
2025-03-06 21:59:47,641 - INFO - training batch 201, loss: 0.059, 6432/28000 datapoints
2025-03-06 21:59:47,787 - INFO - training batch 251, loss: 0.209, 8032/28000 datapoints
2025-03-06 21:59:47,934 - INFO - training batch 301, loss: 0.289, 9632/28000 datapoints
2025-03-06 21:59:48,079 - INFO - training batch 351, loss: 0.163, 11232/28000 datapoints
2025-03-06 21:59:48,225 - INFO - training batch 401, loss: 0.175, 12832/28000 datapoints
2025-03-06 21:59:48,369 - INFO - training batch 451, loss: 0.306, 14432/28000 datapoints
2025-03-06 21:59:48,528 - INFO - training batch 501, loss: 0.105, 16032/28000 datapoints
2025-03-06 21:59:48,673 - INFO - training batch 551, loss: 0.129, 17632/28000 datapoints
2025-03-06 21:59:48,817 - INFO - training batch 601, loss: 0.075, 19232/28000 datapoints
2025-03-06 21:59:48,979 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 21:59:49,128 - INFO - training batch 701, loss: 0.073, 22432/28000 datapoints
2025-03-06 21:59:49,277 - INFO - training batch 751, loss: 0.095, 24032/28000 datapoints
2025-03-06 21:59:49,428 - INFO - training batch 801, loss: 0.042, 25632/28000 datapoints
2025-03-06 21:59:49,577 - INFO - training batch 851, loss: 0.120, 27232/28000 datapoints
2025-03-06 21:59:49,648 - INFO - validation batch 1, loss: 0.229, 32/6976 datapoints
2025-03-06 21:59:49,695 - INFO - validation batch 51, loss: 2.205, 1632/6976 datapoints
2025-03-06 21:59:49,743 - INFO - validation batch 101, loss: 0.671, 3232/6976 datapoints
2025-03-06 21:59:49,789 - INFO - validation batch 151, loss: 0.806, 4832/6976 datapoints
2025-03-06 21:59:49,836 - INFO - validation batch 201, loss: 0.490, 6432/6976 datapoints
2025-03-06 21:59:49,855 - INFO - Epoch 325/800 done.
2025-03-06 21:59:49,855 - INFO - Final validation performance:
Loss: 0.880, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:59:49,856 - INFO - Beginning epoch 326/800
2025-03-06 21:59:49,860 - INFO - training batch 1, loss: 0.145, 32/28000 datapoints
2025-03-06 21:59:50,006 - INFO - training batch 51, loss: 0.069, 1632/28000 datapoints
2025-03-06 21:59:50,154 - INFO - training batch 101, loss: 0.064, 3232/28000 datapoints
2025-03-06 21:59:50,300 - INFO - training batch 151, loss: 0.106, 4832/28000 datapoints
2025-03-06 21:59:50,446 - INFO - training batch 201, loss: 0.059, 6432/28000 datapoints
2025-03-06 21:59:50,592 - INFO - training batch 251, loss: 0.208, 8032/28000 datapoints
2025-03-06 21:59:50,737 - INFO - training batch 301, loss: 0.285, 9632/28000 datapoints
2025-03-06 21:59:50,885 - INFO - training batch 351, loss: 0.162, 11232/28000 datapoints
2025-03-06 21:59:51,032 - INFO - training batch 401, loss: 0.171, 12832/28000 datapoints
2025-03-06 21:59:51,178 - INFO - training batch 451, loss: 0.305, 14432/28000 datapoints
2025-03-06 21:59:51,322 - INFO - training batch 501, loss: 0.104, 16032/28000 datapoints
2025-03-06 21:59:51,467 - INFO - training batch 551, loss: 0.128, 17632/28000 datapoints
2025-03-06 21:59:51,613 - INFO - training batch 601, loss: 0.079, 19232/28000 datapoints
2025-03-06 21:59:51,760 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 21:59:51,908 - INFO - training batch 701, loss: 0.072, 22432/28000 datapoints
2025-03-06 21:59:52,077 - INFO - training batch 751, loss: 0.095, 24032/28000 datapoints
2025-03-06 21:59:52,223 - INFO - training batch 801, loss: 0.041, 25632/28000 datapoints
2025-03-06 21:59:52,368 - INFO - training batch 851, loss: 0.119, 27232/28000 datapoints
2025-03-06 21:59:52,440 - INFO - validation batch 1, loss: 0.231, 32/6976 datapoints
2025-03-06 21:59:52,486 - INFO - validation batch 51, loss: 2.211, 1632/6976 datapoints
2025-03-06 21:59:52,533 - INFO - validation batch 101, loss: 0.676, 3232/6976 datapoints
2025-03-06 21:59:52,579 - INFO - validation batch 151, loss: 0.812, 4832/6976 datapoints
2025-03-06 21:59:52,624 - INFO - validation batch 201, loss: 0.492, 6432/6976 datapoints
2025-03-06 21:59:52,641 - INFO - Epoch 326/800 done.
2025-03-06 21:59:52,641 - INFO - Final validation performance:
Loss: 0.884, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:59:52,641 - INFO - Beginning epoch 327/800
2025-03-06 21:59:52,645 - INFO - training batch 1, loss: 0.144, 32/28000 datapoints
2025-03-06 21:59:52,794 - INFO - training batch 51, loss: 0.068, 1632/28000 datapoints
2025-03-06 21:59:52,940 - INFO - training batch 101, loss: 0.063, 3232/28000 datapoints
2025-03-06 21:59:53,088 - INFO - training batch 151, loss: 0.106, 4832/28000 datapoints
2025-03-06 21:59:53,232 - INFO - training batch 201, loss: 0.058, 6432/28000 datapoints
2025-03-06 21:59:53,378 - INFO - training batch 251, loss: 0.206, 8032/28000 datapoints
2025-03-06 21:59:53,524 - INFO - training batch 301, loss: 0.278, 9632/28000 datapoints
2025-03-06 21:59:53,667 - INFO - training batch 351, loss: 0.162, 11232/28000 datapoints
2025-03-06 21:59:53,811 - INFO - training batch 401, loss: 0.170, 12832/28000 datapoints
2025-03-06 21:59:53,956 - INFO - training batch 451, loss: 0.301, 14432/28000 datapoints
2025-03-06 21:59:54,105 - INFO - training batch 501, loss: 0.103, 16032/28000 datapoints
2025-03-06 21:59:54,250 - INFO - training batch 551, loss: 0.128, 17632/28000 datapoints
2025-03-06 21:59:54,404 - INFO - training batch 601, loss: 0.076, 19232/28000 datapoints
2025-03-06 21:59:54,555 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 21:59:54,711 - INFO - training batch 701, loss: 0.071, 22432/28000 datapoints
2025-03-06 21:59:54,858 - INFO - training batch 751, loss: 0.095, 24032/28000 datapoints
2025-03-06 21:59:55,011 - INFO - training batch 801, loss: 0.041, 25632/28000 datapoints
2025-03-06 21:59:55,165 - INFO - training batch 851, loss: 0.118, 27232/28000 datapoints
2025-03-06 21:59:55,239 - INFO - validation batch 1, loss: 0.235, 32/6976 datapoints
2025-03-06 21:59:55,286 - INFO - validation batch 51, loss: 2.224, 1632/6976 datapoints
2025-03-06 21:59:55,334 - INFO - validation batch 101, loss: 0.678, 3232/6976 datapoints
2025-03-06 21:59:55,386 - INFO - validation batch 151, loss: 0.815, 4832/6976 datapoints
2025-03-06 21:59:55,450 - INFO - validation batch 201, loss: 0.492, 6432/6976 datapoints
2025-03-06 21:59:55,465 - INFO - Epoch 327/800 done.
2025-03-06 21:59:55,466 - INFO - Final validation performance:
Loss: 0.889, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 21:59:55,466 - INFO - Beginning epoch 328/800
2025-03-06 21:59:55,470 - INFO - training batch 1, loss: 0.142, 32/28000 datapoints
2025-03-06 21:59:55,619 - INFO - training batch 51, loss: 0.068, 1632/28000 datapoints
2025-03-06 21:59:55,770 - INFO - training batch 101, loss: 0.063, 3232/28000 datapoints
2025-03-06 21:59:55,923 - INFO - training batch 151, loss: 0.106, 4832/28000 datapoints
2025-03-06 21:59:56,073 - INFO - training batch 201, loss: 0.058, 6432/28000 datapoints
2025-03-06 21:59:56,220 - INFO - training batch 251, loss: 0.206, 8032/28000 datapoints
2025-03-06 21:59:56,371 - INFO - training batch 301, loss: 0.274, 9632/28000 datapoints
2025-03-06 21:59:56,517 - INFO - training batch 351, loss: 0.161, 11232/28000 datapoints
2025-03-06 21:59:56,664 - INFO - training batch 401, loss: 0.166, 12832/28000 datapoints
2025-03-06 21:59:56,815 - INFO - training batch 451, loss: 0.301, 14432/28000 datapoints
2025-03-06 21:59:56,963 - INFO - training batch 501, loss: 0.103, 16032/28000 datapoints
2025-03-06 21:59:57,114 - INFO - training batch 551, loss: 0.126, 17632/28000 datapoints
2025-03-06 21:59:57,261 - INFO - training batch 601, loss: 0.077, 19232/28000 datapoints
2025-03-06 21:59:57,405 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 21:59:57,548 - INFO - training batch 701, loss: 0.070, 22432/28000 datapoints
2025-03-06 21:59:57,691 - INFO - training batch 751, loss: 0.093, 24032/28000 datapoints
2025-03-06 21:59:57,836 - INFO - training batch 801, loss: 0.040, 25632/28000 datapoints
2025-03-06 21:59:57,983 - INFO - training batch 851, loss: 0.116, 27232/28000 datapoints
2025-03-06 21:59:58,054 - INFO - validation batch 1, loss: 0.240, 32/6976 datapoints
2025-03-06 21:59:58,100 - INFO - validation batch 51, loss: 2.233, 1632/6976 datapoints
2025-03-06 21:59:58,147 - INFO - validation batch 101, loss: 0.682, 3232/6976 datapoints
2025-03-06 21:59:58,193 - INFO - validation batch 151, loss: 0.820, 4832/6976 datapoints
2025-03-06 21:59:58,241 - INFO - validation batch 201, loss: 0.493, 6432/6976 datapoints
2025-03-06 21:59:58,257 - INFO - Epoch 328/800 done.
2025-03-06 21:59:58,257 - INFO - Final validation performance:
Loss: 0.893, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 21:59:58,257 - INFO - Beginning epoch 329/800
2025-03-06 21:59:58,261 - INFO - training batch 1, loss: 0.140, 32/28000 datapoints
2025-03-06 21:59:58,410 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-06 21:59:58,555 - INFO - training batch 101, loss: 0.062, 3232/28000 datapoints
2025-03-06 21:59:58,701 - INFO - training batch 151, loss: 0.106, 4832/28000 datapoints
2025-03-06 21:59:58,849 - INFO - training batch 201, loss: 0.057, 6432/28000 datapoints
2025-03-06 21:59:58,997 - INFO - training batch 251, loss: 0.205, 8032/28000 datapoints
2025-03-06 21:59:59,142 - INFO - training batch 301, loss: 0.269, 9632/28000 datapoints
2025-03-06 21:59:59,285 - INFO - training batch 351, loss: 0.160, 11232/28000 datapoints
2025-03-06 21:59:59,428 - INFO - training batch 401, loss: 0.163, 12832/28000 datapoints
2025-03-06 21:59:59,572 - INFO - training batch 451, loss: 0.298, 14432/28000 datapoints
2025-03-06 21:59:59,719 - INFO - training batch 501, loss: 0.101, 16032/28000 datapoints
2025-03-06 21:59:59,868 - INFO - training batch 551, loss: 0.125, 17632/28000 datapoints
2025-03-06 22:00:00,017 - INFO - training batch 601, loss: 0.076, 19232/28000 datapoints
2025-03-06 22:00:00,165 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 22:00:00,312 - INFO - training batch 701, loss: 0.070, 22432/28000 datapoints
2025-03-06 22:00:00,460 - INFO - training batch 751, loss: 0.093, 24032/28000 datapoints
2025-03-06 22:00:00,603 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-06 22:00:00,752 - INFO - training batch 851, loss: 0.116, 27232/28000 datapoints
2025-03-06 22:00:00,832 - INFO - validation batch 1, loss: 0.239, 32/6976 datapoints
2025-03-06 22:00:00,880 - INFO - validation batch 51, loss: 2.237, 1632/6976 datapoints
2025-03-06 22:00:00,926 - INFO - validation batch 101, loss: 0.687, 3232/6976 datapoints
2025-03-06 22:00:00,972 - INFO - validation batch 151, loss: 0.828, 4832/6976 datapoints
2025-03-06 22:00:01,022 - INFO - validation batch 201, loss: 0.493, 6432/6976 datapoints
2025-03-06 22:00:01,038 - INFO - Epoch 329/800 done.
2025-03-06 22:00:01,038 - INFO - Final validation performance:
Loss: 0.897, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:01,038 - INFO - Beginning epoch 330/800
2025-03-06 22:00:01,043 - INFO - training batch 1, loss: 0.140, 32/28000 datapoints
2025-03-06 22:00:01,187 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-06 22:00:01,337 - INFO - training batch 101, loss: 0.062, 3232/28000 datapoints
2025-03-06 22:00:01,481 - INFO - training batch 151, loss: 0.105, 4832/28000 datapoints
2025-03-06 22:00:01,624 - INFO - training batch 201, loss: 0.058, 6432/28000 datapoints
2025-03-06 22:00:01,767 - INFO - training batch 251, loss: 0.204, 8032/28000 datapoints
2025-03-06 22:00:01,917 - INFO - training batch 301, loss: 0.264, 9632/28000 datapoints
2025-03-06 22:00:02,077 - INFO - training batch 351, loss: 0.160, 11232/28000 datapoints
2025-03-06 22:00:02,231 - INFO - training batch 401, loss: 0.160, 12832/28000 datapoints
2025-03-06 22:00:02,379 - INFO - training batch 451, loss: 0.297, 14432/28000 datapoints
2025-03-06 22:00:02,523 - INFO - training batch 501, loss: 0.101, 16032/28000 datapoints
2025-03-06 22:00:02,668 - INFO - training batch 551, loss: 0.124, 17632/28000 datapoints
2025-03-06 22:00:02,812 - INFO - training batch 601, loss: 0.075, 19232/28000 datapoints
2025-03-06 22:00:02,959 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 22:00:03,108 - INFO - training batch 701, loss: 0.069, 22432/28000 datapoints
2025-03-06 22:00:03,251 - INFO - training batch 751, loss: 0.092, 24032/28000 datapoints
2025-03-06 22:00:03,396 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-06 22:00:03,542 - INFO - training batch 851, loss: 0.116, 27232/28000 datapoints
2025-03-06 22:00:03,614 - INFO - validation batch 1, loss: 0.243, 32/6976 datapoints
2025-03-06 22:00:03,661 - INFO - validation batch 51, loss: 2.251, 1632/6976 datapoints
2025-03-06 22:00:03,707 - INFO - validation batch 101, loss: 0.690, 3232/6976 datapoints
2025-03-06 22:00:03,752 - INFO - validation batch 151, loss: 0.829, 4832/6976 datapoints
2025-03-06 22:00:03,799 - INFO - validation batch 201, loss: 0.494, 6432/6976 datapoints
2025-03-06 22:00:03,815 - INFO - Epoch 330/800 done.
2025-03-06 22:00:03,815 - INFO - Final validation performance:
Loss: 0.901, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:03,815 - INFO - Beginning epoch 331/800
2025-03-06 22:00:03,821 - INFO - training batch 1, loss: 0.139, 32/28000 datapoints
2025-03-06 22:00:03,970 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-06 22:00:04,119 - INFO - training batch 101, loss: 0.061, 3232/28000 datapoints
2025-03-06 22:00:04,261 - INFO - training batch 151, loss: 0.104, 4832/28000 datapoints
2025-03-06 22:00:04,405 - INFO - training batch 201, loss: 0.057, 6432/28000 datapoints
2025-03-06 22:00:04,548 - INFO - training batch 251, loss: 0.203, 8032/28000 datapoints
2025-03-06 22:00:04,692 - INFO - training batch 301, loss: 0.259, 9632/28000 datapoints
2025-03-06 22:00:04,838 - INFO - training batch 351, loss: 0.160, 11232/28000 datapoints
2025-03-06 22:00:04,985 - INFO - training batch 401, loss: 0.157, 12832/28000 datapoints
2025-03-06 22:00:05,142 - INFO - training batch 451, loss: 0.294, 14432/28000 datapoints
2025-03-06 22:00:05,285 - INFO - training batch 501, loss: 0.101, 16032/28000 datapoints
2025-03-06 22:00:05,431 - INFO - training batch 551, loss: 0.122, 17632/28000 datapoints
2025-03-06 22:00:05,574 - INFO - training batch 601, loss: 0.071, 19232/28000 datapoints
2025-03-06 22:00:05,718 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 22:00:05,865 - INFO - training batch 701, loss: 0.068, 22432/28000 datapoints
2025-03-06 22:00:06,015 - INFO - training batch 751, loss: 0.092, 24032/28000 datapoints
2025-03-06 22:00:06,164 - INFO - training batch 801, loss: 0.038, 25632/28000 datapoints
2025-03-06 22:00:06,312 - INFO - training batch 851, loss: 0.114, 27232/28000 datapoints
2025-03-06 22:00:06,387 - INFO - validation batch 1, loss: 0.245, 32/6976 datapoints
2025-03-06 22:00:06,437 - INFO - validation batch 51, loss: 2.257, 1632/6976 datapoints
2025-03-06 22:00:06,484 - INFO - validation batch 101, loss: 0.694, 3232/6976 datapoints
2025-03-06 22:00:06,531 - INFO - validation batch 151, loss: 0.835, 4832/6976 datapoints
2025-03-06 22:00:06,578 - INFO - validation batch 201, loss: 0.494, 6432/6976 datapoints
2025-03-06 22:00:06,594 - INFO - Epoch 331/800 done.
2025-03-06 22:00:06,594 - INFO - Final validation performance:
Loss: 0.905, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:06,595 - INFO - Beginning epoch 332/800
2025-03-06 22:00:06,599 - INFO - training batch 1, loss: 0.138, 32/28000 datapoints
2025-03-06 22:00:06,751 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 22:00:06,911 - INFO - training batch 101, loss: 0.060, 3232/28000 datapoints
2025-03-06 22:00:07,062 - INFO - training batch 151, loss: 0.104, 4832/28000 datapoints
2025-03-06 22:00:07,209 - INFO - training batch 201, loss: 0.057, 6432/28000 datapoints
2025-03-06 22:00:07,363 - INFO - training batch 251, loss: 0.202, 8032/28000 datapoints
2025-03-06 22:00:07,515 - INFO - training batch 301, loss: 0.253, 9632/28000 datapoints
2025-03-06 22:00:07,662 - INFO - training batch 351, loss: 0.159, 11232/28000 datapoints
2025-03-06 22:00:07,812 - INFO - training batch 401, loss: 0.156, 12832/28000 datapoints
2025-03-06 22:00:07,964 - INFO - training batch 451, loss: 0.292, 14432/28000 datapoints
2025-03-06 22:00:08,115 - INFO - training batch 501, loss: 0.099, 16032/28000 datapoints
2025-03-06 22:00:08,264 - INFO - training batch 551, loss: 0.122, 17632/28000 datapoints
2025-03-06 22:00:08,410 - INFO - training batch 601, loss: 0.075, 19232/28000 datapoints
2025-03-06 22:00:08,554 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 22:00:08,700 - INFO - training batch 701, loss: 0.067, 22432/28000 datapoints
2025-03-06 22:00:08,843 - INFO - training batch 751, loss: 0.091, 24032/28000 datapoints
2025-03-06 22:00:08,991 - INFO - training batch 801, loss: 0.038, 25632/28000 datapoints
2025-03-06 22:00:09,140 - INFO - training batch 851, loss: 0.114, 27232/28000 datapoints
2025-03-06 22:00:09,211 - INFO - validation batch 1, loss: 0.249, 32/6976 datapoints
2025-03-06 22:00:09,269 - INFO - validation batch 51, loss: 2.270, 1632/6976 datapoints
2025-03-06 22:00:09,318 - INFO - validation batch 101, loss: 0.697, 3232/6976 datapoints
2025-03-06 22:00:09,364 - INFO - validation batch 151, loss: 0.841, 4832/6976 datapoints
2025-03-06 22:00:09,413 - INFO - validation batch 201, loss: 0.495, 6432/6976 datapoints
2025-03-06 22:00:09,430 - INFO - Epoch 332/800 done.
2025-03-06 22:00:09,430 - INFO - Final validation performance:
Loss: 0.910, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:09,430 - INFO - Beginning epoch 333/800
2025-03-06 22:00:09,434 - INFO - training batch 1, loss: 0.135, 32/28000 datapoints
2025-03-06 22:00:09,581 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 22:00:09,727 - INFO - training batch 101, loss: 0.060, 3232/28000 datapoints
2025-03-06 22:00:09,876 - INFO - training batch 151, loss: 0.103, 4832/28000 datapoints
2025-03-06 22:00:10,022 - INFO - training batch 201, loss: 0.056, 6432/28000 datapoints
2025-03-06 22:00:10,165 - INFO - training batch 251, loss: 0.202, 8032/28000 datapoints
2025-03-06 22:00:10,308 - INFO - training batch 301, loss: 0.249, 9632/28000 datapoints
2025-03-06 22:00:10,452 - INFO - training batch 351, loss: 0.158, 11232/28000 datapoints
2025-03-06 22:00:10,595 - INFO - training batch 401, loss: 0.152, 12832/28000 datapoints
2025-03-06 22:00:10,740 - INFO - training batch 451, loss: 0.291, 14432/28000 datapoints
2025-03-06 22:00:10,886 - INFO - training batch 501, loss: 0.100, 16032/28000 datapoints
2025-03-06 22:00:11,038 - INFO - training batch 551, loss: 0.120, 17632/28000 datapoints
2025-03-06 22:00:11,184 - INFO - training batch 601, loss: 0.075, 19232/28000 datapoints
2025-03-06 22:00:11,327 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 22:00:11,472 - INFO - training batch 701, loss: 0.067, 22432/28000 datapoints
2025-03-06 22:00:11,615 - INFO - training batch 751, loss: 0.091, 24032/28000 datapoints
2025-03-06 22:00:11,762 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-06 22:00:11,909 - INFO - training batch 851, loss: 0.113, 27232/28000 datapoints
2025-03-06 22:00:11,982 - INFO - validation batch 1, loss: 0.252, 32/6976 datapoints
2025-03-06 22:00:12,028 - INFO - validation batch 51, loss: 2.279, 1632/6976 datapoints
2025-03-06 22:00:12,076 - INFO - validation batch 101, loss: 0.701, 3232/6976 datapoints
2025-03-06 22:00:12,132 - INFO - validation batch 151, loss: 0.841, 4832/6976 datapoints
2025-03-06 22:00:12,196 - INFO - validation batch 201, loss: 0.496, 6432/6976 datapoints
2025-03-06 22:00:12,211 - INFO - Epoch 333/800 done.
2025-03-06 22:00:12,212 - INFO - Final validation performance:
Loss: 0.914, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:12,212 - INFO - Beginning epoch 334/800
2025-03-06 22:00:12,216 - INFO - training batch 1, loss: 0.134, 32/28000 datapoints
2025-03-06 22:00:12,362 - INFO - training batch 51, loss: 0.064, 1632/28000 datapoints
2025-03-06 22:00:12,509 - INFO - training batch 101, loss: 0.059, 3232/28000 datapoints
2025-03-06 22:00:12,653 - INFO - training batch 151, loss: 0.103, 4832/28000 datapoints
2025-03-06 22:00:12,809 - INFO - training batch 201, loss: 0.056, 6432/28000 datapoints
2025-03-06 22:00:12,958 - INFO - training batch 251, loss: 0.200, 8032/28000 datapoints
2025-03-06 22:00:13,110 - INFO - training batch 301, loss: 0.244, 9632/28000 datapoints
2025-03-06 22:00:13,259 - INFO - training batch 351, loss: 0.157, 11232/28000 datapoints
2025-03-06 22:00:13,406 - INFO - training batch 401, loss: 0.151, 12832/28000 datapoints
2025-03-06 22:00:13,552 - INFO - training batch 451, loss: 0.287, 14432/28000 datapoints
2025-03-06 22:00:13,703 - INFO - training batch 501, loss: 0.099, 16032/28000 datapoints
2025-03-06 22:00:13,854 - INFO - training batch 551, loss: 0.120, 17632/28000 datapoints
2025-03-06 22:00:13,999 - INFO - training batch 601, loss: 0.070, 19232/28000 datapoints
2025-03-06 22:00:14,150 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 22:00:14,296 - INFO - training batch 701, loss: 0.065, 22432/28000 datapoints
2025-03-06 22:00:14,441 - INFO - training batch 751, loss: 0.090, 24032/28000 datapoints
2025-03-06 22:00:14,587 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-06 22:00:14,733 - INFO - training batch 851, loss: 0.112, 27232/28000 datapoints
2025-03-06 22:00:14,804 - INFO - validation batch 1, loss: 0.253, 32/6976 datapoints
2025-03-06 22:00:14,853 - INFO - validation batch 51, loss: 2.286, 1632/6976 datapoints
2025-03-06 22:00:14,900 - INFO - validation batch 101, loss: 0.705, 3232/6976 datapoints
2025-03-06 22:00:14,947 - INFO - validation batch 151, loss: 0.851, 4832/6976 datapoints
2025-03-06 22:00:14,996 - INFO - validation batch 201, loss: 0.497, 6432/6976 datapoints
2025-03-06 22:00:15,013 - INFO - Epoch 334/800 done.
2025-03-06 22:00:15,013 - INFO - Final validation performance:
Loss: 0.919, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:15,014 - INFO - Beginning epoch 335/800
2025-03-06 22:00:15,018 - INFO - training batch 1, loss: 0.134, 32/28000 datapoints
2025-03-06 22:00:15,174 - INFO - training batch 51, loss: 0.064, 1632/28000 datapoints
2025-03-06 22:00:15,320 - INFO - training batch 101, loss: 0.059, 3232/28000 datapoints
2025-03-06 22:00:15,471 - INFO - training batch 151, loss: 0.102, 4832/28000 datapoints
2025-03-06 22:00:15,614 - INFO - training batch 201, loss: 0.056, 6432/28000 datapoints
2025-03-06 22:00:15,758 - INFO - training batch 251, loss: 0.198, 8032/28000 datapoints
2025-03-06 22:00:15,905 - INFO - training batch 301, loss: 0.237, 9632/28000 datapoints
2025-03-06 22:00:16,050 - INFO - training batch 351, loss: 0.157, 11232/28000 datapoints
2025-03-06 22:00:16,203 - INFO - training batch 401, loss: 0.147, 12832/28000 datapoints
2025-03-06 22:00:16,348 - INFO - training batch 451, loss: 0.286, 14432/28000 datapoints
2025-03-06 22:00:16,493 - INFO - training batch 501, loss: 0.098, 16032/28000 datapoints
2025-03-06 22:00:16,639 - INFO - training batch 551, loss: 0.118, 17632/28000 datapoints
2025-03-06 22:00:16,786 - INFO - training batch 601, loss: 0.072, 19232/28000 datapoints
2025-03-06 22:00:16,933 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 22:00:17,082 - INFO - training batch 701, loss: 0.064, 22432/28000 datapoints
2025-03-06 22:00:17,248 - INFO - training batch 751, loss: 0.089, 24032/28000 datapoints
2025-03-06 22:00:17,410 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-06 22:00:17,555 - INFO - training batch 851, loss: 0.110, 27232/28000 datapoints
2025-03-06 22:00:17,626 - INFO - validation batch 1, loss: 0.259, 32/6976 datapoints
2025-03-06 22:00:17,672 - INFO - validation batch 51, loss: 2.296, 1632/6976 datapoints
2025-03-06 22:00:17,717 - INFO - validation batch 101, loss: 0.709, 3232/6976 datapoints
2025-03-06 22:00:17,764 - INFO - validation batch 151, loss: 0.856, 4832/6976 datapoints
2025-03-06 22:00:17,810 - INFO - validation batch 201, loss: 0.498, 6432/6976 datapoints
2025-03-06 22:00:17,826 - INFO - Epoch 335/800 done.
2025-03-06 22:00:17,826 - INFO - Final validation performance:
Loss: 0.923, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:17,826 - INFO - Beginning epoch 336/800
2025-03-06 22:00:17,831 - INFO - training batch 1, loss: 0.130, 32/28000 datapoints
2025-03-06 22:00:17,981 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 22:00:18,130 - INFO - training batch 101, loss: 0.059, 3232/28000 datapoints
2025-03-06 22:00:18,274 - INFO - training batch 151, loss: 0.102, 4832/28000 datapoints
2025-03-06 22:00:18,417 - INFO - training batch 201, loss: 0.055, 6432/28000 datapoints
2025-03-06 22:00:18,562 - INFO - training batch 251, loss: 0.198, 8032/28000 datapoints
2025-03-06 22:00:18,705 - INFO - training batch 301, loss: 0.234, 9632/28000 datapoints
2025-03-06 22:00:18,865 - INFO - training batch 351, loss: 0.156, 11232/28000 datapoints
2025-03-06 22:00:19,019 - INFO - training batch 401, loss: 0.145, 12832/28000 datapoints
2025-03-06 22:00:19,172 - INFO - training batch 451, loss: 0.283, 14432/28000 datapoints
2025-03-06 22:00:19,330 - INFO - training batch 501, loss: 0.097, 16032/28000 datapoints
2025-03-06 22:00:19,480 - INFO - training batch 551, loss: 0.117, 17632/28000 datapoints
2025-03-06 22:00:19,636 - INFO - training batch 601, loss: 0.073, 19232/28000 datapoints
2025-03-06 22:00:19,785 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 22:00:19,935 - INFO - training batch 701, loss: 0.064, 22432/28000 datapoints
2025-03-06 22:00:20,085 - INFO - training batch 751, loss: 0.090, 24032/28000 datapoints
2025-03-06 22:00:20,235 - INFO - training batch 801, loss: 0.035, 25632/28000 datapoints
2025-03-06 22:00:20,385 - INFO - training batch 851, loss: 0.109, 27232/28000 datapoints
2025-03-06 22:00:20,459 - INFO - validation batch 1, loss: 0.260, 32/6976 datapoints
2025-03-06 22:00:20,507 - INFO - validation batch 51, loss: 2.306, 1632/6976 datapoints
2025-03-06 22:00:20,556 - INFO - validation batch 101, loss: 0.710, 3232/6976 datapoints
2025-03-06 22:00:20,602 - INFO - validation batch 151, loss: 0.862, 4832/6976 datapoints
2025-03-06 22:00:20,649 - INFO - validation batch 201, loss: 0.500, 6432/6976 datapoints
2025-03-06 22:00:20,665 - INFO - Epoch 336/800 done.
2025-03-06 22:00:20,665 - INFO - Final validation performance:
Loss: 0.928, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:20,665 - INFO - Beginning epoch 337/800
2025-03-06 22:00:20,670 - INFO - training batch 1, loss: 0.131, 32/28000 datapoints
2025-03-06 22:00:20,820 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 22:00:20,966 - INFO - training batch 101, loss: 0.058, 3232/28000 datapoints
2025-03-06 22:00:21,119 - INFO - training batch 151, loss: 0.101, 4832/28000 datapoints
2025-03-06 22:00:21,266 - INFO - training batch 201, loss: 0.055, 6432/28000 datapoints
2025-03-06 22:00:21,412 - INFO - training batch 251, loss: 0.197, 8032/28000 datapoints
2025-03-06 22:00:21,555 - INFO - training batch 301, loss: 0.228, 9632/28000 datapoints
2025-03-06 22:00:21,700 - INFO - training batch 351, loss: 0.156, 11232/28000 datapoints
2025-03-06 22:00:21,842 - INFO - training batch 401, loss: 0.143, 12832/28000 datapoints
2025-03-06 22:00:21,989 - INFO - training batch 451, loss: 0.282, 14432/28000 datapoints
2025-03-06 22:00:22,137 - INFO - training batch 501, loss: 0.096, 16032/28000 datapoints
2025-03-06 22:00:22,307 - INFO - training batch 551, loss: 0.116, 17632/28000 datapoints
2025-03-06 22:00:22,454 - INFO - training batch 601, loss: 0.067, 19232/28000 datapoints
2025-03-06 22:00:22,600 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 22:00:22,744 - INFO - training batch 701, loss: 0.064, 22432/28000 datapoints
2025-03-06 22:00:22,892 - INFO - training batch 751, loss: 0.088, 24032/28000 datapoints
2025-03-06 22:00:23,037 - INFO - training batch 801, loss: 0.035, 25632/28000 datapoints
2025-03-06 22:00:23,185 - INFO - training batch 851, loss: 0.108, 27232/28000 datapoints
2025-03-06 22:00:23,258 - INFO - validation batch 1, loss: 0.262, 32/6976 datapoints
2025-03-06 22:00:23,305 - INFO - validation batch 51, loss: 2.314, 1632/6976 datapoints
2025-03-06 22:00:23,350 - INFO - validation batch 101, loss: 0.716, 3232/6976 datapoints
2025-03-06 22:00:23,396 - INFO - validation batch 151, loss: 0.868, 4832/6976 datapoints
2025-03-06 22:00:23,442 - INFO - validation batch 201, loss: 0.497, 6432/6976 datapoints
2025-03-06 22:00:23,459 - INFO - Epoch 337/800 done.
2025-03-06 22:00:23,459 - INFO - Final validation performance:
Loss: 0.931, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:00:23,459 - INFO - Beginning epoch 338/800
2025-03-06 22:00:23,464 - INFO - training batch 1, loss: 0.129, 32/28000 datapoints
2025-03-06 22:00:23,612 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 22:00:23,761 - INFO - training batch 101, loss: 0.058, 3232/28000 datapoints
2025-03-06 22:00:23,911 - INFO - training batch 151, loss: 0.101, 4832/28000 datapoints
2025-03-06 22:00:24,058 - INFO - training batch 201, loss: 0.055, 6432/28000 datapoints
2025-03-06 22:00:24,205 - INFO - training batch 251, loss: 0.195, 8032/28000 datapoints
2025-03-06 22:00:24,352 - INFO - training batch 301, loss: 0.223, 9632/28000 datapoints
2025-03-06 22:00:24,495 - INFO - training batch 351, loss: 0.156, 11232/28000 datapoints
2025-03-06 22:00:24,639 - INFO - training batch 401, loss: 0.142, 12832/28000 datapoints
2025-03-06 22:00:24,787 - INFO - training batch 451, loss: 0.279, 14432/28000 datapoints
2025-03-06 22:00:24,936 - INFO - training batch 501, loss: 0.096, 16032/28000 datapoints
2025-03-06 22:00:25,098 - INFO - training batch 551, loss: 0.114, 17632/28000 datapoints
2025-03-06 22:00:25,249 - INFO - training batch 601, loss: 0.071, 19232/28000 datapoints
2025-03-06 22:00:25,399 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 22:00:25,547 - INFO - training batch 701, loss: 0.063, 22432/28000 datapoints
2025-03-06 22:00:25,694 - INFO - training batch 751, loss: 0.088, 24032/28000 datapoints
2025-03-06 22:00:25,842 - INFO - training batch 801, loss: 0.034, 25632/28000 datapoints
2025-03-06 22:00:25,988 - INFO - training batch 851, loss: 0.108, 27232/28000 datapoints
2025-03-06 22:00:26,060 - INFO - validation batch 1, loss: 0.265, 32/6976 datapoints
2025-03-06 22:00:26,107 - INFO - validation batch 51, loss: 2.327, 1632/6976 datapoints
2025-03-06 22:00:26,162 - INFO - validation batch 101, loss: 0.719, 3232/6976 datapoints
2025-03-06 22:00:26,213 - INFO - validation batch 151, loss: 0.874, 4832/6976 datapoints
2025-03-06 22:00:26,262 - INFO - validation batch 201, loss: 0.502, 6432/6976 datapoints
2025-03-06 22:00:26,278 - INFO - Epoch 338/800 done.
2025-03-06 22:00:26,278 - INFO - Final validation performance:
Loss: 0.937, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:00:26,279 - INFO - Beginning epoch 339/800
2025-03-06 22:00:26,284 - INFO - training batch 1, loss: 0.129, 32/28000 datapoints
2025-03-06 22:00:26,435 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 22:00:26,601 - INFO - training batch 101, loss: 0.057, 3232/28000 datapoints
2025-03-06 22:00:26,752 - INFO - training batch 151, loss: 0.100, 4832/28000 datapoints
2025-03-06 22:00:26,904 - INFO - training batch 201, loss: 0.055, 6432/28000 datapoints
2025-03-06 22:00:27,054 - INFO - training batch 251, loss: 0.194, 8032/28000 datapoints
2025-03-06 22:00:27,208 - INFO - training batch 301, loss: 0.218, 9632/28000 datapoints
2025-03-06 22:00:27,358 - INFO - training batch 351, loss: 0.154, 11232/28000 datapoints
2025-03-06 22:00:27,504 - INFO - training batch 401, loss: 0.139, 12832/28000 datapoints
2025-03-06 22:00:27,653 - INFO - training batch 451, loss: 0.278, 14432/28000 datapoints
2025-03-06 22:00:27,805 - INFO - training batch 501, loss: 0.095, 16032/28000 datapoints
2025-03-06 22:00:27,956 - INFO - training batch 551, loss: 0.114, 17632/28000 datapoints
2025-03-06 22:00:28,105 - INFO - training batch 601, loss: 0.070, 19232/28000 datapoints
2025-03-06 22:00:28,255 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 22:00:28,404 - INFO - training batch 701, loss: 0.062, 22432/28000 datapoints
2025-03-06 22:00:28,550 - INFO - training batch 751, loss: 0.088, 24032/28000 datapoints
2025-03-06 22:00:28,698 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-06 22:00:28,853 - INFO - training batch 851, loss: 0.107, 27232/28000 datapoints
2025-03-06 22:00:28,926 - INFO - validation batch 1, loss: 0.268, 32/6976 datapoints
2025-03-06 22:00:28,978 - INFO - validation batch 51, loss: 2.335, 1632/6976 datapoints
2025-03-06 22:00:29,028 - INFO - validation batch 101, loss: 0.724, 3232/6976 datapoints
2025-03-06 22:00:29,079 - INFO - validation batch 151, loss: 0.883, 4832/6976 datapoints
2025-03-06 22:00:29,132 - INFO - validation batch 201, loss: 0.502, 6432/6976 datapoints
2025-03-06 22:00:29,153 - INFO - Epoch 339/800 done.
2025-03-06 22:00:29,153 - INFO - Final validation performance:
Loss: 0.942, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:00:29,154 - INFO - Beginning epoch 340/800
2025-03-06 22:00:29,161 - INFO - training batch 1, loss: 0.127, 32/28000 datapoints
2025-03-06 22:00:29,314 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 22:00:29,464 - INFO - training batch 101, loss: 0.056, 3232/28000 datapoints
2025-03-06 22:00:29,614 - INFO - training batch 151, loss: 0.100, 4832/28000 datapoints
2025-03-06 22:00:29,766 - INFO - training batch 201, loss: 0.054, 6432/28000 datapoints
2025-03-06 22:00:29,923 - INFO - training batch 251, loss: 0.193, 8032/28000 datapoints
2025-03-06 22:00:30,074 - INFO - training batch 301, loss: 0.212, 9632/28000 datapoints
2025-03-06 22:00:30,230 - INFO - training batch 351, loss: 0.154, 11232/28000 datapoints
2025-03-06 22:00:30,380 - INFO - training batch 401, loss: 0.137, 12832/28000 datapoints
2025-03-06 22:00:30,533 - INFO - training batch 451, loss: 0.275, 14432/28000 datapoints
2025-03-06 22:00:30,685 - INFO - training batch 501, loss: 0.094, 16032/28000 datapoints
2025-03-06 22:00:30,836 - INFO - training batch 551, loss: 0.112, 17632/28000 datapoints
2025-03-06 22:00:30,996 - INFO - training batch 601, loss: 0.069, 19232/28000 datapoints
2025-03-06 22:00:31,167 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 22:00:31,324 - INFO - training batch 701, loss: 0.062, 22432/28000 datapoints
2025-03-06 22:00:31,476 - INFO - training batch 751, loss: 0.088, 24032/28000 datapoints
2025-03-06 22:00:31,636 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-06 22:00:31,792 - INFO - training batch 851, loss: 0.106, 27232/28000 datapoints
2025-03-06 22:00:31,872 - INFO - validation batch 1, loss: 0.272, 32/6976 datapoints
2025-03-06 22:00:31,925 - INFO - validation batch 51, loss: 2.347, 1632/6976 datapoints
2025-03-06 22:00:31,977 - INFO - validation batch 101, loss: 0.727, 3232/6976 datapoints
2025-03-06 22:00:32,027 - INFO - validation batch 151, loss: 0.885, 4832/6976 datapoints
2025-03-06 22:00:32,079 - INFO - validation batch 201, loss: 0.503, 6432/6976 datapoints
2025-03-06 22:00:32,098 - INFO - Epoch 340/800 done.
2025-03-06 22:00:32,099 - INFO - Final validation performance:
Loss: 0.947, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:00:32,099 - INFO - Beginning epoch 341/800
2025-03-06 22:00:32,103 - INFO - training batch 1, loss: 0.126, 32/28000 datapoints
2025-03-06 22:00:32,257 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-06 22:00:32,438 - INFO - training batch 101, loss: 0.056, 3232/28000 datapoints
2025-03-06 22:00:32,589 - INFO - training batch 151, loss: 0.099, 4832/28000 datapoints
2025-03-06 22:00:32,740 - INFO - training batch 201, loss: 0.054, 6432/28000 datapoints
2025-03-06 22:00:32,891 - INFO - training batch 251, loss: 0.192, 8032/28000 datapoints
2025-03-06 22:00:33,038 - INFO - training batch 301, loss: 0.207, 9632/28000 datapoints
2025-03-06 22:00:33,190 - INFO - training batch 351, loss: 0.154, 11232/28000 datapoints
2025-03-06 22:00:33,341 - INFO - training batch 401, loss: 0.136, 12832/28000 datapoints
2025-03-06 22:00:33,491 - INFO - training batch 451, loss: 0.272, 14432/28000 datapoints
2025-03-06 22:00:33,639 - INFO - training batch 501, loss: 0.093, 16032/28000 datapoints
2025-03-06 22:00:33,792 - INFO - training batch 551, loss: 0.111, 17632/28000 datapoints
2025-03-06 22:00:33,942 - INFO - training batch 601, loss: 0.066, 19232/28000 datapoints
2025-03-06 22:00:34,091 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 22:00:34,245 - INFO - training batch 701, loss: 0.061, 22432/28000 datapoints
2025-03-06 22:00:34,395 - INFO - training batch 751, loss: 0.087, 24032/28000 datapoints
2025-03-06 22:00:34,543 - INFO - training batch 801, loss: 0.032, 25632/28000 datapoints
2025-03-06 22:00:34,691 - INFO - training batch 851, loss: 0.105, 27232/28000 datapoints
2025-03-06 22:00:34,768 - INFO - validation batch 1, loss: 0.272, 32/6976 datapoints
2025-03-06 22:00:34,819 - INFO - validation batch 51, loss: 2.361, 1632/6976 datapoints
2025-03-06 22:00:34,871 - INFO - validation batch 101, loss: 0.731, 3232/6976 datapoints
2025-03-06 22:00:34,921 - INFO - validation batch 151, loss: 0.891, 4832/6976 datapoints
2025-03-06 22:00:34,969 - INFO - validation batch 201, loss: 0.504, 6432/6976 datapoints
2025-03-06 22:00:34,987 - INFO - Epoch 341/800 done.
2025-03-06 22:00:34,988 - INFO - Final validation performance:
Loss: 0.952, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:00:34,989 - INFO - Beginning epoch 342/800
2025-03-06 22:00:34,993 - INFO - training batch 1, loss: 0.125, 32/28000 datapoints
2025-03-06 22:00:35,159 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-06 22:00:35,310 - INFO - training batch 101, loss: 0.055, 3232/28000 datapoints
2025-03-06 22:00:35,457 - INFO - training batch 151, loss: 0.099, 4832/28000 datapoints
2025-03-06 22:00:35,608 - INFO - training batch 201, loss: 0.054, 6432/28000 datapoints
2025-03-06 22:00:35,756 - INFO - training batch 251, loss: 0.190, 8032/28000 datapoints
2025-03-06 22:00:35,907 - INFO - training batch 301, loss: 0.202, 9632/28000 datapoints
2025-03-06 22:00:36,055 - INFO - training batch 351, loss: 0.152, 11232/28000 datapoints
2025-03-06 22:00:36,202 - INFO - training batch 401, loss: 0.133, 12832/28000 datapoints
2025-03-06 22:00:36,354 - INFO - training batch 451, loss: 0.271, 14432/28000 datapoints
2025-03-06 22:00:36,502 - INFO - training batch 501, loss: 0.093, 16032/28000 datapoints
2025-03-06 22:00:36,652 - INFO - training batch 551, loss: 0.110, 17632/28000 datapoints
2025-03-06 22:00:36,801 - INFO - training batch 601, loss: 0.069, 19232/28000 datapoints
2025-03-06 22:00:36,952 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 22:00:37,101 - INFO - training batch 701, loss: 0.060, 22432/28000 datapoints
2025-03-06 22:00:37,265 - INFO - training batch 751, loss: 0.087, 24032/28000 datapoints
2025-03-06 22:00:37,421 - INFO - training batch 801, loss: 0.031, 25632/28000 datapoints
2025-03-06 22:00:37,573 - INFO - training batch 851, loss: 0.104, 27232/28000 datapoints
2025-03-06 22:00:37,649 - INFO - validation batch 1, loss: 0.275, 32/6976 datapoints
2025-03-06 22:00:37,698 - INFO - validation batch 51, loss: 2.370, 1632/6976 datapoints
2025-03-06 22:00:37,751 - INFO - validation batch 101, loss: 0.735, 3232/6976 datapoints
2025-03-06 22:00:37,808 - INFO - validation batch 151, loss: 0.898, 4832/6976 datapoints
2025-03-06 22:00:37,876 - INFO - validation batch 201, loss: 0.505, 6432/6976 datapoints
2025-03-06 22:00:37,896 - INFO - Epoch 342/800 done.
2025-03-06 22:00:37,896 - INFO - Final validation performance:
Loss: 0.957, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:37,897 - INFO - Beginning epoch 343/800
2025-03-06 22:00:37,901 - INFO - training batch 1, loss: 0.123, 32/28000 datapoints
2025-03-06 22:00:38,058 - INFO - training batch 51, loss: 0.058, 1632/28000 datapoints
2025-03-06 22:00:38,210 - INFO - training batch 101, loss: 0.054, 3232/28000 datapoints
2025-03-06 22:00:38,365 - INFO - training batch 151, loss: 0.098, 4832/28000 datapoints
2025-03-06 22:00:38,518 - INFO - training batch 201, loss: 0.053, 6432/28000 datapoints
2025-03-06 22:00:38,669 - INFO - training batch 251, loss: 0.189, 8032/28000 datapoints
2025-03-06 22:00:38,823 - INFO - training batch 301, loss: 0.197, 9632/28000 datapoints
2025-03-06 22:00:38,978 - INFO - training batch 351, loss: 0.152, 11232/28000 datapoints
2025-03-06 22:00:39,135 - INFO - training batch 401, loss: 0.132, 12832/28000 datapoints
2025-03-06 22:00:39,296 - INFO - training batch 451, loss: 0.267, 14432/28000 datapoints
2025-03-06 22:00:39,450 - INFO - training batch 501, loss: 0.091, 16032/28000 datapoints
2025-03-06 22:00:39,603 - INFO - training batch 551, loss: 0.109, 17632/28000 datapoints
2025-03-06 22:00:39,754 - INFO - training batch 601, loss: 0.065, 19232/28000 datapoints
2025-03-06 22:00:39,907 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 22:00:40,055 - INFO - training batch 701, loss: 0.059, 22432/28000 datapoints
2025-03-06 22:00:40,202 - INFO - training batch 751, loss: 0.086, 24032/28000 datapoints
2025-03-06 22:00:40,353 - INFO - training batch 801, loss: 0.031, 25632/28000 datapoints
2025-03-06 22:00:40,510 - INFO - training batch 851, loss: 0.102, 27232/28000 datapoints
2025-03-06 22:00:40,585 - INFO - validation batch 1, loss: 0.279, 32/6976 datapoints
2025-03-06 22:00:40,634 - INFO - validation batch 51, loss: 2.379, 1632/6976 datapoints
2025-03-06 22:00:40,684 - INFO - validation batch 101, loss: 0.737, 3232/6976 datapoints
2025-03-06 22:00:40,734 - INFO - validation batch 151, loss: 0.906, 4832/6976 datapoints
2025-03-06 22:00:40,786 - INFO - validation batch 201, loss: 0.506, 6432/6976 datapoints
2025-03-06 22:00:40,805 - INFO - Epoch 343/800 done.
2025-03-06 22:00:40,806 - INFO - Final validation performance:
Loss: 0.961, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:40,806 - INFO - Beginning epoch 344/800
2025-03-06 22:00:40,811 - INFO - training batch 1, loss: 0.122, 32/28000 datapoints
2025-03-06 22:00:40,965 - INFO - training batch 51, loss: 0.058, 1632/28000 datapoints
2025-03-06 22:00:41,116 - INFO - training batch 101, loss: 0.054, 3232/28000 datapoints
2025-03-06 22:00:41,271 - INFO - training batch 151, loss: 0.097, 4832/28000 datapoints
2025-03-06 22:00:41,421 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-06 22:00:41,571 - INFO - training batch 251, loss: 0.188, 8032/28000 datapoints
2025-03-06 22:00:41,722 - INFO - training batch 301, loss: 0.192, 9632/28000 datapoints
2025-03-06 22:00:41,874 - INFO - training batch 351, loss: 0.151, 11232/28000 datapoints
2025-03-06 22:00:42,024 - INFO - training batch 401, loss: 0.129, 12832/28000 datapoints
2025-03-06 22:00:42,174 - INFO - training batch 451, loss: 0.266, 14432/28000 datapoints
2025-03-06 22:00:42,324 - INFO - training batch 501, loss: 0.090, 16032/28000 datapoints
2025-03-06 22:00:42,498 - INFO - training batch 551, loss: 0.108, 17632/28000 datapoints
2025-03-06 22:00:42,647 - INFO - training batch 601, loss: 0.066, 19232/28000 datapoints
2025-03-06 22:00:42,796 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 22:00:42,949 - INFO - training batch 701, loss: 0.059, 22432/28000 datapoints
2025-03-06 22:00:43,097 - INFO - training batch 751, loss: 0.085, 24032/28000 datapoints
2025-03-06 22:00:43,249 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-06 22:00:43,400 - INFO - training batch 851, loss: 0.103, 27232/28000 datapoints
2025-03-06 22:00:43,484 - INFO - validation batch 1, loss: 0.281, 32/6976 datapoints
2025-03-06 22:00:43,542 - INFO - validation batch 51, loss: 2.395, 1632/6976 datapoints
2025-03-06 22:00:43,592 - INFO - validation batch 101, loss: 0.741, 3232/6976 datapoints
2025-03-06 22:00:43,639 - INFO - validation batch 151, loss: 0.908, 4832/6976 datapoints
2025-03-06 22:00:43,686 - INFO - validation batch 201, loss: 0.507, 6432/6976 datapoints
2025-03-06 22:00:43,702 - INFO - Epoch 344/800 done.
2025-03-06 22:00:43,702 - INFO - Final validation performance:
Loss: 0.966, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:43,703 - INFO - Beginning epoch 345/800
2025-03-06 22:00:43,707 - INFO - training batch 1, loss: 0.121, 32/28000 datapoints
2025-03-06 22:00:43,861 - INFO - training batch 51, loss: 0.058, 1632/28000 datapoints
2025-03-06 22:00:44,006 - INFO - training batch 101, loss: 0.053, 3232/28000 datapoints
2025-03-06 22:00:44,157 - INFO - training batch 151, loss: 0.097, 4832/28000 datapoints
2025-03-06 22:00:44,307 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-06 22:00:44,455 - INFO - training batch 251, loss: 0.186, 8032/28000 datapoints
2025-03-06 22:00:44,601 - INFO - training batch 301, loss: 0.186, 9632/28000 datapoints
2025-03-06 22:00:44,746 - INFO - training batch 351, loss: 0.152, 11232/28000 datapoints
2025-03-06 22:00:44,893 - INFO - training batch 401, loss: 0.128, 12832/28000 datapoints
2025-03-06 22:00:45,040 - INFO - training batch 451, loss: 0.263, 14432/28000 datapoints
2025-03-06 22:00:45,195 - INFO - training batch 501, loss: 0.090, 16032/28000 datapoints
2025-03-06 22:00:45,344 - INFO - training batch 551, loss: 0.106, 17632/28000 datapoints
2025-03-06 22:00:45,489 - INFO - training batch 601, loss: 0.066, 19232/28000 datapoints
2025-03-06 22:00:45,634 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 22:00:45,778 - INFO - training batch 701, loss: 0.059, 22432/28000 datapoints
2025-03-06 22:00:45,931 - INFO - training batch 751, loss: 0.085, 24032/28000 datapoints
2025-03-06 22:00:46,076 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-06 22:00:46,223 - INFO - training batch 851, loss: 0.100, 27232/28000 datapoints
2025-03-06 22:00:46,296 - INFO - validation batch 1, loss: 0.285, 32/6976 datapoints
2025-03-06 22:00:46,348 - INFO - validation batch 51, loss: 2.406, 1632/6976 datapoints
2025-03-06 22:00:46,399 - INFO - validation batch 101, loss: 0.746, 3232/6976 datapoints
2025-03-06 22:00:46,452 - INFO - validation batch 151, loss: 0.914, 4832/6976 datapoints
2025-03-06 22:00:46,505 - INFO - validation batch 201, loss: 0.509, 6432/6976 datapoints
2025-03-06 22:00:46,521 - INFO - Epoch 345/800 done.
2025-03-06 22:00:46,521 - INFO - Final validation performance:
Loss: 0.972, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:46,522 - INFO - Beginning epoch 346/800
2025-03-06 22:00:46,526 - INFO - training batch 1, loss: 0.120, 32/28000 datapoints
2025-03-06 22:00:46,680 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 22:00:46,833 - INFO - training batch 101, loss: 0.052, 3232/28000 datapoints
2025-03-06 22:00:46,989 - INFO - training batch 151, loss: 0.097, 4832/28000 datapoints
2025-03-06 22:00:47,140 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-06 22:00:47,297 - INFO - training batch 251, loss: 0.184, 8032/28000 datapoints
2025-03-06 22:00:47,453 - INFO - training batch 301, loss: 0.181, 9632/28000 datapoints
2025-03-06 22:00:47,608 - INFO - training batch 351, loss: 0.150, 11232/28000 datapoints
2025-03-06 22:00:47,759 - INFO - training batch 401, loss: 0.126, 12832/28000 datapoints
2025-03-06 22:00:47,914 - INFO - training batch 451, loss: 0.261, 14432/28000 datapoints
2025-03-06 22:00:48,066 - INFO - training batch 501, loss: 0.089, 16032/28000 datapoints
2025-03-06 22:00:48,219 - INFO - training batch 551, loss: 0.107, 17632/28000 datapoints
2025-03-06 22:00:48,372 - INFO - training batch 601, loss: 0.063, 19232/28000 datapoints
2025-03-06 22:00:48,524 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:00:48,677 - INFO - training batch 701, loss: 0.058, 22432/28000 datapoints
2025-03-06 22:00:48,828 - INFO - training batch 751, loss: 0.084, 24032/28000 datapoints
2025-03-06 22:00:48,983 - INFO - training batch 801, loss: 0.029, 25632/28000 datapoints
2025-03-06 22:00:49,130 - INFO - training batch 851, loss: 0.099, 27232/28000 datapoints
2025-03-06 22:00:49,210 - INFO - validation batch 1, loss: 0.286, 32/6976 datapoints
2025-03-06 22:00:49,261 - INFO - validation batch 51, loss: 2.416, 1632/6976 datapoints
2025-03-06 22:00:49,314 - INFO - validation batch 101, loss: 0.750, 3232/6976 datapoints
2025-03-06 22:00:49,366 - INFO - validation batch 151, loss: 0.921, 4832/6976 datapoints
2025-03-06 22:00:49,418 - INFO - validation batch 201, loss: 0.508, 6432/6976 datapoints
2025-03-06 22:00:49,435 - INFO - Epoch 346/800 done.
2025-03-06 22:00:49,435 - INFO - Final validation performance:
Loss: 0.976, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:49,436 - INFO - Beginning epoch 347/800
2025-03-06 22:00:49,441 - INFO - training batch 1, loss: 0.119, 32/28000 datapoints
2025-03-06 22:00:49,607 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 22:00:49,757 - INFO - training batch 101, loss: 0.052, 3232/28000 datapoints
2025-03-06 22:00:49,913 - INFO - training batch 151, loss: 0.096, 4832/28000 datapoints
2025-03-06 22:00:50,069 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-06 22:00:50,219 - INFO - training batch 251, loss: 0.183, 8032/28000 datapoints
2025-03-06 22:00:50,370 - INFO - training batch 301, loss: 0.176, 9632/28000 datapoints
2025-03-06 22:00:50,514 - INFO - training batch 351, loss: 0.150, 11232/28000 datapoints
2025-03-06 22:00:50,658 - INFO - training batch 401, loss: 0.125, 12832/28000 datapoints
2025-03-06 22:00:50,803 - INFO - training batch 451, loss: 0.257, 14432/28000 datapoints
2025-03-06 22:00:50,952 - INFO - training batch 501, loss: 0.089, 16032/28000 datapoints
2025-03-06 22:00:51,097 - INFO - training batch 551, loss: 0.105, 17632/28000 datapoints
2025-03-06 22:00:51,247 - INFO - training batch 601, loss: 0.065, 19232/28000 datapoints
2025-03-06 22:00:51,393 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:00:51,539 - INFO - training batch 701, loss: 0.058, 22432/28000 datapoints
2025-03-06 22:00:51,684 - INFO - training batch 751, loss: 0.084, 24032/28000 datapoints
2025-03-06 22:00:51,830 - INFO - training batch 801, loss: 0.029, 25632/28000 datapoints
2025-03-06 22:00:51,983 - INFO - training batch 851, loss: 0.098, 27232/28000 datapoints
2025-03-06 22:00:52,054 - INFO - validation batch 1, loss: 0.291, 32/6976 datapoints
2025-03-06 22:00:52,101 - INFO - validation batch 51, loss: 2.431, 1632/6976 datapoints
2025-03-06 22:00:52,148 - INFO - validation batch 101, loss: 0.753, 3232/6976 datapoints
2025-03-06 22:00:52,194 - INFO - validation batch 151, loss: 0.925, 4832/6976 datapoints
2025-03-06 22:00:52,242 - INFO - validation batch 201, loss: 0.512, 6432/6976 datapoints
2025-03-06 22:00:52,258 - INFO - Epoch 347/800 done.
2025-03-06 22:00:52,259 - INFO - Final validation performance:
Loss: 0.982, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:52,259 - INFO - Beginning epoch 348/800
2025-03-06 22:00:52,263 - INFO - training batch 1, loss: 0.117, 32/28000 datapoints
2025-03-06 22:00:52,410 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 22:00:52,580 - INFO - training batch 101, loss: 0.051, 3232/28000 datapoints
2025-03-06 22:00:52,729 - INFO - training batch 151, loss: 0.096, 4832/28000 datapoints
2025-03-06 22:00:52,876 - INFO - training batch 201, loss: 0.051, 6432/28000 datapoints
2025-03-06 22:00:53,021 - INFO - training batch 251, loss: 0.182, 8032/28000 datapoints
2025-03-06 22:00:53,166 - INFO - training batch 301, loss: 0.172, 9632/28000 datapoints
2025-03-06 22:00:53,315 - INFO - training batch 351, loss: 0.149, 11232/28000 datapoints
2025-03-06 22:00:53,461 - INFO - training batch 401, loss: 0.122, 12832/28000 datapoints
2025-03-06 22:00:53,606 - INFO - training batch 451, loss: 0.255, 14432/28000 datapoints
2025-03-06 22:00:53,752 - INFO - training batch 501, loss: 0.088, 16032/28000 datapoints
2025-03-06 22:00:53,899 - INFO - training batch 551, loss: 0.104, 17632/28000 datapoints
2025-03-06 22:00:54,047 - INFO - training batch 601, loss: 0.065, 19232/28000 datapoints
2025-03-06 22:00:54,192 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 22:00:54,342 - INFO - training batch 701, loss: 0.056, 22432/28000 datapoints
2025-03-06 22:00:54,488 - INFO - training batch 751, loss: 0.082, 24032/28000 datapoints
2025-03-06 22:00:54,633 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-06 22:00:54,777 - INFO - training batch 851, loss: 0.097, 27232/28000 datapoints
2025-03-06 22:00:54,852 - INFO - validation batch 1, loss: 0.292, 32/6976 datapoints
2025-03-06 22:00:54,899 - INFO - validation batch 51, loss: 2.443, 1632/6976 datapoints
2025-03-06 22:00:54,946 - INFO - validation batch 101, loss: 0.755, 3232/6976 datapoints
2025-03-06 22:00:54,995 - INFO - validation batch 151, loss: 0.929, 4832/6976 datapoints
2025-03-06 22:00:55,044 - INFO - validation batch 201, loss: 0.511, 6432/6976 datapoints
2025-03-06 22:00:55,060 - INFO - Epoch 348/800 done.
2025-03-06 22:00:55,060 - INFO - Final validation performance:
Loss: 0.986, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:55,060 - INFO - Beginning epoch 349/800
2025-03-06 22:00:55,064 - INFO - training batch 1, loss: 0.115, 32/28000 datapoints
2025-03-06 22:00:55,217 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-06 22:00:55,363 - INFO - training batch 101, loss: 0.051, 3232/28000 datapoints
2025-03-06 22:00:55,510 - INFO - training batch 151, loss: 0.095, 4832/28000 datapoints
2025-03-06 22:00:55,667 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-06 22:00:55,815 - INFO - training batch 251, loss: 0.181, 8032/28000 datapoints
2025-03-06 22:00:55,967 - INFO - training batch 301, loss: 0.166, 9632/28000 datapoints
2025-03-06 22:00:56,118 - INFO - training batch 351, loss: 0.148, 11232/28000 datapoints
2025-03-06 22:00:56,265 - INFO - training batch 401, loss: 0.120, 12832/28000 datapoints
2025-03-06 22:00:56,418 - INFO - training batch 451, loss: 0.253, 14432/28000 datapoints
2025-03-06 22:00:56,565 - INFO - training batch 501, loss: 0.087, 16032/28000 datapoints
2025-03-06 22:00:56,714 - INFO - training batch 551, loss: 0.103, 17632/28000 datapoints
2025-03-06 22:00:56,860 - INFO - training batch 601, loss: 0.060, 19232/28000 datapoints
2025-03-06 22:00:57,007 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 22:00:57,151 - INFO - training batch 701, loss: 0.056, 22432/28000 datapoints
2025-03-06 22:00:57,299 - INFO - training batch 751, loss: 0.082, 24032/28000 datapoints
2025-03-06 22:00:57,448 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-06 22:00:57,594 - INFO - training batch 851, loss: 0.095, 27232/28000 datapoints
2025-03-06 22:00:57,669 - INFO - validation batch 1, loss: 0.296, 32/6976 datapoints
2025-03-06 22:00:57,714 - INFO - validation batch 51, loss: 2.452, 1632/6976 datapoints
2025-03-06 22:00:57,761 - INFO - validation batch 101, loss: 0.761, 3232/6976 datapoints
2025-03-06 22:00:57,807 - INFO - validation batch 151, loss: 0.937, 4832/6976 datapoints
2025-03-06 22:00:57,857 - INFO - validation batch 201, loss: 0.512, 6432/6976 datapoints
2025-03-06 22:00:57,873 - INFO - Epoch 349/800 done.
2025-03-06 22:00:57,873 - INFO - Final validation performance:
Loss: 0.991, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:00:57,874 - INFO - Beginning epoch 350/800
2025-03-06 22:00:57,878 - INFO - training batch 1, loss: 0.114, 32/28000 datapoints
2025-03-06 22:00:58,026 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-06 22:00:58,171 - INFO - training batch 101, loss: 0.050, 3232/28000 datapoints
2025-03-06 22:00:58,316 - INFO - training batch 151, loss: 0.094, 4832/28000 datapoints
2025-03-06 22:00:58,463 - INFO - training batch 201, loss: 0.051, 6432/28000 datapoints
2025-03-06 22:00:58,611 - INFO - training batch 251, loss: 0.179, 8032/28000 datapoints
2025-03-06 22:00:58,761 - INFO - training batch 301, loss: 0.162, 9632/28000 datapoints
2025-03-06 22:00:58,916 - INFO - training batch 351, loss: 0.148, 11232/28000 datapoints
2025-03-06 22:00:59,069 - INFO - training batch 401, loss: 0.119, 12832/28000 datapoints
2025-03-06 22:00:59,221 - INFO - training batch 451, loss: 0.250, 14432/28000 datapoints
2025-03-06 22:00:59,384 - INFO - training batch 501, loss: 0.087, 16032/28000 datapoints
2025-03-06 22:00:59,541 - INFO - training batch 551, loss: 0.102, 17632/28000 datapoints
2025-03-06 22:00:59,698 - INFO - training batch 601, loss: 0.065, 19232/28000 datapoints
2025-03-06 22:00:59,852 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:01:00,007 - INFO - training batch 701, loss: 0.056, 22432/28000 datapoints
2025-03-06 22:01:00,155 - INFO - training batch 751, loss: 0.082, 24032/28000 datapoints
2025-03-06 22:01:00,303 - INFO - training batch 801, loss: 0.027, 25632/28000 datapoints
2025-03-06 22:01:00,452 - INFO - training batch 851, loss: 0.095, 27232/28000 datapoints
2025-03-06 22:01:00,526 - INFO - validation batch 1, loss: 0.299, 32/6976 datapoints
2025-03-06 22:01:00,573 - INFO - validation batch 51, loss: 2.468, 1632/6976 datapoints
2025-03-06 22:01:00,620 - INFO - validation batch 101, loss: 0.765, 3232/6976 datapoints
2025-03-06 22:01:00,667 - INFO - validation batch 151, loss: 0.940, 4832/6976 datapoints
2025-03-06 22:01:00,714 - INFO - validation batch 201, loss: 0.514, 6432/6976 datapoints
2025-03-06 22:01:00,730 - INFO - Epoch 350/800 done.
2025-03-06 22:01:00,730 - INFO - Final validation performance:
Loss: 0.997, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:01:00,731 - INFO - Beginning epoch 351/800
2025-03-06 22:01:00,735 - INFO - training batch 1, loss: 0.114, 32/28000 datapoints
2025-03-06 22:01:00,886 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-06 22:01:01,036 - INFO - training batch 101, loss: 0.049, 3232/28000 datapoints
2025-03-06 22:01:01,183 - INFO - training batch 151, loss: 0.094, 4832/28000 datapoints
2025-03-06 22:01:01,331 - INFO - training batch 201, loss: 0.051, 6432/28000 datapoints
2025-03-06 22:01:01,476 - INFO - training batch 251, loss: 0.178, 8032/28000 datapoints
2025-03-06 22:01:01,626 - INFO - training batch 301, loss: 0.157, 9632/28000 datapoints
2025-03-06 22:01:01,780 - INFO - training batch 351, loss: 0.147, 11232/28000 datapoints
2025-03-06 22:01:01,927 - INFO - training batch 401, loss: 0.117, 12832/28000 datapoints
2025-03-06 22:01:02,076 - INFO - training batch 451, loss: 0.248, 14432/28000 datapoints
2025-03-06 22:01:02,230 - INFO - training batch 501, loss: 0.086, 16032/28000 datapoints
2025-03-06 22:01:02,385 - INFO - training batch 551, loss: 0.101, 17632/28000 datapoints
2025-03-06 22:01:02,536 - INFO - training batch 601, loss: 0.062, 19232/28000 datapoints
2025-03-06 22:01:02,711 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:01:02,861 - INFO - training batch 701, loss: 0.054, 22432/28000 datapoints
2025-03-06 22:01:03,006 - INFO - training batch 751, loss: 0.081, 24032/28000 datapoints
2025-03-06 22:01:03,151 - INFO - training batch 801, loss: 0.027, 25632/28000 datapoints
2025-03-06 22:01:03,298 - INFO - training batch 851, loss: 0.093, 27232/28000 datapoints
2025-03-06 22:01:03,369 - INFO - validation batch 1, loss: 0.303, 32/6976 datapoints
2025-03-06 22:01:03,415 - INFO - validation batch 51, loss: 2.480, 1632/6976 datapoints
2025-03-06 22:01:03,464 - INFO - validation batch 101, loss: 0.768, 3232/6976 datapoints
2025-03-06 22:01:03,511 - INFO - validation batch 151, loss: 0.947, 4832/6976 datapoints
2025-03-06 22:01:03,557 - INFO - validation batch 201, loss: 0.516, 6432/6976 datapoints
2025-03-06 22:01:03,575 - INFO - Epoch 351/800 done.
2025-03-06 22:01:03,575 - INFO - Final validation performance:
Loss: 1.003, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:01:03,575 - INFO - Beginning epoch 352/800
2025-03-06 22:01:03,580 - INFO - training batch 1, loss: 0.111, 32/28000 datapoints
2025-03-06 22:01:03,727 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-06 22:01:03,875 - INFO - training batch 101, loss: 0.048, 3232/28000 datapoints
2025-03-06 22:01:04,021 - INFO - training batch 151, loss: 0.093, 4832/28000 datapoints
2025-03-06 22:01:04,168 - INFO - training batch 201, loss: 0.050, 6432/28000 datapoints
2025-03-06 22:01:04,320 - INFO - training batch 251, loss: 0.175, 8032/28000 datapoints
2025-03-06 22:01:04,470 - INFO - training batch 301, loss: 0.152, 9632/28000 datapoints
2025-03-06 22:01:04,618 - INFO - training batch 351, loss: 0.147, 11232/28000 datapoints
2025-03-06 22:01:04,762 - INFO - training batch 401, loss: 0.116, 12832/28000 datapoints
2025-03-06 22:01:04,911 - INFO - training batch 451, loss: 0.244, 14432/28000 datapoints
2025-03-06 22:01:05,058 - INFO - training batch 501, loss: 0.085, 16032/28000 datapoints
2025-03-06 22:01:05,211 - INFO - training batch 551, loss: 0.100, 17632/28000 datapoints
2025-03-06 22:01:05,361 - INFO - training batch 601, loss: 0.059, 19232/28000 datapoints
2025-03-06 22:01:05,509 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:01:05,655 - INFO - training batch 701, loss: 0.054, 22432/28000 datapoints
2025-03-06 22:01:05,799 - INFO - training batch 751, loss: 0.081, 24032/28000 datapoints
2025-03-06 22:01:05,948 - INFO - training batch 801, loss: 0.026, 25632/28000 datapoints
2025-03-06 22:01:06,092 - INFO - training batch 851, loss: 0.092, 27232/28000 datapoints
2025-03-06 22:01:06,164 - INFO - validation batch 1, loss: 0.307, 32/6976 datapoints
2025-03-06 22:01:06,211 - INFO - validation batch 51, loss: 2.495, 1632/6976 datapoints
2025-03-06 22:01:06,257 - INFO - validation batch 101, loss: 0.772, 3232/6976 datapoints
2025-03-06 22:01:06,303 - INFO - validation batch 151, loss: 0.948, 4832/6976 datapoints
2025-03-06 22:01:06,351 - INFO - validation batch 201, loss: 0.516, 6432/6976 datapoints
2025-03-06 22:01:06,367 - INFO - Epoch 352/800 done.
2025-03-06 22:01:06,368 - INFO - Final validation performance:
Loss: 1.008, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:01:06,368 - INFO - Beginning epoch 353/800
2025-03-06 22:01:06,373 - INFO - training batch 1, loss: 0.110, 32/28000 datapoints
2025-03-06 22:01:06,532 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-06 22:01:06,683 - INFO - training batch 101, loss: 0.048, 3232/28000 datapoints
2025-03-06 22:01:06,831 - INFO - training batch 151, loss: 0.093, 4832/28000 datapoints
2025-03-06 22:01:06,982 - INFO - training batch 201, loss: 0.049, 6432/28000 datapoints
2025-03-06 22:01:07,137 - INFO - training batch 251, loss: 0.174, 8032/28000 datapoints
2025-03-06 22:01:07,290 - INFO - training batch 301, loss: 0.148, 9632/28000 datapoints
2025-03-06 22:01:07,439 - INFO - training batch 351, loss: 0.145, 11232/28000 datapoints
2025-03-06 22:01:07,587 - INFO - training batch 401, loss: 0.114, 12832/28000 datapoints
2025-03-06 22:01:07,749 - INFO - training batch 451, loss: 0.244, 14432/28000 datapoints
2025-03-06 22:01:07,906 - INFO - training batch 501, loss: 0.084, 16032/28000 datapoints
2025-03-06 22:01:08,057 - INFO - training batch 551, loss: 0.098, 17632/28000 datapoints
2025-03-06 22:01:08,216 - INFO - training batch 601, loss: 0.063, 19232/28000 datapoints
2025-03-06 22:01:08,368 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:01:08,524 - INFO - training batch 701, loss: 0.054, 22432/28000 datapoints
2025-03-06 22:01:08,675 - INFO - training batch 751, loss: 0.080, 24032/28000 datapoints
2025-03-06 22:01:08,823 - INFO - training batch 801, loss: 0.026, 25632/28000 datapoints
2025-03-06 22:01:08,974 - INFO - training batch 851, loss: 0.091, 27232/28000 datapoints
2025-03-06 22:01:09,053 - INFO - validation batch 1, loss: 0.310, 32/6976 datapoints
2025-03-06 22:01:09,103 - INFO - validation batch 51, loss: 2.505, 1632/6976 datapoints
2025-03-06 22:01:09,154 - INFO - validation batch 101, loss: 0.775, 3232/6976 datapoints
2025-03-06 22:01:09,206 - INFO - validation batch 151, loss: 0.958, 4832/6976 datapoints
2025-03-06 22:01:09,267 - INFO - validation batch 201, loss: 0.516, 6432/6976 datapoints
2025-03-06 22:01:09,285 - INFO - Epoch 353/800 done.
2025-03-06 22:01:09,286 - INFO - Final validation performance:
Loss: 1.013, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:01:09,286 - INFO - Beginning epoch 354/800
2025-03-06 22:01:09,291 - INFO - training batch 1, loss: 0.107, 32/28000 datapoints
2025-03-06 22:01:09,446 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 22:01:09,593 - INFO - training batch 101, loss: 0.047, 3232/28000 datapoints
2025-03-06 22:01:09,747 - INFO - training batch 151, loss: 0.092, 4832/28000 datapoints
2025-03-06 22:01:09,904 - INFO - training batch 201, loss: 0.049, 6432/28000 datapoints
2025-03-06 22:01:10,054 - INFO - training batch 251, loss: 0.173, 8032/28000 datapoints
2025-03-06 22:01:10,204 - INFO - training batch 301, loss: 0.144, 9632/28000 datapoints
2025-03-06 22:01:10,355 - INFO - training batch 351, loss: 0.146, 11232/28000 datapoints
2025-03-06 22:01:10,507 - INFO - training batch 401, loss: 0.113, 12832/28000 datapoints
2025-03-06 22:01:10,660 - INFO - training batch 451, loss: 0.240, 14432/28000 datapoints
2025-03-06 22:01:10,816 - INFO - training batch 501, loss: 0.084, 16032/28000 datapoints
2025-03-06 22:01:10,972 - INFO - training batch 551, loss: 0.097, 17632/28000 datapoints
2025-03-06 22:01:11,125 - INFO - training batch 601, loss: 0.063, 19232/28000 datapoints
2025-03-06 22:01:11,281 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:01:11,433 - INFO - training batch 701, loss: 0.053, 22432/28000 datapoints
2025-03-06 22:01:11,586 - INFO - training batch 751, loss: 0.079, 24032/28000 datapoints
2025-03-06 22:01:11,740 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-06 22:01:11,894 - INFO - training batch 851, loss: 0.090, 27232/28000 datapoints
2025-03-06 22:01:11,971 - INFO - validation batch 1, loss: 0.311, 32/6976 datapoints
2025-03-06 22:01:12,021 - INFO - validation batch 51, loss: 2.517, 1632/6976 datapoints
2025-03-06 22:01:12,072 - INFO - validation batch 101, loss: 0.780, 3232/6976 datapoints
2025-03-06 22:01:12,123 - INFO - validation batch 151, loss: 0.963, 4832/6976 datapoints
2025-03-06 22:01:12,175 - INFO - validation batch 201, loss: 0.519, 6432/6976 datapoints
2025-03-06 22:01:12,193 - INFO - Epoch 354/800 done.
2025-03-06 22:01:12,193 - INFO - Final validation performance:
Loss: 1.018, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:01:12,194 - INFO - Beginning epoch 355/800
2025-03-06 22:01:12,199 - INFO - training batch 1, loss: 0.108, 32/28000 datapoints
2025-03-06 22:01:12,353 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 22:01:12,500 - INFO - training batch 101, loss: 0.046, 3232/28000 datapoints
2025-03-06 22:01:12,647 - INFO - training batch 151, loss: 0.091, 4832/28000 datapoints
2025-03-06 22:01:12,822 - INFO - training batch 201, loss: 0.049, 6432/28000 datapoints
2025-03-06 22:01:12,968 - INFO - training batch 251, loss: 0.170, 8032/28000 datapoints
2025-03-06 22:01:13,133 - INFO - training batch 301, loss: 0.140, 9632/28000 datapoints
2025-03-06 22:01:13,276 - INFO - training batch 351, loss: 0.145, 11232/28000 datapoints
2025-03-06 22:01:13,423 - INFO - training batch 401, loss: 0.111, 12832/28000 datapoints
2025-03-06 22:01:13,568 - INFO - training batch 451, loss: 0.239, 14432/28000 datapoints
2025-03-06 22:01:13,715 - INFO - training batch 501, loss: 0.083, 16032/28000 datapoints
2025-03-06 22:01:13,880 - INFO - training batch 551, loss: 0.096, 17632/28000 datapoints
2025-03-06 22:01:14,028 - INFO - training batch 601, loss: 0.056, 19232/28000 datapoints
2025-03-06 22:01:14,177 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:01:14,331 - INFO - training batch 701, loss: 0.052, 22432/28000 datapoints
2025-03-06 22:01:14,479 - INFO - training batch 751, loss: 0.080, 24032/28000 datapoints
2025-03-06 22:01:14,630 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-06 22:01:14,775 - INFO - training batch 851, loss: 0.088, 27232/28000 datapoints
2025-03-06 22:01:14,850 - INFO - validation batch 1, loss: 0.315, 32/6976 datapoints
2025-03-06 22:01:14,895 - INFO - validation batch 51, loss: 2.533, 1632/6976 datapoints
2025-03-06 22:01:14,942 - INFO - validation batch 101, loss: 0.783, 3232/6976 datapoints
2025-03-06 22:01:14,987 - INFO - validation batch 151, loss: 0.968, 4832/6976 datapoints
2025-03-06 22:01:15,036 - INFO - validation batch 201, loss: 0.520, 6432/6976 datapoints
2025-03-06 22:01:15,051 - INFO - Epoch 355/800 done.
2025-03-06 22:01:15,052 - INFO - Final validation performance:
Loss: 1.024, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:01:15,052 - INFO - Beginning epoch 356/800
2025-03-06 22:01:15,056 - INFO - training batch 1, loss: 0.106, 32/28000 datapoints
2025-03-06 22:01:15,208 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-06 22:01:15,361 - INFO - training batch 101, loss: 0.045, 3232/28000 datapoints
2025-03-06 22:01:15,529 - INFO - training batch 151, loss: 0.091, 4832/28000 datapoints
2025-03-06 22:01:15,699 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-06 22:01:15,845 - INFO - training batch 251, loss: 0.171, 8032/28000 datapoints
2025-03-06 22:01:15,995 - INFO - training batch 301, loss: 0.137, 9632/28000 datapoints
2025-03-06 22:01:16,140 - INFO - training batch 351, loss: 0.144, 11232/28000 datapoints
2025-03-06 22:01:16,286 - INFO - training batch 401, loss: 0.110, 12832/28000 datapoints
2025-03-06 22:01:16,437 - INFO - training batch 451, loss: 0.236, 14432/28000 datapoints
2025-03-06 22:01:16,584 - INFO - training batch 501, loss: 0.082, 16032/28000 datapoints
2025-03-06 22:01:16,730 - INFO - training batch 551, loss: 0.094, 17632/28000 datapoints
2025-03-06 22:01:16,879 - INFO - training batch 601, loss: 0.060, 19232/28000 datapoints
2025-03-06 22:01:17,023 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:01:17,169 - INFO - training batch 701, loss: 0.052, 22432/28000 datapoints
2025-03-06 22:01:17,319 - INFO - training batch 751, loss: 0.078, 24032/28000 datapoints
2025-03-06 22:01:17,473 - INFO - training batch 801, loss: 0.024, 25632/28000 datapoints
2025-03-06 22:01:17,664 - INFO - training batch 851, loss: 0.088, 27232/28000 datapoints
2025-03-06 22:01:17,742 - INFO - validation batch 1, loss: 0.317, 32/6976 datapoints
2025-03-06 22:01:17,790 - INFO - validation batch 51, loss: 2.547, 1632/6976 datapoints
2025-03-06 22:01:17,837 - INFO - validation batch 101, loss: 0.787, 3232/6976 datapoints
2025-03-06 22:01:17,889 - INFO - validation batch 151, loss: 0.976, 4832/6976 datapoints
2025-03-06 22:01:17,935 - INFO - validation batch 201, loss: 0.522, 6432/6976 datapoints
2025-03-06 22:01:17,951 - INFO - Epoch 356/800 done.
2025-03-06 22:01:17,951 - INFO - Final validation performance:
Loss: 1.030, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:01:17,952 - INFO - Beginning epoch 357/800
2025-03-06 22:01:17,956 - INFO - training batch 1, loss: 0.105, 32/28000 datapoints
2025-03-06 22:01:18,108 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-06 22:01:18,277 - INFO - training batch 101, loss: 0.044, 3232/28000 datapoints
2025-03-06 22:01:18,426 - INFO - training batch 151, loss: 0.090, 4832/28000 datapoints
2025-03-06 22:01:18,576 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-06 22:01:18,723 - INFO - training batch 251, loss: 0.167, 8032/28000 datapoints
2025-03-06 22:01:18,877 - INFO - training batch 301, loss: 0.133, 9632/28000 datapoints
2025-03-06 22:01:19,029 - INFO - training batch 351, loss: 0.143, 11232/28000 datapoints
2025-03-06 22:01:19,175 - INFO - training batch 401, loss: 0.108, 12832/28000 datapoints
2025-03-06 22:01:19,330 - INFO - training batch 451, loss: 0.234, 14432/28000 datapoints
2025-03-06 22:01:19,482 - INFO - training batch 501, loss: 0.081, 16032/28000 datapoints
2025-03-06 22:01:19,631 - INFO - training batch 551, loss: 0.093, 17632/28000 datapoints
2025-03-06 22:01:19,779 - INFO - training batch 601, loss: 0.059, 19232/28000 datapoints
2025-03-06 22:01:19,937 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:01:20,093 - INFO - training batch 701, loss: 0.051, 22432/28000 datapoints
2025-03-06 22:01:20,238 - INFO - training batch 751, loss: 0.078, 24032/28000 datapoints
2025-03-06 22:01:20,407 - INFO - training batch 801, loss: 0.024, 25632/28000 datapoints
2025-03-06 22:01:20,560 - INFO - training batch 851, loss: 0.086, 27232/28000 datapoints
2025-03-06 22:01:20,634 - INFO - validation batch 1, loss: 0.323, 32/6976 datapoints
2025-03-06 22:01:20,682 - INFO - validation batch 51, loss: 2.559, 1632/6976 datapoints
2025-03-06 22:01:20,731 - INFO - validation batch 101, loss: 0.791, 3232/6976 datapoints
2025-03-06 22:01:20,779 - INFO - validation batch 151, loss: 0.982, 4832/6976 datapoints
2025-03-06 22:01:20,827 - INFO - validation batch 201, loss: 0.522, 6432/6976 datapoints
2025-03-06 22:01:20,843 - INFO - Epoch 357/800 done.
2025-03-06 22:01:20,843 - INFO - Final validation performance:
Loss: 1.035, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:01:20,843 - INFO - Beginning epoch 358/800
2025-03-06 22:01:20,849 - INFO - training batch 1, loss: 0.103, 32/28000 datapoints
2025-03-06 22:01:21,013 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 22:01:21,159 - INFO - training batch 101, loss: 0.044, 3232/28000 datapoints
2025-03-06 22:01:21,308 - INFO - training batch 151, loss: 0.089, 4832/28000 datapoints
2025-03-06 22:01:21,461 - INFO - training batch 201, loss: 0.047, 6432/28000 datapoints
2025-03-06 22:01:21,609 - INFO - training batch 251, loss: 0.166, 8032/28000 datapoints
2025-03-06 22:01:21,753 - INFO - training batch 301, loss: 0.129, 9632/28000 datapoints
2025-03-06 22:01:21,902 - INFO - training batch 351, loss: 0.143, 11232/28000 datapoints
2025-03-06 22:01:22,047 - INFO - training batch 401, loss: 0.106, 12832/28000 datapoints
2025-03-06 22:01:22,196 - INFO - training batch 451, loss: 0.232, 14432/28000 datapoints
2025-03-06 22:01:22,343 - INFO - training batch 501, loss: 0.081, 16032/28000 datapoints
2025-03-06 22:01:22,489 - INFO - training batch 551, loss: 0.092, 17632/28000 datapoints
2025-03-06 22:01:22,636 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-06 22:01:22,782 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:01:23,024 - INFO - training batch 701, loss: 0.050, 22432/28000 datapoints
2025-03-06 22:01:23,170 - INFO - training batch 751, loss: 0.077, 24032/28000 datapoints
2025-03-06 22:01:23,314 - INFO - training batch 801, loss: 0.024, 25632/28000 datapoints
2025-03-06 22:01:23,463 - INFO - training batch 851, loss: 0.085, 27232/28000 datapoints
2025-03-06 22:01:23,539 - INFO - validation batch 1, loss: 0.326, 32/6976 datapoints
2025-03-06 22:01:23,585 - INFO - validation batch 51, loss: 2.573, 1632/6976 datapoints
2025-03-06 22:01:23,632 - INFO - validation batch 101, loss: 0.796, 3232/6976 datapoints
2025-03-06 22:01:23,678 - INFO - validation batch 151, loss: 0.985, 4832/6976 datapoints
2025-03-06 22:01:23,725 - INFO - validation batch 201, loss: 0.524, 6432/6976 datapoints
2025-03-06 22:01:23,742 - INFO - Epoch 358/800 done.
2025-03-06 22:01:23,742 - INFO - Final validation performance:
Loss: 1.041, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:01:23,743 - INFO - Beginning epoch 359/800
2025-03-06 22:01:23,747 - INFO - training batch 1, loss: 0.103, 32/28000 datapoints
2025-03-06 22:01:23,898 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 22:01:24,048 - INFO - training batch 101, loss: 0.043, 3232/28000 datapoints
2025-03-06 22:01:24,194 - INFO - training batch 151, loss: 0.089, 4832/28000 datapoints
2025-03-06 22:01:24,343 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-06 22:01:24,490 - INFO - training batch 251, loss: 0.163, 8032/28000 datapoints
2025-03-06 22:01:24,637 - INFO - training batch 301, loss: 0.126, 9632/28000 datapoints
2025-03-06 22:01:24,782 - INFO - training batch 351, loss: 0.141, 11232/28000 datapoints
2025-03-06 22:01:24,941 - INFO - training batch 401, loss: 0.105, 12832/28000 datapoints
2025-03-06 22:01:25,101 - INFO - training batch 451, loss: 0.230, 14432/28000 datapoints
2025-03-06 22:01:25,249 - INFO - training batch 501, loss: 0.079, 16032/28000 datapoints
2025-03-06 22:01:25,399 - INFO - training batch 551, loss: 0.092, 17632/28000 datapoints
2025-03-06 22:01:25,553 - INFO - training batch 601, loss: 0.060, 19232/28000 datapoints
2025-03-06 22:01:25,697 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:01:25,844 - INFO - training batch 701, loss: 0.049, 22432/28000 datapoints
2025-03-06 22:01:25,992 - INFO - training batch 751, loss: 0.077, 24032/28000 datapoints
2025-03-06 22:01:26,149 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-06 22:01:26,293 - INFO - training batch 851, loss: 0.084, 27232/28000 datapoints
2025-03-06 22:01:26,364 - INFO - validation batch 1, loss: 0.331, 32/6976 datapoints
2025-03-06 22:01:26,411 - INFO - validation batch 51, loss: 2.588, 1632/6976 datapoints
2025-03-06 22:01:26,466 - INFO - validation batch 101, loss: 0.799, 3232/6976 datapoints
2025-03-06 22:01:26,516 - INFO - validation batch 151, loss: 0.991, 4832/6976 datapoints
2025-03-06 22:01:26,576 - INFO - validation batch 201, loss: 0.527, 6432/6976 datapoints
2025-03-06 22:01:26,599 - INFO - Epoch 359/800 done.
2025-03-06 22:01:26,600 - INFO - Final validation performance:
Loss: 1.047, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:01:26,600 - INFO - Beginning epoch 360/800
2025-03-06 22:01:26,604 - INFO - training batch 1, loss: 0.101, 32/28000 datapoints
2025-03-06 22:01:26,764 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 22:01:26,918 - INFO - training batch 101, loss: 0.043, 3232/28000 datapoints
2025-03-06 22:01:27,069 - INFO - training batch 151, loss: 0.089, 4832/28000 datapoints
2025-03-06 22:01:27,218 - INFO - training batch 201, loss: 0.047, 6432/28000 datapoints
2025-03-06 22:01:27,373 - INFO - training batch 251, loss: 0.162, 8032/28000 datapoints
2025-03-06 22:01:27,526 - INFO - training batch 301, loss: 0.122, 9632/28000 datapoints
2025-03-06 22:01:27,675 - INFO - training batch 351, loss: 0.141, 11232/28000 datapoints
2025-03-06 22:01:27,824 - INFO - training batch 401, loss: 0.103, 12832/28000 datapoints
2025-03-06 22:01:27,977 - INFO - training batch 451, loss: 0.228, 14432/28000 datapoints
2025-03-06 22:01:28,127 - INFO - training batch 501, loss: 0.079, 16032/28000 datapoints
2025-03-06 22:01:28,275 - INFO - training batch 551, loss: 0.090, 17632/28000 datapoints
2025-03-06 22:01:28,424 - INFO - training batch 601, loss: 0.056, 19232/28000 datapoints
2025-03-06 22:01:28,579 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:01:28,730 - INFO - training batch 701, loss: 0.049, 22432/28000 datapoints
2025-03-06 22:01:28,887 - INFO - training batch 751, loss: 0.076, 24032/28000 datapoints
2025-03-06 22:01:29,045 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-06 22:01:29,197 - INFO - training batch 851, loss: 0.083, 27232/28000 datapoints
2025-03-06 22:01:29,273 - INFO - validation batch 1, loss: 0.332, 32/6976 datapoints
2025-03-06 22:01:29,325 - INFO - validation batch 51, loss: 2.601, 1632/6976 datapoints
2025-03-06 22:01:29,380 - INFO - validation batch 101, loss: 0.804, 3232/6976 datapoints
2025-03-06 22:01:29,433 - INFO - validation batch 151, loss: 0.996, 4832/6976 datapoints
2025-03-06 22:01:29,487 - INFO - validation batch 201, loss: 0.528, 6432/6976 datapoints
2025-03-06 22:01:29,507 - INFO - Epoch 360/800 done.
2025-03-06 22:01:29,507 - INFO - Final validation performance:
Loss: 1.052, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:01:29,508 - INFO - Beginning epoch 361/800
2025-03-06 22:01:29,512 - INFO - training batch 1, loss: 0.100, 32/28000 datapoints
2025-03-06 22:01:29,668 - INFO - training batch 51, loss: 0.047, 1632/28000 datapoints
2025-03-06 22:01:29,822 - INFO - training batch 101, loss: 0.042, 3232/28000 datapoints
2025-03-06 22:01:29,981 - INFO - training batch 151, loss: 0.088, 4832/28000 datapoints
2025-03-06 22:01:30,135 - INFO - training batch 201, loss: 0.045, 6432/28000 datapoints
2025-03-06 22:01:30,285 - INFO - training batch 251, loss: 0.160, 8032/28000 datapoints
2025-03-06 22:01:30,440 - INFO - training batch 301, loss: 0.120, 9632/28000 datapoints
2025-03-06 22:01:30,594 - INFO - training batch 351, loss: 0.140, 11232/28000 datapoints
2025-03-06 22:01:30,742 - INFO - training batch 401, loss: 0.102, 12832/28000 datapoints
2025-03-06 22:01:30,895 - INFO - training batch 451, loss: 0.224, 14432/28000 datapoints
2025-03-06 22:01:31,068 - INFO - training batch 501, loss: 0.077, 16032/28000 datapoints
2025-03-06 22:01:31,218 - INFO - training batch 551, loss: 0.089, 17632/28000 datapoints
2025-03-06 22:01:31,371 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-06 22:01:31,521 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:01:31,670 - INFO - training batch 701, loss: 0.048, 22432/28000 datapoints
2025-03-06 22:01:31,819 - INFO - training batch 751, loss: 0.076, 24032/28000 datapoints
2025-03-06 22:01:31,971 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-06 22:01:32,122 - INFO - training batch 851, loss: 0.081, 27232/28000 datapoints
2025-03-06 22:01:32,198 - INFO - validation batch 1, loss: 0.336, 32/6976 datapoints
2025-03-06 22:01:32,249 - INFO - validation batch 51, loss: 2.618, 1632/6976 datapoints
2025-03-06 22:01:32,312 - INFO - validation batch 101, loss: 0.807, 3232/6976 datapoints
2025-03-06 22:01:32,367 - INFO - validation batch 151, loss: 1.000, 4832/6976 datapoints
2025-03-06 22:01:32,420 - INFO - validation batch 201, loss: 0.530, 6432/6976 datapoints
2025-03-06 22:01:32,438 - INFO - Epoch 361/800 done.
2025-03-06 22:01:32,438 - INFO - Final validation performance:
Loss: 1.058, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:01:32,439 - INFO - Beginning epoch 362/800
2025-03-06 22:01:32,444 - INFO - training batch 1, loss: 0.099, 32/28000 datapoints
2025-03-06 22:01:32,597 - INFO - training batch 51, loss: 0.047, 1632/28000 datapoints
2025-03-06 22:01:32,742 - INFO - training batch 101, loss: 0.040, 3232/28000 datapoints
2025-03-06 22:01:32,895 - INFO - training batch 151, loss: 0.087, 4832/28000 datapoints
2025-03-06 22:01:33,066 - INFO - training batch 201, loss: 0.045, 6432/28000 datapoints
2025-03-06 22:01:33,211 - INFO - training batch 251, loss: 0.158, 8032/28000 datapoints
2025-03-06 22:01:33,357 - INFO - training batch 301, loss: 0.117, 9632/28000 datapoints
2025-03-06 22:01:33,509 - INFO - training batch 351, loss: 0.139, 11232/28000 datapoints
2025-03-06 22:01:33,656 - INFO - training batch 401, loss: 0.101, 12832/28000 datapoints
2025-03-06 22:01:33,807 - INFO - training batch 451, loss: 0.222, 14432/28000 datapoints
2025-03-06 22:01:33,953 - INFO - training batch 501, loss: 0.077, 16032/28000 datapoints
2025-03-06 22:01:34,102 - INFO - training batch 551, loss: 0.087, 17632/28000 datapoints
2025-03-06 22:01:34,247 - INFO - training batch 601, loss: 0.052, 19232/28000 datapoints
2025-03-06 22:01:34,398 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:01:34,547 - INFO - training batch 701, loss: 0.048, 22432/28000 datapoints
2025-03-06 22:01:34,692 - INFO - training batch 751, loss: 0.075, 24032/28000 datapoints
2025-03-06 22:01:34,837 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-06 22:01:34,985 - INFO - training batch 851, loss: 0.080, 27232/28000 datapoints
2025-03-06 22:01:35,063 - INFO - validation batch 1, loss: 0.342, 32/6976 datapoints
2025-03-06 22:01:35,111 - INFO - validation batch 51, loss: 2.628, 1632/6976 datapoints
2025-03-06 22:01:35,164 - INFO - validation batch 101, loss: 0.813, 3232/6976 datapoints
2025-03-06 22:01:35,210 - INFO - validation batch 151, loss: 1.011, 4832/6976 datapoints
2025-03-06 22:01:35,256 - INFO - validation batch 201, loss: 0.529, 6432/6976 datapoints
2025-03-06 22:01:35,272 - INFO - Epoch 362/800 done.
2025-03-06 22:01:35,272 - INFO - Final validation performance:
Loss: 1.065, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:01:35,273 - INFO - Beginning epoch 363/800
2025-03-06 22:01:35,277 - INFO - training batch 1, loss: 0.097, 32/28000 datapoints
2025-03-06 22:01:35,428 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 22:01:35,576 - INFO - training batch 101, loss: 0.040, 3232/28000 datapoints
2025-03-06 22:01:35,721 - INFO - training batch 151, loss: 0.087, 4832/28000 datapoints
2025-03-06 22:01:35,869 - INFO - training batch 201, loss: 0.045, 6432/28000 datapoints
2025-03-06 22:01:36,014 - INFO - training batch 251, loss: 0.155, 8032/28000 datapoints
2025-03-06 22:01:36,161 - INFO - training batch 301, loss: 0.114, 9632/28000 datapoints
2025-03-06 22:01:36,307 - INFO - training batch 351, loss: 0.138, 11232/28000 datapoints
2025-03-06 22:01:36,453 - INFO - training batch 401, loss: 0.100, 12832/28000 datapoints
2025-03-06 22:01:36,598 - INFO - training batch 451, loss: 0.219, 14432/28000 datapoints
2025-03-06 22:01:36,744 - INFO - training batch 501, loss: 0.076, 16032/28000 datapoints
2025-03-06 22:01:36,892 - INFO - training batch 551, loss: 0.087, 17632/28000 datapoints
2025-03-06 22:01:37,037 - INFO - training batch 601, loss: 0.057, 19232/28000 datapoints
2025-03-06 22:01:37,188 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:01:37,335 - INFO - training batch 701, loss: 0.047, 22432/28000 datapoints
2025-03-06 22:01:37,486 - INFO - training batch 751, loss: 0.075, 24032/28000 datapoints
2025-03-06 22:01:37,634 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-06 22:01:37,779 - INFO - training batch 851, loss: 0.080, 27232/28000 datapoints
2025-03-06 22:01:37,865 - INFO - validation batch 1, loss: 0.346, 32/6976 datapoints
2025-03-06 22:01:37,911 - INFO - validation batch 51, loss: 2.647, 1632/6976 datapoints
2025-03-06 22:01:37,957 - INFO - validation batch 101, loss: 0.815, 3232/6976 datapoints
2025-03-06 22:01:38,003 - INFO - validation batch 151, loss: 1.015, 4832/6976 datapoints
2025-03-06 22:01:38,049 - INFO - validation batch 201, loss: 0.535, 6432/6976 datapoints
2025-03-06 22:01:38,065 - INFO - Epoch 363/800 done.
2025-03-06 22:01:38,065 - INFO - Final validation performance:
Loss: 1.071, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:01:38,066 - INFO - Beginning epoch 364/800
2025-03-06 22:01:38,070 - INFO - training batch 1, loss: 0.097, 32/28000 datapoints
2025-03-06 22:01:38,221 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 22:01:38,370 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-06 22:01:38,517 - INFO - training batch 151, loss: 0.086, 4832/28000 datapoints
2025-03-06 22:01:38,663 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-06 22:01:38,808 - INFO - training batch 251, loss: 0.153, 8032/28000 datapoints
2025-03-06 22:01:38,955 - INFO - training batch 301, loss: 0.111, 9632/28000 datapoints
2025-03-06 22:01:39,101 - INFO - training batch 351, loss: 0.137, 11232/28000 datapoints
2025-03-06 22:01:39,247 - INFO - training batch 401, loss: 0.098, 12832/28000 datapoints
2025-03-06 22:01:39,408 - INFO - training batch 451, loss: 0.216, 14432/28000 datapoints
2025-03-06 22:01:39,555 - INFO - training batch 501, loss: 0.075, 16032/28000 datapoints
2025-03-06 22:01:39,703 - INFO - training batch 551, loss: 0.085, 17632/28000 datapoints
2025-03-06 22:01:39,851 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-06 22:01:39,998 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:01:40,148 - INFO - training batch 701, loss: 0.047, 22432/28000 datapoints
2025-03-06 22:01:40,293 - INFO - training batch 751, loss: 0.074, 24032/28000 datapoints
2025-03-06 22:01:40,439 - INFO - training batch 801, loss: 0.021, 25632/28000 datapoints
2025-03-06 22:01:40,586 - INFO - training batch 851, loss: 0.079, 27232/28000 datapoints
2025-03-06 22:01:40,663 - INFO - validation batch 1, loss: 0.347, 32/6976 datapoints
2025-03-06 22:01:40,713 - INFO - validation batch 51, loss: 2.658, 1632/6976 datapoints
2025-03-06 22:01:40,760 - INFO - validation batch 101, loss: 0.820, 3232/6976 datapoints
2025-03-06 22:01:40,808 - INFO - validation batch 151, loss: 1.020, 4832/6976 datapoints
2025-03-06 22:01:40,861 - INFO - validation batch 201, loss: 0.534, 6432/6976 datapoints
2025-03-06 22:01:40,877 - INFO - Epoch 364/800 done.
2025-03-06 22:01:40,877 - INFO - Final validation performance:
Loss: 1.076, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:01:40,878 - INFO - Beginning epoch 365/800
2025-03-06 22:01:40,882 - INFO - training batch 1, loss: 0.096, 32/28000 datapoints
2025-03-06 22:01:41,033 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 22:01:41,182 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-06 22:01:41,326 - INFO - training batch 151, loss: 0.086, 4832/28000 datapoints
2025-03-06 22:01:41,475 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-06 22:01:41,622 - INFO - training batch 251, loss: 0.151, 8032/28000 datapoints
2025-03-06 22:01:41,766 - INFO - training batch 301, loss: 0.108, 9632/28000 datapoints
2025-03-06 22:01:41,914 - INFO - training batch 351, loss: 0.136, 11232/28000 datapoints
2025-03-06 22:01:42,061 - INFO - training batch 401, loss: 0.096, 12832/28000 datapoints
2025-03-06 22:01:42,214 - INFO - training batch 451, loss: 0.215, 14432/28000 datapoints
2025-03-06 22:01:42,364 - INFO - training batch 501, loss: 0.074, 16032/28000 datapoints
2025-03-06 22:01:42,519 - INFO - training batch 551, loss: 0.084, 17632/28000 datapoints
2025-03-06 22:01:42,668 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 22:01:42,815 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:01:42,966 - INFO - training batch 701, loss: 0.046, 22432/28000 datapoints
2025-03-06 22:01:43,142 - INFO - training batch 751, loss: 0.072, 24032/28000 datapoints
2025-03-06 22:01:43,293 - INFO - training batch 801, loss: 0.021, 25632/28000 datapoints
2025-03-06 22:01:43,443 - INFO - training batch 851, loss: 0.076, 27232/28000 datapoints
2025-03-06 22:01:43,516 - INFO - validation batch 1, loss: 0.351, 32/6976 datapoints
2025-03-06 22:01:43,563 - INFO - validation batch 51, loss: 2.672, 1632/6976 datapoints
2025-03-06 22:01:43,610 - INFO - validation batch 101, loss: 0.823, 3232/6976 datapoints
2025-03-06 22:01:43,661 - INFO - validation batch 151, loss: 1.028, 4832/6976 datapoints
2025-03-06 22:01:43,710 - INFO - validation batch 201, loss: 0.535, 6432/6976 datapoints
2025-03-06 22:01:43,726 - INFO - Epoch 365/800 done.
2025-03-06 22:01:43,726 - INFO - Final validation performance:
Loss: 1.082, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:01:43,727 - INFO - Beginning epoch 366/800
2025-03-06 22:01:43,731 - INFO - training batch 1, loss: 0.094, 32/28000 datapoints
2025-03-06 22:01:43,881 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 22:01:44,026 - INFO - training batch 101, loss: 0.038, 3232/28000 datapoints
2025-03-06 22:01:44,176 - INFO - training batch 151, loss: 0.086, 4832/28000 datapoints
2025-03-06 22:01:44,323 - INFO - training batch 201, loss: 0.043, 6432/28000 datapoints
2025-03-06 22:01:44,473 - INFO - training batch 251, loss: 0.149, 8032/28000 datapoints
2025-03-06 22:01:44,619 - INFO - training batch 301, loss: 0.107, 9632/28000 datapoints
2025-03-06 22:01:44,766 - INFO - training batch 351, loss: 0.135, 11232/28000 datapoints
2025-03-06 22:01:44,914 - INFO - training batch 401, loss: 0.096, 12832/28000 datapoints
2025-03-06 22:01:45,061 - INFO - training batch 451, loss: 0.211, 14432/28000 datapoints
2025-03-06 22:01:45,217 - INFO - training batch 501, loss: 0.074, 16032/28000 datapoints
2025-03-06 22:01:45,366 - INFO - training batch 551, loss: 0.084, 17632/28000 datapoints
2025-03-06 22:01:45,516 - INFO - training batch 601, loss: 0.053, 19232/28000 datapoints
2025-03-06 22:01:45,662 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:01:45,809 - INFO - training batch 701, loss: 0.045, 22432/28000 datapoints
2025-03-06 22:01:45,955 - INFO - training batch 751, loss: 0.073, 24032/28000 datapoints
2025-03-06 22:01:46,100 - INFO - training batch 801, loss: 0.020, 25632/28000 datapoints
2025-03-06 22:01:46,247 - INFO - training batch 851, loss: 0.076, 27232/28000 datapoints
2025-03-06 22:01:46,321 - INFO - validation batch 1, loss: 0.354, 32/6976 datapoints
2025-03-06 22:01:46,367 - INFO - validation batch 51, loss: 2.685, 1632/6976 datapoints
2025-03-06 22:01:46,414 - INFO - validation batch 101, loss: 0.827, 3232/6976 datapoints
2025-03-06 22:01:46,463 - INFO - validation batch 151, loss: 1.035, 4832/6976 datapoints
2025-03-06 22:01:46,511 - INFO - validation batch 201, loss: 0.538, 6432/6976 datapoints
2025-03-06 22:01:46,526 - INFO - Epoch 366/800 done.
2025-03-06 22:01:46,526 - INFO - Final validation performance:
Loss: 1.088, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:01:46,527 - INFO - Beginning epoch 367/800
2025-03-06 22:01:46,531 - INFO - training batch 1, loss: 0.093, 32/28000 datapoints
2025-03-06 22:01:46,692 - INFO - training batch 51, loss: 0.044, 1632/28000 datapoints
2025-03-06 22:01:46,846 - INFO - training batch 101, loss: 0.037, 3232/28000 datapoints
2025-03-06 22:01:46,999 - INFO - training batch 151, loss: 0.085, 4832/28000 datapoints
2025-03-06 22:01:47,147 - INFO - training batch 201, loss: 0.043, 6432/28000 datapoints
2025-03-06 22:01:47,298 - INFO - training batch 251, loss: 0.147, 8032/28000 datapoints
2025-03-06 22:01:47,453 - INFO - training batch 301, loss: 0.104, 9632/28000 datapoints
2025-03-06 22:01:47,602 - INFO - training batch 351, loss: 0.134, 11232/28000 datapoints
2025-03-06 22:01:47,752 - INFO - training batch 401, loss: 0.094, 12832/28000 datapoints
2025-03-06 22:01:47,904 - INFO - training batch 451, loss: 0.209, 14432/28000 datapoints
2025-03-06 22:01:48,055 - INFO - training batch 501, loss: 0.073, 16032/28000 datapoints
2025-03-06 22:01:48,207 - INFO - training batch 551, loss: 0.083, 17632/28000 datapoints
2025-03-06 22:01:48,358 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 22:01:48,507 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:01:48,657 - INFO - training batch 701, loss: 0.045, 22432/28000 datapoints
2025-03-06 22:01:48,806 - INFO - training batch 751, loss: 0.071, 24032/28000 datapoints
2025-03-06 22:01:48,957 - INFO - training batch 801, loss: 0.020, 25632/28000 datapoints
2025-03-06 22:01:49,105 - INFO - training batch 851, loss: 0.075, 27232/28000 datapoints
2025-03-06 22:01:49,178 - INFO - validation batch 1, loss: 0.359, 32/6976 datapoints
2025-03-06 22:01:49,231 - INFO - validation batch 51, loss: 2.701, 1632/6976 datapoints
2025-03-06 22:01:49,284 - INFO - validation batch 101, loss: 0.830, 3232/6976 datapoints
2025-03-06 22:01:49,335 - INFO - validation batch 151, loss: 1.037, 4832/6976 datapoints
2025-03-06 22:01:49,385 - INFO - validation batch 201, loss: 0.539, 6432/6976 datapoints
2025-03-06 22:01:49,406 - INFO - Epoch 367/800 done.
2025-03-06 22:01:49,406 - INFO - Final validation performance:
Loss: 1.093, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:01:49,406 - INFO - Beginning epoch 368/800
2025-03-06 22:01:49,410 - INFO - training batch 1, loss: 0.091, 32/28000 datapoints
2025-03-06 22:01:49,563 - INFO - training batch 51, loss: 0.044, 1632/28000 datapoints
2025-03-06 22:01:49,712 - INFO - training batch 101, loss: 0.037, 3232/28000 datapoints
2025-03-06 22:01:49,869 - INFO - training batch 151, loss: 0.084, 4832/28000 datapoints
2025-03-06 22:01:50,021 - INFO - training batch 201, loss: 0.042, 6432/28000 datapoints
2025-03-06 22:01:50,176 - INFO - training batch 251, loss: 0.145, 8032/28000 datapoints
2025-03-06 22:01:50,332 - INFO - training batch 301, loss: 0.101, 9632/28000 datapoints
2025-03-06 22:01:50,481 - INFO - training batch 351, loss: 0.133, 11232/28000 datapoints
2025-03-06 22:01:50,629 - INFO - training batch 401, loss: 0.093, 12832/28000 datapoints
2025-03-06 22:01:50,782 - INFO - training batch 451, loss: 0.205, 14432/28000 datapoints
2025-03-06 22:01:50,933 - INFO - training batch 501, loss: 0.072, 16032/28000 datapoints
2025-03-06 22:01:51,086 - INFO - training batch 551, loss: 0.081, 17632/28000 datapoints
2025-03-06 22:01:51,236 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 22:01:51,387 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:01:51,541 - INFO - training batch 701, loss: 0.044, 22432/28000 datapoints
2025-03-06 22:01:51,691 - INFO - training batch 751, loss: 0.072, 24032/28000 datapoints
2025-03-06 22:01:51,841 - INFO - training batch 801, loss: 0.019, 25632/28000 datapoints
2025-03-06 22:01:51,993 - INFO - training batch 851, loss: 0.074, 27232/28000 datapoints
2025-03-06 22:01:52,067 - INFO - validation batch 1, loss: 0.363, 32/6976 datapoints
2025-03-06 22:01:52,117 - INFO - validation batch 51, loss: 2.716, 1632/6976 datapoints
2025-03-06 22:01:52,167 - INFO - validation batch 101, loss: 0.833, 3232/6976 datapoints
2025-03-06 22:01:52,218 - INFO - validation batch 151, loss: 1.042, 4832/6976 datapoints
2025-03-06 22:01:52,270 - INFO - validation batch 201, loss: 0.541, 6432/6976 datapoints
2025-03-06 22:01:52,287 - INFO - Epoch 368/800 done.
2025-03-06 22:01:52,287 - INFO - Final validation performance:
Loss: 1.099, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:01:52,288 - INFO - Beginning epoch 369/800
2025-03-06 22:01:52,292 - INFO - training batch 1, loss: 0.091, 32/28000 datapoints
2025-03-06 22:01:52,443 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 22:01:52,586 - INFO - training batch 101, loss: 0.036, 3232/28000 datapoints
2025-03-06 22:01:52,730 - INFO - training batch 151, loss: 0.084, 4832/28000 datapoints
2025-03-06 22:01:52,878 - INFO - training batch 201, loss: 0.042, 6432/28000 datapoints
2025-03-06 22:01:53,023 - INFO - training batch 251, loss: 0.143, 8032/28000 datapoints
2025-03-06 22:01:53,191 - INFO - training batch 301, loss: 0.099, 9632/28000 datapoints
2025-03-06 22:01:53,335 - INFO - training batch 351, loss: 0.132, 11232/28000 datapoints
2025-03-06 22:01:53,484 - INFO - training batch 401, loss: 0.092, 12832/28000 datapoints
2025-03-06 22:01:53,631 - INFO - training batch 451, loss: 0.202, 14432/28000 datapoints
2025-03-06 22:01:53,778 - INFO - training batch 501, loss: 0.072, 16032/28000 datapoints
2025-03-06 22:01:53,930 - INFO - training batch 551, loss: 0.081, 17632/28000 datapoints
2025-03-06 22:01:54,082 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-06 22:01:54,230 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:01:54,383 - INFO - training batch 701, loss: 0.043, 22432/28000 datapoints
2025-03-06 22:01:54,538 - INFO - training batch 751, loss: 0.070, 24032/28000 datapoints
2025-03-06 22:01:54,688 - INFO - training batch 801, loss: 0.019, 25632/28000 datapoints
2025-03-06 22:01:54,839 - INFO - training batch 851, loss: 0.072, 27232/28000 datapoints
2025-03-06 22:01:54,915 - INFO - validation batch 1, loss: 0.365, 32/6976 datapoints
2025-03-06 22:01:54,962 - INFO - validation batch 51, loss: 2.732, 1632/6976 datapoints
2025-03-06 22:01:55,009 - INFO - validation batch 101, loss: 0.836, 3232/6976 datapoints
2025-03-06 22:01:55,059 - INFO - validation batch 151, loss: 1.048, 4832/6976 datapoints
2025-03-06 22:01:55,114 - INFO - validation batch 201, loss: 0.541, 6432/6976 datapoints
2025-03-06 22:01:55,130 - INFO - Epoch 369/800 done.
2025-03-06 22:01:55,130 - INFO - Final validation performance:
Loss: 1.105, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:01:55,131 - INFO - Beginning epoch 370/800
2025-03-06 22:01:55,136 - INFO - training batch 1, loss: 0.089, 32/28000 datapoints
2025-03-06 22:01:55,290 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 22:01:55,438 - INFO - training batch 101, loss: 0.036, 3232/28000 datapoints
2025-03-06 22:01:55,589 - INFO - training batch 151, loss: 0.083, 4832/28000 datapoints
2025-03-06 22:01:55,733 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-06 22:01:55,884 - INFO - training batch 251, loss: 0.140, 8032/28000 datapoints
2025-03-06 22:01:56,030 - INFO - training batch 301, loss: 0.096, 9632/28000 datapoints
2025-03-06 22:01:56,176 - INFO - training batch 351, loss: 0.131, 11232/28000 datapoints
2025-03-06 22:01:56,324 - INFO - training batch 401, loss: 0.091, 12832/28000 datapoints
2025-03-06 22:01:56,470 - INFO - training batch 451, loss: 0.201, 14432/28000 datapoints
2025-03-06 22:01:56,615 - INFO - training batch 501, loss: 0.071, 16032/28000 datapoints
2025-03-06 22:01:56,764 - INFO - training batch 551, loss: 0.079, 17632/28000 datapoints
2025-03-06 22:01:56,913 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 22:01:57,057 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:01:57,205 - INFO - training batch 701, loss: 0.043, 22432/28000 datapoints
2025-03-06 22:01:57,351 - INFO - training batch 751, loss: 0.070, 24032/28000 datapoints
2025-03-06 22:01:57,499 - INFO - training batch 801, loss: 0.019, 25632/28000 datapoints
2025-03-06 22:01:57,644 - INFO - training batch 851, loss: 0.070, 27232/28000 datapoints
2025-03-06 22:01:57,715 - INFO - validation batch 1, loss: 0.372, 32/6976 datapoints
2025-03-06 22:01:57,761 - INFO - validation batch 51, loss: 2.745, 1632/6976 datapoints
2025-03-06 22:01:57,809 - INFO - validation batch 101, loss: 0.839, 3232/6976 datapoints
2025-03-06 22:01:57,858 - INFO - validation batch 151, loss: 1.056, 4832/6976 datapoints
2025-03-06 22:01:57,906 - INFO - validation batch 201, loss: 0.543, 6432/6976 datapoints
2025-03-06 22:01:57,922 - INFO - Epoch 370/800 done.
2025-03-06 22:01:57,922 - INFO - Final validation performance:
Loss: 1.111, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:01:57,923 - INFO - Beginning epoch 371/800
2025-03-06 22:01:57,927 - INFO - training batch 1, loss: 0.087, 32/28000 datapoints
2025-03-06 22:01:58,075 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 22:01:58,219 - INFO - training batch 101, loss: 0.035, 3232/28000 datapoints
2025-03-06 22:01:58,369 - INFO - training batch 151, loss: 0.082, 4832/28000 datapoints
2025-03-06 22:01:58,513 - INFO - training batch 201, loss: 0.040, 6432/28000 datapoints
2025-03-06 22:01:58,659 - INFO - training batch 251, loss: 0.138, 8032/28000 datapoints
2025-03-06 22:01:58,806 - INFO - training batch 301, loss: 0.095, 9632/28000 datapoints
2025-03-06 22:01:58,955 - INFO - training batch 351, loss: 0.129, 11232/28000 datapoints
2025-03-06 22:01:59,100 - INFO - training batch 401, loss: 0.089, 12832/28000 datapoints
2025-03-06 22:01:59,244 - INFO - training batch 451, loss: 0.198, 14432/28000 datapoints
2025-03-06 22:01:59,392 - INFO - training batch 501, loss: 0.070, 16032/28000 datapoints
2025-03-06 22:01:59,542 - INFO - training batch 551, loss: 0.079, 17632/28000 datapoints
2025-03-06 22:01:59,690 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 22:01:59,835 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:01:59,985 - INFO - training batch 701, loss: 0.042, 22432/28000 datapoints
2025-03-06 22:02:00,131 - INFO - training batch 751, loss: 0.070, 24032/28000 datapoints
2025-03-06 22:02:00,277 - INFO - training batch 801, loss: 0.018, 25632/28000 datapoints
2025-03-06 22:02:00,426 - INFO - training batch 851, loss: 0.070, 27232/28000 datapoints
2025-03-06 22:02:00,499 - INFO - validation batch 1, loss: 0.372, 32/6976 datapoints
2025-03-06 22:02:00,546 - INFO - validation batch 51, loss: 2.763, 1632/6976 datapoints
2025-03-06 22:02:00,593 - INFO - validation batch 101, loss: 0.842, 3232/6976 datapoints
2025-03-06 22:02:00,640 - INFO - validation batch 151, loss: 1.059, 4832/6976 datapoints
2025-03-06 22:02:00,686 - INFO - validation batch 201, loss: 0.545, 6432/6976 datapoints
2025-03-06 22:02:00,702 - INFO - Epoch 371/800 done.
2025-03-06 22:02:00,703 - INFO - Final validation performance:
Loss: 1.116, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:02:00,703 - INFO - Beginning epoch 372/800
2025-03-06 22:02:00,707 - INFO - training batch 1, loss: 0.087, 32/28000 datapoints
2025-03-06 22:02:00,859 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:02:01,003 - INFO - training batch 101, loss: 0.034, 3232/28000 datapoints
2025-03-06 22:02:01,148 - INFO - training batch 151, loss: 0.081, 4832/28000 datapoints
2025-03-06 22:02:01,294 - INFO - training batch 201, loss: 0.040, 6432/28000 datapoints
2025-03-06 22:02:01,440 - INFO - training batch 251, loss: 0.136, 8032/28000 datapoints
2025-03-06 22:02:01,589 - INFO - training batch 301, loss: 0.092, 9632/28000 datapoints
2025-03-06 22:02:01,733 - INFO - training batch 351, loss: 0.129, 11232/28000 datapoints
2025-03-06 22:02:01,880 - INFO - training batch 401, loss: 0.087, 12832/28000 datapoints
2025-03-06 22:02:02,028 - INFO - training batch 451, loss: 0.196, 14432/28000 datapoints
2025-03-06 22:02:02,174 - INFO - training batch 501, loss: 0.069, 16032/28000 datapoints
2025-03-06 22:02:02,319 - INFO - training batch 551, loss: 0.077, 17632/28000 datapoints
2025-03-06 22:02:02,468 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 22:02:02,615 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:02:02,766 - INFO - training batch 701, loss: 0.042, 22432/28000 datapoints
2025-03-06 22:02:02,914 - INFO - training batch 751, loss: 0.069, 24032/28000 datapoints
2025-03-06 22:02:03,058 - INFO - training batch 801, loss: 0.018, 25632/28000 datapoints
2025-03-06 22:02:03,207 - INFO - training batch 851, loss: 0.069, 27232/28000 datapoints
2025-03-06 22:02:03,298 - INFO - validation batch 1, loss: 0.374, 32/6976 datapoints
2025-03-06 22:02:03,344 - INFO - validation batch 51, loss: 2.773, 1632/6976 datapoints
2025-03-06 22:02:03,392 - INFO - validation batch 101, loss: 0.848, 3232/6976 datapoints
2025-03-06 22:02:03,438 - INFO - validation batch 151, loss: 1.067, 4832/6976 datapoints
2025-03-06 22:02:03,484 - INFO - validation batch 201, loss: 0.546, 6432/6976 datapoints
2025-03-06 22:02:03,504 - INFO - Epoch 372/800 done.
2025-03-06 22:02:03,504 - INFO - Final validation performance:
Loss: 1.121, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:02:03,505 - INFO - Beginning epoch 373/800
2025-03-06 22:02:03,509 - INFO - training batch 1, loss: 0.086, 32/28000 datapoints
2025-03-06 22:02:03,662 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 22:02:03,806 - INFO - training batch 101, loss: 0.033, 3232/28000 datapoints
2025-03-06 22:02:03,955 - INFO - training batch 151, loss: 0.082, 4832/28000 datapoints
2025-03-06 22:02:04,101 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-06 22:02:04,246 - INFO - training batch 251, loss: 0.133, 8032/28000 datapoints
2025-03-06 22:02:04,392 - INFO - training batch 301, loss: 0.091, 9632/28000 datapoints
2025-03-06 22:02:04,541 - INFO - training batch 351, loss: 0.127, 11232/28000 datapoints
2025-03-06 22:02:04,687 - INFO - training batch 401, loss: 0.086, 12832/28000 datapoints
2025-03-06 22:02:04,833 - INFO - training batch 451, loss: 0.193, 14432/28000 datapoints
2025-03-06 22:02:04,982 - INFO - training batch 501, loss: 0.068, 16032/28000 datapoints
2025-03-06 22:02:05,133 - INFO - training batch 551, loss: 0.078, 17632/28000 datapoints
2025-03-06 22:02:05,279 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 22:02:05,424 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:02:05,575 - INFO - training batch 701, loss: 0.041, 22432/28000 datapoints
2025-03-06 22:02:05,720 - INFO - training batch 751, loss: 0.069, 24032/28000 datapoints
2025-03-06 22:02:05,870 - INFO - training batch 801, loss: 0.018, 25632/28000 datapoints
2025-03-06 22:02:06,021 - INFO - training batch 851, loss: 0.067, 27232/28000 datapoints
2025-03-06 22:02:06,093 - INFO - validation batch 1, loss: 0.380, 32/6976 datapoints
2025-03-06 22:02:06,140 - INFO - validation batch 51, loss: 2.791, 1632/6976 datapoints
2025-03-06 22:02:06,188 - INFO - validation batch 101, loss: 0.850, 3232/6976 datapoints
2025-03-06 22:02:06,237 - INFO - validation batch 151, loss: 1.072, 4832/6976 datapoints
2025-03-06 22:02:06,283 - INFO - validation batch 201, loss: 0.547, 6432/6976 datapoints
2025-03-06 22:02:06,298 - INFO - Epoch 373/800 done.
2025-03-06 22:02:06,299 - INFO - Final validation performance:
Loss: 1.128, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:02:06,299 - INFO - Beginning epoch 374/800
2025-03-06 22:02:06,303 - INFO - training batch 1, loss: 0.084, 32/28000 datapoints
2025-03-06 22:02:06,454 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 22:02:06,598 - INFO - training batch 101, loss: 0.033, 3232/28000 datapoints
2025-03-06 22:02:06,759 - INFO - training batch 151, loss: 0.081, 4832/28000 datapoints
2025-03-06 22:02:06,912 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-06 22:02:07,059 - INFO - training batch 251, loss: 0.133, 8032/28000 datapoints
2025-03-06 22:02:07,207 - INFO - training batch 301, loss: 0.089, 9632/28000 datapoints
2025-03-06 22:02:07,355 - INFO - training batch 351, loss: 0.126, 11232/28000 datapoints
2025-03-06 22:02:07,506 - INFO - training batch 401, loss: 0.085, 12832/28000 datapoints
2025-03-06 22:02:07,661 - INFO - training batch 451, loss: 0.190, 14432/28000 datapoints
2025-03-06 22:02:07,811 - INFO - training batch 501, loss: 0.067, 16032/28000 datapoints
2025-03-06 22:02:07,965 - INFO - training batch 551, loss: 0.077, 17632/28000 datapoints
2025-03-06 22:02:08,115 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 22:02:08,265 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:02:08,416 - INFO - training batch 701, loss: 0.041, 22432/28000 datapoints
2025-03-06 22:02:08,567 - INFO - training batch 751, loss: 0.067, 24032/28000 datapoints
2025-03-06 22:02:08,716 - INFO - training batch 801, loss: 0.017, 25632/28000 datapoints
2025-03-06 22:02:08,869 - INFO - training batch 851, loss: 0.068, 27232/28000 datapoints
2025-03-06 22:02:08,947 - INFO - validation batch 1, loss: 0.380, 32/6976 datapoints
2025-03-06 22:02:08,999 - INFO - validation batch 51, loss: 2.806, 1632/6976 datapoints
2025-03-06 22:02:09,048 - INFO - validation batch 101, loss: 0.852, 3232/6976 datapoints
2025-03-06 22:02:09,098 - INFO - validation batch 151, loss: 1.077, 4832/6976 datapoints
2025-03-06 22:02:09,148 - INFO - validation batch 201, loss: 0.550, 6432/6976 datapoints
2025-03-06 22:02:09,163 - INFO - Epoch 374/800 done.
2025-03-06 22:02:09,164 - INFO - Final validation performance:
Loss: 1.133, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:02:09,164 - INFO - Beginning epoch 375/800
2025-03-06 22:02:09,168 - INFO - training batch 1, loss: 0.084, 32/28000 datapoints
2025-03-06 22:02:09,327 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 22:02:09,473 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 22:02:09,623 - INFO - training batch 151, loss: 0.080, 4832/28000 datapoints
2025-03-06 22:02:09,769 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-06 22:02:09,916 - INFO - training batch 251, loss: 0.129, 8032/28000 datapoints
2025-03-06 22:02:10,062 - INFO - training batch 301, loss: 0.088, 9632/28000 datapoints
2025-03-06 22:02:10,206 - INFO - training batch 351, loss: 0.126, 11232/28000 datapoints
2025-03-06 22:02:10,351 - INFO - training batch 401, loss: 0.084, 12832/28000 datapoints
2025-03-06 22:02:10,496 - INFO - training batch 451, loss: 0.187, 14432/28000 datapoints
2025-03-06 22:02:10,642 - INFO - training batch 501, loss: 0.067, 16032/28000 datapoints
2025-03-06 22:02:10,787 - INFO - training batch 551, loss: 0.075, 17632/28000 datapoints
2025-03-06 22:02:10,938 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 22:02:11,088 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:02:11,237 - INFO - training batch 701, loss: 0.041, 22432/28000 datapoints
2025-03-06 22:02:11,385 - INFO - training batch 751, loss: 0.066, 24032/28000 datapoints
2025-03-06 22:02:11,540 - INFO - training batch 801, loss: 0.017, 25632/28000 datapoints
2025-03-06 22:02:11,689 - INFO - training batch 851, loss: 0.066, 27232/28000 datapoints
2025-03-06 22:02:11,764 - INFO - validation batch 1, loss: 0.384, 32/6976 datapoints
2025-03-06 22:02:11,810 - INFO - validation batch 51, loss: 2.821, 1632/6976 datapoints
2025-03-06 22:02:11,860 - INFO - validation batch 101, loss: 0.856, 3232/6976 datapoints
2025-03-06 22:02:11,906 - INFO - validation batch 151, loss: 1.084, 4832/6976 datapoints
2025-03-06 22:02:11,953 - INFO - validation batch 201, loss: 0.551, 6432/6976 datapoints
2025-03-06 22:02:11,971 - INFO - Epoch 375/800 done.
2025-03-06 22:02:11,972 - INFO - Final validation performance:
Loss: 1.139, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:02:11,972 - INFO - Beginning epoch 376/800
2025-03-06 22:02:11,977 - INFO - training batch 1, loss: 0.083, 32/28000 datapoints
2025-03-06 22:02:12,130 - INFO - training batch 51, loss: 0.039, 1632/28000 datapoints
2025-03-06 22:02:12,277 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 22:02:12,427 - INFO - training batch 151, loss: 0.080, 4832/28000 datapoints
2025-03-06 22:02:12,578 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-06 22:02:12,723 - INFO - training batch 251, loss: 0.127, 8032/28000 datapoints
2025-03-06 22:02:12,872 - INFO - training batch 301, loss: 0.086, 9632/28000 datapoints
2025-03-06 22:02:13,019 - INFO - training batch 351, loss: 0.124, 11232/28000 datapoints
2025-03-06 22:02:13,184 - INFO - training batch 401, loss: 0.083, 12832/28000 datapoints
2025-03-06 22:02:13,345 - INFO - training batch 451, loss: 0.185, 14432/28000 datapoints
2025-03-06 22:02:13,498 - INFO - training batch 501, loss: 0.066, 16032/28000 datapoints
2025-03-06 22:02:13,647 - INFO - training batch 551, loss: 0.075, 17632/28000 datapoints
2025-03-06 22:02:13,793 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 22:02:13,940 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:02:14,090 - INFO - training batch 701, loss: 0.039, 22432/28000 datapoints
2025-03-06 22:02:14,237 - INFO - training batch 751, loss: 0.066, 24032/28000 datapoints
2025-03-06 22:02:14,382 - INFO - training batch 801, loss: 0.017, 25632/28000 datapoints
2025-03-06 22:02:14,532 - INFO - training batch 851, loss: 0.064, 27232/28000 datapoints
2025-03-06 22:02:14,604 - INFO - validation batch 1, loss: 0.390, 32/6976 datapoints
2025-03-06 22:02:14,651 - INFO - validation batch 51, loss: 2.834, 1632/6976 datapoints
2025-03-06 22:02:14,698 - INFO - validation batch 101, loss: 0.859, 3232/6976 datapoints
2025-03-06 22:02:14,747 - INFO - validation batch 151, loss: 1.090, 4832/6976 datapoints
2025-03-06 22:02:14,793 - INFO - validation batch 201, loss: 0.552, 6432/6976 datapoints
2025-03-06 22:02:14,809 - INFO - Epoch 376/800 done.
2025-03-06 22:02:14,809 - INFO - Final validation performance:
Loss: 1.145, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:02:14,809 - INFO - Beginning epoch 377/800
2025-03-06 22:02:14,813 - INFO - training batch 1, loss: 0.081, 32/28000 datapoints
2025-03-06 22:02:14,965 - INFO - training batch 51, loss: 0.039, 1632/28000 datapoints
2025-03-06 22:02:15,119 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 22:02:15,264 - INFO - training batch 151, loss: 0.079, 4832/28000 datapoints
2025-03-06 22:02:15,409 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-06 22:02:15,562 - INFO - training batch 251, loss: 0.125, 8032/28000 datapoints
2025-03-06 22:02:15,711 - INFO - training batch 301, loss: 0.083, 9632/28000 datapoints
2025-03-06 22:02:15,858 - INFO - training batch 351, loss: 0.122, 11232/28000 datapoints
2025-03-06 22:02:16,006 - INFO - training batch 401, loss: 0.081, 12832/28000 datapoints
2025-03-06 22:02:16,153 - INFO - training batch 451, loss: 0.183, 14432/28000 datapoints
2025-03-06 22:02:16,299 - INFO - training batch 501, loss: 0.065, 16032/28000 datapoints
2025-03-06 22:02:16,443 - INFO - training batch 551, loss: 0.074, 17632/28000 datapoints
2025-03-06 22:02:16,590 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-06 22:02:16,735 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:02:16,891 - INFO - training batch 701, loss: 0.038, 22432/28000 datapoints
2025-03-06 22:02:17,047 - INFO - training batch 751, loss: 0.066, 24032/28000 datapoints
2025-03-06 22:02:17,193 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-06 22:02:17,337 - INFO - training batch 851, loss: 0.064, 27232/28000 datapoints
2025-03-06 22:02:17,408 - INFO - validation batch 1, loss: 0.388, 32/6976 datapoints
2025-03-06 22:02:17,456 - INFO - validation batch 51, loss: 2.851, 1632/6976 datapoints
2025-03-06 22:02:17,502 - INFO - validation batch 101, loss: 0.860, 3232/6976 datapoints
2025-03-06 22:02:17,551 - INFO - validation batch 151, loss: 1.095, 4832/6976 datapoints
2025-03-06 22:02:17,600 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 22:02:17,616 - INFO - Epoch 377/800 done.
2025-03-06 22:02:17,616 - INFO - Final validation performance:
Loss: 1.150, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:02:17,617 - INFO - Beginning epoch 378/800
2025-03-06 22:02:17,621 - INFO - training batch 1, loss: 0.081, 32/28000 datapoints
2025-03-06 22:02:17,773 - INFO - training batch 51, loss: 0.038, 1632/28000 datapoints
2025-03-06 22:02:17,926 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-06 22:02:18,150 - INFO - training batch 151, loss: 0.078, 4832/28000 datapoints
2025-03-06 22:02:18,296 - INFO - training batch 201, loss: 0.036, 6432/28000 datapoints
2025-03-06 22:02:18,440 - INFO - training batch 251, loss: 0.123, 8032/28000 datapoints
2025-03-06 22:02:18,587 - INFO - training batch 301, loss: 0.082, 9632/28000 datapoints
2025-03-06 22:02:18,734 - INFO - training batch 351, loss: 0.122, 11232/28000 datapoints
2025-03-06 22:02:18,881 - INFO - training batch 401, loss: 0.080, 12832/28000 datapoints
2025-03-06 22:02:19,027 - INFO - training batch 451, loss: 0.179, 14432/28000 datapoints
2025-03-06 22:02:19,173 - INFO - training batch 501, loss: 0.064, 16032/28000 datapoints
2025-03-06 22:02:19,319 - INFO - training batch 551, loss: 0.072, 17632/28000 datapoints
2025-03-06 22:02:19,465 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-06 22:02:19,615 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:02:19,765 - INFO - training batch 701, loss: 0.038, 22432/28000 datapoints
2025-03-06 22:02:19,913 - INFO - training batch 751, loss: 0.065, 24032/28000 datapoints
2025-03-06 22:02:20,058 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-06 22:02:20,204 - INFO - training batch 851, loss: 0.063, 27232/28000 datapoints
2025-03-06 22:02:20,276 - INFO - validation batch 1, loss: 0.394, 32/6976 datapoints
2025-03-06 22:02:20,322 - INFO - validation batch 51, loss: 2.865, 1632/6976 datapoints
2025-03-06 22:02:20,368 - INFO - validation batch 101, loss: 0.864, 3232/6976 datapoints
2025-03-06 22:02:20,417 - INFO - validation batch 151, loss: 1.101, 4832/6976 datapoints
2025-03-06 22:02:20,466 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 22:02:20,482 - INFO - Epoch 378/800 done.
2025-03-06 22:02:20,482 - INFO - Final validation performance:
Loss: 1.156, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:02:20,483 - INFO - Beginning epoch 379/800
2025-03-06 22:02:20,486 - INFO - training batch 1, loss: 0.079, 32/28000 datapoints
2025-03-06 22:02:20,636 - INFO - training batch 51, loss: 0.037, 1632/28000 datapoints
2025-03-06 22:02:20,781 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-06 22:02:20,932 - INFO - training batch 151, loss: 0.078, 4832/28000 datapoints
2025-03-06 22:02:21,091 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-06 22:02:21,236 - INFO - training batch 251, loss: 0.121, 8032/28000 datapoints
2025-03-06 22:02:21,381 - INFO - training batch 301, loss: 0.082, 9632/28000 datapoints
2025-03-06 22:02:21,527 - INFO - training batch 351, loss: 0.120, 11232/28000 datapoints
2025-03-06 22:02:21,676 - INFO - training batch 401, loss: 0.079, 12832/28000 datapoints
2025-03-06 22:02:21,822 - INFO - training batch 451, loss: 0.177, 14432/28000 datapoints
2025-03-06 22:02:21,972 - INFO - training batch 501, loss: 0.063, 16032/28000 datapoints
2025-03-06 22:02:22,119 - INFO - training batch 551, loss: 0.071, 17632/28000 datapoints
2025-03-06 22:02:22,266 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-06 22:02:22,415 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:02:22,567 - INFO - training batch 701, loss: 0.038, 22432/28000 datapoints
2025-03-06 22:02:22,717 - INFO - training batch 751, loss: 0.064, 24032/28000 datapoints
2025-03-06 22:02:22,868 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-06 22:02:23,017 - INFO - training batch 851, loss: 0.061, 27232/28000 datapoints
2025-03-06 22:02:23,092 - INFO - validation batch 1, loss: 0.401, 32/6976 datapoints
2025-03-06 22:02:23,138 - INFO - validation batch 51, loss: 2.874, 1632/6976 datapoints
2025-03-06 22:02:23,185 - INFO - validation batch 101, loss: 0.869, 3232/6976 datapoints
2025-03-06 22:02:23,233 - INFO - validation batch 151, loss: 1.113, 4832/6976 datapoints
2025-03-06 22:02:23,280 - INFO - validation batch 201, loss: 0.558, 6432/6976 datapoints
2025-03-06 22:02:23,296 - INFO - Epoch 379/800 done.
2025-03-06 22:02:23,296 - INFO - Final validation performance:
Loss: 1.163, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:02:23,297 - INFO - Beginning epoch 380/800
2025-03-06 22:02:23,301 - INFO - training batch 1, loss: 0.078, 32/28000 datapoints
2025-03-06 22:02:23,498 - INFO - training batch 51, loss: 0.037, 1632/28000 datapoints
2025-03-06 22:02:23,653 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-06 22:02:23,806 - INFO - training batch 151, loss: 0.078, 4832/28000 datapoints
2025-03-06 22:02:23,960 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 22:02:24,109 - INFO - training batch 251, loss: 0.119, 8032/28000 datapoints
2025-03-06 22:02:24,257 - INFO - training batch 301, loss: 0.080, 9632/28000 datapoints
2025-03-06 22:02:24,403 - INFO - training batch 351, loss: 0.119, 11232/28000 datapoints
2025-03-06 22:02:24,552 - INFO - training batch 401, loss: 0.077, 12832/28000 datapoints
2025-03-06 22:02:24,697 - INFO - training batch 451, loss: 0.175, 14432/28000 datapoints
2025-03-06 22:02:24,846 - INFO - training batch 501, loss: 0.063, 16032/28000 datapoints
2025-03-06 22:02:24,993 - INFO - training batch 551, loss: 0.070, 17632/28000 datapoints
2025-03-06 22:02:25,148 - INFO - training batch 601, loss: 0.044, 19232/28000 datapoints
2025-03-06 22:02:25,292 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:02:25,439 - INFO - training batch 701, loss: 0.037, 22432/28000 datapoints
2025-03-06 22:02:25,585 - INFO - training batch 751, loss: 0.064, 24032/28000 datapoints
2025-03-06 22:02:25,735 - INFO - training batch 801, loss: 0.015, 25632/28000 datapoints
2025-03-06 22:02:25,883 - INFO - training batch 851, loss: 0.060, 27232/28000 datapoints
2025-03-06 22:02:25,960 - INFO - validation batch 1, loss: 0.403, 32/6976 datapoints
2025-03-06 22:02:26,008 - INFO - validation batch 51, loss: 2.896, 1632/6976 datapoints
2025-03-06 22:02:26,055 - INFO - validation batch 101, loss: 0.870, 3232/6976 datapoints
2025-03-06 22:02:26,102 - INFO - validation batch 151, loss: 1.115, 4832/6976 datapoints
2025-03-06 22:02:26,149 - INFO - validation batch 201, loss: 0.560, 6432/6976 datapoints
2025-03-06 22:02:26,165 - INFO - Epoch 380/800 done.
2025-03-06 22:02:26,165 - INFO - Final validation performance:
Loss: 1.169, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:02:26,166 - INFO - Beginning epoch 381/800
2025-03-06 22:02:26,170 - INFO - training batch 1, loss: 0.077, 32/28000 datapoints
2025-03-06 22:02:26,321 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-06 22:02:26,465 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 22:02:26,609 - INFO - training batch 151, loss: 0.077, 4832/28000 datapoints
2025-03-06 22:02:26,769 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 22:02:26,927 - INFO - training batch 251, loss: 0.118, 8032/28000 datapoints
2025-03-06 22:02:27,077 - INFO - training batch 301, loss: 0.078, 9632/28000 datapoints
2025-03-06 22:02:27,227 - INFO - training batch 351, loss: 0.117, 11232/28000 datapoints
2025-03-06 22:02:27,376 - INFO - training batch 401, loss: 0.076, 12832/28000 datapoints
2025-03-06 22:02:27,527 - INFO - training batch 451, loss: 0.172, 14432/28000 datapoints
2025-03-06 22:02:27,682 - INFO - training batch 501, loss: 0.062, 16032/28000 datapoints
2025-03-06 22:02:27,831 - INFO - training batch 551, loss: 0.069, 17632/28000 datapoints
2025-03-06 22:02:27,986 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-06 22:02:28,133 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:02:28,286 - INFO - training batch 701, loss: 0.036, 22432/28000 datapoints
2025-03-06 22:02:28,434 - INFO - training batch 751, loss: 0.062, 24032/28000 datapoints
2025-03-06 22:02:28,582 - INFO - training batch 801, loss: 0.015, 25632/28000 datapoints
2025-03-06 22:02:28,733 - INFO - training batch 851, loss: 0.060, 27232/28000 datapoints
2025-03-06 22:02:28,810 - INFO - validation batch 1, loss: 0.402, 32/6976 datapoints
2025-03-06 22:02:28,863 - INFO - validation batch 51, loss: 2.915, 1632/6976 datapoints
2025-03-06 22:02:28,914 - INFO - validation batch 101, loss: 0.871, 3232/6976 datapoints
2025-03-06 22:02:28,964 - INFO - validation batch 151, loss: 1.120, 4832/6976 datapoints
2025-03-06 22:02:29,016 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 22:02:29,032 - INFO - Epoch 381/800 done.
2025-03-06 22:02:29,032 - INFO - Final validation performance:
Loss: 1.174, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:02:29,033 - INFO - Beginning epoch 382/800
2025-03-06 22:02:29,038 - INFO - training batch 1, loss: 0.077, 32/28000 datapoints
2025-03-06 22:02:29,192 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-06 22:02:29,336 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 22:02:29,481 - INFO - training batch 151, loss: 0.077, 4832/28000 datapoints
2025-03-06 22:02:29,631 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 22:02:29,781 - INFO - training batch 251, loss: 0.116, 8032/28000 datapoints
2025-03-06 22:02:29,927 - INFO - training batch 301, loss: 0.078, 9632/28000 datapoints
2025-03-06 22:02:30,073 - INFO - training batch 351, loss: 0.117, 11232/28000 datapoints
2025-03-06 22:02:30,221 - INFO - training batch 401, loss: 0.075, 12832/28000 datapoints
2025-03-06 22:02:30,366 - INFO - training batch 451, loss: 0.169, 14432/28000 datapoints
2025-03-06 22:02:30,511 - INFO - training batch 501, loss: 0.061, 16032/28000 datapoints
2025-03-06 22:02:30,659 - INFO - training batch 551, loss: 0.069, 17632/28000 datapoints
2025-03-06 22:02:30,814 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-06 22:02:30,963 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:02:31,113 - INFO - training batch 701, loss: 0.035, 22432/28000 datapoints
2025-03-06 22:02:31,263 - INFO - training batch 751, loss: 0.063, 24032/28000 datapoints
2025-03-06 22:02:31,407 - INFO - training batch 801, loss: 0.015, 25632/28000 datapoints
2025-03-06 22:02:31,554 - INFO - training batch 851, loss: 0.060, 27232/28000 datapoints
2025-03-06 22:02:31,628 - INFO - validation batch 1, loss: 0.404, 32/6976 datapoints
2025-03-06 22:02:31,674 - INFO - validation batch 51, loss: 2.925, 1632/6976 datapoints
2025-03-06 22:02:31,723 - INFO - validation batch 101, loss: 0.875, 3232/6976 datapoints
2025-03-06 22:02:31,770 - INFO - validation batch 151, loss: 1.128, 4832/6976 datapoints
2025-03-06 22:02:31,816 - INFO - validation batch 201, loss: 0.563, 6432/6976 datapoints
2025-03-06 22:02:31,832 - INFO - Epoch 382/800 done.
2025-03-06 22:02:31,832 - INFO - Final validation performance:
Loss: 1.179, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:02:31,833 - INFO - Beginning epoch 383/800
2025-03-06 22:02:31,837 - INFO - training batch 1, loss: 0.076, 32/28000 datapoints
2025-03-06 22:02:31,987 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-06 22:02:32,134 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 22:02:32,281 - INFO - training batch 151, loss: 0.076, 4832/28000 datapoints
2025-03-06 22:02:32,426 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-06 22:02:32,573 - INFO - training batch 251, loss: 0.113, 8032/28000 datapoints
2025-03-06 22:02:32,718 - INFO - training batch 301, loss: 0.074, 9632/28000 datapoints
2025-03-06 22:02:32,868 - INFO - training batch 351, loss: 0.115, 11232/28000 datapoints
2025-03-06 22:02:33,019 - INFO - training batch 401, loss: 0.074, 12832/28000 datapoints
2025-03-06 22:02:33,164 - INFO - training batch 451, loss: 0.167, 14432/28000 datapoints
2025-03-06 22:02:33,312 - INFO - training batch 501, loss: 0.060, 16032/28000 datapoints
2025-03-06 22:02:33,457 - INFO - training batch 551, loss: 0.069, 17632/28000 datapoints
2025-03-06 22:02:33,626 - INFO - training batch 601, loss: 0.040, 19232/28000 datapoints
2025-03-06 22:02:33,777 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:02:33,927 - INFO - training batch 701, loss: 0.035, 22432/28000 datapoints
2025-03-06 22:02:34,073 - INFO - training batch 751, loss: 0.062, 24032/28000 datapoints
2025-03-06 22:02:34,218 - INFO - training batch 801, loss: 0.015, 25632/28000 datapoints
2025-03-06 22:02:34,372 - INFO - training batch 851, loss: 0.058, 27232/28000 datapoints
2025-03-06 22:02:34,445 - INFO - validation batch 1, loss: 0.410, 32/6976 datapoints
2025-03-06 22:02:34,499 - INFO - validation batch 51, loss: 2.941, 1632/6976 datapoints
2025-03-06 22:02:34,547 - INFO - validation batch 101, loss: 0.878, 3232/6976 datapoints
2025-03-06 22:02:34,594 - INFO - validation batch 151, loss: 1.135, 4832/6976 datapoints
2025-03-06 22:02:34,641 - INFO - validation batch 201, loss: 0.562, 6432/6976 datapoints
2025-03-06 22:02:34,657 - INFO - Epoch 383/800 done.
2025-03-06 22:02:34,657 - INFO - Final validation performance:
Loss: 1.185, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:02:34,658 - INFO - Beginning epoch 384/800
2025-03-06 22:02:34,661 - INFO - training batch 1, loss: 0.073, 32/28000 datapoints
2025-03-06 22:02:34,814 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-06 22:02:34,963 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 22:02:35,116 - INFO - training batch 151, loss: 0.075, 4832/28000 datapoints
2025-03-06 22:02:35,263 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-06 22:02:35,411 - INFO - training batch 251, loss: 0.112, 8032/28000 datapoints
2025-03-06 22:02:35,558 - INFO - training batch 301, loss: 0.075, 9632/28000 datapoints
2025-03-06 22:02:35,707 - INFO - training batch 351, loss: 0.114, 11232/28000 datapoints
2025-03-06 22:02:35,858 - INFO - training batch 401, loss: 0.073, 12832/28000 datapoints
2025-03-06 22:02:36,006 - INFO - training batch 451, loss: 0.164, 14432/28000 datapoints
2025-03-06 22:02:36,151 - INFO - training batch 501, loss: 0.060, 16032/28000 datapoints
2025-03-06 22:02:36,304 - INFO - training batch 551, loss: 0.067, 17632/28000 datapoints
2025-03-06 22:02:36,451 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-06 22:02:36,597 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:02:36,745 - INFO - training batch 701, loss: 0.034, 22432/28000 datapoints
2025-03-06 22:02:36,896 - INFO - training batch 751, loss: 0.061, 24032/28000 datapoints
2025-03-06 22:02:37,041 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-06 22:02:37,188 - INFO - training batch 851, loss: 0.058, 27232/28000 datapoints
2025-03-06 22:02:37,262 - INFO - validation batch 1, loss: 0.413, 32/6976 datapoints
2025-03-06 22:02:37,309 - INFO - validation batch 51, loss: 2.957, 1632/6976 datapoints
2025-03-06 22:02:37,356 - INFO - validation batch 101, loss: 0.880, 3232/6976 datapoints
2025-03-06 22:02:37,403 - INFO - validation batch 151, loss: 1.140, 4832/6976 datapoints
2025-03-06 22:02:37,449 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 22:02:37,466 - INFO - Epoch 384/800 done.
2025-03-06 22:02:37,466 - INFO - Final validation performance:
Loss: 1.191, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:02:37,467 - INFO - Beginning epoch 385/800
2025-03-06 22:02:37,471 - INFO - training batch 1, loss: 0.074, 32/28000 datapoints
2025-03-06 22:02:37,625 - INFO - training batch 51, loss: 0.034, 1632/28000 datapoints
2025-03-06 22:02:37,779 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 22:02:37,942 - INFO - training batch 151, loss: 0.075, 4832/28000 datapoints
2025-03-06 22:02:38,092 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 22:02:38,241 - INFO - training batch 251, loss: 0.109, 8032/28000 datapoints
2025-03-06 22:02:38,393 - INFO - training batch 301, loss: 0.072, 9632/28000 datapoints
2025-03-06 22:02:38,541 - INFO - training batch 351, loss: 0.113, 11232/28000 datapoints
2025-03-06 22:02:38,689 - INFO - training batch 401, loss: 0.071, 12832/28000 datapoints
2025-03-06 22:02:38,837 - INFO - training batch 451, loss: 0.161, 14432/28000 datapoints
2025-03-06 22:02:38,984 - INFO - training batch 501, loss: 0.059, 16032/28000 datapoints
2025-03-06 22:02:39,133 - INFO - training batch 551, loss: 0.065, 17632/28000 datapoints
2025-03-06 22:02:39,286 - INFO - training batch 601, loss: 0.040, 19232/28000 datapoints
2025-03-06 22:02:39,432 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:02:39,580 - INFO - training batch 701, loss: 0.034, 22432/28000 datapoints
2025-03-06 22:02:39,729 - INFO - training batch 751, loss: 0.061, 24032/28000 datapoints
2025-03-06 22:02:39,879 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-06 22:02:40,025 - INFO - training batch 851, loss: 0.055, 27232/28000 datapoints
2025-03-06 22:02:40,099 - INFO - validation batch 1, loss: 0.418, 32/6976 datapoints
2025-03-06 22:02:40,144 - INFO - validation batch 51, loss: 2.976, 1632/6976 datapoints
2025-03-06 22:02:40,190 - INFO - validation batch 101, loss: 0.881, 3232/6976 datapoints
2025-03-06 22:02:40,236 - INFO - validation batch 151, loss: 1.140, 4832/6976 datapoints
2025-03-06 22:02:40,283 - INFO - validation batch 201, loss: 0.564, 6432/6976 datapoints
2025-03-06 22:02:40,299 - INFO - Epoch 385/800 done.
2025-03-06 22:02:40,299 - INFO - Final validation performance:
Loss: 1.196, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:02:40,300 - INFO - Beginning epoch 386/800
2025-03-06 22:02:40,304 - INFO - training batch 1, loss: 0.072, 32/28000 datapoints
2025-03-06 22:02:40,455 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-06 22:02:40,599 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 22:02:40,744 - INFO - training batch 151, loss: 0.074, 4832/28000 datapoints
2025-03-06 22:02:40,894 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 22:02:41,041 - INFO - training batch 251, loss: 0.107, 8032/28000 datapoints
2025-03-06 22:02:41,186 - INFO - training batch 301, loss: 0.072, 9632/28000 datapoints
2025-03-06 22:02:41,332 - INFO - training batch 351, loss: 0.111, 11232/28000 datapoints
2025-03-06 22:02:41,476 - INFO - training batch 401, loss: 0.070, 12832/28000 datapoints
2025-03-06 22:02:41,622 - INFO - training batch 451, loss: 0.158, 14432/28000 datapoints
2025-03-06 22:02:41,770 - INFO - training batch 501, loss: 0.058, 16032/28000 datapoints
2025-03-06 22:02:41,923 - INFO - training batch 551, loss: 0.066, 17632/28000 datapoints
2025-03-06 22:02:42,068 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-06 22:02:42,214 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:02:42,362 - INFO - training batch 701, loss: 0.033, 22432/28000 datapoints
2025-03-06 22:02:42,510 - INFO - training batch 751, loss: 0.061, 24032/28000 datapoints
2025-03-06 22:02:42,659 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-06 22:02:42,807 - INFO - training batch 851, loss: 0.055, 27232/28000 datapoints
2025-03-06 22:02:42,888 - INFO - validation batch 1, loss: 0.422, 32/6976 datapoints
2025-03-06 22:02:42,935 - INFO - validation batch 51, loss: 2.987, 1632/6976 datapoints
2025-03-06 22:02:42,981 - INFO - validation batch 101, loss: 0.884, 3232/6976 datapoints
2025-03-06 22:02:43,027 - INFO - validation batch 151, loss: 1.151, 4832/6976 datapoints
2025-03-06 22:02:43,076 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 22:02:43,091 - INFO - Epoch 386/800 done.
2025-03-06 22:02:43,092 - INFO - Final validation performance:
Loss: 1.202, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:02:43,092 - INFO - Beginning epoch 387/800
2025-03-06 22:02:43,096 - INFO - training batch 1, loss: 0.071, 32/28000 datapoints
2025-03-06 22:02:43,243 - INFO - training batch 51, loss: 0.034, 1632/28000 datapoints
2025-03-06 22:02:43,389 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 22:02:43,534 - INFO - training batch 151, loss: 0.073, 4832/28000 datapoints
2025-03-06 22:02:43,737 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-06 22:02:43,888 - INFO - training batch 251, loss: 0.105, 8032/28000 datapoints
2025-03-06 22:02:44,033 - INFO - training batch 301, loss: 0.070, 9632/28000 datapoints
2025-03-06 22:02:44,178 - INFO - training batch 351, loss: 0.109, 11232/28000 datapoints
2025-03-06 22:02:44,324 - INFO - training batch 401, loss: 0.069, 12832/28000 datapoints
2025-03-06 22:02:44,474 - INFO - training batch 451, loss: 0.155, 14432/28000 datapoints
2025-03-06 22:02:44,625 - INFO - training batch 501, loss: 0.058, 16032/28000 datapoints
2025-03-06 22:02:44,771 - INFO - training batch 551, loss: 0.065, 17632/28000 datapoints
2025-03-06 22:02:44,922 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-06 22:02:45,072 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:02:45,228 - INFO - training batch 701, loss: 0.033, 22432/28000 datapoints
2025-03-06 22:02:45,376 - INFO - training batch 751, loss: 0.059, 24032/28000 datapoints
2025-03-06 22:02:45,520 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-06 22:02:45,664 - INFO - training batch 851, loss: 0.053, 27232/28000 datapoints
2025-03-06 22:02:45,740 - INFO - validation batch 1, loss: 0.430, 32/6976 datapoints
2025-03-06 22:02:45,786 - INFO - validation batch 51, loss: 3.003, 1632/6976 datapoints
2025-03-06 22:02:45,833 - INFO - validation batch 101, loss: 0.885, 3232/6976 datapoints
2025-03-06 22:02:45,885 - INFO - validation batch 151, loss: 1.155, 4832/6976 datapoints
2025-03-06 22:02:45,930 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 22:02:45,946 - INFO - Epoch 387/800 done.
2025-03-06 22:02:45,946 - INFO - Final validation performance:
Loss: 1.208, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:02:45,947 - INFO - Beginning epoch 388/800
2025-03-06 22:02:45,952 - INFO - training batch 1, loss: 0.070, 32/28000 datapoints
2025-03-06 22:02:46,104 - INFO - training batch 51, loss: 0.033, 1632/28000 datapoints
2025-03-06 22:02:46,251 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-06 22:02:46,399 - INFO - training batch 151, loss: 0.073, 4832/28000 datapoints
2025-03-06 22:02:46,546 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-06 22:02:46,692 - INFO - training batch 251, loss: 0.104, 8032/28000 datapoints
2025-03-06 22:02:46,857 - INFO - training batch 301, loss: 0.069, 9632/28000 datapoints
2025-03-06 22:02:47,015 - INFO - training batch 351, loss: 0.108, 11232/28000 datapoints
2025-03-06 22:02:47,164 - INFO - training batch 401, loss: 0.068, 12832/28000 datapoints
2025-03-06 22:02:47,317 - INFO - training batch 451, loss: 0.153, 14432/28000 datapoints
2025-03-06 22:02:47,467 - INFO - training batch 501, loss: 0.057, 16032/28000 datapoints
2025-03-06 22:02:47,620 - INFO - training batch 551, loss: 0.064, 17632/28000 datapoints
2025-03-06 22:02:47,774 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-06 22:02:47,926 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:02:48,077 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-06 22:02:48,239 - INFO - training batch 751, loss: 0.059, 24032/28000 datapoints
2025-03-06 22:02:48,389 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-06 22:02:48,540 - INFO - training batch 851, loss: 0.053, 27232/28000 datapoints
2025-03-06 22:02:48,618 - INFO - validation batch 1, loss: 0.429, 32/6976 datapoints
2025-03-06 22:02:48,671 - INFO - validation batch 51, loss: 3.023, 1632/6976 datapoints
2025-03-06 22:02:48,722 - INFO - validation batch 101, loss: 0.885, 3232/6976 datapoints
2025-03-06 22:02:48,775 - INFO - validation batch 151, loss: 1.156, 4832/6976 datapoints
2025-03-06 22:02:48,826 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 22:02:48,846 - INFO - Epoch 388/800 done.
2025-03-06 22:02:48,846 - INFO - Final validation performance:
Loss: 1.213, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:02:48,847 - INFO - Beginning epoch 389/800
2025-03-06 22:02:48,854 - INFO - training batch 1, loss: 0.069, 32/28000 datapoints
2025-03-06 22:02:49,008 - INFO - training batch 51, loss: 0.033, 1632/28000 datapoints
2025-03-06 22:02:49,156 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-06 22:02:49,306 - INFO - training batch 151, loss: 0.072, 4832/28000 datapoints
2025-03-06 22:02:49,459 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 22:02:49,610 - INFO - training batch 251, loss: 0.101, 8032/28000 datapoints
2025-03-06 22:02:49,764 - INFO - training batch 301, loss: 0.069, 9632/28000 datapoints
2025-03-06 22:02:49,919 - INFO - training batch 351, loss: 0.106, 11232/28000 datapoints
2025-03-06 22:02:50,069 - INFO - training batch 401, loss: 0.067, 12832/28000 datapoints
2025-03-06 22:02:50,220 - INFO - training batch 451, loss: 0.150, 14432/28000 datapoints
2025-03-06 22:02:50,370 - INFO - training batch 501, loss: 0.056, 16032/28000 datapoints
2025-03-06 22:02:50,519 - INFO - training batch 551, loss: 0.064, 17632/28000 datapoints
2025-03-06 22:02:50,676 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-06 22:02:50,823 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:02:50,974 - INFO - training batch 701, loss: 0.032, 22432/28000 datapoints
2025-03-06 22:02:51,120 - INFO - training batch 751, loss: 0.059, 24032/28000 datapoints
2025-03-06 22:02:51,267 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-06 22:02:51,414 - INFO - training batch 851, loss: 0.052, 27232/28000 datapoints
2025-03-06 22:02:51,488 - INFO - validation batch 1, loss: 0.434, 32/6976 datapoints
2025-03-06 22:02:51,534 - INFO - validation batch 51, loss: 3.033, 1632/6976 datapoints
2025-03-06 22:02:51,580 - INFO - validation batch 101, loss: 0.889, 3232/6976 datapoints
2025-03-06 22:02:51,626 - INFO - validation batch 151, loss: 1.168, 4832/6976 datapoints
2025-03-06 22:02:51,672 - INFO - validation batch 201, loss: 0.570, 6432/6976 datapoints
2025-03-06 22:02:51,689 - INFO - Epoch 389/800 done.
2025-03-06 22:02:51,689 - INFO - Final validation performance:
Loss: 1.219, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:02:51,689 - INFO - Beginning epoch 390/800
2025-03-06 22:02:51,696 - INFO - training batch 1, loss: 0.067, 32/28000 datapoints
2025-03-06 22:02:51,842 - INFO - training batch 51, loss: 0.032, 1632/28000 datapoints
2025-03-06 22:02:51,995 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 22:02:52,142 - INFO - training batch 151, loss: 0.072, 4832/28000 datapoints
2025-03-06 22:02:52,288 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 22:02:52,435 - INFO - training batch 251, loss: 0.099, 8032/28000 datapoints
2025-03-06 22:02:52,583 - INFO - training batch 301, loss: 0.067, 9632/28000 datapoints
2025-03-06 22:02:52,729 - INFO - training batch 351, loss: 0.105, 11232/28000 datapoints
2025-03-06 22:02:52,878 - INFO - training batch 401, loss: 0.066, 12832/28000 datapoints
2025-03-06 22:02:53,025 - INFO - training batch 451, loss: 0.148, 14432/28000 datapoints
2025-03-06 22:02:53,172 - INFO - training batch 501, loss: 0.056, 16032/28000 datapoints
2025-03-06 22:02:53,319 - INFO - training batch 551, loss: 0.063, 17632/28000 datapoints
2025-03-06 22:02:53,467 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-06 22:02:53,613 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:02:53,779 - INFO - training batch 701, loss: 0.030, 22432/28000 datapoints
2025-03-06 22:02:53,942 - INFO - training batch 751, loss: 0.058, 24032/28000 datapoints
2025-03-06 22:02:54,091 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 22:02:54,237 - INFO - training batch 851, loss: 0.052, 27232/28000 datapoints
2025-03-06 22:02:54,310 - INFO - validation batch 1, loss: 0.436, 32/6976 datapoints
2025-03-06 22:02:54,357 - INFO - validation batch 51, loss: 3.049, 1632/6976 datapoints
2025-03-06 22:02:54,402 - INFO - validation batch 101, loss: 0.891, 3232/6976 datapoints
2025-03-06 22:02:54,449 - INFO - validation batch 151, loss: 1.177, 4832/6976 datapoints
2025-03-06 22:02:54,497 - INFO - validation batch 201, loss: 0.574, 6432/6976 datapoints
2025-03-06 22:02:54,514 - INFO - Epoch 390/800 done.
2025-03-06 22:02:54,514 - INFO - Final validation performance:
Loss: 1.225, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:02:54,514 - INFO - Beginning epoch 391/800
2025-03-06 22:02:54,518 - INFO - training batch 1, loss: 0.067, 32/28000 datapoints
2025-03-06 22:02:54,667 - INFO - training batch 51, loss: 0.032, 1632/28000 datapoints
2025-03-06 22:02:54,811 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-06 22:02:54,962 - INFO - training batch 151, loss: 0.071, 4832/28000 datapoints
2025-03-06 22:02:55,115 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 22:02:55,267 - INFO - training batch 251, loss: 0.096, 8032/28000 datapoints
2025-03-06 22:02:55,413 - INFO - training batch 301, loss: 0.065, 9632/28000 datapoints
2025-03-06 22:02:55,559 - INFO - training batch 351, loss: 0.103, 11232/28000 datapoints
2025-03-06 22:02:55,708 - INFO - training batch 401, loss: 0.065, 12832/28000 datapoints
2025-03-06 22:02:55,856 - INFO - training batch 451, loss: 0.144, 14432/28000 datapoints
2025-03-06 22:02:56,005 - INFO - training batch 501, loss: 0.054, 16032/28000 datapoints
2025-03-06 22:02:56,154 - INFO - training batch 551, loss: 0.062, 17632/28000 datapoints
2025-03-06 22:02:56,304 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-06 22:02:56,452 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:02:56,607 - INFO - training batch 701, loss: 0.030, 22432/28000 datapoints
2025-03-06 22:02:56,754 - INFO - training batch 751, loss: 0.057, 24032/28000 datapoints
2025-03-06 22:02:56,905 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 22:02:57,053 - INFO - training batch 851, loss: 0.051, 27232/28000 datapoints
2025-03-06 22:02:57,125 - INFO - validation batch 1, loss: 0.441, 32/6976 datapoints
2025-03-06 22:02:57,172 - INFO - validation batch 51, loss: 3.071, 1632/6976 datapoints
2025-03-06 22:02:57,218 - INFO - validation batch 101, loss: 0.893, 3232/6976 datapoints
2025-03-06 22:02:57,265 - INFO - validation batch 151, loss: 1.180, 4832/6976 datapoints
2025-03-06 22:02:57,311 - INFO - validation batch 201, loss: 0.576, 6432/6976 datapoints
2025-03-06 22:02:57,329 - INFO - Epoch 391/800 done.
2025-03-06 22:02:57,329 - INFO - Final validation performance:
Loss: 1.232, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:02:57,330 - INFO - Beginning epoch 392/800
2025-03-06 22:02:57,334 - INFO - training batch 1, loss: 0.066, 32/28000 datapoints
2025-03-06 22:02:57,482 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-06 22:02:57,631 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-06 22:02:57,781 - INFO - training batch 151, loss: 0.071, 4832/28000 datapoints
2025-03-06 22:02:57,930 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 22:02:58,076 - INFO - training batch 251, loss: 0.095, 8032/28000 datapoints
2025-03-06 22:02:58,224 - INFO - training batch 301, loss: 0.064, 9632/28000 datapoints
2025-03-06 22:02:58,370 - INFO - training batch 351, loss: 0.102, 11232/28000 datapoints
2025-03-06 22:02:58,514 - INFO - training batch 401, loss: 0.064, 12832/28000 datapoints
2025-03-06 22:02:58,664 - INFO - training batch 451, loss: 0.142, 14432/28000 datapoints
2025-03-06 22:02:58,814 - INFO - training batch 501, loss: 0.054, 16032/28000 datapoints
2025-03-06 22:02:58,964 - INFO - training batch 551, loss: 0.061, 17632/28000 datapoints
2025-03-06 22:02:59,111 - INFO - training batch 601, loss: 0.035, 19232/28000 datapoints
2025-03-06 22:02:59,257 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:02:59,406 - INFO - training batch 701, loss: 0.029, 22432/28000 datapoints
2025-03-06 22:02:59,551 - INFO - training batch 751, loss: 0.056, 24032/28000 datapoints
2025-03-06 22:02:59,697 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 22:02:59,845 - INFO - training batch 851, loss: 0.049, 27232/28000 datapoints
2025-03-06 22:02:59,921 - INFO - validation batch 1, loss: 0.449, 32/6976 datapoints
2025-03-06 22:02:59,968 - INFO - validation batch 51, loss: 3.084, 1632/6976 datapoints
2025-03-06 22:03:00,018 - INFO - validation batch 101, loss: 0.895, 3232/6976 datapoints
2025-03-06 22:03:00,068 - INFO - validation batch 151, loss: 1.186, 4832/6976 datapoints
2025-03-06 22:03:00,115 - INFO - validation batch 201, loss: 0.577, 6432/6976 datapoints
2025-03-06 22:03:00,131 - INFO - Epoch 392/800 done.
2025-03-06 22:03:00,131 - INFO - Final validation performance:
Loss: 1.238, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:03:00,132 - INFO - Beginning epoch 393/800
2025-03-06 22:03:00,136 - INFO - training batch 1, loss: 0.063, 32/28000 datapoints
2025-03-06 22:03:00,283 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-06 22:03:00,427 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-06 22:03:00,575 - INFO - training batch 151, loss: 0.070, 4832/28000 datapoints
2025-03-06 22:03:00,720 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 22:03:00,867 - INFO - training batch 251, loss: 0.091, 8032/28000 datapoints
2025-03-06 22:03:01,015 - INFO - training batch 301, loss: 0.064, 9632/28000 datapoints
2025-03-06 22:03:01,162 - INFO - training batch 351, loss: 0.100, 11232/28000 datapoints
2025-03-06 22:03:01,309 - INFO - training batch 401, loss: 0.063, 12832/28000 datapoints
2025-03-06 22:03:01,459 - INFO - training batch 451, loss: 0.141, 14432/28000 datapoints
2025-03-06 22:03:01,608 - INFO - training batch 501, loss: 0.053, 16032/28000 datapoints
2025-03-06 22:03:01,758 - INFO - training batch 551, loss: 0.060, 17632/28000 datapoints
2025-03-06 22:03:01,907 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-06 22:03:02,053 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:03:02,205 - INFO - training batch 701, loss: 0.029, 22432/28000 datapoints
2025-03-06 22:03:02,350 - INFO - training batch 751, loss: 0.056, 24032/28000 datapoints
2025-03-06 22:03:02,496 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 22:03:02,647 - INFO - training batch 851, loss: 0.049, 27232/28000 datapoints
2025-03-06 22:03:02,721 - INFO - validation batch 1, loss: 0.447, 32/6976 datapoints
2025-03-06 22:03:02,768 - INFO - validation batch 51, loss: 3.108, 1632/6976 datapoints
2025-03-06 22:03:02,814 - INFO - validation batch 101, loss: 0.898, 3232/6976 datapoints
2025-03-06 22:03:02,862 - INFO - validation batch 151, loss: 1.190, 4832/6976 datapoints
2025-03-06 22:03:02,911 - INFO - validation batch 201, loss: 0.580, 6432/6976 datapoints
2025-03-06 22:03:02,927 - INFO - Epoch 393/800 done.
2025-03-06 22:03:02,927 - INFO - Final validation performance:
Loss: 1.245, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:03:02,928 - INFO - Beginning epoch 394/800
2025-03-06 22:03:02,932 - INFO - training batch 1, loss: 0.064, 32/28000 datapoints
2025-03-06 22:03:03,082 - INFO - training batch 51, loss: 0.030, 1632/28000 datapoints
2025-03-06 22:03:03,234 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 22:03:03,382 - INFO - training batch 151, loss: 0.070, 4832/28000 datapoints
2025-03-06 22:03:03,534 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 22:03:03,681 - INFO - training batch 251, loss: 0.091, 8032/28000 datapoints
2025-03-06 22:03:03,838 - INFO - training batch 301, loss: 0.062, 9632/28000 datapoints
2025-03-06 22:03:04,002 - INFO - training batch 351, loss: 0.098, 11232/28000 datapoints
2025-03-06 22:03:04,148 - INFO - training batch 401, loss: 0.062, 12832/28000 datapoints
2025-03-06 22:03:04,312 - INFO - training batch 451, loss: 0.138, 14432/28000 datapoints
2025-03-06 22:03:04,493 - INFO - training batch 501, loss: 0.052, 16032/28000 datapoints
2025-03-06 22:03:04,682 - INFO - training batch 551, loss: 0.059, 17632/28000 datapoints
2025-03-06 22:03:04,858 - INFO - training batch 601, loss: 0.035, 19232/28000 datapoints
2025-03-06 22:03:05,031 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:03:05,191 - INFO - training batch 701, loss: 0.028, 22432/28000 datapoints
2025-03-06 22:03:05,341 - INFO - training batch 751, loss: 0.055, 24032/28000 datapoints
2025-03-06 22:03:05,489 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 22:03:05,639 - INFO - training batch 851, loss: 0.048, 27232/28000 datapoints
2025-03-06 22:03:05,713 - INFO - validation batch 1, loss: 0.447, 32/6976 datapoints
2025-03-06 22:03:05,763 - INFO - validation batch 51, loss: 3.128, 1632/6976 datapoints
2025-03-06 22:03:05,810 - INFO - validation batch 101, loss: 0.898, 3232/6976 datapoints
2025-03-06 22:03:05,860 - INFO - validation batch 151, loss: 1.196, 4832/6976 datapoints
2025-03-06 22:03:05,909 - INFO - validation batch 201, loss: 0.580, 6432/6976 datapoints
2025-03-06 22:03:05,925 - INFO - Epoch 394/800 done.
2025-03-06 22:03:05,925 - INFO - Final validation performance:
Loss: 1.250, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:03:05,926 - INFO - Beginning epoch 395/800
2025-03-06 22:03:05,930 - INFO - training batch 1, loss: 0.064, 32/28000 datapoints
2025-03-06 22:03:06,090 - INFO - training batch 51, loss: 0.030, 1632/28000 datapoints
2025-03-06 22:03:06,243 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 22:03:06,392 - INFO - training batch 151, loss: 0.069, 4832/28000 datapoints
2025-03-06 22:03:06,544 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 22:03:06,699 - INFO - training batch 251, loss: 0.089, 8032/28000 datapoints
2025-03-06 22:03:06,869 - INFO - training batch 301, loss: 0.062, 9632/28000 datapoints
2025-03-06 22:03:07,024 - INFO - training batch 351, loss: 0.096, 11232/28000 datapoints
2025-03-06 22:03:07,180 - INFO - training batch 401, loss: 0.061, 12832/28000 datapoints
2025-03-06 22:03:07,333 - INFO - training batch 451, loss: 0.136, 14432/28000 datapoints
2025-03-06 22:03:07,484 - INFO - training batch 501, loss: 0.052, 16032/28000 datapoints
2025-03-06 22:03:07,638 - INFO - training batch 551, loss: 0.058, 17632/28000 datapoints
2025-03-06 22:03:07,794 - INFO - training batch 601, loss: 0.034, 19232/28000 datapoints
2025-03-06 22:03:07,947 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:03:08,102 - INFO - training batch 701, loss: 0.028, 22432/28000 datapoints
2025-03-06 22:03:08,252 - INFO - training batch 751, loss: 0.055, 24032/28000 datapoints
2025-03-06 22:03:08,398 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 22:03:08,546 - INFO - training batch 851, loss: 0.047, 27232/28000 datapoints
2025-03-06 22:03:08,622 - INFO - validation batch 1, loss: 0.457, 32/6976 datapoints
2025-03-06 22:03:08,674 - INFO - validation batch 51, loss: 3.140, 1632/6976 datapoints
2025-03-06 22:03:08,725 - INFO - validation batch 101, loss: 0.901, 3232/6976 datapoints
2025-03-06 22:03:08,775 - INFO - validation batch 151, loss: 1.204, 4832/6976 datapoints
2025-03-06 22:03:08,826 - INFO - validation batch 201, loss: 0.584, 6432/6976 datapoints
2025-03-06 22:03:08,844 - INFO - Epoch 395/800 done.
2025-03-06 22:03:08,844 - INFO - Final validation performance:
Loss: 1.257, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:03:08,845 - INFO - Beginning epoch 396/800
2025-03-06 22:03:08,852 - INFO - training batch 1, loss: 0.061, 32/28000 datapoints
2025-03-06 22:03:09,033 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-06 22:03:09,182 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 22:03:09,335 - INFO - training batch 151, loss: 0.068, 4832/28000 datapoints
2025-03-06 22:03:09,484 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 22:03:09,630 - INFO - training batch 251, loss: 0.087, 8032/28000 datapoints
2025-03-06 22:03:09,781 - INFO - training batch 301, loss: 0.059, 9632/28000 datapoints
2025-03-06 22:03:09,929 - INFO - training batch 351, loss: 0.095, 11232/28000 datapoints
2025-03-06 22:03:10,078 - INFO - training batch 401, loss: 0.060, 12832/28000 datapoints
2025-03-06 22:03:10,226 - INFO - training batch 451, loss: 0.133, 14432/28000 datapoints
2025-03-06 22:03:10,376 - INFO - training batch 501, loss: 0.051, 16032/28000 datapoints
2025-03-06 22:03:10,524 - INFO - training batch 551, loss: 0.058, 17632/28000 datapoints
2025-03-06 22:03:10,671 - INFO - training batch 601, loss: 0.034, 19232/28000 datapoints
2025-03-06 22:03:10,819 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:03:10,973 - INFO - training batch 701, loss: 0.027, 22432/28000 datapoints
2025-03-06 22:03:11,119 - INFO - training batch 751, loss: 0.053, 24032/28000 datapoints
2025-03-06 22:03:11,266 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 22:03:11,413 - INFO - training batch 851, loss: 0.046, 27232/28000 datapoints
2025-03-06 22:03:11,486 - INFO - validation batch 1, loss: 0.458, 32/6976 datapoints
2025-03-06 22:03:11,531 - INFO - validation batch 51, loss: 3.158, 1632/6976 datapoints
2025-03-06 22:03:11,579 - INFO - validation batch 101, loss: 0.903, 3232/6976 datapoints
2025-03-06 22:03:11,625 - INFO - validation batch 151, loss: 1.211, 4832/6976 datapoints
2025-03-06 22:03:11,672 - INFO - validation batch 201, loss: 0.583, 6432/6976 datapoints
2025-03-06 22:03:11,688 - INFO - Epoch 396/800 done.
2025-03-06 22:03:11,688 - INFO - Final validation performance:
Loss: 1.263, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:03:11,688 - INFO - Beginning epoch 397/800
2025-03-06 22:03:11,695 - INFO - training batch 1, loss: 0.061, 32/28000 datapoints
2025-03-06 22:03:11,844 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-06 22:03:11,992 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 22:03:12,140 - INFO - training batch 151, loss: 0.067, 4832/28000 datapoints
2025-03-06 22:03:12,286 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:03:12,431 - INFO - training batch 251, loss: 0.086, 8032/28000 datapoints
2025-03-06 22:03:12,580 - INFO - training batch 301, loss: 0.058, 9632/28000 datapoints
2025-03-06 22:03:12,728 - INFO - training batch 351, loss: 0.094, 11232/28000 datapoints
2025-03-06 22:03:12,879 - INFO - training batch 401, loss: 0.058, 12832/28000 datapoints
2025-03-06 22:03:13,031 - INFO - training batch 451, loss: 0.131, 14432/28000 datapoints
2025-03-06 22:03:13,218 - INFO - training batch 501, loss: 0.050, 16032/28000 datapoints
2025-03-06 22:03:13,379 - INFO - training batch 551, loss: 0.057, 17632/28000 datapoints
2025-03-06 22:03:13,529 - INFO - training batch 601, loss: 0.031, 19232/28000 datapoints
2025-03-06 22:03:13,679 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:03:13,832 - INFO - training batch 701, loss: 0.027, 22432/28000 datapoints
2025-03-06 22:03:14,005 - INFO - training batch 751, loss: 0.053, 24032/28000 datapoints
2025-03-06 22:03:14,153 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 22:03:14,299 - INFO - training batch 851, loss: 0.045, 27232/28000 datapoints
2025-03-06 22:03:14,371 - INFO - validation batch 1, loss: 0.457, 32/6976 datapoints
2025-03-06 22:03:14,417 - INFO - validation batch 51, loss: 3.177, 1632/6976 datapoints
2025-03-06 22:03:14,463 - INFO - validation batch 101, loss: 0.908, 3232/6976 datapoints
2025-03-06 22:03:14,509 - INFO - validation batch 151, loss: 1.216, 4832/6976 datapoints
2025-03-06 22:03:14,557 - INFO - validation batch 201, loss: 0.585, 6432/6976 datapoints
2025-03-06 22:03:14,572 - INFO - Epoch 397/800 done.
2025-03-06 22:03:14,573 - INFO - Final validation performance:
Loss: 1.268, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:03:14,573 - INFO - Beginning epoch 398/800
2025-03-06 22:03:14,577 - INFO - training batch 1, loss: 0.060, 32/28000 datapoints
2025-03-06 22:03:14,733 - INFO - training batch 51, loss: 0.028, 1632/28000 datapoints
2025-03-06 22:03:14,882 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 22:03:15,036 - INFO - training batch 151, loss: 0.067, 4832/28000 datapoints
2025-03-06 22:03:15,190 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:03:15,344 - INFO - training batch 251, loss: 0.083, 8032/28000 datapoints
2025-03-06 22:03:15,496 - INFO - training batch 301, loss: 0.058, 9632/28000 datapoints
2025-03-06 22:03:15,646 - INFO - training batch 351, loss: 0.092, 11232/28000 datapoints
2025-03-06 22:03:15,802 - INFO - training batch 401, loss: 0.058, 12832/28000 datapoints
2025-03-06 22:03:15,954 - INFO - training batch 451, loss: 0.129, 14432/28000 datapoints
2025-03-06 22:03:16,110 - INFO - training batch 501, loss: 0.050, 16032/28000 datapoints
2025-03-06 22:03:16,267 - INFO - training batch 551, loss: 0.056, 17632/28000 datapoints
2025-03-06 22:03:16,417 - INFO - training batch 601, loss: 0.034, 19232/28000 datapoints
2025-03-06 22:03:16,573 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 22:03:16,758 - INFO - training batch 701, loss: 0.025, 22432/28000 datapoints
2025-03-06 22:03:16,912 - INFO - training batch 751, loss: 0.051, 24032/28000 datapoints
2025-03-06 22:03:17,074 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:03:17,225 - INFO - training batch 851, loss: 0.045, 27232/28000 datapoints
2025-03-06 22:03:17,320 - INFO - validation batch 1, loss: 0.460, 32/6976 datapoints
2025-03-06 22:03:17,388 - INFO - validation batch 51, loss: 3.198, 1632/6976 datapoints
2025-03-06 22:03:17,434 - INFO - validation batch 101, loss: 0.908, 3232/6976 datapoints
2025-03-06 22:03:17,483 - INFO - validation batch 151, loss: 1.217, 4832/6976 datapoints
2025-03-06 22:03:17,530 - INFO - validation batch 201, loss: 0.587, 6432/6976 datapoints
2025-03-06 22:03:17,546 - INFO - Epoch 398/800 done.
2025-03-06 22:03:17,547 - INFO - Final validation performance:
Loss: 1.274, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:03:17,547 - INFO - Beginning epoch 399/800
2025-03-06 22:03:17,551 - INFO - training batch 1, loss: 0.060, 32/28000 datapoints
2025-03-06 22:03:17,701 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-06 22:03:17,855 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-06 22:03:18,003 - INFO - training batch 151, loss: 0.065, 4832/28000 datapoints
2025-03-06 22:03:18,150 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:03:18,300 - INFO - training batch 251, loss: 0.080, 8032/28000 datapoints
2025-03-06 22:03:18,493 - INFO - training batch 301, loss: 0.057, 9632/28000 datapoints
2025-03-06 22:03:18,647 - INFO - training batch 351, loss: 0.091, 11232/28000 datapoints
2025-03-06 22:03:18,792 - INFO - training batch 401, loss: 0.057, 12832/28000 datapoints
2025-03-06 22:03:18,966 - INFO - training batch 451, loss: 0.127, 14432/28000 datapoints
2025-03-06 22:03:19,113 - INFO - training batch 501, loss: 0.049, 16032/28000 datapoints
2025-03-06 22:03:19,261 - INFO - training batch 551, loss: 0.055, 17632/28000 datapoints
2025-03-06 22:03:19,411 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-06 22:03:19,557 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:03:19,706 - INFO - training batch 701, loss: 0.025, 22432/28000 datapoints
2025-03-06 22:03:19,859 - INFO - training batch 751, loss: 0.052, 24032/28000 datapoints
2025-03-06 22:03:20,005 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:03:20,152 - INFO - training batch 851, loss: 0.043, 27232/28000 datapoints
2025-03-06 22:03:20,225 - INFO - validation batch 1, loss: 0.462, 32/6976 datapoints
2025-03-06 22:03:20,271 - INFO - validation batch 51, loss: 3.214, 1632/6976 datapoints
2025-03-06 22:03:20,320 - INFO - validation batch 101, loss: 0.911, 3232/6976 datapoints
2025-03-06 22:03:20,366 - INFO - validation batch 151, loss: 1.231, 4832/6976 datapoints
2025-03-06 22:03:20,412 - INFO - validation batch 201, loss: 0.592, 6432/6976 datapoints
2025-03-06 22:03:20,428 - INFO - Epoch 399/800 done.
2025-03-06 22:03:20,428 - INFO - Final validation performance:
Loss: 1.282, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 22:03:20,428 - INFO - Beginning epoch 400/800
2025-03-06 22:03:20,432 - INFO - training batch 1, loss: 0.059, 32/28000 datapoints
2025-03-06 22:03:20,579 - INFO - training batch 51, loss: 0.028, 1632/28000 datapoints
2025-03-06 22:03:20,725 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-06 22:03:20,877 - INFO - training batch 151, loss: 0.065, 4832/28000 datapoints
2025-03-06 22:03:21,025 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:03:21,175 - INFO - training batch 251, loss: 0.081, 8032/28000 datapoints
2025-03-06 22:03:21,321 - INFO - training batch 301, loss: 0.056, 9632/28000 datapoints
2025-03-06 22:03:21,470 - INFO - training batch 351, loss: 0.089, 11232/28000 datapoints
2025-03-06 22:03:21,617 - INFO - training batch 401, loss: 0.057, 12832/28000 datapoints
2025-03-06 22:03:21,766 - INFO - training batch 451, loss: 0.124, 14432/28000 datapoints
2025-03-06 22:03:21,922 - INFO - training batch 501, loss: 0.048, 16032/28000 datapoints
2025-03-06 22:03:22,071 - INFO - training batch 551, loss: 0.055, 17632/28000 datapoints
2025-03-06 22:03:22,218 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-06 22:03:22,367 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:03:22,519 - INFO - training batch 701, loss: 0.024, 22432/28000 datapoints
2025-03-06 22:03:22,677 - INFO - training batch 751, loss: 0.052, 24032/28000 datapoints
2025-03-06 22:03:22,823 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:03:22,973 - INFO - training batch 851, loss: 0.042, 27232/28000 datapoints
2025-03-06 22:03:23,045 - INFO - validation batch 1, loss: 0.467, 32/6976 datapoints
2025-03-06 22:03:23,093 - INFO - validation batch 51, loss: 3.233, 1632/6976 datapoints
2025-03-06 22:03:23,139 - INFO - validation batch 101, loss: 0.916, 3232/6976 datapoints
2025-03-06 22:03:23,185 - INFO - validation batch 151, loss: 1.233, 4832/6976 datapoints
2025-03-06 22:03:23,233 - INFO - validation batch 201, loss: 0.590, 6432/6976 datapoints
2025-03-06 22:03:23,249 - INFO - Epoch 400/800 done.
2025-03-06 22:03:23,249 - INFO - Final validation performance:
Loss: 1.288, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:03:23,250 - INFO - Beginning epoch 401/800
2025-03-06 22:03:23,254 - INFO - training batch 1, loss: 0.057, 32/28000 datapoints
2025-03-06 22:03:23,416 - INFO - training batch 51, loss: 0.028, 1632/28000 datapoints
2025-03-06 22:03:23,563 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-06 22:03:23,712 - INFO - training batch 151, loss: 0.065, 4832/28000 datapoints
2025-03-06 22:03:23,865 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:03:24,013 - INFO - training batch 251, loss: 0.079, 8032/28000 datapoints
2025-03-06 22:03:24,189 - INFO - training batch 301, loss: 0.055, 9632/28000 datapoints
2025-03-06 22:03:24,340 - INFO - training batch 351, loss: 0.087, 11232/28000 datapoints
2025-03-06 22:03:24,491 - INFO - training batch 401, loss: 0.055, 12832/28000 datapoints
2025-03-06 22:03:24,642 - INFO - training batch 451, loss: 0.122, 14432/28000 datapoints
2025-03-06 22:03:24,816 - INFO - training batch 501, loss: 0.047, 16032/28000 datapoints
2025-03-06 22:03:24,972 - INFO - training batch 551, loss: 0.054, 17632/28000 datapoints
2025-03-06 22:03:25,135 - INFO - training batch 601, loss: 0.031, 19232/28000 datapoints
2025-03-06 22:03:25,286 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:03:25,442 - INFO - training batch 701, loss: 0.024, 22432/28000 datapoints
2025-03-06 22:03:25,590 - INFO - training batch 751, loss: 0.051, 24032/28000 datapoints
2025-03-06 22:03:25,740 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:03:25,896 - INFO - training batch 851, loss: 0.042, 27232/28000 datapoints
2025-03-06 22:03:25,969 - INFO - validation batch 1, loss: 0.468, 32/6976 datapoints
2025-03-06 22:03:26,018 - INFO - validation batch 51, loss: 3.251, 1632/6976 datapoints
2025-03-06 22:03:26,065 - INFO - validation batch 101, loss: 0.920, 3232/6976 datapoints
2025-03-06 22:03:26,110 - INFO - validation batch 151, loss: 1.239, 4832/6976 datapoints
2025-03-06 22:03:26,156 - INFO - validation batch 201, loss: 0.596, 6432/6976 datapoints
2025-03-06 22:03:26,171 - INFO - Epoch 401/800 done.
2025-03-06 22:03:26,172 - INFO - Final validation performance:
Loss: 1.295, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:03:26,172 - INFO - Beginning epoch 402/800
2025-03-06 22:03:26,176 - INFO - training batch 1, loss: 0.058, 32/28000 datapoints
2025-03-06 22:03:26,323 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-06 22:03:26,472 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 22:03:26,617 - INFO - training batch 151, loss: 0.064, 4832/28000 datapoints
2025-03-06 22:03:26,765 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:03:26,931 - INFO - training batch 251, loss: 0.076, 8032/28000 datapoints
2025-03-06 22:03:27,087 - INFO - training batch 301, loss: 0.054, 9632/28000 datapoints
2025-03-06 22:03:27,238 - INFO - training batch 351, loss: 0.085, 11232/28000 datapoints
2025-03-06 22:03:27,391 - INFO - training batch 401, loss: 0.054, 12832/28000 datapoints
2025-03-06 22:03:27,546 - INFO - training batch 451, loss: 0.120, 14432/28000 datapoints
2025-03-06 22:03:27,699 - INFO - training batch 501, loss: 0.047, 16032/28000 datapoints
2025-03-06 22:03:27,861 - INFO - training batch 551, loss: 0.052, 17632/28000 datapoints
2025-03-06 22:03:28,013 - INFO - training batch 601, loss: 0.031, 19232/28000 datapoints
2025-03-06 22:03:28,166 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:03:28,319 - INFO - training batch 701, loss: 0.024, 22432/28000 datapoints
2025-03-06 22:03:28,472 - INFO - training batch 751, loss: 0.049, 24032/28000 datapoints
2025-03-06 22:03:28,621 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:03:28,778 - INFO - training batch 851, loss: 0.041, 27232/28000 datapoints
2025-03-06 22:03:28,858 - INFO - validation batch 1, loss: 0.475, 32/6976 datapoints
2025-03-06 22:03:28,908 - INFO - validation batch 51, loss: 3.272, 1632/6976 datapoints
2025-03-06 22:03:28,960 - INFO - validation batch 101, loss: 0.922, 3232/6976 datapoints
2025-03-06 22:03:29,011 - INFO - validation batch 151, loss: 1.245, 4832/6976 datapoints
2025-03-06 22:03:29,062 - INFO - validation batch 201, loss: 0.601, 6432/6976 datapoints
2025-03-06 22:03:29,079 - INFO - Epoch 402/800 done.
2025-03-06 22:03:29,079 - INFO - Final validation performance:
Loss: 1.303, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:03:29,080 - INFO - Beginning epoch 403/800
2025-03-06 22:03:29,084 - INFO - training batch 1, loss: 0.055, 32/28000 datapoints
2025-03-06 22:03:29,240 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-06 22:03:29,391 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-06 22:03:29,544 - INFO - training batch 151, loss: 0.063, 4832/28000 datapoints
2025-03-06 22:03:29,693 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:03:29,854 - INFO - training batch 251, loss: 0.075, 8032/28000 datapoints
2025-03-06 22:03:30,007 - INFO - training batch 301, loss: 0.053, 9632/28000 datapoints
2025-03-06 22:03:30,159 - INFO - training batch 351, loss: 0.084, 11232/28000 datapoints
2025-03-06 22:03:30,307 - INFO - training batch 401, loss: 0.053, 12832/28000 datapoints
2025-03-06 22:03:30,460 - INFO - training batch 451, loss: 0.118, 14432/28000 datapoints
2025-03-06 22:03:30,611 - INFO - training batch 501, loss: 0.047, 16032/28000 datapoints
2025-03-06 22:03:30,764 - INFO - training batch 551, loss: 0.052, 17632/28000 datapoints
2025-03-06 22:03:30,916 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 22:03:31,070 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:03:31,223 - INFO - training batch 701, loss: 0.023, 22432/28000 datapoints
2025-03-06 22:03:31,373 - INFO - training batch 751, loss: 0.049, 24032/28000 datapoints
2025-03-06 22:03:31,526 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:03:31,681 - INFO - training batch 851, loss: 0.040, 27232/28000 datapoints
2025-03-06 22:03:31,757 - INFO - validation batch 1, loss: 0.472, 32/6976 datapoints
2025-03-06 22:03:31,810 - INFO - validation batch 51, loss: 3.294, 1632/6976 datapoints
2025-03-06 22:03:31,869 - INFO - validation batch 101, loss: 0.923, 3232/6976 datapoints
2025-03-06 22:03:31,919 - INFO - validation batch 151, loss: 1.250, 4832/6976 datapoints
2025-03-06 22:03:31,971 - INFO - validation batch 201, loss: 0.599, 6432/6976 datapoints
2025-03-06 22:03:31,988 - INFO - Epoch 403/800 done.
2025-03-06 22:03:31,989 - INFO - Final validation performance:
Loss: 1.308, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:03:31,989 - INFO - Beginning epoch 404/800
2025-03-06 22:03:31,994 - INFO - training batch 1, loss: 0.056, 32/28000 datapoints
2025-03-06 22:03:32,155 - INFO - training batch 51, loss: 0.026, 1632/28000 datapoints
2025-03-06 22:03:32,305 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 22:03:32,459 - INFO - training batch 151, loss: 0.063, 4832/28000 datapoints
2025-03-06 22:03:32,609 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:03:32,761 - INFO - training batch 251, loss: 0.075, 8032/28000 datapoints
2025-03-06 22:03:32,921 - INFO - training batch 301, loss: 0.052, 9632/28000 datapoints
2025-03-06 22:03:33,108 - INFO - training batch 351, loss: 0.082, 11232/28000 datapoints
2025-03-06 22:03:33,259 - INFO - training batch 401, loss: 0.053, 12832/28000 datapoints
2025-03-06 22:03:33,409 - INFO - training batch 451, loss: 0.115, 14432/28000 datapoints
2025-03-06 22:03:33,567 - INFO - training batch 501, loss: 0.046, 16032/28000 datapoints
2025-03-06 22:03:33,737 - INFO - training batch 551, loss: 0.051, 17632/28000 datapoints
2025-03-06 22:03:33,898 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-06 22:03:34,060 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:03:34,248 - INFO - training batch 701, loss: 0.023, 22432/28000 datapoints
2025-03-06 22:03:34,407 - INFO - training batch 751, loss: 0.049, 24032/28000 datapoints
2025-03-06 22:03:34,566 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:03:34,720 - INFO - training batch 851, loss: 0.039, 27232/28000 datapoints
2025-03-06 22:03:34,802 - INFO - validation batch 1, loss: 0.476, 32/6976 datapoints
2025-03-06 22:03:34,856 - INFO - validation batch 51, loss: 3.314, 1632/6976 datapoints
2025-03-06 22:03:34,906 - INFO - validation batch 101, loss: 0.928, 3232/6976 datapoints
2025-03-06 22:03:34,960 - INFO - validation batch 151, loss: 1.258, 4832/6976 datapoints
2025-03-06 22:03:35,015 - INFO - validation batch 201, loss: 0.602, 6432/6976 datapoints
2025-03-06 22:03:35,035 - INFO - Epoch 404/800 done.
2025-03-06 22:03:35,035 - INFO - Final validation performance:
Loss: 1.315, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 22:03:35,036 - INFO - Beginning epoch 405/800
2025-03-06 22:03:35,041 - INFO - training batch 1, loss: 0.055, 32/28000 datapoints
2025-03-06 22:03:35,205 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-06 22:03:35,359 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 22:03:35,513 - INFO - training batch 151, loss: 0.062, 4832/28000 datapoints
2025-03-06 22:03:35,666 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:03:35,822 - INFO - training batch 251, loss: 0.073, 8032/28000 datapoints
2025-03-06 22:03:35,982 - INFO - training batch 301, loss: 0.051, 9632/28000 datapoints
2025-03-06 22:03:36,136 - INFO - training batch 351, loss: 0.081, 11232/28000 datapoints
2025-03-06 22:03:36,289 - INFO - training batch 401, loss: 0.052, 12832/28000 datapoints
2025-03-06 22:03:36,441 - INFO - training batch 451, loss: 0.113, 14432/28000 datapoints
2025-03-06 22:03:36,594 - INFO - training batch 501, loss: 0.045, 16032/28000 datapoints
2025-03-06 22:03:36,746 - INFO - training batch 551, loss: 0.051, 17632/28000 datapoints
2025-03-06 22:03:36,905 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 22:03:37,061 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 22:03:37,214 - INFO - training batch 701, loss: 0.022, 22432/28000 datapoints
2025-03-06 22:03:37,366 - INFO - training batch 751, loss: 0.048, 24032/28000 datapoints
2025-03-06 22:03:37,518 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:03:37,668 - INFO - training batch 851, loss: 0.039, 27232/28000 datapoints
2025-03-06 22:03:37,746 - INFO - validation batch 1, loss: 0.476, 32/6976 datapoints
2025-03-06 22:03:37,795 - INFO - validation batch 51, loss: 3.332, 1632/6976 datapoints
2025-03-06 22:03:37,866 - INFO - validation batch 101, loss: 0.931, 3232/6976 datapoints
2025-03-06 22:03:37,918 - INFO - validation batch 151, loss: 1.268, 4832/6976 datapoints
2025-03-06 22:03:37,969 - INFO - validation batch 201, loss: 0.607, 6432/6976 datapoints
2025-03-06 22:03:37,985 - INFO - Epoch 405/800 done.
2025-03-06 22:03:37,986 - INFO - Final validation performance:
Loss: 1.323, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:03:37,987 - INFO - Beginning epoch 406/800
2025-03-06 22:03:37,991 - INFO - training batch 1, loss: 0.055, 32/28000 datapoints
2025-03-06 22:03:38,144 - INFO - training batch 51, loss: 0.026, 1632/28000 datapoints
2025-03-06 22:03:38,291 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 22:03:38,439 - INFO - training batch 151, loss: 0.062, 4832/28000 datapoints
2025-03-06 22:03:38,585 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 22:03:38,732 - INFO - training batch 251, loss: 0.070, 8032/28000 datapoints
2025-03-06 22:03:38,882 - INFO - training batch 301, loss: 0.050, 9632/28000 datapoints
2025-03-06 22:03:39,027 - INFO - training batch 351, loss: 0.078, 11232/28000 datapoints
2025-03-06 22:03:39,174 - INFO - training batch 401, loss: 0.052, 12832/28000 datapoints
2025-03-06 22:03:39,327 - INFO - training batch 451, loss: 0.111, 14432/28000 datapoints
2025-03-06 22:03:39,475 - INFO - training batch 501, loss: 0.044, 16032/28000 datapoints
2025-03-06 22:03:39,624 - INFO - training batch 551, loss: 0.050, 17632/28000 datapoints
2025-03-06 22:03:39,785 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 22:03:39,940 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 22:03:40,095 - INFO - training batch 701, loss: 0.022, 22432/28000 datapoints
2025-03-06 22:03:40,250 - INFO - training batch 751, loss: 0.048, 24032/28000 datapoints
2025-03-06 22:03:40,402 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:03:40,551 - INFO - training batch 851, loss: 0.038, 27232/28000 datapoints
2025-03-06 22:03:40,624 - INFO - validation batch 1, loss: 0.483, 32/6976 datapoints
2025-03-06 22:03:40,670 - INFO - validation batch 51, loss: 3.351, 1632/6976 datapoints
2025-03-06 22:03:40,716 - INFO - validation batch 101, loss: 0.936, 3232/6976 datapoints
2025-03-06 22:03:40,762 - INFO - validation batch 151, loss: 1.274, 4832/6976 datapoints
2025-03-06 22:03:40,809 - INFO - validation batch 201, loss: 0.607, 6432/6976 datapoints
2025-03-06 22:03:40,825 - INFO - Epoch 406/800 done.
2025-03-06 22:03:40,825 - INFO - Final validation performance:
Loss: 1.330, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 22:03:40,825 - INFO - Beginning epoch 407/800
2025-03-06 22:03:40,829 - INFO - training batch 1, loss: 0.054, 32/28000 datapoints
2025-03-06 22:03:40,977 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-06 22:03:41,125 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 22:03:41,280 - INFO - training batch 151, loss: 0.061, 4832/28000 datapoints
2025-03-06 22:03:41,425 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 22:03:41,576 - INFO - training batch 251, loss: 0.071, 8032/28000 datapoints
2025-03-06 22:03:41,729 - INFO - training batch 301, loss: 0.049, 9632/28000 datapoints
2025-03-06 22:03:41,880 - INFO - training batch 351, loss: 0.078, 11232/28000 datapoints
2025-03-06 22:03:42,025 - INFO - training batch 401, loss: 0.051, 12832/28000 datapoints
2025-03-06 22:03:42,174 - INFO - training batch 451, loss: 0.109, 14432/28000 datapoints
2025-03-06 22:03:42,324 - INFO - training batch 501, loss: 0.043, 16032/28000 datapoints
2025-03-06 22:03:42,473 - INFO - training batch 551, loss: 0.049, 17632/28000 datapoints
2025-03-06 22:03:42,623 - INFO - training batch 601, loss: 0.028, 19232/28000 datapoints
2025-03-06 22:03:42,772 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 22:03:42,923 - INFO - training batch 701, loss: 0.021, 22432/28000 datapoints
2025-03-06 22:03:43,069 - INFO - training batch 751, loss: 0.047, 24032/28000 datapoints
2025-03-06 22:03:43,220 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:03:43,368 - INFO - training batch 851, loss: 0.037, 27232/28000 datapoints
2025-03-06 22:03:43,440 - INFO - validation batch 1, loss: 0.478, 32/6976 datapoints
2025-03-06 22:03:43,488 - INFO - validation batch 51, loss: 3.372, 1632/6976 datapoints
2025-03-06 22:03:43,543 - INFO - validation batch 101, loss: 0.940, 3232/6976 datapoints
2025-03-06 22:03:43,590 - INFO - validation batch 151, loss: 1.280, 4832/6976 datapoints
2025-03-06 22:03:43,637 - INFO - validation batch 201, loss: 0.614, 6432/6976 datapoints
2025-03-06 22:03:43,653 - INFO - Epoch 407/800 done.
2025-03-06 22:03:43,653 - INFO - Final validation performance:
Loss: 1.337, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 22:03:43,654 - INFO - Beginning epoch 408/800
2025-03-06 22:03:43,658 - INFO - training batch 1, loss: 0.053, 32/28000 datapoints
2025-03-06 22:03:43,808 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-06 22:03:43,962 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 22:03:44,110 - INFO - training batch 151, loss: 0.060, 4832/28000 datapoints
2025-03-06 22:03:44,280 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 22:03:44,432 - INFO - training batch 251, loss: 0.068, 8032/28000 datapoints
2025-03-06 22:03:44,585 - INFO - training batch 301, loss: 0.048, 9632/28000 datapoints
2025-03-06 22:03:44,732 - INFO - training batch 351, loss: 0.076, 11232/28000 datapoints
2025-03-06 22:03:44,883 - INFO - training batch 401, loss: 0.050, 12832/28000 datapoints
2025-03-06 22:03:45,034 - INFO - training batch 451, loss: 0.107, 14432/28000 datapoints
2025-03-06 22:03:45,192 - INFO - training batch 501, loss: 0.043, 16032/28000 datapoints
2025-03-06 22:03:45,343 - INFO - training batch 551, loss: 0.048, 17632/28000 datapoints
2025-03-06 22:03:45,489 - INFO - training batch 601, loss: 0.028, 19232/28000 datapoints
2025-03-06 22:03:45,637 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 22:03:45,787 - INFO - training batch 701, loss: 0.020, 22432/28000 datapoints
2025-03-06 22:03:45,955 - INFO - training batch 751, loss: 0.046, 24032/28000 datapoints
2025-03-06 22:03:46,102 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:03:46,255 - INFO - training batch 851, loss: 0.036, 27232/28000 datapoints
2025-03-06 22:03:46,334 - INFO - validation batch 1, loss: 0.486, 32/6976 datapoints
2025-03-06 22:03:46,384 - INFO - validation batch 51, loss: 3.392, 1632/6976 datapoints
2025-03-06 22:03:46,432 - INFO - validation batch 101, loss: 0.940, 3232/6976 datapoints
2025-03-06 22:03:46,479 - INFO - validation batch 151, loss: 1.286, 4832/6976 datapoints
2025-03-06 22:03:46,530 - INFO - validation batch 201, loss: 0.615, 6432/6976 datapoints
2025-03-06 22:03:46,546 - INFO - Epoch 408/800 done.
2025-03-06 22:03:46,546 - INFO - Final validation performance:
Loss: 1.344, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 22:03:46,547 - INFO - Beginning epoch 409/800
2025-03-06 22:03:46,551 - INFO - training batch 1, loss: 0.052, 32/28000 datapoints
2025-03-06 22:03:46,706 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-06 22:03:46,860 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-06 22:03:47,014 - INFO - training batch 151, loss: 0.060, 4832/28000 datapoints
2025-03-06 22:03:47,180 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 22:03:47,341 - INFO - training batch 251, loss: 0.069, 8032/28000 datapoints
2025-03-06 22:03:47,505 - INFO - training batch 301, loss: 0.048, 9632/28000 datapoints
2025-03-06 22:03:47,659 - INFO - training batch 351, loss: 0.074, 11232/28000 datapoints
2025-03-06 22:03:47,815 - INFO - training batch 401, loss: 0.049, 12832/28000 datapoints
2025-03-06 22:03:47,976 - INFO - training batch 451, loss: 0.105, 14432/28000 datapoints
2025-03-06 22:03:48,132 - INFO - training batch 501, loss: 0.043, 16032/28000 datapoints
2025-03-06 22:03:48,298 - INFO - training batch 551, loss: 0.047, 17632/28000 datapoints
2025-03-06 22:03:48,450 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 22:03:48,603 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 22:03:48,756 - INFO - training batch 701, loss: 0.020, 22432/28000 datapoints
2025-03-06 22:03:48,909 - INFO - training batch 751, loss: 0.046, 24032/28000 datapoints
2025-03-06 22:03:49,060 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:03:49,213 - INFO - training batch 851, loss: 0.036, 27232/28000 datapoints
2025-03-06 22:03:49,290 - INFO - validation batch 1, loss: 0.489, 32/6976 datapoints
2025-03-06 22:03:49,343 - INFO - validation batch 51, loss: 3.424, 1632/6976 datapoints
2025-03-06 22:03:49,403 - INFO - validation batch 101, loss: 0.940, 3232/6976 datapoints
2025-03-06 22:03:49,453 - INFO - validation batch 151, loss: 1.288, 4832/6976 datapoints
2025-03-06 22:03:49,505 - INFO - validation batch 201, loss: 0.619, 6432/6976 datapoints
2025-03-06 22:03:49,521 - INFO - Epoch 409/800 done.
2025-03-06 22:03:49,521 - INFO - Final validation performance:
Loss: 1.352, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 22:03:49,522 - INFO - Beginning epoch 410/800
2025-03-06 22:03:49,526 - INFO - training batch 1, loss: 0.051, 32/28000 datapoints
2025-03-06 22:03:49,681 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-06 22:03:49,836 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-06 22:03:49,999 - INFO - training batch 151, loss: 0.058, 4832/28000 datapoints
2025-03-06 22:03:50,150 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 22:03:50,303 - INFO - training batch 251, loss: 0.066, 8032/28000 datapoints
2025-03-06 22:03:50,455 - INFO - training batch 301, loss: 0.048, 9632/28000 datapoints
2025-03-06 22:03:50,607 - INFO - training batch 351, loss: 0.073, 11232/28000 datapoints
2025-03-06 22:03:50,757 - INFO - training batch 401, loss: 0.049, 12832/28000 datapoints
2025-03-06 22:03:50,916 - INFO - training batch 451, loss: 0.103, 14432/28000 datapoints
2025-03-06 22:03:51,072 - INFO - training batch 501, loss: 0.041, 16032/28000 datapoints
2025-03-06 22:03:51,228 - INFO - training batch 551, loss: 0.046, 17632/28000 datapoints
2025-03-06 22:03:51,378 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 22:03:51,531 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 22:03:51,688 - INFO - training batch 701, loss: 0.020, 22432/28000 datapoints
2025-03-06 22:03:51,839 - INFO - training batch 751, loss: 0.045, 24032/28000 datapoints
2025-03-06 22:03:51,996 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:03:52,162 - INFO - training batch 851, loss: 0.035, 27232/28000 datapoints
2025-03-06 22:03:52,239 - INFO - validation batch 1, loss: 0.493, 32/6976 datapoints
2025-03-06 22:03:52,290 - INFO - validation batch 51, loss: 3.436, 1632/6976 datapoints
2025-03-06 22:03:52,341 - INFO - validation batch 101, loss: 0.947, 3232/6976 datapoints
2025-03-06 22:03:52,391 - INFO - validation batch 151, loss: 1.304, 4832/6976 datapoints
2025-03-06 22:03:52,443 - INFO - validation batch 201, loss: 0.622, 6432/6976 datapoints
2025-03-06 22:03:52,461 - INFO - Epoch 410/800 done.
2025-03-06 22:03:52,461 - INFO - Final validation performance:
Loss: 1.360, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:03:52,462 - INFO - Beginning epoch 411/800
2025-03-06 22:03:52,466 - INFO - training batch 1, loss: 0.049, 32/28000 datapoints
2025-03-06 22:03:52,623 - INFO - training batch 51, loss: 0.024, 1632/28000 datapoints
2025-03-06 22:03:52,867 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-06 22:03:53,019 - INFO - training batch 151, loss: 0.057, 4832/28000 datapoints
2025-03-06 22:03:53,172 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 22:03:53,323 - INFO - training batch 251, loss: 0.066, 8032/28000 datapoints
2025-03-06 22:03:53,478 - INFO - training batch 301, loss: 0.045, 9632/28000 datapoints
2025-03-06 22:03:53,629 - INFO - training batch 351, loss: 0.072, 11232/28000 datapoints
2025-03-06 22:03:53,778 - INFO - training batch 401, loss: 0.048, 12832/28000 datapoints
2025-03-06 22:03:53,955 - INFO - training batch 451, loss: 0.101, 14432/28000 datapoints
2025-03-06 22:03:54,141 - INFO - training batch 501, loss: 0.041, 16032/28000 datapoints
2025-03-06 22:03:54,294 - INFO - training batch 551, loss: 0.046, 17632/28000 datapoints
2025-03-06 22:03:54,467 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 22:03:54,621 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 22:03:54,774 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-06 22:03:54,934 - INFO - training batch 751, loss: 0.044, 24032/28000 datapoints
2025-03-06 22:03:55,089 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:03:55,242 - INFO - training batch 851, loss: 0.034, 27232/28000 datapoints
2025-03-06 22:03:55,323 - INFO - validation batch 1, loss: 0.498, 32/6976 datapoints
2025-03-06 22:03:55,374 - INFO - validation batch 51, loss: 3.464, 1632/6976 datapoints
2025-03-06 22:03:55,425 - INFO - validation batch 101, loss: 0.949, 3232/6976 datapoints
2025-03-06 22:03:55,475 - INFO - validation batch 151, loss: 1.302, 4832/6976 datapoints
2025-03-06 22:03:55,526 - INFO - validation batch 201, loss: 0.624, 6432/6976 datapoints
2025-03-06 22:03:55,545 - INFO - Epoch 411/800 done.
2025-03-06 22:03:55,545 - INFO - Final validation performance:
Loss: 1.368, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:03:55,546 - INFO - Beginning epoch 412/800
2025-03-06 22:03:55,550 - INFO - training batch 1, loss: 0.049, 32/28000 datapoints
2025-03-06 22:03:55,701 - INFO - training batch 51, loss: 0.024, 1632/28000 datapoints
2025-03-06 22:03:55,856 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-06 22:03:56,012 - INFO - training batch 151, loss: 0.057, 4832/28000 datapoints
2025-03-06 22:03:56,161 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 22:03:56,313 - INFO - training batch 251, loss: 0.065, 8032/28000 datapoints
2025-03-06 22:03:56,467 - INFO - training batch 301, loss: 0.046, 9632/28000 datapoints
2025-03-06 22:03:56,616 - INFO - training batch 351, loss: 0.070, 11232/28000 datapoints
2025-03-06 22:03:56,765 - INFO - training batch 401, loss: 0.047, 12832/28000 datapoints
2025-03-06 22:03:56,919 - INFO - training batch 451, loss: 0.095, 14432/28000 datapoints
2025-03-06 22:03:57,071 - INFO - training batch 501, loss: 0.042, 16032/28000 datapoints
2025-03-06 22:03:57,224 - INFO - training batch 551, loss: 0.045, 17632/28000 datapoints
2025-03-06 22:03:57,372 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 22:03:57,522 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 22:03:57,672 - INFO - training batch 701, loss: 0.018, 22432/28000 datapoints
2025-03-06 22:03:57,820 - INFO - training batch 751, loss: 0.045, 24032/28000 datapoints
2025-03-06 22:03:57,973 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:03:58,120 - INFO - training batch 851, loss: 0.034, 27232/28000 datapoints
2025-03-06 22:03:58,194 - INFO - validation batch 1, loss: 0.500, 32/6976 datapoints
2025-03-06 22:03:58,242 - INFO - validation batch 51, loss: 3.483, 1632/6976 datapoints
2025-03-06 22:03:58,296 - INFO - validation batch 101, loss: 0.952, 3232/6976 datapoints
2025-03-06 22:03:58,350 - INFO - validation batch 151, loss: 1.310, 4832/6976 datapoints
2025-03-06 22:03:58,397 - INFO - validation batch 201, loss: 0.630, 6432/6976 datapoints
2025-03-06 22:03:58,412 - INFO - Epoch 412/800 done.
2025-03-06 22:03:58,413 - INFO - Final validation performance:
Loss: 1.375, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:03:58,413 - INFO - Beginning epoch 413/800
2025-03-06 22:03:58,417 - INFO - training batch 1, loss: 0.049, 32/28000 datapoints
2025-03-06 22:03:58,566 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-06 22:03:58,718 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 22:03:58,870 - INFO - training batch 151, loss: 0.056, 4832/28000 datapoints
2025-03-06 22:03:59,016 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 22:03:59,165 - INFO - training batch 251, loss: 0.065, 8032/28000 datapoints
2025-03-06 22:03:59,317 - INFO - training batch 301, loss: 0.044, 9632/28000 datapoints
2025-03-06 22:03:59,467 - INFO - training batch 351, loss: 0.069, 11232/28000 datapoints
2025-03-06 22:03:59,613 - INFO - training batch 401, loss: 0.047, 12832/28000 datapoints
2025-03-06 22:03:59,764 - INFO - training batch 451, loss: 0.093, 14432/28000 datapoints
2025-03-06 22:03:59,920 - INFO - training batch 501, loss: 0.041, 16032/28000 datapoints
2025-03-06 22:04:00,076 - INFO - training batch 551, loss: 0.044, 17632/28000 datapoints
2025-03-06 22:04:00,224 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-06 22:04:00,375 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 22:04:00,524 - INFO - training batch 701, loss: 0.018, 22432/28000 datapoints
2025-03-06 22:04:00,672 - INFO - training batch 751, loss: 0.043, 24032/28000 datapoints
2025-03-06 22:04:00,820 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:04:00,970 - INFO - training batch 851, loss: 0.033, 27232/28000 datapoints
2025-03-06 22:04:01,043 - INFO - validation batch 1, loss: 0.501, 32/6976 datapoints
2025-03-06 22:04:01,089 - INFO - validation batch 51, loss: 3.505, 1632/6976 datapoints
2025-03-06 22:04:01,136 - INFO - validation batch 101, loss: 0.957, 3232/6976 datapoints
2025-03-06 22:04:01,182 - INFO - validation batch 151, loss: 1.322, 4832/6976 datapoints
2025-03-06 22:04:01,230 - INFO - validation batch 201, loss: 0.632, 6432/6976 datapoints
2025-03-06 22:04:01,246 - INFO - Epoch 413/800 done.
2025-03-06 22:04:01,246 - INFO - Final validation performance:
Loss: 1.384, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:04:01,247 - INFO - Beginning epoch 414/800
2025-03-06 22:04:01,251 - INFO - training batch 1, loss: 0.048, 32/28000 datapoints
2025-03-06 22:04:01,400 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-06 22:04:01,549 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 22:04:01,698 - INFO - training batch 151, loss: 0.055, 4832/28000 datapoints
2025-03-06 22:04:01,843 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 22:04:02,000 - INFO - training batch 251, loss: 0.063, 8032/28000 datapoints
2025-03-06 22:04:02,150 - INFO - training batch 301, loss: 0.043, 9632/28000 datapoints
2025-03-06 22:04:02,304 - INFO - training batch 351, loss: 0.067, 11232/28000 datapoints
2025-03-06 22:04:02,456 - INFO - training batch 401, loss: 0.046, 12832/28000 datapoints
2025-03-06 22:04:02,606 - INFO - training batch 451, loss: 0.096, 14432/28000 datapoints
2025-03-06 22:04:02,756 - INFO - training batch 501, loss: 0.040, 16032/28000 datapoints
2025-03-06 22:04:02,909 - INFO - training batch 551, loss: 0.044, 17632/28000 datapoints
2025-03-06 22:04:03,145 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 22:04:03,295 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 22:04:03,447 - INFO - training batch 701, loss: 0.018, 22432/28000 datapoints
2025-03-06 22:04:03,596 - INFO - training batch 751, loss: 0.043, 24032/28000 datapoints
2025-03-06 22:04:03,745 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:04:03,894 - INFO - training batch 851, loss: 0.032, 27232/28000 datapoints
2025-03-06 22:04:03,973 - INFO - validation batch 1, loss: 0.500, 32/6976 datapoints
2025-03-06 22:04:04,021 - INFO - validation batch 51, loss: 3.526, 1632/6976 datapoints
2025-03-06 22:04:04,067 - INFO - validation batch 101, loss: 0.959, 3232/6976 datapoints
2025-03-06 22:04:04,113 - INFO - validation batch 151, loss: 1.331, 4832/6976 datapoints
2025-03-06 22:04:04,159 - INFO - validation batch 201, loss: 0.636, 6432/6976 datapoints
2025-03-06 22:04:04,176 - INFO - Epoch 414/800 done.
2025-03-06 22:04:04,176 - INFO - Final validation performance:
Loss: 1.391, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:04:04,176 - INFO - Beginning epoch 415/800
2025-03-06 22:04:04,181 - INFO - training batch 1, loss: 0.047, 32/28000 datapoints
2025-03-06 22:04:04,340 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-06 22:04:04,513 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 22:04:04,662 - INFO - training batch 151, loss: 0.054, 4832/28000 datapoints
2025-03-06 22:04:04,817 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 22:04:04,978 - INFO - training batch 251, loss: 0.062, 8032/28000 datapoints
2025-03-06 22:04:05,135 - INFO - training batch 301, loss: 0.043, 9632/28000 datapoints
2025-03-06 22:04:05,288 - INFO - training batch 351, loss: 0.066, 11232/28000 datapoints
2025-03-06 22:04:05,436 - INFO - training batch 401, loss: 0.046, 12832/28000 datapoints
2025-03-06 22:04:05,587 - INFO - training batch 451, loss: 0.093, 14432/28000 datapoints
2025-03-06 22:04:05,736 - INFO - training batch 501, loss: 0.039, 16032/28000 datapoints
2025-03-06 22:04:05,888 - INFO - training batch 551, loss: 0.043, 17632/28000 datapoints
2025-03-06 22:04:06,041 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 22:04:06,189 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 22:04:06,338 - INFO - training batch 701, loss: 0.017, 22432/28000 datapoints
2025-03-06 22:04:06,487 - INFO - training batch 751, loss: 0.042, 24032/28000 datapoints
2025-03-06 22:04:06,635 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:04:06,794 - INFO - training batch 851, loss: 0.032, 27232/28000 datapoints
2025-03-06 22:04:06,870 - INFO - validation batch 1, loss: 0.499, 32/6976 datapoints
2025-03-06 22:04:06,918 - INFO - validation batch 51, loss: 3.554, 1632/6976 datapoints
2025-03-06 22:04:06,976 - INFO - validation batch 101, loss: 0.963, 3232/6976 datapoints
2025-03-06 22:04:07,023 - INFO - validation batch 151, loss: 1.336, 4832/6976 datapoints
2025-03-06 22:04:07,071 - INFO - validation batch 201, loss: 0.639, 6432/6976 datapoints
2025-03-06 22:04:07,087 - INFO - Epoch 415/800 done.
2025-03-06 22:04:07,087 - INFO - Final validation performance:
Loss: 1.398, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:04:07,088 - INFO - Beginning epoch 416/800
2025-03-06 22:04:07,092 - INFO - training batch 1, loss: 0.047, 32/28000 datapoints
2025-03-06 22:04:07,242 - INFO - training batch 51, loss: 0.022, 1632/28000 datapoints
2025-03-06 22:04:07,394 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 22:04:07,547 - INFO - training batch 151, loss: 0.054, 4832/28000 datapoints
2025-03-06 22:04:07,695 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 22:04:07,843 - INFO - training batch 251, loss: 0.061, 8032/28000 datapoints
2025-03-06 22:04:08,005 - INFO - training batch 301, loss: 0.042, 9632/28000 datapoints
2025-03-06 22:04:08,156 - INFO - training batch 351, loss: 0.065, 11232/28000 datapoints
2025-03-06 22:04:08,310 - INFO - training batch 401, loss: 0.045, 12832/28000 datapoints
2025-03-06 22:04:08,462 - INFO - training batch 451, loss: 0.092, 14432/28000 datapoints
2025-03-06 22:04:08,618 - INFO - training batch 501, loss: 0.038, 16032/28000 datapoints
2025-03-06 22:04:08,772 - INFO - training batch 551, loss: 0.042, 17632/28000 datapoints
2025-03-06 22:04:08,926 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-06 22:04:09,079 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 22:04:09,232 - INFO - training batch 701, loss: 0.017, 22432/28000 datapoints
2025-03-06 22:04:09,395 - INFO - training batch 751, loss: 0.041, 24032/28000 datapoints
2025-03-06 22:04:09,548 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:04:09,695 - INFO - training batch 851, loss: 0.031, 27232/28000 datapoints
2025-03-06 22:04:09,767 - INFO - validation batch 1, loss: 0.506, 32/6976 datapoints
2025-03-06 22:04:09,813 - INFO - validation batch 51, loss: 3.577, 1632/6976 datapoints
2025-03-06 22:04:09,862 - INFO - validation batch 101, loss: 0.965, 3232/6976 datapoints
2025-03-06 22:04:09,908 - INFO - validation batch 151, loss: 1.338, 4832/6976 datapoints
2025-03-06 22:04:09,955 - INFO - validation batch 201, loss: 0.643, 6432/6976 datapoints
2025-03-06 22:04:09,971 - INFO - Epoch 416/800 done.
2025-03-06 22:04:09,972 - INFO - Final validation performance:
Loss: 1.406, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:04:09,972 - INFO - Beginning epoch 417/800
2025-03-06 22:04:09,976 - INFO - training batch 1, loss: 0.046, 32/28000 datapoints
2025-03-06 22:04:10,131 - INFO - training batch 51, loss: 0.022, 1632/28000 datapoints
2025-03-06 22:04:10,280 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 22:04:10,443 - INFO - training batch 151, loss: 0.053, 4832/28000 datapoints
2025-03-06 22:04:10,593 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 22:04:10,742 - INFO - training batch 251, loss: 0.060, 8032/28000 datapoints
2025-03-06 22:04:10,903 - INFO - training batch 301, loss: 0.041, 9632/28000 datapoints
2025-03-06 22:04:11,054 - INFO - training batch 351, loss: 0.064, 11232/28000 datapoints
2025-03-06 22:04:11,203 - INFO - training batch 401, loss: 0.045, 12832/28000 datapoints
2025-03-06 22:04:11,356 - INFO - training batch 451, loss: 0.089, 14432/28000 datapoints
2025-03-06 22:04:11,508 - INFO - training batch 501, loss: 0.037, 16032/28000 datapoints
2025-03-06 22:04:11,659 - INFO - training batch 551, loss: 0.041, 17632/28000 datapoints
2025-03-06 22:04:11,808 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-06 22:04:11,958 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 22:04:12,113 - INFO - training batch 701, loss: 0.017, 22432/28000 datapoints
2025-03-06 22:04:12,262 - INFO - training batch 751, loss: 0.040, 24032/28000 datapoints
2025-03-06 22:04:12,414 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:04:12,564 - INFO - training batch 851, loss: 0.031, 27232/28000 datapoints
2025-03-06 22:04:12,638 - INFO - validation batch 1, loss: 0.499, 32/6976 datapoints
2025-03-06 22:04:12,685 - INFO - validation batch 51, loss: 3.600, 1632/6976 datapoints
2025-03-06 22:04:12,733 - INFO - validation batch 101, loss: 0.970, 3232/6976 datapoints
2025-03-06 22:04:12,779 - INFO - validation batch 151, loss: 1.348, 4832/6976 datapoints
2025-03-06 22:04:12,826 - INFO - validation batch 201, loss: 0.641, 6432/6976 datapoints
2025-03-06 22:04:12,842 - INFO - Epoch 417/800 done.
2025-03-06 22:04:12,842 - INFO - Final validation performance:
Loss: 1.412, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:04:12,843 - INFO - Beginning epoch 418/800
2025-03-06 22:04:12,847 - INFO - training batch 1, loss: 0.046, 32/28000 datapoints
2025-03-06 22:04:12,998 - INFO - training batch 51, loss: 0.022, 1632/28000 datapoints
2025-03-06 22:04:13,157 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 22:04:13,306 - INFO - training batch 151, loss: 0.053, 4832/28000 datapoints
2025-03-06 22:04:13,452 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 22:04:13,602 - INFO - training batch 251, loss: 0.058, 8032/28000 datapoints
2025-03-06 22:04:13,751 - INFO - training batch 301, loss: 0.041, 9632/28000 datapoints
2025-03-06 22:04:13,902 - INFO - training batch 351, loss: 0.062, 11232/28000 datapoints
2025-03-06 22:04:14,053 - INFO - training batch 401, loss: 0.044, 12832/28000 datapoints
2025-03-06 22:04:14,202 - INFO - training batch 451, loss: 0.089, 14432/28000 datapoints
2025-03-06 22:04:14,351 - INFO - training batch 501, loss: 0.037, 16032/28000 datapoints
2025-03-06 22:04:14,512 - INFO - training batch 551, loss: 0.041, 17632/28000 datapoints
2025-03-06 22:04:14,675 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 22:04:14,824 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 22:04:14,983 - INFO - training batch 701, loss: 0.016, 22432/28000 datapoints
2025-03-06 22:04:15,142 - INFO - training batch 751, loss: 0.040, 24032/28000 datapoints
2025-03-06 22:04:15,292 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:04:15,441 - INFO - training batch 851, loss: 0.030, 27232/28000 datapoints
2025-03-06 22:04:15,514 - INFO - validation batch 1, loss: 0.508, 32/6976 datapoints
2025-03-06 22:04:15,560 - INFO - validation batch 51, loss: 3.622, 1632/6976 datapoints
2025-03-06 22:04:15,608 - INFO - validation batch 101, loss: 0.973, 3232/6976 datapoints
2025-03-06 22:04:15,654 - INFO - validation batch 151, loss: 1.357, 4832/6976 datapoints
2025-03-06 22:04:15,700 - INFO - validation batch 201, loss: 0.646, 6432/6976 datapoints
2025-03-06 22:04:15,716 - INFO - Epoch 418/800 done.
2025-03-06 22:04:15,717 - INFO - Final validation performance:
Loss: 1.421, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:04:15,717 - INFO - Beginning epoch 419/800
2025-03-06 22:04:15,721 - INFO - training batch 1, loss: 0.045, 32/28000 datapoints
2025-03-06 22:04:15,872 - INFO - training batch 51, loss: 0.021, 1632/28000 datapoints
2025-03-06 22:04:16,022 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 22:04:16,176 - INFO - training batch 151, loss: 0.052, 4832/28000 datapoints
2025-03-06 22:04:16,324 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 22:04:16,488 - INFO - training batch 251, loss: 0.057, 8032/28000 datapoints
2025-03-06 22:04:16,638 - INFO - training batch 301, loss: 0.040, 9632/28000 datapoints
2025-03-06 22:04:16,788 - INFO - training batch 351, loss: 0.061, 11232/28000 datapoints
2025-03-06 22:04:16,946 - INFO - training batch 401, loss: 0.043, 12832/28000 datapoints
2025-03-06 22:04:17,097 - INFO - training batch 451, loss: 0.086, 14432/28000 datapoints
2025-03-06 22:04:17,249 - INFO - training batch 501, loss: 0.036, 16032/28000 datapoints
2025-03-06 22:04:17,402 - INFO - training batch 551, loss: 0.039, 17632/28000 datapoints
2025-03-06 22:04:17,550 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 22:04:17,716 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 22:04:17,870 - INFO - training batch 701, loss: 0.015, 22432/28000 datapoints
2025-03-06 22:04:18,019 - INFO - training batch 751, loss: 0.040, 24032/28000 datapoints
2025-03-06 22:04:18,175 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:04:18,329 - INFO - training batch 851, loss: 0.029, 27232/28000 datapoints
2025-03-06 22:04:18,403 - INFO - validation batch 1, loss: 0.521, 32/6976 datapoints
2025-03-06 22:04:18,449 - INFO - validation batch 51, loss: 3.648, 1632/6976 datapoints
2025-03-06 22:04:18,496 - INFO - validation batch 101, loss: 0.975, 3232/6976 datapoints
2025-03-06 22:04:18,543 - INFO - validation batch 151, loss: 1.368, 4832/6976 datapoints
2025-03-06 22:04:18,589 - INFO - validation batch 201, loss: 0.656, 6432/6976 datapoints
2025-03-06 22:04:18,605 - INFO - Epoch 419/800 done.
2025-03-06 22:04:18,605 - INFO - Final validation performance:
Loss: 1.434, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:04:18,606 - INFO - Beginning epoch 420/800
2025-03-06 22:04:18,610 - INFO - training batch 1, loss: 0.045, 32/28000 datapoints
2025-03-06 22:04:18,797 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-06 22:04:18,954 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 22:04:19,105 - INFO - training batch 151, loss: 0.051, 4832/28000 datapoints
2025-03-06 22:04:19,254 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 22:04:19,402 - INFO - training batch 251, loss: 0.055, 8032/28000 datapoints
2025-03-06 22:04:19,550 - INFO - training batch 301, loss: 0.039, 9632/28000 datapoints
2025-03-06 22:04:19,700 - INFO - training batch 351, loss: 0.060, 11232/28000 datapoints
2025-03-06 22:04:19,855 - INFO - training batch 401, loss: 0.043, 12832/28000 datapoints
2025-03-06 22:04:20,009 - INFO - training batch 451, loss: 0.081, 14432/28000 datapoints
2025-03-06 22:04:20,169 - INFO - training batch 501, loss: 0.036, 16032/28000 datapoints
2025-03-06 22:04:20,325 - INFO - training batch 551, loss: 0.039, 17632/28000 datapoints
2025-03-06 22:04:20,478 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 22:04:20,632 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 22:04:20,786 - INFO - training batch 701, loss: 0.016, 22432/28000 datapoints
2025-03-06 22:04:20,939 - INFO - training batch 751, loss: 0.039, 24032/28000 datapoints
2025-03-06 22:04:21,093 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:04:21,247 - INFO - training batch 851, loss: 0.028, 27232/28000 datapoints
2025-03-06 22:04:21,322 - INFO - validation batch 1, loss: 0.524, 32/6976 datapoints
2025-03-06 22:04:21,370 - INFO - validation batch 51, loss: 3.679, 1632/6976 datapoints
2025-03-06 22:04:21,416 - INFO - validation batch 101, loss: 0.980, 3232/6976 datapoints
2025-03-06 22:04:21,462 - INFO - validation batch 151, loss: 1.370, 4832/6976 datapoints
2025-03-06 22:04:21,509 - INFO - validation batch 201, loss: 0.659, 6432/6976 datapoints
2025-03-06 22:04:21,525 - INFO - Epoch 420/800 done.
2025-03-06 22:04:21,525 - INFO - Final validation performance:
Loss: 1.442, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:04:21,526 - INFO - Beginning epoch 421/800
2025-03-06 22:04:21,530 - INFO - training batch 1, loss: 0.044, 32/28000 datapoints
2025-03-06 22:04:21,682 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-06 22:04:21,831 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 22:04:21,983 - INFO - training batch 151, loss: 0.050, 4832/28000 datapoints
2025-03-06 22:04:22,135 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 22:04:22,284 - INFO - training batch 251, loss: 0.055, 8032/28000 datapoints
2025-03-06 22:04:22,445 - INFO - training batch 301, loss: 0.039, 9632/28000 datapoints
2025-03-06 22:04:22,617 - INFO - training batch 351, loss: 0.059, 11232/28000 datapoints
2025-03-06 22:04:22,766 - INFO - training batch 401, loss: 0.042, 12832/28000 datapoints
2025-03-06 22:04:22,924 - INFO - training batch 451, loss: 0.079, 14432/28000 datapoints
2025-03-06 22:04:23,097 - INFO - training batch 501, loss: 0.036, 16032/28000 datapoints
2025-03-06 22:04:23,250 - INFO - training batch 551, loss: 0.038, 17632/28000 datapoints
2025-03-06 22:04:23,402 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 22:04:23,552 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 22:04:23,702 - INFO - training batch 701, loss: 0.015, 22432/28000 datapoints
2025-03-06 22:04:23,852 - INFO - training batch 751, loss: 0.038, 24032/28000 datapoints
2025-03-06 22:04:24,003 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:04:24,154 - INFO - training batch 851, loss: 0.027, 27232/28000 datapoints
2025-03-06 22:04:24,228 - INFO - validation batch 1, loss: 0.522, 32/6976 datapoints
2025-03-06 22:04:24,274 - INFO - validation batch 51, loss: 3.696, 1632/6976 datapoints
2025-03-06 22:04:24,321 - INFO - validation batch 101, loss: 0.984, 3232/6976 datapoints
2025-03-06 22:04:24,369 - INFO - validation batch 151, loss: 1.384, 4832/6976 datapoints
2025-03-06 22:04:24,416 - INFO - validation batch 201, loss: 0.664, 6432/6976 datapoints
2025-03-06 22:04:24,432 - INFO - Epoch 421/800 done.
2025-03-06 22:04:24,432 - INFO - Final validation performance:
Loss: 1.450, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:04:24,432 - INFO - Beginning epoch 422/800
2025-03-06 22:04:24,436 - INFO - training batch 1, loss: 0.043, 32/28000 datapoints
2025-03-06 22:04:24,599 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-06 22:04:24,759 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-06 22:04:24,914 - INFO - training batch 151, loss: 0.049, 4832/28000 datapoints
2025-03-06 22:04:25,066 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 22:04:25,223 - INFO - training batch 251, loss: 0.054, 8032/28000 datapoints
2025-03-06 22:04:25,373 - INFO - training batch 301, loss: 0.038, 9632/28000 datapoints
2025-03-06 22:04:25,521 - INFO - training batch 351, loss: 0.057, 11232/28000 datapoints
2025-03-06 22:04:25,670 - INFO - training batch 401, loss: 0.041, 12832/28000 datapoints
2025-03-06 22:04:25,819 - INFO - training batch 451, loss: 0.078, 14432/28000 datapoints
2025-03-06 22:04:25,971 - INFO - training batch 501, loss: 0.035, 16032/28000 datapoints
2025-03-06 22:04:26,126 - INFO - training batch 551, loss: 0.038, 17632/28000 datapoints
2025-03-06 22:04:26,275 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 22:04:26,423 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 22:04:26,572 - INFO - training batch 701, loss: 0.015, 22432/28000 datapoints
2025-03-06 22:04:26,721 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-06 22:04:26,874 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:04:27,023 - INFO - training batch 851, loss: 0.027, 27232/28000 datapoints
2025-03-06 22:04:27,095 - INFO - validation batch 1, loss: 0.524, 32/6976 datapoints
2025-03-06 22:04:27,142 - INFO - validation batch 51, loss: 3.726, 1632/6976 datapoints
2025-03-06 22:04:27,189 - INFO - validation batch 101, loss: 0.986, 3232/6976 datapoints
2025-03-06 22:04:27,236 - INFO - validation batch 151, loss: 1.389, 4832/6976 datapoints
2025-03-06 22:04:27,283 - INFO - validation batch 201, loss: 0.667, 6432/6976 datapoints
2025-03-06 22:04:27,300 - INFO - Epoch 422/800 done.
2025-03-06 22:04:27,300 - INFO - Final validation performance:
Loss: 1.458, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:04:27,300 - INFO - Beginning epoch 423/800
2025-03-06 22:04:27,304 - INFO - training batch 1, loss: 0.043, 32/28000 datapoints
2025-03-06 22:04:27,460 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-06 22:04:27,613 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-06 22:04:27,767 - INFO - training batch 151, loss: 0.050, 4832/28000 datapoints
2025-03-06 22:04:27,923 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 22:04:28,077 - INFO - training batch 251, loss: 0.053, 8032/28000 datapoints
2025-03-06 22:04:28,238 - INFO - training batch 301, loss: 0.037, 9632/28000 datapoints
2025-03-06 22:04:28,395 - INFO - training batch 351, loss: 0.055, 11232/28000 datapoints
2025-03-06 22:04:28,557 - INFO - training batch 401, loss: 0.041, 12832/28000 datapoints
2025-03-06 22:04:28,713 - INFO - training batch 451, loss: 0.076, 14432/28000 datapoints
2025-03-06 22:04:28,874 - INFO - training batch 501, loss: 0.034, 16032/28000 datapoints
2025-03-06 22:04:29,037 - INFO - training batch 551, loss: 0.037, 17632/28000 datapoints
2025-03-06 22:04:29,191 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 22:04:29,348 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 22:04:29,500 - INFO - training batch 701, loss: 0.015, 22432/28000 datapoints
2025-03-06 22:04:29,654 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-06 22:04:29,809 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:04:29,964 - INFO - training batch 851, loss: 0.026, 27232/28000 datapoints
2025-03-06 22:04:30,040 - INFO - validation batch 1, loss: 0.524, 32/6976 datapoints
2025-03-06 22:04:30,090 - INFO - validation batch 51, loss: 3.744, 1632/6976 datapoints
2025-03-06 22:04:30,147 - INFO - validation batch 101, loss: 0.993, 3232/6976 datapoints
2025-03-06 22:04:30,197 - INFO - validation batch 151, loss: 1.407, 4832/6976 datapoints
2025-03-06 22:04:30,247 - INFO - validation batch 201, loss: 0.673, 6432/6976 datapoints
2025-03-06 22:04:30,262 - INFO - Epoch 423/800 done.
2025-03-06 22:04:30,262 - INFO - Final validation performance:
Loss: 1.468, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:04:30,263 - INFO - Beginning epoch 424/800
2025-03-06 22:04:30,267 - INFO - training batch 1, loss: 0.042, 32/28000 datapoints
2025-03-06 22:04:30,421 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-06 22:04:30,568 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-06 22:04:30,717 - INFO - training batch 151, loss: 0.048, 4832/28000 datapoints
2025-03-06 22:04:30,871 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 22:04:31,019 - INFO - training batch 251, loss: 0.053, 8032/28000 datapoints
2025-03-06 22:04:31,167 - INFO - training batch 301, loss: 0.036, 9632/28000 datapoints
2025-03-06 22:04:31,319 - INFO - training batch 351, loss: 0.055, 11232/28000 datapoints
2025-03-06 22:04:31,466 - INFO - training batch 401, loss: 0.040, 12832/28000 datapoints
2025-03-06 22:04:31,614 - INFO - training batch 451, loss: 0.074, 14432/28000 datapoints
2025-03-06 22:04:31,762 - INFO - training batch 501, loss: 0.034, 16032/28000 datapoints
2025-03-06 22:04:31,915 - INFO - training batch 551, loss: 0.036, 17632/28000 datapoints
2025-03-06 22:04:32,066 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 22:04:32,221 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 22:04:32,376 - INFO - training batch 701, loss: 0.014, 22432/28000 datapoints
2025-03-06 22:04:32,528 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-06 22:04:32,678 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:04:32,830 - INFO - training batch 851, loss: 0.027, 27232/28000 datapoints
2025-03-06 22:04:32,908 - INFO - validation batch 1, loss: 0.519, 32/6976 datapoints
2025-03-06 22:04:32,954 - INFO - validation batch 51, loss: 3.779, 1632/6976 datapoints
2025-03-06 22:04:33,001 - INFO - validation batch 101, loss: 0.995, 3232/6976 datapoints
2025-03-06 22:04:33,050 - INFO - validation batch 151, loss: 1.402, 4832/6976 datapoints
2025-03-06 22:04:33,097 - INFO - validation batch 201, loss: 0.670, 6432/6976 datapoints
2025-03-06 22:04:33,114 - INFO - Epoch 424/800 done.
2025-03-06 22:04:33,114 - INFO - Final validation performance:
Loss: 1.473, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:04:33,115 - INFO - Beginning epoch 425/800
2025-03-06 22:04:33,119 - INFO - training batch 1, loss: 0.043, 32/28000 datapoints
2025-03-06 22:04:33,267 - INFO - training batch 51, loss: 0.019, 1632/28000 datapoints
2025-03-06 22:04:33,419 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 22:04:33,572 - INFO - training batch 151, loss: 0.048, 4832/28000 datapoints
2025-03-06 22:04:33,722 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 22:04:33,877 - INFO - training batch 251, loss: 0.051, 8032/28000 datapoints
2025-03-06 22:04:34,028 - INFO - training batch 301, loss: 0.034, 9632/28000 datapoints
2025-03-06 22:04:34,186 - INFO - training batch 351, loss: 0.054, 11232/28000 datapoints
2025-03-06 22:04:34,337 - INFO - training batch 401, loss: 0.040, 12832/28000 datapoints
2025-03-06 22:04:34,491 - INFO - training batch 451, loss: 0.072, 14432/28000 datapoints
2025-03-06 22:04:34,661 - INFO - training batch 501, loss: 0.034, 16032/28000 datapoints
2025-03-06 22:04:34,830 - INFO - training batch 551, loss: 0.035, 17632/28000 datapoints
2025-03-06 22:04:34,997 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 22:04:35,165 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 22:04:35,319 - INFO - training batch 701, loss: 0.014, 22432/28000 datapoints
2025-03-06 22:04:35,475 - INFO - training batch 751, loss: 0.036, 24032/28000 datapoints
2025-03-06 22:04:35,631 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:04:35,781 - INFO - training batch 851, loss: 0.024, 27232/28000 datapoints
2025-03-06 22:04:35,858 - INFO - validation batch 1, loss: 0.531, 32/6976 datapoints
2025-03-06 22:04:35,904 - INFO - validation batch 51, loss: 3.801, 1632/6976 datapoints
2025-03-06 22:04:35,950 - INFO - validation batch 101, loss: 1.003, 3232/6976 datapoints
2025-03-06 22:04:35,996 - INFO - validation batch 151, loss: 1.418, 4832/6976 datapoints
2025-03-06 22:04:36,042 - INFO - validation batch 201, loss: 0.677, 6432/6976 datapoints
2025-03-06 22:04:36,058 - INFO - Epoch 425/800 done.
2025-03-06 22:04:36,058 - INFO - Final validation performance:
Loss: 1.486, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:04:36,059 - INFO - Beginning epoch 426/800
2025-03-06 22:04:36,063 - INFO - training batch 1, loss: 0.041, 32/28000 datapoints
2025-03-06 22:04:36,216 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-06 22:04:36,366 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 22:04:36,520 - INFO - training batch 151, loss: 0.047, 4832/28000 datapoints
2025-03-06 22:04:36,666 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 22:04:36,815 - INFO - training batch 251, loss: 0.051, 8032/28000 datapoints
2025-03-06 22:04:36,965 - INFO - training batch 301, loss: 0.034, 9632/28000 datapoints
2025-03-06 22:04:37,119 - INFO - training batch 351, loss: 0.052, 11232/28000 datapoints
2025-03-06 22:04:37,267 - INFO - training batch 401, loss: 0.039, 12832/28000 datapoints
2025-03-06 22:04:37,417 - INFO - training batch 451, loss: 0.070, 14432/28000 datapoints
2025-03-06 22:04:37,564 - INFO - training batch 501, loss: 0.033, 16032/28000 datapoints
2025-03-06 22:04:37,714 - INFO - training batch 551, loss: 0.035, 17632/28000 datapoints
2025-03-06 22:04:37,881 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 22:04:38,030 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 22:04:38,183 - INFO - training batch 701, loss: 0.014, 22432/28000 datapoints
2025-03-06 22:04:38,332 - INFO - training batch 751, loss: 0.036, 24032/28000 datapoints
2025-03-06 22:04:38,485 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:04:38,632 - INFO - training batch 851, loss: 0.024, 27232/28000 datapoints
2025-03-06 22:04:38,707 - INFO - validation batch 1, loss: 0.534, 32/6976 datapoints
2025-03-06 22:04:38,753 - INFO - validation batch 51, loss: 3.827, 1632/6976 datapoints
2025-03-06 22:04:38,799 - INFO - validation batch 101, loss: 1.008, 3232/6976 datapoints
2025-03-06 22:04:38,845 - INFO - validation batch 151, loss: 1.431, 4832/6976 datapoints
2025-03-06 22:04:38,895 - INFO - validation batch 201, loss: 0.685, 6432/6976 datapoints
2025-03-06 22:04:38,911 - INFO - Epoch 426/800 done.
2025-03-06 22:04:38,911 - INFO - Final validation performance:
Loss: 1.497, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:04:38,912 - INFO - Beginning epoch 427/800
2025-03-06 22:04:38,916 - INFO - training batch 1, loss: 0.040, 32/28000 datapoints
2025-03-06 22:04:39,075 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-06 22:04:39,223 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 22:04:39,382 - INFO - training batch 151, loss: 0.046, 4832/28000 datapoints
2025-03-06 22:04:39,531 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 22:04:39,679 - INFO - training batch 251, loss: 0.049, 8032/28000 datapoints
2025-03-06 22:04:39,827 - INFO - training batch 301, loss: 0.034, 9632/28000 datapoints
2025-03-06 22:04:39,985 - INFO - training batch 351, loss: 0.052, 11232/28000 datapoints
2025-03-06 22:04:40,137 - INFO - training batch 401, loss: 0.039, 12832/28000 datapoints
2025-03-06 22:04:40,287 - INFO - training batch 451, loss: 0.069, 14432/28000 datapoints
2025-03-06 22:04:40,440 - INFO - training batch 501, loss: 0.033, 16032/28000 datapoints
2025-03-06 22:04:40,589 - INFO - training batch 551, loss: 0.035, 17632/28000 datapoints
2025-03-06 22:04:40,746 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-06 22:04:40,899 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 22:04:41,050 - INFO - training batch 701, loss: 0.014, 22432/28000 datapoints
2025-03-06 22:04:41,206 - INFO - training batch 751, loss: 0.035, 24032/28000 datapoints
2025-03-06 22:04:41,360 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:04:41,517 - INFO - training batch 851, loss: 0.023, 27232/28000 datapoints
2025-03-06 22:04:41,592 - INFO - validation batch 1, loss: 0.534, 32/6976 datapoints
2025-03-06 22:04:41,638 - INFO - validation batch 51, loss: 3.861, 1632/6976 datapoints
2025-03-06 22:04:41,684 - INFO - validation batch 101, loss: 1.009, 3232/6976 datapoints
2025-03-06 22:04:41,731 - INFO - validation batch 151, loss: 1.437, 4832/6976 datapoints
2025-03-06 22:04:41,777 - INFO - validation batch 201, loss: 0.686, 6432/6976 datapoints
2025-03-06 22:04:41,793 - INFO - Epoch 427/800 done.
2025-03-06 22:04:41,793 - INFO - Final validation performance:
Loss: 1.505, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:04:41,794 - INFO - Beginning epoch 428/800
2025-03-06 22:04:41,798 - INFO - training batch 1, loss: 0.040, 32/28000 datapoints
2025-03-06 22:04:41,954 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-06 22:04:42,101 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 22:04:42,256 - INFO - training batch 151, loss: 0.046, 4832/28000 datapoints
2025-03-06 22:04:42,403 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 22:04:42,553 - INFO - training batch 251, loss: 0.047, 8032/28000 datapoints
2025-03-06 22:04:42,706 - INFO - training batch 301, loss: 0.032, 9632/28000 datapoints
2025-03-06 22:04:42,864 - INFO - training batch 351, loss: 0.050, 11232/28000 datapoints
2025-03-06 22:04:43,013 - INFO - training batch 401, loss: 0.038, 12832/28000 datapoints
2025-03-06 22:04:43,165 - INFO - training batch 451, loss: 0.067, 14432/28000 datapoints
2025-03-06 22:04:43,315 - INFO - training batch 501, loss: 0.032, 16032/28000 datapoints
2025-03-06 22:04:43,466 - INFO - training batch 551, loss: 0.034, 17632/28000 datapoints
2025-03-06 22:04:43,614 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-06 22:04:43,762 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 22:04:43,913 - INFO - training batch 701, loss: 0.013, 22432/28000 datapoints
2025-03-06 22:04:44,063 - INFO - training batch 751, loss: 0.035, 24032/28000 datapoints
2025-03-06 22:04:44,216 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:04:44,365 - INFO - training batch 851, loss: 0.023, 27232/28000 datapoints
2025-03-06 22:04:44,438 - INFO - validation batch 1, loss: 0.542, 32/6976 datapoints
2025-03-06 22:04:44,485 - INFO - validation batch 51, loss: 3.890, 1632/6976 datapoints
2025-03-06 22:04:44,531 - INFO - validation batch 101, loss: 1.012, 3232/6976 datapoints
2025-03-06 22:04:44,578 - INFO - validation batch 151, loss: 1.435, 4832/6976 datapoints
2025-03-06 22:04:44,624 - INFO - validation batch 201, loss: 0.693, 6432/6976 datapoints
2025-03-06 22:04:44,641 - INFO - Epoch 428/800 done.
2025-03-06 22:04:44,641 - INFO - Final validation performance:
Loss: 1.514, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:04:44,641 - INFO - Beginning epoch 429/800
2025-03-06 22:04:44,646 - INFO - training batch 1, loss: 0.039, 32/28000 datapoints
2025-03-06 22:04:44,836 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-06 22:04:44,995 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 22:04:45,152 - INFO - training batch 151, loss: 0.045, 4832/28000 datapoints
2025-03-06 22:04:45,303 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 22:04:45,454 - INFO - training batch 251, loss: 0.047, 8032/28000 datapoints
2025-03-06 22:04:45,605 - INFO - training batch 301, loss: 0.032, 9632/28000 datapoints
2025-03-06 22:04:45,757 - INFO - training batch 351, loss: 0.049, 11232/28000 datapoints
2025-03-06 22:04:45,907 - INFO - training batch 401, loss: 0.038, 12832/28000 datapoints
2025-03-06 22:04:46,061 - INFO - training batch 451, loss: 0.064, 14432/28000 datapoints
2025-03-06 22:04:46,217 - INFO - training batch 501, loss: 0.032, 16032/28000 datapoints
2025-03-06 22:04:46,366 - INFO - training batch 551, loss: 0.033, 17632/28000 datapoints
2025-03-06 22:04:46,517 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-06 22:04:46,664 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 22:04:46,826 - INFO - training batch 701, loss: 0.013, 22432/28000 datapoints
2025-03-06 22:04:46,977 - INFO - training batch 751, loss: 0.034, 24032/28000 datapoints
2025-03-06 22:04:47,132 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:04:47,287 - INFO - training batch 851, loss: 0.022, 27232/28000 datapoints
2025-03-06 22:04:47,364 - INFO - validation batch 1, loss: 0.547, 32/6976 datapoints
2025-03-06 22:04:47,413 - INFO - validation batch 51, loss: 3.914, 1632/6976 datapoints
2025-03-06 22:04:47,459 - INFO - validation batch 101, loss: 1.019, 3232/6976 datapoints
2025-03-06 22:04:47,507 - INFO - validation batch 151, loss: 1.453, 4832/6976 datapoints
2025-03-06 22:04:47,557 - INFO - validation batch 201, loss: 0.698, 6432/6976 datapoints
2025-03-06 22:04:47,573 - INFO - Epoch 429/800 done.
2025-03-06 22:04:47,573 - INFO - Final validation performance:
Loss: 1.526, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:04:47,574 - INFO - Beginning epoch 430/800
2025-03-06 22:04:47,578 - INFO - training batch 1, loss: 0.038, 32/28000 datapoints
2025-03-06 22:04:47,744 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-06 22:04:47,903 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 22:04:48,063 - INFO - training batch 151, loss: 0.045, 4832/28000 datapoints
2025-03-06 22:04:48,222 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 22:04:48,382 - INFO - training batch 251, loss: 0.046, 8032/28000 datapoints
2025-03-06 22:04:48,539 - INFO - training batch 301, loss: 0.031, 9632/28000 datapoints
2025-03-06 22:04:48,695 - INFO - training batch 351, loss: 0.048, 11232/28000 datapoints
2025-03-06 22:04:48,845 - INFO - training batch 401, loss: 0.037, 12832/28000 datapoints
2025-03-06 22:04:49,004 - INFO - training batch 451, loss: 0.063, 14432/28000 datapoints
2025-03-06 22:04:49,175 - INFO - training batch 501, loss: 0.031, 16032/28000 datapoints
2025-03-06 22:04:49,334 - INFO - training batch 551, loss: 0.032, 17632/28000 datapoints
2025-03-06 22:04:49,489 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-06 22:04:49,646 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 22:04:49,802 - INFO - training batch 701, loss: 0.013, 22432/28000 datapoints
2025-03-06 22:04:49,961 - INFO - training batch 751, loss: 0.034, 24032/28000 datapoints
2025-03-06 22:04:50,121 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:04:50,283 - INFO - training batch 851, loss: 0.021, 27232/28000 datapoints
2025-03-06 22:04:50,363 - INFO - validation batch 1, loss: 0.554, 32/6976 datapoints
2025-03-06 22:04:50,413 - INFO - validation batch 51, loss: 3.940, 1632/6976 datapoints
2025-03-06 22:04:50,465 - INFO - validation batch 101, loss: 1.025, 3232/6976 datapoints
2025-03-06 22:04:50,517 - INFO - validation batch 151, loss: 1.472, 4832/6976 datapoints
2025-03-06 22:04:50,569 - INFO - validation batch 201, loss: 0.701, 6432/6976 datapoints
2025-03-06 22:04:50,585 - INFO - Epoch 430/800 done.
2025-03-06 22:04:50,586 - INFO - Final validation performance:
Loss: 1.538, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:04:50,586 - INFO - Beginning epoch 431/800
2025-03-06 22:04:50,591 - INFO - training batch 1, loss: 0.038, 32/28000 datapoints
2025-03-06 22:04:50,749 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-06 22:04:50,904 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 22:04:51,061 - INFO - training batch 151, loss: 0.043, 4832/28000 datapoints
2025-03-06 22:04:51,212 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 22:04:51,370 - INFO - training batch 251, loss: 0.043, 8032/28000 datapoints
2025-03-06 22:04:51,525 - INFO - training batch 301, loss: 0.030, 9632/28000 datapoints
2025-03-06 22:04:51,678 - INFO - training batch 351, loss: 0.047, 11232/28000 datapoints
2025-03-06 22:04:51,826 - INFO - training batch 401, loss: 0.037, 12832/28000 datapoints
2025-03-06 22:04:51,980 - INFO - training batch 451, loss: 0.061, 14432/28000 datapoints
2025-03-06 22:04:52,131 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-06 22:04:52,285 - INFO - training batch 551, loss: 0.031, 17632/28000 datapoints
2025-03-06 22:04:52,435 - INFO - training batch 601, loss: 0.018, 19232/28000 datapoints
2025-03-06 22:04:52,588 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 22:04:52,737 - INFO - training batch 701, loss: 0.013, 22432/28000 datapoints
2025-03-06 22:04:52,921 - INFO - training batch 751, loss: 0.033, 24032/28000 datapoints
2025-03-06 22:04:53,079 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:04:53,238 - INFO - training batch 851, loss: 0.021, 27232/28000 datapoints
2025-03-06 22:04:53,316 - INFO - validation batch 1, loss: 0.540, 32/6976 datapoints
2025-03-06 22:04:53,363 - INFO - validation batch 51, loss: 3.979, 1632/6976 datapoints
2025-03-06 22:04:53,414 - INFO - validation batch 101, loss: 1.024, 3232/6976 datapoints
2025-03-06 22:04:53,463 - INFO - validation batch 151, loss: 1.458, 4832/6976 datapoints
2025-03-06 22:04:53,510 - INFO - validation batch 201, loss: 0.701, 6432/6976 datapoints
2025-03-06 22:04:53,527 - INFO - Epoch 431/800 done.
2025-03-06 22:04:53,527 - INFO - Final validation performance:
Loss: 1.540, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:04:53,528 - INFO - Beginning epoch 432/800
2025-03-06 22:04:53,532 - INFO - training batch 1, loss: 0.038, 32/28000 datapoints
2025-03-06 22:04:53,687 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 22:04:53,834 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 22:04:53,988 - INFO - training batch 151, loss: 0.043, 4832/28000 datapoints
2025-03-06 22:04:54,139 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 22:04:54,290 - INFO - training batch 251, loss: 0.044, 8032/28000 datapoints
2025-03-06 22:04:54,440 - INFO - training batch 301, loss: 0.031, 9632/28000 datapoints
2025-03-06 22:04:54,592 - INFO - training batch 351, loss: 0.046, 11232/28000 datapoints
2025-03-06 22:04:54,740 - INFO - training batch 401, loss: 0.036, 12832/28000 datapoints
2025-03-06 22:04:54,915 - INFO - training batch 451, loss: 0.059, 14432/28000 datapoints
2025-03-06 22:04:55,076 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-06 22:04:55,232 - INFO - training batch 551, loss: 0.031, 17632/28000 datapoints
2025-03-06 22:04:55,384 - INFO - training batch 601, loss: 0.018, 19232/28000 datapoints
2025-03-06 22:04:55,531 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 22:04:55,682 - INFO - training batch 701, loss: 0.012, 22432/28000 datapoints
2025-03-06 22:04:55,830 - INFO - training batch 751, loss: 0.032, 24032/28000 datapoints
2025-03-06 22:04:55,990 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:04:56,139 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-06 22:04:56,215 - INFO - validation batch 1, loss: 0.562, 32/6976 datapoints
2025-03-06 22:04:56,262 - INFO - validation batch 51, loss: 4.005, 1632/6976 datapoints
2025-03-06 22:04:56,308 - INFO - validation batch 101, loss: 1.031, 3232/6976 datapoints
2025-03-06 22:04:56,357 - INFO - validation batch 151, loss: 1.478, 4832/6976 datapoints
2025-03-06 22:04:56,403 - INFO - validation batch 201, loss: 0.713, 6432/6976 datapoints
2025-03-06 22:04:56,419 - INFO - Epoch 432/800 done.
2025-03-06 22:04:56,419 - INFO - Final validation performance:
Loss: 1.558, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:04:56,420 - INFO - Beginning epoch 433/800
2025-03-06 22:04:56,424 - INFO - training batch 1, loss: 0.037, 32/28000 datapoints
2025-03-06 22:04:56,573 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 22:04:56,725 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 22:04:56,876 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-06 22:04:57,024 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 22:04:57,176 - INFO - training batch 251, loss: 0.042, 8032/28000 datapoints
2025-03-06 22:04:57,325 - INFO - training batch 301, loss: 0.030, 9632/28000 datapoints
2025-03-06 22:04:57,476 - INFO - training batch 351, loss: 0.045, 11232/28000 datapoints
2025-03-06 22:04:57,624 - INFO - training batch 401, loss: 0.036, 12832/28000 datapoints
2025-03-06 22:04:57,775 - INFO - training batch 451, loss: 0.058, 14432/28000 datapoints
2025-03-06 22:04:57,926 - INFO - training batch 501, loss: 0.029, 16032/28000 datapoints
2025-03-06 22:04:58,077 - INFO - training batch 551, loss: 0.031, 17632/28000 datapoints
2025-03-06 22:04:58,233 - INFO - training batch 601, loss: 0.017, 19232/28000 datapoints
2025-03-06 22:04:58,383 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:04:58,534 - INFO - training batch 701, loss: 0.012, 22432/28000 datapoints
2025-03-06 22:04:58,683 - INFO - training batch 751, loss: 0.032, 24032/28000 datapoints
2025-03-06 22:04:58,835 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:04:58,988 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-06 22:04:59,078 - INFO - validation batch 1, loss: 0.563, 32/6976 datapoints
2025-03-06 22:04:59,125 - INFO - validation batch 51, loss: 4.039, 1632/6976 datapoints
2025-03-06 22:04:59,173 - INFO - validation batch 101, loss: 1.036, 3232/6976 datapoints
2025-03-06 22:04:59,219 - INFO - validation batch 151, loss: 1.491, 4832/6976 datapoints
2025-03-06 22:04:59,265 - INFO - validation batch 201, loss: 0.720, 6432/6976 datapoints
2025-03-06 22:04:59,281 - INFO - Epoch 433/800 done.
2025-03-06 22:04:59,281 - INFO - Final validation performance:
Loss: 1.569, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:04:59,281 - INFO - Beginning epoch 434/800
2025-03-06 22:04:59,285 - INFO - training batch 1, loss: 0.036, 32/28000 datapoints
2025-03-06 22:04:59,448 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 22:04:59,597 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 22:04:59,749 - INFO - training batch 151, loss: 0.041, 4832/28000 datapoints
2025-03-06 22:04:59,902 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 22:05:00,052 - INFO - training batch 251, loss: 0.040, 8032/28000 datapoints
2025-03-06 22:05:00,207 - INFO - training batch 301, loss: 0.028, 9632/28000 datapoints
2025-03-06 22:05:00,365 - INFO - training batch 351, loss: 0.044, 11232/28000 datapoints
2025-03-06 22:05:00,517 - INFO - training batch 401, loss: 0.035, 12832/28000 datapoints
2025-03-06 22:05:00,673 - INFO - training batch 451, loss: 0.056, 14432/28000 datapoints
2025-03-06 22:05:00,827 - INFO - training batch 501, loss: 0.029, 16032/28000 datapoints
2025-03-06 22:05:00,983 - INFO - training batch 551, loss: 0.030, 17632/28000 datapoints
2025-03-06 22:05:01,140 - INFO - training batch 601, loss: 0.017, 19232/28000 datapoints
2025-03-06 22:05:01,292 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:05:01,452 - INFO - training batch 701, loss: 0.012, 22432/28000 datapoints
2025-03-06 22:05:01,605 - INFO - training batch 751, loss: 0.031, 24032/28000 datapoints
2025-03-06 22:05:01,761 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:05:01,917 - INFO - training batch 851, loss: 0.019, 27232/28000 datapoints
2025-03-06 22:05:01,993 - INFO - validation batch 1, loss: 0.571, 32/6976 datapoints
2025-03-06 22:05:02,040 - INFO - validation batch 51, loss: 4.064, 1632/6976 datapoints
2025-03-06 22:05:02,087 - INFO - validation batch 101, loss: 1.045, 3232/6976 datapoints
2025-03-06 22:05:02,134 - INFO - validation batch 151, loss: 1.510, 4832/6976 datapoints
2025-03-06 22:05:02,180 - INFO - validation batch 201, loss: 0.725, 6432/6976 datapoints
2025-03-06 22:05:02,198 - INFO - Epoch 434/800 done.
2025-03-06 22:05:02,198 - INFO - Final validation performance:
Loss: 1.583, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:05:02,198 - INFO - Beginning epoch 435/800
2025-03-06 22:05:02,206 - INFO - training batch 1, loss: 0.035, 32/28000 datapoints
2025-03-06 22:05:02,363 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 22:05:02,512 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 22:05:02,663 - INFO - training batch 151, loss: 0.041, 4832/28000 datapoints
2025-03-06 22:05:02,814 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 22:05:02,965 - INFO - training batch 251, loss: 0.042, 8032/28000 datapoints
2025-03-06 22:05:03,119 - INFO - training batch 301, loss: 0.028, 9632/28000 datapoints
2025-03-06 22:05:03,277 - INFO - training batch 351, loss: 0.042, 11232/28000 datapoints
2025-03-06 22:05:03,430 - INFO - training batch 401, loss: 0.035, 12832/28000 datapoints
2025-03-06 22:05:03,582 - INFO - training batch 451, loss: 0.055, 14432/28000 datapoints
2025-03-06 22:05:03,734 - INFO - training batch 501, loss: 0.029, 16032/28000 datapoints
2025-03-06 22:05:03,885 - INFO - training batch 551, loss: 0.029, 17632/28000 datapoints
2025-03-06 22:05:04,035 - INFO - training batch 601, loss: 0.016, 19232/28000 datapoints
2025-03-06 22:05:04,184 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:05:04,336 - INFO - training batch 701, loss: 0.011, 22432/28000 datapoints
2025-03-06 22:05:04,487 - INFO - training batch 751, loss: 0.030, 24032/28000 datapoints
2025-03-06 22:05:04,639 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:05:04,789 - INFO - training batch 851, loss: 0.018, 27232/28000 datapoints
2025-03-06 22:05:04,868 - INFO - validation batch 1, loss: 0.571, 32/6976 datapoints
2025-03-06 22:05:04,923 - INFO - validation batch 51, loss: 4.111, 1632/6976 datapoints
2025-03-06 22:05:04,999 - INFO - validation batch 101, loss: 1.048, 3232/6976 datapoints
2025-03-06 22:05:05,048 - INFO - validation batch 151, loss: 1.514, 4832/6976 datapoints
2025-03-06 22:05:05,095 - INFO - validation batch 201, loss: 0.722, 6432/6976 datapoints
2025-03-06 22:05:05,113 - INFO - Epoch 435/800 done.
2025-03-06 22:05:05,113 - INFO - Final validation performance:
Loss: 1.593, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:05:05,114 - INFO - Beginning epoch 436/800
2025-03-06 22:05:05,118 - INFO - training batch 1, loss: 0.035, 32/28000 datapoints
2025-03-06 22:05:05,294 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 22:05:05,458 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 22:05:05,608 - INFO - training batch 151, loss: 0.039, 4832/28000 datapoints
2025-03-06 22:05:05,758 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 22:05:05,910 - INFO - training batch 251, loss: 0.039, 8032/28000 datapoints
2025-03-06 22:05:06,060 - INFO - training batch 301, loss: 0.028, 9632/28000 datapoints
2025-03-06 22:05:06,213 - INFO - training batch 351, loss: 0.041, 11232/28000 datapoints
2025-03-06 22:05:06,365 - INFO - training batch 401, loss: 0.034, 12832/28000 datapoints
2025-03-06 22:05:06,518 - INFO - training batch 451, loss: 0.054, 14432/28000 datapoints
2025-03-06 22:05:06,666 - INFO - training batch 501, loss: 0.028, 16032/28000 datapoints
2025-03-06 22:05:06,816 - INFO - training batch 551, loss: 0.028, 17632/28000 datapoints
2025-03-06 22:05:06,968 - INFO - training batch 601, loss: 0.016, 19232/28000 datapoints
2025-03-06 22:05:07,121 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:05:07,275 - INFO - training batch 701, loss: 0.012, 22432/28000 datapoints
2025-03-06 22:05:07,424 - INFO - training batch 751, loss: 0.031, 24032/28000 datapoints
2025-03-06 22:05:07,576 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:05:07,725 - INFO - training batch 851, loss: 0.018, 27232/28000 datapoints
2025-03-06 22:05:07,807 - INFO - validation batch 1, loss: 0.579, 32/6976 datapoints
2025-03-06 22:05:07,860 - INFO - validation batch 51, loss: 4.134, 1632/6976 datapoints
2025-03-06 22:05:07,910 - INFO - validation batch 101, loss: 1.052, 3232/6976 datapoints
2025-03-06 22:05:07,959 - INFO - validation batch 151, loss: 1.522, 4832/6976 datapoints
2025-03-06 22:05:08,009 - INFO - validation batch 201, loss: 0.730, 6432/6976 datapoints
2025-03-06 22:05:08,027 - INFO - Epoch 436/800 done.
2025-03-06 22:05:08,027 - INFO - Final validation performance:
Loss: 1.603, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:05:08,028 - INFO - Beginning epoch 437/800
2025-03-06 22:05:08,032 - INFO - training batch 1, loss: 0.035, 32/28000 datapoints
2025-03-06 22:05:08,202 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 22:05:08,366 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 22:05:08,523 - INFO - training batch 151, loss: 0.038, 4832/28000 datapoints
2025-03-06 22:05:08,675 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 22:05:08,827 - INFO - training batch 251, loss: 0.038, 8032/28000 datapoints
2025-03-06 22:05:08,984 - INFO - training batch 301, loss: 0.027, 9632/28000 datapoints
2025-03-06 22:05:09,147 - INFO - training batch 351, loss: 0.041, 11232/28000 datapoints
2025-03-06 22:05:09,310 - INFO - training batch 401, loss: 0.033, 12832/28000 datapoints
2025-03-06 22:05:09,472 - INFO - training batch 451, loss: 0.051, 14432/28000 datapoints
2025-03-06 22:05:09,625 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-06 22:05:09,778 - INFO - training batch 551, loss: 0.028, 17632/28000 datapoints
2025-03-06 22:05:09,937 - INFO - training batch 601, loss: 0.016, 19232/28000 datapoints
2025-03-06 22:05:10,092 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:05:10,250 - INFO - training batch 701, loss: 0.010, 22432/28000 datapoints
2025-03-06 22:05:10,405 - INFO - training batch 751, loss: 0.029, 24032/28000 datapoints
2025-03-06 22:05:10,559 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:05:10,714 - INFO - training batch 851, loss: 0.017, 27232/28000 datapoints
2025-03-06 22:05:10,793 - INFO - validation batch 1, loss: 0.573, 32/6976 datapoints
2025-03-06 22:05:10,845 - INFO - validation batch 51, loss: 4.166, 1632/6976 datapoints
2025-03-06 22:05:10,896 - INFO - validation batch 101, loss: 1.054, 3232/6976 datapoints
2025-03-06 22:05:10,941 - INFO - validation batch 151, loss: 1.529, 4832/6976 datapoints
2025-03-06 22:05:10,988 - INFO - validation batch 201, loss: 0.738, 6432/6976 datapoints
2025-03-06 22:05:11,004 - INFO - Epoch 437/800 done.
2025-03-06 22:05:11,004 - INFO - Final validation performance:
Loss: 1.612, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:05:11,005 - INFO - Beginning epoch 438/800
2025-03-06 22:05:11,009 - INFO - training batch 1, loss: 0.033, 32/28000 datapoints
2025-03-06 22:05:11,165 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 22:05:11,318 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 22:05:11,471 - INFO - training batch 151, loss: 0.037, 4832/28000 datapoints
2025-03-06 22:05:11,625 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 22:05:11,779 - INFO - training batch 251, loss: 0.038, 8032/28000 datapoints
2025-03-06 22:05:11,936 - INFO - training batch 301, loss: 0.027, 9632/28000 datapoints
2025-03-06 22:05:12,092 - INFO - training batch 351, loss: 0.041, 11232/28000 datapoints
2025-03-06 22:05:12,245 - INFO - training batch 401, loss: 0.032, 12832/28000 datapoints
2025-03-06 22:05:12,406 - INFO - training batch 451, loss: 0.050, 14432/28000 datapoints
2025-03-06 22:05:12,559 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-06 22:05:12,713 - INFO - training batch 551, loss: 0.027, 17632/28000 datapoints
2025-03-06 22:05:12,873 - INFO - training batch 601, loss: 0.016, 19232/28000 datapoints
2025-03-06 22:05:13,029 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:05:13,192 - INFO - training batch 701, loss: 0.011, 22432/28000 datapoints
2025-03-06 22:05:13,343 - INFO - training batch 751, loss: 0.029, 24032/28000 datapoints
2025-03-06 22:05:13,498 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:05:13,650 - INFO - training batch 851, loss: 0.016, 27232/28000 datapoints
2025-03-06 22:05:13,724 - INFO - validation batch 1, loss: 0.589, 32/6976 datapoints
2025-03-06 22:05:13,770 - INFO - validation batch 51, loss: 4.198, 1632/6976 datapoints
2025-03-06 22:05:13,817 - INFO - validation batch 101, loss: 1.065, 3232/6976 datapoints
2025-03-06 22:05:13,867 - INFO - validation batch 151, loss: 1.548, 4832/6976 datapoints
2025-03-06 22:05:13,914 - INFO - validation batch 201, loss: 0.741, 6432/6976 datapoints
2025-03-06 22:05:13,929 - INFO - Epoch 438/800 done.
2025-03-06 22:05:13,930 - INFO - Final validation performance:
Loss: 1.628, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:05:13,930 - INFO - Beginning epoch 439/800
2025-03-06 22:05:13,934 - INFO - training batch 1, loss: 0.033, 32/28000 datapoints
2025-03-06 22:05:14,086 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 22:05:14,235 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 22:05:14,392 - INFO - training batch 151, loss: 0.037, 4832/28000 datapoints
2025-03-06 22:05:14,542 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 22:05:14,690 - INFO - training batch 251, loss: 0.038, 8032/28000 datapoints
2025-03-06 22:05:14,841 - INFO - training batch 301, loss: 0.027, 9632/28000 datapoints
2025-03-06 22:05:14,999 - INFO - training batch 351, loss: 0.039, 11232/28000 datapoints
2025-03-06 22:05:15,181 - INFO - training batch 401, loss: 0.033, 12832/28000 datapoints
2025-03-06 22:05:15,332 - INFO - training batch 451, loss: 0.047, 14432/28000 datapoints
2025-03-06 22:05:15,483 - INFO - training batch 501, loss: 0.026, 16032/28000 datapoints
2025-03-06 22:05:15,634 - INFO - training batch 551, loss: 0.026, 17632/28000 datapoints
2025-03-06 22:05:15,786 - INFO - training batch 601, loss: 0.015, 19232/28000 datapoints
2025-03-06 22:05:15,939 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:05:16,091 - INFO - training batch 701, loss: 0.011, 22432/28000 datapoints
2025-03-06 22:05:16,242 - INFO - training batch 751, loss: 0.028, 24032/28000 datapoints
2025-03-06 22:05:16,398 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:05:16,547 - INFO - training batch 851, loss: 0.017, 27232/28000 datapoints
2025-03-06 22:05:16,621 - INFO - validation batch 1, loss: 0.563, 32/6976 datapoints
2025-03-06 22:05:16,667 - INFO - validation batch 51, loss: 4.250, 1632/6976 datapoints
2025-03-06 22:05:16,714 - INFO - validation batch 101, loss: 1.060, 3232/6976 datapoints
2025-03-06 22:05:16,761 - INFO - validation batch 151, loss: 1.533, 4832/6976 datapoints
2025-03-06 22:05:16,809 - INFO - validation batch 201, loss: 0.737, 6432/6976 datapoints
2025-03-06 22:05:16,826 - INFO - Epoch 439/800 done.
2025-03-06 22:05:16,826 - INFO - Final validation performance:
Loss: 1.629, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:05:16,826 - INFO - Beginning epoch 440/800
2025-03-06 22:05:16,831 - INFO - training batch 1, loss: 0.033, 32/28000 datapoints
2025-03-06 22:05:16,987 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 22:05:17,139 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 22:05:17,291 - INFO - training batch 151, loss: 0.035, 4832/28000 datapoints
2025-03-06 22:05:17,441 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 22:05:17,590 - INFO - training batch 251, loss: 0.035, 8032/28000 datapoints
2025-03-06 22:05:17,741 - INFO - training batch 301, loss: 0.025, 9632/28000 datapoints
2025-03-06 22:05:17,895 - INFO - training batch 351, loss: 0.038, 11232/28000 datapoints
2025-03-06 22:05:18,045 - INFO - training batch 401, loss: 0.031, 12832/28000 datapoints
2025-03-06 22:05:18,209 - INFO - training batch 451, loss: 0.046, 14432/28000 datapoints
2025-03-06 22:05:18,364 - INFO - training batch 501, loss: 0.026, 16032/28000 datapoints
2025-03-06 22:05:18,517 - INFO - training batch 551, loss: 0.026, 17632/28000 datapoints
2025-03-06 22:05:18,671 - INFO - training batch 601, loss: 0.015, 19232/28000 datapoints
2025-03-06 22:05:18,822 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:05:18,975 - INFO - training batch 701, loss: 0.010, 22432/28000 datapoints
2025-03-06 22:05:19,143 - INFO - training batch 751, loss: 0.028, 24032/28000 datapoints
2025-03-06 22:05:19,338 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:05:19,488 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-06 22:05:19,561 - INFO - validation batch 1, loss: 0.601, 32/6976 datapoints
2025-03-06 22:05:19,607 - INFO - validation batch 51, loss: 4.272, 1632/6976 datapoints
2025-03-06 22:05:19,653 - INFO - validation batch 101, loss: 1.075, 3232/6976 datapoints
2025-03-06 22:05:19,699 - INFO - validation batch 151, loss: 1.567, 4832/6976 datapoints
2025-03-06 22:05:19,745 - INFO - validation batch 201, loss: 0.753, 6432/6976 datapoints
2025-03-06 22:05:19,761 - INFO - Epoch 440/800 done.
2025-03-06 22:05:19,762 - INFO - Final validation performance:
Loss: 1.654, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:05:19,762 - INFO - Beginning epoch 441/800
2025-03-06 22:05:19,766 - INFO - training batch 1, loss: 0.032, 32/28000 datapoints
2025-03-06 22:05:19,921 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 22:05:20,076 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 22:05:20,231 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-06 22:05:20,383 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 22:05:20,532 - INFO - training batch 251, loss: 0.036, 8032/28000 datapoints
2025-03-06 22:05:20,682 - INFO - training batch 301, loss: 0.025, 9632/28000 datapoints
2025-03-06 22:05:20,834 - INFO - training batch 351, loss: 0.037, 11232/28000 datapoints
2025-03-06 22:05:20,986 - INFO - training batch 401, loss: 0.032, 12832/28000 datapoints
2025-03-06 22:05:21,139 - INFO - training batch 451, loss: 0.045, 14432/28000 datapoints
2025-03-06 22:05:21,293 - INFO - training batch 501, loss: 0.025, 16032/28000 datapoints
2025-03-06 22:05:21,444 - INFO - training batch 551, loss: 0.025, 17632/28000 datapoints
2025-03-06 22:05:21,601 - INFO - training batch 601, loss: 0.015, 19232/28000 datapoints
2025-03-06 22:05:21,750 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:05:21,904 - INFO - training batch 701, loss: 0.010, 22432/28000 datapoints
2025-03-06 22:05:22,054 - INFO - training batch 751, loss: 0.028, 24032/28000 datapoints
2025-03-06 22:05:22,205 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:05:22,357 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-06 22:05:22,432 - INFO - validation batch 1, loss: 0.588, 32/6976 datapoints
2025-03-06 22:05:22,480 - INFO - validation batch 51, loss: 4.303, 1632/6976 datapoints
2025-03-06 22:05:22,527 - INFO - validation batch 101, loss: 1.079, 3232/6976 datapoints
2025-03-06 22:05:22,573 - INFO - validation batch 151, loss: 1.581, 4832/6976 datapoints
2025-03-06 22:05:22,620 - INFO - validation batch 201, loss: 0.756, 6432/6976 datapoints
2025-03-06 22:05:22,636 - INFO - Epoch 441/800 done.
2025-03-06 22:05:22,636 - INFO - Final validation performance:
Loss: 1.662, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:05:22,637 - INFO - Beginning epoch 442/800
2025-03-06 22:05:22,642 - INFO - training batch 1, loss: 0.031, 32/28000 datapoints
2025-03-06 22:05:22,795 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 22:05:22,948 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:05:23,104 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-06 22:05:23,252 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 22:05:23,399 - INFO - training batch 251, loss: 0.034, 8032/28000 datapoints
2025-03-06 22:05:23,552 - INFO - training batch 301, loss: 0.024, 9632/28000 datapoints
2025-03-06 22:05:23,704 - INFO - training batch 351, loss: 0.036, 11232/28000 datapoints
2025-03-06 22:05:23,853 - INFO - training batch 401, loss: 0.031, 12832/28000 datapoints
2025-03-06 22:05:24,009 - INFO - training batch 451, loss: 0.044, 14432/28000 datapoints
2025-03-06 22:05:24,160 - INFO - training batch 501, loss: 0.024, 16032/28000 datapoints
2025-03-06 22:05:24,313 - INFO - training batch 551, loss: 0.025, 17632/28000 datapoints
2025-03-06 22:05:24,467 - INFO - training batch 601, loss: 0.015, 19232/28000 datapoints
2025-03-06 22:05:24,618 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:05:24,770 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-06 22:05:24,928 - INFO - training batch 751, loss: 0.027, 24032/28000 datapoints
2025-03-06 22:05:25,106 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:05:25,301 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-06 22:05:25,378 - INFO - validation batch 1, loss: 0.598, 32/6976 datapoints
2025-03-06 22:05:25,424 - INFO - validation batch 51, loss: 4.350, 1632/6976 datapoints
2025-03-06 22:05:25,473 - INFO - validation batch 101, loss: 1.085, 3232/6976 datapoints
2025-03-06 22:05:25,522 - INFO - validation batch 151, loss: 1.591, 4832/6976 datapoints
2025-03-06 22:05:25,571 - INFO - validation batch 201, loss: 0.764, 6432/6976 datapoints
2025-03-06 22:05:25,587 - INFO - Epoch 442/800 done.
2025-03-06 22:05:25,587 - INFO - Final validation performance:
Loss: 1.678, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:05:25,587 - INFO - Beginning epoch 443/800
2025-03-06 22:05:25,591 - INFO - training batch 1, loss: 0.031, 32/28000 datapoints
2025-03-06 22:05:25,748 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 22:05:25,907 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 22:05:26,065 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-06 22:05:26,216 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 22:05:26,371 - INFO - training batch 251, loss: 0.033, 8032/28000 datapoints
2025-03-06 22:05:26,523 - INFO - training batch 301, loss: 0.024, 9632/28000 datapoints
2025-03-06 22:05:26,676 - INFO - training batch 351, loss: 0.036, 11232/28000 datapoints
2025-03-06 22:05:26,824 - INFO - training batch 401, loss: 0.031, 12832/28000 datapoints
2025-03-06 22:05:26,979 - INFO - training batch 451, loss: 0.041, 14432/28000 datapoints
2025-03-06 22:05:27,131 - INFO - training batch 501, loss: 0.024, 16032/28000 datapoints
2025-03-06 22:05:27,283 - INFO - training batch 551, loss: 0.024, 17632/28000 datapoints
2025-03-06 22:05:27,438 - INFO - training batch 601, loss: 0.015, 19232/28000 datapoints
2025-03-06 22:05:27,588 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:05:27,738 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-06 22:05:27,896 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-06 22:05:28,049 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:05:28,204 - INFO - training batch 851, loss: 0.014, 27232/28000 datapoints
2025-03-06 22:05:28,287 - INFO - validation batch 1, loss: 0.592, 32/6976 datapoints
2025-03-06 22:05:28,338 - INFO - validation batch 51, loss: 4.388, 1632/6976 datapoints
2025-03-06 22:05:28,386 - INFO - validation batch 101, loss: 1.086, 3232/6976 datapoints
2025-03-06 22:05:28,436 - INFO - validation batch 151, loss: 1.593, 4832/6976 datapoints
2025-03-06 22:05:28,485 - INFO - validation batch 201, loss: 0.760, 6432/6976 datapoints
2025-03-06 22:05:28,508 - INFO - Epoch 443/800 done.
2025-03-06 22:05:28,508 - INFO - Final validation performance:
Loss: 1.684, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:05:28,509 - INFO - Beginning epoch 444/800
2025-03-06 22:05:28,513 - INFO - training batch 1, loss: 0.030, 32/28000 datapoints
2025-03-06 22:05:28,672 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 22:05:28,832 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:05:28,990 - INFO - training batch 151, loss: 0.033, 4832/28000 datapoints
2025-03-06 22:05:29,144 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 22:05:29,294 - INFO - training batch 251, loss: 0.033, 8032/28000 datapoints
2025-03-06 22:05:29,447 - INFO - training batch 301, loss: 0.024, 9632/28000 datapoints
2025-03-06 22:05:29,609 - INFO - training batch 351, loss: 0.035, 11232/28000 datapoints
2025-03-06 22:05:29,762 - INFO - training batch 401, loss: 0.029, 12832/28000 datapoints
2025-03-06 22:05:29,928 - INFO - training batch 451, loss: 0.041, 14432/28000 datapoints
2025-03-06 22:05:30,104 - INFO - training batch 501, loss: 0.024, 16032/28000 datapoints
2025-03-06 22:05:30,287 - INFO - training batch 551, loss: 0.023, 17632/28000 datapoints
2025-03-06 22:05:30,447 - INFO - training batch 601, loss: 0.014, 19232/28000 datapoints
2025-03-06 22:05:30,603 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:05:30,757 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-06 22:05:30,913 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-06 22:05:31,066 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:05:31,221 - INFO - training batch 851, loss: 0.013, 27232/28000 datapoints
2025-03-06 22:05:31,300 - INFO - validation batch 1, loss: 0.608, 32/6976 datapoints
2025-03-06 22:05:31,348 - INFO - validation batch 51, loss: 4.421, 1632/6976 datapoints
2025-03-06 22:05:31,397 - INFO - validation batch 101, loss: 1.094, 3232/6976 datapoints
2025-03-06 22:05:31,447 - INFO - validation batch 151, loss: 1.612, 4832/6976 datapoints
2025-03-06 22:05:31,496 - INFO - validation batch 201, loss: 0.769, 6432/6976 datapoints
2025-03-06 22:05:31,512 - INFO - Epoch 444/800 done.
2025-03-06 22:05:31,512 - INFO - Final validation performance:
Loss: 1.701, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:05:31,512 - INFO - Beginning epoch 445/800
2025-03-06 22:05:31,517 - INFO - training batch 1, loss: 0.030, 32/28000 datapoints
2025-03-06 22:05:31,671 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 22:05:31,825 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:05:31,980 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-06 22:05:32,131 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 22:05:32,281 - INFO - training batch 251, loss: 0.032, 8032/28000 datapoints
2025-03-06 22:05:32,433 - INFO - training batch 301, loss: 0.023, 9632/28000 datapoints
2025-03-06 22:05:32,584 - INFO - training batch 351, loss: 0.033, 11232/28000 datapoints
2025-03-06 22:05:32,737 - INFO - training batch 401, loss: 0.030, 12832/28000 datapoints
2025-03-06 22:05:32,893 - INFO - training batch 451, loss: 0.039, 14432/28000 datapoints
2025-03-06 22:05:33,072 - INFO - training batch 501, loss: 0.022, 16032/28000 datapoints
2025-03-06 22:05:33,232 - INFO - training batch 551, loss: 0.023, 17632/28000 datapoints
2025-03-06 22:05:33,386 - INFO - training batch 601, loss: 0.014, 19232/28000 datapoints
2025-03-06 22:05:33,540 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:05:33,697 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:05:33,854 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-06 22:05:34,013 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:05:34,168 - INFO - training batch 851, loss: 0.014, 27232/28000 datapoints
2025-03-06 22:05:34,245 - INFO - validation batch 1, loss: 0.585, 32/6976 datapoints
2025-03-06 22:05:34,292 - INFO - validation batch 51, loss: 4.471, 1632/6976 datapoints
2025-03-06 22:05:34,338 - INFO - validation batch 101, loss: 1.094, 3232/6976 datapoints
2025-03-06 22:05:34,388 - INFO - validation batch 151, loss: 1.610, 4832/6976 datapoints
2025-03-06 22:05:34,435 - INFO - validation batch 201, loss: 0.773, 6432/6976 datapoints
2025-03-06 22:05:34,451 - INFO - Epoch 445/800 done.
2025-03-06 22:05:34,451 - INFO - Final validation performance:
Loss: 1.707, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:05:34,451 - INFO - Beginning epoch 446/800
2025-03-06 22:05:34,456 - INFO - training batch 1, loss: 0.029, 32/28000 datapoints
2025-03-06 22:05:34,611 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 22:05:34,770 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:05:34,931 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-06 22:05:35,095 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 22:05:35,264 - INFO - training batch 251, loss: 0.032, 8032/28000 datapoints
2025-03-06 22:05:35,432 - INFO - training batch 301, loss: 0.023, 9632/28000 datapoints
2025-03-06 22:05:35,591 - INFO - training batch 351, loss: 0.033, 11232/28000 datapoints
2025-03-06 22:05:35,744 - INFO - training batch 401, loss: 0.029, 12832/28000 datapoints
2025-03-06 22:05:35,903 - INFO - training batch 451, loss: 0.038, 14432/28000 datapoints
2025-03-06 22:05:36,059 - INFO - training batch 501, loss: 0.023, 16032/28000 datapoints
2025-03-06 22:05:36,213 - INFO - training batch 551, loss: 0.022, 17632/28000 datapoints
2025-03-06 22:05:36,370 - INFO - training batch 601, loss: 0.013, 19232/28000 datapoints
2025-03-06 22:05:36,522 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:05:36,674 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-06 22:05:36,824 - INFO - training batch 751, loss: 0.025, 24032/28000 datapoints
2025-03-06 22:05:36,978 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:05:37,129 - INFO - training batch 851, loss: 0.012, 27232/28000 datapoints
2025-03-06 22:05:37,208 - INFO - validation batch 1, loss: 0.620, 32/6976 datapoints
2025-03-06 22:05:37,254 - INFO - validation batch 51, loss: 4.494, 1632/6976 datapoints
2025-03-06 22:05:37,301 - INFO - validation batch 101, loss: 1.108, 3232/6976 datapoints
2025-03-06 22:05:37,348 - INFO - validation batch 151, loss: 1.640, 4832/6976 datapoints
2025-03-06 22:05:37,395 - INFO - validation batch 201, loss: 0.783, 6432/6976 datapoints
2025-03-06 22:05:37,411 - INFO - Epoch 446/800 done.
2025-03-06 22:05:37,411 - INFO - Final validation performance:
Loss: 1.729, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:05:37,412 - INFO - Beginning epoch 447/800
2025-03-06 22:05:37,416 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-06 22:05:37,566 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 22:05:37,723 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:05:37,889 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-06 22:05:38,039 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 22:05:38,187 - INFO - training batch 251, loss: 0.031, 8032/28000 datapoints
2025-03-06 22:05:38,337 - INFO - training batch 301, loss: 0.022, 9632/28000 datapoints
2025-03-06 22:05:38,494 - INFO - training batch 351, loss: 0.031, 11232/28000 datapoints
2025-03-06 22:05:38,647 - INFO - training batch 401, loss: 0.029, 12832/28000 datapoints
2025-03-06 22:05:38,801 - INFO - training batch 451, loss: 0.037, 14432/28000 datapoints
2025-03-06 22:05:38,960 - INFO - training batch 501, loss: 0.022, 16032/28000 datapoints
2025-03-06 22:05:39,110 - INFO - training batch 551, loss: 0.022, 17632/28000 datapoints
2025-03-06 22:05:39,270 - INFO - training batch 601, loss: 0.014, 19232/28000 datapoints
2025-03-06 22:05:39,421 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:05:39,572 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-06 22:05:39,723 - INFO - training batch 751, loss: 0.024, 24032/28000 datapoints
2025-03-06 22:05:39,878 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:05:40,029 - INFO - training batch 851, loss: 0.012, 27232/28000 datapoints
2025-03-06 22:05:40,104 - INFO - validation batch 1, loss: 0.582, 32/6976 datapoints
2025-03-06 22:05:40,151 - INFO - validation batch 51, loss: 4.545, 1632/6976 datapoints
2025-03-06 22:05:40,198 - INFO - validation batch 101, loss: 1.109, 3232/6976 datapoints
2025-03-06 22:05:40,246 - INFO - validation batch 151, loss: 1.628, 4832/6976 datapoints
2025-03-06 22:05:40,292 - INFO - validation batch 201, loss: 0.776, 6432/6976 datapoints
2025-03-06 22:05:40,308 - INFO - Epoch 447/800 done.
2025-03-06 22:05:40,308 - INFO - Final validation performance:
Loss: 1.728, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:05:40,309 - INFO - Beginning epoch 448/800
2025-03-06 22:05:40,313 - INFO - training batch 1, loss: 0.029, 32/28000 datapoints
2025-03-06 22:05:40,470 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 22:05:40,624 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-06 22:05:40,781 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 22:05:40,935 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 22:05:41,084 - INFO - training batch 251, loss: 0.030, 8032/28000 datapoints
2025-03-06 22:05:41,234 - INFO - training batch 301, loss: 0.022, 9632/28000 datapoints
2025-03-06 22:05:41,386 - INFO - training batch 351, loss: 0.031, 11232/28000 datapoints
2025-03-06 22:05:41,537 - INFO - training batch 401, loss: 0.028, 12832/28000 datapoints
2025-03-06 22:05:41,696 - INFO - training batch 451, loss: 0.036, 14432/28000 datapoints
2025-03-06 22:05:41,850 - INFO - training batch 501, loss: 0.022, 16032/28000 datapoints
2025-03-06 22:05:42,005 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-06 22:05:42,161 - INFO - training batch 601, loss: 0.013, 19232/28000 datapoints
2025-03-06 22:05:42,314 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:05:42,469 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-06 22:05:42,620 - INFO - training batch 751, loss: 0.024, 24032/28000 datapoints
2025-03-06 22:05:42,774 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:05:42,931 - INFO - training batch 851, loss: 0.012, 27232/28000 datapoints
2025-03-06 22:05:43,006 - INFO - validation batch 1, loss: 0.616, 32/6976 datapoints
2025-03-06 22:05:43,052 - INFO - validation batch 51, loss: 4.578, 1632/6976 datapoints
2025-03-06 22:05:43,102 - INFO - validation batch 101, loss: 1.122, 3232/6976 datapoints
2025-03-06 22:05:43,148 - INFO - validation batch 151, loss: 1.663, 4832/6976 datapoints
2025-03-06 22:05:43,195 - INFO - validation batch 201, loss: 0.791, 6432/6976 datapoints
2025-03-06 22:05:43,211 - INFO - Epoch 448/800 done.
2025-03-06 22:05:43,212 - INFO - Final validation performance:
Loss: 1.754, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:05:43,212 - INFO - Beginning epoch 449/800
2025-03-06 22:05:43,216 - INFO - training batch 1, loss: 0.027, 32/28000 datapoints
2025-03-06 22:05:43,373 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 22:05:43,525 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-06 22:05:43,677 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-06 22:05:43,828 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 22:05:43,981 - INFO - training batch 251, loss: 0.030, 8032/28000 datapoints
2025-03-06 22:05:44,133 - INFO - training batch 301, loss: 0.021, 9632/28000 datapoints
2025-03-06 22:05:44,287 - INFO - training batch 351, loss: 0.029, 11232/28000 datapoints
2025-03-06 22:05:44,443 - INFO - training batch 401, loss: 0.028, 12832/28000 datapoints
2025-03-06 22:05:44,596 - INFO - training batch 451, loss: 0.034, 14432/28000 datapoints
2025-03-06 22:05:44,754 - INFO - training batch 501, loss: 0.021, 16032/28000 datapoints
2025-03-06 22:05:44,908 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-06 22:05:45,063 - INFO - training batch 601, loss: 0.013, 19232/28000 datapoints
2025-03-06 22:05:45,227 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:05:45,400 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:05:45,553 - INFO - training batch 751, loss: 0.024, 24032/28000 datapoints
2025-03-06 22:05:45,704 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:05:45,858 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-06 22:05:45,934 - INFO - validation batch 1, loss: 0.599, 32/6976 datapoints
2025-03-06 22:05:45,981 - INFO - validation batch 51, loss: 4.624, 1632/6976 datapoints
2025-03-06 22:05:46,027 - INFO - validation batch 101, loss: 1.130, 3232/6976 datapoints
2025-03-06 22:05:46,076 - INFO - validation batch 151, loss: 1.659, 4832/6976 datapoints
2025-03-06 22:05:46,123 - INFO - validation batch 201, loss: 0.787, 6432/6976 datapoints
2025-03-06 22:05:46,139 - INFO - Epoch 449/800 done.
2025-03-06 22:05:46,139 - INFO - Final validation performance:
Loss: 1.760, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:05:46,140 - INFO - Beginning epoch 450/800
2025-03-06 22:05:46,144 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-06 22:05:46,299 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 22:05:46,456 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-06 22:05:46,607 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 22:05:46,757 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 22:05:46,915 - INFO - training batch 251, loss: 0.028, 8032/28000 datapoints
2025-03-06 22:05:47,066 - INFO - training batch 301, loss: 0.020, 9632/28000 datapoints
2025-03-06 22:05:47,219 - INFO - training batch 351, loss: 0.029, 11232/28000 datapoints
2025-03-06 22:05:47,370 - INFO - training batch 401, loss: 0.027, 12832/28000 datapoints
2025-03-06 22:05:47,526 - INFO - training batch 451, loss: 0.034, 14432/28000 datapoints
2025-03-06 22:05:47,683 - INFO - training batch 501, loss: 0.021, 16032/28000 datapoints
2025-03-06 22:05:47,837 - INFO - training batch 551, loss: 0.020, 17632/28000 datapoints
2025-03-06 22:05:48,003 - INFO - training batch 601, loss: 0.012, 19232/28000 datapoints
2025-03-06 22:05:48,164 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:05:48,329 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:05:48,490 - INFO - training batch 751, loss: 0.022, 24032/28000 datapoints
2025-03-06 22:05:48,650 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:05:48,808 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-06 22:05:48,895 - INFO - validation batch 1, loss: 0.616, 32/6976 datapoints
2025-03-06 22:05:48,946 - INFO - validation batch 51, loss: 4.664, 1632/6976 datapoints
2025-03-06 22:05:48,993 - INFO - validation batch 101, loss: 1.135, 3232/6976 datapoints
2025-03-06 22:05:49,039 - INFO - validation batch 151, loss: 1.691, 4832/6976 datapoints
2025-03-06 22:05:49,086 - INFO - validation batch 201, loss: 0.798, 6432/6976 datapoints
2025-03-06 22:05:49,103 - INFO - Epoch 450/800 done.
2025-03-06 22:05:49,103 - INFO - Final validation performance:
Loss: 1.781, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:05:49,103 - INFO - Beginning epoch 451/800
2025-03-06 22:05:49,108 - INFO - training batch 1, loss: 0.025, 32/28000 datapoints
2025-03-06 22:05:49,258 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 22:05:49,415 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-06 22:05:49,566 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 22:05:49,716 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 22:05:49,870 - INFO - training batch 251, loss: 0.029, 8032/28000 datapoints
2025-03-06 22:05:50,023 - INFO - training batch 301, loss: 0.021, 9632/28000 datapoints
2025-03-06 22:05:50,176 - INFO - training batch 351, loss: 0.029, 11232/28000 datapoints
2025-03-06 22:05:50,327 - INFO - training batch 401, loss: 0.027, 12832/28000 datapoints
2025-03-06 22:05:50,485 - INFO - training batch 451, loss: 0.032, 14432/28000 datapoints
2025-03-06 22:05:50,650 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-06 22:05:50,801 - INFO - training batch 551, loss: 0.020, 17632/28000 datapoints
2025-03-06 22:05:50,960 - INFO - training batch 601, loss: 0.013, 19232/28000 datapoints
2025-03-06 22:05:51,111 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:05:51,264 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:05:51,414 - INFO - training batch 751, loss: 0.023, 24032/28000 datapoints
2025-03-06 22:05:51,566 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:05:51,724 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-06 22:05:51,804 - INFO - validation batch 1, loss: 0.612, 32/6976 datapoints
2025-03-06 22:05:51,850 - INFO - validation batch 51, loss: 4.710, 1632/6976 datapoints
2025-03-06 22:05:51,900 - INFO - validation batch 101, loss: 1.139, 3232/6976 datapoints
2025-03-06 22:05:51,948 - INFO - validation batch 151, loss: 1.687, 4832/6976 datapoints
2025-03-06 22:05:51,994 - INFO - validation batch 201, loss: 0.802, 6432/6976 datapoints
2025-03-06 22:05:52,010 - INFO - Epoch 451/800 done.
2025-03-06 22:05:52,010 - INFO - Final validation performance:
Loss: 1.790, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:05:52,011 - INFO - Beginning epoch 452/800
2025-03-06 22:05:52,015 - INFO - training batch 1, loss: 0.026, 32/28000 datapoints
2025-03-06 22:05:52,169 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 22:05:52,322 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-06 22:05:52,479 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 22:05:52,629 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 22:05:52,779 - INFO - training batch 251, loss: 0.028, 8032/28000 datapoints
2025-03-06 22:05:52,938 - INFO - training batch 301, loss: 0.020, 9632/28000 datapoints
2025-03-06 22:05:53,090 - INFO - training batch 351, loss: 0.028, 11232/28000 datapoints
2025-03-06 22:05:53,238 - INFO - training batch 401, loss: 0.025, 12832/28000 datapoints
2025-03-06 22:05:53,393 - INFO - training batch 451, loss: 0.030, 14432/28000 datapoints
2025-03-06 22:05:53,549 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-06 22:05:53,700 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-06 22:05:53,853 - INFO - training batch 601, loss: 0.012, 19232/28000 datapoints
2025-03-06 22:05:54,013 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:05:54,166 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:05:54,319 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-06 22:05:54,475 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:05:54,628 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-06 22:05:54,704 - INFO - validation batch 1, loss: 0.625, 32/6976 datapoints
2025-03-06 22:05:54,750 - INFO - validation batch 51, loss: 4.759, 1632/6976 datapoints
2025-03-06 22:05:54,796 - INFO - validation batch 101, loss: 1.149, 3232/6976 datapoints
2025-03-06 22:05:54,843 - INFO - validation batch 151, loss: 1.711, 4832/6976 datapoints
2025-03-06 22:05:54,893 - INFO - validation batch 201, loss: 0.812, 6432/6976 datapoints
2025-03-06 22:05:54,911 - INFO - Epoch 452/800 done.
2025-03-06 22:05:54,911 - INFO - Final validation performance:
Loss: 1.811, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:05:54,911 - INFO - Beginning epoch 453/800
2025-03-06 22:05:54,915 - INFO - training batch 1, loss: 0.024, 32/28000 datapoints
2025-03-06 22:05:55,074 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 22:05:55,244 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-06 22:05:55,398 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-06 22:05:55,576 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 22:05:55,728 - INFO - training batch 251, loss: 0.027, 8032/28000 datapoints
2025-03-06 22:05:55,883 - INFO - training batch 301, loss: 0.018, 9632/28000 datapoints
2025-03-06 22:05:56,037 - INFO - training batch 351, loss: 0.027, 11232/28000 datapoints
2025-03-06 22:05:56,190 - INFO - training batch 401, loss: 0.026, 12832/28000 datapoints
2025-03-06 22:05:56,350 - INFO - training batch 451, loss: 0.030, 14432/28000 datapoints
2025-03-06 22:05:56,514 - INFO - training batch 501, loss: 0.019, 16032/28000 datapoints
2025-03-06 22:05:56,669 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 22:05:56,827 - INFO - training batch 601, loss: 0.012, 19232/28000 datapoints
2025-03-06 22:05:56,986 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:05:57,142 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:05:57,296 - INFO - training batch 751, loss: 0.022, 24032/28000 datapoints
2025-03-06 22:05:57,452 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:05:57,607 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-06 22:05:57,683 - INFO - validation batch 1, loss: 0.612, 32/6976 datapoints
2025-03-06 22:05:57,730 - INFO - validation batch 51, loss: 4.807, 1632/6976 datapoints
2025-03-06 22:05:57,776 - INFO - validation batch 101, loss: 1.153, 3232/6976 datapoints
2025-03-06 22:05:57,823 - INFO - validation batch 151, loss: 1.699, 4832/6976 datapoints
2025-03-06 22:05:57,873 - INFO - validation batch 201, loss: 0.809, 6432/6976 datapoints
2025-03-06 22:05:57,889 - INFO - Epoch 453/800 done.
2025-03-06 22:05:57,889 - INFO - Final validation performance:
Loss: 1.816, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:05:57,890 - INFO - Beginning epoch 454/800
2025-03-06 22:05:57,894 - INFO - training batch 1, loss: 0.025, 32/28000 datapoints
2025-03-06 22:05:58,051 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 22:05:58,205 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-06 22:05:58,359 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-06 22:05:58,513 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:05:58,663 - INFO - training batch 251, loss: 0.026, 8032/28000 datapoints
2025-03-06 22:05:58,817 - INFO - training batch 301, loss: 0.019, 9632/28000 datapoints
2025-03-06 22:05:58,972 - INFO - training batch 351, loss: 0.027, 11232/28000 datapoints
2025-03-06 22:05:59,121 - INFO - training batch 401, loss: 0.025, 12832/28000 datapoints
2025-03-06 22:05:59,277 - INFO - training batch 451, loss: 0.029, 14432/28000 datapoints
2025-03-06 22:05:59,432 - INFO - training batch 501, loss: 0.019, 16032/28000 datapoints
2025-03-06 22:05:59,598 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-06 22:05:59,761 - INFO - training batch 601, loss: 0.012, 19232/28000 datapoints
2025-03-06 22:05:59,916 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:06:00,073 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:06:00,230 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-06 22:06:00,382 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:00,537 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:06:00,613 - INFO - validation batch 1, loss: 0.636, 32/6976 datapoints
2025-03-06 22:06:00,659 - INFO - validation batch 51, loss: 4.840, 1632/6976 datapoints
2025-03-06 22:06:00,706 - INFO - validation batch 101, loss: 1.166, 3232/6976 datapoints
2025-03-06 22:06:00,755 - INFO - validation batch 151, loss: 1.734, 4832/6976 datapoints
2025-03-06 22:06:00,801 - INFO - validation batch 201, loss: 0.825, 6432/6976 datapoints
2025-03-06 22:06:00,817 - INFO - Epoch 454/800 done.
2025-03-06 22:06:00,817 - INFO - Final validation performance:
Loss: 1.840, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:06:00,818 - INFO - Beginning epoch 455/800
2025-03-06 22:06:00,822 - INFO - training batch 1, loss: 0.021, 32/28000 datapoints
2025-03-06 22:06:00,978 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 22:06:01,135 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:06:01,294 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 22:06:01,446 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 22:06:01,599 - INFO - training batch 251, loss: 0.025, 8032/28000 datapoints
2025-03-06 22:06:01,751 - INFO - training batch 301, loss: 0.018, 9632/28000 datapoints
2025-03-06 22:06:01,907 - INFO - training batch 351, loss: 0.026, 11232/28000 datapoints
2025-03-06 22:06:02,058 - INFO - training batch 401, loss: 0.025, 12832/28000 datapoints
2025-03-06 22:06:02,216 - INFO - training batch 451, loss: 0.029, 14432/28000 datapoints
2025-03-06 22:06:02,371 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-06 22:06:02,528 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 22:06:02,686 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-06 22:06:02,839 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:06:02,994 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:06:03,147 - INFO - training batch 751, loss: 0.020, 24032/28000 datapoints
2025-03-06 22:06:03,298 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:03,448 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-06 22:06:03,527 - INFO - validation batch 1, loss: 0.615, 32/6976 datapoints
2025-03-06 22:06:03,574 - INFO - validation batch 51, loss: 4.894, 1632/6976 datapoints
2025-03-06 22:06:03,621 - INFO - validation batch 101, loss: 1.171, 3232/6976 datapoints
2025-03-06 22:06:03,668 - INFO - validation batch 151, loss: 1.749, 4832/6976 datapoints
2025-03-06 22:06:03,716 - INFO - validation batch 201, loss: 0.827, 6432/6976 datapoints
2025-03-06 22:06:03,732 - INFO - Epoch 455/800 done.
2025-03-06 22:06:03,732 - INFO - Final validation performance:
Loss: 1.851, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:06:03,733 - INFO - Beginning epoch 456/800
2025-03-06 22:06:03,737 - INFO - training batch 1, loss: 0.021, 32/28000 datapoints
2025-03-06 22:06:03,895 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 22:06:04,054 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-06 22:06:04,217 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-06 22:06:04,370 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:06:04,526 - INFO - training batch 251, loss: 0.026, 8032/28000 datapoints
2025-03-06 22:06:04,681 - INFO - training batch 301, loss: 0.018, 9632/28000 datapoints
2025-03-06 22:06:04,833 - INFO - training batch 351, loss: 0.026, 11232/28000 datapoints
2025-03-06 22:06:04,987 - INFO - training batch 401, loss: 0.024, 12832/28000 datapoints
2025-03-06 22:06:05,151 - INFO - training batch 451, loss: 0.027, 14432/28000 datapoints
2025-03-06 22:06:05,317 - INFO - training batch 501, loss: 0.018, 16032/28000 datapoints
2025-03-06 22:06:05,469 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 22:06:05,651 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-06 22:06:05,806 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:06:05,962 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:06:06,116 - INFO - training batch 751, loss: 0.020, 24032/28000 datapoints
2025-03-06 22:06:06,271 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:06,424 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:06:06,505 - INFO - validation batch 1, loss: 0.630, 32/6976 datapoints
2025-03-06 22:06:06,553 - INFO - validation batch 51, loss: 4.921, 1632/6976 datapoints
2025-03-06 22:06:06,598 - INFO - validation batch 101, loss: 1.187, 3232/6976 datapoints
2025-03-06 22:06:06,644 - INFO - validation batch 151, loss: 1.772, 4832/6976 datapoints
2025-03-06 22:06:06,692 - INFO - validation batch 201, loss: 0.835, 6432/6976 datapoints
2025-03-06 22:06:06,725 - INFO - Epoch 456/800 done.
2025-03-06 22:06:06,725 - INFO - Final validation performance:
Loss: 1.869, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:06:06,726 - INFO - Beginning epoch 457/800
2025-03-06 22:06:06,730 - INFO - training batch 1, loss: 0.022, 32/28000 datapoints
2025-03-06 22:06:06,887 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 22:06:07,042 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:06:07,201 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-06 22:06:07,352 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:06:07,503 - INFO - training batch 251, loss: 0.024, 8032/28000 datapoints
2025-03-06 22:06:07,656 - INFO - training batch 301, loss: 0.017, 9632/28000 datapoints
2025-03-06 22:06:07,812 - INFO - training batch 351, loss: 0.025, 11232/28000 datapoints
2025-03-06 22:06:07,971 - INFO - training batch 401, loss: 0.024, 12832/28000 datapoints
2025-03-06 22:06:08,131 - INFO - training batch 451, loss: 0.026, 14432/28000 datapoints
2025-03-06 22:06:08,286 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-06 22:06:08,443 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 22:06:08,607 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-06 22:06:08,764 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:06:08,925 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:06:09,084 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-06 22:06:09,241 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:09,401 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:06:09,482 - INFO - validation batch 1, loss: 0.618, 32/6976 datapoints
2025-03-06 22:06:09,533 - INFO - validation batch 51, loss: 4.988, 1632/6976 datapoints
2025-03-06 22:06:09,582 - INFO - validation batch 101, loss: 1.195, 3232/6976 datapoints
2025-03-06 22:06:09,634 - INFO - validation batch 151, loss: 1.769, 4832/6976 datapoints
2025-03-06 22:06:09,685 - INFO - validation batch 201, loss: 0.830, 6432/6976 datapoints
2025-03-06 22:06:09,704 - INFO - Epoch 457/800 done.
2025-03-06 22:06:09,704 - INFO - Final validation performance:
Loss: 1.880, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:06:09,705 - INFO - Beginning epoch 458/800
2025-03-06 22:06:09,709 - INFO - training batch 1, loss: 0.022, 32/28000 datapoints
2025-03-06 22:06:09,870 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 22:06:10,029 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:06:10,189 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 22:06:10,347 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:06:10,502 - INFO - training batch 251, loss: 0.023, 8032/28000 datapoints
2025-03-06 22:06:10,665 - INFO - training batch 301, loss: 0.016, 9632/28000 datapoints
2025-03-06 22:06:10,823 - INFO - training batch 351, loss: 0.024, 11232/28000 datapoints
2025-03-06 22:06:10,980 - INFO - training batch 401, loss: 0.023, 12832/28000 datapoints
2025-03-06 22:06:11,140 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-06 22:06:11,298 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-06 22:06:11,453 - INFO - training batch 551, loss: 0.017, 17632/28000 datapoints
2025-03-06 22:06:11,613 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-06 22:06:11,775 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:06:11,939 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:06:12,124 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-06 22:06:12,285 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:12,448 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:06:12,533 - INFO - validation batch 1, loss: 0.632, 32/6976 datapoints
2025-03-06 22:06:12,588 - INFO - validation batch 51, loss: 5.033, 1632/6976 datapoints
2025-03-06 22:06:12,641 - INFO - validation batch 101, loss: 1.193, 3232/6976 datapoints
2025-03-06 22:06:12,692 - INFO - validation batch 151, loss: 1.789, 4832/6976 datapoints
2025-03-06 22:06:12,750 - INFO - validation batch 201, loss: 0.849, 6432/6976 datapoints
2025-03-06 22:06:12,769 - INFO - Epoch 458/800 done.
2025-03-06 22:06:12,769 - INFO - Final validation performance:
Loss: 1.899, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:06:12,770 - INFO - Beginning epoch 459/800
2025-03-06 22:06:12,775 - INFO - training batch 1, loss: 0.020, 32/28000 datapoints
2025-03-06 22:06:12,945 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 22:06:13,114 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:06:13,282 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-06 22:06:13,443 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:06:13,602 - INFO - training batch 251, loss: 0.023, 8032/28000 datapoints
2025-03-06 22:06:13,765 - INFO - training batch 301, loss: 0.016, 9632/28000 datapoints
2025-03-06 22:06:13,925 - INFO - training batch 351, loss: 0.023, 11232/28000 datapoints
2025-03-06 22:06:14,078 - INFO - training batch 401, loss: 0.023, 12832/28000 datapoints
2025-03-06 22:06:14,239 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-06 22:06:14,398 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 22:06:14,558 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 22:06:14,719 - INFO - training batch 601, loss: 0.009, 19232/28000 datapoints
2025-03-06 22:06:14,878 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:06:15,035 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:06:15,203 - INFO - training batch 751, loss: 0.018, 24032/28000 datapoints
2025-03-06 22:06:15,372 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:15,527 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:06:15,611 - INFO - validation batch 1, loss: 0.605, 32/6976 datapoints
2025-03-06 22:06:15,681 - INFO - validation batch 51, loss: 5.081, 1632/6976 datapoints
2025-03-06 22:06:15,738 - INFO - validation batch 101, loss: 1.204, 3232/6976 datapoints
2025-03-06 22:06:15,790 - INFO - validation batch 151, loss: 1.783, 4832/6976 datapoints
2025-03-06 22:06:15,843 - INFO - validation batch 201, loss: 0.831, 6432/6976 datapoints
2025-03-06 22:06:15,867 - INFO - Epoch 459/800 done.
2025-03-06 22:06:15,867 - INFO - Final validation performance:
Loss: 1.901, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:06:15,867 - INFO - Beginning epoch 460/800
2025-03-06 22:06:15,872 - INFO - training batch 1, loss: 0.020, 32/28000 datapoints
2025-03-06 22:06:16,034 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 22:06:16,196 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:06:16,352 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 22:06:16,508 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:06:16,668 - INFO - training batch 251, loss: 0.020, 8032/28000 datapoints
2025-03-06 22:06:16,827 - INFO - training batch 301, loss: 0.015, 9632/28000 datapoints
2025-03-06 22:06:16,984 - INFO - training batch 351, loss: 0.024, 11232/28000 datapoints
2025-03-06 22:06:17,138 - INFO - training batch 401, loss: 0.021, 12832/28000 datapoints
2025-03-06 22:06:17,300 - INFO - training batch 451, loss: 0.024, 14432/28000 datapoints
2025-03-06 22:06:17,460 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 22:06:17,619 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 22:06:17,777 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-06 22:06:17,935 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:06:18,091 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:06:18,248 - INFO - training batch 751, loss: 0.018, 24032/28000 datapoints
2025-03-06 22:06:18,411 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:18,577 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:06:18,658 - INFO - validation batch 1, loss: 0.639, 32/6976 datapoints
2025-03-06 22:06:18,713 - INFO - validation batch 51, loss: 5.114, 1632/6976 datapoints
2025-03-06 22:06:18,764 - INFO - validation batch 101, loss: 1.218, 3232/6976 datapoints
2025-03-06 22:06:18,814 - INFO - validation batch 151, loss: 1.818, 4832/6976 datapoints
2025-03-06 22:06:18,866 - INFO - validation batch 201, loss: 0.855, 6432/6976 datapoints
2025-03-06 22:06:18,882 - INFO - Epoch 460/800 done.
2025-03-06 22:06:18,882 - INFO - Final validation performance:
Loss: 1.929, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:06:18,883 - INFO - Beginning epoch 461/800
2025-03-06 22:06:18,887 - INFO - training batch 1, loss: 0.019, 32/28000 datapoints
2025-03-06 22:06:19,054 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 22:06:19,214 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:06:19,377 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 22:06:19,570 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:06:19,734 - INFO - training batch 251, loss: 0.023, 8032/28000 datapoints
2025-03-06 22:06:19,896 - INFO - training batch 301, loss: 0.016, 9632/28000 datapoints
2025-03-06 22:06:20,056 - INFO - training batch 351, loss: 0.025, 11232/28000 datapoints
2025-03-06 22:06:20,214 - INFO - training batch 401, loss: 0.133, 12832/28000 datapoints
2025-03-06 22:06:20,377 - INFO - training batch 451, loss: 0.019, 14432/28000 datapoints
2025-03-06 22:06:20,543 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 22:06:20,707 - INFO - training batch 551, loss: 0.134, 17632/28000 datapoints
2025-03-06 22:06:20,874 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 22:06:21,034 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:06:21,201 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-06 22:06:21,363 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-06 22:06:21,522 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:06:21,682 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:06:21,767 - INFO - validation batch 1, loss: 0.797, 32/6976 datapoints
2025-03-06 22:06:21,822 - INFO - validation batch 51, loss: 5.467, 1632/6976 datapoints
2025-03-06 22:06:21,879 - INFO - validation batch 101, loss: 1.318, 3232/6976 datapoints
2025-03-06 22:06:21,933 - INFO - validation batch 151, loss: 1.745, 4832/6976 datapoints
2025-03-06 22:06:21,986 - INFO - validation batch 201, loss: 0.907, 6432/6976 datapoints
2025-03-06 22:06:22,004 - INFO - Epoch 461/800 done.
2025-03-06 22:06:22,004 - INFO - Final validation performance:
Loss: 2.047, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:06:22,005 - INFO - Beginning epoch 462/800
2025-03-06 22:06:22,010 - INFO - training batch 1, loss: 0.032, 32/28000 datapoints
2025-03-06 22:06:22,179 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 22:06:22,341 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:06:22,498 - INFO - training batch 151, loss: 0.037, 4832/28000 datapoints
2025-03-06 22:06:22,657 - INFO - training batch 201, loss: 0.439, 6432/28000 datapoints
2025-03-06 22:06:22,813 - INFO - training batch 251, loss: 0.103, 8032/28000 datapoints
2025-03-06 22:06:22,977 - INFO - training batch 301, loss: 0.047, 9632/28000 datapoints
2025-03-06 22:06:23,138 - INFO - training batch 351, loss: 0.028, 11232/28000 datapoints
2025-03-06 22:06:23,296 - INFO - training batch 401, loss: 0.032, 12832/28000 datapoints
2025-03-06 22:06:23,454 - INFO - training batch 451, loss: 0.031, 14432/28000 datapoints
2025-03-06 22:06:23,614 - INFO - training batch 501, loss: 0.022, 16032/28000 datapoints
2025-03-06 22:06:23,779 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 22:06:23,939 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-06 22:06:24,096 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:06:24,253 - INFO - training batch 701, loss: 0.011, 22432/28000 datapoints
2025-03-06 22:06:24,413 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 22:06:24,572 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:24,732 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:06:24,812 - INFO - validation batch 1, loss: 0.726, 32/6976 datapoints
2025-03-06 22:06:24,865 - INFO - validation batch 51, loss: 5.201, 1632/6976 datapoints
2025-03-06 22:06:24,919 - INFO - validation batch 101, loss: 1.252, 3232/6976 datapoints
2025-03-06 22:06:24,973 - INFO - validation batch 151, loss: 1.723, 4832/6976 datapoints
2025-03-06 22:06:25,026 - INFO - validation batch 201, loss: 0.892, 6432/6976 datapoints
2025-03-06 22:06:25,046 - INFO - Epoch 462/800 done.
2025-03-06 22:06:25,046 - INFO - Final validation performance:
Loss: 1.959, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:06:25,047 - INFO - Beginning epoch 463/800
2025-03-06 22:06:25,052 - INFO - training batch 1, loss: 0.017, 32/28000 datapoints
2025-03-06 22:06:25,217 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 22:06:25,394 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:06:25,551 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-06 22:06:25,709 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:06:25,892 - INFO - training batch 251, loss: 0.019, 8032/28000 datapoints
2025-03-06 22:06:26,049 - INFO - training batch 301, loss: 0.029, 9632/28000 datapoints
2025-03-06 22:06:26,203 - INFO - training batch 351, loss: 0.031, 11232/28000 datapoints
2025-03-06 22:06:26,354 - INFO - training batch 401, loss: 0.032, 12832/28000 datapoints
2025-03-06 22:06:26,505 - INFO - training batch 451, loss: 0.026, 14432/28000 datapoints
2025-03-06 22:06:26,663 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-06 22:06:26,816 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 22:06:26,974 - INFO - training batch 601, loss: 0.014, 19232/28000 datapoints
2025-03-06 22:06:27,126 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:06:27,278 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:06:27,432 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-06 22:06:27,585 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:27,737 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:06:27,887 - INFO - validation batch 1, loss: 0.718, 32/6976 datapoints
2025-03-06 22:06:27,932 - INFO - validation batch 51, loss: 5.175, 1632/6976 datapoints
2025-03-06 22:06:27,979 - INFO - validation batch 101, loss: 1.199, 3232/6976 datapoints
2025-03-06 22:06:28,025 - INFO - validation batch 151, loss: 1.614, 4832/6976 datapoints
2025-03-06 22:06:28,073 - INFO - validation batch 201, loss: 0.930, 6432/6976 datapoints
2025-03-06 22:06:28,089 - INFO - Epoch 463/800 done.
2025-03-06 22:06:28,089 - INFO - Final validation performance:
Loss: 1.927, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:06:28,090 - INFO - Beginning epoch 464/800
2025-03-06 22:06:28,094 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 22:06:28,256 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 22:06:28,418 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:06:28,579 - INFO - training batch 151, loss: 0.013, 4832/28000 datapoints
2025-03-06 22:06:28,743 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 22:06:28,905 - INFO - training batch 251, loss: 0.024, 8032/28000 datapoints
2025-03-06 22:06:29,064 - INFO - training batch 301, loss: 0.019, 9632/28000 datapoints
2025-03-06 22:06:29,221 - INFO - training batch 351, loss: 0.026, 11232/28000 datapoints
2025-03-06 22:06:29,378 - INFO - training batch 401, loss: 0.024, 12832/28000 datapoints
2025-03-06 22:06:29,536 - INFO - training batch 451, loss: 0.037, 14432/28000 datapoints
2025-03-06 22:06:29,694 - INFO - training batch 501, loss: 0.023, 16032/28000 datapoints
2025-03-06 22:06:29,849 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-06 22:06:30,009 - INFO - training batch 601, loss: 0.014, 19232/28000 datapoints
2025-03-06 22:06:30,167 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:06:30,328 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:06:30,489 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 22:06:30,658 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:30,811 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:06:30,894 - INFO - validation batch 1, loss: 0.779, 32/6976 datapoints
2025-03-06 22:06:30,945 - INFO - validation batch 51, loss: 5.177, 1632/6976 datapoints
2025-03-06 22:06:30,995 - INFO - validation batch 101, loss: 1.193, 3232/6976 datapoints
2025-03-06 22:06:31,046 - INFO - validation batch 151, loss: 1.716, 4832/6976 datapoints
2025-03-06 22:06:31,097 - INFO - validation batch 201, loss: 0.916, 6432/6976 datapoints
2025-03-06 22:06:31,117 - INFO - Epoch 464/800 done.
2025-03-06 22:06:31,117 - INFO - Final validation performance:
Loss: 1.956, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:06:31,118 - INFO - Beginning epoch 465/800
2025-03-06 22:06:31,122 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-06 22:06:31,284 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-06 22:06:31,445 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:06:31,603 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-06 22:06:31,762 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:06:31,946 - INFO - training batch 251, loss: 0.020, 8032/28000 datapoints
2025-03-06 22:06:32,110 - INFO - training batch 301, loss: 0.022, 9632/28000 datapoints
2025-03-06 22:06:32,272 - INFO - training batch 351, loss: 0.028, 11232/28000 datapoints
2025-03-06 22:06:32,431 - INFO - training batch 401, loss: 0.019, 12832/28000 datapoints
2025-03-06 22:06:32,595 - INFO - training batch 451, loss: 0.035, 14432/28000 datapoints
2025-03-06 22:06:32,759 - INFO - training batch 501, loss: 0.019, 16032/28000 datapoints
2025-03-06 22:06:32,923 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 22:06:33,088 - INFO - training batch 601, loss: 0.015, 19232/28000 datapoints
2025-03-06 22:06:33,249 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:06:33,423 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:06:33,585 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 22:06:33,748 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:33,908 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:06:33,994 - INFO - validation batch 1, loss: 0.594, 32/6976 datapoints
2025-03-06 22:06:34,045 - INFO - validation batch 51, loss: 5.159, 1632/6976 datapoints
2025-03-06 22:06:34,094 - INFO - validation batch 101, loss: 1.167, 3232/6976 datapoints
2025-03-06 22:06:34,145 - INFO - validation batch 151, loss: 1.658, 4832/6976 datapoints
2025-03-06 22:06:34,198 - INFO - validation batch 201, loss: 0.853, 6432/6976 datapoints
2025-03-06 22:06:34,217 - INFO - Epoch 465/800 done.
2025-03-06 22:06:34,217 - INFO - Final validation performance:
Loss: 1.886, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:06:34,218 - INFO - Beginning epoch 466/800
2025-03-06 22:06:34,222 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-06 22:06:34,382 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:06:34,544 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:06:34,709 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-06 22:06:34,870 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:06:35,029 - INFO - training batch 251, loss: 0.020, 8032/28000 datapoints
2025-03-06 22:06:35,199 - INFO - training batch 301, loss: 0.023, 9632/28000 datapoints
2025-03-06 22:06:35,357 - INFO - training batch 351, loss: 0.023, 11232/28000 datapoints
2025-03-06 22:06:35,517 - INFO - training batch 401, loss: 0.018, 12832/28000 datapoints
2025-03-06 22:06:35,676 - INFO - training batch 451, loss: 0.032, 14432/28000 datapoints
2025-03-06 22:06:35,854 - INFO - training batch 501, loss: 0.016, 16032/28000 datapoints
2025-03-06 22:06:36,025 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 22:06:36,185 - INFO - training batch 601, loss: 0.013, 19232/28000 datapoints
2025-03-06 22:06:36,342 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:06:36,501 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:06:36,665 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 22:06:36,826 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:36,984 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:06:37,066 - INFO - validation batch 1, loss: 0.559, 32/6976 datapoints
2025-03-06 22:06:37,117 - INFO - validation batch 51, loss: 5.149, 1632/6976 datapoints
2025-03-06 22:06:37,168 - INFO - validation batch 101, loss: 1.194, 3232/6976 datapoints
2025-03-06 22:06:37,221 - INFO - validation batch 151, loss: 1.736, 4832/6976 datapoints
2025-03-06 22:06:37,273 - INFO - validation batch 201, loss: 0.858, 6432/6976 datapoints
2025-03-06 22:06:37,288 - INFO - Epoch 466/800 done.
2025-03-06 22:06:37,289 - INFO - Final validation performance:
Loss: 1.899, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:06:37,289 - INFO - Beginning epoch 467/800
2025-03-06 22:06:37,295 - INFO - training batch 1, loss: 0.012, 32/28000 datapoints
2025-03-06 22:06:37,459 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:06:37,621 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:06:37,783 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 22:06:37,960 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:06:38,119 - INFO - training batch 251, loss: 0.020, 8032/28000 datapoints
2025-03-06 22:06:38,280 - INFO - training batch 301, loss: 0.018, 9632/28000 datapoints
2025-03-06 22:06:38,437 - INFO - training batch 351, loss: 0.022, 11232/28000 datapoints
2025-03-06 22:06:38,594 - INFO - training batch 401, loss: 0.018, 12832/28000 datapoints
2025-03-06 22:06:38,757 - INFO - training batch 451, loss: 0.028, 14432/28000 datapoints
2025-03-06 22:06:38,919 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 22:06:39,076 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-06 22:06:39,235 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-06 22:06:39,399 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:06:39,558 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:06:39,717 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 22:06:39,877 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:40,036 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:06:40,119 - INFO - validation batch 1, loss: 0.543, 32/6976 datapoints
2025-03-06 22:06:40,170 - INFO - validation batch 51, loss: 5.175, 1632/6976 datapoints
2025-03-06 22:06:40,220 - INFO - validation batch 101, loss: 1.230, 3232/6976 datapoints
2025-03-06 22:06:40,272 - INFO - validation batch 151, loss: 1.786, 4832/6976 datapoints
2025-03-06 22:06:40,325 - INFO - validation batch 201, loss: 0.867, 6432/6976 datapoints
2025-03-06 22:06:40,343 - INFO - Epoch 467/800 done.
2025-03-06 22:06:40,343 - INFO - Final validation performance:
Loss: 1.920, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:06:40,344 - INFO - Beginning epoch 468/800
2025-03-06 22:06:40,348 - INFO - training batch 1, loss: 0.016, 32/28000 datapoints
2025-03-06 22:06:40,516 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 22:06:40,682 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:06:40,842 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 22:06:41,009 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:06:41,168 - INFO - training batch 251, loss: 0.020, 8032/28000 datapoints
2025-03-06 22:06:41,332 - INFO - training batch 301, loss: 0.016, 9632/28000 datapoints
2025-03-06 22:06:41,489 - INFO - training batch 351, loss: 0.021, 11232/28000 datapoints
2025-03-06 22:06:41,647 - INFO - training batch 401, loss: 0.018, 12832/28000 datapoints
2025-03-06 22:06:41,806 - INFO - training batch 451, loss: 0.023, 14432/28000 datapoints
2025-03-06 22:06:41,968 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 22:06:42,128 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 22:06:42,285 - INFO - training batch 601, loss: 0.009, 19232/28000 datapoints
2025-03-06 22:06:42,441 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:06:42,600 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:06:42,761 - INFO - training batch 751, loss: 0.017, 24032/28000 datapoints
2025-03-06 22:06:42,921 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:43,080 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:06:43,162 - INFO - validation batch 1, loss: 0.572, 32/6976 datapoints
2025-03-06 22:06:43,212 - INFO - validation batch 51, loss: 5.233, 1632/6976 datapoints
2025-03-06 22:06:43,262 - INFO - validation batch 101, loss: 1.249, 3232/6976 datapoints
2025-03-06 22:06:43,313 - INFO - validation batch 151, loss: 1.822, 4832/6976 datapoints
2025-03-06 22:06:43,367 - INFO - validation batch 201, loss: 0.867, 6432/6976 datapoints
2025-03-06 22:06:43,382 - INFO - Epoch 468/800 done.
2025-03-06 22:06:43,382 - INFO - Final validation performance:
Loss: 1.948, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:06:43,383 - INFO - Beginning epoch 469/800
2025-03-06 22:06:43,387 - INFO - training batch 1, loss: 0.016, 32/28000 datapoints
2025-03-06 22:06:43,551 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 22:06:43,718 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:06:43,884 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 22:06:44,048 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:06:44,212 - INFO - training batch 251, loss: 0.018, 8032/28000 datapoints
2025-03-06 22:06:44,377 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-06 22:06:44,536 - INFO - training batch 351, loss: 0.020, 11232/28000 datapoints
2025-03-06 22:06:44,706 - INFO - training batch 401, loss: 0.017, 12832/28000 datapoints
2025-03-06 22:06:44,871 - INFO - training batch 451, loss: 0.020, 14432/28000 datapoints
2025-03-06 22:06:45,040 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 22:06:45,211 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 22:06:45,374 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-06 22:06:45,540 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:06:45,700 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:06:45,860 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 22:06:46,046 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:46,206 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:06:46,286 - INFO - validation batch 1, loss: 0.580, 32/6976 datapoints
2025-03-06 22:06:46,336 - INFO - validation batch 51, loss: 5.297, 1632/6976 datapoints
2025-03-06 22:06:46,386 - INFO - validation batch 101, loss: 1.278, 3232/6976 datapoints
2025-03-06 22:06:46,437 - INFO - validation batch 151, loss: 1.864, 4832/6976 datapoints
2025-03-06 22:06:46,488 - INFO - validation batch 201, loss: 0.880, 6432/6976 datapoints
2025-03-06 22:06:46,507 - INFO - Epoch 469/800 done.
2025-03-06 22:06:46,507 - INFO - Final validation performance:
Loss: 1.980, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:06:46,508 - INFO - Beginning epoch 470/800
2025-03-06 22:06:46,512 - INFO - training batch 1, loss: 0.016, 32/28000 datapoints
2025-03-06 22:06:46,678 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 22:06:46,841 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:06:47,006 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 22:06:47,165 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:06:47,324 - INFO - training batch 251, loss: 0.018, 8032/28000 datapoints
2025-03-06 22:06:47,485 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-06 22:06:47,640 - INFO - training batch 351, loss: 0.020, 11232/28000 datapoints
2025-03-06 22:06:47,797 - INFO - training batch 401, loss: 0.018, 12832/28000 datapoints
2025-03-06 22:06:47,961 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-06 22:06:48,121 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 22:06:48,281 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 22:06:48,439 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-06 22:06:48,606 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:06:48,772 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:06:48,933 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 22:06:49,093 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:49,255 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:06:49,338 - INFO - validation batch 1, loss: 0.573, 32/6976 datapoints
2025-03-06 22:06:49,389 - INFO - validation batch 51, loss: 5.355, 1632/6976 datapoints
2025-03-06 22:06:49,441 - INFO - validation batch 101, loss: 1.297, 3232/6976 datapoints
2025-03-06 22:06:49,491 - INFO - validation batch 151, loss: 1.863, 4832/6976 datapoints
2025-03-06 22:06:49,543 - INFO - validation batch 201, loss: 0.877, 6432/6976 datapoints
2025-03-06 22:06:49,563 - INFO - Epoch 470/800 done.
2025-03-06 22:06:49,563 - INFO - Final validation performance:
Loss: 1.993, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:06:49,564 - INFO - Beginning epoch 471/800
2025-03-06 22:06:49,568 - INFO - training batch 1, loss: 0.017, 32/28000 datapoints
2025-03-06 22:06:49,738 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 22:06:49,906 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:06:50,071 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 22:06:50,231 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:06:50,392 - INFO - training batch 251, loss: 0.016, 8032/28000 datapoints
2025-03-06 22:06:50,555 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-06 22:06:50,716 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-06 22:06:50,878 - INFO - training batch 401, loss: 0.017, 12832/28000 datapoints
2025-03-06 22:06:51,039 - INFO - training batch 451, loss: 0.018, 14432/28000 datapoints
2025-03-06 22:06:51,197 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 22:06:51,357 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 22:06:51,517 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-06 22:06:51,676 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:06:51,837 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:06:51,998 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 22:06:52,164 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:06:52,324 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:06:52,405 - INFO - validation batch 1, loss: 0.590, 32/6976 datapoints
2025-03-06 22:06:52,455 - INFO - validation batch 51, loss: 5.432, 1632/6976 datapoints
2025-03-06 22:06:52,504 - INFO - validation batch 101, loss: 1.323, 3232/6976 datapoints
2025-03-06 22:06:52,552 - INFO - validation batch 151, loss: 1.921, 4832/6976 datapoints
2025-03-06 22:06:52,598 - INFO - validation batch 201, loss: 0.882, 6432/6976 datapoints
2025-03-06 22:06:52,614 - INFO - Epoch 471/800 done.
2025-03-06 22:06:52,614 - INFO - Final validation performance:
Loss: 2.029, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:06:52,614 - INFO - Beginning epoch 472/800
2025-03-06 22:06:52,619 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-06 22:06:52,781 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:06:52,941 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:06:53,100 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 22:06:53,258 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:06:53,415 - INFO - training batch 251, loss: 0.017, 8032/28000 datapoints
2025-03-06 22:06:53,574 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-06 22:06:53,728 - INFO - training batch 351, loss: 0.017, 11232/28000 datapoints
2025-03-06 22:06:53,886 - INFO - training batch 401, loss: 0.017, 12832/28000 datapoints
2025-03-06 22:06:54,042 - INFO - training batch 451, loss: 0.016, 14432/28000 datapoints
2025-03-06 22:06:54,199 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 22:06:54,361 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:06:54,519 - INFO - training batch 601, loss: 0.006, 19232/28000 datapoints
2025-03-06 22:06:54,678 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:06:54,842 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:06:55,006 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-06 22:06:55,173 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:06:55,336 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:06:55,416 - INFO - validation batch 1, loss: 0.540, 32/6976 datapoints
2025-03-06 22:06:55,462 - INFO - validation batch 51, loss: 5.465, 1632/6976 datapoints
2025-03-06 22:06:55,512 - INFO - validation batch 101, loss: 1.323, 3232/6976 datapoints
2025-03-06 22:06:55,558 - INFO - validation batch 151, loss: 1.912, 4832/6976 datapoints
2025-03-06 22:06:55,605 - INFO - validation batch 201, loss: 0.887, 6432/6976 datapoints
2025-03-06 22:06:55,621 - INFO - Epoch 472/800 done.
2025-03-06 22:06:55,622 - INFO - Final validation performance:
Loss: 2.025, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:06:55,622 - INFO - Beginning epoch 473/800
2025-03-06 22:06:55,626 - INFO - training batch 1, loss: 0.017, 32/28000 datapoints
2025-03-06 22:06:55,793 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:06:55,955 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:06:56,138 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 22:06:56,296 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:06:56,450 - INFO - training batch 251, loss: 0.014, 8032/28000 datapoints
2025-03-06 22:06:56,610 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-06 22:06:56,770 - INFO - training batch 351, loss: 0.017, 11232/28000 datapoints
2025-03-06 22:06:56,927 - INFO - training batch 401, loss: 0.016, 12832/28000 datapoints
2025-03-06 22:06:57,085 - INFO - training batch 451, loss: 0.016, 14432/28000 datapoints
2025-03-06 22:06:57,239 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 22:06:57,395 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 22:06:57,548 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-06 22:06:57,702 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:06:57,862 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:06:58,020 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-06 22:06:58,175 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:06:58,333 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:06:58,411 - INFO - validation batch 1, loss: 0.593, 32/6976 datapoints
2025-03-06 22:06:58,458 - INFO - validation batch 51, loss: 5.555, 1632/6976 datapoints
2025-03-06 22:06:58,508 - INFO - validation batch 101, loss: 1.308, 3232/6976 datapoints
2025-03-06 22:06:58,554 - INFO - validation batch 151, loss: 1.915, 4832/6976 datapoints
2025-03-06 22:06:58,601 - INFO - validation batch 201, loss: 0.877, 6432/6976 datapoints
2025-03-06 22:06:58,617 - INFO - Epoch 473/800 done.
2025-03-06 22:06:58,618 - INFO - Final validation performance:
Loss: 2.050, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:06:58,618 - INFO - Beginning epoch 474/800
2025-03-06 22:06:58,622 - INFO - training batch 1, loss: 0.014, 32/28000 datapoints
2025-03-06 22:06:58,784 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:06:58,946 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:06:59,103 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 22:06:59,260 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:06:59,421 - INFO - training batch 251, loss: 0.015, 8032/28000 datapoints
2025-03-06 22:06:59,583 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:06:59,736 - INFO - training batch 351, loss: 0.016, 11232/28000 datapoints
2025-03-06 22:06:59,894 - INFO - training batch 401, loss: 0.017, 12832/28000 datapoints
2025-03-06 22:07:00,050 - INFO - training batch 451, loss: 0.013, 14432/28000 datapoints
2025-03-06 22:07:00,206 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 22:07:00,368 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-06 22:07:00,522 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-06 22:07:00,676 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:07:00,839 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:07:00,998 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 22:07:01,153 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:01,310 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:07:01,389 - INFO - validation batch 1, loss: 0.575, 32/6976 datapoints
2025-03-06 22:07:01,436 - INFO - validation batch 51, loss: 5.625, 1632/6976 datapoints
2025-03-06 22:07:01,482 - INFO - validation batch 101, loss: 1.321, 3232/6976 datapoints
2025-03-06 22:07:01,529 - INFO - validation batch 151, loss: 1.905, 4832/6976 datapoints
2025-03-06 22:07:01,577 - INFO - validation batch 201, loss: 0.899, 6432/6976 datapoints
2025-03-06 22:07:01,593 - INFO - Epoch 474/800 done.
2025-03-06 22:07:01,593 - INFO - Final validation performance:
Loss: 2.065, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:07:01,594 - INFO - Beginning epoch 475/800
2025-03-06 22:07:01,599 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-06 22:07:01,766 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 22:07:01,940 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:07:02,101 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 22:07:02,259 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:07:02,418 - INFO - training batch 251, loss: 0.016, 8032/28000 datapoints
2025-03-06 22:07:02,585 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-06 22:07:02,752 - INFO - training batch 351, loss: 0.017, 11232/28000 datapoints
2025-03-06 22:07:02,913 - INFO - training batch 401, loss: 0.016, 12832/28000 datapoints
2025-03-06 22:07:03,069 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-06 22:07:03,226 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:07:03,382 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:07:03,540 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-06 22:07:03,697 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:07:03,861 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:07:04,019 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-06 22:07:04,177 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:04,337 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:07:04,422 - INFO - validation batch 1, loss: 0.617, 32/6976 datapoints
2025-03-06 22:07:04,470 - INFO - validation batch 51, loss: 5.767, 1632/6976 datapoints
2025-03-06 22:07:04,516 - INFO - validation batch 101, loss: 1.324, 3232/6976 datapoints
2025-03-06 22:07:04,563 - INFO - validation batch 151, loss: 1.967, 4832/6976 datapoints
2025-03-06 22:07:04,610 - INFO - validation batch 201, loss: 0.889, 6432/6976 datapoints
2025-03-06 22:07:04,626 - INFO - Epoch 475/800 done.
2025-03-06 22:07:04,626 - INFO - Final validation performance:
Loss: 2.113, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:07:04,627 - INFO - Beginning epoch 476/800
2025-03-06 22:07:04,631 - INFO - training batch 1, loss: 0.016, 32/28000 datapoints
2025-03-06 22:07:04,792 - INFO - training batch 51, loss: 0.189, 1632/28000 datapoints
2025-03-06 22:07:04,955 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 22:07:05,120 - INFO - training batch 151, loss: 0.090, 4832/28000 datapoints
2025-03-06 22:07:05,281 - INFO - training batch 201, loss: 0.056, 6432/28000 datapoints
2025-03-06 22:07:05,438 - INFO - training batch 251, loss: 0.037, 8032/28000 datapoints
2025-03-06 22:07:05,602 - INFO - training batch 301, loss: 0.015, 9632/28000 datapoints
2025-03-06 22:07:05,758 - INFO - training batch 351, loss: 0.027, 11232/28000 datapoints
2025-03-06 22:07:05,915 - INFO - training batch 401, loss: 0.049, 12832/28000 datapoints
2025-03-06 22:07:06,074 - INFO - training batch 451, loss: 0.031, 14432/28000 datapoints
2025-03-06 22:07:06,250 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 22:07:06,408 - INFO - training batch 551, loss: 0.017, 17632/28000 datapoints
2025-03-06 22:07:06,562 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-06 22:07:06,715 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:07:06,882 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:07:07,039 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 22:07:07,194 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:07:07,352 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-06 22:07:07,435 - INFO - validation batch 1, loss: 0.852, 32/6976 datapoints
2025-03-06 22:07:07,482 - INFO - validation batch 51, loss: 5.952, 1632/6976 datapoints
2025-03-06 22:07:07,528 - INFO - validation batch 101, loss: 1.239, 3232/6976 datapoints
2025-03-06 22:07:07,575 - INFO - validation batch 151, loss: 1.631, 4832/6976 datapoints
2025-03-06 22:07:07,622 - INFO - validation batch 201, loss: 0.789, 6432/6976 datapoints
2025-03-06 22:07:07,638 - INFO - Epoch 476/800 done.
2025-03-06 22:07:07,638 - INFO - Final validation performance:
Loss: 2.093, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 22:07:07,639 - INFO - Beginning epoch 477/800
2025-03-06 22:07:07,643 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-06 22:07:07,815 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:07:07,986 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:07:08,144 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 22:07:08,308 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 22:07:08,468 - INFO - training batch 251, loss: 0.024, 8032/28000 datapoints
2025-03-06 22:07:08,632 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-06 22:07:08,802 - INFO - training batch 351, loss: 0.026, 11232/28000 datapoints
2025-03-06 22:07:08,965 - INFO - training batch 401, loss: 0.028, 12832/28000 datapoints
2025-03-06 22:07:09,123 - INFO - training batch 451, loss: 0.051, 14432/28000 datapoints
2025-03-06 22:07:09,294 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:07:09,458 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 22:07:09,617 - INFO - training batch 601, loss: 0.031, 19232/28000 datapoints
2025-03-06 22:07:09,780 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:07:09,946 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:07:10,111 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 22:07:10,274 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:10,436 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:07:10,521 - INFO - validation batch 1, loss: 0.756, 32/6976 datapoints
2025-03-06 22:07:10,573 - INFO - validation batch 51, loss: 5.697, 1632/6976 datapoints
2025-03-06 22:07:10,623 - INFO - validation batch 101, loss: 1.251, 3232/6976 datapoints
2025-03-06 22:07:10,674 - INFO - validation batch 151, loss: 1.891, 4832/6976 datapoints
2025-03-06 22:07:10,724 - INFO - validation batch 201, loss: 0.947, 6432/6976 datapoints
2025-03-06 22:07:10,740 - INFO - Epoch 477/800 done.
2025-03-06 22:07:10,740 - INFO - Final validation performance:
Loss: 2.108, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:07:10,741 - INFO - Beginning epoch 478/800
2025-03-06 22:07:10,746 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-06 22:07:10,915 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:07:11,079 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:07:11,240 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 22:07:11,399 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:07:11,556 - INFO - training batch 251, loss: 0.021, 8032/28000 datapoints
2025-03-06 22:07:11,718 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:07:11,874 - INFO - training batch 351, loss: 0.028, 11232/28000 datapoints
2025-03-06 22:07:12,035 - INFO - training batch 401, loss: 0.017, 12832/28000 datapoints
2025-03-06 22:07:12,191 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-06 22:07:12,347 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 22:07:12,507 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 22:07:12,661 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-06 22:07:12,824 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:07:12,987 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:07:13,162 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 22:07:13,318 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:13,479 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:07:13,563 - INFO - validation batch 1, loss: 0.640, 32/6976 datapoints
2025-03-06 22:07:13,609 - INFO - validation batch 51, loss: 5.586, 1632/6976 datapoints
2025-03-06 22:07:13,657 - INFO - validation batch 101, loss: 1.182, 3232/6976 datapoints
2025-03-06 22:07:13,704 - INFO - validation batch 151, loss: 1.797, 4832/6976 datapoints
2025-03-06 22:07:13,751 - INFO - validation batch 201, loss: 0.911, 6432/6976 datapoints
2025-03-06 22:07:13,767 - INFO - Epoch 478/800 done.
2025-03-06 22:07:13,768 - INFO - Final validation performance:
Loss: 2.023, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:07:13,768 - INFO - Beginning epoch 479/800
2025-03-06 22:07:13,772 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:07:13,951 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:07:14,116 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:07:14,279 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 22:07:14,446 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:07:14,609 - INFO - training batch 251, loss: 0.016, 8032/28000 datapoints
2025-03-06 22:07:14,778 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:07:14,946 - INFO - training batch 351, loss: 0.022, 11232/28000 datapoints
2025-03-06 22:07:15,116 - INFO - training batch 401, loss: 0.019, 12832/28000 datapoints
2025-03-06 22:07:15,278 - INFO - training batch 451, loss: 0.038, 14432/28000 datapoints
2025-03-06 22:07:15,436 - INFO - training batch 501, loss: 0.018, 16032/28000 datapoints
2025-03-06 22:07:15,599 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 22:07:15,754 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-06 22:07:15,914 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:07:16,075 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:07:16,255 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-06 22:07:16,414 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:16,574 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:07:16,655 - INFO - validation batch 1, loss: 0.569, 32/6976 datapoints
2025-03-06 22:07:16,702 - INFO - validation batch 51, loss: 5.611, 1632/6976 datapoints
2025-03-06 22:07:16,749 - INFO - validation batch 101, loss: 1.173, 3232/6976 datapoints
2025-03-06 22:07:16,798 - INFO - validation batch 151, loss: 1.771, 4832/6976 datapoints
2025-03-06 22:07:16,847 - INFO - validation batch 201, loss: 0.895, 6432/6976 datapoints
2025-03-06 22:07:16,865 - INFO - Epoch 479/800 done.
2025-03-06 22:07:16,866 - INFO - Final validation performance:
Loss: 2.004, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:07:16,866 - INFO - Beginning epoch 480/800
2025-03-06 22:07:16,870 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:07:17,034 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:07:17,193 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:07:17,354 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 22:07:17,512 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-06 22:07:17,668 - INFO - training batch 251, loss: 0.014, 8032/28000 datapoints
2025-03-06 22:07:17,831 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-06 22:07:17,988 - INFO - training batch 351, loss: 0.019, 11232/28000 datapoints
2025-03-06 22:07:18,145 - INFO - training batch 401, loss: 0.015, 12832/28000 datapoints
2025-03-06 22:07:18,302 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-06 22:07:18,459 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 22:07:18,617 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 22:07:18,773 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-06 22:07:18,944 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:07:19,103 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:07:19,264 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 22:07:19,428 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:19,590 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:07:19,670 - INFO - validation batch 1, loss: 0.559, 32/6976 datapoints
2025-03-06 22:07:19,717 - INFO - validation batch 51, loss: 5.683, 1632/6976 datapoints
2025-03-06 22:07:19,766 - INFO - validation batch 101, loss: 1.179, 3232/6976 datapoints
2025-03-06 22:07:19,813 - INFO - validation batch 151, loss: 1.817, 4832/6976 datapoints
2025-03-06 22:07:19,863 - INFO - validation batch 201, loss: 0.887, 6432/6976 datapoints
2025-03-06 22:07:19,886 - INFO - Epoch 480/800 done.
2025-03-06 22:07:19,887 - INFO - Final validation performance:
Loss: 2.025, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:07:19,887 - INFO - Beginning epoch 481/800
2025-03-06 22:07:19,892 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-06 22:07:20,091 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:07:20,262 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:07:20,427 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 22:07:20,593 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:07:20,752 - INFO - training batch 251, loss: 0.015, 8032/28000 datapoints
2025-03-06 22:07:20,927 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-06 22:07:21,083 - INFO - training batch 351, loss: 0.016, 11232/28000 datapoints
2025-03-06 22:07:21,240 - INFO - training batch 401, loss: 0.014, 12832/28000 datapoints
2025-03-06 22:07:21,398 - INFO - training batch 451, loss: 0.020, 14432/28000 datapoints
2025-03-06 22:07:21,553 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 22:07:21,712 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 22:07:21,870 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-06 22:07:22,029 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:07:22,189 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:07:22,348 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 22:07:22,503 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:22,660 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:07:22,743 - INFO - validation batch 1, loss: 0.514, 32/6976 datapoints
2025-03-06 22:07:22,789 - INFO - validation batch 51, loss: 5.703, 1632/6976 datapoints
2025-03-06 22:07:22,839 - INFO - validation batch 101, loss: 1.232, 3232/6976 datapoints
2025-03-06 22:07:22,888 - INFO - validation batch 151, loss: 1.863, 4832/6976 datapoints
2025-03-06 22:07:22,937 - INFO - validation batch 201, loss: 0.891, 6432/6976 datapoints
2025-03-06 22:07:22,953 - INFO - Epoch 481/800 done.
2025-03-06 22:07:22,953 - INFO - Final validation performance:
Loss: 2.041, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:07:22,954 - INFO - Beginning epoch 482/800
2025-03-06 22:07:22,958 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 22:07:23,124 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:07:23,282 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:07:23,442 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 22:07:23,601 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:07:23,757 - INFO - training batch 251, loss: 0.015, 8032/28000 datapoints
2025-03-06 22:07:23,924 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-06 22:07:24,080 - INFO - training batch 351, loss: 0.015, 11232/28000 datapoints
2025-03-06 22:07:24,237 - INFO - training batch 401, loss: 0.014, 12832/28000 datapoints
2025-03-06 22:07:24,392 - INFO - training batch 451, loss: 0.016, 14432/28000 datapoints
2025-03-06 22:07:24,549 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:07:24,707 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:07:24,867 - INFO - training batch 601, loss: 0.006, 19232/28000 datapoints
2025-03-06 22:07:25,025 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:07:25,195 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:07:25,359 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-06 22:07:25,519 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:25,686 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:07:25,771 - INFO - validation batch 1, loss: 0.529, 32/6976 datapoints
2025-03-06 22:07:25,817 - INFO - validation batch 51, loss: 5.760, 1632/6976 datapoints
2025-03-06 22:07:25,868 - INFO - validation batch 101, loss: 1.264, 3232/6976 datapoints
2025-03-06 22:07:25,915 - INFO - validation batch 151, loss: 1.939, 4832/6976 datapoints
2025-03-06 22:07:25,962 - INFO - validation batch 201, loss: 0.910, 6432/6976 datapoints
2025-03-06 22:07:25,978 - INFO - Epoch 482/800 done.
2025-03-06 22:07:25,978 - INFO - Final validation performance:
Loss: 2.080, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:07:25,979 - INFO - Beginning epoch 483/800
2025-03-06 22:07:25,984 - INFO - training batch 1, loss: 0.011, 32/28000 datapoints
2025-03-06 22:07:26,169 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:07:26,357 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:07:26,526 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 22:07:26,696 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:07:26,864 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-06 22:07:27,041 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:07:27,199 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-06 22:07:27,356 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 22:07:27,515 - INFO - training batch 451, loss: 0.014, 14432/28000 datapoints
2025-03-06 22:07:27,674 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 22:07:27,832 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:07:27,992 - INFO - training batch 601, loss: 0.006, 19232/28000 datapoints
2025-03-06 22:07:28,150 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:07:28,309 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:07:28,468 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 22:07:28,626 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:28,793 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:07:28,884 - INFO - validation batch 1, loss: 0.540, 32/6976 datapoints
2025-03-06 22:07:28,935 - INFO - validation batch 51, loss: 5.829, 1632/6976 datapoints
2025-03-06 22:07:28,984 - INFO - validation batch 101, loss: 1.301, 3232/6976 datapoints
2025-03-06 22:07:29,034 - INFO - validation batch 151, loss: 1.970, 4832/6976 datapoints
2025-03-06 22:07:29,087 - INFO - validation batch 201, loss: 0.923, 6432/6976 datapoints
2025-03-06 22:07:29,104 - INFO - Epoch 483/800 done.
2025-03-06 22:07:29,104 - INFO - Final validation performance:
Loss: 2.113, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:07:29,105 - INFO - Beginning epoch 484/800
2025-03-06 22:07:29,110 - INFO - training batch 1, loss: 0.012, 32/28000 datapoints
2025-03-06 22:07:29,281 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:07:29,446 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:07:29,608 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 22:07:29,769 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:07:29,930 - INFO - training batch 251, loss: 0.012, 8032/28000 datapoints
2025-03-06 22:07:30,101 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:07:30,262 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-06 22:07:30,423 - INFO - training batch 401, loss: 0.014, 12832/28000 datapoints
2025-03-06 22:07:30,582 - INFO - training batch 451, loss: 0.013, 14432/28000 datapoints
2025-03-06 22:07:30,741 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 22:07:30,911 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-06 22:07:31,073 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-06 22:07:31,233 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:07:31,397 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:07:31,559 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 22:07:31,721 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:31,889 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:07:31,973 - INFO - validation batch 1, loss: 0.546, 32/6976 datapoints
2025-03-06 22:07:32,023 - INFO - validation batch 51, loss: 5.912, 1632/6976 datapoints
2025-03-06 22:07:32,075 - INFO - validation batch 101, loss: 1.346, 3232/6976 datapoints
2025-03-06 22:07:32,124 - INFO - validation batch 151, loss: 1.988, 4832/6976 datapoints
2025-03-06 22:07:32,176 - INFO - validation batch 201, loss: 0.923, 6432/6976 datapoints
2025-03-06 22:07:32,194 - INFO - Epoch 484/800 done.
2025-03-06 22:07:32,195 - INFO - Final validation performance:
Loss: 2.143, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:07:32,195 - INFO - Beginning epoch 485/800
2025-03-06 22:07:32,200 - INFO - training batch 1, loss: 0.013, 32/28000 datapoints
2025-03-06 22:07:32,367 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:07:32,538 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:07:32,703 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 22:07:32,870 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:07:33,039 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-06 22:07:33,208 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:07:33,371 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-06 22:07:33,532 - INFO - training batch 401, loss: 0.014, 12832/28000 datapoints
2025-03-06 22:07:33,694 - INFO - training batch 451, loss: 0.013, 14432/28000 datapoints
2025-03-06 22:07:33,852 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 22:07:34,015 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-06 22:07:34,178 - INFO - training batch 601, loss: 0.015, 19232/28000 datapoints
2025-03-06 22:07:34,341 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 22:07:34,512 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:07:34,678 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 22:07:34,839 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:35,003 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:07:35,089 - INFO - validation batch 1, loss: 0.553, 32/6976 datapoints
2025-03-06 22:07:35,147 - INFO - validation batch 51, loss: 6.374, 1632/6976 datapoints
2025-03-06 22:07:35,198 - INFO - validation batch 101, loss: 1.329, 3232/6976 datapoints
2025-03-06 22:07:35,250 - INFO - validation batch 151, loss: 2.007, 4832/6976 datapoints
2025-03-06 22:07:35,297 - INFO - validation batch 201, loss: 0.914, 6432/6976 datapoints
2025-03-06 22:07:35,317 - INFO - Epoch 485/800 done.
2025-03-06 22:07:35,318 - INFO - Final validation performance:
Loss: 2.236, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:07:35,318 - INFO - Beginning epoch 486/800
2025-03-06 22:07:35,323 - INFO - training batch 1, loss: 0.045, 32/28000 datapoints
2025-03-06 22:07:35,487 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 22:07:35,664 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:07:35,833 - INFO - training batch 151, loss: 0.047, 4832/28000 datapoints
2025-03-06 22:07:35,997 - INFO - training batch 201, loss: 0.390, 6432/28000 datapoints
2025-03-06 22:07:36,158 - INFO - training batch 251, loss: 0.028, 8032/28000 datapoints
2025-03-06 22:07:36,327 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:07:36,515 - INFO - training batch 351, loss: 0.025, 11232/28000 datapoints
2025-03-06 22:07:36,677 - INFO - training batch 401, loss: 0.034, 12832/28000 datapoints
2025-03-06 22:07:36,842 - INFO - training batch 451, loss: 0.023, 14432/28000 datapoints
2025-03-06 22:07:37,014 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:07:37,179 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 22:07:37,345 - INFO - training batch 601, loss: 0.006, 19232/28000 datapoints
2025-03-06 22:07:37,511 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:07:37,676 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:07:37,842 - INFO - training batch 751, loss: 0.009, 24032/28000 datapoints
2025-03-06 22:07:38,020 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:38,186 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:07:38,274 - INFO - validation batch 1, loss: 0.675, 32/6976 datapoints
2025-03-06 22:07:38,325 - INFO - validation batch 51, loss: 5.792, 1632/6976 datapoints
2025-03-06 22:07:38,378 - INFO - validation batch 101, loss: 1.367, 3232/6976 datapoints
2025-03-06 22:07:38,429 - INFO - validation batch 151, loss: 2.034, 4832/6976 datapoints
2025-03-06 22:07:38,480 - INFO - validation batch 201, loss: 0.949, 6432/6976 datapoints
2025-03-06 22:07:38,498 - INFO - Epoch 486/800 done.
2025-03-06 22:07:38,499 - INFO - Final validation performance:
Loss: 2.163, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:07:38,499 - INFO - Beginning epoch 487/800
2025-03-06 22:07:38,504 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:07:38,677 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:07:38,844 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-06 22:07:39,010 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 22:07:39,177 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:07:39,342 - INFO - training batch 251, loss: 0.012, 8032/28000 datapoints
2025-03-06 22:07:39,513 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:07:39,677 - INFO - training batch 351, loss: 0.020, 11232/28000 datapoints
2025-03-06 22:07:39,836 - INFO - training batch 401, loss: 0.022, 12832/28000 datapoints
2025-03-06 22:07:39,996 - INFO - training batch 451, loss: 0.020, 14432/28000 datapoints
2025-03-06 22:07:40,153 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:07:40,313 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:07:40,471 - INFO - training batch 601, loss: 0.009, 19232/28000 datapoints
2025-03-06 22:07:40,632 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:07:40,794 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:07:40,960 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 22:07:41,117 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:41,279 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:07:41,360 - INFO - validation batch 1, loss: 0.615, 32/6976 datapoints
2025-03-06 22:07:41,406 - INFO - validation batch 51, loss: 5.838, 1632/6976 datapoints
2025-03-06 22:07:41,453 - INFO - validation batch 101, loss: 1.328, 3232/6976 datapoints
2025-03-06 22:07:41,499 - INFO - validation batch 151, loss: 2.054, 4832/6976 datapoints
2025-03-06 22:07:41,546 - INFO - validation batch 201, loss: 0.938, 6432/6976 datapoints
2025-03-06 22:07:41,562 - INFO - Epoch 487/800 done.
2025-03-06 22:07:41,562 - INFO - Final validation performance:
Loss: 2.155, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:07:41,563 - INFO - Beginning epoch 488/800
2025-03-06 22:07:41,567 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:07:41,725 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:07:41,891 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:07:42,056 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-06 22:07:42,218 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:07:42,374 - INFO - training batch 251, loss: 0.016, 8032/28000 datapoints
2025-03-06 22:07:42,536 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:07:42,692 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-06 22:07:42,849 - INFO - training batch 401, loss: 0.014, 12832/28000 datapoints
2025-03-06 22:07:43,010 - INFO - training batch 451, loss: 0.041, 14432/28000 datapoints
2025-03-06 22:07:43,167 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:07:43,333 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 22:07:43,492 - INFO - training batch 601, loss: 0.012, 19232/28000 datapoints
2025-03-06 22:07:43,649 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:07:43,809 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:07:43,974 - INFO - training batch 751, loss: 0.009, 24032/28000 datapoints
2025-03-06 22:07:44,131 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:07:44,290 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:07:44,373 - INFO - validation batch 1, loss: 0.690, 32/6976 datapoints
2025-03-06 22:07:44,422 - INFO - validation batch 51, loss: 5.931, 1632/6976 datapoints
2025-03-06 22:07:44,470 - INFO - validation batch 101, loss: 1.312, 3232/6976 datapoints
2025-03-06 22:07:44,517 - INFO - validation batch 151, loss: 2.003, 4832/6976 datapoints
2025-03-06 22:07:44,563 - INFO - validation batch 201, loss: 0.991, 6432/6976 datapoints
2025-03-06 22:07:44,579 - INFO - Epoch 488/800 done.
2025-03-06 22:07:44,579 - INFO - Final validation performance:
Loss: 2.186, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:07:44,580 - INFO - Beginning epoch 489/800
2025-03-06 22:07:44,584 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:07:44,741 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:07:44,915 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:07:45,083 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 22:07:45,248 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:07:45,414 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:07:45,579 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-06 22:07:45,751 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-06 22:07:45,911 - INFO - training batch 401, loss: 0.012, 12832/28000 datapoints
2025-03-06 22:07:46,066 - INFO - training batch 451, loss: 0.026, 14432/28000 datapoints
2025-03-06 22:07:46,224 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:07:46,383 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-06 22:07:46,561 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-06 22:07:46,722 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:07:46,886 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:07:47,045 - INFO - training batch 751, loss: 0.009, 24032/28000 datapoints
2025-03-06 22:07:47,204 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:47,363 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:07:47,446 - INFO - validation batch 1, loss: 0.613, 32/6976 datapoints
2025-03-06 22:07:47,494 - INFO - validation batch 51, loss: 5.910, 1632/6976 datapoints
2025-03-06 22:07:47,540 - INFO - validation batch 101, loss: 1.245, 3232/6976 datapoints
2025-03-06 22:07:47,586 - INFO - validation batch 151, loss: 1.916, 4832/6976 datapoints
2025-03-06 22:07:47,633 - INFO - validation batch 201, loss: 0.951, 6432/6976 datapoints
2025-03-06 22:07:47,649 - INFO - Epoch 489/800 done.
2025-03-06 22:07:47,649 - INFO - Final validation performance:
Loss: 2.127, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:07:47,650 - INFO - Beginning epoch 490/800
2025-03-06 22:07:47,654 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:07:47,813 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:07:47,977 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:07:48,139 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 22:07:48,300 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:07:48,459 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-06 22:07:48,620 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-06 22:07:48,782 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-06 22:07:48,953 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:07:49,115 - INFO - training batch 451, loss: 0.023, 14432/28000 datapoints
2025-03-06 22:07:49,276 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 22:07:49,440 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:07:49,601 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-06 22:07:49,767 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:07:49,937 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:07:50,097 - INFO - training batch 751, loss: 0.009, 24032/28000 datapoints
2025-03-06 22:07:50,260 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:50,425 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:07:50,509 - INFO - validation batch 1, loss: 0.581, 32/6976 datapoints
2025-03-06 22:07:50,560 - INFO - validation batch 51, loss: 5.902, 1632/6976 datapoints
2025-03-06 22:07:50,611 - INFO - validation batch 101, loss: 1.266, 3232/6976 datapoints
2025-03-06 22:07:50,662 - INFO - validation batch 151, loss: 1.933, 4832/6976 datapoints
2025-03-06 22:07:50,713 - INFO - validation batch 201, loss: 0.937, 6432/6976 datapoints
2025-03-06 22:07:50,729 - INFO - Epoch 490/800 done.
2025-03-06 22:07:50,729 - INFO - Final validation performance:
Loss: 2.124, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:07:50,730 - INFO - Beginning epoch 491/800
2025-03-06 22:07:50,734 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:07:50,908 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:07:51,091 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:07:51,257 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 22:07:51,426 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:07:51,589 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-06 22:07:51,768 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-06 22:07:51,937 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-06 22:07:52,103 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:07:52,266 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-06 22:07:52,436 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 22:07:52,604 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-06 22:07:52,769 - INFO - training batch 601, loss: 0.006, 19232/28000 datapoints
2025-03-06 22:07:52,937 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:07:53,110 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:07:53,277 - INFO - training batch 751, loss: 0.009, 24032/28000 datapoints
2025-03-06 22:07:53,440 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:53,610 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:07:53,700 - INFO - validation batch 1, loss: 0.556, 32/6976 datapoints
2025-03-06 22:07:53,749 - INFO - validation batch 51, loss: 5.922, 1632/6976 datapoints
2025-03-06 22:07:53,799 - INFO - validation batch 101, loss: 1.307, 3232/6976 datapoints
2025-03-06 22:07:53,850 - INFO - validation batch 151, loss: 2.014, 4832/6976 datapoints
2025-03-06 22:07:53,904 - INFO - validation batch 201, loss: 0.949, 6432/6976 datapoints
2025-03-06 22:07:53,920 - INFO - Epoch 491/800 done.
2025-03-06 22:07:53,920 - INFO - Final validation performance:
Loss: 2.150, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:07:53,920 - INFO - Beginning epoch 492/800
2025-03-06 22:07:53,925 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-06 22:07:54,089 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:07:54,250 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:07:54,410 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 22:07:54,570 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:07:54,726 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-06 22:07:54,890 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:07:55,054 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-06 22:07:55,217 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:07:55,385 - INFO - training batch 451, loss: 0.014, 14432/28000 datapoints
2025-03-06 22:07:55,552 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:07:55,713 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-06 22:07:55,872 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-06 22:07:56,031 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:07:56,194 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:07:56,354 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 22:07:56,513 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:56,698 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:07:56,780 - INFO - validation batch 1, loss: 0.539, 32/6976 datapoints
2025-03-06 22:07:56,825 - INFO - validation batch 51, loss: 5.963, 1632/6976 datapoints
2025-03-06 22:07:56,874 - INFO - validation batch 101, loss: 1.377, 3232/6976 datapoints
2025-03-06 22:07:56,921 - INFO - validation batch 151, loss: 2.068, 4832/6976 datapoints
2025-03-06 22:07:56,972 - INFO - validation batch 201, loss: 0.951, 6432/6976 datapoints
2025-03-06 22:07:56,987 - INFO - Epoch 492/800 done.
2025-03-06 22:07:56,988 - INFO - Final validation performance:
Loss: 2.179, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:07:56,988 - INFO - Beginning epoch 493/800
2025-03-06 22:07:56,992 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 22:07:57,167 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:07:57,328 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:07:57,489 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 22:07:57,652 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-06 22:07:57,814 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-06 22:07:57,985 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:07:58,148 - INFO - training batch 351, loss: 0.013, 11232/28000 datapoints
2025-03-06 22:07:58,304 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:07:58,463 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-06 22:07:58,622 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:07:58,785 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-06 22:07:58,946 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-06 22:07:59,113 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:07:59,273 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:07:59,429 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 22:07:59,594 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:07:59,760 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:07:59,841 - INFO - validation batch 1, loss: 0.561, 32/6976 datapoints
2025-03-06 22:07:59,892 - INFO - validation batch 51, loss: 6.038, 1632/6976 datapoints
2025-03-06 22:07:59,938 - INFO - validation batch 101, loss: 1.407, 3232/6976 datapoints
2025-03-06 22:07:59,984 - INFO - validation batch 151, loss: 2.083, 4832/6976 datapoints
2025-03-06 22:08:00,033 - INFO - validation batch 201, loss: 0.956, 6432/6976 datapoints
2025-03-06 22:08:00,049 - INFO - Epoch 493/800 done.
2025-03-06 22:08:00,049 - INFO - Final validation performance:
Loss: 2.209, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:08:00,050 - INFO - Beginning epoch 494/800
2025-03-06 22:08:00,054 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 22:08:00,215 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:08:00,373 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:08:00,538 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 22:08:00,697 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-06 22:08:00,853 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-06 22:08:01,024 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:08:01,185 - INFO - training batch 351, loss: 0.013, 11232/28000 datapoints
2025-03-06 22:08:01,344 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:08:01,504 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-06 22:08:01,662 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:08:01,824 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:08:01,984 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:08:02,148 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:08:02,316 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:08:02,474 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 22:08:02,633 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:02,794 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:08:02,878 - INFO - validation batch 1, loss: 0.544, 32/6976 datapoints
2025-03-06 22:08:02,926 - INFO - validation batch 51, loss: 6.127, 1632/6976 datapoints
2025-03-06 22:08:02,973 - INFO - validation batch 101, loss: 1.475, 3232/6976 datapoints
2025-03-06 22:08:03,022 - INFO - validation batch 151, loss: 2.143, 4832/6976 datapoints
2025-03-06 22:08:03,068 - INFO - validation batch 201, loss: 0.978, 6432/6976 datapoints
2025-03-06 22:08:03,086 - INFO - Epoch 494/800 done.
2025-03-06 22:08:03,086 - INFO - Final validation performance:
Loss: 2.253, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:08:03,087 - INFO - Beginning epoch 495/800
2025-03-06 22:08:03,091 - INFO - training batch 1, loss: 0.012, 32/28000 datapoints
2025-03-06 22:08:03,248 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:08:03,415 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:08:03,582 - INFO - training batch 151, loss: 0.052, 4832/28000 datapoints
2025-03-06 22:08:03,739 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:08:03,898 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-06 22:08:04,065 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-06 22:08:04,225 - INFO - training batch 351, loss: 0.020, 11232/28000 datapoints
2025-03-06 22:08:04,389 - INFO - training batch 401, loss: 0.093, 12832/28000 datapoints
2025-03-06 22:08:04,552 - INFO - training batch 451, loss: 0.020, 14432/28000 datapoints
2025-03-06 22:08:04,711 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:08:04,874 - INFO - training batch 551, loss: 0.040, 17632/28000 datapoints
2025-03-06 22:08:05,037 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-06 22:08:05,207 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:08:05,368 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:08:05,532 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:08:05,690 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:05,856 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:08:05,946 - INFO - validation batch 1, loss: 0.632, 32/6976 datapoints
2025-03-06 22:08:05,998 - INFO - validation batch 51, loss: 6.421, 1632/6976 datapoints
2025-03-06 22:08:06,059 - INFO - validation batch 101, loss: 1.353, 3232/6976 datapoints
2025-03-06 22:08:06,122 - INFO - validation batch 151, loss: 1.762, 4832/6976 datapoints
2025-03-06 22:08:06,185 - INFO - validation batch 201, loss: 0.950, 6432/6976 datapoints
2025-03-06 22:08:06,204 - INFO - Epoch 495/800 done.
2025-03-06 22:08:06,204 - INFO - Final validation performance:
Loss: 2.224, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:08:06,205 - INFO - Beginning epoch 496/800
2025-03-06 22:08:06,210 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 22:08:06,400 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:08:06,588 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:08:06,787 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:08:06,968 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 22:08:07,152 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:08:07,338 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:08:07,524 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-06 22:08:07,710 - INFO - training batch 401, loss: 0.010, 12832/28000 datapoints
2025-03-06 22:08:07,901 - INFO - training batch 451, loss: 0.013, 14432/28000 datapoints
2025-03-06 22:08:08,088 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 22:08:08,291 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-06 22:08:08,486 - INFO - training batch 601, loss: 0.009, 19232/28000 datapoints
2025-03-06 22:08:08,669 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:08,844 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:08:09,020 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:08:09,189 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:09,372 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:08:09,475 - INFO - validation batch 1, loss: 0.679, 32/6976 datapoints
2025-03-06 22:08:09,544 - INFO - validation batch 51, loss: 6.345, 1632/6976 datapoints
2025-03-06 22:08:09,613 - INFO - validation batch 101, loss: 1.292, 3232/6976 datapoints
2025-03-06 22:08:09,691 - INFO - validation batch 151, loss: 1.916, 4832/6976 datapoints
2025-03-06 22:08:09,770 - INFO - validation batch 201, loss: 0.972, 6432/6976 datapoints
2025-03-06 22:08:09,792 - INFO - Epoch 496/800 done.
2025-03-06 22:08:09,793 - INFO - Final validation performance:
Loss: 2.241, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:08:09,793 - INFO - Beginning epoch 497/800
2025-03-06 22:08:09,799 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-06 22:08:09,990 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:08:10,202 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:08:10,413 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:08:10,604 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:08:10,805 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:08:11,019 - INFO - training batch 301, loss: 0.040, 9632/28000 datapoints
2025-03-06 22:08:11,188 - INFO - training batch 351, loss: 0.013, 11232/28000 datapoints
2025-03-06 22:08:11,356 - INFO - training batch 401, loss: 0.015, 12832/28000 datapoints
2025-03-06 22:08:11,522 - INFO - training batch 451, loss: 0.013, 14432/28000 datapoints
2025-03-06 22:08:11,688 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:08:11,851 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 22:08:12,017 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 22:08:12,190 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:12,353 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:08:12,510 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:08:12,667 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:12,830 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:08:12,915 - INFO - validation batch 1, loss: 0.632, 32/6976 datapoints
2025-03-06 22:08:12,961 - INFO - validation batch 51, loss: 6.241, 1632/6976 datapoints
2025-03-06 22:08:13,012 - INFO - validation batch 101, loss: 1.281, 3232/6976 datapoints
2025-03-06 22:08:13,073 - INFO - validation batch 151, loss: 1.843, 4832/6976 datapoints
2025-03-06 22:08:13,125 - INFO - validation batch 201, loss: 0.920, 6432/6976 datapoints
2025-03-06 22:08:13,140 - INFO - Epoch 497/800 done.
2025-03-06 22:08:13,141 - INFO - Final validation performance:
Loss: 2.183, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:08:13,141 - INFO - Beginning epoch 498/800
2025-03-06 22:08:13,146 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:08:13,308 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:08:13,467 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:08:13,631 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:08:13,791 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-06 22:08:13,950 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:08:14,111 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-06 22:08:14,273 - INFO - training batch 351, loss: 0.016, 11232/28000 datapoints
2025-03-06 22:08:14,428 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 22:08:14,585 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-06 22:08:14,748 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 22:08:14,914 - INFO - training batch 551, loss: 0.028, 17632/28000 datapoints
2025-03-06 22:08:15,082 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-06 22:08:15,253 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:15,424 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:08:15,588 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-06 22:08:15,748 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:15,925 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:08:16,010 - INFO - validation batch 1, loss: 0.617, 32/6976 datapoints
2025-03-06 22:08:16,059 - INFO - validation batch 51, loss: 6.434, 1632/6976 datapoints
2025-03-06 22:08:16,104 - INFO - validation batch 101, loss: 1.262, 3232/6976 datapoints
2025-03-06 22:08:16,151 - INFO - validation batch 151, loss: 1.914, 4832/6976 datapoints
2025-03-06 22:08:16,197 - INFO - validation batch 201, loss: 1.008, 6432/6976 datapoints
2025-03-06 22:08:16,215 - INFO - Epoch 498/800 done.
2025-03-06 22:08:16,215 - INFO - Final validation performance:
Loss: 2.247, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:08:16,216 - INFO - Beginning epoch 499/800
2025-03-06 22:08:16,220 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:08:16,388 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:08:16,549 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:08:16,713 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:08:16,904 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:08:17,064 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-06 22:08:17,228 - INFO - training batch 301, loss: 0.016, 9632/28000 datapoints
2025-03-06 22:08:17,389 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-06 22:08:17,547 - INFO - training batch 401, loss: 0.012, 12832/28000 datapoints
2025-03-06 22:08:17,708 - INFO - training batch 451, loss: 0.016, 14432/28000 datapoints
2025-03-06 22:08:17,870 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 22:08:18,031 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-06 22:08:18,192 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:08:18,356 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:18,519 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:08:18,680 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:08:18,839 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:19,003 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:08:19,087 - INFO - validation batch 1, loss: 0.576, 32/6976 datapoints
2025-03-06 22:08:19,133 - INFO - validation batch 51, loss: 6.363, 1632/6976 datapoints
2025-03-06 22:08:19,180 - INFO - validation batch 101, loss: 1.233, 3232/6976 datapoints
2025-03-06 22:08:19,236 - INFO - validation batch 151, loss: 1.919, 4832/6976 datapoints
2025-03-06 22:08:19,284 - INFO - validation batch 201, loss: 1.004, 6432/6976 datapoints
2025-03-06 22:08:19,300 - INFO - Epoch 499/800 done.
2025-03-06 22:08:19,300 - INFO - Final validation performance:
Loss: 2.219, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:08:19,301 - INFO - Beginning epoch 500/800
2025-03-06 22:08:19,305 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:08:19,467 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:08:19,632 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:08:19,798 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:08:19,966 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:08:20,123 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-06 22:08:20,311 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:08:20,496 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-06 22:08:20,657 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-06 22:08:20,817 - INFO - training batch 451, loss: 0.015, 14432/28000 datapoints
2025-03-06 22:08:20,976 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 22:08:21,141 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-06 22:08:21,308 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:08:21,473 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:21,638 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:08:21,798 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:08:21,958 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:22,125 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:08:22,208 - INFO - validation batch 1, loss: 0.603, 32/6976 datapoints
2025-03-06 22:08:22,254 - INFO - validation batch 51, loss: 6.345, 1632/6976 datapoints
2025-03-06 22:08:22,301 - INFO - validation batch 101, loss: 1.246, 3232/6976 datapoints
2025-03-06 22:08:22,348 - INFO - validation batch 151, loss: 1.955, 4832/6976 datapoints
2025-03-06 22:08:22,394 - INFO - validation batch 201, loss: 0.985, 6432/6976 datapoints
2025-03-06 22:08:22,411 - INFO - Epoch 500/800 done.
2025-03-06 22:08:22,411 - INFO - Final validation performance:
Loss: 2.227, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:08:22,411 - INFO - Beginning epoch 501/800
2025-03-06 22:08:22,415 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:08:22,578 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:08:22,848 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:08:23,073 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-06 22:08:23,249 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:08:23,411 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-06 22:08:23,577 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:08:23,749 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-06 22:08:23,916 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:08:24,079 - INFO - training batch 451, loss: 0.014, 14432/28000 datapoints
2025-03-06 22:08:24,257 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:08:24,424 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-06 22:08:24,589 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:08:24,758 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:24,928 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:08:25,104 - INFO - training batch 751, loss: 0.009, 24032/28000 datapoints
2025-03-06 22:08:25,267 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:25,437 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:08:25,521 - INFO - validation batch 1, loss: 0.589, 32/6976 datapoints
2025-03-06 22:08:25,570 - INFO - validation batch 51, loss: 6.355, 1632/6976 datapoints
2025-03-06 22:08:25,627 - INFO - validation batch 101, loss: 1.274, 3232/6976 datapoints
2025-03-06 22:08:25,680 - INFO - validation batch 151, loss: 1.993, 4832/6976 datapoints
2025-03-06 22:08:25,728 - INFO - validation batch 201, loss: 0.978, 6432/6976 datapoints
2025-03-06 22:08:25,745 - INFO - Epoch 501/800 done.
2025-03-06 22:08:25,745 - INFO - Final validation performance:
Loss: 2.238, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:08:25,746 - INFO - Beginning epoch 502/800
2025-03-06 22:08:25,751 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:08:25,924 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:08:26,085 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:08:26,247 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-06 22:08:26,412 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:08:26,569 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:08:26,734 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:08:26,917 - INFO - training batch 351, loss: 0.010, 11232/28000 datapoints
2025-03-06 22:08:27,087 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:08:27,247 - INFO - training batch 451, loss: 0.013, 14432/28000 datapoints
2025-03-06 22:08:27,408 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:08:27,573 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-06 22:08:27,736 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:08:27,901 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:28,071 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:08:28,230 - INFO - training batch 751, loss: 0.009, 24032/28000 datapoints
2025-03-06 22:08:28,393 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:28,556 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:08:28,640 - INFO - validation batch 1, loss: 0.570, 32/6976 datapoints
2025-03-06 22:08:28,686 - INFO - validation batch 51, loss: 6.335, 1632/6976 datapoints
2025-03-06 22:08:28,733 - INFO - validation batch 101, loss: 1.336, 3232/6976 datapoints
2025-03-06 22:08:28,781 - INFO - validation batch 151, loss: 2.100, 4832/6976 datapoints
2025-03-06 22:08:28,829 - INFO - validation batch 201, loss: 0.999, 6432/6976 datapoints
2025-03-06 22:08:28,848 - INFO - Epoch 502/800 done.
2025-03-06 22:08:28,848 - INFO - Final validation performance:
Loss: 2.268, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:08:28,849 - INFO - Beginning epoch 503/800
2025-03-06 22:08:28,855 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:08:29,028 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:08:29,196 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:08:29,366 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-06 22:08:29,531 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:08:29,693 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-06 22:08:29,863 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:08:30,031 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:08:30,194 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-06 22:08:30,359 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-06 22:08:30,523 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:08:30,689 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:08:30,876 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:08:31,039 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:31,210 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:08:31,375 - INFO - training batch 751, loss: 0.009, 24032/28000 datapoints
2025-03-06 22:08:31,538 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:31,708 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:08:31,799 - INFO - validation batch 1, loss: 0.543, 32/6976 datapoints
2025-03-06 22:08:31,849 - INFO - validation batch 51, loss: 6.329, 1632/6976 datapoints
2025-03-06 22:08:31,905 - INFO - validation batch 101, loss: 1.395, 3232/6976 datapoints
2025-03-06 22:08:31,956 - INFO - validation batch 151, loss: 2.137, 4832/6976 datapoints
2025-03-06 22:08:32,003 - INFO - validation batch 201, loss: 1.006, 6432/6976 datapoints
2025-03-06 22:08:32,019 - INFO - Epoch 503/800 done.
2025-03-06 22:08:32,019 - INFO - Final validation performance:
Loss: 2.282, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:08:32,020 - INFO - Beginning epoch 504/800
2025-03-06 22:08:32,024 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-06 22:08:32,189 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:08:32,350 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:08:32,515 - INFO - training batch 151, loss: 0.008, 4832/28000 datapoints
2025-03-06 22:08:32,681 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:08:32,842 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:08:33,008 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-06 22:08:33,177 - INFO - training batch 351, loss: 0.010, 11232/28000 datapoints
2025-03-06 22:08:33,341 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-06 22:08:33,508 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-06 22:08:33,671 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:08:33,839 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:08:34,011 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:08:34,178 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:08:34,347 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:08:34,513 - INFO - training batch 751, loss: 0.009, 24032/28000 datapoints
2025-03-06 22:08:34,679 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:34,848 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:08:34,942 - INFO - validation batch 1, loss: 0.576, 32/6976 datapoints
2025-03-06 22:08:34,990 - INFO - validation batch 51, loss: 6.419, 1632/6976 datapoints
2025-03-06 22:08:35,040 - INFO - validation batch 101, loss: 1.459, 3232/6976 datapoints
2025-03-06 22:08:35,087 - INFO - validation batch 151, loss: 2.184, 4832/6976 datapoints
2025-03-06 22:08:35,138 - INFO - validation batch 201, loss: 1.013, 6432/6976 datapoints
2025-03-06 22:08:35,156 - INFO - Epoch 504/800 done.
2025-03-06 22:08:35,156 - INFO - Final validation performance:
Loss: 2.330, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:08:35,157 - INFO - Beginning epoch 505/800
2025-03-06 22:08:35,162 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-06 22:08:35,327 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-06 22:08:35,493 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 22:08:35,658 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 22:08:35,822 - INFO - training batch 201, loss: 0.405, 6432/28000 datapoints
2025-03-06 22:08:35,987 - INFO - training batch 251, loss: 0.015, 8032/28000 datapoints
2025-03-06 22:08:36,151 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:08:36,314 - INFO - training batch 351, loss: 0.017, 11232/28000 datapoints
2025-03-06 22:08:36,478 - INFO - training batch 401, loss: 0.029, 12832/28000 datapoints
2025-03-06 22:08:36,645 - INFO - training batch 451, loss: 0.011, 14432/28000 datapoints
2025-03-06 22:08:36,807 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 22:08:36,981 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-06 22:08:37,167 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-06 22:08:37,329 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:37,492 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:08:37,652 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:08:37,811 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:37,990 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:08:38,072 - INFO - validation batch 1, loss: 0.830, 32/6976 datapoints
2025-03-06 22:08:38,117 - INFO - validation batch 51, loss: 6.263, 1632/6976 datapoints
2025-03-06 22:08:38,164 - INFO - validation batch 101, loss: 1.349, 3232/6976 datapoints
2025-03-06 22:08:38,212 - INFO - validation batch 151, loss: 1.737, 4832/6976 datapoints
2025-03-06 22:08:38,258 - INFO - validation batch 201, loss: 1.083, 6432/6976 datapoints
2025-03-06 22:08:38,274 - INFO - Epoch 505/800 done.
2025-03-06 22:08:38,275 - INFO - Final validation performance:
Loss: 2.252, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:08:38,275 - INFO - Beginning epoch 506/800
2025-03-06 22:08:38,279 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:08:38,443 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:08:38,609 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:08:38,770 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:08:38,935 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:08:39,097 - INFO - training batch 251, loss: 0.012, 8032/28000 datapoints
2025-03-06 22:08:39,269 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:08:39,435 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-06 22:08:39,596 - INFO - training batch 401, loss: 0.032, 12832/28000 datapoints
2025-03-06 22:08:39,756 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-06 22:08:39,921 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:08:40,083 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:08:40,246 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:08:40,407 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:40,573 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:08:40,736 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:08:40,897 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:08:41,062 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:08:41,144 - INFO - validation batch 1, loss: 0.725, 32/6976 datapoints
2025-03-06 22:08:41,192 - INFO - validation batch 51, loss: 6.352, 1632/6976 datapoints
2025-03-06 22:08:41,238 - INFO - validation batch 101, loss: 1.306, 3232/6976 datapoints
2025-03-06 22:08:41,286 - INFO - validation batch 151, loss: 1.923, 4832/6976 datapoints
2025-03-06 22:08:41,332 - INFO - validation batch 201, loss: 1.079, 6432/6976 datapoints
2025-03-06 22:08:41,348 - INFO - Epoch 506/800 done.
2025-03-06 22:08:41,349 - INFO - Final validation performance:
Loss: 2.277, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:08:41,349 - INFO - Beginning epoch 507/800
2025-03-06 22:08:41,353 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:08:41,520 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:08:41,683 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:08:41,846 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:08:42,011 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:08:42,176 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:08:42,340 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:08:42,503 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-06 22:08:42,667 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 22:08:42,831 - INFO - training batch 451, loss: 0.015, 14432/28000 datapoints
2025-03-06 22:08:42,996 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:08:43,169 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:08:43,334 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:08:43,497 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:43,661 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:08:43,821 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:08:43,983 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:44,149 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:08:44,231 - INFO - validation batch 1, loss: 0.660, 32/6976 datapoints
2025-03-06 22:08:44,279 - INFO - validation batch 51, loss: 6.257, 1632/6976 datapoints
2025-03-06 22:08:44,326 - INFO - validation batch 101, loss: 1.285, 3232/6976 datapoints
2025-03-06 22:08:44,374 - INFO - validation batch 151, loss: 1.915, 4832/6976 datapoints
2025-03-06 22:08:44,423 - INFO - validation batch 201, loss: 1.039, 6432/6976 datapoints
2025-03-06 22:08:44,440 - INFO - Epoch 507/800 done.
2025-03-06 22:08:44,440 - INFO - Final validation performance:
Loss: 2.231, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:08:44,440 - INFO - Beginning epoch 508/800
2025-03-06 22:08:44,445 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:08:44,609 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:08:44,769 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:08:44,933 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:08:45,104 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:08:45,266 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-06 22:08:45,429 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:08:45,591 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-06 22:08:45,758 - INFO - training batch 401, loss: 0.010, 12832/28000 datapoints
2025-03-06 22:08:45,925 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-06 22:08:46,086 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:08:46,246 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:08:46,409 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:08:46,572 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:46,735 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:08:46,901 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:08:47,066 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:47,254 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:08:47,335 - INFO - validation batch 1, loss: 0.620, 32/6976 datapoints
2025-03-06 22:08:47,382 - INFO - validation batch 51, loss: 6.323, 1632/6976 datapoints
2025-03-06 22:08:47,430 - INFO - validation batch 101, loss: 1.276, 3232/6976 datapoints
2025-03-06 22:08:47,477 - INFO - validation batch 151, loss: 1.934, 4832/6976 datapoints
2025-03-06 22:08:47,525 - INFO - validation batch 201, loss: 1.025, 6432/6976 datapoints
2025-03-06 22:08:47,541 - INFO - Epoch 508/800 done.
2025-03-06 22:08:47,541 - INFO - Final validation performance:
Loss: 2.236, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:08:47,541 - INFO - Beginning epoch 509/800
2025-03-06 22:08:47,546 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:08:47,712 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:08:47,877 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:08:48,043 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:08:48,213 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:08:48,373 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-06 22:08:48,541 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:08:48,709 - INFO - training batch 351, loss: 0.010, 11232/28000 datapoints
2025-03-06 22:08:48,877 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-06 22:08:49,047 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-06 22:08:49,221 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:08:49,391 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:08:49,564 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:08:49,734 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:49,912 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:08:50,081 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-06 22:08:50,247 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:50,416 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:08:50,502 - INFO - validation batch 1, loss: 0.586, 32/6976 datapoints
2025-03-06 22:08:50,553 - INFO - validation batch 51, loss: 6.395, 1632/6976 datapoints
2025-03-06 22:08:50,603 - INFO - validation batch 101, loss: 1.288, 3232/6976 datapoints
2025-03-06 22:08:50,652 - INFO - validation batch 151, loss: 1.966, 4832/6976 datapoints
2025-03-06 22:08:50,700 - INFO - validation batch 201, loss: 1.011, 6432/6976 datapoints
2025-03-06 22:08:50,716 - INFO - Epoch 509/800 done.
2025-03-06 22:08:50,716 - INFO - Final validation performance:
Loss: 2.249, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:08:50,717 - INFO - Beginning epoch 510/800
2025-03-06 22:08:50,721 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:08:50,887 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:08:51,048 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:08:51,216 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:08:51,377 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:08:51,538 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:08:51,704 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:08:51,872 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-06 22:08:52,034 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-06 22:08:52,198 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-06 22:08:52,356 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:08:52,518 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:08:52,681 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:08:52,848 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:53,020 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:08:53,181 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-06 22:08:53,344 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:53,511 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:08:53,593 - INFO - validation batch 1, loss: 0.555, 32/6976 datapoints
2025-03-06 22:08:53,639 - INFO - validation batch 51, loss: 6.468, 1632/6976 datapoints
2025-03-06 22:08:53,687 - INFO - validation batch 101, loss: 1.355, 3232/6976 datapoints
2025-03-06 22:08:53,734 - INFO - validation batch 151, loss: 2.081, 4832/6976 datapoints
2025-03-06 22:08:53,781 - INFO - validation batch 201, loss: 1.026, 6432/6976 datapoints
2025-03-06 22:08:53,797 - INFO - Epoch 510/800 done.
2025-03-06 22:08:53,798 - INFO - Final validation performance:
Loss: 2.297, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:08:53,798 - INFO - Beginning epoch 511/800
2025-03-06 22:08:53,802 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:08:53,967 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:08:54,134 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:08:54,306 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:08:54,470 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:08:54,631 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:08:54,796 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:08:54,959 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:08:55,132 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:08:55,300 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-06 22:08:55,462 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:08:55,623 - INFO - training batch 551, loss: 0.329, 17632/28000 datapoints
2025-03-06 22:08:55,786 - INFO - training batch 601, loss: 0.094, 19232/28000 datapoints
2025-03-06 22:08:55,956 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:56,120 - INFO - training batch 701, loss: 0.013, 22432/28000 datapoints
2025-03-06 22:08:56,281 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:08:56,444 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:08:56,607 - INFO - training batch 851, loss: 0.016, 27232/28000 datapoints
2025-03-06 22:08:56,688 - INFO - validation batch 1, loss: 0.458, 32/6976 datapoints
2025-03-06 22:08:56,734 - INFO - validation batch 51, loss: 6.803, 1632/6976 datapoints
2025-03-06 22:08:56,780 - INFO - validation batch 101, loss: 1.469, 3232/6976 datapoints
2025-03-06 22:08:56,826 - INFO - validation batch 151, loss: 1.921, 4832/6976 datapoints
2025-03-06 22:08:56,876 - INFO - validation batch 201, loss: 1.022, 6432/6976 datapoints
2025-03-06 22:08:56,891 - INFO - Epoch 511/800 done.
2025-03-06 22:08:56,891 - INFO - Final validation performance:
Loss: 2.335, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:08:56,892 - INFO - Beginning epoch 512/800
2025-03-06 22:08:56,896 - INFO - training batch 1, loss: 0.052, 32/28000 datapoints
2025-03-06 22:08:57,061 - INFO - training batch 51, loss: 0.032, 1632/28000 datapoints
2025-03-06 22:08:57,252 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 22:08:57,413 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:08:57,572 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:08:57,732 - INFO - training batch 251, loss: 0.025, 8032/28000 datapoints
2025-03-06 22:08:57,903 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:08:58,097 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-06 22:08:58,306 - INFO - training batch 401, loss: 0.015, 12832/28000 datapoints
2025-03-06 22:08:58,469 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:08:58,632 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:08:58,802 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:08:58,974 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:08:59,140 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:08:59,314 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:08:59,478 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:08:59,641 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:08:59,810 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:08:59,897 - INFO - validation batch 1, loss: 0.615, 32/6976 datapoints
2025-03-06 22:08:59,944 - INFO - validation batch 51, loss: 6.374, 1632/6976 datapoints
2025-03-06 22:08:59,993 - INFO - validation batch 101, loss: 1.275, 3232/6976 datapoints
2025-03-06 22:09:00,041 - INFO - validation batch 151, loss: 2.149, 4832/6976 datapoints
2025-03-06 22:09:00,090 - INFO - validation batch 201, loss: 1.064, 6432/6976 datapoints
2025-03-06 22:09:00,108 - INFO - Epoch 512/800 done.
2025-03-06 22:09:00,108 - INFO - Final validation performance:
Loss: 2.295, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:09:00,108 - INFO - Beginning epoch 513/800
2025-03-06 22:09:00,113 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:09:00,283 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:09:00,448 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:09:00,620 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:09:00,788 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:09:00,949 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-06 22:09:01,110 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:09:01,276 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-06 22:09:01,436 - INFO - training batch 401, loss: 0.012, 12832/28000 datapoints
2025-03-06 22:09:01,600 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-06 22:09:01,759 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:09:01,924 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-06 22:09:02,089 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-06 22:09:02,253 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:02,417 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:09:02,576 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:09:02,734 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:09:02,902 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:09:02,983 - INFO - validation batch 1, loss: 0.568, 32/6976 datapoints
2025-03-06 22:09:03,031 - INFO - validation batch 51, loss: 6.318, 1632/6976 datapoints
2025-03-06 22:09:03,078 - INFO - validation batch 101, loss: 1.265, 3232/6976 datapoints
2025-03-06 22:09:03,127 - INFO - validation batch 151, loss: 2.120, 4832/6976 datapoints
2025-03-06 22:09:03,173 - INFO - validation batch 201, loss: 1.094, 6432/6976 datapoints
2025-03-06 22:09:03,189 - INFO - Epoch 513/800 done.
2025-03-06 22:09:03,189 - INFO - Final validation performance:
Loss: 2.273, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:09:03,189 - INFO - Beginning epoch 514/800
2025-03-06 22:09:03,194 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:09:03,361 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:09:03,524 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:09:03,687 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:09:03,850 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:09:04,095 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-06 22:09:04,262 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-06 22:09:04,428 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-06 22:09:04,592 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:09:04,753 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-06 22:09:04,916 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:09:05,082 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:09:05,257 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:09:05,425 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:05,589 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:09:05,751 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:09:05,919 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:09:06,086 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:09:06,168 - INFO - validation batch 1, loss: 0.562, 32/6976 datapoints
2025-03-06 22:09:06,215 - INFO - validation batch 51, loss: 6.351, 1632/6976 datapoints
2025-03-06 22:09:06,262 - INFO - validation batch 101, loss: 1.254, 3232/6976 datapoints
2025-03-06 22:09:06,310 - INFO - validation batch 151, loss: 2.104, 4832/6976 datapoints
2025-03-06 22:09:06,357 - INFO - validation batch 201, loss: 1.071, 6432/6976 datapoints
2025-03-06 22:09:06,372 - INFO - Epoch 514/800 done.
2025-03-06 22:09:06,373 - INFO - Final validation performance:
Loss: 2.268, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:09:06,373 - INFO - Beginning epoch 515/800
2025-03-06 22:09:06,377 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:09:06,540 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:09:06,702 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:09:06,870 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:09:07,032 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:09:07,195 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:09:07,390 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:09:07,553 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:09:07,715 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:09:07,880 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-06 22:09:08,041 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:09:08,206 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:09:08,375 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:09:08,538 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:08,701 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:09:08,863 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:09:09,025 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:09:09,197 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:09:09,293 - INFO - validation batch 1, loss: 0.545, 32/6976 datapoints
2025-03-06 22:09:09,346 - INFO - validation batch 51, loss: 6.422, 1632/6976 datapoints
2025-03-06 22:09:09,396 - INFO - validation batch 101, loss: 1.266, 3232/6976 datapoints
2025-03-06 22:09:09,446 - INFO - validation batch 151, loss: 2.083, 4832/6976 datapoints
2025-03-06 22:09:09,499 - INFO - validation batch 201, loss: 1.050, 6432/6976 datapoints
2025-03-06 22:09:09,518 - INFO - Epoch 515/800 done.
2025-03-06 22:09:09,518 - INFO - Final validation performance:
Loss: 2.273, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:09:09,519 - INFO - Beginning epoch 516/800
2025-03-06 22:09:09,523 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:09:09,694 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:09:09,936 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:09:10,106 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:09:10,275 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:09:10,443 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 22:09:10,614 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:09:10,784 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:09:10,957 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:09:11,127 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-06 22:09:11,301 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:09:11,477 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:09:11,648 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:09:11,815 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:11,991 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:09:12,155 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:09:12,318 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:09:12,489 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:09:12,573 - INFO - validation batch 1, loss: 0.482, 32/6976 datapoints
2025-03-06 22:09:12,625 - INFO - validation batch 51, loss: 6.484, 1632/6976 datapoints
2025-03-06 22:09:12,676 - INFO - validation batch 101, loss: 1.339, 3232/6976 datapoints
2025-03-06 22:09:12,729 - INFO - validation batch 151, loss: 2.192, 4832/6976 datapoints
2025-03-06 22:09:12,782 - INFO - validation batch 201, loss: 1.051, 6432/6976 datapoints
2025-03-06 22:09:12,800 - INFO - Epoch 516/800 done.
2025-03-06 22:09:12,800 - INFO - Final validation performance:
Loss: 2.310, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:09:12,801 - INFO - Beginning epoch 517/800
2025-03-06 22:09:12,806 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:09:12,983 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:09:13,165 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:09:13,334 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:09:13,500 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:09:13,665 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 22:09:13,832 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:09:14,004 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:09:14,170 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:09:14,337 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-06 22:09:14,503 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:09:14,671 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:09:14,838 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:09:15,009 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:09:15,185 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:09:15,353 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:09:15,519 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:09:15,687 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:09:15,773 - INFO - validation batch 1, loss: 0.481, 32/6976 datapoints
2025-03-06 22:09:15,824 - INFO - validation batch 51, loss: 6.631, 1632/6976 datapoints
2025-03-06 22:09:15,878 - INFO - validation batch 101, loss: 1.371, 3232/6976 datapoints
2025-03-06 22:09:15,929 - INFO - validation batch 151, loss: 2.225, 4832/6976 datapoints
2025-03-06 22:09:15,984 - INFO - validation batch 201, loss: 1.053, 6432/6976 datapoints
2025-03-06 22:09:16,005 - INFO - Epoch 517/800 done.
2025-03-06 22:09:16,006 - INFO - Final validation performance:
Loss: 2.352, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:09:16,006 - INFO - Beginning epoch 518/800
2025-03-06 22:09:16,011 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-06 22:09:16,176 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:09:16,337 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:09:16,503 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:09:16,669 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:09:16,827 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 22:09:16,994 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-06 22:09:17,159 - INFO - training batch 351, loss: 0.010, 11232/28000 datapoints
2025-03-06 22:09:17,324 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:09:17,514 - INFO - training batch 451, loss: 0.013, 14432/28000 datapoints
2025-03-06 22:09:17,674 - INFO - training batch 501, loss: 0.039, 16032/28000 datapoints
2025-03-06 22:09:17,837 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:09:18,002 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 22:09:18,167 - INFO - training batch 651, loss: 0.041, 20832/28000 datapoints
2025-03-06 22:09:18,330 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:09:18,490 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:09:18,654 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:09:18,817 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:09:18,901 - INFO - validation batch 1, loss: 0.711, 32/6976 datapoints
2025-03-06 22:09:18,948 - INFO - validation batch 51, loss: 6.661, 1632/6976 datapoints
2025-03-06 22:09:18,994 - INFO - validation batch 101, loss: 1.314, 3232/6976 datapoints
2025-03-06 22:09:19,041 - INFO - validation batch 151, loss: 2.058, 4832/6976 datapoints
2025-03-06 22:09:19,092 - INFO - validation batch 201, loss: 1.195, 6432/6976 datapoints
2025-03-06 22:09:19,108 - INFO - Epoch 518/800 done.
2025-03-06 22:09:19,108 - INFO - Final validation performance:
Loss: 2.388, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:09:19,108 - INFO - Beginning epoch 519/800
2025-03-06 22:09:19,113 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-06 22:09:19,277 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 22:09:19,441 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:09:19,604 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:09:19,784 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 22:09:19,953 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-06 22:09:20,124 - INFO - training batch 301, loss: 0.053, 9632/28000 datapoints
2025-03-06 22:09:20,297 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-06 22:09:20,467 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:09:20,636 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-06 22:09:20,843 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 22:09:21,014 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:09:21,183 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-06 22:09:21,352 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:09:21,519 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:09:21,688 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-06 22:09:21,854 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:09:22,025 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:09:22,107 - INFO - validation batch 1, loss: 0.709, 32/6976 datapoints
2025-03-06 22:09:22,154 - INFO - validation batch 51, loss: 6.683, 1632/6976 datapoints
2025-03-06 22:09:22,201 - INFO - validation batch 101, loss: 1.298, 3232/6976 datapoints
2025-03-06 22:09:22,249 - INFO - validation batch 151, loss: 2.069, 4832/6976 datapoints
2025-03-06 22:09:22,295 - INFO - validation batch 201, loss: 1.071, 6432/6976 datapoints
2025-03-06 22:09:22,311 - INFO - Epoch 519/800 done.
2025-03-06 22:09:22,311 - INFO - Final validation performance:
Loss: 2.366, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:09:22,311 - INFO - Beginning epoch 520/800
2025-03-06 22:09:22,316 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:09:22,483 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:09:22,649 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:09:22,811 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:09:22,978 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:09:23,143 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:09:23,306 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:09:23,473 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:09:23,640 - INFO - training batch 401, loss: 0.010, 12832/28000 datapoints
2025-03-06 22:09:23,801 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-06 22:09:23,965 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 22:09:24,132 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:09:24,299 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:09:24,470 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:24,636 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:09:24,798 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:09:24,962 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:09:25,134 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:09:25,217 - INFO - validation batch 1, loss: 0.548, 32/6976 datapoints
2025-03-06 22:09:25,264 - INFO - validation batch 51, loss: 7.017, 1632/6976 datapoints
2025-03-06 22:09:25,312 - INFO - validation batch 101, loss: 1.361, 3232/6976 datapoints
2025-03-06 22:09:25,361 - INFO - validation batch 151, loss: 2.100, 4832/6976 datapoints
2025-03-06 22:09:25,408 - INFO - validation batch 201, loss: 1.018, 6432/6976 datapoints
2025-03-06 22:09:25,424 - INFO - Epoch 520/800 done.
2025-03-06 22:09:25,424 - INFO - Final validation performance:
Loss: 2.409, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:09:25,425 - INFO - Beginning epoch 521/800
2025-03-06 22:09:25,429 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:09:25,594 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:09:25,764 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:09:25,933 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-06 22:09:26,101 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-06 22:09:26,262 - INFO - training batch 251, loss: 0.025, 8032/28000 datapoints
2025-03-06 22:09:26,426 - INFO - training batch 301, loss: 0.055, 9632/28000 datapoints
2025-03-06 22:09:26,588 - INFO - training batch 351, loss: 0.019, 11232/28000 datapoints
2025-03-06 22:09:26,754 - INFO - training batch 401, loss: 0.012, 12832/28000 datapoints
2025-03-06 22:09:26,917 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-06 22:09:27,077 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:09:27,242 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:09:27,412 - INFO - training batch 601, loss: 0.006, 19232/28000 datapoints
2025-03-06 22:09:27,604 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:27,770 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:09:27,933 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:09:28,095 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:09:28,262 - INFO - training batch 851, loss: 0.012, 27232/28000 datapoints
2025-03-06 22:09:28,342 - INFO - validation batch 1, loss: 0.526, 32/6976 datapoints
2025-03-06 22:09:28,389 - INFO - validation batch 51, loss: 6.642, 1632/6976 datapoints
2025-03-06 22:09:28,436 - INFO - validation batch 101, loss: 1.335, 3232/6976 datapoints
2025-03-06 22:09:28,483 - INFO - validation batch 151, loss: 2.087, 4832/6976 datapoints
2025-03-06 22:09:28,530 - INFO - validation batch 201, loss: 1.090, 6432/6976 datapoints
2025-03-06 22:09:28,546 - INFO - Epoch 521/800 done.
2025-03-06 22:09:28,546 - INFO - Final validation performance:
Loss: 2.336, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:09:28,546 - INFO - Beginning epoch 522/800
2025-03-06 22:09:28,551 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:09:28,718 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:09:28,882 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:09:29,045 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:09:29,208 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:09:29,377 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-06 22:09:29,545 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:09:29,716 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:09:29,885 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:09:30,054 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:09:30,218 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 22:09:30,387 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:09:30,560 - INFO - training batch 601, loss: 0.012, 19232/28000 datapoints
2025-03-06 22:09:30,728 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:30,899 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:09:31,064 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:09:31,233 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:09:31,430 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:09:31,515 - INFO - validation batch 1, loss: 0.647, 32/6976 datapoints
2025-03-06 22:09:31,567 - INFO - validation batch 51, loss: 6.614, 1632/6976 datapoints
2025-03-06 22:09:31,618 - INFO - validation batch 101, loss: 1.290, 3232/6976 datapoints
2025-03-06 22:09:31,670 - INFO - validation batch 151, loss: 2.044, 4832/6976 datapoints
2025-03-06 22:09:31,723 - INFO - validation batch 201, loss: 1.125, 6432/6976 datapoints
2025-03-06 22:09:31,738 - INFO - Epoch 522/800 done.
2025-03-06 22:09:31,739 - INFO - Final validation performance:
Loss: 2.344, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:09:31,739 - INFO - Beginning epoch 523/800
2025-03-06 22:09:31,743 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:09:31,913 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:09:32,079 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:09:32,246 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:09:32,416 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:09:32,581 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-06 22:09:32,749 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:09:32,921 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:09:33,093 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:09:33,262 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-06 22:09:33,436 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:09:33,608 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:09:33,784 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:09:33,958 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:34,128 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:09:34,297 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:09:34,467 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:09:34,637 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:09:34,723 - INFO - validation batch 1, loss: 0.608, 32/6976 datapoints
2025-03-06 22:09:34,775 - INFO - validation batch 51, loss: 6.602, 1632/6976 datapoints
2025-03-06 22:09:34,827 - INFO - validation batch 101, loss: 1.313, 3232/6976 datapoints
2025-03-06 22:09:34,881 - INFO - validation batch 151, loss: 2.066, 4832/6976 datapoints
2025-03-06 22:09:34,934 - INFO - validation batch 201, loss: 1.096, 6432/6976 datapoints
2025-03-06 22:09:34,952 - INFO - Epoch 523/800 done.
2025-03-06 22:09:34,952 - INFO - Final validation performance:
Loss: 2.337, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:09:34,953 - INFO - Beginning epoch 524/800
2025-03-06 22:09:34,958 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:09:35,141 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:09:35,312 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:09:35,484 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:09:35,659 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:09:35,828 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 22:09:36,004 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:09:36,174 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:09:36,346 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:09:36,520 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-06 22:09:36,688 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:09:36,863 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:09:37,034 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:09:37,204 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:37,372 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:09:37,549 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:09:37,738 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:09:37,934 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:09:38,033 - INFO - validation batch 1, loss: 0.575, 32/6976 datapoints
2025-03-06 22:09:38,101 - INFO - validation batch 51, loss: 6.644, 1632/6976 datapoints
2025-03-06 22:09:38,164 - INFO - validation batch 101, loss: 1.382, 3232/6976 datapoints
2025-03-06 22:09:38,228 - INFO - validation batch 151, loss: 2.177, 4832/6976 datapoints
2025-03-06 22:09:38,311 - INFO - validation batch 201, loss: 1.096, 6432/6976 datapoints
2025-03-06 22:09:38,328 - INFO - Epoch 524/800 done.
2025-03-06 22:09:38,328 - INFO - Final validation performance:
Loss: 2.375, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:09:38,329 - INFO - Beginning epoch 525/800
2025-03-06 22:09:38,333 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:09:38,504 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:09:38,672 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:09:38,844 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:09:39,018 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:09:39,188 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:09:39,365 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:09:39,542 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:09:39,713 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:09:39,888 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-06 22:09:40,058 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:09:40,233 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:09:40,407 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:09:40,581 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:40,754 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:09:40,925 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-06 22:09:41,093 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:09:41,261 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:09:41,344 - INFO - validation batch 1, loss: 0.533, 32/6976 datapoints
2025-03-06 22:09:41,395 - INFO - validation batch 51, loss: 6.658, 1632/6976 datapoints
2025-03-06 22:09:41,449 - INFO - validation batch 101, loss: 1.425, 3232/6976 datapoints
2025-03-06 22:09:41,502 - INFO - validation batch 151, loss: 2.319, 4832/6976 datapoints
2025-03-06 22:09:41,554 - INFO - validation batch 201, loss: 1.104, 6432/6976 datapoints
2025-03-06 22:09:41,571 - INFO - Epoch 525/800 done.
2025-03-06 22:09:41,572 - INFO - Final validation performance:
Loss: 2.408, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:09:41,572 - INFO - Beginning epoch 526/800
2025-03-06 22:09:41,577 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:09:41,749 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:09:41,921 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:09:42,089 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:09:42,255 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:09:42,426 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:09:42,596 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:09:42,765 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:09:42,942 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:09:43,109 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:09:43,275 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:09:43,447 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:09:43,619 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:09:43,787 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:43,961 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:09:44,127 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-06 22:09:44,294 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:09:44,464 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:09:44,552 - INFO - validation batch 1, loss: 0.611, 32/6976 datapoints
2025-03-06 22:09:44,604 - INFO - validation batch 51, loss: 6.950, 1632/6976 datapoints
2025-03-06 22:09:44,655 - INFO - validation batch 101, loss: 1.587, 3232/6976 datapoints
2025-03-06 22:09:44,706 - INFO - validation batch 151, loss: 3.213, 4832/6976 datapoints
2025-03-06 22:09:44,753 - INFO - validation batch 201, loss: 1.200, 6432/6976 datapoints
2025-03-06 22:09:44,768 - INFO - Epoch 526/800 done.
2025-03-06 22:09:44,769 - INFO - Final validation performance:
Loss: 2.712, top-1 acc: 0.846top-5 acc: 0.846
2025-03-06 22:09:44,769 - INFO - Beginning epoch 527/800
2025-03-06 22:09:44,774 - INFO - training batch 1, loss: 0.051, 32/28000 datapoints
2025-03-06 22:09:44,942 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 22:09:45,112 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:09:45,276 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-06 22:09:45,448 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 22:09:45,613 - INFO - training batch 251, loss: 0.030, 8032/28000 datapoints
2025-03-06 22:09:45,780 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:09:45,953 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-06 22:09:46,123 - INFO - training batch 401, loss: 0.022, 12832/28000 datapoints
2025-03-06 22:09:46,285 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:09:46,445 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 22:09:46,609 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:09:46,778 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-06 22:09:46,948 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:47,113 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:09:47,277 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:09:47,443 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:09:47,609 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:09:47,705 - INFO - validation batch 1, loss: 0.504, 32/6976 datapoints
2025-03-06 22:09:47,766 - INFO - validation batch 51, loss: 6.777, 1632/6976 datapoints
2025-03-06 22:09:47,812 - INFO - validation batch 101, loss: 1.272, 3232/6976 datapoints
2025-03-06 22:09:47,860 - INFO - validation batch 151, loss: 2.076, 4832/6976 datapoints
2025-03-06 22:09:47,912 - INFO - validation batch 201, loss: 1.074, 6432/6976 datapoints
2025-03-06 22:09:47,928 - INFO - Epoch 527/800 done.
2025-03-06 22:09:47,928 - INFO - Final validation performance:
Loss: 2.341, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:09:47,929 - INFO - Beginning epoch 528/800
2025-03-06 22:09:47,933 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:09:48,103 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:09:48,268 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:09:48,431 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-06 22:09:48,596 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:09:48,758 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:09:48,927 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:09:49,095 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-06 22:09:49,260 - INFO - training batch 401, loss: 0.016, 12832/28000 datapoints
2025-03-06 22:09:49,425 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:09:49,605 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:09:49,781 - INFO - training batch 551, loss: 0.060, 17632/28000 datapoints
2025-03-06 22:09:49,962 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:09:50,134 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:50,306 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:09:50,481 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:09:50,656 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:09:50,827 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:09:50,915 - INFO - validation batch 1, loss: 0.724, 32/6976 datapoints
2025-03-06 22:09:50,968 - INFO - validation batch 51, loss: 6.840, 1632/6976 datapoints
2025-03-06 22:09:51,019 - INFO - validation batch 101, loss: 1.260, 3232/6976 datapoints
2025-03-06 22:09:51,073 - INFO - validation batch 151, loss: 2.056, 4832/6976 datapoints
2025-03-06 22:09:51,124 - INFO - validation batch 201, loss: 1.125, 6432/6976 datapoints
2025-03-06 22:09:51,140 - INFO - Epoch 528/800 done.
2025-03-06 22:09:51,140 - INFO - Final validation performance:
Loss: 2.401, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:09:51,141 - INFO - Beginning epoch 529/800
2025-03-06 22:09:51,146 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:09:51,320 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:09:51,494 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:09:51,668 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:09:51,837 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:09:52,006 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:09:52,175 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:09:52,344 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:09:52,515 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-06 22:09:52,681 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:09:52,851 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:09:53,026 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:09:53,205 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:09:53,376 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:53,551 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:09:53,719 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:09:53,891 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:09:54,061 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:09:54,143 - INFO - validation batch 1, loss: 0.701, 32/6976 datapoints
2025-03-06 22:09:54,195 - INFO - validation batch 51, loss: 6.753, 1632/6976 datapoints
2025-03-06 22:09:54,245 - INFO - validation batch 101, loss: 1.246, 3232/6976 datapoints
2025-03-06 22:09:54,297 - INFO - validation batch 151, loss: 1.964, 4832/6976 datapoints
2025-03-06 22:09:54,350 - INFO - validation batch 201, loss: 1.121, 6432/6976 datapoints
2025-03-06 22:09:54,370 - INFO - Epoch 529/800 done.
2025-03-06 22:09:54,370 - INFO - Final validation performance:
Loss: 2.357, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:09:54,371 - INFO - Beginning epoch 530/800
2025-03-06 22:09:54,375 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:09:54,544 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:09:54,709 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:09:54,876 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:09:55,051 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:09:55,222 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:09:55,394 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:09:55,566 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:09:55,733 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-06 22:09:55,901 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:09:56,071 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:09:56,241 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:09:56,411 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:09:56,579 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:56,747 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:09:56,918 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:09:57,086 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:09:57,253 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:09:57,336 - INFO - validation batch 1, loss: 0.612, 32/6976 datapoints
2025-03-06 22:09:57,385 - INFO - validation batch 51, loss: 6.784, 1632/6976 datapoints
2025-03-06 22:09:57,439 - INFO - validation batch 101, loss: 1.225, 3232/6976 datapoints
2025-03-06 22:09:57,492 - INFO - validation batch 151, loss: 1.940, 4832/6976 datapoints
2025-03-06 22:09:57,544 - INFO - validation batch 201, loss: 1.122, 6432/6976 datapoints
2025-03-06 22:09:57,566 - INFO - Epoch 530/800 done.
2025-03-06 22:09:57,566 - INFO - Final validation performance:
Loss: 2.337, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:09:57,566 - INFO - Beginning epoch 531/800
2025-03-06 22:09:57,571 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:09:57,740 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:09:57,931 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:09:58,102 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:09:58,269 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:09:58,436 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:09:58,605 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:09:58,778 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:09:58,954 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:09:59,124 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:09:59,294 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:09:59,465 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:09:59,646 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:09:59,817 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:09:59,991 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:10:00,164 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:10:00,337 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:00,511 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:10:00,609 - INFO - validation batch 1, loss: 0.593, 32/6976 datapoints
2025-03-06 22:10:00,659 - INFO - validation batch 51, loss: 6.747, 1632/6976 datapoints
2025-03-06 22:10:00,707 - INFO - validation batch 101, loss: 1.243, 3232/6976 datapoints
2025-03-06 22:10:00,758 - INFO - validation batch 151, loss: 1.980, 4832/6976 datapoints
2025-03-06 22:10:00,804 - INFO - validation batch 201, loss: 1.108, 6432/6976 datapoints
2025-03-06 22:10:00,820 - INFO - Epoch 531/800 done.
2025-03-06 22:10:00,821 - INFO - Final validation performance:
Loss: 2.334, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:10:00,821 - INFO - Beginning epoch 532/800
2025-03-06 22:10:00,825 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:10:00,988 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:10:01,152 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:10:01,316 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:10:01,478 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:10:01,646 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:10:01,807 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:10:01,977 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:10:02,143 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:10:02,306 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:10:02,468 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:10:02,634 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:10:02,801 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:10:02,971 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:10:03,138 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:10:03,301 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:10:03,462 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:03,630 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:10:03,709 - INFO - validation batch 1, loss: 0.573, 32/6976 datapoints
2025-03-06 22:10:03,757 - INFO - validation batch 51, loss: 6.759, 1632/6976 datapoints
2025-03-06 22:10:03,803 - INFO - validation batch 101, loss: 1.274, 3232/6976 datapoints
2025-03-06 22:10:03,850 - INFO - validation batch 151, loss: 2.055, 4832/6976 datapoints
2025-03-06 22:10:03,899 - INFO - validation batch 201, loss: 1.100, 6432/6976 datapoints
2025-03-06 22:10:03,915 - INFO - Epoch 532/800 done.
2025-03-06 22:10:03,915 - INFO - Final validation performance:
Loss: 2.352, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:10:03,916 - INFO - Beginning epoch 533/800
2025-03-06 22:10:03,920 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:10:04,083 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:10:04,255 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:10:04,420 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:10:04,584 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:10:04,747 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:10:04,914 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:10:05,083 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:10:05,254 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:10:05,417 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:10:05,585 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:10:05,754 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:10:05,935 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:10:06,102 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:10:06,267 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:10:06,429 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:10:06,593 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:06,760 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:10:06,842 - INFO - validation batch 1, loss: 0.532, 32/6976 datapoints
2025-03-06 22:10:06,890 - INFO - validation batch 51, loss: 6.760, 1632/6976 datapoints
2025-03-06 22:10:06,936 - INFO - validation batch 101, loss: 1.338, 3232/6976 datapoints
2025-03-06 22:10:06,982 - INFO - validation batch 151, loss: 2.203, 4832/6976 datapoints
2025-03-06 22:10:07,029 - INFO - validation batch 201, loss: 1.109, 6432/6976 datapoints
2025-03-06 22:10:07,044 - INFO - Epoch 533/800 done.
2025-03-06 22:10:07,045 - INFO - Final validation performance:
Loss: 2.388, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:10:07,045 - INFO - Beginning epoch 534/800
2025-03-06 22:10:07,049 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:10:07,216 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:10:07,378 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:10:07,548 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:10:07,714 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:10:07,899 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:10:08,077 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:10:08,244 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:10:08,412 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:10:08,571 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:10:08,736 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:10:08,906 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:10:09,075 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:10:09,240 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:10:09,411 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:10:09,584 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-06 22:10:09,755 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:10:09,925 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-06 22:10:10,010 - INFO - validation batch 1, loss: 0.262, 32/6976 datapoints
2025-03-06 22:10:10,059 - INFO - validation batch 51, loss: 6.696, 1632/6976 datapoints
2025-03-06 22:10:10,112 - INFO - validation batch 101, loss: 1.363, 3232/6976 datapoints
2025-03-06 22:10:10,163 - INFO - validation batch 151, loss: 2.145, 4832/6976 datapoints
2025-03-06 22:10:10,217 - INFO - validation batch 201, loss: 0.942, 6432/6976 datapoints
2025-03-06 22:10:10,233 - INFO - Epoch 534/800 done.
2025-03-06 22:10:10,233 - INFO - Final validation performance:
Loss: 2.282, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:10:10,233 - INFO - Beginning epoch 535/800
2025-03-06 22:10:10,237 - INFO - training batch 1, loss: 0.017, 32/28000 datapoints
2025-03-06 22:10:10,407 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:10:10,576 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 22:10:10,754 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 22:10:10,931 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 22:10:11,103 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-06 22:10:11,270 - INFO - training batch 301, loss: 0.036, 9632/28000 datapoints
2025-03-06 22:10:11,441 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:10:11,613 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 22:10:11,782 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-06 22:10:11,959 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:10:12,135 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:10:12,317 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:10:12,488 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:10:12,658 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:10:12,834 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:10:13,011 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:13,224 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:10:13,324 - INFO - validation batch 1, loss: 0.720, 32/6976 datapoints
2025-03-06 22:10:13,378 - INFO - validation batch 51, loss: 7.296, 1632/6976 datapoints
2025-03-06 22:10:13,432 - INFO - validation batch 101, loss: 1.136, 3232/6976 datapoints
2025-03-06 22:10:13,488 - INFO - validation batch 151, loss: 2.127, 4832/6976 datapoints
2025-03-06 22:10:13,540 - INFO - validation batch 201, loss: 1.146, 6432/6976 datapoints
2025-03-06 22:10:13,565 - INFO - Epoch 535/800 done.
2025-03-06 22:10:13,566 - INFO - Final validation performance:
Loss: 2.485, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:10:13,566 - INFO - Beginning epoch 536/800
2025-03-06 22:10:13,571 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:10:13,755 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:10:13,930 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:10:14,102 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:10:14,271 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-06 22:10:14,444 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 22:10:14,616 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:10:14,791 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:10:14,971 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:10:15,146 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:10:15,315 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:10:15,484 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:10:15,661 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:10:15,828 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:10:15,999 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:10:16,174 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:10:16,342 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:16,511 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:10:16,592 - INFO - validation batch 1, loss: 0.689, 32/6976 datapoints
2025-03-06 22:10:16,642 - INFO - validation batch 51, loss: 6.993, 1632/6976 datapoints
2025-03-06 22:10:16,694 - INFO - validation batch 101, loss: 1.173, 3232/6976 datapoints
2025-03-06 22:10:16,745 - INFO - validation batch 151, loss: 2.082, 4832/6976 datapoints
2025-03-06 22:10:16,797 - INFO - validation batch 201, loss: 1.163, 6432/6976 datapoints
2025-03-06 22:10:16,817 - INFO - Epoch 536/800 done.
2025-03-06 22:10:16,817 - INFO - Final validation performance:
Loss: 2.420, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:10:16,818 - INFO - Beginning epoch 537/800
2025-03-06 22:10:16,822 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:10:16,998 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:10:17,163 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:10:17,333 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:10:17,500 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:10:17,674 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:10:17,845 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:10:18,044 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:10:18,218 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:10:18,386 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:10:18,552 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:10:18,725 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:10:18,900 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:10:19,069 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:10:19,254 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:10:19,430 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:10:19,600 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:19,768 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:10:19,856 - INFO - validation batch 1, loss: 0.623, 32/6976 datapoints
2025-03-06 22:10:19,913 - INFO - validation batch 51, loss: 6.951, 1632/6976 datapoints
2025-03-06 22:10:19,965 - INFO - validation batch 101, loss: 1.233, 3232/6976 datapoints
2025-03-06 22:10:20,015 - INFO - validation batch 151, loss: 2.120, 4832/6976 datapoints
2025-03-06 22:10:20,080 - INFO - validation batch 201, loss: 1.149, 6432/6976 datapoints
2025-03-06 22:10:20,099 - INFO - Epoch 537/800 done.
2025-03-06 22:10:20,099 - INFO - Final validation performance:
Loss: 2.415, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:10:20,100 - INFO - Beginning epoch 538/800
2025-03-06 22:10:20,105 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:10:20,279 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:10:20,450 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:10:20,628 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:10:20,801 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:10:20,980 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 22:10:21,182 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:10:21,375 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:10:21,550 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:10:21,724 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:10:21,902 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:10:22,075 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:10:22,253 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:10:22,426 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:10:22,597 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:10:22,772 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:10:22,946 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:23,121 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:10:23,205 - INFO - validation batch 1, loss: 0.576, 32/6976 datapoints
2025-03-06 22:10:23,255 - INFO - validation batch 51, loss: 6.996, 1632/6976 datapoints
2025-03-06 22:10:23,314 - INFO - validation batch 101, loss: 1.245, 3232/6976 datapoints
2025-03-06 22:10:23,364 - INFO - validation batch 151, loss: 2.106, 4832/6976 datapoints
2025-03-06 22:10:23,411 - INFO - validation batch 201, loss: 1.143, 6432/6976 datapoints
2025-03-06 22:10:23,430 - INFO - Epoch 538/800 done.
2025-03-06 22:10:23,430 - INFO - Final validation performance:
Loss: 2.413, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:10:23,431 - INFO - Beginning epoch 539/800
2025-03-06 22:10:23,435 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:10:23,603 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:10:23,766 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:10:23,936 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:10:24,102 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:10:24,267 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:10:24,432 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:10:24,601 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:10:24,766 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:10:24,933 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:10:25,109 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:10:25,278 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:10:25,462 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:10:25,630 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:10:25,802 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:10:25,991 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:10:26,168 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:26,338 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:10:26,418 - INFO - validation batch 1, loss: 0.560, 32/6976 datapoints
2025-03-06 22:10:26,464 - INFO - validation batch 51, loss: 7.035, 1632/6976 datapoints
2025-03-06 22:10:26,511 - INFO - validation batch 101, loss: 1.273, 3232/6976 datapoints
2025-03-06 22:10:26,559 - INFO - validation batch 151, loss: 2.138, 4832/6976 datapoints
2025-03-06 22:10:26,606 - INFO - validation batch 201, loss: 1.129, 6432/6976 datapoints
2025-03-06 22:10:26,622 - INFO - Epoch 539/800 done.
2025-03-06 22:10:26,622 - INFO - Final validation performance:
Loss: 2.427, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:10:26,622 - INFO - Beginning epoch 540/800
2025-03-06 22:10:26,627 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:10:26,792 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:10:26,959 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:10:27,123 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:10:27,302 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:10:27,472 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:10:27,638 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:10:27,805 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:10:27,976 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:10:28,166 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:10:28,330 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:10:28,499 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:10:28,668 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:10:28,832 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:10:29,003 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:10:29,170 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:10:29,333 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:29,499 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:10:29,578 - INFO - validation batch 1, loss: 0.548, 32/6976 datapoints
2025-03-06 22:10:29,629 - INFO - validation batch 51, loss: 7.080, 1632/6976 datapoints
2025-03-06 22:10:29,675 - INFO - validation batch 101, loss: 1.332, 3232/6976 datapoints
2025-03-06 22:10:29,723 - INFO - validation batch 151, loss: 2.214, 4832/6976 datapoints
2025-03-06 22:10:29,776 - INFO - validation batch 201, loss: 1.131, 6432/6976 datapoints
2025-03-06 22:10:29,792 - INFO - Epoch 540/800 done.
2025-03-06 22:10:29,792 - INFO - Final validation performance:
Loss: 2.461, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:10:29,793 - INFO - Beginning epoch 541/800
2025-03-06 22:10:29,797 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:10:29,974 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:10:30,142 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:10:30,311 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:10:30,482 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:10:30,652 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:10:30,822 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:10:30,997 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:10:31,167 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:10:31,331 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:10:31,516 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:10:31,695 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:10:31,882 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:10:32,060 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:10:32,239 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:10:32,414 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:10:32,586 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:32,756 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:10:32,840 - INFO - validation batch 1, loss: 0.545, 32/6976 datapoints
2025-03-06 22:10:32,892 - INFO - validation batch 51, loss: 7.071, 1632/6976 datapoints
2025-03-06 22:10:32,943 - INFO - validation batch 101, loss: 1.414, 3232/6976 datapoints
2025-03-06 22:10:32,995 - INFO - validation batch 151, loss: 2.279, 4832/6976 datapoints
2025-03-06 22:10:33,046 - INFO - validation batch 201, loss: 1.141, 6432/6976 datapoints
2025-03-06 22:10:33,067 - INFO - Epoch 541/800 done.
2025-03-06 22:10:33,068 - INFO - Final validation performance:
Loss: 2.490, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:10:33,068 - INFO - Beginning epoch 542/800
2025-03-06 22:10:33,073 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:10:33,249 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:10:33,420 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:10:33,594 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:10:33,773 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:10:33,950 - INFO - training batch 251, loss: 0.093, 8032/28000 datapoints
2025-03-06 22:10:34,117 - INFO - training batch 301, loss: 0.335, 9632/28000 datapoints
2025-03-06 22:10:34,287 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-06 22:10:34,456 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:10:34,624 - INFO - training batch 451, loss: 0.019, 14432/28000 datapoints
2025-03-06 22:10:34,796 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:10:34,970 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-06 22:10:35,153 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-06 22:10:35,322 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:10:35,491 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:10:35,670 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-06 22:10:35,843 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:36,014 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:10:36,100 - INFO - validation batch 1, loss: 0.485, 32/6976 datapoints
2025-03-06 22:10:36,153 - INFO - validation batch 51, loss: 7.042, 1632/6976 datapoints
2025-03-06 22:10:36,206 - INFO - validation batch 101, loss: 1.401, 3232/6976 datapoints
2025-03-06 22:10:36,254 - INFO - validation batch 151, loss: 1.875, 4832/6976 datapoints
2025-03-06 22:10:36,300 - INFO - validation batch 201, loss: 1.119, 6432/6976 datapoints
2025-03-06 22:10:36,315 - INFO - Epoch 542/800 done.
2025-03-06 22:10:36,316 - INFO - Final validation performance:
Loss: 2.384, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:10:36,316 - INFO - Beginning epoch 543/800
2025-03-06 22:10:36,321 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:10:36,486 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:10:36,651 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:10:36,817 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:10:36,984 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:10:37,151 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:10:37,315 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:10:37,483 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:10:37,664 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:10:37,830 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-06 22:10:38,017 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:10:38,197 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:10:38,383 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:10:38,551 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:10:38,720 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:10:38,893 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:10:39,060 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:39,224 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:10:39,309 - INFO - validation batch 1, loss: 0.579, 32/6976 datapoints
2025-03-06 22:10:39,358 - INFO - validation batch 51, loss: 7.175, 1632/6976 datapoints
2025-03-06 22:10:39,405 - INFO - validation batch 101, loss: 1.272, 3232/6976 datapoints
2025-03-06 22:10:39,452 - INFO - validation batch 151, loss: 1.875, 4832/6976 datapoints
2025-03-06 22:10:39,499 - INFO - validation batch 201, loss: 1.173, 6432/6976 datapoints
2025-03-06 22:10:39,515 - INFO - Epoch 543/800 done.
2025-03-06 22:10:39,516 - INFO - Final validation performance:
Loss: 2.415, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:10:39,516 - INFO - Beginning epoch 544/800
2025-03-06 22:10:39,520 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:10:39,692 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:10:39,855 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:10:40,025 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:10:40,192 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:10:40,360 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:10:40,525 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:10:40,693 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:10:40,860 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-06 22:10:41,026 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:10:41,196 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:10:41,362 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:10:41,533 - INFO - training batch 601, loss: 0.006, 19232/28000 datapoints
2025-03-06 22:10:41,703 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:10:41,874 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:10:42,070 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:10:42,267 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:42,437 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:10:42,518 - INFO - validation batch 1, loss: 0.594, 32/6976 datapoints
2025-03-06 22:10:42,565 - INFO - validation batch 51, loss: 7.093, 1632/6976 datapoints
2025-03-06 22:10:42,613 - INFO - validation batch 101, loss: 1.317, 3232/6976 datapoints
2025-03-06 22:10:42,660 - INFO - validation batch 151, loss: 2.014, 4832/6976 datapoints
2025-03-06 22:10:42,708 - INFO - validation batch 201, loss: 1.163, 6432/6976 datapoints
2025-03-06 22:10:42,724 - INFO - Epoch 544/800 done.
2025-03-06 22:10:42,724 - INFO - Final validation performance:
Loss: 2.436, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:10:42,724 - INFO - Beginning epoch 545/800
2025-03-06 22:10:42,729 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:10:42,902 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:10:43,068 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:10:43,244 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:10:43,414 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:10:43,598 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:10:43,776 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:10:43,967 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:10:44,146 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:10:44,317 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:10:44,485 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:10:44,655 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:10:44,824 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:10:44,991 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:10:45,164 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:10:45,333 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:10:45,500 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:45,673 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:10:45,756 - INFO - validation batch 1, loss: 0.564, 32/6976 datapoints
2025-03-06 22:10:45,803 - INFO - validation batch 51, loss: 7.096, 1632/6976 datapoints
2025-03-06 22:10:45,850 - INFO - validation batch 101, loss: 1.302, 3232/6976 datapoints
2025-03-06 22:10:45,900 - INFO - validation batch 151, loss: 2.065, 4832/6976 datapoints
2025-03-06 22:10:45,949 - INFO - validation batch 201, loss: 1.151, 6432/6976 datapoints
2025-03-06 22:10:45,964 - INFO - Epoch 545/800 done.
2025-03-06 22:10:45,965 - INFO - Final validation performance:
Loss: 2.436, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:10:45,965 - INFO - Beginning epoch 546/800
2025-03-06 22:10:45,970 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:10:46,140 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:10:46,308 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:10:46,474 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:10:46,639 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:10:46,806 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:10:46,975 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:10:47,142 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:10:47,310 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:10:47,473 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:10:47,637 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:10:47,810 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:10:47,982 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:10:48,147 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:10:48,336 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:10:48,507 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:10:48,674 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:48,843 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:10:48,924 - INFO - validation batch 1, loss: 0.542, 32/6976 datapoints
2025-03-06 22:10:48,973 - INFO - validation batch 51, loss: 7.085, 1632/6976 datapoints
2025-03-06 22:10:49,019 - INFO - validation batch 101, loss: 1.324, 3232/6976 datapoints
2025-03-06 22:10:49,066 - INFO - validation batch 151, loss: 2.129, 4832/6976 datapoints
2025-03-06 22:10:49,114 - INFO - validation batch 201, loss: 1.142, 6432/6976 datapoints
2025-03-06 22:10:49,130 - INFO - Epoch 546/800 done.
2025-03-06 22:10:49,130 - INFO - Final validation performance:
Loss: 2.444, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:10:49,130 - INFO - Beginning epoch 547/800
2025-03-06 22:10:49,135 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:10:49,305 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:10:49,466 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:10:49,632 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:10:49,827 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:10:50,003 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:10:50,188 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:10:50,363 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:10:50,540 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:10:50,715 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:10:50,889 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:10:51,062 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:10:51,241 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:10:51,409 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:10:51,579 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:10:51,755 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:10:51,929 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:52,105 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:10:52,190 - INFO - validation batch 1, loss: 0.522, 32/6976 datapoints
2025-03-06 22:10:52,242 - INFO - validation batch 51, loss: 7.119, 1632/6976 datapoints
2025-03-06 22:10:52,293 - INFO - validation batch 101, loss: 1.370, 3232/6976 datapoints
2025-03-06 22:10:52,345 - INFO - validation batch 151, loss: 2.209, 4832/6976 datapoints
2025-03-06 22:10:52,396 - INFO - validation batch 201, loss: 1.138, 6432/6976 datapoints
2025-03-06 22:10:52,415 - INFO - Epoch 547/800 done.
2025-03-06 22:10:52,415 - INFO - Final validation performance:
Loss: 2.471, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:10:52,416 - INFO - Beginning epoch 548/800
2025-03-06 22:10:52,420 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:10:52,591 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:10:52,760 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:10:52,938 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:10:53,111 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:10:53,288 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:10:53,459 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:10:53,642 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:10:53,826 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:10:54,001 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:10:54,175 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:10:54,352 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:10:54,530 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:10:54,703 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:10:54,885 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:10:55,061 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:10:55,234 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:55,403 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:10:55,486 - INFO - validation batch 1, loss: 0.508, 32/6976 datapoints
2025-03-06 22:10:55,536 - INFO - validation batch 51, loss: 7.124, 1632/6976 datapoints
2025-03-06 22:10:55,587 - INFO - validation batch 101, loss: 1.451, 3232/6976 datapoints
2025-03-06 22:10:55,637 - INFO - validation batch 151, loss: 2.358, 4832/6976 datapoints
2025-03-06 22:10:55,689 - INFO - validation batch 201, loss: 1.161, 6432/6976 datapoints
2025-03-06 22:10:55,707 - INFO - Epoch 548/800 done.
2025-03-06 22:10:55,708 - INFO - Final validation performance:
Loss: 2.520, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:10:55,708 - INFO - Beginning epoch 549/800
2025-03-06 22:10:55,714 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:10:55,912 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:10:56,080 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:10:56,257 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:10:56,434 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:10:56,608 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:10:56,784 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:10:56,958 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:10:57,135 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:10:57,305 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:10:57,472 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:10:57,642 - INFO - training batch 551, loss: 0.131, 17632/28000 datapoints
2025-03-06 22:10:57,820 - INFO - training batch 601, loss: 0.192, 19232/28000 datapoints
2025-03-06 22:10:57,993 - INFO - training batch 651, loss: 0.050, 20832/28000 datapoints
2025-03-06 22:10:58,163 - INFO - training batch 701, loss: 0.018, 22432/28000 datapoints
2025-03-06 22:10:58,336 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:10:58,533 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:10:58,707 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-06 22:10:58,796 - INFO - validation batch 1, loss: 0.637, 32/6976 datapoints
2025-03-06 22:10:58,850 - INFO - validation batch 51, loss: 7.347, 1632/6976 datapoints
2025-03-06 22:10:58,909 - INFO - validation batch 101, loss: 1.330, 3232/6976 datapoints
2025-03-06 22:10:58,961 - INFO - validation batch 151, loss: 1.773, 4832/6976 datapoints
2025-03-06 22:10:59,011 - INFO - validation batch 201, loss: 1.135, 6432/6976 datapoints
2025-03-06 22:10:59,028 - INFO - Epoch 549/800 done.
2025-03-06 22:10:59,029 - INFO - Final validation performance:
Loss: 2.444, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:10:59,029 - INFO - Beginning epoch 550/800
2025-03-06 22:10:59,034 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-06 22:10:59,210 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:10:59,382 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:10:59,560 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:10:59,730 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:10:59,915 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:11:00,088 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:11:00,263 - INFO - training batch 351, loss: 0.017, 11232/28000 datapoints
2025-03-06 22:11:00,434 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:11:00,600 - INFO - training batch 451, loss: 0.011, 14432/28000 datapoints
2025-03-06 22:11:00,772 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:11:00,951 - INFO - training batch 551, loss: 0.020, 17632/28000 datapoints
2025-03-06 22:11:01,128 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-06 22:11:01,295 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:11:01,464 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:11:01,637 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:11:01,809 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:01,984 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:11:02,079 - INFO - validation batch 1, loss: 0.656, 32/6976 datapoints
2025-03-06 22:11:02,125 - INFO - validation batch 51, loss: 7.144, 1632/6976 datapoints
2025-03-06 22:11:02,172 - INFO - validation batch 101, loss: 1.235, 3232/6976 datapoints
2025-03-06 22:11:02,218 - INFO - validation batch 151, loss: 2.004, 4832/6976 datapoints
2025-03-06 22:11:02,266 - INFO - validation batch 201, loss: 1.148, 6432/6976 datapoints
2025-03-06 22:11:02,283 - INFO - Epoch 550/800 done.
2025-03-06 22:11:02,283 - INFO - Final validation performance:
Loss: 2.437, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:11:02,283 - INFO - Beginning epoch 551/800
2025-03-06 22:11:02,287 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:11:02,462 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:11:02,623 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:11:02,792 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:11:02,960 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:11:03,130 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:11:03,295 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:11:03,461 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:11:03,628 - INFO - training batch 401, loss: 0.016, 12832/28000 datapoints
2025-03-06 22:11:03,795 - INFO - training batch 451, loss: 0.071, 14432/28000 datapoints
2025-03-06 22:11:03,964 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:11:04,132 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:11:04,307 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:11:04,473 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:11:04,638 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:11:04,808 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:11:04,979 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:05,151 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:11:05,232 - INFO - validation batch 1, loss: 0.939, 32/6976 datapoints
2025-03-06 22:11:05,280 - INFO - validation batch 51, loss: 7.440, 1632/6976 datapoints
2025-03-06 22:11:05,329 - INFO - validation batch 101, loss: 1.140, 3232/6976 datapoints
2025-03-06 22:11:05,377 - INFO - validation batch 151, loss: 2.168, 4832/6976 datapoints
2025-03-06 22:11:05,426 - INFO - validation batch 201, loss: 1.179, 6432/6976 datapoints
2025-03-06 22:11:05,442 - INFO - Epoch 551/800 done.
2025-03-06 22:11:05,442 - INFO - Final validation performance:
Loss: 2.573, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 22:11:05,442 - INFO - Beginning epoch 552/800
2025-03-06 22:11:05,447 - INFO - training batch 1, loss: 0.011, 32/28000 datapoints
2025-03-06 22:11:05,614 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:11:05,780 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:11:05,958 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:11:06,123 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:11:06,297 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 22:11:06,464 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:11:06,629 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-06 22:11:06,795 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 22:11:06,964 - INFO - training batch 451, loss: 0.016, 14432/28000 datapoints
2025-03-06 22:11:07,134 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:11:07,303 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:11:07,478 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-06 22:11:07,644 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:11:07,812 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:11:07,987 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:11:08,158 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:08,334 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:11:08,415 - INFO - validation batch 1, loss: 0.783, 32/6976 datapoints
2025-03-06 22:11:08,465 - INFO - validation batch 51, loss: 7.161, 1632/6976 datapoints
2025-03-06 22:11:08,530 - INFO - validation batch 101, loss: 1.207, 3232/6976 datapoints
2025-03-06 22:11:08,592 - INFO - validation batch 151, loss: 2.140, 4832/6976 datapoints
2025-03-06 22:11:08,640 - INFO - validation batch 201, loss: 1.239, 6432/6976 datapoints
2025-03-06 22:11:08,659 - INFO - Epoch 552/800 done.
2025-03-06 22:11:08,659 - INFO - Final validation performance:
Loss: 2.506, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:11:08,660 - INFO - Beginning epoch 553/800
2025-03-06 22:11:08,664 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:11:08,836 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:11:09,005 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:11:09,179 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:11:09,357 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:11:09,527 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:11:09,692 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:11:09,872 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:11:10,046 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:11:10,215 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:11:10,389 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:11:10,567 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:11:10,746 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:11:10,919 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:11:11,090 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:11:11,264 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:11:11,434 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:11,603 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:11:11,686 - INFO - validation batch 1, loss: 0.676, 32/6976 datapoints
2025-03-06 22:11:11,739 - INFO - validation batch 51, loss: 7.170, 1632/6976 datapoints
2025-03-06 22:11:11,790 - INFO - validation batch 101, loss: 1.214, 3232/6976 datapoints
2025-03-06 22:11:11,842 - INFO - validation batch 151, loss: 2.233, 4832/6976 datapoints
2025-03-06 22:11:11,895 - INFO - validation batch 201, loss: 1.180, 6432/6976 datapoints
2025-03-06 22:11:11,916 - INFO - Epoch 553/800 done.
2025-03-06 22:11:11,916 - INFO - Final validation performance:
Loss: 2.494, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:11:11,917 - INFO - Beginning epoch 554/800
2025-03-06 22:11:11,921 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:11:12,094 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:11:12,265 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:11:12,438 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:11:12,606 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:11:12,781 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:11:12,959 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:11:13,149 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:11:13,327 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:11:13,502 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:11:13,686 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:11:13,893 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:11:14,074 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:11:14,249 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:11:14,440 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:11:14,622 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:11:14,797 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:14,978 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:11:15,066 - INFO - validation batch 1, loss: 0.633, 32/6976 datapoints
2025-03-06 22:11:15,119 - INFO - validation batch 51, loss: 7.165, 1632/6976 datapoints
2025-03-06 22:11:15,179 - INFO - validation batch 101, loss: 1.234, 3232/6976 datapoints
2025-03-06 22:11:15,232 - INFO - validation batch 151, loss: 2.203, 4832/6976 datapoints
2025-03-06 22:11:15,286 - INFO - validation batch 201, loss: 1.173, 6432/6976 datapoints
2025-03-06 22:11:15,305 - INFO - Epoch 554/800 done.
2025-03-06 22:11:15,305 - INFO - Final validation performance:
Loss: 2.482, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:11:15,306 - INFO - Beginning epoch 555/800
2025-03-06 22:11:15,311 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:11:15,496 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:11:15,668 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:11:15,846 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:11:16,017 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:11:16,189 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:11:16,367 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:11:16,539 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:11:16,711 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:11:16,885 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-06 22:11:17,057 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:11:17,231 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:11:17,424 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:11:17,593 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:11:17,765 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:11:17,946 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:11:18,118 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:18,310 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:11:18,393 - INFO - validation batch 1, loss: 0.578, 32/6976 datapoints
2025-03-06 22:11:18,444 - INFO - validation batch 51, loss: 7.169, 1632/6976 datapoints
2025-03-06 22:11:18,495 - INFO - validation batch 101, loss: 1.262, 3232/6976 datapoints
2025-03-06 22:11:18,550 - INFO - validation batch 151, loss: 2.230, 4832/6976 datapoints
2025-03-06 22:11:18,621 - INFO - validation batch 201, loss: 1.172, 6432/6976 datapoints
2025-03-06 22:11:18,643 - INFO - Epoch 555/800 done.
2025-03-06 22:11:18,643 - INFO - Final validation performance:
Loss: 2.482, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:11:18,644 - INFO - Beginning epoch 556/800
2025-03-06 22:11:18,650 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:11:18,825 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:11:18,996 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:11:19,172 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:11:19,341 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:11:19,515 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:11:19,687 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:11:19,862 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:11:20,038 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:11:20,207 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:11:20,379 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:11:20,572 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:11:20,749 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:11:20,937 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:11:21,119 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:11:21,304 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:11:21,483 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:21,700 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:11:21,788 - INFO - validation batch 1, loss: 0.522, 32/6976 datapoints
2025-03-06 22:11:21,839 - INFO - validation batch 51, loss: 7.195, 1632/6976 datapoints
2025-03-06 22:11:21,897 - INFO - validation batch 101, loss: 1.305, 3232/6976 datapoints
2025-03-06 22:11:21,948 - INFO - validation batch 151, loss: 2.285, 4832/6976 datapoints
2025-03-06 22:11:22,002 - INFO - validation batch 201, loss: 1.162, 6432/6976 datapoints
2025-03-06 22:11:22,024 - INFO - Epoch 556/800 done.
2025-03-06 22:11:22,024 - INFO - Final validation performance:
Loss: 2.494, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:11:22,024 - INFO - Beginning epoch 557/800
2025-03-06 22:11:22,029 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:11:22,215 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:11:22,386 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:11:22,567 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:11:22,749 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:11:22,933 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:11:23,110 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:11:23,288 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:11:23,463 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:11:23,638 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:11:23,815 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:11:23,997 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:11:24,179 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:11:24,355 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:11:24,524 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:11:24,701 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:11:24,876 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:25,047 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:11:25,132 - INFO - validation batch 1, loss: 0.446, 32/6976 datapoints
2025-03-06 22:11:25,188 - INFO - validation batch 51, loss: 7.229, 1632/6976 datapoints
2025-03-06 22:11:25,237 - INFO - validation batch 101, loss: 1.385, 3232/6976 datapoints
2025-03-06 22:11:25,288 - INFO - validation batch 151, loss: 2.427, 4832/6976 datapoints
2025-03-06 22:11:25,342 - INFO - validation batch 201, loss: 1.169, 6432/6976 datapoints
2025-03-06 22:11:25,362 - INFO - Epoch 557/800 done.
2025-03-06 22:11:25,362 - INFO - Final validation performance:
Loss: 2.531, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:11:25,363 - INFO - Beginning epoch 558/800
2025-03-06 22:11:25,368 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:11:25,539 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:11:25,707 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:11:25,885 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:11:26,052 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:11:26,234 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:11:26,414 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:11:26,596 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:11:26,764 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:11:26,944 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:11:27,120 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:11:27,288 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:11:27,463 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:11:27,629 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:11:27,792 - INFO - training batch 701, loss: 0.022, 22432/28000 datapoints
2025-03-06 22:11:27,971 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:11:28,145 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:28,313 - INFO - training batch 851, loss: 0.046, 27232/28000 datapoints
2025-03-06 22:11:28,394 - INFO - validation batch 1, loss: 0.371, 32/6976 datapoints
2025-03-06 22:11:28,440 - INFO - validation batch 51, loss: 7.563, 1632/6976 datapoints
2025-03-06 22:11:28,487 - INFO - validation batch 101, loss: 1.380, 3232/6976 datapoints
2025-03-06 22:11:28,536 - INFO - validation batch 151, loss: 1.810, 4832/6976 datapoints
2025-03-06 22:11:28,582 - INFO - validation batch 201, loss: 0.996, 6432/6976 datapoints
2025-03-06 22:11:28,598 - INFO - Epoch 558/800 done.
2025-03-06 22:11:28,598 - INFO - Final validation performance:
Loss: 2.424, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:11:28,599 - INFO - Beginning epoch 559/800
2025-03-06 22:11:28,603 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:11:28,806 - INFO - training batch 51, loss: 0.019, 1632/28000 datapoints
2025-03-06 22:11:28,973 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:11:29,144 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-06 22:11:29,312 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:11:29,485 - INFO - training batch 251, loss: 0.094, 8032/28000 datapoints
2025-03-06 22:11:29,652 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:11:29,820 - INFO - training batch 351, loss: 0.027, 11232/28000 datapoints
2025-03-06 22:11:29,996 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:11:30,169 - INFO - training batch 451, loss: 0.011, 14432/28000 datapoints
2025-03-06 22:11:30,341 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:11:30,513 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:11:30,690 - INFO - training batch 601, loss: 0.006, 19232/28000 datapoints
2025-03-06 22:11:30,859 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:11:31,034 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:11:31,210 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:11:31,382 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:31,552 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:11:31,637 - INFO - validation batch 1, loss: 0.674, 32/6976 datapoints
2025-03-06 22:11:31,691 - INFO - validation batch 51, loss: 7.260, 1632/6976 datapoints
2025-03-06 22:11:31,742 - INFO - validation batch 101, loss: 1.340, 3232/6976 datapoints
2025-03-06 22:11:31,793 - INFO - validation batch 151, loss: 2.138, 4832/6976 datapoints
2025-03-06 22:11:31,844 - INFO - validation batch 201, loss: 1.170, 6432/6976 datapoints
2025-03-06 22:11:31,863 - INFO - Epoch 559/800 done.
2025-03-06 22:11:31,864 - INFO - Final validation performance:
Loss: 2.516, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:11:31,865 - INFO - Beginning epoch 560/800
2025-03-06 22:11:31,872 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:11:32,066 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:11:32,239 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:11:32,418 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:11:32,607 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:11:32,804 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 22:11:32,996 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:11:33,207 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:11:33,425 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:11:33,624 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:11:33,800 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:11:33,984 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-06 22:11:34,164 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:11:34,337 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:11:34,515 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:11:34,696 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:11:34,878 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:35,053 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:11:35,150 - INFO - validation batch 1, loss: 0.677, 32/6976 datapoints
2025-03-06 22:11:35,202 - INFO - validation batch 51, loss: 7.354, 1632/6976 datapoints
2025-03-06 22:11:35,256 - INFO - validation batch 101, loss: 1.313, 3232/6976 datapoints
2025-03-06 22:11:35,309 - INFO - validation batch 151, loss: 2.126, 4832/6976 datapoints
2025-03-06 22:11:35,357 - INFO - validation batch 201, loss: 1.151, 6432/6976 datapoints
2025-03-06 22:11:35,374 - INFO - Epoch 560/800 done.
2025-03-06 22:11:35,375 - INFO - Final validation performance:
Loss: 2.524, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:11:35,375 - INFO - Beginning epoch 561/800
2025-03-06 22:11:35,379 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:11:35,554 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:11:35,730 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:11:35,909 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:11:36,077 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:11:36,251 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:11:36,425 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:11:36,595 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:11:36,766 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:11:36,938 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:11:37,107 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:11:37,277 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:11:37,476 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:11:37,671 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:11:37,894 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:11:38,094 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:11:38,295 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:38,484 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:11:38,577 - INFO - validation batch 1, loss: 0.631, 32/6976 datapoints
2025-03-06 22:11:38,639 - INFO - validation batch 51, loss: 7.382, 1632/6976 datapoints
2025-03-06 22:11:38,703 - INFO - validation batch 101, loss: 1.282, 3232/6976 datapoints
2025-03-06 22:11:38,771 - INFO - validation batch 151, loss: 2.129, 4832/6976 datapoints
2025-03-06 22:11:38,845 - INFO - validation batch 201, loss: 1.144, 6432/6976 datapoints
2025-03-06 22:11:38,870 - INFO - Epoch 561/800 done.
2025-03-06 22:11:38,870 - INFO - Final validation performance:
Loss: 2.514, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:11:38,871 - INFO - Beginning epoch 562/800
2025-03-06 22:11:38,875 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:11:39,076 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:11:39,276 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:11:39,473 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:11:39,679 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:11:40,014 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:11:40,251 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:11:40,468 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:11:40,674 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:11:40,883 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:11:41,089 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:11:41,305 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:11:41,500 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:11:41,689 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:11:41,884 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:11:42,096 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:11:42,303 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:42,502 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:11:42,616 - INFO - validation batch 1, loss: 0.605, 32/6976 datapoints
2025-03-06 22:11:42,690 - INFO - validation batch 51, loss: 7.400, 1632/6976 datapoints
2025-03-06 22:11:42,760 - INFO - validation batch 101, loss: 1.285, 3232/6976 datapoints
2025-03-06 22:11:42,824 - INFO - validation batch 151, loss: 2.183, 4832/6976 datapoints
2025-03-06 22:11:42,887 - INFO - validation batch 201, loss: 1.140, 6432/6976 datapoints
2025-03-06 22:11:42,907 - INFO - Epoch 562/800 done.
2025-03-06 22:11:42,907 - INFO - Final validation performance:
Loss: 2.522, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:11:42,908 - INFO - Beginning epoch 563/800
2025-03-06 22:11:42,913 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:11:43,123 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:11:43,336 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:11:43,541 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:11:43,762 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:11:44,028 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:11:44,290 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:11:44,486 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:11:44,683 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:11:44,883 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:11:45,122 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:11:45,356 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:11:45,576 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:11:45,787 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:11:46,036 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:11:46,282 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:11:46,522 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:46,770 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:11:46,884 - INFO - validation batch 1, loss: 0.578, 32/6976 datapoints
2025-03-06 22:11:46,957 - INFO - validation batch 51, loss: 7.425, 1632/6976 datapoints
2025-03-06 22:11:47,029 - INFO - validation batch 101, loss: 1.300, 3232/6976 datapoints
2025-03-06 22:11:47,103 - INFO - validation batch 151, loss: 2.234, 4832/6976 datapoints
2025-03-06 22:11:47,175 - INFO - validation batch 201, loss: 1.134, 6432/6976 datapoints
2025-03-06 22:11:47,200 - INFO - Epoch 563/800 done.
2025-03-06 22:11:47,200 - INFO - Final validation performance:
Loss: 2.534, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:11:47,201 - INFO - Beginning epoch 564/800
2025-03-06 22:11:47,208 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:11:47,460 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:11:47,688 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:11:47,931 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:11:48,173 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:11:48,416 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:11:48,637 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:11:48,836 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:11:49,056 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:11:49,247 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:11:49,486 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:11:49,706 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:11:49,920 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:11:50,123 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:11:50,318 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:11:50,531 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:11:50,728 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:50,944 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:11:51,041 - INFO - validation batch 1, loss: 0.548, 32/6976 datapoints
2025-03-06 22:11:51,104 - INFO - validation batch 51, loss: 7.470, 1632/6976 datapoints
2025-03-06 22:11:51,180 - INFO - validation batch 101, loss: 1.347, 3232/6976 datapoints
2025-03-06 22:11:51,238 - INFO - validation batch 151, loss: 2.340, 4832/6976 datapoints
2025-03-06 22:11:51,304 - INFO - validation batch 201, loss: 1.133, 6432/6976 datapoints
2025-03-06 22:11:51,326 - INFO - Epoch 564/800 done.
2025-03-06 22:11:51,326 - INFO - Final validation performance:
Loss: 2.568, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:11:51,327 - INFO - Beginning epoch 565/800
2025-03-06 22:11:51,331 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:11:51,535 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:11:51,721 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:11:51,923 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:11:52,127 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:11:52,338 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:11:52,538 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:11:52,742 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:11:52,952 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:11:53,146 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:11:53,352 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:11:53,553 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:11:53,762 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:11:53,972 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:11:54,186 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:11:54,409 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:11:54,617 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:11:54,829 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:11:54,943 - INFO - validation batch 1, loss: 0.484, 32/6976 datapoints
2025-03-06 22:11:55,017 - INFO - validation batch 51, loss: 7.477, 1632/6976 datapoints
2025-03-06 22:11:55,085 - INFO - validation batch 101, loss: 1.445, 3232/6976 datapoints
2025-03-06 22:11:55,160 - INFO - validation batch 151, loss: 2.520, 4832/6976 datapoints
2025-03-06 22:11:55,226 - INFO - validation batch 201, loss: 1.157, 6432/6976 datapoints
2025-03-06 22:11:55,248 - INFO - Epoch 565/800 done.
2025-03-06 22:11:55,248 - INFO - Final validation performance:
Loss: 2.617, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:11:55,249 - INFO - Beginning epoch 566/800
2025-03-06 22:11:55,255 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:11:55,744 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:11:55,956 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:11:56,157 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:11:56,359 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:11:56,558 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:11:56,761 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:11:57,035 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:11:57,312 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:11:57,512 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:11:57,712 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:11:57,919 - INFO - training batch 551, loss: 0.024, 17632/28000 datapoints
2025-03-06 22:11:58,122 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 22:11:58,323 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 22:11:58,544 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:11:58,771 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:11:59,021 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:11:59,234 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:11:59,338 - INFO - validation batch 1, loss: 0.266, 32/6976 datapoints
2025-03-06 22:11:59,399 - INFO - validation batch 51, loss: 8.277, 1632/6976 datapoints
2025-03-06 22:11:59,456 - INFO - validation batch 101, loss: 1.469, 3232/6976 datapoints
2025-03-06 22:11:59,515 - INFO - validation batch 151, loss: 2.100, 4832/6976 datapoints
2025-03-06 22:11:59,575 - INFO - validation batch 201, loss: 1.087, 6432/6976 datapoints
2025-03-06 22:11:59,592 - INFO - Epoch 566/800 done.
2025-03-06 22:11:59,592 - INFO - Final validation performance:
Loss: 2.640, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:11:59,593 - INFO - Beginning epoch 567/800
2025-03-06 22:11:59,599 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:11:59,788 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 22:11:59,969 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 22:12:00,173 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:12:00,351 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:12:00,536 - INFO - training batch 251, loss: 0.022, 8032/28000 datapoints
2025-03-06 22:12:00,712 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:12:00,886 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:12:01,060 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:12:01,229 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:12:01,398 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:12:01,565 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:12:01,736 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 22:12:01,909 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:02,076 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:12:02,250 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:12:02,422 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:02,586 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:12:02,668 - INFO - validation batch 1, loss: 0.301, 32/6976 datapoints
2025-03-06 22:12:02,714 - INFO - validation batch 51, loss: 7.474, 1632/6976 datapoints
2025-03-06 22:12:02,761 - INFO - validation batch 101, loss: 1.495, 3232/6976 datapoints
2025-03-06 22:12:02,812 - INFO - validation batch 151, loss: 2.222, 4832/6976 datapoints
2025-03-06 22:12:02,860 - INFO - validation batch 201, loss: 1.010, 6432/6976 datapoints
2025-03-06 22:12:02,879 - INFO - Epoch 567/800 done.
2025-03-06 22:12:02,893 - INFO - Final validation performance:
Loss: 2.501, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:12:02,894 - INFO - Beginning epoch 568/800
2025-03-06 22:12:02,916 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:12:03,113 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:12:03,298 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:03,474 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:12:03,644 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:12:03,831 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:12:04,011 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:12:04,189 - INFO - training batch 351, loss: 0.023, 11232/28000 datapoints
2025-03-06 22:12:04,360 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:12:04,528 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:12:04,710 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:12:04,880 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:12:05,049 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:12:05,222 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:05,394 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:12:05,572 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:12:05,747 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:05,917 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:12:06,000 - INFO - validation batch 1, loss: 0.414, 32/6976 datapoints
2025-03-06 22:12:06,049 - INFO - validation batch 51, loss: 7.458, 1632/6976 datapoints
2025-03-06 22:12:06,100 - INFO - validation batch 101, loss: 1.477, 3232/6976 datapoints
2025-03-06 22:12:06,154 - INFO - validation batch 151, loss: 2.218, 4832/6976 datapoints
2025-03-06 22:12:06,204 - INFO - validation batch 201, loss: 1.135, 6432/6976 datapoints
2025-03-06 22:12:06,225 - INFO - Epoch 568/800 done.
2025-03-06 22:12:06,225 - INFO - Final validation performance:
Loss: 2.540, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:12:06,226 - INFO - Beginning epoch 569/800
2025-03-06 22:12:06,230 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:12:06,405 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:12:06,578 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:06,753 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:12:06,931 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:12:07,107 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:12:07,284 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-06 22:12:07,463 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:12:07,642 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:12:07,813 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:12:07,993 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:12:08,172 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:12:08,350 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:12:08,523 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:08,698 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:12:08,878 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:12:09,056 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:09,266 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:12:09,360 - INFO - validation batch 1, loss: 0.469, 32/6976 datapoints
2025-03-06 22:12:09,412 - INFO - validation batch 51, loss: 7.531, 1632/6976 datapoints
2025-03-06 22:12:09,459 - INFO - validation batch 101, loss: 1.450, 3232/6976 datapoints
2025-03-06 22:12:09,506 - INFO - validation batch 151, loss: 2.157, 4832/6976 datapoints
2025-03-06 22:12:09,554 - INFO - validation batch 201, loss: 1.041, 6432/6976 datapoints
2025-03-06 22:12:09,572 - INFO - Epoch 569/800 done.
2025-03-06 22:12:09,573 - INFO - Final validation performance:
Loss: 2.530, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:12:09,573 - INFO - Beginning epoch 570/800
2025-03-06 22:12:09,578 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:12:09,759 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:12:09,929 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:10,106 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:12:10,275 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:12:10,447 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-06 22:12:10,614 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:12:10,786 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:12:10,962 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:12:11,132 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:12:11,305 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:12:11,478 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:12:11,655 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:12:11,822 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:11,992 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:12:12,173 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:12:12,356 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:12,524 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:12:12,607 - INFO - validation batch 1, loss: 0.478, 32/6976 datapoints
2025-03-06 22:12:12,653 - INFO - validation batch 51, loss: 7.454, 1632/6976 datapoints
2025-03-06 22:12:12,700 - INFO - validation batch 101, loss: 1.408, 3232/6976 datapoints
2025-03-06 22:12:12,746 - INFO - validation batch 151, loss: 2.222, 4832/6976 datapoints
2025-03-06 22:12:12,792 - INFO - validation batch 201, loss: 1.090, 6432/6976 datapoints
2025-03-06 22:12:12,808 - INFO - Epoch 570/800 done.
2025-03-06 22:12:12,809 - INFO - Final validation performance:
Loss: 2.530, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:12:12,809 - INFO - Beginning epoch 571/800
2025-03-06 22:12:12,814 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:12:12,995 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:12:13,180 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:13,354 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:12:13,523 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:12:13,695 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:12:13,863 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:12:14,041 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:12:14,221 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:12:14,393 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:12:14,568 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:12:14,742 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:12:14,923 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:12:15,095 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:15,275 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:12:15,459 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:12:15,635 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:15,806 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:12:15,891 - INFO - validation batch 1, loss: 0.463, 32/6976 datapoints
2025-03-06 22:12:15,937 - INFO - validation batch 51, loss: 7.439, 1632/6976 datapoints
2025-03-06 22:12:15,986 - INFO - validation batch 101, loss: 1.394, 3232/6976 datapoints
2025-03-06 22:12:16,032 - INFO - validation batch 151, loss: 2.229, 4832/6976 datapoints
2025-03-06 22:12:16,081 - INFO - validation batch 201, loss: 1.096, 6432/6976 datapoints
2025-03-06 22:12:16,098 - INFO - Epoch 571/800 done.
2025-03-06 22:12:16,098 - INFO - Final validation performance:
Loss: 2.524, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:12:16,099 - INFO - Beginning epoch 572/800
2025-03-06 22:12:16,103 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:12:16,276 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:12:16,444 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:16,622 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:12:16,788 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:12:16,965 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 22:12:17,135 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:12:17,306 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:12:17,480 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:12:17,650 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:12:17,821 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:12:17,994 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:12:18,167 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:12:18,335 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:18,502 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:12:18,677 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:12:18,848 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:19,019 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:12:19,104 - INFO - validation batch 1, loss: 0.449, 32/6976 datapoints
2025-03-06 22:12:19,150 - INFO - validation batch 51, loss: 7.453, 1632/6976 datapoints
2025-03-06 22:12:19,207 - INFO - validation batch 101, loss: 1.397, 3232/6976 datapoints
2025-03-06 22:12:19,273 - INFO - validation batch 151, loss: 2.260, 4832/6976 datapoints
2025-03-06 22:12:19,319 - INFO - validation batch 201, loss: 1.100, 6432/6976 datapoints
2025-03-06 22:12:19,335 - INFO - Epoch 572/800 done.
2025-03-06 22:12:19,336 - INFO - Final validation performance:
Loss: 2.532, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:12:19,336 - INFO - Beginning epoch 573/800
2025-03-06 22:12:19,341 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:12:19,518 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:12:19,683 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:19,854 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:12:20,023 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:12:20,200 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:12:20,372 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:12:20,543 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:12:20,716 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:12:20,893 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:12:21,070 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:12:21,244 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:12:21,414 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:12:21,588 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:21,754 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:12:21,938 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:12:22,145 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:22,323 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:12:22,409 - INFO - validation batch 1, loss: 0.445, 32/6976 datapoints
2025-03-06 22:12:22,456 - INFO - validation batch 51, loss: 7.472, 1632/6976 datapoints
2025-03-06 22:12:22,503 - INFO - validation batch 101, loss: 1.414, 3232/6976 datapoints
2025-03-06 22:12:22,551 - INFO - validation batch 151, loss: 2.313, 4832/6976 datapoints
2025-03-06 22:12:22,597 - INFO - validation batch 201, loss: 1.109, 6432/6976 datapoints
2025-03-06 22:12:22,614 - INFO - Epoch 573/800 done.
2025-03-06 22:12:22,614 - INFO - Final validation performance:
Loss: 2.551, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:12:22,614 - INFO - Beginning epoch 574/800
2025-03-06 22:12:22,619 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:12:22,794 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:12:22,962 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:23,135 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:12:23,304 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:12:23,476 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:12:23,646 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:12:23,820 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:12:23,995 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:12:24,165 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:12:24,338 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:12:24,506 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:12:24,677 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:12:24,844 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:25,014 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:12:25,196 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:12:25,377 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:25,548 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:12:25,635 - INFO - validation batch 1, loss: 0.443, 32/6976 datapoints
2025-03-06 22:12:25,681 - INFO - validation batch 51, loss: 7.535, 1632/6976 datapoints
2025-03-06 22:12:25,729 - INFO - validation batch 101, loss: 1.475, 3232/6976 datapoints
2025-03-06 22:12:25,776 - INFO - validation batch 151, loss: 2.447, 4832/6976 datapoints
2025-03-06 22:12:25,823 - INFO - validation batch 201, loss: 1.138, 6432/6976 datapoints
2025-03-06 22:12:25,839 - INFO - Epoch 574/800 done.
2025-03-06 22:12:25,839 - INFO - Final validation performance:
Loss: 2.608, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:12:25,840 - INFO - Beginning epoch 575/800
2025-03-06 22:12:25,844 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:12:26,024 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:12:26,196 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:26,369 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:12:26,545 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:12:26,718 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:12:26,891 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:12:27,064 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:12:27,238 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:12:27,413 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:12:27,588 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:12:27,762 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:12:27,945 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:12:28,116 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:28,292 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:12:28,475 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:12:28,655 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:28,828 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:12:28,917 - INFO - validation batch 1, loss: 0.405, 32/6976 datapoints
2025-03-06 22:12:28,966 - INFO - validation batch 51, loss: 7.674, 1632/6976 datapoints
2025-03-06 22:12:29,015 - INFO - validation batch 101, loss: 1.530, 3232/6976 datapoints
2025-03-06 22:12:29,063 - INFO - validation batch 151, loss: 2.633, 4832/6976 datapoints
2025-03-06 22:12:29,111 - INFO - validation batch 201, loss: 1.180, 6432/6976 datapoints
2025-03-06 22:12:29,129 - INFO - Epoch 575/800 done.
2025-03-06 22:12:29,129 - INFO - Final validation performance:
Loss: 2.685, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:12:29,129 - INFO - Beginning epoch 576/800
2025-03-06 22:12:29,134 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:12:29,324 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:12:29,502 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:29,680 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:12:29,854 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:12:30,031 - INFO - training batch 251, loss: 0.053, 8032/28000 datapoints
2025-03-06 22:12:30,206 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:12:30,385 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:12:30,559 - INFO - training batch 401, loss: 0.047, 12832/28000 datapoints
2025-03-06 22:12:30,733 - INFO - training batch 451, loss: 0.028, 14432/28000 datapoints
2025-03-06 22:12:30,910 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:12:31,080 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:12:31,253 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:12:31,422 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:31,589 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:12:31,766 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:12:31,940 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:32,112 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:12:32,201 - INFO - validation batch 1, loss: 0.557, 32/6976 datapoints
2025-03-06 22:12:32,248 - INFO - validation batch 51, loss: 7.700, 1632/6976 datapoints
2025-03-06 22:12:32,297 - INFO - validation batch 101, loss: 1.802, 3232/6976 datapoints
2025-03-06 22:12:32,343 - INFO - validation batch 151, loss: 2.686, 4832/6976 datapoints
2025-03-06 22:12:32,390 - INFO - validation batch 201, loss: 1.249, 6432/6976 datapoints
2025-03-06 22:12:32,406 - INFO - Epoch 576/800 done.
2025-03-06 22:12:32,406 - INFO - Final validation performance:
Loss: 2.798, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:12:32,407 - INFO - Beginning epoch 577/800
2025-03-06 22:12:32,411 - INFO - training batch 1, loss: 0.011, 32/28000 datapoints
2025-03-06 22:12:32,583 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:12:32,752 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:12:32,924 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:12:33,088 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:12:33,266 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:12:33,447 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:12:33,619 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:12:33,791 - INFO - training batch 401, loss: 0.018, 12832/28000 datapoints
2025-03-06 22:12:33,963 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-06 22:12:34,140 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:12:34,310 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:12:34,484 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:12:34,661 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:34,829 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:12:35,009 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:12:35,189 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:35,360 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:12:35,445 - INFO - validation batch 1, loss: 0.155, 32/6976 datapoints
2025-03-06 22:12:35,492 - INFO - validation batch 51, loss: 7.506, 1632/6976 datapoints
2025-03-06 22:12:35,539 - INFO - validation batch 101, loss: 1.604, 3232/6976 datapoints
2025-03-06 22:12:35,586 - INFO - validation batch 151, loss: 2.310, 4832/6976 datapoints
2025-03-06 22:12:35,632 - INFO - validation batch 201, loss: 1.044, 6432/6976 datapoints
2025-03-06 22:12:35,648 - INFO - Epoch 577/800 done.
2025-03-06 22:12:35,648 - INFO - Final validation performance:
Loss: 2.524, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:12:35,649 - INFO - Beginning epoch 578/800
2025-03-06 22:12:35,653 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:12:35,830 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:12:35,999 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:36,175 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:12:36,345 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:12:36,524 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:12:36,698 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:12:36,875 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:12:37,052 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 22:12:37,225 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:12:37,405 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:12:37,575 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:12:37,746 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:12:37,937 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:38,104 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:12:38,283 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:12:38,460 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:38,628 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:12:38,714 - INFO - validation batch 1, loss: 0.323, 32/6976 datapoints
2025-03-06 22:12:38,761 - INFO - validation batch 51, loss: 7.610, 1632/6976 datapoints
2025-03-06 22:12:38,807 - INFO - validation batch 101, loss: 1.475, 3232/6976 datapoints
2025-03-06 22:12:38,854 - INFO - validation batch 151, loss: 2.273, 4832/6976 datapoints
2025-03-06 22:12:38,902 - INFO - validation batch 201, loss: 1.049, 6432/6976 datapoints
2025-03-06 22:12:38,918 - INFO - Epoch 578/800 done.
2025-03-06 22:12:38,918 - INFO - Final validation performance:
Loss: 2.546, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:12:38,919 - INFO - Beginning epoch 579/800
2025-03-06 22:12:38,924 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:12:39,098 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:12:39,266 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:39,468 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:12:39,634 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:12:39,810 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:12:39,984 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:12:40,159 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:12:40,338 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:12:40,512 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:12:40,685 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:12:40,856 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:12:41,031 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:12:41,199 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:41,369 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:12:41,542 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:12:41,715 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:41,888 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:12:41,972 - INFO - validation batch 1, loss: 0.378, 32/6976 datapoints
2025-03-06 22:12:42,019 - INFO - validation batch 51, loss: 7.654, 1632/6976 datapoints
2025-03-06 22:12:42,065 - INFO - validation batch 101, loss: 1.465, 3232/6976 datapoints
2025-03-06 22:12:42,112 - INFO - validation batch 151, loss: 2.316, 4832/6976 datapoints
2025-03-06 22:12:42,161 - INFO - validation batch 201, loss: 1.055, 6432/6976 datapoints
2025-03-06 22:12:42,177 - INFO - Epoch 579/800 done.
2025-03-06 22:12:42,177 - INFO - Final validation performance:
Loss: 2.573, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:12:42,178 - INFO - Beginning epoch 580/800
2025-03-06 22:12:42,182 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:12:42,358 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:12:42,524 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:42,696 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:12:42,863 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:12:43,039 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:12:43,208 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:12:43,382 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:12:43,554 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:12:43,722 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:12:43,898 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:12:44,065 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:12:44,239 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:12:44,407 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:44,575 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:12:44,749 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:12:44,923 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:45,093 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:12:45,182 - INFO - validation batch 1, loss: 0.391, 32/6976 datapoints
2025-03-06 22:12:45,230 - INFO - validation batch 51, loss: 7.626, 1632/6976 datapoints
2025-03-06 22:12:45,276 - INFO - validation batch 101, loss: 1.483, 3232/6976 datapoints
2025-03-06 22:12:45,325 - INFO - validation batch 151, loss: 2.368, 4832/6976 datapoints
2025-03-06 22:12:45,372 - INFO - validation batch 201, loss: 1.072, 6432/6976 datapoints
2025-03-06 22:12:45,388 - INFO - Epoch 580/800 done.
2025-03-06 22:12:45,388 - INFO - Final validation performance:
Loss: 2.588, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:12:45,389 - INFO - Beginning epoch 581/800
2025-03-06 22:12:45,393 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:12:45,565 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:12:45,730 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:45,917 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:12:46,098 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:12:46,289 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:12:46,474 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:12:46,663 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:12:46,850 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:12:47,063 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:12:47,293 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:12:47,489 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:12:47,693 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:12:47,863 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:48,035 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:12:48,216 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:12:48,396 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:48,566 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:12:48,655 - INFO - validation batch 1, loss: 0.396, 32/6976 datapoints
2025-03-06 22:12:48,706 - INFO - validation batch 51, loss: 7.617, 1632/6976 datapoints
2025-03-06 22:12:48,757 - INFO - validation batch 101, loss: 1.506, 3232/6976 datapoints
2025-03-06 22:12:48,807 - INFO - validation batch 151, loss: 2.408, 4832/6976 datapoints
2025-03-06 22:12:48,860 - INFO - validation batch 201, loss: 1.090, 6432/6976 datapoints
2025-03-06 22:12:48,880 - INFO - Epoch 581/800 done.
2025-03-06 22:12:48,880 - INFO - Final validation performance:
Loss: 2.603, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:12:48,881 - INFO - Beginning epoch 582/800
2025-03-06 22:12:48,885 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:12:49,067 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:12:49,240 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:49,422 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:12:49,615 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:12:49,797 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:12:49,976 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:12:50,157 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:12:50,338 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:12:50,514 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:12:50,694 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:12:50,870 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:12:51,054 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:12:51,232 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:51,406 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:12:51,584 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:12:51,761 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:51,936 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:12:52,024 - INFO - validation batch 1, loss: 0.388, 32/6976 datapoints
2025-03-06 22:12:52,075 - INFO - validation batch 51, loss: 7.623, 1632/6976 datapoints
2025-03-06 22:12:52,125 - INFO - validation batch 101, loss: 1.547, 3232/6976 datapoints
2025-03-06 22:12:52,176 - INFO - validation batch 151, loss: 2.493, 4832/6976 datapoints
2025-03-06 22:12:52,230 - INFO - validation batch 201, loss: 1.111, 6432/6976 datapoints
2025-03-06 22:12:52,247 - INFO - Epoch 582/800 done.
2025-03-06 22:12:52,247 - INFO - Final validation performance:
Loss: 2.633, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:12:52,247 - INFO - Beginning epoch 583/800
2025-03-06 22:12:52,253 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:12:52,440 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:12:52,610 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:52,785 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:12:52,959 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:12:53,136 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:12:53,310 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:12:53,489 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:12:53,662 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:12:53,833 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:12:54,010 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:12:54,180 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:12:54,358 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:12:54,545 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:54,717 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:12:54,896 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:12:55,071 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:12:55,247 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:12:55,336 - INFO - validation batch 1, loss: 0.356, 32/6976 datapoints
2025-03-06 22:12:55,388 - INFO - validation batch 51, loss: 7.630, 1632/6976 datapoints
2025-03-06 22:12:55,440 - INFO - validation batch 101, loss: 1.624, 3232/6976 datapoints
2025-03-06 22:12:55,492 - INFO - validation batch 151, loss: 2.704, 4832/6976 datapoints
2025-03-06 22:12:55,542 - INFO - validation batch 201, loss: 1.170, 6432/6976 datapoints
2025-03-06 22:12:55,561 - INFO - Epoch 583/800 done.
2025-03-06 22:12:55,562 - INFO - Final validation performance:
Loss: 2.697, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:12:55,562 - INFO - Beginning epoch 584/800
2025-03-06 22:12:55,567 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:12:55,740 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:12:55,907 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:12:56,082 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:12:56,254 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:12:56,427 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:12:56,603 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:12:56,778 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:12:56,949 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:12:57,115 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:12:57,283 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:12:57,458 - INFO - training batch 551, loss: 0.062, 17632/28000 datapoints
2025-03-06 22:12:57,628 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-06 22:12:57,796 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:12:57,967 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:12:58,139 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:12:58,311 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:12:58,483 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:12:58,567 - INFO - validation batch 1, loss: 0.497, 32/6976 datapoints
2025-03-06 22:12:58,613 - INFO - validation batch 51, loss: 7.937, 1632/6976 datapoints
2025-03-06 22:12:58,660 - INFO - validation batch 101, loss: 1.181, 3232/6976 datapoints
2025-03-06 22:12:58,708 - INFO - validation batch 151, loss: 2.592, 4832/6976 datapoints
2025-03-06 22:12:58,755 - INFO - validation batch 201, loss: 1.078, 6432/6976 datapoints
2025-03-06 22:12:58,771 - INFO - Epoch 584/800 done.
2025-03-06 22:12:58,771 - INFO - Final validation performance:
Loss: 2.657, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:12:58,772 - INFO - Beginning epoch 585/800
2025-03-06 22:12:58,776 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:12:58,954 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:12:59,121 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:12:59,292 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:12:59,463 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:12:59,666 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:12:59,838 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:13:00,015 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:13:00,187 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:13:00,359 - INFO - training batch 451, loss: 0.014, 14432/28000 datapoints
2025-03-06 22:13:00,530 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:13:00,704 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:13:00,879 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:13:01,050 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:01,218 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:13:01,398 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:13:01,570 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:01,736 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:13:01,821 - INFO - validation batch 1, loss: 0.257, 32/6976 datapoints
2025-03-06 22:13:01,870 - INFO - validation batch 51, loss: 8.114, 1632/6976 datapoints
2025-03-06 22:13:01,918 - INFO - validation batch 101, loss: 1.284, 3232/6976 datapoints
2025-03-06 22:13:01,964 - INFO - validation batch 151, loss: 2.356, 4832/6976 datapoints
2025-03-06 22:13:02,012 - INFO - validation batch 201, loss: 0.950, 6432/6976 datapoints
2025-03-06 22:13:02,029 - INFO - Epoch 585/800 done.
2025-03-06 22:13:02,029 - INFO - Final validation performance:
Loss: 2.592, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:13:02,030 - INFO - Beginning epoch 586/800
2025-03-06 22:13:02,034 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:13:02,205 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:13:02,371 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:13:02,546 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:13:02,714 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:13:02,890 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:13:03,061 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:13:03,238 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:13:03,410 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:13:03,579 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:13:03,746 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:13:03,919 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:13:04,087 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:13:04,268 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:04,435 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:13:04,612 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:13:04,788 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:04,959 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:13:05,045 - INFO - validation batch 1, loss: 0.507, 32/6976 datapoints
2025-03-06 22:13:05,093 - INFO - validation batch 51, loss: 7.907, 1632/6976 datapoints
2025-03-06 22:13:05,147 - INFO - validation batch 101, loss: 1.388, 3232/6976 datapoints
2025-03-06 22:13:05,195 - INFO - validation batch 151, loss: 2.515, 4832/6976 datapoints
2025-03-06 22:13:05,243 - INFO - validation batch 201, loss: 1.156, 6432/6976 datapoints
2025-03-06 22:13:05,262 - INFO - Epoch 586/800 done.
2025-03-06 22:13:05,262 - INFO - Final validation performance:
Loss: 2.695, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:13:05,263 - INFO - Beginning epoch 587/800
2025-03-06 22:13:05,268 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:13:05,456 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:13:05,630 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:13:05,803 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:13:05,974 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:13:06,147 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:13:06,343 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:13:06,539 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:13:06,742 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:13:06,956 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:13:07,150 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:13:07,358 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:13:07,541 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:13:07,721 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:07,900 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:13:08,084 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:13:08,268 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:08,444 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:13:08,533 - INFO - validation batch 1, loss: 0.513, 32/6976 datapoints
2025-03-06 22:13:08,584 - INFO - validation batch 51, loss: 7.830, 1632/6976 datapoints
2025-03-06 22:13:08,637 - INFO - validation batch 101, loss: 1.351, 3232/6976 datapoints
2025-03-06 22:13:08,688 - INFO - validation batch 151, loss: 2.427, 4832/6976 datapoints
2025-03-06 22:13:08,739 - INFO - validation batch 201, loss: 1.135, 6432/6976 datapoints
2025-03-06 22:13:08,757 - INFO - Epoch 587/800 done.
2025-03-06 22:13:08,757 - INFO - Final validation performance:
Loss: 2.651, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:13:08,758 - INFO - Beginning epoch 588/800
2025-03-06 22:13:08,763 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:13:08,944 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:13:09,116 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:13:09,299 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:13:09,470 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:13:09,658 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:13:09,843 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:13:10,019 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:13:10,191 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:13:10,366 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:13:10,534 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:13:10,704 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:13:10,879 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:13:11,050 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:11,237 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:13:11,452 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:13:11,646 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:11,825 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:13:11,912 - INFO - validation batch 1, loss: 0.503, 32/6976 datapoints
2025-03-06 22:13:11,958 - INFO - validation batch 51, loss: 7.823, 1632/6976 datapoints
2025-03-06 22:13:12,005 - INFO - validation batch 101, loss: 1.385, 3232/6976 datapoints
2025-03-06 22:13:12,052 - INFO - validation batch 151, loss: 2.454, 4832/6976 datapoints
2025-03-06 22:13:12,099 - INFO - validation batch 201, loss: 1.116, 6432/6976 datapoints
2025-03-06 22:13:12,115 - INFO - Epoch 588/800 done.
2025-03-06 22:13:12,115 - INFO - Final validation performance:
Loss: 2.656, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:13:12,116 - INFO - Beginning epoch 589/800
2025-03-06 22:13:12,121 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:13:12,303 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:13:12,468 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:13:12,645 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:13:12,813 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:13:12,990 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:13:13,168 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:13:13,348 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:13:13,520 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:13:13,689 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:13:13,858 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:13:14,027 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:13:14,197 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:13:14,366 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:14,533 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:13:14,708 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:13:14,886 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:15,055 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:13:15,145 - INFO - validation batch 1, loss: 0.493, 32/6976 datapoints
2025-03-06 22:13:15,193 - INFO - validation batch 51, loss: 7.815, 1632/6976 datapoints
2025-03-06 22:13:15,240 - INFO - validation batch 101, loss: 1.399, 3232/6976 datapoints
2025-03-06 22:13:15,286 - INFO - validation batch 151, loss: 2.449, 4832/6976 datapoints
2025-03-06 22:13:15,332 - INFO - validation batch 201, loss: 1.118, 6432/6976 datapoints
2025-03-06 22:13:15,348 - INFO - Epoch 589/800 done.
2025-03-06 22:13:15,348 - INFO - Final validation performance:
Loss: 2.655, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:13:15,349 - INFO - Beginning epoch 590/800
2025-03-06 22:13:15,353 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:13:15,523 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:13:15,689 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:13:15,865 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:13:16,035 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:13:16,213 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:13:16,390 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:13:16,568 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:13:16,759 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:13:16,983 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:13:17,168 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:13:17,337 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:13:17,507 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:13:17,676 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:17,845 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:13:18,021 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:13:18,192 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:18,363 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:13:18,448 - INFO - validation batch 1, loss: 0.484, 32/6976 datapoints
2025-03-06 22:13:18,497 - INFO - validation batch 51, loss: 7.833, 1632/6976 datapoints
2025-03-06 22:13:18,547 - INFO - validation batch 101, loss: 1.434, 3232/6976 datapoints
2025-03-06 22:13:18,594 - INFO - validation batch 151, loss: 2.461, 4832/6976 datapoints
2025-03-06 22:13:18,641 - INFO - validation batch 201, loss: 1.118, 6432/6976 datapoints
2025-03-06 22:13:18,657 - INFO - Epoch 590/800 done.
2025-03-06 22:13:18,657 - INFO - Final validation performance:
Loss: 2.666, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:13:18,657 - INFO - Beginning epoch 591/800
2025-03-06 22:13:18,662 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:13:18,834 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:13:19,002 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:13:19,177 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:13:19,345 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:13:19,518 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:13:19,685 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:13:19,889 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:13:20,057 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:13:20,225 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:13:20,399 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:13:20,570 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:13:20,746 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:13:20,921 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:21,093 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:13:21,279 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:13:21,464 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:21,639 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:13:21,724 - INFO - validation batch 1, loss: 0.448, 32/6976 datapoints
2025-03-06 22:13:21,772 - INFO - validation batch 51, loss: 7.864, 1632/6976 datapoints
2025-03-06 22:13:21,819 - INFO - validation batch 101, loss: 1.534, 3232/6976 datapoints
2025-03-06 22:13:21,866 - INFO - validation batch 151, loss: 2.612, 4832/6976 datapoints
2025-03-06 22:13:21,917 - INFO - validation batch 201, loss: 1.139, 6432/6976 datapoints
2025-03-06 22:13:21,933 - INFO - Epoch 591/800 done.
2025-03-06 22:13:21,933 - INFO - Final validation performance:
Loss: 2.719, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:13:21,934 - INFO - Beginning epoch 592/800
2025-03-06 22:13:21,938 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:13:22,111 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:13:22,278 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:13:22,488 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:13:22,656 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:13:22,831 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:13:23,006 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:13:23,184 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:13:23,356 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:13:23,523 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:13:23,692 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:13:23,860 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:13:24,034 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:13:24,205 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:24,376 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:13:24,551 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:13:24,725 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:24,905 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:13:24,989 - INFO - validation batch 1, loss: 1.203, 32/6976 datapoints
2025-03-06 22:13:25,036 - INFO - validation batch 51, loss: 8.504, 1632/6976 datapoints
2025-03-06 22:13:25,082 - INFO - validation batch 101, loss: 1.818, 3232/6976 datapoints
2025-03-06 22:13:25,130 - INFO - validation batch 151, loss: 3.516, 4832/6976 datapoints
2025-03-06 22:13:25,183 - INFO - validation batch 201, loss: 1.433, 6432/6976 datapoints
2025-03-06 22:13:25,199 - INFO - Epoch 592/800 done.
2025-03-06 22:13:25,199 - INFO - Final validation performance:
Loss: 3.295, top-1 acc: 0.845top-5 acc: 0.845
2025-03-06 22:13:25,200 - INFO - Beginning epoch 593/800
2025-03-06 22:13:25,204 - INFO - training batch 1, loss: 0.346, 32/28000 datapoints
2025-03-06 22:13:25,377 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:13:25,541 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:13:25,710 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-06 22:13:25,880 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-06 22:13:26,052 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:13:26,226 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-06 22:13:26,409 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:13:26,579 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:13:26,753 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:13:26,927 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:13:27,098 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:13:27,269 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:13:27,439 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:27,610 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:13:27,792 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:13:27,972 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-06 22:13:28,142 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:13:28,233 - INFO - validation batch 1, loss: 0.268, 32/6976 datapoints
2025-03-06 22:13:28,280 - INFO - validation batch 51, loss: 7.853, 1632/6976 datapoints
2025-03-06 22:13:28,334 - INFO - validation batch 101, loss: 1.706, 3232/6976 datapoints
2025-03-06 22:13:28,384 - INFO - validation batch 151, loss: 2.344, 4832/6976 datapoints
2025-03-06 22:13:28,436 - INFO - validation batch 201, loss: 1.015, 6432/6976 datapoints
2025-03-06 22:13:28,452 - INFO - Epoch 593/800 done.
2025-03-06 22:13:28,452 - INFO - Final validation performance:
Loss: 2.637, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:13:28,453 - INFO - Beginning epoch 594/800
2025-03-06 22:13:28,459 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:13:28,636 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:13:28,808 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:13:28,992 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:13:29,166 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:13:29,345 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:13:29,517 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:13:29,699 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:13:29,897 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:13:30,072 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:13:30,246 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:13:30,419 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:13:30,595 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:13:30,766 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:30,942 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:13:31,122 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:13:31,300 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:31,472 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:13:31,561 - INFO - validation batch 1, loss: 0.444, 32/6976 datapoints
2025-03-06 22:13:31,618 - INFO - validation batch 51, loss: 7.878, 1632/6976 datapoints
2025-03-06 22:13:31,672 - INFO - validation batch 101, loss: 1.575, 3232/6976 datapoints
2025-03-06 22:13:31,724 - INFO - validation batch 151, loss: 2.336, 4832/6976 datapoints
2025-03-06 22:13:31,775 - INFO - validation batch 201, loss: 1.094, 6432/6976 datapoints
2025-03-06 22:13:31,791 - INFO - Epoch 594/800 done.
2025-03-06 22:13:31,791 - INFO - Final validation performance:
Loss: 2.665, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:13:31,791 - INFO - Beginning epoch 595/800
2025-03-06 22:13:31,796 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:13:31,982 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:13:32,153 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:13:32,331 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:13:32,515 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:13:32,694 - INFO - training batch 251, loss: 0.024, 8032/28000 datapoints
2025-03-06 22:13:32,866 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:13:33,049 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:13:33,224 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:13:33,402 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:13:33,577 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:13:33,747 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:13:33,928 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:13:34,111 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:34,283 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:13:34,464 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:13:34,644 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:34,816 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:13:34,908 - INFO - validation batch 1, loss: 0.333, 32/6976 datapoints
2025-03-06 22:13:34,958 - INFO - validation batch 51, loss: 7.946, 1632/6976 datapoints
2025-03-06 22:13:35,010 - INFO - validation batch 101, loss: 1.517, 3232/6976 datapoints
2025-03-06 22:13:35,062 - INFO - validation batch 151, loss: 2.353, 4832/6976 datapoints
2025-03-06 22:13:35,109 - INFO - validation batch 201, loss: 1.103, 6432/6976 datapoints
2025-03-06 22:13:35,125 - INFO - Epoch 595/800 done.
2025-03-06 22:13:35,126 - INFO - Final validation performance:
Loss: 2.650, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:13:35,126 - INFO - Beginning epoch 596/800
2025-03-06 22:13:35,131 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:13:35,308 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:13:35,479 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:13:35,650 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:13:35,820 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:13:36,000 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:13:36,170 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:13:36,345 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:13:36,519 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:13:36,699 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:13:36,869 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:13:37,039 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:13:37,213 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:13:37,382 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:37,552 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:13:37,728 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:13:37,919 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:38,087 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:13:38,174 - INFO - validation batch 1, loss: 0.336, 32/6976 datapoints
2025-03-06 22:13:38,220 - INFO - validation batch 51, loss: 7.918, 1632/6976 datapoints
2025-03-06 22:13:38,266 - INFO - validation batch 101, loss: 1.531, 3232/6976 datapoints
2025-03-06 22:13:38,313 - INFO - validation batch 151, loss: 2.409, 4832/6976 datapoints
2025-03-06 22:13:38,361 - INFO - validation batch 201, loss: 1.089, 6432/6976 datapoints
2025-03-06 22:13:38,381 - INFO - Epoch 596/800 done.
2025-03-06 22:13:38,381 - INFO - Final validation performance:
Loss: 2.656, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:13:38,381 - INFO - Beginning epoch 597/800
2025-03-06 22:13:38,386 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:13:38,560 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:13:38,728 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:13:38,902 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:13:39,074 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:13:39,253 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:13:39,434 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:13:39,611 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:13:39,782 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:13:39,972 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:13:40,150 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:13:40,320 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:13:40,495 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:13:40,665 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:40,836 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:13:41,014 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:13:41,189 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:41,359 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:13:41,443 - INFO - validation batch 1, loss: 0.355, 32/6976 datapoints
2025-03-06 22:13:41,492 - INFO - validation batch 51, loss: 7.919, 1632/6976 datapoints
2025-03-06 22:13:41,540 - INFO - validation batch 101, loss: 1.532, 3232/6976 datapoints
2025-03-06 22:13:41,589 - INFO - validation batch 151, loss: 2.465, 4832/6976 datapoints
2025-03-06 22:13:41,638 - INFO - validation batch 201, loss: 1.104, 6432/6976 datapoints
2025-03-06 22:13:41,654 - INFO - Epoch 597/800 done.
2025-03-06 22:13:41,655 - INFO - Final validation performance:
Loss: 2.675, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:13:41,655 - INFO - Beginning epoch 598/800
2025-03-06 22:13:41,660 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:13:41,830 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:13:42,004 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:13:42,176 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:13:42,342 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:13:42,519 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:13:42,689 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:13:42,865 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:13:43,039 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:13:43,217 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:13:43,412 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:13:43,616 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:13:43,813 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:13:44,010 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:44,193 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:13:44,371 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:13:44,550 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:44,723 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:13:44,809 - INFO - validation batch 1, loss: 0.361, 32/6976 datapoints
2025-03-06 22:13:44,856 - INFO - validation batch 51, loss: 7.921, 1632/6976 datapoints
2025-03-06 22:13:44,905 - INFO - validation batch 101, loss: 1.536, 3232/6976 datapoints
2025-03-06 22:13:44,953 - INFO - validation batch 151, loss: 2.496, 4832/6976 datapoints
2025-03-06 22:13:45,004 - INFO - validation batch 201, loss: 1.119, 6432/6976 datapoints
2025-03-06 22:13:45,020 - INFO - Epoch 598/800 done.
2025-03-06 22:13:45,020 - INFO - Final validation performance:
Loss: 2.687, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:13:45,021 - INFO - Beginning epoch 599/800
2025-03-06 22:13:45,025 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:13:45,208 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:13:45,380 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:13:45,557 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:13:45,728 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:13:45,906 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:13:46,077 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:13:46,253 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:13:46,426 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:13:46,599 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:13:46,773 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:13:46,947 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:13:47,121 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:13:47,290 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:47,456 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:13:47,630 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:13:47,810 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:47,989 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:13:48,077 - INFO - validation batch 1, loss: 0.371, 32/6976 datapoints
2025-03-06 22:13:48,131 - INFO - validation batch 51, loss: 7.922, 1632/6976 datapoints
2025-03-06 22:13:48,182 - INFO - validation batch 101, loss: 1.556, 3232/6976 datapoints
2025-03-06 22:13:48,234 - INFO - validation batch 151, loss: 2.547, 4832/6976 datapoints
2025-03-06 22:13:48,282 - INFO - validation batch 201, loss: 1.127, 6432/6976 datapoints
2025-03-06 22:13:48,298 - INFO - Epoch 599/800 done.
2025-03-06 22:13:48,298 - INFO - Final validation performance:
Loss: 2.705, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:13:48,299 - INFO - Beginning epoch 600/800
2025-03-06 22:13:48,304 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:13:48,487 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:13:48,664 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:13:48,838 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:13:49,015 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:13:49,194 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:13:49,370 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:13:49,548 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:13:49,721 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:13:49,898 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:13:50,089 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:13:50,266 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:13:50,444 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:13:50,619 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:50,791 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:13:50,970 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:13:51,150 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:51,327 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:13:51,416 - INFO - validation batch 1, loss: 0.284, 32/6976 datapoints
2025-03-06 22:13:51,466 - INFO - validation batch 51, loss: 7.802, 1632/6976 datapoints
2025-03-06 22:13:51,521 - INFO - validation batch 101, loss: 1.665, 3232/6976 datapoints
2025-03-06 22:13:51,573 - INFO - validation batch 151, loss: 2.856, 4832/6976 datapoints
2025-03-06 22:13:51,626 - INFO - validation batch 201, loss: 1.162, 6432/6976 datapoints
2025-03-06 22:13:51,642 - INFO - Epoch 600/800 done.
2025-03-06 22:13:51,642 - INFO - Final validation performance:
Loss: 2.754, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:13:51,643 - INFO - Beginning epoch 601/800
2025-03-06 22:13:51,647 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:13:51,824 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:13:51,997 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:13:52,175 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:13:52,345 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:13:52,528 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:13:52,703 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:13:52,887 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:13:53,060 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:13:53,243 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:13:53,419 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:13:53,590 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:13:53,766 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:13:53,950 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:54,120 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:13:54,301 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:13:54,481 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:54,652 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:13:54,748 - INFO - validation batch 1, loss: 0.273, 32/6976 datapoints
2025-03-06 22:13:54,801 - INFO - validation batch 51, loss: 7.891, 1632/6976 datapoints
2025-03-06 22:13:54,854 - INFO - validation batch 101, loss: 1.702, 3232/6976 datapoints
2025-03-06 22:13:54,912 - INFO - validation batch 151, loss: 2.876, 4832/6976 datapoints
2025-03-06 22:13:54,959 - INFO - validation batch 201, loss: 1.171, 6432/6976 datapoints
2025-03-06 22:13:54,975 - INFO - Epoch 601/800 done.
2025-03-06 22:13:54,976 - INFO - Final validation performance:
Loss: 2.783, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:13:54,976 - INFO - Beginning epoch 602/800
2025-03-06 22:13:54,981 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:13:55,167 - INFO - training batch 51, loss: 0.310, 1632/28000 datapoints
2025-03-06 22:13:55,337 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:13:55,508 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:13:55,676 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 22:13:55,853 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:13:56,029 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:13:56,204 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:13:56,374 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:13:56,545 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:13:56,715 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 22:13:56,892 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:13:57,063 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:13:57,235 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:13:57,401 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:13:57,576 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:13:57,751 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:13:57,927 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:13:58,015 - INFO - validation batch 1, loss: 0.226, 32/6976 datapoints
2025-03-06 22:13:58,062 - INFO - validation batch 51, loss: 7.955, 1632/6976 datapoints
2025-03-06 22:13:58,109 - INFO - validation batch 101, loss: 1.570, 3232/6976 datapoints
2025-03-06 22:13:58,156 - INFO - validation batch 151, loss: 2.437, 4832/6976 datapoints
2025-03-06 22:13:58,205 - INFO - validation batch 201, loss: 1.111, 6432/6976 datapoints
2025-03-06 22:13:58,221 - INFO - Epoch 602/800 done.
2025-03-06 22:13:58,222 - INFO - Final validation performance:
Loss: 2.660, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:13:58,222 - INFO - Beginning epoch 603/800
2025-03-06 22:13:58,227 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:13:58,399 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-06 22:13:58,572 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:13:58,748 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:13:58,921 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:13:59,098 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:13:59,272 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:13:59,450 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:13:59,618 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:13:59,788 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:13:59,961 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:00,136 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:14:00,325 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:14:00,496 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:14:00,672 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:00,848 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:14:01,021 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:01,192 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:14:01,278 - INFO - validation batch 1, loss: 0.158, 32/6976 datapoints
2025-03-06 22:14:01,326 - INFO - validation batch 51, loss: 7.910, 1632/6976 datapoints
2025-03-06 22:14:01,373 - INFO - validation batch 101, loss: 1.520, 3232/6976 datapoints
2025-03-06 22:14:01,419 - INFO - validation batch 151, loss: 2.420, 4832/6976 datapoints
2025-03-06 22:14:01,465 - INFO - validation batch 201, loss: 1.185, 6432/6976 datapoints
2025-03-06 22:14:01,481 - INFO - Epoch 603/800 done.
2025-03-06 22:14:01,482 - INFO - Final validation performance:
Loss: 2.639, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:14:01,482 - INFO - Beginning epoch 604/800
2025-03-06 22:14:01,487 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:14:01,659 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:14:01,833 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:14:02,012 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:14:02,185 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:02,362 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:02,541 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:14:02,719 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:14:02,893 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:14:03,065 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:14:03,234 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:03,404 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:14:03,575 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:14:03,744 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:03,914 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:04,091 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:14:04,266 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:04,434 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:14:04,522 - INFO - validation batch 1, loss: 0.141, 32/6976 datapoints
2025-03-06 22:14:04,568 - INFO - validation batch 51, loss: 7.967, 1632/6976 datapoints
2025-03-06 22:14:04,615 - INFO - validation batch 101, loss: 1.508, 3232/6976 datapoints
2025-03-06 22:14:04,661 - INFO - validation batch 151, loss: 2.342, 4832/6976 datapoints
2025-03-06 22:14:04,707 - INFO - validation batch 201, loss: 1.167, 6432/6976 datapoints
2025-03-06 22:14:04,723 - INFO - Epoch 604/800 done.
2025-03-06 22:14:04,723 - INFO - Final validation performance:
Loss: 2.625, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:14:04,724 - INFO - Beginning epoch 605/800
2025-03-06 22:14:04,729 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:14:04,909 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:14:05,119 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:14:05,302 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:14:05,479 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:05,659 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:05,839 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:14:06,028 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:14:06,202 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:14:06,379 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:14:06,556 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:06,724 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:14:06,906 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:14:07,077 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:07,246 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:07,423 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:14:07,596 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:07,765 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:14:07,858 - INFO - validation batch 1, loss: 0.190, 32/6976 datapoints
2025-03-06 22:14:07,909 - INFO - validation batch 51, loss: 7.970, 1632/6976 datapoints
2025-03-06 22:14:07,961 - INFO - validation batch 101, loss: 1.535, 3232/6976 datapoints
2025-03-06 22:14:08,014 - INFO - validation batch 151, loss: 2.417, 4832/6976 datapoints
2025-03-06 22:14:08,063 - INFO - validation batch 201, loss: 1.190, 6432/6976 datapoints
2025-03-06 22:14:08,081 - INFO - Epoch 605/800 done.
2025-03-06 22:14:08,081 - INFO - Final validation performance:
Loss: 2.660, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:14:08,082 - INFO - Beginning epoch 606/800
2025-03-06 22:14:08,087 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:14:08,270 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:14:08,445 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:14:08,625 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:14:08,799 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:08,983 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:09,158 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:14:09,347 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:14:09,520 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:14:09,692 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:14:09,870 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:10,044 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:14:10,229 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:14:10,418 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:10,591 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:10,769 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:14:10,953 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:11,124 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:14:11,215 - INFO - validation batch 1, loss: 0.164, 32/6976 datapoints
2025-03-06 22:14:11,262 - INFO - validation batch 51, loss: 8.020, 1632/6976 datapoints
2025-03-06 22:14:11,307 - INFO - validation batch 101, loss: 1.540, 3232/6976 datapoints
2025-03-06 22:14:11,354 - INFO - validation batch 151, loss: 2.416, 4832/6976 datapoints
2025-03-06 22:14:11,400 - INFO - validation batch 201, loss: 1.163, 6432/6976 datapoints
2025-03-06 22:14:11,417 - INFO - Epoch 606/800 done.
2025-03-06 22:14:11,417 - INFO - Final validation performance:
Loss: 2.661, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:14:11,418 - INFO - Beginning epoch 607/800
2025-03-06 22:14:11,422 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:14:11,593 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:14:11,762 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:14:11,940 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:14:12,132 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:12,306 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:12,480 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:14:12,666 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:14:12,841 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:14:13,021 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:14:13,214 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:13,383 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:14:13,557 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:14:13,727 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:13,903 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:14,077 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:14:14,256 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:14,425 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:14:14,512 - INFO - validation batch 1, loss: 0.180, 32/6976 datapoints
2025-03-06 22:14:14,560 - INFO - validation batch 51, loss: 8.046, 1632/6976 datapoints
2025-03-06 22:14:14,607 - INFO - validation batch 101, loss: 1.541, 3232/6976 datapoints
2025-03-06 22:14:14,653 - INFO - validation batch 151, loss: 2.426, 4832/6976 datapoints
2025-03-06 22:14:14,701 - INFO - validation batch 201, loss: 1.166, 6432/6976 datapoints
2025-03-06 22:14:14,717 - INFO - Epoch 607/800 done.
2025-03-06 22:14:14,717 - INFO - Final validation performance:
Loss: 2.672, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:14:14,718 - INFO - Beginning epoch 608/800
2025-03-06 22:14:14,722 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:14:14,901 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:14:15,073 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:14:15,252 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:14:15,426 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:15,600 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:15,774 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:14:15,959 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:14:16,127 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:14:16,297 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:14:16,469 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:16,640 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:14:16,815 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:14:16,992 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:17,162 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:17,335 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:14:17,511 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:17,681 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:14:17,767 - INFO - validation batch 1, loss: 0.219, 32/6976 datapoints
2025-03-06 22:14:17,816 - INFO - validation batch 51, loss: 8.077, 1632/6976 datapoints
2025-03-06 22:14:17,862 - INFO - validation batch 101, loss: 1.560, 3232/6976 datapoints
2025-03-06 22:14:17,911 - INFO - validation batch 151, loss: 2.437, 4832/6976 datapoints
2025-03-06 22:14:17,959 - INFO - validation batch 201, loss: 1.167, 6432/6976 datapoints
2025-03-06 22:14:17,976 - INFO - Epoch 608/800 done.
2025-03-06 22:14:17,976 - INFO - Final validation performance:
Loss: 2.692, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:14:17,976 - INFO - Beginning epoch 609/800
2025-03-06 22:14:17,981 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:14:18,156 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:14:18,336 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:14:18,515 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:14:18,690 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:18,984 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:19,181 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:14:19,363 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:14:19,532 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:14:19,702 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:14:19,877 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:20,045 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:14:20,217 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:14:20,409 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:20,581 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:20,758 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:14:20,938 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:21,109 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:14:21,197 - INFO - validation batch 1, loss: 0.148, 32/6976 datapoints
2025-03-06 22:14:21,245 - INFO - validation batch 51, loss: 8.087, 1632/6976 datapoints
2025-03-06 22:14:21,292 - INFO - validation batch 101, loss: 1.649, 3232/6976 datapoints
2025-03-06 22:14:21,339 - INFO - validation batch 151, loss: 2.567, 4832/6976 datapoints
2025-03-06 22:14:21,387 - INFO - validation batch 201, loss: 1.191, 6432/6976 datapoints
2025-03-06 22:14:21,404 - INFO - Epoch 609/800 done.
2025-03-06 22:14:21,404 - INFO - Final validation performance:
Loss: 2.729, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:14:21,404 - INFO - Beginning epoch 610/800
2025-03-06 22:14:21,409 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:14:21,585 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:14:21,762 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:14:21,938 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:14:22,109 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:22,286 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:22,465 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:14:22,648 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:14:22,858 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:14:23,038 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:14:23,216 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:23,393 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:14:23,571 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:14:23,746 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:23,922 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:24,103 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:14:24,286 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:24,460 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:14:24,547 - INFO - validation batch 1, loss: 0.297, 32/6976 datapoints
2025-03-06 22:14:24,607 - INFO - validation batch 51, loss: 8.187, 1632/6976 datapoints
2025-03-06 22:14:24,659 - INFO - validation batch 101, loss: 1.721, 3232/6976 datapoints
2025-03-06 22:14:24,706 - INFO - validation batch 151, loss: 2.643, 4832/6976 datapoints
2025-03-06 22:14:24,755 - INFO - validation batch 201, loss: 1.223, 6432/6976 datapoints
2025-03-06 22:14:24,771 - INFO - Epoch 610/800 done.
2025-03-06 22:14:24,771 - INFO - Final validation performance:
Loss: 2.814, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:14:24,772 - INFO - Beginning epoch 611/800
2025-03-06 22:14:24,777 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:14:24,952 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:14:25,128 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:14:25,305 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:14:25,476 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:25,652 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:25,828 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:14:26,007 - INFO - training batch 351, loss: 0.024, 11232/28000 datapoints
2025-03-06 22:14:26,177 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:14:26,346 - INFO - training batch 451, loss: 0.011, 14432/28000 datapoints
2025-03-06 22:14:26,520 - INFO - training batch 501, loss: 0.039, 16032/28000 datapoints
2025-03-06 22:14:26,694 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:14:26,867 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:14:27,039 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:27,208 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:27,385 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:14:27,563 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:27,731 - INFO - training batch 851, loss: 0.025, 27232/28000 datapoints
2025-03-06 22:14:27,819 - INFO - validation batch 1, loss: 0.476, 32/6976 datapoints
2025-03-06 22:14:27,874 - INFO - validation batch 51, loss: 8.124, 1632/6976 datapoints
2025-03-06 22:14:27,926 - INFO - validation batch 101, loss: 1.820, 3232/6976 datapoints
2025-03-06 22:14:27,977 - INFO - validation batch 151, loss: 2.495, 4832/6976 datapoints
2025-03-06 22:14:28,026 - INFO - validation batch 201, loss: 1.250, 6432/6976 datapoints
2025-03-06 22:14:28,042 - INFO - Epoch 611/800 done.
2025-03-06 22:14:28,042 - INFO - Final validation performance:
Loss: 2.833, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:14:28,043 - INFO - Beginning epoch 612/800
2025-03-06 22:14:28,047 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:14:28,229 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:14:28,404 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:14:28,586 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:14:28,763 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:28,945 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:14:29,124 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:14:29,309 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:14:29,483 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:14:29,661 - INFO - training batch 451, loss: 0.021, 14432/28000 datapoints
2025-03-06 22:14:29,835 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:30,008 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:14:30,184 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:14:30,359 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:30,557 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:30,738 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:14:30,923 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:31,099 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:14:31,191 - INFO - validation batch 1, loss: 0.354, 32/6976 datapoints
2025-03-06 22:14:31,242 - INFO - validation batch 51, loss: 8.161, 1632/6976 datapoints
2025-03-06 22:14:31,292 - INFO - validation batch 101, loss: 1.608, 3232/6976 datapoints
2025-03-06 22:14:31,343 - INFO - validation batch 151, loss: 2.387, 4832/6976 datapoints
2025-03-06 22:14:31,393 - INFO - validation batch 201, loss: 1.205, 6432/6976 datapoints
2025-03-06 22:14:31,411 - INFO - Epoch 612/800 done.
2025-03-06 22:14:31,412 - INFO - Final validation performance:
Loss: 2.743, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:14:31,412 - INFO - Beginning epoch 613/800
2025-03-06 22:14:31,417 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:14:31,593 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:14:31,768 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:14:31,945 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 22:14:32,120 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:32,298 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:32,471 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:14:32,655 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:14:32,825 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:14:33,000 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:14:33,174 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:33,344 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:14:33,519 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:14:33,692 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:33,861 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:34,065 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:14:34,290 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:34,460 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:14:34,549 - INFO - validation batch 1, loss: 0.377, 32/6976 datapoints
2025-03-06 22:14:34,598 - INFO - validation batch 51, loss: 8.093, 1632/6976 datapoints
2025-03-06 22:14:34,644 - INFO - validation batch 101, loss: 1.628, 3232/6976 datapoints
2025-03-06 22:14:34,691 - INFO - validation batch 151, loss: 2.349, 4832/6976 datapoints
2025-03-06 22:14:34,740 - INFO - validation batch 201, loss: 1.213, 6432/6976 datapoints
2025-03-06 22:14:34,757 - INFO - Epoch 613/800 done.
2025-03-06 22:14:34,757 - INFO - Final validation performance:
Loss: 2.732, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:14:34,758 - INFO - Beginning epoch 614/800
2025-03-06 22:14:34,762 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:14:34,936 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:14:35,108 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:14:35,290 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:14:35,462 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:35,639 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:35,815 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:14:35,998 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:14:36,168 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:14:36,339 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:14:36,511 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:36,681 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:14:36,854 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:14:37,030 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:37,208 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:37,410 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:14:37,592 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:37,766 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:14:37,853 - INFO - validation batch 1, loss: 0.314, 32/6976 datapoints
2025-03-06 22:14:37,912 - INFO - validation batch 51, loss: 8.192, 1632/6976 datapoints
2025-03-06 22:14:37,958 - INFO - validation batch 101, loss: 1.582, 3232/6976 datapoints
2025-03-06 22:14:38,003 - INFO - validation batch 151, loss: 2.369, 4832/6976 datapoints
2025-03-06 22:14:38,049 - INFO - validation batch 201, loss: 1.134, 6432/6976 datapoints
2025-03-06 22:14:38,065 - INFO - Epoch 614/800 done.
2025-03-06 22:14:38,065 - INFO - Final validation performance:
Loss: 2.718, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:14:38,066 - INFO - Beginning epoch 615/800
2025-03-06 22:14:38,070 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:14:38,248 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:14:38,422 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:14:38,595 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:14:38,777 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:38,955 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:39,130 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:14:39,316 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:14:39,488 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:14:39,659 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:14:39,904 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:40,075 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:14:40,246 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:14:40,418 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:40,609 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:40,788 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:14:40,973 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:41,145 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:14:41,233 - INFO - validation batch 1, loss: 0.309, 32/6976 datapoints
2025-03-06 22:14:41,279 - INFO - validation batch 51, loss: 8.171, 1632/6976 datapoints
2025-03-06 22:14:41,327 - INFO - validation batch 101, loss: 1.614, 3232/6976 datapoints
2025-03-06 22:14:41,375 - INFO - validation batch 151, loss: 2.453, 4832/6976 datapoints
2025-03-06 22:14:41,421 - INFO - validation batch 201, loss: 1.158, 6432/6976 datapoints
2025-03-06 22:14:41,437 - INFO - Epoch 615/800 done.
2025-03-06 22:14:41,438 - INFO - Final validation performance:
Loss: 2.741, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:14:41,438 - INFO - Beginning epoch 616/800
2025-03-06 22:14:41,442 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:14:41,616 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:14:41,788 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:14:41,967 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:14:42,139 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:42,316 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:42,488 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:14:42,675 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:14:42,848 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:14:43,024 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:14:43,199 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:43,368 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:14:43,540 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:14:43,709 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:43,884 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:44,060 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:14:44,240 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:44,416 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:14:44,503 - INFO - validation batch 1, loss: 0.319, 32/6976 datapoints
2025-03-06 22:14:44,549 - INFO - validation batch 51, loss: 8.171, 1632/6976 datapoints
2025-03-06 22:14:44,595 - INFO - validation batch 101, loss: 1.639, 3232/6976 datapoints
2025-03-06 22:14:44,646 - INFO - validation batch 151, loss: 2.527, 4832/6976 datapoints
2025-03-06 22:14:44,695 - INFO - validation batch 201, loss: 1.177, 6432/6976 datapoints
2025-03-06 22:14:44,710 - INFO - Epoch 616/800 done.
2025-03-06 22:14:44,710 - INFO - Final validation performance:
Loss: 2.767, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:14:44,711 - INFO - Beginning epoch 617/800
2025-03-06 22:14:44,716 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:14:44,893 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:14:45,067 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:14:45,249 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:14:45,421 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:45,600 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:45,774 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:14:45,958 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:14:46,129 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:14:46,302 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:14:46,473 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:46,649 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:14:46,819 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:14:46,999 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:47,170 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:47,346 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:14:47,525 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:47,696 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:14:47,783 - INFO - validation batch 1, loss: 0.329, 32/6976 datapoints
2025-03-06 22:14:47,831 - INFO - validation batch 51, loss: 8.188, 1632/6976 datapoints
2025-03-06 22:14:47,884 - INFO - validation batch 101, loss: 1.665, 3232/6976 datapoints
2025-03-06 22:14:47,939 - INFO - validation batch 151, loss: 2.564, 4832/6976 datapoints
2025-03-06 22:14:47,990 - INFO - validation batch 201, loss: 1.189, 6432/6976 datapoints
2025-03-06 22:14:48,007 - INFO - Epoch 617/800 done.
2025-03-06 22:14:48,007 - INFO - Final validation performance:
Loss: 2.787, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:14:48,008 - INFO - Beginning epoch 618/800
2025-03-06 22:14:48,013 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:14:48,189 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:14:48,362 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:14:48,540 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:14:48,714 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:48,894 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:49,071 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:14:49,251 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:14:49,424 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:14:49,594 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:14:49,764 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:49,938 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:14:50,111 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:14:50,285 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:50,459 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:50,652 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:14:50,837 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:51,015 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:14:51,104 - INFO - validation batch 1, loss: 0.328, 32/6976 datapoints
2025-03-06 22:14:51,151 - INFO - validation batch 51, loss: 8.219, 1632/6976 datapoints
2025-03-06 22:14:51,200 - INFO - validation batch 101, loss: 1.701, 3232/6976 datapoints
2025-03-06 22:14:51,247 - INFO - validation batch 151, loss: 2.622, 4832/6976 datapoints
2025-03-06 22:14:51,294 - INFO - validation batch 201, loss: 1.194, 6432/6976 datapoints
2025-03-06 22:14:51,310 - INFO - Epoch 618/800 done.
2025-03-06 22:14:51,311 - INFO - Final validation performance:
Loss: 2.813, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:14:51,311 - INFO - Beginning epoch 619/800
2025-03-06 22:14:51,316 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:14:51,490 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:14:51,663 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:14:51,842 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:14:52,018 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:52,196 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:52,372 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:14:52,552 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:14:52,729 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:14:52,904 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:14:53,080 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:14:53,254 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:14:53,428 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:14:53,599 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:53,769 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:14:53,954 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:14:54,135 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:54,308 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:14:54,395 - INFO - validation batch 1, loss: 0.260, 32/6976 datapoints
2025-03-06 22:14:54,442 - INFO - validation batch 51, loss: 8.177, 1632/6976 datapoints
2025-03-06 22:14:54,490 - INFO - validation batch 101, loss: 1.786, 3232/6976 datapoints
2025-03-06 22:14:54,537 - INFO - validation batch 151, loss: 2.848, 4832/6976 datapoints
2025-03-06 22:14:54,584 - INFO - validation batch 201, loss: 1.237, 6432/6976 datapoints
2025-03-06 22:14:54,600 - INFO - Epoch 619/800 done.
2025-03-06 22:14:54,600 - INFO - Final validation performance:
Loss: 2.862, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:14:54,601 - INFO - Beginning epoch 620/800
2025-03-06 22:14:54,605 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:14:54,779 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:14:54,954 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:14:55,138 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:14:55,321 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:14:55,497 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:14:55,674 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:14:55,855 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:14:56,031 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:14:56,202 - INFO - training batch 451, loss: 0.459, 14432/28000 datapoints
2025-03-06 22:14:56,378 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:14:56,551 - INFO - training batch 551, loss: 0.058, 17632/28000 datapoints
2025-03-06 22:14:56,726 - INFO - training batch 601, loss: 0.514, 19232/28000 datapoints
2025-03-06 22:14:56,908 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:14:57,082 - INFO - training batch 701, loss: 0.048, 22432/28000 datapoints
2025-03-06 22:14:57,262 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:14:57,444 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:14:57,614 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:14:57,702 - INFO - validation batch 1, loss: 0.759, 32/6976 datapoints
2025-03-06 22:14:57,749 - INFO - validation batch 51, loss: 8.503, 1632/6976 datapoints
2025-03-06 22:14:57,797 - INFO - validation batch 101, loss: 1.816, 3232/6976 datapoints
2025-03-06 22:14:57,844 - INFO - validation batch 151, loss: 2.292, 4832/6976 datapoints
2025-03-06 22:14:57,896 - INFO - validation batch 201, loss: 1.326, 6432/6976 datapoints
2025-03-06 22:14:57,918 - INFO - Epoch 620/800 done.
2025-03-06 22:14:57,918 - INFO - Final validation performance:
Loss: 2.939, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:14:57,919 - INFO - Beginning epoch 621/800
2025-03-06 22:14:57,923 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:14:58,098 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:14:58,274 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:14:58,449 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:14:58,624 - INFO - training batch 201, loss: 0.574, 6432/28000 datapoints
2025-03-06 22:14:58,804 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:14:58,979 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-06 22:14:59,162 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:14:59,334 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:14:59,502 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-06 22:14:59,671 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:14:59,845 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:15:00,017 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:15:00,192 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:15:00,363 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:15:00,537 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:15:00,735 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:00,908 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:15:00,996 - INFO - validation batch 1, loss: 0.722, 32/6976 datapoints
2025-03-06 22:15:01,044 - INFO - validation batch 51, loss: 8.131, 1632/6976 datapoints
2025-03-06 22:15:01,092 - INFO - validation batch 101, loss: 1.773, 3232/6976 datapoints
2025-03-06 22:15:01,139 - INFO - validation batch 151, loss: 2.341, 4832/6976 datapoints
2025-03-06 22:15:01,185 - INFO - validation batch 201, loss: 1.222, 6432/6976 datapoints
2025-03-06 22:15:01,201 - INFO - Epoch 621/800 done.
2025-03-06 22:15:01,201 - INFO - Final validation performance:
Loss: 2.838, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:15:01,202 - INFO - Beginning epoch 622/800
2025-03-06 22:15:01,206 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:15:01,377 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:15:01,548 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:15:01,723 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:01,895 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:02,073 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 22:15:02,250 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:15:02,425 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:15:02,593 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:15:02,767 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:15:02,938 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:15:03,111 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:15:03,282 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:15:03,451 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:15:03,623 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:15:03,796 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:15:03,978 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:04,153 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:15:04,241 - INFO - validation batch 1, loss: 0.558, 32/6976 datapoints
2025-03-06 22:15:04,289 - INFO - validation batch 51, loss: 8.095, 1632/6976 datapoints
2025-03-06 22:15:04,338 - INFO - validation batch 101, loss: 1.605, 3232/6976 datapoints
2025-03-06 22:15:04,386 - INFO - validation batch 151, loss: 2.413, 4832/6976 datapoints
2025-03-06 22:15:04,435 - INFO - validation batch 201, loss: 1.143, 6432/6976 datapoints
2025-03-06 22:15:04,451 - INFO - Epoch 622/800 done.
2025-03-06 22:15:04,451 - INFO - Final validation performance:
Loss: 2.763, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:15:04,452 - INFO - Beginning epoch 623/800
2025-03-06 22:15:04,457 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:15:04,630 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:15:04,807 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:15:04,981 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:05,160 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:05,339 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 22:15:05,513 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:15:05,693 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:15:05,862 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:15:06,039 - INFO - training batch 451, loss: 0.015, 14432/28000 datapoints
2025-03-06 22:15:06,213 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:15:06,384 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:15:06,556 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:15:06,732 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:15:06,903 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:15:07,083 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:15:07,265 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:07,437 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:15:07,525 - INFO - validation batch 1, loss: 0.408, 32/6976 datapoints
2025-03-06 22:15:07,574 - INFO - validation batch 51, loss: 8.210, 1632/6976 datapoints
2025-03-06 22:15:07,621 - INFO - validation batch 101, loss: 1.547, 3232/6976 datapoints
2025-03-06 22:15:07,667 - INFO - validation batch 151, loss: 2.409, 4832/6976 datapoints
2025-03-06 22:15:07,714 - INFO - validation batch 201, loss: 1.223, 6432/6976 datapoints
2025-03-06 22:15:07,730 - INFO - Epoch 623/800 done.
2025-03-06 22:15:07,730 - INFO - Final validation performance:
Loss: 2.759, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:15:07,731 - INFO - Beginning epoch 624/800
2025-03-06 22:15:07,735 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:15:07,913 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:15:08,096 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:15:08,277 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:08,455 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:08,638 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:15:08,821 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:15:09,003 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:15:09,180 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:15:09,367 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:15:09,540 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:15:09,711 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:15:09,900 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:15:10,084 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:15:10,266 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:15:10,454 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:15:10,644 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:10,861 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:15:10,966 - INFO - validation batch 1, loss: 0.627, 32/6976 datapoints
2025-03-06 22:15:11,026 - INFO - validation batch 51, loss: 8.208, 1632/6976 datapoints
2025-03-06 22:15:11,085 - INFO - validation batch 101, loss: 1.526, 3232/6976 datapoints
2025-03-06 22:15:11,142 - INFO - validation batch 151, loss: 2.428, 4832/6976 datapoints
2025-03-06 22:15:11,198 - INFO - validation batch 201, loss: 1.252, 6432/6976 datapoints
2025-03-06 22:15:11,226 - INFO - Epoch 624/800 done.
2025-03-06 22:15:11,227 - INFO - Final validation performance:
Loss: 2.808, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:15:11,228 - INFO - Beginning epoch 625/800
2025-03-06 22:15:11,233 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:15:11,434 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:15:11,653 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:15:11,852 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:12,083 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:12,284 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:15:12,480 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:15:12,685 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:15:12,876 - INFO - training batch 401, loss: 0.127, 12832/28000 datapoints
2025-03-06 22:15:13,071 - INFO - training batch 451, loss: 0.016, 14432/28000 datapoints
2025-03-06 22:15:13,258 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:15:13,442 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:15:13,632 - INFO - training batch 601, loss: 0.063, 19232/28000 datapoints
2025-03-06 22:15:13,817 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:15:13,999 - INFO - training batch 701, loss: 0.073, 22432/28000 datapoints
2025-03-06 22:15:14,180 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:15:14,364 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:14,538 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:15:14,629 - INFO - validation batch 1, loss: 0.510, 32/6976 datapoints
2025-03-06 22:15:14,678 - INFO - validation batch 51, loss: 8.777, 1632/6976 datapoints
2025-03-06 22:15:14,730 - INFO - validation batch 101, loss: 1.695, 3232/6976 datapoints
2025-03-06 22:15:14,783 - INFO - validation batch 151, loss: 2.355, 4832/6976 datapoints
2025-03-06 22:15:14,845 - INFO - validation batch 201, loss: 1.305, 6432/6976 datapoints
2025-03-06 22:15:14,877 - INFO - Epoch 625/800 done.
2025-03-06 22:15:14,878 - INFO - Final validation performance:
Loss: 2.928, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:15:14,878 - INFO - Beginning epoch 626/800
2025-03-06 22:15:14,887 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:15:15,069 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:15:15,256 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:15:15,431 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:15:15,618 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:15,798 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-06 22:15:15,978 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:15:16,161 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:15:16,336 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:15:16,511 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:15:16,684 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:15:16,861 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:15:17,044 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:15:17,220 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:15:17,395 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:15:17,573 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:15:17,787 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:18,016 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:15:18,110 - INFO - validation batch 1, loss: 0.559, 32/6976 datapoints
2025-03-06 22:15:18,162 - INFO - validation batch 51, loss: 8.228, 1632/6976 datapoints
2025-03-06 22:15:18,212 - INFO - validation batch 101, loss: 1.593, 3232/6976 datapoints
2025-03-06 22:15:18,263 - INFO - validation batch 151, loss: 2.332, 4832/6976 datapoints
2025-03-06 22:15:18,311 - INFO - validation batch 201, loss: 1.253, 6432/6976 datapoints
2025-03-06 22:15:18,327 - INFO - Epoch 626/800 done.
2025-03-06 22:15:18,327 - INFO - Final validation performance:
Loss: 2.793, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:15:18,327 - INFO - Beginning epoch 627/800
2025-03-06 22:15:18,332 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:15:18,505 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:15:18,677 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:15:18,854 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:19,028 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:19,207 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-06 22:15:19,382 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:15:19,563 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:15:19,736 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:15:19,912 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:15:20,082 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:15:20,257 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:15:20,440 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:15:20,611 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:15:20,787 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:15:20,990 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:15:21,173 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:21,349 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:15:21,435 - INFO - validation batch 1, loss: 0.488, 32/6976 datapoints
2025-03-06 22:15:21,481 - INFO - validation batch 51, loss: 8.176, 1632/6976 datapoints
2025-03-06 22:15:21,527 - INFO - validation batch 101, loss: 1.529, 3232/6976 datapoints
2025-03-06 22:15:21,573 - INFO - validation batch 151, loss: 2.394, 4832/6976 datapoints
2025-03-06 22:15:21,619 - INFO - validation batch 201, loss: 1.202, 6432/6976 datapoints
2025-03-06 22:15:21,635 - INFO - Epoch 627/800 done.
2025-03-06 22:15:21,635 - INFO - Final validation performance:
Loss: 2.758, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:15:21,636 - INFO - Beginning epoch 628/800
2025-03-06 22:15:21,640 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:15:21,813 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:15:21,991 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:15:22,171 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:22,347 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:22,524 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:15:22,701 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:15:22,899 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:15:23,073 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:15:23,279 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:15:23,471 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:15:23,648 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:15:23,824 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:15:24,001 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:15:24,179 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:15:24,358 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:15:24,540 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:24,714 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:15:24,803 - INFO - validation batch 1, loss: 0.506, 32/6976 datapoints
2025-03-06 22:15:24,850 - INFO - validation batch 51, loss: 8.181, 1632/6976 datapoints
2025-03-06 22:15:24,898 - INFO - validation batch 101, loss: 1.524, 3232/6976 datapoints
2025-03-06 22:15:24,944 - INFO - validation batch 151, loss: 2.437, 4832/6976 datapoints
2025-03-06 22:15:24,991 - INFO - validation batch 201, loss: 1.216, 6432/6976 datapoints
2025-03-06 22:15:25,007 - INFO - Epoch 628/800 done.
2025-03-06 22:15:25,007 - INFO - Final validation performance:
Loss: 2.773, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:15:25,007 - INFO - Beginning epoch 629/800
2025-03-06 22:15:25,012 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:15:25,188 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:15:25,366 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:15:25,538 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:25,715 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:25,897 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:15:26,071 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:15:26,250 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:15:26,421 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:15:26,592 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:15:26,762 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:15:26,937 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:15:27,109 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:15:27,280 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:15:27,453 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:15:27,625 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:15:27,804 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:27,986 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:15:28,102 - INFO - validation batch 1, loss: 0.494, 32/6976 datapoints
2025-03-06 22:15:28,152 - INFO - validation batch 51, loss: 8.222, 1632/6976 datapoints
2025-03-06 22:15:28,203 - INFO - validation batch 101, loss: 1.514, 3232/6976 datapoints
2025-03-06 22:15:28,253 - INFO - validation batch 151, loss: 2.471, 4832/6976 datapoints
2025-03-06 22:15:28,304 - INFO - validation batch 201, loss: 1.216, 6432/6976 datapoints
2025-03-06 22:15:28,324 - INFO - Epoch 629/800 done.
2025-03-06 22:15:28,324 - INFO - Final validation performance:
Loss: 2.784, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:15:28,324 - INFO - Beginning epoch 630/800
2025-03-06 22:15:28,329 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:15:28,511 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:15:28,686 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:15:28,872 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:29,047 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:29,226 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:15:29,407 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:15:29,590 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:15:29,765 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:15:29,943 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:15:30,118 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:15:30,292 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:15:30,467 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:15:30,643 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:15:30,818 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:15:31,018 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:15:31,207 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:31,386 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:15:31,476 - INFO - validation batch 1, loss: 0.463, 32/6976 datapoints
2025-03-06 22:15:31,527 - INFO - validation batch 51, loss: 8.262, 1632/6976 datapoints
2025-03-06 22:15:31,577 - INFO - validation batch 101, loss: 1.511, 3232/6976 datapoints
2025-03-06 22:15:31,628 - INFO - validation batch 151, loss: 2.496, 4832/6976 datapoints
2025-03-06 22:15:31,679 - INFO - validation batch 201, loss: 1.224, 6432/6976 datapoints
2025-03-06 22:15:31,696 - INFO - Epoch 630/800 done.
2025-03-06 22:15:31,696 - INFO - Final validation performance:
Loss: 2.791, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:15:31,697 - INFO - Beginning epoch 631/800
2025-03-06 22:15:31,702 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:15:31,880 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:15:32,059 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:15:32,238 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:32,414 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:32,594 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:15:32,772 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:15:32,960 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:15:33,134 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:15:33,309 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:15:33,486 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:15:33,659 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:15:33,833 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:15:34,012 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:15:34,187 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:15:34,368 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:15:34,553 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:34,731 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:15:34,820 - INFO - validation batch 1, loss: 0.410, 32/6976 datapoints
2025-03-06 22:15:34,875 - INFO - validation batch 51, loss: 8.302, 1632/6976 datapoints
2025-03-06 22:15:34,928 - INFO - validation batch 101, loss: 1.531, 3232/6976 datapoints
2025-03-06 22:15:34,977 - INFO - validation batch 151, loss: 2.529, 4832/6976 datapoints
2025-03-06 22:15:35,027 - INFO - validation batch 201, loss: 1.231, 6432/6976 datapoints
2025-03-06 22:15:35,043 - INFO - Epoch 631/800 done.
2025-03-06 22:15:35,044 - INFO - Final validation performance:
Loss: 2.801, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:15:35,044 - INFO - Beginning epoch 632/800
2025-03-06 22:15:35,049 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:15:35,230 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:15:35,412 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:15:35,593 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:35,768 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:35,952 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:15:36,133 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:15:36,316 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:15:36,492 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:15:36,667 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:15:36,845 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:15:37,027 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:15:37,203 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:15:37,378 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:15:37,555 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:15:37,732 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:15:37,928 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:38,106 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:15:38,195 - INFO - validation batch 1, loss: 0.376, 32/6976 datapoints
2025-03-06 22:15:38,246 - INFO - validation batch 51, loss: 8.318, 1632/6976 datapoints
2025-03-06 22:15:38,298 - INFO - validation batch 101, loss: 1.585, 3232/6976 datapoints
2025-03-06 22:15:38,348 - INFO - validation batch 151, loss: 2.640, 4832/6976 datapoints
2025-03-06 22:15:38,401 - INFO - validation batch 201, loss: 1.236, 6432/6976 datapoints
2025-03-06 22:15:38,421 - INFO - Epoch 632/800 done.
2025-03-06 22:15:38,421 - INFO - Final validation performance:
Loss: 2.831, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:15:38,422 - INFO - Beginning epoch 633/800
2025-03-06 22:15:38,427 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:15:38,603 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:15:38,780 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:15:38,968 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:39,144 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:39,329 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:15:39,510 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:15:39,692 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:15:39,867 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:15:40,047 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:15:40,224 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:15:40,406 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:15:40,581 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:15:40,754 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:15:40,935 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:15:41,137 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:15:41,327 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:41,507 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:15:41,599 - INFO - validation batch 1, loss: 0.338, 32/6976 datapoints
2025-03-06 22:15:41,651 - INFO - validation batch 51, loss: 8.389, 1632/6976 datapoints
2025-03-06 22:15:41,701 - INFO - validation batch 101, loss: 1.646, 3232/6976 datapoints
2025-03-06 22:15:41,752 - INFO - validation batch 151, loss: 2.805, 4832/6976 datapoints
2025-03-06 22:15:41,803 - INFO - validation batch 201, loss: 1.254, 6432/6976 datapoints
2025-03-06 22:15:41,823 - INFO - Epoch 633/800 done.
2025-03-06 22:15:41,823 - INFO - Final validation performance:
Loss: 2.886, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:15:41,824 - INFO - Beginning epoch 634/800
2025-03-06 22:15:41,829 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:15:42,011 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:15:42,194 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:15:42,376 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:42,558 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:42,742 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:15:42,932 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:15:43,116 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:15:43,288 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:15:43,465 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:15:43,642 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:15:43,825 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:15:44,002 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:15:44,182 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:15:44,354 - INFO - training batch 701, loss: 0.030, 22432/28000 datapoints
2025-03-06 22:15:44,536 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:15:44,717 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:15:44,901 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:15:44,993 - INFO - validation batch 1, loss: 0.449, 32/6976 datapoints
2025-03-06 22:15:45,045 - INFO - validation batch 51, loss: 8.215, 1632/6976 datapoints
2025-03-06 22:15:45,098 - INFO - validation batch 101, loss: 1.834, 3232/6976 datapoints
2025-03-06 22:15:45,153 - INFO - validation batch 151, loss: 3.777, 4832/6976 datapoints
2025-03-06 22:15:45,206 - INFO - validation batch 201, loss: 1.215, 6432/6976 datapoints
2025-03-06 22:15:45,226 - INFO - Epoch 634/800 done.
2025-03-06 22:15:45,226 - INFO - Final validation performance:
Loss: 3.098, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 22:15:45,227 - INFO - Beginning epoch 635/800
2025-03-06 22:15:45,231 - INFO - training batch 1, loss: 0.041, 32/28000 datapoints
2025-03-06 22:15:45,411 - INFO - training batch 51, loss: 0.196, 1632/28000 datapoints
2025-03-06 22:15:45,590 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:15:45,769 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:45,948 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:15:46,132 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-06 22:15:46,311 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:15:46,494 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:15:46,670 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:15:46,848 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:15:47,034 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:15:47,215 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:15:47,390 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:15:47,569 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:15:47,742 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:15:47,925 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:15:48,108 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:15:48,283 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:15:48,375 - INFO - validation batch 1, loss: 0.717, 32/6976 datapoints
2025-03-06 22:15:48,424 - INFO - validation batch 51, loss: 8.539, 1632/6976 datapoints
2025-03-06 22:15:48,475 - INFO - validation batch 101, loss: 1.545, 3232/6976 datapoints
2025-03-06 22:15:48,526 - INFO - validation batch 151, loss: 2.630, 4832/6976 datapoints
2025-03-06 22:15:48,577 - INFO - validation batch 201, loss: 1.146, 6432/6976 datapoints
2025-03-06 22:15:48,593 - INFO - Epoch 635/800 done.
2025-03-06 22:15:48,593 - INFO - Final validation performance:
Loss: 2.915, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:15:48,594 - INFO - Beginning epoch 636/800
2025-03-06 22:15:48,598 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:15:48,774 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:15:48,956 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:15:49,136 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:49,312 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:15:49,496 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:15:49,676 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:15:49,863 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:15:50,038 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:15:50,219 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:15:50,395 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:15:50,575 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:15:50,754 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:15:50,940 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:15:51,117 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:15:51,319 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:15:51,505 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:51,682 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:15:51,773 - INFO - validation batch 1, loss: 0.684, 32/6976 datapoints
2025-03-06 22:15:51,823 - INFO - validation batch 51, loss: 8.299, 1632/6976 datapoints
2025-03-06 22:15:51,878 - INFO - validation batch 101, loss: 1.641, 3232/6976 datapoints
2025-03-06 22:15:51,929 - INFO - validation batch 151, loss: 2.587, 4832/6976 datapoints
2025-03-06 22:15:51,980 - INFO - validation batch 201, loss: 1.298, 6432/6976 datapoints
2025-03-06 22:15:51,998 - INFO - Epoch 636/800 done.
2025-03-06 22:15:51,998 - INFO - Final validation performance:
Loss: 2.902, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:15:51,999 - INFO - Beginning epoch 637/800
2025-03-06 22:15:52,003 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:15:52,181 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 22:15:52,367 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:15:52,544 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:52,723 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:52,905 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:15:53,094 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:15:53,278 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:15:53,453 - INFO - training batch 401, loss: 0.012, 12832/28000 datapoints
2025-03-06 22:15:53,631 - INFO - training batch 451, loss: 0.020, 14432/28000 datapoints
2025-03-06 22:15:53,809 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:15:53,992 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:15:54,167 - INFO - training batch 601, loss: 0.091, 19232/28000 datapoints
2025-03-06 22:15:54,342 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:15:54,516 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:15:54,699 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:15:54,886 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:55,065 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:15:55,161 - INFO - validation batch 1, loss: 0.453, 32/6976 datapoints
2025-03-06 22:15:55,211 - INFO - validation batch 51, loss: 8.491, 1632/6976 datapoints
2025-03-06 22:15:55,263 - INFO - validation batch 101, loss: 1.585, 3232/6976 datapoints
2025-03-06 22:15:55,311 - INFO - validation batch 151, loss: 2.300, 4832/6976 datapoints
2025-03-06 22:15:55,358 - INFO - validation batch 201, loss: 1.217, 6432/6976 datapoints
2025-03-06 22:15:55,375 - INFO - Epoch 637/800 done.
2025-03-06 22:15:55,375 - INFO - Final validation performance:
Loss: 2.809, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:15:55,375 - INFO - Beginning epoch 638/800
2025-03-06 22:15:55,380 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:15:55,558 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:15:55,739 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:15:55,917 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:56,092 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:56,274 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:15:56,451 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:15:56,631 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:15:56,808 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:15:56,985 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:15:57,159 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:15:57,333 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:15:57,505 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:15:57,677 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:15:57,848 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:15:58,029 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:15:58,211 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:15:58,388 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:15:58,477 - INFO - validation batch 1, loss: 0.435, 32/6976 datapoints
2025-03-06 22:15:58,524 - INFO - validation batch 51, loss: 8.438, 1632/6976 datapoints
2025-03-06 22:15:58,571 - INFO - validation batch 101, loss: 1.551, 3232/6976 datapoints
2025-03-06 22:15:58,617 - INFO - validation batch 151, loss: 2.319, 4832/6976 datapoints
2025-03-06 22:15:58,664 - INFO - validation batch 201, loss: 1.230, 6432/6976 datapoints
2025-03-06 22:15:58,681 - INFO - Epoch 638/800 done.
2025-03-06 22:15:58,681 - INFO - Final validation performance:
Loss: 2.795, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:15:58,681 - INFO - Beginning epoch 639/800
2025-03-06 22:15:58,686 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:15:58,860 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:15:59,044 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:15:59,217 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:15:59,393 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:15:59,575 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:15:59,753 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:15:59,934 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:16:00,103 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:16:00,275 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:16:00,448 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:16:00,620 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:16:00,792 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:16:00,969 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:01,143 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:01,342 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:01,526 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:16:01,703 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:16:01,790 - INFO - validation batch 1, loss: 0.423, 32/6976 datapoints
2025-03-06 22:16:01,837 - INFO - validation batch 51, loss: 8.496, 1632/6976 datapoints
2025-03-06 22:16:01,888 - INFO - validation batch 101, loss: 1.538, 3232/6976 datapoints
2025-03-06 22:16:01,936 - INFO - validation batch 151, loss: 2.344, 4832/6976 datapoints
2025-03-06 22:16:01,982 - INFO - validation batch 201, loss: 1.239, 6432/6976 datapoints
2025-03-06 22:16:01,998 - INFO - Epoch 639/800 done.
2025-03-06 22:16:01,998 - INFO - Final validation performance:
Loss: 2.808, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:16:01,999 - INFO - Beginning epoch 640/800
2025-03-06 22:16:02,003 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:16:02,172 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:16:02,350 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:02,524 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:02,700 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:16:02,879 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:16:03,061 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:16:03,239 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:16:03,411 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:16:03,584 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:16:03,753 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:16:03,929 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:16:04,102 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:16:04,277 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:04,449 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:04,630 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:04,809 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:16:04,989 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:16:05,075 - INFO - validation batch 1, loss: 0.420, 32/6976 datapoints
2025-03-06 22:16:05,122 - INFO - validation batch 51, loss: 8.502, 1632/6976 datapoints
2025-03-06 22:16:05,176 - INFO - validation batch 101, loss: 1.543, 3232/6976 datapoints
2025-03-06 22:16:05,222 - INFO - validation batch 151, loss: 2.362, 4832/6976 datapoints
2025-03-06 22:16:05,270 - INFO - validation batch 201, loss: 1.254, 6432/6976 datapoints
2025-03-06 22:16:05,289 - INFO - Epoch 640/800 done.
2025-03-06 22:16:05,289 - INFO - Final validation performance:
Loss: 2.816, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:16:05,290 - INFO - Beginning epoch 641/800
2025-03-06 22:16:05,295 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:16:05,465 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:16:05,641 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:05,814 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:05,991 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:16:06,172 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:16:06,350 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:16:06,534 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:16:06,705 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:16:06,879 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:16:07,054 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:16:07,229 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:16:07,402 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:16:07,575 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:07,748 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:07,931 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:08,130 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:16:08,304 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:16:08,399 - INFO - validation batch 1, loss: 0.396, 32/6976 datapoints
2025-03-06 22:16:08,449 - INFO - validation batch 51, loss: 8.514, 1632/6976 datapoints
2025-03-06 22:16:08,499 - INFO - validation batch 101, loss: 1.551, 3232/6976 datapoints
2025-03-06 22:16:08,550 - INFO - validation batch 151, loss: 2.400, 4832/6976 datapoints
2025-03-06 22:16:08,600 - INFO - validation batch 201, loss: 1.261, 6432/6976 datapoints
2025-03-06 22:16:08,617 - INFO - Epoch 641/800 done.
2025-03-06 22:16:08,617 - INFO - Final validation performance:
Loss: 2.824, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:16:08,618 - INFO - Beginning epoch 642/800
2025-03-06 22:16:08,623 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:16:08,801 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:16:08,993 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:09,169 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:09,355 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:16:09,536 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:16:09,715 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:16:09,902 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:16:10,073 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:16:10,249 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:16:10,429 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:16:10,606 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:16:10,778 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:16:10,959 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:11,139 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:11,321 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:11,531 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:16:11,714 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:16:11,807 - INFO - validation batch 1, loss: 0.379, 32/6976 datapoints
2025-03-06 22:16:11,859 - INFO - validation batch 51, loss: 8.534, 1632/6976 datapoints
2025-03-06 22:16:11,916 - INFO - validation batch 101, loss: 1.556, 3232/6976 datapoints
2025-03-06 22:16:11,966 - INFO - validation batch 151, loss: 2.438, 4832/6976 datapoints
2025-03-06 22:16:12,017 - INFO - validation batch 201, loss: 1.273, 6432/6976 datapoints
2025-03-06 22:16:12,034 - INFO - Epoch 642/800 done.
2025-03-06 22:16:12,035 - INFO - Final validation performance:
Loss: 2.836, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:16:12,035 - INFO - Beginning epoch 643/800
2025-03-06 22:16:12,040 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:16:12,218 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:16:12,402 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:12,584 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:12,764 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:16:12,951 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:16:13,144 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:16:13,329 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:16:13,503 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:16:13,680 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:16:13,855 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:16:14,035 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:16:14,210 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:16:14,391 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:14,569 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:14,751 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:14,936 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:16:15,124 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:16:15,218 - INFO - validation batch 1, loss: 0.371, 32/6976 datapoints
2025-03-06 22:16:15,271 - INFO - validation batch 51, loss: 8.549, 1632/6976 datapoints
2025-03-06 22:16:15,319 - INFO - validation batch 101, loss: 1.564, 3232/6976 datapoints
2025-03-06 22:16:15,365 - INFO - validation batch 151, loss: 2.494, 4832/6976 datapoints
2025-03-06 22:16:15,415 - INFO - validation batch 201, loss: 1.279, 6432/6976 datapoints
2025-03-06 22:16:15,430 - INFO - Epoch 643/800 done.
2025-03-06 22:16:15,431 - INFO - Final validation performance:
Loss: 2.852, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:16:15,431 - INFO - Beginning epoch 644/800
2025-03-06 22:16:15,436 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:16:15,612 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:16:15,799 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:15,979 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:16,153 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:16:16,331 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:16:16,510 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:16:16,690 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:16:16,858 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:16:17,042 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:16:17,218 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:16:17,393 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:16:17,564 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:16:17,738 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:17,913 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:18,091 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:18,270 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:16:18,451 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:16:18,543 - INFO - validation batch 1, loss: 0.392, 32/6976 datapoints
2025-03-06 22:16:18,591 - INFO - validation batch 51, loss: 8.557, 1632/6976 datapoints
2025-03-06 22:16:18,639 - INFO - validation batch 101, loss: 1.591, 3232/6976 datapoints
2025-03-06 22:16:18,688 - INFO - validation batch 151, loss: 2.585, 4832/6976 datapoints
2025-03-06 22:16:18,734 - INFO - validation batch 201, loss: 1.277, 6432/6976 datapoints
2025-03-06 22:16:18,750 - INFO - Epoch 644/800 done.
2025-03-06 22:16:18,750 - INFO - Final validation performance:
Loss: 2.880, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:16:18,751 - INFO - Beginning epoch 645/800
2025-03-06 22:16:18,755 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:16:18,930 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:16:19,117 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:19,297 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:19,475 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:16:19,654 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:16:19,831 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:16:20,014 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:16:20,185 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:16:20,362 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:16:20,539 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:16:20,718 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:16:20,892 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:16:21,070 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:21,244 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:21,435 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:21,634 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:16:21,808 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:16:21,899 - INFO - validation batch 1, loss: 0.408, 32/6976 datapoints
2025-03-06 22:16:21,946 - INFO - validation batch 51, loss: 8.556, 1632/6976 datapoints
2025-03-06 22:16:21,994 - INFO - validation batch 101, loss: 1.651, 3232/6976 datapoints
2025-03-06 22:16:22,040 - INFO - validation batch 151, loss: 2.724, 4832/6976 datapoints
2025-03-06 22:16:22,086 - INFO - validation batch 201, loss: 1.282, 6432/6976 datapoints
2025-03-06 22:16:22,102 - INFO - Epoch 645/800 done.
2025-03-06 22:16:22,102 - INFO - Final validation performance:
Loss: 2.924, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:16:22,103 - INFO - Beginning epoch 646/800
2025-03-06 22:16:22,108 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:16:22,278 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:16:22,452 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:22,637 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:22,812 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:16:23,003 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:16:23,186 - INFO - training batch 301, loss: 1.251, 9632/28000 datapoints
2025-03-06 22:16:23,365 - INFO - training batch 351, loss: 0.036, 11232/28000 datapoints
2025-03-06 22:16:23,537 - INFO - training batch 401, loss: 0.035, 12832/28000 datapoints
2025-03-06 22:16:23,765 - INFO - training batch 451, loss: 0.049, 14432/28000 datapoints
2025-03-06 22:16:23,941 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:16:24,118 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:16:24,288 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:16:24,465 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 22:16:24,639 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:16:24,819 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:16:25,014 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:16:25,197 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:16:25,287 - INFO - validation batch 1, loss: 0.658, 32/6976 datapoints
2025-03-06 22:16:25,334 - INFO - validation batch 51, loss: 8.607, 1632/6976 datapoints
2025-03-06 22:16:25,381 - INFO - validation batch 101, loss: 1.427, 3232/6976 datapoints
2025-03-06 22:16:25,428 - INFO - validation batch 151, loss: 2.278, 4832/6976 datapoints
2025-03-06 22:16:25,475 - INFO - validation batch 201, loss: 1.200, 6432/6976 datapoints
2025-03-06 22:16:25,491 - INFO - Epoch 646/800 done.
2025-03-06 22:16:25,491 - INFO - Final validation performance:
Loss: 2.834, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:16:25,492 - INFO - Beginning epoch 647/800
2025-03-06 22:16:25,496 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:16:25,672 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:16:25,847 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:16:26,025 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:26,200 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:16:26,381 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 22:16:26,558 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:16:26,738 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:16:26,911 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:16:27,088 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:16:27,265 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:16:27,442 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:16:27,629 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:16:27,805 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:27,984 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:28,174 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:28,363 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:16:28,551 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:16:28,646 - INFO - validation batch 1, loss: 0.271, 32/6976 datapoints
2025-03-06 22:16:28,698 - INFO - validation batch 51, loss: 8.532, 1632/6976 datapoints
2025-03-06 22:16:28,748 - INFO - validation batch 101, loss: 1.503, 3232/6976 datapoints
2025-03-06 22:16:28,797 - INFO - validation batch 151, loss: 2.539, 4832/6976 datapoints
2025-03-06 22:16:28,849 - INFO - validation batch 201, loss: 1.230, 6432/6976 datapoints
2025-03-06 22:16:28,867 - INFO - Epoch 647/800 done.
2025-03-06 22:16:28,867 - INFO - Final validation performance:
Loss: 2.815, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:16:28,868 - INFO - Beginning epoch 648/800
2025-03-06 22:16:28,875 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:16:29,053 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:16:29,239 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:16:29,417 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:29,603 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:16:29,789 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:16:29,977 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:16:30,167 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:16:30,346 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:16:30,532 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:16:30,718 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:16:30,900 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:16:31,083 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:16:31,266 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:31,443 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:31,654 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:31,841 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:16:32,024 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:16:32,116 - INFO - validation batch 1, loss: 0.252, 32/6976 datapoints
2025-03-06 22:16:32,166 - INFO - validation batch 51, loss: 8.649, 1632/6976 datapoints
2025-03-06 22:16:32,219 - INFO - validation batch 101, loss: 1.509, 3232/6976 datapoints
2025-03-06 22:16:32,273 - INFO - validation batch 151, loss: 2.640, 4832/6976 datapoints
2025-03-06 22:16:32,325 - INFO - validation batch 201, loss: 1.159, 6432/6976 datapoints
2025-03-06 22:16:32,341 - INFO - Epoch 648/800 done.
2025-03-06 22:16:32,341 - INFO - Final validation performance:
Loss: 2.842, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:16:32,342 - INFO - Beginning epoch 649/800
2025-03-06 22:16:32,346 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:16:32,518 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:16:32,703 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:32,882 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:16:33,060 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:16:33,246 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:16:33,427 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:16:33,642 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:16:33,828 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:16:34,008 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:16:34,191 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:16:34,371 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:16:34,555 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:16:34,738 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:34,916 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:35,100 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:35,291 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:16:35,471 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:16:35,562 - INFO - validation batch 1, loss: 0.194, 32/6976 datapoints
2025-03-06 22:16:35,613 - INFO - validation batch 51, loss: 8.716, 1632/6976 datapoints
2025-03-06 22:16:35,665 - INFO - validation batch 101, loss: 1.477, 3232/6976 datapoints
2025-03-06 22:16:35,714 - INFO - validation batch 151, loss: 2.354, 4832/6976 datapoints
2025-03-06 22:16:35,760 - INFO - validation batch 201, loss: 1.224, 6432/6976 datapoints
2025-03-06 22:16:35,777 - INFO - Epoch 649/800 done.
2025-03-06 22:16:35,777 - INFO - Final validation performance:
Loss: 2.793, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:16:35,778 - INFO - Beginning epoch 650/800
2025-03-06 22:16:35,782 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:16:35,955 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:16:36,133 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:36,307 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:36,480 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:16:36,659 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:16:36,837 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:16:37,021 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:16:37,199 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:16:37,377 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:16:37,553 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:16:37,730 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:16:37,926 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:16:38,099 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:38,274 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:38,452 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:38,640 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:16:38,816 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:16:38,907 - INFO - validation batch 1, loss: 0.238, 32/6976 datapoints
2025-03-06 22:16:38,956 - INFO - validation batch 51, loss: 8.707, 1632/6976 datapoints
2025-03-06 22:16:39,004 - INFO - validation batch 101, loss: 1.467, 3232/6976 datapoints
2025-03-06 22:16:39,050 - INFO - validation batch 151, loss: 2.378, 4832/6976 datapoints
2025-03-06 22:16:39,098 - INFO - validation batch 201, loss: 1.227, 6432/6976 datapoints
2025-03-06 22:16:39,117 - INFO - Epoch 650/800 done.
2025-03-06 22:16:39,117 - INFO - Final validation performance:
Loss: 2.803, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:16:39,118 - INFO - Beginning epoch 651/800
2025-03-06 22:16:39,122 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:16:39,304 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:16:39,485 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:39,674 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:39,853 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:16:40,044 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:16:40,230 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:16:40,417 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:16:40,590 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:16:40,770 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:16:40,950 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:16:41,132 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:16:41,311 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:16:41,491 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:41,688 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:41,868 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:42,051 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:16:42,227 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:16:42,317 - INFO - validation batch 1, loss: 0.240, 32/6976 datapoints
2025-03-06 22:16:42,362 - INFO - validation batch 51, loss: 8.713, 1632/6976 datapoints
2025-03-06 22:16:42,408 - INFO - validation batch 101, loss: 1.488, 3232/6976 datapoints
2025-03-06 22:16:42,455 - INFO - validation batch 151, loss: 2.402, 4832/6976 datapoints
2025-03-06 22:16:42,501 - INFO - validation batch 201, loss: 1.204, 6432/6976 datapoints
2025-03-06 22:16:42,517 - INFO - Epoch 651/800 done.
2025-03-06 22:16:42,518 - INFO - Final validation performance:
Loss: 2.809, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:16:42,518 - INFO - Beginning epoch 652/800
2025-03-06 22:16:42,523 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:16:42,690 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:16:42,871 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:43,046 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:43,223 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:16:43,402 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:16:43,581 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:16:43,763 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:16:43,934 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:16:44,108 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:16:44,284 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:16:44,459 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:16:44,637 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:16:44,814 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:44,988 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:45,172 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:45,354 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:16:45,530 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:16:45,618 - INFO - validation batch 1, loss: 0.237, 32/6976 datapoints
2025-03-06 22:16:45,664 - INFO - validation batch 51, loss: 8.724, 1632/6976 datapoints
2025-03-06 22:16:45,710 - INFO - validation batch 101, loss: 1.505, 3232/6976 datapoints
2025-03-06 22:16:45,756 - INFO - validation batch 151, loss: 2.438, 4832/6976 datapoints
2025-03-06 22:16:45,818 - INFO - validation batch 201, loss: 1.207, 6432/6976 datapoints
2025-03-06 22:16:45,834 - INFO - Epoch 652/800 done.
2025-03-06 22:16:45,834 - INFO - Final validation performance:
Loss: 2.822, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:16:45,835 - INFO - Beginning epoch 653/800
2025-03-06 22:16:45,839 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:16:46,013 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:16:46,188 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:46,362 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:46,535 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:16:46,714 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:16:46,895 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:16:47,078 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:16:47,255 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:16:47,430 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:16:47,603 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:16:47,777 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:16:47,954 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:16:48,127 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:48,300 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:48,485 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:48,671 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:16:48,852 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:16:48,946 - INFO - validation batch 1, loss: 0.225, 32/6976 datapoints
2025-03-06 22:16:48,994 - INFO - validation batch 51, loss: 8.740, 1632/6976 datapoints
2025-03-06 22:16:49,045 - INFO - validation batch 101, loss: 1.517, 3232/6976 datapoints
2025-03-06 22:16:49,098 - INFO - validation batch 151, loss: 2.481, 4832/6976 datapoints
2025-03-06 22:16:49,154 - INFO - validation batch 201, loss: 1.217, 6432/6976 datapoints
2025-03-06 22:16:49,175 - INFO - Epoch 653/800 done.
2025-03-06 22:16:49,175 - INFO - Final validation performance:
Loss: 2.836, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:16:49,176 - INFO - Beginning epoch 654/800
2025-03-06 22:16:49,180 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:16:49,356 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:16:49,535 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:49,712 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:49,896 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:16:50,079 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:16:50,260 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:16:50,446 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:16:50,618 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:16:50,796 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:16:50,980 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:16:51,162 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:16:51,343 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:16:51,521 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:51,704 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:51,907 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:52,106 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:16:52,286 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:16:52,378 - INFO - validation batch 1, loss: 0.220, 32/6976 datapoints
2025-03-06 22:16:52,429 - INFO - validation batch 51, loss: 8.774, 1632/6976 datapoints
2025-03-06 22:16:52,479 - INFO - validation batch 101, loss: 1.527, 3232/6976 datapoints
2025-03-06 22:16:52,530 - INFO - validation batch 151, loss: 2.525, 4832/6976 datapoints
2025-03-06 22:16:52,587 - INFO - validation batch 201, loss: 1.230, 6432/6976 datapoints
2025-03-06 22:16:52,603 - INFO - Epoch 654/800 done.
2025-03-06 22:16:52,604 - INFO - Final validation performance:
Loss: 2.855, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:16:52,604 - INFO - Beginning epoch 655/800
2025-03-06 22:16:52,609 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:16:52,793 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:16:52,979 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:53,166 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:53,349 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:16:53,540 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:16:53,730 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:16:53,922 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:16:54,101 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:16:54,282 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:16:54,465 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:16:54,652 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:16:54,834 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:16:55,020 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:55,203 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:55,385 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:55,572 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:16:55,753 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:16:55,847 - INFO - validation batch 1, loss: 0.232, 32/6976 datapoints
2025-03-06 22:16:55,910 - INFO - validation batch 51, loss: 8.817, 1632/6976 datapoints
2025-03-06 22:16:55,965 - INFO - validation batch 101, loss: 1.558, 3232/6976 datapoints
2025-03-06 22:16:56,016 - INFO - validation batch 151, loss: 2.596, 4832/6976 datapoints
2025-03-06 22:16:56,067 - INFO - validation batch 201, loss: 1.249, 6432/6976 datapoints
2025-03-06 22:16:56,084 - INFO - Epoch 655/800 done.
2025-03-06 22:16:56,085 - INFO - Final validation performance:
Loss: 2.890, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:16:56,085 - INFO - Beginning epoch 656/800
2025-03-06 22:16:56,090 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:16:56,258 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:16:56,437 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:56,616 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:16:56,790 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:16:56,974 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:16:57,153 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:16:57,341 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:16:57,511 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:16:57,688 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:16:57,862 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:16:58,049 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:16:58,226 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:16:58,401 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:16:58,582 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:16:58,769 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:16:58,959 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:16:59,134 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:16:59,225 - INFO - validation batch 1, loss: 0.245, 32/6976 datapoints
2025-03-06 22:16:59,273 - INFO - validation batch 51, loss: 8.843, 1632/6976 datapoints
2025-03-06 22:16:59,320 - INFO - validation batch 101, loss: 1.610, 3232/6976 datapoints
2025-03-06 22:16:59,367 - INFO - validation batch 151, loss: 2.705, 4832/6976 datapoints
2025-03-06 22:16:59,414 - INFO - validation batch 201, loss: 1.292, 6432/6976 datapoints
2025-03-06 22:16:59,430 - INFO - Epoch 656/800 done.
2025-03-06 22:16:59,431 - INFO - Final validation performance:
Loss: 2.939, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:16:59,431 - INFO - Beginning epoch 657/800
2025-03-06 22:16:59,436 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:16:59,607 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:16:59,786 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:16:59,970 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:00,147 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:17:00,332 - INFO - training batch 251, loss: 0.292, 8032/28000 datapoints
2025-03-06 22:17:00,509 - INFO - training batch 301, loss: 0.050, 9632/28000 datapoints
2025-03-06 22:17:00,696 - INFO - training batch 351, loss: 0.010, 11232/28000 datapoints
2025-03-06 22:17:00,866 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:17:01,046 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:17:01,227 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:17:01,405 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:17:01,578 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:17:01,754 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:01,955 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:17:02,139 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:17:02,320 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:02,497 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:17:02,584 - INFO - validation batch 1, loss: 0.224, 32/6976 datapoints
2025-03-06 22:17:02,632 - INFO - validation batch 51, loss: 8.711, 1632/6976 datapoints
2025-03-06 22:17:02,678 - INFO - validation batch 101, loss: 1.716, 3232/6976 datapoints
2025-03-06 22:17:02,724 - INFO - validation batch 151, loss: 2.635, 4832/6976 datapoints
2025-03-06 22:17:02,773 - INFO - validation batch 201, loss: 1.360, 6432/6976 datapoints
2025-03-06 22:17:02,789 - INFO - Epoch 657/800 done.
2025-03-06 22:17:02,789 - INFO - Final validation performance:
Loss: 2.929, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:17:02,790 - INFO - Beginning epoch 658/800
2025-03-06 22:17:02,794 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:17:02,968 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:17:03,146 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:17:03,327 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:03,504 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 22:17:03,682 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:17:03,862 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:17:04,046 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:17:04,232 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:17:04,410 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:17:04,593 - INFO - training batch 501, loss: 0.034, 16032/28000 datapoints
2025-03-06 22:17:04,773 - INFO - training batch 551, loss: 0.057, 17632/28000 datapoints
2025-03-06 22:17:04,952 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:17:05,129 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:05,309 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:17:05,489 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:05,670 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:05,844 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:17:05,937 - INFO - validation batch 1, loss: 0.503, 32/6976 datapoints
2025-03-06 22:17:05,983 - INFO - validation batch 51, loss: 8.901, 1632/6976 datapoints
2025-03-06 22:17:06,031 - INFO - validation batch 101, loss: 1.605, 3232/6976 datapoints
2025-03-06 22:17:06,077 - INFO - validation batch 151, loss: 2.674, 4832/6976 datapoints
2025-03-06 22:17:06,125 - INFO - validation batch 201, loss: 1.364, 6432/6976 datapoints
2025-03-06 22:17:06,141 - INFO - Epoch 658/800 done.
2025-03-06 22:17:06,141 - INFO - Final validation performance:
Loss: 3.009, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:17:06,142 - INFO - Beginning epoch 659/800
2025-03-06 22:17:06,146 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:17:06,321 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 22:17:06,493 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:17:06,675 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:17:06,855 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:17:07,033 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:17:07,210 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:17:07,399 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:17:07,571 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:17:07,747 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:17:07,927 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:17:08,105 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:17:08,276 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:17:08,449 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:08,629 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:17:08,835 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:09,022 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:09,201 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:17:09,303 - INFO - validation batch 1, loss: 0.335, 32/6976 datapoints
2025-03-06 22:17:09,365 - INFO - validation batch 51, loss: 8.863, 1632/6976 datapoints
2025-03-06 22:17:09,415 - INFO - validation batch 101, loss: 1.459, 3232/6976 datapoints
2025-03-06 22:17:09,465 - INFO - validation batch 151, loss: 2.373, 4832/6976 datapoints
2025-03-06 22:17:09,516 - INFO - validation batch 201, loss: 1.395, 6432/6976 datapoints
2025-03-06 22:17:09,534 - INFO - Epoch 659/800 done.
2025-03-06 22:17:09,534 - INFO - Final validation performance:
Loss: 2.885, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:17:09,534 - INFO - Beginning epoch 660/800
2025-03-06 22:17:09,539 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:17:09,723 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:17:09,911 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:17:10,103 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:10,292 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:17:10,478 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:17:10,672 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:17:10,860 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:17:11,045 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:17:11,231 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:17:11,419 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:17:11,598 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:17:11,775 - INFO - training batch 601, loss: 0.009, 19232/28000 datapoints
2025-03-06 22:17:11,979 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:12,160 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:17:12,346 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:12,532 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:12,713 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:17:12,806 - INFO - validation batch 1, loss: 0.365, 32/6976 datapoints
2025-03-06 22:17:12,857 - INFO - validation batch 51, loss: 8.817, 1632/6976 datapoints
2025-03-06 22:17:12,910 - INFO - validation batch 101, loss: 1.546, 3232/6976 datapoints
2025-03-06 22:17:12,961 - INFO - validation batch 151, loss: 2.593, 4832/6976 datapoints
2025-03-06 22:17:13,012 - INFO - validation batch 201, loss: 1.397, 6432/6976 datapoints
2025-03-06 22:17:13,036 - INFO - Epoch 660/800 done.
2025-03-06 22:17:13,037 - INFO - Final validation performance:
Loss: 2.944, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:17:13,037 - INFO - Beginning epoch 661/800
2025-03-06 22:17:13,042 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:17:13,263 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:17:13,447 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:17:13,630 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:13,810 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:17:14,000 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:17:14,183 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:17:14,364 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:17:14,540 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:17:14,722 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:17:14,903 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:17:15,084 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:17:15,275 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:17:15,455 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:15,634 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:17:15,820 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:16,010 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:16,192 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:17:16,287 - INFO - validation batch 1, loss: 0.280, 32/6976 datapoints
2025-03-06 22:17:16,349 - INFO - validation batch 51, loss: 8.868, 1632/6976 datapoints
2025-03-06 22:17:16,410 - INFO - validation batch 101, loss: 1.525, 3232/6976 datapoints
2025-03-06 22:17:16,462 - INFO - validation batch 151, loss: 2.527, 4832/6976 datapoints
2025-03-06 22:17:16,513 - INFO - validation batch 201, loss: 1.338, 6432/6976 datapoints
2025-03-06 22:17:16,534 - INFO - Epoch 661/800 done.
2025-03-06 22:17:16,534 - INFO - Final validation performance:
Loss: 2.908, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:17:16,534 - INFO - Beginning epoch 662/800
2025-03-06 22:17:16,539 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:17:16,720 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:17:16,902 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:17:17,084 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:17,268 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:17:17,454 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:17:17,638 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:17:17,825 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:17:18,001 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:17:18,180 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:17:18,358 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:17:18,536 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:17:18,715 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:17:18,897 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:19,075 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:17:19,260 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:19,456 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:19,640 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:17:19,740 - INFO - validation batch 1, loss: 0.263, 32/6976 datapoints
2025-03-06 22:17:19,791 - INFO - validation batch 51, loss: 8.897, 1632/6976 datapoints
2025-03-06 22:17:19,842 - INFO - validation batch 101, loss: 1.522, 3232/6976 datapoints
2025-03-06 22:17:19,896 - INFO - validation batch 151, loss: 2.527, 4832/6976 datapoints
2025-03-06 22:17:19,947 - INFO - validation batch 201, loss: 1.326, 6432/6976 datapoints
2025-03-06 22:17:19,967 - INFO - Epoch 662/800 done.
2025-03-06 22:17:19,967 - INFO - Final validation performance:
Loss: 2.907, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:17:19,967 - INFO - Beginning epoch 663/800
2025-03-06 22:17:19,972 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:17:20,156 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:17:20,344 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:17:20,531 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:20,712 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:17:20,903 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:17:21,090 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:17:21,284 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:17:21,463 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:17:21,646 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:17:21,827 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:17:22,028 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:17:22,211 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:17:22,391 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:22,577 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:17:22,771 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:22,960 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:23,155 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:17:23,252 - INFO - validation batch 1, loss: 0.255, 32/6976 datapoints
2025-03-06 22:17:23,305 - INFO - validation batch 51, loss: 8.894, 1632/6976 datapoints
2025-03-06 22:17:23,357 - INFO - validation batch 101, loss: 1.535, 3232/6976 datapoints
2025-03-06 22:17:23,412 - INFO - validation batch 151, loss: 2.558, 4832/6976 datapoints
2025-03-06 22:17:23,465 - INFO - validation batch 201, loss: 1.326, 6432/6976 datapoints
2025-03-06 22:17:23,487 - INFO - Epoch 663/800 done.
2025-03-06 22:17:23,487 - INFO - Final validation performance:
Loss: 2.914, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:17:23,487 - INFO - Beginning epoch 664/800
2025-03-06 22:17:23,492 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:17:23,673 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:17:23,856 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:17:24,046 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:24,261 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:17:24,445 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:17:24,626 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:17:24,816 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:17:24,993 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:17:25,180 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:17:25,365 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:17:25,543 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:17:25,719 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:17:25,903 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:26,084 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:17:26,271 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:26,456 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:26,641 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:17:26,736 - INFO - validation batch 1, loss: 0.232, 32/6976 datapoints
2025-03-06 22:17:26,790 - INFO - validation batch 51, loss: 8.906, 1632/6976 datapoints
2025-03-06 22:17:26,840 - INFO - validation batch 101, loss: 1.544, 3232/6976 datapoints
2025-03-06 22:17:26,895 - INFO - validation batch 151, loss: 2.581, 4832/6976 datapoints
2025-03-06 22:17:26,946 - INFO - validation batch 201, loss: 1.325, 6432/6976 datapoints
2025-03-06 22:17:26,965 - INFO - Epoch 664/800 done.
2025-03-06 22:17:26,965 - INFO - Final validation performance:
Loss: 2.917, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:17:26,971 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:17:27,149 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:17:27,413 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:17:27,593 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:27,772 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:17:27,959 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:17:28,146 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:17:28,329 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:17:28,502 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:17:28,683 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:17:28,878 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:17:29,058 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:17:29,243 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:17:29,431 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:29,614 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:17:29,800 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:29,988 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:30,167 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:17:30,261 - INFO - validation batch 1, loss: 0.211, 32/6976 datapoints
2025-03-06 22:17:30,314 - INFO - validation batch 51, loss: 8.932, 1632/6976 datapoints
2025-03-06 22:17:30,373 - INFO - validation batch 101, loss: 1.552, 3232/6976 datapoints
2025-03-06 22:17:30,422 - INFO - validation batch 151, loss: 2.611, 4832/6976 datapoints
2025-03-06 22:17:30,474 - INFO - validation batch 201, loss: 1.321, 6432/6976 datapoints
2025-03-06 22:17:30,490 - INFO - Epoch 665/800 done.
2025-03-06 22:17:30,490 - INFO - Final validation performance:
Loss: 2.925, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:17:30,491 - INFO - Beginning epoch 666/800
2025-03-06 22:17:30,495 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:17:30,668 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:17:30,845 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:17:31,029 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:31,205 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:17:31,388 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:17:31,568 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:17:31,748 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:17:31,923 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:17:32,118 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:17:32,301 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:17:32,481 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:17:32,656 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:17:32,835 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:33,014 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:17:33,197 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:33,380 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:33,559 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:17:33,648 - INFO - validation batch 1, loss: 0.204, 32/6976 datapoints
2025-03-06 22:17:33,695 - INFO - validation batch 51, loss: 8.962, 1632/6976 datapoints
2025-03-06 22:17:33,742 - INFO - validation batch 101, loss: 1.572, 3232/6976 datapoints
2025-03-06 22:17:33,789 - INFO - validation batch 151, loss: 2.692, 4832/6976 datapoints
2025-03-06 22:17:33,836 - INFO - validation batch 201, loss: 1.324, 6432/6976 datapoints
2025-03-06 22:17:33,851 - INFO - Epoch 666/800 done.
2025-03-06 22:17:33,852 - INFO - Final validation performance:
Loss: 2.951, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:17:33,852 - INFO - Beginning epoch 667/800
2025-03-06 22:17:33,857 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:17:34,033 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:17:34,208 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:17:34,386 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:34,562 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:17:34,743 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:17:34,943 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:17:35,181 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:17:35,383 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:17:35,603 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:17:35,784 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:17:35,989 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:17:36,185 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:17:36,368 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:36,549 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:17:36,737 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:36,924 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:37,108 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:17:37,198 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 22:17:37,245 - INFO - validation batch 51, loss: 8.950, 1632/6976 datapoints
2025-03-06 22:17:37,292 - INFO - validation batch 101, loss: 1.628, 3232/6976 datapoints
2025-03-06 22:17:37,338 - INFO - validation batch 151, loss: 2.940, 4832/6976 datapoints
2025-03-06 22:17:37,387 - INFO - validation batch 201, loss: 1.354, 6432/6976 datapoints
2025-03-06 22:17:37,405 - INFO - Epoch 667/800 done.
2025-03-06 22:17:37,406 - INFO - Final validation performance:
Loss: 3.001, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:17:37,406 - INFO - Beginning epoch 668/800
2025-03-06 22:17:37,412 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:17:37,591 - INFO - training batch 51, loss: 0.555, 1632/28000 datapoints
2025-03-06 22:17:37,771 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:17:37,978 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:17:38,158 - INFO - training batch 201, loss: 0.180, 6432/28000 datapoints
2025-03-06 22:17:38,344 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:17:38,524 - INFO - training batch 301, loss: 0.035, 9632/28000 datapoints
2025-03-06 22:17:38,702 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:17:38,879 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:17:39,058 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:17:39,236 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:17:39,420 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:17:39,594 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:17:39,774 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:39,951 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:17:40,133 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:40,312 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:40,488 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:17:40,577 - INFO - validation batch 1, loss: 0.245, 32/6976 datapoints
2025-03-06 22:17:40,624 - INFO - validation batch 51, loss: 8.919, 1632/6976 datapoints
2025-03-06 22:17:40,671 - INFO - validation batch 101, loss: 1.805, 3232/6976 datapoints
2025-03-06 22:17:40,717 - INFO - validation batch 151, loss: 2.761, 4832/6976 datapoints
2025-03-06 22:17:40,765 - INFO - validation batch 201, loss: 1.364, 6432/6976 datapoints
2025-03-06 22:17:40,781 - INFO - Epoch 668/800 done.
2025-03-06 22:17:40,781 - INFO - Final validation performance:
Loss: 3.019, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:17:40,782 - INFO - Beginning epoch 669/800
2025-03-06 22:17:40,787 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:17:40,963 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:17:41,144 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:17:41,330 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:41,515 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:17:41,696 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 22:17:41,885 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:17:42,067 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:17:42,266 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:17:42,442 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:17:42,618 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:17:42,793 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:17:42,968 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:17:43,145 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:43,318 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:17:43,502 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:43,685 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:43,863 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:17:43,956 - INFO - validation batch 1, loss: 0.220, 32/6976 datapoints
2025-03-06 22:17:44,002 - INFO - validation batch 51, loss: 8.944, 1632/6976 datapoints
2025-03-06 22:17:44,050 - INFO - validation batch 101, loss: 1.768, 3232/6976 datapoints
2025-03-06 22:17:44,096 - INFO - validation batch 151, loss: 2.553, 4832/6976 datapoints
2025-03-06 22:17:44,143 - INFO - validation batch 201, loss: 1.326, 6432/6976 datapoints
2025-03-06 22:17:44,159 - INFO - Epoch 669/800 done.
2025-03-06 22:17:44,159 - INFO - Final validation performance:
Loss: 2.962, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:17:44,160 - INFO - Beginning epoch 670/800
2025-03-06 22:17:44,165 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:17:44,341 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:17:44,516 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:17:44,697 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:44,870 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:17:45,051 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:17:45,239 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:17:45,422 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:17:45,593 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:17:45,774 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:17:45,956 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:17:46,135 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:17:46,312 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:17:46,487 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:46,661 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:17:46,844 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:47,030 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:47,210 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:17:47,298 - INFO - validation batch 1, loss: 0.141, 32/6976 datapoints
2025-03-06 22:17:47,344 - INFO - validation batch 51, loss: 9.006, 1632/6976 datapoints
2025-03-06 22:17:47,391 - INFO - validation batch 101, loss: 1.729, 3232/6976 datapoints
2025-03-06 22:17:47,445 - INFO - validation batch 151, loss: 2.646, 4832/6976 datapoints
2025-03-06 22:17:47,492 - INFO - validation batch 201, loss: 1.282, 6432/6976 datapoints
2025-03-06 22:17:47,507 - INFO - Epoch 670/800 done.
2025-03-06 22:17:47,508 - INFO - Final validation performance:
Loss: 2.961, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:17:47,508 - INFO - Beginning epoch 671/800
2025-03-06 22:17:47,512 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:17:47,701 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:17:47,882 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:17:48,073 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:48,252 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:17:48,434 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:17:48,618 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:17:48,800 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:17:48,976 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:17:49,157 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:17:49,334 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:17:49,519 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:17:49,698 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:17:49,885 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:50,062 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:17:50,251 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:50,435 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:50,616 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:17:50,708 - INFO - validation batch 1, loss: 0.169, 32/6976 datapoints
2025-03-06 22:17:50,761 - INFO - validation batch 51, loss: 8.932, 1632/6976 datapoints
2025-03-06 22:17:50,813 - INFO - validation batch 101, loss: 1.700, 3232/6976 datapoints
2025-03-06 22:17:50,863 - INFO - validation batch 151, loss: 2.710, 4832/6976 datapoints
2025-03-06 22:17:50,916 - INFO - validation batch 201, loss: 1.290, 6432/6976 datapoints
2025-03-06 22:17:50,935 - INFO - Epoch 671/800 done.
2025-03-06 22:17:50,936 - INFO - Final validation performance:
Loss: 2.960, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:17:50,936 - INFO - Beginning epoch 672/800
2025-03-06 22:17:50,940 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:17:51,123 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:17:51,305 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:17:51,492 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:51,675 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:17:51,863 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:17:52,053 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:17:52,268 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:17:52,463 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:17:52,648 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:17:52,836 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:17:53,023 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:17:53,210 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:17:53,396 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:53,584 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:17:53,777 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:53,976 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:54,162 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:17:54,262 - INFO - validation batch 1, loss: 0.169, 32/6976 datapoints
2025-03-06 22:17:54,313 - INFO - validation batch 51, loss: 9.007, 1632/6976 datapoints
2025-03-06 22:17:54,359 - INFO - validation batch 101, loss: 1.663, 3232/6976 datapoints
2025-03-06 22:17:54,410 - INFO - validation batch 151, loss: 2.703, 4832/6976 datapoints
2025-03-06 22:17:54,457 - INFO - validation batch 201, loss: 1.268, 6432/6976 datapoints
2025-03-06 22:17:54,474 - INFO - Epoch 672/800 done.
2025-03-06 22:17:54,474 - INFO - Final validation performance:
Loss: 2.962, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:17:54,475 - INFO - Beginning epoch 673/800
2025-03-06 22:17:54,479 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:17:54,658 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:17:54,834 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:17:55,013 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:55,196 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:17:55,374 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:17:55,556 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:17:55,736 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:17:55,907 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:17:56,087 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:17:56,274 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:17:56,453 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:17:56,626 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:17:56,804 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:17:56,982 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:17:57,164 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:17:57,346 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:17:57,532 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:17:57,620 - INFO - validation batch 1, loss: 0.172, 32/6976 datapoints
2025-03-06 22:17:57,668 - INFO - validation batch 51, loss: 9.030, 1632/6976 datapoints
2025-03-06 22:17:57,713 - INFO - validation batch 101, loss: 1.656, 3232/6976 datapoints
2025-03-06 22:17:57,760 - INFO - validation batch 151, loss: 2.741, 4832/6976 datapoints
2025-03-06 22:17:57,806 - INFO - validation batch 201, loss: 1.273, 6432/6976 datapoints
2025-03-06 22:17:57,822 - INFO - Epoch 673/800 done.
2025-03-06 22:17:57,822 - INFO - Final validation performance:
Loss: 2.974, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:17:57,823 - INFO - Beginning epoch 674/800
2025-03-06 22:17:57,828 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:17:58,004 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:17:58,184 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:17:58,364 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:17:58,538 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:17:58,720 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:17:58,904 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:17:59,084 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:17:59,254 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:17:59,430 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:17:59,610 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:17:59,786 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:17:59,969 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:18:00,153 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:00,329 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:00,511 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:00,699 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:00,885 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:18:00,977 - INFO - validation batch 1, loss: 0.166, 32/6976 datapoints
2025-03-06 22:18:01,025 - INFO - validation batch 51, loss: 9.049, 1632/6976 datapoints
2025-03-06 22:18:01,073 - INFO - validation batch 101, loss: 1.649, 3232/6976 datapoints
2025-03-06 22:18:01,121 - INFO - validation batch 151, loss: 2.758, 4832/6976 datapoints
2025-03-06 22:18:01,168 - INFO - validation batch 201, loss: 1.285, 6432/6976 datapoints
2025-03-06 22:18:01,183 - INFO - Epoch 674/800 done.
2025-03-06 22:18:01,184 - INFO - Final validation performance:
Loss: 2.981, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:18:01,184 - INFO - Beginning epoch 675/800
2025-03-06 22:18:01,188 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:18:01,364 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:18:01,547 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:01,727 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:18:01,904 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:18:02,086 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:18:02,267 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:18:02,471 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:18:02,641 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:18:02,821 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:18:02,999 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:03,178 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:18:03,352 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:18:03,531 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:03,709 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:03,895 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:04,078 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:04,259 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:18:04,348 - INFO - validation batch 1, loss: 0.158, 32/6976 datapoints
2025-03-06 22:18:04,397 - INFO - validation batch 51, loss: 9.076, 1632/6976 datapoints
2025-03-06 22:18:04,444 - INFO - validation batch 101, loss: 1.639, 3232/6976 datapoints
2025-03-06 22:18:04,491 - INFO - validation batch 151, loss: 2.764, 4832/6976 datapoints
2025-03-06 22:18:04,538 - INFO - validation batch 201, loss: 1.297, 6432/6976 datapoints
2025-03-06 22:18:04,554 - INFO - Epoch 675/800 done.
2025-03-06 22:18:04,555 - INFO - Final validation performance:
Loss: 2.987, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:18:04,555 - INFO - Beginning epoch 676/800
2025-03-06 22:18:04,559 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:18:04,731 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:18:04,913 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:05,093 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:18:05,274 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:18:05,455 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:18:05,636 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:18:05,820 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:18:06,005 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:18:06,191 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:18:06,375 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:06,558 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:18:06,734 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:18:06,916 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:07,097 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:07,282 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:07,464 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:07,650 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:18:07,739 - INFO - validation batch 1, loss: 0.162, 32/6976 datapoints
2025-03-06 22:18:07,786 - INFO - validation batch 51, loss: 9.115, 1632/6976 datapoints
2025-03-06 22:18:07,834 - INFO - validation batch 101, loss: 1.636, 3232/6976 datapoints
2025-03-06 22:18:07,883 - INFO - validation batch 151, loss: 2.769, 4832/6976 datapoints
2025-03-06 22:18:07,930 - INFO - validation batch 201, loss: 1.302, 6432/6976 datapoints
2025-03-06 22:18:07,948 - INFO - Epoch 676/800 done.
2025-03-06 22:18:07,948 - INFO - Final validation performance:
Loss: 2.997, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:18:07,948 - INFO - Beginning epoch 677/800
2025-03-06 22:18:07,953 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:18:08,128 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:18:08,309 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:08,491 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:18:08,669 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:18:08,858 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:18:09,076 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:18:09,299 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:18:09,506 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:18:09,709 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:18:09,899 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:10,095 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:18:10,277 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:18:10,464 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:10,646 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:10,838 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:11,032 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:11,222 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:18:11,315 - INFO - validation batch 1, loss: 0.175, 32/6976 datapoints
2025-03-06 22:18:11,367 - INFO - validation batch 51, loss: 9.172, 1632/6976 datapoints
2025-03-06 22:18:11,418 - INFO - validation batch 101, loss: 1.667, 3232/6976 datapoints
2025-03-06 22:18:11,466 - INFO - validation batch 151, loss: 2.840, 4832/6976 datapoints
2025-03-06 22:18:11,516 - INFO - validation batch 201, loss: 1.319, 6432/6976 datapoints
2025-03-06 22:18:11,533 - INFO - Epoch 677/800 done.
2025-03-06 22:18:11,533 - INFO - Final validation performance:
Loss: 3.035, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:18:11,534 - INFO - Beginning epoch 678/800
2025-03-06 22:18:11,538 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:18:11,717 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:18:11,902 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:12,096 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:18:12,280 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:18:12,469 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:18:12,673 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:18:12,857 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:18:13,042 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:18:13,245 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:18:13,428 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:13,608 - INFO - training batch 551, loss: 0.137, 17632/28000 datapoints
2025-03-06 22:18:13,781 - INFO - training batch 601, loss: 0.006, 19232/28000 datapoints
2025-03-06 22:18:13,976 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:14,180 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:18:14,397 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:18:14,580 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:14,756 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:18:14,847 - INFO - validation batch 1, loss: 0.343, 32/6976 datapoints
2025-03-06 22:18:14,897 - INFO - validation batch 51, loss: 9.440, 1632/6976 datapoints
2025-03-06 22:18:14,944 - INFO - validation batch 101, loss: 1.916, 3232/6976 datapoints
2025-03-06 22:18:14,991 - INFO - validation batch 151, loss: 2.939, 4832/6976 datapoints
2025-03-06 22:18:15,038 - INFO - validation batch 201, loss: 1.464, 6432/6976 datapoints
2025-03-06 22:18:15,054 - INFO - Epoch 678/800 done.
2025-03-06 22:18:15,054 - INFO - Final validation performance:
Loss: 3.220, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:18:15,054 - INFO - Beginning epoch 679/800
2025-03-06 22:18:15,060 - INFO - training batch 1, loss: 0.022, 32/28000 datapoints
2025-03-06 22:18:15,237 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:18:15,418 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:15,601 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:18:15,777 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:18:15,966 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:18:16,152 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:18:16,334 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:18:16,510 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:18:16,690 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:18:16,867 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:17,051 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:18:17,227 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-06 22:18:17,403 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:17,587 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:17,771 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:17,957 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:18,136 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:18:18,227 - INFO - validation batch 1, loss: 0.055, 32/6976 datapoints
2025-03-06 22:18:18,274 - INFO - validation batch 51, loss: 9.805, 1632/6976 datapoints
2025-03-06 22:18:18,328 - INFO - validation batch 101, loss: 1.717, 3232/6976 datapoints
2025-03-06 22:18:18,383 - INFO - validation batch 151, loss: 2.915, 4832/6976 datapoints
2025-03-06 22:18:18,433 - INFO - validation batch 201, loss: 1.426, 6432/6976 datapoints
2025-03-06 22:18:18,449 - INFO - Epoch 679/800 done.
2025-03-06 22:18:18,449 - INFO - Final validation performance:
Loss: 3.183, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:18:18,450 - INFO - Beginning epoch 680/800
2025-03-06 22:18:18,454 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:18:18,629 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:18:18,808 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:18,992 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:18:19,170 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:18:19,352 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:18:19,538 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:18:19,717 - INFO - training batch 351, loss: 0.396, 11232/28000 datapoints
2025-03-06 22:18:19,895 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:18:20,071 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:18:20,249 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:20,426 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:18:20,603 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:18:20,782 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:20,965 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:21,151 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:21,342 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:21,526 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:18:21,619 - INFO - validation batch 1, loss: 0.174, 32/6976 datapoints
2025-03-06 22:18:21,666 - INFO - validation batch 51, loss: 9.442, 1632/6976 datapoints
2025-03-06 22:18:21,714 - INFO - validation batch 101, loss: 1.695, 3232/6976 datapoints
2025-03-06 22:18:21,781 - INFO - validation batch 151, loss: 2.870, 4832/6976 datapoints
2025-03-06 22:18:21,830 - INFO - validation batch 201, loss: 1.231, 6432/6976 datapoints
2025-03-06 22:18:21,846 - INFO - Epoch 680/800 done.
2025-03-06 22:18:21,846 - INFO - Final validation performance:
Loss: 3.082, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:18:21,847 - INFO - Beginning epoch 681/800
2025-03-06 22:18:21,851 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:18:22,027 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:18:22,203 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:22,383 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:18:22,563 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:18:22,760 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:18:22,942 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:18:23,127 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:18:23,303 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:18:23,487 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:18:23,669 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:23,845 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:18:24,026 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:18:24,205 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:24,380 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:24,625 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:24,808 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:24,986 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:18:25,079 - INFO - validation batch 1, loss: 0.149, 32/6976 datapoints
2025-03-06 22:18:25,135 - INFO - validation batch 51, loss: 9.133, 1632/6976 datapoints
2025-03-06 22:18:25,197 - INFO - validation batch 101, loss: 1.597, 3232/6976 datapoints
2025-03-06 22:18:25,246 - INFO - validation batch 151, loss: 2.836, 4832/6976 datapoints
2025-03-06 22:18:25,293 - INFO - validation batch 201, loss: 1.354, 6432/6976 datapoints
2025-03-06 22:18:25,313 - INFO - Epoch 681/800 done.
2025-03-06 22:18:25,313 - INFO - Final validation performance:
Loss: 3.014, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:18:25,314 - INFO - Beginning epoch 682/800
2025-03-06 22:18:25,319 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:18:25,495 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:18:25,680 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:25,860 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:18:26,040 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:18:26,222 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:18:26,403 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:18:26,586 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:18:26,759 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:18:26,940 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:18:27,118 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:27,295 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:18:27,468 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:18:27,654 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:27,832 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:28,020 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:28,205 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:28,383 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:18:28,474 - INFO - validation batch 1, loss: 0.155, 32/6976 datapoints
2025-03-06 22:18:28,521 - INFO - validation batch 51, loss: 9.271, 1632/6976 datapoints
2025-03-06 22:18:28,570 - INFO - validation batch 101, loss: 1.545, 3232/6976 datapoints
2025-03-06 22:18:28,616 - INFO - validation batch 151, loss: 2.734, 4832/6976 datapoints
2025-03-06 22:18:28,663 - INFO - validation batch 201, loss: 1.288, 6432/6976 datapoints
2025-03-06 22:18:28,680 - INFO - Epoch 682/800 done.
2025-03-06 22:18:28,680 - INFO - Final validation performance:
Loss: 2.999, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:18:28,682 - INFO - Beginning epoch 683/800
2025-03-06 22:18:28,686 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:18:28,856 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:18:29,044 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:29,231 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:18:29,408 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:18:29,598 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:18:29,786 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:18:29,972 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:18:30,150 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:18:30,335 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:18:30,516 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:30,711 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:18:30,892 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:18:31,074 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:31,254 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:31,458 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:31,654 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:31,842 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:18:31,941 - INFO - validation batch 1, loss: 0.149, 32/6976 datapoints
2025-03-06 22:18:31,993 - INFO - validation batch 51, loss: 9.312, 1632/6976 datapoints
2025-03-06 22:18:32,045 - INFO - validation batch 101, loss: 1.576, 3232/6976 datapoints
2025-03-06 22:18:32,097 - INFO - validation batch 151, loss: 2.719, 4832/6976 datapoints
2025-03-06 22:18:32,150 - INFO - validation batch 201, loss: 1.279, 6432/6976 datapoints
2025-03-06 22:18:32,170 - INFO - Epoch 683/800 done.
2025-03-06 22:18:32,170 - INFO - Final validation performance:
Loss: 3.007, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:18:32,171 - INFO - Beginning epoch 684/800
2025-03-06 22:18:32,176 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:18:32,359 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:18:32,544 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:32,758 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:18:32,951 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:18:33,138 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:18:33,327 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:18:33,513 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:18:33,701 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:18:33,887 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:18:34,070 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:34,252 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:18:34,429 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:18:34,610 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:34,790 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:34,978 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:35,172 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:35,354 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:18:35,448 - INFO - validation batch 1, loss: 0.161, 32/6976 datapoints
2025-03-06 22:18:35,499 - INFO - validation batch 51, loss: 9.264, 1632/6976 datapoints
2025-03-06 22:18:35,551 - INFO - validation batch 101, loss: 1.596, 3232/6976 datapoints
2025-03-06 22:18:35,604 - INFO - validation batch 151, loss: 2.758, 4832/6976 datapoints
2025-03-06 22:18:35,659 - INFO - validation batch 201, loss: 1.284, 6432/6976 datapoints
2025-03-06 22:18:35,681 - INFO - Epoch 684/800 done.
2025-03-06 22:18:35,681 - INFO - Final validation performance:
Loss: 3.013, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:18:35,682 - INFO - Beginning epoch 685/800
2025-03-06 22:18:35,687 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:18:35,863 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:18:36,045 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:36,231 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:18:36,412 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:18:36,596 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:18:36,797 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:18:36,980 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:18:37,165 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:18:37,353 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:18:37,540 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:37,732 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:18:37,924 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:18:38,105 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:38,285 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:38,471 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:38,658 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:38,842 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:18:38,939 - INFO - validation batch 1, loss: 0.166, 32/6976 datapoints
2025-03-06 22:18:38,992 - INFO - validation batch 51, loss: 9.274, 1632/6976 datapoints
2025-03-06 22:18:39,044 - INFO - validation batch 101, loss: 1.624, 3232/6976 datapoints
2025-03-06 22:18:39,094 - INFO - validation batch 151, loss: 2.799, 4832/6976 datapoints
2025-03-06 22:18:39,145 - INFO - validation batch 201, loss: 1.285, 6432/6976 datapoints
2025-03-06 22:18:39,163 - INFO - Epoch 685/800 done.
2025-03-06 22:18:39,163 - INFO - Final validation performance:
Loss: 3.030, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:18:39,164 - INFO - Beginning epoch 686/800
2025-03-06 22:18:39,171 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:18:39,352 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:18:39,527 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:39,711 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:18:39,890 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:18:40,071 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:18:40,254 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:18:40,432 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:18:40,604 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:18:40,788 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:18:40,968 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:41,145 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:18:41,319 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:18:41,494 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:41,672 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:41,857 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:42,042 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:42,222 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:18:42,312 - INFO - validation batch 1, loss: 0.177, 32/6976 datapoints
2025-03-06 22:18:42,358 - INFO - validation batch 51, loss: 9.286, 1632/6976 datapoints
2025-03-06 22:18:42,405 - INFO - validation batch 101, loss: 1.644, 3232/6976 datapoints
2025-03-06 22:18:42,452 - INFO - validation batch 151, loss: 2.822, 4832/6976 datapoints
2025-03-06 22:18:42,498 - INFO - validation batch 201, loss: 1.299, 6432/6976 datapoints
2025-03-06 22:18:42,514 - INFO - Epoch 686/800 done.
2025-03-06 22:18:42,514 - INFO - Final validation performance:
Loss: 3.046, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:18:42,514 - INFO - Beginning epoch 687/800
2025-03-06 22:18:42,519 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:18:42,688 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:18:42,893 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:43,094 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:18:43,274 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:18:43,464 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:18:43,657 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:18:43,844 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:18:44,026 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:18:44,210 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:18:44,401 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:44,582 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:18:44,761 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:18:44,939 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:45,117 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:45,305 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:45,488 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:45,668 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:18:45,758 - INFO - validation batch 1, loss: 0.186, 32/6976 datapoints
2025-03-06 22:18:45,805 - INFO - validation batch 51, loss: 9.316, 1632/6976 datapoints
2025-03-06 22:18:45,851 - INFO - validation batch 101, loss: 1.647, 3232/6976 datapoints
2025-03-06 22:18:45,899 - INFO - validation batch 151, loss: 2.837, 4832/6976 datapoints
2025-03-06 22:18:45,946 - INFO - validation batch 201, loss: 1.310, 6432/6976 datapoints
2025-03-06 22:18:45,961 - INFO - Epoch 687/800 done.
2025-03-06 22:18:45,962 - INFO - Final validation performance:
Loss: 3.059, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:18:45,962 - INFO - Beginning epoch 688/800
2025-03-06 22:18:45,967 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:18:46,153 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:18:46,333 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:46,512 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:18:46,687 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:18:46,870 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:18:47,057 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:18:47,240 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:18:47,412 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:18:47,592 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:18:47,777 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:47,960 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:18:48,136 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:18:48,313 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:48,487 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:48,675 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:48,857 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:49,044 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:18:49,138 - INFO - validation batch 1, loss: 0.231, 32/6976 datapoints
2025-03-06 22:18:49,188 - INFO - validation batch 51, loss: 9.382, 1632/6976 datapoints
2025-03-06 22:18:49,243 - INFO - validation batch 101, loss: 1.657, 3232/6976 datapoints
2025-03-06 22:18:49,308 - INFO - validation batch 151, loss: 2.853, 4832/6976 datapoints
2025-03-06 22:18:49,359 - INFO - validation batch 201, loss: 1.314, 6432/6976 datapoints
2025-03-06 22:18:49,378 - INFO - Epoch 688/800 done.
2025-03-06 22:18:49,379 - INFO - Final validation performance:
Loss: 3.087, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:18:49,379 - INFO - Beginning epoch 689/800
2025-03-06 22:18:49,384 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:18:49,563 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:18:49,748 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:49,941 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:18:50,117 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:18:50,304 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:18:50,491 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:18:50,676 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:18:50,853 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:18:51,040 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:18:51,222 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:51,406 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:18:51,586 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:18:51,770 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:51,954 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:52,143 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:52,336 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:52,520 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:18:52,613 - INFO - validation batch 1, loss: 0.253, 32/6976 datapoints
2025-03-06 22:18:52,664 - INFO - validation batch 51, loss: 9.444, 1632/6976 datapoints
2025-03-06 22:18:52,716 - INFO - validation batch 101, loss: 1.690, 3232/6976 datapoints
2025-03-06 22:18:52,766 - INFO - validation batch 151, loss: 2.978, 4832/6976 datapoints
2025-03-06 22:18:52,816 - INFO - validation batch 201, loss: 1.323, 6432/6976 datapoints
2025-03-06 22:18:52,840 - INFO - Epoch 689/800 done.
2025-03-06 22:18:52,840 - INFO - Final validation performance:
Loss: 3.138, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:18:52,840 - INFO - Beginning epoch 690/800
2025-03-06 22:18:52,846 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:18:53,046 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:18:53,230 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:53,417 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:18:53,602 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:18:53,794 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:18:53,989 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:18:54,172 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:18:54,354 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:18:54,538 - INFO - training batch 451, loss: 0.101, 14432/28000 datapoints
2025-03-06 22:18:54,719 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:18:54,906 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:18:55,082 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:18:55,280 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:18:55,461 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:55,663 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:18:55,854 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:56,052 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:18:56,151 - INFO - validation batch 1, loss: 0.839, 32/6976 datapoints
2025-03-06 22:18:56,204 - INFO - validation batch 51, loss: 9.180, 1632/6976 datapoints
2025-03-06 22:18:56,258 - INFO - validation batch 101, loss: 1.979, 3232/6976 datapoints
2025-03-06 22:18:56,310 - INFO - validation batch 151, loss: 3.648, 4832/6976 datapoints
2025-03-06 22:18:56,364 - INFO - validation batch 201, loss: 1.521, 6432/6976 datapoints
2025-03-06 22:18:56,388 - INFO - Epoch 690/800 done.
2025-03-06 22:18:56,388 - INFO - Final validation performance:
Loss: 3.433, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 22:18:56,389 - INFO - Beginning epoch 691/800
2025-03-06 22:18:56,394 - INFO - training batch 1, loss: 0.013, 32/28000 datapoints
2025-03-06 22:18:56,576 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:18:56,771 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:18:56,963 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:18:57,148 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:18:57,336 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:18:57,527 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:18:57,722 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:18:57,910 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:18:58,096 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:18:58,281 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:18:58,463 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:18:58,637 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:18:58,821 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:18:59,002 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:18:59,190 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:18:59,378 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:18:59,563 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:18:59,657 - INFO - validation batch 1, loss: 0.256, 32/6976 datapoints
2025-03-06 22:18:59,714 - INFO - validation batch 51, loss: 9.014, 1632/6976 datapoints
2025-03-06 22:18:59,766 - INFO - validation batch 101, loss: 1.733, 3232/6976 datapoints
2025-03-06 22:18:59,815 - INFO - validation batch 151, loss: 2.660, 4832/6976 datapoints
2025-03-06 22:18:59,866 - INFO - validation batch 201, loss: 1.363, 6432/6976 datapoints
2025-03-06 22:18:59,888 - INFO - Epoch 691/800 done.
2025-03-06 22:18:59,888 - INFO - Final validation performance:
Loss: 3.005, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:18:59,889 - INFO - Beginning epoch 692/800
2025-03-06 22:18:59,893 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:19:00,074 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:00,254 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:19:00,438 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:19:00,617 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:19:00,802 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:19:00,990 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:19:01,170 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:19:01,347 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:19:01,536 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:19:01,732 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:19:01,919 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:19:02,104 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:19:02,294 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:02,475 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:19:02,664 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:19:02,853 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:19:03,061 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:19:03,155 - INFO - validation batch 1, loss: 0.321, 32/6976 datapoints
2025-03-06 22:19:03,206 - INFO - validation batch 51, loss: 9.204, 1632/6976 datapoints
2025-03-06 22:19:03,258 - INFO - validation batch 101, loss: 1.675, 3232/6976 datapoints
2025-03-06 22:19:03,309 - INFO - validation batch 151, loss: 2.448, 4832/6976 datapoints
2025-03-06 22:19:03,359 - INFO - validation batch 201, loss: 1.349, 6432/6976 datapoints
2025-03-06 22:19:03,379 - INFO - Epoch 692/800 done.
2025-03-06 22:19:03,379 - INFO - Final validation performance:
Loss: 2.999, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:19:03,380 - INFO - Beginning epoch 693/800
2025-03-06 22:19:03,385 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:19:03,565 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:03,748 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:19:03,938 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:19:04,119 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:19:04,305 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:19:04,492 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:19:04,674 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:19:04,853 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:19:05,040 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:19:05,226 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:19:05,407 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:19:05,586 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:19:05,770 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:05,953 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:06,158 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:19:06,347 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:06,532 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:19:06,626 - INFO - validation batch 1, loss: 0.249, 32/6976 datapoints
2025-03-06 22:19:06,677 - INFO - validation batch 51, loss: 9.248, 1632/6976 datapoints
2025-03-06 22:19:06,728 - INFO - validation batch 101, loss: 1.649, 3232/6976 datapoints
2025-03-06 22:19:06,780 - INFO - validation batch 151, loss: 2.383, 4832/6976 datapoints
2025-03-06 22:19:06,830 - INFO - validation batch 201, loss: 1.304, 6432/6976 datapoints
2025-03-06 22:19:06,847 - INFO - Epoch 693/800 done.
2025-03-06 22:19:06,847 - INFO - Final validation performance:
Loss: 2.967, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:19:06,847 - INFO - Beginning epoch 694/800
2025-03-06 22:19:06,852 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:19:07,034 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:07,217 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:19:07,404 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:19:07,583 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:19:07,792 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:19:07,987 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:19:08,181 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:19:08,368 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:19:08,563 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:19:08,746 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:19:08,938 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:19:09,121 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:19:09,313 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:09,494 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:09,687 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:19:09,883 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:10,068 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:19:10,161 - INFO - validation batch 1, loss: 0.250, 32/6976 datapoints
2025-03-06 22:19:10,212 - INFO - validation batch 51, loss: 9.275, 1632/6976 datapoints
2025-03-06 22:19:10,264 - INFO - validation batch 101, loss: 1.644, 3232/6976 datapoints
2025-03-06 22:19:10,315 - INFO - validation batch 151, loss: 2.435, 4832/6976 datapoints
2025-03-06 22:19:10,367 - INFO - validation batch 201, loss: 1.292, 6432/6976 datapoints
2025-03-06 22:19:10,386 - INFO - Epoch 694/800 done.
2025-03-06 22:19:10,386 - INFO - Final validation performance:
Loss: 2.979, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:19:10,387 - INFO - Beginning epoch 695/800
2025-03-06 22:19:10,392 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:19:10,574 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:10,754 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:19:10,942 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:19:11,122 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:19:11,309 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:19:11,498 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:19:11,678 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:19:11,861 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:19:12,047 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:19:12,229 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:19:12,410 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:19:12,587 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:19:12,772 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:12,952 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:13,182 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:19:13,368 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:13,551 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:19:13,644 - INFO - validation batch 1, loss: 0.251, 32/6976 datapoints
2025-03-06 22:19:13,694 - INFO - validation batch 51, loss: 9.268, 1632/6976 datapoints
2025-03-06 22:19:13,747 - INFO - validation batch 101, loss: 1.649, 3232/6976 datapoints
2025-03-06 22:19:13,803 - INFO - validation batch 151, loss: 2.503, 4832/6976 datapoints
2025-03-06 22:19:13,853 - INFO - validation batch 201, loss: 1.292, 6432/6976 datapoints
2025-03-06 22:19:13,872 - INFO - Epoch 695/800 done.
2025-03-06 22:19:13,872 - INFO - Final validation performance:
Loss: 2.992, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:19:13,872 - INFO - Beginning epoch 696/800
2025-03-06 22:19:13,881 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:19:14,064 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:14,248 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:19:14,431 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:19:14,611 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:19:14,796 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:19:14,984 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:19:15,166 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:19:15,342 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:19:15,523 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:19:15,702 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:19:15,885 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:19:16,061 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:19:16,241 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:16,414 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:16,598 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:19:16,781 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:16,964 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:19:17,058 - INFO - validation batch 1, loss: 0.249, 32/6976 datapoints
2025-03-06 22:19:17,104 - INFO - validation batch 51, loss: 9.266, 1632/6976 datapoints
2025-03-06 22:19:17,151 - INFO - validation batch 101, loss: 1.657, 3232/6976 datapoints
2025-03-06 22:19:17,205 - INFO - validation batch 151, loss: 2.575, 4832/6976 datapoints
2025-03-06 22:19:17,251 - INFO - validation batch 201, loss: 1.294, 6432/6976 datapoints
2025-03-06 22:19:17,267 - INFO - Epoch 696/800 done.
2025-03-06 22:19:17,267 - INFO - Final validation performance:
Loss: 3.008, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:19:17,268 - INFO - Beginning epoch 697/800
2025-03-06 22:19:17,272 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:19:17,449 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:17,626 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:19:17,816 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:19:17,993 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:19:18,176 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:19:18,359 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:19:18,536 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:19:18,710 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:19:18,895 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:19:19,075 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:19:19,256 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:19:19,443 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:19:19,625 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:19,803 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:19,992 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:19:20,176 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:20,374 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:19:20,462 - INFO - validation batch 1, loss: 0.248, 32/6976 datapoints
2025-03-06 22:19:20,510 - INFO - validation batch 51, loss: 9.271, 1632/6976 datapoints
2025-03-06 22:19:20,557 - INFO - validation batch 101, loss: 1.662, 3232/6976 datapoints
2025-03-06 22:19:20,603 - INFO - validation batch 151, loss: 2.643, 4832/6976 datapoints
2025-03-06 22:19:20,650 - INFO - validation batch 201, loss: 1.302, 6432/6976 datapoints
2025-03-06 22:19:20,675 - INFO - Epoch 697/800 done.
2025-03-06 22:19:20,675 - INFO - Final validation performance:
Loss: 3.025, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:19:20,676 - INFO - Beginning epoch 698/800
2025-03-06 22:19:20,681 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:19:20,860 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:21,039 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:19:21,222 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:19:21,400 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:19:21,581 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:19:21,763 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:19:21,945 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:19:22,123 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:19:22,305 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:19:22,484 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:19:22,666 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:19:22,846 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:19:23,032 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:23,243 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:23,443 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:19:23,629 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:23,820 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:19:23,917 - INFO - validation batch 1, loss: 0.245, 32/6976 datapoints
2025-03-06 22:19:23,965 - INFO - validation batch 51, loss: 9.292, 1632/6976 datapoints
2025-03-06 22:19:24,018 - INFO - validation batch 101, loss: 1.662, 3232/6976 datapoints
2025-03-06 22:19:24,065 - INFO - validation batch 151, loss: 2.690, 4832/6976 datapoints
2025-03-06 22:19:24,114 - INFO - validation batch 201, loss: 1.312, 6432/6976 datapoints
2025-03-06 22:19:24,131 - INFO - Epoch 698/800 done.
2025-03-06 22:19:24,131 - INFO - Final validation performance:
Loss: 3.040, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:19:24,132 - INFO - Beginning epoch 699/800
2025-03-06 22:19:24,136 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:19:24,317 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:24,503 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:19:24,683 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:19:24,885 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:19:25,085 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:19:25,274 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:19:25,452 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:19:25,625 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:19:25,811 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:19:25,993 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:19:26,173 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:19:26,349 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:19:26,539 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:26,718 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:26,911 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:19:27,099 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:27,279 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:19:27,372 - INFO - validation batch 1, loss: 0.246, 32/6976 datapoints
2025-03-06 22:19:27,418 - INFO - validation batch 51, loss: 9.344, 1632/6976 datapoints
2025-03-06 22:19:27,464 - INFO - validation batch 101, loss: 1.659, 3232/6976 datapoints
2025-03-06 22:19:27,510 - INFO - validation batch 151, loss: 2.747, 4832/6976 datapoints
2025-03-06 22:19:27,557 - INFO - validation batch 201, loss: 1.320, 6432/6976 datapoints
2025-03-06 22:19:27,574 - INFO - Epoch 699/800 done.
2025-03-06 22:19:27,574 - INFO - Final validation performance:
Loss: 3.063, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:19:27,575 - INFO - Beginning epoch 700/800
2025-03-06 22:19:27,580 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:19:27,763 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:27,952 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:19:28,137 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:19:28,315 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:19:28,497 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:19:28,679 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:19:28,860 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:19:29,040 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:19:29,223 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:19:29,413 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:19:29,597 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:19:29,777 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:19:29,966 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:30,147 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:30,340 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:19:30,527 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:30,708 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:19:30,801 - INFO - validation batch 1, loss: 0.253, 32/6976 datapoints
2025-03-06 22:19:30,852 - INFO - validation batch 51, loss: 9.411, 1632/6976 datapoints
2025-03-06 22:19:30,907 - INFO - validation batch 101, loss: 1.676, 3232/6976 datapoints
2025-03-06 22:19:30,957 - INFO - validation batch 151, loss: 2.842, 4832/6976 datapoints
2025-03-06 22:19:31,008 - INFO - validation batch 201, loss: 1.335, 6432/6976 datapoints
2025-03-06 22:19:31,028 - INFO - Epoch 700/800 done.
2025-03-06 22:19:31,029 - INFO - Final validation performance:
Loss: 3.103, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:19:31,029 - INFO - Beginning epoch 701/800
2025-03-06 22:19:31,034 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:19:31,215 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:31,405 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:19:31,590 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:19:31,769 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:19:31,963 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:19:32,152 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:19:32,334 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:19:32,529 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:19:32,720 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:19:32,905 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:19:33,097 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:19:33,283 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:19:33,490 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:33,675 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:33,872 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:19:34,066 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:34,255 - INFO - training batch 851, loss: 0.889, 27232/28000 datapoints
2025-03-06 22:19:34,349 - INFO - validation batch 1, loss: 0.389, 32/6976 datapoints
2025-03-06 22:19:34,405 - INFO - validation batch 51, loss: 10.347, 1632/6976 datapoints
2025-03-06 22:19:34,457 - INFO - validation batch 101, loss: 1.375, 3232/6976 datapoints
2025-03-06 22:19:34,511 - INFO - validation batch 151, loss: 2.850, 4832/6976 datapoints
2025-03-06 22:19:34,562 - INFO - validation batch 201, loss: 1.265, 6432/6976 datapoints
2025-03-06 22:19:34,583 - INFO - Epoch 701/800 done.
2025-03-06 22:19:34,583 - INFO - Final validation performance:
Loss: 3.245, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:19:34,584 - INFO - Beginning epoch 702/800
2025-03-06 22:19:34,589 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:19:34,774 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 22:19:34,963 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:19:35,161 - INFO - training batch 151, loss: 0.223, 4832/28000 datapoints
2025-03-06 22:19:35,346 - INFO - training batch 201, loss: 1.425, 6432/28000 datapoints
2025-03-06 22:19:35,540 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:19:35,725 - INFO - training batch 301, loss: 0.074, 9632/28000 datapoints
2025-03-06 22:19:35,970 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:19:36,154 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:19:36,338 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-06 22:19:36,524 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:19:36,708 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-06 22:19:36,889 - INFO - training batch 601, loss: 0.009, 19232/28000 datapoints
2025-03-06 22:19:37,073 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:37,256 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:37,444 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:19:37,632 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:37,818 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:19:37,930 - INFO - validation batch 1, loss: 0.184, 32/6976 datapoints
2025-03-06 22:19:37,980 - INFO - validation batch 51, loss: 9.486, 1632/6976 datapoints
2025-03-06 22:19:38,030 - INFO - validation batch 101, loss: 1.823, 3232/6976 datapoints
2025-03-06 22:19:38,080 - INFO - validation batch 151, loss: 3.002, 4832/6976 datapoints
2025-03-06 22:19:38,133 - INFO - validation batch 201, loss: 1.572, 6432/6976 datapoints
2025-03-06 22:19:38,149 - INFO - Epoch 702/800 done.
2025-03-06 22:19:38,150 - INFO - Final validation performance:
Loss: 3.213, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:19:38,150 - INFO - Beginning epoch 703/800
2025-03-06 22:19:38,154 - INFO - training batch 1, loss: 0.011, 32/28000 datapoints
2025-03-06 22:19:38,332 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:38,526 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:19:38,715 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:19:38,900 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:19:39,092 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:19:39,282 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:19:39,470 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:19:39,652 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:19:39,834 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:19:40,024 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:19:40,206 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:19:40,389 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:19:40,577 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:40,757 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:40,951 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:19:41,140 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:41,326 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:19:41,441 - INFO - validation batch 1, loss: 0.408, 32/6976 datapoints
2025-03-06 22:19:41,492 - INFO - validation batch 51, loss: 9.318, 1632/6976 datapoints
2025-03-06 22:19:41,544 - INFO - validation batch 101, loss: 1.575, 3232/6976 datapoints
2025-03-06 22:19:41,595 - INFO - validation batch 151, loss: 2.743, 4832/6976 datapoints
2025-03-06 22:19:41,645 - INFO - validation batch 201, loss: 1.478, 6432/6976 datapoints
2025-03-06 22:19:41,661 - INFO - Epoch 703/800 done.
2025-03-06 22:19:41,662 - INFO - Final validation performance:
Loss: 3.104, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:19:41,662 - INFO - Beginning epoch 704/800
2025-03-06 22:19:41,668 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:19:41,852 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:19:42,038 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:19:42,225 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:19:42,410 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:19:42,603 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:19:42,787 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:19:42,973 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:19:43,154 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:19:43,341 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:19:43,549 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:19:43,737 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:19:43,927 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:19:44,117 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:44,301 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:44,495 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:19:44,687 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:44,890 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:19:44,991 - INFO - validation batch 1, loss: 0.272, 32/6976 datapoints
2025-03-06 22:19:45,041 - INFO - validation batch 51, loss: 9.363, 1632/6976 datapoints
2025-03-06 22:19:45,092 - INFO - validation batch 101, loss: 1.507, 3232/6976 datapoints
2025-03-06 22:19:45,150 - INFO - validation batch 151, loss: 2.767, 4832/6976 datapoints
2025-03-06 22:19:45,210 - INFO - validation batch 201, loss: 1.394, 6432/6976 datapoints
2025-03-06 22:19:45,232 - INFO - Epoch 704/800 done.
2025-03-06 22:19:45,233 - INFO - Final validation performance:
Loss: 3.061, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:19:45,233 - INFO - Beginning epoch 705/800
2025-03-06 22:19:45,238 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:19:45,426 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:45,614 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:19:45,805 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:19:45,993 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:19:46,181 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:19:46,366 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:19:46,552 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:19:46,731 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:19:46,919 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:19:47,105 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:19:47,290 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:19:47,466 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:19:47,653 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:47,839 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:48,036 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:19:48,225 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:48,406 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:19:48,502 - INFO - validation batch 1, loss: 0.265, 32/6976 datapoints
2025-03-06 22:19:48,554 - INFO - validation batch 51, loss: 9.426, 1632/6976 datapoints
2025-03-06 22:19:48,606 - INFO - validation batch 101, loss: 1.539, 3232/6976 datapoints
2025-03-06 22:19:48,656 - INFO - validation batch 151, loss: 2.717, 4832/6976 datapoints
2025-03-06 22:19:48,706 - INFO - validation batch 201, loss: 1.365, 6432/6976 datapoints
2025-03-06 22:19:48,726 - INFO - Epoch 705/800 done.
2025-03-06 22:19:48,726 - INFO - Final validation performance:
Loss: 3.062, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:19:48,726 - INFO - Beginning epoch 706/800
2025-03-06 22:19:48,732 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:19:48,909 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:49,091 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:19:49,274 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:19:49,460 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:19:49,648 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:19:49,833 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:19:50,021 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:19:50,203 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:19:50,387 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:19:50,572 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:19:50,756 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:19:50,946 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:19:51,136 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:51,323 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:51,518 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:19:51,710 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:51,898 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:19:51,995 - INFO - validation batch 1, loss: 0.285, 32/6976 datapoints
2025-03-06 22:19:52,046 - INFO - validation batch 51, loss: 9.358, 1632/6976 datapoints
2025-03-06 22:19:52,099 - INFO - validation batch 101, loss: 1.535, 3232/6976 datapoints
2025-03-06 22:19:52,150 - INFO - validation batch 151, loss: 2.771, 4832/6976 datapoints
2025-03-06 22:19:52,202 - INFO - validation batch 201, loss: 1.372, 6432/6976 datapoints
2025-03-06 22:19:52,220 - INFO - Epoch 706/800 done.
2025-03-06 22:19:52,220 - INFO - Final validation performance:
Loss: 3.064, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:19:52,221 - INFO - Beginning epoch 707/800
2025-03-06 22:19:52,226 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:19:52,410 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:52,593 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:19:52,776 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:19:52,960 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:19:53,146 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:19:53,333 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:19:53,537 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:19:53,728 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:19:53,924 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:19:54,114 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:19:54,297 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:19:54,476 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:19:54,661 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:54,840 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:55,030 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:19:55,225 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:55,407 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:19:55,501 - INFO - validation batch 1, loss: 0.294, 32/6976 datapoints
2025-03-06 22:19:55,553 - INFO - validation batch 51, loss: 9.410, 1632/6976 datapoints
2025-03-06 22:19:55,606 - INFO - validation batch 101, loss: 1.537, 3232/6976 datapoints
2025-03-06 22:19:55,658 - INFO - validation batch 151, loss: 2.793, 4832/6976 datapoints
2025-03-06 22:19:55,710 - INFO - validation batch 201, loss: 1.355, 6432/6976 datapoints
2025-03-06 22:19:55,731 - INFO - Epoch 707/800 done.
2025-03-06 22:19:55,731 - INFO - Final validation performance:
Loss: 3.078, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:19:55,732 - INFO - Beginning epoch 708/800
2025-03-06 22:19:55,736 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:19:55,923 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:56,110 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:19:56,300 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:19:56,487 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:19:56,678 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:19:56,867 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:19:57,072 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:19:57,261 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:19:57,449 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:19:57,645 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:19:57,833 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:19:58,023 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:19:58,216 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:19:58,394 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:19:58,581 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:19:58,771 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:19:58,956 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:19:59,052 - INFO - validation batch 1, loss: 0.297, 32/6976 datapoints
2025-03-06 22:19:59,102 - INFO - validation batch 51, loss: 9.411, 1632/6976 datapoints
2025-03-06 22:19:59,154 - INFO - validation batch 101, loss: 1.553, 3232/6976 datapoints
2025-03-06 22:19:59,207 - INFO - validation batch 151, loss: 2.851, 4832/6976 datapoints
2025-03-06 22:19:59,258 - INFO - validation batch 201, loss: 1.357, 6432/6976 datapoints
2025-03-06 22:19:59,277 - INFO - Epoch 708/800 done.
2025-03-06 22:19:59,277 - INFO - Final validation performance:
Loss: 3.094, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:19:59,278 - INFO - Beginning epoch 709/800
2025-03-06 22:19:59,283 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:19:59,464 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:19:59,649 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:19:59,834 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:00,022 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:20:00,208 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:20:00,393 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:20:00,574 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:20:00,756 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:20:00,942 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:20:01,127 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:01,310 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:20:01,491 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:20:01,676 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:20:01,858 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:20:02,051 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:20:02,241 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:02,425 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:20:02,518 - INFO - validation batch 1, loss: 0.292, 32/6976 datapoints
2025-03-06 22:20:02,569 - INFO - validation batch 51, loss: 9.404, 1632/6976 datapoints
2025-03-06 22:20:02,620 - INFO - validation batch 101, loss: 1.571, 3232/6976 datapoints
2025-03-06 22:20:02,670 - INFO - validation batch 151, loss: 2.913, 4832/6976 datapoints
2025-03-06 22:20:02,719 - INFO - validation batch 201, loss: 1.361, 6432/6976 datapoints
2025-03-06 22:20:02,735 - INFO - Epoch 709/800 done.
2025-03-06 22:20:02,736 - INFO - Final validation performance:
Loss: 3.108, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:20:02,736 - INFO - Beginning epoch 710/800
2025-03-06 22:20:02,741 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:20:02,917 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:20:03,095 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:20:03,282 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:03,467 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:20:03,667 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:20:03,858 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:20:04,045 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:20:04,225 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:20:04,408 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:20:04,589 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:04,770 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:20:04,948 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:20:05,133 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:20:05,313 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:20:05,497 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:20:05,680 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:05,858 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:20:05,952 - INFO - validation batch 1, loss: 0.283, 32/6976 datapoints
2025-03-06 22:20:05,999 - INFO - validation batch 51, loss: 9.404, 1632/6976 datapoints
2025-03-06 22:20:06,045 - INFO - validation batch 101, loss: 1.583, 3232/6976 datapoints
2025-03-06 22:20:06,092 - INFO - validation batch 151, loss: 2.950, 4832/6976 datapoints
2025-03-06 22:20:06,142 - INFO - validation batch 201, loss: 1.368, 6432/6976 datapoints
2025-03-06 22:20:06,159 - INFO - Epoch 710/800 done.
2025-03-06 22:20:06,159 - INFO - Final validation performance:
Loss: 3.117, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:20:06,159 - INFO - Beginning epoch 711/800
2025-03-06 22:20:06,164 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:20:06,344 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:20:06,525 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:20:06,706 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:06,885 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:20:07,065 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:20:07,247 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:20:07,422 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:20:07,600 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:20:07,784 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:20:07,972 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:08,152 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:20:08,329 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:20:08,507 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:20:08,684 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:20:08,867 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:20:09,052 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:09,239 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:20:09,330 - INFO - validation batch 1, loss: 0.286, 32/6976 datapoints
2025-03-06 22:20:09,378 - INFO - validation batch 51, loss: 9.430, 1632/6976 datapoints
2025-03-06 22:20:09,430 - INFO - validation batch 101, loss: 1.596, 3232/6976 datapoints
2025-03-06 22:20:09,484 - INFO - validation batch 151, loss: 2.960, 4832/6976 datapoints
2025-03-06 22:20:09,538 - INFO - validation batch 201, loss: 1.369, 6432/6976 datapoints
2025-03-06 22:20:09,562 - INFO - Epoch 711/800 done.
2025-03-06 22:20:09,562 - INFO - Final validation performance:
Loss: 3.128, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:20:09,562 - INFO - Beginning epoch 712/800
2025-03-06 22:20:09,570 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:20:09,761 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:20:09,951 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:20:10,142 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:10,329 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:20:10,521 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:20:10,710 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:20:10,900 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:20:11,083 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:20:11,276 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:20:11,467 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:11,651 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:20:11,831 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:20:12,020 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:20:12,203 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:20:12,390 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:20:12,578 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:12,763 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:20:12,855 - INFO - validation batch 1, loss: 0.316, 32/6976 datapoints
2025-03-06 22:20:12,908 - INFO - validation batch 51, loss: 9.484, 1632/6976 datapoints
2025-03-06 22:20:12,959 - INFO - validation batch 101, loss: 1.636, 3232/6976 datapoints
2025-03-06 22:20:13,010 - INFO - validation batch 151, loss: 3.019, 4832/6976 datapoints
2025-03-06 22:20:13,066 - INFO - validation batch 201, loss: 1.371, 6432/6976 datapoints
2025-03-06 22:20:13,088 - INFO - Epoch 712/800 done.
2025-03-06 22:20:13,088 - INFO - Final validation performance:
Loss: 3.165, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:20:13,089 - INFO - Beginning epoch 713/800
2025-03-06 22:20:13,094 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:20:13,276 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:20:13,464 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:20:13,650 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:20:13,856 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:20:14,048 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:20:14,234 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:20:14,426 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:20:14,610 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:20:14,799 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:20:14,980 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:15,164 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:20:15,352 - INFO - training batch 601, loss: 0.320, 19232/28000 datapoints
2025-03-06 22:20:15,539 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:20:15,726 - INFO - training batch 701, loss: 0.115, 22432/28000 datapoints
2025-03-06 22:20:15,931 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 22:20:16,118 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:16,309 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:20:16,409 - INFO - validation batch 1, loss: 1.276, 32/6976 datapoints
2025-03-06 22:20:16,462 - INFO - validation batch 51, loss: 9.718, 1632/6976 datapoints
2025-03-06 22:20:16,513 - INFO - validation batch 101, loss: 1.703, 3232/6976 datapoints
2025-03-06 22:20:16,563 - INFO - validation batch 151, loss: 2.659, 4832/6976 datapoints
2025-03-06 22:20:16,621 - INFO - validation batch 201, loss: 1.536, 6432/6976 datapoints
2025-03-06 22:20:16,640 - INFO - Epoch 713/800 done.
2025-03-06 22:20:16,641 - INFO - Final validation performance:
Loss: 3.378, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:20:16,641 - INFO - Beginning epoch 714/800
2025-03-06 22:20:16,647 - INFO - training batch 1, loss: 0.035, 32/28000 datapoints
2025-03-06 22:20:16,912 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:20:17,097 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:20:17,279 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:20:17,461 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:20:17,645 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:20:17,832 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:20:18,019 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:20:18,202 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:20:18,390 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:20:18,573 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:18,751 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:20:18,932 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:20:19,115 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:20:19,299 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:20:19,484 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:20:19,674 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:19,858 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:20:19,957 - INFO - validation batch 1, loss: 0.469, 32/6976 datapoints
2025-03-06 22:20:20,011 - INFO - validation batch 51, loss: 9.515, 1632/6976 datapoints
2025-03-06 22:20:20,063 - INFO - validation batch 101, loss: 1.573, 3232/6976 datapoints
2025-03-06 22:20:20,114 - INFO - validation batch 151, loss: 2.540, 4832/6976 datapoints
2025-03-06 22:20:20,166 - INFO - validation batch 201, loss: 1.248, 6432/6976 datapoints
2025-03-06 22:20:20,186 - INFO - Epoch 714/800 done.
2025-03-06 22:20:20,187 - INFO - Final validation performance:
Loss: 3.069, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:20:20,187 - INFO - Beginning epoch 715/800
2025-03-06 22:20:20,192 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:20:20,371 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:20:20,552 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:20:20,745 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:20,933 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:20:21,130 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:20:21,323 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:20:21,508 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:20:21,693 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:20:21,901 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:20:22,088 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:22,281 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:20:22,471 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:20:22,658 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:20:22,843 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:20:23,032 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:20:23,220 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:23,407 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:20:23,503 - INFO - validation batch 1, loss: 0.323, 32/6976 datapoints
2025-03-06 22:20:23,554 - INFO - validation batch 51, loss: 9.409, 1632/6976 datapoints
2025-03-06 22:20:23,606 - INFO - validation batch 101, loss: 1.613, 3232/6976 datapoints
2025-03-06 22:20:23,656 - INFO - validation batch 151, loss: 2.834, 4832/6976 datapoints
2025-03-06 22:20:23,708 - INFO - validation batch 201, loss: 1.274, 6432/6976 datapoints
2025-03-06 22:20:23,728 - INFO - Epoch 715/800 done.
2025-03-06 22:20:23,728 - INFO - Final validation performance:
Loss: 3.091, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:20:23,729 - INFO - Beginning epoch 716/800
2025-03-06 22:20:23,740 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:20:23,952 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:20:24,154 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:20:24,343 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:24,528 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:20:24,714 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:20:24,906 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:20:25,084 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:20:25,312 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:20:25,499 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:20:25,682 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:25,862 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:20:26,048 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:20:26,233 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:20:26,418 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:20:26,604 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:20:26,793 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:26,978 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:20:27,072 - INFO - validation batch 1, loss: 0.376, 32/6976 datapoints
2025-03-06 22:20:27,122 - INFO - validation batch 51, loss: 10.719, 1632/6976 datapoints
2025-03-06 22:20:27,173 - INFO - validation batch 101, loss: 1.727, 3232/6976 datapoints
2025-03-06 22:20:27,220 - INFO - validation batch 151, loss: 2.207, 4832/6976 datapoints
2025-03-06 22:20:27,269 - INFO - validation batch 201, loss: 1.367, 6432/6976 datapoints
2025-03-06 22:20:27,285 - INFO - Epoch 716/800 done.
2025-03-06 22:20:27,285 - INFO - Final validation performance:
Loss: 3.279, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:20:27,286 - INFO - Beginning epoch 717/800
2025-03-06 22:20:27,292 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:20:27,464 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:20:27,647 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:20:27,837 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:28,028 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:20:28,220 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:20:28,412 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:20:28,595 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:20:28,784 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:20:28,976 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:20:29,162 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:20:29,346 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:20:29,526 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:20:29,720 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:20:29,908 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:20:30,102 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:20:30,291 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:30,476 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:20:30,571 - INFO - validation batch 1, loss: 0.162, 32/6976 datapoints
2025-03-06 22:20:30,622 - INFO - validation batch 51, loss: 9.931, 1632/6976 datapoints
2025-03-06 22:20:30,675 - INFO - validation batch 101, loss: 1.600, 3232/6976 datapoints
2025-03-06 22:20:30,721 - INFO - validation batch 151, loss: 2.742, 4832/6976 datapoints
2025-03-06 22:20:30,768 - INFO - validation batch 201, loss: 1.451, 6432/6976 datapoints
2025-03-06 22:20:30,784 - INFO - Epoch 717/800 done.
2025-03-06 22:20:30,784 - INFO - Final validation performance:
Loss: 3.177, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:20:30,785 - INFO - Beginning epoch 718/800
2025-03-06 22:20:30,790 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:20:30,966 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:20:31,149 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:20:31,329 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:31,513 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:20:31,697 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:20:31,879 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:20:32,062 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:20:32,242 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:20:32,425 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:20:32,602 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:32,780 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:20:32,957 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:20:33,136 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:20:33,316 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:20:33,506 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:20:33,690 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:20:33,878 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:20:33,989 - INFO - validation batch 1, loss: 0.112, 32/6976 datapoints
2025-03-06 22:20:34,040 - INFO - validation batch 51, loss: 9.859, 1632/6976 datapoints
2025-03-06 22:20:34,098 - INFO - validation batch 101, loss: 1.656, 3232/6976 datapoints
2025-03-06 22:20:34,153 - INFO - validation batch 151, loss: 2.726, 4832/6976 datapoints
2025-03-06 22:20:34,205 - INFO - validation batch 201, loss: 1.337, 6432/6976 datapoints
2025-03-06 22:20:34,221 - INFO - Epoch 718/800 done.
2025-03-06 22:20:34,221 - INFO - Final validation performance:
Loss: 3.138, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:20:34,222 - INFO - Beginning epoch 719/800
2025-03-06 22:20:34,227 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:20:34,403 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:20:34,578 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:20:34,763 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:34,943 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:20:35,131 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:20:35,320 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:20:35,497 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:20:35,675 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:20:35,859 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:20:36,038 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:36,218 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:20:36,395 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:20:36,575 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:20:36,757 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:20:36,943 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:20:37,127 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:37,308 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:20:37,400 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 22:20:37,446 - INFO - validation batch 51, loss: 9.775, 1632/6976 datapoints
2025-03-06 22:20:37,493 - INFO - validation batch 101, loss: 1.636, 3232/6976 datapoints
2025-03-06 22:20:37,540 - INFO - validation batch 151, loss: 2.667, 4832/6976 datapoints
2025-03-06 22:20:37,586 - INFO - validation batch 201, loss: 1.319, 6432/6976 datapoints
2025-03-06 22:20:37,602 - INFO - Epoch 719/800 done.
2025-03-06 22:20:37,602 - INFO - Final validation performance:
Loss: 3.106, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:20:37,603 - INFO - Beginning epoch 720/800
2025-03-06 22:20:37,608 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:20:37,782 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:20:37,970 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:20:38,159 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:38,339 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:20:38,521 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:20:38,705 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:20:38,885 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:20:39,070 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:20:39,255 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:20:39,438 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:39,613 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:20:39,790 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:20:39,972 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:20:40,152 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:20:40,348 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:20:40,533 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:40,716 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:20:40,811 - INFO - validation batch 1, loss: 0.141, 32/6976 datapoints
2025-03-06 22:20:40,860 - INFO - validation batch 51, loss: 9.720, 1632/6976 datapoints
2025-03-06 22:20:40,910 - INFO - validation batch 101, loss: 1.622, 3232/6976 datapoints
2025-03-06 22:20:40,957 - INFO - validation batch 151, loss: 2.709, 4832/6976 datapoints
2025-03-06 22:20:41,008 - INFO - validation batch 201, loss: 1.309, 6432/6976 datapoints
2025-03-06 22:20:41,024 - INFO - Epoch 720/800 done.
2025-03-06 22:20:41,024 - INFO - Final validation performance:
Loss: 3.100, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:20:41,025 - INFO - Beginning epoch 721/800
2025-03-06 22:20:41,030 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:20:41,210 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:20:41,389 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:20:41,574 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:41,753 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:20:41,939 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:20:42,123 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:20:42,302 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:20:42,491 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:20:42,705 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:20:42,907 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:43,087 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:20:43,262 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:20:43,442 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:20:43,620 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:20:43,806 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:20:44,008 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:44,211 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:20:44,308 - INFO - validation batch 1, loss: 0.157, 32/6976 datapoints
2025-03-06 22:20:44,357 - INFO - validation batch 51, loss: 9.707, 1632/6976 datapoints
2025-03-06 22:20:44,407 - INFO - validation batch 101, loss: 1.622, 3232/6976 datapoints
2025-03-06 22:20:44,456 - INFO - validation batch 151, loss: 2.760, 4832/6976 datapoints
2025-03-06 22:20:44,506 - INFO - validation batch 201, loss: 1.312, 6432/6976 datapoints
2025-03-06 22:20:44,522 - INFO - Epoch 721/800 done.
2025-03-06 22:20:44,522 - INFO - Final validation performance:
Loss: 3.111, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:20:44,522 - INFO - Beginning epoch 722/800
2025-03-06 22:20:44,527 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:20:44,706 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:20:44,897 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:20:45,086 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:45,273 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:20:45,461 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:20:45,645 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:20:45,831 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:20:46,012 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:20:46,197 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:20:46,379 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:46,571 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:20:46,745 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:20:46,929 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:20:47,117 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:20:47,307 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:20:47,493 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:47,672 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:20:47,764 - INFO - validation batch 1, loss: 0.176, 32/6976 datapoints
2025-03-06 22:20:47,811 - INFO - validation batch 51, loss: 9.689, 1632/6976 datapoints
2025-03-06 22:20:47,860 - INFO - validation batch 101, loss: 1.631, 3232/6976 datapoints
2025-03-06 22:20:47,910 - INFO - validation batch 151, loss: 2.822, 4832/6976 datapoints
2025-03-06 22:20:47,955 - INFO - validation batch 201, loss: 1.322, 6432/6976 datapoints
2025-03-06 22:20:47,971 - INFO - Epoch 722/800 done.
2025-03-06 22:20:47,972 - INFO - Final validation performance:
Loss: 3.128, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:20:47,972 - INFO - Beginning epoch 723/800
2025-03-06 22:20:47,977 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:20:48,155 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:20:48,335 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:20:48,520 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:48,701 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:20:48,888 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:20:49,071 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:20:49,249 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:20:49,428 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:20:49,612 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:20:49,803 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:49,988 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:20:50,169 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:20:50,354 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:20:50,538 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:20:50,726 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:20:50,918 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:51,104 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:20:51,197 - INFO - validation batch 1, loss: 0.190, 32/6976 datapoints
2025-03-06 22:20:51,247 - INFO - validation batch 51, loss: 9.673, 1632/6976 datapoints
2025-03-06 22:20:51,299 - INFO - validation batch 101, loss: 1.639, 3232/6976 datapoints
2025-03-06 22:20:51,352 - INFO - validation batch 151, loss: 2.866, 4832/6976 datapoints
2025-03-06 22:20:51,405 - INFO - validation batch 201, loss: 1.340, 6432/6976 datapoints
2025-03-06 22:20:51,423 - INFO - Epoch 723/800 done.
2025-03-06 22:20:51,424 - INFO - Final validation performance:
Loss: 3.141, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:20:51,424 - INFO - Beginning epoch 724/800
2025-03-06 22:20:51,429 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:20:51,607 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:20:51,784 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:20:51,972 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:52,151 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:20:52,336 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:20:52,521 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:20:52,709 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:20:52,893 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:20:53,077 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:20:53,265 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:53,449 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:20:53,629 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:20:53,810 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:20:53,993 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:20:54,205 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:20:54,399 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:54,579 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:20:54,670 - INFO - validation batch 1, loss: 0.194, 32/6976 datapoints
2025-03-06 22:20:54,716 - INFO - validation batch 51, loss: 9.664, 1632/6976 datapoints
2025-03-06 22:20:54,763 - INFO - validation batch 101, loss: 1.640, 3232/6976 datapoints
2025-03-06 22:20:54,811 - INFO - validation batch 151, loss: 2.914, 4832/6976 datapoints
2025-03-06 22:20:54,858 - INFO - validation batch 201, loss: 1.357, 6432/6976 datapoints
2025-03-06 22:20:54,877 - INFO - Epoch 724/800 done.
2025-03-06 22:20:54,878 - INFO - Final validation performance:
Loss: 3.154, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:20:54,878 - INFO - Beginning epoch 725/800
2025-03-06 22:20:54,885 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:20:55,061 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:20:55,245 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:20:55,431 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:55,606 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:20:55,787 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:20:55,973 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:20:56,153 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:20:56,334 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:20:56,527 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:20:56,706 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:20:56,887 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:20:57,062 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:20:57,242 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:20:57,425 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:20:57,611 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:20:57,793 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:20:57,975 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:20:58,069 - INFO - validation batch 1, loss: 0.179, 32/6976 datapoints
2025-03-06 22:20:58,116 - INFO - validation batch 51, loss: 9.665, 1632/6976 datapoints
2025-03-06 22:20:58,164 - INFO - validation batch 101, loss: 1.652, 3232/6976 datapoints
2025-03-06 22:20:58,211 - INFO - validation batch 151, loss: 2.993, 4832/6976 datapoints
2025-03-06 22:20:58,257 - INFO - validation batch 201, loss: 1.375, 6432/6976 datapoints
2025-03-06 22:20:58,274 - INFO - Epoch 725/800 done.
2025-03-06 22:20:58,274 - INFO - Final validation performance:
Loss: 3.173, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:20:58,274 - INFO - Beginning epoch 726/800
2025-03-06 22:20:58,279 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:20:58,456 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:20:58,648 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:20:58,834 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:20:59,022 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:20:59,228 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:20:59,428 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:20:59,616 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:20:59,806 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:21:00,013 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:21:00,203 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:21:00,387 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:21:00,569 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:21:00,755 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:00,941 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:21:01,131 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:21:01,315 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:01,496 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:21:01,586 - INFO - validation batch 1, loss: 0.168, 32/6976 datapoints
2025-03-06 22:21:01,633 - INFO - validation batch 51, loss: 9.696, 1632/6976 datapoints
2025-03-06 22:21:01,679 - INFO - validation batch 101, loss: 1.688, 3232/6976 datapoints
2025-03-06 22:21:01,725 - INFO - validation batch 151, loss: 3.125, 4832/6976 datapoints
2025-03-06 22:21:01,773 - INFO - validation batch 201, loss: 1.383, 6432/6976 datapoints
2025-03-06 22:21:01,789 - INFO - Epoch 726/800 done.
2025-03-06 22:21:01,789 - INFO - Final validation performance:
Loss: 3.212, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:21:01,790 - INFO - Beginning epoch 727/800
2025-03-06 22:21:01,795 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:21:01,975 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:21:02,154 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:21:02,341 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:21:02,518 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:21:02,704 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:21:02,888 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:21:03,067 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:21:03,244 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:21:03,428 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:21:03,606 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:21:03,785 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:21:03,969 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:21:04,157 - INFO - training batch 651, loss: 0.211, 20832/28000 datapoints
2025-03-06 22:21:04,360 - INFO - training batch 701, loss: 0.107, 22432/28000 datapoints
2025-03-06 22:21:04,547 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-06 22:21:04,733 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:21:04,933 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:21:05,025 - INFO - validation batch 1, loss: 0.219, 32/6976 datapoints
2025-03-06 22:21:05,072 - INFO - validation batch 51, loss: 9.727, 1632/6976 datapoints
2025-03-06 22:21:05,124 - INFO - validation batch 101, loss: 1.450, 3232/6976 datapoints
2025-03-06 22:21:05,172 - INFO - validation batch 151, loss: 3.309, 4832/6976 datapoints
2025-03-06 22:21:05,220 - INFO - validation batch 201, loss: 1.470, 6432/6976 datapoints
2025-03-06 22:21:05,236 - INFO - Epoch 727/800 done.
2025-03-06 22:21:05,236 - INFO - Final validation performance:
Loss: 3.235, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:21:05,237 - INFO - Beginning epoch 728/800
2025-03-06 22:21:05,242 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:21:05,426 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:21:05,608 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:21:05,791 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:21:05,971 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:21:06,159 - INFO - training batch 251, loss: 0.022, 8032/28000 datapoints
2025-03-06 22:21:06,343 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:21:06,526 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:21:06,700 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:21:06,886 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:21:07,068 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:21:07,245 - INFO - training batch 551, loss: 0.357, 17632/28000 datapoints
2025-03-06 22:21:07,421 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:21:07,602 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:07,777 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:21:07,968 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:21:08,155 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:08,337 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:21:08,428 - INFO - validation batch 1, loss: 0.299, 32/6976 datapoints
2025-03-06 22:21:08,475 - INFO - validation batch 51, loss: 9.838, 1632/6976 datapoints
2025-03-06 22:21:08,523 - INFO - validation batch 101, loss: 1.764, 3232/6976 datapoints
2025-03-06 22:21:08,570 - INFO - validation batch 151, loss: 3.550, 4832/6976 datapoints
2025-03-06 22:21:08,620 - INFO - validation batch 201, loss: 1.364, 6432/6976 datapoints
2025-03-06 22:21:08,636 - INFO - Epoch 728/800 done.
2025-03-06 22:21:08,636 - INFO - Final validation performance:
Loss: 3.363, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:21:08,637 - INFO - Beginning epoch 729/800
2025-03-06 22:21:08,641 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:21:08,819 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-06 22:21:09,006 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:21:09,195 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:21:09,382 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:21:09,575 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:21:09,760 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:21:09,955 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:21:10,140 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:21:10,333 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:21:10,522 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:21:10,712 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:21:10,900 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:21:11,102 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:11,285 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:21:11,481 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:21:11,677 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:11,870 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:21:11,971 - INFO - validation batch 1, loss: 0.272, 32/6976 datapoints
2025-03-06 22:21:12,022 - INFO - validation batch 51, loss: 9.536, 1632/6976 datapoints
2025-03-06 22:21:12,073 - INFO - validation batch 101, loss: 1.522, 3232/6976 datapoints
2025-03-06 22:21:12,121 - INFO - validation batch 151, loss: 3.433, 4832/6976 datapoints
2025-03-06 22:21:12,170 - INFO - validation batch 201, loss: 1.355, 6432/6976 datapoints
2025-03-06 22:21:12,186 - INFO - Epoch 729/800 done.
2025-03-06 22:21:12,187 - INFO - Final validation performance:
Loss: 3.223, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:21:12,187 - INFO - Beginning epoch 730/800
2025-03-06 22:21:12,192 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:21:12,375 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:21:12,560 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:21:12,750 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:21:12,933 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:21:13,129 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:21:13,313 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:21:13,498 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:21:13,683 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:21:13,874 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:21:14,085 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:21:14,284 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:21:14,487 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:21:14,672 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:14,857 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:21:15,052 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:21:15,251 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:15,439 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:21:15,532 - INFO - validation batch 1, loss: 0.408, 32/6976 datapoints
2025-03-06 22:21:15,578 - INFO - validation batch 51, loss: 9.615, 1632/6976 datapoints
2025-03-06 22:21:15,626 - INFO - validation batch 101, loss: 1.561, 3232/6976 datapoints
2025-03-06 22:21:15,673 - INFO - validation batch 151, loss: 3.088, 4832/6976 datapoints
2025-03-06 22:21:15,720 - INFO - validation batch 201, loss: 1.363, 6432/6976 datapoints
2025-03-06 22:21:15,736 - INFO - Epoch 730/800 done.
2025-03-06 22:21:15,736 - INFO - Final validation performance:
Loss: 3.207, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:21:15,737 - INFO - Beginning epoch 731/800
2025-03-06 22:21:15,741 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:21:15,920 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:21:16,106 - INFO - training batch 101, loss: 0.061, 3232/28000 datapoints
2025-03-06 22:21:16,301 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 22:21:16,483 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-06 22:21:16,674 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:21:16,858 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:21:17,056 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:21:17,241 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:21:17,430 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:21:17,619 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:21:17,812 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:21:18,001 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:21:18,194 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:18,398 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:21:18,588 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:21:18,771 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:18,958 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:21:19,053 - INFO - validation batch 1, loss: 0.269, 32/6976 datapoints
2025-03-06 22:21:19,102 - INFO - validation batch 51, loss: 9.598, 1632/6976 datapoints
2025-03-06 22:21:19,152 - INFO - validation batch 101, loss: 1.581, 3232/6976 datapoints
2025-03-06 22:21:19,201 - INFO - validation batch 151, loss: 2.681, 4832/6976 datapoints
2025-03-06 22:21:19,248 - INFO - validation batch 201, loss: 1.367, 6432/6976 datapoints
2025-03-06 22:21:19,264 - INFO - Epoch 731/800 done.
2025-03-06 22:21:19,264 - INFO - Final validation performance:
Loss: 3.099, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:21:19,264 - INFO - Beginning epoch 732/800
2025-03-06 22:21:19,269 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:21:19,453 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:21:19,635 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:21:19,825 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:21:20,012 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:21:20,200 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:21:20,388 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:21:20,572 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:21:20,757 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:21:20,952 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:21:21,136 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:21:21,318 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:21:21,500 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:21:21,684 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:21,864 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:21:22,063 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:21:22,251 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:22,436 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:21:22,530 - INFO - validation batch 1, loss: 0.313, 32/6976 datapoints
2025-03-06 22:21:22,578 - INFO - validation batch 51, loss: 9.620, 1632/6976 datapoints
2025-03-06 22:21:22,625 - INFO - validation batch 101, loss: 1.491, 3232/6976 datapoints
2025-03-06 22:21:22,672 - INFO - validation batch 151, loss: 2.738, 4832/6976 datapoints
2025-03-06 22:21:22,720 - INFO - validation batch 201, loss: 1.360, 6432/6976 datapoints
2025-03-06 22:21:22,736 - INFO - Epoch 732/800 done.
2025-03-06 22:21:22,736 - INFO - Final validation performance:
Loss: 3.104, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:21:22,737 - INFO - Beginning epoch 733/800
2025-03-06 22:21:22,742 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:21:22,923 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:21:23,121 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:21:23,312 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:21:23,501 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:21:23,694 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:21:23,884 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:21:24,079 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:21:24,264 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:21:24,492 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:21:24,698 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:21:24,891 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:21:25,076 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:21:25,270 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:25,452 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:21:25,655 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:21:25,873 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:26,059 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:21:26,155 - INFO - validation batch 1, loss: 0.309, 32/6976 datapoints
2025-03-06 22:21:26,202 - INFO - validation batch 51, loss: 9.610, 1632/6976 datapoints
2025-03-06 22:21:26,248 - INFO - validation batch 101, loss: 1.478, 3232/6976 datapoints
2025-03-06 22:21:26,300 - INFO - validation batch 151, loss: 2.763, 4832/6976 datapoints
2025-03-06 22:21:26,348 - INFO - validation batch 201, loss: 1.350, 6432/6976 datapoints
2025-03-06 22:21:26,364 - INFO - Epoch 733/800 done.
2025-03-06 22:21:26,364 - INFO - Final validation performance:
Loss: 3.102, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:21:26,364 - INFO - Beginning epoch 734/800
2025-03-06 22:21:26,369 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:21:26,547 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:21:26,731 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:21:26,925 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:21:27,107 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:21:27,297 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:21:27,480 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:21:27,664 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:21:27,849 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:21:28,042 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:21:28,228 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:21:28,414 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:21:28,596 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:21:28,782 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:28,967 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:21:29,156 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:21:29,356 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:29,538 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:21:29,636 - INFO - validation batch 1, loss: 0.316, 32/6976 datapoints
2025-03-06 22:21:29,690 - INFO - validation batch 51, loss: 9.621, 1632/6976 datapoints
2025-03-06 22:21:29,740 - INFO - validation batch 101, loss: 1.469, 3232/6976 datapoints
2025-03-06 22:21:29,789 - INFO - validation batch 151, loss: 2.801, 4832/6976 datapoints
2025-03-06 22:21:29,844 - INFO - validation batch 201, loss: 1.341, 6432/6976 datapoints
2025-03-06 22:21:29,864 - INFO - Epoch 734/800 done.
2025-03-06 22:21:29,864 - INFO - Final validation performance:
Loss: 3.110, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:21:29,864 - INFO - Beginning epoch 735/800
2025-03-06 22:21:29,870 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:21:30,059 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:21:30,241 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:21:30,434 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:21:30,617 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:21:30,806 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:21:30,994 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:21:31,177 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:21:31,363 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:21:31,554 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:21:31,738 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:21:31,926 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:21:32,109 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:21:32,294 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:32,478 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:21:32,668 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:21:32,855 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:33,039 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:21:33,134 - INFO - validation batch 1, loss: 0.320, 32/6976 datapoints
2025-03-06 22:21:33,181 - INFO - validation batch 51, loss: 9.632, 1632/6976 datapoints
2025-03-06 22:21:33,229 - INFO - validation batch 101, loss: 1.472, 3232/6976 datapoints
2025-03-06 22:21:33,276 - INFO - validation batch 151, loss: 2.848, 4832/6976 datapoints
2025-03-06 22:21:33,324 - INFO - validation batch 201, loss: 1.341, 6432/6976 datapoints
2025-03-06 22:21:33,340 - INFO - Epoch 735/800 done.
2025-03-06 22:21:33,340 - INFO - Final validation performance:
Loss: 3.123, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:21:33,341 - INFO - Beginning epoch 736/800
2025-03-06 22:21:33,346 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:21:33,530 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:21:33,713 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:21:33,906 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:21:34,091 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:21:34,281 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:21:34,479 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:21:34,703 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:21:34,894 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:21:35,088 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:21:35,278 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:21:35,480 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:21:35,663 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:21:35,855 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:36,045 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:21:36,241 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:21:36,430 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:36,615 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:21:36,711 - INFO - validation batch 1, loss: 0.320, 32/6976 datapoints
2025-03-06 22:21:36,758 - INFO - validation batch 51, loss: 9.632, 1632/6976 datapoints
2025-03-06 22:21:36,805 - INFO - validation batch 101, loss: 1.482, 3232/6976 datapoints
2025-03-06 22:21:36,851 - INFO - validation batch 151, loss: 2.908, 4832/6976 datapoints
2025-03-06 22:21:36,902 - INFO - validation batch 201, loss: 1.351, 6432/6976 datapoints
2025-03-06 22:21:36,919 - INFO - Epoch 736/800 done.
2025-03-06 22:21:36,919 - INFO - Final validation performance:
Loss: 3.139, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:21:36,919 - INFO - Beginning epoch 737/800
2025-03-06 22:21:36,924 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:21:37,104 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:21:37,286 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:21:37,478 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:21:37,661 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:21:37,850 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:21:38,050 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:21:38,243 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:21:38,431 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:21:38,620 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:21:38,803 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:21:38,991 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:21:39,173 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:21:39,362 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:39,544 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:21:39,735 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:21:39,922 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:40,108 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:21:40,203 - INFO - validation batch 1, loss: 0.307, 32/6976 datapoints
2025-03-06 22:21:40,251 - INFO - validation batch 51, loss: 9.630, 1632/6976 datapoints
2025-03-06 22:21:40,300 - INFO - validation batch 101, loss: 1.495, 3232/6976 datapoints
2025-03-06 22:21:40,350 - INFO - validation batch 151, loss: 2.966, 4832/6976 datapoints
2025-03-06 22:21:40,397 - INFO - validation batch 201, loss: 1.372, 6432/6976 datapoints
2025-03-06 22:21:40,413 - INFO - Epoch 737/800 done.
2025-03-06 22:21:40,413 - INFO - Final validation performance:
Loss: 3.154, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:21:40,414 - INFO - Beginning epoch 738/800
2025-03-06 22:21:40,418 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:21:40,600 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:21:40,784 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:21:40,974 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:21:41,157 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:21:41,346 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:21:41,555 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:21:41,740 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:21:41,933 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:21:42,127 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:21:42,315 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:21:42,505 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:21:42,687 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:21:42,872 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:43,057 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:21:43,246 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:21:43,432 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:43,616 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:21:43,714 - INFO - validation batch 1, loss: 0.277, 32/6976 datapoints
2025-03-06 22:21:43,762 - INFO - validation batch 51, loss: 9.643, 1632/6976 datapoints
2025-03-06 22:21:43,809 - INFO - validation batch 101, loss: 1.511, 3232/6976 datapoints
2025-03-06 22:21:43,856 - INFO - validation batch 151, loss: 3.009, 4832/6976 datapoints
2025-03-06 22:21:43,907 - INFO - validation batch 201, loss: 1.395, 6432/6976 datapoints
2025-03-06 22:21:43,924 - INFO - Epoch 738/800 done.
2025-03-06 22:21:43,924 - INFO - Final validation performance:
Loss: 3.167, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:21:43,925 - INFO - Beginning epoch 739/800
2025-03-06 22:21:43,929 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:21:44,116 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:21:44,303 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:21:44,492 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:21:44,700 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:21:44,892 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:21:45,082 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:21:45,271 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:21:45,454 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:21:45,645 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:21:45,828 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:21:46,016 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:21:46,205 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:21:46,393 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:46,577 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:21:46,767 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:21:46,955 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:47,142 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:21:47,236 - INFO - validation batch 1, loss: 0.237, 32/6976 datapoints
2025-03-06 22:21:47,282 - INFO - validation batch 51, loss: 9.650, 1632/6976 datapoints
2025-03-06 22:21:47,329 - INFO - validation batch 101, loss: 1.551, 3232/6976 datapoints
2025-03-06 22:21:47,376 - INFO - validation batch 151, loss: 3.107, 4832/6976 datapoints
2025-03-06 22:21:47,422 - INFO - validation batch 201, loss: 1.408, 6432/6976 datapoints
2025-03-06 22:21:47,438 - INFO - Epoch 739/800 done.
2025-03-06 22:21:47,439 - INFO - Final validation performance:
Loss: 3.191, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:21:47,439 - INFO - Beginning epoch 740/800
2025-03-06 22:21:47,444 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:21:47,626 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:21:47,827 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:21:48,017 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:21:48,207 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:21:48,405 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:21:48,597 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:21:48,781 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:21:48,968 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:21:49,162 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:21:49,344 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:21:49,527 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:21:49,718 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:21:49,916 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:50,131 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:21:50,349 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:21:50,580 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:50,776 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:21:50,877 - INFO - validation batch 1, loss: 0.184, 32/6976 datapoints
2025-03-06 22:21:50,934 - INFO - validation batch 51, loss: 9.712, 1632/6976 datapoints
2025-03-06 22:21:50,991 - INFO - validation batch 101, loss: 1.611, 3232/6976 datapoints
2025-03-06 22:21:51,050 - INFO - validation batch 151, loss: 3.212, 4832/6976 datapoints
2025-03-06 22:21:51,103 - INFO - validation batch 201, loss: 1.390, 6432/6976 datapoints
2025-03-06 22:21:51,120 - INFO - Epoch 740/800 done.
2025-03-06 22:21:51,120 - INFO - Final validation performance:
Loss: 3.222, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:21:51,121 - INFO - Beginning epoch 741/800
2025-03-06 22:21:51,127 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:21:51,312 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:21:51,502 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:21:51,696 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:21:51,887 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:21:52,080 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:21:52,272 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:21:52,466 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:21:52,657 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:21:52,854 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:21:53,042 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:21:53,229 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:21:53,418 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:21:53,609 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:53,801 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:21:54,012 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:21:54,206 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:54,401 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:21:54,504 - INFO - validation batch 1, loss: 0.200, 32/6976 datapoints
2025-03-06 22:21:54,554 - INFO - validation batch 51, loss: 10.044, 1632/6976 datapoints
2025-03-06 22:21:54,610 - INFO - validation batch 101, loss: 1.641, 3232/6976 datapoints
2025-03-06 22:21:54,678 - INFO - validation batch 151, loss: 3.089, 4832/6976 datapoints
2025-03-06 22:21:54,747 - INFO - validation batch 201, loss: 1.299, 6432/6976 datapoints
2025-03-06 22:21:54,764 - INFO - Epoch 741/800 done.
2025-03-06 22:21:54,764 - INFO - Final validation performance:
Loss: 3.254, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:21:54,765 - INFO - Beginning epoch 742/800
2025-03-06 22:21:54,774 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:21:54,965 - INFO - training batch 51, loss: 0.270, 1632/28000 datapoints
2025-03-06 22:21:55,167 - INFO - training batch 101, loss: 0.215, 3232/28000 datapoints
2025-03-06 22:21:55,363 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 22:21:55,546 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 22:21:55,741 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:21:55,938 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:21:56,121 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:21:56,312 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:21:56,511 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:21:56,701 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:21:56,896 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-06 22:21:57,084 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:21:57,274 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:21:57,462 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:21:57,665 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:21:57,876 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:21:58,068 - INFO - training batch 851, loss: 0.018, 27232/28000 datapoints
2025-03-06 22:21:58,162 - INFO - validation batch 1, loss: 0.553, 32/6976 datapoints
2025-03-06 22:21:58,220 - INFO - validation batch 51, loss: 10.033, 1632/6976 datapoints
2025-03-06 22:21:58,270 - INFO - validation batch 101, loss: 1.853, 3232/6976 datapoints
2025-03-06 22:21:58,321 - INFO - validation batch 151, loss: 3.503, 4832/6976 datapoints
2025-03-06 22:21:58,373 - INFO - validation batch 201, loss: 1.443, 6432/6976 datapoints
2025-03-06 22:21:58,394 - INFO - Epoch 742/800 done.
2025-03-06 22:21:58,394 - INFO - Final validation performance:
Loss: 3.477, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:21:58,395 - INFO - Beginning epoch 743/800
2025-03-06 22:21:58,400 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:21:58,584 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:21:58,776 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:21:58,969 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:21:59,161 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:21:59,350 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:21:59,543 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:21:59,730 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:21:59,926 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-06 22:22:00,135 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:22:00,330 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:00,528 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:22:00,717 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:00,914 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:01,133 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:01,367 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:22:01,562 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:01,751 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:22:01,849 - INFO - validation batch 1, loss: 0.488, 32/6976 datapoints
2025-03-06 22:22:01,905 - INFO - validation batch 51, loss: 9.759, 1632/6976 datapoints
2025-03-06 22:22:01,955 - INFO - validation batch 101, loss: 1.574, 3232/6976 datapoints
2025-03-06 22:22:02,006 - INFO - validation batch 151, loss: 2.847, 4832/6976 datapoints
2025-03-06 22:22:02,057 - INFO - validation batch 201, loss: 1.405, 6432/6976 datapoints
2025-03-06 22:22:02,076 - INFO - Epoch 743/800 done.
2025-03-06 22:22:02,076 - INFO - Final validation performance:
Loss: 3.215, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:22:02,077 - INFO - Beginning epoch 744/800
2025-03-06 22:22:02,083 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:22:02,276 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:02,467 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:22:02,664 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:22:02,853 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:22:03,046 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:22:03,239 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:22:03,427 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:22:03,614 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:22:03,809 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-06 22:22:04,002 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:04,190 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:22:04,378 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:04,567 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:04,758 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:04,982 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:22:05,182 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:05,386 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:22:05,483 - INFO - validation batch 1, loss: 0.420, 32/6976 datapoints
2025-03-06 22:22:05,534 - INFO - validation batch 51, loss: 10.273, 1632/6976 datapoints
2025-03-06 22:22:05,584 - INFO - validation batch 101, loss: 1.588, 3232/6976 datapoints
2025-03-06 22:22:05,634 - INFO - validation batch 151, loss: 2.793, 4832/6976 datapoints
2025-03-06 22:22:05,685 - INFO - validation batch 201, loss: 1.366, 6432/6976 datapoints
2025-03-06 22:22:05,702 - INFO - Epoch 744/800 done.
2025-03-06 22:22:05,702 - INFO - Final validation performance:
Loss: 3.288, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:22:05,703 - INFO - Beginning epoch 745/800
2025-03-06 22:22:05,707 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 22:22:05,899 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:06,099 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:22:06,297 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:22:06,487 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:22:06,685 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:22:06,881 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:22:07,071 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:22:07,258 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:22:07,453 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:22:07,639 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:07,829 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:22:08,015 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:08,209 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:08,404 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:08,599 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:22:08,794 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:08,986 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:22:09,082 - INFO - validation batch 1, loss: 0.313, 32/6976 datapoints
2025-03-06 22:22:09,135 - INFO - validation batch 51, loss: 9.905, 1632/6976 datapoints
2025-03-06 22:22:09,187 - INFO - validation batch 101, loss: 1.779, 3232/6976 datapoints
2025-03-06 22:22:09,238 - INFO - validation batch 151, loss: 2.599, 4832/6976 datapoints
2025-03-06 22:22:09,291 - INFO - validation batch 201, loss: 1.402, 6432/6976 datapoints
2025-03-06 22:22:09,313 - INFO - Epoch 745/800 done.
2025-03-06 22:22:09,313 - INFO - Final validation performance:
Loss: 3.200, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:22:09,314 - INFO - Beginning epoch 746/800
2025-03-06 22:22:09,320 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:22:09,510 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:09,700 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:22:09,905 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:22:10,094 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:22:10,288 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:22:10,484 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:22:10,671 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:22:10,861 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:22:11,057 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:22:11,246 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:11,435 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:22:11,620 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:11,808 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:11,995 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:12,190 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:22:12,397 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:12,590 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:22:12,687 - INFO - validation batch 1, loss: 0.282, 32/6976 datapoints
2025-03-06 22:22:12,741 - INFO - validation batch 51, loss: 9.804, 1632/6976 datapoints
2025-03-06 22:22:12,800 - INFO - validation batch 101, loss: 1.627, 3232/6976 datapoints
2025-03-06 22:22:12,855 - INFO - validation batch 151, loss: 2.720, 4832/6976 datapoints
2025-03-06 22:22:12,908 - INFO - validation batch 201, loss: 1.221, 6432/6976 datapoints
2025-03-06 22:22:12,927 - INFO - Epoch 746/800 done.
2025-03-06 22:22:12,927 - INFO - Final validation performance:
Loss: 3.131, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:22:12,928 - INFO - Beginning epoch 747/800
2025-03-06 22:22:12,933 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:22:13,126 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:13,316 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:22:13,508 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:22:13,692 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:22:13,885 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:22:14,074 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:22:14,261 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:22:14,447 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:22:14,641 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:22:14,828 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:15,045 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 22:22:15,237 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:15,428 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:15,610 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:15,799 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:22:15,989 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:16,176 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:22:16,270 - INFO - validation batch 1, loss: 0.435, 32/6976 datapoints
2025-03-06 22:22:16,318 - INFO - validation batch 51, loss: 9.654, 1632/6976 datapoints
2025-03-06 22:22:16,366 - INFO - validation batch 101, loss: 1.500, 3232/6976 datapoints
2025-03-06 22:22:16,415 - INFO - validation batch 151, loss: 2.940, 4832/6976 datapoints
2025-03-06 22:22:16,464 - INFO - validation batch 201, loss: 1.371, 6432/6976 datapoints
2025-03-06 22:22:16,481 - INFO - Epoch 747/800 done.
2025-03-06 22:22:16,481 - INFO - Final validation performance:
Loss: 3.180, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:22:16,481 - INFO - Beginning epoch 748/800
2025-03-06 22:22:16,486 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:22:16,670 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:16,853 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:22:17,052 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:22:17,233 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:22:17,419 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:22:17,605 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:22:17,791 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:22:17,980 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:22:18,170 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:22:18,366 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:18,567 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:22:18,749 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:18,946 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:19,132 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:19,336 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:22:19,526 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:19,710 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:22:19,803 - INFO - validation batch 1, loss: 0.463, 32/6976 datapoints
2025-03-06 22:22:19,850 - INFO - validation batch 51, loss: 9.702, 1632/6976 datapoints
2025-03-06 22:22:19,901 - INFO - validation batch 101, loss: 1.467, 3232/6976 datapoints
2025-03-06 22:22:19,951 - INFO - validation batch 151, loss: 2.897, 4832/6976 datapoints
2025-03-06 22:22:20,000 - INFO - validation batch 201, loss: 1.379, 6432/6976 datapoints
2025-03-06 22:22:20,016 - INFO - Epoch 748/800 done.
2025-03-06 22:22:20,016 - INFO - Final validation performance:
Loss: 3.181, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:22:20,017 - INFO - Beginning epoch 749/800
2025-03-06 22:22:20,022 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:22:20,208 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:20,396 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:22:20,595 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:22:20,778 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:22:20,968 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:22:21,154 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:22:21,337 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:22:21,525 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:22:21,715 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:22:21,903 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:22,088 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:22:22,272 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:22,460 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:22,643 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:22,834 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:22:23,025 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:23,213 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:22:23,310 - INFO - validation batch 1, loss: 0.402, 32/6976 datapoints
2025-03-06 22:22:23,361 - INFO - validation batch 51, loss: 9.687, 1632/6976 datapoints
2025-03-06 22:22:23,408 - INFO - validation batch 101, loss: 1.486, 3232/6976 datapoints
2025-03-06 22:22:23,455 - INFO - validation batch 151, loss: 2.865, 4832/6976 datapoints
2025-03-06 22:22:23,505 - INFO - validation batch 201, loss: 1.357, 6432/6976 datapoints
2025-03-06 22:22:23,521 - INFO - Epoch 749/800 done.
2025-03-06 22:22:23,521 - INFO - Final validation performance:
Loss: 3.159, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:22:23,521 - INFO - Beginning epoch 750/800
2025-03-06 22:22:23,526 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:22:23,706 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:23,893 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:22:24,088 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:22:24,272 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:22:24,473 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:22:24,665 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:22:24,849 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:22:25,077 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:22:25,282 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:22:25,473 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:25,662 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:22:25,846 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:26,049 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:26,258 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:26,450 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:22:26,643 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:26,831 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:22:26,928 - INFO - validation batch 1, loss: 0.407, 32/6976 datapoints
2025-03-06 22:22:26,976 - INFO - validation batch 51, loss: 9.721, 1632/6976 datapoints
2025-03-06 22:22:27,024 - INFO - validation batch 101, loss: 1.502, 3232/6976 datapoints
2025-03-06 22:22:27,072 - INFO - validation batch 151, loss: 2.892, 4832/6976 datapoints
2025-03-06 22:22:27,119 - INFO - validation batch 201, loss: 1.349, 6432/6976 datapoints
2025-03-06 22:22:27,135 - INFO - Epoch 750/800 done.
2025-03-06 22:22:27,135 - INFO - Final validation performance:
Loss: 3.174, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:22:27,136 - INFO - Beginning epoch 751/800
2025-03-06 22:22:27,140 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:22:27,325 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:27,507 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:22:27,701 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:22:27,882 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:22:28,077 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:22:28,267 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:22:28,455 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:22:28,645 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:22:28,836 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:22:29,026 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:29,211 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:22:29,396 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:29,583 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:29,765 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:29,961 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:22:30,159 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:30,351 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:22:30,447 - INFO - validation batch 1, loss: 0.419, 32/6976 datapoints
2025-03-06 22:22:30,495 - INFO - validation batch 51, loss: 9.753, 1632/6976 datapoints
2025-03-06 22:22:30,550 - INFO - validation batch 101, loss: 1.516, 3232/6976 datapoints
2025-03-06 22:22:30,599 - INFO - validation batch 151, loss: 2.920, 4832/6976 datapoints
2025-03-06 22:22:30,651 - INFO - validation batch 201, loss: 1.347, 6432/6976 datapoints
2025-03-06 22:22:30,673 - INFO - Epoch 751/800 done.
2025-03-06 22:22:30,673 - INFO - Final validation performance:
Loss: 3.191, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:22:30,674 - INFO - Beginning epoch 752/800
2025-03-06 22:22:30,679 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:22:30,874 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:31,065 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:22:31,260 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:22:31,447 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:22:31,641 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:22:31,841 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:22:32,028 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:22:32,219 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:22:32,413 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:22:32,609 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:32,795 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:22:32,984 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:33,174 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:33,363 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:33,558 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:22:33,750 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:33,942 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:22:34,040 - INFO - validation batch 1, loss: 0.424, 32/6976 datapoints
2025-03-06 22:22:34,092 - INFO - validation batch 51, loss: 9.774, 1632/6976 datapoints
2025-03-06 22:22:34,144 - INFO - validation batch 101, loss: 1.532, 3232/6976 datapoints
2025-03-06 22:22:34,195 - INFO - validation batch 151, loss: 2.949, 4832/6976 datapoints
2025-03-06 22:22:34,248 - INFO - validation batch 201, loss: 1.350, 6432/6976 datapoints
2025-03-06 22:22:34,265 - INFO - Epoch 752/800 done.
2025-03-06 22:22:34,265 - INFO - Final validation performance:
Loss: 3.206, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:22:34,266 - INFO - Beginning epoch 753/800
2025-03-06 22:22:34,271 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:22:34,456 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:34,644 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:22:34,834 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:22:35,021 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:22:35,248 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:22:35,448 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:22:35,631 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:22:35,816 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:22:36,009 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:22:36,198 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:36,385 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:22:36,572 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:36,758 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:36,959 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:37,151 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:22:37,343 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:37,531 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:22:37,628 - INFO - validation batch 1, loss: 0.418, 32/6976 datapoints
2025-03-06 22:22:37,676 - INFO - validation batch 51, loss: 9.790, 1632/6976 datapoints
2025-03-06 22:22:37,723 - INFO - validation batch 101, loss: 1.548, 3232/6976 datapoints
2025-03-06 22:22:37,772 - INFO - validation batch 151, loss: 2.978, 4832/6976 datapoints
2025-03-06 22:22:37,820 - INFO - validation batch 201, loss: 1.361, 6432/6976 datapoints
2025-03-06 22:22:37,837 - INFO - Epoch 753/800 done.
2025-03-06 22:22:37,837 - INFO - Final validation performance:
Loss: 3.219, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:22:37,837 - INFO - Beginning epoch 754/800
2025-03-06 22:22:37,842 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:22:38,044 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:38,231 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:22:38,432 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:22:38,620 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:22:38,807 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:22:38,999 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:22:39,182 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:22:39,375 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:22:39,566 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:22:39,754 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:39,945 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:22:40,130 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:40,315 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:40,499 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:40,692 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:22:40,878 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:41,068 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:22:41,162 - INFO - validation batch 1, loss: 0.391, 32/6976 datapoints
2025-03-06 22:22:41,210 - INFO - validation batch 51, loss: 9.807, 1632/6976 datapoints
2025-03-06 22:22:41,256 - INFO - validation batch 101, loss: 1.558, 3232/6976 datapoints
2025-03-06 22:22:41,304 - INFO - validation batch 151, loss: 2.989, 4832/6976 datapoints
2025-03-06 22:22:41,351 - INFO - validation batch 201, loss: 1.374, 6432/6976 datapoints
2025-03-06 22:22:41,367 - INFO - Epoch 754/800 done.
2025-03-06 22:22:41,367 - INFO - Final validation performance:
Loss: 3.224, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:22:41,368 - INFO - Beginning epoch 755/800
2025-03-06 22:22:41,373 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:22:41,556 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:41,744 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:22:41,935 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:22:42,119 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:22:42,308 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:22:42,500 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:22:42,684 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:22:42,875 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:22:43,077 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:22:43,263 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:43,456 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:22:43,644 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:43,834 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:44,022 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:44,214 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:22:44,403 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:44,592 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:22:44,687 - INFO - validation batch 1, loss: 0.387, 32/6976 datapoints
2025-03-06 22:22:44,734 - INFO - validation batch 51, loss: 9.855, 1632/6976 datapoints
2025-03-06 22:22:44,782 - INFO - validation batch 101, loss: 1.561, 3232/6976 datapoints
2025-03-06 22:22:44,829 - INFO - validation batch 151, loss: 3.014, 4832/6976 datapoints
2025-03-06 22:22:44,878 - INFO - validation batch 201, loss: 1.381, 6432/6976 datapoints
2025-03-06 22:22:44,896 - INFO - Epoch 755/800 done.
2025-03-06 22:22:44,896 - INFO - Final validation performance:
Loss: 3.240, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:22:44,896 - INFO - Beginning epoch 756/800
2025-03-06 22:22:44,901 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:22:45,084 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:45,304 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:22:45,501 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:22:45,688 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:22:45,877 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:22:46,071 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:22:46,256 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:22:46,442 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:22:46,637 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:22:46,821 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:47,009 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:22:47,205 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:47,395 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:47,579 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:47,769 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:22:47,964 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:48,149 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:22:48,244 - INFO - validation batch 1, loss: 0.432, 32/6976 datapoints
2025-03-06 22:22:48,292 - INFO - validation batch 51, loss: 9.935, 1632/6976 datapoints
2025-03-06 22:22:48,339 - INFO - validation batch 101, loss: 1.590, 3232/6976 datapoints
2025-03-06 22:22:48,388 - INFO - validation batch 151, loss: 3.069, 4832/6976 datapoints
2025-03-06 22:22:48,444 - INFO - validation batch 201, loss: 1.388, 6432/6976 datapoints
2025-03-06 22:22:48,460 - INFO - Epoch 756/800 done.
2025-03-06 22:22:48,460 - INFO - Final validation performance:
Loss: 3.283, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:22:48,461 - INFO - Beginning epoch 757/800
2025-03-06 22:22:48,466 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:22:48,649 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:48,836 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:22:49,044 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:22:49,228 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:22:49,419 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:22:49,618 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:22:49,802 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:22:49,996 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:22:50,197 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:22:50,388 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:50,582 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:22:50,776 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:50,969 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:51,158 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:51,355 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:22:51,545 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:51,737 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:22:51,836 - INFO - validation batch 1, loss: 0.419, 32/6976 datapoints
2025-03-06 22:22:51,889 - INFO - validation batch 51, loss: 10.001, 1632/6976 datapoints
2025-03-06 22:22:51,941 - INFO - validation batch 101, loss: 1.648, 3232/6976 datapoints
2025-03-06 22:22:51,993 - INFO - validation batch 151, loss: 3.144, 4832/6976 datapoints
2025-03-06 22:22:52,044 - INFO - validation batch 201, loss: 1.408, 6432/6976 datapoints
2025-03-06 22:22:52,061 - INFO - Epoch 757/800 done.
2025-03-06 22:22:52,061 - INFO - Final validation performance:
Loss: 3.324, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:22:52,061 - INFO - Beginning epoch 758/800
2025-03-06 22:22:52,066 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:22:52,254 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:52,447 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:22:52,645 - INFO - training batch 151, loss: 0.453, 4832/28000 datapoints
2025-03-06 22:22:52,837 - INFO - training batch 201, loss: 0.363, 6432/28000 datapoints
2025-03-06 22:22:53,031 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:22:53,222 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:22:53,415 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:22:53,602 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:22:53,795 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:22:53,989 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:54,177 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:22:54,368 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:22:54,560 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:54,750 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:22:54,947 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:22:55,162 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:55,389 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:22:55,487 - INFO - validation batch 1, loss: 0.618, 32/6976 datapoints
2025-03-06 22:22:55,545 - INFO - validation batch 51, loss: 10.318, 1632/6976 datapoints
2025-03-06 22:22:55,600 - INFO - validation batch 101, loss: 1.838, 3232/6976 datapoints
2025-03-06 22:22:55,651 - INFO - validation batch 151, loss: 2.692, 4832/6976 datapoints
2025-03-06 22:22:55,707 - INFO - validation batch 201, loss: 1.306, 6432/6976 datapoints
2025-03-06 22:22:55,726 - INFO - Epoch 758/800 done.
2025-03-06 22:22:55,726 - INFO - Final validation performance:
Loss: 3.355, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:22:55,726 - INFO - Beginning epoch 759/800
2025-03-06 22:22:55,732 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:22:55,924 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:56,114 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:22:56,305 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:22:56,492 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:22:56,685 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 22:22:56,874 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:22:57,062 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:22:57,248 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:22:57,439 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:22:57,626 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:22:57,819 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:22:58,007 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:22:58,202 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:22:58,392 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:22:58,586 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:22:58,782 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:22:58,975 - INFO - training batch 851, loss: 0.086, 27232/28000 datapoints
2025-03-06 22:22:59,067 - INFO - validation batch 1, loss: 0.082, 32/6976 datapoints
2025-03-06 22:22:59,115 - INFO - validation batch 51, loss: 10.743, 1632/6976 datapoints
2025-03-06 22:22:59,162 - INFO - validation batch 101, loss: 2.136, 3232/6976 datapoints
2025-03-06 22:22:59,211 - INFO - validation batch 151, loss: 3.785, 4832/6976 datapoints
2025-03-06 22:22:59,257 - INFO - validation batch 201, loss: 1.295, 6432/6976 datapoints
2025-03-06 22:22:59,274 - INFO - Epoch 759/800 done.
2025-03-06 22:22:59,275 - INFO - Final validation performance:
Loss: 3.608, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:22:59,275 - INFO - Beginning epoch 760/800
2025-03-06 22:22:59,280 - INFO - training batch 1, loss: 0.041, 32/28000 datapoints
2025-03-06 22:22:59,464 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:22:59,651 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:22:59,845 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:00,036 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:23:00,223 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:23:00,417 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:23:00,602 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:23:00,796 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:23:00,992 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:23:01,178 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:01,381 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:23:01,567 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:23:01,759 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:01,952 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:02,146 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:23:02,336 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:02,523 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:23:02,616 - INFO - validation batch 1, loss: 0.237, 32/6976 datapoints
2025-03-06 22:23:02,666 - INFO - validation batch 51, loss: 9.317, 1632/6976 datapoints
2025-03-06 22:23:02,714 - INFO - validation batch 101, loss: 2.021, 3232/6976 datapoints
2025-03-06 22:23:02,761 - INFO - validation batch 151, loss: 3.317, 4832/6976 datapoints
2025-03-06 22:23:02,808 - INFO - validation batch 201, loss: 1.464, 6432/6976 datapoints
2025-03-06 22:23:02,824 - INFO - Epoch 760/800 done.
2025-03-06 22:23:02,824 - INFO - Final validation performance:
Loss: 3.271, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:23:02,825 - INFO - Beginning epoch 761/800
2025-03-06 22:23:02,830 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:23:03,016 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:23:03,199 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:23:03,390 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:03,577 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:23:03,764 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:23:03,955 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:23:04,137 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:23:04,324 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:23:04,519 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:23:04,708 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:04,897 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:23:05,084 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:23:05,282 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:05,494 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:05,685 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:23:05,875 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:06,064 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:23:06,157 - INFO - validation batch 1, loss: 0.969, 32/6976 datapoints
2025-03-06 22:23:06,205 - INFO - validation batch 51, loss: 9.350, 1632/6976 datapoints
2025-03-06 22:23:06,254 - INFO - validation batch 101, loss: 2.133, 3232/6976 datapoints
2025-03-06 22:23:06,303 - INFO - validation batch 151, loss: 3.596, 4832/6976 datapoints
2025-03-06 22:23:06,353 - INFO - validation batch 201, loss: 1.665, 6432/6976 datapoints
2025-03-06 22:23:06,370 - INFO - Epoch 761/800 done.
2025-03-06 22:23:06,370 - INFO - Final validation performance:
Loss: 3.543, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:23:06,371 - INFO - Beginning epoch 762/800
2025-03-06 22:23:06,376 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:23:06,560 - INFO - training batch 51, loss: 0.080, 1632/28000 datapoints
2025-03-06 22:23:06,751 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:23:06,944 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:07,128 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:23:07,317 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:23:07,509 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:23:07,699 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:23:07,893 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:23:08,088 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:23:08,283 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:08,557 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:23:08,745 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:23:08,934 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:09,119 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:09,309 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:23:09,501 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:09,689 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:23:09,781 - INFO - validation batch 1, loss: 0.379, 32/6976 datapoints
2025-03-06 22:23:09,828 - INFO - validation batch 51, loss: 9.130, 1632/6976 datapoints
2025-03-06 22:23:09,875 - INFO - validation batch 101, loss: 2.025, 3232/6976 datapoints
2025-03-06 22:23:09,925 - INFO - validation batch 151, loss: 4.107, 4832/6976 datapoints
2025-03-06 22:23:09,972 - INFO - validation batch 201, loss: 1.573, 6432/6976 datapoints
2025-03-06 22:23:09,988 - INFO - Epoch 762/800 done.
2025-03-06 22:23:09,989 - INFO - Final validation performance:
Loss: 3.443, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:23:09,989 - INFO - Beginning epoch 763/800
2025-03-06 22:23:09,994 - INFO - training batch 1, loss: 0.011, 32/28000 datapoints
2025-03-06 22:23:10,183 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:23:10,377 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:23:10,574 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:10,766 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:23:10,974 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-06 22:23:11,188 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:23:11,419 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:23:11,638 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:23:11,864 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:23:12,062 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:12,256 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:23:12,444 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:23:12,634 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:12,823 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:13,027 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:23:13,224 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:13,415 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:23:13,512 - INFO - validation batch 1, loss: 0.430, 32/6976 datapoints
2025-03-06 22:23:13,564 - INFO - validation batch 51, loss: 9.744, 1632/6976 datapoints
2025-03-06 22:23:13,617 - INFO - validation batch 101, loss: 1.749, 3232/6976 datapoints
2025-03-06 22:23:13,668 - INFO - validation batch 151, loss: 3.024, 4832/6976 datapoints
2025-03-06 22:23:13,722 - INFO - validation batch 201, loss: 1.415, 6432/6976 datapoints
2025-03-06 22:23:13,742 - INFO - Epoch 763/800 done.
2025-03-06 22:23:13,742 - INFO - Final validation performance:
Loss: 3.272, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:23:13,743 - INFO - Beginning epoch 764/800
2025-03-06 22:23:13,748 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:23:13,950 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:23:14,140 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:23:14,348 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:14,540 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:23:14,738 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:23:14,930 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:23:15,115 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:23:15,311 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:23:15,522 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:23:15,730 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:15,921 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:23:16,112 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:23:16,304 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:16,492 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:16,693 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:23:16,887 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:17,079 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:23:17,176 - INFO - validation batch 1, loss: 0.478, 32/6976 datapoints
2025-03-06 22:23:17,228 - INFO - validation batch 51, loss: 9.862, 1632/6976 datapoints
2025-03-06 22:23:17,278 - INFO - validation batch 101, loss: 1.724, 3232/6976 datapoints
2025-03-06 22:23:17,325 - INFO - validation batch 151, loss: 2.967, 4832/6976 datapoints
2025-03-06 22:23:17,373 - INFO - validation batch 201, loss: 1.401, 6432/6976 datapoints
2025-03-06 22:23:17,389 - INFO - Epoch 764/800 done.
2025-03-06 22:23:17,389 - INFO - Final validation performance:
Loss: 3.286, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:23:17,389 - INFO - Beginning epoch 765/800
2025-03-06 22:23:17,394 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:23:17,579 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:23:17,766 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:23:17,960 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:18,142 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:23:18,331 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:23:18,526 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:23:18,712 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:23:18,907 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:23:19,099 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:23:19,285 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:19,474 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:23:19,659 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:23:19,844 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:20,043 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:20,237 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:23:20,426 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:20,648 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:23:20,746 - INFO - validation batch 1, loss: 0.408, 32/6976 datapoints
2025-03-06 22:23:20,794 - INFO - validation batch 51, loss: 9.895, 1632/6976 datapoints
2025-03-06 22:23:20,843 - INFO - validation batch 101, loss: 1.744, 3232/6976 datapoints
2025-03-06 22:23:20,897 - INFO - validation batch 151, loss: 2.862, 4832/6976 datapoints
2025-03-06 22:23:20,944 - INFO - validation batch 201, loss: 1.374, 6432/6976 datapoints
2025-03-06 22:23:20,961 - INFO - Epoch 765/800 done.
2025-03-06 22:23:20,961 - INFO - Final validation performance:
Loss: 3.257, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:23:20,961 - INFO - Beginning epoch 766/800
2025-03-06 22:23:20,967 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:23:21,155 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:23:21,341 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:23:21,532 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:21,718 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:23:21,908 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:23:22,096 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:23:22,286 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:23:22,476 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:23:22,667 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:23:22,858 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:23,048 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:23:23,237 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:23:23,421 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:23,606 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:23,802 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:23:23,993 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:24,179 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:23:24,275 - INFO - validation batch 1, loss: 0.384, 32/6976 datapoints
2025-03-06 22:23:24,323 - INFO - validation batch 51, loss: 9.886, 1632/6976 datapoints
2025-03-06 22:23:24,371 - INFO - validation batch 101, loss: 1.749, 3232/6976 datapoints
2025-03-06 22:23:24,418 - INFO - validation batch 151, loss: 2.976, 4832/6976 datapoints
2025-03-06 22:23:24,466 - INFO - validation batch 201, loss: 1.388, 6432/6976 datapoints
2025-03-06 22:23:24,483 - INFO - Epoch 766/800 done.
2025-03-06 22:23:24,483 - INFO - Final validation performance:
Loss: 3.277, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:23:24,484 - INFO - Beginning epoch 767/800
2025-03-06 22:23:24,488 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:23:24,671 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:23:24,867 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:23:25,061 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:25,251 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:23:25,455 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:23:25,660 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:23:25,854 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:23:26,054 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:23:26,252 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:23:26,444 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:26,673 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:23:26,874 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:23:27,069 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:27,254 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:27,447 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:23:27,638 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:27,824 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:23:27,924 - INFO - validation batch 1, loss: 0.371, 32/6976 datapoints
2025-03-06 22:23:27,973 - INFO - validation batch 51, loss: 9.902, 1632/6976 datapoints
2025-03-06 22:23:28,020 - INFO - validation batch 101, loss: 1.764, 3232/6976 datapoints
2025-03-06 22:23:28,068 - INFO - validation batch 151, loss: 3.001, 4832/6976 datapoints
2025-03-06 22:23:28,115 - INFO - validation batch 201, loss: 1.402, 6432/6976 datapoints
2025-03-06 22:23:28,131 - INFO - Epoch 767/800 done.
2025-03-06 22:23:28,131 - INFO - Final validation performance:
Loss: 3.288, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:23:28,132 - INFO - Beginning epoch 768/800
2025-03-06 22:23:28,136 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:23:28,326 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:23:28,510 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:23:28,708 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:28,898 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:23:29,085 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:23:29,275 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:23:29,460 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:23:29,648 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:23:29,841 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:23:30,032 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:30,219 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:23:30,412 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:23:30,601 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:30,792 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:30,988 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:23:31,181 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:31,374 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:23:31,471 - INFO - validation batch 1, loss: 0.353, 32/6976 datapoints
2025-03-06 22:23:31,521 - INFO - validation batch 51, loss: 9.914, 1632/6976 datapoints
2025-03-06 22:23:31,576 - INFO - validation batch 101, loss: 1.777, 3232/6976 datapoints
2025-03-06 22:23:31,624 - INFO - validation batch 151, loss: 3.030, 4832/6976 datapoints
2025-03-06 22:23:31,671 - INFO - validation batch 201, loss: 1.417, 6432/6976 datapoints
2025-03-06 22:23:31,687 - INFO - Epoch 768/800 done.
2025-03-06 22:23:31,688 - INFO - Final validation performance:
Loss: 3.298, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:23:31,688 - INFO - Beginning epoch 769/800
2025-03-06 22:23:31,693 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:23:31,877 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:23:32,065 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:23:32,263 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:32,457 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:23:32,647 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:23:32,847 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:23:33,034 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:23:33,226 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:23:33,422 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:23:33,607 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:33,793 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:23:33,984 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:23:34,170 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:34,355 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:34,548 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:23:34,738 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:34,928 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:23:35,022 - INFO - validation batch 1, loss: 0.327, 32/6976 datapoints
2025-03-06 22:23:35,069 - INFO - validation batch 51, loss: 9.919, 1632/6976 datapoints
2025-03-06 22:23:35,118 - INFO - validation batch 101, loss: 1.787, 3232/6976 datapoints
2025-03-06 22:23:35,173 - INFO - validation batch 151, loss: 3.067, 4832/6976 datapoints
2025-03-06 22:23:35,220 - INFO - validation batch 201, loss: 1.437, 6432/6976 datapoints
2025-03-06 22:23:35,236 - INFO - Epoch 769/800 done.
2025-03-06 22:23:35,236 - INFO - Final validation performance:
Loss: 3.307, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:23:35,237 - INFO - Beginning epoch 770/800
2025-03-06 22:23:35,242 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:23:35,428 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:23:35,622 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:23:35,835 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:36,022 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:23:36,209 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:23:36,399 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:23:36,584 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:23:36,774 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:23:36,969 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:23:37,153 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:37,340 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:23:37,533 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:23:37,721 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:37,922 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:38,110 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:23:38,297 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:38,494 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:23:38,597 - INFO - validation batch 1, loss: 0.292, 32/6976 datapoints
2025-03-06 22:23:38,644 - INFO - validation batch 51, loss: 9.942, 1632/6976 datapoints
2025-03-06 22:23:38,691 - INFO - validation batch 101, loss: 1.786, 3232/6976 datapoints
2025-03-06 22:23:38,739 - INFO - validation batch 151, loss: 3.091, 4832/6976 datapoints
2025-03-06 22:23:38,789 - INFO - validation batch 201, loss: 1.458, 6432/6976 datapoints
2025-03-06 22:23:38,806 - INFO - Epoch 770/800 done.
2025-03-06 22:23:38,806 - INFO - Final validation performance:
Loss: 3.314, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:23:38,806 - INFO - Beginning epoch 771/800
2025-03-06 22:23:38,811 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:23:39,004 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:23:39,192 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:23:39,384 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:39,571 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:23:39,759 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:23:39,953 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:23:40,135 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:23:40,324 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:23:40,517 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:23:40,704 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:40,898 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:23:41,086 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:23:41,275 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:41,464 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:41,657 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:23:41,845 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:42,034 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:23:42,128 - INFO - validation batch 1, loss: 0.273, 32/6976 datapoints
2025-03-06 22:23:42,176 - INFO - validation batch 51, loss: 10.003, 1632/6976 datapoints
2025-03-06 22:23:42,222 - INFO - validation batch 101, loss: 1.783, 3232/6976 datapoints
2025-03-06 22:23:42,269 - INFO - validation batch 151, loss: 3.120, 4832/6976 datapoints
2025-03-06 22:23:42,316 - INFO - validation batch 201, loss: 1.467, 6432/6976 datapoints
2025-03-06 22:23:42,332 - INFO - Epoch 771/800 done.
2025-03-06 22:23:42,333 - INFO - Final validation performance:
Loss: 3.329, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:23:42,333 - INFO - Beginning epoch 772/800
2025-03-06 22:23:42,339 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:23:42,525 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:23:42,712 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:23:42,905 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:43,090 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:23:43,280 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:23:43,470 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:23:43,658 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:23:43,845 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:23:44,042 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:23:44,230 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:44,409 - INFO - training batch 551, loss: 0.239, 17632/28000 datapoints
2025-03-06 22:23:44,599 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:23:44,807 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:44,996 - INFO - training batch 701, loss: 0.035, 22432/28000 datapoints
2025-03-06 22:23:45,191 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:23:45,392 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:45,587 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:23:45,688 - INFO - validation batch 1, loss: 0.504, 32/6976 datapoints
2025-03-06 22:23:45,736 - INFO - validation batch 51, loss: 10.786, 1632/6976 datapoints
2025-03-06 22:23:45,785 - INFO - validation batch 101, loss: 1.696, 3232/6976 datapoints
2025-03-06 22:23:45,850 - INFO - validation batch 151, loss: 2.813, 4832/6976 datapoints
2025-03-06 22:23:45,926 - INFO - validation batch 201, loss: 1.601, 6432/6976 datapoints
2025-03-06 22:23:45,943 - INFO - Epoch 772/800 done.
2025-03-06 22:23:45,943 - INFO - Final validation performance:
Loss: 3.480, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:23:45,944 - INFO - Beginning epoch 773/800
2025-03-06 22:23:45,952 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-06 22:23:46,137 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:23:46,324 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:23:46,518 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:46,705 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:23:46,910 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:23:47,104 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:23:47,289 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:23:47,481 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:23:47,674 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:23:47,860 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:48,052 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:23:48,239 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:23:48,426 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:48,617 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:48,813 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:23:49,007 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:49,196 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:23:49,289 - INFO - validation batch 1, loss: 0.586, 32/6976 datapoints
2025-03-06 22:23:49,337 - INFO - validation batch 51, loss: 10.291, 1632/6976 datapoints
2025-03-06 22:23:49,385 - INFO - validation batch 101, loss: 1.704, 3232/6976 datapoints
2025-03-06 22:23:49,433 - INFO - validation batch 151, loss: 3.238, 4832/6976 datapoints
2025-03-06 22:23:49,481 - INFO - validation batch 201, loss: 1.567, 6432/6976 datapoints
2025-03-06 22:23:49,499 - INFO - Epoch 773/800 done.
2025-03-06 22:23:49,499 - INFO - Final validation performance:
Loss: 3.477, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:23:49,499 - INFO - Beginning epoch 774/800
2025-03-06 22:23:49,505 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:23:49,698 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:23:49,880 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:23:50,076 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:50,258 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:23:50,454 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:23:50,652 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:23:50,861 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:23:51,058 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:23:51,260 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:23:51,456 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:51,657 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:23:51,847 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:23:52,044 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:52,234 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:52,430 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:23:52,627 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:52,825 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:23:52,926 - INFO - validation batch 1, loss: 0.596, 32/6976 datapoints
2025-03-06 22:23:52,978 - INFO - validation batch 51, loss: 10.172, 1632/6976 datapoints
2025-03-06 22:23:53,031 - INFO - validation batch 101, loss: 1.945, 3232/6976 datapoints
2025-03-06 22:23:53,080 - INFO - validation batch 151, loss: 3.812, 4832/6976 datapoints
2025-03-06 22:23:53,128 - INFO - validation batch 201, loss: 1.510, 6432/6976 datapoints
2025-03-06 22:23:53,144 - INFO - Epoch 774/800 done.
2025-03-06 22:23:53,144 - INFO - Final validation performance:
Loss: 3.607, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:23:53,145 - INFO - Beginning epoch 775/800
2025-03-06 22:23:53,151 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:23:53,336 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-06 22:23:53,522 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:23:53,713 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:53,902 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:23:54,098 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:23:54,287 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:23:54,468 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:23:54,656 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:23:54,854 - INFO - training batch 451, loss: 0.081, 14432/28000 datapoints
2025-03-06 22:23:55,040 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:23:55,240 - INFO - training batch 551, loss: 0.029, 17632/28000 datapoints
2025-03-06 22:23:55,430 - INFO - training batch 601, loss: 0.089, 19232/28000 datapoints
2025-03-06 22:23:55,624 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:55,814 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:56,031 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:23:56,223 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:23:56,414 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:23:56,510 - INFO - validation batch 1, loss: 0.378, 32/6976 datapoints
2025-03-06 22:23:56,556 - INFO - validation batch 51, loss: 10.253, 1632/6976 datapoints
2025-03-06 22:23:56,605 - INFO - validation batch 101, loss: 1.485, 3232/6976 datapoints
2025-03-06 22:23:56,654 - INFO - validation batch 151, loss: 3.044, 4832/6976 datapoints
2025-03-06 22:23:56,701 - INFO - validation batch 201, loss: 1.401, 6432/6976 datapoints
2025-03-06 22:23:56,717 - INFO - Epoch 775/800 done.
2025-03-06 22:23:56,717 - INFO - Final validation performance:
Loss: 3.312, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:23:56,718 - INFO - Beginning epoch 776/800
2025-03-06 22:23:56,723 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:23:56,913 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:23:57,113 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:23:57,310 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:23:57,501 - INFO - training batch 201, loss: 0.162, 6432/28000 datapoints
2025-03-06 22:23:57,693 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:23:57,891 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:23:58,076 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:23:58,265 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:23:58,464 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:23:58,661 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:23:58,857 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:23:59,050 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:23:59,239 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:23:59,426 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:23:59,623 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:23:59,818 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:00,010 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:24:00,104 - INFO - validation batch 1, loss: 0.342, 32/6976 datapoints
2025-03-06 22:24:00,152 - INFO - validation batch 51, loss: 10.676, 1632/6976 datapoints
2025-03-06 22:24:00,200 - INFO - validation batch 101, loss: 1.525, 3232/6976 datapoints
2025-03-06 22:24:00,247 - INFO - validation batch 151, loss: 3.159, 4832/6976 datapoints
2025-03-06 22:24:00,294 - INFO - validation batch 201, loss: 1.554, 6432/6976 datapoints
2025-03-06 22:24:00,310 - INFO - Epoch 776/800 done.
2025-03-06 22:24:00,311 - INFO - Final validation performance:
Loss: 3.451, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:24:00,311 - INFO - Beginning epoch 777/800
2025-03-06 22:24:00,316 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:24:00,498 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:24:00,683 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:24:00,881 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:01,069 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:01,257 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:24:01,448 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:24:01,635 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:24:01,827 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:24:02,094 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:24:02,284 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:24:02,477 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:24:02,667 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:24:02,858 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:24:03,045 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:24:03,248 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:24:03,444 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:03,631 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:24:03,729 - INFO - validation batch 1, loss: 0.289, 32/6976 datapoints
2025-03-06 22:24:03,776 - INFO - validation batch 51, loss: 9.658, 1632/6976 datapoints
2025-03-06 22:24:03,829 - INFO - validation batch 101, loss: 1.668, 3232/6976 datapoints
2025-03-06 22:24:03,878 - INFO - validation batch 151, loss: 3.167, 4832/6976 datapoints
2025-03-06 22:24:03,928 - INFO - validation batch 201, loss: 1.381, 6432/6976 datapoints
2025-03-06 22:24:03,944 - INFO - Epoch 777/800 done.
2025-03-06 22:24:03,944 - INFO - Final validation performance:
Loss: 3.233, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:24:03,944 - INFO - Beginning epoch 778/800
2025-03-06 22:24:03,949 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:24:04,135 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:24:04,321 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:24:04,514 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:04,702 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:04,896 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:24:05,090 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:24:05,284 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:24:05,475 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:24:05,674 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:24:05,866 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:24:06,087 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:24:06,279 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:24:06,467 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:24:06,656 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:24:06,849 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:24:07,078 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:07,271 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:24:07,363 - INFO - validation batch 1, loss: 0.311, 32/6976 datapoints
2025-03-06 22:24:07,413 - INFO - validation batch 51, loss: 9.895, 1632/6976 datapoints
2025-03-06 22:24:07,464 - INFO - validation batch 101, loss: 1.611, 3232/6976 datapoints
2025-03-06 22:24:07,511 - INFO - validation batch 151, loss: 3.109, 4832/6976 datapoints
2025-03-06 22:24:07,559 - INFO - validation batch 201, loss: 1.346, 6432/6976 datapoints
2025-03-06 22:24:07,575 - INFO - Epoch 778/800 done.
2025-03-06 22:24:07,575 - INFO - Final validation performance:
Loss: 3.254, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:24:07,576 - INFO - Beginning epoch 779/800
2025-03-06 22:24:07,580 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:24:07,767 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:24:07,956 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:24:08,152 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:08,338 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:08,529 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:24:08,771 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:24:09,011 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:24:09,216 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:24:09,429 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:24:09,618 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:24:09,812 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:24:10,008 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:24:10,199 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:24:10,391 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:24:10,585 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:24:10,783 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:10,978 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:24:11,073 - INFO - validation batch 1, loss: 0.297, 32/6976 datapoints
2025-03-06 22:24:11,121 - INFO - validation batch 51, loss: 9.964, 1632/6976 datapoints
2025-03-06 22:24:11,174 - INFO - validation batch 101, loss: 1.628, 3232/6976 datapoints
2025-03-06 22:24:11,227 - INFO - validation batch 151, loss: 3.055, 4832/6976 datapoints
2025-03-06 22:24:11,278 - INFO - validation batch 201, loss: 1.349, 6432/6976 datapoints
2025-03-06 22:24:11,295 - INFO - Epoch 779/800 done.
2025-03-06 22:24:11,296 - INFO - Final validation performance:
Loss: 3.259, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:24:11,296 - INFO - Beginning epoch 780/800
2025-03-06 22:24:11,301 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:24:11,493 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:24:11,687 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:24:11,891 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:12,085 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:12,298 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:24:12,491 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:24:12,680 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:24:12,875 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:24:13,084 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:24:13,276 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:24:13,467 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:24:13,660 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:24:13,854 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:24:14,048 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:24:14,245 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:24:14,440 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:14,629 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:24:14,728 - INFO - validation batch 1, loss: 0.336, 32/6976 datapoints
2025-03-06 22:24:14,779 - INFO - validation batch 51, loss: 9.999, 1632/6976 datapoints
2025-03-06 22:24:14,828 - INFO - validation batch 101, loss: 1.632, 3232/6976 datapoints
2025-03-06 22:24:14,875 - INFO - validation batch 151, loss: 3.098, 4832/6976 datapoints
2025-03-06 22:24:14,927 - INFO - validation batch 201, loss: 1.361, 6432/6976 datapoints
2025-03-06 22:24:14,943 - INFO - Epoch 780/800 done.
2025-03-06 22:24:14,943 - INFO - Final validation performance:
Loss: 3.285, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:24:14,943 - INFO - Beginning epoch 781/800
2025-03-06 22:24:14,948 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:24:15,132 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:24:15,331 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:24:15,537 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:15,727 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:15,928 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:24:16,130 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:24:16,337 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:24:16,526 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:24:16,724 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:24:16,918 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:24:17,124 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:24:17,311 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:24:17,499 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:24:17,687 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:24:17,880 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:24:18,073 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:18,261 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:24:18,356 - INFO - validation batch 1, loss: 0.337, 32/6976 datapoints
2025-03-06 22:24:18,403 - INFO - validation batch 51, loss: 10.029, 1632/6976 datapoints
2025-03-06 22:24:18,450 - INFO - validation batch 101, loss: 1.637, 3232/6976 datapoints
2025-03-06 22:24:18,496 - INFO - validation batch 151, loss: 3.143, 4832/6976 datapoints
2025-03-06 22:24:18,543 - INFO - validation batch 201, loss: 1.374, 6432/6976 datapoints
2025-03-06 22:24:18,559 - INFO - Epoch 781/800 done.
2025-03-06 22:24:18,559 - INFO - Final validation performance:
Loss: 3.304, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:24:18,560 - INFO - Beginning epoch 782/800
2025-03-06 22:24:18,564 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:24:18,748 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:24:18,945 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:24:19,140 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:19,328 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:19,517 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:24:19,709 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:24:19,898 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:24:20,088 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:24:20,285 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:24:20,476 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:24:20,670 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:24:20,859 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:24:21,050 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:24:21,235 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:24:21,429 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:24:21,620 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:21,820 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:24:21,918 - INFO - validation batch 1, loss: 0.325, 32/6976 datapoints
2025-03-06 22:24:21,965 - INFO - validation batch 51, loss: 10.056, 1632/6976 datapoints
2025-03-06 22:24:22,012 - INFO - validation batch 101, loss: 1.642, 3232/6976 datapoints
2025-03-06 22:24:22,058 - INFO - validation batch 151, loss: 3.182, 4832/6976 datapoints
2025-03-06 22:24:22,107 - INFO - validation batch 201, loss: 1.386, 6432/6976 datapoints
2025-03-06 22:24:22,123 - INFO - Epoch 782/800 done.
2025-03-06 22:24:22,123 - INFO - Final validation performance:
Loss: 3.318, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:24:22,124 - INFO - Beginning epoch 783/800
2025-03-06 22:24:22,129 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:24:22,315 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:24:22,507 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:24:22,700 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:22,887 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:23,078 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:24:23,276 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:24:23,466 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:24:23,656 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:24:23,853 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:24:24,045 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:24:24,233 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:24:24,422 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:24:24,615 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:24:24,803 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:24:24,999 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:24:25,194 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:25,380 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:24:25,478 - INFO - validation batch 1, loss: 0.310, 32/6976 datapoints
2025-03-06 22:24:25,525 - INFO - validation batch 51, loss: 10.078, 1632/6976 datapoints
2025-03-06 22:24:25,572 - INFO - validation batch 101, loss: 1.642, 3232/6976 datapoints
2025-03-06 22:24:25,619 - INFO - validation batch 151, loss: 3.222, 4832/6976 datapoints
2025-03-06 22:24:25,666 - INFO - validation batch 201, loss: 1.400, 6432/6976 datapoints
2025-03-06 22:24:25,683 - INFO - Epoch 783/800 done.
2025-03-06 22:24:25,683 - INFO - Final validation performance:
Loss: 3.331, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:24:25,683 - INFO - Beginning epoch 784/800
2025-03-06 22:24:25,688 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:24:25,888 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:24:26,077 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:24:26,288 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:26,475 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:26,672 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:24:26,893 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:24:27,090 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:24:27,282 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:24:27,477 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:24:27,663 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:24:27,852 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:24:28,043 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:24:28,231 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:24:28,417 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:24:28,611 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:24:28,805 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:28,998 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:24:29,093 - INFO - validation batch 1, loss: 0.274, 32/6976 datapoints
2025-03-06 22:24:29,141 - INFO - validation batch 51, loss: 10.091, 1632/6976 datapoints
2025-03-06 22:24:29,189 - INFO - validation batch 101, loss: 1.645, 3232/6976 datapoints
2025-03-06 22:24:29,236 - INFO - validation batch 151, loss: 3.252, 4832/6976 datapoints
2025-03-06 22:24:29,283 - INFO - validation batch 201, loss: 1.421, 6432/6976 datapoints
2025-03-06 22:24:29,300 - INFO - Epoch 784/800 done.
2025-03-06 22:24:29,300 - INFO - Final validation performance:
Loss: 3.336, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:24:29,301 - INFO - Beginning epoch 785/800
2025-03-06 22:24:29,305 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:24:29,491 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:24:29,682 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:24:29,874 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:30,060 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:30,250 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:24:30,440 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:24:30,624 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:24:30,825 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:24:31,029 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:24:31,218 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:24:31,410 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:24:31,607 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:24:31,800 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:24:31,998 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:24:32,198 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:24:32,389 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:32,581 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:24:32,678 - INFO - validation batch 1, loss: 0.257, 32/6976 datapoints
2025-03-06 22:24:32,730 - INFO - validation batch 51, loss: 10.124, 1632/6976 datapoints
2025-03-06 22:24:32,782 - INFO - validation batch 101, loss: 1.646, 3232/6976 datapoints
2025-03-06 22:24:32,831 - INFO - validation batch 151, loss: 3.269, 4832/6976 datapoints
2025-03-06 22:24:32,878 - INFO - validation batch 201, loss: 1.446, 6432/6976 datapoints
2025-03-06 22:24:32,896 - INFO - Epoch 785/800 done.
2025-03-06 22:24:32,896 - INFO - Final validation performance:
Loss: 3.348, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:24:32,897 - INFO - Beginning epoch 786/800
2025-03-06 22:24:32,902 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:24:33,092 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:24:33,278 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:24:33,468 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:33,656 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:33,846 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:24:34,045 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:24:34,232 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:24:34,427 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:24:34,626 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:24:34,819 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:24:35,014 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:24:35,214 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:24:35,409 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:24:35,617 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:24:35,830 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:24:36,043 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:36,233 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:24:36,346 - INFO - validation batch 1, loss: 0.247, 32/6976 datapoints
2025-03-06 22:24:36,406 - INFO - validation batch 51, loss: 10.186, 1632/6976 datapoints
2025-03-06 22:24:36,460 - INFO - validation batch 101, loss: 1.675, 3232/6976 datapoints
2025-03-06 22:24:36,512 - INFO - validation batch 151, loss: 3.310, 4832/6976 datapoints
2025-03-06 22:24:36,565 - INFO - validation batch 201, loss: 1.460, 6432/6976 datapoints
2025-03-06 22:24:36,585 - INFO - Epoch 786/800 done.
2025-03-06 22:24:36,586 - INFO - Final validation performance:
Loss: 3.376, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:24:36,586 - INFO - Beginning epoch 787/800
2025-03-06 22:24:36,592 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:24:36,782 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:24:36,972 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:24:37,164 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:37,350 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:37,539 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:24:37,732 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:24:37,930 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:24:38,121 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:24:38,313 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:24:38,503 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:24:38,692 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:24:38,886 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:24:39,080 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:24:39,268 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:24:39,464 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:24:39,656 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:39,844 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:24:39,944 - INFO - validation batch 1, loss: 0.273, 32/6976 datapoints
2025-03-06 22:24:39,991 - INFO - validation batch 51, loss: 10.261, 1632/6976 datapoints
2025-03-06 22:24:40,038 - INFO - validation batch 101, loss: 1.729, 3232/6976 datapoints
2025-03-06 22:24:40,087 - INFO - validation batch 151, loss: 3.393, 4832/6976 datapoints
2025-03-06 22:24:40,135 - INFO - validation batch 201, loss: 1.475, 6432/6976 datapoints
2025-03-06 22:24:40,152 - INFO - Epoch 787/800 done.
2025-03-06 22:24:40,152 - INFO - Final validation performance:
Loss: 3.426, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:24:40,153 - INFO - Beginning epoch 788/800
2025-03-06 22:24:40,158 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:24:40,347 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:24:40,534 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:24:40,726 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:40,918 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:41,114 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:24:41,306 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:24:41,491 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:24:41,684 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:24:41,879 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:24:42,072 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:24:42,259 - INFO - training batch 551, loss: 0.059, 17632/28000 datapoints
2025-03-06 22:24:42,449 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:24:42,641 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:24:42,833 - INFO - training batch 701, loss: 0.035, 22432/28000 datapoints
2025-03-06 22:24:43,031 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:24:43,224 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:43,413 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:24:43,509 - INFO - validation batch 1, loss: 0.484, 32/6976 datapoints
2025-03-06 22:24:43,556 - INFO - validation batch 51, loss: 10.495, 1632/6976 datapoints
2025-03-06 22:24:43,603 - INFO - validation batch 101, loss: 1.860, 3232/6976 datapoints
2025-03-06 22:24:43,651 - INFO - validation batch 151, loss: 3.708, 4832/6976 datapoints
2025-03-06 22:24:43,699 - INFO - validation batch 201, loss: 1.586, 6432/6976 datapoints
2025-03-06 22:24:43,716 - INFO - Epoch 788/800 done.
2025-03-06 22:24:43,716 - INFO - Final validation performance:
Loss: 3.627, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:24:43,716 - INFO - Beginning epoch 789/800
2025-03-06 22:24:43,721 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:24:43,912 - INFO - training batch 51, loss: 0.082, 1632/28000 datapoints
2025-03-06 22:24:44,100 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:24:44,292 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:44,479 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:44,671 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:24:44,861 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:24:45,051 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:24:45,246 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:24:45,441 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:24:45,627 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:24:45,819 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:24:46,033 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:24:46,239 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:24:46,449 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:24:46,646 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:24:46,838 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:47,031 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-06 22:24:47,131 - INFO - validation batch 1, loss: 0.217, 32/6976 datapoints
2025-03-06 22:24:47,179 - INFO - validation batch 51, loss: 10.548, 1632/6976 datapoints
2025-03-06 22:24:47,226 - INFO - validation batch 101, loss: 1.953, 3232/6976 datapoints
2025-03-06 22:24:47,273 - INFO - validation batch 151, loss: 3.475, 4832/6976 datapoints
2025-03-06 22:24:47,321 - INFO - validation batch 201, loss: 1.265, 6432/6976 datapoints
2025-03-06 22:24:47,337 - INFO - Epoch 789/800 done.
2025-03-06 22:24:47,337 - INFO - Final validation performance:
Loss: 3.491, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:24:47,337 - INFO - Beginning epoch 790/800
2025-03-06 22:24:47,342 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:24:47,529 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:24:47,715 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:24:47,913 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:48,101 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:48,290 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:24:48,481 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:24:48,663 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:24:48,854 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:24:49,050 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:24:49,240 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:24:49,429 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:24:49,616 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:24:49,807 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:24:49,997 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:24:50,189 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:24:50,385 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:50,573 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:24:50,670 - INFO - validation batch 1, loss: 0.474, 32/6976 datapoints
2025-03-06 22:24:50,719 - INFO - validation batch 51, loss: 10.437, 1632/6976 datapoints
2025-03-06 22:24:50,766 - INFO - validation batch 101, loss: 1.752, 3232/6976 datapoints
2025-03-06 22:24:50,813 - INFO - validation batch 151, loss: 3.426, 4832/6976 datapoints
2025-03-06 22:24:50,860 - INFO - validation batch 201, loss: 1.503, 6432/6976 datapoints
2025-03-06 22:24:50,876 - INFO - Epoch 790/800 done.
2025-03-06 22:24:50,876 - INFO - Final validation performance:
Loss: 3.518, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:24:50,876 - INFO - Beginning epoch 791/800
2025-03-06 22:24:50,881 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:24:51,071 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:24:51,260 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:24:51,456 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:51,644 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:51,837 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:24:52,030 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:24:52,223 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:24:52,413 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:24:52,604 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:24:52,797 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:24:52,988 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:24:53,180 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:24:53,374 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:24:53,559 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:24:53,755 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:24:53,952 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:54,174 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:24:54,273 - INFO - validation batch 1, loss: 0.574, 32/6976 datapoints
2025-03-06 22:24:54,328 - INFO - validation batch 51, loss: 10.365, 1632/6976 datapoints
2025-03-06 22:24:54,381 - INFO - validation batch 101, loss: 1.749, 3232/6976 datapoints
2025-03-06 22:24:54,428 - INFO - validation batch 151, loss: 3.345, 4832/6976 datapoints
2025-03-06 22:24:54,478 - INFO - validation batch 201, loss: 1.511, 6432/6976 datapoints
2025-03-06 22:24:54,495 - INFO - Epoch 791/800 done.
2025-03-06 22:24:54,495 - INFO - Final validation performance:
Loss: 3.509, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:24:54,496 - INFO - Beginning epoch 792/800
2025-03-06 22:24:54,500 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:24:54,689 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:24:54,879 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:24:55,079 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:55,272 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:55,467 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:24:55,658 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:24:55,847 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:24:56,042 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:24:56,244 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:24:56,437 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:24:56,652 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:24:56,842 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:24:57,036 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:24:57,231 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:24:57,423 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:24:57,616 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:24:57,806 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:24:57,907 - INFO - validation batch 1, loss: 0.389, 32/6976 datapoints
2025-03-06 22:24:57,955 - INFO - validation batch 51, loss: 10.346, 1632/6976 datapoints
2025-03-06 22:24:58,002 - INFO - validation batch 101, loss: 1.839, 3232/6976 datapoints
2025-03-06 22:24:58,049 - INFO - validation batch 151, loss: 3.281, 4832/6976 datapoints
2025-03-06 22:24:58,096 - INFO - validation batch 201, loss: 1.459, 6432/6976 datapoints
2025-03-06 22:24:58,112 - INFO - Epoch 792/800 done.
2025-03-06 22:24:58,112 - INFO - Final validation performance:
Loss: 3.463, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:24:58,113 - INFO - Beginning epoch 793/800
2025-03-06 22:24:58,117 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:24:58,312 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:24:58,502 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:24:58,697 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:24:58,904 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:24:59,099 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:24:59,292 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:24:59,478 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:24:59,668 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:24:59,860 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:25:00,054 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:25:00,250 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:25:00,441 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:25:00,632 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:25:00,818 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:25:01,012 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:25:01,205 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:25:01,394 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:25:01,491 - INFO - validation batch 1, loss: 0.396, 32/6976 datapoints
2025-03-06 22:25:01,539 - INFO - validation batch 51, loss: 10.273, 1632/6976 datapoints
2025-03-06 22:25:01,586 - INFO - validation batch 101, loss: 1.828, 3232/6976 datapoints
2025-03-06 22:25:01,633 - INFO - validation batch 151, loss: 3.303, 4832/6976 datapoints
2025-03-06 22:25:01,681 - INFO - validation batch 201, loss: 1.463, 6432/6976 datapoints
2025-03-06 22:25:01,697 - INFO - Epoch 793/800 done.
2025-03-06 22:25:01,698 - INFO - Final validation performance:
Loss: 3.453, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:25:01,698 - INFO - Beginning epoch 794/800
2025-03-06 22:25:01,703 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:25:01,894 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:25:02,082 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:25:02,275 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:25:02,463 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:25:02,653 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:25:02,846 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:25:03,149 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:25:03,338 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:25:03,530 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:25:03,720 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:25:03,915 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:25:04,105 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:25:04,297 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:25:04,485 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:25:04,678 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:25:04,870 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:25:05,063 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:25:05,168 - INFO - validation batch 1, loss: 0.388, 32/6976 datapoints
2025-03-06 22:25:05,216 - INFO - validation batch 51, loss: 10.307, 1632/6976 datapoints
2025-03-06 22:25:05,265 - INFO - validation batch 101, loss: 1.807, 3232/6976 datapoints
2025-03-06 22:25:05,313 - INFO - validation batch 151, loss: 3.307, 4832/6976 datapoints
2025-03-06 22:25:05,361 - INFO - validation batch 201, loss: 1.461, 6432/6976 datapoints
2025-03-06 22:25:05,379 - INFO - Epoch 794/800 done.
2025-03-06 22:25:05,379 - INFO - Final validation performance:
Loss: 3.454, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:25:05,380 - INFO - Beginning epoch 795/800
2025-03-06 22:25:05,385 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:25:05,576 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:25:05,762 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:25:05,958 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:25:06,148 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:25:06,339 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:25:06,531 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:25:06,736 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:25:06,930 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:25:07,125 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:25:07,315 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:25:07,509 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:25:07,695 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:25:07,891 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:25:08,110 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:25:08,369 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:25:08,566 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:25:08,754 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:25:08,853 - INFO - validation batch 1, loss: 0.377, 32/6976 datapoints
2025-03-06 22:25:08,911 - INFO - validation batch 51, loss: 10.316, 1632/6976 datapoints
2025-03-06 22:25:08,960 - INFO - validation batch 101, loss: 1.793, 3232/6976 datapoints
2025-03-06 22:25:09,009 - INFO - validation batch 151, loss: 3.324, 4832/6976 datapoints
2025-03-06 22:25:09,058 - INFO - validation batch 201, loss: 1.464, 6432/6976 datapoints
2025-03-06 22:25:09,076 - INFO - Epoch 795/800 done.
2025-03-06 22:25:09,076 - INFO - Final validation performance:
Loss: 3.455, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:25:09,077 - INFO - Beginning epoch 796/800
2025-03-06 22:25:09,082 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:25:09,273 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:25:09,469 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:25:09,663 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:25:09,852 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:25:10,047 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:25:10,240 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:25:10,425 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:25:10,617 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:25:10,811 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:25:11,004 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:25:11,205 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:25:11,402 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:25:11,598 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:25:11,786 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:25:11,981 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:25:12,177 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:25:12,369 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:25:12,472 - INFO - validation batch 1, loss: 0.350, 32/6976 datapoints
2025-03-06 22:25:12,520 - INFO - validation batch 51, loss: 10.314, 1632/6976 datapoints
2025-03-06 22:25:12,567 - INFO - validation batch 101, loss: 1.781, 3232/6976 datapoints
2025-03-06 22:25:12,614 - INFO - validation batch 151, loss: 3.349, 4832/6976 datapoints
2025-03-06 22:25:12,663 - INFO - validation batch 201, loss: 1.475, 6432/6976 datapoints
2025-03-06 22:25:12,680 - INFO - Epoch 796/800 done.
2025-03-06 22:25:12,680 - INFO - Final validation performance:
Loss: 3.454, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:25:12,681 - INFO - Beginning epoch 797/800
2025-03-06 22:25:12,686 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:25:12,875 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:25:13,075 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:25:13,271 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:25:13,458 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:25:13,650 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:25:13,845 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:25:14,033 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:25:14,223 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:25:14,417 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:25:14,613 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:25:14,806 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:25:15,003 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:25:15,208 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:25:15,402 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:25:15,600 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:25:15,794 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:25:15,989 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:25:16,092 - INFO - validation batch 1, loss: 0.307, 32/6976 datapoints
2025-03-06 22:25:16,144 - INFO - validation batch 51, loss: 10.312, 1632/6976 datapoints
2025-03-06 22:25:16,195 - INFO - validation batch 101, loss: 1.771, 3232/6976 datapoints
2025-03-06 22:25:16,247 - INFO - validation batch 151, loss: 3.374, 4832/6976 datapoints
2025-03-06 22:25:16,299 - INFO - validation batch 201, loss: 1.491, 6432/6976 datapoints
2025-03-06 22:25:16,315 - INFO - Epoch 797/800 done.
2025-03-06 22:25:16,316 - INFO - Final validation performance:
Loss: 3.451, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:25:16,316 - INFO - Beginning epoch 798/800
2025-03-06 22:25:16,321 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:25:16,510 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:25:16,725 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:25:16,926 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:25:17,121 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:25:17,319 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:25:17,513 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:25:17,702 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:25:17,901 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:25:18,098 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:25:18,288 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:25:18,480 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:25:18,674 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:25:18,867 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:25:19,065 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:25:19,265 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:25:19,463 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:25:19,656 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:25:19,756 - INFO - validation batch 1, loss: 0.262, 32/6976 datapoints
2025-03-06 22:25:19,808 - INFO - validation batch 51, loss: 10.325, 1632/6976 datapoints
2025-03-06 22:25:19,860 - INFO - validation batch 101, loss: 1.767, 3232/6976 datapoints
2025-03-06 22:25:19,916 - INFO - validation batch 151, loss: 3.410, 4832/6976 datapoints
2025-03-06 22:25:19,970 - INFO - validation batch 201, loss: 1.509, 6432/6976 datapoints
2025-03-06 22:25:19,990 - INFO - Epoch 798/800 done.
2025-03-06 22:25:19,990 - INFO - Final validation performance:
Loss: 3.455, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:25:19,991 - INFO - Beginning epoch 799/800
2025-03-06 22:25:19,996 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:25:20,195 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:25:20,386 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:25:20,583 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:25:20,778 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:25:20,975 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:25:21,177 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:25:21,366 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:25:21,561 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:25:21,758 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:25:21,953 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:25:22,146 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:25:22,346 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:25:22,541 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:25:22,733 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:25:22,931 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:25:23,131 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:25:23,326 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:25:23,425 - INFO - validation batch 1, loss: 0.246, 32/6976 datapoints
2025-03-06 22:25:23,476 - INFO - validation batch 51, loss: 10.362, 1632/6976 datapoints
2025-03-06 22:25:23,526 - INFO - validation batch 101, loss: 1.772, 3232/6976 datapoints
2025-03-06 22:25:23,578 - INFO - validation batch 151, loss: 3.478, 4832/6976 datapoints
2025-03-06 22:25:23,631 - INFO - validation batch 201, loss: 1.517, 6432/6976 datapoints
2025-03-06 22:25:23,649 - INFO - Epoch 799/800 done.
2025-03-06 22:25:23,650 - INFO - Final validation performance:
Loss: 3.475, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:25:23,650 - INFO - Beginning epoch 800/800
2025-03-06 22:25:23,656 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 22:25:23,849 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 22:25:24,044 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 22:25:24,238 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:25:24,434 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:25:24,631 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 22:25:24,826 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 22:25:25,020 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:25:25,224 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 22:25:25,420 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 22:25:25,611 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 22:25:25,805 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 22:25:26,003 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:25:26,208 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:25:26,404 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:25:26,601 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:25:26,824 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 22:25:27,021 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 22:25:27,123 - INFO - validation batch 1, loss: 0.333, 32/6976 datapoints
2025-03-06 22:25:27,185 - INFO - validation batch 51, loss: 10.371, 1632/6976 datapoints
2025-03-06 22:25:27,257 - INFO - validation batch 101, loss: 1.787, 3232/6976 datapoints
2025-03-06 22:25:27,323 - INFO - validation batch 151, loss: 3.566, 4832/6976 datapoints
2025-03-06 22:25:27,382 - INFO - validation batch 201, loss: 1.533, 6432/6976 datapoints
2025-03-06 22:25:27,400 - INFO - Epoch 800/800 done.
2025-03-06 22:25:27,400 - INFO - Final validation performance:
Loss: 3.518, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:25:27,400 - INFO - Finished training in 2489.08 seconds.
2025-03-06 22:25:27,401 - INFO - Model trained in {train_time:.2f} s
2025-03-06 22:25:27,401 - INFO - Evaluating model...
2025-03-06 22:25:27,402 - INFO - validation batch 1, loss: 0.333, 32/6976 datapoints
2025-03-06 22:25:27,456 - INFO - validation batch 51, loss: 10.371, 1632/6976 datapoints
2025-03-06 22:25:27,507 - INFO - validation batch 101, loss: 1.787, 3232/6976 datapoints
2025-03-06 22:25:27,558 - INFO - validation batch 151, loss: 3.566, 4832/6976 datapoints
2025-03-06 22:25:27,610 - INFO - validation batch 201, loss: 1.533, 6432/6976 datapoints
2025-03-06 22:25:27,627 - INFO - Done evaluating.
2025-03-06 22:25:27,628 - INFO - Average final validation loss: 3.518
2025-03-06 22:25:27,628 - INFO - Saving...
2025-03-06 22:25:33,324 - INFO - Done saving.
2025-03-06 22:25:33,328 - INFO - Successfully completed hyperparameter combination 3 of 4