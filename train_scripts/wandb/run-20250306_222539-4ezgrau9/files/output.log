2025-03-06 22:25:44,442 - INFO - Running hyperparameter combination 4 of 4
2025-03-06 22:25:44,443 - INFO - 3_CTCNet_TC_multi_pre_activation_reciprocal
2025-03-06 22:25:44,445 - INFO - Loading data...
2025-03-06 22:25:45,692 - INFO - Done loading.
2025-03-06 22:25:45,692 - INFO - Building model and optimiser...
2025-03-06 22:25:45,698 - INFO - =================================================================
Layer (type:depth-idx)                   Param #
=================================================================
├─Sequential: 1-1                        --
|    └─Linear: 2-1                       8,224
|    └─ReLU: 2-2                         --
├─Linear: 1-2                            4,224
├─Linear: 1-3                            4,224
├─CortexWithThalamicMultiPreAct: 1-4     --
|    └─Linear: 2-3                       200,832
|    └─ReLU: 2-4                         --
├─CortexWithThalamicMultiPreAct: 1-5     --
|    └─Linear: 2-5                       16,512
|    └─ReLU: 2-6                         --
├─Sequential: 1-6                        --
|    └─Linear: 2-7                       1,290
=================================================================
Total params: 235,306
Trainable params: 235,306
Non-trainable params: 0
=================================================================
2025-03-06 22:25:45,700 - INFO - Done.
2025-03-06 22:25:45,700 - INFO - Training...
2025-03-06 22:25:45,700 - INFO - Beginning epoch 1/800
2025-03-06 22:25:45,720 - INFO - training batch 1, loss: 2.292, 32/28000 datapoints
2025-03-06 22:25:45,923 - INFO - training batch 51, loss: 2.292, 1632/28000 datapoints
2025-03-06 22:25:46,077 - INFO - training batch 101, loss: 2.295, 3232/28000 datapoints
2025-03-06 22:25:46,238 - INFO - training batch 151, loss: 2.306, 4832/28000 datapoints
2025-03-06 22:25:46,396 - INFO - training batch 201, loss: 2.300, 6432/28000 datapoints
2025-03-06 22:25:46,551 - INFO - training batch 251, loss: 2.295, 8032/28000 datapoints
2025-03-06 22:25:46,701 - INFO - training batch 301, loss: 2.306, 9632/28000 datapoints
2025-03-06 22:25:46,853 - INFO - training batch 351, loss: 2.307, 11232/28000 datapoints
2025-03-06 22:25:47,028 - INFO - training batch 401, loss: 2.302, 12832/28000 datapoints
2025-03-06 22:25:47,189 - INFO - training batch 451, loss: 2.305, 14432/28000 datapoints
2025-03-06 22:25:47,341 - INFO - training batch 501, loss: 2.303, 16032/28000 datapoints
2025-03-06 22:25:47,491 - INFO - training batch 551, loss: 2.308, 17632/28000 datapoints
2025-03-06 22:25:47,641 - INFO - training batch 601, loss: 2.295, 19232/28000 datapoints
2025-03-06 22:25:47,789 - INFO - training batch 651, loss: 2.300, 20832/28000 datapoints
2025-03-06 22:25:47,944 - INFO - training batch 701, loss: 2.299, 22432/28000 datapoints
2025-03-06 22:25:48,104 - INFO - training batch 751, loss: 2.306, 24032/28000 datapoints
2025-03-06 22:25:48,260 - INFO - training batch 801, loss: 2.293, 25632/28000 datapoints
2025-03-06 22:25:48,414 - INFO - training batch 851, loss: 2.305, 27232/28000 datapoints
2025-03-06 22:25:48,498 - INFO - validation batch 1, loss: 2.300, 32/6976 datapoints
2025-03-06 22:25:48,550 - INFO - validation batch 51, loss: 2.300, 1632/6976 datapoints
2025-03-06 22:25:48,606 - INFO - validation batch 101, loss: 2.306, 3232/6976 datapoints
2025-03-06 22:25:48,658 - INFO - validation batch 151, loss: 2.310, 4832/6976 datapoints
2025-03-06 22:25:48,716 - INFO - validation batch 201, loss: 2.303, 6432/6976 datapoints
2025-03-06 22:25:48,736 - INFO - Epoch 1/800 done.
2025-03-06 22:25:48,736 - INFO - Final validation performance:
Loss: 2.304, top-1 acc: 0.101top-5 acc: 0.101
2025-03-06 22:25:48,737 - INFO - Beginning epoch 2/800
2025-03-06 22:25:48,742 - INFO - training batch 1, loss: 2.292, 32/28000 datapoints
2025-03-06 22:25:48,906 - INFO - training batch 51, loss: 2.292, 1632/28000 datapoints
2025-03-06 22:25:49,064 - INFO - training batch 101, loss: 2.294, 3232/28000 datapoints
2025-03-06 22:25:49,217 - INFO - training batch 151, loss: 2.306, 4832/28000 datapoints
2025-03-06 22:25:49,374 - INFO - training batch 201, loss: 2.299, 6432/28000 datapoints
2025-03-06 22:25:49,530 - INFO - training batch 251, loss: 2.295, 8032/28000 datapoints
2025-03-06 22:25:49,689 - INFO - training batch 301, loss: 2.305, 9632/28000 datapoints
2025-03-06 22:25:49,842 - INFO - training batch 351, loss: 2.306, 11232/28000 datapoints
2025-03-06 22:25:50,000 - INFO - training batch 401, loss: 2.300, 12832/28000 datapoints
2025-03-06 22:25:50,152 - INFO - training batch 451, loss: 2.304, 14432/28000 datapoints
2025-03-06 22:25:50,307 - INFO - training batch 501, loss: 2.302, 16032/28000 datapoints
2025-03-06 22:25:50,462 - INFO - training batch 551, loss: 2.306, 17632/28000 datapoints
2025-03-06 22:25:50,617 - INFO - training batch 601, loss: 2.294, 19232/28000 datapoints
2025-03-06 22:25:50,772 - INFO - training batch 651, loss: 2.299, 20832/28000 datapoints
2025-03-06 22:25:50,931 - INFO - training batch 701, loss: 2.298, 22432/28000 datapoints
2025-03-06 22:25:51,085 - INFO - training batch 751, loss: 2.305, 24032/28000 datapoints
2025-03-06 22:25:51,240 - INFO - training batch 801, loss: 2.292, 25632/28000 datapoints
2025-03-06 22:25:51,394 - INFO - training batch 851, loss: 2.304, 27232/28000 datapoints
2025-03-06 22:25:51,472 - INFO - validation batch 1, loss: 2.298, 32/6976 datapoints
2025-03-06 22:25:51,528 - INFO - validation batch 51, loss: 2.299, 1632/6976 datapoints
2025-03-06 22:25:51,584 - INFO - validation batch 101, loss: 2.305, 3232/6976 datapoints
2025-03-06 22:25:51,637 - INFO - validation batch 151, loss: 2.309, 4832/6976 datapoints
2025-03-06 22:25:51,692 - INFO - validation batch 201, loss: 2.301, 6432/6976 datapoints
2025-03-06 22:25:51,709 - INFO - Epoch 2/800 done.
2025-03-06 22:25:51,710 - INFO - Final validation performance:
Loss: 2.302, top-1 acc: 0.101top-5 acc: 0.101
2025-03-06 22:25:51,710 - INFO - Beginning epoch 3/800
2025-03-06 22:25:51,714 - INFO - training batch 1, loss: 2.292, 32/28000 datapoints
2025-03-06 22:25:51,871 - INFO - training batch 51, loss: 2.291, 1632/28000 datapoints
2025-03-06 22:25:52,029 - INFO - training batch 101, loss: 2.292, 3232/28000 datapoints
2025-03-06 22:25:52,183 - INFO - training batch 151, loss: 2.305, 4832/28000 datapoints
2025-03-06 22:25:52,340 - INFO - training batch 201, loss: 2.297, 6432/28000 datapoints
2025-03-06 22:25:52,497 - INFO - training batch 251, loss: 2.294, 8032/28000 datapoints
2025-03-06 22:25:52,654 - INFO - training batch 301, loss: 2.303, 9632/28000 datapoints
2025-03-06 22:25:52,806 - INFO - training batch 351, loss: 2.303, 11232/28000 datapoints
2025-03-06 22:25:52,964 - INFO - training batch 401, loss: 2.298, 12832/28000 datapoints
2025-03-06 22:25:53,118 - INFO - training batch 451, loss: 2.301, 14432/28000 datapoints
2025-03-06 22:25:53,277 - INFO - training batch 501, loss: 2.298, 16032/28000 datapoints
2025-03-06 22:25:53,434 - INFO - training batch 551, loss: 2.303, 17632/28000 datapoints
2025-03-06 22:25:53,589 - INFO - training batch 601, loss: 2.292, 19232/28000 datapoints
2025-03-06 22:25:53,743 - INFO - training batch 651, loss: 2.295, 20832/28000 datapoints
2025-03-06 22:25:53,898 - INFO - training batch 701, loss: 2.292, 22432/28000 datapoints
2025-03-06 22:25:54,053 - INFO - training batch 751, loss: 2.300, 24032/28000 datapoints
2025-03-06 22:25:54,209 - INFO - training batch 801, loss: 2.289, 25632/28000 datapoints
2025-03-06 22:25:54,363 - INFO - training batch 851, loss: 2.297, 27232/28000 datapoints
2025-03-06 22:25:54,439 - INFO - validation batch 1, loss: 2.293, 32/6976 datapoints
2025-03-06 22:25:54,496 - INFO - validation batch 51, loss: 2.295, 1632/6976 datapoints
2025-03-06 22:25:54,552 - INFO - validation batch 101, loss: 2.299, 3232/6976 datapoints
2025-03-06 22:25:54,605 - INFO - validation batch 151, loss: 2.305, 4832/6976 datapoints
2025-03-06 22:25:54,659 - INFO - validation batch 201, loss: 2.293, 6432/6976 datapoints
2025-03-06 22:25:54,679 - INFO - Epoch 3/800 done.
2025-03-06 22:25:54,680 - INFO - Final validation performance:
Loss: 2.297, top-1 acc: 0.101top-5 acc: 0.101
2025-03-06 22:25:54,680 - INFO - Beginning epoch 4/800
2025-03-06 22:25:54,685 - INFO - training batch 1, loss: 2.290, 32/28000 datapoints
2025-03-06 22:25:54,840 - INFO - training batch 51, loss: 2.288, 1632/28000 datapoints
2025-03-06 22:25:54,990 - INFO - training batch 101, loss: 2.286, 3232/28000 datapoints
2025-03-06 22:25:55,150 - INFO - training batch 151, loss: 2.299, 4832/28000 datapoints
2025-03-06 22:25:55,304 - INFO - training batch 201, loss: 2.285, 6432/28000 datapoints
2025-03-06 22:25:55,465 - INFO - training batch 251, loss: 2.293, 8032/28000 datapoints
2025-03-06 22:25:55,614 - INFO - training batch 301, loss: 2.289, 9632/28000 datapoints
2025-03-06 22:25:55,765 - INFO - training batch 351, loss: 2.287, 11232/28000 datapoints
2025-03-06 22:25:55,921 - INFO - training batch 401, loss: 2.280, 12832/28000 datapoints
2025-03-06 22:25:56,074 - INFO - training batch 451, loss: 2.281, 14432/28000 datapoints
2025-03-06 22:25:56,236 - INFO - training batch 501, loss: 2.264, 16032/28000 datapoints
2025-03-06 22:25:56,394 - INFO - training batch 551, loss: 2.269, 17632/28000 datapoints
2025-03-06 22:25:56,555 - INFO - training batch 601, loss: 2.270, 19232/28000 datapoints
2025-03-06 22:25:56,710 - INFO - training batch 651, loss: 2.251, 20832/28000 datapoints
2025-03-06 22:25:56,879 - INFO - training batch 701, loss: 2.237, 22432/28000 datapoints
2025-03-06 22:25:57,041 - INFO - training batch 751, loss: 2.240, 24032/28000 datapoints
2025-03-06 22:25:57,218 - INFO - training batch 801, loss: 2.254, 25632/28000 datapoints
2025-03-06 22:25:57,372 - INFO - training batch 851, loss: 2.214, 27232/28000 datapoints
2025-03-06 22:25:57,450 - INFO - validation batch 1, loss: 2.225, 32/6976 datapoints
2025-03-06 22:25:57,501 - INFO - validation batch 51, loss: 2.262, 1632/6976 datapoints
2025-03-06 22:25:57,550 - INFO - validation batch 101, loss: 2.232, 3232/6976 datapoints
2025-03-06 22:25:57,601 - INFO - validation batch 151, loss: 2.281, 4832/6976 datapoints
2025-03-06 22:25:57,652 - INFO - validation batch 201, loss: 2.194, 6432/6976 datapoints
2025-03-06 22:25:57,669 - INFO - Epoch 4/800 done.
2025-03-06 22:25:57,670 - INFO - Final validation performance:
Loss: 2.239, top-1 acc: 0.253top-5 acc: 0.253
2025-03-06 22:25:57,670 - INFO - Beginning epoch 5/800
2025-03-06 22:25:57,674 - INFO - training batch 1, loss: 2.281, 32/28000 datapoints
2025-03-06 22:25:57,832 - INFO - training batch 51, loss: 2.267, 1632/28000 datapoints
2025-03-06 22:25:57,982 - INFO - training batch 101, loss: 2.231, 3232/28000 datapoints
2025-03-06 22:25:58,138 - INFO - training batch 151, loss: 2.255, 4832/28000 datapoints
2025-03-06 22:25:58,302 - INFO - training batch 201, loss: 2.137, 6432/28000 datapoints
2025-03-06 22:25:58,454 - INFO - training batch 251, loss: 2.289, 8032/28000 datapoints
2025-03-06 22:25:58,613 - INFO - training batch 301, loss: 2.154, 9632/28000 datapoints
2025-03-06 22:25:58,769 - INFO - training batch 351, loss: 2.176, 11232/28000 datapoints
2025-03-06 22:25:58,925 - INFO - training batch 401, loss: 2.136, 12832/28000 datapoints
2025-03-06 22:25:59,083 - INFO - training batch 451, loss: 2.114, 14432/28000 datapoints
2025-03-06 22:25:59,253 - INFO - training batch 501, loss: 2.030, 16032/28000 datapoints
2025-03-06 22:25:59,411 - INFO - training batch 551, loss: 2.068, 17632/28000 datapoints
2025-03-06 22:25:59,565 - INFO - training batch 601, loss: 2.066, 19232/28000 datapoints
2025-03-06 22:25:59,726 - INFO - training batch 651, loss: 2.017, 20832/28000 datapoints
2025-03-06 22:25:59,876 - INFO - training batch 701, loss: 1.943, 22432/28000 datapoints
2025-03-06 22:26:00,034 - INFO - training batch 751, loss: 2.011, 24032/28000 datapoints
2025-03-06 22:26:00,188 - INFO - training batch 801, loss: 2.017, 25632/28000 datapoints
2025-03-06 22:26:00,342 - INFO - training batch 851, loss: 1.925, 27232/28000 datapoints
2025-03-06 22:26:00,418 - INFO - validation batch 1, loss: 1.904, 32/6976 datapoints
2025-03-06 22:26:00,468 - INFO - validation batch 51, loss: 2.180, 1632/6976 datapoints
2025-03-06 22:26:00,521 - INFO - validation batch 101, loss: 1.986, 3232/6976 datapoints
2025-03-06 22:26:00,573 - INFO - validation batch 151, loss: 2.154, 4832/6976 datapoints
2025-03-06 22:26:00,623 - INFO - validation batch 201, loss: 1.847, 6432/6976 datapoints
2025-03-06 22:26:00,643 - INFO - Epoch 5/800 done.
2025-03-06 22:26:00,643 - INFO - Final validation performance:
Loss: 2.014, top-1 acc: 0.366top-5 acc: 0.366
2025-03-06 22:26:00,643 - INFO - Beginning epoch 6/800
2025-03-06 22:26:00,648 - INFO - training batch 1, loss: 2.144, 32/28000 datapoints
2025-03-06 22:26:00,804 - INFO - training batch 51, loss: 2.028, 1632/28000 datapoints
2025-03-06 22:26:00,960 - INFO - training batch 101, loss: 1.940, 3232/28000 datapoints
2025-03-06 22:26:01,116 - INFO - training batch 151, loss: 2.085, 4832/28000 datapoints
2025-03-06 22:26:01,274 - INFO - training batch 201, loss: 1.924, 6432/28000 datapoints
2025-03-06 22:26:01,426 - INFO - training batch 251, loss: 2.074, 8032/28000 datapoints
2025-03-06 22:26:01,578 - INFO - training batch 301, loss: 1.952, 9632/28000 datapoints
2025-03-06 22:26:01,735 - INFO - training batch 351, loss: 1.998, 11232/28000 datapoints
2025-03-06 22:26:01,890 - INFO - training batch 401, loss: 1.882, 12832/28000 datapoints
2025-03-06 22:26:02,048 - INFO - training batch 451, loss: 1.836, 14432/28000 datapoints
2025-03-06 22:26:02,205 - INFO - training batch 501, loss: 1.632, 16032/28000 datapoints
2025-03-06 22:26:02,360 - INFO - training batch 551, loss: 1.765, 17632/28000 datapoints
2025-03-06 22:26:02,517 - INFO - training batch 601, loss: 1.729, 19232/28000 datapoints
2025-03-06 22:26:02,672 - INFO - training batch 651, loss: 1.704, 20832/28000 datapoints
2025-03-06 22:26:02,826 - INFO - training batch 701, loss: 1.615, 22432/28000 datapoints
2025-03-06 22:26:02,980 - INFO - training batch 751, loss: 1.805, 24032/28000 datapoints
2025-03-06 22:26:03,133 - INFO - training batch 801, loss: 1.675, 25632/28000 datapoints
2025-03-06 22:26:03,289 - INFO - training batch 851, loss: 1.711, 27232/28000 datapoints
2025-03-06 22:26:03,366 - INFO - validation batch 1, loss: 1.551, 32/6976 datapoints
2025-03-06 22:26:03,416 - INFO - validation batch 51, loss: 2.169, 1632/6976 datapoints
2025-03-06 22:26:03,466 - INFO - validation batch 101, loss: 1.738, 3232/6976 datapoints
2025-03-06 22:26:03,514 - INFO - validation batch 151, loss: 2.027, 4832/6976 datapoints
2025-03-06 22:26:03,564 - INFO - validation batch 201, loss: 1.461, 6432/6976 datapoints
2025-03-06 22:26:03,581 - INFO - Epoch 6/800 done.
2025-03-06 22:26:03,582 - INFO - Final validation performance:
Loss: 1.789, top-1 acc: 0.399top-5 acc: 0.399
2025-03-06 22:26:03,582 - INFO - Beginning epoch 7/800
2025-03-06 22:26:03,586 - INFO - training batch 1, loss: 2.046, 32/28000 datapoints
2025-03-06 22:26:03,745 - INFO - training batch 51, loss: 1.822, 1632/28000 datapoints
2025-03-06 22:26:03,901 - INFO - training batch 101, loss: 1.685, 3232/28000 datapoints
2025-03-06 22:26:04,056 - INFO - training batch 151, loss: 1.946, 4832/28000 datapoints
2025-03-06 22:26:04,210 - INFO - training batch 201, loss: 1.888, 6432/28000 datapoints
2025-03-06 22:26:04,364 - INFO - training batch 251, loss: 1.921, 8032/28000 datapoints
2025-03-06 22:26:04,524 - INFO - training batch 301, loss: 1.839, 9632/28000 datapoints
2025-03-06 22:26:04,676 - INFO - training batch 351, loss: 1.919, 11232/28000 datapoints
2025-03-06 22:26:04,830 - INFO - training batch 401, loss: 1.781, 12832/28000 datapoints
2025-03-06 22:26:04,989 - INFO - training batch 451, loss: 1.701, 14432/28000 datapoints
2025-03-06 22:26:05,147 - INFO - training batch 501, loss: 1.434, 16032/28000 datapoints
2025-03-06 22:26:05,303 - INFO - training batch 551, loss: 1.650, 17632/28000 datapoints
2025-03-06 22:26:05,460 - INFO - training batch 601, loss: 1.632, 19232/28000 datapoints
2025-03-06 22:26:05,612 - INFO - training batch 651, loss: 1.544, 20832/28000 datapoints
2025-03-06 22:26:05,807 - INFO - training batch 701, loss: 1.497, 22432/28000 datapoints
2025-03-06 22:26:05,965 - INFO - training batch 751, loss: 1.756, 24032/28000 datapoints
2025-03-06 22:26:06,118 - INFO - training batch 801, loss: 1.535, 25632/28000 datapoints
2025-03-06 22:26:06,275 - INFO - training batch 851, loss: 1.650, 27232/28000 datapoints
2025-03-06 22:26:06,353 - INFO - validation batch 1, loss: 1.401, 32/6976 datapoints
2025-03-06 22:26:06,404 - INFO - validation batch 51, loss: 2.168, 1632/6976 datapoints
2025-03-06 22:26:06,456 - INFO - validation batch 101, loss: 1.658, 3232/6976 datapoints
2025-03-06 22:26:06,508 - INFO - validation batch 151, loss: 1.991, 4832/6976 datapoints
2025-03-06 22:26:06,564 - INFO - validation batch 201, loss: 1.332, 6432/6976 datapoints
2025-03-06 22:26:06,580 - INFO - Epoch 7/800 done.
2025-03-06 22:26:06,580 - INFO - Final validation performance:
Loss: 1.710, top-1 acc: 0.413top-5 acc: 0.413
2025-03-06 22:26:06,581 - INFO - Beginning epoch 8/800
2025-03-06 22:26:06,586 - INFO - training batch 1, loss: 2.052, 32/28000 datapoints
2025-03-06 22:26:06,746 - INFO - training batch 51, loss: 1.779, 1632/28000 datapoints
2025-03-06 22:26:06,905 - INFO - training batch 101, loss: 1.588, 3232/28000 datapoints
2025-03-06 22:26:07,059 - INFO - training batch 151, loss: 1.907, 4832/28000 datapoints
2025-03-06 22:26:07,241 - INFO - training batch 201, loss: 1.875, 6432/28000 datapoints
2025-03-06 22:26:07,394 - INFO - training batch 251, loss: 1.856, 8032/28000 datapoints
2025-03-06 22:26:07,552 - INFO - training batch 301, loss: 1.797, 9632/28000 datapoints
2025-03-06 22:26:07,707 - INFO - training batch 351, loss: 1.867, 11232/28000 datapoints
2025-03-06 22:26:07,863 - INFO - training batch 401, loss: 1.739, 12832/28000 datapoints
2025-03-06 22:26:08,018 - INFO - training batch 451, loss: 1.644, 14432/28000 datapoints
2025-03-06 22:26:08,175 - INFO - training batch 501, loss: 1.354, 16032/28000 datapoints
2025-03-06 22:26:08,338 - INFO - training batch 551, loss: 1.615, 17632/28000 datapoints
2025-03-06 22:26:08,492 - INFO - training batch 601, loss: 1.607, 19232/28000 datapoints
2025-03-06 22:26:08,654 - INFO - training batch 651, loss: 1.458, 20832/28000 datapoints
2025-03-06 22:26:08,812 - INFO - training batch 701, loss: 1.448, 22432/28000 datapoints
2025-03-06 22:26:08,970 - INFO - training batch 751, loss: 1.737, 24032/28000 datapoints
2025-03-06 22:26:09,133 - INFO - training batch 801, loss: 1.475, 25632/28000 datapoints
2025-03-06 22:26:09,314 - INFO - training batch 851, loss: 1.614, 27232/28000 datapoints
2025-03-06 22:26:09,392 - INFO - validation batch 1, loss: 1.328, 32/6976 datapoints
2025-03-06 22:26:09,443 - INFO - validation batch 51, loss: 2.133, 1632/6976 datapoints
2025-03-06 22:26:09,492 - INFO - validation batch 101, loss: 1.617, 3232/6976 datapoints
2025-03-06 22:26:09,541 - INFO - validation batch 151, loss: 1.964, 4832/6976 datapoints
2025-03-06 22:26:09,590 - INFO - validation batch 201, loss: 1.270, 6432/6976 datapoints
2025-03-06 22:26:09,606 - INFO - Epoch 8/800 done.
2025-03-06 22:26:09,607 - INFO - Final validation performance:
Loss: 1.663, top-1 acc: 0.423top-5 acc: 0.423
2025-03-06 22:26:09,607 - INFO - Beginning epoch 9/800
2025-03-06 22:26:09,612 - INFO - training batch 1, loss: 2.049, 32/28000 datapoints
2025-03-06 22:26:09,777 - INFO - training batch 51, loss: 1.767, 1632/28000 datapoints
2025-03-06 22:26:09,935 - INFO - training batch 101, loss: 1.534, 3232/28000 datapoints
2025-03-06 22:26:10,091 - INFO - training batch 151, loss: 1.883, 4832/28000 datapoints
2025-03-06 22:26:10,245 - INFO - training batch 201, loss: 1.858, 6432/28000 datapoints
2025-03-06 22:26:10,401 - INFO - training batch 251, loss: 1.806, 8032/28000 datapoints
2025-03-06 22:26:10,562 - INFO - training batch 301, loss: 1.770, 9632/28000 datapoints
2025-03-06 22:26:10,718 - INFO - training batch 351, loss: 1.822, 11232/28000 datapoints
2025-03-06 22:26:10,874 - INFO - training batch 401, loss: 1.707, 12832/28000 datapoints
2025-03-06 22:26:11,032 - INFO - training batch 451, loss: 1.608, 14432/28000 datapoints
2025-03-06 22:26:11,187 - INFO - training batch 501, loss: 1.308, 16032/28000 datapoints
2025-03-06 22:26:11,346 - INFO - training batch 551, loss: 1.595, 17632/28000 datapoints
2025-03-06 22:26:11,501 - INFO - training batch 601, loss: 1.593, 19232/28000 datapoints
2025-03-06 22:26:11,657 - INFO - training batch 651, loss: 1.397, 20832/28000 datapoints
2025-03-06 22:26:11,814 - INFO - training batch 701, loss: 1.419, 22432/28000 datapoints
2025-03-06 22:26:11,971 - INFO - training batch 751, loss: 1.721, 24032/28000 datapoints
2025-03-06 22:26:12,123 - INFO - training batch 801, loss: 1.441, 25632/28000 datapoints
2025-03-06 22:26:12,280 - INFO - training batch 851, loss: 1.582, 27232/28000 datapoints
2025-03-06 22:26:12,363 - INFO - validation batch 1, loss: 1.283, 32/6976 datapoints
2025-03-06 22:26:12,417 - INFO - validation batch 51, loss: 2.092, 1632/6976 datapoints
2025-03-06 22:26:12,467 - INFO - validation batch 101, loss: 1.585, 3232/6976 datapoints
2025-03-06 22:26:12,517 - INFO - validation batch 151, loss: 1.937, 4832/6976 datapoints
2025-03-06 22:26:12,570 - INFO - validation batch 201, loss: 1.229, 6432/6976 datapoints
2025-03-06 22:26:12,588 - INFO - Epoch 9/800 done.
2025-03-06 22:26:12,588 - INFO - Final validation performance:
Loss: 1.625, top-1 acc: 0.432top-5 acc: 0.432
2025-03-06 22:26:12,589 - INFO - Beginning epoch 10/800
2025-03-06 22:26:12,593 - INFO - training batch 1, loss: 2.037, 32/28000 datapoints
2025-03-06 22:26:12,752 - INFO - training batch 51, loss: 1.759, 1632/28000 datapoints
2025-03-06 22:26:12,914 - INFO - training batch 101, loss: 1.495, 3232/28000 datapoints
2025-03-06 22:26:13,068 - INFO - training batch 151, loss: 1.862, 4832/28000 datapoints
2025-03-06 22:26:13,222 - INFO - training batch 201, loss: 1.841, 6432/28000 datapoints
2025-03-06 22:26:13,383 - INFO - training batch 251, loss: 1.760, 8032/28000 datapoints
2025-03-06 22:26:13,543 - INFO - training batch 301, loss: 1.751, 9632/28000 datapoints
2025-03-06 22:26:13,714 - INFO - training batch 351, loss: 1.783, 11232/28000 datapoints
2025-03-06 22:26:13,901 - INFO - training batch 401, loss: 1.681, 12832/28000 datapoints
2025-03-06 22:26:14,059 - INFO - training batch 451, loss: 1.580, 14432/28000 datapoints
2025-03-06 22:26:14,220 - INFO - training batch 501, loss: 1.277, 16032/28000 datapoints
2025-03-06 22:26:14,378 - INFO - training batch 551, loss: 1.581, 17632/28000 datapoints
2025-03-06 22:26:14,533 - INFO - training batch 601, loss: 1.582, 19232/28000 datapoints
2025-03-06 22:26:14,691 - INFO - training batch 651, loss: 1.349, 20832/28000 datapoints
2025-03-06 22:26:14,845 - INFO - training batch 701, loss: 1.398, 22432/28000 datapoints
2025-03-06 22:26:15,008 - INFO - training batch 751, loss: 1.707, 24032/28000 datapoints
2025-03-06 22:26:15,169 - INFO - training batch 801, loss: 1.416, 25632/28000 datapoints
2025-03-06 22:26:15,326 - INFO - training batch 851, loss: 1.555, 27232/28000 datapoints
2025-03-06 22:26:15,404 - INFO - validation batch 1, loss: 1.247, 32/6976 datapoints
2025-03-06 22:26:15,459 - INFO - validation batch 51, loss: 2.052, 1632/6976 datapoints
2025-03-06 22:26:15,508 - INFO - validation batch 101, loss: 1.560, 3232/6976 datapoints
2025-03-06 22:26:15,559 - INFO - validation batch 151, loss: 1.911, 4832/6976 datapoints
2025-03-06 22:26:15,609 - INFO - validation batch 201, loss: 1.196, 6432/6976 datapoints
2025-03-06 22:26:15,626 - INFO - Epoch 10/800 done.
2025-03-06 22:26:15,626 - INFO - Final validation performance:
Loss: 1.593, top-1 acc: 0.442top-5 acc: 0.442
2025-03-06 22:26:15,627 - INFO - Beginning epoch 11/800
2025-03-06 22:26:15,631 - INFO - training batch 1, loss: 2.020, 32/28000 datapoints
2025-03-06 22:26:15,788 - INFO - training batch 51, loss: 1.752, 1632/28000 datapoints
2025-03-06 22:26:15,943 - INFO - training batch 101, loss: 1.465, 3232/28000 datapoints
2025-03-06 22:26:16,097 - INFO - training batch 151, loss: 1.845, 4832/28000 datapoints
2025-03-06 22:26:16,253 - INFO - training batch 201, loss: 1.824, 6432/28000 datapoints
2025-03-06 22:26:16,410 - INFO - training batch 251, loss: 1.719, 8032/28000 datapoints
2025-03-06 22:26:16,571 - INFO - training batch 301, loss: 1.733, 9632/28000 datapoints
2025-03-06 22:26:16,726 - INFO - training batch 351, loss: 1.750, 11232/28000 datapoints
2025-03-06 22:26:16,882 - INFO - training batch 401, loss: 1.658, 12832/28000 datapoints
2025-03-06 22:26:17,045 - INFO - training batch 451, loss: 1.557, 14432/28000 datapoints
2025-03-06 22:26:17,207 - INFO - training batch 501, loss: 1.253, 16032/28000 datapoints
2025-03-06 22:26:17,389 - INFO - training batch 551, loss: 1.570, 17632/28000 datapoints
2025-03-06 22:26:17,543 - INFO - training batch 601, loss: 1.574, 19232/28000 datapoints
2025-03-06 22:26:17,701 - INFO - training batch 651, loss: 1.307, 20832/28000 datapoints
2025-03-06 22:26:17,861 - INFO - training batch 701, loss: 1.383, 22432/28000 datapoints
2025-03-06 22:26:18,021 - INFO - training batch 751, loss: 1.693, 24032/28000 datapoints
2025-03-06 22:26:18,177 - INFO - training batch 801, loss: 1.397, 25632/28000 datapoints
2025-03-06 22:26:18,334 - INFO - training batch 851, loss: 1.531, 27232/28000 datapoints
2025-03-06 22:26:18,413 - INFO - validation batch 1, loss: 1.218, 32/6976 datapoints
2025-03-06 22:26:18,469 - INFO - validation batch 51, loss: 2.017, 1632/6976 datapoints
2025-03-06 22:26:18,526 - INFO - validation batch 101, loss: 1.537, 3232/6976 datapoints
2025-03-06 22:26:18,586 - INFO - validation batch 151, loss: 1.888, 4832/6976 datapoints
2025-03-06 22:26:18,640 - INFO - validation batch 201, loss: 1.169, 6432/6976 datapoints
2025-03-06 22:26:18,658 - INFO - Epoch 11/800 done.
2025-03-06 22:26:18,658 - INFO - Final validation performance:
Loss: 1.566, top-1 acc: 0.450top-5 acc: 0.450
2025-03-06 22:26:18,659 - INFO - Beginning epoch 12/800
2025-03-06 22:26:18,663 - INFO - training batch 1, loss: 1.999, 32/28000 datapoints
2025-03-06 22:26:18,825 - INFO - training batch 51, loss: 1.745, 1632/28000 datapoints
2025-03-06 22:26:18,992 - INFO - training batch 101, loss: 1.440, 3232/28000 datapoints
2025-03-06 22:26:19,167 - INFO - training batch 151, loss: 1.829, 4832/28000 datapoints
2025-03-06 22:26:19,346 - INFO - training batch 201, loss: 1.809, 6432/28000 datapoints
2025-03-06 22:26:19,527 - INFO - training batch 251, loss: 1.680, 8032/28000 datapoints
2025-03-06 22:26:19,708 - INFO - training batch 301, loss: 1.717, 9632/28000 datapoints
2025-03-06 22:26:19,893 - INFO - training batch 351, loss: 1.721, 11232/28000 datapoints
2025-03-06 22:26:20,078 - INFO - training batch 401, loss: 1.638, 12832/28000 datapoints
2025-03-06 22:26:20,274 - INFO - training batch 451, loss: 1.538, 14432/28000 datapoints
2025-03-06 22:26:20,486 - INFO - training batch 501, loss: 1.235, 16032/28000 datapoints
2025-03-06 22:26:20,706 - INFO - training batch 551, loss: 1.561, 17632/28000 datapoints
2025-03-06 22:26:20,932 - INFO - training batch 601, loss: 1.566, 19232/28000 datapoints
2025-03-06 22:26:21,163 - INFO - training batch 651, loss: 1.270, 20832/28000 datapoints
2025-03-06 22:26:21,400 - INFO - training batch 701, loss: 1.370, 22432/28000 datapoints
2025-03-06 22:26:21,636 - INFO - training batch 751, loss: 1.679, 24032/28000 datapoints
2025-03-06 22:26:21,881 - INFO - training batch 801, loss: 1.380, 25632/28000 datapoints
2025-03-06 22:26:22,127 - INFO - training batch 851, loss: 1.510, 27232/28000 datapoints
2025-03-06 22:26:22,253 - INFO - validation batch 1, loss: 1.194, 32/6976 datapoints
2025-03-06 22:26:22,345 - INFO - validation batch 51, loss: 1.985, 1632/6976 datapoints
2025-03-06 22:26:22,431 - INFO - validation batch 101, loss: 1.517, 3232/6976 datapoints
2025-03-06 22:26:22,517 - INFO - validation batch 151, loss: 1.866, 4832/6976 datapoints
2025-03-06 22:26:22,607 - INFO - validation batch 201, loss: 1.145, 6432/6976 datapoints
2025-03-06 22:26:22,639 - INFO - Epoch 12/800 done.
2025-03-06 22:26:22,640 - INFO - Final validation performance:
Loss: 1.541, top-1 acc: 0.456top-5 acc: 0.456
2025-03-06 22:26:22,640 - INFO - Beginning epoch 13/800
2025-03-06 22:26:22,651 - INFO - training batch 1, loss: 1.978, 32/28000 datapoints
2025-03-06 22:26:22,911 - INFO - training batch 51, loss: 1.738, 1632/28000 datapoints
2025-03-06 22:26:23,187 - INFO - training batch 101, loss: 1.419, 3232/28000 datapoints
2025-03-06 22:26:23,464 - INFO - training batch 151, loss: 1.815, 4832/28000 datapoints
2025-03-06 22:26:23,789 - INFO - training batch 201, loss: 1.795, 6432/28000 datapoints
2025-03-06 22:26:24,089 - INFO - training batch 251, loss: 1.645, 8032/28000 datapoints
2025-03-06 22:26:24,393 - INFO - training batch 301, loss: 1.702, 9632/28000 datapoints
2025-03-06 22:26:24,684 - INFO - training batch 351, loss: 1.695, 11232/28000 datapoints
2025-03-06 22:26:24,988 - INFO - training batch 401, loss: 1.619, 12832/28000 datapoints
2025-03-06 22:26:25,280 - INFO - training batch 451, loss: 1.521, 14432/28000 datapoints
2025-03-06 22:26:25,582 - INFO - training batch 501, loss: 1.221, 16032/28000 datapoints
2025-03-06 22:26:25,892 - INFO - training batch 551, loss: 1.553, 17632/28000 datapoints
2025-03-06 22:26:26,205 - INFO - training batch 601, loss: 1.560, 19232/28000 datapoints
2025-03-06 22:26:26,583 - INFO - training batch 651, loss: 1.238, 20832/28000 datapoints
2025-03-06 22:26:26,912 - INFO - training batch 701, loss: 1.359, 22432/28000 datapoints
2025-03-06 22:26:27,246 - INFO - training batch 751, loss: 1.666, 24032/28000 datapoints
2025-03-06 22:26:27,634 - INFO - training batch 801, loss: 1.366, 25632/28000 datapoints
2025-03-06 22:26:28,051 - INFO - training batch 851, loss: 1.491, 27232/28000 datapoints
2025-03-06 22:26:28,233 - INFO - validation batch 1, loss: 1.172, 32/6976 datapoints
2025-03-06 22:26:28,371 - INFO - validation batch 51, loss: 1.957, 1632/6976 datapoints
2025-03-06 22:26:28,510 - INFO - validation batch 101, loss: 1.498, 3232/6976 datapoints
2025-03-06 22:26:28,653 - INFO - validation batch 151, loss: 1.845, 4832/6976 datapoints
2025-03-06 22:26:28,788 - INFO - validation batch 201, loss: 1.123, 6432/6976 datapoints
2025-03-06 22:26:28,832 - INFO - Epoch 13/800 done.
2025-03-06 22:26:28,833 - INFO - Final validation performance:
Loss: 1.519, top-1 acc: 0.459top-5 acc: 0.459
2025-03-06 22:26:28,835 - INFO - Beginning epoch 14/800
2025-03-06 22:26:28,844 - INFO - training batch 1, loss: 1.955, 32/28000 datapoints
2025-03-06 22:26:29,243 - INFO - training batch 51, loss: 1.730, 1632/28000 datapoints
2025-03-06 22:26:29,601 - INFO - training batch 101, loss: 1.402, 3232/28000 datapoints
2025-03-06 22:26:29,961 - INFO - training batch 151, loss: 1.802, 4832/28000 datapoints
2025-03-06 22:26:30,319 - INFO - training batch 201, loss: 1.782, 6432/28000 datapoints
2025-03-06 22:26:30,676 - INFO - training batch 251, loss: 1.612, 8032/28000 datapoints
2025-03-06 22:26:31,038 - INFO - training batch 301, loss: 1.689, 9632/28000 datapoints
2025-03-06 22:26:31,401 - INFO - training batch 351, loss: 1.672, 11232/28000 datapoints
2025-03-06 22:26:31,754 - INFO - training batch 401, loss: 1.601, 12832/28000 datapoints
2025-03-06 22:26:32,120 - INFO - training batch 451, loss: 1.507, 14432/28000 datapoints
2025-03-06 22:26:32,488 - INFO - training batch 501, loss: 1.210, 16032/28000 datapoints
2025-03-06 22:26:32,849 - INFO - training batch 551, loss: 1.545, 17632/28000 datapoints
2025-03-06 22:26:33,203 - INFO - training batch 601, loss: 1.555, 19232/28000 datapoints
2025-03-06 22:26:33,543 - INFO - training batch 651, loss: 1.210, 20832/28000 datapoints
2025-03-06 22:26:33,869 - INFO - training batch 701, loss: 1.349, 22432/28000 datapoints
2025-03-06 22:26:34,187 - INFO - training batch 751, loss: 1.652, 24032/28000 datapoints
2025-03-06 22:26:34,508 - INFO - training batch 801, loss: 1.354, 25632/28000 datapoints
2025-03-06 22:26:34,829 - INFO - training batch 851, loss: 1.475, 27232/28000 datapoints
2025-03-06 22:26:34,993 - INFO - validation batch 1, loss: 1.153, 32/6976 datapoints
2025-03-06 22:26:35,099 - INFO - validation batch 51, loss: 1.932, 1632/6976 datapoints
2025-03-06 22:26:35,216 - INFO - validation batch 101, loss: 1.481, 3232/6976 datapoints
2025-03-06 22:26:35,327 - INFO - validation batch 151, loss: 1.826, 4832/6976 datapoints
2025-03-06 22:26:35,439 - INFO - validation batch 201, loss: 1.102, 6432/6976 datapoints
2025-03-06 22:26:35,476 - INFO - Epoch 14/800 done.
2025-03-06 22:26:35,477 - INFO - Final validation performance:
Loss: 1.499, top-1 acc: 0.464top-5 acc: 0.464
2025-03-06 22:26:35,478 - INFO - Beginning epoch 15/800
2025-03-06 22:26:35,488 - INFO - training batch 1, loss: 1.933, 32/28000 datapoints
2025-03-06 22:26:35,851 - INFO - training batch 51, loss: 1.722, 1632/28000 datapoints
2025-03-06 22:26:36,146 - INFO - training batch 101, loss: 1.386, 3232/28000 datapoints
2025-03-06 22:26:36,438 - INFO - training batch 151, loss: 1.791, 4832/28000 datapoints
2025-03-06 22:26:36,726 - INFO - training batch 201, loss: 1.770, 6432/28000 datapoints
2025-03-06 22:26:37,008 - INFO - training batch 251, loss: 1.582, 8032/28000 datapoints
2025-03-06 22:26:37,283 - INFO - training batch 301, loss: 1.677, 9632/28000 datapoints
2025-03-06 22:26:37,583 - INFO - training batch 351, loss: 1.652, 11232/28000 datapoints
2025-03-06 22:26:37,876 - INFO - training batch 401, loss: 1.586, 12832/28000 datapoints
2025-03-06 22:26:38,171 - INFO - training batch 451, loss: 1.494, 14432/28000 datapoints
2025-03-06 22:26:38,459 - INFO - training batch 501, loss: 1.202, 16032/28000 datapoints
2025-03-06 22:26:38,719 - INFO - training batch 551, loss: 1.539, 17632/28000 datapoints
2025-03-06 22:26:38,991 - INFO - training batch 601, loss: 1.550, 19232/28000 datapoints
2025-03-06 22:26:39,267 - INFO - training batch 651, loss: 1.186, 20832/28000 datapoints
2025-03-06 22:26:39,519 - INFO - training batch 701, loss: 1.340, 22432/28000 datapoints
2025-03-06 22:26:39,760 - INFO - training batch 751, loss: 1.639, 24032/28000 datapoints
2025-03-06 22:26:40,003 - INFO - training batch 801, loss: 1.342, 25632/28000 datapoints
2025-03-06 22:26:40,248 - INFO - training batch 851, loss: 1.461, 27232/28000 datapoints
2025-03-06 22:26:40,367 - INFO - validation batch 1, loss: 1.136, 32/6976 datapoints
2025-03-06 22:26:40,452 - INFO - validation batch 51, loss: 1.911, 1632/6976 datapoints
2025-03-06 22:26:40,548 - INFO - validation batch 101, loss: 1.465, 3232/6976 datapoints
2025-03-06 22:26:40,631 - INFO - validation batch 151, loss: 1.808, 4832/6976 datapoints
2025-03-06 22:26:40,714 - INFO - validation batch 201, loss: 1.084, 6432/6976 datapoints
2025-03-06 22:26:40,742 - INFO - Epoch 15/800 done.
2025-03-06 22:26:40,743 - INFO - Final validation performance:
Loss: 1.481, top-1 acc: 0.466top-5 acc: 0.466
2025-03-06 22:26:40,746 - INFO - Beginning epoch 16/800
2025-03-06 22:26:40,752 - INFO - training batch 1, loss: 1.911, 32/28000 datapoints
2025-03-06 22:26:40,988 - INFO - training batch 51, loss: 1.714, 1632/28000 datapoints
2025-03-06 22:26:41,211 - INFO - training batch 101, loss: 1.371, 3232/28000 datapoints
2025-03-06 22:26:41,438 - INFO - training batch 151, loss: 1.780, 4832/28000 datapoints
2025-03-06 22:26:41,894 - INFO - training batch 201, loss: 1.759, 6432/28000 datapoints
2025-03-06 22:26:42,104 - INFO - training batch 251, loss: 1.555, 8032/28000 datapoints
2025-03-06 22:26:42,319 - INFO - training batch 301, loss: 1.665, 9632/28000 datapoints
2025-03-06 22:26:42,529 - INFO - training batch 351, loss: 1.635, 11232/28000 datapoints
2025-03-06 22:26:42,736 - INFO - training batch 401, loss: 1.572, 12832/28000 datapoints
2025-03-06 22:26:42,944 - INFO - training batch 451, loss: 1.482, 14432/28000 datapoints
2025-03-06 22:26:43,151 - INFO - training batch 501, loss: 1.196, 16032/28000 datapoints
2025-03-06 22:26:43,358 - INFO - training batch 551, loss: 1.533, 17632/28000 datapoints
2025-03-06 22:26:43,561 - INFO - training batch 601, loss: 1.545, 19232/28000 datapoints
2025-03-06 22:26:43,758 - INFO - training batch 651, loss: 1.164, 20832/28000 datapoints
2025-03-06 22:26:43,973 - INFO - training batch 701, loss: 1.330, 22432/28000 datapoints
2025-03-06 22:26:44,165 - INFO - training batch 751, loss: 1.627, 24032/28000 datapoints
2025-03-06 22:26:44,363 - INFO - training batch 801, loss: 1.332, 25632/28000 datapoints
2025-03-06 22:26:44,565 - INFO - training batch 851, loss: 1.448, 27232/28000 datapoints
2025-03-06 22:26:44,669 - INFO - validation batch 1, loss: 1.121, 32/6976 datapoints
2025-03-06 22:26:44,736 - INFO - validation batch 51, loss: 1.892, 1632/6976 datapoints
2025-03-06 22:26:44,800 - INFO - validation batch 101, loss: 1.451, 3232/6976 datapoints
2025-03-06 22:26:44,863 - INFO - validation batch 151, loss: 1.792, 4832/6976 datapoints
2025-03-06 22:26:44,934 - INFO - validation batch 201, loss: 1.067, 6432/6976 datapoints
2025-03-06 22:26:44,955 - INFO - Epoch 16/800 done.
2025-03-06 22:26:44,955 - INFO - Final validation performance:
Loss: 1.465, top-1 acc: 0.469top-5 acc: 0.469
2025-03-06 22:26:44,956 - INFO - Beginning epoch 17/800
2025-03-06 22:26:44,961 - INFO - training batch 1, loss: 1.890, 32/28000 datapoints
2025-03-06 22:26:45,167 - INFO - training batch 51, loss: 1.705, 1632/28000 datapoints
2025-03-06 22:26:45,352 - INFO - training batch 101, loss: 1.358, 3232/28000 datapoints
2025-03-06 22:26:45,534 - INFO - training batch 151, loss: 1.770, 4832/28000 datapoints
2025-03-06 22:26:45,705 - INFO - training batch 201, loss: 1.749, 6432/28000 datapoints
2025-03-06 22:26:45,879 - INFO - training batch 251, loss: 1.529, 8032/28000 datapoints
2025-03-06 22:26:46,049 - INFO - training batch 301, loss: 1.654, 9632/28000 datapoints
2025-03-06 22:26:46,221 - INFO - training batch 351, loss: 1.620, 11232/28000 datapoints
2025-03-06 22:26:46,401 - INFO - training batch 401, loss: 1.558, 12832/28000 datapoints
2025-03-06 22:26:46,577 - INFO - training batch 451, loss: 1.472, 14432/28000 datapoints
2025-03-06 22:26:46,753 - INFO - training batch 501, loss: 1.191, 16032/28000 datapoints
2025-03-06 22:26:46,933 - INFO - training batch 551, loss: 1.528, 17632/28000 datapoints
2025-03-06 22:26:47,104 - INFO - training batch 601, loss: 1.540, 19232/28000 datapoints
2025-03-06 22:26:47,279 - INFO - training batch 651, loss: 1.146, 20832/28000 datapoints
2025-03-06 22:26:47,451 - INFO - training batch 701, loss: 1.322, 22432/28000 datapoints
2025-03-06 22:26:47,622 - INFO - training batch 751, loss: 1.614, 24032/28000 datapoints
2025-03-06 22:26:47,815 - INFO - training batch 801, loss: 1.322, 25632/28000 datapoints
2025-03-06 22:26:47,986 - INFO - training batch 851, loss: 1.437, 27232/28000 datapoints
2025-03-06 22:26:48,074 - INFO - validation batch 1, loss: 1.108, 32/6976 datapoints
2025-03-06 22:26:48,136 - INFO - validation batch 51, loss: 1.875, 1632/6976 datapoints
2025-03-06 22:26:48,197 - INFO - validation batch 101, loss: 1.438, 3232/6976 datapoints
2025-03-06 22:26:48,255 - INFO - validation batch 151, loss: 1.776, 4832/6976 datapoints
2025-03-06 22:26:48,315 - INFO - validation batch 201, loss: 1.050, 6432/6976 datapoints
2025-03-06 22:26:48,336 - INFO - Epoch 17/800 done.
2025-03-06 22:26:48,336 - INFO - Final validation performance:
Loss: 1.450, top-1 acc: 0.472top-5 acc: 0.472
2025-03-06 22:26:48,337 - INFO - Beginning epoch 18/800
2025-03-06 22:26:48,343 - INFO - training batch 1, loss: 1.869, 32/28000 datapoints
2025-03-06 22:26:48,532 - INFO - training batch 51, loss: 1.696, 1632/28000 datapoints
2025-03-06 22:26:48,700 - INFO - training batch 101, loss: 1.346, 3232/28000 datapoints
2025-03-06 22:26:48,871 - INFO - training batch 151, loss: 1.760, 4832/28000 datapoints
2025-03-06 22:26:49,040 - INFO - training batch 201, loss: 1.739, 6432/28000 datapoints
2025-03-06 22:26:49,205 - INFO - training batch 251, loss: 1.505, 8032/28000 datapoints
2025-03-06 22:26:49,376 - INFO - training batch 301, loss: 1.643, 9632/28000 datapoints
2025-03-06 22:26:49,542 - INFO - training batch 351, loss: 1.607, 11232/28000 datapoints
2025-03-06 22:26:49,704 - INFO - training batch 401, loss: 1.546, 12832/28000 datapoints
2025-03-06 22:26:49,870 - INFO - training batch 451, loss: 1.463, 14432/28000 datapoints
2025-03-06 22:26:50,041 - INFO - training batch 501, loss: 1.188, 16032/28000 datapoints
2025-03-06 22:26:50,207 - INFO - training batch 551, loss: 1.523, 17632/28000 datapoints
2025-03-06 22:26:50,377 - INFO - training batch 601, loss: 1.536, 19232/28000 datapoints
2025-03-06 22:26:50,544 - INFO - training batch 651, loss: 1.129, 20832/28000 datapoints
2025-03-06 22:26:50,714 - INFO - training batch 701, loss: 1.314, 22432/28000 datapoints
2025-03-06 22:26:50,883 - INFO - training batch 751, loss: 1.603, 24032/28000 datapoints
2025-03-06 22:26:51,048 - INFO - training batch 801, loss: 1.313, 25632/28000 datapoints
2025-03-06 22:26:51,221 - INFO - training batch 851, loss: 1.427, 27232/28000 datapoints
2025-03-06 22:26:51,306 - INFO - validation batch 1, loss: 1.097, 32/6976 datapoints
2025-03-06 22:26:51,364 - INFO - validation batch 51, loss: 1.861, 1632/6976 datapoints
2025-03-06 22:26:51,424 - INFO - validation batch 101, loss: 1.427, 3232/6976 datapoints
2025-03-06 22:26:51,483 - INFO - validation batch 151, loss: 1.762, 4832/6976 datapoints
2025-03-06 22:26:51,543 - INFO - validation batch 201, loss: 1.036, 6432/6976 datapoints
2025-03-06 22:26:51,564 - INFO - Epoch 18/800 done.
2025-03-06 22:26:51,564 - INFO - Final validation performance:
Loss: 1.437, top-1 acc: 0.475top-5 acc: 0.475
2025-03-06 22:26:51,565 - INFO - Beginning epoch 19/800
2025-03-06 22:26:51,570 - INFO - training batch 1, loss: 1.848, 32/28000 datapoints
2025-03-06 22:26:51,754 - INFO - training batch 51, loss: 1.687, 1632/28000 datapoints
2025-03-06 22:26:51,949 - INFO - training batch 101, loss: 1.334, 3232/28000 datapoints
2025-03-06 22:26:52,139 - INFO - training batch 151, loss: 1.750, 4832/28000 datapoints
2025-03-06 22:26:52,326 - INFO - training batch 201, loss: 1.729, 6432/28000 datapoints
2025-03-06 22:26:52,518 - INFO - training batch 251, loss: 1.483, 8032/28000 datapoints
2025-03-06 22:26:52,716 - INFO - training batch 301, loss: 1.633, 9632/28000 datapoints
2025-03-06 22:26:52,911 - INFO - training batch 351, loss: 1.596, 11232/28000 datapoints
2025-03-06 22:26:53,101 - INFO - training batch 401, loss: 1.535, 12832/28000 datapoints
2025-03-06 22:26:53,291 - INFO - training batch 451, loss: 1.456, 14432/28000 datapoints
2025-03-06 22:26:53,482 - INFO - training batch 501, loss: 1.186, 16032/28000 datapoints
2025-03-06 22:26:53,677 - INFO - training batch 551, loss: 1.517, 17632/28000 datapoints
2025-03-06 22:26:53,872 - INFO - training batch 601, loss: 1.531, 19232/28000 datapoints
2025-03-06 22:26:54,070 - INFO - training batch 651, loss: 1.115, 20832/28000 datapoints
2025-03-06 22:26:54,262 - INFO - training batch 701, loss: 1.306, 22432/28000 datapoints
2025-03-06 22:26:54,462 - INFO - training batch 751, loss: 1.592, 24032/28000 datapoints
2025-03-06 22:26:54,659 - INFO - training batch 801, loss: 1.305, 25632/28000 datapoints
2025-03-06 22:26:54,862 - INFO - training batch 851, loss: 1.419, 27232/28000 datapoints
2025-03-06 22:26:54,965 - INFO - validation batch 1, loss: 1.087, 32/6976 datapoints
2025-03-06 22:26:55,029 - INFO - validation batch 51, loss: 1.849, 1632/6976 datapoints
2025-03-06 22:26:55,094 - INFO - validation batch 101, loss: 1.417, 3232/6976 datapoints
2025-03-06 22:26:55,156 - INFO - validation batch 151, loss: 1.749, 4832/6976 datapoints
2025-03-06 22:26:55,230 - INFO - validation batch 201, loss: 1.022, 6432/6976 datapoints
2025-03-06 22:26:55,251 - INFO - Epoch 19/800 done.
2025-03-06 22:26:55,251 - INFO - Final validation performance:
Loss: 1.425, top-1 acc: 0.479top-5 acc: 0.479
2025-03-06 22:26:55,252 - INFO - Beginning epoch 20/800
2025-03-06 22:26:55,258 - INFO - training batch 1, loss: 1.828, 32/28000 datapoints
2025-03-06 22:26:55,464 - INFO - training batch 51, loss: 1.678, 1632/28000 datapoints
2025-03-06 22:26:55,663 - INFO - training batch 101, loss: 1.323, 3232/28000 datapoints
2025-03-06 22:26:55,862 - INFO - training batch 151, loss: 1.741, 4832/28000 datapoints
2025-03-06 22:26:56,063 - INFO - training batch 201, loss: 1.719, 6432/28000 datapoints
2025-03-06 22:26:56,248 - INFO - training batch 251, loss: 1.462, 8032/28000 datapoints
2025-03-06 22:26:56,449 - INFO - training batch 301, loss: 1.624, 9632/28000 datapoints
2025-03-06 22:26:56,660 - INFO - training batch 351, loss: 1.585, 11232/28000 datapoints
2025-03-06 22:26:56,858 - INFO - training batch 401, loss: 1.525, 12832/28000 datapoints
2025-03-06 22:26:57,058 - INFO - training batch 451, loss: 1.449, 14432/28000 datapoints
2025-03-06 22:26:57,255 - INFO - training batch 501, loss: 1.185, 16032/28000 datapoints
2025-03-06 22:26:57,471 - INFO - training batch 551, loss: 1.512, 17632/28000 datapoints
2025-03-06 22:26:57,692 - INFO - training batch 601, loss: 1.526, 19232/28000 datapoints
2025-03-06 22:26:57,940 - INFO - training batch 651, loss: 1.102, 20832/28000 datapoints
2025-03-06 22:26:58,147 - INFO - training batch 701, loss: 1.300, 22432/28000 datapoints
2025-03-06 22:26:58,362 - INFO - training batch 751, loss: 1.581, 24032/28000 datapoints
2025-03-06 22:26:58,578 - INFO - training batch 801, loss: 1.296, 25632/28000 datapoints
2025-03-06 22:26:58,790 - INFO - training batch 851, loss: 1.411, 27232/28000 datapoints
2025-03-06 22:26:58,910 - INFO - validation batch 1, loss: 1.078, 32/6976 datapoints
2025-03-06 22:26:58,984 - INFO - validation batch 51, loss: 1.838, 1632/6976 datapoints
2025-03-06 22:26:59,054 - INFO - validation batch 101, loss: 1.408, 3232/6976 datapoints
2025-03-06 22:26:59,129 - INFO - validation batch 151, loss: 1.737, 4832/6976 datapoints
2025-03-06 22:26:59,205 - INFO - validation batch 201, loss: 1.009, 6432/6976 datapoints
2025-03-06 22:26:59,229 - INFO - Epoch 20/800 done.
2025-03-06 22:26:59,230 - INFO - Final validation performance:
Loss: 1.414, top-1 acc: 0.480top-5 acc: 0.480
2025-03-06 22:26:59,231 - INFO - Beginning epoch 21/800
2025-03-06 22:26:59,237 - INFO - training batch 1, loss: 1.809, 32/28000 datapoints
2025-03-06 22:26:59,479 - INFO - training batch 51, loss: 1.670, 1632/28000 datapoints
2025-03-06 22:26:59,700 - INFO - training batch 101, loss: 1.313, 3232/28000 datapoints
2025-03-06 22:26:59,921 - INFO - training batch 151, loss: 1.733, 4832/28000 datapoints
2025-03-06 22:27:00,174 - INFO - training batch 201, loss: 1.709, 6432/28000 datapoints
2025-03-06 22:27:00,432 - INFO - training batch 251, loss: 1.444, 8032/28000 datapoints
2025-03-06 22:27:00,673 - INFO - training batch 301, loss: 1.615, 9632/28000 datapoints
2025-03-06 22:27:00,885 - INFO - training batch 351, loss: 1.577, 11232/28000 datapoints
2025-03-06 22:27:01,094 - INFO - training batch 401, loss: 1.515, 12832/28000 datapoints
2025-03-06 22:27:01,300 - INFO - training batch 451, loss: 1.443, 14432/28000 datapoints
2025-03-06 22:27:01,511 - INFO - training batch 501, loss: 1.184, 16032/28000 datapoints
2025-03-06 22:27:01,722 - INFO - training batch 551, loss: 1.508, 17632/28000 datapoints
2025-03-06 22:27:01,936 - INFO - training batch 601, loss: 1.521, 19232/28000 datapoints
2025-03-06 22:27:02,144 - INFO - training batch 651, loss: 1.091, 20832/28000 datapoints
2025-03-06 22:27:02,344 - INFO - training batch 701, loss: 1.293, 22432/28000 datapoints
2025-03-06 22:27:02,551 - INFO - training batch 751, loss: 1.571, 24032/28000 datapoints
2025-03-06 22:27:02,755 - INFO - training batch 801, loss: 1.289, 25632/28000 datapoints
2025-03-06 22:27:02,960 - INFO - training batch 851, loss: 1.405, 27232/28000 datapoints
2025-03-06 22:27:03,062 - INFO - validation batch 1, loss: 1.070, 32/6976 datapoints
2025-03-06 22:27:03,134 - INFO - validation batch 51, loss: 1.828, 1632/6976 datapoints
2025-03-06 22:27:03,204 - INFO - validation batch 101, loss: 1.400, 3232/6976 datapoints
2025-03-06 22:27:03,273 - INFO - validation batch 151, loss: 1.726, 4832/6976 datapoints
2025-03-06 22:27:03,343 - INFO - validation batch 201, loss: 0.997, 6432/6976 datapoints
2025-03-06 22:27:03,363 - INFO - Epoch 21/800 done.
2025-03-06 22:27:03,364 - INFO - Final validation performance:
Loss: 1.404, top-1 acc: 0.483top-5 acc: 0.483
2025-03-06 22:27:03,364 - INFO - Beginning epoch 22/800
2025-03-06 22:27:03,369 - INFO - training batch 1, loss: 1.791, 32/28000 datapoints
2025-03-06 22:27:03,576 - INFO - training batch 51, loss: 1.661, 1632/28000 datapoints
2025-03-06 22:27:03,779 - INFO - training batch 101, loss: 1.303, 3232/28000 datapoints
2025-03-06 22:27:03,993 - INFO - training batch 151, loss: 1.725, 4832/28000 datapoints
2025-03-06 22:27:04,191 - INFO - training batch 201, loss: 1.700, 6432/28000 datapoints
2025-03-06 22:27:04,399 - INFO - training batch 251, loss: 1.426, 8032/28000 datapoints
2025-03-06 22:27:04,601 - INFO - training batch 301, loss: 1.606, 9632/28000 datapoints
2025-03-06 22:27:04,805 - INFO - training batch 351, loss: 1.568, 11232/28000 datapoints
2025-03-06 22:27:05,004 - INFO - training batch 401, loss: 1.506, 12832/28000 datapoints
2025-03-06 22:27:05,210 - INFO - training batch 451, loss: 1.438, 14432/28000 datapoints
2025-03-06 22:27:05,412 - INFO - training batch 501, loss: 1.184, 16032/28000 datapoints
2025-03-06 22:27:05,612 - INFO - training batch 551, loss: 1.503, 17632/28000 datapoints
2025-03-06 22:27:05,807 - INFO - training batch 601, loss: 1.516, 19232/28000 datapoints
2025-03-06 22:27:06,003 - INFO - training batch 651, loss: 1.081, 20832/28000 datapoints
2025-03-06 22:27:06,196 - INFO - training batch 701, loss: 1.288, 22432/28000 datapoints
2025-03-06 22:27:06,383 - INFO - training batch 751, loss: 1.561, 24032/28000 datapoints
2025-03-06 22:27:06,586 - INFO - training batch 801, loss: 1.281, 25632/28000 datapoints
2025-03-06 22:27:06,780 - INFO - training batch 851, loss: 1.399, 27232/28000 datapoints
2025-03-06 22:27:06,880 - INFO - validation batch 1, loss: 1.063, 32/6976 datapoints
2025-03-06 22:27:06,951 - INFO - validation batch 51, loss: 1.820, 1632/6976 datapoints
2025-03-06 22:27:07,016 - INFO - validation batch 101, loss: 1.393, 3232/6976 datapoints
2025-03-06 22:27:07,082 - INFO - validation batch 151, loss: 1.715, 4832/6976 datapoints
2025-03-06 22:27:07,149 - INFO - validation batch 201, loss: 0.986, 6432/6976 datapoints
2025-03-06 22:27:07,169 - INFO - Epoch 22/800 done.
2025-03-06 22:27:07,169 - INFO - Final validation performance:
Loss: 1.396, top-1 acc: 0.485top-5 acc: 0.485
2025-03-06 22:27:07,170 - INFO - Beginning epoch 23/800
2025-03-06 22:27:07,176 - INFO - training batch 1, loss: 1.773, 32/28000 datapoints
2025-03-06 22:27:07,372 - INFO - training batch 51, loss: 1.653, 1632/28000 datapoints
2025-03-06 22:27:07,561 - INFO - training batch 101, loss: 1.294, 3232/28000 datapoints
2025-03-06 22:27:07,744 - INFO - training batch 151, loss: 1.717, 4832/28000 datapoints
2025-03-06 22:27:07,953 - INFO - training batch 201, loss: 1.692, 6432/28000 datapoints
2025-03-06 22:27:08,124 - INFO - training batch 251, loss: 1.410, 8032/28000 datapoints
2025-03-06 22:27:08,287 - INFO - training batch 301, loss: 1.599, 9632/28000 datapoints
2025-03-06 22:27:08,457 - INFO - training batch 351, loss: 1.561, 11232/28000 datapoints
2025-03-06 22:27:08,623 - INFO - training batch 401, loss: 1.497, 12832/28000 datapoints
2025-03-06 22:27:08,795 - INFO - training batch 451, loss: 1.433, 14432/28000 datapoints
2025-03-06 22:27:08,975 - INFO - training batch 501, loss: 1.184, 16032/28000 datapoints
2025-03-06 22:27:09,142 - INFO - training batch 551, loss: 1.498, 17632/28000 datapoints
2025-03-06 22:27:09,315 - INFO - training batch 601, loss: 1.511, 19232/28000 datapoints
2025-03-06 22:27:09,493 - INFO - training batch 651, loss: 1.072, 20832/28000 datapoints
2025-03-06 22:27:09,659 - INFO - training batch 701, loss: 1.282, 22432/28000 datapoints
2025-03-06 22:27:09,823 - INFO - training batch 751, loss: 1.553, 24032/28000 datapoints
2025-03-06 22:27:09,996 - INFO - training batch 801, loss: 1.274, 25632/28000 datapoints
2025-03-06 22:27:10,163 - INFO - training batch 851, loss: 1.393, 27232/28000 datapoints
2025-03-06 22:27:10,246 - INFO - validation batch 1, loss: 1.057, 32/6976 datapoints
2025-03-06 22:27:10,303 - INFO - validation batch 51, loss: 1.812, 1632/6976 datapoints
2025-03-06 22:27:10,359 - INFO - validation batch 101, loss: 1.387, 3232/6976 datapoints
2025-03-06 22:27:10,418 - INFO - validation batch 151, loss: 1.706, 4832/6976 datapoints
2025-03-06 22:27:10,478 - INFO - validation batch 201, loss: 0.976, 6432/6976 datapoints
2025-03-06 22:27:10,497 - INFO - Epoch 23/800 done.
2025-03-06 22:27:10,498 - INFO - Final validation performance:
Loss: 1.388, top-1 acc: 0.487top-5 acc: 0.487
2025-03-06 22:27:10,498 - INFO - Beginning epoch 24/800
2025-03-06 22:27:10,504 - INFO - training batch 1, loss: 1.756, 32/28000 datapoints
2025-03-06 22:27:10,683 - INFO - training batch 51, loss: 1.645, 1632/28000 datapoints
2025-03-06 22:27:10,867 - INFO - training batch 101, loss: 1.285, 3232/28000 datapoints
2025-03-06 22:27:11,052 - INFO - training batch 151, loss: 1.709, 4832/28000 datapoints
2025-03-06 22:27:11,229 - INFO - training batch 201, loss: 1.683, 6432/28000 datapoints
2025-03-06 22:27:11,409 - INFO - training batch 251, loss: 1.395, 8032/28000 datapoints
2025-03-06 22:27:11,591 - INFO - training batch 301, loss: 1.592, 9632/28000 datapoints
2025-03-06 22:27:11,769 - INFO - training batch 351, loss: 1.554, 11232/28000 datapoints
2025-03-06 22:27:11,954 - INFO - training batch 401, loss: 1.490, 12832/28000 datapoints
2025-03-06 22:27:12,137 - INFO - training batch 451, loss: 1.429, 14432/28000 datapoints
2025-03-06 22:27:12,316 - INFO - training batch 501, loss: 1.184, 16032/28000 datapoints
2025-03-06 22:27:12,499 - INFO - training batch 551, loss: 1.493, 17632/28000 datapoints
2025-03-06 22:27:12,679 - INFO - training batch 601, loss: 1.506, 19232/28000 datapoints
2025-03-06 22:27:12,861 - INFO - training batch 651, loss: 1.065, 20832/28000 datapoints
2025-03-06 22:27:13,052 - INFO - training batch 701, loss: 1.277, 22432/28000 datapoints
2025-03-06 22:27:13,232 - INFO - training batch 751, loss: 1.545, 24032/28000 datapoints
2025-03-06 22:27:13,412 - INFO - training batch 801, loss: 1.268, 25632/28000 datapoints
2025-03-06 22:27:13,596 - INFO - training batch 851, loss: 1.389, 27232/28000 datapoints
2025-03-06 22:27:13,687 - INFO - validation batch 1, loss: 1.052, 32/6976 datapoints
2025-03-06 22:27:13,743 - INFO - validation batch 51, loss: 1.806, 1632/6976 datapoints
2025-03-06 22:27:13,797 - INFO - validation batch 101, loss: 1.381, 3232/6976 datapoints
2025-03-06 22:27:13,852 - INFO - validation batch 151, loss: 1.697, 4832/6976 datapoints
2025-03-06 22:27:13,912 - INFO - validation batch 201, loss: 0.966, 6432/6976 datapoints
2025-03-06 22:27:13,930 - INFO - Epoch 24/800 done.
2025-03-06 22:27:13,931 - INFO - Final validation performance:
Loss: 1.380, top-1 acc: 0.489top-5 acc: 0.489
2025-03-06 22:27:13,931 - INFO - Beginning epoch 25/800
2025-03-06 22:27:13,936 - INFO - training batch 1, loss: 1.740, 32/28000 datapoints
2025-03-06 22:27:14,121 - INFO - training batch 51, loss: 1.637, 1632/28000 datapoints
2025-03-06 22:27:14,300 - INFO - training batch 101, loss: 1.276, 3232/28000 datapoints
2025-03-06 22:27:14,486 - INFO - training batch 151, loss: 1.702, 4832/28000 datapoints
2025-03-06 22:27:14,669 - INFO - training batch 201, loss: 1.674, 6432/28000 datapoints
2025-03-06 22:27:14,887 - INFO - training batch 251, loss: 1.381, 8032/28000 datapoints
2025-03-06 22:27:15,071 - INFO - training batch 301, loss: 1.585, 9632/28000 datapoints
2025-03-06 22:27:15,258 - INFO - training batch 351, loss: 1.548, 11232/28000 datapoints
2025-03-06 22:27:15,443 - INFO - training batch 401, loss: 1.482, 12832/28000 datapoints
2025-03-06 22:27:15,629 - INFO - training batch 451, loss: 1.426, 14432/28000 datapoints
2025-03-06 22:27:15,813 - INFO - training batch 501, loss: 1.184, 16032/28000 datapoints
2025-03-06 22:27:15,999 - INFO - training batch 551, loss: 1.487, 17632/28000 datapoints
2025-03-06 22:27:16,190 - INFO - training batch 601, loss: 1.500, 19232/28000 datapoints
2025-03-06 22:27:16,374 - INFO - training batch 651, loss: 1.059, 20832/28000 datapoints
2025-03-06 22:27:16,563 - INFO - training batch 701, loss: 1.273, 22432/28000 datapoints
2025-03-06 22:27:16,747 - INFO - training batch 751, loss: 1.537, 24032/28000 datapoints
2025-03-06 22:27:16,939 - INFO - training batch 801, loss: 1.261, 25632/28000 datapoints
2025-03-06 22:27:17,124 - INFO - training batch 851, loss: 1.385, 27232/28000 datapoints
2025-03-06 22:27:17,218 - INFO - validation batch 1, loss: 1.047, 32/6976 datapoints
2025-03-06 22:27:17,277 - INFO - validation batch 51, loss: 1.800, 1632/6976 datapoints
2025-03-06 22:27:17,336 - INFO - validation batch 101, loss: 1.376, 3232/6976 datapoints
2025-03-06 22:27:17,399 - INFO - validation batch 151, loss: 1.690, 4832/6976 datapoints
2025-03-06 22:27:17,463 - INFO - validation batch 201, loss: 0.957, 6432/6976 datapoints
2025-03-06 22:27:17,487 - INFO - Epoch 25/800 done.
2025-03-06 22:27:17,487 - INFO - Final validation performance:
Loss: 1.374, top-1 acc: 0.490top-5 acc: 0.490
2025-03-06 22:27:17,488 - INFO - Beginning epoch 26/800
2025-03-06 22:27:17,497 - INFO - training batch 1, loss: 1.724, 32/28000 datapoints
2025-03-06 22:27:17,686 - INFO - training batch 51, loss: 1.630, 1632/28000 datapoints
2025-03-06 22:27:17,869 - INFO - training batch 101, loss: 1.267, 3232/28000 datapoints
2025-03-06 22:27:18,090 - INFO - training batch 151, loss: 1.695, 4832/28000 datapoints
2025-03-06 22:27:18,274 - INFO - training batch 201, loss: 1.666, 6432/28000 datapoints
2025-03-06 22:27:18,456 - INFO - training batch 251, loss: 1.368, 8032/28000 datapoints
2025-03-06 22:27:18,642 - INFO - training batch 301, loss: 1.578, 9632/28000 datapoints
2025-03-06 22:27:18,826 - INFO - training batch 351, loss: 1.542, 11232/28000 datapoints
2025-03-06 22:27:19,016 - INFO - training batch 401, loss: 1.476, 12832/28000 datapoints
2025-03-06 22:27:19,202 - INFO - training batch 451, loss: 1.423, 14432/28000 datapoints
2025-03-06 22:27:19,394 - INFO - training batch 501, loss: 1.185, 16032/28000 datapoints
2025-03-06 22:27:19,582 - INFO - training batch 551, loss: 1.482, 17632/28000 datapoints
2025-03-06 22:27:19,770 - INFO - training batch 601, loss: 1.494, 19232/28000 datapoints
2025-03-06 22:27:19,962 - INFO - training batch 651, loss: 1.053, 20832/28000 datapoints
2025-03-06 22:27:20,158 - INFO - training batch 701, loss: 1.269, 22432/28000 datapoints
2025-03-06 22:27:20,355 - INFO - training batch 751, loss: 1.530, 24032/28000 datapoints
2025-03-06 22:27:20,541 - INFO - training batch 801, loss: 1.255, 25632/28000 datapoints
2025-03-06 22:27:20,725 - INFO - training batch 851, loss: 1.381, 27232/28000 datapoints
2025-03-06 22:27:20,820 - INFO - validation batch 1, loss: 1.042, 32/6976 datapoints
2025-03-06 22:27:20,877 - INFO - validation batch 51, loss: 1.795, 1632/6976 datapoints
2025-03-06 22:27:20,940 - INFO - validation batch 101, loss: 1.372, 3232/6976 datapoints
2025-03-06 22:27:21,000 - INFO - validation batch 151, loss: 1.682, 4832/6976 datapoints
2025-03-06 22:27:21,056 - INFO - validation batch 201, loss: 0.948, 6432/6976 datapoints
2025-03-06 22:27:21,080 - INFO - Epoch 26/800 done.
2025-03-06 22:27:21,080 - INFO - Final validation performance:
Loss: 1.368, top-1 acc: 0.492top-5 acc: 0.492
2025-03-06 22:27:21,081 - INFO - Beginning epoch 27/800
2025-03-06 22:27:21,086 - INFO - training batch 1, loss: 1.708, 32/28000 datapoints
2025-03-06 22:27:21,274 - INFO - training batch 51, loss: 1.623, 1632/28000 datapoints
2025-03-06 22:27:21,462 - INFO - training batch 101, loss: 1.258, 3232/28000 datapoints
2025-03-06 22:27:21,650 - INFO - training batch 151, loss: 1.688, 4832/28000 datapoints
2025-03-06 22:27:21,834 - INFO - training batch 201, loss: 1.657, 6432/28000 datapoints
2025-03-06 22:27:22,025 - INFO - training batch 251, loss: 1.356, 8032/28000 datapoints
2025-03-06 22:27:22,215 - INFO - training batch 301, loss: 1.572, 9632/28000 datapoints
2025-03-06 22:27:22,398 - INFO - training batch 351, loss: 1.536, 11232/28000 datapoints
2025-03-06 22:27:22,585 - INFO - training batch 401, loss: 1.469, 12832/28000 datapoints
2025-03-06 22:27:22,769 - INFO - training batch 451, loss: 1.420, 14432/28000 datapoints
2025-03-06 22:27:22,960 - INFO - training batch 501, loss: 1.186, 16032/28000 datapoints
2025-03-06 22:27:23,158 - INFO - training batch 551, loss: 1.477, 17632/28000 datapoints
2025-03-06 22:27:23,345 - INFO - training batch 601, loss: 1.489, 19232/28000 datapoints
2025-03-06 22:27:23,531 - INFO - training batch 651, loss: 1.048, 20832/28000 datapoints
2025-03-06 22:27:23,719 - INFO - training batch 701, loss: 1.264, 22432/28000 datapoints
2025-03-06 22:27:23,909 - INFO - training batch 751, loss: 1.524, 24032/28000 datapoints
2025-03-06 22:27:24,097 - INFO - training batch 801, loss: 1.249, 25632/28000 datapoints
2025-03-06 22:27:24,282 - INFO - training batch 851, loss: 1.377, 27232/28000 datapoints
2025-03-06 22:27:24,373 - INFO - validation batch 1, loss: 1.038, 32/6976 datapoints
2025-03-06 22:27:24,431 - INFO - validation batch 51, loss: 1.790, 1632/6976 datapoints
2025-03-06 22:27:24,492 - INFO - validation batch 101, loss: 1.368, 3232/6976 datapoints
2025-03-06 22:27:24,553 - INFO - validation batch 151, loss: 1.676, 4832/6976 datapoints
2025-03-06 22:27:24,615 - INFO - validation batch 201, loss: 0.940, 6432/6976 datapoints
2025-03-06 22:27:24,636 - INFO - Epoch 27/800 done.
2025-03-06 22:27:24,636 - INFO - Final validation performance:
Loss: 1.362, top-1 acc: 0.493top-5 acc: 0.493
2025-03-06 22:27:24,637 - INFO - Beginning epoch 28/800
2025-03-06 22:27:24,642 - INFO - training batch 1, loss: 1.693, 32/28000 datapoints
2025-03-06 22:27:24,835 - INFO - training batch 51, loss: 1.617, 1632/28000 datapoints
2025-03-06 22:27:25,021 - INFO - training batch 101, loss: 1.247, 3232/28000 datapoints
2025-03-06 22:27:25,215 - INFO - training batch 151, loss: 1.682, 4832/28000 datapoints
2025-03-06 22:27:25,402 - INFO - training batch 201, loss: 1.649, 6432/28000 datapoints
2025-03-06 22:27:25,588 - INFO - training batch 251, loss: 1.344, 8032/28000 datapoints
2025-03-06 22:27:25,777 - INFO - training batch 301, loss: 1.567, 9632/28000 datapoints
2025-03-06 22:27:25,973 - INFO - training batch 351, loss: 1.529, 11232/28000 datapoints
2025-03-06 22:27:26,155 - INFO - training batch 401, loss: 1.462, 12832/28000 datapoints
2025-03-06 22:27:26,332 - INFO - training batch 451, loss: 1.418, 14432/28000 datapoints
2025-03-06 22:27:26,506 - INFO - training batch 501, loss: 1.186, 16032/28000 datapoints
2025-03-06 22:27:26,688 - INFO - training batch 551, loss: 1.471, 17632/28000 datapoints
2025-03-06 22:27:26,871 - INFO - training batch 601, loss: 1.484, 19232/28000 datapoints
2025-03-06 22:27:27,051 - INFO - training batch 651, loss: 1.043, 20832/28000 datapoints
2025-03-06 22:27:27,247 - INFO - training batch 701, loss: 1.260, 22432/28000 datapoints
2025-03-06 22:27:27,430 - INFO - training batch 751, loss: 1.517, 24032/28000 datapoints
2025-03-06 22:27:27,616 - INFO - training batch 801, loss: 1.243, 25632/28000 datapoints
2025-03-06 22:27:27,798 - INFO - training batch 851, loss: 1.375, 27232/28000 datapoints
2025-03-06 22:27:27,888 - INFO - validation batch 1, loss: 1.034, 32/6976 datapoints
2025-03-06 22:27:27,947 - INFO - validation batch 51, loss: 1.785, 1632/6976 datapoints
2025-03-06 22:27:28,002 - INFO - validation batch 101, loss: 1.365, 3232/6976 datapoints
2025-03-06 22:27:28,057 - INFO - validation batch 151, loss: 1.670, 4832/6976 datapoints
2025-03-06 22:27:28,134 - INFO - validation batch 201, loss: 0.933, 6432/6976 datapoints
2025-03-06 22:27:28,165 - INFO - Epoch 28/800 done.
2025-03-06 22:27:28,165 - INFO - Final validation performance:
Loss: 1.357, top-1 acc: 0.494top-5 acc: 0.494
2025-03-06 22:27:28,166 - INFO - Beginning epoch 29/800
2025-03-06 22:27:28,172 - INFO - training batch 1, loss: 1.679, 32/28000 datapoints
2025-03-06 22:27:28,382 - INFO - training batch 51, loss: 1.611, 1632/28000 datapoints
2025-03-06 22:27:28,543 - INFO - training batch 101, loss: 1.238, 3232/28000 datapoints
2025-03-06 22:27:28,706 - INFO - training batch 151, loss: 1.676, 4832/28000 datapoints
2025-03-06 22:27:28,872 - INFO - training batch 201, loss: 1.641, 6432/28000 datapoints
2025-03-06 22:27:29,035 - INFO - training batch 251, loss: 1.334, 8032/28000 datapoints
2025-03-06 22:27:29,196 - INFO - training batch 301, loss: 1.562, 9632/28000 datapoints
2025-03-06 22:27:29,360 - INFO - training batch 351, loss: 1.523, 11232/28000 datapoints
2025-03-06 22:27:29,521 - INFO - training batch 401, loss: 1.457, 12832/28000 datapoints
2025-03-06 22:27:29,689 - INFO - training batch 451, loss: 1.415, 14432/28000 datapoints
2025-03-06 22:27:29,847 - INFO - training batch 501, loss: 1.187, 16032/28000 datapoints
2025-03-06 22:27:30,011 - INFO - training batch 551, loss: 1.466, 17632/28000 datapoints
2025-03-06 22:27:30,174 - INFO - training batch 601, loss: 1.478, 19232/28000 datapoints
2025-03-06 22:27:30,337 - INFO - training batch 651, loss: 1.039, 20832/28000 datapoints
2025-03-06 22:27:30,498 - INFO - training batch 701, loss: 1.257, 22432/28000 datapoints
2025-03-06 22:27:30,661 - INFO - training batch 751, loss: 1.512, 24032/28000 datapoints
2025-03-06 22:27:30,822 - INFO - training batch 801, loss: 1.237, 25632/28000 datapoints
2025-03-06 22:27:30,987 - INFO - training batch 851, loss: 1.373, 27232/28000 datapoints
2025-03-06 22:27:31,067 - INFO - validation batch 1, loss: 1.031, 32/6976 datapoints
2025-03-06 22:27:31,120 - INFO - validation batch 51, loss: 1.781, 1632/6976 datapoints
2025-03-06 22:27:31,177 - INFO - validation batch 101, loss: 1.361, 3232/6976 datapoints
2025-03-06 22:27:31,230 - INFO - validation batch 151, loss: 1.664, 4832/6976 datapoints
2025-03-06 22:27:31,284 - INFO - validation batch 201, loss: 0.926, 6432/6976 datapoints
2025-03-06 22:27:31,304 - INFO - Epoch 29/800 done.
2025-03-06 22:27:31,304 - INFO - Final validation performance:
Loss: 1.353, top-1 acc: 0.494top-5 acc: 0.494
2025-03-06 22:27:31,304 - INFO - Beginning epoch 30/800
2025-03-06 22:27:31,309 - INFO - training batch 1, loss: 1.666, 32/28000 datapoints
2025-03-06 22:27:31,489 - INFO - training batch 51, loss: 1.605, 1632/28000 datapoints
2025-03-06 22:27:31,662 - INFO - training batch 101, loss: 1.230, 3232/28000 datapoints
2025-03-06 22:27:31,834 - INFO - training batch 151, loss: 1.670, 4832/28000 datapoints
2025-03-06 22:27:32,012 - INFO - training batch 201, loss: 1.633, 6432/28000 datapoints
2025-03-06 22:27:32,188 - INFO - training batch 251, loss: 1.323, 8032/28000 datapoints
2025-03-06 22:27:32,364 - INFO - training batch 301, loss: 1.557, 9632/28000 datapoints
2025-03-06 22:27:32,550 - INFO - training batch 351, loss: 1.517, 11232/28000 datapoints
2025-03-06 22:27:32,728 - INFO - training batch 401, loss: 1.452, 12832/28000 datapoints
2025-03-06 22:27:32,911 - INFO - training batch 451, loss: 1.413, 14432/28000 datapoints
2025-03-06 22:27:33,085 - INFO - training batch 501, loss: 1.188, 16032/28000 datapoints
2025-03-06 22:27:33,261 - INFO - training batch 551, loss: 1.461, 17632/28000 datapoints
2025-03-06 22:27:33,439 - INFO - training batch 601, loss: 1.472, 19232/28000 datapoints
2025-03-06 22:27:33,615 - INFO - training batch 651, loss: 1.036, 20832/28000 datapoints
2025-03-06 22:27:33,792 - INFO - training batch 701, loss: 1.253, 22432/28000 datapoints
2025-03-06 22:27:33,970 - INFO - training batch 751, loss: 1.506, 24032/28000 datapoints
2025-03-06 22:27:34,144 - INFO - training batch 801, loss: 1.231, 25632/28000 datapoints
2025-03-06 22:27:34,319 - INFO - training batch 851, loss: 1.371, 27232/28000 datapoints
2025-03-06 22:27:34,406 - INFO - validation batch 1, loss: 1.028, 32/6976 datapoints
2025-03-06 22:27:34,462 - INFO - validation batch 51, loss: 1.778, 1632/6976 datapoints
2025-03-06 22:27:34,515 - INFO - validation batch 101, loss: 1.357, 3232/6976 datapoints
2025-03-06 22:27:34,571 - INFO - validation batch 151, loss: 1.659, 4832/6976 datapoints
2025-03-06 22:27:34,624 - INFO - validation batch 201, loss: 0.920, 6432/6976 datapoints
2025-03-06 22:27:34,644 - INFO - Epoch 30/800 done.
2025-03-06 22:27:34,644 - INFO - Final validation performance:
Loss: 1.348, top-1 acc: 0.494top-5 acc: 0.494
2025-03-06 22:27:34,645 - INFO - Beginning epoch 31/800
2025-03-06 22:27:34,651 - INFO - training batch 1, loss: 1.654, 32/28000 datapoints
2025-03-06 22:27:34,830 - INFO - training batch 51, loss: 1.599, 1632/28000 datapoints
2025-03-06 22:27:35,015 - INFO - training batch 101, loss: 1.223, 3232/28000 datapoints
2025-03-06 22:27:35,199 - INFO - training batch 151, loss: 1.665, 4832/28000 datapoints
2025-03-06 22:27:35,362 - INFO - training batch 201, loss: 1.627, 6432/28000 datapoints
2025-03-06 22:27:35,544 - INFO - training batch 251, loss: 1.314, 8032/28000 datapoints
2025-03-06 22:27:35,706 - INFO - training batch 301, loss: 1.552, 9632/28000 datapoints
2025-03-06 22:27:35,865 - INFO - training batch 351, loss: 1.511, 11232/28000 datapoints
2025-03-06 22:27:36,030 - INFO - training batch 401, loss: 1.447, 12832/28000 datapoints
2025-03-06 22:27:36,185 - INFO - training batch 451, loss: 1.411, 14432/28000 datapoints
2025-03-06 22:27:36,349 - INFO - training batch 501, loss: 1.189, 16032/28000 datapoints
2025-03-06 22:27:36,510 - INFO - training batch 551, loss: 1.456, 17632/28000 datapoints
2025-03-06 22:27:36,676 - INFO - training batch 601, loss: 1.466, 19232/28000 datapoints
2025-03-06 22:27:36,850 - INFO - training batch 651, loss: 1.033, 20832/28000 datapoints
2025-03-06 22:27:37,019 - INFO - training batch 701, loss: 1.250, 22432/28000 datapoints
2025-03-06 22:27:37,194 - INFO - training batch 751, loss: 1.501, 24032/28000 datapoints
2025-03-06 22:27:37,364 - INFO - training batch 801, loss: 1.226, 25632/28000 datapoints
2025-03-06 22:27:37,533 - INFO - training batch 851, loss: 1.370, 27232/28000 datapoints
2025-03-06 22:27:37,621 - INFO - validation batch 1, loss: 1.025, 32/6976 datapoints
2025-03-06 22:27:37,681 - INFO - validation batch 51, loss: 1.775, 1632/6976 datapoints
2025-03-06 22:27:37,744 - INFO - validation batch 101, loss: 1.354, 3232/6976 datapoints
2025-03-06 22:27:37,803 - INFO - validation batch 151, loss: 1.654, 4832/6976 datapoints
2025-03-06 22:27:37,865 - INFO - validation batch 201, loss: 0.914, 6432/6976 datapoints
2025-03-06 22:27:37,886 - INFO - Epoch 31/800 done.
2025-03-06 22:27:37,887 - INFO - Final validation performance:
Loss: 1.344, top-1 acc: 0.495top-5 acc: 0.495
2025-03-06 22:27:37,888 - INFO - Beginning epoch 32/800
2025-03-06 22:27:37,910 - INFO - training batch 1, loss: 1.641, 32/28000 datapoints
2025-03-06 22:27:38,079 - INFO - training batch 51, loss: 1.593, 1632/28000 datapoints
2025-03-06 22:27:38,284 - INFO - training batch 101, loss: 1.215, 3232/28000 datapoints
2025-03-06 22:27:38,459 - INFO - training batch 151, loss: 1.659, 4832/28000 datapoints
2025-03-06 22:27:38,628 - INFO - training batch 201, loss: 1.620, 6432/28000 datapoints
2025-03-06 22:27:38,802 - INFO - training batch 251, loss: 1.304, 8032/28000 datapoints
2025-03-06 22:27:38,983 - INFO - training batch 301, loss: 1.548, 9632/28000 datapoints
2025-03-06 22:27:39,158 - INFO - training batch 351, loss: 1.505, 11232/28000 datapoints
2025-03-06 22:27:39,340 - INFO - training batch 401, loss: 1.442, 12832/28000 datapoints
2025-03-06 22:27:39,519 - INFO - training batch 451, loss: 1.409, 14432/28000 datapoints
2025-03-06 22:27:39,699 - INFO - training batch 501, loss: 1.190, 16032/28000 datapoints
2025-03-06 22:27:39,874 - INFO - training batch 551, loss: 1.451, 17632/28000 datapoints
2025-03-06 22:27:40,045 - INFO - training batch 601, loss: 1.461, 19232/28000 datapoints
2025-03-06 22:27:40,224 - INFO - training batch 651, loss: 1.030, 20832/28000 datapoints
2025-03-06 22:27:40,402 - INFO - training batch 701, loss: 1.247, 22432/28000 datapoints
2025-03-06 22:27:40,579 - INFO - training batch 751, loss: 1.497, 24032/28000 datapoints
2025-03-06 22:27:40,757 - INFO - training batch 801, loss: 1.220, 25632/28000 datapoints
2025-03-06 22:27:40,954 - INFO - training batch 851, loss: 1.368, 27232/28000 datapoints
2025-03-06 22:27:41,045 - INFO - validation batch 1, loss: 1.023, 32/6976 datapoints
2025-03-06 22:27:41,106 - INFO - validation batch 51, loss: 1.774, 1632/6976 datapoints
2025-03-06 22:27:41,165 - INFO - validation batch 101, loss: 1.350, 3232/6976 datapoints
2025-03-06 22:27:41,226 - INFO - validation batch 151, loss: 1.650, 4832/6976 datapoints
2025-03-06 22:27:41,287 - INFO - validation batch 201, loss: 0.908, 6432/6976 datapoints
2025-03-06 22:27:41,307 - INFO - Epoch 32/800 done.
2025-03-06 22:27:41,308 - INFO - Final validation performance:
Loss: 1.341, top-1 acc: 0.495top-5 acc: 0.495
2025-03-06 22:27:41,308 - INFO - Beginning epoch 33/800
2025-03-06 22:27:41,313 - INFO - training batch 1, loss: 1.630, 32/28000 datapoints
2025-03-06 22:27:41,511 - INFO - training batch 51, loss: 1.588, 1632/28000 datapoints
2025-03-06 22:27:41,699 - INFO - training batch 101, loss: 1.208, 3232/28000 datapoints
2025-03-06 22:27:41,890 - INFO - training batch 151, loss: 1.654, 4832/28000 datapoints
2025-03-06 22:27:42,077 - INFO - training batch 201, loss: 1.612, 6432/28000 datapoints
2025-03-06 22:27:42,266 - INFO - training batch 251, loss: 1.296, 8032/28000 datapoints
2025-03-06 22:27:42,456 - INFO - training batch 301, loss: 1.543, 9632/28000 datapoints
2025-03-06 22:27:42,643 - INFO - training batch 351, loss: 1.499, 11232/28000 datapoints
2025-03-06 22:27:42,836 - INFO - training batch 401, loss: 1.438, 12832/28000 datapoints
2025-03-06 22:27:43,028 - INFO - training batch 451, loss: 1.407, 14432/28000 datapoints
2025-03-06 22:27:43,224 - INFO - training batch 501, loss: 1.191, 16032/28000 datapoints
2025-03-06 22:27:43,416 - INFO - training batch 551, loss: 1.446, 17632/28000 datapoints
2025-03-06 22:27:43,611 - INFO - training batch 601, loss: 1.456, 19232/28000 datapoints
2025-03-06 22:27:43,806 - INFO - training batch 651, loss: 1.027, 20832/28000 datapoints
2025-03-06 22:27:44,003 - INFO - training batch 701, loss: 1.243, 22432/28000 datapoints
2025-03-06 22:27:44,193 - INFO - training batch 751, loss: 1.493, 24032/28000 datapoints
2025-03-06 22:27:44,388 - INFO - training batch 801, loss: 1.215, 25632/28000 datapoints
2025-03-06 22:27:44,590 - INFO - training batch 851, loss: 1.366, 27232/28000 datapoints
2025-03-06 22:27:44,689 - INFO - validation batch 1, loss: 1.020, 32/6976 datapoints
2025-03-06 22:27:44,753 - INFO - validation batch 51, loss: 1.772, 1632/6976 datapoints
2025-03-06 22:27:44,815 - INFO - validation batch 101, loss: 1.346, 3232/6976 datapoints
2025-03-06 22:27:44,879 - INFO - validation batch 151, loss: 1.646, 4832/6976 datapoints
2025-03-06 22:27:44,946 - INFO - validation batch 201, loss: 0.903, 6432/6976 datapoints
2025-03-06 22:27:44,967 - INFO - Epoch 33/800 done.
2025-03-06 22:27:44,967 - INFO - Final validation performance:
Loss: 1.337, top-1 acc: 0.496top-5 acc: 0.496
2025-03-06 22:27:44,968 - INFO - Beginning epoch 34/800
2025-03-06 22:27:44,973 - INFO - training batch 1, loss: 1.619, 32/28000 datapoints
2025-03-06 22:27:45,172 - INFO - training batch 51, loss: 1.583, 1632/28000 datapoints
2025-03-06 22:27:45,370 - INFO - training batch 101, loss: 1.201, 3232/28000 datapoints
2025-03-06 22:27:45,565 - INFO - training batch 151, loss: 1.649, 4832/28000 datapoints
2025-03-06 22:27:45,764 - INFO - training batch 201, loss: 1.606, 6432/28000 datapoints
2025-03-06 22:27:45,964 - INFO - training batch 251, loss: 1.288, 8032/28000 datapoints
2025-03-06 22:27:46,156 - INFO - training batch 301, loss: 1.539, 9632/28000 datapoints
2025-03-06 22:27:46,348 - INFO - training batch 351, loss: 1.493, 11232/28000 datapoints
2025-03-06 22:27:46,541 - INFO - training batch 401, loss: 1.433, 12832/28000 datapoints
2025-03-06 22:27:46,742 - INFO - training batch 451, loss: 1.406, 14432/28000 datapoints
2025-03-06 22:27:46,948 - INFO - training batch 501, loss: 1.192, 16032/28000 datapoints
2025-03-06 22:27:47,146 - INFO - training batch 551, loss: 1.441, 17632/28000 datapoints
2025-03-06 22:27:47,335 - INFO - training batch 601, loss: 1.451, 19232/28000 datapoints
2025-03-06 22:27:47,527 - INFO - training batch 651, loss: 1.024, 20832/28000 datapoints
2025-03-06 22:27:47,726 - INFO - training batch 701, loss: 1.240, 22432/28000 datapoints
2025-03-06 22:27:47,924 - INFO - training batch 751, loss: 1.489, 24032/28000 datapoints
2025-03-06 22:27:48,115 - INFO - training batch 801, loss: 1.209, 25632/28000 datapoints
2025-03-06 22:27:48,318 - INFO - training batch 851, loss: 1.365, 27232/28000 datapoints
2025-03-06 22:27:48,435 - INFO - validation batch 1, loss: 1.018, 32/6976 datapoints
2025-03-06 22:27:48,498 - INFO - validation batch 51, loss: 1.771, 1632/6976 datapoints
2025-03-06 22:27:48,558 - INFO - validation batch 101, loss: 1.343, 3232/6976 datapoints
2025-03-06 22:27:48,619 - INFO - validation batch 151, loss: 1.641, 4832/6976 datapoints
2025-03-06 22:27:48,678 - INFO - validation batch 201, loss: 0.898, 6432/6976 datapoints
2025-03-06 22:27:48,699 - INFO - Epoch 34/800 done.
2025-03-06 22:27:48,700 - INFO - Final validation performance:
Loss: 1.334, top-1 acc: 0.498top-5 acc: 0.498
2025-03-06 22:27:48,701 - INFO - Beginning epoch 35/800
2025-03-06 22:27:48,706 - INFO - training batch 1, loss: 1.608, 32/28000 datapoints
2025-03-06 22:27:48,911 - INFO - training batch 51, loss: 1.578, 1632/28000 datapoints
2025-03-06 22:27:49,102 - INFO - training batch 101, loss: 1.195, 3232/28000 datapoints
2025-03-06 22:27:49,294 - INFO - training batch 151, loss: 1.645, 4832/28000 datapoints
2025-03-06 22:27:49,490 - INFO - training batch 201, loss: 1.599, 6432/28000 datapoints
2025-03-06 22:27:49,683 - INFO - training batch 251, loss: 1.280, 8032/28000 datapoints
2025-03-06 22:27:49,878 - INFO - training batch 301, loss: 1.535, 9632/28000 datapoints
2025-03-06 22:27:50,073 - INFO - training batch 351, loss: 1.487, 11232/28000 datapoints
2025-03-06 22:27:50,261 - INFO - training batch 401, loss: 1.429, 12832/28000 datapoints
2025-03-06 22:27:50,443 - INFO - training batch 451, loss: 1.404, 14432/28000 datapoints
2025-03-06 22:27:50,632 - INFO - training batch 501, loss: 1.193, 16032/28000 datapoints
2025-03-06 22:27:50,818 - INFO - training batch 551, loss: 1.437, 17632/28000 datapoints
2025-03-06 22:27:51,011 - INFO - training batch 601, loss: 1.448, 19232/28000 datapoints
2025-03-06 22:27:51,197 - INFO - training batch 651, loss: 1.021, 20832/28000 datapoints
2025-03-06 22:27:51,379 - INFO - training batch 701, loss: 1.237, 22432/28000 datapoints
2025-03-06 22:27:51,557 - INFO - training batch 751, loss: 1.485, 24032/28000 datapoints
2025-03-06 22:27:51,743 - INFO - training batch 801, loss: 1.204, 25632/28000 datapoints
2025-03-06 22:27:51,929 - INFO - training batch 851, loss: 1.363, 27232/28000 datapoints
2025-03-06 22:27:52,031 - INFO - validation batch 1, loss: 1.016, 32/6976 datapoints
2025-03-06 22:27:52,086 - INFO - validation batch 51, loss: 1.770, 1632/6976 datapoints
2025-03-06 22:27:52,140 - INFO - validation batch 101, loss: 1.340, 3232/6976 datapoints
2025-03-06 22:27:52,197 - INFO - validation batch 151, loss: 1.637, 4832/6976 datapoints
2025-03-06 22:27:52,252 - INFO - validation batch 201, loss: 0.893, 6432/6976 datapoints
2025-03-06 22:27:52,270 - INFO - Epoch 35/800 done.
2025-03-06 22:27:52,270 - INFO - Final validation performance:
Loss: 1.331, top-1 acc: 0.499top-5 acc: 0.499
2025-03-06 22:27:52,271 - INFO - Beginning epoch 36/800
2025-03-06 22:27:52,276 - INFO - training batch 1, loss: 1.598, 32/28000 datapoints
2025-03-06 22:27:52,457 - INFO - training batch 51, loss: 1.573, 1632/28000 datapoints
2025-03-06 22:27:52,631 - INFO - training batch 101, loss: 1.188, 3232/28000 datapoints
2025-03-06 22:27:52,805 - INFO - training batch 151, loss: 1.640, 4832/28000 datapoints
2025-03-06 22:27:52,992 - INFO - training batch 201, loss: 1.593, 6432/28000 datapoints
2025-03-06 22:27:53,167 - INFO - training batch 251, loss: 1.273, 8032/28000 datapoints
2025-03-06 22:27:53,343 - INFO - training batch 301, loss: 1.531, 9632/28000 datapoints
2025-03-06 22:27:53,520 - INFO - training batch 351, loss: 1.480, 11232/28000 datapoints
2025-03-06 22:27:53,702 - INFO - training batch 401, loss: 1.425, 12832/28000 datapoints
2025-03-06 22:27:53,888 - INFO - training batch 451, loss: 1.403, 14432/28000 datapoints
2025-03-06 22:27:54,066 - INFO - training batch 501, loss: 1.194, 16032/28000 datapoints
2025-03-06 22:27:54,241 - INFO - training batch 551, loss: 1.433, 17632/28000 datapoints
2025-03-06 22:27:54,416 - INFO - training batch 601, loss: 1.444, 19232/28000 datapoints
2025-03-06 22:27:54,589 - INFO - training batch 651, loss: 1.018, 20832/28000 datapoints
2025-03-06 22:27:54,762 - INFO - training batch 701, loss: 1.234, 22432/28000 datapoints
2025-03-06 22:27:54,942 - INFO - training batch 751, loss: 1.482, 24032/28000 datapoints
2025-03-06 22:27:55,122 - INFO - training batch 801, loss: 1.198, 25632/28000 datapoints
2025-03-06 22:27:55,286 - INFO - training batch 851, loss: 1.362, 27232/28000 datapoints
2025-03-06 22:27:55,367 - INFO - validation batch 1, loss: 1.014, 32/6976 datapoints
2025-03-06 22:27:55,421 - INFO - validation batch 51, loss: 1.769, 1632/6976 datapoints
2025-03-06 22:27:55,483 - INFO - validation batch 101, loss: 1.337, 3232/6976 datapoints
2025-03-06 22:27:55,535 - INFO - validation batch 151, loss: 1.633, 4832/6976 datapoints
2025-03-06 22:27:55,588 - INFO - validation batch 201, loss: 0.888, 6432/6976 datapoints
2025-03-06 22:27:55,610 - INFO - Epoch 36/800 done.
2025-03-06 22:27:55,610 - INFO - Final validation performance:
Loss: 1.328, top-1 acc: 0.500top-5 acc: 0.500
2025-03-06 22:27:55,611 - INFO - Beginning epoch 37/800
2025-03-06 22:27:55,616 - INFO - training batch 1, loss: 1.588, 32/28000 datapoints
2025-03-06 22:27:55,808 - INFO - training batch 51, loss: 1.568, 1632/28000 datapoints
2025-03-06 22:27:55,977 - INFO - training batch 101, loss: 1.181, 3232/28000 datapoints
2025-03-06 22:27:56,139 - INFO - training batch 151, loss: 1.636, 4832/28000 datapoints
2025-03-06 22:27:56,301 - INFO - training batch 201, loss: 1.587, 6432/28000 datapoints
2025-03-06 22:27:56,462 - INFO - training batch 251, loss: 1.266, 8032/28000 datapoints
2025-03-06 22:27:56,621 - INFO - training batch 301, loss: 1.527, 9632/28000 datapoints
2025-03-06 22:27:56,783 - INFO - training batch 351, loss: 1.474, 11232/28000 datapoints
2025-03-06 22:27:56,957 - INFO - training batch 401, loss: 1.421, 12832/28000 datapoints
2025-03-06 22:27:57,122 - INFO - training batch 451, loss: 1.400, 14432/28000 datapoints
2025-03-06 22:27:57,294 - INFO - training batch 501, loss: 1.194, 16032/28000 datapoints
2025-03-06 22:27:57,458 - INFO - training batch 551, loss: 1.429, 17632/28000 datapoints
2025-03-06 22:27:57,624 - INFO - training batch 601, loss: 1.440, 19232/28000 datapoints
2025-03-06 22:27:57,787 - INFO - training batch 651, loss: 1.015, 20832/28000 datapoints
2025-03-06 22:27:57,955 - INFO - training batch 701, loss: 1.231, 22432/28000 datapoints
2025-03-06 22:27:58,119 - INFO - training batch 751, loss: 1.478, 24032/28000 datapoints
2025-03-06 22:27:58,287 - INFO - training batch 801, loss: 1.193, 25632/28000 datapoints
2025-03-06 22:27:58,492 - INFO - training batch 851, loss: 1.361, 27232/28000 datapoints
2025-03-06 22:27:58,574 - INFO - validation batch 1, loss: 1.012, 32/6976 datapoints
2025-03-06 22:27:58,631 - INFO - validation batch 51, loss: 1.769, 1632/6976 datapoints
2025-03-06 22:27:58,689 - INFO - validation batch 101, loss: 1.333, 3232/6976 datapoints
2025-03-06 22:27:58,746 - INFO - validation batch 151, loss: 1.629, 4832/6976 datapoints
2025-03-06 22:27:58,805 - INFO - validation batch 201, loss: 0.884, 6432/6976 datapoints
2025-03-06 22:27:58,824 - INFO - Epoch 37/800 done.
2025-03-06 22:27:58,824 - INFO - Final validation performance:
Loss: 1.325, top-1 acc: 0.501top-5 acc: 0.501
2025-03-06 22:27:58,825 - INFO - Beginning epoch 38/800
2025-03-06 22:27:58,830 - INFO - training batch 1, loss: 1.579, 32/28000 datapoints
2025-03-06 22:27:59,007 - INFO - training batch 51, loss: 1.563, 1632/28000 datapoints
2025-03-06 22:27:59,170 - INFO - training batch 101, loss: 1.174, 3232/28000 datapoints
2025-03-06 22:27:59,337 - INFO - training batch 151, loss: 1.631, 4832/28000 datapoints
2025-03-06 22:27:59,508 - INFO - training batch 201, loss: 1.582, 6432/28000 datapoints
2025-03-06 22:27:59,669 - INFO - training batch 251, loss: 1.259, 8032/28000 datapoints
2025-03-06 22:27:59,850 - INFO - training batch 301, loss: 1.523, 9632/28000 datapoints
2025-03-06 22:28:00,022 - INFO - training batch 351, loss: 1.467, 11232/28000 datapoints
2025-03-06 22:28:00,198 - INFO - training batch 401, loss: 1.417, 12832/28000 datapoints
2025-03-06 22:28:00,368 - INFO - training batch 451, loss: 1.399, 14432/28000 datapoints
2025-03-06 22:28:00,538 - INFO - training batch 501, loss: 1.194, 16032/28000 datapoints
2025-03-06 22:28:00,705 - INFO - training batch 551, loss: 1.425, 17632/28000 datapoints
2025-03-06 22:28:00,876 - INFO - training batch 601, loss: 1.437, 19232/28000 datapoints
2025-03-06 22:28:01,051 - INFO - training batch 651, loss: 1.012, 20832/28000 datapoints
2025-03-06 22:28:01,219 - INFO - training batch 701, loss: 1.228, 22432/28000 datapoints
2025-03-06 22:28:01,387 - INFO - training batch 751, loss: 1.474, 24032/28000 datapoints
2025-03-06 22:28:01,555 - INFO - training batch 801, loss: 1.187, 25632/28000 datapoints
2025-03-06 22:28:01,729 - INFO - training batch 851, loss: 1.359, 27232/28000 datapoints
2025-03-06 22:28:01,819 - INFO - validation batch 1, loss: 1.010, 32/6976 datapoints
2025-03-06 22:28:01,881 - INFO - validation batch 51, loss: 1.769, 1632/6976 datapoints
2025-03-06 22:28:01,946 - INFO - validation batch 101, loss: 1.329, 3232/6976 datapoints
2025-03-06 22:28:02,007 - INFO - validation batch 151, loss: 1.624, 4832/6976 datapoints
2025-03-06 22:28:02,068 - INFO - validation batch 201, loss: 0.880, 6432/6976 datapoints
2025-03-06 22:28:02,090 - INFO - Epoch 38/800 done.
2025-03-06 22:28:02,091 - INFO - Final validation performance:
Loss: 1.323, top-1 acc: 0.503top-5 acc: 0.503
2025-03-06 22:28:02,091 - INFO - Beginning epoch 39/800
2025-03-06 22:28:02,100 - INFO - training batch 1, loss: 1.569, 32/28000 datapoints
2025-03-06 22:28:02,277 - INFO - training batch 51, loss: 1.558, 1632/28000 datapoints
2025-03-06 22:28:02,454 - INFO - training batch 101, loss: 1.168, 3232/28000 datapoints
2025-03-06 22:28:02,630 - INFO - training batch 151, loss: 1.627, 4832/28000 datapoints
2025-03-06 22:28:02,810 - INFO - training batch 201, loss: 1.577, 6432/28000 datapoints
2025-03-06 22:28:03,004 - INFO - training batch 251, loss: 1.253, 8032/28000 datapoints
2025-03-06 22:28:03,179 - INFO - training batch 301, loss: 1.520, 9632/28000 datapoints
2025-03-06 22:28:03,355 - INFO - training batch 351, loss: 1.460, 11232/28000 datapoints
2025-03-06 22:28:03,534 - INFO - training batch 401, loss: 1.412, 12832/28000 datapoints
2025-03-06 22:28:03,714 - INFO - training batch 451, loss: 1.396, 14432/28000 datapoints
2025-03-06 22:28:03,893 - INFO - training batch 501, loss: 1.194, 16032/28000 datapoints
2025-03-06 22:28:04,074 - INFO - training batch 551, loss: 1.421, 17632/28000 datapoints
2025-03-06 22:28:04,252 - INFO - training batch 601, loss: 1.433, 19232/28000 datapoints
2025-03-06 22:28:04,431 - INFO - training batch 651, loss: 1.008, 20832/28000 datapoints
2025-03-06 22:28:04,610 - INFO - training batch 701, loss: 1.224, 22432/28000 datapoints
2025-03-06 22:28:04,791 - INFO - training batch 751, loss: 1.470, 24032/28000 datapoints
2025-03-06 22:28:04,977 - INFO - training batch 801, loss: 1.181, 25632/28000 datapoints
2025-03-06 22:28:05,164 - INFO - training batch 851, loss: 1.358, 27232/28000 datapoints
2025-03-06 22:28:05,257 - INFO - validation batch 1, loss: 1.008, 32/6976 datapoints
2025-03-06 22:28:05,316 - INFO - validation batch 51, loss: 1.769, 1632/6976 datapoints
2025-03-06 22:28:05,377 - INFO - validation batch 101, loss: 1.324, 3232/6976 datapoints
2025-03-06 22:28:05,441 - INFO - validation batch 151, loss: 1.619, 4832/6976 datapoints
2025-03-06 22:28:05,502 - INFO - validation batch 201, loss: 0.876, 6432/6976 datapoints
2025-03-06 22:28:05,522 - INFO - Epoch 39/800 done.
2025-03-06 22:28:05,522 - INFO - Final validation performance:
Loss: 1.319, top-1 acc: 0.504top-5 acc: 0.504
2025-03-06 22:28:05,523 - INFO - Beginning epoch 40/800
2025-03-06 22:28:05,528 - INFO - training batch 1, loss: 1.560, 32/28000 datapoints
2025-03-06 22:28:05,719 - INFO - training batch 51, loss: 1.553, 1632/28000 datapoints
2025-03-06 22:28:05,914 - INFO - training batch 101, loss: 1.161, 3232/28000 datapoints
2025-03-06 22:28:06,107 - INFO - training batch 151, loss: 1.623, 4832/28000 datapoints
2025-03-06 22:28:06,293 - INFO - training batch 201, loss: 1.573, 6432/28000 datapoints
2025-03-06 22:28:06,476 - INFO - training batch 251, loss: 1.246, 8032/28000 datapoints
2025-03-06 22:28:06,659 - INFO - training batch 301, loss: 1.516, 9632/28000 datapoints
2025-03-06 22:28:06,840 - INFO - training batch 351, loss: 1.453, 11232/28000 datapoints
2025-03-06 22:28:07,029 - INFO - training batch 401, loss: 1.408, 12832/28000 datapoints
2025-03-06 22:28:07,219 - INFO - training batch 451, loss: 1.394, 14432/28000 datapoints
2025-03-06 22:28:07,384 - INFO - training batch 501, loss: 1.194, 16032/28000 datapoints
2025-03-06 22:28:07,545 - INFO - training batch 551, loss: 1.416, 17632/28000 datapoints
2025-03-06 22:28:07,707 - INFO - training batch 601, loss: 1.430, 19232/28000 datapoints
2025-03-06 22:28:07,871 - INFO - training batch 651, loss: 1.005, 20832/28000 datapoints
2025-03-06 22:28:08,035 - INFO - training batch 701, loss: 1.221, 22432/28000 datapoints
2025-03-06 22:28:08,190 - INFO - training batch 751, loss: 1.467, 24032/28000 datapoints
2025-03-06 22:28:08,358 - INFO - training batch 801, loss: 1.175, 25632/28000 datapoints
2025-03-06 22:28:08,541 - INFO - training batch 851, loss: 1.358, 27232/28000 datapoints
2025-03-06 22:28:08,628 - INFO - validation batch 1, loss: 1.006, 32/6976 datapoints
2025-03-06 22:28:08,680 - INFO - validation batch 51, loss: 1.768, 1632/6976 datapoints
2025-03-06 22:28:08,732 - INFO - validation batch 101, loss: 1.320, 3232/6976 datapoints
2025-03-06 22:28:08,782 - INFO - validation batch 151, loss: 1.614, 4832/6976 datapoints
2025-03-06 22:28:08,834 - INFO - validation batch 201, loss: 0.872, 6432/6976 datapoints
2025-03-06 22:28:08,851 - INFO - Epoch 40/800 done.
2025-03-06 22:28:08,851 - INFO - Final validation performance:
Loss: 1.316, top-1 acc: 0.505top-5 acc: 0.505
2025-03-06 22:28:08,852 - INFO - Beginning epoch 41/800
2025-03-06 22:28:08,856 - INFO - training batch 1, loss: 1.551, 32/28000 datapoints
2025-03-06 22:28:09,025 - INFO - training batch 51, loss: 1.549, 1632/28000 datapoints
2025-03-06 22:28:09,181 - INFO - training batch 101, loss: 1.154, 3232/28000 datapoints
2025-03-06 22:28:09,364 - INFO - training batch 151, loss: 1.619, 4832/28000 datapoints
2025-03-06 22:28:09,546 - INFO - training batch 201, loss: 1.567, 6432/28000 datapoints
2025-03-06 22:28:09,704 - INFO - training batch 251, loss: 1.239, 8032/28000 datapoints
2025-03-06 22:28:09,865 - INFO - training batch 301, loss: 1.513, 9632/28000 datapoints
2025-03-06 22:28:10,030 - INFO - training batch 351, loss: 1.445, 11232/28000 datapoints
2025-03-06 22:28:10,187 - INFO - training batch 401, loss: 1.404, 12832/28000 datapoints
2025-03-06 22:28:10,345 - INFO - training batch 451, loss: 1.391, 14432/28000 datapoints
2025-03-06 22:28:10,500 - INFO - training batch 501, loss: 1.193, 16032/28000 datapoints
2025-03-06 22:28:10,657 - INFO - training batch 551, loss: 1.412, 17632/28000 datapoints
2025-03-06 22:28:10,821 - INFO - training batch 601, loss: 1.427, 19232/28000 datapoints
2025-03-06 22:28:10,986 - INFO - training batch 651, loss: 1.002, 20832/28000 datapoints
2025-03-06 22:28:11,142 - INFO - training batch 701, loss: 1.217, 22432/28000 datapoints
2025-03-06 22:28:11,294 - INFO - training batch 751, loss: 1.463, 24032/28000 datapoints
2025-03-06 22:28:11,446 - INFO - training batch 801, loss: 1.169, 25632/28000 datapoints
2025-03-06 22:28:11,604 - INFO - training batch 851, loss: 1.357, 27232/28000 datapoints
2025-03-06 22:28:11,681 - INFO - validation batch 1, loss: 1.004, 32/6976 datapoints
2025-03-06 22:28:11,731 - INFO - validation batch 51, loss: 1.768, 1632/6976 datapoints
2025-03-06 22:28:11,781 - INFO - validation batch 101, loss: 1.315, 3232/6976 datapoints
2025-03-06 22:28:11,831 - INFO - validation batch 151, loss: 1.609, 4832/6976 datapoints
2025-03-06 22:28:11,880 - INFO - validation batch 201, loss: 0.869, 6432/6976 datapoints
2025-03-06 22:28:11,901 - INFO - Epoch 41/800 done.
2025-03-06 22:28:11,901 - INFO - Final validation performance:
Loss: 1.313, top-1 acc: 0.507top-5 acc: 0.507
2025-03-06 22:28:11,902 - INFO - Beginning epoch 42/800
2025-03-06 22:28:11,906 - INFO - training batch 1, loss: 1.542, 32/28000 datapoints
2025-03-06 22:28:12,066 - INFO - training batch 51, loss: 1.544, 1632/28000 datapoints
2025-03-06 22:28:12,221 - INFO - training batch 101, loss: 1.146, 3232/28000 datapoints
2025-03-06 22:28:12,377 - INFO - training batch 151, loss: 1.614, 4832/28000 datapoints
2025-03-06 22:28:12,530 - INFO - training batch 201, loss: 1.561, 6432/28000 datapoints
2025-03-06 22:28:12,694 - INFO - training batch 251, loss: 1.233, 8032/28000 datapoints
2025-03-06 22:28:12,847 - INFO - training batch 301, loss: 1.509, 9632/28000 datapoints
2025-03-06 22:28:13,007 - INFO - training batch 351, loss: 1.437, 11232/28000 datapoints
2025-03-06 22:28:13,185 - INFO - training batch 401, loss: 1.399, 12832/28000 datapoints
2025-03-06 22:28:13,373 - INFO - training batch 451, loss: 1.389, 14432/28000 datapoints
2025-03-06 22:28:13,556 - INFO - training batch 501, loss: 1.193, 16032/28000 datapoints
2025-03-06 22:28:13,744 - INFO - training batch 551, loss: 1.408, 17632/28000 datapoints
2025-03-06 22:28:13,908 - INFO - training batch 601, loss: 1.424, 19232/28000 datapoints
2025-03-06 22:28:14,068 - INFO - training batch 651, loss: 0.998, 20832/28000 datapoints
2025-03-06 22:28:14,224 - INFO - training batch 701, loss: 1.213, 22432/28000 datapoints
2025-03-06 22:28:14,380 - INFO - training batch 751, loss: 1.459, 24032/28000 datapoints
2025-03-06 22:28:14,539 - INFO - training batch 801, loss: 1.163, 25632/28000 datapoints
2025-03-06 22:28:14,696 - INFO - training batch 851, loss: 1.355, 27232/28000 datapoints
2025-03-06 22:28:14,777 - INFO - validation batch 1, loss: 1.002, 32/6976 datapoints
2025-03-06 22:28:14,830 - INFO - validation batch 51, loss: 1.768, 1632/6976 datapoints
2025-03-06 22:28:14,883 - INFO - validation batch 101, loss: 1.310, 3232/6976 datapoints
2025-03-06 22:28:14,945 - INFO - validation batch 151, loss: 1.604, 4832/6976 datapoints
2025-03-06 22:28:15,004 - INFO - validation batch 201, loss: 0.866, 6432/6976 datapoints
2025-03-06 22:28:15,022 - INFO - Epoch 42/800 done.
2025-03-06 22:28:15,022 - INFO - Final validation performance:
Loss: 1.310, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 22:28:15,023 - INFO - Beginning epoch 43/800
2025-03-06 22:28:15,027 - INFO - training batch 1, loss: 1.533, 32/28000 datapoints
2025-03-06 22:28:15,201 - INFO - training batch 51, loss: 1.540, 1632/28000 datapoints
2025-03-06 22:28:15,363 - INFO - training batch 101, loss: 1.140, 3232/28000 datapoints
2025-03-06 22:28:15,531 - INFO - training batch 151, loss: 1.611, 4832/28000 datapoints
2025-03-06 22:28:15,693 - INFO - training batch 201, loss: 1.556, 6432/28000 datapoints
2025-03-06 22:28:15,860 - INFO - training batch 251, loss: 1.227, 8032/28000 datapoints
2025-03-06 22:28:16,031 - INFO - training batch 301, loss: 1.506, 9632/28000 datapoints
2025-03-06 22:28:16,196 - INFO - training batch 351, loss: 1.428, 11232/28000 datapoints
2025-03-06 22:28:16,363 - INFO - training batch 401, loss: 1.394, 12832/28000 datapoints
2025-03-06 22:28:16,536 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 22:28:16,703 - INFO - training batch 501, loss: 1.192, 16032/28000 datapoints
2025-03-06 22:28:16,870 - INFO - training batch 551, loss: 1.404, 17632/28000 datapoints
2025-03-06 22:28:17,044 - INFO - training batch 601, loss: 1.421, 19232/28000 datapoints
2025-03-06 22:28:17,217 - INFO - training batch 651, loss: 0.994, 20832/28000 datapoints
2025-03-06 22:28:17,388 - INFO - training batch 701, loss: 1.209, 22432/28000 datapoints
2025-03-06 22:28:17,564 - INFO - training batch 751, loss: 1.455, 24032/28000 datapoints
2025-03-06 22:28:17,740 - INFO - training batch 801, loss: 1.156, 25632/28000 datapoints
2025-03-06 22:28:17,922 - INFO - training batch 851, loss: 1.353, 27232/28000 datapoints
2025-03-06 22:28:18,011 - INFO - validation batch 1, loss: 0.999, 32/6976 datapoints
2025-03-06 22:28:18,069 - INFO - validation batch 51, loss: 1.767, 1632/6976 datapoints
2025-03-06 22:28:18,140 - INFO - validation batch 101, loss: 1.305, 3232/6976 datapoints
2025-03-06 22:28:18,203 - INFO - validation batch 151, loss: 1.597, 4832/6976 datapoints
2025-03-06 22:28:18,268 - INFO - validation batch 201, loss: 0.863, 6432/6976 datapoints
2025-03-06 22:28:18,293 - INFO - Epoch 43/800 done.
2025-03-06 22:28:18,293 - INFO - Final validation performance:
Loss: 1.306, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 22:28:18,294 - INFO - Beginning epoch 44/800
2025-03-06 22:28:18,299 - INFO - training batch 1, loss: 1.524, 32/28000 datapoints
2025-03-06 22:28:18,498 - INFO - training batch 51, loss: 1.535, 1632/28000 datapoints
2025-03-06 22:28:18,731 - INFO - training batch 101, loss: 1.132, 3232/28000 datapoints
2025-03-06 22:28:18,933 - INFO - training batch 151, loss: 1.607, 4832/28000 datapoints
2025-03-06 22:28:19,132 - INFO - training batch 201, loss: 1.551, 6432/28000 datapoints
2025-03-06 22:28:19,326 - INFO - training batch 251, loss: 1.220, 8032/28000 datapoints
2025-03-06 22:28:19,528 - INFO - training batch 301, loss: 1.503, 9632/28000 datapoints
2025-03-06 22:28:19,727 - INFO - training batch 351, loss: 1.419, 11232/28000 datapoints
2025-03-06 22:28:19,925 - INFO - training batch 401, loss: 1.389, 12832/28000 datapoints
2025-03-06 22:28:20,120 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 22:28:20,313 - INFO - training batch 501, loss: 1.191, 16032/28000 datapoints
2025-03-06 22:28:20,512 - INFO - training batch 551, loss: 1.401, 17632/28000 datapoints
2025-03-06 22:28:20,709 - INFO - training batch 601, loss: 1.419, 19232/28000 datapoints
2025-03-06 22:28:20,909 - INFO - training batch 651, loss: 0.989, 20832/28000 datapoints
2025-03-06 22:28:21,110 - INFO - training batch 701, loss: 1.205, 22432/28000 datapoints
2025-03-06 22:28:21,307 - INFO - training batch 751, loss: 1.450, 24032/28000 datapoints
2025-03-06 22:28:21,500 - INFO - training batch 801, loss: 1.149, 25632/28000 datapoints
2025-03-06 22:28:21,699 - INFO - training batch 851, loss: 1.351, 27232/28000 datapoints
2025-03-06 22:28:21,799 - INFO - validation batch 1, loss: 0.997, 32/6976 datapoints
2025-03-06 22:28:21,865 - INFO - validation batch 51, loss: 1.767, 1632/6976 datapoints
2025-03-06 22:28:21,937 - INFO - validation batch 101, loss: 1.300, 3232/6976 datapoints
2025-03-06 22:28:22,008 - INFO - validation batch 151, loss: 1.591, 4832/6976 datapoints
2025-03-06 22:28:22,085 - INFO - validation batch 201, loss: 0.860, 6432/6976 datapoints
2025-03-06 22:28:22,107 - INFO - Epoch 44/800 done.
2025-03-06 22:28:22,107 - INFO - Final validation performance:
Loss: 1.303, top-1 acc: 0.512top-5 acc: 0.512
2025-03-06 22:28:22,108 - INFO - Beginning epoch 45/800
2025-03-06 22:28:22,113 - INFO - training batch 1, loss: 1.515, 32/28000 datapoints
2025-03-06 22:28:22,316 - INFO - training batch 51, loss: 1.531, 1632/28000 datapoints
2025-03-06 22:28:22,513 - INFO - training batch 101, loss: 1.125, 3232/28000 datapoints
2025-03-06 22:28:22,709 - INFO - training batch 151, loss: 1.603, 4832/28000 datapoints
2025-03-06 22:28:22,906 - INFO - training batch 201, loss: 1.546, 6432/28000 datapoints
2025-03-06 22:28:23,124 - INFO - training batch 251, loss: 1.214, 8032/28000 datapoints
2025-03-06 22:28:23,319 - INFO - training batch 301, loss: 1.500, 9632/28000 datapoints
2025-03-06 22:28:23,516 - INFO - training batch 351, loss: 1.410, 11232/28000 datapoints
2025-03-06 22:28:23,711 - INFO - training batch 401, loss: 1.385, 12832/28000 datapoints
2025-03-06 22:28:23,907 - INFO - training batch 451, loss: 1.380, 14432/28000 datapoints
2025-03-06 22:28:24,103 - INFO - training batch 501, loss: 1.190, 16032/28000 datapoints
2025-03-06 22:28:24,298 - INFO - training batch 551, loss: 1.398, 17632/28000 datapoints
2025-03-06 22:28:24,494 - INFO - training batch 601, loss: 1.417, 19232/28000 datapoints
2025-03-06 22:28:24,693 - INFO - training batch 651, loss: 0.984, 20832/28000 datapoints
2025-03-06 22:28:24,892 - INFO - training batch 701, loss: 1.200, 22432/28000 datapoints
2025-03-06 22:28:25,093 - INFO - training batch 751, loss: 1.444, 24032/28000 datapoints
2025-03-06 22:28:25,296 - INFO - training batch 801, loss: 1.142, 25632/28000 datapoints
2025-03-06 22:28:25,504 - INFO - training batch 851, loss: 1.349, 27232/28000 datapoints
2025-03-06 22:28:25,604 - INFO - validation batch 1, loss: 0.994, 32/6976 datapoints
2025-03-06 22:28:25,671 - INFO - validation batch 51, loss: 1.767, 1632/6976 datapoints
2025-03-06 22:28:25,740 - INFO - validation batch 101, loss: 1.295, 3232/6976 datapoints
2025-03-06 22:28:25,806 - INFO - validation batch 151, loss: 1.585, 4832/6976 datapoints
2025-03-06 22:28:25,875 - INFO - validation batch 201, loss: 0.857, 6432/6976 datapoints
2025-03-06 22:28:25,906 - INFO - Epoch 45/800 done.
2025-03-06 22:28:25,906 - INFO - Final validation performance:
Loss: 1.300, top-1 acc: 0.513top-5 acc: 0.513
2025-03-06 22:28:25,907 - INFO - Beginning epoch 46/800
2025-03-06 22:28:25,912 - INFO - training batch 1, loss: 1.506, 32/28000 datapoints
2025-03-06 22:28:26,114 - INFO - training batch 51, loss: 1.528, 1632/28000 datapoints
2025-03-06 22:28:26,314 - INFO - training batch 101, loss: 1.117, 3232/28000 datapoints
2025-03-06 22:28:26,510 - INFO - training batch 151, loss: 1.598, 4832/28000 datapoints
2025-03-06 22:28:26,716 - INFO - training batch 201, loss: 1.538, 6432/28000 datapoints
2025-03-06 22:28:26,922 - INFO - training batch 251, loss: 1.207, 8032/28000 datapoints
2025-03-06 22:28:27,127 - INFO - training batch 301, loss: 1.496, 9632/28000 datapoints
2025-03-06 22:28:27,330 - INFO - training batch 351, loss: 1.400, 11232/28000 datapoints
2025-03-06 22:28:27,529 - INFO - training batch 401, loss: 1.380, 12832/28000 datapoints
2025-03-06 22:28:27,744 - INFO - training batch 451, loss: 1.377, 14432/28000 datapoints
2025-03-06 22:28:27,947 - INFO - training batch 501, loss: 1.188, 16032/28000 datapoints
2025-03-06 22:28:28,151 - INFO - training batch 551, loss: 1.394, 17632/28000 datapoints
2025-03-06 22:28:28,346 - INFO - training batch 601, loss: 1.414, 19232/28000 datapoints
2025-03-06 22:28:28,543 - INFO - training batch 651, loss: 0.980, 20832/28000 datapoints
2025-03-06 22:28:28,800 - INFO - training batch 701, loss: 1.196, 22432/28000 datapoints
2025-03-06 22:28:28,980 - INFO - training batch 751, loss: 1.439, 24032/28000 datapoints
2025-03-06 22:28:29,160 - INFO - training batch 801, loss: 1.134, 25632/28000 datapoints
2025-03-06 22:28:29,338 - INFO - training batch 851, loss: 1.347, 27232/28000 datapoints
2025-03-06 22:28:29,426 - INFO - validation batch 1, loss: 0.992, 32/6976 datapoints
2025-03-06 22:28:29,491 - INFO - validation batch 51, loss: 1.767, 1632/6976 datapoints
2025-03-06 22:28:29,558 - INFO - validation batch 101, loss: 1.289, 3232/6976 datapoints
2025-03-06 22:28:29,620 - INFO - validation batch 151, loss: 1.577, 4832/6976 datapoints
2025-03-06 22:28:29,684 - INFO - validation batch 201, loss: 0.853, 6432/6976 datapoints
2025-03-06 22:28:29,707 - INFO - Epoch 46/800 done.
2025-03-06 22:28:29,708 - INFO - Final validation performance:
Loss: 1.296, top-1 acc: 0.513top-5 acc: 0.513
2025-03-06 22:28:29,708 - INFO - Beginning epoch 47/800
2025-03-06 22:28:29,714 - INFO - training batch 1, loss: 1.496, 32/28000 datapoints
2025-03-06 22:28:29,900 - INFO - training batch 51, loss: 1.523, 1632/28000 datapoints
2025-03-06 22:28:30,079 - INFO - training batch 101, loss: 1.109, 3232/28000 datapoints
2025-03-06 22:28:30,258 - INFO - training batch 151, loss: 1.594, 4832/28000 datapoints
2025-03-06 22:28:30,430 - INFO - training batch 201, loss: 1.534, 6432/28000 datapoints
2025-03-06 22:28:30,605 - INFO - training batch 251, loss: 1.200, 8032/28000 datapoints
2025-03-06 22:28:30,784 - INFO - training batch 301, loss: 1.492, 9632/28000 datapoints
2025-03-06 22:28:30,961 - INFO - training batch 351, loss: 1.390, 11232/28000 datapoints
2025-03-06 22:28:31,139 - INFO - training batch 401, loss: 1.375, 12832/28000 datapoints
2025-03-06 22:28:31,310 - INFO - training batch 451, loss: 1.374, 14432/28000 datapoints
2025-03-06 22:28:31,486 - INFO - training batch 501, loss: 1.187, 16032/28000 datapoints
2025-03-06 22:28:31,656 - INFO - training batch 551, loss: 1.390, 17632/28000 datapoints
2025-03-06 22:28:31,828 - INFO - training batch 601, loss: 1.411, 19232/28000 datapoints
2025-03-06 22:28:32,006 - INFO - training batch 651, loss: 0.974, 20832/28000 datapoints
2025-03-06 22:28:32,177 - INFO - training batch 701, loss: 1.191, 22432/28000 datapoints
2025-03-06 22:28:32,349 - INFO - training batch 751, loss: 1.434, 24032/28000 datapoints
2025-03-06 22:28:32,518 - INFO - training batch 801, loss: 1.125, 25632/28000 datapoints
2025-03-06 22:28:32,689 - INFO - training batch 851, loss: 1.344, 27232/28000 datapoints
2025-03-06 22:28:32,776 - INFO - validation batch 1, loss: 0.989, 32/6976 datapoints
2025-03-06 22:28:32,834 - INFO - validation batch 51, loss: 1.767, 1632/6976 datapoints
2025-03-06 22:28:32,899 - INFO - validation batch 101, loss: 1.283, 3232/6976 datapoints
2025-03-06 22:28:32,961 - INFO - validation batch 151, loss: 1.570, 4832/6976 datapoints
2025-03-06 22:28:33,026 - INFO - validation batch 201, loss: 0.849, 6432/6976 datapoints
2025-03-06 22:28:33,048 - INFO - Epoch 47/800 done.
2025-03-06 22:28:33,049 - INFO - Final validation performance:
Loss: 1.292, top-1 acc: 0.514top-5 acc: 0.514
2025-03-06 22:28:33,049 - INFO - Beginning epoch 48/800
2025-03-06 22:28:33,057 - INFO - training batch 1, loss: 1.486, 32/28000 datapoints
2025-03-06 22:28:33,232 - INFO - training batch 51, loss: 1.518, 1632/28000 datapoints
2025-03-06 22:28:33,408 - INFO - training batch 101, loss: 1.101, 3232/28000 datapoints
2025-03-06 22:28:33,577 - INFO - training batch 151, loss: 1.589, 4832/28000 datapoints
2025-03-06 22:28:33,745 - INFO - training batch 201, loss: 1.529, 6432/28000 datapoints
2025-03-06 22:28:33,921 - INFO - training batch 251, loss: 1.193, 8032/28000 datapoints
2025-03-06 22:28:34,090 - INFO - training batch 301, loss: 1.487, 9632/28000 datapoints
2025-03-06 22:28:34,258 - INFO - training batch 351, loss: 1.379, 11232/28000 datapoints
2025-03-06 22:28:34,427 - INFO - training batch 401, loss: 1.369, 12832/28000 datapoints
2025-03-06 22:28:34,592 - INFO - training batch 451, loss: 1.370, 14432/28000 datapoints
2025-03-06 22:28:34,763 - INFO - training batch 501, loss: 1.185, 16032/28000 datapoints
2025-03-06 22:28:34,938 - INFO - training batch 551, loss: 1.387, 17632/28000 datapoints
2025-03-06 22:28:35,111 - INFO - training batch 601, loss: 1.408, 19232/28000 datapoints
2025-03-06 22:28:35,292 - INFO - training batch 651, loss: 0.968, 20832/28000 datapoints
2025-03-06 22:28:35,460 - INFO - training batch 701, loss: 1.186, 22432/28000 datapoints
2025-03-06 22:28:35,629 - INFO - training batch 751, loss: 1.429, 24032/28000 datapoints
2025-03-06 22:28:35,804 - INFO - training batch 801, loss: 1.117, 25632/28000 datapoints
2025-03-06 22:28:35,984 - INFO - training batch 851, loss: 1.342, 27232/28000 datapoints
2025-03-06 22:28:36,069 - INFO - validation batch 1, loss: 0.986, 32/6976 datapoints
2025-03-06 22:28:36,133 - INFO - validation batch 51, loss: 1.768, 1632/6976 datapoints
2025-03-06 22:28:36,193 - INFO - validation batch 101, loss: 1.276, 3232/6976 datapoints
2025-03-06 22:28:36,254 - INFO - validation batch 151, loss: 1.563, 4832/6976 datapoints
2025-03-06 22:28:36,322 - INFO - validation batch 201, loss: 0.846, 6432/6976 datapoints
2025-03-06 22:28:36,350 - INFO - Epoch 48/800 done.
2025-03-06 22:28:36,350 - INFO - Final validation performance:
Loss: 1.288, top-1 acc: 0.517top-5 acc: 0.517
2025-03-06 22:28:36,351 - INFO - Beginning epoch 49/800
2025-03-06 22:28:36,355 - INFO - training batch 1, loss: 1.476, 32/28000 datapoints
2025-03-06 22:28:36,546 - INFO - training batch 51, loss: 1.513, 1632/28000 datapoints
2025-03-06 22:28:36,740 - INFO - training batch 101, loss: 1.092, 3232/28000 datapoints
2025-03-06 22:28:36,935 - INFO - training batch 151, loss: 1.585, 4832/28000 datapoints
2025-03-06 22:28:37,133 - INFO - training batch 201, loss: 1.524, 6432/28000 datapoints
2025-03-06 22:28:37,323 - INFO - training batch 251, loss: 1.187, 8032/28000 datapoints
2025-03-06 22:28:37,520 - INFO - training batch 301, loss: 1.482, 9632/28000 datapoints
2025-03-06 22:28:37,713 - INFO - training batch 351, loss: 1.367, 11232/28000 datapoints
2025-03-06 22:28:37,922 - INFO - training batch 401, loss: 1.364, 12832/28000 datapoints
2025-03-06 22:28:38,119 - INFO - training batch 451, loss: 1.366, 14432/28000 datapoints
2025-03-06 22:28:38,319 - INFO - training batch 501, loss: 1.183, 16032/28000 datapoints
2025-03-06 22:28:38,518 - INFO - training batch 551, loss: 1.383, 17632/28000 datapoints
2025-03-06 22:28:38,708 - INFO - training batch 601, loss: 1.405, 19232/28000 datapoints
2025-03-06 22:28:38,941 - INFO - training batch 651, loss: 0.961, 20832/28000 datapoints
2025-03-06 22:28:39,142 - INFO - training batch 701, loss: 1.182, 22432/28000 datapoints
2025-03-06 22:28:39,351 - INFO - training batch 751, loss: 1.424, 24032/28000 datapoints
2025-03-06 22:28:39,550 - INFO - training batch 801, loss: 1.108, 25632/28000 datapoints
2025-03-06 22:28:39,751 - INFO - training batch 851, loss: 1.340, 27232/28000 datapoints
2025-03-06 22:28:39,852 - INFO - validation batch 1, loss: 0.982, 32/6976 datapoints
2025-03-06 22:28:39,923 - INFO - validation batch 51, loss: 1.768, 1632/6976 datapoints
2025-03-06 22:28:39,991 - INFO - validation batch 101, loss: 1.270, 3232/6976 datapoints
2025-03-06 22:28:40,059 - INFO - validation batch 151, loss: 1.555, 4832/6976 datapoints
2025-03-06 22:28:40,125 - INFO - validation batch 201, loss: 0.843, 6432/6976 datapoints
2025-03-06 22:28:40,153 - INFO - Epoch 49/800 done.
2025-03-06 22:28:40,153 - INFO - Final validation performance:
Loss: 1.284, top-1 acc: 0.519top-5 acc: 0.519
2025-03-06 22:28:40,154 - INFO - Beginning epoch 50/800
2025-03-06 22:28:40,159 - INFO - training batch 1, loss: 1.465, 32/28000 datapoints
2025-03-06 22:28:40,365 - INFO - training batch 51, loss: 1.508, 1632/28000 datapoints
2025-03-06 22:28:40,563 - INFO - training batch 101, loss: 1.082, 3232/28000 datapoints
2025-03-06 22:28:40,764 - INFO - training batch 151, loss: 1.580, 4832/28000 datapoints
2025-03-06 22:28:40,967 - INFO - training batch 201, loss: 1.518, 6432/28000 datapoints
2025-03-06 22:28:41,167 - INFO - training batch 251, loss: 1.179, 8032/28000 datapoints
2025-03-06 22:28:41,366 - INFO - training batch 301, loss: 1.477, 9632/28000 datapoints
2025-03-06 22:28:41,559 - INFO - training batch 351, loss: 1.354, 11232/28000 datapoints
2025-03-06 22:28:41,763 - INFO - training batch 401, loss: 1.357, 12832/28000 datapoints
2025-03-06 22:28:41,970 - INFO - training batch 451, loss: 1.362, 14432/28000 datapoints
2025-03-06 22:28:42,170 - INFO - training batch 501, loss: 1.181, 16032/28000 datapoints
2025-03-06 22:28:42,374 - INFO - training batch 551, loss: 1.379, 17632/28000 datapoints
2025-03-06 22:28:42,568 - INFO - training batch 601, loss: 1.402, 19232/28000 datapoints
2025-03-06 22:28:42,770 - INFO - training batch 651, loss: 0.954, 20832/28000 datapoints
2025-03-06 22:28:42,971 - INFO - training batch 701, loss: 1.176, 22432/28000 datapoints
2025-03-06 22:28:43,171 - INFO - training batch 751, loss: 1.418, 24032/28000 datapoints
2025-03-06 22:28:43,373 - INFO - training batch 801, loss: 1.098, 25632/28000 datapoints
2025-03-06 22:28:43,588 - INFO - training batch 851, loss: 1.337, 27232/28000 datapoints
2025-03-06 22:28:43,696 - INFO - validation batch 1, loss: 0.979, 32/6976 datapoints
2025-03-06 22:28:43,782 - INFO - validation batch 51, loss: 1.768, 1632/6976 datapoints
2025-03-06 22:28:43,859 - INFO - validation batch 101, loss: 1.263, 3232/6976 datapoints
2025-03-06 22:28:43,945 - INFO - validation batch 151, loss: 1.545, 4832/6976 datapoints
2025-03-06 22:28:44,017 - INFO - validation batch 201, loss: 0.838, 6432/6976 datapoints
2025-03-06 22:28:44,042 - INFO - Epoch 50/800 done.
2025-03-06 22:28:44,042 - INFO - Final validation performance:
Loss: 1.279, top-1 acc: 0.522top-5 acc: 0.522
2025-03-06 22:28:44,042 - INFO - Beginning epoch 51/800
2025-03-06 22:28:44,051 - INFO - training batch 1, loss: 1.454, 32/28000 datapoints
2025-03-06 22:28:44,244 - INFO - training batch 51, loss: 1.501, 1632/28000 datapoints
2025-03-06 22:28:44,435 - INFO - training batch 101, loss: 1.073, 3232/28000 datapoints
2025-03-06 22:28:44,652 - INFO - training batch 151, loss: 1.575, 4832/28000 datapoints
2025-03-06 22:28:44,864 - INFO - training batch 201, loss: 1.512, 6432/28000 datapoints
2025-03-06 22:28:45,055 - INFO - training batch 251, loss: 1.172, 8032/28000 datapoints
2025-03-06 22:28:45,259 - INFO - training batch 301, loss: 1.472, 9632/28000 datapoints
2025-03-06 22:28:45,448 - INFO - training batch 351, loss: 1.340, 11232/28000 datapoints
2025-03-06 22:28:45,630 - INFO - training batch 401, loss: 1.352, 12832/28000 datapoints
2025-03-06 22:28:45,807 - INFO - training batch 451, loss: 1.359, 14432/28000 datapoints
2025-03-06 22:28:45,988 - INFO - training batch 501, loss: 1.178, 16032/28000 datapoints
2025-03-06 22:28:46,172 - INFO - training batch 551, loss: 1.376, 17632/28000 datapoints
2025-03-06 22:28:46,344 - INFO - training batch 601, loss: 1.398, 19232/28000 datapoints
2025-03-06 22:28:46,514 - INFO - training batch 651, loss: 0.947, 20832/28000 datapoints
2025-03-06 22:28:46,684 - INFO - training batch 701, loss: 1.170, 22432/28000 datapoints
2025-03-06 22:28:46,855 - INFO - training batch 751, loss: 1.413, 24032/28000 datapoints
2025-03-06 22:28:47,029 - INFO - training batch 801, loss: 1.088, 25632/28000 datapoints
2025-03-06 22:28:47,200 - INFO - training batch 851, loss: 1.334, 27232/28000 datapoints
2025-03-06 22:28:47,281 - INFO - validation batch 1, loss: 0.975, 32/6976 datapoints
2025-03-06 22:28:47,334 - INFO - validation batch 51, loss: 1.769, 1632/6976 datapoints
2025-03-06 22:28:47,385 - INFO - validation batch 101, loss: 1.256, 3232/6976 datapoints
2025-03-06 22:28:47,437 - INFO - validation batch 151, loss: 1.535, 4832/6976 datapoints
2025-03-06 22:28:47,490 - INFO - validation batch 201, loss: 0.833, 6432/6976 datapoints
2025-03-06 22:28:47,507 - INFO - Epoch 51/800 done.
2025-03-06 22:28:47,508 - INFO - Final validation performance:
Loss: 1.274, top-1 acc: 0.523top-5 acc: 0.523
2025-03-06 22:28:47,508 - INFO - Beginning epoch 52/800
2025-03-06 22:28:47,513 - INFO - training batch 1, loss: 1.442, 32/28000 datapoints
2025-03-06 22:28:47,678 - INFO - training batch 51, loss: 1.494, 1632/28000 datapoints
2025-03-06 22:28:47,852 - INFO - training batch 101, loss: 1.062, 3232/28000 datapoints
2025-03-06 22:28:48,023 - INFO - training batch 151, loss: 1.569, 4832/28000 datapoints
2025-03-06 22:28:48,187 - INFO - training batch 201, loss: 1.505, 6432/28000 datapoints
2025-03-06 22:28:48,358 - INFO - training batch 251, loss: 1.164, 8032/28000 datapoints
2025-03-06 22:28:48,509 - INFO - training batch 301, loss: 1.466, 9632/28000 datapoints
2025-03-06 22:28:48,663 - INFO - training batch 351, loss: 1.326, 11232/28000 datapoints
2025-03-06 22:28:48,818 - INFO - training batch 401, loss: 1.346, 12832/28000 datapoints
2025-03-06 22:28:49,000 - INFO - training batch 451, loss: 1.354, 14432/28000 datapoints
2025-03-06 22:28:49,156 - INFO - training batch 501, loss: 1.175, 16032/28000 datapoints
2025-03-06 22:28:49,298 - INFO - training batch 551, loss: 1.372, 17632/28000 datapoints
2025-03-06 22:28:49,445 - INFO - training batch 601, loss: 1.394, 19232/28000 datapoints
2025-03-06 22:28:49,594 - INFO - training batch 651, loss: 0.939, 20832/28000 datapoints
2025-03-06 22:28:49,738 - INFO - training batch 701, loss: 1.164, 22432/28000 datapoints
2025-03-06 22:28:49,881 - INFO - training batch 751, loss: 1.406, 24032/28000 datapoints
2025-03-06 22:28:50,028 - INFO - training batch 801, loss: 1.077, 25632/28000 datapoints
2025-03-06 22:28:50,174 - INFO - training batch 851, loss: 1.331, 27232/28000 datapoints
2025-03-06 22:28:50,246 - INFO - validation batch 1, loss: 0.970, 32/6976 datapoints
2025-03-06 22:28:50,294 - INFO - validation batch 51, loss: 1.768, 1632/6976 datapoints
2025-03-06 22:28:50,341 - INFO - validation batch 101, loss: 1.248, 3232/6976 datapoints
2025-03-06 22:28:50,388 - INFO - validation batch 151, loss: 1.521, 4832/6976 datapoints
2025-03-06 22:28:50,439 - INFO - validation batch 201, loss: 0.829, 6432/6976 datapoints
2025-03-06 22:28:50,455 - INFO - Epoch 52/800 done.
2025-03-06 22:28:50,456 - INFO - Final validation performance:
Loss: 1.268, top-1 acc: 0.527top-5 acc: 0.527
2025-03-06 22:28:50,456 - INFO - Beginning epoch 53/800
2025-03-06 22:28:50,460 - INFO - training batch 1, loss: 1.430, 32/28000 datapoints
2025-03-06 22:28:50,615 - INFO - training batch 51, loss: 1.488, 1632/28000 datapoints
2025-03-06 22:28:50,765 - INFO - training batch 101, loss: 1.053, 3232/28000 datapoints
2025-03-06 22:28:50,917 - INFO - training batch 151, loss: 1.564, 4832/28000 datapoints
2025-03-06 22:28:51,069 - INFO - training batch 201, loss: 1.498, 6432/28000 datapoints
2025-03-06 22:28:51,223 - INFO - training batch 251, loss: 1.157, 8032/28000 datapoints
2025-03-06 22:28:51,368 - INFO - training batch 301, loss: 1.459, 9632/28000 datapoints
2025-03-06 22:28:51,513 - INFO - training batch 351, loss: 1.310, 11232/28000 datapoints
2025-03-06 22:28:51,656 - INFO - training batch 401, loss: 1.339, 12832/28000 datapoints
2025-03-06 22:28:51,800 - INFO - training batch 451, loss: 1.348, 14432/28000 datapoints
2025-03-06 22:28:51,948 - INFO - training batch 501, loss: 1.172, 16032/28000 datapoints
2025-03-06 22:28:52,097 - INFO - training batch 551, loss: 1.368, 17632/28000 datapoints
2025-03-06 22:28:52,262 - INFO - training batch 601, loss: 1.389, 19232/28000 datapoints
2025-03-06 22:28:52,410 - INFO - training batch 651, loss: 0.932, 20832/28000 datapoints
2025-03-06 22:28:52,560 - INFO - training batch 701, loss: 1.159, 22432/28000 datapoints
2025-03-06 22:28:52,709 - INFO - training batch 751, loss: 1.399, 24032/28000 datapoints
2025-03-06 22:28:52,857 - INFO - training batch 801, loss: 1.066, 25632/28000 datapoints
2025-03-06 22:28:53,009 - INFO - training batch 851, loss: 1.328, 27232/28000 datapoints
2025-03-06 22:28:53,083 - INFO - validation batch 1, loss: 0.966, 32/6976 datapoints
2025-03-06 22:28:53,135 - INFO - validation batch 51, loss: 1.767, 1632/6976 datapoints
2025-03-06 22:28:53,183 - INFO - validation batch 101, loss: 1.241, 3232/6976 datapoints
2025-03-06 22:28:53,230 - INFO - validation batch 151, loss: 1.508, 4832/6976 datapoints
2025-03-06 22:28:53,277 - INFO - validation batch 201, loss: 0.825, 6432/6976 datapoints
2025-03-06 22:28:53,293 - INFO - Epoch 53/800 done.
2025-03-06 22:28:53,293 - INFO - Final validation performance:
Loss: 1.261, top-1 acc: 0.530top-5 acc: 0.530
2025-03-06 22:28:53,294 - INFO - Beginning epoch 54/800
2025-03-06 22:28:53,298 - INFO - training batch 1, loss: 1.417, 32/28000 datapoints
2025-03-06 22:28:53,445 - INFO - training batch 51, loss: 1.479, 1632/28000 datapoints
2025-03-06 22:28:53,597 - INFO - training batch 101, loss: 1.042, 3232/28000 datapoints
2025-03-06 22:28:53,744 - INFO - training batch 151, loss: 1.559, 4832/28000 datapoints
2025-03-06 22:28:53,892 - INFO - training batch 201, loss: 1.492, 6432/28000 datapoints
2025-03-06 22:28:54,044 - INFO - training batch 251, loss: 1.149, 8032/28000 datapoints
2025-03-06 22:28:54,192 - INFO - training batch 301, loss: 1.452, 9632/28000 datapoints
2025-03-06 22:28:54,352 - INFO - training batch 351, loss: 1.294, 11232/28000 datapoints
2025-03-06 22:28:54,501 - INFO - training batch 401, loss: 1.332, 12832/28000 datapoints
2025-03-06 22:28:54,649 - INFO - training batch 451, loss: 1.342, 14432/28000 datapoints
2025-03-06 22:28:54,803 - INFO - training batch 501, loss: 1.168, 16032/28000 datapoints
2025-03-06 22:28:54,955 - INFO - training batch 551, loss: 1.364, 17632/28000 datapoints
2025-03-06 22:28:55,107 - INFO - training batch 601, loss: 1.385, 19232/28000 datapoints
2025-03-06 22:28:55,264 - INFO - training batch 651, loss: 0.923, 20832/28000 datapoints
2025-03-06 22:28:55,414 - INFO - training batch 701, loss: 1.152, 22432/28000 datapoints
2025-03-06 22:28:55,565 - INFO - training batch 751, loss: 1.391, 24032/28000 datapoints
2025-03-06 22:28:55,713 - INFO - training batch 801, loss: 1.054, 25632/28000 datapoints
2025-03-06 22:28:55,862 - INFO - training batch 851, loss: 1.324, 27232/28000 datapoints
2025-03-06 22:28:55,937 - INFO - validation batch 1, loss: 0.962, 32/6976 datapoints
2025-03-06 22:28:55,986 - INFO - validation batch 51, loss: 1.765, 1632/6976 datapoints
2025-03-06 22:28:56,034 - INFO - validation batch 101, loss: 1.233, 3232/6976 datapoints
2025-03-06 22:28:56,082 - INFO - validation batch 151, loss: 1.494, 4832/6976 datapoints
2025-03-06 22:28:56,130 - INFO - validation batch 201, loss: 0.821, 6432/6976 datapoints
2025-03-06 22:28:56,146 - INFO - Epoch 54/800 done.
2025-03-06 22:28:56,146 - INFO - Final validation performance:
Loss: 1.255, top-1 acc: 0.533top-5 acc: 0.533
2025-03-06 22:28:56,147 - INFO - Beginning epoch 55/800
2025-03-06 22:28:56,151 - INFO - training batch 1, loss: 1.405, 32/28000 datapoints
2025-03-06 22:28:56,300 - INFO - training batch 51, loss: 1.470, 1632/28000 datapoints
2025-03-06 22:28:56,449 - INFO - training batch 101, loss: 1.031, 3232/28000 datapoints
2025-03-06 22:28:56,599 - INFO - training batch 151, loss: 1.554, 4832/28000 datapoints
2025-03-06 22:28:56,749 - INFO - training batch 201, loss: 1.487, 6432/28000 datapoints
2025-03-06 22:28:56,897 - INFO - training batch 251, loss: 1.141, 8032/28000 datapoints
2025-03-06 22:28:57,048 - INFO - training batch 301, loss: 1.444, 9632/28000 datapoints
2025-03-06 22:28:57,201 - INFO - training batch 351, loss: 1.277, 11232/28000 datapoints
2025-03-06 22:28:57,352 - INFO - training batch 401, loss: 1.324, 12832/28000 datapoints
2025-03-06 22:28:57,499 - INFO - training batch 451, loss: 1.336, 14432/28000 datapoints
2025-03-06 22:28:57,653 - INFO - training batch 501, loss: 1.165, 16032/28000 datapoints
2025-03-06 22:28:57,803 - INFO - training batch 551, loss: 1.361, 17632/28000 datapoints
2025-03-06 22:28:57,967 - INFO - training batch 601, loss: 1.379, 19232/28000 datapoints
2025-03-06 22:28:58,121 - INFO - training batch 651, loss: 0.915, 20832/28000 datapoints
2025-03-06 22:28:58,273 - INFO - training batch 701, loss: 1.145, 22432/28000 datapoints
2025-03-06 22:28:58,423 - INFO - training batch 751, loss: 1.382, 24032/28000 datapoints
2025-03-06 22:28:58,576 - INFO - training batch 801, loss: 1.041, 25632/28000 datapoints
2025-03-06 22:28:58,732 - INFO - training batch 851, loss: 1.321, 27232/28000 datapoints
2025-03-06 22:28:58,811 - INFO - validation batch 1, loss: 0.957, 32/6976 datapoints
2025-03-06 22:28:58,862 - INFO - validation batch 51, loss: 1.764, 1632/6976 datapoints
2025-03-06 22:28:58,916 - INFO - validation batch 101, loss: 1.225, 3232/6976 datapoints
2025-03-06 22:28:58,967 - INFO - validation batch 151, loss: 1.481, 4832/6976 datapoints
2025-03-06 22:28:59,027 - INFO - validation batch 201, loss: 0.816, 6432/6976 datapoints
2025-03-06 22:28:59,056 - INFO - Epoch 55/800 done.
2025-03-06 22:28:59,056 - INFO - Final validation performance:
Loss: 1.248, top-1 acc: 0.536top-5 acc: 0.536
2025-03-06 22:28:59,057 - INFO - Beginning epoch 56/800
2025-03-06 22:28:59,062 - INFO - training batch 1, loss: 1.392, 32/28000 datapoints
2025-03-06 22:28:59,226 - INFO - training batch 51, loss: 1.459, 1632/28000 datapoints
2025-03-06 22:28:59,377 - INFO - training batch 101, loss: 1.020, 3232/28000 datapoints
2025-03-06 22:28:59,530 - INFO - training batch 151, loss: 1.547, 4832/28000 datapoints
2025-03-06 22:28:59,686 - INFO - training batch 201, loss: 1.481, 6432/28000 datapoints
2025-03-06 22:28:59,838 - INFO - training batch 251, loss: 1.132, 8032/28000 datapoints
2025-03-06 22:28:59,993 - INFO - training batch 301, loss: 1.436, 9632/28000 datapoints
2025-03-06 22:29:00,154 - INFO - training batch 351, loss: 1.260, 11232/28000 datapoints
2025-03-06 22:29:00,307 - INFO - training batch 401, loss: 1.317, 12832/28000 datapoints
2025-03-06 22:29:00,471 - INFO - training batch 451, loss: 1.330, 14432/28000 datapoints
2025-03-06 22:29:00,623 - INFO - training batch 501, loss: 1.160, 16032/28000 datapoints
2025-03-06 22:29:00,786 - INFO - training batch 551, loss: 1.357, 17632/28000 datapoints
2025-03-06 22:29:00,946 - INFO - training batch 601, loss: 1.374, 19232/28000 datapoints
2025-03-06 22:29:01,099 - INFO - training batch 651, loss: 0.905, 20832/28000 datapoints
2025-03-06 22:29:01,258 - INFO - training batch 701, loss: 1.138, 22432/28000 datapoints
2025-03-06 22:29:01,409 - INFO - training batch 751, loss: 1.371, 24032/28000 datapoints
2025-03-06 22:29:01,560 - INFO - training batch 801, loss: 1.028, 25632/28000 datapoints
2025-03-06 22:29:01,714 - INFO - training batch 851, loss: 1.317, 27232/28000 datapoints
2025-03-06 22:29:01,791 - INFO - validation batch 1, loss: 0.951, 32/6976 datapoints
2025-03-06 22:29:01,844 - INFO - validation batch 51, loss: 1.762, 1632/6976 datapoints
2025-03-06 22:29:01,900 - INFO - validation batch 101, loss: 1.215, 3232/6976 datapoints
2025-03-06 22:29:01,953 - INFO - validation batch 151, loss: 1.465, 4832/6976 datapoints
2025-03-06 22:29:02,004 - INFO - validation batch 201, loss: 0.810, 6432/6976 datapoints
2025-03-06 22:29:02,021 - INFO - Epoch 56/800 done.
2025-03-06 22:29:02,021 - INFO - Final validation performance:
Loss: 1.241, top-1 acc: 0.540top-5 acc: 0.540
2025-03-06 22:29:02,022 - INFO - Beginning epoch 57/800
2025-03-06 22:29:02,026 - INFO - training batch 1, loss: 1.379, 32/28000 datapoints
2025-03-06 22:29:02,188 - INFO - training batch 51, loss: 1.448, 1632/28000 datapoints
2025-03-06 22:29:02,340 - INFO - training batch 101, loss: 1.007, 3232/28000 datapoints
2025-03-06 22:29:02,491 - INFO - training batch 151, loss: 1.541, 4832/28000 datapoints
2025-03-06 22:29:02,643 - INFO - training batch 201, loss: 1.474, 6432/28000 datapoints
2025-03-06 22:29:02,796 - INFO - training batch 251, loss: 1.123, 8032/28000 datapoints
2025-03-06 22:29:02,951 - INFO - training batch 301, loss: 1.426, 9632/28000 datapoints
2025-03-06 22:29:03,103 - INFO - training batch 351, loss: 1.242, 11232/28000 datapoints
2025-03-06 22:29:03,259 - INFO - training batch 401, loss: 1.309, 12832/28000 datapoints
2025-03-06 22:29:03,410 - INFO - training batch 451, loss: 1.322, 14432/28000 datapoints
2025-03-06 22:29:03,567 - INFO - training batch 501, loss: 1.156, 16032/28000 datapoints
2025-03-06 22:29:03,721 - INFO - training batch 551, loss: 1.353, 17632/28000 datapoints
2025-03-06 22:29:03,871 - INFO - training batch 601, loss: 1.367, 19232/28000 datapoints
2025-03-06 22:29:04,026 - INFO - training batch 651, loss: 0.896, 20832/28000 datapoints
2025-03-06 22:29:04,181 - INFO - training batch 701, loss: 1.129, 22432/28000 datapoints
2025-03-06 22:29:04,332 - INFO - training batch 751, loss: 1.360, 24032/28000 datapoints
2025-03-06 22:29:04,483 - INFO - training batch 801, loss: 1.014, 25632/28000 datapoints
2025-03-06 22:29:04,635 - INFO - training batch 851, loss: 1.313, 27232/28000 datapoints
2025-03-06 22:29:04,712 - INFO - validation batch 1, loss: 0.945, 32/6976 datapoints
2025-03-06 22:29:04,766 - INFO - validation batch 51, loss: 1.760, 1632/6976 datapoints
2025-03-06 22:29:04,819 - INFO - validation batch 101, loss: 1.206, 3232/6976 datapoints
2025-03-06 22:29:04,872 - INFO - validation batch 151, loss: 1.450, 4832/6976 datapoints
2025-03-06 22:29:04,927 - INFO - validation batch 201, loss: 0.803, 6432/6976 datapoints
2025-03-06 22:29:04,949 - INFO - Epoch 57/800 done.
2025-03-06 22:29:04,949 - INFO - Final validation performance:
Loss: 1.233, top-1 acc: 0.544top-5 acc: 0.544
2025-03-06 22:29:04,949 - INFO - Beginning epoch 58/800
2025-03-06 22:29:04,954 - INFO - training batch 1, loss: 1.364, 32/28000 datapoints
2025-03-06 22:29:05,109 - INFO - training batch 51, loss: 1.438, 1632/28000 datapoints
2025-03-06 22:29:05,269 - INFO - training batch 101, loss: 0.992, 3232/28000 datapoints
2025-03-06 22:29:05,422 - INFO - training batch 151, loss: 1.535, 4832/28000 datapoints
2025-03-06 22:29:05,578 - INFO - training batch 201, loss: 1.464, 6432/28000 datapoints
2025-03-06 22:29:05,734 - INFO - training batch 251, loss: 1.114, 8032/28000 datapoints
2025-03-06 22:29:05,887 - INFO - training batch 301, loss: 1.414, 9632/28000 datapoints
2025-03-06 22:29:06,040 - INFO - training batch 351, loss: 1.224, 11232/28000 datapoints
2025-03-06 22:29:06,195 - INFO - training batch 401, loss: 1.301, 12832/28000 datapoints
2025-03-06 22:29:06,346 - INFO - training batch 451, loss: 1.315, 14432/28000 datapoints
2025-03-06 22:29:06,513 - INFO - training batch 501, loss: 1.150, 16032/28000 datapoints
2025-03-06 22:29:06,666 - INFO - training batch 551, loss: 1.351, 17632/28000 datapoints
2025-03-06 22:29:06,819 - INFO - training batch 601, loss: 1.360, 19232/28000 datapoints
2025-03-06 22:29:06,980 - INFO - training batch 651, loss: 0.887, 20832/28000 datapoints
2025-03-06 22:29:07,139 - INFO - training batch 701, loss: 1.121, 22432/28000 datapoints
2025-03-06 22:29:07,299 - INFO - training batch 751, loss: 1.348, 24032/28000 datapoints
2025-03-06 22:29:07,451 - INFO - training batch 801, loss: 0.999, 25632/28000 datapoints
2025-03-06 22:29:07,604 - INFO - training batch 851, loss: 1.309, 27232/28000 datapoints
2025-03-06 22:29:07,681 - INFO - validation batch 1, loss: 0.938, 32/6976 datapoints
2025-03-06 22:29:07,734 - INFO - validation batch 51, loss: 1.758, 1632/6976 datapoints
2025-03-06 22:29:07,786 - INFO - validation batch 101, loss: 1.197, 3232/6976 datapoints
2025-03-06 22:29:07,838 - INFO - validation batch 151, loss: 1.433, 4832/6976 datapoints
2025-03-06 22:29:07,886 - INFO - validation batch 201, loss: 0.796, 6432/6976 datapoints
2025-03-06 22:29:07,910 - INFO - Epoch 58/800 done.
2025-03-06 22:29:07,910 - INFO - Final validation performance:
Loss: 1.225, top-1 acc: 0.547top-5 acc: 0.547
2025-03-06 22:29:07,910 - INFO - Beginning epoch 59/800
2025-03-06 22:29:07,915 - INFO - training batch 1, loss: 1.349, 32/28000 datapoints
2025-03-06 22:29:08,091 - INFO - training batch 51, loss: 1.427, 1632/28000 datapoints
2025-03-06 22:29:08,243 - INFO - training batch 101, loss: 0.977, 3232/28000 datapoints
2025-03-06 22:29:08,393 - INFO - training batch 151, loss: 1.529, 4832/28000 datapoints
2025-03-06 22:29:08,542 - INFO - training batch 201, loss: 1.456, 6432/28000 datapoints
2025-03-06 22:29:08,690 - INFO - training batch 251, loss: 1.105, 8032/28000 datapoints
2025-03-06 22:29:08,841 - INFO - training batch 301, loss: 1.402, 9632/28000 datapoints
2025-03-06 22:29:08,992 - INFO - training batch 351, loss: 1.205, 11232/28000 datapoints
2025-03-06 22:29:09,161 - INFO - training batch 401, loss: 1.291, 12832/28000 datapoints
2025-03-06 22:29:09,320 - INFO - training batch 451, loss: 1.307, 14432/28000 datapoints
2025-03-06 22:29:09,468 - INFO - training batch 501, loss: 1.144, 16032/28000 datapoints
2025-03-06 22:29:09,620 - INFO - training batch 551, loss: 1.348, 17632/28000 datapoints
2025-03-06 22:29:09,770 - INFO - training batch 601, loss: 1.353, 19232/28000 datapoints
2025-03-06 22:29:09,922 - INFO - training batch 651, loss: 0.875, 20832/28000 datapoints
2025-03-06 22:29:10,071 - INFO - training batch 701, loss: 1.113, 22432/28000 datapoints
2025-03-06 22:29:10,222 - INFO - training batch 751, loss: 1.336, 24032/28000 datapoints
2025-03-06 22:29:10,373 - INFO - training batch 801, loss: 0.984, 25632/28000 datapoints
2025-03-06 22:29:10,522 - INFO - training batch 851, loss: 1.306, 27232/28000 datapoints
2025-03-06 22:29:10,595 - INFO - validation batch 1, loss: 0.930, 32/6976 datapoints
2025-03-06 22:29:10,643 - INFO - validation batch 51, loss: 1.757, 1632/6976 datapoints
2025-03-06 22:29:10,691 - INFO - validation batch 101, loss: 1.189, 3232/6976 datapoints
2025-03-06 22:29:10,739 - INFO - validation batch 151, loss: 1.416, 4832/6976 datapoints
2025-03-06 22:29:10,787 - INFO - validation batch 201, loss: 0.789, 6432/6976 datapoints
2025-03-06 22:29:10,804 - INFO - Epoch 59/800 done.
2025-03-06 22:29:10,804 - INFO - Final validation performance:
Loss: 1.216, top-1 acc: 0.551top-5 acc: 0.551
2025-03-06 22:29:10,805 - INFO - Beginning epoch 60/800
2025-03-06 22:29:10,808 - INFO - training batch 1, loss: 1.334, 32/28000 datapoints
2025-03-06 22:29:10,960 - INFO - training batch 51, loss: 1.416, 1632/28000 datapoints
2025-03-06 22:29:11,115 - INFO - training batch 101, loss: 0.961, 3232/28000 datapoints
2025-03-06 22:29:11,271 - INFO - training batch 151, loss: 1.524, 4832/28000 datapoints
2025-03-06 22:29:11,430 - INFO - training batch 201, loss: 1.446, 6432/28000 datapoints
2025-03-06 22:29:11,593 - INFO - training batch 251, loss: 1.096, 8032/28000 datapoints
2025-03-06 22:29:11,742 - INFO - training batch 301, loss: 1.389, 9632/28000 datapoints
2025-03-06 22:29:11,894 - INFO - training batch 351, loss: 1.186, 11232/28000 datapoints
2025-03-06 22:29:12,044 - INFO - training batch 401, loss: 1.281, 12832/28000 datapoints
2025-03-06 22:29:12,197 - INFO - training batch 451, loss: 1.299, 14432/28000 datapoints
2025-03-06 22:29:12,345 - INFO - training batch 501, loss: 1.137, 16032/28000 datapoints
2025-03-06 22:29:12,501 - INFO - training batch 551, loss: 1.344, 17632/28000 datapoints
2025-03-06 22:29:12,654 - INFO - training batch 601, loss: 1.344, 19232/28000 datapoints
2025-03-06 22:29:12,805 - INFO - training batch 651, loss: 0.864, 20832/28000 datapoints
2025-03-06 22:29:12,963 - INFO - training batch 701, loss: 1.104, 22432/28000 datapoints
2025-03-06 22:29:13,116 - INFO - training batch 751, loss: 1.323, 24032/28000 datapoints
2025-03-06 22:29:13,269 - INFO - training batch 801, loss: 0.968, 25632/28000 datapoints
2025-03-06 22:29:13,421 - INFO - training batch 851, loss: 1.301, 27232/28000 datapoints
2025-03-06 22:29:13,494 - INFO - validation batch 1, loss: 0.922, 32/6976 datapoints
2025-03-06 22:29:13,542 - INFO - validation batch 51, loss: 1.757, 1632/6976 datapoints
2025-03-06 22:29:13,589 - INFO - validation batch 101, loss: 1.180, 3232/6976 datapoints
2025-03-06 22:29:13,636 - INFO - validation batch 151, loss: 1.396, 4832/6976 datapoints
2025-03-06 22:29:13,684 - INFO - validation batch 201, loss: 0.782, 6432/6976 datapoints
2025-03-06 22:29:13,700 - INFO - Epoch 60/800 done.
2025-03-06 22:29:13,700 - INFO - Final validation performance:
Loss: 1.207, top-1 acc: 0.555top-5 acc: 0.555
2025-03-06 22:29:13,700 - INFO - Beginning epoch 61/800
2025-03-06 22:29:13,708 - INFO - training batch 1, loss: 1.319, 32/28000 datapoints
2025-03-06 22:29:13,860 - INFO - training batch 51, loss: 1.403, 1632/28000 datapoints
2025-03-06 22:29:14,013 - INFO - training batch 101, loss: 0.945, 3232/28000 datapoints
2025-03-06 22:29:14,166 - INFO - training batch 151, loss: 1.517, 4832/28000 datapoints
2025-03-06 22:29:14,316 - INFO - training batch 201, loss: 1.436, 6432/28000 datapoints
2025-03-06 22:29:14,464 - INFO - training batch 251, loss: 1.087, 8032/28000 datapoints
2025-03-06 22:29:14,613 - INFO - training batch 301, loss: 1.376, 9632/28000 datapoints
2025-03-06 22:29:14,766 - INFO - training batch 351, loss: 1.165, 11232/28000 datapoints
2025-03-06 22:29:14,918 - INFO - training batch 401, loss: 1.270, 12832/28000 datapoints
2025-03-06 22:29:15,066 - INFO - training batch 451, loss: 1.290, 14432/28000 datapoints
2025-03-06 22:29:15,223 - INFO - training batch 501, loss: 1.131, 16032/28000 datapoints
2025-03-06 22:29:15,379 - INFO - training batch 551, loss: 1.341, 17632/28000 datapoints
2025-03-06 22:29:15,532 - INFO - training batch 601, loss: 1.337, 19232/28000 datapoints
2025-03-06 22:29:15,680 - INFO - training batch 651, loss: 0.853, 20832/28000 datapoints
2025-03-06 22:29:15,831 - INFO - training batch 701, loss: 1.095, 22432/28000 datapoints
2025-03-06 22:29:15,987 - INFO - training batch 751, loss: 1.310, 24032/28000 datapoints
2025-03-06 22:29:16,136 - INFO - training batch 801, loss: 0.951, 25632/28000 datapoints
2025-03-06 22:29:16,286 - INFO - training batch 851, loss: 1.296, 27232/28000 datapoints
2025-03-06 22:29:16,359 - INFO - validation batch 1, loss: 0.913, 32/6976 datapoints
2025-03-06 22:29:16,406 - INFO - validation batch 51, loss: 1.757, 1632/6976 datapoints
2025-03-06 22:29:16,453 - INFO - validation batch 101, loss: 1.171, 3232/6976 datapoints
2025-03-06 22:29:16,500 - INFO - validation batch 151, loss: 1.376, 4832/6976 datapoints
2025-03-06 22:29:16,548 - INFO - validation batch 201, loss: 0.775, 6432/6976 datapoints
2025-03-06 22:29:16,564 - INFO - Epoch 61/800 done.
2025-03-06 22:29:16,565 - INFO - Final validation performance:
Loss: 1.198, top-1 acc: 0.559top-5 acc: 0.559
2025-03-06 22:29:16,565 - INFO - Beginning epoch 62/800
2025-03-06 22:29:16,569 - INFO - training batch 1, loss: 1.302, 32/28000 datapoints
2025-03-06 22:29:16,719 - INFO - training batch 51, loss: 1.390, 1632/28000 datapoints
2025-03-06 22:29:16,870 - INFO - training batch 101, loss: 0.930, 3232/28000 datapoints
2025-03-06 22:29:17,023 - INFO - training batch 151, loss: 1.509, 4832/28000 datapoints
2025-03-06 22:29:17,177 - INFO - training batch 201, loss: 1.425, 6432/28000 datapoints
2025-03-06 22:29:17,332 - INFO - training batch 251, loss: 1.077, 8032/28000 datapoints
2025-03-06 22:29:17,480 - INFO - training batch 301, loss: 1.362, 9632/28000 datapoints
2025-03-06 22:29:17,628 - INFO - training batch 351, loss: 1.143, 11232/28000 datapoints
2025-03-06 22:29:17,778 - INFO - training batch 401, loss: 1.259, 12832/28000 datapoints
2025-03-06 22:29:17,930 - INFO - training batch 451, loss: 1.282, 14432/28000 datapoints
2025-03-06 22:29:18,086 - INFO - training batch 501, loss: 1.124, 16032/28000 datapoints
2025-03-06 22:29:18,241 - INFO - training batch 551, loss: 1.339, 17632/28000 datapoints
2025-03-06 22:29:18,394 - INFO - training batch 601, loss: 1.329, 19232/28000 datapoints
2025-03-06 22:29:18,550 - INFO - training batch 651, loss: 0.839, 20832/28000 datapoints
2025-03-06 22:29:18,714 - INFO - training batch 701, loss: 1.085, 22432/28000 datapoints
2025-03-06 22:29:18,871 - INFO - training batch 751, loss: 1.296, 24032/28000 datapoints
2025-03-06 22:29:19,027 - INFO - training batch 801, loss: 0.934, 25632/28000 datapoints
2025-03-06 22:29:19,181 - INFO - training batch 851, loss: 1.290, 27232/28000 datapoints
2025-03-06 22:29:19,288 - INFO - validation batch 1, loss: 0.903, 32/6976 datapoints
2025-03-06 22:29:19,343 - INFO - validation batch 51, loss: 1.756, 1632/6976 datapoints
2025-03-06 22:29:19,392 - INFO - validation batch 101, loss: 1.161, 3232/6976 datapoints
2025-03-06 22:29:19,444 - INFO - validation batch 151, loss: 1.354, 4832/6976 datapoints
2025-03-06 22:29:19,491 - INFO - validation batch 201, loss: 0.768, 6432/6976 datapoints
2025-03-06 22:29:19,507 - INFO - Epoch 62/800 done.
2025-03-06 22:29:19,508 - INFO - Final validation performance:
Loss: 1.188, top-1 acc: 0.565top-5 acc: 0.565
2025-03-06 22:29:19,508 - INFO - Beginning epoch 63/800
2025-03-06 22:29:19,512 - INFO - training batch 1, loss: 1.285, 32/28000 datapoints
2025-03-06 22:29:19,671 - INFO - training batch 51, loss: 1.375, 1632/28000 datapoints
2025-03-06 22:29:19,823 - INFO - training batch 101, loss: 0.914, 3232/28000 datapoints
2025-03-06 22:29:19,976 - INFO - training batch 151, loss: 1.502, 4832/28000 datapoints
2025-03-06 22:29:20,125 - INFO - training batch 201, loss: 1.412, 6432/28000 datapoints
2025-03-06 22:29:20,276 - INFO - training batch 251, loss: 1.067, 8032/28000 datapoints
2025-03-06 22:29:20,426 - INFO - training batch 301, loss: 1.348, 9632/28000 datapoints
2025-03-06 22:29:20,575 - INFO - training batch 351, loss: 1.120, 11232/28000 datapoints
2025-03-06 22:29:20,725 - INFO - training batch 401, loss: 1.248, 12832/28000 datapoints
2025-03-06 22:29:20,882 - INFO - training batch 451, loss: 1.274, 14432/28000 datapoints
2025-03-06 22:29:21,034 - INFO - training batch 501, loss: 1.116, 16032/28000 datapoints
2025-03-06 22:29:21,185 - INFO - training batch 551, loss: 1.335, 17632/28000 datapoints
2025-03-06 22:29:21,341 - INFO - training batch 601, loss: 1.321, 19232/28000 datapoints
2025-03-06 22:29:21,491 - INFO - training batch 651, loss: 0.825, 20832/28000 datapoints
2025-03-06 22:29:21,643 - INFO - training batch 701, loss: 1.074, 22432/28000 datapoints
2025-03-06 22:29:21,792 - INFO - training batch 751, loss: 1.280, 24032/28000 datapoints
2025-03-06 22:29:21,945 - INFO - training batch 801, loss: 0.917, 25632/28000 datapoints
2025-03-06 22:29:22,094 - INFO - training batch 851, loss: 1.284, 27232/28000 datapoints
2025-03-06 22:29:22,168 - INFO - validation batch 1, loss: 0.891, 32/6976 datapoints
2025-03-06 22:29:22,218 - INFO - validation batch 51, loss: 1.754, 1632/6976 datapoints
2025-03-06 22:29:22,266 - INFO - validation batch 101, loss: 1.150, 3232/6976 datapoints
2025-03-06 22:29:22,314 - INFO - validation batch 151, loss: 1.331, 4832/6976 datapoints
2025-03-06 22:29:22,362 - INFO - validation batch 201, loss: 0.760, 6432/6976 datapoints
2025-03-06 22:29:22,378 - INFO - Epoch 63/800 done.
2025-03-06 22:29:22,379 - INFO - Final validation performance:
Loss: 1.177, top-1 acc: 0.571top-5 acc: 0.571
2025-03-06 22:29:22,379 - INFO - Beginning epoch 64/800
2025-03-06 22:29:22,383 - INFO - training batch 1, loss: 1.268, 32/28000 datapoints
2025-03-06 22:29:22,533 - INFO - training batch 51, loss: 1.359, 1632/28000 datapoints
2025-03-06 22:29:22,681 - INFO - training batch 101, loss: 0.899, 3232/28000 datapoints
2025-03-06 22:29:22,834 - INFO - training batch 151, loss: 1.495, 4832/28000 datapoints
2025-03-06 22:29:22,990 - INFO - training batch 201, loss: 1.400, 6432/28000 datapoints
2025-03-06 22:29:23,148 - INFO - training batch 251, loss: 1.057, 8032/28000 datapoints
2025-03-06 22:29:23,302 - INFO - training batch 301, loss: 1.333, 9632/28000 datapoints
2025-03-06 22:29:23,454 - INFO - training batch 351, loss: 1.098, 11232/28000 datapoints
2025-03-06 22:29:23,604 - INFO - training batch 401, loss: 1.236, 12832/28000 datapoints
2025-03-06 22:29:23,753 - INFO - training batch 451, loss: 1.266, 14432/28000 datapoints
2025-03-06 22:29:23,907 - INFO - training batch 501, loss: 1.109, 16032/28000 datapoints
2025-03-06 22:29:24,058 - INFO - training batch 551, loss: 1.333, 17632/28000 datapoints
2025-03-06 22:29:24,209 - INFO - training batch 601, loss: 1.313, 19232/28000 datapoints
2025-03-06 22:29:24,362 - INFO - training batch 651, loss: 0.810, 20832/28000 datapoints
2025-03-06 22:29:24,512 - INFO - training batch 701, loss: 1.061, 22432/28000 datapoints
2025-03-06 22:29:24,661 - INFO - training batch 751, loss: 1.263, 24032/28000 datapoints
2025-03-06 22:29:24,812 - INFO - training batch 801, loss: 0.900, 25632/28000 datapoints
2025-03-06 22:29:24,976 - INFO - training batch 851, loss: 1.278, 27232/28000 datapoints
2025-03-06 22:29:25,049 - INFO - validation batch 1, loss: 0.879, 32/6976 datapoints
2025-03-06 22:29:25,097 - INFO - validation batch 51, loss: 1.753, 1632/6976 datapoints
2025-03-06 22:29:25,145 - INFO - validation batch 101, loss: 1.139, 3232/6976 datapoints
2025-03-06 22:29:25,196 - INFO - validation batch 151, loss: 1.306, 4832/6976 datapoints
2025-03-06 22:29:25,243 - INFO - validation batch 201, loss: 0.752, 6432/6976 datapoints
2025-03-06 22:29:25,260 - INFO - Epoch 64/800 done.
2025-03-06 22:29:25,260 - INFO - Final validation performance:
Loss: 1.166, top-1 acc: 0.577top-5 acc: 0.577
2025-03-06 22:29:25,261 - INFO - Beginning epoch 65/800
2025-03-06 22:29:25,265 - INFO - training batch 1, loss: 1.252, 32/28000 datapoints
2025-03-06 22:29:25,426 - INFO - training batch 51, loss: 1.342, 1632/28000 datapoints
2025-03-06 22:29:25,582 - INFO - training batch 101, loss: 0.883, 3232/28000 datapoints
2025-03-06 22:29:25,731 - INFO - training batch 151, loss: 1.488, 4832/28000 datapoints
2025-03-06 22:29:25,882 - INFO - training batch 201, loss: 1.389, 6432/28000 datapoints
2025-03-06 22:29:26,036 - INFO - training batch 251, loss: 1.048, 8032/28000 datapoints
2025-03-06 22:29:26,186 - INFO - training batch 301, loss: 1.319, 9632/28000 datapoints
2025-03-06 22:29:26,334 - INFO - training batch 351, loss: 1.079, 11232/28000 datapoints
2025-03-06 22:29:26,484 - INFO - training batch 401, loss: 1.226, 12832/28000 datapoints
2025-03-06 22:29:26,634 - INFO - training batch 451, loss: 1.260, 14432/28000 datapoints
2025-03-06 22:29:26,783 - INFO - training batch 501, loss: 1.102, 16032/28000 datapoints
2025-03-06 22:29:26,937 - INFO - training batch 551, loss: 1.330, 17632/28000 datapoints
2025-03-06 22:29:27,088 - INFO - training batch 601, loss: 1.302, 19232/28000 datapoints
2025-03-06 22:29:27,240 - INFO - training batch 651, loss: 0.796, 20832/28000 datapoints
2025-03-06 22:29:27,397 - INFO - training batch 701, loss: 1.049, 22432/28000 datapoints
2025-03-06 22:29:27,546 - INFO - training batch 751, loss: 1.247, 24032/28000 datapoints
2025-03-06 22:29:27,695 - INFO - training batch 801, loss: 0.883, 25632/28000 datapoints
2025-03-06 22:29:27,845 - INFO - training batch 851, loss: 1.271, 27232/28000 datapoints
2025-03-06 22:29:27,926 - INFO - validation batch 1, loss: 0.865, 32/6976 datapoints
2025-03-06 22:29:27,982 - INFO - validation batch 51, loss: 1.752, 1632/6976 datapoints
2025-03-06 22:29:28,029 - INFO - validation batch 101, loss: 1.128, 3232/6976 datapoints
2025-03-06 22:29:28,077 - INFO - validation batch 151, loss: 1.281, 4832/6976 datapoints
2025-03-06 22:29:28,125 - INFO - validation batch 201, loss: 0.744, 6432/6976 datapoints
2025-03-06 22:29:28,141 - INFO - Epoch 65/800 done.
2025-03-06 22:29:28,141 - INFO - Final validation performance:
Loss: 1.154, top-1 acc: 0.582top-5 acc: 0.582
2025-03-06 22:29:28,142 - INFO - Beginning epoch 66/800
2025-03-06 22:29:28,146 - INFO - training batch 1, loss: 1.236, 32/28000 datapoints
2025-03-06 22:29:28,297 - INFO - training batch 51, loss: 1.326, 1632/28000 datapoints
2025-03-06 22:29:28,513 - INFO - training batch 101, loss: 0.866, 3232/28000 datapoints
2025-03-06 22:29:28,666 - INFO - training batch 151, loss: 1.481, 4832/28000 datapoints
2025-03-06 22:29:28,817 - INFO - training batch 201, loss: 1.375, 6432/28000 datapoints
2025-03-06 22:29:28,981 - INFO - training batch 251, loss: 1.038, 8032/28000 datapoints
2025-03-06 22:29:29,166 - INFO - training batch 301, loss: 1.306, 9632/28000 datapoints
2025-03-06 22:29:29,328 - INFO - training batch 351, loss: 1.058, 11232/28000 datapoints
2025-03-06 22:29:29,493 - INFO - training batch 401, loss: 1.215, 12832/28000 datapoints
2025-03-06 22:29:29,644 - INFO - training batch 451, loss: 1.252, 14432/28000 datapoints
2025-03-06 22:29:29,800 - INFO - training batch 501, loss: 1.094, 16032/28000 datapoints
2025-03-06 22:29:29,955 - INFO - training batch 551, loss: 1.328, 17632/28000 datapoints
2025-03-06 22:29:30,106 - INFO - training batch 601, loss: 1.292, 19232/28000 datapoints
2025-03-06 22:29:30,257 - INFO - training batch 651, loss: 0.781, 20832/28000 datapoints
2025-03-06 22:29:30,409 - INFO - training batch 701, loss: 1.034, 22432/28000 datapoints
2025-03-06 22:29:30,562 - INFO - training batch 751, loss: 1.230, 24032/28000 datapoints
2025-03-06 22:29:30,712 - INFO - training batch 801, loss: 0.867, 25632/28000 datapoints
2025-03-06 22:29:30,861 - INFO - training batch 851, loss: 1.264, 27232/28000 datapoints
2025-03-06 22:29:30,938 - INFO - validation batch 1, loss: 0.852, 32/6976 datapoints
2025-03-06 22:29:30,988 - INFO - validation batch 51, loss: 1.751, 1632/6976 datapoints
2025-03-06 22:29:31,039 - INFO - validation batch 101, loss: 1.116, 3232/6976 datapoints
2025-03-06 22:29:31,103 - INFO - validation batch 151, loss: 1.256, 4832/6976 datapoints
2025-03-06 22:29:31,152 - INFO - validation batch 201, loss: 0.736, 6432/6976 datapoints
2025-03-06 22:29:31,169 - INFO - Epoch 66/800 done.
2025-03-06 22:29:31,169 - INFO - Final validation performance:
Loss: 1.142, top-1 acc: 0.588top-5 acc: 0.588
2025-03-06 22:29:31,170 - INFO - Beginning epoch 67/800
2025-03-06 22:29:31,174 - INFO - training batch 1, loss: 1.219, 32/28000 datapoints
2025-03-06 22:29:31,328 - INFO - training batch 51, loss: 1.309, 1632/28000 datapoints
2025-03-06 22:29:31,486 - INFO - training batch 101, loss: 0.849, 3232/28000 datapoints
2025-03-06 22:29:31,636 - INFO - training batch 151, loss: 1.475, 4832/28000 datapoints
2025-03-06 22:29:31,787 - INFO - training batch 201, loss: 1.360, 6432/28000 datapoints
2025-03-06 22:29:31,940 - INFO - training batch 251, loss: 1.025, 8032/28000 datapoints
2025-03-06 22:29:32,092 - INFO - training batch 301, loss: 1.292, 9632/28000 datapoints
2025-03-06 22:29:32,244 - INFO - training batch 351, loss: 1.038, 11232/28000 datapoints
2025-03-06 22:29:32,394 - INFO - training batch 401, loss: 1.203, 12832/28000 datapoints
2025-03-06 22:29:32,544 - INFO - training batch 451, loss: 1.244, 14432/28000 datapoints
2025-03-06 22:29:32,694 - INFO - training batch 501, loss: 1.086, 16032/28000 datapoints
2025-03-06 22:29:32,846 - INFO - training batch 551, loss: 1.325, 17632/28000 datapoints
2025-03-06 22:29:33,000 - INFO - training batch 601, loss: 1.281, 19232/28000 datapoints
2025-03-06 22:29:33,150 - INFO - training batch 651, loss: 0.766, 20832/28000 datapoints
2025-03-06 22:29:33,305 - INFO - training batch 701, loss: 1.022, 22432/28000 datapoints
2025-03-06 22:29:33,518 - INFO - training batch 751, loss: 1.213, 24032/28000 datapoints
2025-03-06 22:29:33,754 - INFO - training batch 801, loss: 0.850, 25632/28000 datapoints
2025-03-06 22:29:33,948 - INFO - training batch 851, loss: 1.257, 27232/28000 datapoints
2025-03-06 22:29:34,043 - INFO - validation batch 1, loss: 0.838, 32/6976 datapoints
2025-03-06 22:29:34,102 - INFO - validation batch 51, loss: 1.750, 1632/6976 datapoints
2025-03-06 22:29:34,158 - INFO - validation batch 101, loss: 1.103, 3232/6976 datapoints
2025-03-06 22:29:34,212 - INFO - validation batch 151, loss: 1.231, 4832/6976 datapoints
2025-03-06 22:29:34,270 - INFO - validation batch 201, loss: 0.729, 6432/6976 datapoints
2025-03-06 22:29:34,290 - INFO - Epoch 67/800 done.
2025-03-06 22:29:34,290 - INFO - Final validation performance:
Loss: 1.130, top-1 acc: 0.597top-5 acc: 0.597
2025-03-06 22:29:34,290 - INFO - Beginning epoch 68/800
2025-03-06 22:29:34,295 - INFO - training batch 1, loss: 1.203, 32/28000 datapoints
2025-03-06 22:29:34,462 - INFO - training batch 51, loss: 1.291, 1632/28000 datapoints
2025-03-06 22:29:34,630 - INFO - training batch 101, loss: 0.830, 3232/28000 datapoints
2025-03-06 22:29:34,780 - INFO - training batch 151, loss: 1.470, 4832/28000 datapoints
2025-03-06 22:29:34,936 - INFO - training batch 201, loss: 1.344, 6432/28000 datapoints
2025-03-06 22:29:35,089 - INFO - training batch 251, loss: 1.014, 8032/28000 datapoints
2025-03-06 22:29:35,247 - INFO - training batch 301, loss: 1.278, 9632/28000 datapoints
2025-03-06 22:29:35,403 - INFO - training batch 351, loss: 1.019, 11232/28000 datapoints
2025-03-06 22:29:35,555 - INFO - training batch 401, loss: 1.192, 12832/28000 datapoints
2025-03-06 22:29:35,707 - INFO - training batch 451, loss: 1.236, 14432/28000 datapoints
2025-03-06 22:29:35,862 - INFO - training batch 501, loss: 1.078, 16032/28000 datapoints
2025-03-06 22:29:36,020 - INFO - training batch 551, loss: 1.323, 17632/28000 datapoints
2025-03-06 22:29:36,172 - INFO - training batch 601, loss: 1.272, 19232/28000 datapoints
2025-03-06 22:29:36,324 - INFO - training batch 651, loss: 0.751, 20832/28000 datapoints
2025-03-06 22:29:36,474 - INFO - training batch 701, loss: 1.009, 22432/28000 datapoints
2025-03-06 22:29:36,625 - INFO - training batch 751, loss: 1.193, 24032/28000 datapoints
2025-03-06 22:29:36,775 - INFO - training batch 801, loss: 0.835, 25632/28000 datapoints
2025-03-06 22:29:36,958 - INFO - training batch 851, loss: 1.250, 27232/28000 datapoints
2025-03-06 22:29:37,051 - INFO - validation batch 1, loss: 0.826, 32/6976 datapoints
2025-03-06 22:29:37,100 - INFO - validation batch 51, loss: 1.750, 1632/6976 datapoints
2025-03-06 22:29:37,166 - INFO - validation batch 101, loss: 1.089, 3232/6976 datapoints
2025-03-06 22:29:37,225 - INFO - validation batch 151, loss: 1.206, 4832/6976 datapoints
2025-03-06 22:29:37,275 - INFO - validation batch 201, loss: 0.722, 6432/6976 datapoints
2025-03-06 22:29:37,291 - INFO - Epoch 68/800 done.
2025-03-06 22:29:37,291 - INFO - Final validation performance:
Loss: 1.118, top-1 acc: 0.604top-5 acc: 0.604
2025-03-06 22:29:37,292 - INFO - Beginning epoch 69/800
2025-03-06 22:29:37,296 - INFO - training batch 1, loss: 1.186, 32/28000 datapoints
2025-03-06 22:29:37,455 - INFO - training batch 51, loss: 1.271, 1632/28000 datapoints
2025-03-06 22:29:37,608 - INFO - training batch 101, loss: 0.812, 3232/28000 datapoints
2025-03-06 22:29:37,758 - INFO - training batch 151, loss: 1.465, 4832/28000 datapoints
2025-03-06 22:29:37,923 - INFO - training batch 201, loss: 1.326, 6432/28000 datapoints
2025-03-06 22:29:38,076 - INFO - training batch 251, loss: 1.002, 8032/28000 datapoints
2025-03-06 22:29:38,233 - INFO - training batch 301, loss: 1.264, 9632/28000 datapoints
2025-03-06 22:29:38,386 - INFO - training batch 351, loss: 0.999, 11232/28000 datapoints
2025-03-06 22:29:38,543 - INFO - training batch 401, loss: 1.181, 12832/28000 datapoints
2025-03-06 22:29:38,699 - INFO - training batch 451, loss: 1.229, 14432/28000 datapoints
2025-03-06 22:29:38,854 - INFO - training batch 501, loss: 1.070, 16032/28000 datapoints
2025-03-06 22:29:39,010 - INFO - training batch 551, loss: 1.320, 17632/28000 datapoints
2025-03-06 22:29:39,169 - INFO - training batch 601, loss: 1.263, 19232/28000 datapoints
2025-03-06 22:29:39,326 - INFO - training batch 651, loss: 0.736, 20832/28000 datapoints
2025-03-06 22:29:39,510 - INFO - training batch 701, loss: 0.997, 22432/28000 datapoints
2025-03-06 22:29:39,666 - INFO - training batch 751, loss: 1.174, 24032/28000 datapoints
2025-03-06 22:29:39,827 - INFO - training batch 801, loss: 0.820, 25632/28000 datapoints
2025-03-06 22:29:39,985 - INFO - training batch 851, loss: 1.244, 27232/28000 datapoints
2025-03-06 22:29:40,066 - INFO - validation batch 1, loss: 0.812, 32/6976 datapoints
2025-03-06 22:29:40,117 - INFO - validation batch 51, loss: 1.749, 1632/6976 datapoints
2025-03-06 22:29:40,169 - INFO - validation batch 101, loss: 1.075, 3232/6976 datapoints
2025-03-06 22:29:40,222 - INFO - validation batch 151, loss: 1.183, 4832/6976 datapoints
2025-03-06 22:29:40,274 - INFO - validation batch 201, loss: 0.715, 6432/6976 datapoints
2025-03-06 22:29:40,294 - INFO - Epoch 69/800 done.
2025-03-06 22:29:40,294 - INFO - Final validation performance:
Loss: 1.107, top-1 acc: 0.613top-5 acc: 0.613
2025-03-06 22:29:40,295 - INFO - Beginning epoch 70/800
2025-03-06 22:29:40,300 - INFO - training batch 1, loss: 1.171, 32/28000 datapoints
2025-03-06 22:29:40,457 - INFO - training batch 51, loss: 1.252, 1632/28000 datapoints
2025-03-06 22:29:40,613 - INFO - training batch 101, loss: 0.794, 3232/28000 datapoints
2025-03-06 22:29:40,763 - INFO - training batch 151, loss: 1.461, 4832/28000 datapoints
2025-03-06 22:29:40,916 - INFO - training batch 201, loss: 1.307, 6432/28000 datapoints
2025-03-06 22:29:41,068 - INFO - training batch 251, loss: 0.991, 8032/28000 datapoints
2025-03-06 22:29:41,219 - INFO - training batch 301, loss: 1.251, 9632/28000 datapoints
2025-03-06 22:29:41,374 - INFO - training batch 351, loss: 0.981, 11232/28000 datapoints
2025-03-06 22:29:41,526 - INFO - training batch 401, loss: 1.172, 12832/28000 datapoints
2025-03-06 22:29:41,676 - INFO - training batch 451, loss: 1.221, 14432/28000 datapoints
2025-03-06 22:29:41,826 - INFO - training batch 501, loss: 1.063, 16032/28000 datapoints
2025-03-06 22:29:41,980 - INFO - training batch 551, loss: 1.316, 17632/28000 datapoints
2025-03-06 22:29:42,135 - INFO - training batch 601, loss: 1.253, 19232/28000 datapoints
2025-03-06 22:29:42,287 - INFO - training batch 651, loss: 0.722, 20832/28000 datapoints
2025-03-06 22:29:42,438 - INFO - training batch 701, loss: 0.985, 22432/28000 datapoints
2025-03-06 22:29:42,588 - INFO - training batch 751, loss: 1.152, 24032/28000 datapoints
2025-03-06 22:29:42,741 - INFO - training batch 801, loss: 0.805, 25632/28000 datapoints
2025-03-06 22:29:42,889 - INFO - training batch 851, loss: 1.238, 27232/28000 datapoints
2025-03-06 22:29:42,967 - INFO - validation batch 1, loss: 0.799, 32/6976 datapoints
2025-03-06 22:29:43,014 - INFO - validation batch 51, loss: 1.748, 1632/6976 datapoints
2025-03-06 22:29:43,064 - INFO - validation batch 101, loss: 1.059, 3232/6976 datapoints
2025-03-06 22:29:43,113 - INFO - validation batch 151, loss: 1.162, 4832/6976 datapoints
2025-03-06 22:29:43,161 - INFO - validation batch 201, loss: 0.708, 6432/6976 datapoints
2025-03-06 22:29:43,178 - INFO - Epoch 70/800 done.
2025-03-06 22:29:43,178 - INFO - Final validation performance:
Loss: 1.095, top-1 acc: 0.618top-5 acc: 0.618
2025-03-06 22:29:43,179 - INFO - Beginning epoch 71/800
2025-03-06 22:29:43,183 - INFO - training batch 1, loss: 1.155, 32/28000 datapoints
2025-03-06 22:29:43,334 - INFO - training batch 51, loss: 1.232, 1632/28000 datapoints
2025-03-06 22:29:43,501 - INFO - training batch 101, loss: 0.778, 3232/28000 datapoints
2025-03-06 22:29:43,655 - INFO - training batch 151, loss: 1.457, 4832/28000 datapoints
2025-03-06 22:29:43,804 - INFO - training batch 201, loss: 1.288, 6432/28000 datapoints
2025-03-06 22:29:43,971 - INFO - training batch 251, loss: 0.980, 8032/28000 datapoints
2025-03-06 22:29:44,154 - INFO - training batch 301, loss: 1.239, 9632/28000 datapoints
2025-03-06 22:29:44,323 - INFO - training batch 351, loss: 0.961, 11232/28000 datapoints
2025-03-06 22:29:44,501 - INFO - training batch 401, loss: 1.163, 12832/28000 datapoints
2025-03-06 22:29:44,663 - INFO - training batch 451, loss: 1.212, 14432/28000 datapoints
2025-03-06 22:29:44,823 - INFO - training batch 501, loss: 1.055, 16032/28000 datapoints
2025-03-06 22:29:44,989 - INFO - training batch 551, loss: 1.309, 17632/28000 datapoints
2025-03-06 22:29:45,223 - INFO - training batch 601, loss: 1.243, 19232/28000 datapoints
2025-03-06 22:29:45,398 - INFO - training batch 651, loss: 0.708, 20832/28000 datapoints
2025-03-06 22:29:45,550 - INFO - training batch 701, loss: 0.972, 22432/28000 datapoints
2025-03-06 22:29:45,701 - INFO - training batch 751, loss: 1.129, 24032/28000 datapoints
2025-03-06 22:29:45,850 - INFO - training batch 801, loss: 0.789, 25632/28000 datapoints
2025-03-06 22:29:46,002 - INFO - training batch 851, loss: 1.232, 27232/28000 datapoints
2025-03-06 22:29:46,077 - INFO - validation batch 1, loss: 0.786, 32/6976 datapoints
2025-03-06 22:29:46,144 - INFO - validation batch 51, loss: 1.748, 1632/6976 datapoints
2025-03-06 22:29:46,193 - INFO - validation batch 101, loss: 1.043, 3232/6976 datapoints
2025-03-06 22:29:46,243 - INFO - validation batch 151, loss: 1.142, 4832/6976 datapoints
2025-03-06 22:29:46,291 - INFO - validation batch 201, loss: 0.703, 6432/6976 datapoints
2025-03-06 22:29:46,307 - INFO - Epoch 71/800 done.
2025-03-06 22:29:46,307 - INFO - Final validation performance:
Loss: 1.084, top-1 acc: 0.623top-5 acc: 0.623
2025-03-06 22:29:46,308 - INFO - Beginning epoch 72/800
2025-03-06 22:29:46,312 - INFO - training batch 1, loss: 1.139, 32/28000 datapoints
2025-03-06 22:29:46,466 - INFO - training batch 51, loss: 1.212, 1632/28000 datapoints
2025-03-06 22:29:46,619 - INFO - training batch 101, loss: 0.761, 3232/28000 datapoints
2025-03-06 22:29:46,771 - INFO - training batch 151, loss: 1.454, 4832/28000 datapoints
2025-03-06 22:29:46,932 - INFO - training batch 201, loss: 1.266, 6432/28000 datapoints
2025-03-06 22:29:47,082 - INFO - training batch 251, loss: 0.969, 8032/28000 datapoints
2025-03-06 22:29:47,262 - INFO - training batch 301, loss: 1.227, 9632/28000 datapoints
2025-03-06 22:29:47,433 - INFO - training batch 351, loss: 0.944, 11232/28000 datapoints
2025-03-06 22:29:47,583 - INFO - training batch 401, loss: 1.153, 12832/28000 datapoints
2025-03-06 22:29:47,736 - INFO - training batch 451, loss: 1.203, 14432/28000 datapoints
2025-03-06 22:29:47,887 - INFO - training batch 501, loss: 1.047, 16032/28000 datapoints
2025-03-06 22:29:48,041 - INFO - training batch 551, loss: 1.303, 17632/28000 datapoints
2025-03-06 22:29:48,194 - INFO - training batch 601, loss: 1.233, 19232/28000 datapoints
2025-03-06 22:29:48,345 - INFO - training batch 651, loss: 0.694, 20832/28000 datapoints
2025-03-06 22:29:48,497 - INFO - training batch 701, loss: 0.959, 22432/28000 datapoints
2025-03-06 22:29:48,649 - INFO - training batch 751, loss: 1.107, 24032/28000 datapoints
2025-03-06 22:29:48,799 - INFO - training batch 801, loss: 0.775, 25632/28000 datapoints
2025-03-06 22:29:48,954 - INFO - training batch 851, loss: 1.226, 27232/28000 datapoints
2025-03-06 22:29:49,028 - INFO - validation batch 1, loss: 0.772, 32/6976 datapoints
2025-03-06 22:29:49,076 - INFO - validation batch 51, loss: 1.746, 1632/6976 datapoints
2025-03-06 22:29:49,125 - INFO - validation batch 101, loss: 1.026, 3232/6976 datapoints
2025-03-06 22:29:49,177 - INFO - validation batch 151, loss: 1.122, 4832/6976 datapoints
2025-03-06 22:29:49,233 - INFO - validation batch 201, loss: 0.698, 6432/6976 datapoints
2025-03-06 22:29:49,253 - INFO - Epoch 72/800 done.
2025-03-06 22:29:49,254 - INFO - Final validation performance:
Loss: 1.073, top-1 acc: 0.628top-5 acc: 0.628
2025-03-06 22:29:49,254 - INFO - Beginning epoch 73/800
2025-03-06 22:29:49,258 - INFO - training batch 1, loss: 1.125, 32/28000 datapoints
2025-03-06 22:29:49,421 - INFO - training batch 51, loss: 1.191, 1632/28000 datapoints
2025-03-06 22:29:49,605 - INFO - training batch 101, loss: 0.745, 3232/28000 datapoints
2025-03-06 22:29:49,776 - INFO - training batch 151, loss: 1.451, 4832/28000 datapoints
2025-03-06 22:29:49,930 - INFO - training batch 201, loss: 1.247, 6432/28000 datapoints
2025-03-06 22:29:50,080 - INFO - training batch 251, loss: 0.958, 8032/28000 datapoints
2025-03-06 22:29:50,240 - INFO - training batch 301, loss: 1.215, 9632/28000 datapoints
2025-03-06 22:29:50,395 - INFO - training batch 351, loss: 0.927, 11232/28000 datapoints
2025-03-06 22:29:50,550 - INFO - training batch 401, loss: 1.145, 12832/28000 datapoints
2025-03-06 22:29:50,703 - INFO - training batch 451, loss: 1.193, 14432/28000 datapoints
2025-03-06 22:29:50,853 - INFO - training batch 501, loss: 1.040, 16032/28000 datapoints
2025-03-06 22:29:51,007 - INFO - training batch 551, loss: 1.295, 17632/28000 datapoints
2025-03-06 22:29:51,159 - INFO - training batch 601, loss: 1.223, 19232/28000 datapoints
2025-03-06 22:29:51,311 - INFO - training batch 651, loss: 0.681, 20832/28000 datapoints
2025-03-06 22:29:51,466 - INFO - training batch 701, loss: 0.946, 22432/28000 datapoints
2025-03-06 22:29:51,616 - INFO - training batch 751, loss: 1.084, 24032/28000 datapoints
2025-03-06 22:29:51,767 - INFO - training batch 801, loss: 0.761, 25632/28000 datapoints
2025-03-06 22:29:51,918 - INFO - training batch 851, loss: 1.219, 27232/28000 datapoints
2025-03-06 22:29:51,993 - INFO - validation batch 1, loss: 0.759, 32/6976 datapoints
2025-03-06 22:29:52,041 - INFO - validation batch 51, loss: 1.743, 1632/6976 datapoints
2025-03-06 22:29:52,088 - INFO - validation batch 101, loss: 1.009, 3232/6976 datapoints
2025-03-06 22:29:52,138 - INFO - validation batch 151, loss: 1.104, 4832/6976 datapoints
2025-03-06 22:29:52,187 - INFO - validation batch 201, loss: 0.693, 6432/6976 datapoints
2025-03-06 22:29:52,204 - INFO - Epoch 73/800 done.
2025-03-06 22:29:52,204 - INFO - Final validation performance:
Loss: 1.062, top-1 acc: 0.634top-5 acc: 0.634
2025-03-06 22:29:52,204 - INFO - Beginning epoch 74/800
2025-03-06 22:29:52,209 - INFO - training batch 1, loss: 1.109, 32/28000 datapoints
2025-03-06 22:29:52,364 - INFO - training batch 51, loss: 1.171, 1632/28000 datapoints
2025-03-06 22:29:52,516 - INFO - training batch 101, loss: 0.729, 3232/28000 datapoints
2025-03-06 22:29:52,667 - INFO - training batch 151, loss: 1.449, 4832/28000 datapoints
2025-03-06 22:29:52,820 - INFO - training batch 201, loss: 1.226, 6432/28000 datapoints
2025-03-06 22:29:52,973 - INFO - training batch 251, loss: 0.948, 8032/28000 datapoints
2025-03-06 22:29:53,123 - INFO - training batch 301, loss: 1.203, 9632/28000 datapoints
2025-03-06 22:29:53,275 - INFO - training batch 351, loss: 0.910, 11232/28000 datapoints
2025-03-06 22:29:53,429 - INFO - training batch 401, loss: 1.137, 12832/28000 datapoints
2025-03-06 22:29:53,580 - INFO - training batch 451, loss: 1.184, 14432/28000 datapoints
2025-03-06 22:29:53,729 - INFO - training batch 501, loss: 1.032, 16032/28000 datapoints
2025-03-06 22:29:53,882 - INFO - training batch 551, loss: 1.286, 17632/28000 datapoints
2025-03-06 22:29:54,038 - INFO - training batch 601, loss: 1.213, 19232/28000 datapoints
2025-03-06 22:29:54,189 - INFO - training batch 651, loss: 0.667, 20832/28000 datapoints
2025-03-06 22:29:54,341 - INFO - training batch 701, loss: 0.933, 22432/28000 datapoints
2025-03-06 22:29:54,494 - INFO - training batch 751, loss: 1.061, 24032/28000 datapoints
2025-03-06 22:29:54,642 - INFO - training batch 801, loss: 0.747, 25632/28000 datapoints
2025-03-06 22:29:54,794 - INFO - training batch 851, loss: 1.214, 27232/28000 datapoints
2025-03-06 22:29:54,869 - INFO - validation batch 1, loss: 0.745, 32/6976 datapoints
2025-03-06 22:29:54,916 - INFO - validation batch 51, loss: 1.743, 1632/6976 datapoints
2025-03-06 22:29:54,965 - INFO - validation batch 101, loss: 0.990, 3232/6976 datapoints
2025-03-06 22:29:55,013 - INFO - validation batch 151, loss: 1.087, 4832/6976 datapoints
2025-03-06 22:29:55,060 - INFO - validation batch 201, loss: 0.687, 6432/6976 datapoints
2025-03-06 22:29:55,077 - INFO - Epoch 74/800 done.
2025-03-06 22:29:55,077 - INFO - Final validation performance:
Loss: 1.050, top-1 acc: 0.640top-5 acc: 0.640
2025-03-06 22:29:55,077 - INFO - Beginning epoch 75/800
2025-03-06 22:29:55,082 - INFO - training batch 1, loss: 1.095, 32/28000 datapoints
2025-03-06 22:29:55,305 - INFO - training batch 51, loss: 1.151, 1632/28000 datapoints
2025-03-06 22:29:55,462 - INFO - training batch 101, loss: 0.713, 3232/28000 datapoints
2025-03-06 22:29:55,617 - INFO - training batch 151, loss: 1.442, 4832/28000 datapoints
2025-03-06 22:29:55,780 - INFO - training batch 201, loss: 1.205, 6432/28000 datapoints
2025-03-06 22:29:55,933 - INFO - training batch 251, loss: 0.937, 8032/28000 datapoints
2025-03-06 22:29:56,083 - INFO - training batch 301, loss: 1.192, 9632/28000 datapoints
2025-03-06 22:29:56,243 - INFO - training batch 351, loss: 0.893, 11232/28000 datapoints
2025-03-06 22:29:56,399 - INFO - training batch 401, loss: 1.130, 12832/28000 datapoints
2025-03-06 22:29:56,555 - INFO - training batch 451, loss: 1.173, 14432/28000 datapoints
2025-03-06 22:29:56,705 - INFO - training batch 501, loss: 1.023, 16032/28000 datapoints
2025-03-06 22:29:56,857 - INFO - training batch 551, loss: 1.277, 17632/28000 datapoints
2025-03-06 22:29:57,010 - INFO - training batch 601, loss: 1.205, 19232/28000 datapoints
2025-03-06 22:29:57,163 - INFO - training batch 651, loss: 0.653, 20832/28000 datapoints
2025-03-06 22:29:57,315 - INFO - training batch 701, loss: 0.920, 22432/28000 datapoints
2025-03-06 22:29:57,469 - INFO - training batch 751, loss: 1.037, 24032/28000 datapoints
2025-03-06 22:29:57,620 - INFO - training batch 801, loss: 0.733, 25632/28000 datapoints
2025-03-06 22:29:57,769 - INFO - training batch 851, loss: 1.207, 27232/28000 datapoints
2025-03-06 22:29:57,844 - INFO - validation batch 1, loss: 0.731, 32/6976 datapoints
2025-03-06 22:29:57,891 - INFO - validation batch 51, loss: 1.742, 1632/6976 datapoints
2025-03-06 22:29:57,942 - INFO - validation batch 101, loss: 0.972, 3232/6976 datapoints
2025-03-06 22:29:57,993 - INFO - validation batch 151, loss: 1.071, 4832/6976 datapoints
2025-03-06 22:29:58,046 - INFO - validation batch 201, loss: 0.682, 6432/6976 datapoints
2025-03-06 22:29:58,063 - INFO - Epoch 75/800 done.
2025-03-06 22:29:58,063 - INFO - Final validation performance:
Loss: 1.039, top-1 acc: 0.646top-5 acc: 0.646
2025-03-06 22:29:58,064 - INFO - Beginning epoch 76/800
2025-03-06 22:29:58,068 - INFO - training batch 1, loss: 1.079, 32/28000 datapoints
2025-03-06 22:29:58,225 - INFO - training batch 51, loss: 1.131, 1632/28000 datapoints
2025-03-06 22:29:58,381 - INFO - training batch 101, loss: 0.697, 3232/28000 datapoints
2025-03-06 22:29:58,546 - INFO - training batch 151, loss: 1.431, 4832/28000 datapoints
2025-03-06 22:29:58,699 - INFO - training batch 201, loss: 1.185, 6432/28000 datapoints
2025-03-06 22:29:58,857 - INFO - training batch 251, loss: 0.927, 8032/28000 datapoints
2025-03-06 22:29:59,012 - INFO - training batch 301, loss: 1.179, 9632/28000 datapoints
2025-03-06 22:29:59,182 - INFO - training batch 351, loss: 0.874, 11232/28000 datapoints
2025-03-06 22:29:59,379 - INFO - training batch 401, loss: 1.123, 12832/28000 datapoints
2025-03-06 22:29:59,576 - INFO - training batch 451, loss: 1.162, 14432/28000 datapoints
2025-03-06 22:29:59,790 - INFO - training batch 501, loss: 1.014, 16032/28000 datapoints
2025-03-06 22:29:59,989 - INFO - training batch 551, loss: 1.267, 17632/28000 datapoints
2025-03-06 22:30:00,160 - INFO - training batch 601, loss: 1.197, 19232/28000 datapoints
2025-03-06 22:30:00,314 - INFO - training batch 651, loss: 0.640, 20832/28000 datapoints
2025-03-06 22:30:00,473 - INFO - training batch 701, loss: 0.908, 22432/28000 datapoints
2025-03-06 22:30:00,633 - INFO - training batch 751, loss: 1.014, 24032/28000 datapoints
2025-03-06 22:30:00,787 - INFO - training batch 801, loss: 0.721, 25632/28000 datapoints
2025-03-06 22:30:00,952 - INFO - training batch 851, loss: 1.202, 27232/28000 datapoints
2025-03-06 22:30:01,047 - INFO - validation batch 1, loss: 0.717, 32/6976 datapoints
2025-03-06 22:30:01,115 - INFO - validation batch 51, loss: 1.740, 1632/6976 datapoints
2025-03-06 22:30:01,179 - INFO - validation batch 101, loss: 0.953, 3232/6976 datapoints
2025-03-06 22:30:01,247 - INFO - validation batch 151, loss: 1.054, 4832/6976 datapoints
2025-03-06 22:30:01,307 - INFO - validation batch 201, loss: 0.675, 6432/6976 datapoints
2025-03-06 22:30:01,335 - INFO - Epoch 76/800 done.
2025-03-06 22:30:01,335 - INFO - Final validation performance:
Loss: 1.028, top-1 acc: 0.653top-5 acc: 0.653
2025-03-06 22:30:01,336 - INFO - Beginning epoch 77/800
2025-03-06 22:30:01,340 - INFO - training batch 1, loss: 1.065, 32/28000 datapoints
2025-03-06 22:30:01,543 - INFO - training batch 51, loss: 1.111, 1632/28000 datapoints
2025-03-06 22:30:01,697 - INFO - training batch 101, loss: 0.681, 3232/28000 datapoints
2025-03-06 22:30:01,868 - INFO - training batch 151, loss: 1.422, 4832/28000 datapoints
2025-03-06 22:30:02,025 - INFO - training batch 201, loss: 1.163, 6432/28000 datapoints
2025-03-06 22:30:02,180 - INFO - training batch 251, loss: 0.917, 8032/28000 datapoints
2025-03-06 22:30:02,343 - INFO - training batch 301, loss: 1.168, 9632/28000 datapoints
2025-03-06 22:30:02,501 - INFO - training batch 351, loss: 0.857, 11232/28000 datapoints
2025-03-06 22:30:02,663 - INFO - training batch 401, loss: 1.117, 12832/28000 datapoints
2025-03-06 22:30:02,819 - INFO - training batch 451, loss: 1.151, 14432/28000 datapoints
2025-03-06 22:30:02,977 - INFO - training batch 501, loss: 1.006, 16032/28000 datapoints
2025-03-06 22:30:03,132 - INFO - training batch 551, loss: 1.257, 17632/28000 datapoints
2025-03-06 22:30:03,288 - INFO - training batch 601, loss: 1.188, 19232/28000 datapoints
2025-03-06 22:30:03,447 - INFO - training batch 651, loss: 0.628, 20832/28000 datapoints
2025-03-06 22:30:03,606 - INFO - training batch 701, loss: 0.896, 22432/28000 datapoints
2025-03-06 22:30:03,761 - INFO - training batch 751, loss: 0.993, 24032/28000 datapoints
2025-03-06 22:30:03,919 - INFO - training batch 801, loss: 0.709, 25632/28000 datapoints
2025-03-06 22:30:04,076 - INFO - training batch 851, loss: 1.197, 27232/28000 datapoints
2025-03-06 22:30:04,155 - INFO - validation batch 1, loss: 0.703, 32/6976 datapoints
2025-03-06 22:30:04,205 - INFO - validation batch 51, loss: 1.738, 1632/6976 datapoints
2025-03-06 22:30:04,256 - INFO - validation batch 101, loss: 0.934, 3232/6976 datapoints
2025-03-06 22:30:04,308 - INFO - validation batch 151, loss: 1.038, 4832/6976 datapoints
2025-03-06 22:30:04,362 - INFO - validation batch 201, loss: 0.668, 6432/6976 datapoints
2025-03-06 22:30:04,385 - INFO - Epoch 77/800 done.
2025-03-06 22:30:04,385 - INFO - Final validation performance:
Loss: 1.016, top-1 acc: 0.659top-5 acc: 0.659
2025-03-06 22:30:04,385 - INFO - Beginning epoch 78/800
2025-03-06 22:30:04,390 - INFO - training batch 1, loss: 1.051, 32/28000 datapoints
2025-03-06 22:30:04,554 - INFO - training batch 51, loss: 1.093, 1632/28000 datapoints
2025-03-06 22:30:04,710 - INFO - training batch 101, loss: 0.665, 3232/28000 datapoints
2025-03-06 22:30:04,864 - INFO - training batch 151, loss: 1.411, 4832/28000 datapoints
2025-03-06 22:30:05,022 - INFO - training batch 201, loss: 1.141, 6432/28000 datapoints
2025-03-06 22:30:05,182 - INFO - training batch 251, loss: 0.907, 8032/28000 datapoints
2025-03-06 22:30:05,336 - INFO - training batch 301, loss: 1.156, 9632/28000 datapoints
2025-03-06 22:30:05,500 - INFO - training batch 351, loss: 0.839, 11232/28000 datapoints
2025-03-06 22:30:05,656 - INFO - training batch 401, loss: 1.112, 12832/28000 datapoints
2025-03-06 22:30:05,809 - INFO - training batch 451, loss: 1.139, 14432/28000 datapoints
2025-03-06 22:30:05,966 - INFO - training batch 501, loss: 0.997, 16032/28000 datapoints
2025-03-06 22:30:06,120 - INFO - training batch 551, loss: 1.245, 17632/28000 datapoints
2025-03-06 22:30:06,279 - INFO - training batch 601, loss: 1.180, 19232/28000 datapoints
2025-03-06 22:30:06,435 - INFO - training batch 651, loss: 0.615, 20832/28000 datapoints
2025-03-06 22:30:06,593 - INFO - training batch 701, loss: 0.883, 22432/28000 datapoints
2025-03-06 22:30:06,746 - INFO - training batch 751, loss: 0.969, 24032/28000 datapoints
2025-03-06 22:30:06,902 - INFO - training batch 801, loss: 0.697, 25632/28000 datapoints
2025-03-06 22:30:07,057 - INFO - training batch 851, loss: 1.191, 27232/28000 datapoints
2025-03-06 22:30:07,136 - INFO - validation batch 1, loss: 0.689, 32/6976 datapoints
2025-03-06 22:30:07,189 - INFO - validation batch 51, loss: 1.736, 1632/6976 datapoints
2025-03-06 22:30:07,243 - INFO - validation batch 101, loss: 0.915, 3232/6976 datapoints
2025-03-06 22:30:07,294 - INFO - validation batch 151, loss: 1.022, 4832/6976 datapoints
2025-03-06 22:30:07,349 - INFO - validation batch 201, loss: 0.661, 6432/6976 datapoints
2025-03-06 22:30:07,369 - INFO - Epoch 78/800 done.
2025-03-06 22:30:07,369 - INFO - Final validation performance:
Loss: 1.005, top-1 acc: 0.665top-5 acc: 0.665
2025-03-06 22:30:07,370 - INFO - Beginning epoch 79/800
2025-03-06 22:30:07,375 - INFO - training batch 1, loss: 1.036, 32/28000 datapoints
2025-03-06 22:30:07,538 - INFO - training batch 51, loss: 1.072, 1632/28000 datapoints
2025-03-06 22:30:07,693 - INFO - training batch 101, loss: 0.649, 3232/28000 datapoints
2025-03-06 22:30:07,848 - INFO - training batch 151, loss: 1.398, 4832/28000 datapoints
2025-03-06 22:30:08,020 - INFO - training batch 201, loss: 1.118, 6432/28000 datapoints
2025-03-06 22:30:08,173 - INFO - training batch 251, loss: 0.897, 8032/28000 datapoints
2025-03-06 22:30:08,326 - INFO - training batch 301, loss: 1.145, 9632/28000 datapoints
2025-03-06 22:30:08,493 - INFO - training batch 351, loss: 0.822, 11232/28000 datapoints
2025-03-06 22:30:08,653 - INFO - training batch 401, loss: 1.107, 12832/28000 datapoints
2025-03-06 22:30:08,808 - INFO - training batch 451, loss: 1.127, 14432/28000 datapoints
2025-03-06 22:30:08,966 - INFO - training batch 501, loss: 0.987, 16032/28000 datapoints
2025-03-06 22:30:09,122 - INFO - training batch 551, loss: 1.232, 17632/28000 datapoints
2025-03-06 22:30:09,278 - INFO - training batch 601, loss: 1.173, 19232/28000 datapoints
2025-03-06 22:30:09,436 - INFO - training batch 651, loss: 0.603, 20832/28000 datapoints
2025-03-06 22:30:09,593 - INFO - training batch 701, loss: 0.870, 22432/28000 datapoints
2025-03-06 22:30:09,773 - INFO - training batch 751, loss: 0.946, 24032/28000 datapoints
2025-03-06 22:30:09,935 - INFO - training batch 801, loss: 0.687, 25632/28000 datapoints
2025-03-06 22:30:10,091 - INFO - training batch 851, loss: 1.184, 27232/28000 datapoints
2025-03-06 22:30:10,171 - INFO - validation batch 1, loss: 0.675, 32/6976 datapoints
2025-03-06 22:30:10,223 - INFO - validation batch 51, loss: 1.735, 1632/6976 datapoints
2025-03-06 22:30:10,275 - INFO - validation batch 101, loss: 0.895, 3232/6976 datapoints
2025-03-06 22:30:10,329 - INFO - validation batch 151, loss: 1.006, 4832/6976 datapoints
2025-03-06 22:30:10,382 - INFO - validation batch 201, loss: 0.654, 6432/6976 datapoints
2025-03-06 22:30:10,399 - INFO - Epoch 79/800 done.
2025-03-06 22:30:10,399 - INFO - Final validation performance:
Loss: 0.993, top-1 acc: 0.670top-5 acc: 0.670
2025-03-06 22:30:10,399 - INFO - Beginning epoch 80/800
2025-03-06 22:30:10,404 - INFO - training batch 1, loss: 1.022, 32/28000 datapoints
2025-03-06 22:30:10,565 - INFO - training batch 51, loss: 1.051, 1632/28000 datapoints
2025-03-06 22:30:10,720 - INFO - training batch 101, loss: 0.633, 3232/28000 datapoints
2025-03-06 22:30:10,874 - INFO - training batch 151, loss: 1.384, 4832/28000 datapoints
2025-03-06 22:30:11,033 - INFO - training batch 201, loss: 1.095, 6432/28000 datapoints
2025-03-06 22:30:11,188 - INFO - training batch 251, loss: 0.886, 8032/28000 datapoints
2025-03-06 22:30:11,342 - INFO - training batch 301, loss: 1.128, 9632/28000 datapoints
2025-03-06 22:30:11,499 - INFO - training batch 351, loss: 0.805, 11232/28000 datapoints
2025-03-06 22:30:11,655 - INFO - training batch 401, loss: 1.102, 12832/28000 datapoints
2025-03-06 22:30:11,809 - INFO - training batch 451, loss: 1.115, 14432/28000 datapoints
2025-03-06 22:30:11,966 - INFO - training batch 501, loss: 0.977, 16032/28000 datapoints
2025-03-06 22:30:12,122 - INFO - training batch 551, loss: 1.217, 17632/28000 datapoints
2025-03-06 22:30:12,280 - INFO - training batch 601, loss: 1.166, 19232/28000 datapoints
2025-03-06 22:30:12,435 - INFO - training batch 651, loss: 0.592, 20832/28000 datapoints
2025-03-06 22:30:12,591 - INFO - training batch 701, loss: 0.857, 22432/28000 datapoints
2025-03-06 22:30:12,745 - INFO - training batch 751, loss: 0.924, 24032/28000 datapoints
2025-03-06 22:30:12,904 - INFO - training batch 801, loss: 0.675, 25632/28000 datapoints
2025-03-06 22:30:13,069 - INFO - training batch 851, loss: 1.177, 27232/28000 datapoints
2025-03-06 22:30:13,150 - INFO - validation batch 1, loss: 0.661, 32/6976 datapoints
2025-03-06 22:30:13,207 - INFO - validation batch 51, loss: 1.732, 1632/6976 datapoints
2025-03-06 22:30:13,264 - INFO - validation batch 101, loss: 0.875, 3232/6976 datapoints
2025-03-06 22:30:13,318 - INFO - validation batch 151, loss: 0.991, 4832/6976 datapoints
2025-03-06 22:30:13,370 - INFO - validation batch 201, loss: 0.648, 6432/6976 datapoints
2025-03-06 22:30:13,388 - INFO - Epoch 80/800 done.
2025-03-06 22:30:13,388 - INFO - Final validation performance:
Loss: 0.981, top-1 acc: 0.676top-5 acc: 0.676
2025-03-06 22:30:13,388 - INFO - Beginning epoch 81/800
2025-03-06 22:30:13,393 - INFO - training batch 1, loss: 1.008, 32/28000 datapoints
2025-03-06 22:30:13,551 - INFO - training batch 51, loss: 1.030, 1632/28000 datapoints
2025-03-06 22:30:13,704 - INFO - training batch 101, loss: 0.617, 3232/28000 datapoints
2025-03-06 22:30:13,854 - INFO - training batch 151, loss: 1.372, 4832/28000 datapoints
2025-03-06 22:30:14,027 - INFO - training batch 201, loss: 1.075, 6432/28000 datapoints
2025-03-06 22:30:14,179 - INFO - training batch 251, loss: 0.875, 8032/28000 datapoints
2025-03-06 22:30:14,330 - INFO - training batch 301, loss: 1.114, 9632/28000 datapoints
2025-03-06 22:30:14,489 - INFO - training batch 351, loss: 0.789, 11232/28000 datapoints
2025-03-06 22:30:14,646 - INFO - training batch 401, loss: 1.097, 12832/28000 datapoints
2025-03-06 22:30:14,801 - INFO - training batch 451, loss: 1.102, 14432/28000 datapoints
2025-03-06 22:30:14,954 - INFO - training batch 501, loss: 0.966, 16032/28000 datapoints
2025-03-06 22:30:15,107 - INFO - training batch 551, loss: 1.202, 17632/28000 datapoints
2025-03-06 22:30:15,264 - INFO - training batch 601, loss: 1.158, 19232/28000 datapoints
2025-03-06 22:30:15,417 - INFO - training batch 651, loss: 0.580, 20832/28000 datapoints
2025-03-06 22:30:15,575 - INFO - training batch 701, loss: 0.844, 22432/28000 datapoints
2025-03-06 22:30:15,727 - INFO - training batch 751, loss: 0.902, 24032/28000 datapoints
2025-03-06 22:30:15,876 - INFO - training batch 801, loss: 0.665, 25632/28000 datapoints
2025-03-06 22:30:16,031 - INFO - training batch 851, loss: 1.169, 27232/28000 datapoints
2025-03-06 22:30:16,104 - INFO - validation batch 1, loss: 0.647, 32/6976 datapoints
2025-03-06 22:30:16,152 - INFO - validation batch 51, loss: 1.727, 1632/6976 datapoints
2025-03-06 22:30:16,200 - INFO - validation batch 101, loss: 0.855, 3232/6976 datapoints
2025-03-06 22:30:16,249 - INFO - validation batch 151, loss: 0.977, 4832/6976 datapoints
2025-03-06 22:30:16,297 - INFO - validation batch 201, loss: 0.642, 6432/6976 datapoints
2025-03-06 22:30:16,313 - INFO - Epoch 81/800 done.
2025-03-06 22:30:16,314 - INFO - Final validation performance:
Loss: 0.970, top-1 acc: 0.682top-5 acc: 0.682
2025-03-06 22:30:16,314 - INFO - Beginning epoch 82/800
2025-03-06 22:30:16,318 - INFO - training batch 1, loss: 0.994, 32/28000 datapoints
2025-03-06 22:30:16,472 - INFO - training batch 51, loss: 1.008, 1632/28000 datapoints
2025-03-06 22:30:16,632 - INFO - training batch 101, loss: 0.601, 3232/28000 datapoints
2025-03-06 22:30:16,835 - INFO - training batch 151, loss: 1.357, 4832/28000 datapoints
2025-03-06 22:30:17,011 - INFO - training batch 201, loss: 1.056, 6432/28000 datapoints
2025-03-06 22:30:17,175 - INFO - training batch 251, loss: 0.864, 8032/28000 datapoints
2025-03-06 22:30:17,333 - INFO - training batch 301, loss: 1.100, 9632/28000 datapoints
2025-03-06 22:30:17,487 - INFO - training batch 351, loss: 0.772, 11232/28000 datapoints
2025-03-06 22:30:17,649 - INFO - training batch 401, loss: 1.091, 12832/28000 datapoints
2025-03-06 22:30:17,804 - INFO - training batch 451, loss: 1.089, 14432/28000 datapoints
2025-03-06 22:30:17,965 - INFO - training batch 501, loss: 0.954, 16032/28000 datapoints
2025-03-06 22:30:18,122 - INFO - training batch 551, loss: 1.188, 17632/28000 datapoints
2025-03-06 22:30:18,277 - INFO - training batch 601, loss: 1.152, 19232/28000 datapoints
2025-03-06 22:30:18,433 - INFO - training batch 651, loss: 0.570, 20832/28000 datapoints
2025-03-06 22:30:18,588 - INFO - training batch 701, loss: 0.830, 22432/28000 datapoints
2025-03-06 22:30:18,743 - INFO - training batch 751, loss: 0.882, 24032/28000 datapoints
2025-03-06 22:30:18,898 - INFO - training batch 801, loss: 0.654, 25632/28000 datapoints
2025-03-06 22:30:19,054 - INFO - training batch 851, loss: 1.160, 27232/28000 datapoints
2025-03-06 22:30:19,134 - INFO - validation batch 1, loss: 0.634, 32/6976 datapoints
2025-03-06 22:30:19,186 - INFO - validation batch 51, loss: 1.721, 1632/6976 datapoints
2025-03-06 22:30:19,237 - INFO - validation batch 101, loss: 0.835, 3232/6976 datapoints
2025-03-06 22:30:19,289 - INFO - validation batch 151, loss: 0.963, 4832/6976 datapoints
2025-03-06 22:30:19,342 - INFO - validation batch 201, loss: 0.635, 6432/6976 datapoints
2025-03-06 22:30:19,359 - INFO - Epoch 82/800 done.
2025-03-06 22:30:19,359 - INFO - Final validation performance:
Loss: 0.958, top-1 acc: 0.687top-5 acc: 0.687
2025-03-06 22:30:19,360 - INFO - Beginning epoch 83/800
2025-03-06 22:30:19,365 - INFO - training batch 1, loss: 0.979, 32/28000 datapoints
2025-03-06 22:30:19,520 - INFO - training batch 51, loss: 0.987, 1632/28000 datapoints
2025-03-06 22:30:19,681 - INFO - training batch 101, loss: 0.586, 3232/28000 datapoints
2025-03-06 22:30:19,855 - INFO - training batch 151, loss: 1.343, 4832/28000 datapoints
2025-03-06 22:30:20,033 - INFO - training batch 201, loss: 1.037, 6432/28000 datapoints
2025-03-06 22:30:20,183 - INFO - training batch 251, loss: 0.852, 8032/28000 datapoints
2025-03-06 22:30:20,335 - INFO - training batch 301, loss: 1.087, 9632/28000 datapoints
2025-03-06 22:30:20,492 - INFO - training batch 351, loss: 0.754, 11232/28000 datapoints
2025-03-06 22:30:20,648 - INFO - training batch 401, loss: 1.085, 12832/28000 datapoints
2025-03-06 22:30:20,800 - INFO - training batch 451, loss: 1.075, 14432/28000 datapoints
2025-03-06 22:30:20,968 - INFO - training batch 501, loss: 0.942, 16032/28000 datapoints
2025-03-06 22:30:21,121 - INFO - training batch 551, loss: 1.172, 17632/28000 datapoints
2025-03-06 22:30:21,274 - INFO - training batch 601, loss: 1.146, 19232/28000 datapoints
2025-03-06 22:30:21,427 - INFO - training batch 651, loss: 0.559, 20832/28000 datapoints
2025-03-06 22:30:21,580 - INFO - training batch 701, loss: 0.816, 22432/28000 datapoints
2025-03-06 22:30:21,731 - INFO - training batch 751, loss: 0.860, 24032/28000 datapoints
2025-03-06 22:30:21,881 - INFO - training batch 801, loss: 0.644, 25632/28000 datapoints
2025-03-06 22:30:22,036 - INFO - training batch 851, loss: 1.151, 27232/28000 datapoints
2025-03-06 22:30:22,112 - INFO - validation batch 1, loss: 0.620, 32/6976 datapoints
2025-03-06 22:30:22,161 - INFO - validation batch 51, loss: 1.713, 1632/6976 datapoints
2025-03-06 22:30:22,209 - INFO - validation batch 101, loss: 0.814, 3232/6976 datapoints
2025-03-06 22:30:22,259 - INFO - validation batch 151, loss: 0.951, 4832/6976 datapoints
2025-03-06 22:30:22,306 - INFO - validation batch 201, loss: 0.628, 6432/6976 datapoints
2025-03-06 22:30:22,323 - INFO - Epoch 83/800 done.
2025-03-06 22:30:22,323 - INFO - Final validation performance:
Loss: 0.945, top-1 acc: 0.695top-5 acc: 0.695
2025-03-06 22:30:22,324 - INFO - Beginning epoch 84/800
2025-03-06 22:30:22,328 - INFO - training batch 1, loss: 0.965, 32/28000 datapoints
2025-03-06 22:30:22,482 - INFO - training batch 51, loss: 0.966, 1632/28000 datapoints
2025-03-06 22:30:22,638 - INFO - training batch 101, loss: 0.569, 3232/28000 datapoints
2025-03-06 22:30:22,790 - INFO - training batch 151, loss: 1.329, 4832/28000 datapoints
2025-03-06 22:30:22,944 - INFO - training batch 201, loss: 1.017, 6432/28000 datapoints
2025-03-06 22:30:23,104 - INFO - training batch 251, loss: 0.839, 8032/28000 datapoints
2025-03-06 22:30:23,256 - INFO - training batch 301, loss: 1.074, 9632/28000 datapoints
2025-03-06 22:30:23,406 - INFO - training batch 351, loss: 0.736, 11232/28000 datapoints
2025-03-06 22:30:23,562 - INFO - training batch 401, loss: 1.080, 12832/28000 datapoints
2025-03-06 22:30:23,713 - INFO - training batch 451, loss: 1.060, 14432/28000 datapoints
2025-03-06 22:30:23,864 - INFO - training batch 501, loss: 0.928, 16032/28000 datapoints
2025-03-06 22:30:24,018 - INFO - training batch 551, loss: 1.153, 17632/28000 datapoints
2025-03-06 22:30:24,170 - INFO - training batch 601, loss: 1.138, 19232/28000 datapoints
2025-03-06 22:30:24,323 - INFO - training batch 651, loss: 0.549, 20832/28000 datapoints
2025-03-06 22:30:24,474 - INFO - training batch 701, loss: 0.802, 22432/28000 datapoints
2025-03-06 22:30:24,628 - INFO - training batch 751, loss: 0.836, 24032/28000 datapoints
2025-03-06 22:30:24,786 - INFO - training batch 801, loss: 0.634, 25632/28000 datapoints
2025-03-06 22:30:24,942 - INFO - training batch 851, loss: 1.142, 27232/28000 datapoints
2025-03-06 22:30:25,016 - INFO - validation batch 1, loss: 0.607, 32/6976 datapoints
2025-03-06 22:30:25,063 - INFO - validation batch 51, loss: 1.707, 1632/6976 datapoints
2025-03-06 22:30:25,112 - INFO - validation batch 101, loss: 0.793, 3232/6976 datapoints
2025-03-06 22:30:25,169 - INFO - validation batch 151, loss: 0.938, 4832/6976 datapoints
2025-03-06 22:30:25,217 - INFO - validation batch 201, loss: 0.622, 6432/6976 datapoints
2025-03-06 22:30:25,234 - INFO - Epoch 84/800 done.
2025-03-06 22:30:25,234 - INFO - Final validation performance:
Loss: 0.933, top-1 acc: 0.702top-5 acc: 0.702
2025-03-06 22:30:25,235 - INFO - Beginning epoch 85/800
2025-03-06 22:30:25,239 - INFO - training batch 1, loss: 0.949, 32/28000 datapoints
2025-03-06 22:30:25,395 - INFO - training batch 51, loss: 0.943, 1632/28000 datapoints
2025-03-06 22:30:25,547 - INFO - training batch 101, loss: 0.552, 3232/28000 datapoints
2025-03-06 22:30:25,704 - INFO - training batch 151, loss: 1.314, 4832/28000 datapoints
2025-03-06 22:30:25,857 - INFO - training batch 201, loss: 0.996, 6432/28000 datapoints
2025-03-06 22:30:26,020 - INFO - training batch 251, loss: 0.825, 8032/28000 datapoints
2025-03-06 22:30:26,176 - INFO - training batch 301, loss: 1.058, 9632/28000 datapoints
2025-03-06 22:30:26,329 - INFO - training batch 351, loss: 0.716, 11232/28000 datapoints
2025-03-06 22:30:26,488 - INFO - training batch 401, loss: 1.074, 12832/28000 datapoints
2025-03-06 22:30:26,644 - INFO - training batch 451, loss: 1.044, 14432/28000 datapoints
2025-03-06 22:30:26,801 - INFO - training batch 501, loss: 0.915, 16032/28000 datapoints
2025-03-06 22:30:26,954 - INFO - training batch 551, loss: 1.134, 17632/28000 datapoints
2025-03-06 22:30:27,105 - INFO - training batch 601, loss: 1.129, 19232/28000 datapoints
2025-03-06 22:30:27,259 - INFO - training batch 651, loss: 0.538, 20832/28000 datapoints
2025-03-06 22:30:27,412 - INFO - training batch 701, loss: 0.788, 22432/28000 datapoints
2025-03-06 22:30:27,570 - INFO - training batch 751, loss: 0.812, 24032/28000 datapoints
2025-03-06 22:30:27,727 - INFO - training batch 801, loss: 0.624, 25632/28000 datapoints
2025-03-06 22:30:27,878 - INFO - training batch 851, loss: 1.132, 27232/28000 datapoints
2025-03-06 22:30:27,955 - INFO - validation batch 1, loss: 0.594, 32/6976 datapoints
2025-03-06 22:30:28,002 - INFO - validation batch 51, loss: 1.697, 1632/6976 datapoints
2025-03-06 22:30:28,051 - INFO - validation batch 101, loss: 0.773, 3232/6976 datapoints
2025-03-06 22:30:28,098 - INFO - validation batch 151, loss: 0.925, 4832/6976 datapoints
2025-03-06 22:30:28,147 - INFO - validation batch 201, loss: 0.614, 6432/6976 datapoints
2025-03-06 22:30:28,164 - INFO - Epoch 85/800 done.
2025-03-06 22:30:28,164 - INFO - Final validation performance:
Loss: 0.920, top-1 acc: 0.708top-5 acc: 0.708
2025-03-06 22:30:28,164 - INFO - Beginning epoch 86/800
2025-03-06 22:30:28,169 - INFO - training batch 1, loss: 0.935, 32/28000 datapoints
2025-03-06 22:30:28,332 - INFO - training batch 51, loss: 0.920, 1632/28000 datapoints
2025-03-06 22:30:28,491 - INFO - training batch 101, loss: 0.536, 3232/28000 datapoints
2025-03-06 22:30:28,653 - INFO - training batch 151, loss: 1.300, 4832/28000 datapoints
2025-03-06 22:30:28,808 - INFO - training batch 201, loss: 0.978, 6432/28000 datapoints
2025-03-06 22:30:28,964 - INFO - training batch 251, loss: 0.810, 8032/28000 datapoints
2025-03-06 22:30:29,116 - INFO - training batch 301, loss: 1.043, 9632/28000 datapoints
2025-03-06 22:30:29,268 - INFO - training batch 351, loss: 0.697, 11232/28000 datapoints
2025-03-06 22:30:29,450 - INFO - training batch 401, loss: 1.068, 12832/28000 datapoints
2025-03-06 22:30:29,615 - INFO - training batch 451, loss: 1.028, 14432/28000 datapoints
2025-03-06 22:30:29,769 - INFO - training batch 501, loss: 0.901, 16032/28000 datapoints
2025-03-06 22:30:29,942 - INFO - training batch 551, loss: 1.115, 17632/28000 datapoints
2025-03-06 22:30:30,108 - INFO - training batch 601, loss: 1.122, 19232/28000 datapoints
2025-03-06 22:30:30,260 - INFO - training batch 651, loss: 0.527, 20832/28000 datapoints
2025-03-06 22:30:30,413 - INFO - training batch 701, loss: 0.774, 22432/28000 datapoints
2025-03-06 22:30:30,565 - INFO - training batch 751, loss: 0.788, 24032/28000 datapoints
2025-03-06 22:30:30,718 - INFO - training batch 801, loss: 0.614, 25632/28000 datapoints
2025-03-06 22:30:30,871 - INFO - training batch 851, loss: 1.124, 27232/28000 datapoints
2025-03-06 22:30:30,947 - INFO - validation batch 1, loss: 0.582, 32/6976 datapoints
2025-03-06 22:30:30,995 - INFO - validation batch 51, loss: 1.687, 1632/6976 datapoints
2025-03-06 22:30:31,042 - INFO - validation batch 101, loss: 0.753, 3232/6976 datapoints
2025-03-06 22:30:31,091 - INFO - validation batch 151, loss: 0.912, 4832/6976 datapoints
2025-03-06 22:30:31,139 - INFO - validation batch 201, loss: 0.607, 6432/6976 datapoints
2025-03-06 22:30:31,155 - INFO - Epoch 86/800 done.
2025-03-06 22:30:31,155 - INFO - Final validation performance:
Loss: 0.908, top-1 acc: 0.713top-5 acc: 0.713
2025-03-06 22:30:31,156 - INFO - Beginning epoch 87/800
2025-03-06 22:30:31,160 - INFO - training batch 1, loss: 0.920, 32/28000 datapoints
2025-03-06 22:30:31,315 - INFO - training batch 51, loss: 0.897, 1632/28000 datapoints
2025-03-06 22:30:31,470 - INFO - training batch 101, loss: 0.520, 3232/28000 datapoints
2025-03-06 22:30:31,626 - INFO - training batch 151, loss: 1.285, 4832/28000 datapoints
2025-03-06 22:30:31,779 - INFO - training batch 201, loss: 0.957, 6432/28000 datapoints
2025-03-06 22:30:31,933 - INFO - training batch 251, loss: 0.795, 8032/28000 datapoints
2025-03-06 22:30:32,090 - INFO - training batch 301, loss: 1.029, 9632/28000 datapoints
2025-03-06 22:30:32,249 - INFO - training batch 351, loss: 0.678, 11232/28000 datapoints
2025-03-06 22:30:32,402 - INFO - training batch 401, loss: 1.063, 12832/28000 datapoints
2025-03-06 22:30:32,553 - INFO - training batch 451, loss: 1.013, 14432/28000 datapoints
2025-03-06 22:30:32,716 - INFO - training batch 501, loss: 0.887, 16032/28000 datapoints
2025-03-06 22:30:32,870 - INFO - training batch 551, loss: 1.094, 17632/28000 datapoints
2025-03-06 22:30:33,026 - INFO - training batch 601, loss: 1.113, 19232/28000 datapoints
2025-03-06 22:30:33,177 - INFO - training batch 651, loss: 0.516, 20832/28000 datapoints
2025-03-06 22:30:33,331 - INFO - training batch 701, loss: 0.760, 22432/28000 datapoints
2025-03-06 22:30:33,483 - INFO - training batch 751, loss: 0.766, 24032/28000 datapoints
2025-03-06 22:30:33,638 - INFO - training batch 801, loss: 0.604, 25632/28000 datapoints
2025-03-06 22:30:33,790 - INFO - training batch 851, loss: 1.117, 27232/28000 datapoints
2025-03-06 22:30:33,864 - INFO - validation batch 1, loss: 0.569, 32/6976 datapoints
2025-03-06 22:30:33,911 - INFO - validation batch 51, loss: 1.677, 1632/6976 datapoints
2025-03-06 22:30:33,962 - INFO - validation batch 101, loss: 0.732, 3232/6976 datapoints
2025-03-06 22:30:34,009 - INFO - validation batch 151, loss: 0.900, 4832/6976 datapoints
2025-03-06 22:30:34,057 - INFO - validation batch 201, loss: 0.599, 6432/6976 datapoints
2025-03-06 22:30:34,073 - INFO - Epoch 87/800 done.
2025-03-06 22:30:34,074 - INFO - Final validation performance:
Loss: 0.895, top-1 acc: 0.720top-5 acc: 0.720
2025-03-06 22:30:34,074 - INFO - Beginning epoch 88/800
2025-03-06 22:30:34,078 - INFO - training batch 1, loss: 0.905, 32/28000 datapoints
2025-03-06 22:30:34,237 - INFO - training batch 51, loss: 0.874, 1632/28000 datapoints
2025-03-06 22:30:34,390 - INFO - training batch 101, loss: 0.506, 3232/28000 datapoints
2025-03-06 22:30:34,542 - INFO - training batch 151, loss: 1.270, 4832/28000 datapoints
2025-03-06 22:30:34,693 - INFO - training batch 201, loss: 0.935, 6432/28000 datapoints
2025-03-06 22:30:34,848 - INFO - training batch 251, loss: 0.781, 8032/28000 datapoints
2025-03-06 22:30:35,007 - INFO - training batch 301, loss: 1.016, 9632/28000 datapoints
2025-03-06 22:30:35,159 - INFO - training batch 351, loss: 0.660, 11232/28000 datapoints
2025-03-06 22:30:35,317 - INFO - training batch 401, loss: 1.058, 12832/28000 datapoints
2025-03-06 22:30:35,471 - INFO - training batch 451, loss: 0.998, 14432/28000 datapoints
2025-03-06 22:30:35,626 - INFO - training batch 501, loss: 0.873, 16032/28000 datapoints
2025-03-06 22:30:35,780 - INFO - training batch 551, loss: 1.074, 17632/28000 datapoints
2025-03-06 22:30:35,935 - INFO - training batch 601, loss: 1.104, 19232/28000 datapoints
2025-03-06 22:30:36,088 - INFO - training batch 651, loss: 0.505, 20832/28000 datapoints
2025-03-06 22:30:36,238 - INFO - training batch 701, loss: 0.747, 22432/28000 datapoints
2025-03-06 22:30:36,392 - INFO - training batch 751, loss: 0.744, 24032/28000 datapoints
2025-03-06 22:30:36,544 - INFO - training batch 801, loss: 0.594, 25632/28000 datapoints
2025-03-06 22:30:36,695 - INFO - training batch 851, loss: 1.110, 27232/28000 datapoints
2025-03-06 22:30:36,772 - INFO - validation batch 1, loss: 0.556, 32/6976 datapoints
2025-03-06 22:30:36,820 - INFO - validation batch 51, loss: 1.665, 1632/6976 datapoints
2025-03-06 22:30:36,867 - INFO - validation batch 101, loss: 0.712, 3232/6976 datapoints
2025-03-06 22:30:36,915 - INFO - validation batch 151, loss: 0.886, 4832/6976 datapoints
2025-03-06 22:30:36,964 - INFO - validation batch 201, loss: 0.593, 6432/6976 datapoints
2025-03-06 22:30:36,980 - INFO - Epoch 88/800 done.
2025-03-06 22:30:36,981 - INFO - Final validation performance:
Loss: 0.883, top-1 acc: 0.724top-5 acc: 0.724
2025-03-06 22:30:36,981 - INFO - Beginning epoch 89/800
2025-03-06 22:30:36,985 - INFO - training batch 1, loss: 0.890, 32/28000 datapoints
2025-03-06 22:30:37,138 - INFO - training batch 51, loss: 0.852, 1632/28000 datapoints
2025-03-06 22:30:37,299 - INFO - training batch 101, loss: 0.492, 3232/28000 datapoints
2025-03-06 22:30:37,455 - INFO - training batch 151, loss: 1.255, 4832/28000 datapoints
2025-03-06 22:30:37,615 - INFO - training batch 201, loss: 0.911, 6432/28000 datapoints
2025-03-06 22:30:37,775 - INFO - training batch 251, loss: 0.767, 8032/28000 datapoints
2025-03-06 22:30:37,943 - INFO - training batch 301, loss: 1.002, 9632/28000 datapoints
2025-03-06 22:30:38,101 - INFO - training batch 351, loss: 0.641, 11232/28000 datapoints
2025-03-06 22:30:38,268 - INFO - training batch 401, loss: 1.052, 12832/28000 datapoints
2025-03-06 22:30:38,424 - INFO - training batch 451, loss: 0.983, 14432/28000 datapoints
2025-03-06 22:30:38,585 - INFO - training batch 501, loss: 0.857, 16032/28000 datapoints
2025-03-06 22:30:38,744 - INFO - training batch 551, loss: 1.052, 17632/28000 datapoints
2025-03-06 22:30:38,902 - INFO - training batch 601, loss: 1.097, 19232/28000 datapoints
2025-03-06 22:30:39,065 - INFO - training batch 651, loss: 0.493, 20832/28000 datapoints
2025-03-06 22:30:39,224 - INFO - training batch 701, loss: 0.733, 22432/28000 datapoints
2025-03-06 22:30:39,381 - INFO - training batch 751, loss: 0.723, 24032/28000 datapoints
2025-03-06 22:30:39,537 - INFO - training batch 801, loss: 0.583, 25632/28000 datapoints
2025-03-06 22:30:39,694 - INFO - training batch 851, loss: 1.102, 27232/28000 datapoints
2025-03-06 22:30:39,773 - INFO - validation batch 1, loss: 0.545, 32/6976 datapoints
2025-03-06 22:30:39,826 - INFO - validation batch 51, loss: 1.654, 1632/6976 datapoints
2025-03-06 22:30:39,881 - INFO - validation batch 101, loss: 0.692, 3232/6976 datapoints
2025-03-06 22:30:39,939 - INFO - validation batch 151, loss: 0.873, 4832/6976 datapoints
2025-03-06 22:30:39,997 - INFO - validation batch 201, loss: 0.585, 6432/6976 datapoints
2025-03-06 22:30:40,021 - INFO - Epoch 89/800 done.
2025-03-06 22:30:40,022 - INFO - Final validation performance:
Loss: 0.870, top-1 acc: 0.729top-5 acc: 0.729
2025-03-06 22:30:40,023 - INFO - Beginning epoch 90/800
2025-03-06 22:30:40,029 - INFO - training batch 1, loss: 0.874, 32/28000 datapoints
2025-03-06 22:30:40,194 - INFO - training batch 51, loss: 0.830, 1632/28000 datapoints
2025-03-06 22:30:40,351 - INFO - training batch 101, loss: 0.478, 3232/28000 datapoints
2025-03-06 22:30:40,506 - INFO - training batch 151, loss: 1.238, 4832/28000 datapoints
2025-03-06 22:30:40,658 - INFO - training batch 201, loss: 0.888, 6432/28000 datapoints
2025-03-06 22:30:40,813 - INFO - training batch 251, loss: 0.752, 8032/28000 datapoints
2025-03-06 22:30:40,966 - INFO - training batch 301, loss: 0.988, 9632/28000 datapoints
2025-03-06 22:30:41,122 - INFO - training batch 351, loss: 0.621, 11232/28000 datapoints
2025-03-06 22:30:41,274 - INFO - training batch 401, loss: 1.044, 12832/28000 datapoints
2025-03-06 22:30:41,430 - INFO - training batch 451, loss: 0.968, 14432/28000 datapoints
2025-03-06 22:30:41,581 - INFO - training batch 501, loss: 0.840, 16032/28000 datapoints
2025-03-06 22:30:41,738 - INFO - training batch 551, loss: 1.031, 17632/28000 datapoints
2025-03-06 22:30:41,890 - INFO - training batch 601, loss: 1.089, 19232/28000 datapoints
2025-03-06 22:30:42,044 - INFO - training batch 651, loss: 0.482, 20832/28000 datapoints
2025-03-06 22:30:42,196 - INFO - training batch 701, loss: 0.720, 22432/28000 datapoints
2025-03-06 22:30:42,350 - INFO - training batch 751, loss: 0.700, 24032/28000 datapoints
2025-03-06 22:30:42,502 - INFO - training batch 801, loss: 0.572, 25632/28000 datapoints
2025-03-06 22:30:42,653 - INFO - training batch 851, loss: 1.094, 27232/28000 datapoints
2025-03-06 22:30:42,730 - INFO - validation batch 1, loss: 0.534, 32/6976 datapoints
2025-03-06 22:30:42,777 - INFO - validation batch 51, loss: 1.639, 1632/6976 datapoints
2025-03-06 22:30:42,826 - INFO - validation batch 101, loss: 0.673, 3232/6976 datapoints
2025-03-06 22:30:42,873 - INFO - validation batch 151, loss: 0.860, 4832/6976 datapoints
2025-03-06 22:30:42,921 - INFO - validation batch 201, loss: 0.578, 6432/6976 datapoints
2025-03-06 22:30:42,939 - INFO - Epoch 90/800 done.
2025-03-06 22:30:42,940 - INFO - Final validation performance:
Loss: 0.857, top-1 acc: 0.735top-5 acc: 0.735
2025-03-06 22:30:42,940 - INFO - Beginning epoch 91/800
2025-03-06 22:30:42,944 - INFO - training batch 1, loss: 0.860, 32/28000 datapoints
2025-03-06 22:30:43,098 - INFO - training batch 51, loss: 0.808, 1632/28000 datapoints
2025-03-06 22:30:43,263 - INFO - training batch 101, loss: 0.465, 3232/28000 datapoints
2025-03-06 22:30:43,420 - INFO - training batch 151, loss: 1.221, 4832/28000 datapoints
2025-03-06 22:30:43,574 - INFO - training batch 201, loss: 0.865, 6432/28000 datapoints
2025-03-06 22:30:43,729 - INFO - training batch 251, loss: 0.738, 8032/28000 datapoints
2025-03-06 22:30:43,883 - INFO - training batch 301, loss: 0.975, 9632/28000 datapoints
2025-03-06 22:30:44,064 - INFO - training batch 351, loss: 0.601, 11232/28000 datapoints
2025-03-06 22:30:44,266 - INFO - training batch 401, loss: 1.038, 12832/28000 datapoints
2025-03-06 22:30:44,427 - INFO - training batch 451, loss: 0.952, 14432/28000 datapoints
2025-03-06 22:30:44,578 - INFO - training batch 501, loss: 0.823, 16032/28000 datapoints
2025-03-06 22:30:44,748 - INFO - training batch 551, loss: 1.010, 17632/28000 datapoints
2025-03-06 22:30:44,905 - INFO - training batch 601, loss: 1.080, 19232/28000 datapoints
2025-03-06 22:30:45,067 - INFO - training batch 651, loss: 0.470, 20832/28000 datapoints
2025-03-06 22:30:45,234 - INFO - training batch 701, loss: 0.707, 22432/28000 datapoints
2025-03-06 22:30:45,394 - INFO - training batch 751, loss: 0.680, 24032/28000 datapoints
2025-03-06 22:30:45,546 - INFO - training batch 801, loss: 0.562, 25632/28000 datapoints
2025-03-06 22:30:45,700 - INFO - training batch 851, loss: 1.086, 27232/28000 datapoints
2025-03-06 22:30:45,776 - INFO - validation batch 1, loss: 0.522, 32/6976 datapoints
2025-03-06 22:30:45,825 - INFO - validation batch 51, loss: 1.627, 1632/6976 datapoints
2025-03-06 22:30:45,874 - INFO - validation batch 101, loss: 0.654, 3232/6976 datapoints
2025-03-06 22:30:45,921 - INFO - validation batch 151, loss: 0.848, 4832/6976 datapoints
2025-03-06 22:30:45,985 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 22:30:46,003 - INFO - Epoch 91/800 done.
2025-03-06 22:30:46,003 - INFO - Final validation performance:
Loss: 0.844, top-1 acc: 0.739top-5 acc: 0.739
2025-03-06 22:30:46,004 - INFO - Beginning epoch 92/800
2025-03-06 22:30:46,009 - INFO - training batch 1, loss: 0.845, 32/28000 datapoints
2025-03-06 22:30:46,183 - INFO - training batch 51, loss: 0.786, 1632/28000 datapoints
2025-03-06 22:30:46,335 - INFO - training batch 101, loss: 0.452, 3232/28000 datapoints
2025-03-06 22:30:46,490 - INFO - training batch 151, loss: 1.203, 4832/28000 datapoints
2025-03-06 22:30:46,646 - INFO - training batch 201, loss: 0.841, 6432/28000 datapoints
2025-03-06 22:30:46,799 - INFO - training batch 251, loss: 0.723, 8032/28000 datapoints
2025-03-06 22:30:46,953 - INFO - training batch 301, loss: 0.962, 9632/28000 datapoints
2025-03-06 22:30:47,108 - INFO - training batch 351, loss: 0.583, 11232/28000 datapoints
2025-03-06 22:30:47,270 - INFO - training batch 401, loss: 1.031, 12832/28000 datapoints
2025-03-06 22:30:47,422 - INFO - training batch 451, loss: 0.937, 14432/28000 datapoints
2025-03-06 22:30:47,576 - INFO - training batch 501, loss: 0.806, 16032/28000 datapoints
2025-03-06 22:30:47,737 - INFO - training batch 551, loss: 0.988, 17632/28000 datapoints
2025-03-06 22:30:47,890 - INFO - training batch 601, loss: 1.072, 19232/28000 datapoints
2025-03-06 22:30:48,044 - INFO - training batch 651, loss: 0.457, 20832/28000 datapoints
2025-03-06 22:30:48,197 - INFO - training batch 701, loss: 0.694, 22432/28000 datapoints
2025-03-06 22:30:48,347 - INFO - training batch 751, loss: 0.659, 24032/28000 datapoints
2025-03-06 22:30:48,502 - INFO - training batch 801, loss: 0.551, 25632/28000 datapoints
2025-03-06 22:30:48,653 - INFO - training batch 851, loss: 1.078, 27232/28000 datapoints
2025-03-06 22:30:48,729 - INFO - validation batch 1, loss: 0.510, 32/6976 datapoints
2025-03-06 22:30:48,777 - INFO - validation batch 51, loss: 1.613, 1632/6976 datapoints
2025-03-06 22:30:48,828 - INFO - validation batch 101, loss: 0.635, 3232/6976 datapoints
2025-03-06 22:30:48,878 - INFO - validation batch 151, loss: 0.835, 4832/6976 datapoints
2025-03-06 22:30:48,929 - INFO - validation batch 201, loss: 0.565, 6432/6976 datapoints
2025-03-06 22:30:48,949 - INFO - Epoch 92/800 done.
2025-03-06 22:30:48,949 - INFO - Final validation performance:
Loss: 0.832, top-1 acc: 0.744top-5 acc: 0.744
2025-03-06 22:30:48,950 - INFO - Beginning epoch 93/800
2025-03-06 22:30:48,954 - INFO - training batch 1, loss: 0.830, 32/28000 datapoints
2025-03-06 22:30:49,113 - INFO - training batch 51, loss: 0.763, 1632/28000 datapoints
2025-03-06 22:30:49,268 - INFO - training batch 101, loss: 0.439, 3232/28000 datapoints
2025-03-06 22:30:49,437 - INFO - training batch 151, loss: 1.186, 4832/28000 datapoints
2025-03-06 22:30:49,600 - INFO - training batch 201, loss: 0.815, 6432/28000 datapoints
2025-03-06 22:30:49,763 - INFO - training batch 251, loss: 0.709, 8032/28000 datapoints
2025-03-06 22:30:49,930 - INFO - training batch 301, loss: 0.950, 9632/28000 datapoints
2025-03-06 22:30:50,105 - INFO - training batch 351, loss: 0.566, 11232/28000 datapoints
2025-03-06 22:30:50,279 - INFO - training batch 401, loss: 1.025, 12832/28000 datapoints
2025-03-06 22:30:50,446 - INFO - training batch 451, loss: 0.920, 14432/28000 datapoints
2025-03-06 22:30:50,599 - INFO - training batch 501, loss: 0.790, 16032/28000 datapoints
2025-03-06 22:30:50,757 - INFO - training batch 551, loss: 0.965, 17632/28000 datapoints
2025-03-06 22:30:50,914 - INFO - training batch 601, loss: 1.064, 19232/28000 datapoints
2025-03-06 22:30:51,071 - INFO - training batch 651, loss: 0.446, 20832/28000 datapoints
2025-03-06 22:30:51,227 - INFO - training batch 701, loss: 0.682, 22432/28000 datapoints
2025-03-06 22:30:51,379 - INFO - training batch 751, loss: 0.639, 24032/28000 datapoints
2025-03-06 22:30:51,534 - INFO - training batch 801, loss: 0.541, 25632/28000 datapoints
2025-03-06 22:30:51,701 - INFO - training batch 851, loss: 1.069, 27232/28000 datapoints
2025-03-06 22:30:51,790 - INFO - validation batch 1, loss: 0.499, 32/6976 datapoints
2025-03-06 22:30:51,838 - INFO - validation batch 51, loss: 1.600, 1632/6976 datapoints
2025-03-06 22:30:51,885 - INFO - validation batch 101, loss: 0.617, 3232/6976 datapoints
2025-03-06 22:30:51,935 - INFO - validation batch 151, loss: 0.822, 4832/6976 datapoints
2025-03-06 22:30:51,985 - INFO - validation batch 201, loss: 0.560, 6432/6976 datapoints
2025-03-06 22:30:52,001 - INFO - Epoch 93/800 done.
2025-03-06 22:30:52,001 - INFO - Final validation performance:
Loss: 0.820, top-1 acc: 0.748top-5 acc: 0.748
2025-03-06 22:30:52,001 - INFO - Beginning epoch 94/800
2025-03-06 22:30:52,006 - INFO - training batch 1, loss: 0.815, 32/28000 datapoints
2025-03-06 22:30:52,161 - INFO - training batch 51, loss: 0.741, 1632/28000 datapoints
2025-03-06 22:30:52,315 - INFO - training batch 101, loss: 0.428, 3232/28000 datapoints
2025-03-06 22:30:52,471 - INFO - training batch 151, loss: 1.169, 4832/28000 datapoints
2025-03-06 22:30:52,624 - INFO - training batch 201, loss: 0.791, 6432/28000 datapoints
2025-03-06 22:30:52,777 - INFO - training batch 251, loss: 0.695, 8032/28000 datapoints
2025-03-06 22:30:52,932 - INFO - training batch 301, loss: 0.939, 9632/28000 datapoints
2025-03-06 22:30:53,090 - INFO - training batch 351, loss: 0.549, 11232/28000 datapoints
2025-03-06 22:30:53,243 - INFO - training batch 401, loss: 1.018, 12832/28000 datapoints
2025-03-06 22:30:53,396 - INFO - training batch 451, loss: 0.904, 14432/28000 datapoints
2025-03-06 22:30:53,550 - INFO - training batch 501, loss: 0.773, 16032/28000 datapoints
2025-03-06 22:30:53,706 - INFO - training batch 551, loss: 0.942, 17632/28000 datapoints
2025-03-06 22:30:53,858 - INFO - training batch 601, loss: 1.057, 19232/28000 datapoints
2025-03-06 22:30:54,012 - INFO - training batch 651, loss: 0.435, 20832/28000 datapoints
2025-03-06 22:30:54,166 - INFO - training batch 701, loss: 0.670, 22432/28000 datapoints
2025-03-06 22:30:54,319 - INFO - training batch 751, loss: 0.621, 24032/28000 datapoints
2025-03-06 22:30:54,474 - INFO - training batch 801, loss: 0.531, 25632/28000 datapoints
2025-03-06 22:30:54,627 - INFO - training batch 851, loss: 1.061, 27232/28000 datapoints
2025-03-06 22:30:54,701 - INFO - validation batch 1, loss: 0.487, 32/6976 datapoints
2025-03-06 22:30:54,750 - INFO - validation batch 51, loss: 1.587, 1632/6976 datapoints
2025-03-06 22:30:54,801 - INFO - validation batch 101, loss: 0.600, 3232/6976 datapoints
2025-03-06 22:30:54,863 - INFO - validation batch 151, loss: 0.811, 4832/6976 datapoints
2025-03-06 22:30:54,911 - INFO - validation batch 201, loss: 0.555, 6432/6976 datapoints
2025-03-06 22:30:54,928 - INFO - Epoch 94/800 done.
2025-03-06 22:30:54,928 - INFO - Final validation performance:
Loss: 0.808, top-1 acc: 0.753top-5 acc: 0.753
2025-03-06 22:30:54,928 - INFO - Beginning epoch 95/800
2025-03-06 22:30:54,934 - INFO - training batch 1, loss: 0.801, 32/28000 datapoints
2025-03-06 22:30:55,090 - INFO - training batch 51, loss: 0.719, 1632/28000 datapoints
2025-03-06 22:30:55,248 - INFO - training batch 101, loss: 0.417, 3232/28000 datapoints
2025-03-06 22:30:55,404 - INFO - training batch 151, loss: 1.151, 4832/28000 datapoints
2025-03-06 22:30:55,558 - INFO - training batch 201, loss: 0.765, 6432/28000 datapoints
2025-03-06 22:30:55,713 - INFO - training batch 251, loss: 0.683, 8032/28000 datapoints
2025-03-06 22:30:55,866 - INFO - training batch 301, loss: 0.928, 9632/28000 datapoints
2025-03-06 22:30:56,021 - INFO - training batch 351, loss: 0.534, 11232/28000 datapoints
2025-03-06 22:30:56,172 - INFO - training batch 401, loss: 1.011, 12832/28000 datapoints
2025-03-06 22:30:56,325 - INFO - training batch 451, loss: 0.889, 14432/28000 datapoints
2025-03-06 22:30:56,493 - INFO - training batch 501, loss: 0.756, 16032/28000 datapoints
2025-03-06 22:30:56,650 - INFO - training batch 551, loss: 0.920, 17632/28000 datapoints
2025-03-06 22:30:56,802 - INFO - training batch 601, loss: 1.049, 19232/28000 datapoints
2025-03-06 22:30:56,965 - INFO - training batch 651, loss: 0.425, 20832/28000 datapoints
2025-03-06 22:30:57,120 - INFO - training batch 701, loss: 0.659, 22432/28000 datapoints
2025-03-06 22:30:57,275 - INFO - training batch 751, loss: 0.604, 24032/28000 datapoints
2025-03-06 22:30:57,435 - INFO - training batch 801, loss: 0.521, 25632/28000 datapoints
2025-03-06 22:30:57,593 - INFO - training batch 851, loss: 1.053, 27232/28000 datapoints
2025-03-06 22:30:57,675 - INFO - validation batch 1, loss: 0.475, 32/6976 datapoints
2025-03-06 22:30:57,728 - INFO - validation batch 51, loss: 1.575, 1632/6976 datapoints
2025-03-06 22:30:57,783 - INFO - validation batch 101, loss: 0.584, 3232/6976 datapoints
2025-03-06 22:30:57,835 - INFO - validation batch 151, loss: 0.801, 4832/6976 datapoints
2025-03-06 22:30:57,885 - INFO - validation batch 201, loss: 0.551, 6432/6976 datapoints
2025-03-06 22:30:57,901 - INFO - Epoch 95/800 done.
2025-03-06 22:30:57,902 - INFO - Final validation performance:
Loss: 0.797, top-1 acc: 0.758top-5 acc: 0.758
2025-03-06 22:30:57,902 - INFO - Beginning epoch 96/800
2025-03-06 22:30:57,907 - INFO - training batch 1, loss: 0.787, 32/28000 datapoints
2025-03-06 22:30:58,075 - INFO - training batch 51, loss: 0.698, 1632/28000 datapoints
2025-03-06 22:30:58,229 - INFO - training batch 101, loss: 0.406, 3232/28000 datapoints
2025-03-06 22:30:58,387 - INFO - training batch 151, loss: 1.134, 4832/28000 datapoints
2025-03-06 22:30:58,549 - INFO - training batch 201, loss: 0.741, 6432/28000 datapoints
2025-03-06 22:30:58,706 - INFO - training batch 251, loss: 0.671, 8032/28000 datapoints
2025-03-06 22:30:58,868 - INFO - training batch 301, loss: 0.918, 9632/28000 datapoints
2025-03-06 22:30:59,028 - INFO - training batch 351, loss: 0.520, 11232/28000 datapoints
2025-03-06 22:30:59,188 - INFO - training batch 401, loss: 1.005, 12832/28000 datapoints
2025-03-06 22:30:59,344 - INFO - training batch 451, loss: 0.872, 14432/28000 datapoints
2025-03-06 22:30:59,502 - INFO - training batch 501, loss: 0.740, 16032/28000 datapoints
2025-03-06 22:30:59,661 - INFO - training batch 551, loss: 0.898, 17632/28000 datapoints
2025-03-06 22:30:59,822 - INFO - training batch 601, loss: 1.041, 19232/28000 datapoints
2025-03-06 22:30:59,987 - INFO - training batch 651, loss: 0.414, 20832/28000 datapoints
2025-03-06 22:31:00,146 - INFO - training batch 701, loss: 0.648, 22432/28000 datapoints
2025-03-06 22:31:00,325 - INFO - training batch 751, loss: 0.586, 24032/28000 datapoints
2025-03-06 22:31:00,482 - INFO - training batch 801, loss: 0.511, 25632/28000 datapoints
2025-03-06 22:31:00,640 - INFO - training batch 851, loss: 1.046, 27232/28000 datapoints
2025-03-06 22:31:00,718 - INFO - validation batch 1, loss: 0.464, 32/6976 datapoints
2025-03-06 22:31:00,771 - INFO - validation batch 51, loss: 1.565, 1632/6976 datapoints
2025-03-06 22:31:00,824 - INFO - validation batch 101, loss: 0.568, 3232/6976 datapoints
2025-03-06 22:31:00,881 - INFO - validation batch 151, loss: 0.791, 4832/6976 datapoints
2025-03-06 22:31:00,936 - INFO - validation batch 201, loss: 0.549, 6432/6976 datapoints
2025-03-06 22:31:00,952 - INFO - Epoch 96/800 done.
2025-03-06 22:31:00,952 - INFO - Final validation performance:
Loss: 0.787, top-1 acc: 0.762top-5 acc: 0.762
2025-03-06 22:31:00,953 - INFO - Beginning epoch 97/800
2025-03-06 22:31:00,957 - INFO - training batch 1, loss: 0.773, 32/28000 datapoints
2025-03-06 22:31:01,122 - INFO - training batch 51, loss: 0.678, 1632/28000 datapoints
2025-03-06 22:31:01,279 - INFO - training batch 101, loss: 0.396, 3232/28000 datapoints
2025-03-06 22:31:01,440 - INFO - training batch 151, loss: 1.116, 4832/28000 datapoints
2025-03-06 22:31:01,598 - INFO - training batch 201, loss: 0.715, 6432/28000 datapoints
2025-03-06 22:31:01,758 - INFO - training batch 251, loss: 0.659, 8032/28000 datapoints
2025-03-06 22:31:01,918 - INFO - training batch 301, loss: 0.909, 9632/28000 datapoints
2025-03-06 22:31:02,080 - INFO - training batch 351, loss: 0.508, 11232/28000 datapoints
2025-03-06 22:31:02,238 - INFO - training batch 401, loss: 0.998, 12832/28000 datapoints
2025-03-06 22:31:02,399 - INFO - training batch 451, loss: 0.857, 14432/28000 datapoints
2025-03-06 22:31:02,568 - INFO - training batch 501, loss: 0.723, 16032/28000 datapoints
2025-03-06 22:31:02,726 - INFO - training batch 551, loss: 0.876, 17632/28000 datapoints
2025-03-06 22:31:02,891 - INFO - training batch 601, loss: 1.034, 19232/28000 datapoints
2025-03-06 22:31:03,054 - INFO - training batch 651, loss: 0.402, 20832/28000 datapoints
2025-03-06 22:31:03,211 - INFO - training batch 701, loss: 0.638, 22432/28000 datapoints
2025-03-06 22:31:03,371 - INFO - training batch 751, loss: 0.570, 24032/28000 datapoints
2025-03-06 22:31:03,527 - INFO - training batch 801, loss: 0.502, 25632/28000 datapoints
2025-03-06 22:31:03,684 - INFO - training batch 851, loss: 1.038, 27232/28000 datapoints
2025-03-06 22:31:03,764 - INFO - validation batch 1, loss: 0.454, 32/6976 datapoints
2025-03-06 22:31:03,817 - INFO - validation batch 51, loss: 1.553, 1632/6976 datapoints
2025-03-06 22:31:03,871 - INFO - validation batch 101, loss: 0.553, 3232/6976 datapoints
2025-03-06 22:31:03,925 - INFO - validation batch 151, loss: 0.782, 4832/6976 datapoints
2025-03-06 22:31:03,979 - INFO - validation batch 201, loss: 0.545, 6432/6976 datapoints
2025-03-06 22:31:03,996 - INFO - Epoch 97/800 done.
2025-03-06 22:31:03,996 - INFO - Final validation performance:
Loss: 0.777, top-1 acc: 0.766top-5 acc: 0.766
2025-03-06 22:31:03,997 - INFO - Beginning epoch 98/800
2025-03-06 22:31:04,001 - INFO - training batch 1, loss: 0.759, 32/28000 datapoints
2025-03-06 22:31:04,168 - INFO - training batch 51, loss: 0.657, 1632/28000 datapoints
2025-03-06 22:31:04,324 - INFO - training batch 101, loss: 0.386, 3232/28000 datapoints
2025-03-06 22:31:04,481 - INFO - training batch 151, loss: 1.098, 4832/28000 datapoints
2025-03-06 22:31:04,639 - INFO - training batch 201, loss: 0.693, 6432/28000 datapoints
2025-03-06 22:31:04,797 - INFO - training batch 251, loss: 0.649, 8032/28000 datapoints
2025-03-06 22:31:04,958 - INFO - training batch 301, loss: 0.901, 9632/28000 datapoints
2025-03-06 22:31:05,116 - INFO - training batch 351, loss: 0.498, 11232/28000 datapoints
2025-03-06 22:31:05,282 - INFO - training batch 401, loss: 0.992, 12832/28000 datapoints
2025-03-06 22:31:05,440 - INFO - training batch 451, loss: 0.841, 14432/28000 datapoints
2025-03-06 22:31:05,599 - INFO - training batch 501, loss: 0.707, 16032/28000 datapoints
2025-03-06 22:31:05,762 - INFO - training batch 551, loss: 0.856, 17632/28000 datapoints
2025-03-06 22:31:05,921 - INFO - training batch 601, loss: 1.029, 19232/28000 datapoints
2025-03-06 22:31:06,082 - INFO - training batch 651, loss: 0.391, 20832/28000 datapoints
2025-03-06 22:31:06,240 - INFO - training batch 701, loss: 0.627, 22432/28000 datapoints
2025-03-06 22:31:06,397 - INFO - training batch 751, loss: 0.555, 24032/28000 datapoints
2025-03-06 22:31:06,557 - INFO - training batch 801, loss: 0.492, 25632/28000 datapoints
2025-03-06 22:31:06,715 - INFO - training batch 851, loss: 1.031, 27232/28000 datapoints
2025-03-06 22:31:06,793 - INFO - validation batch 1, loss: 0.445, 32/6976 datapoints
2025-03-06 22:31:06,847 - INFO - validation batch 51, loss: 1.543, 1632/6976 datapoints
2025-03-06 22:31:06,901 - INFO - validation batch 101, loss: 0.537, 3232/6976 datapoints
2025-03-06 22:31:06,955 - INFO - validation batch 151, loss: 0.771, 4832/6976 datapoints
2025-03-06 22:31:07,006 - INFO - validation batch 201, loss: 0.544, 6432/6976 datapoints
2025-03-06 22:31:07,025 - INFO - Epoch 98/800 done.
2025-03-06 22:31:07,025 - INFO - Final validation performance:
Loss: 0.768, top-1 acc: 0.770top-5 acc: 0.770
2025-03-06 22:31:07,026 - INFO - Beginning epoch 99/800
2025-03-06 22:31:07,030 - INFO - training batch 1, loss: 0.744, 32/28000 datapoints
2025-03-06 22:31:07,188 - INFO - training batch 51, loss: 0.637, 1632/28000 datapoints
2025-03-06 22:31:07,340 - INFO - training batch 101, loss: 0.377, 3232/28000 datapoints
2025-03-06 22:31:07,494 - INFO - training batch 151, loss: 1.080, 4832/28000 datapoints
2025-03-06 22:31:07,649 - INFO - training batch 201, loss: 0.669, 6432/28000 datapoints
2025-03-06 22:31:07,806 - INFO - training batch 251, loss: 0.639, 8032/28000 datapoints
2025-03-06 22:31:07,961 - INFO - training batch 301, loss: 0.893, 9632/28000 datapoints
2025-03-06 22:31:08,113 - INFO - training batch 351, loss: 0.489, 11232/28000 datapoints
2025-03-06 22:31:08,266 - INFO - training batch 401, loss: 0.984, 12832/28000 datapoints
2025-03-06 22:31:08,418 - INFO - training batch 451, loss: 0.826, 14432/28000 datapoints
2025-03-06 22:31:08,583 - INFO - training batch 501, loss: 0.691, 16032/28000 datapoints
2025-03-06 22:31:08,737 - INFO - training batch 551, loss: 0.837, 17632/28000 datapoints
2025-03-06 22:31:08,891 - INFO - training batch 601, loss: 1.023, 19232/28000 datapoints
2025-03-06 22:31:09,055 - INFO - training batch 651, loss: 0.378, 20832/28000 datapoints
2025-03-06 22:31:09,209 - INFO - training batch 701, loss: 0.617, 22432/28000 datapoints
2025-03-06 22:31:09,368 - INFO - training batch 751, loss: 0.541, 24032/28000 datapoints
2025-03-06 22:31:09,525 - INFO - training batch 801, loss: 0.482, 25632/28000 datapoints
2025-03-06 22:31:09,677 - INFO - training batch 851, loss: 1.022, 27232/28000 datapoints
2025-03-06 22:31:09,755 - INFO - validation batch 1, loss: 0.435, 32/6976 datapoints
2025-03-06 22:31:09,803 - INFO - validation batch 51, loss: 1.532, 1632/6976 datapoints
2025-03-06 22:31:09,851 - INFO - validation batch 101, loss: 0.523, 3232/6976 datapoints
2025-03-06 22:31:09,900 - INFO - validation batch 151, loss: 0.764, 4832/6976 datapoints
2025-03-06 22:31:09,953 - INFO - validation batch 201, loss: 0.542, 6432/6976 datapoints
2025-03-06 22:31:09,974 - INFO - Epoch 99/800 done.
2025-03-06 22:31:09,974 - INFO - Final validation performance:
Loss: 0.759, top-1 acc: 0.774top-5 acc: 0.774
2025-03-06 22:31:09,974 - INFO - Beginning epoch 100/800
2025-03-06 22:31:09,979 - INFO - training batch 1, loss: 0.732, 32/28000 datapoints
2025-03-06 22:31:10,132 - INFO - training batch 51, loss: 0.618, 1632/28000 datapoints
2025-03-06 22:31:10,293 - INFO - training batch 101, loss: 0.367, 3232/28000 datapoints
2025-03-06 22:31:10,467 - INFO - training batch 151, loss: 1.064, 4832/28000 datapoints
2025-03-06 22:31:10,622 - INFO - training batch 201, loss: 0.648, 6432/28000 datapoints
2025-03-06 22:31:10,776 - INFO - training batch 251, loss: 0.629, 8032/28000 datapoints
2025-03-06 22:31:10,932 - INFO - training batch 301, loss: 0.887, 9632/28000 datapoints
2025-03-06 22:31:11,085 - INFO - training batch 351, loss: 0.481, 11232/28000 datapoints
2025-03-06 22:31:11,239 - INFO - training batch 401, loss: 0.979, 12832/28000 datapoints
2025-03-06 22:31:11,391 - INFO - training batch 451, loss: 0.810, 14432/28000 datapoints
2025-03-06 22:31:11,542 - INFO - training batch 501, loss: 0.675, 16032/28000 datapoints
2025-03-06 22:31:11,697 - INFO - training batch 551, loss: 0.817, 17632/28000 datapoints
2025-03-06 22:31:11,853 - INFO - training batch 601, loss: 1.016, 19232/28000 datapoints
2025-03-06 22:31:12,009 - INFO - training batch 651, loss: 0.366, 20832/28000 datapoints
2025-03-06 22:31:12,162 - INFO - training batch 701, loss: 0.606, 22432/28000 datapoints
2025-03-06 22:31:12,318 - INFO - training batch 751, loss: 0.528, 24032/28000 datapoints
2025-03-06 22:31:12,470 - INFO - training batch 801, loss: 0.472, 25632/28000 datapoints
2025-03-06 22:31:12,623 - INFO - training batch 851, loss: 1.013, 27232/28000 datapoints
2025-03-06 22:31:12,701 - INFO - validation batch 1, loss: 0.424, 32/6976 datapoints
2025-03-06 22:31:12,749 - INFO - validation batch 51, loss: 1.521, 1632/6976 datapoints
2025-03-06 22:31:12,797 - INFO - validation batch 101, loss: 0.509, 3232/6976 datapoints
2025-03-06 22:31:12,846 - INFO - validation batch 151, loss: 0.757, 4832/6976 datapoints
2025-03-06 22:31:12,894 - INFO - validation batch 201, loss: 0.540, 6432/6976 datapoints
2025-03-06 22:31:12,911 - INFO - Epoch 100/800 done.
2025-03-06 22:31:12,911 - INFO - Final validation performance:
Loss: 0.750, top-1 acc: 0.777top-5 acc: 0.777
2025-03-06 22:31:12,911 - INFO - Beginning epoch 101/800
2025-03-06 22:31:12,916 - INFO - training batch 1, loss: 0.719, 32/28000 datapoints
2025-03-06 22:31:13,071 - INFO - training batch 51, loss: 0.600, 1632/28000 datapoints
2025-03-06 22:31:13,226 - INFO - training batch 101, loss: 0.359, 3232/28000 datapoints
2025-03-06 22:31:13,379 - INFO - training batch 151, loss: 1.048, 4832/28000 datapoints
2025-03-06 22:31:13,531 - INFO - training batch 201, loss: 0.632, 6432/28000 datapoints
2025-03-06 22:31:13,684 - INFO - training batch 251, loss: 0.621, 8032/28000 datapoints
2025-03-06 22:31:13,841 - INFO - training batch 301, loss: 0.881, 9632/28000 datapoints
2025-03-06 22:31:13,997 - INFO - training batch 351, loss: 0.473, 11232/28000 datapoints
2025-03-06 22:31:14,148 - INFO - training batch 401, loss: 0.971, 12832/28000 datapoints
2025-03-06 22:31:14,302 - INFO - training batch 451, loss: 0.794, 14432/28000 datapoints
2025-03-06 22:31:14,458 - INFO - training batch 501, loss: 0.659, 16032/28000 datapoints
2025-03-06 22:31:14,611 - INFO - training batch 551, loss: 0.798, 17632/28000 datapoints
2025-03-06 22:31:14,781 - INFO - training batch 601, loss: 1.006, 19232/28000 datapoints
2025-03-06 22:31:14,935 - INFO - training batch 651, loss: 0.354, 20832/28000 datapoints
2025-03-06 22:31:15,087 - INFO - training batch 701, loss: 0.597, 22432/28000 datapoints
2025-03-06 22:31:15,252 - INFO - training batch 751, loss: 0.517, 24032/28000 datapoints
2025-03-06 22:31:15,408 - INFO - training batch 801, loss: 0.462, 25632/28000 datapoints
2025-03-06 22:31:15,564 - INFO - training batch 851, loss: 1.004, 27232/28000 datapoints
2025-03-06 22:31:15,640 - INFO - validation batch 1, loss: 0.414, 32/6976 datapoints
2025-03-06 22:31:15,690 - INFO - validation batch 51, loss: 1.510, 1632/6976 datapoints
2025-03-06 22:31:15,740 - INFO - validation batch 101, loss: 0.494, 3232/6976 datapoints
2025-03-06 22:31:15,791 - INFO - validation batch 151, loss: 0.750, 4832/6976 datapoints
2025-03-06 22:31:15,840 - INFO - validation batch 201, loss: 0.538, 6432/6976 datapoints
2025-03-06 22:31:15,856 - INFO - Epoch 101/800 done.
2025-03-06 22:31:15,856 - INFO - Final validation performance:
Loss: 0.741, top-1 acc: 0.782top-5 acc: 0.782
2025-03-06 22:31:15,857 - INFO - Beginning epoch 102/800
2025-03-06 22:31:15,861 - INFO - training batch 1, loss: 0.706, 32/28000 datapoints
2025-03-06 22:31:16,020 - INFO - training batch 51, loss: 0.582, 1632/28000 datapoints
2025-03-06 22:31:16,173 - INFO - training batch 101, loss: 0.351, 3232/28000 datapoints
2025-03-06 22:31:16,327 - INFO - training batch 151, loss: 1.034, 4832/28000 datapoints
2025-03-06 22:31:16,480 - INFO - training batch 201, loss: 0.617, 6432/28000 datapoints
2025-03-06 22:31:16,633 - INFO - training batch 251, loss: 0.613, 8032/28000 datapoints
2025-03-06 22:31:16,789 - INFO - training batch 301, loss: 0.876, 9632/28000 datapoints
2025-03-06 22:31:16,945 - INFO - training batch 351, loss: 0.465, 11232/28000 datapoints
2025-03-06 22:31:17,098 - INFO - training batch 401, loss: 0.966, 12832/28000 datapoints
2025-03-06 22:31:17,253 - INFO - training batch 451, loss: 0.780, 14432/28000 datapoints
2025-03-06 22:31:17,428 - INFO - training batch 501, loss: 0.645, 16032/28000 datapoints
2025-03-06 22:31:17,589 - INFO - training batch 551, loss: 0.779, 17632/28000 datapoints
2025-03-06 22:31:17,748 - INFO - training batch 601, loss: 0.997, 19232/28000 datapoints
2025-03-06 22:31:17,913 - INFO - training batch 651, loss: 0.343, 20832/28000 datapoints
2025-03-06 22:31:18,073 - INFO - training batch 701, loss: 0.588, 22432/28000 datapoints
2025-03-06 22:31:18,270 - INFO - training batch 751, loss: 0.506, 24032/28000 datapoints
2025-03-06 22:31:18,501 - INFO - training batch 801, loss: 0.453, 25632/28000 datapoints
2025-03-06 22:31:18,686 - INFO - training batch 851, loss: 0.995, 27232/28000 datapoints
2025-03-06 22:31:18,775 - INFO - validation batch 1, loss: 0.402, 32/6976 datapoints
2025-03-06 22:31:18,827 - INFO - validation batch 51, loss: 1.497, 1632/6976 datapoints
2025-03-06 22:31:18,878 - INFO - validation batch 101, loss: 0.485, 3232/6976 datapoints
2025-03-06 22:31:18,927 - INFO - validation batch 151, loss: 0.744, 4832/6976 datapoints
2025-03-06 22:31:18,977 - INFO - validation batch 201, loss: 0.536, 6432/6976 datapoints
2025-03-06 22:31:18,994 - INFO - Epoch 102/800 done.
2025-03-06 22:31:18,994 - INFO - Final validation performance:
Loss: 0.733, top-1 acc: 0.786top-5 acc: 0.786
2025-03-06 22:31:18,995 - INFO - Beginning epoch 103/800
2025-03-06 22:31:18,999 - INFO - training batch 1, loss: 0.694, 32/28000 datapoints
2025-03-06 22:31:19,153 - INFO - training batch 51, loss: 0.565, 1632/28000 datapoints
2025-03-06 22:31:19,307 - INFO - training batch 101, loss: 0.344, 3232/28000 datapoints
2025-03-06 22:31:19,459 - INFO - training batch 151, loss: 1.020, 4832/28000 datapoints
2025-03-06 22:31:19,610 - INFO - training batch 201, loss: 0.604, 6432/28000 datapoints
2025-03-06 22:31:19,762 - INFO - training batch 251, loss: 0.606, 8032/28000 datapoints
2025-03-06 22:31:19,919 - INFO - training batch 301, loss: 0.871, 9632/28000 datapoints
2025-03-06 22:31:20,079 - INFO - training batch 351, loss: 0.459, 11232/28000 datapoints
2025-03-06 22:31:20,230 - INFO - training batch 401, loss: 0.961, 12832/28000 datapoints
2025-03-06 22:31:20,391 - INFO - training batch 451, loss: 0.766, 14432/28000 datapoints
2025-03-06 22:31:20,566 - INFO - training batch 501, loss: 0.630, 16032/28000 datapoints
2025-03-06 22:31:20,723 - INFO - training batch 551, loss: 0.761, 17632/28000 datapoints
2025-03-06 22:31:20,893 - INFO - training batch 601, loss: 0.986, 19232/28000 datapoints
2025-03-06 22:31:21,049 - INFO - training batch 651, loss: 0.332, 20832/28000 datapoints
2025-03-06 22:31:21,211 - INFO - training batch 701, loss: 0.579, 22432/28000 datapoints
2025-03-06 22:31:21,364 - INFO - training batch 751, loss: 0.496, 24032/28000 datapoints
2025-03-06 22:31:21,518 - INFO - training batch 801, loss: 0.445, 25632/28000 datapoints
2025-03-06 22:31:21,675 - INFO - training batch 851, loss: 0.986, 27232/28000 datapoints
2025-03-06 22:31:21,749 - INFO - validation batch 1, loss: 0.391, 32/6976 datapoints
2025-03-06 22:31:21,800 - INFO - validation batch 51, loss: 1.487, 1632/6976 datapoints
2025-03-06 22:31:21,848 - INFO - validation batch 101, loss: 0.473, 3232/6976 datapoints
2025-03-06 22:31:21,896 - INFO - validation batch 151, loss: 0.737, 4832/6976 datapoints
2025-03-06 22:31:21,946 - INFO - validation batch 201, loss: 0.535, 6432/6976 datapoints
2025-03-06 22:31:21,962 - INFO - Epoch 103/800 done.
2025-03-06 22:31:21,963 - INFO - Final validation performance:
Loss: 0.725, top-1 acc: 0.789top-5 acc: 0.789
2025-03-06 22:31:21,963 - INFO - Beginning epoch 104/800
2025-03-06 22:31:21,968 - INFO - training batch 1, loss: 0.683, 32/28000 datapoints
2025-03-06 22:31:22,123 - INFO - training batch 51, loss: 0.550, 1632/28000 datapoints
2025-03-06 22:31:22,276 - INFO - training batch 101, loss: 0.337, 3232/28000 datapoints
2025-03-06 22:31:22,430 - INFO - training batch 151, loss: 1.007, 4832/28000 datapoints
2025-03-06 22:31:22,584 - INFO - training batch 201, loss: 0.591, 6432/28000 datapoints
2025-03-06 22:31:22,735 - INFO - training batch 251, loss: 0.599, 8032/28000 datapoints
2025-03-06 22:31:22,888 - INFO - training batch 301, loss: 0.867, 9632/28000 datapoints
2025-03-06 22:31:23,043 - INFO - training batch 351, loss: 0.453, 11232/28000 datapoints
2025-03-06 22:31:23,195 - INFO - training batch 401, loss: 0.954, 12832/28000 datapoints
2025-03-06 22:31:23,348 - INFO - training batch 451, loss: 0.753, 14432/28000 datapoints
2025-03-06 22:31:23,498 - INFO - training batch 501, loss: 0.617, 16032/28000 datapoints
2025-03-06 22:31:23,652 - INFO - training batch 551, loss: 0.745, 17632/28000 datapoints
2025-03-06 22:31:23,808 - INFO - training batch 601, loss: 0.979, 19232/28000 datapoints
2025-03-06 22:31:23,964 - INFO - training batch 651, loss: 0.322, 20832/28000 datapoints
2025-03-06 22:31:24,117 - INFO - training batch 701, loss: 0.570, 22432/28000 datapoints
2025-03-06 22:31:24,267 - INFO - training batch 751, loss: 0.487, 24032/28000 datapoints
2025-03-06 22:31:24,419 - INFO - training batch 801, loss: 0.438, 25632/28000 datapoints
2025-03-06 22:31:24,570 - INFO - training batch 851, loss: 0.976, 27232/28000 datapoints
2025-03-06 22:31:24,644 - INFO - validation batch 1, loss: 0.381, 32/6976 datapoints
2025-03-06 22:31:24,692 - INFO - validation batch 51, loss: 1.475, 1632/6976 datapoints
2025-03-06 22:31:24,740 - INFO - validation batch 101, loss: 0.460, 3232/6976 datapoints
2025-03-06 22:31:24,790 - INFO - validation batch 151, loss: 0.730, 4832/6976 datapoints
2025-03-06 22:31:24,839 - INFO - validation batch 201, loss: 0.533, 6432/6976 datapoints
2025-03-06 22:31:24,855 - INFO - Epoch 104/800 done.
2025-03-06 22:31:24,856 - INFO - Final validation performance:
Loss: 0.716, top-1 acc: 0.792top-5 acc: 0.792
2025-03-06 22:31:24,856 - INFO - Beginning epoch 105/800
2025-03-06 22:31:24,861 - INFO - training batch 1, loss: 0.672, 32/28000 datapoints
2025-03-06 22:31:25,017 - INFO - training batch 51, loss: 0.534, 1632/28000 datapoints
2025-03-06 22:31:25,178 - INFO - training batch 101, loss: 0.330, 3232/28000 datapoints
2025-03-06 22:31:25,330 - INFO - training batch 151, loss: 0.994, 4832/28000 datapoints
2025-03-06 22:31:25,484 - INFO - training batch 201, loss: 0.579, 6432/28000 datapoints
2025-03-06 22:31:25,634 - INFO - training batch 251, loss: 0.593, 8032/28000 datapoints
2025-03-06 22:31:25,790 - INFO - training batch 301, loss: 0.863, 9632/28000 datapoints
2025-03-06 22:31:25,946 - INFO - training batch 351, loss: 0.448, 11232/28000 datapoints
2025-03-06 22:31:26,110 - INFO - training batch 401, loss: 0.949, 12832/28000 datapoints
2025-03-06 22:31:26,262 - INFO - training batch 451, loss: 0.740, 14432/28000 datapoints
2025-03-06 22:31:26,415 - INFO - training batch 501, loss: 0.603, 16032/28000 datapoints
2025-03-06 22:31:26,569 - INFO - training batch 551, loss: 0.728, 17632/28000 datapoints
2025-03-06 22:31:26,732 - INFO - training batch 601, loss: 0.968, 19232/28000 datapoints
2025-03-06 22:31:26,891 - INFO - training batch 651, loss: 0.312, 20832/28000 datapoints
2025-03-06 22:31:27,061 - INFO - training batch 701, loss: 0.562, 22432/28000 datapoints
2025-03-06 22:31:27,215 - INFO - training batch 751, loss: 0.478, 24032/28000 datapoints
2025-03-06 22:31:27,372 - INFO - training batch 801, loss: 0.431, 25632/28000 datapoints
2025-03-06 22:31:27,526 - INFO - training batch 851, loss: 0.967, 27232/28000 datapoints
2025-03-06 22:31:27,604 - INFO - validation batch 1, loss: 0.371, 32/6976 datapoints
2025-03-06 22:31:27,651 - INFO - validation batch 51, loss: 1.467, 1632/6976 datapoints
2025-03-06 22:31:27,699 - INFO - validation batch 101, loss: 0.449, 3232/6976 datapoints
2025-03-06 22:31:27,746 - INFO - validation batch 151, loss: 0.724, 4832/6976 datapoints
2025-03-06 22:31:27,802 - INFO - validation batch 201, loss: 0.534, 6432/6976 datapoints
2025-03-06 22:31:27,818 - INFO - Epoch 105/800 done.
2025-03-06 22:31:27,818 - INFO - Final validation performance:
Loss: 0.709, top-1 acc: 0.795top-5 acc: 0.795
2025-03-06 22:31:27,819 - INFO - Beginning epoch 106/800
2025-03-06 22:31:27,823 - INFO - training batch 1, loss: 0.661, 32/28000 datapoints
2025-03-06 22:31:27,985 - INFO - training batch 51, loss: 0.519, 1632/28000 datapoints
2025-03-06 22:31:28,137 - INFO - training batch 101, loss: 0.323, 3232/28000 datapoints
2025-03-06 22:31:28,290 - INFO - training batch 151, loss: 0.981, 4832/28000 datapoints
2025-03-06 22:31:28,444 - INFO - training batch 201, loss: 0.569, 6432/28000 datapoints
2025-03-06 22:31:28,595 - INFO - training batch 251, loss: 0.587, 8032/28000 datapoints
2025-03-06 22:31:28,757 - INFO - training batch 301, loss: 0.859, 9632/28000 datapoints
2025-03-06 22:31:28,915 - INFO - training batch 351, loss: 0.442, 11232/28000 datapoints
2025-03-06 22:31:29,069 - INFO - training batch 401, loss: 0.943, 12832/28000 datapoints
2025-03-06 22:31:29,222 - INFO - training batch 451, loss: 0.728, 14432/28000 datapoints
2025-03-06 22:31:29,376 - INFO - training batch 501, loss: 0.591, 16032/28000 datapoints
2025-03-06 22:31:29,529 - INFO - training batch 551, loss: 0.714, 17632/28000 datapoints
2025-03-06 22:31:29,683 - INFO - training batch 601, loss: 0.959, 19232/28000 datapoints
2025-03-06 22:31:29,870 - INFO - training batch 651, loss: 0.303, 20832/28000 datapoints
2025-03-06 22:31:30,042 - INFO - training batch 701, loss: 0.554, 22432/28000 datapoints
2025-03-06 22:31:30,196 - INFO - training batch 751, loss: 0.470, 24032/28000 datapoints
2025-03-06 22:31:30,347 - INFO - training batch 801, loss: 0.424, 25632/28000 datapoints
2025-03-06 22:31:30,513 - INFO - training batch 851, loss: 0.958, 27232/28000 datapoints
2025-03-06 22:31:30,601 - INFO - validation batch 1, loss: 0.360, 32/6976 datapoints
2025-03-06 22:31:30,648 - INFO - validation batch 51, loss: 1.458, 1632/6976 datapoints
2025-03-06 22:31:30,696 - INFO - validation batch 101, loss: 0.439, 3232/6976 datapoints
2025-03-06 22:31:30,744 - INFO - validation batch 151, loss: 0.720, 4832/6976 datapoints
2025-03-06 22:31:30,791 - INFO - validation batch 201, loss: 0.534, 6432/6976 datapoints
2025-03-06 22:31:30,809 - INFO - Epoch 106/800 done.
2025-03-06 22:31:30,809 - INFO - Final validation performance:
Loss: 0.702, top-1 acc: 0.798top-5 acc: 0.798
2025-03-06 22:31:30,809 - INFO - Beginning epoch 107/800
2025-03-06 22:31:30,814 - INFO - training batch 1, loss: 0.649, 32/28000 datapoints
2025-03-06 22:31:30,973 - INFO - training batch 51, loss: 0.505, 1632/28000 datapoints
2025-03-06 22:31:31,126 - INFO - training batch 101, loss: 0.318, 3232/28000 datapoints
2025-03-06 22:31:31,279 - INFO - training batch 151, loss: 0.969, 4832/28000 datapoints
2025-03-06 22:31:31,431 - INFO - training batch 201, loss: 0.561, 6432/28000 datapoints
2025-03-06 22:31:31,584 - INFO - training batch 251, loss: 0.581, 8032/28000 datapoints
2025-03-06 22:31:31,735 - INFO - training batch 301, loss: 0.855, 9632/28000 datapoints
2025-03-06 22:31:31,891 - INFO - training batch 351, loss: 0.437, 11232/28000 datapoints
2025-03-06 22:31:32,047 - INFO - training batch 401, loss: 0.938, 12832/28000 datapoints
2025-03-06 22:31:32,198 - INFO - training batch 451, loss: 0.716, 14432/28000 datapoints
2025-03-06 22:31:32,350 - INFO - training batch 501, loss: 0.580, 16032/28000 datapoints
2025-03-06 22:31:32,503 - INFO - training batch 551, loss: 0.699, 17632/28000 datapoints
2025-03-06 22:31:32,654 - INFO - training batch 601, loss: 0.949, 19232/28000 datapoints
2025-03-06 22:31:32,814 - INFO - training batch 651, loss: 0.294, 20832/28000 datapoints
2025-03-06 22:31:32,976 - INFO - training batch 701, loss: 0.547, 22432/28000 datapoints
2025-03-06 22:31:33,147 - INFO - training batch 751, loss: 0.460, 24032/28000 datapoints
2025-03-06 22:31:33,298 - INFO - training batch 801, loss: 0.417, 25632/28000 datapoints
2025-03-06 22:31:33,452 - INFO - training batch 851, loss: 0.948, 27232/28000 datapoints
2025-03-06 22:31:33,533 - INFO - validation batch 1, loss: 0.349, 32/6976 datapoints
2025-03-06 22:31:33,583 - INFO - validation batch 51, loss: 1.449, 1632/6976 datapoints
2025-03-06 22:31:33,630 - INFO - validation batch 101, loss: 0.430, 3232/6976 datapoints
2025-03-06 22:31:33,680 - INFO - validation batch 151, loss: 0.716, 4832/6976 datapoints
2025-03-06 22:31:33,729 - INFO - validation batch 201, loss: 0.534, 6432/6976 datapoints
2025-03-06 22:31:33,746 - INFO - Epoch 107/800 done.
2025-03-06 22:31:33,747 - INFO - Final validation performance:
Loss: 0.696, top-1 acc: 0.802top-5 acc: 0.802
2025-03-06 22:31:33,747 - INFO - Beginning epoch 108/800
2025-03-06 22:31:33,751 - INFO - training batch 1, loss: 0.639, 32/28000 datapoints
2025-03-06 22:31:33,910 - INFO - training batch 51, loss: 0.492, 1632/28000 datapoints
2025-03-06 22:31:34,066 - INFO - training batch 101, loss: 0.312, 3232/28000 datapoints
2025-03-06 22:31:34,218 - INFO - training batch 151, loss: 0.957, 4832/28000 datapoints
2025-03-06 22:31:34,370 - INFO - training batch 201, loss: 0.552, 6432/28000 datapoints
2025-03-06 22:31:34,524 - INFO - training batch 251, loss: 0.576, 8032/28000 datapoints
2025-03-06 22:31:34,676 - INFO - training batch 301, loss: 0.853, 9632/28000 datapoints
2025-03-06 22:31:34,828 - INFO - training batch 351, loss: 0.434, 11232/28000 datapoints
2025-03-06 22:31:34,984 - INFO - training batch 401, loss: 0.932, 12832/28000 datapoints
2025-03-06 22:31:35,135 - INFO - training batch 451, loss: 0.704, 14432/28000 datapoints
2025-03-06 22:31:35,294 - INFO - training batch 501, loss: 0.567, 16032/28000 datapoints
2025-03-06 22:31:35,448 - INFO - training batch 551, loss: 0.685, 17632/28000 datapoints
2025-03-06 22:31:35,601 - INFO - training batch 601, loss: 0.939, 19232/28000 datapoints
2025-03-06 22:31:35,758 - INFO - training batch 651, loss: 0.286, 20832/28000 datapoints
2025-03-06 22:31:35,918 - INFO - training batch 701, loss: 0.540, 22432/28000 datapoints
2025-03-06 22:31:36,075 - INFO - training batch 751, loss: 0.452, 24032/28000 datapoints
2025-03-06 22:31:36,228 - INFO - training batch 801, loss: 0.411, 25632/28000 datapoints
2025-03-06 22:31:36,381 - INFO - training batch 851, loss: 0.940, 27232/28000 datapoints
2025-03-06 22:31:36,455 - INFO - validation batch 1, loss: 0.339, 32/6976 datapoints
2025-03-06 22:31:36,506 - INFO - validation batch 51, loss: 1.441, 1632/6976 datapoints
2025-03-06 22:31:36,554 - INFO - validation batch 101, loss: 0.422, 3232/6976 datapoints
2025-03-06 22:31:36,603 - INFO - validation batch 151, loss: 0.712, 4832/6976 datapoints
2025-03-06 22:31:36,653 - INFO - validation batch 201, loss: 0.535, 6432/6976 datapoints
2025-03-06 22:31:36,673 - INFO - Epoch 108/800 done.
2025-03-06 22:31:36,673 - INFO - Final validation performance:
Loss: 0.690, top-1 acc: 0.805top-5 acc: 0.805
2025-03-06 22:31:36,674 - INFO - Beginning epoch 109/800
2025-03-06 22:31:36,679 - INFO - training batch 1, loss: 0.628, 32/28000 datapoints
2025-03-06 22:31:36,853 - INFO - training batch 51, loss: 0.480, 1632/28000 datapoints
2025-03-06 22:31:37,009 - INFO - training batch 101, loss: 0.307, 3232/28000 datapoints
2025-03-06 22:31:37,162 - INFO - training batch 151, loss: 0.946, 4832/28000 datapoints
2025-03-06 22:31:37,314 - INFO - training batch 201, loss: 0.544, 6432/28000 datapoints
2025-03-06 22:31:37,466 - INFO - training batch 251, loss: 0.571, 8032/28000 datapoints
2025-03-06 22:31:37,622 - INFO - training batch 301, loss: 0.851, 9632/28000 datapoints
2025-03-06 22:31:37,782 - INFO - training batch 351, loss: 0.431, 11232/28000 datapoints
2025-03-06 22:31:37,959 - INFO - training batch 401, loss: 0.927, 12832/28000 datapoints
2025-03-06 22:31:38,117 - INFO - training batch 451, loss: 0.691, 14432/28000 datapoints
2025-03-06 22:31:38,273 - INFO - training batch 501, loss: 0.555, 16032/28000 datapoints
2025-03-06 22:31:38,433 - INFO - training batch 551, loss: 0.673, 17632/28000 datapoints
2025-03-06 22:31:38,593 - INFO - training batch 601, loss: 0.929, 19232/28000 datapoints
2025-03-06 22:31:38,752 - INFO - training batch 651, loss: 0.277, 20832/28000 datapoints
2025-03-06 22:31:38,909 - INFO - training batch 701, loss: 0.533, 22432/28000 datapoints
2025-03-06 22:31:39,068 - INFO - training batch 751, loss: 0.444, 24032/28000 datapoints
2025-03-06 22:31:39,236 - INFO - training batch 801, loss: 0.405, 25632/28000 datapoints
2025-03-06 22:31:39,396 - INFO - training batch 851, loss: 0.930, 27232/28000 datapoints
2025-03-06 22:31:39,474 - INFO - validation batch 1, loss: 0.330, 32/6976 datapoints
2025-03-06 22:31:39,524 - INFO - validation batch 51, loss: 1.433, 1632/6976 datapoints
2025-03-06 22:31:39,578 - INFO - validation batch 101, loss: 0.413, 3232/6976 datapoints
2025-03-06 22:31:39,638 - INFO - validation batch 151, loss: 0.708, 4832/6976 datapoints
2025-03-06 22:31:39,693 - INFO - validation batch 201, loss: 0.536, 6432/6976 datapoints
2025-03-06 22:31:39,709 - INFO - Epoch 109/800 done.
2025-03-06 22:31:39,709 - INFO - Final validation performance:
Loss: 0.684, top-1 acc: 0.807top-5 acc: 0.807
2025-03-06 22:31:39,710 - INFO - Beginning epoch 110/800
2025-03-06 22:31:39,714 - INFO - training batch 1, loss: 0.617, 32/28000 datapoints
2025-03-06 22:31:39,878 - INFO - training batch 51, loss: 0.468, 1632/28000 datapoints
2025-03-06 22:31:40,039 - INFO - training batch 101, loss: 0.303, 3232/28000 datapoints
2025-03-06 22:31:40,198 - INFO - training batch 151, loss: 0.936, 4832/28000 datapoints
2025-03-06 22:31:40,353 - INFO - training batch 201, loss: 0.538, 6432/28000 datapoints
2025-03-06 22:31:40,506 - INFO - training batch 251, loss: 0.567, 8032/28000 datapoints
2025-03-06 22:31:40,689 - INFO - training batch 301, loss: 0.848, 9632/28000 datapoints
2025-03-06 22:31:40,845 - INFO - training batch 351, loss: 0.428, 11232/28000 datapoints
2025-03-06 22:31:41,004 - INFO - training batch 401, loss: 0.923, 12832/28000 datapoints
2025-03-06 22:31:41,169 - INFO - training batch 451, loss: 0.679, 14432/28000 datapoints
2025-03-06 22:31:41,325 - INFO - training batch 501, loss: 0.544, 16032/28000 datapoints
2025-03-06 22:31:41,478 - INFO - training batch 551, loss: 0.661, 17632/28000 datapoints
2025-03-06 22:31:41,634 - INFO - training batch 601, loss: 0.919, 19232/28000 datapoints
2025-03-06 22:31:41,790 - INFO - training batch 651, loss: 0.269, 20832/28000 datapoints
2025-03-06 22:31:41,950 - INFO - training batch 701, loss: 0.526, 22432/28000 datapoints
2025-03-06 22:31:42,107 - INFO - training batch 751, loss: 0.437, 24032/28000 datapoints
2025-03-06 22:31:42,262 - INFO - training batch 801, loss: 0.400, 25632/28000 datapoints
2025-03-06 22:31:42,418 - INFO - training batch 851, loss: 0.923, 27232/28000 datapoints
2025-03-06 22:31:42,496 - INFO - validation batch 1, loss: 0.320, 32/6976 datapoints
2025-03-06 22:31:42,547 - INFO - validation batch 51, loss: 1.424, 1632/6976 datapoints
2025-03-06 22:31:42,600 - INFO - validation batch 101, loss: 0.406, 3232/6976 datapoints
2025-03-06 22:31:42,652 - INFO - validation batch 151, loss: 0.704, 4832/6976 datapoints
2025-03-06 22:31:42,706 - INFO - validation batch 201, loss: 0.538, 6432/6976 datapoints
2025-03-06 22:31:42,727 - INFO - Epoch 110/800 done.
2025-03-06 22:31:42,727 - INFO - Final validation performance:
Loss: 0.678, top-1 acc: 0.809top-5 acc: 0.809
2025-03-06 22:31:42,728 - INFO - Beginning epoch 111/800
2025-03-06 22:31:42,732 - INFO - training batch 1, loss: 0.608, 32/28000 datapoints
2025-03-06 22:31:42,888 - INFO - training batch 51, loss: 0.455, 1632/28000 datapoints
2025-03-06 22:31:43,041 - INFO - training batch 101, loss: 0.299, 3232/28000 datapoints
2025-03-06 22:31:43,195 - INFO - training batch 151, loss: 0.926, 4832/28000 datapoints
2025-03-06 22:31:43,348 - INFO - training batch 201, loss: 0.533, 6432/28000 datapoints
2025-03-06 22:31:43,498 - INFO - training batch 251, loss: 0.562, 8032/28000 datapoints
2025-03-06 22:31:43,653 - INFO - training batch 301, loss: 0.845, 9632/28000 datapoints
2025-03-06 22:31:43,810 - INFO - training batch 351, loss: 0.425, 11232/28000 datapoints
2025-03-06 22:31:43,969 - INFO - training batch 401, loss: 0.918, 12832/28000 datapoints
2025-03-06 22:31:44,121 - INFO - training batch 451, loss: 0.667, 14432/28000 datapoints
2025-03-06 22:31:44,272 - INFO - training batch 501, loss: 0.532, 16032/28000 datapoints
2025-03-06 22:31:44,423 - INFO - training batch 551, loss: 0.650, 17632/28000 datapoints
2025-03-06 22:31:44,575 - INFO - training batch 601, loss: 0.910, 19232/28000 datapoints
2025-03-06 22:31:44,728 - INFO - training batch 651, loss: 0.262, 20832/28000 datapoints
2025-03-06 22:31:44,880 - INFO - training batch 701, loss: 0.520, 22432/28000 datapoints
2025-03-06 22:31:45,037 - INFO - training batch 751, loss: 0.430, 24032/28000 datapoints
2025-03-06 22:31:45,195 - INFO - training batch 801, loss: 0.394, 25632/28000 datapoints
2025-03-06 22:31:45,354 - INFO - training batch 851, loss: 0.914, 27232/28000 datapoints
2025-03-06 22:31:45,438 - INFO - validation batch 1, loss: 0.312, 32/6976 datapoints
2025-03-06 22:31:45,486 - INFO - validation batch 51, loss: 1.417, 1632/6976 datapoints
2025-03-06 22:31:45,533 - INFO - validation batch 101, loss: 0.397, 3232/6976 datapoints
2025-03-06 22:31:45,580 - INFO - validation batch 151, loss: 0.701, 4832/6976 datapoints
2025-03-06 22:31:45,630 - INFO - validation batch 201, loss: 0.538, 6432/6976 datapoints
2025-03-06 22:31:45,646 - INFO - Epoch 111/800 done.
2025-03-06 22:31:45,646 - INFO - Final validation performance:
Loss: 0.673, top-1 acc: 0.812top-5 acc: 0.812
2025-03-06 22:31:45,646 - INFO - Beginning epoch 112/800
2025-03-06 22:31:45,651 - INFO - training batch 1, loss: 0.599, 32/28000 datapoints
2025-03-06 22:31:45,805 - INFO - training batch 51, loss: 0.443, 1632/28000 datapoints
2025-03-06 22:31:45,965 - INFO - training batch 101, loss: 0.295, 3232/28000 datapoints
2025-03-06 22:31:46,120 - INFO - training batch 151, loss: 0.918, 4832/28000 datapoints
2025-03-06 22:31:46,272 - INFO - training batch 201, loss: 0.527, 6432/28000 datapoints
2025-03-06 22:31:46,424 - INFO - training batch 251, loss: 0.558, 8032/28000 datapoints
2025-03-06 22:31:46,579 - INFO - training batch 301, loss: 0.841, 9632/28000 datapoints
2025-03-06 22:31:46,736 - INFO - training batch 351, loss: 0.422, 11232/28000 datapoints
2025-03-06 22:31:46,886 - INFO - training batch 401, loss: 0.913, 12832/28000 datapoints
2025-03-06 22:31:47,039 - INFO - training batch 451, loss: 0.656, 14432/28000 datapoints
2025-03-06 22:31:47,190 - INFO - training batch 501, loss: 0.521, 16032/28000 datapoints
2025-03-06 22:31:47,343 - INFO - training batch 551, loss: 0.639, 17632/28000 datapoints
2025-03-06 22:31:47,495 - INFO - training batch 601, loss: 0.900, 19232/28000 datapoints
2025-03-06 22:31:47,647 - INFO - training batch 651, loss: 0.254, 20832/28000 datapoints
2025-03-06 22:31:47,802 - INFO - training batch 701, loss: 0.514, 22432/28000 datapoints
2025-03-06 22:31:47,958 - INFO - training batch 751, loss: 0.424, 24032/28000 datapoints
2025-03-06 22:31:48,110 - INFO - training batch 801, loss: 0.388, 25632/28000 datapoints
2025-03-06 22:31:48,261 - INFO - training batch 851, loss: 0.905, 27232/28000 datapoints
2025-03-06 22:31:48,335 - INFO - validation batch 1, loss: 0.303, 32/6976 datapoints
2025-03-06 22:31:48,382 - INFO - validation batch 51, loss: 1.409, 1632/6976 datapoints
2025-03-06 22:31:48,429 - INFO - validation batch 101, loss: 0.392, 3232/6976 datapoints
2025-03-06 22:31:48,477 - INFO - validation batch 151, loss: 0.697, 4832/6976 datapoints
2025-03-06 22:31:48,525 - INFO - validation batch 201, loss: 0.539, 6432/6976 datapoints
2025-03-06 22:31:48,541 - INFO - Epoch 112/800 done.
2025-03-06 22:31:48,542 - INFO - Final validation performance:
Loss: 0.668, top-1 acc: 0.816top-5 acc: 0.816
2025-03-06 22:31:48,542 - INFO - Beginning epoch 113/800
2025-03-06 22:31:48,546 - INFO - training batch 1, loss: 0.590, 32/28000 datapoints
2025-03-06 22:31:48,702 - INFO - training batch 51, loss: 0.432, 1632/28000 datapoints
2025-03-06 22:31:48,853 - INFO - training batch 101, loss: 0.291, 3232/28000 datapoints
2025-03-06 22:31:49,006 - INFO - training batch 151, loss: 0.910, 4832/28000 datapoints
2025-03-06 22:31:49,159 - INFO - training batch 201, loss: 0.520, 6432/28000 datapoints
2025-03-06 22:31:49,310 - INFO - training batch 251, loss: 0.554, 8032/28000 datapoints
2025-03-06 22:31:49,461 - INFO - training batch 301, loss: 0.839, 9632/28000 datapoints
2025-03-06 22:31:49,610 - INFO - training batch 351, loss: 0.421, 11232/28000 datapoints
2025-03-06 22:31:49,762 - INFO - training batch 401, loss: 0.909, 12832/28000 datapoints
2025-03-06 22:31:49,917 - INFO - training batch 451, loss: 0.646, 14432/28000 datapoints
2025-03-06 22:31:50,076 - INFO - training batch 501, loss: 0.510, 16032/28000 datapoints
2025-03-06 22:31:50,230 - INFO - training batch 551, loss: 0.629, 17632/28000 datapoints
2025-03-06 22:31:50,382 - INFO - training batch 601, loss: 0.890, 19232/28000 datapoints
2025-03-06 22:31:50,534 - INFO - training batch 651, loss: 0.247, 20832/28000 datapoints
2025-03-06 22:31:50,695 - INFO - training batch 701, loss: 0.508, 22432/28000 datapoints
2025-03-06 22:31:50,863 - INFO - training batch 751, loss: 0.418, 24032/28000 datapoints
2025-03-06 22:31:51,021 - INFO - training batch 801, loss: 0.382, 25632/28000 datapoints
2025-03-06 22:31:51,176 - INFO - training batch 851, loss: 0.897, 27232/28000 datapoints
2025-03-06 22:31:51,250 - INFO - validation batch 1, loss: 0.293, 32/6976 datapoints
2025-03-06 22:31:51,299 - INFO - validation batch 51, loss: 1.404, 1632/6976 datapoints
2025-03-06 22:31:51,346 - INFO - validation batch 101, loss: 0.387, 3232/6976 datapoints
2025-03-06 22:31:51,394 - INFO - validation batch 151, loss: 0.694, 4832/6976 datapoints
2025-03-06 22:31:51,441 - INFO - validation batch 201, loss: 0.541, 6432/6976 datapoints
2025-03-06 22:31:51,457 - INFO - Epoch 113/800 done.
2025-03-06 22:31:51,458 - INFO - Final validation performance:
Loss: 0.664, top-1 acc: 0.817top-5 acc: 0.817
2025-03-06 22:31:51,458 - INFO - Beginning epoch 114/800
2025-03-06 22:31:51,462 - INFO - training batch 1, loss: 0.582, 32/28000 datapoints
2025-03-06 22:31:51,626 - INFO - training batch 51, loss: 0.421, 1632/28000 datapoints
2025-03-06 22:31:51,781 - INFO - training batch 101, loss: 0.288, 3232/28000 datapoints
2025-03-06 22:31:51,940 - INFO - training batch 151, loss: 0.902, 4832/28000 datapoints
2025-03-06 22:31:52,096 - INFO - training batch 201, loss: 0.516, 6432/28000 datapoints
2025-03-06 22:31:52,255 - INFO - training batch 251, loss: 0.550, 8032/28000 datapoints
2025-03-06 22:31:52,410 - INFO - training batch 301, loss: 0.836, 9632/28000 datapoints
2025-03-06 22:31:52,566 - INFO - training batch 351, loss: 0.420, 11232/28000 datapoints
2025-03-06 22:31:52,719 - INFO - training batch 401, loss: 0.904, 12832/28000 datapoints
2025-03-06 22:31:52,873 - INFO - training batch 451, loss: 0.635, 14432/28000 datapoints
2025-03-06 22:31:53,027 - INFO - training batch 501, loss: 0.499, 16032/28000 datapoints
2025-03-06 22:31:53,180 - INFO - training batch 551, loss: 0.620, 17632/28000 datapoints
2025-03-06 22:31:53,332 - INFO - training batch 601, loss: 0.881, 19232/28000 datapoints
2025-03-06 22:31:53,485 - INFO - training batch 651, loss: 0.241, 20832/28000 datapoints
2025-03-06 22:31:53,638 - INFO - training batch 701, loss: 0.503, 22432/28000 datapoints
2025-03-06 22:31:53,795 - INFO - training batch 751, loss: 0.412, 24032/28000 datapoints
2025-03-06 22:31:53,955 - INFO - training batch 801, loss: 0.376, 25632/28000 datapoints
2025-03-06 22:31:54,105 - INFO - training batch 851, loss: 0.890, 27232/28000 datapoints
2025-03-06 22:31:54,180 - INFO - validation batch 1, loss: 0.285, 32/6976 datapoints
2025-03-06 22:31:54,231 - INFO - validation batch 51, loss: 1.397, 1632/6976 datapoints
2025-03-06 22:31:54,279 - INFO - validation batch 101, loss: 0.383, 3232/6976 datapoints
2025-03-06 22:31:54,326 - INFO - validation batch 151, loss: 0.691, 4832/6976 datapoints
2025-03-06 22:31:54,374 - INFO - validation batch 201, loss: 0.542, 6432/6976 datapoints
2025-03-06 22:31:54,392 - INFO - Epoch 114/800 done.
2025-03-06 22:31:54,392 - INFO - Final validation performance:
Loss: 0.659, top-1 acc: 0.820top-5 acc: 0.820
2025-03-06 22:31:54,393 - INFO - Beginning epoch 115/800
2025-03-06 22:31:54,397 - INFO - training batch 1, loss: 0.576, 32/28000 datapoints
2025-03-06 22:31:54,550 - INFO - training batch 51, loss: 0.411, 1632/28000 datapoints
2025-03-06 22:31:54,701 - INFO - training batch 101, loss: 0.285, 3232/28000 datapoints
2025-03-06 22:31:54,855 - INFO - training batch 151, loss: 0.894, 4832/28000 datapoints
2025-03-06 22:31:55,009 - INFO - training batch 201, loss: 0.510, 6432/28000 datapoints
2025-03-06 22:31:55,160 - INFO - training batch 251, loss: 0.546, 8032/28000 datapoints
2025-03-06 22:31:55,315 - INFO - training batch 301, loss: 0.833, 9632/28000 datapoints
2025-03-06 22:31:55,468 - INFO - training batch 351, loss: 0.418, 11232/28000 datapoints
2025-03-06 22:31:55,619 - INFO - training batch 401, loss: 0.899, 12832/28000 datapoints
2025-03-06 22:31:55,771 - INFO - training batch 451, loss: 0.625, 14432/28000 datapoints
2025-03-06 22:31:55,925 - INFO - training batch 501, loss: 0.489, 16032/28000 datapoints
2025-03-06 22:31:56,083 - INFO - training batch 551, loss: 0.611, 17632/28000 datapoints
2025-03-06 22:31:56,236 - INFO - training batch 601, loss: 0.872, 19232/28000 datapoints
2025-03-06 22:31:56,389 - INFO - training batch 651, loss: 0.236, 20832/28000 datapoints
2025-03-06 22:31:56,540 - INFO - training batch 701, loss: 0.497, 22432/28000 datapoints
2025-03-06 22:31:56,692 - INFO - training batch 751, loss: 0.407, 24032/28000 datapoints
2025-03-06 22:31:56,843 - INFO - training batch 801, loss: 0.371, 25632/28000 datapoints
2025-03-06 22:31:56,997 - INFO - training batch 851, loss: 0.882, 27232/28000 datapoints
2025-03-06 22:31:57,071 - INFO - validation batch 1, loss: 0.277, 32/6976 datapoints
2025-03-06 22:31:57,119 - INFO - validation batch 51, loss: 1.391, 1632/6976 datapoints
2025-03-06 22:31:57,167 - INFO - validation batch 101, loss: 0.380, 3232/6976 datapoints
2025-03-06 22:31:57,215 - INFO - validation batch 151, loss: 0.689, 4832/6976 datapoints
2025-03-06 22:31:57,264 - INFO - validation batch 201, loss: 0.544, 6432/6976 datapoints
2025-03-06 22:31:57,280 - INFO - Epoch 115/800 done.
2025-03-06 22:31:57,280 - INFO - Final validation performance:
Loss: 0.656, top-1 acc: 0.821top-5 acc: 0.821
2025-03-06 22:31:57,280 - INFO - Beginning epoch 116/800
2025-03-06 22:31:57,285 - INFO - training batch 1, loss: 0.568, 32/28000 datapoints
2025-03-06 22:31:57,439 - INFO - training batch 51, loss: 0.401, 1632/28000 datapoints
2025-03-06 22:31:57,604 - INFO - training batch 101, loss: 0.282, 3232/28000 datapoints
2025-03-06 22:31:57,759 - INFO - training batch 151, loss: 0.887, 4832/28000 datapoints
2025-03-06 22:31:57,918 - INFO - training batch 201, loss: 0.505, 6432/28000 datapoints
2025-03-06 22:31:58,083 - INFO - training batch 251, loss: 0.542, 8032/28000 datapoints
2025-03-06 22:31:58,245 - INFO - training batch 301, loss: 0.830, 9632/28000 datapoints
2025-03-06 22:31:58,398 - INFO - training batch 351, loss: 0.416, 11232/28000 datapoints
2025-03-06 22:31:58,556 - INFO - training batch 401, loss: 0.895, 12832/28000 datapoints
2025-03-06 22:31:58,715 - INFO - training batch 451, loss: 0.615, 14432/28000 datapoints
2025-03-06 22:31:58,881 - INFO - training batch 501, loss: 0.479, 16032/28000 datapoints
2025-03-06 22:31:59,042 - INFO - training batch 551, loss: 0.604, 17632/28000 datapoints
2025-03-06 22:31:59,199 - INFO - training batch 601, loss: 0.864, 19232/28000 datapoints
2025-03-06 22:31:59,356 - INFO - training batch 651, loss: 0.230, 20832/28000 datapoints
2025-03-06 22:31:59,516 - INFO - training batch 701, loss: 0.491, 22432/28000 datapoints
2025-03-06 22:31:59,673 - INFO - training batch 751, loss: 0.402, 24032/28000 datapoints
2025-03-06 22:31:59,831 - INFO - training batch 801, loss: 0.365, 25632/28000 datapoints
2025-03-06 22:31:59,993 - INFO - training batch 851, loss: 0.875, 27232/28000 datapoints
2025-03-06 22:32:00,072 - INFO - validation batch 1, loss: 0.268, 32/6976 datapoints
2025-03-06 22:32:00,128 - INFO - validation batch 51, loss: 1.386, 1632/6976 datapoints
2025-03-06 22:32:00,182 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-06 22:32:00,232 - INFO - validation batch 151, loss: 0.688, 4832/6976 datapoints
2025-03-06 22:32:00,282 - INFO - validation batch 201, loss: 0.546, 6432/6976 datapoints
2025-03-06 22:32:00,299 - INFO - Epoch 116/800 done.
2025-03-06 22:32:00,299 - INFO - Final validation performance:
Loss: 0.653, top-1 acc: 0.824top-5 acc: 0.824
2025-03-06 22:32:00,300 - INFO - Beginning epoch 117/800
2025-03-06 22:32:00,304 - INFO - training batch 1, loss: 0.561, 32/28000 datapoints
2025-03-06 22:32:00,456 - INFO - training batch 51, loss: 0.392, 1632/28000 datapoints
2025-03-06 22:32:00,607 - INFO - training batch 101, loss: 0.279, 3232/28000 datapoints
2025-03-06 22:32:00,771 - INFO - training batch 151, loss: 0.880, 4832/28000 datapoints
2025-03-06 22:32:00,948 - INFO - training batch 201, loss: 0.498, 6432/28000 datapoints
2025-03-06 22:32:01,100 - INFO - training batch 251, loss: 0.538, 8032/28000 datapoints
2025-03-06 22:32:01,262 - INFO - training batch 301, loss: 0.827, 9632/28000 datapoints
2025-03-06 22:32:01,477 - INFO - training batch 351, loss: 0.414, 11232/28000 datapoints
2025-03-06 22:32:01,628 - INFO - training batch 401, loss: 0.891, 12832/28000 datapoints
2025-03-06 22:32:01,780 - INFO - training batch 451, loss: 0.606, 14432/28000 datapoints
2025-03-06 22:32:01,933 - INFO - training batch 501, loss: 0.470, 16032/28000 datapoints
2025-03-06 22:32:02,090 - INFO - training batch 551, loss: 0.597, 17632/28000 datapoints
2025-03-06 22:32:02,243 - INFO - training batch 601, loss: 0.855, 19232/28000 datapoints
2025-03-06 22:32:02,396 - INFO - training batch 651, loss: 0.225, 20832/28000 datapoints
2025-03-06 22:32:02,547 - INFO - training batch 701, loss: 0.486, 22432/28000 datapoints
2025-03-06 22:32:02,698 - INFO - training batch 751, loss: 0.397, 24032/28000 datapoints
2025-03-06 22:32:02,849 - INFO - training batch 801, loss: 0.360, 25632/28000 datapoints
2025-03-06 22:32:03,002 - INFO - training batch 851, loss: 0.867, 27232/28000 datapoints
2025-03-06 22:32:03,076 - INFO - validation batch 1, loss: 0.260, 32/6976 datapoints
2025-03-06 22:32:03,123 - INFO - validation batch 51, loss: 1.379, 1632/6976 datapoints
2025-03-06 22:32:03,173 - INFO - validation batch 101, loss: 0.376, 3232/6976 datapoints
2025-03-06 22:32:03,220 - INFO - validation batch 151, loss: 0.688, 4832/6976 datapoints
2025-03-06 22:32:03,267 - INFO - validation batch 201, loss: 0.547, 6432/6976 datapoints
2025-03-06 22:32:03,283 - INFO - Epoch 117/800 done.
2025-03-06 22:32:03,283 - INFO - Final validation performance:
Loss: 0.650, top-1 acc: 0.826top-5 acc: 0.826
2025-03-06 22:32:03,284 - INFO - Beginning epoch 118/800
2025-03-06 22:32:03,288 - INFO - training batch 1, loss: 0.554, 32/28000 datapoints
2025-03-06 22:32:03,442 - INFO - training batch 51, loss: 0.382, 1632/28000 datapoints
2025-03-06 22:32:03,603 - INFO - training batch 101, loss: 0.277, 3232/28000 datapoints
2025-03-06 22:32:03,776 - INFO - training batch 151, loss: 0.873, 4832/28000 datapoints
2025-03-06 22:32:03,933 - INFO - training batch 201, loss: 0.491, 6432/28000 datapoints
2025-03-06 22:32:04,104 - INFO - training batch 251, loss: 0.534, 8032/28000 datapoints
2025-03-06 22:32:04,264 - INFO - training batch 301, loss: 0.825, 9632/28000 datapoints
2025-03-06 22:32:04,416 - INFO - training batch 351, loss: 0.411, 11232/28000 datapoints
2025-03-06 22:32:04,571 - INFO - training batch 401, loss: 0.886, 12832/28000 datapoints
2025-03-06 22:32:04,722 - INFO - training batch 451, loss: 0.596, 14432/28000 datapoints
2025-03-06 22:32:04,875 - INFO - training batch 501, loss: 0.459, 16032/28000 datapoints
2025-03-06 22:32:05,032 - INFO - training batch 551, loss: 0.589, 17632/28000 datapoints
2025-03-06 22:32:05,182 - INFO - training batch 601, loss: 0.847, 19232/28000 datapoints
2025-03-06 22:32:05,339 - INFO - training batch 651, loss: 0.220, 20832/28000 datapoints
2025-03-06 22:32:05,491 - INFO - training batch 701, loss: 0.481, 22432/28000 datapoints
2025-03-06 22:32:05,641 - INFO - training batch 751, loss: 0.392, 24032/28000 datapoints
2025-03-06 22:32:05,791 - INFO - training batch 801, loss: 0.355, 25632/28000 datapoints
2025-03-06 22:32:05,946 - INFO - training batch 851, loss: 0.858, 27232/28000 datapoints
2025-03-06 22:32:06,023 - INFO - validation batch 1, loss: 0.252, 32/6976 datapoints
2025-03-06 22:32:06,071 - INFO - validation batch 51, loss: 1.371, 1632/6976 datapoints
2025-03-06 22:32:06,118 - INFO - validation batch 101, loss: 0.376, 3232/6976 datapoints
2025-03-06 22:32:06,168 - INFO - validation batch 151, loss: 0.686, 4832/6976 datapoints
2025-03-06 22:32:06,216 - INFO - validation batch 201, loss: 0.548, 6432/6976 datapoints
2025-03-06 22:32:06,232 - INFO - Epoch 118/800 done.
2025-03-06 22:32:06,232 - INFO - Final validation performance:
Loss: 0.646, top-1 acc: 0.827top-5 acc: 0.827
2025-03-06 22:32:06,233 - INFO - Beginning epoch 119/800
2025-03-06 22:32:06,237 - INFO - training batch 1, loss: 0.547, 32/28000 datapoints
2025-03-06 22:32:06,390 - INFO - training batch 51, loss: 0.373, 1632/28000 datapoints
2025-03-06 22:32:06,544 - INFO - training batch 101, loss: 0.275, 3232/28000 datapoints
2025-03-06 22:32:06,697 - INFO - training batch 151, loss: 0.868, 4832/28000 datapoints
2025-03-06 22:32:06,850 - INFO - training batch 201, loss: 0.482, 6432/28000 datapoints
2025-03-06 22:32:07,003 - INFO - training batch 251, loss: 0.531, 8032/28000 datapoints
2025-03-06 22:32:07,153 - INFO - training batch 301, loss: 0.823, 9632/28000 datapoints
2025-03-06 22:32:07,304 - INFO - training batch 351, loss: 0.409, 11232/28000 datapoints
2025-03-06 22:32:07,457 - INFO - training batch 401, loss: 0.883, 12832/28000 datapoints
2025-03-06 22:32:07,607 - INFO - training batch 451, loss: 0.587, 14432/28000 datapoints
2025-03-06 22:32:07,765 - INFO - training batch 501, loss: 0.450, 16032/28000 datapoints
2025-03-06 22:32:07,919 - INFO - training batch 551, loss: 0.583, 17632/28000 datapoints
2025-03-06 22:32:08,077 - INFO - training batch 601, loss: 0.839, 19232/28000 datapoints
2025-03-06 22:32:08,229 - INFO - training batch 651, loss: 0.216, 20832/28000 datapoints
2025-03-06 22:32:08,379 - INFO - training batch 701, loss: 0.476, 22432/28000 datapoints
2025-03-06 22:32:08,530 - INFO - training batch 751, loss: 0.387, 24032/28000 datapoints
2025-03-06 22:32:08,680 - INFO - training batch 801, loss: 0.350, 25632/28000 datapoints
2025-03-06 22:32:08,831 - INFO - training batch 851, loss: 0.850, 27232/28000 datapoints
2025-03-06 22:32:08,905 - INFO - validation batch 1, loss: 0.244, 32/6976 datapoints
2025-03-06 22:32:08,956 - INFO - validation batch 51, loss: 1.364, 1632/6976 datapoints
2025-03-06 22:32:09,004 - INFO - validation batch 101, loss: 0.375, 3232/6976 datapoints
2025-03-06 22:32:09,051 - INFO - validation batch 151, loss: 0.684, 4832/6976 datapoints
2025-03-06 22:32:09,099 - INFO - validation batch 201, loss: 0.548, 6432/6976 datapoints
2025-03-06 22:32:09,115 - INFO - Epoch 119/800 done.
2025-03-06 22:32:09,115 - INFO - Final validation performance:
Loss: 0.643, top-1 acc: 0.828top-5 acc: 0.828
2025-03-06 22:32:09,116 - INFO - Beginning epoch 120/800
2025-03-06 22:32:09,120 - INFO - training batch 1, loss: 0.540, 32/28000 datapoints
2025-03-06 22:32:09,273 - INFO - training batch 51, loss: 0.364, 1632/28000 datapoints
2025-03-06 22:32:09,430 - INFO - training batch 101, loss: 0.273, 3232/28000 datapoints
2025-03-06 22:32:09,585 - INFO - training batch 151, loss: 0.862, 4832/28000 datapoints
2025-03-06 22:32:09,752 - INFO - training batch 201, loss: 0.471, 6432/28000 datapoints
2025-03-06 22:32:09,905 - INFO - training batch 251, loss: 0.528, 8032/28000 datapoints
2025-03-06 22:32:10,064 - INFO - training batch 301, loss: 0.821, 9632/28000 datapoints
2025-03-06 22:32:10,227 - INFO - training batch 351, loss: 0.407, 11232/28000 datapoints
2025-03-06 22:32:10,381 - INFO - training batch 401, loss: 0.880, 12832/28000 datapoints
2025-03-06 22:32:10,540 - INFO - training batch 451, loss: 0.578, 14432/28000 datapoints
2025-03-06 22:32:10,693 - INFO - training batch 501, loss: 0.440, 16032/28000 datapoints
2025-03-06 22:32:10,849 - INFO - training batch 551, loss: 0.577, 17632/28000 datapoints
2025-03-06 22:32:11,033 - INFO - training batch 601, loss: 0.831, 19232/28000 datapoints
2025-03-06 22:32:11,185 - INFO - training batch 651, loss: 0.212, 20832/28000 datapoints
2025-03-06 22:32:11,339 - INFO - training batch 701, loss: 0.471, 22432/28000 datapoints
2025-03-06 22:32:11,491 - INFO - training batch 751, loss: 0.383, 24032/28000 datapoints
2025-03-06 22:32:11,641 - INFO - training batch 801, loss: 0.345, 25632/28000 datapoints
2025-03-06 22:32:11,793 - INFO - training batch 851, loss: 0.842, 27232/28000 datapoints
2025-03-06 22:32:11,866 - INFO - validation batch 1, loss: 0.237, 32/6976 datapoints
2025-03-06 22:32:11,914 - INFO - validation batch 51, loss: 1.356, 1632/6976 datapoints
2025-03-06 22:32:11,967 - INFO - validation batch 101, loss: 0.374, 3232/6976 datapoints
2025-03-06 22:32:12,018 - INFO - validation batch 151, loss: 0.684, 4832/6976 datapoints
2025-03-06 22:32:12,065 - INFO - validation batch 201, loss: 0.549, 6432/6976 datapoints
2025-03-06 22:32:12,082 - INFO - Epoch 120/800 done.
2025-03-06 22:32:12,082 - INFO - Final validation performance:
Loss: 0.640, top-1 acc: 0.829top-5 acc: 0.829
2025-03-06 22:32:12,082 - INFO - Beginning epoch 121/800
2025-03-06 22:32:12,087 - INFO - training batch 1, loss: 0.535, 32/28000 datapoints
2025-03-06 22:32:12,242 - INFO - training batch 51, loss: 0.355, 1632/28000 datapoints
2025-03-06 22:32:12,393 - INFO - training batch 101, loss: 0.270, 3232/28000 datapoints
2025-03-06 22:32:12,546 - INFO - training batch 151, loss: 0.857, 4832/28000 datapoints
2025-03-06 22:32:12,696 - INFO - training batch 201, loss: 0.462, 6432/28000 datapoints
2025-03-06 22:32:12,848 - INFO - training batch 251, loss: 0.525, 8032/28000 datapoints
2025-03-06 22:32:13,003 - INFO - training batch 301, loss: 0.819, 9632/28000 datapoints
2025-03-06 22:32:13,152 - INFO - training batch 351, loss: 0.405, 11232/28000 datapoints
2025-03-06 22:32:13,305 - INFO - training batch 401, loss: 0.876, 12832/28000 datapoints
2025-03-06 22:32:13,456 - INFO - training batch 451, loss: 0.571, 14432/28000 datapoints
2025-03-06 22:32:13,608 - INFO - training batch 501, loss: 0.431, 16032/28000 datapoints
2025-03-06 22:32:13,761 - INFO - training batch 551, loss: 0.571, 17632/28000 datapoints
2025-03-06 22:32:13,913 - INFO - training batch 601, loss: 0.823, 19232/28000 datapoints
2025-03-06 22:32:14,074 - INFO - training batch 651, loss: 0.208, 20832/28000 datapoints
2025-03-06 22:32:14,225 - INFO - training batch 701, loss: 0.466, 22432/28000 datapoints
2025-03-06 22:32:14,378 - INFO - training batch 751, loss: 0.379, 24032/28000 datapoints
2025-03-06 22:32:14,530 - INFO - training batch 801, loss: 0.339, 25632/28000 datapoints
2025-03-06 22:32:14,681 - INFO - training batch 851, loss: 0.835, 27232/28000 datapoints
2025-03-06 22:32:14,756 - INFO - validation batch 1, loss: 0.230, 32/6976 datapoints
2025-03-06 22:32:14,804 - INFO - validation batch 51, loss: 1.350, 1632/6976 datapoints
2025-03-06 22:32:14,852 - INFO - validation batch 101, loss: 0.373, 3232/6976 datapoints
2025-03-06 22:32:14,900 - INFO - validation batch 151, loss: 0.683, 4832/6976 datapoints
2025-03-06 22:32:14,949 - INFO - validation batch 201, loss: 0.548, 6432/6976 datapoints
2025-03-06 22:32:14,965 - INFO - Epoch 121/800 done.
2025-03-06 22:32:14,965 - INFO - Final validation performance:
Loss: 0.637, top-1 acc: 0.830top-5 acc: 0.830
2025-03-06 22:32:14,966 - INFO - Beginning epoch 122/800
2025-03-06 22:32:14,970 - INFO - training batch 1, loss: 0.528, 32/28000 datapoints
2025-03-06 22:32:15,126 - INFO - training batch 51, loss: 0.347, 1632/28000 datapoints
2025-03-06 22:32:15,291 - INFO - training batch 101, loss: 0.268, 3232/28000 datapoints
2025-03-06 22:32:15,451 - INFO - training batch 151, loss: 0.853, 4832/28000 datapoints
2025-03-06 22:32:15,607 - INFO - training batch 201, loss: 0.454, 6432/28000 datapoints
2025-03-06 22:32:15,774 - INFO - training batch 251, loss: 0.522, 8032/28000 datapoints
2025-03-06 22:32:15,926 - INFO - training batch 301, loss: 0.817, 9632/28000 datapoints
2025-03-06 22:32:16,086 - INFO - training batch 351, loss: 0.403, 11232/28000 datapoints
2025-03-06 22:32:16,246 - INFO - training batch 401, loss: 0.873, 12832/28000 datapoints
2025-03-06 22:32:16,396 - INFO - training batch 451, loss: 0.563, 14432/28000 datapoints
2025-03-06 22:32:16,552 - INFO - training batch 501, loss: 0.422, 16032/28000 datapoints
2025-03-06 22:32:16,709 - INFO - training batch 551, loss: 0.566, 17632/28000 datapoints
2025-03-06 22:32:16,860 - INFO - training batch 601, loss: 0.815, 19232/28000 datapoints
2025-03-06 22:32:17,014 - INFO - training batch 651, loss: 0.204, 20832/28000 datapoints
2025-03-06 22:32:17,165 - INFO - training batch 701, loss: 0.462, 22432/28000 datapoints
2025-03-06 22:32:17,317 - INFO - training batch 751, loss: 0.375, 24032/28000 datapoints
2025-03-06 22:32:17,467 - INFO - training batch 801, loss: 0.335, 25632/28000 datapoints
2025-03-06 22:32:17,618 - INFO - training batch 851, loss: 0.828, 27232/28000 datapoints
2025-03-06 22:32:17,692 - INFO - validation batch 1, loss: 0.224, 32/6976 datapoints
2025-03-06 22:32:17,739 - INFO - validation batch 51, loss: 1.346, 1632/6976 datapoints
2025-03-06 22:32:17,788 - INFO - validation batch 101, loss: 0.373, 3232/6976 datapoints
2025-03-06 22:32:17,837 - INFO - validation batch 151, loss: 0.681, 4832/6976 datapoints
2025-03-06 22:32:17,892 - INFO - validation batch 201, loss: 0.549, 6432/6976 datapoints
2025-03-06 22:32:17,908 - INFO - Epoch 122/800 done.
2025-03-06 22:32:17,909 - INFO - Final validation performance:
Loss: 0.635, top-1 acc: 0.831top-5 acc: 0.831
2025-03-06 22:32:17,909 - INFO - Beginning epoch 123/800
2025-03-06 22:32:17,913 - INFO - training batch 1, loss: 0.523, 32/28000 datapoints
2025-03-06 22:32:18,077 - INFO - training batch 51, loss: 0.339, 1632/28000 datapoints
2025-03-06 22:32:18,234 - INFO - training batch 101, loss: 0.266, 3232/28000 datapoints
2025-03-06 22:32:18,391 - INFO - training batch 151, loss: 0.847, 4832/28000 datapoints
2025-03-06 22:32:18,546 - INFO - training batch 201, loss: 0.447, 6432/28000 datapoints
2025-03-06 22:32:18,704 - INFO - training batch 251, loss: 0.519, 8032/28000 datapoints
2025-03-06 22:32:18,861 - INFO - training batch 301, loss: 0.816, 9632/28000 datapoints
2025-03-06 22:32:19,019 - INFO - training batch 351, loss: 0.400, 11232/28000 datapoints
2025-03-06 22:32:19,175 - INFO - training batch 401, loss: 0.870, 12832/28000 datapoints
2025-03-06 22:32:19,329 - INFO - training batch 451, loss: 0.556, 14432/28000 datapoints
2025-03-06 22:32:19,484 - INFO - training batch 501, loss: 0.413, 16032/28000 datapoints
2025-03-06 22:32:19,641 - INFO - training batch 551, loss: 0.562, 17632/28000 datapoints
2025-03-06 22:32:19,796 - INFO - training batch 601, loss: 0.805, 19232/28000 datapoints
2025-03-06 22:32:19,956 - INFO - training batch 651, loss: 0.200, 20832/28000 datapoints
2025-03-06 22:32:20,116 - INFO - training batch 701, loss: 0.458, 22432/28000 datapoints
2025-03-06 22:32:20,274 - INFO - training batch 751, loss: 0.372, 24032/28000 datapoints
2025-03-06 22:32:20,429 - INFO - training batch 801, loss: 0.330, 25632/28000 datapoints
2025-03-06 22:32:20,582 - INFO - training batch 851, loss: 0.821, 27232/28000 datapoints
2025-03-06 22:32:20,661 - INFO - validation batch 1, loss: 0.218, 32/6976 datapoints
2025-03-06 22:32:20,712 - INFO - validation batch 51, loss: 1.339, 1632/6976 datapoints
2025-03-06 22:32:20,765 - INFO - validation batch 101, loss: 0.373, 3232/6976 datapoints
2025-03-06 22:32:20,817 - INFO - validation batch 151, loss: 0.680, 4832/6976 datapoints
2025-03-06 22:32:20,869 - INFO - validation batch 201, loss: 0.549, 6432/6976 datapoints
2025-03-06 22:32:20,889 - INFO - Epoch 123/800 done.
2025-03-06 22:32:20,889 - INFO - Final validation performance:
Loss: 0.632, top-1 acc: 0.833top-5 acc: 0.833
2025-03-06 22:32:20,890 - INFO - Beginning epoch 124/800
2025-03-06 22:32:20,894 - INFO - training batch 1, loss: 0.517, 32/28000 datapoints
2025-03-06 22:32:21,081 - INFO - training batch 51, loss: 0.332, 1632/28000 datapoints
2025-03-06 22:32:21,244 - INFO - training batch 101, loss: 0.264, 3232/28000 datapoints
2025-03-06 22:32:21,405 - INFO - training batch 151, loss: 0.842, 4832/28000 datapoints
2025-03-06 22:32:21,560 - INFO - training batch 201, loss: 0.438, 6432/28000 datapoints
2025-03-06 22:32:21,721 - INFO - training batch 251, loss: 0.516, 8032/28000 datapoints
2025-03-06 22:32:21,883 - INFO - training batch 301, loss: 0.814, 9632/28000 datapoints
2025-03-06 22:32:22,044 - INFO - training batch 351, loss: 0.398, 11232/28000 datapoints
2025-03-06 22:32:22,200 - INFO - training batch 401, loss: 0.867, 12832/28000 datapoints
2025-03-06 22:32:22,363 - INFO - training batch 451, loss: 0.550, 14432/28000 datapoints
2025-03-06 22:32:22,521 - INFO - training batch 501, loss: 0.406, 16032/28000 datapoints
2025-03-06 22:32:22,680 - INFO - training batch 551, loss: 0.558, 17632/28000 datapoints
2025-03-06 22:32:22,839 - INFO - training batch 601, loss: 0.796, 19232/28000 datapoints
2025-03-06 22:32:22,998 - INFO - training batch 651, loss: 0.197, 20832/28000 datapoints
2025-03-06 22:32:23,155 - INFO - training batch 701, loss: 0.453, 22432/28000 datapoints
2025-03-06 22:32:23,312 - INFO - training batch 751, loss: 0.368, 24032/28000 datapoints
2025-03-06 22:32:23,467 - INFO - training batch 801, loss: 0.325, 25632/28000 datapoints
2025-03-06 22:32:23,625 - INFO - training batch 851, loss: 0.815, 27232/28000 datapoints
2025-03-06 22:32:23,704 - INFO - validation batch 1, loss: 0.212, 32/6976 datapoints
2025-03-06 22:32:23,761 - INFO - validation batch 51, loss: 1.334, 1632/6976 datapoints
2025-03-06 22:32:23,815 - INFO - validation batch 101, loss: 0.373, 3232/6976 datapoints
2025-03-06 22:32:23,868 - INFO - validation batch 151, loss: 0.679, 4832/6976 datapoints
2025-03-06 22:32:23,920 - INFO - validation batch 201, loss: 0.550, 6432/6976 datapoints
2025-03-06 22:32:23,942 - INFO - Epoch 124/800 done.
2025-03-06 22:32:23,942 - INFO - Final validation performance:
Loss: 0.630, top-1 acc: 0.834top-5 acc: 0.834
2025-03-06 22:32:23,942 - INFO - Beginning epoch 125/800
2025-03-06 22:32:23,947 - INFO - training batch 1, loss: 0.511, 32/28000 datapoints
2025-03-06 22:32:24,108 - INFO - training batch 51, loss: 0.324, 1632/28000 datapoints
2025-03-06 22:32:24,267 - INFO - training batch 101, loss: 0.263, 3232/28000 datapoints
2025-03-06 22:32:24,424 - INFO - training batch 151, loss: 0.837, 4832/28000 datapoints
2025-03-06 22:32:24,578 - INFO - training batch 201, loss: 0.428, 6432/28000 datapoints
2025-03-06 22:32:24,735 - INFO - training batch 251, loss: 0.514, 8032/28000 datapoints
2025-03-06 22:32:24,890 - INFO - training batch 301, loss: 0.814, 9632/28000 datapoints
2025-03-06 22:32:25,048 - INFO - training batch 351, loss: 0.395, 11232/28000 datapoints
2025-03-06 22:32:25,208 - INFO - training batch 401, loss: 0.864, 12832/28000 datapoints
2025-03-06 22:32:25,365 - INFO - training batch 451, loss: 0.544, 14432/28000 datapoints
2025-03-06 22:32:25,522 - INFO - training batch 501, loss: 0.398, 16032/28000 datapoints
2025-03-06 22:32:25,680 - INFO - training batch 551, loss: 0.554, 17632/28000 datapoints
2025-03-06 22:32:25,835 - INFO - training batch 601, loss: 0.786, 19232/28000 datapoints
2025-03-06 22:32:25,993 - INFO - training batch 651, loss: 0.194, 20832/28000 datapoints
2025-03-06 22:32:26,151 - INFO - training batch 701, loss: 0.449, 22432/28000 datapoints
2025-03-06 22:32:26,307 - INFO - training batch 751, loss: 0.366, 24032/28000 datapoints
2025-03-06 22:32:26,461 - INFO - training batch 801, loss: 0.321, 25632/28000 datapoints
2025-03-06 22:32:26,616 - INFO - training batch 851, loss: 0.809, 27232/28000 datapoints
2025-03-06 22:32:26,695 - INFO - validation batch 1, loss: 0.206, 32/6976 datapoints
2025-03-06 22:32:26,746 - INFO - validation batch 51, loss: 1.329, 1632/6976 datapoints
2025-03-06 22:32:26,798 - INFO - validation batch 101, loss: 0.374, 3232/6976 datapoints
2025-03-06 22:32:26,852 - INFO - validation batch 151, loss: 0.679, 4832/6976 datapoints
2025-03-06 22:32:26,904 - INFO - validation batch 201, loss: 0.551, 6432/6976 datapoints
2025-03-06 22:32:26,922 - INFO - Epoch 125/800 done.
2025-03-06 22:32:26,922 - INFO - Final validation performance:
Loss: 0.628, top-1 acc: 0.836top-5 acc: 0.836
2025-03-06 22:32:26,923 - INFO - Beginning epoch 126/800
2025-03-06 22:32:26,928 - INFO - training batch 1, loss: 0.506, 32/28000 datapoints
2025-03-06 22:32:27,094 - INFO - training batch 51, loss: 0.317, 1632/28000 datapoints
2025-03-06 22:32:27,251 - INFO - training batch 101, loss: 0.262, 3232/28000 datapoints
2025-03-06 22:32:27,412 - INFO - training batch 151, loss: 0.832, 4832/28000 datapoints
2025-03-06 22:32:27,568 - INFO - training batch 201, loss: 0.418, 6432/28000 datapoints
2025-03-06 22:32:27,724 - INFO - training batch 251, loss: 0.511, 8032/28000 datapoints
2025-03-06 22:32:27,892 - INFO - training batch 301, loss: 0.812, 9632/28000 datapoints
2025-03-06 22:32:28,049 - INFO - training batch 351, loss: 0.394, 11232/28000 datapoints
2025-03-06 22:32:28,214 - INFO - training batch 401, loss: 0.861, 12832/28000 datapoints
2025-03-06 22:32:28,375 - INFO - training batch 451, loss: 0.537, 14432/28000 datapoints
2025-03-06 22:32:28,528 - INFO - training batch 501, loss: 0.391, 16032/28000 datapoints
2025-03-06 22:32:28,688 - INFO - training batch 551, loss: 0.549, 17632/28000 datapoints
2025-03-06 22:32:28,843 - INFO - training batch 601, loss: 0.776, 19232/28000 datapoints
2025-03-06 22:32:29,001 - INFO - training batch 651, loss: 0.191, 20832/28000 datapoints
2025-03-06 22:32:29,165 - INFO - training batch 701, loss: 0.445, 22432/28000 datapoints
2025-03-06 22:32:29,323 - INFO - training batch 751, loss: 0.362, 24032/28000 datapoints
2025-03-06 22:32:29,478 - INFO - training batch 801, loss: 0.317, 25632/28000 datapoints
2025-03-06 22:32:29,633 - INFO - training batch 851, loss: 0.802, 27232/28000 datapoints
2025-03-06 22:32:29,712 - INFO - validation batch 1, loss: 0.201, 32/6976 datapoints
2025-03-06 22:32:29,765 - INFO - validation batch 51, loss: 1.324, 1632/6976 datapoints
2025-03-06 22:32:29,816 - INFO - validation batch 101, loss: 0.375, 3232/6976 datapoints
2025-03-06 22:32:29,871 - INFO - validation batch 151, loss: 0.679, 4832/6976 datapoints
2025-03-06 22:32:29,926 - INFO - validation batch 201, loss: 0.552, 6432/6976 datapoints
2025-03-06 22:32:29,947 - INFO - Epoch 126/800 done.
2025-03-06 22:32:29,947 - INFO - Final validation performance:
Loss: 0.626, top-1 acc: 0.837top-5 acc: 0.837
2025-03-06 22:32:29,948 - INFO - Beginning epoch 127/800
2025-03-06 22:32:29,952 - INFO - training batch 1, loss: 0.500, 32/28000 datapoints
2025-03-06 22:32:30,127 - INFO - training batch 51, loss: 0.311, 1632/28000 datapoints
2025-03-06 22:32:30,314 - INFO - training batch 101, loss: 0.260, 3232/28000 datapoints
2025-03-06 22:32:30,473 - INFO - training batch 151, loss: 0.828, 4832/28000 datapoints
2025-03-06 22:32:30,628 - INFO - training batch 201, loss: 0.409, 6432/28000 datapoints
2025-03-06 22:32:30,784 - INFO - training batch 251, loss: 0.508, 8032/28000 datapoints
2025-03-06 22:32:30,941 - INFO - training batch 301, loss: 0.811, 9632/28000 datapoints
2025-03-06 22:32:31,123 - INFO - training batch 351, loss: 0.391, 11232/28000 datapoints
2025-03-06 22:32:31,280 - INFO - training batch 401, loss: 0.859, 12832/28000 datapoints
2025-03-06 22:32:31,437 - INFO - training batch 451, loss: 0.532, 14432/28000 datapoints
2025-03-06 22:32:31,594 - INFO - training batch 501, loss: 0.383, 16032/28000 datapoints
2025-03-06 22:32:31,759 - INFO - training batch 551, loss: 0.545, 17632/28000 datapoints
2025-03-06 22:32:31,914 - INFO - training batch 601, loss: 0.767, 19232/28000 datapoints
2025-03-06 22:32:32,076 - INFO - training batch 651, loss: 0.188, 20832/28000 datapoints
2025-03-06 22:32:32,232 - INFO - training batch 701, loss: 0.441, 22432/28000 datapoints
2025-03-06 22:32:32,388 - INFO - training batch 751, loss: 0.359, 24032/28000 datapoints
2025-03-06 22:32:32,544 - INFO - training batch 801, loss: 0.312, 25632/28000 datapoints
2025-03-06 22:32:32,695 - INFO - training batch 851, loss: 0.794, 27232/28000 datapoints
2025-03-06 22:32:32,774 - INFO - validation batch 1, loss: 0.196, 32/6976 datapoints
2025-03-06 22:32:32,825 - INFO - validation batch 51, loss: 1.320, 1632/6976 datapoints
2025-03-06 22:32:32,877 - INFO - validation batch 101, loss: 0.376, 3232/6976 datapoints
2025-03-06 22:32:32,928 - INFO - validation batch 151, loss: 0.679, 4832/6976 datapoints
2025-03-06 22:32:32,978 - INFO - validation batch 201, loss: 0.554, 6432/6976 datapoints
2025-03-06 22:32:32,995 - INFO - Epoch 127/800 done.
2025-03-06 22:32:32,995 - INFO - Final validation performance:
Loss: 0.625, top-1 acc: 0.839top-5 acc: 0.839
2025-03-06 22:32:32,996 - INFO - Beginning epoch 128/800
2025-03-06 22:32:33,000 - INFO - training batch 1, loss: 0.495, 32/28000 datapoints
2025-03-06 22:32:33,152 - INFO - training batch 51, loss: 0.305, 1632/28000 datapoints
2025-03-06 22:32:33,307 - INFO - training batch 101, loss: 0.259, 3232/28000 datapoints
2025-03-06 22:32:33,459 - INFO - training batch 151, loss: 0.823, 4832/28000 datapoints
2025-03-06 22:32:33,610 - INFO - training batch 201, loss: 0.400, 6432/28000 datapoints
2025-03-06 22:32:33,764 - INFO - training batch 251, loss: 0.505, 8032/28000 datapoints
2025-03-06 22:32:33,927 - INFO - training batch 301, loss: 0.809, 9632/28000 datapoints
2025-03-06 22:32:34,086 - INFO - training batch 351, loss: 0.389, 11232/28000 datapoints
2025-03-06 22:32:34,239 - INFO - training batch 401, loss: 0.856, 12832/28000 datapoints
2025-03-06 22:32:34,399 - INFO - training batch 451, loss: 0.528, 14432/28000 datapoints
2025-03-06 22:32:34,553 - INFO - training batch 501, loss: 0.378, 16032/28000 datapoints
2025-03-06 22:32:34,709 - INFO - training batch 551, loss: 0.541, 17632/28000 datapoints
2025-03-06 22:32:34,863 - INFO - training batch 601, loss: 0.759, 19232/28000 datapoints
2025-03-06 22:32:35,018 - INFO - training batch 651, loss: 0.186, 20832/28000 datapoints
2025-03-06 22:32:35,172 - INFO - training batch 701, loss: 0.438, 22432/28000 datapoints
2025-03-06 22:32:35,332 - INFO - training batch 751, loss: 0.357, 24032/28000 datapoints
2025-03-06 22:32:35,483 - INFO - training batch 801, loss: 0.308, 25632/28000 datapoints
2025-03-06 22:32:35,635 - INFO - training batch 851, loss: 0.787, 27232/28000 datapoints
2025-03-06 22:32:35,708 - INFO - validation batch 1, loss: 0.191, 32/6976 datapoints
2025-03-06 22:32:35,756 - INFO - validation batch 51, loss: 1.315, 1632/6976 datapoints
2025-03-06 22:32:35,805 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-06 22:32:35,853 - INFO - validation batch 151, loss: 0.679, 4832/6976 datapoints
2025-03-06 22:32:35,901 - INFO - validation batch 201, loss: 0.555, 6432/6976 datapoints
2025-03-06 22:32:35,917 - INFO - Epoch 128/800 done.
2025-03-06 22:32:35,917 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.840top-5 acc: 0.840
2025-03-06 22:32:35,918 - INFO - Beginning epoch 129/800
2025-03-06 22:32:35,922 - INFO - training batch 1, loss: 0.490, 32/28000 datapoints
2025-03-06 22:32:36,081 - INFO - training batch 51, loss: 0.300, 1632/28000 datapoints
2025-03-06 22:32:36,237 - INFO - training batch 101, loss: 0.258, 3232/28000 datapoints
2025-03-06 22:32:36,392 - INFO - training batch 151, loss: 0.819, 4832/28000 datapoints
2025-03-06 22:32:36,545 - INFO - training batch 201, loss: 0.390, 6432/28000 datapoints
2025-03-06 22:32:36,697 - INFO - training batch 251, loss: 0.502, 8032/28000 datapoints
2025-03-06 22:32:36,849 - INFO - training batch 301, loss: 0.807, 9632/28000 datapoints
2025-03-06 22:32:37,014 - INFO - training batch 351, loss: 0.387, 11232/28000 datapoints
2025-03-06 22:32:37,180 - INFO - training batch 401, loss: 0.853, 12832/28000 datapoints
2025-03-06 22:32:37,335 - INFO - training batch 451, loss: 0.523, 14432/28000 datapoints
2025-03-06 22:32:37,491 - INFO - training batch 501, loss: 0.370, 16032/28000 datapoints
2025-03-06 22:32:37,647 - INFO - training batch 551, loss: 0.537, 17632/28000 datapoints
2025-03-06 22:32:37,805 - INFO - training batch 601, loss: 0.751, 19232/28000 datapoints
2025-03-06 22:32:37,980 - INFO - training batch 651, loss: 0.184, 20832/28000 datapoints
2025-03-06 22:32:38,142 - INFO - training batch 701, loss: 0.435, 22432/28000 datapoints
2025-03-06 22:32:38,299 - INFO - training batch 751, loss: 0.355, 24032/28000 datapoints
2025-03-06 22:32:38,457 - INFO - training batch 801, loss: 0.304, 25632/28000 datapoints
2025-03-06 22:32:38,612 - INFO - training batch 851, loss: 0.781, 27232/28000 datapoints
2025-03-06 22:32:38,689 - INFO - validation batch 1, loss: 0.187, 32/6976 datapoints
2025-03-06 22:32:38,741 - INFO - validation batch 51, loss: 1.313, 1632/6976 datapoints
2025-03-06 22:32:38,792 - INFO - validation batch 101, loss: 0.378, 3232/6976 datapoints
2025-03-06 22:32:38,846 - INFO - validation batch 151, loss: 0.679, 4832/6976 datapoints
2025-03-06 22:32:38,899 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 22:32:38,915 - INFO - Epoch 129/800 done.
2025-03-06 22:32:38,916 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.842top-5 acc: 0.842
2025-03-06 22:32:38,916 - INFO - Beginning epoch 130/800
2025-03-06 22:32:38,922 - INFO - training batch 1, loss: 0.485, 32/28000 datapoints
2025-03-06 22:32:39,078 - INFO - training batch 51, loss: 0.295, 1632/28000 datapoints
2025-03-06 22:32:39,233 - INFO - training batch 101, loss: 0.257, 3232/28000 datapoints
2025-03-06 22:32:39,388 - INFO - training batch 151, loss: 0.815, 4832/28000 datapoints
2025-03-06 22:32:39,540 - INFO - training batch 201, loss: 0.380, 6432/28000 datapoints
2025-03-06 22:32:39,691 - INFO - training batch 251, loss: 0.500, 8032/28000 datapoints
2025-03-06 22:32:39,853 - INFO - training batch 301, loss: 0.806, 9632/28000 datapoints
2025-03-06 22:32:40,013 - INFO - training batch 351, loss: 0.386, 11232/28000 datapoints
2025-03-06 22:32:40,169 - INFO - training batch 401, loss: 0.850, 12832/28000 datapoints
2025-03-06 22:32:40,332 - INFO - training batch 451, loss: 0.518, 14432/28000 datapoints
2025-03-06 22:32:40,487 - INFO - training batch 501, loss: 0.364, 16032/28000 datapoints
2025-03-06 22:32:40,642 - INFO - training batch 551, loss: 0.534, 17632/28000 datapoints
2025-03-06 22:32:40,804 - INFO - training batch 601, loss: 0.743, 19232/28000 datapoints
2025-03-06 22:32:40,966 - INFO - training batch 651, loss: 0.182, 20832/28000 datapoints
2025-03-06 22:32:41,119 - INFO - training batch 701, loss: 0.432, 22432/28000 datapoints
2025-03-06 22:32:41,298 - INFO - training batch 751, loss: 0.352, 24032/28000 datapoints
2025-03-06 22:32:41,452 - INFO - training batch 801, loss: 0.300, 25632/28000 datapoints
2025-03-06 22:32:41,602 - INFO - training batch 851, loss: 0.775, 27232/28000 datapoints
2025-03-06 22:32:41,676 - INFO - validation batch 1, loss: 0.183, 32/6976 datapoints
2025-03-06 22:32:41,723 - INFO - validation batch 51, loss: 1.311, 1632/6976 datapoints
2025-03-06 22:32:41,770 - INFO - validation batch 101, loss: 0.378, 3232/6976 datapoints
2025-03-06 22:32:41,818 - INFO - validation batch 151, loss: 0.680, 4832/6976 datapoints
2025-03-06 22:32:41,868 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 22:32:41,884 - INFO - Epoch 130/800 done.
2025-03-06 22:32:41,884 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.843top-5 acc: 0.843
2025-03-06 22:32:41,885 - INFO - Beginning epoch 131/800
2025-03-06 22:32:41,889 - INFO - training batch 1, loss: 0.480, 32/28000 datapoints
2025-03-06 22:32:42,046 - INFO - training batch 51, loss: 0.289, 1632/28000 datapoints
2025-03-06 22:32:42,202 - INFO - training batch 101, loss: 0.256, 3232/28000 datapoints
2025-03-06 22:32:42,357 - INFO - training batch 151, loss: 0.811, 4832/28000 datapoints
2025-03-06 22:32:42,508 - INFO - training batch 201, loss: 0.371, 6432/28000 datapoints
2025-03-06 22:32:42,657 - INFO - training batch 251, loss: 0.498, 8032/28000 datapoints
2025-03-06 22:32:42,810 - INFO - training batch 301, loss: 0.805, 9632/28000 datapoints
2025-03-06 22:32:42,967 - INFO - training batch 351, loss: 0.385, 11232/28000 datapoints
2025-03-06 22:32:43,118 - INFO - training batch 401, loss: 0.847, 12832/28000 datapoints
2025-03-06 22:32:43,270 - INFO - training batch 451, loss: 0.515, 14432/28000 datapoints
2025-03-06 22:32:43,423 - INFO - training batch 501, loss: 0.357, 16032/28000 datapoints
2025-03-06 22:32:43,576 - INFO - training batch 551, loss: 0.530, 17632/28000 datapoints
2025-03-06 22:32:43,726 - INFO - training batch 601, loss: 0.735, 19232/28000 datapoints
2025-03-06 22:32:43,880 - INFO - training batch 651, loss: 0.180, 20832/28000 datapoints
2025-03-06 22:32:44,035 - INFO - training batch 701, loss: 0.428, 22432/28000 datapoints
2025-03-06 22:32:44,189 - INFO - training batch 751, loss: 0.350, 24032/28000 datapoints
2025-03-06 22:32:44,341 - INFO - training batch 801, loss: 0.296, 25632/28000 datapoints
2025-03-06 22:32:44,494 - INFO - training batch 851, loss: 0.768, 27232/28000 datapoints
2025-03-06 22:32:44,569 - INFO - validation batch 1, loss: 0.178, 32/6976 datapoints
2025-03-06 22:32:44,617 - INFO - validation batch 51, loss: 1.309, 1632/6976 datapoints
2025-03-06 22:32:44,664 - INFO - validation batch 101, loss: 0.378, 3232/6976 datapoints
2025-03-06 22:32:44,710 - INFO - validation batch 151, loss: 0.679, 4832/6976 datapoints
2025-03-06 22:32:44,758 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 22:32:44,774 - INFO - Epoch 131/800 done.
2025-03-06 22:32:44,775 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.844top-5 acc: 0.844
2025-03-06 22:32:44,775 - INFO - Beginning epoch 132/800
2025-03-06 22:32:44,779 - INFO - training batch 1, loss: 0.476, 32/28000 datapoints
2025-03-06 22:32:44,936 - INFO - training batch 51, loss: 0.284, 1632/28000 datapoints
2025-03-06 22:32:45,087 - INFO - training batch 101, loss: 0.255, 3232/28000 datapoints
2025-03-06 22:32:45,247 - INFO - training batch 151, loss: 0.807, 4832/28000 datapoints
2025-03-06 22:32:45,400 - INFO - training batch 201, loss: 0.363, 6432/28000 datapoints
2025-03-06 22:32:45,551 - INFO - training batch 251, loss: 0.496, 8032/28000 datapoints
2025-03-06 22:32:45,702 - INFO - training batch 301, loss: 0.803, 9632/28000 datapoints
2025-03-06 22:32:45,853 - INFO - training batch 351, loss: 0.384, 11232/28000 datapoints
2025-03-06 22:32:46,023 - INFO - training batch 401, loss: 0.844, 12832/28000 datapoints
2025-03-06 22:32:46,181 - INFO - training batch 451, loss: 0.511, 14432/28000 datapoints
2025-03-06 22:32:46,338 - INFO - training batch 501, loss: 0.353, 16032/28000 datapoints
2025-03-06 22:32:46,496 - INFO - training batch 551, loss: 0.527, 17632/28000 datapoints
2025-03-06 22:32:46,648 - INFO - training batch 601, loss: 0.728, 19232/28000 datapoints
2025-03-06 22:32:46,803 - INFO - training batch 651, loss: 0.178, 20832/28000 datapoints
2025-03-06 22:32:46,958 - INFO - training batch 701, loss: 0.425, 22432/28000 datapoints
2025-03-06 22:32:47,108 - INFO - training batch 751, loss: 0.348, 24032/28000 datapoints
2025-03-06 22:32:47,262 - INFO - training batch 801, loss: 0.292, 25632/28000 datapoints
2025-03-06 22:32:47,423 - INFO - training batch 851, loss: 0.762, 27232/28000 datapoints
2025-03-06 22:32:47,497 - INFO - validation batch 1, loss: 0.175, 32/6976 datapoints
2025-03-06 22:32:47,545 - INFO - validation batch 51, loss: 1.309, 1632/6976 datapoints
2025-03-06 22:32:47,593 - INFO - validation batch 101, loss: 0.378, 3232/6976 datapoints
2025-03-06 22:32:47,639 - INFO - validation batch 151, loss: 0.677, 4832/6976 datapoints
2025-03-06 22:32:47,687 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 22:32:47,703 - INFO - Epoch 132/800 done.
2025-03-06 22:32:47,703 - INFO - Final validation performance:
Loss: 0.619, top-1 acc: 0.845top-5 acc: 0.845
2025-03-06 22:32:47,704 - INFO - Beginning epoch 133/800
2025-03-06 22:32:47,708 - INFO - training batch 1, loss: 0.471, 32/28000 datapoints
2025-03-06 22:32:47,862 - INFO - training batch 51, loss: 0.279, 1632/28000 datapoints
2025-03-06 22:32:48,018 - INFO - training batch 101, loss: 0.254, 3232/28000 datapoints
2025-03-06 22:32:48,175 - INFO - training batch 151, loss: 0.804, 4832/28000 datapoints
2025-03-06 22:32:48,326 - INFO - training batch 201, loss: 0.353, 6432/28000 datapoints
2025-03-06 22:32:48,481 - INFO - training batch 251, loss: 0.494, 8032/28000 datapoints
2025-03-06 22:32:48,633 - INFO - training batch 301, loss: 0.802, 9632/28000 datapoints
2025-03-06 22:32:48,784 - INFO - training batch 351, loss: 0.383, 11232/28000 datapoints
2025-03-06 22:32:48,940 - INFO - training batch 401, loss: 0.840, 12832/28000 datapoints
2025-03-06 22:32:49,091 - INFO - training batch 451, loss: 0.507, 14432/28000 datapoints
2025-03-06 22:32:49,242 - INFO - training batch 501, loss: 0.345, 16032/28000 datapoints
2025-03-06 22:32:49,393 - INFO - training batch 551, loss: 0.524, 17632/28000 datapoints
2025-03-06 22:32:49,546 - INFO - training batch 601, loss: 0.721, 19232/28000 datapoints
2025-03-06 22:32:49,695 - INFO - training batch 651, loss: 0.176, 20832/28000 datapoints
2025-03-06 22:32:49,848 - INFO - training batch 701, loss: 0.421, 22432/28000 datapoints
2025-03-06 22:32:50,004 - INFO - training batch 751, loss: 0.346, 24032/28000 datapoints
2025-03-06 22:32:50,156 - INFO - training batch 801, loss: 0.288, 25632/28000 datapoints
2025-03-06 22:32:50,315 - INFO - training batch 851, loss: 0.755, 27232/28000 datapoints
2025-03-06 22:32:50,389 - INFO - validation batch 1, loss: 0.171, 32/6976 datapoints
2025-03-06 22:32:50,436 - INFO - validation batch 51, loss: 1.308, 1632/6976 datapoints
2025-03-06 22:32:50,486 - INFO - validation batch 101, loss: 0.380, 3232/6976 datapoints
2025-03-06 22:32:50,533 - INFO - validation batch 151, loss: 0.677, 4832/6976 datapoints
2025-03-06 22:32:50,581 - INFO - validation batch 201, loss: 0.557, 6432/6976 datapoints
2025-03-06 22:32:50,597 - INFO - Epoch 133/800 done.
2025-03-06 22:32:50,598 - INFO - Final validation performance:
Loss: 0.618, top-1 acc: 0.846top-5 acc: 0.846
2025-03-06 22:32:50,598 - INFO - Beginning epoch 134/800
2025-03-06 22:32:50,603 - INFO - training batch 1, loss: 0.467, 32/28000 datapoints
2025-03-06 22:32:50,756 - INFO - training batch 51, loss: 0.275, 1632/28000 datapoints
2025-03-06 22:32:50,907 - INFO - training batch 101, loss: 0.253, 3232/28000 datapoints
2025-03-06 22:32:51,070 - INFO - training batch 151, loss: 0.799, 4832/28000 datapoints
2025-03-06 22:32:51,225 - INFO - training batch 201, loss: 0.343, 6432/28000 datapoints
2025-03-06 22:32:51,405 - INFO - training batch 251, loss: 0.492, 8032/28000 datapoints
2025-03-06 22:32:51,557 - INFO - training batch 301, loss: 0.801, 9632/28000 datapoints
2025-03-06 22:32:51,707 - INFO - training batch 351, loss: 0.381, 11232/28000 datapoints
2025-03-06 22:32:51,858 - INFO - training batch 401, loss: 0.837, 12832/28000 datapoints
2025-03-06 22:32:52,019 - INFO - training batch 451, loss: 0.503, 14432/28000 datapoints
2025-03-06 22:32:52,177 - INFO - training batch 501, loss: 0.339, 16032/28000 datapoints
2025-03-06 22:32:52,330 - INFO - training batch 551, loss: 0.521, 17632/28000 datapoints
2025-03-06 22:32:52,484 - INFO - training batch 601, loss: 0.714, 19232/28000 datapoints
2025-03-06 22:32:52,643 - INFO - training batch 651, loss: 0.174, 20832/28000 datapoints
2025-03-06 22:32:52,796 - INFO - training batch 701, loss: 0.418, 22432/28000 datapoints
2025-03-06 22:32:52,955 - INFO - training batch 751, loss: 0.344, 24032/28000 datapoints
2025-03-06 22:32:53,105 - INFO - training batch 801, loss: 0.285, 25632/28000 datapoints
2025-03-06 22:32:53,257 - INFO - training batch 851, loss: 0.749, 27232/28000 datapoints
2025-03-06 22:32:53,335 - INFO - validation batch 1, loss: 0.167, 32/6976 datapoints
2025-03-06 22:32:53,385 - INFO - validation batch 51, loss: 1.307, 1632/6976 datapoints
2025-03-06 22:32:53,433 - INFO - validation batch 101, loss: 0.380, 3232/6976 datapoints
2025-03-06 22:32:53,480 - INFO - validation batch 151, loss: 0.676, 4832/6976 datapoints
2025-03-06 22:32:53,529 - INFO - validation batch 201, loss: 0.557, 6432/6976 datapoints
2025-03-06 22:32:53,547 - INFO - Epoch 134/800 done.
2025-03-06 22:32:53,547 - INFO - Final validation performance:
Loss: 0.617, top-1 acc: 0.848top-5 acc: 0.848
2025-03-06 22:32:53,548 - INFO - Beginning epoch 135/800
2025-03-06 22:32:53,552 - INFO - training batch 1, loss: 0.464, 32/28000 datapoints
2025-03-06 22:32:53,706 - INFO - training batch 51, loss: 0.271, 1632/28000 datapoints
2025-03-06 22:32:53,860 - INFO - training batch 101, loss: 0.252, 3232/28000 datapoints
2025-03-06 22:32:54,016 - INFO - training batch 151, loss: 0.796, 4832/28000 datapoints
2025-03-06 22:32:54,172 - INFO - training batch 201, loss: 0.336, 6432/28000 datapoints
2025-03-06 22:32:54,327 - INFO - training batch 251, loss: 0.491, 8032/28000 datapoints
2025-03-06 22:32:54,479 - INFO - training batch 301, loss: 0.800, 9632/28000 datapoints
2025-03-06 22:32:54,632 - INFO - training batch 351, loss: 0.380, 11232/28000 datapoints
2025-03-06 22:32:54,784 - INFO - training batch 401, loss: 0.834, 12832/28000 datapoints
2025-03-06 22:32:54,939 - INFO - training batch 451, loss: 0.500, 14432/28000 datapoints
2025-03-06 22:32:55,093 - INFO - training batch 501, loss: 0.334, 16032/28000 datapoints
2025-03-06 22:32:55,254 - INFO - training batch 551, loss: 0.518, 17632/28000 datapoints
2025-03-06 22:32:55,405 - INFO - training batch 601, loss: 0.706, 19232/28000 datapoints
2025-03-06 22:32:55,558 - INFO - training batch 651, loss: 0.173, 20832/28000 datapoints
2025-03-06 22:32:55,711 - INFO - training batch 701, loss: 0.415, 22432/28000 datapoints
2025-03-06 22:32:55,862 - INFO - training batch 751, loss: 0.342, 24032/28000 datapoints
2025-03-06 22:32:56,017 - INFO - training batch 801, loss: 0.281, 25632/28000 datapoints
2025-03-06 22:32:56,171 - INFO - training batch 851, loss: 0.743, 27232/28000 datapoints
2025-03-06 22:32:56,246 - INFO - validation batch 1, loss: 0.164, 32/6976 datapoints
2025-03-06 22:32:56,295 - INFO - validation batch 51, loss: 1.307, 1632/6976 datapoints
2025-03-06 22:32:56,343 - INFO - validation batch 101, loss: 0.381, 3232/6976 datapoints
2025-03-06 22:32:56,390 - INFO - validation batch 151, loss: 0.676, 4832/6976 datapoints
2025-03-06 22:32:56,439 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 22:32:56,455 - INFO - Epoch 135/800 done.
2025-03-06 22:32:56,455 - INFO - Final validation performance:
Loss: 0.617, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 22:32:56,456 - INFO - Beginning epoch 136/800
2025-03-06 22:32:56,459 - INFO - training batch 1, loss: 0.462, 32/28000 datapoints
2025-03-06 22:32:56,619 - INFO - training batch 51, loss: 0.267, 1632/28000 datapoints
2025-03-06 22:32:56,771 - INFO - training batch 101, loss: 0.252, 3232/28000 datapoints
2025-03-06 22:32:56,925 - INFO - training batch 151, loss: 0.792, 4832/28000 datapoints
2025-03-06 22:32:57,080 - INFO - training batch 201, loss: 0.330, 6432/28000 datapoints
2025-03-06 22:32:57,234 - INFO - training batch 251, loss: 0.490, 8032/28000 datapoints
2025-03-06 22:32:57,387 - INFO - training batch 301, loss: 0.798, 9632/28000 datapoints
2025-03-06 22:32:57,546 - INFO - training batch 351, loss: 0.378, 11232/28000 datapoints
2025-03-06 22:32:57,696 - INFO - training batch 401, loss: 0.830, 12832/28000 datapoints
2025-03-06 22:32:57,847 - INFO - training batch 451, loss: 0.498, 14432/28000 datapoints
2025-03-06 22:32:58,000 - INFO - training batch 501, loss: 0.329, 16032/28000 datapoints
2025-03-06 22:32:58,169 - INFO - training batch 551, loss: 0.515, 17632/28000 datapoints
2025-03-06 22:32:58,324 - INFO - training batch 601, loss: 0.699, 19232/28000 datapoints
2025-03-06 22:32:58,483 - INFO - training batch 651, loss: 0.171, 20832/28000 datapoints
2025-03-06 22:32:58,646 - INFO - training batch 701, loss: 0.411, 22432/28000 datapoints
2025-03-06 22:32:58,800 - INFO - training batch 751, loss: 0.339, 24032/28000 datapoints
2025-03-06 22:32:58,957 - INFO - training batch 801, loss: 0.278, 25632/28000 datapoints
2025-03-06 22:32:59,112 - INFO - training batch 851, loss: 0.737, 27232/28000 datapoints
2025-03-06 22:32:59,187 - INFO - validation batch 1, loss: 0.160, 32/6976 datapoints
2025-03-06 22:32:59,235 - INFO - validation batch 51, loss: 1.306, 1632/6976 datapoints
2025-03-06 22:32:59,283 - INFO - validation batch 101, loss: 0.382, 3232/6976 datapoints
2025-03-06 22:32:59,330 - INFO - validation batch 151, loss: 0.675, 4832/6976 datapoints
2025-03-06 22:32:59,378 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 22:32:59,394 - INFO - Epoch 136/800 done.
2025-03-06 22:32:59,394 - INFO - Final validation performance:
Loss: 0.616, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 22:32:59,395 - INFO - Beginning epoch 137/800
2025-03-06 22:32:59,399 - INFO - training batch 1, loss: 0.459, 32/28000 datapoints
2025-03-06 22:32:59,551 - INFO - training batch 51, loss: 0.263, 1632/28000 datapoints
2025-03-06 22:32:59,707 - INFO - training batch 101, loss: 0.251, 3232/28000 datapoints
2025-03-06 22:32:59,858 - INFO - training batch 151, loss: 0.789, 4832/28000 datapoints
2025-03-06 22:33:00,014 - INFO - training batch 201, loss: 0.321, 6432/28000 datapoints
2025-03-06 22:33:00,172 - INFO - training batch 251, loss: 0.488, 8032/28000 datapoints
2025-03-06 22:33:00,332 - INFO - training batch 301, loss: 0.797, 9632/28000 datapoints
2025-03-06 22:33:00,488 - INFO - training batch 351, loss: 0.376, 11232/28000 datapoints
2025-03-06 22:33:00,641 - INFO - training batch 401, loss: 0.827, 12832/28000 datapoints
2025-03-06 22:33:00,793 - INFO - training batch 451, loss: 0.495, 14432/28000 datapoints
2025-03-06 22:33:00,946 - INFO - training batch 501, loss: 0.323, 16032/28000 datapoints
2025-03-06 22:33:01,098 - INFO - training batch 551, loss: 0.512, 17632/28000 datapoints
2025-03-06 22:33:01,249 - INFO - training batch 601, loss: 0.692, 19232/28000 datapoints
2025-03-06 22:33:01,426 - INFO - training batch 651, loss: 0.169, 20832/28000 datapoints
2025-03-06 22:33:01,589 - INFO - training batch 701, loss: 0.408, 22432/28000 datapoints
2025-03-06 22:33:01,752 - INFO - training batch 751, loss: 0.335, 24032/28000 datapoints
2025-03-06 22:33:01,902 - INFO - training batch 801, loss: 0.274, 25632/28000 datapoints
2025-03-06 22:33:02,054 - INFO - training batch 851, loss: 0.730, 27232/28000 datapoints
2025-03-06 22:33:02,129 - INFO - validation batch 1, loss: 0.158, 32/6976 datapoints
2025-03-06 22:33:02,177 - INFO - validation batch 51, loss: 1.305, 1632/6976 datapoints
2025-03-06 22:33:02,229 - INFO - validation batch 101, loss: 0.382, 3232/6976 datapoints
2025-03-06 22:33:02,278 - INFO - validation batch 151, loss: 0.671, 4832/6976 datapoints
2025-03-06 22:33:02,325 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 22:33:02,341 - INFO - Epoch 137/800 done.
2025-03-06 22:33:02,342 - INFO - Final validation performance:
Loss: 0.614, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 22:33:02,342 - INFO - Beginning epoch 138/800
2025-03-06 22:33:02,346 - INFO - training batch 1, loss: 0.457, 32/28000 datapoints
2025-03-06 22:33:02,501 - INFO - training batch 51, loss: 0.259, 1632/28000 datapoints
2025-03-06 22:33:02,655 - INFO - training batch 101, loss: 0.250, 3232/28000 datapoints
2025-03-06 22:33:02,805 - INFO - training batch 151, loss: 0.786, 4832/28000 datapoints
2025-03-06 22:33:02,960 - INFO - training batch 201, loss: 0.313, 6432/28000 datapoints
2025-03-06 22:33:03,111 - INFO - training batch 251, loss: 0.487, 8032/28000 datapoints
2025-03-06 22:33:03,263 - INFO - training batch 301, loss: 0.794, 9632/28000 datapoints
2025-03-06 22:33:03,415 - INFO - training batch 351, loss: 0.375, 11232/28000 datapoints
2025-03-06 22:33:03,568 - INFO - training batch 401, loss: 0.825, 12832/28000 datapoints
2025-03-06 22:33:03,721 - INFO - training batch 451, loss: 0.492, 14432/28000 datapoints
2025-03-06 22:33:03,874 - INFO - training batch 501, loss: 0.319, 16032/28000 datapoints
2025-03-06 22:33:04,027 - INFO - training batch 551, loss: 0.509, 17632/28000 datapoints
2025-03-06 22:33:04,178 - INFO - training batch 601, loss: 0.685, 19232/28000 datapoints
2025-03-06 22:33:04,348 - INFO - training batch 651, loss: 0.168, 20832/28000 datapoints
2025-03-06 22:33:04,500 - INFO - training batch 701, loss: 0.405, 22432/28000 datapoints
2025-03-06 22:33:04,651 - INFO - training batch 751, loss: 0.330, 24032/28000 datapoints
2025-03-06 22:33:04,811 - INFO - training batch 801, loss: 0.271, 25632/28000 datapoints
2025-03-06 22:33:04,968 - INFO - training batch 851, loss: 0.723, 27232/28000 datapoints
2025-03-06 22:33:05,041 - INFO - validation batch 1, loss: 0.155, 32/6976 datapoints
2025-03-06 22:33:05,094 - INFO - validation batch 51, loss: 1.304, 1632/6976 datapoints
2025-03-06 22:33:05,145 - INFO - validation batch 101, loss: 0.383, 3232/6976 datapoints
2025-03-06 22:33:05,193 - INFO - validation batch 151, loss: 0.666, 4832/6976 datapoints
2025-03-06 22:33:05,250 - INFO - validation batch 201, loss: 0.557, 6432/6976 datapoints
2025-03-06 22:33:05,266 - INFO - Epoch 138/800 done.
2025-03-06 22:33:05,267 - INFO - Final validation performance:
Loss: 0.613, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 22:33:05,267 - INFO - Beginning epoch 139/800
2025-03-06 22:33:05,272 - INFO - training batch 1, loss: 0.454, 32/28000 datapoints
2025-03-06 22:33:05,425 - INFO - training batch 51, loss: 0.256, 1632/28000 datapoints
2025-03-06 22:33:05,576 - INFO - training batch 101, loss: 0.249, 3232/28000 datapoints
2025-03-06 22:33:05,729 - INFO - training batch 151, loss: 0.782, 4832/28000 datapoints
2025-03-06 22:33:05,882 - INFO - training batch 201, loss: 0.304, 6432/28000 datapoints
2025-03-06 22:33:06,040 - INFO - training batch 251, loss: 0.486, 8032/28000 datapoints
2025-03-06 22:33:06,192 - INFO - training batch 301, loss: 0.794, 9632/28000 datapoints
2025-03-06 22:33:06,350 - INFO - training batch 351, loss: 0.373, 11232/28000 datapoints
2025-03-06 22:33:06,501 - INFO - training batch 401, loss: 0.822, 12832/28000 datapoints
2025-03-06 22:33:06,654 - INFO - training batch 451, loss: 0.489, 14432/28000 datapoints
2025-03-06 22:33:06,804 - INFO - training batch 501, loss: 0.313, 16032/28000 datapoints
2025-03-06 22:33:06,958 - INFO - training batch 551, loss: 0.505, 17632/28000 datapoints
2025-03-06 22:33:07,110 - INFO - training batch 601, loss: 0.677, 19232/28000 datapoints
2025-03-06 22:33:07,262 - INFO - training batch 651, loss: 0.167, 20832/28000 datapoints
2025-03-06 22:33:07,422 - INFO - training batch 701, loss: 0.402, 22432/28000 datapoints
2025-03-06 22:33:07,574 - INFO - training batch 751, loss: 0.328, 24032/28000 datapoints
2025-03-06 22:33:07,725 - INFO - training batch 801, loss: 0.267, 25632/28000 datapoints
2025-03-06 22:33:07,876 - INFO - training batch 851, loss: 0.716, 27232/28000 datapoints
2025-03-06 22:33:07,953 - INFO - validation batch 1, loss: 0.152, 32/6976 datapoints
2025-03-06 22:33:08,001 - INFO - validation batch 51, loss: 1.304, 1632/6976 datapoints
2025-03-06 22:33:08,048 - INFO - validation batch 101, loss: 0.383, 3232/6976 datapoints
2025-03-06 22:33:08,096 - INFO - validation batch 151, loss: 0.659, 4832/6976 datapoints
2025-03-06 22:33:08,143 - INFO - validation batch 201, loss: 0.557, 6432/6976 datapoints
2025-03-06 22:33:08,160 - INFO - Epoch 139/800 done.
2025-03-06 22:33:08,160 - INFO - Final validation performance:
Loss: 0.611, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 22:33:08,163 - INFO - Beginning epoch 140/800
2025-03-06 22:33:08,167 - INFO - training batch 1, loss: 0.451, 32/28000 datapoints
2025-03-06 22:33:08,323 - INFO - training batch 51, loss: 0.252, 1632/28000 datapoints
2025-03-06 22:33:08,476 - INFO - training batch 101, loss: 0.249, 3232/28000 datapoints
2025-03-06 22:33:08,639 - INFO - training batch 151, loss: 0.778, 4832/28000 datapoints
2025-03-06 22:33:08,793 - INFO - training batch 201, loss: 0.295, 6432/28000 datapoints
2025-03-06 22:33:08,947 - INFO - training batch 251, loss: 0.485, 8032/28000 datapoints
2025-03-06 22:33:09,099 - INFO - training batch 301, loss: 0.791, 9632/28000 datapoints
2025-03-06 22:33:09,253 - INFO - training batch 351, loss: 0.371, 11232/28000 datapoints
2025-03-06 22:33:09,408 - INFO - training batch 401, loss: 0.819, 12832/28000 datapoints
2025-03-06 22:33:09,559 - INFO - training batch 451, loss: 0.486, 14432/28000 datapoints
2025-03-06 22:33:09,714 - INFO - training batch 501, loss: 0.308, 16032/28000 datapoints
2025-03-06 22:33:09,869 - INFO - training batch 551, loss: 0.501, 17632/28000 datapoints
2025-03-06 22:33:10,029 - INFO - training batch 601, loss: 0.671, 19232/28000 datapoints
2025-03-06 22:33:10,183 - INFO - training batch 651, loss: 0.166, 20832/28000 datapoints
2025-03-06 22:33:10,344 - INFO - training batch 701, loss: 0.400, 22432/28000 datapoints
2025-03-06 22:33:10,508 - INFO - training batch 751, loss: 0.325, 24032/28000 datapoints
2025-03-06 22:33:10,659 - INFO - training batch 801, loss: 0.264, 25632/28000 datapoints
2025-03-06 22:33:10,810 - INFO - training batch 851, loss: 0.709, 27232/28000 datapoints
2025-03-06 22:33:10,885 - INFO - validation batch 1, loss: 0.150, 32/6976 datapoints
2025-03-06 22:33:10,942 - INFO - validation batch 51, loss: 1.305, 1632/6976 datapoints
2025-03-06 22:33:10,992 - INFO - validation batch 101, loss: 0.384, 3232/6976 datapoints
2025-03-06 22:33:11,042 - INFO - validation batch 151, loss: 0.653, 4832/6976 datapoints
2025-03-06 22:33:11,090 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 22:33:11,106 - INFO - Epoch 140/800 done.
2025-03-06 22:33:11,106 - INFO - Final validation performance:
Loss: 0.610, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 22:33:11,107 - INFO - Beginning epoch 141/800
2025-03-06 22:33:11,113 - INFO - training batch 1, loss: 0.447, 32/28000 datapoints
2025-03-06 22:33:11,271 - INFO - training batch 51, loss: 0.249, 1632/28000 datapoints
2025-03-06 22:33:11,430 - INFO - training batch 101, loss: 0.249, 3232/28000 datapoints
2025-03-06 22:33:11,614 - INFO - training batch 151, loss: 0.774, 4832/28000 datapoints
2025-03-06 22:33:11,768 - INFO - training batch 201, loss: 0.288, 6432/28000 datapoints
2025-03-06 22:33:11,919 - INFO - training batch 251, loss: 0.484, 8032/28000 datapoints
2025-03-06 22:33:12,072 - INFO - training batch 301, loss: 0.790, 9632/28000 datapoints
2025-03-06 22:33:12,225 - INFO - training batch 351, loss: 0.370, 11232/28000 datapoints
2025-03-06 22:33:12,381 - INFO - training batch 401, loss: 0.816, 12832/28000 datapoints
2025-03-06 22:33:12,531 - INFO - training batch 451, loss: 0.483, 14432/28000 datapoints
2025-03-06 22:33:12,683 - INFO - training batch 501, loss: 0.304, 16032/28000 datapoints
2025-03-06 22:33:12,835 - INFO - training batch 551, loss: 0.498, 17632/28000 datapoints
2025-03-06 22:33:12,990 - INFO - training batch 601, loss: 0.663, 19232/28000 datapoints
2025-03-06 22:33:13,141 - INFO - training batch 651, loss: 0.165, 20832/28000 datapoints
2025-03-06 22:33:13,293 - INFO - training batch 701, loss: 0.397, 22432/28000 datapoints
2025-03-06 22:33:13,446 - INFO - training batch 751, loss: 0.324, 24032/28000 datapoints
2025-03-06 22:33:13,599 - INFO - training batch 801, loss: 0.261, 25632/28000 datapoints
2025-03-06 22:33:13,751 - INFO - training batch 851, loss: 0.703, 27232/28000 datapoints
2025-03-06 22:33:13,829 - INFO - validation batch 1, loss: 0.148, 32/6976 datapoints
2025-03-06 22:33:13,876 - INFO - validation batch 51, loss: 1.303, 1632/6976 datapoints
2025-03-06 22:33:13,923 - INFO - validation batch 101, loss: 0.384, 3232/6976 datapoints
2025-03-06 22:33:13,975 - INFO - validation batch 151, loss: 0.649, 4832/6976 datapoints
2025-03-06 22:33:14,023 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 22:33:14,039 - INFO - Epoch 141/800 done.
2025-03-06 22:33:14,040 - INFO - Final validation performance:
Loss: 0.609, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 22:33:14,040 - INFO - Beginning epoch 142/800
2025-03-06 22:33:14,044 - INFO - training batch 1, loss: 0.445, 32/28000 datapoints
2025-03-06 22:33:14,199 - INFO - training batch 51, loss: 0.245, 1632/28000 datapoints
2025-03-06 22:33:14,387 - INFO - training batch 101, loss: 0.249, 3232/28000 datapoints
2025-03-06 22:33:14,579 - INFO - training batch 151, loss: 0.771, 4832/28000 datapoints
2025-03-06 22:33:14,749 - INFO - training batch 201, loss: 0.282, 6432/28000 datapoints
2025-03-06 22:33:14,921 - INFO - training batch 251, loss: 0.483, 8032/28000 datapoints
2025-03-06 22:33:15,075 - INFO - training batch 301, loss: 0.788, 9632/28000 datapoints
2025-03-06 22:33:15,239 - INFO - training batch 351, loss: 0.368, 11232/28000 datapoints
2025-03-06 22:33:15,401 - INFO - training batch 401, loss: 0.812, 12832/28000 datapoints
2025-03-06 22:33:15,554 - INFO - training batch 451, loss: 0.481, 14432/28000 datapoints
2025-03-06 22:33:15,704 - INFO - training batch 501, loss: 0.299, 16032/28000 datapoints
2025-03-06 22:33:15,856 - INFO - training batch 551, loss: 0.496, 17632/28000 datapoints
2025-03-06 22:33:16,010 - INFO - training batch 601, loss: 0.657, 19232/28000 datapoints
2025-03-06 22:33:16,160 - INFO - training batch 651, loss: 0.163, 20832/28000 datapoints
2025-03-06 22:33:16,315 - INFO - training batch 701, loss: 0.394, 22432/28000 datapoints
2025-03-06 22:33:16,470 - INFO - training batch 751, loss: 0.321, 24032/28000 datapoints
2025-03-06 22:33:16,621 - INFO - training batch 801, loss: 0.258, 25632/28000 datapoints
2025-03-06 22:33:16,789 - INFO - training batch 851, loss: 0.696, 27232/28000 datapoints
2025-03-06 22:33:16,863 - INFO - validation batch 1, loss: 0.145, 32/6976 datapoints
2025-03-06 22:33:16,910 - INFO - validation batch 51, loss: 1.301, 1632/6976 datapoints
2025-03-06 22:33:16,961 - INFO - validation batch 101, loss: 0.386, 3232/6976 datapoints
2025-03-06 22:33:17,011 - INFO - validation batch 151, loss: 0.645, 4832/6976 datapoints
2025-03-06 22:33:17,058 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 22:33:17,079 - INFO - Epoch 142/800 done.
2025-03-06 22:33:17,079 - INFO - Final validation performance:
Loss: 0.607, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 22:33:17,080 - INFO - Beginning epoch 143/800
2025-03-06 22:33:17,085 - INFO - training batch 1, loss: 0.443, 32/28000 datapoints
2025-03-06 22:33:17,248 - INFO - training batch 51, loss: 0.242, 1632/28000 datapoints
2025-03-06 22:33:17,465 - INFO - training batch 101, loss: 0.248, 3232/28000 datapoints
2025-03-06 22:33:17,637 - INFO - training batch 151, loss: 0.767, 4832/28000 datapoints
2025-03-06 22:33:17,801 - INFO - training batch 201, loss: 0.276, 6432/28000 datapoints
2025-03-06 22:33:17,959 - INFO - training batch 251, loss: 0.483, 8032/28000 datapoints
2025-03-06 22:33:18,110 - INFO - training batch 301, loss: 0.787, 9632/28000 datapoints
2025-03-06 22:33:18,264 - INFO - training batch 351, loss: 0.366, 11232/28000 datapoints
2025-03-06 22:33:18,416 - INFO - training batch 401, loss: 0.809, 12832/28000 datapoints
2025-03-06 22:33:18,573 - INFO - training batch 451, loss: 0.478, 14432/28000 datapoints
2025-03-06 22:33:18,725 - INFO - training batch 501, loss: 0.295, 16032/28000 datapoints
2025-03-06 22:33:18,894 - INFO - training batch 551, loss: 0.493, 17632/28000 datapoints
2025-03-06 22:33:19,052 - INFO - training batch 601, loss: 0.650, 19232/28000 datapoints
2025-03-06 22:33:19,208 - INFO - training batch 651, loss: 0.162, 20832/28000 datapoints
2025-03-06 22:33:19,368 - INFO - training batch 701, loss: 0.391, 22432/28000 datapoints
2025-03-06 22:33:19,521 - INFO - training batch 751, loss: 0.320, 24032/28000 datapoints
2025-03-06 22:33:19,673 - INFO - training batch 801, loss: 0.255, 25632/28000 datapoints
2025-03-06 22:33:19,829 - INFO - training batch 851, loss: 0.690, 27232/28000 datapoints
2025-03-06 22:33:19,907 - INFO - validation batch 1, loss: 0.143, 32/6976 datapoints
2025-03-06 22:33:19,963 - INFO - validation batch 51, loss: 1.301, 1632/6976 datapoints
2025-03-06 22:33:20,015 - INFO - validation batch 101, loss: 0.386, 3232/6976 datapoints
2025-03-06 22:33:20,067 - INFO - validation batch 151, loss: 0.640, 4832/6976 datapoints
2025-03-06 22:33:20,119 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 22:33:20,140 - INFO - Epoch 143/800 done.
2025-03-06 22:33:20,140 - INFO - Final validation performance:
Loss: 0.606, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 22:33:20,141 - INFO - Beginning epoch 144/800
2025-03-06 22:33:20,145 - INFO - training batch 1, loss: 0.441, 32/28000 datapoints
2025-03-06 22:33:20,309 - INFO - training batch 51, loss: 0.239, 1632/28000 datapoints
2025-03-06 22:33:20,469 - INFO - training batch 101, loss: 0.247, 3232/28000 datapoints
2025-03-06 22:33:20,623 - INFO - training batch 151, loss: 0.764, 4832/28000 datapoints
2025-03-06 22:33:20,778 - INFO - training batch 201, loss: 0.271, 6432/28000 datapoints
2025-03-06 22:33:20,937 - INFO - training batch 251, loss: 0.483, 8032/28000 datapoints
2025-03-06 22:33:21,092 - INFO - training batch 301, loss: 0.785, 9632/28000 datapoints
2025-03-06 22:33:21,246 - INFO - training batch 351, loss: 0.363, 11232/28000 datapoints
2025-03-06 22:33:21,403 - INFO - training batch 401, loss: 0.805, 12832/28000 datapoints
2025-03-06 22:33:21,562 - INFO - training batch 451, loss: 0.476, 14432/28000 datapoints
2025-03-06 22:33:21,737 - INFO - training batch 501, loss: 0.290, 16032/28000 datapoints
2025-03-06 22:33:21,893 - INFO - training batch 551, loss: 0.490, 17632/28000 datapoints
2025-03-06 22:33:22,050 - INFO - training batch 601, loss: 0.645, 19232/28000 datapoints
2025-03-06 22:33:22,204 - INFO - training batch 651, loss: 0.161, 20832/28000 datapoints
2025-03-06 22:33:22,366 - INFO - training batch 701, loss: 0.388, 22432/28000 datapoints
2025-03-06 22:33:22,520 - INFO - training batch 751, loss: 0.317, 24032/28000 datapoints
2025-03-06 22:33:22,673 - INFO - training batch 801, loss: 0.252, 25632/28000 datapoints
2025-03-06 22:33:22,830 - INFO - training batch 851, loss: 0.684, 27232/28000 datapoints
2025-03-06 22:33:22,919 - INFO - validation batch 1, loss: 0.141, 32/6976 datapoints
2025-03-06 22:33:22,979 - INFO - validation batch 51, loss: 1.299, 1632/6976 datapoints
2025-03-06 22:33:23,031 - INFO - validation batch 101, loss: 0.387, 3232/6976 datapoints
2025-03-06 22:33:23,083 - INFO - validation batch 151, loss: 0.634, 4832/6976 datapoints
2025-03-06 22:33:23,132 - INFO - validation batch 201, loss: 0.560, 6432/6976 datapoints
2025-03-06 22:33:23,150 - INFO - Epoch 144/800 done.
2025-03-06 22:33:23,150 - INFO - Final validation performance:
Loss: 0.604, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:33:23,151 - INFO - Beginning epoch 145/800
2025-03-06 22:33:23,155 - INFO - training batch 1, loss: 0.438, 32/28000 datapoints
2025-03-06 22:33:23,311 - INFO - training batch 51, loss: 0.236, 1632/28000 datapoints
2025-03-06 22:33:23,467 - INFO - training batch 101, loss: 0.247, 3232/28000 datapoints
2025-03-06 22:33:23,620 - INFO - training batch 151, loss: 0.760, 4832/28000 datapoints
2025-03-06 22:33:23,775 - INFO - training batch 201, loss: 0.265, 6432/28000 datapoints
2025-03-06 22:33:23,927 - INFO - training batch 251, loss: 0.482, 8032/28000 datapoints
2025-03-06 22:33:24,081 - INFO - training batch 301, loss: 0.783, 9632/28000 datapoints
2025-03-06 22:33:24,231 - INFO - training batch 351, loss: 0.360, 11232/28000 datapoints
2025-03-06 22:33:24,388 - INFO - training batch 401, loss: 0.802, 12832/28000 datapoints
2025-03-06 22:33:24,539 - INFO - training batch 451, loss: 0.474, 14432/28000 datapoints
2025-03-06 22:33:24,690 - INFO - training batch 501, loss: 0.286, 16032/28000 datapoints
2025-03-06 22:33:24,842 - INFO - training batch 551, loss: 0.487, 17632/28000 datapoints
2025-03-06 22:33:24,997 - INFO - training batch 601, loss: 0.638, 19232/28000 datapoints
2025-03-06 22:33:25,148 - INFO - training batch 651, loss: 0.159, 20832/28000 datapoints
2025-03-06 22:33:25,305 - INFO - training batch 701, loss: 0.386, 22432/28000 datapoints
2025-03-06 22:33:25,458 - INFO - training batch 751, loss: 0.317, 24032/28000 datapoints
2025-03-06 22:33:25,608 - INFO - training batch 801, loss: 0.249, 25632/28000 datapoints
2025-03-06 22:33:25,760 - INFO - training batch 851, loss: 0.678, 27232/28000 datapoints
2025-03-06 22:33:25,834 - INFO - validation batch 1, loss: 0.139, 32/6976 datapoints
2025-03-06 22:33:25,885 - INFO - validation batch 51, loss: 1.297, 1632/6976 datapoints
2025-03-06 22:33:25,934 - INFO - validation batch 101, loss: 0.387, 3232/6976 datapoints
2025-03-06 22:33:25,986 - INFO - validation batch 151, loss: 0.627, 4832/6976 datapoints
2025-03-06 22:33:26,034 - INFO - validation batch 201, loss: 0.560, 6432/6976 datapoints
2025-03-06 22:33:26,051 - INFO - Epoch 145/800 done.
2025-03-06 22:33:26,051 - INFO - Final validation performance:
Loss: 0.602, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:33:26,051 - INFO - Beginning epoch 146/800
2025-03-06 22:33:26,056 - INFO - training batch 1, loss: 0.436, 32/28000 datapoints
2025-03-06 22:33:26,209 - INFO - training batch 51, loss: 0.233, 1632/28000 datapoints
2025-03-06 22:33:26,363 - INFO - training batch 101, loss: 0.245, 3232/28000 datapoints
2025-03-06 22:33:26,517 - INFO - training batch 151, loss: 0.756, 4832/28000 datapoints
2025-03-06 22:33:26,668 - INFO - training batch 201, loss: 0.260, 6432/28000 datapoints
2025-03-06 22:33:26,819 - INFO - training batch 251, loss: 0.482, 8032/28000 datapoints
2025-03-06 22:33:26,971 - INFO - training batch 301, loss: 0.782, 9632/28000 datapoints
2025-03-06 22:33:27,123 - INFO - training batch 351, loss: 0.358, 11232/28000 datapoints
2025-03-06 22:33:27,275 - INFO - training batch 401, loss: 0.797, 12832/28000 datapoints
2025-03-06 22:33:27,427 - INFO - training batch 451, loss: 0.471, 14432/28000 datapoints
2025-03-06 22:33:27,585 - INFO - training batch 501, loss: 0.282, 16032/28000 datapoints
2025-03-06 22:33:27,734 - INFO - training batch 551, loss: 0.484, 17632/28000 datapoints
2025-03-06 22:33:27,885 - INFO - training batch 601, loss: 0.632, 19232/28000 datapoints
2025-03-06 22:33:28,040 - INFO - training batch 651, loss: 0.158, 20832/28000 datapoints
2025-03-06 22:33:28,190 - INFO - training batch 701, loss: 0.383, 22432/28000 datapoints
2025-03-06 22:33:28,344 - INFO - training batch 751, loss: 0.313, 24032/28000 datapoints
2025-03-06 22:33:28,495 - INFO - training batch 801, loss: 0.247, 25632/28000 datapoints
2025-03-06 22:33:28,648 - INFO - training batch 851, loss: 0.671, 27232/28000 datapoints
2025-03-06 22:33:28,722 - INFO - validation batch 1, loss: 0.137, 32/6976 datapoints
2025-03-06 22:33:28,770 - INFO - validation batch 51, loss: 1.294, 1632/6976 datapoints
2025-03-06 22:33:28,818 - INFO - validation batch 101, loss: 0.388, 3232/6976 datapoints
2025-03-06 22:33:28,865 - INFO - validation batch 151, loss: 0.621, 4832/6976 datapoints
2025-03-06 22:33:28,914 - INFO - validation batch 201, loss: 0.561, 6432/6976 datapoints
2025-03-06 22:33:28,930 - INFO - Epoch 146/800 done.
2025-03-06 22:33:28,930 - INFO - Final validation performance:
Loss: 0.600, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:33:28,931 - INFO - Beginning epoch 147/800
2025-03-06 22:33:28,937 - INFO - training batch 1, loss: 0.434, 32/28000 datapoints
2025-03-06 22:33:29,103 - INFO - training batch 51, loss: 0.230, 1632/28000 datapoints
2025-03-06 22:33:29,253 - INFO - training batch 101, loss: 0.245, 3232/28000 datapoints
2025-03-06 22:33:29,410 - INFO - training batch 151, loss: 0.752, 4832/28000 datapoints
2025-03-06 22:33:29,571 - INFO - training batch 201, loss: 0.255, 6432/28000 datapoints
2025-03-06 22:33:29,725 - INFO - training batch 251, loss: 0.482, 8032/28000 datapoints
2025-03-06 22:33:29,879 - INFO - training batch 301, loss: 0.780, 9632/28000 datapoints
2025-03-06 22:33:30,036 - INFO - training batch 351, loss: 0.355, 11232/28000 datapoints
2025-03-06 22:33:30,188 - INFO - training batch 401, loss: 0.794, 12832/28000 datapoints
2025-03-06 22:33:30,350 - INFO - training batch 451, loss: 0.469, 14432/28000 datapoints
2025-03-06 22:33:30,536 - INFO - training batch 501, loss: 0.278, 16032/28000 datapoints
2025-03-06 22:33:30,702 - INFO - training batch 551, loss: 0.482, 17632/28000 datapoints
2025-03-06 22:33:30,854 - INFO - training batch 601, loss: 0.627, 19232/28000 datapoints
2025-03-06 22:33:31,010 - INFO - training batch 651, loss: 0.156, 20832/28000 datapoints
2025-03-06 22:33:31,161 - INFO - training batch 701, loss: 0.380, 22432/28000 datapoints
2025-03-06 22:33:31,311 - INFO - training batch 751, loss: 0.313, 24032/28000 datapoints
2025-03-06 22:33:31,464 - INFO - training batch 801, loss: 0.245, 25632/28000 datapoints
2025-03-06 22:33:31,618 - INFO - training batch 851, loss: 0.666, 27232/28000 datapoints
2025-03-06 22:33:31,710 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 22:33:31,769 - INFO - validation batch 51, loss: 1.295, 1632/6976 datapoints
2025-03-06 22:33:31,818 - INFO - validation batch 101, loss: 0.387, 3232/6976 datapoints
2025-03-06 22:33:31,865 - INFO - validation batch 151, loss: 0.616, 4832/6976 datapoints
2025-03-06 22:33:31,912 - INFO - validation batch 201, loss: 0.560, 6432/6976 datapoints
2025-03-06 22:33:31,929 - INFO - Epoch 147/800 done.
2025-03-06 22:33:31,929 - INFO - Final validation performance:
Loss: 0.599, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:33:31,929 - INFO - Beginning epoch 148/800
2025-03-06 22:33:31,936 - INFO - training batch 1, loss: 0.431, 32/28000 datapoints
2025-03-06 22:33:32,091 - INFO - training batch 51, loss: 0.227, 1632/28000 datapoints
2025-03-06 22:33:32,243 - INFO - training batch 101, loss: 0.244, 3232/28000 datapoints
2025-03-06 22:33:32,399 - INFO - training batch 151, loss: 0.748, 4832/28000 datapoints
2025-03-06 22:33:32,554 - INFO - training batch 201, loss: 0.250, 6432/28000 datapoints
2025-03-06 22:33:32,705 - INFO - training batch 251, loss: 0.481, 8032/28000 datapoints
2025-03-06 22:33:32,856 - INFO - training batch 301, loss: 0.778, 9632/28000 datapoints
2025-03-06 22:33:33,011 - INFO - training batch 351, loss: 0.353, 11232/28000 datapoints
2025-03-06 22:33:33,162 - INFO - training batch 401, loss: 0.790, 12832/28000 datapoints
2025-03-06 22:33:33,314 - INFO - training batch 451, loss: 0.466, 14432/28000 datapoints
2025-03-06 22:33:33,466 - INFO - training batch 501, loss: 0.275, 16032/28000 datapoints
2025-03-06 22:33:33,621 - INFO - training batch 551, loss: 0.479, 17632/28000 datapoints
2025-03-06 22:33:33,775 - INFO - training batch 601, loss: 0.619, 19232/28000 datapoints
2025-03-06 22:33:33,926 - INFO - training batch 651, loss: 0.155, 20832/28000 datapoints
2025-03-06 22:33:34,081 - INFO - training batch 701, loss: 0.377, 22432/28000 datapoints
2025-03-06 22:33:34,230 - INFO - training batch 751, loss: 0.311, 24032/28000 datapoints
2025-03-06 22:33:34,384 - INFO - training batch 801, loss: 0.242, 25632/28000 datapoints
2025-03-06 22:33:34,538 - INFO - training batch 851, loss: 0.660, 27232/28000 datapoints
2025-03-06 22:33:34,613 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 22:33:34,660 - INFO - validation batch 51, loss: 1.293, 1632/6976 datapoints
2025-03-06 22:33:34,707 - INFO - validation batch 101, loss: 0.387, 3232/6976 datapoints
2025-03-06 22:33:34,755 - INFO - validation batch 151, loss: 0.611, 4832/6976 datapoints
2025-03-06 22:33:34,803 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 22:33:34,820 - INFO - Epoch 148/800 done.
2025-03-06 22:33:34,820 - INFO - Final validation performance:
Loss: 0.597, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:33:34,820 - INFO - Beginning epoch 149/800
2025-03-06 22:33:34,825 - INFO - training batch 1, loss: 0.429, 32/28000 datapoints
2025-03-06 22:33:34,979 - INFO - training batch 51, loss: 0.224, 1632/28000 datapoints
2025-03-06 22:33:35,150 - INFO - training batch 101, loss: 0.242, 3232/28000 datapoints
2025-03-06 22:33:35,304 - INFO - training batch 151, loss: 0.745, 4832/28000 datapoints
2025-03-06 22:33:35,455 - INFO - training batch 201, loss: 0.246, 6432/28000 datapoints
2025-03-06 22:33:35,613 - INFO - training batch 251, loss: 0.481, 8032/28000 datapoints
2025-03-06 22:33:35,766 - INFO - training batch 301, loss: 0.775, 9632/28000 datapoints
2025-03-06 22:33:35,920 - INFO - training batch 351, loss: 0.350, 11232/28000 datapoints
2025-03-06 22:33:36,076 - INFO - training batch 401, loss: 0.786, 12832/28000 datapoints
2025-03-06 22:33:36,225 - INFO - training batch 451, loss: 0.463, 14432/28000 datapoints
2025-03-06 22:33:36,378 - INFO - training batch 501, loss: 0.271, 16032/28000 datapoints
2025-03-06 22:33:36,532 - INFO - training batch 551, loss: 0.477, 17632/28000 datapoints
2025-03-06 22:33:36,682 - INFO - training batch 601, loss: 0.613, 19232/28000 datapoints
2025-03-06 22:33:36,839 - INFO - training batch 651, loss: 0.154, 20832/28000 datapoints
2025-03-06 22:33:36,994 - INFO - training batch 701, loss: 0.374, 22432/28000 datapoints
2025-03-06 22:33:37,147 - INFO - training batch 751, loss: 0.309, 24032/28000 datapoints
2025-03-06 22:33:37,297 - INFO - training batch 801, loss: 0.239, 25632/28000 datapoints
2025-03-06 22:33:37,449 - INFO - training batch 851, loss: 0.656, 27232/28000 datapoints
2025-03-06 22:33:37,524 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 22:33:37,572 - INFO - validation batch 51, loss: 1.295, 1632/6976 datapoints
2025-03-06 22:33:37,620 - INFO - validation batch 101, loss: 0.386, 3232/6976 datapoints
2025-03-06 22:33:37,667 - INFO - validation batch 151, loss: 0.606, 4832/6976 datapoints
2025-03-06 22:33:37,714 - INFO - validation batch 201, loss: 0.560, 6432/6976 datapoints
2025-03-06 22:33:37,730 - INFO - Epoch 149/800 done.
2025-03-06 22:33:37,730 - INFO - Final validation performance:
Loss: 0.596, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:33:37,731 - INFO - Beginning epoch 150/800
2025-03-06 22:33:37,735 - INFO - training batch 1, loss: 0.426, 32/28000 datapoints
2025-03-06 22:33:37,886 - INFO - training batch 51, loss: 0.221, 1632/28000 datapoints
2025-03-06 22:33:38,053 - INFO - training batch 101, loss: 0.241, 3232/28000 datapoints
2025-03-06 22:33:38,205 - INFO - training batch 151, loss: 0.742, 4832/28000 datapoints
2025-03-06 22:33:38,361 - INFO - training batch 201, loss: 0.241, 6432/28000 datapoints
2025-03-06 22:33:38,513 - INFO - training batch 251, loss: 0.481, 8032/28000 datapoints
2025-03-06 22:33:38,669 - INFO - training batch 301, loss: 0.773, 9632/28000 datapoints
2025-03-06 22:33:38,829 - INFO - training batch 351, loss: 0.348, 11232/28000 datapoints
2025-03-06 22:33:38,986 - INFO - training batch 401, loss: 0.782, 12832/28000 datapoints
2025-03-06 22:33:39,144 - INFO - training batch 451, loss: 0.461, 14432/28000 datapoints
2025-03-06 22:33:39,300 - INFO - training batch 501, loss: 0.268, 16032/28000 datapoints
2025-03-06 22:33:39,463 - INFO - training batch 551, loss: 0.476, 17632/28000 datapoints
2025-03-06 22:33:39,619 - INFO - training batch 601, loss: 0.605, 19232/28000 datapoints
2025-03-06 22:33:39,794 - INFO - training batch 651, loss: 0.152, 20832/28000 datapoints
2025-03-06 22:33:39,979 - INFO - training batch 701, loss: 0.371, 22432/28000 datapoints
2025-03-06 22:33:40,139 - INFO - training batch 751, loss: 0.308, 24032/28000 datapoints
2025-03-06 22:33:40,293 - INFO - training batch 801, loss: 0.236, 25632/28000 datapoints
2025-03-06 22:33:40,457 - INFO - training batch 851, loss: 0.651, 27232/28000 datapoints
2025-03-06 22:33:40,534 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 22:33:40,588 - INFO - validation batch 51, loss: 1.294, 1632/6976 datapoints
2025-03-06 22:33:40,640 - INFO - validation batch 101, loss: 0.385, 3232/6976 datapoints
2025-03-06 22:33:40,693 - INFO - validation batch 151, loss: 0.601, 4832/6976 datapoints
2025-03-06 22:33:40,747 - INFO - validation batch 201, loss: 0.557, 6432/6976 datapoints
2025-03-06 22:33:40,763 - INFO - Epoch 150/800 done.
2025-03-06 22:33:40,764 - INFO - Final validation performance:
Loss: 0.594, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:33:40,764 - INFO - Beginning epoch 151/800
2025-03-06 22:33:40,769 - INFO - training batch 1, loss: 0.423, 32/28000 datapoints
2025-03-06 22:33:40,924 - INFO - training batch 51, loss: 0.219, 1632/28000 datapoints
2025-03-06 22:33:41,083 - INFO - training batch 101, loss: 0.240, 3232/28000 datapoints
2025-03-06 22:33:41,237 - INFO - training batch 151, loss: 0.737, 4832/28000 datapoints
2025-03-06 22:33:41,406 - INFO - training batch 201, loss: 0.236, 6432/28000 datapoints
2025-03-06 22:33:41,561 - INFO - training batch 251, loss: 0.481, 8032/28000 datapoints
2025-03-06 22:33:41,716 - INFO - training batch 301, loss: 0.771, 9632/28000 datapoints
2025-03-06 22:33:41,905 - INFO - training batch 351, loss: 0.345, 11232/28000 datapoints
2025-03-06 22:33:42,080 - INFO - training batch 401, loss: 0.778, 12832/28000 datapoints
2025-03-06 22:33:42,241 - INFO - training batch 451, loss: 0.459, 14432/28000 datapoints
2025-03-06 22:33:42,399 - INFO - training batch 501, loss: 0.264, 16032/28000 datapoints
2025-03-06 22:33:42,555 - INFO - training batch 551, loss: 0.473, 17632/28000 datapoints
2025-03-06 22:33:42,710 - INFO - training batch 601, loss: 0.599, 19232/28000 datapoints
2025-03-06 22:33:42,865 - INFO - training batch 651, loss: 0.151, 20832/28000 datapoints
2025-03-06 22:33:43,024 - INFO - training batch 701, loss: 0.368, 22432/28000 datapoints
2025-03-06 22:33:43,180 - INFO - training batch 751, loss: 0.306, 24032/28000 datapoints
2025-03-06 22:33:43,333 - INFO - training batch 801, loss: 0.235, 25632/28000 datapoints
2025-03-06 22:33:43,491 - INFO - training batch 851, loss: 0.646, 27232/28000 datapoints
2025-03-06 22:33:43,570 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 22:33:43,626 - INFO - validation batch 51, loss: 1.292, 1632/6976 datapoints
2025-03-06 22:33:43,676 - INFO - validation batch 101, loss: 0.385, 3232/6976 datapoints
2025-03-06 22:33:43,729 - INFO - validation batch 151, loss: 0.595, 4832/6976 datapoints
2025-03-06 22:33:43,784 - INFO - validation batch 201, loss: 0.557, 6432/6976 datapoints
2025-03-06 22:33:43,802 - INFO - Epoch 151/800 done.
2025-03-06 22:33:43,802 - INFO - Final validation performance:
Loss: 0.592, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:33:43,802 - INFO - Beginning epoch 152/800
2025-03-06 22:33:43,806 - INFO - training batch 1, loss: 0.421, 32/28000 datapoints
2025-03-06 22:33:43,972 - INFO - training batch 51, loss: 0.216, 1632/28000 datapoints
2025-03-06 22:33:44,130 - INFO - training batch 101, loss: 0.239, 3232/28000 datapoints
2025-03-06 22:33:44,285 - INFO - training batch 151, loss: 0.733, 4832/28000 datapoints
2025-03-06 22:33:44,450 - INFO - training batch 201, loss: 0.231, 6432/28000 datapoints
2025-03-06 22:33:44,614 - INFO - training batch 251, loss: 0.480, 8032/28000 datapoints
2025-03-06 22:33:44,788 - INFO - training batch 301, loss: 0.769, 9632/28000 datapoints
2025-03-06 22:33:44,944 - INFO - training batch 351, loss: 0.342, 11232/28000 datapoints
2025-03-06 22:33:45,098 - INFO - training batch 401, loss: 0.775, 12832/28000 datapoints
2025-03-06 22:33:45,262 - INFO - training batch 451, loss: 0.456, 14432/28000 datapoints
2025-03-06 22:33:45,423 - INFO - training batch 501, loss: 0.260, 16032/28000 datapoints
2025-03-06 22:33:45,583 - INFO - training batch 551, loss: 0.470, 17632/28000 datapoints
2025-03-06 22:33:45,746 - INFO - training batch 601, loss: 0.592, 19232/28000 datapoints
2025-03-06 22:33:45,910 - INFO - training batch 651, loss: 0.150, 20832/28000 datapoints
2025-03-06 22:33:46,071 - INFO - training batch 701, loss: 0.364, 22432/28000 datapoints
2025-03-06 22:33:46,232 - INFO - training batch 751, loss: 0.305, 24032/28000 datapoints
2025-03-06 22:33:46,398 - INFO - training batch 801, loss: 0.232, 25632/28000 datapoints
2025-03-06 22:33:46,566 - INFO - training batch 851, loss: 0.641, 27232/28000 datapoints
2025-03-06 22:33:46,649 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 22:33:46,707 - INFO - validation batch 51, loss: 1.292, 1632/6976 datapoints
2025-03-06 22:33:46,762 - INFO - validation batch 101, loss: 0.383, 3232/6976 datapoints
2025-03-06 22:33:46,816 - INFO - validation batch 151, loss: 0.589, 4832/6976 datapoints
2025-03-06 22:33:46,871 - INFO - validation batch 201, loss: 0.555, 6432/6976 datapoints
2025-03-06 22:33:46,894 - INFO - Epoch 152/800 done.
2025-03-06 22:33:46,894 - INFO - Final validation performance:
Loss: 0.589, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:33:46,894 - INFO - Beginning epoch 153/800
2025-03-06 22:33:46,899 - INFO - training batch 1, loss: 0.418, 32/28000 datapoints
2025-03-06 22:33:47,073 - INFO - training batch 51, loss: 0.214, 1632/28000 datapoints
2025-03-06 22:33:47,243 - INFO - training batch 101, loss: 0.238, 3232/28000 datapoints
2025-03-06 22:33:47,404 - INFO - training batch 151, loss: 0.730, 4832/28000 datapoints
2025-03-06 22:33:47,574 - INFO - training batch 201, loss: 0.227, 6432/28000 datapoints
2025-03-06 22:33:47,734 - INFO - training batch 251, loss: 0.480, 8032/28000 datapoints
2025-03-06 22:33:47,895 - INFO - training batch 301, loss: 0.768, 9632/28000 datapoints
2025-03-06 22:33:48,060 - INFO - training batch 351, loss: 0.340, 11232/28000 datapoints
2025-03-06 22:33:48,217 - INFO - training batch 401, loss: 0.771, 12832/28000 datapoints
2025-03-06 22:33:48,374 - INFO - training batch 451, loss: 0.454, 14432/28000 datapoints
2025-03-06 22:33:48,538 - INFO - training batch 501, loss: 0.258, 16032/28000 datapoints
2025-03-06 22:33:48,699 - INFO - training batch 551, loss: 0.468, 17632/28000 datapoints
2025-03-06 22:33:48,857 - INFO - training batch 601, loss: 0.585, 19232/28000 datapoints
2025-03-06 22:33:49,015 - INFO - training batch 651, loss: 0.148, 20832/28000 datapoints
2025-03-06 22:33:49,171 - INFO - training batch 701, loss: 0.362, 22432/28000 datapoints
2025-03-06 22:33:49,325 - INFO - training batch 751, loss: 0.302, 24032/28000 datapoints
2025-03-06 22:33:49,481 - INFO - training batch 801, loss: 0.228, 25632/28000 datapoints
2025-03-06 22:33:49,638 - INFO - training batch 851, loss: 0.637, 27232/28000 datapoints
2025-03-06 22:33:49,718 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 22:33:49,774 - INFO - validation batch 51, loss: 1.289, 1632/6976 datapoints
2025-03-06 22:33:49,828 - INFO - validation batch 101, loss: 0.382, 3232/6976 datapoints
2025-03-06 22:33:49,881 - INFO - validation batch 151, loss: 0.583, 4832/6976 datapoints
2025-03-06 22:33:49,931 - INFO - validation batch 201, loss: 0.551, 6432/6976 datapoints
2025-03-06 22:33:49,952 - INFO - Epoch 153/800 done.
2025-03-06 22:33:49,952 - INFO - Final validation performance:
Loss: 0.586, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:33:49,952 - INFO - Beginning epoch 154/800
2025-03-06 22:33:49,957 - INFO - training batch 1, loss: 0.415, 32/28000 datapoints
2025-03-06 22:33:50,109 - INFO - training batch 51, loss: 0.212, 1632/28000 datapoints
2025-03-06 22:33:50,264 - INFO - training batch 101, loss: 0.237, 3232/28000 datapoints
2025-03-06 22:33:50,424 - INFO - training batch 151, loss: 0.726, 4832/28000 datapoints
2025-03-06 22:33:50,579 - INFO - training batch 201, loss: 0.222, 6432/28000 datapoints
2025-03-06 22:33:50,731 - INFO - training batch 251, loss: 0.480, 8032/28000 datapoints
2025-03-06 22:33:50,882 - INFO - training batch 301, loss: 0.766, 9632/28000 datapoints
2025-03-06 22:33:51,041 - INFO - training batch 351, loss: 0.338, 11232/28000 datapoints
2025-03-06 22:33:51,193 - INFO - training batch 401, loss: 0.767, 12832/28000 datapoints
2025-03-06 22:33:51,346 - INFO - training batch 451, loss: 0.452, 14432/28000 datapoints
2025-03-06 22:33:51,498 - INFO - training batch 501, loss: 0.254, 16032/28000 datapoints
2025-03-06 22:33:51,651 - INFO - training batch 551, loss: 0.466, 17632/28000 datapoints
2025-03-06 22:33:51,803 - INFO - training batch 601, loss: 0.577, 19232/28000 datapoints
2025-03-06 22:33:51,986 - INFO - training batch 651, loss: 0.147, 20832/28000 datapoints
2025-03-06 22:33:52,137 - INFO - training batch 701, loss: 0.359, 22432/28000 datapoints
2025-03-06 22:33:52,291 - INFO - training batch 751, loss: 0.301, 24032/28000 datapoints
2025-03-06 22:33:52,444 - INFO - training batch 801, loss: 0.225, 25632/28000 datapoints
2025-03-06 22:33:52,598 - INFO - training batch 851, loss: 0.632, 27232/28000 datapoints
2025-03-06 22:33:52,671 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 22:33:52,719 - INFO - validation batch 51, loss: 1.288, 1632/6976 datapoints
2025-03-06 22:33:52,766 - INFO - validation batch 101, loss: 0.382, 3232/6976 datapoints
2025-03-06 22:33:52,812 - INFO - validation batch 151, loss: 0.576, 4832/6976 datapoints
2025-03-06 22:33:52,861 - INFO - validation batch 201, loss: 0.548, 6432/6976 datapoints
2025-03-06 22:33:52,877 - INFO - Epoch 154/800 done.
2025-03-06 22:33:52,877 - INFO - Final validation performance:
Loss: 0.584, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:33:52,878 - INFO - Beginning epoch 155/800
2025-03-06 22:33:52,882 - INFO - training batch 1, loss: 0.412, 32/28000 datapoints
2025-03-06 22:33:53,037 - INFO - training batch 51, loss: 0.210, 1632/28000 datapoints
2025-03-06 22:33:53,188 - INFO - training batch 101, loss: 0.235, 3232/28000 datapoints
2025-03-06 22:33:53,343 - INFO - training batch 151, loss: 0.723, 4832/28000 datapoints
2025-03-06 22:33:53,515 - INFO - training batch 201, loss: 0.218, 6432/28000 datapoints
2025-03-06 22:33:53,689 - INFO - training batch 251, loss: 0.479, 8032/28000 datapoints
2025-03-06 22:33:53,875 - INFO - training batch 301, loss: 0.763, 9632/28000 datapoints
2025-03-06 22:33:54,039 - INFO - training batch 351, loss: 0.335, 11232/28000 datapoints
2025-03-06 22:33:54,191 - INFO - training batch 401, loss: 0.764, 12832/28000 datapoints
2025-03-06 22:33:54,350 - INFO - training batch 451, loss: 0.450, 14432/28000 datapoints
2025-03-06 22:33:54,506 - INFO - training batch 501, loss: 0.251, 16032/28000 datapoints
2025-03-06 22:33:54,659 - INFO - training batch 551, loss: 0.463, 17632/28000 datapoints
2025-03-06 22:33:54,815 - INFO - training batch 601, loss: 0.570, 19232/28000 datapoints
2025-03-06 22:33:54,978 - INFO - training batch 651, loss: 0.146, 20832/28000 datapoints
2025-03-06 22:33:55,134 - INFO - training batch 701, loss: 0.356, 22432/28000 datapoints
2025-03-06 22:33:55,300 - INFO - training batch 751, loss: 0.299, 24032/28000 datapoints
2025-03-06 22:33:55,451 - INFO - training batch 801, loss: 0.222, 25632/28000 datapoints
2025-03-06 22:33:55,610 - INFO - training batch 851, loss: 0.627, 27232/28000 datapoints
2025-03-06 22:33:55,685 - INFO - validation batch 1, loss: 0.123, 32/6976 datapoints
2025-03-06 22:33:55,738 - INFO - validation batch 51, loss: 1.287, 1632/6976 datapoints
2025-03-06 22:33:55,791 - INFO - validation batch 101, loss: 0.381, 3232/6976 datapoints
2025-03-06 22:33:55,841 - INFO - validation batch 151, loss: 0.571, 4832/6976 datapoints
2025-03-06 22:33:55,890 - INFO - validation batch 201, loss: 0.547, 6432/6976 datapoints
2025-03-06 22:33:55,906 - INFO - Epoch 155/800 done.
2025-03-06 22:33:55,906 - INFO - Final validation performance:
Loss: 0.582, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:33:55,907 - INFO - Beginning epoch 156/800
2025-03-06 22:33:55,911 - INFO - training batch 1, loss: 0.411, 32/28000 datapoints
2025-03-06 22:33:56,069 - INFO - training batch 51, loss: 0.208, 1632/28000 datapoints
2025-03-06 22:33:56,219 - INFO - training batch 101, loss: 0.233, 3232/28000 datapoints
2025-03-06 22:33:56,372 - INFO - training batch 151, loss: 0.719, 4832/28000 datapoints
2025-03-06 22:33:56,528 - INFO - training batch 201, loss: 0.213, 6432/28000 datapoints
2025-03-06 22:33:56,679 - INFO - training batch 251, loss: 0.478, 8032/28000 datapoints
2025-03-06 22:33:56,831 - INFO - training batch 301, loss: 0.760, 9632/28000 datapoints
2025-03-06 22:33:56,984 - INFO - training batch 351, loss: 0.332, 11232/28000 datapoints
2025-03-06 22:33:57,134 - INFO - training batch 401, loss: 0.760, 12832/28000 datapoints
2025-03-06 22:33:57,286 - INFO - training batch 451, loss: 0.448, 14432/28000 datapoints
2025-03-06 22:33:57,436 - INFO - training batch 501, loss: 0.248, 16032/28000 datapoints
2025-03-06 22:33:57,591 - INFO - training batch 551, loss: 0.461, 17632/28000 datapoints
2025-03-06 22:33:57,744 - INFO - training batch 601, loss: 0.562, 19232/28000 datapoints
2025-03-06 22:33:57,895 - INFO - training batch 651, loss: 0.145, 20832/28000 datapoints
2025-03-06 22:33:58,052 - INFO - training batch 701, loss: 0.354, 22432/28000 datapoints
2025-03-06 22:33:58,201 - INFO - training batch 751, loss: 0.298, 24032/28000 datapoints
2025-03-06 22:33:58,353 - INFO - training batch 801, loss: 0.220, 25632/28000 datapoints
2025-03-06 22:33:58,505 - INFO - training batch 851, loss: 0.622, 27232/28000 datapoints
2025-03-06 22:33:58,581 - INFO - validation batch 1, loss: 0.122, 32/6976 datapoints
2025-03-06 22:33:58,629 - INFO - validation batch 51, loss: 1.284, 1632/6976 datapoints
2025-03-06 22:33:58,679 - INFO - validation batch 101, loss: 0.381, 3232/6976 datapoints
2025-03-06 22:33:58,726 - INFO - validation batch 151, loss: 0.566, 4832/6976 datapoints
2025-03-06 22:33:58,774 - INFO - validation batch 201, loss: 0.548, 6432/6976 datapoints
2025-03-06 22:33:58,792 - INFO - Epoch 156/800 done.
2025-03-06 22:33:58,792 - INFO - Final validation performance:
Loss: 0.580, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:33:58,793 - INFO - Beginning epoch 157/800
2025-03-06 22:33:58,797 - INFO - training batch 1, loss: 0.409, 32/28000 datapoints
2025-03-06 22:33:58,964 - INFO - training batch 51, loss: 0.206, 1632/28000 datapoints
2025-03-06 22:33:59,118 - INFO - training batch 101, loss: 0.232, 3232/28000 datapoints
2025-03-06 22:33:59,272 - INFO - training batch 151, loss: 0.714, 4832/28000 datapoints
2025-03-06 22:33:59,434 - INFO - training batch 201, loss: 0.209, 6432/28000 datapoints
2025-03-06 22:33:59,603 - INFO - training batch 251, loss: 0.478, 8032/28000 datapoints
2025-03-06 22:33:59,756 - INFO - training batch 301, loss: 0.758, 9632/28000 datapoints
2025-03-06 22:33:59,912 - INFO - training batch 351, loss: 0.331, 11232/28000 datapoints
2025-03-06 22:34:00,080 - INFO - training batch 401, loss: 0.756, 12832/28000 datapoints
2025-03-06 22:34:00,239 - INFO - training batch 451, loss: 0.446, 14432/28000 datapoints
2025-03-06 22:34:00,403 - INFO - training batch 501, loss: 0.245, 16032/28000 datapoints
2025-03-06 22:34:00,568 - INFO - training batch 551, loss: 0.458, 17632/28000 datapoints
2025-03-06 22:34:00,724 - INFO - training batch 601, loss: 0.556, 19232/28000 datapoints
2025-03-06 22:34:00,882 - INFO - training batch 651, loss: 0.143, 20832/28000 datapoints
2025-03-06 22:34:01,043 - INFO - training batch 701, loss: 0.352, 22432/28000 datapoints
2025-03-06 22:34:01,197 - INFO - training batch 751, loss: 0.296, 24032/28000 datapoints
2025-03-06 22:34:01,353 - INFO - training batch 801, loss: 0.217, 25632/28000 datapoints
2025-03-06 22:34:01,506 - INFO - training batch 851, loss: 0.617, 27232/28000 datapoints
2025-03-06 22:34:01,585 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 22:34:01,640 - INFO - validation batch 51, loss: 1.283, 1632/6976 datapoints
2025-03-06 22:34:01,691 - INFO - validation batch 101, loss: 0.379, 3232/6976 datapoints
2025-03-06 22:34:01,743 - INFO - validation batch 151, loss: 0.561, 4832/6976 datapoints
2025-03-06 22:34:01,796 - INFO - validation batch 201, loss: 0.548, 6432/6976 datapoints
2025-03-06 22:34:01,812 - INFO - Epoch 157/800 done.
2025-03-06 22:34:01,812 - INFO - Final validation performance:
Loss: 0.578, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:34:01,813 - INFO - Beginning epoch 158/800
2025-03-06 22:34:01,817 - INFO - training batch 1, loss: 0.408, 32/28000 datapoints
2025-03-06 22:34:01,992 - INFO - training batch 51, loss: 0.204, 1632/28000 datapoints
2025-03-06 22:34:02,167 - INFO - training batch 101, loss: 0.230, 3232/28000 datapoints
2025-03-06 22:34:02,323 - INFO - training batch 151, loss: 0.709, 4832/28000 datapoints
2025-03-06 22:34:02,480 - INFO - training batch 201, loss: 0.205, 6432/28000 datapoints
2025-03-06 22:34:02,637 - INFO - training batch 251, loss: 0.478, 8032/28000 datapoints
2025-03-06 22:34:02,797 - INFO - training batch 301, loss: 0.756, 9632/28000 datapoints
2025-03-06 22:34:02,955 - INFO - training batch 351, loss: 0.328, 11232/28000 datapoints
2025-03-06 22:34:03,111 - INFO - training batch 401, loss: 0.752, 12832/28000 datapoints
2025-03-06 22:34:03,265 - INFO - training batch 451, loss: 0.444, 14432/28000 datapoints
2025-03-06 22:34:03,418 - INFO - training batch 501, loss: 0.242, 16032/28000 datapoints
2025-03-06 22:34:03,577 - INFO - training batch 551, loss: 0.456, 17632/28000 datapoints
2025-03-06 22:34:03,731 - INFO - training batch 601, loss: 0.551, 19232/28000 datapoints
2025-03-06 22:34:03,889 - INFO - training batch 651, loss: 0.142, 20832/28000 datapoints
2025-03-06 22:34:04,046 - INFO - training batch 701, loss: 0.350, 22432/28000 datapoints
2025-03-06 22:34:04,200 - INFO - training batch 751, loss: 0.295, 24032/28000 datapoints
2025-03-06 22:34:04,355 - INFO - training batch 801, loss: 0.215, 25632/28000 datapoints
2025-03-06 22:34:04,513 - INFO - training batch 851, loss: 0.613, 27232/28000 datapoints
2025-03-06 22:34:04,591 - INFO - validation batch 1, loss: 0.119, 32/6976 datapoints
2025-03-06 22:34:04,642 - INFO - validation batch 51, loss: 1.282, 1632/6976 datapoints
2025-03-06 22:34:04,695 - INFO - validation batch 101, loss: 0.379, 3232/6976 datapoints
2025-03-06 22:34:04,747 - INFO - validation batch 151, loss: 0.556, 4832/6976 datapoints
2025-03-06 22:34:04,800 - INFO - validation batch 201, loss: 0.548, 6432/6976 datapoints
2025-03-06 22:34:04,816 - INFO - Epoch 158/800 done.
2025-03-06 22:34:04,816 - INFO - Final validation performance:
Loss: 0.577, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:34:04,817 - INFO - Beginning epoch 159/800
2025-03-06 22:34:04,821 - INFO - training batch 1, loss: 0.406, 32/28000 datapoints
2025-03-06 22:34:04,983 - INFO - training batch 51, loss: 0.201, 1632/28000 datapoints
2025-03-06 22:34:05,137 - INFO - training batch 101, loss: 0.229, 3232/28000 datapoints
2025-03-06 22:34:05,297 - INFO - training batch 151, loss: 0.705, 4832/28000 datapoints
2025-03-06 22:34:05,453 - INFO - training batch 201, loss: 0.202, 6432/28000 datapoints
2025-03-06 22:34:05,620 - INFO - training batch 251, loss: 0.478, 8032/28000 datapoints
2025-03-06 22:34:05,777 - INFO - training batch 301, loss: 0.754, 9632/28000 datapoints
2025-03-06 22:34:05,934 - INFO - training batch 351, loss: 0.325, 11232/28000 datapoints
2025-03-06 22:34:06,100 - INFO - training batch 401, loss: 0.748, 12832/28000 datapoints
2025-03-06 22:34:06,258 - INFO - training batch 451, loss: 0.442, 14432/28000 datapoints
2025-03-06 22:34:06,413 - INFO - training batch 501, loss: 0.239, 16032/28000 datapoints
2025-03-06 22:34:06,578 - INFO - training batch 551, loss: 0.454, 17632/28000 datapoints
2025-03-06 22:34:06,732 - INFO - training batch 601, loss: 0.546, 19232/28000 datapoints
2025-03-06 22:34:06,889 - INFO - training batch 651, loss: 0.141, 20832/28000 datapoints
2025-03-06 22:34:07,048 - INFO - training batch 701, loss: 0.347, 22432/28000 datapoints
2025-03-06 22:34:07,200 - INFO - training batch 751, loss: 0.293, 24032/28000 datapoints
2025-03-06 22:34:07,352 - INFO - training batch 801, loss: 0.212, 25632/28000 datapoints
2025-03-06 22:34:07,508 - INFO - training batch 851, loss: 0.609, 27232/28000 datapoints
2025-03-06 22:34:07,589 - INFO - validation batch 1, loss: 0.118, 32/6976 datapoints
2025-03-06 22:34:07,643 - INFO - validation batch 51, loss: 1.281, 1632/6976 datapoints
2025-03-06 22:34:07,698 - INFO - validation batch 101, loss: 0.378, 3232/6976 datapoints
2025-03-06 22:34:07,752 - INFO - validation batch 151, loss: 0.552, 4832/6976 datapoints
2025-03-06 22:34:07,806 - INFO - validation batch 201, loss: 0.547, 6432/6976 datapoints
2025-03-06 22:34:07,824 - INFO - Epoch 159/800 done.
2025-03-06 22:34:07,824 - INFO - Final validation performance:
Loss: 0.575, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:34:07,825 - INFO - Beginning epoch 160/800
2025-03-06 22:34:07,830 - INFO - training batch 1, loss: 0.404, 32/28000 datapoints
2025-03-06 22:34:07,989 - INFO - training batch 51, loss: 0.200, 1632/28000 datapoints
2025-03-06 22:34:08,140 - INFO - training batch 101, loss: 0.228, 3232/28000 datapoints
2025-03-06 22:34:08,293 - INFO - training batch 151, loss: 0.701, 4832/28000 datapoints
2025-03-06 22:34:08,446 - INFO - training batch 201, loss: 0.199, 6432/28000 datapoints
2025-03-06 22:34:08,601 - INFO - training batch 251, loss: 0.477, 8032/28000 datapoints
2025-03-06 22:34:08,752 - INFO - training batch 301, loss: 0.752, 9632/28000 datapoints
2025-03-06 22:34:08,902 - INFO - training batch 351, loss: 0.323, 11232/28000 datapoints
2025-03-06 22:34:09,082 - INFO - training batch 401, loss: 0.745, 12832/28000 datapoints
2025-03-06 22:34:09,237 - INFO - training batch 451, loss: 0.439, 14432/28000 datapoints
2025-03-06 22:34:09,391 - INFO - training batch 501, loss: 0.237, 16032/28000 datapoints
2025-03-06 22:34:09,547 - INFO - training batch 551, loss: 0.451, 17632/28000 datapoints
2025-03-06 22:34:09,700 - INFO - training batch 601, loss: 0.540, 19232/28000 datapoints
2025-03-06 22:34:09,850 - INFO - training batch 651, loss: 0.140, 20832/28000 datapoints
2025-03-06 22:34:10,005 - INFO - training batch 701, loss: 0.345, 22432/28000 datapoints
2025-03-06 22:34:10,154 - INFO - training batch 751, loss: 0.292, 24032/28000 datapoints
2025-03-06 22:34:10,306 - INFO - training batch 801, loss: 0.210, 25632/28000 datapoints
2025-03-06 22:34:10,458 - INFO - training batch 851, loss: 0.604, 27232/28000 datapoints
2025-03-06 22:34:10,536 - INFO - validation batch 1, loss: 0.117, 32/6976 datapoints
2025-03-06 22:34:10,586 - INFO - validation batch 51, loss: 1.281, 1632/6976 datapoints
2025-03-06 22:34:10,634 - INFO - validation batch 101, loss: 0.378, 3232/6976 datapoints
2025-03-06 22:34:10,682 - INFO - validation batch 151, loss: 0.546, 4832/6976 datapoints
2025-03-06 22:34:10,729 - INFO - validation batch 201, loss: 0.548, 6432/6976 datapoints
2025-03-06 22:34:10,746 - INFO - Epoch 160/800 done.
2025-03-06 22:34:10,746 - INFO - Final validation performance:
Loss: 0.574, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:34:10,746 - INFO - Beginning epoch 161/800
2025-03-06 22:34:10,751 - INFO - training batch 1, loss: 0.402, 32/28000 datapoints
2025-03-06 22:34:10,902 - INFO - training batch 51, loss: 0.198, 1632/28000 datapoints
2025-03-06 22:34:11,060 - INFO - training batch 101, loss: 0.227, 3232/28000 datapoints
2025-03-06 22:34:11,210 - INFO - training batch 151, loss: 0.697, 4832/28000 datapoints
2025-03-06 22:34:11,361 - INFO - training batch 201, loss: 0.195, 6432/28000 datapoints
2025-03-06 22:34:11,511 - INFO - training batch 251, loss: 0.477, 8032/28000 datapoints
2025-03-06 22:34:11,679 - INFO - training batch 301, loss: 0.750, 9632/28000 datapoints
2025-03-06 22:34:11,830 - INFO - training batch 351, loss: 0.321, 11232/28000 datapoints
2025-03-06 22:34:11,987 - INFO - training batch 401, loss: 0.741, 12832/28000 datapoints
2025-03-06 22:34:12,168 - INFO - training batch 451, loss: 0.437, 14432/28000 datapoints
2025-03-06 22:34:12,325 - INFO - training batch 501, loss: 0.234, 16032/28000 datapoints
2025-03-06 22:34:12,480 - INFO - training batch 551, loss: 0.450, 17632/28000 datapoints
2025-03-06 22:34:12,637 - INFO - training batch 601, loss: 0.535, 19232/28000 datapoints
2025-03-06 22:34:12,788 - INFO - training batch 651, loss: 0.139, 20832/28000 datapoints
2025-03-06 22:34:12,939 - INFO - training batch 701, loss: 0.343, 22432/28000 datapoints
2025-03-06 22:34:13,090 - INFO - training batch 751, loss: 0.289, 24032/28000 datapoints
2025-03-06 22:34:13,239 - INFO - training batch 801, loss: 0.207, 25632/28000 datapoints
2025-03-06 22:34:13,390 - INFO - training batch 851, loss: 0.599, 27232/28000 datapoints
2025-03-06 22:34:13,464 - INFO - validation batch 1, loss: 0.116, 32/6976 datapoints
2025-03-06 22:34:13,513 - INFO - validation batch 51, loss: 1.280, 1632/6976 datapoints
2025-03-06 22:34:13,565 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-06 22:34:13,615 - INFO - validation batch 151, loss: 0.541, 4832/6976 datapoints
2025-03-06 22:34:13,665 - INFO - validation batch 201, loss: 0.548, 6432/6976 datapoints
2025-03-06 22:34:13,681 - INFO - Epoch 161/800 done.
2025-03-06 22:34:13,682 - INFO - Final validation performance:
Loss: 0.572, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:34:13,682 - INFO - Beginning epoch 162/800
2025-03-06 22:34:13,686 - INFO - training batch 1, loss: 0.401, 32/28000 datapoints
2025-03-06 22:34:13,843 - INFO - training batch 51, loss: 0.197, 1632/28000 datapoints
2025-03-06 22:34:13,998 - INFO - training batch 101, loss: 0.226, 3232/28000 datapoints
2025-03-06 22:34:14,152 - INFO - training batch 151, loss: 0.694, 4832/28000 datapoints
2025-03-06 22:34:14,303 - INFO - training batch 201, loss: 0.192, 6432/28000 datapoints
2025-03-06 22:34:14,453 - INFO - training batch 251, loss: 0.477, 8032/28000 datapoints
2025-03-06 22:34:14,608 - INFO - training batch 301, loss: 0.747, 9632/28000 datapoints
2025-03-06 22:34:14,759 - INFO - training batch 351, loss: 0.318, 11232/28000 datapoints
2025-03-06 22:34:14,911 - INFO - training batch 401, loss: 0.737, 12832/28000 datapoints
2025-03-06 22:34:15,065 - INFO - training batch 451, loss: 0.435, 14432/28000 datapoints
2025-03-06 22:34:15,220 - INFO - training batch 501, loss: 0.232, 16032/28000 datapoints
2025-03-06 22:34:15,373 - INFO - training batch 551, loss: 0.448, 17632/28000 datapoints
2025-03-06 22:34:15,524 - INFO - training batch 601, loss: 0.531, 19232/28000 datapoints
2025-03-06 22:34:15,676 - INFO - training batch 651, loss: 0.137, 20832/28000 datapoints
2025-03-06 22:34:15,828 - INFO - training batch 701, loss: 0.341, 22432/28000 datapoints
2025-03-06 22:34:15,982 - INFO - training batch 751, loss: 0.287, 24032/28000 datapoints
2025-03-06 22:34:16,134 - INFO - training batch 801, loss: 0.205, 25632/28000 datapoints
2025-03-06 22:34:16,285 - INFO - training batch 851, loss: 0.595, 27232/28000 datapoints
2025-03-06 22:34:16,358 - INFO - validation batch 1, loss: 0.115, 32/6976 datapoints
2025-03-06 22:34:16,405 - INFO - validation batch 51, loss: 1.279, 1632/6976 datapoints
2025-03-06 22:34:16,453 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-06 22:34:16,500 - INFO - validation batch 151, loss: 0.538, 4832/6976 datapoints
2025-03-06 22:34:16,551 - INFO - validation batch 201, loss: 0.549, 6432/6976 datapoints
2025-03-06 22:34:16,568 - INFO - Epoch 162/800 done.
2025-03-06 22:34:16,568 - INFO - Final validation performance:
Loss: 0.571, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:34:16,569 - INFO - Beginning epoch 163/800
2025-03-06 22:34:16,573 - INFO - training batch 1, loss: 0.400, 32/28000 datapoints
2025-03-06 22:34:16,730 - INFO - training batch 51, loss: 0.195, 1632/28000 datapoints
2025-03-06 22:34:16,881 - INFO - training batch 101, loss: 0.225, 3232/28000 datapoints
2025-03-06 22:34:17,036 - INFO - training batch 151, loss: 0.689, 4832/28000 datapoints
2025-03-06 22:34:17,189 - INFO - training batch 201, loss: 0.188, 6432/28000 datapoints
2025-03-06 22:34:17,341 - INFO - training batch 251, loss: 0.477, 8032/28000 datapoints
2025-03-06 22:34:17,490 - INFO - training batch 301, loss: 0.746, 9632/28000 datapoints
2025-03-06 22:34:17,650 - INFO - training batch 351, loss: 0.316, 11232/28000 datapoints
2025-03-06 22:34:17,812 - INFO - training batch 401, loss: 0.733, 12832/28000 datapoints
2025-03-06 22:34:17,965 - INFO - training batch 451, loss: 0.433, 14432/28000 datapoints
2025-03-06 22:34:18,121 - INFO - training batch 501, loss: 0.230, 16032/28000 datapoints
2025-03-06 22:34:18,277 - INFO - training batch 551, loss: 0.446, 17632/28000 datapoints
2025-03-06 22:34:18,431 - INFO - training batch 601, loss: 0.526, 19232/28000 datapoints
2025-03-06 22:34:18,591 - INFO - training batch 651, loss: 0.136, 20832/28000 datapoints
2025-03-06 22:34:18,744 - INFO - training batch 701, loss: 0.339, 22432/28000 datapoints
2025-03-06 22:34:18,900 - INFO - training batch 751, loss: 0.286, 24032/28000 datapoints
2025-03-06 22:34:19,058 - INFO - training batch 801, loss: 0.202, 25632/28000 datapoints
2025-03-06 22:34:19,211 - INFO - training batch 851, loss: 0.591, 27232/28000 datapoints
2025-03-06 22:34:19,288 - INFO - validation batch 1, loss: 0.114, 32/6976 datapoints
2025-03-06 22:34:19,337 - INFO - validation batch 51, loss: 1.278, 1632/6976 datapoints
2025-03-06 22:34:19,390 - INFO - validation batch 101, loss: 0.376, 3232/6976 datapoints
2025-03-06 22:34:19,440 - INFO - validation batch 151, loss: 0.533, 4832/6976 datapoints
2025-03-06 22:34:19,494 - INFO - validation batch 201, loss: 0.550, 6432/6976 datapoints
2025-03-06 22:34:19,510 - INFO - Epoch 163/800 done.
2025-03-06 22:34:19,510 - INFO - Final validation performance:
Loss: 0.570, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:34:19,511 - INFO - Beginning epoch 164/800
2025-03-06 22:34:19,515 - INFO - training batch 1, loss: 0.398, 32/28000 datapoints
2025-03-06 22:34:19,682 - INFO - training batch 51, loss: 0.193, 1632/28000 datapoints
2025-03-06 22:34:19,837 - INFO - training batch 101, loss: 0.223, 3232/28000 datapoints
2025-03-06 22:34:19,997 - INFO - training batch 151, loss: 0.686, 4832/28000 datapoints
2025-03-06 22:34:20,157 - INFO - training batch 201, loss: 0.186, 6432/28000 datapoints
2025-03-06 22:34:20,311 - INFO - training batch 251, loss: 0.476, 8032/28000 datapoints
2025-03-06 22:34:20,464 - INFO - training batch 301, loss: 0.743, 9632/28000 datapoints
2025-03-06 22:34:20,626 - INFO - training batch 351, loss: 0.315, 11232/28000 datapoints
2025-03-06 22:34:20,780 - INFO - training batch 401, loss: 0.728, 12832/28000 datapoints
2025-03-06 22:34:20,932 - INFO - training batch 451, loss: 0.430, 14432/28000 datapoints
2025-03-06 22:34:21,090 - INFO - training batch 501, loss: 0.229, 16032/28000 datapoints
2025-03-06 22:34:21,244 - INFO - training batch 551, loss: 0.444, 17632/28000 datapoints
2025-03-06 22:34:21,399 - INFO - training batch 601, loss: 0.520, 19232/28000 datapoints
2025-03-06 22:34:21,555 - INFO - training batch 651, loss: 0.134, 20832/28000 datapoints
2025-03-06 22:34:21,714 - INFO - training batch 701, loss: 0.337, 22432/28000 datapoints
2025-03-06 22:34:21,867 - INFO - training batch 751, loss: 0.285, 24032/28000 datapoints
2025-03-06 22:34:22,024 - INFO - training batch 801, loss: 0.200, 25632/28000 datapoints
2025-03-06 22:34:22,183 - INFO - training batch 851, loss: 0.586, 27232/28000 datapoints
2025-03-06 22:34:22,280 - INFO - validation batch 1, loss: 0.113, 32/6976 datapoints
2025-03-06 22:34:22,334 - INFO - validation batch 51, loss: 1.277, 1632/6976 datapoints
2025-03-06 22:34:22,386 - INFO - validation batch 101, loss: 0.376, 3232/6976 datapoints
2025-03-06 22:34:22,434 - INFO - validation batch 151, loss: 0.528, 4832/6976 datapoints
2025-03-06 22:34:22,482 - INFO - validation batch 201, loss: 0.551, 6432/6976 datapoints
2025-03-06 22:34:22,498 - INFO - Epoch 164/800 done.
2025-03-06 22:34:22,499 - INFO - Final validation performance:
Loss: 0.569, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:34:22,499 - INFO - Beginning epoch 165/800
2025-03-06 22:34:22,503 - INFO - training batch 1, loss: 0.398, 32/28000 datapoints
2025-03-06 22:34:22,662 - INFO - training batch 51, loss: 0.190, 1632/28000 datapoints
2025-03-06 22:34:22,815 - INFO - training batch 101, loss: 0.222, 3232/28000 datapoints
2025-03-06 22:34:22,970 - INFO - training batch 151, loss: 0.682, 4832/28000 datapoints
2025-03-06 22:34:23,123 - INFO - training batch 201, loss: 0.182, 6432/28000 datapoints
2025-03-06 22:34:23,273 - INFO - training batch 251, loss: 0.476, 8032/28000 datapoints
2025-03-06 22:34:23,423 - INFO - training batch 301, loss: 0.741, 9632/28000 datapoints
2025-03-06 22:34:23,574 - INFO - training batch 351, loss: 0.313, 11232/28000 datapoints
2025-03-06 22:34:23,735 - INFO - training batch 401, loss: 0.725, 12832/28000 datapoints
2025-03-06 22:34:23,892 - INFO - training batch 451, loss: 0.428, 14432/28000 datapoints
2025-03-06 22:34:24,047 - INFO - training batch 501, loss: 0.226, 16032/28000 datapoints
2025-03-06 22:34:24,206 - INFO - training batch 551, loss: 0.442, 17632/28000 datapoints
2025-03-06 22:34:24,360 - INFO - training batch 601, loss: 0.514, 19232/28000 datapoints
2025-03-06 22:34:24,515 - INFO - training batch 651, loss: 0.133, 20832/28000 datapoints
2025-03-06 22:34:24,669 - INFO - training batch 701, loss: 0.334, 22432/28000 datapoints
2025-03-06 22:34:24,825 - INFO - training batch 751, loss: 0.284, 24032/28000 datapoints
2025-03-06 22:34:24,980 - INFO - training batch 801, loss: 0.198, 25632/28000 datapoints
2025-03-06 22:34:25,132 - INFO - training batch 851, loss: 0.581, 27232/28000 datapoints
2025-03-06 22:34:25,212 - INFO - validation batch 1, loss: 0.112, 32/6976 datapoints
2025-03-06 22:34:25,259 - INFO - validation batch 51, loss: 1.277, 1632/6976 datapoints
2025-03-06 22:34:25,307 - INFO - validation batch 101, loss: 0.376, 3232/6976 datapoints
2025-03-06 22:34:25,355 - INFO - validation batch 151, loss: 0.524, 4832/6976 datapoints
2025-03-06 22:34:25,402 - INFO - validation batch 201, loss: 0.552, 6432/6976 datapoints
2025-03-06 22:34:25,418 - INFO - Epoch 165/800 done.
2025-03-06 22:34:25,419 - INFO - Final validation performance:
Loss: 0.568, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:34:25,419 - INFO - Beginning epoch 166/800
2025-03-06 22:34:25,423 - INFO - training batch 1, loss: 0.397, 32/28000 datapoints
2025-03-06 22:34:25,574 - INFO - training batch 51, loss: 0.189, 1632/28000 datapoints
2025-03-06 22:34:25,728 - INFO - training batch 101, loss: 0.220, 3232/28000 datapoints
2025-03-06 22:34:25,881 - INFO - training batch 151, loss: 0.678, 4832/28000 datapoints
2025-03-06 22:34:26,034 - INFO - training batch 201, loss: 0.179, 6432/28000 datapoints
2025-03-06 22:34:26,188 - INFO - training batch 251, loss: 0.476, 8032/28000 datapoints
2025-03-06 22:34:26,337 - INFO - training batch 301, loss: 0.739, 9632/28000 datapoints
2025-03-06 22:34:26,487 - INFO - training batch 351, loss: 0.311, 11232/28000 datapoints
2025-03-06 22:34:26,642 - INFO - training batch 401, loss: 0.721, 12832/28000 datapoints
2025-03-06 22:34:26,795 - INFO - training batch 451, loss: 0.426, 14432/28000 datapoints
2025-03-06 22:34:26,948 - INFO - training batch 501, loss: 0.223, 16032/28000 datapoints
2025-03-06 22:34:27,099 - INFO - training batch 551, loss: 0.440, 17632/28000 datapoints
2025-03-06 22:34:27,251 - INFO - training batch 601, loss: 0.509, 19232/28000 datapoints
2025-03-06 22:34:27,402 - INFO - training batch 651, loss: 0.132, 20832/28000 datapoints
2025-03-06 22:34:27,553 - INFO - training batch 701, loss: 0.332, 22432/28000 datapoints
2025-03-06 22:34:27,704 - INFO - training batch 751, loss: 0.280, 24032/28000 datapoints
2025-03-06 22:34:27,856 - INFO - training batch 801, loss: 0.196, 25632/28000 datapoints
2025-03-06 22:34:28,008 - INFO - training batch 851, loss: 0.577, 27232/28000 datapoints
2025-03-06 22:34:28,082 - INFO - validation batch 1, loss: 0.111, 32/6976 datapoints
2025-03-06 22:34:28,129 - INFO - validation batch 51, loss: 1.277, 1632/6976 datapoints
2025-03-06 22:34:28,178 - INFO - validation batch 101, loss: 0.376, 3232/6976 datapoints
2025-03-06 22:34:28,225 - INFO - validation batch 151, loss: 0.519, 4832/6976 datapoints
2025-03-06 22:34:28,274 - INFO - validation batch 201, loss: 0.552, 6432/6976 datapoints
2025-03-06 22:34:28,291 - INFO - Epoch 166/800 done.
2025-03-06 22:34:28,291 - INFO - Final validation performance:
Loss: 0.567, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:34:28,292 - INFO - Beginning epoch 167/800
2025-03-06 22:34:28,296 - INFO - training batch 1, loss: 0.396, 32/28000 datapoints
2025-03-06 22:34:28,448 - INFO - training batch 51, loss: 0.188, 1632/28000 datapoints
2025-03-06 22:34:28,603 - INFO - training batch 101, loss: 0.219, 3232/28000 datapoints
2025-03-06 22:34:28,759 - INFO - training batch 151, loss: 0.673, 4832/28000 datapoints
2025-03-06 22:34:28,910 - INFO - training batch 201, loss: 0.176, 6432/28000 datapoints
2025-03-06 22:34:29,065 - INFO - training batch 251, loss: 0.476, 8032/28000 datapoints
2025-03-06 22:34:29,217 - INFO - training batch 301, loss: 0.738, 9632/28000 datapoints
2025-03-06 22:34:29,367 - INFO - training batch 351, loss: 0.309, 11232/28000 datapoints
2025-03-06 22:34:29,517 - INFO - training batch 401, loss: 0.718, 12832/28000 datapoints
2025-03-06 22:34:29,666 - INFO - training batch 451, loss: 0.424, 14432/28000 datapoints
2025-03-06 22:34:29,839 - INFO - training batch 501, loss: 0.221, 16032/28000 datapoints
2025-03-06 22:34:29,994 - INFO - training batch 551, loss: 0.439, 17632/28000 datapoints
2025-03-06 22:34:30,146 - INFO - training batch 601, loss: 0.504, 19232/28000 datapoints
2025-03-06 22:34:30,309 - INFO - training batch 651, loss: 0.130, 20832/28000 datapoints
2025-03-06 22:34:30,467 - INFO - training batch 701, loss: 0.330, 22432/28000 datapoints
2025-03-06 22:34:30,631 - INFO - training batch 751, loss: 0.279, 24032/28000 datapoints
2025-03-06 22:34:30,792 - INFO - training batch 801, loss: 0.194, 25632/28000 datapoints
2025-03-06 22:34:30,978 - INFO - training batch 851, loss: 0.572, 27232/28000 datapoints
2025-03-06 22:34:31,052 - INFO - validation batch 1, loss: 0.110, 32/6976 datapoints
2025-03-06 22:34:31,100 - INFO - validation batch 51, loss: 1.275, 1632/6976 datapoints
2025-03-06 22:34:31,148 - INFO - validation batch 101, loss: 0.374, 3232/6976 datapoints
2025-03-06 22:34:31,195 - INFO - validation batch 151, loss: 0.515, 4832/6976 datapoints
2025-03-06 22:34:31,244 - INFO - validation batch 201, loss: 0.553, 6432/6976 datapoints
2025-03-06 22:34:31,261 - INFO - Epoch 167/800 done.
2025-03-06 22:34:31,261 - INFO - Final validation performance:
Loss: 0.565, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 22:34:31,261 - INFO - Beginning epoch 168/800
2025-03-06 22:34:31,266 - INFO - training batch 1, loss: 0.395, 32/28000 datapoints
2025-03-06 22:34:31,418 - INFO - training batch 51, loss: 0.186, 1632/28000 datapoints
2025-03-06 22:34:31,569 - INFO - training batch 101, loss: 0.218, 3232/28000 datapoints
2025-03-06 22:34:31,723 - INFO - training batch 151, loss: 0.669, 4832/28000 datapoints
2025-03-06 22:34:31,876 - INFO - training batch 201, loss: 0.174, 6432/28000 datapoints
2025-03-06 22:34:32,029 - INFO - training batch 251, loss: 0.475, 8032/28000 datapoints
2025-03-06 22:34:32,183 - INFO - training batch 301, loss: 0.735, 9632/28000 datapoints
2025-03-06 22:34:32,362 - INFO - training batch 351, loss: 0.307, 11232/28000 datapoints
2025-03-06 22:34:32,515 - INFO - training batch 401, loss: 0.714, 12832/28000 datapoints
2025-03-06 22:34:32,669 - INFO - training batch 451, loss: 0.423, 14432/28000 datapoints
2025-03-06 22:34:32,822 - INFO - training batch 501, loss: 0.220, 16032/28000 datapoints
2025-03-06 22:34:32,976 - INFO - training batch 551, loss: 0.436, 17632/28000 datapoints
2025-03-06 22:34:33,127 - INFO - training batch 601, loss: 0.499, 19232/28000 datapoints
2025-03-06 22:34:33,279 - INFO - training batch 651, loss: 0.128, 20832/28000 datapoints
2025-03-06 22:34:33,429 - INFO - training batch 701, loss: 0.328, 22432/28000 datapoints
2025-03-06 22:34:33,585 - INFO - training batch 751, loss: 0.278, 24032/28000 datapoints
2025-03-06 22:34:33,742 - INFO - training batch 801, loss: 0.191, 25632/28000 datapoints
2025-03-06 22:34:33,898 - INFO - training batch 851, loss: 0.568, 27232/28000 datapoints
2025-03-06 22:34:33,975 - INFO - validation batch 1, loss: 0.109, 32/6976 datapoints
2025-03-06 22:34:34,022 - INFO - validation batch 51, loss: 1.275, 1632/6976 datapoints
2025-03-06 22:34:34,069 - INFO - validation batch 101, loss: 0.374, 3232/6976 datapoints
2025-03-06 22:34:34,116 - INFO - validation batch 151, loss: 0.511, 4832/6976 datapoints
2025-03-06 22:34:34,164 - INFO - validation batch 201, loss: 0.553, 6432/6976 datapoints
2025-03-06 22:34:34,180 - INFO - Epoch 168/800 done.
2025-03-06 22:34:34,180 - INFO - Final validation performance:
Loss: 0.564, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:34:34,180 - INFO - Beginning epoch 169/800
2025-03-06 22:34:34,184 - INFO - training batch 1, loss: 0.394, 32/28000 datapoints
2025-03-06 22:34:34,341 - INFO - training batch 51, loss: 0.185, 1632/28000 datapoints
2025-03-06 22:34:34,492 - INFO - training batch 101, loss: 0.217, 3232/28000 datapoints
2025-03-06 22:34:34,647 - INFO - training batch 151, loss: 0.663, 4832/28000 datapoints
2025-03-06 22:34:34,810 - INFO - training batch 201, loss: 0.171, 6432/28000 datapoints
2025-03-06 22:34:34,965 - INFO - training batch 251, loss: 0.476, 8032/28000 datapoints
2025-03-06 22:34:35,116 - INFO - training batch 301, loss: 0.733, 9632/28000 datapoints
2025-03-06 22:34:35,273 - INFO - training batch 351, loss: 0.305, 11232/28000 datapoints
2025-03-06 22:34:35,425 - INFO - training batch 401, loss: 0.711, 12832/28000 datapoints
2025-03-06 22:34:35,575 - INFO - training batch 451, loss: 0.420, 14432/28000 datapoints
2025-03-06 22:34:35,726 - INFO - training batch 501, loss: 0.218, 16032/28000 datapoints
2025-03-06 22:34:35,958 - INFO - training batch 551, loss: 0.435, 17632/28000 datapoints
2025-03-06 22:34:36,114 - INFO - training batch 601, loss: 0.495, 19232/28000 datapoints
2025-03-06 22:34:36,266 - INFO - training batch 651, loss: 0.127, 20832/28000 datapoints
2025-03-06 22:34:36,417 - INFO - training batch 701, loss: 0.326, 22432/28000 datapoints
2025-03-06 22:34:36,575 - INFO - training batch 751, loss: 0.276, 24032/28000 datapoints
2025-03-06 22:34:36,733 - INFO - training batch 801, loss: 0.189, 25632/28000 datapoints
2025-03-06 22:34:36,889 - INFO - training batch 851, loss: 0.563, 27232/28000 datapoints
2025-03-06 22:34:36,964 - INFO - validation batch 1, loss: 0.108, 32/6976 datapoints
2025-03-06 22:34:37,012 - INFO - validation batch 51, loss: 1.274, 1632/6976 datapoints
2025-03-06 22:34:37,058 - INFO - validation batch 101, loss: 0.373, 3232/6976 datapoints
2025-03-06 22:34:37,106 - INFO - validation batch 151, loss: 0.507, 4832/6976 datapoints
2025-03-06 22:34:37,153 - INFO - validation batch 201, loss: 0.554, 6432/6976 datapoints
2025-03-06 22:34:37,170 - INFO - Epoch 169/800 done.
2025-03-06 22:34:37,170 - INFO - Final validation performance:
Loss: 0.563, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 22:34:37,171 - INFO - Beginning epoch 170/800
2025-03-06 22:34:37,175 - INFO - training batch 1, loss: 0.392, 32/28000 datapoints
2025-03-06 22:34:37,327 - INFO - training batch 51, loss: 0.183, 1632/28000 datapoints
2025-03-06 22:34:37,481 - INFO - training batch 101, loss: 0.216, 3232/28000 datapoints
2025-03-06 22:34:37,652 - INFO - training batch 151, loss: 0.658, 4832/28000 datapoints
2025-03-06 22:34:37,803 - INFO - training batch 201, loss: 0.168, 6432/28000 datapoints
2025-03-06 22:34:37,968 - INFO - training batch 251, loss: 0.476, 8032/28000 datapoints
2025-03-06 22:34:38,118 - INFO - training batch 301, loss: 0.731, 9632/28000 datapoints
2025-03-06 22:34:38,268 - INFO - training batch 351, loss: 0.303, 11232/28000 datapoints
2025-03-06 22:34:38,420 - INFO - training batch 401, loss: 0.708, 12832/28000 datapoints
2025-03-06 22:34:38,573 - INFO - training batch 451, loss: 0.418, 14432/28000 datapoints
2025-03-06 22:34:38,731 - INFO - training batch 501, loss: 0.216, 16032/28000 datapoints
2025-03-06 22:34:38,885 - INFO - training batch 551, loss: 0.433, 17632/28000 datapoints
2025-03-06 22:34:39,048 - INFO - training batch 601, loss: 0.489, 19232/28000 datapoints
2025-03-06 22:34:39,206 - INFO - training batch 651, loss: 0.125, 20832/28000 datapoints
2025-03-06 22:34:39,361 - INFO - training batch 701, loss: 0.324, 22432/28000 datapoints
2025-03-06 22:34:39,522 - INFO - training batch 751, loss: 0.276, 24032/28000 datapoints
2025-03-06 22:34:39,677 - INFO - training batch 801, loss: 0.187, 25632/28000 datapoints
2025-03-06 22:34:39,834 - INFO - training batch 851, loss: 0.559, 27232/28000 datapoints
2025-03-06 22:34:39,916 - INFO - validation batch 1, loss: 0.107, 32/6976 datapoints
2025-03-06 22:34:39,971 - INFO - validation batch 51, loss: 1.273, 1632/6976 datapoints
2025-03-06 22:34:40,024 - INFO - validation batch 101, loss: 0.373, 3232/6976 datapoints
2025-03-06 22:34:40,072 - INFO - validation batch 151, loss: 0.503, 4832/6976 datapoints
2025-03-06 22:34:40,119 - INFO - validation batch 201, loss: 0.554, 6432/6976 datapoints
2025-03-06 22:34:40,136 - INFO - Epoch 170/800 done.
2025-03-06 22:34:40,136 - INFO - Final validation performance:
Loss: 0.562, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:34:40,136 - INFO - Beginning epoch 171/800
2025-03-06 22:34:40,141 - INFO - training batch 1, loss: 0.391, 32/28000 datapoints
2025-03-06 22:34:40,295 - INFO - training batch 51, loss: 0.181, 1632/28000 datapoints
2025-03-06 22:34:40,453 - INFO - training batch 101, loss: 0.214, 3232/28000 datapoints
2025-03-06 22:34:40,607 - INFO - training batch 151, loss: 0.653, 4832/28000 datapoints
2025-03-06 22:34:40,763 - INFO - training batch 201, loss: 0.166, 6432/28000 datapoints
2025-03-06 22:34:40,915 - INFO - training batch 251, loss: 0.476, 8032/28000 datapoints
2025-03-06 22:34:41,070 - INFO - training batch 301, loss: 0.729, 9632/28000 datapoints
2025-03-06 22:34:41,221 - INFO - training batch 351, loss: 0.301, 11232/28000 datapoints
2025-03-06 22:34:41,371 - INFO - training batch 401, loss: 0.704, 12832/28000 datapoints
2025-03-06 22:34:41,521 - INFO - training batch 451, loss: 0.415, 14432/28000 datapoints
2025-03-06 22:34:41,674 - INFO - training batch 501, loss: 0.214, 16032/28000 datapoints
2025-03-06 22:34:41,826 - INFO - training batch 551, loss: 0.431, 17632/28000 datapoints
2025-03-06 22:34:41,981 - INFO - training batch 601, loss: 0.484, 19232/28000 datapoints
2025-03-06 22:34:42,150 - INFO - training batch 651, loss: 0.124, 20832/28000 datapoints
2025-03-06 22:34:42,302 - INFO - training batch 701, loss: 0.322, 22432/28000 datapoints
2025-03-06 22:34:42,488 - INFO - training batch 751, loss: 0.275, 24032/28000 datapoints
2025-03-06 22:34:42,646 - INFO - training batch 801, loss: 0.185, 25632/28000 datapoints
2025-03-06 22:34:42,796 - INFO - training batch 851, loss: 0.554, 27232/28000 datapoints
2025-03-06 22:34:42,875 - INFO - validation batch 1, loss: 0.107, 32/6976 datapoints
2025-03-06 22:34:42,923 - INFO - validation batch 51, loss: 1.271, 1632/6976 datapoints
2025-03-06 22:34:42,972 - INFO - validation batch 101, loss: 0.373, 3232/6976 datapoints
2025-03-06 22:34:43,019 - INFO - validation batch 151, loss: 0.500, 4832/6976 datapoints
2025-03-06 22:34:43,067 - INFO - validation batch 201, loss: 0.555, 6432/6976 datapoints
2025-03-06 22:34:43,083 - INFO - Epoch 171/800 done.
2025-03-06 22:34:43,083 - INFO - Final validation performance:
Loss: 0.561, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:34:43,084 - INFO - Beginning epoch 172/800
2025-03-06 22:34:43,088 - INFO - training batch 1, loss: 0.389, 32/28000 datapoints
2025-03-06 22:34:43,240 - INFO - training batch 51, loss: 0.180, 1632/28000 datapoints
2025-03-06 22:34:43,393 - INFO - training batch 101, loss: 0.213, 3232/28000 datapoints
2025-03-06 22:34:43,546 - INFO - training batch 151, loss: 0.650, 4832/28000 datapoints
2025-03-06 22:34:43,698 - INFO - training batch 201, loss: 0.163, 6432/28000 datapoints
2025-03-06 22:34:43,852 - INFO - training batch 251, loss: 0.475, 8032/28000 datapoints
2025-03-06 22:34:44,007 - INFO - training batch 301, loss: 0.725, 9632/28000 datapoints
2025-03-06 22:34:44,158 - INFO - training batch 351, loss: 0.302, 11232/28000 datapoints
2025-03-06 22:34:44,309 - INFO - training batch 401, loss: 0.699, 12832/28000 datapoints
2025-03-06 22:34:44,460 - INFO - training batch 451, loss: 0.413, 14432/28000 datapoints
2025-03-06 22:34:44,612 - INFO - training batch 501, loss: 0.212, 16032/28000 datapoints
2025-03-06 22:34:44,775 - INFO - training batch 551, loss: 0.430, 17632/28000 datapoints
2025-03-06 22:34:44,926 - INFO - training batch 601, loss: 0.480, 19232/28000 datapoints
2025-03-06 22:34:45,080 - INFO - training batch 651, loss: 0.122, 20832/28000 datapoints
2025-03-06 22:34:45,237 - INFO - training batch 701, loss: 0.320, 22432/28000 datapoints
2025-03-06 22:34:45,388 - INFO - training batch 751, loss: 0.273, 24032/28000 datapoints
2025-03-06 22:34:45,539 - INFO - training batch 801, loss: 0.183, 25632/28000 datapoints
2025-03-06 22:34:45,689 - INFO - training batch 851, loss: 0.549, 27232/28000 datapoints
2025-03-06 22:34:45,763 - INFO - validation batch 1, loss: 0.106, 32/6976 datapoints
2025-03-06 22:34:45,812 - INFO - validation batch 51, loss: 1.271, 1632/6976 datapoints
2025-03-06 22:34:45,859 - INFO - validation batch 101, loss: 0.373, 3232/6976 datapoints
2025-03-06 22:34:45,907 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 22:34:45,957 - INFO - validation batch 201, loss: 0.555, 6432/6976 datapoints
2025-03-06 22:34:45,976 - INFO - Epoch 172/800 done.
2025-03-06 22:34:45,976 - INFO - Final validation performance:
Loss: 0.560, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:34:45,976 - INFO - Beginning epoch 173/800
2025-03-06 22:34:45,981 - INFO - training batch 1, loss: 0.388, 32/28000 datapoints
2025-03-06 22:34:46,133 - INFO - training batch 51, loss: 0.178, 1632/28000 datapoints
2025-03-06 22:34:46,286 - INFO - training batch 101, loss: 0.212, 3232/28000 datapoints
2025-03-06 22:34:46,439 - INFO - training batch 151, loss: 0.645, 4832/28000 datapoints
2025-03-06 22:34:46,591 - INFO - training batch 201, loss: 0.161, 6432/28000 datapoints
2025-03-06 22:34:46,746 - INFO - training batch 251, loss: 0.476, 8032/28000 datapoints
2025-03-06 22:34:46,902 - INFO - training batch 301, loss: 0.724, 9632/28000 datapoints
2025-03-06 22:34:47,090 - INFO - training batch 351, loss: 0.299, 11232/28000 datapoints
2025-03-06 22:34:47,272 - INFO - training batch 401, loss: 0.696, 12832/28000 datapoints
2025-03-06 22:34:47,457 - INFO - training batch 451, loss: 0.412, 14432/28000 datapoints
2025-03-06 22:34:47,649 - INFO - training batch 501, loss: 0.210, 16032/28000 datapoints
2025-03-06 22:34:47,803 - INFO - training batch 551, loss: 0.428, 17632/28000 datapoints
2025-03-06 22:34:47,958 - INFO - training batch 601, loss: 0.476, 19232/28000 datapoints
2025-03-06 22:34:48,109 - INFO - training batch 651, loss: 0.121, 20832/28000 datapoints
2025-03-06 22:34:48,267 - INFO - training batch 701, loss: 0.318, 22432/28000 datapoints
2025-03-06 22:34:48,424 - INFO - training batch 751, loss: 0.272, 24032/28000 datapoints
2025-03-06 22:34:48,575 - INFO - training batch 801, loss: 0.182, 25632/28000 datapoints
2025-03-06 22:34:48,734 - INFO - training batch 851, loss: 0.545, 27232/28000 datapoints
2025-03-06 22:34:48,811 - INFO - validation batch 1, loss: 0.105, 32/6976 datapoints
2025-03-06 22:34:48,860 - INFO - validation batch 51, loss: 1.270, 1632/6976 datapoints
2025-03-06 22:34:48,911 - INFO - validation batch 101, loss: 0.373, 3232/6976 datapoints
2025-03-06 22:34:48,961 - INFO - validation batch 151, loss: 0.493, 4832/6976 datapoints
2025-03-06 22:34:49,009 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 22:34:49,026 - INFO - Epoch 173/800 done.
2025-03-06 22:34:49,026 - INFO - Final validation performance:
Loss: 0.559, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:34:49,027 - INFO - Beginning epoch 174/800
2025-03-06 22:34:49,031 - INFO - training batch 1, loss: 0.387, 32/28000 datapoints
2025-03-06 22:34:49,188 - INFO - training batch 51, loss: 0.176, 1632/28000 datapoints
2025-03-06 22:34:49,340 - INFO - training batch 101, loss: 0.211, 3232/28000 datapoints
2025-03-06 22:34:49,493 - INFO - training batch 151, loss: 0.642, 4832/28000 datapoints
2025-03-06 22:34:49,647 - INFO - training batch 201, loss: 0.159, 6432/28000 datapoints
2025-03-06 22:34:49,798 - INFO - training batch 251, loss: 0.475, 8032/28000 datapoints
2025-03-06 22:34:49,954 - INFO - training batch 301, loss: 0.722, 9632/28000 datapoints
2025-03-06 22:34:50,109 - INFO - training batch 351, loss: 0.297, 11232/28000 datapoints
2025-03-06 22:34:50,263 - INFO - training batch 401, loss: 0.692, 12832/28000 datapoints
2025-03-06 22:34:50,416 - INFO - training batch 451, loss: 0.410, 14432/28000 datapoints
2025-03-06 22:34:50,568 - INFO - training batch 501, loss: 0.208, 16032/28000 datapoints
2025-03-06 22:34:50,726 - INFO - training batch 551, loss: 0.427, 17632/28000 datapoints
2025-03-06 22:34:50,879 - INFO - training batch 601, loss: 0.471, 19232/28000 datapoints
2025-03-06 22:34:51,040 - INFO - training batch 651, loss: 0.120, 20832/28000 datapoints
2025-03-06 22:34:51,193 - INFO - training batch 701, loss: 0.317, 22432/28000 datapoints
2025-03-06 22:34:51,344 - INFO - training batch 751, loss: 0.270, 24032/28000 datapoints
2025-03-06 22:34:51,494 - INFO - training batch 801, loss: 0.180, 25632/28000 datapoints
2025-03-06 22:34:51,647 - INFO - training batch 851, loss: 0.541, 27232/28000 datapoints
2025-03-06 22:34:51,723 - INFO - validation batch 1, loss: 0.104, 32/6976 datapoints
2025-03-06 22:34:51,770 - INFO - validation batch 51, loss: 1.270, 1632/6976 datapoints
2025-03-06 22:34:51,818 - INFO - validation batch 101, loss: 0.372, 3232/6976 datapoints
2025-03-06 22:34:51,866 - INFO - validation batch 151, loss: 0.490, 4832/6976 datapoints
2025-03-06 22:34:51,913 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 22:34:51,929 - INFO - Epoch 174/800 done.
2025-03-06 22:34:51,930 - INFO - Final validation performance:
Loss: 0.559, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:34:51,930 - INFO - Beginning epoch 175/800
2025-03-06 22:34:51,934 - INFO - training batch 1, loss: 0.386, 32/28000 datapoints
2025-03-06 22:34:52,092 - INFO - training batch 51, loss: 0.174, 1632/28000 datapoints
2025-03-06 22:34:52,250 - INFO - training batch 101, loss: 0.209, 3232/28000 datapoints
2025-03-06 22:34:52,401 - INFO - training batch 151, loss: 0.637, 4832/28000 datapoints
2025-03-06 22:34:52,580 - INFO - training batch 201, loss: 0.157, 6432/28000 datapoints
2025-03-06 22:34:52,734 - INFO - training batch 251, loss: 0.474, 8032/28000 datapoints
2025-03-06 22:34:52,885 - INFO - training batch 301, loss: 0.719, 9632/28000 datapoints
2025-03-06 22:34:53,095 - INFO - training batch 351, loss: 0.296, 11232/28000 datapoints
2025-03-06 22:34:53,246 - INFO - training batch 401, loss: 0.688, 12832/28000 datapoints
2025-03-06 22:34:53,397 - INFO - training batch 451, loss: 0.409, 14432/28000 datapoints
2025-03-06 22:34:53,548 - INFO - training batch 501, loss: 0.207, 16032/28000 datapoints
2025-03-06 22:34:53,700 - INFO - training batch 551, loss: 0.425, 17632/28000 datapoints
2025-03-06 22:34:53,851 - INFO - training batch 601, loss: 0.464, 19232/28000 datapoints
2025-03-06 22:34:54,006 - INFO - training batch 651, loss: 0.118, 20832/28000 datapoints
2025-03-06 22:34:54,159 - INFO - training batch 701, loss: 0.316, 22432/28000 datapoints
2025-03-06 22:34:54,311 - INFO - training batch 751, loss: 0.268, 24032/28000 datapoints
2025-03-06 22:34:54,469 - INFO - training batch 801, loss: 0.178, 25632/28000 datapoints
2025-03-06 22:34:54,626 - INFO - training batch 851, loss: 0.536, 27232/28000 datapoints
2025-03-06 22:34:54,703 - INFO - validation batch 1, loss: 0.103, 32/6976 datapoints
2025-03-06 22:34:54,750 - INFO - validation batch 51, loss: 1.270, 1632/6976 datapoints
2025-03-06 22:34:54,798 - INFO - validation batch 101, loss: 0.372, 3232/6976 datapoints
2025-03-06 22:34:54,846 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 22:34:54,894 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 22:34:54,911 - INFO - Epoch 175/800 done.
2025-03-06 22:34:54,911 - INFO - Final validation performance:
Loss: 0.558, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:34:54,911 - INFO - Beginning epoch 176/800
2025-03-06 22:34:54,915 - INFO - training batch 1, loss: 0.384, 32/28000 datapoints
2025-03-06 22:34:55,076 - INFO - training batch 51, loss: 0.173, 1632/28000 datapoints
2025-03-06 22:34:55,238 - INFO - training batch 101, loss: 0.208, 3232/28000 datapoints
2025-03-06 22:34:55,394 - INFO - training batch 151, loss: 0.632, 4832/28000 datapoints
2025-03-06 22:34:55,544 - INFO - training batch 201, loss: 0.154, 6432/28000 datapoints
2025-03-06 22:34:55,698 - INFO - training batch 251, loss: 0.473, 8032/28000 datapoints
2025-03-06 22:34:55,851 - INFO - training batch 301, loss: 0.717, 9632/28000 datapoints
2025-03-06 22:34:56,004 - INFO - training batch 351, loss: 0.294, 11232/28000 datapoints
2025-03-06 22:34:56,154 - INFO - training batch 401, loss: 0.684, 12832/28000 datapoints
2025-03-06 22:34:56,306 - INFO - training batch 451, loss: 0.406, 14432/28000 datapoints
2025-03-06 22:34:56,457 - INFO - training batch 501, loss: 0.205, 16032/28000 datapoints
2025-03-06 22:34:56,611 - INFO - training batch 551, loss: 0.424, 17632/28000 datapoints
2025-03-06 22:34:56,765 - INFO - training batch 601, loss: 0.460, 19232/28000 datapoints
2025-03-06 22:34:56,916 - INFO - training batch 651, loss: 0.117, 20832/28000 datapoints
2025-03-06 22:34:57,067 - INFO - training batch 701, loss: 0.314, 22432/28000 datapoints
2025-03-06 22:34:57,218 - INFO - training batch 751, loss: 0.268, 24032/28000 datapoints
2025-03-06 22:34:57,368 - INFO - training batch 801, loss: 0.177, 25632/28000 datapoints
2025-03-06 22:34:57,517 - INFO - training batch 851, loss: 0.532, 27232/28000 datapoints
2025-03-06 22:34:57,592 - INFO - validation batch 1, loss: 0.102, 32/6976 datapoints
2025-03-06 22:34:57,640 - INFO - validation batch 51, loss: 1.269, 1632/6976 datapoints
2025-03-06 22:34:57,687 - INFO - validation batch 101, loss: 0.372, 3232/6976 datapoints
2025-03-06 22:34:57,734 - INFO - validation batch 151, loss: 0.483, 4832/6976 datapoints
2025-03-06 22:34:57,781 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 22:34:57,797 - INFO - Epoch 176/800 done.
2025-03-06 22:34:57,798 - INFO - Final validation performance:
Loss: 0.556, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:34:57,798 - INFO - Beginning epoch 177/800
2025-03-06 22:34:57,802 - INFO - training batch 1, loss: 0.383, 32/28000 datapoints
2025-03-06 22:34:57,958 - INFO - training batch 51, loss: 0.171, 1632/28000 datapoints
2025-03-06 22:34:58,108 - INFO - training batch 101, loss: 0.207, 3232/28000 datapoints
2025-03-06 22:34:58,263 - INFO - training batch 151, loss: 0.628, 4832/28000 datapoints
2025-03-06 22:34:58,415 - INFO - training batch 201, loss: 0.152, 6432/28000 datapoints
2025-03-06 22:34:58,566 - INFO - training batch 251, loss: 0.473, 8032/28000 datapoints
2025-03-06 22:34:58,721 - INFO - training batch 301, loss: 0.715, 9632/28000 datapoints
2025-03-06 22:34:58,877 - INFO - training batch 351, loss: 0.292, 11232/28000 datapoints
2025-03-06 22:34:59,040 - INFO - training batch 401, loss: 0.681, 12832/28000 datapoints
2025-03-06 22:34:59,197 - INFO - training batch 451, loss: 0.404, 14432/28000 datapoints
2025-03-06 22:34:59,351 - INFO - training batch 501, loss: 0.203, 16032/28000 datapoints
2025-03-06 22:34:59,510 - INFO - training batch 551, loss: 0.423, 17632/28000 datapoints
2025-03-06 22:34:59,668 - INFO - training batch 601, loss: 0.459, 19232/28000 datapoints
2025-03-06 22:34:59,830 - INFO - training batch 651, loss: 0.115, 20832/28000 datapoints
2025-03-06 22:34:59,990 - INFO - training batch 701, loss: 0.312, 22432/28000 datapoints
2025-03-06 22:35:00,163 - INFO - training batch 751, loss: 0.267, 24032/28000 datapoints
2025-03-06 22:35:00,320 - INFO - training batch 801, loss: 0.175, 25632/28000 datapoints
2025-03-06 22:35:00,474 - INFO - training batch 851, loss: 0.529, 27232/28000 datapoints
2025-03-06 22:35:00,552 - INFO - validation batch 1, loss: 0.101, 32/6976 datapoints
2025-03-06 22:35:00,607 - INFO - validation batch 51, loss: 1.269, 1632/6976 datapoints
2025-03-06 22:35:00,678 - INFO - validation batch 101, loss: 0.371, 3232/6976 datapoints
2025-03-06 22:35:00,740 - INFO - validation batch 151, loss: 0.479, 4832/6976 datapoints
2025-03-06 22:35:00,793 - INFO - validation batch 201, loss: 0.557, 6432/6976 datapoints
2025-03-06 22:35:00,809 - INFO - Epoch 177/800 done.
2025-03-06 22:35:00,809 - INFO - Final validation performance:
Loss: 0.555, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:35:00,810 - INFO - Beginning epoch 178/800
2025-03-06 22:35:00,814 - INFO - training batch 1, loss: 0.381, 32/28000 datapoints
2025-03-06 22:35:00,974 - INFO - training batch 51, loss: 0.170, 1632/28000 datapoints
2025-03-06 22:35:01,137 - INFO - training batch 101, loss: 0.206, 3232/28000 datapoints
2025-03-06 22:35:01,295 - INFO - training batch 151, loss: 0.623, 4832/28000 datapoints
2025-03-06 22:35:01,450 - INFO - training batch 201, loss: 0.150, 6432/28000 datapoints
2025-03-06 22:35:01,605 - INFO - training batch 251, loss: 0.473, 8032/28000 datapoints
2025-03-06 22:35:01,761 - INFO - training batch 301, loss: 0.712, 9632/28000 datapoints
2025-03-06 22:35:01,914 - INFO - training batch 351, loss: 0.290, 11232/28000 datapoints
2025-03-06 22:35:02,073 - INFO - training batch 401, loss: 0.677, 12832/28000 datapoints
2025-03-06 22:35:02,229 - INFO - training batch 451, loss: 0.403, 14432/28000 datapoints
2025-03-06 22:35:02,392 - INFO - training batch 501, loss: 0.201, 16032/28000 datapoints
2025-03-06 22:35:02,548 - INFO - training batch 551, loss: 0.421, 17632/28000 datapoints
2025-03-06 22:35:02,731 - INFO - training batch 601, loss: 0.456, 19232/28000 datapoints
2025-03-06 22:35:02,887 - INFO - training batch 651, loss: 0.114, 20832/28000 datapoints
2025-03-06 22:35:03,051 - INFO - training batch 701, loss: 0.310, 22432/28000 datapoints
2025-03-06 22:35:03,206 - INFO - training batch 751, loss: 0.266, 24032/28000 datapoints
2025-03-06 22:35:03,359 - INFO - training batch 801, loss: 0.173, 25632/28000 datapoints
2025-03-06 22:35:03,513 - INFO - training batch 851, loss: 0.524, 27232/28000 datapoints
2025-03-06 22:35:03,592 - INFO - validation batch 1, loss: 0.100, 32/6976 datapoints
2025-03-06 22:35:03,645 - INFO - validation batch 51, loss: 1.270, 1632/6976 datapoints
2025-03-06 22:35:03,699 - INFO - validation batch 101, loss: 0.370, 3232/6976 datapoints
2025-03-06 22:35:03,750 - INFO - validation batch 151, loss: 0.476, 4832/6976 datapoints
2025-03-06 22:35:03,802 - INFO - validation batch 201, loss: 0.557, 6432/6976 datapoints
2025-03-06 22:35:03,819 - INFO - Epoch 178/800 done.
2025-03-06 22:35:03,819 - INFO - Final validation performance:
Loss: 0.555, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:35:03,819 - INFO - Beginning epoch 179/800
2025-03-06 22:35:03,824 - INFO - training batch 1, loss: 0.380, 32/28000 datapoints
2025-03-06 22:35:03,983 - INFO - training batch 51, loss: 0.168, 1632/28000 datapoints
2025-03-06 22:35:04,138 - INFO - training batch 101, loss: 0.205, 3232/28000 datapoints
2025-03-06 22:35:04,296 - INFO - training batch 151, loss: 0.618, 4832/28000 datapoints
2025-03-06 22:35:04,451 - INFO - training batch 201, loss: 0.149, 6432/28000 datapoints
2025-03-06 22:35:04,605 - INFO - training batch 251, loss: 0.473, 8032/28000 datapoints
2025-03-06 22:35:04,765 - INFO - training batch 301, loss: 0.710, 9632/28000 datapoints
2025-03-06 22:35:04,921 - INFO - training batch 351, loss: 0.288, 11232/28000 datapoints
2025-03-06 22:35:05,080 - INFO - training batch 401, loss: 0.673, 12832/28000 datapoints
2025-03-06 22:35:05,238 - INFO - training batch 451, loss: 0.400, 14432/28000 datapoints
2025-03-06 22:35:05,394 - INFO - training batch 501, loss: 0.199, 16032/28000 datapoints
2025-03-06 22:35:05,550 - INFO - training batch 551, loss: 0.420, 17632/28000 datapoints
2025-03-06 22:35:05,708 - INFO - training batch 601, loss: 0.450, 19232/28000 datapoints
2025-03-06 22:35:05,864 - INFO - training batch 651, loss: 0.113, 20832/28000 datapoints
2025-03-06 22:35:06,023 - INFO - training batch 701, loss: 0.308, 22432/28000 datapoints
2025-03-06 22:35:06,180 - INFO - training batch 751, loss: 0.265, 24032/28000 datapoints
2025-03-06 22:35:06,335 - INFO - training batch 801, loss: 0.171, 25632/28000 datapoints
2025-03-06 22:35:06,489 - INFO - training batch 851, loss: 0.520, 27232/28000 datapoints
2025-03-06 22:35:06,567 - INFO - validation batch 1, loss: 0.100, 32/6976 datapoints
2025-03-06 22:35:06,619 - INFO - validation batch 51, loss: 1.269, 1632/6976 datapoints
2025-03-06 22:35:06,673 - INFO - validation batch 101, loss: 0.370, 3232/6976 datapoints
2025-03-06 22:35:06,727 - INFO - validation batch 151, loss: 0.473, 4832/6976 datapoints
2025-03-06 22:35:06,783 - INFO - validation batch 201, loss: 0.558, 6432/6976 datapoints
2025-03-06 22:35:06,800 - INFO - Epoch 179/800 done.
2025-03-06 22:35:06,800 - INFO - Final validation performance:
Loss: 0.554, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:35:06,801 - INFO - Beginning epoch 180/800
2025-03-06 22:35:06,805 - INFO - training batch 1, loss: 0.379, 32/28000 datapoints
2025-03-06 22:35:06,980 - INFO - training batch 51, loss: 0.167, 1632/28000 datapoints
2025-03-06 22:35:07,134 - INFO - training batch 101, loss: 0.205, 3232/28000 datapoints
2025-03-06 22:35:07,296 - INFO - training batch 151, loss: 0.613, 4832/28000 datapoints
2025-03-06 22:35:07,466 - INFO - training batch 201, loss: 0.146, 6432/28000 datapoints
2025-03-06 22:35:07,626 - INFO - training batch 251, loss: 0.474, 8032/28000 datapoints
2025-03-06 22:35:07,785 - INFO - training batch 301, loss: 0.708, 9632/28000 datapoints
2025-03-06 22:35:07,944 - INFO - training batch 351, loss: 0.287, 11232/28000 datapoints
2025-03-06 22:35:08,101 - INFO - training batch 401, loss: 0.671, 12832/28000 datapoints
2025-03-06 22:35:08,258 - INFO - training batch 451, loss: 0.399, 14432/28000 datapoints
2025-03-06 22:35:08,413 - INFO - training batch 501, loss: 0.198, 16032/28000 datapoints
2025-03-06 22:35:08,569 - INFO - training batch 551, loss: 0.418, 17632/28000 datapoints
2025-03-06 22:35:08,723 - INFO - training batch 601, loss: 0.446, 19232/28000 datapoints
2025-03-06 22:35:08,882 - INFO - training batch 651, loss: 0.112, 20832/28000 datapoints
2025-03-06 22:35:09,040 - INFO - training batch 701, loss: 0.307, 22432/28000 datapoints
2025-03-06 22:35:09,196 - INFO - training batch 751, loss: 0.264, 24032/28000 datapoints
2025-03-06 22:35:09,354 - INFO - training batch 801, loss: 0.169, 25632/28000 datapoints
2025-03-06 22:35:09,513 - INFO - training batch 851, loss: 0.515, 27232/28000 datapoints
2025-03-06 22:35:09,595 - INFO - validation batch 1, loss: 0.099, 32/6976 datapoints
2025-03-06 22:35:09,646 - INFO - validation batch 51, loss: 1.268, 1632/6976 datapoints
2025-03-06 22:35:09,698 - INFO - validation batch 101, loss: 0.370, 3232/6976 datapoints
2025-03-06 22:35:09,751 - INFO - validation batch 151, loss: 0.470, 4832/6976 datapoints
2025-03-06 22:35:09,804 - INFO - validation batch 201, loss: 0.558, 6432/6976 datapoints
2025-03-06 22:35:09,820 - INFO - Epoch 180/800 done.
2025-03-06 22:35:09,820 - INFO - Final validation performance:
Loss: 0.553, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:35:09,821 - INFO - Beginning epoch 181/800
2025-03-06 22:35:09,826 - INFO - training batch 1, loss: 0.377, 32/28000 datapoints
2025-03-06 22:35:09,984 - INFO - training batch 51, loss: 0.165, 1632/28000 datapoints
2025-03-06 22:35:10,135 - INFO - training batch 101, loss: 0.204, 3232/28000 datapoints
2025-03-06 22:35:10,289 - INFO - training batch 151, loss: 0.609, 4832/28000 datapoints
2025-03-06 22:35:10,443 - INFO - training batch 201, loss: 0.145, 6432/28000 datapoints
2025-03-06 22:35:10,595 - INFO - training batch 251, loss: 0.473, 8032/28000 datapoints
2025-03-06 22:35:10,756 - INFO - training batch 301, loss: 0.705, 9632/28000 datapoints
2025-03-06 22:35:10,908 - INFO - training batch 351, loss: 0.286, 11232/28000 datapoints
2025-03-06 22:35:11,063 - INFO - training batch 401, loss: 0.667, 12832/28000 datapoints
2025-03-06 22:35:11,213 - INFO - training batch 451, loss: 0.397, 14432/28000 datapoints
2025-03-06 22:35:11,365 - INFO - training batch 501, loss: 0.196, 16032/28000 datapoints
2025-03-06 22:35:11,516 - INFO - training batch 551, loss: 0.416, 17632/28000 datapoints
2025-03-06 22:35:11,667 - INFO - training batch 601, loss: 0.442, 19232/28000 datapoints
2025-03-06 22:35:11,821 - INFO - training batch 651, loss: 0.111, 20832/28000 datapoints
2025-03-06 22:35:11,978 - INFO - training batch 701, loss: 0.305, 22432/28000 datapoints
2025-03-06 22:35:12,127 - INFO - training batch 751, loss: 0.262, 24032/28000 datapoints
2025-03-06 22:35:12,279 - INFO - training batch 801, loss: 0.166, 25632/28000 datapoints
2025-03-06 22:35:12,430 - INFO - training batch 851, loss: 0.511, 27232/28000 datapoints
2025-03-06 22:35:12,504 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 22:35:12,552 - INFO - validation batch 51, loss: 1.269, 1632/6976 datapoints
2025-03-06 22:35:12,600 - INFO - validation batch 101, loss: 0.370, 3232/6976 datapoints
2025-03-06 22:35:12,649 - INFO - validation batch 151, loss: 0.466, 4832/6976 datapoints
2025-03-06 22:35:12,718 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 22:35:12,743 - INFO - Epoch 181/800 done.
2025-03-06 22:35:12,743 - INFO - Final validation performance:
Loss: 0.552, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:35:12,744 - INFO - Beginning epoch 182/800
2025-03-06 22:35:12,748 - INFO - training batch 1, loss: 0.375, 32/28000 datapoints
2025-03-06 22:35:12,913 - INFO - training batch 51, loss: 0.164, 1632/28000 datapoints
2025-03-06 22:35:13,074 - INFO - training batch 101, loss: 0.203, 3232/28000 datapoints
2025-03-06 22:35:13,224 - INFO - training batch 151, loss: 0.604, 4832/28000 datapoints
2025-03-06 22:35:13,375 - INFO - training batch 201, loss: 0.143, 6432/28000 datapoints
2025-03-06 22:35:13,535 - INFO - training batch 251, loss: 0.473, 8032/28000 datapoints
2025-03-06 22:35:13,690 - INFO - training batch 301, loss: 0.703, 9632/28000 datapoints
2025-03-06 22:35:13,850 - INFO - training batch 351, loss: 0.283, 11232/28000 datapoints
2025-03-06 22:35:14,008 - INFO - training batch 401, loss: 0.663, 12832/28000 datapoints
2025-03-06 22:35:14,159 - INFO - training batch 451, loss: 0.397, 14432/28000 datapoints
2025-03-06 22:35:14,310 - INFO - training batch 501, loss: 0.194, 16032/28000 datapoints
2025-03-06 22:35:14,464 - INFO - training batch 551, loss: 0.415, 17632/28000 datapoints
2025-03-06 22:35:14,615 - INFO - training batch 601, loss: 0.439, 19232/28000 datapoints
2025-03-06 22:35:14,771 - INFO - training batch 651, loss: 0.110, 20832/28000 datapoints
2025-03-06 22:35:14,925 - INFO - training batch 701, loss: 0.303, 22432/28000 datapoints
2025-03-06 22:35:15,080 - INFO - training batch 751, loss: 0.262, 24032/28000 datapoints
2025-03-06 22:35:15,237 - INFO - training batch 801, loss: 0.165, 25632/28000 datapoints
2025-03-06 22:35:15,391 - INFO - training batch 851, loss: 0.508, 27232/28000 datapoints
2025-03-06 22:35:15,464 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 22:35:15,511 - INFO - validation batch 51, loss: 1.268, 1632/6976 datapoints
2025-03-06 22:35:15,561 - INFO - validation batch 101, loss: 0.369, 3232/6976 datapoints
2025-03-06 22:35:15,608 - INFO - validation batch 151, loss: 0.463, 4832/6976 datapoints
2025-03-06 22:35:15,656 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 22:35:15,674 - INFO - Epoch 182/800 done.
2025-03-06 22:35:15,675 - INFO - Final validation performance:
Loss: 0.551, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:35:15,675 - INFO - Beginning epoch 183/800
2025-03-06 22:35:15,679 - INFO - training batch 1, loss: 0.374, 32/28000 datapoints
2025-03-06 22:35:15,835 - INFO - training batch 51, loss: 0.162, 1632/28000 datapoints
2025-03-06 22:35:15,990 - INFO - training batch 101, loss: 0.202, 3232/28000 datapoints
2025-03-06 22:35:16,143 - INFO - training batch 151, loss: 0.599, 4832/28000 datapoints
2025-03-06 22:35:16,294 - INFO - training batch 201, loss: 0.141, 6432/28000 datapoints
2025-03-06 22:35:16,446 - INFO - training batch 251, loss: 0.472, 8032/28000 datapoints
2025-03-06 22:35:16,598 - INFO - training batch 301, loss: 0.700, 9632/28000 datapoints
2025-03-06 22:35:16,749 - INFO - training batch 351, loss: 0.280, 11232/28000 datapoints
2025-03-06 22:35:16,905 - INFO - training batch 401, loss: 0.659, 12832/28000 datapoints
2025-03-06 22:35:17,061 - INFO - training batch 451, loss: 0.395, 14432/28000 datapoints
2025-03-06 22:35:17,213 - INFO - training batch 501, loss: 0.192, 16032/28000 datapoints
2025-03-06 22:35:17,368 - INFO - training batch 551, loss: 0.413, 17632/28000 datapoints
2025-03-06 22:35:17,520 - INFO - training batch 601, loss: 0.435, 19232/28000 datapoints
2025-03-06 22:35:17,672 - INFO - training batch 651, loss: 0.108, 20832/28000 datapoints
2025-03-06 22:35:17,823 - INFO - training batch 701, loss: 0.302, 22432/28000 datapoints
2025-03-06 22:35:17,977 - INFO - training batch 751, loss: 0.261, 24032/28000 datapoints
2025-03-06 22:35:18,128 - INFO - training batch 801, loss: 0.163, 25632/28000 datapoints
2025-03-06 22:35:18,281 - INFO - training batch 851, loss: 0.504, 27232/28000 datapoints
2025-03-06 22:35:18,355 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 22:35:18,406 - INFO - validation batch 51, loss: 1.268, 1632/6976 datapoints
2025-03-06 22:35:18,453 - INFO - validation batch 101, loss: 0.368, 3232/6976 datapoints
2025-03-06 22:35:18,501 - INFO - validation batch 151, loss: 0.460, 4832/6976 datapoints
2025-03-06 22:35:18,548 - INFO - validation batch 201, loss: 0.560, 6432/6976 datapoints
2025-03-06 22:35:18,565 - INFO - Epoch 183/800 done.
2025-03-06 22:35:18,565 - INFO - Final validation performance:
Loss: 0.551, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:35:18,565 - INFO - Beginning epoch 184/800
2025-03-06 22:35:18,570 - INFO - training batch 1, loss: 0.372, 32/28000 datapoints
2025-03-06 22:35:18,722 - INFO - training batch 51, loss: 0.161, 1632/28000 datapoints
2025-03-06 22:35:18,879 - INFO - training batch 101, loss: 0.201, 3232/28000 datapoints
2025-03-06 22:35:19,051 - INFO - training batch 151, loss: 0.594, 4832/28000 datapoints
2025-03-06 22:35:19,203 - INFO - training batch 201, loss: 0.139, 6432/28000 datapoints
2025-03-06 22:35:19,367 - INFO - training batch 251, loss: 0.472, 8032/28000 datapoints
2025-03-06 22:35:19,528 - INFO - training batch 301, loss: 0.696, 9632/28000 datapoints
2025-03-06 22:35:19,684 - INFO - training batch 351, loss: 0.279, 11232/28000 datapoints
2025-03-06 22:35:19,842 - INFO - training batch 401, loss: 0.655, 12832/28000 datapoints
2025-03-06 22:35:20,002 - INFO - training batch 451, loss: 0.393, 14432/28000 datapoints
2025-03-06 22:35:20,157 - INFO - training batch 501, loss: 0.192, 16032/28000 datapoints
2025-03-06 22:35:20,314 - INFO - training batch 551, loss: 0.412, 17632/28000 datapoints
2025-03-06 22:35:20,471 - INFO - training batch 601, loss: 0.430, 19232/28000 datapoints
2025-03-06 22:35:20,629 - INFO - training batch 651, loss: 0.107, 20832/28000 datapoints
2025-03-06 22:35:20,793 - INFO - training batch 701, loss: 0.301, 22432/28000 datapoints
2025-03-06 22:35:20,952 - INFO - training batch 751, loss: 0.260, 24032/28000 datapoints
2025-03-06 22:35:21,109 - INFO - training batch 801, loss: 0.162, 25632/28000 datapoints
2025-03-06 22:35:21,262 - INFO - training batch 851, loss: 0.500, 27232/28000 datapoints
2025-03-06 22:35:21,339 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 22:35:21,392 - INFO - validation batch 51, loss: 1.269, 1632/6976 datapoints
2025-03-06 22:35:21,447 - INFO - validation batch 101, loss: 0.368, 3232/6976 datapoints
2025-03-06 22:35:21,499 - INFO - validation batch 151, loss: 0.458, 4832/6976 datapoints
2025-03-06 22:35:21,554 - INFO - validation batch 201, loss: 0.561, 6432/6976 datapoints
2025-03-06 22:35:21,570 - INFO - Epoch 184/800 done.
2025-03-06 22:35:21,570 - INFO - Final validation performance:
Loss: 0.550, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:35:21,571 - INFO - Beginning epoch 185/800
2025-03-06 22:35:21,576 - INFO - training batch 1, loss: 0.370, 32/28000 datapoints
2025-03-06 22:35:21,731 - INFO - training batch 51, loss: 0.160, 1632/28000 datapoints
2025-03-06 22:35:21,888 - INFO - training batch 101, loss: 0.200, 3232/28000 datapoints
2025-03-06 22:35:22,049 - INFO - training batch 151, loss: 0.590, 4832/28000 datapoints
2025-03-06 22:35:22,206 - INFO - training batch 201, loss: 0.139, 6432/28000 datapoints
2025-03-06 22:35:22,361 - INFO - training batch 251, loss: 0.472, 8032/28000 datapoints
2025-03-06 22:35:22,518 - INFO - training batch 301, loss: 0.695, 9632/28000 datapoints
2025-03-06 22:35:22,674 - INFO - training batch 351, loss: 0.277, 11232/28000 datapoints
2025-03-06 22:35:22,863 - INFO - training batch 401, loss: 0.651, 12832/28000 datapoints
2025-03-06 22:35:23,020 - INFO - training batch 451, loss: 0.392, 14432/28000 datapoints
2025-03-06 22:35:23,176 - INFO - training batch 501, loss: 0.190, 16032/28000 datapoints
2025-03-06 22:35:23,333 - INFO - training batch 551, loss: 0.411, 17632/28000 datapoints
2025-03-06 22:35:23,488 - INFO - training batch 601, loss: 0.427, 19232/28000 datapoints
2025-03-06 22:35:23,644 - INFO - training batch 651, loss: 0.106, 20832/28000 datapoints
2025-03-06 22:35:23,801 - INFO - training batch 701, loss: 0.299, 22432/28000 datapoints
2025-03-06 22:35:23,960 - INFO - training batch 751, loss: 0.258, 24032/28000 datapoints
2025-03-06 22:35:24,115 - INFO - training batch 801, loss: 0.160, 25632/28000 datapoints
2025-03-06 22:35:24,269 - INFO - training batch 851, loss: 0.496, 27232/28000 datapoints
2025-03-06 22:35:24,346 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 22:35:24,398 - INFO - validation batch 51, loss: 1.269, 1632/6976 datapoints
2025-03-06 22:35:24,452 - INFO - validation batch 101, loss: 0.367, 3232/6976 datapoints
2025-03-06 22:35:24,504 - INFO - validation batch 151, loss: 0.454, 4832/6976 datapoints
2025-03-06 22:35:24,557 - INFO - validation batch 201, loss: 0.562, 6432/6976 datapoints
2025-03-06 22:35:24,575 - INFO - Epoch 185/800 done.
2025-03-06 22:35:24,575 - INFO - Final validation performance:
Loss: 0.549, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:35:24,576 - INFO - Beginning epoch 186/800
2025-03-06 22:35:24,581 - INFO - training batch 1, loss: 0.368, 32/28000 datapoints
2025-03-06 22:35:24,734 - INFO - training batch 51, loss: 0.159, 1632/28000 datapoints
2025-03-06 22:35:24,889 - INFO - training batch 101, loss: 0.199, 3232/28000 datapoints
2025-03-06 22:35:25,047 - INFO - training batch 151, loss: 0.585, 4832/28000 datapoints
2025-03-06 22:35:25,219 - INFO - training batch 201, loss: 0.137, 6432/28000 datapoints
2025-03-06 22:35:25,372 - INFO - training batch 251, loss: 0.471, 8032/28000 datapoints
2025-03-06 22:35:25,524 - INFO - training batch 301, loss: 0.692, 9632/28000 datapoints
2025-03-06 22:35:25,683 - INFO - training batch 351, loss: 0.275, 11232/28000 datapoints
2025-03-06 22:35:25,844 - INFO - training batch 401, loss: 0.647, 12832/28000 datapoints
2025-03-06 22:35:26,004 - INFO - training batch 451, loss: 0.390, 14432/28000 datapoints
2025-03-06 22:35:26,155 - INFO - training batch 501, loss: 0.189, 16032/28000 datapoints
2025-03-06 22:35:26,307 - INFO - training batch 551, loss: 0.411, 17632/28000 datapoints
2025-03-06 22:35:26,459 - INFO - training batch 601, loss: 0.424, 19232/28000 datapoints
2025-03-06 22:35:26,612 - INFO - training batch 651, loss: 0.105, 20832/28000 datapoints
2025-03-06 22:35:26,763 - INFO - training batch 701, loss: 0.298, 22432/28000 datapoints
2025-03-06 22:35:26,916 - INFO - training batch 751, loss: 0.257, 24032/28000 datapoints
2025-03-06 22:35:27,070 - INFO - training batch 801, loss: 0.158, 25632/28000 datapoints
2025-03-06 22:35:27,221 - INFO - training batch 851, loss: 0.491, 27232/28000 datapoints
2025-03-06 22:35:27,295 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 22:35:27,344 - INFO - validation batch 51, loss: 1.270, 1632/6976 datapoints
2025-03-06 22:35:27,392 - INFO - validation batch 101, loss: 0.367, 3232/6976 datapoints
2025-03-06 22:35:27,442 - INFO - validation batch 151, loss: 0.450, 4832/6976 datapoints
2025-03-06 22:35:27,491 - INFO - validation batch 201, loss: 0.563, 6432/6976 datapoints
2025-03-06 22:35:27,507 - INFO - Epoch 186/800 done.
2025-03-06 22:35:27,507 - INFO - Final validation performance:
Loss: 0.549, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:35:27,508 - INFO - Beginning epoch 187/800
2025-03-06 22:35:27,512 - INFO - training batch 1, loss: 0.367, 32/28000 datapoints
2025-03-06 22:35:27,667 - INFO - training batch 51, loss: 0.157, 1632/28000 datapoints
2025-03-06 22:35:27,820 - INFO - training batch 101, loss: 0.197, 3232/28000 datapoints
2025-03-06 22:35:27,978 - INFO - training batch 151, loss: 0.580, 4832/28000 datapoints
2025-03-06 22:35:28,131 - INFO - training batch 201, loss: 0.135, 6432/28000 datapoints
2025-03-06 22:35:28,282 - INFO - training batch 251, loss: 0.471, 8032/28000 datapoints
2025-03-06 22:35:28,433 - INFO - training batch 301, loss: 0.690, 9632/28000 datapoints
2025-03-06 22:35:28,585 - INFO - training batch 351, loss: 0.273, 11232/28000 datapoints
2025-03-06 22:35:28,735 - INFO - training batch 401, loss: 0.644, 12832/28000 datapoints
2025-03-06 22:35:28,889 - INFO - training batch 451, loss: 0.389, 14432/28000 datapoints
2025-03-06 22:35:29,045 - INFO - training batch 501, loss: 0.187, 16032/28000 datapoints
2025-03-06 22:35:29,199 - INFO - training batch 551, loss: 0.409, 17632/28000 datapoints
2025-03-06 22:35:29,351 - INFO - training batch 601, loss: 0.420, 19232/28000 datapoints
2025-03-06 22:35:29,502 - INFO - training batch 651, loss: 0.104, 20832/28000 datapoints
2025-03-06 22:35:29,654 - INFO - training batch 701, loss: 0.298, 22432/28000 datapoints
2025-03-06 22:35:29,804 - INFO - training batch 751, loss: 0.255, 24032/28000 datapoints
2025-03-06 22:35:29,962 - INFO - training batch 801, loss: 0.156, 25632/28000 datapoints
2025-03-06 22:35:30,143 - INFO - training batch 851, loss: 0.488, 27232/28000 datapoints
2025-03-06 22:35:30,244 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 22:35:30,292 - INFO - validation batch 51, loss: 1.270, 1632/6976 datapoints
2025-03-06 22:35:30,342 - INFO - validation batch 101, loss: 0.366, 3232/6976 datapoints
2025-03-06 22:35:30,390 - INFO - validation batch 151, loss: 0.449, 4832/6976 datapoints
2025-03-06 22:35:30,438 - INFO - validation batch 201, loss: 0.564, 6432/6976 datapoints
2025-03-06 22:35:30,455 - INFO - Epoch 187/800 done.
2025-03-06 22:35:30,455 - INFO - Final validation performance:
Loss: 0.548, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:35:30,455 - INFO - Beginning epoch 188/800
2025-03-06 22:35:30,459 - INFO - training batch 1, loss: 0.365, 32/28000 datapoints
2025-03-06 22:35:30,614 - INFO - training batch 51, loss: 0.156, 1632/28000 datapoints
2025-03-06 22:35:30,772 - INFO - training batch 101, loss: 0.196, 3232/28000 datapoints
2025-03-06 22:35:30,932 - INFO - training batch 151, loss: 0.576, 4832/28000 datapoints
2025-03-06 22:35:31,088 - INFO - training batch 201, loss: 0.134, 6432/28000 datapoints
2025-03-06 22:35:31,275 - INFO - training batch 251, loss: 0.471, 8032/28000 datapoints
2025-03-06 22:35:31,446 - INFO - training batch 301, loss: 0.688, 9632/28000 datapoints
2025-03-06 22:35:31,599 - INFO - training batch 351, loss: 0.271, 11232/28000 datapoints
2025-03-06 22:35:31,750 - INFO - training batch 401, loss: 0.640, 12832/28000 datapoints
2025-03-06 22:35:31,908 - INFO - training batch 451, loss: 0.388, 14432/28000 datapoints
2025-03-06 22:35:32,067 - INFO - training batch 501, loss: 0.186, 16032/28000 datapoints
2025-03-06 22:35:32,223 - INFO - training batch 551, loss: 0.407, 17632/28000 datapoints
2025-03-06 22:35:32,377 - INFO - training batch 601, loss: 0.415, 19232/28000 datapoints
2025-03-06 22:35:32,530 - INFO - training batch 651, loss: 0.102, 20832/28000 datapoints
2025-03-06 22:35:32,681 - INFO - training batch 701, loss: 0.296, 22432/28000 datapoints
2025-03-06 22:35:32,834 - INFO - training batch 751, loss: 0.254, 24032/28000 datapoints
2025-03-06 22:35:33,017 - INFO - training batch 801, loss: 0.155, 25632/28000 datapoints
2025-03-06 22:35:33,170 - INFO - training batch 851, loss: 0.484, 27232/28000 datapoints
2025-03-06 22:35:33,244 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 22:35:33,291 - INFO - validation batch 51, loss: 1.271, 1632/6976 datapoints
2025-03-06 22:35:33,339 - INFO - validation batch 101, loss: 0.365, 3232/6976 datapoints
2025-03-06 22:35:33,387 - INFO - validation batch 151, loss: 0.445, 4832/6976 datapoints
2025-03-06 22:35:33,434 - INFO - validation batch 201, loss: 0.565, 6432/6976 datapoints
2025-03-06 22:35:33,451 - INFO - Epoch 188/800 done.
2025-03-06 22:35:33,451 - INFO - Final validation performance:
Loss: 0.548, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:35:33,451 - INFO - Beginning epoch 189/800
2025-03-06 22:35:33,455 - INFO - training batch 1, loss: 0.363, 32/28000 datapoints
2025-03-06 22:35:33,611 - INFO - training batch 51, loss: 0.154, 1632/28000 datapoints
2025-03-06 22:35:33,761 - INFO - training batch 101, loss: 0.195, 3232/28000 datapoints
2025-03-06 22:35:33,912 - INFO - training batch 151, loss: 0.570, 4832/28000 datapoints
2025-03-06 22:35:34,072 - INFO - training batch 201, loss: 0.132, 6432/28000 datapoints
2025-03-06 22:35:34,224 - INFO - training batch 251, loss: 0.470, 8032/28000 datapoints
2025-03-06 22:35:34,374 - INFO - training batch 301, loss: 0.686, 9632/28000 datapoints
2025-03-06 22:35:34,525 - INFO - training batch 351, loss: 0.269, 11232/28000 datapoints
2025-03-06 22:35:34,677 - INFO - training batch 401, loss: 0.636, 12832/28000 datapoints
2025-03-06 22:35:34,826 - INFO - training batch 451, loss: 0.387, 14432/28000 datapoints
2025-03-06 22:35:34,984 - INFO - training batch 501, loss: 0.184, 16032/28000 datapoints
2025-03-06 22:35:35,138 - INFO - training batch 551, loss: 0.407, 17632/28000 datapoints
2025-03-06 22:35:35,297 - INFO - training batch 601, loss: 0.412, 19232/28000 datapoints
2025-03-06 22:35:35,450 - INFO - training batch 651, loss: 0.101, 20832/28000 datapoints
2025-03-06 22:35:35,602 - INFO - training batch 701, loss: 0.295, 22432/28000 datapoints
2025-03-06 22:35:35,755 - INFO - training batch 751, loss: 0.253, 24032/28000 datapoints
2025-03-06 22:35:35,904 - INFO - training batch 801, loss: 0.153, 25632/28000 datapoints
2025-03-06 22:35:36,059 - INFO - training batch 851, loss: 0.480, 27232/28000 datapoints
2025-03-06 22:35:36,141 - INFO - validation batch 1, loss: 0.092, 32/6976 datapoints
2025-03-06 22:35:36,189 - INFO - validation batch 51, loss: 1.273, 1632/6976 datapoints
2025-03-06 22:35:36,236 - INFO - validation batch 101, loss: 0.364, 3232/6976 datapoints
2025-03-06 22:35:36,283 - INFO - validation batch 151, loss: 0.442, 4832/6976 datapoints
2025-03-06 22:35:36,330 - INFO - validation batch 201, loss: 0.565, 6432/6976 datapoints
2025-03-06 22:35:36,346 - INFO - Epoch 189/800 done.
2025-03-06 22:35:36,346 - INFO - Final validation performance:
Loss: 0.547, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:35:36,347 - INFO - Beginning epoch 190/800
2025-03-06 22:35:36,351 - INFO - training batch 1, loss: 0.362, 32/28000 datapoints
2025-03-06 22:35:36,501 - INFO - training batch 51, loss: 0.153, 1632/28000 datapoints
2025-03-06 22:35:36,654 - INFO - training batch 101, loss: 0.194, 3232/28000 datapoints
2025-03-06 22:35:36,805 - INFO - training batch 151, loss: 0.565, 4832/28000 datapoints
2025-03-06 22:35:36,962 - INFO - training batch 201, loss: 0.131, 6432/28000 datapoints
2025-03-06 22:35:37,117 - INFO - training batch 251, loss: 0.470, 8032/28000 datapoints
2025-03-06 22:35:37,280 - INFO - training batch 301, loss: 0.684, 9632/28000 datapoints
2025-03-06 22:35:37,429 - INFO - training batch 351, loss: 0.268, 11232/28000 datapoints
2025-03-06 22:35:37,583 - INFO - training batch 401, loss: 0.632, 12832/28000 datapoints
2025-03-06 22:35:37,736 - INFO - training batch 451, loss: 0.386, 14432/28000 datapoints
2025-03-06 22:35:37,890 - INFO - training batch 501, loss: 0.183, 16032/28000 datapoints
2025-03-06 22:35:38,061 - INFO - training batch 551, loss: 0.406, 17632/28000 datapoints
2025-03-06 22:35:38,213 - INFO - training batch 601, loss: 0.409, 19232/28000 datapoints
2025-03-06 22:35:38,364 - INFO - training batch 651, loss: 0.100, 20832/28000 datapoints
2025-03-06 22:35:38,513 - INFO - training batch 701, loss: 0.294, 22432/28000 datapoints
2025-03-06 22:35:38,664 - INFO - training batch 751, loss: 0.252, 24032/28000 datapoints
2025-03-06 22:35:38,814 - INFO - training batch 801, loss: 0.152, 25632/28000 datapoints
2025-03-06 22:35:38,971 - INFO - training batch 851, loss: 0.477, 27232/28000 datapoints
2025-03-06 22:35:39,044 - INFO - validation batch 1, loss: 0.092, 32/6976 datapoints
2025-03-06 22:35:39,094 - INFO - validation batch 51, loss: 1.272, 1632/6976 datapoints
2025-03-06 22:35:39,143 - INFO - validation batch 101, loss: 0.364, 3232/6976 datapoints
2025-03-06 22:35:39,191 - INFO - validation batch 151, loss: 0.438, 4832/6976 datapoints
2025-03-06 22:35:39,239 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 22:35:39,255 - INFO - Epoch 190/800 done.
2025-03-06 22:35:39,255 - INFO - Final validation performance:
Loss: 0.546, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:35:39,256 - INFO - Beginning epoch 191/800
2025-03-06 22:35:39,260 - INFO - training batch 1, loss: 0.360, 32/28000 datapoints
2025-03-06 22:35:39,415 - INFO - training batch 51, loss: 0.151, 1632/28000 datapoints
2025-03-06 22:35:39,576 - INFO - training batch 101, loss: 0.193, 3232/28000 datapoints
2025-03-06 22:35:39,731 - INFO - training batch 151, loss: 0.561, 4832/28000 datapoints
2025-03-06 22:35:39,886 - INFO - training batch 201, loss: 0.130, 6432/28000 datapoints
2025-03-06 22:35:40,044 - INFO - training batch 251, loss: 0.470, 8032/28000 datapoints
2025-03-06 22:35:40,204 - INFO - training batch 301, loss: 0.682, 9632/28000 datapoints
2025-03-06 22:35:40,362 - INFO - training batch 351, loss: 0.266, 11232/28000 datapoints
2025-03-06 22:35:40,520 - INFO - training batch 401, loss: 0.628, 12832/28000 datapoints
2025-03-06 22:35:40,676 - INFO - training batch 451, loss: 0.385, 14432/28000 datapoints
2025-03-06 22:35:40,835 - INFO - training batch 501, loss: 0.182, 16032/28000 datapoints
2025-03-06 22:35:41,002 - INFO - training batch 551, loss: 0.405, 17632/28000 datapoints
2025-03-06 22:35:41,158 - INFO - training batch 601, loss: 0.406, 19232/28000 datapoints
2025-03-06 22:35:41,316 - INFO - training batch 651, loss: 0.099, 20832/28000 datapoints
2025-03-06 22:35:41,470 - INFO - training batch 701, loss: 0.292, 22432/28000 datapoints
2025-03-06 22:35:41,626 - INFO - training batch 751, loss: 0.251, 24032/28000 datapoints
2025-03-06 22:35:41,781 - INFO - training batch 801, loss: 0.150, 25632/28000 datapoints
2025-03-06 22:35:41,937 - INFO - training batch 851, loss: 0.472, 27232/28000 datapoints
2025-03-06 22:35:42,018 - INFO - validation batch 1, loss: 0.091, 32/6976 datapoints
2025-03-06 22:35:42,071 - INFO - validation batch 51, loss: 1.272, 1632/6976 datapoints
2025-03-06 22:35:42,124 - INFO - validation batch 101, loss: 0.364, 3232/6976 datapoints
2025-03-06 22:35:42,179 - INFO - validation batch 151, loss: 0.436, 4832/6976 datapoints
2025-03-06 22:35:42,231 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 22:35:42,249 - INFO - Epoch 191/800 done.
2025-03-06 22:35:42,250 - INFO - Final validation performance:
Loss: 0.546, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:35:42,250 - INFO - Beginning epoch 192/800
2025-03-06 22:35:42,255 - INFO - training batch 1, loss: 0.358, 32/28000 datapoints
2025-03-06 22:35:42,413 - INFO - training batch 51, loss: 0.151, 1632/28000 datapoints
2025-03-06 22:35:42,569 - INFO - training batch 101, loss: 0.192, 3232/28000 datapoints
2025-03-06 22:35:42,726 - INFO - training batch 151, loss: 0.554, 4832/28000 datapoints
2025-03-06 22:35:42,880 - INFO - training batch 201, loss: 0.129, 6432/28000 datapoints
2025-03-06 22:35:43,067 - INFO - training batch 251, loss: 0.469, 8032/28000 datapoints
2025-03-06 22:35:43,239 - INFO - training batch 301, loss: 0.681, 9632/28000 datapoints
2025-03-06 22:35:43,397 - INFO - training batch 351, loss: 0.265, 11232/28000 datapoints
2025-03-06 22:35:43,553 - INFO - training batch 401, loss: 0.623, 12832/28000 datapoints
2025-03-06 22:35:43,715 - INFO - training batch 451, loss: 0.383, 14432/28000 datapoints
2025-03-06 22:35:43,871 - INFO - training batch 501, loss: 0.181, 16032/28000 datapoints
2025-03-06 22:35:44,033 - INFO - training batch 551, loss: 0.403, 17632/28000 datapoints
2025-03-06 22:35:44,192 - INFO - training batch 601, loss: 0.402, 19232/28000 datapoints
2025-03-06 22:35:44,347 - INFO - training batch 651, loss: 0.098, 20832/28000 datapoints
2025-03-06 22:35:44,502 - INFO - training batch 701, loss: 0.291, 22432/28000 datapoints
2025-03-06 22:35:44,657 - INFO - training batch 751, loss: 0.248, 24032/28000 datapoints
2025-03-06 22:35:44,814 - INFO - training batch 801, loss: 0.148, 25632/28000 datapoints
2025-03-06 22:35:44,973 - INFO - training batch 851, loss: 0.468, 27232/28000 datapoints
2025-03-06 22:35:45,052 - INFO - validation batch 1, loss: 0.090, 32/6976 datapoints
2025-03-06 22:35:45,104 - INFO - validation batch 51, loss: 1.272, 1632/6976 datapoints
2025-03-06 22:35:45,159 - INFO - validation batch 101, loss: 0.364, 3232/6976 datapoints
2025-03-06 22:35:45,220 - INFO - validation batch 151, loss: 0.434, 4832/6976 datapoints
2025-03-06 22:35:45,273 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 22:35:45,293 - INFO - Epoch 192/800 done.
2025-03-06 22:35:45,293 - INFO - Final validation performance:
Loss: 0.546, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:35:45,294 - INFO - Beginning epoch 193/800
2025-03-06 22:35:45,298 - INFO - training batch 1, loss: 0.357, 32/28000 datapoints
2025-03-06 22:35:45,455 - INFO - training batch 51, loss: 0.150, 1632/28000 datapoints
2025-03-06 22:35:45,609 - INFO - training batch 101, loss: 0.191, 3232/28000 datapoints
2025-03-06 22:35:45,769 - INFO - training batch 151, loss: 0.550, 4832/28000 datapoints
2025-03-06 22:35:45,922 - INFO - training batch 201, loss: 0.127, 6432/28000 datapoints
2025-03-06 22:35:46,079 - INFO - training batch 251, loss: 0.469, 8032/28000 datapoints
2025-03-06 22:35:46,236 - INFO - training batch 301, loss: 0.679, 9632/28000 datapoints
2025-03-06 22:35:46,390 - INFO - training batch 351, loss: 0.262, 11232/28000 datapoints
2025-03-06 22:35:46,543 - INFO - training batch 401, loss: 0.618, 12832/28000 datapoints
2025-03-06 22:35:46,697 - INFO - training batch 451, loss: 0.382, 14432/28000 datapoints
2025-03-06 22:35:46,852 - INFO - training batch 501, loss: 0.180, 16032/28000 datapoints
2025-03-06 22:35:47,013 - INFO - training batch 551, loss: 0.402, 17632/28000 datapoints
2025-03-06 22:35:47,167 - INFO - training batch 601, loss: 0.399, 19232/28000 datapoints
2025-03-06 22:35:47,324 - INFO - training batch 651, loss: 0.096, 20832/28000 datapoints
2025-03-06 22:35:47,477 - INFO - training batch 701, loss: 0.290, 22432/28000 datapoints
2025-03-06 22:35:47,632 - INFO - training batch 751, loss: 0.247, 24032/28000 datapoints
2025-03-06 22:35:47,791 - INFO - training batch 801, loss: 0.147, 25632/28000 datapoints
2025-03-06 22:35:47,955 - INFO - training batch 851, loss: 0.464, 27232/28000 datapoints
2025-03-06 22:35:48,034 - INFO - validation batch 1, loss: 0.090, 32/6976 datapoints
2025-03-06 22:35:48,085 - INFO - validation batch 51, loss: 1.273, 1632/6976 datapoints
2025-03-06 22:35:48,135 - INFO - validation batch 101, loss: 0.364, 3232/6976 datapoints
2025-03-06 22:35:48,183 - INFO - validation batch 151, loss: 0.431, 4832/6976 datapoints
2025-03-06 22:35:48,231 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 22:35:48,249 - INFO - Epoch 193/800 done.
2025-03-06 22:35:48,249 - INFO - Final validation performance:
Loss: 0.545, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:35:48,250 - INFO - Beginning epoch 194/800
2025-03-06 22:35:48,254 - INFO - training batch 1, loss: 0.355, 32/28000 datapoints
2025-03-06 22:35:48,405 - INFO - training batch 51, loss: 0.148, 1632/28000 datapoints
2025-03-06 22:35:48,557 - INFO - training batch 101, loss: 0.191, 3232/28000 datapoints
2025-03-06 22:35:48,708 - INFO - training batch 151, loss: 0.545, 4832/28000 datapoints
2025-03-06 22:35:48,862 - INFO - training batch 201, loss: 0.126, 6432/28000 datapoints
2025-03-06 22:35:49,017 - INFO - training batch 251, loss: 0.470, 8032/28000 datapoints
2025-03-06 22:35:49,176 - INFO - training batch 301, loss: 0.676, 9632/28000 datapoints
2025-03-06 22:35:49,339 - INFO - training batch 351, loss: 0.261, 11232/28000 datapoints
2025-03-06 22:35:49,490 - INFO - training batch 401, loss: 0.615, 12832/28000 datapoints
2025-03-06 22:35:49,640 - INFO - training batch 451, loss: 0.381, 14432/28000 datapoints
2025-03-06 22:35:49,797 - INFO - training batch 501, loss: 0.178, 16032/28000 datapoints
2025-03-06 22:35:49,955 - INFO - training batch 551, loss: 0.400, 17632/28000 datapoints
2025-03-06 22:35:50,108 - INFO - training batch 601, loss: 0.396, 19232/28000 datapoints
2025-03-06 22:35:50,265 - INFO - training batch 651, loss: 0.095, 20832/28000 datapoints
2025-03-06 22:35:50,418 - INFO - training batch 701, loss: 0.289, 22432/28000 datapoints
2025-03-06 22:35:50,568 - INFO - training batch 751, loss: 0.247, 24032/28000 datapoints
2025-03-06 22:35:50,722 - INFO - training batch 801, loss: 0.145, 25632/28000 datapoints
2025-03-06 22:35:50,876 - INFO - training batch 851, loss: 0.460, 27232/28000 datapoints
2025-03-06 22:35:50,955 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 22:35:51,003 - INFO - validation batch 51, loss: 1.274, 1632/6976 datapoints
2025-03-06 22:35:51,060 - INFO - validation batch 101, loss: 0.364, 3232/6976 datapoints
2025-03-06 22:35:51,108 - INFO - validation batch 151, loss: 0.429, 4832/6976 datapoints
2025-03-06 22:35:51,156 - INFO - validation batch 201, loss: 0.569, 6432/6976 datapoints
2025-03-06 22:35:51,172 - INFO - Epoch 194/800 done.
2025-03-06 22:35:51,173 - INFO - Final validation performance:
Loss: 0.545, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:35:51,173 - INFO - Beginning epoch 195/800
2025-03-06 22:35:51,177 - INFO - training batch 1, loss: 0.354, 32/28000 datapoints
2025-03-06 22:35:51,334 - INFO - training batch 51, loss: 0.147, 1632/28000 datapoints
2025-03-06 22:35:51,484 - INFO - training batch 101, loss: 0.190, 3232/28000 datapoints
2025-03-06 22:35:51,638 - INFO - training batch 151, loss: 0.540, 4832/28000 datapoints
2025-03-06 22:35:51,789 - INFO - training batch 201, loss: 0.124, 6432/28000 datapoints
2025-03-06 22:35:51,944 - INFO - training batch 251, loss: 0.469, 8032/28000 datapoints
2025-03-06 22:35:52,094 - INFO - training batch 301, loss: 0.674, 9632/28000 datapoints
2025-03-06 22:35:52,247 - INFO - training batch 351, loss: 0.260, 11232/28000 datapoints
2025-03-06 22:35:52,397 - INFO - training batch 401, loss: 0.610, 12832/28000 datapoints
2025-03-06 22:35:52,548 - INFO - training batch 451, loss: 0.380, 14432/28000 datapoints
2025-03-06 22:35:52,700 - INFO - training batch 501, loss: 0.177, 16032/28000 datapoints
2025-03-06 22:35:52,852 - INFO - training batch 551, loss: 0.399, 17632/28000 datapoints
2025-03-06 22:35:53,008 - INFO - training batch 601, loss: 0.392, 19232/28000 datapoints
2025-03-06 22:35:53,190 - INFO - training batch 651, loss: 0.094, 20832/28000 datapoints
2025-03-06 22:35:53,343 - INFO - training batch 701, loss: 0.288, 22432/28000 datapoints
2025-03-06 22:35:53,492 - INFO - training batch 751, loss: 0.244, 24032/28000 datapoints
2025-03-06 22:35:53,643 - INFO - training batch 801, loss: 0.144, 25632/28000 datapoints
2025-03-06 22:35:53,794 - INFO - training batch 851, loss: 0.456, 27232/28000 datapoints
2025-03-06 22:35:53,868 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 22:35:53,915 - INFO - validation batch 51, loss: 1.274, 1632/6976 datapoints
2025-03-06 22:35:53,972 - INFO - validation batch 101, loss: 0.363, 3232/6976 datapoints
2025-03-06 22:35:54,030 - INFO - validation batch 151, loss: 0.427, 4832/6976 datapoints
2025-03-06 22:35:54,092 - INFO - validation batch 201, loss: 0.571, 6432/6976 datapoints
2025-03-06 22:35:54,113 - INFO - Epoch 195/800 done.
2025-03-06 22:35:54,113 - INFO - Final validation performance:
Loss: 0.545, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:35:54,114 - INFO - Beginning epoch 196/800
2025-03-06 22:35:54,120 - INFO - training batch 1, loss: 0.352, 32/28000 datapoints
2025-03-06 22:35:54,299 - INFO - training batch 51, loss: 0.146, 1632/28000 datapoints
2025-03-06 22:35:54,449 - INFO - training batch 101, loss: 0.189, 3232/28000 datapoints
2025-03-06 22:35:54,601 - INFO - training batch 151, loss: 0.533, 4832/28000 datapoints
2025-03-06 22:35:54,752 - INFO - training batch 201, loss: 0.122, 6432/28000 datapoints
2025-03-06 22:35:54,903 - INFO - training batch 251, loss: 0.469, 8032/28000 datapoints
2025-03-06 22:35:55,058 - INFO - training batch 301, loss: 0.673, 9632/28000 datapoints
2025-03-06 22:35:55,215 - INFO - training batch 351, loss: 0.258, 11232/28000 datapoints
2025-03-06 22:35:55,386 - INFO - training batch 401, loss: 0.606, 12832/28000 datapoints
2025-03-06 22:35:55,535 - INFO - training batch 451, loss: 0.379, 14432/28000 datapoints
2025-03-06 22:35:55,690 - INFO - training batch 501, loss: 0.176, 16032/28000 datapoints
2025-03-06 22:35:55,848 - INFO - training batch 551, loss: 0.397, 17632/28000 datapoints
2025-03-06 22:35:56,007 - INFO - training batch 601, loss: 0.389, 19232/28000 datapoints
2025-03-06 22:35:56,159 - INFO - training batch 651, loss: 0.093, 20832/28000 datapoints
2025-03-06 22:35:56,320 - INFO - training batch 701, loss: 0.287, 22432/28000 datapoints
2025-03-06 22:35:56,470 - INFO - training batch 751, loss: 0.244, 24032/28000 datapoints
2025-03-06 22:35:56,620 - INFO - training batch 801, loss: 0.143, 25632/28000 datapoints
2025-03-06 22:35:56,771 - INFO - training batch 851, loss: 0.454, 27232/28000 datapoints
2025-03-06 22:35:56,845 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 22:35:56,893 - INFO - validation batch 51, loss: 1.275, 1632/6976 datapoints
2025-03-06 22:35:56,942 - INFO - validation batch 101, loss: 0.363, 3232/6976 datapoints
2025-03-06 22:35:56,994 - INFO - validation batch 151, loss: 0.426, 4832/6976 datapoints
2025-03-06 22:35:57,047 - INFO - validation batch 201, loss: 0.571, 6432/6976 datapoints
2025-03-06 22:35:57,063 - INFO - Epoch 196/800 done.
2025-03-06 22:35:57,063 - INFO - Final validation performance:
Loss: 0.545, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:35:57,064 - INFO - Beginning epoch 197/800
2025-03-06 22:35:57,068 - INFO - training batch 1, loss: 0.351, 32/28000 datapoints
2025-03-06 22:35:57,222 - INFO - training batch 51, loss: 0.144, 1632/28000 datapoints
2025-03-06 22:35:57,376 - INFO - training batch 101, loss: 0.188, 3232/28000 datapoints
2025-03-06 22:35:57,526 - INFO - training batch 151, loss: 0.529, 4832/28000 datapoints
2025-03-06 22:35:57,679 - INFO - training batch 201, loss: 0.122, 6432/28000 datapoints
2025-03-06 22:35:57,830 - INFO - training batch 251, loss: 0.468, 8032/28000 datapoints
2025-03-06 22:35:57,984 - INFO - training batch 301, loss: 0.671, 9632/28000 datapoints
2025-03-06 22:35:58,138 - INFO - training batch 351, loss: 0.256, 11232/28000 datapoints
2025-03-06 22:35:58,291 - INFO - training batch 401, loss: 0.602, 12832/28000 datapoints
2025-03-06 22:35:58,444 - INFO - training batch 451, loss: 0.377, 14432/28000 datapoints
2025-03-06 22:35:58,596 - INFO - training batch 501, loss: 0.175, 16032/28000 datapoints
2025-03-06 22:35:58,746 - INFO - training batch 551, loss: 0.395, 17632/28000 datapoints
2025-03-06 22:35:58,898 - INFO - training batch 601, loss: 0.385, 19232/28000 datapoints
2025-03-06 22:35:59,054 - INFO - training batch 651, loss: 0.092, 20832/28000 datapoints
2025-03-06 22:35:59,206 - INFO - training batch 701, loss: 0.287, 22432/28000 datapoints
2025-03-06 22:35:59,358 - INFO - training batch 751, loss: 0.242, 24032/28000 datapoints
2025-03-06 22:35:59,513 - INFO - training batch 801, loss: 0.141, 25632/28000 datapoints
2025-03-06 22:35:59,669 - INFO - training batch 851, loss: 0.450, 27232/28000 datapoints
2025-03-06 22:35:59,746 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 22:35:59,798 - INFO - validation batch 51, loss: 1.277, 1632/6976 datapoints
2025-03-06 22:35:59,849 - INFO - validation batch 101, loss: 0.363, 3232/6976 datapoints
2025-03-06 22:35:59,902 - INFO - validation batch 151, loss: 0.423, 4832/6976 datapoints
2025-03-06 22:35:59,955 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 22:35:59,971 - INFO - Epoch 197/800 done.
2025-03-06 22:35:59,972 - INFO - Final validation performance:
Loss: 0.544, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:35:59,972 - INFO - Beginning epoch 198/800
2025-03-06 22:35:59,977 - INFO - training batch 1, loss: 0.349, 32/28000 datapoints
2025-03-06 22:36:00,135 - INFO - training batch 51, loss: 0.143, 1632/28000 datapoints
2025-03-06 22:36:00,297 - INFO - training batch 101, loss: 0.187, 3232/28000 datapoints
2025-03-06 22:36:00,456 - INFO - training batch 151, loss: 0.524, 4832/28000 datapoints
2025-03-06 22:36:00,609 - INFO - training batch 201, loss: 0.120, 6432/28000 datapoints
2025-03-06 22:36:00,764 - INFO - training batch 251, loss: 0.467, 8032/28000 datapoints
2025-03-06 22:36:00,928 - INFO - training batch 301, loss: 0.669, 9632/28000 datapoints
2025-03-06 22:36:01,089 - INFO - training batch 351, loss: 0.255, 11232/28000 datapoints
2025-03-06 22:36:01,246 - INFO - training batch 401, loss: 0.598, 12832/28000 datapoints
2025-03-06 22:36:01,417 - INFO - training batch 451, loss: 0.375, 14432/28000 datapoints
2025-03-06 22:36:01,573 - INFO - training batch 501, loss: 0.174, 16032/28000 datapoints
2025-03-06 22:36:01,727 - INFO - training batch 551, loss: 0.394, 17632/28000 datapoints
2025-03-06 22:36:01,889 - INFO - training batch 601, loss: 0.381, 19232/28000 datapoints
2025-03-06 22:36:02,050 - INFO - training batch 651, loss: 0.091, 20832/28000 datapoints
2025-03-06 22:36:02,209 - INFO - training batch 701, loss: 0.286, 22432/28000 datapoints
2025-03-06 22:36:02,368 - INFO - training batch 751, loss: 0.241, 24032/28000 datapoints
2025-03-06 22:36:02,522 - INFO - training batch 801, loss: 0.140, 25632/28000 datapoints
2025-03-06 22:36:02,681 - INFO - training batch 851, loss: 0.447, 27232/28000 datapoints
2025-03-06 22:36:02,759 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 22:36:02,811 - INFO - validation batch 51, loss: 1.277, 1632/6976 datapoints
2025-03-06 22:36:02,863 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 22:36:02,918 - INFO - validation batch 151, loss: 0.421, 4832/6976 datapoints
2025-03-06 22:36:02,977 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 22:36:02,998 - INFO - Epoch 198/800 done.
2025-03-06 22:36:02,998 - INFO - Final validation performance:
Loss: 0.544, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:02,999 - INFO - Beginning epoch 199/800
2025-03-06 22:36:03,003 - INFO - training batch 1, loss: 0.347, 32/28000 datapoints
2025-03-06 22:36:03,166 - INFO - training batch 51, loss: 0.142, 1632/28000 datapoints
2025-03-06 22:36:03,342 - INFO - training batch 101, loss: 0.186, 3232/28000 datapoints
2025-03-06 22:36:03,499 - INFO - training batch 151, loss: 0.520, 4832/28000 datapoints
2025-03-06 22:36:03,656 - INFO - training batch 201, loss: 0.119, 6432/28000 datapoints
2025-03-06 22:36:03,813 - INFO - training batch 251, loss: 0.466, 8032/28000 datapoints
2025-03-06 22:36:03,971 - INFO - training batch 301, loss: 0.667, 9632/28000 datapoints
2025-03-06 22:36:04,124 - INFO - training batch 351, loss: 0.254, 11232/28000 datapoints
2025-03-06 22:36:04,281 - INFO - training batch 401, loss: 0.594, 12832/28000 datapoints
2025-03-06 22:36:04,436 - INFO - training batch 451, loss: 0.374, 14432/28000 datapoints
2025-03-06 22:36:04,590 - INFO - training batch 501, loss: 0.172, 16032/28000 datapoints
2025-03-06 22:36:04,744 - INFO - training batch 551, loss: 0.392, 17632/28000 datapoints
2025-03-06 22:36:04,898 - INFO - training batch 601, loss: 0.378, 19232/28000 datapoints
2025-03-06 22:36:05,060 - INFO - training batch 651, loss: 0.090, 20832/28000 datapoints
2025-03-06 22:36:05,222 - INFO - training batch 701, loss: 0.285, 22432/28000 datapoints
2025-03-06 22:36:05,378 - INFO - training batch 751, loss: 0.238, 24032/28000 datapoints
2025-03-06 22:36:05,533 - INFO - training batch 801, loss: 0.139, 25632/28000 datapoints
2025-03-06 22:36:05,690 - INFO - training batch 851, loss: 0.442, 27232/28000 datapoints
2025-03-06 22:36:05,767 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 22:36:05,820 - INFO - validation batch 51, loss: 1.277, 1632/6976 datapoints
2025-03-06 22:36:05,871 - INFO - validation batch 101, loss: 0.363, 3232/6976 datapoints
2025-03-06 22:36:05,927 - INFO - validation batch 151, loss: 0.416, 4832/6976 datapoints
2025-03-06 22:36:05,980 - INFO - validation batch 201, loss: 0.573, 6432/6976 datapoints
2025-03-06 22:36:06,000 - INFO - Epoch 199/800 done.
2025-03-06 22:36:06,001 - INFO - Final validation performance:
Loss: 0.543, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:06,001 - INFO - Beginning epoch 200/800
2025-03-06 22:36:06,006 - INFO - training batch 1, loss: 0.346, 32/28000 datapoints
2025-03-06 22:36:06,163 - INFO - training batch 51, loss: 0.141, 1632/28000 datapoints
2025-03-06 22:36:06,319 - INFO - training batch 101, loss: 0.185, 3232/28000 datapoints
2025-03-06 22:36:06,477 - INFO - training batch 151, loss: 0.515, 4832/28000 datapoints
2025-03-06 22:36:06,632 - INFO - training batch 201, loss: 0.118, 6432/28000 datapoints
2025-03-06 22:36:06,789 - INFO - training batch 251, loss: 0.465, 8032/28000 datapoints
2025-03-06 22:36:06,945 - INFO - training batch 301, loss: 0.666, 9632/28000 datapoints
2025-03-06 22:36:07,104 - INFO - training batch 351, loss: 0.253, 11232/28000 datapoints
2025-03-06 22:36:07,259 - INFO - training batch 401, loss: 0.590, 12832/28000 datapoints
2025-03-06 22:36:07,424 - INFO - training batch 451, loss: 0.373, 14432/28000 datapoints
2025-03-06 22:36:07,582 - INFO - training batch 501, loss: 0.171, 16032/28000 datapoints
2025-03-06 22:36:07,738 - INFO - training batch 551, loss: 0.390, 17632/28000 datapoints
2025-03-06 22:36:07,903 - INFO - training batch 601, loss: 0.374, 19232/28000 datapoints
2025-03-06 22:36:08,069 - INFO - training batch 651, loss: 0.089, 20832/28000 datapoints
2025-03-06 22:36:08,224 - INFO - training batch 701, loss: 0.284, 22432/28000 datapoints
2025-03-06 22:36:08,382 - INFO - training batch 751, loss: 0.238, 24032/28000 datapoints
2025-03-06 22:36:08,536 - INFO - training batch 801, loss: 0.137, 25632/28000 datapoints
2025-03-06 22:36:08,689 - INFO - training batch 851, loss: 0.438, 27232/28000 datapoints
2025-03-06 22:36:08,767 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 22:36:08,820 - INFO - validation batch 51, loss: 1.278, 1632/6976 datapoints
2025-03-06 22:36:08,872 - INFO - validation batch 101, loss: 0.363, 3232/6976 datapoints
2025-03-06 22:36:08,922 - INFO - validation batch 151, loss: 0.412, 4832/6976 datapoints
2025-03-06 22:36:08,979 - INFO - validation batch 201, loss: 0.575, 6432/6976 datapoints
2025-03-06 22:36:08,999 - INFO - Epoch 200/800 done.
2025-03-06 22:36:09,000 - INFO - Final validation performance:
Loss: 0.543, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:09,000 - INFO - Beginning epoch 201/800
2025-03-06 22:36:09,007 - INFO - training batch 1, loss: 0.346, 32/28000 datapoints
2025-03-06 22:36:09,163 - INFO - training batch 51, loss: 0.139, 1632/28000 datapoints
2025-03-06 22:36:09,320 - INFO - training batch 101, loss: 0.184, 3232/28000 datapoints
2025-03-06 22:36:09,481 - INFO - training batch 151, loss: 0.509, 4832/28000 datapoints
2025-03-06 22:36:09,638 - INFO - training batch 201, loss: 0.117, 6432/28000 datapoints
2025-03-06 22:36:09,792 - INFO - training batch 251, loss: 0.464, 8032/28000 datapoints
2025-03-06 22:36:09,950 - INFO - training batch 301, loss: 0.663, 9632/28000 datapoints
2025-03-06 22:36:10,105 - INFO - training batch 351, loss: 0.251, 11232/28000 datapoints
2025-03-06 22:36:10,261 - INFO - training batch 401, loss: 0.586, 12832/28000 datapoints
2025-03-06 22:36:10,418 - INFO - training batch 451, loss: 0.371, 14432/28000 datapoints
2025-03-06 22:36:10,573 - INFO - training batch 501, loss: 0.170, 16032/28000 datapoints
2025-03-06 22:36:10,727 - INFO - training batch 551, loss: 0.389, 17632/28000 datapoints
2025-03-06 22:36:10,886 - INFO - training batch 601, loss: 0.372, 19232/28000 datapoints
2025-03-06 22:36:11,047 - INFO - training batch 651, loss: 0.087, 20832/28000 datapoints
2025-03-06 22:36:11,201 - INFO - training batch 701, loss: 0.283, 22432/28000 datapoints
2025-03-06 22:36:11,360 - INFO - training batch 751, loss: 0.235, 24032/28000 datapoints
2025-03-06 22:36:11,516 - INFO - training batch 801, loss: 0.136, 25632/28000 datapoints
2025-03-06 22:36:11,670 - INFO - training batch 851, loss: 0.435, 27232/28000 datapoints
2025-03-06 22:36:11,750 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 22:36:11,802 - INFO - validation batch 51, loss: 1.278, 1632/6976 datapoints
2025-03-06 22:36:11,853 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 22:36:11,906 - INFO - validation batch 151, loss: 0.411, 4832/6976 datapoints
2025-03-06 22:36:11,961 - INFO - validation batch 201, loss: 0.575, 6432/6976 datapoints
2025-03-06 22:36:11,980 - INFO - Epoch 201/800 done.
2025-03-06 22:36:11,980 - INFO - Final validation performance:
Loss: 0.542, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:36:11,981 - INFO - Beginning epoch 202/800
2025-03-06 22:36:11,988 - INFO - training batch 1, loss: 0.345, 32/28000 datapoints
2025-03-06 22:36:12,146 - INFO - training batch 51, loss: 0.139, 1632/28000 datapoints
2025-03-06 22:36:12,303 - INFO - training batch 101, loss: 0.183, 3232/28000 datapoints
2025-03-06 22:36:12,458 - INFO - training batch 151, loss: 0.504, 4832/28000 datapoints
2025-03-06 22:36:12,615 - INFO - training batch 201, loss: 0.116, 6432/28000 datapoints
2025-03-06 22:36:12,770 - INFO - training batch 251, loss: 0.463, 8032/28000 datapoints
2025-03-06 22:36:12,925 - INFO - training batch 301, loss: 0.663, 9632/28000 datapoints
2025-03-06 22:36:13,085 - INFO - training batch 351, loss: 0.249, 11232/28000 datapoints
2025-03-06 22:36:13,241 - INFO - training batch 401, loss: 0.581, 12832/28000 datapoints
2025-03-06 22:36:13,420 - INFO - training batch 451, loss: 0.370, 14432/28000 datapoints
2025-03-06 22:36:13,591 - INFO - training batch 501, loss: 0.170, 16032/28000 datapoints
2025-03-06 22:36:13,747 - INFO - training batch 551, loss: 0.387, 17632/28000 datapoints
2025-03-06 22:36:13,909 - INFO - training batch 601, loss: 0.369, 19232/28000 datapoints
2025-03-06 22:36:14,071 - INFO - training batch 651, loss: 0.086, 20832/28000 datapoints
2025-03-06 22:36:14,228 - INFO - training batch 701, loss: 0.283, 22432/28000 datapoints
2025-03-06 22:36:14,386 - INFO - training batch 751, loss: 0.236, 24032/28000 datapoints
2025-03-06 22:36:14,545 - INFO - training batch 801, loss: 0.135, 25632/28000 datapoints
2025-03-06 22:36:14,699 - INFO - training batch 851, loss: 0.431, 27232/28000 datapoints
2025-03-06 22:36:14,777 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 22:36:14,831 - INFO - validation batch 51, loss: 1.278, 1632/6976 datapoints
2025-03-06 22:36:14,882 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 22:36:14,930 - INFO - validation batch 151, loss: 0.409, 4832/6976 datapoints
2025-03-06 22:36:14,980 - INFO - validation batch 201, loss: 0.575, 6432/6976 datapoints
2025-03-06 22:36:14,996 - INFO - Epoch 202/800 done.
2025-03-06 22:36:14,996 - INFO - Final validation performance:
Loss: 0.542, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:36:14,997 - INFO - Beginning epoch 203/800
2025-03-06 22:36:15,001 - INFO - training batch 1, loss: 0.344, 32/28000 datapoints
2025-03-06 22:36:15,159 - INFO - training batch 51, loss: 0.137, 1632/28000 datapoints
2025-03-06 22:36:15,316 - INFO - training batch 101, loss: 0.182, 3232/28000 datapoints
2025-03-06 22:36:15,468 - INFO - training batch 151, loss: 0.499, 4832/28000 datapoints
2025-03-06 22:36:15,623 - INFO - training batch 201, loss: 0.115, 6432/28000 datapoints
2025-03-06 22:36:15,775 - INFO - training batch 251, loss: 0.462, 8032/28000 datapoints
2025-03-06 22:36:15,925 - INFO - training batch 301, loss: 0.661, 9632/28000 datapoints
2025-03-06 22:36:16,079 - INFO - training batch 351, loss: 0.248, 11232/28000 datapoints
2025-03-06 22:36:16,230 - INFO - training batch 401, loss: 0.577, 12832/28000 datapoints
2025-03-06 22:36:16,380 - INFO - training batch 451, loss: 0.369, 14432/28000 datapoints
2025-03-06 22:36:16,529 - INFO - training batch 501, loss: 0.169, 16032/28000 datapoints
2025-03-06 22:36:16,684 - INFO - training batch 551, loss: 0.385, 17632/28000 datapoints
2025-03-06 22:36:16,837 - INFO - training batch 601, loss: 0.366, 19232/28000 datapoints
2025-03-06 22:36:16,990 - INFO - training batch 651, loss: 0.085, 20832/28000 datapoints
2025-03-06 22:36:17,145 - INFO - training batch 701, loss: 0.282, 22432/28000 datapoints
2025-03-06 22:36:17,297 - INFO - training batch 751, loss: 0.232, 24032/28000 datapoints
2025-03-06 22:36:17,448 - INFO - training batch 801, loss: 0.134, 25632/28000 datapoints
2025-03-06 22:36:17,599 - INFO - training batch 851, loss: 0.427, 27232/28000 datapoints
2025-03-06 22:36:17,674 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 22:36:17,721 - INFO - validation batch 51, loss: 1.278, 1632/6976 datapoints
2025-03-06 22:36:17,768 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 22:36:17,816 - INFO - validation batch 151, loss: 0.408, 4832/6976 datapoints
2025-03-06 22:36:17,862 - INFO - validation batch 201, loss: 0.576, 6432/6976 datapoints
2025-03-06 22:36:17,879 - INFO - Epoch 203/800 done.
2025-03-06 22:36:17,879 - INFO - Final validation performance:
Loss: 0.541, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:17,879 - INFO - Beginning epoch 204/800
2025-03-06 22:36:17,883 - INFO - training batch 1, loss: 0.343, 32/28000 datapoints
2025-03-06 22:36:18,039 - INFO - training batch 51, loss: 0.137, 1632/28000 datapoints
2025-03-06 22:36:18,193 - INFO - training batch 101, loss: 0.182, 3232/28000 datapoints
2025-03-06 22:36:18,344 - INFO - training batch 151, loss: 0.494, 4832/28000 datapoints
2025-03-06 22:36:18,496 - INFO - training batch 201, loss: 0.113, 6432/28000 datapoints
2025-03-06 22:36:18,647 - INFO - training batch 251, loss: 0.461, 8032/28000 datapoints
2025-03-06 22:36:18,797 - INFO - training batch 301, loss: 0.659, 9632/28000 datapoints
2025-03-06 22:36:18,949 - INFO - training batch 351, loss: 0.246, 11232/28000 datapoints
2025-03-06 22:36:19,106 - INFO - training batch 401, loss: 0.574, 12832/28000 datapoints
2025-03-06 22:36:19,258 - INFO - training batch 451, loss: 0.367, 14432/28000 datapoints
2025-03-06 22:36:19,411 - INFO - training batch 501, loss: 0.168, 16032/28000 datapoints
2025-03-06 22:36:19,562 - INFO - training batch 551, loss: 0.383, 17632/28000 datapoints
2025-03-06 22:36:19,736 - INFO - training batch 601, loss: 0.363, 19232/28000 datapoints
2025-03-06 22:36:19,891 - INFO - training batch 651, loss: 0.084, 20832/28000 datapoints
2025-03-06 22:36:20,044 - INFO - training batch 701, loss: 0.281, 22432/28000 datapoints
2025-03-06 22:36:20,205 - INFO - training batch 751, loss: 0.232, 24032/28000 datapoints
2025-03-06 22:36:20,359 - INFO - training batch 801, loss: 0.132, 25632/28000 datapoints
2025-03-06 22:36:20,513 - INFO - training batch 851, loss: 0.424, 27232/28000 datapoints
2025-03-06 22:36:20,587 - INFO - validation batch 1, loss: 0.083, 32/6976 datapoints
2025-03-06 22:36:20,635 - INFO - validation batch 51, loss: 1.278, 1632/6976 datapoints
2025-03-06 22:36:20,682 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 22:36:20,730 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 22:36:20,778 - INFO - validation batch 201, loss: 0.576, 6432/6976 datapoints
2025-03-06 22:36:20,794 - INFO - Epoch 204/800 done.
2025-03-06 22:36:20,794 - INFO - Final validation performance:
Loss: 0.541, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:20,795 - INFO - Beginning epoch 205/800
2025-03-06 22:36:20,799 - INFO - training batch 1, loss: 0.342, 32/28000 datapoints
2025-03-06 22:36:20,967 - INFO - training batch 51, loss: 0.135, 1632/28000 datapoints
2025-03-06 22:36:21,132 - INFO - training batch 101, loss: 0.181, 3232/28000 datapoints
2025-03-06 22:36:21,285 - INFO - training batch 151, loss: 0.487, 4832/28000 datapoints
2025-03-06 22:36:21,438 - INFO - training batch 201, loss: 0.113, 6432/28000 datapoints
2025-03-06 22:36:21,589 - INFO - training batch 251, loss: 0.461, 8032/28000 datapoints
2025-03-06 22:36:21,741 - INFO - training batch 301, loss: 0.658, 9632/28000 datapoints
2025-03-06 22:36:21,896 - INFO - training batch 351, loss: 0.245, 11232/28000 datapoints
2025-03-06 22:36:22,049 - INFO - training batch 401, loss: 0.570, 12832/28000 datapoints
2025-03-06 22:36:22,202 - INFO - training batch 451, loss: 0.366, 14432/28000 datapoints
2025-03-06 22:36:22,354 - INFO - training batch 501, loss: 0.167, 16032/28000 datapoints
2025-03-06 22:36:22,505 - INFO - training batch 551, loss: 0.381, 17632/28000 datapoints
2025-03-06 22:36:22,656 - INFO - training batch 601, loss: 0.359, 19232/28000 datapoints
2025-03-06 22:36:22,808 - INFO - training batch 651, loss: 0.083, 20832/28000 datapoints
2025-03-06 22:36:22,963 - INFO - training batch 701, loss: 0.280, 22432/28000 datapoints
2025-03-06 22:36:23,115 - INFO - training batch 751, loss: 0.230, 24032/28000 datapoints
2025-03-06 22:36:23,266 - INFO - training batch 801, loss: 0.131, 25632/28000 datapoints
2025-03-06 22:36:23,445 - INFO - training batch 851, loss: 0.417, 27232/28000 datapoints
2025-03-06 22:36:23,521 - INFO - validation batch 1, loss: 0.083, 32/6976 datapoints
2025-03-06 22:36:23,570 - INFO - validation batch 51, loss: 1.279, 1632/6976 datapoints
2025-03-06 22:36:23,617 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 22:36:23,666 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 22:36:23,715 - INFO - validation batch 201, loss: 0.578, 6432/6976 datapoints
2025-03-06 22:36:23,731 - INFO - Epoch 205/800 done.
2025-03-06 22:36:23,732 - INFO - Final validation performance:
Loss: 0.541, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:23,732 - INFO - Beginning epoch 206/800
2025-03-06 22:36:23,736 - INFO - training batch 1, loss: 0.340, 32/28000 datapoints
2025-03-06 22:36:23,891 - INFO - training batch 51, loss: 0.134, 1632/28000 datapoints
2025-03-06 22:36:24,045 - INFO - training batch 101, loss: 0.180, 3232/28000 datapoints
2025-03-06 22:36:24,198 - INFO - training batch 151, loss: 0.483, 4832/28000 datapoints
2025-03-06 22:36:24,351 - INFO - training batch 201, loss: 0.112, 6432/28000 datapoints
2025-03-06 22:36:24,501 - INFO - training batch 251, loss: 0.460, 8032/28000 datapoints
2025-03-06 22:36:24,652 - INFO - training batch 301, loss: 0.655, 9632/28000 datapoints
2025-03-06 22:36:24,802 - INFO - training batch 351, loss: 0.244, 11232/28000 datapoints
2025-03-06 22:36:24,957 - INFO - training batch 401, loss: 0.566, 12832/28000 datapoints
2025-03-06 22:36:25,111 - INFO - training batch 451, loss: 0.365, 14432/28000 datapoints
2025-03-06 22:36:25,268 - INFO - training batch 501, loss: 0.166, 16032/28000 datapoints
2025-03-06 22:36:25,422 - INFO - training batch 551, loss: 0.380, 17632/28000 datapoints
2025-03-06 22:36:25,573 - INFO - training batch 601, loss: 0.355, 19232/28000 datapoints
2025-03-06 22:36:25,734 - INFO - training batch 651, loss: 0.082, 20832/28000 datapoints
2025-03-06 22:36:25,893 - INFO - training batch 701, loss: 0.279, 22432/28000 datapoints
2025-03-06 22:36:26,045 - INFO - training batch 751, loss: 0.230, 24032/28000 datapoints
2025-03-06 22:36:26,197 - INFO - training batch 801, loss: 0.130, 25632/28000 datapoints
2025-03-06 22:36:26,356 - INFO - training batch 851, loss: 0.414, 27232/28000 datapoints
2025-03-06 22:36:26,433 - INFO - validation batch 1, loss: 0.082, 32/6976 datapoints
2025-03-06 22:36:26,481 - INFO - validation batch 51, loss: 1.280, 1632/6976 datapoints
2025-03-06 22:36:26,528 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 22:36:26,577 - INFO - validation batch 151, loss: 0.404, 4832/6976 datapoints
2025-03-06 22:36:26,626 - INFO - validation batch 201, loss: 0.579, 6432/6976 datapoints
2025-03-06 22:36:26,646 - INFO - Epoch 206/800 done.
2025-03-06 22:36:26,646 - INFO - Final validation performance:
Loss: 0.541, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:26,647 - INFO - Beginning epoch 207/800
2025-03-06 22:36:26,651 - INFO - training batch 1, loss: 0.339, 32/28000 datapoints
2025-03-06 22:36:26,818 - INFO - training batch 51, loss: 0.132, 1632/28000 datapoints
2025-03-06 22:36:26,975 - INFO - training batch 101, loss: 0.179, 3232/28000 datapoints
2025-03-06 22:36:27,131 - INFO - training batch 151, loss: 0.479, 4832/28000 datapoints
2025-03-06 22:36:27,284 - INFO - training batch 201, loss: 0.111, 6432/28000 datapoints
2025-03-06 22:36:27,437 - INFO - training batch 251, loss: 0.460, 8032/28000 datapoints
2025-03-06 22:36:27,598 - INFO - training batch 301, loss: 0.653, 9632/28000 datapoints
2025-03-06 22:36:27,750 - INFO - training batch 351, loss: 0.243, 11232/28000 datapoints
2025-03-06 22:36:27,909 - INFO - training batch 401, loss: 0.562, 12832/28000 datapoints
2025-03-06 22:36:28,063 - INFO - training batch 451, loss: 0.363, 14432/28000 datapoints
2025-03-06 22:36:28,216 - INFO - training batch 501, loss: 0.165, 16032/28000 datapoints
2025-03-06 22:36:28,369 - INFO - training batch 551, loss: 0.378, 17632/28000 datapoints
2025-03-06 22:36:28,520 - INFO - training batch 601, loss: 0.352, 19232/28000 datapoints
2025-03-06 22:36:28,671 - INFO - training batch 651, loss: 0.081, 20832/28000 datapoints
2025-03-06 22:36:28,822 - INFO - training batch 701, loss: 0.279, 22432/28000 datapoints
2025-03-06 22:36:28,975 - INFO - training batch 751, loss: 0.228, 24032/28000 datapoints
2025-03-06 22:36:29,127 - INFO - training batch 801, loss: 0.129, 25632/28000 datapoints
2025-03-06 22:36:29,278 - INFO - training batch 851, loss: 0.410, 27232/28000 datapoints
2025-03-06 22:36:29,353 - INFO - validation batch 1, loss: 0.082, 32/6976 datapoints
2025-03-06 22:36:29,401 - INFO - validation batch 51, loss: 1.281, 1632/6976 datapoints
2025-03-06 22:36:29,448 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 22:36:29,495 - INFO - validation batch 151, loss: 0.403, 4832/6976 datapoints
2025-03-06 22:36:29,543 - INFO - validation batch 201, loss: 0.580, 6432/6976 datapoints
2025-03-06 22:36:29,559 - INFO - Epoch 207/800 done.
2025-03-06 22:36:29,560 - INFO - Final validation performance:
Loss: 0.541, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:29,560 - INFO - Beginning epoch 208/800
2025-03-06 22:36:29,564 - INFO - training batch 1, loss: 0.338, 32/28000 datapoints
2025-03-06 22:36:29,715 - INFO - training batch 51, loss: 0.132, 1632/28000 datapoints
2025-03-06 22:36:29,870 - INFO - training batch 101, loss: 0.178, 3232/28000 datapoints
2025-03-06 22:36:30,023 - INFO - training batch 151, loss: 0.473, 4832/28000 datapoints
2025-03-06 22:36:30,176 - INFO - training batch 201, loss: 0.110, 6432/28000 datapoints
2025-03-06 22:36:30,330 - INFO - training batch 251, loss: 0.459, 8032/28000 datapoints
2025-03-06 22:36:30,487 - INFO - training batch 301, loss: 0.652, 9632/28000 datapoints
2025-03-06 22:36:30,643 - INFO - training batch 351, loss: 0.242, 11232/28000 datapoints
2025-03-06 22:36:30,794 - INFO - training batch 401, loss: 0.558, 12832/28000 datapoints
2025-03-06 22:36:30,953 - INFO - training batch 451, loss: 0.363, 14432/28000 datapoints
2025-03-06 22:36:31,130 - INFO - training batch 501, loss: 0.164, 16032/28000 datapoints
2025-03-06 22:36:31,283 - INFO - training batch 551, loss: 0.376, 17632/28000 datapoints
2025-03-06 22:36:31,436 - INFO - training batch 601, loss: 0.348, 19232/28000 datapoints
2025-03-06 22:36:31,612 - INFO - training batch 651, loss: 0.080, 20832/28000 datapoints
2025-03-06 22:36:31,783 - INFO - training batch 701, loss: 0.277, 22432/28000 datapoints
2025-03-06 22:36:31,952 - INFO - training batch 751, loss: 0.225, 24032/28000 datapoints
2025-03-06 22:36:32,104 - INFO - training batch 801, loss: 0.128, 25632/28000 datapoints
2025-03-06 22:36:32,260 - INFO - training batch 851, loss: 0.406, 27232/28000 datapoints
2025-03-06 22:36:32,349 - INFO - validation batch 1, loss: 0.081, 32/6976 datapoints
2025-03-06 22:36:32,405 - INFO - validation batch 51, loss: 1.282, 1632/6976 datapoints
2025-03-06 22:36:32,456 - INFO - validation batch 101, loss: 0.361, 3232/6976 datapoints
2025-03-06 22:36:32,504 - INFO - validation batch 151, loss: 0.403, 4832/6976 datapoints
2025-03-06 22:36:32,554 - INFO - validation batch 201, loss: 0.581, 6432/6976 datapoints
2025-03-06 22:36:32,570 - INFO - Epoch 208/800 done.
2025-03-06 22:36:32,570 - INFO - Final validation performance:
Loss: 0.542, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:32,571 - INFO - Beginning epoch 209/800
2025-03-06 22:36:32,575 - INFO - training batch 1, loss: 0.336, 32/28000 datapoints
2025-03-06 22:36:32,730 - INFO - training batch 51, loss: 0.131, 1632/28000 datapoints
2025-03-06 22:36:32,885 - INFO - training batch 101, loss: 0.178, 3232/28000 datapoints
2025-03-06 22:36:33,039 - INFO - training batch 151, loss: 0.468, 4832/28000 datapoints
2025-03-06 22:36:33,195 - INFO - training batch 201, loss: 0.109, 6432/28000 datapoints
2025-03-06 22:36:33,349 - INFO - training batch 251, loss: 0.458, 8032/28000 datapoints
2025-03-06 22:36:33,526 - INFO - training batch 301, loss: 0.649, 9632/28000 datapoints
2025-03-06 22:36:33,680 - INFO - training batch 351, loss: 0.242, 11232/28000 datapoints
2025-03-06 22:36:33,831 - INFO - training batch 401, loss: 0.554, 12832/28000 datapoints
2025-03-06 22:36:33,984 - INFO - training batch 451, loss: 0.362, 14432/28000 datapoints
2025-03-06 22:36:34,135 - INFO - training batch 501, loss: 0.163, 16032/28000 datapoints
2025-03-06 22:36:34,287 - INFO - training batch 551, loss: 0.374, 17632/28000 datapoints
2025-03-06 22:36:34,441 - INFO - training batch 601, loss: 0.345, 19232/28000 datapoints
2025-03-06 22:36:34,593 - INFO - training batch 651, loss: 0.079, 20832/28000 datapoints
2025-03-06 22:36:34,745 - INFO - training batch 701, loss: 0.277, 22432/28000 datapoints
2025-03-06 22:36:34,898 - INFO - training batch 751, loss: 0.226, 24032/28000 datapoints
2025-03-06 22:36:35,050 - INFO - training batch 801, loss: 0.127, 25632/28000 datapoints
2025-03-06 22:36:35,206 - INFO - training batch 851, loss: 0.402, 27232/28000 datapoints
2025-03-06 22:36:35,283 - INFO - validation batch 1, loss: 0.081, 32/6976 datapoints
2025-03-06 22:36:35,331 - INFO - validation batch 51, loss: 1.283, 1632/6976 datapoints
2025-03-06 22:36:35,380 - INFO - validation batch 101, loss: 0.361, 3232/6976 datapoints
2025-03-06 22:36:35,429 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 22:36:35,476 - INFO - validation batch 201, loss: 0.582, 6432/6976 datapoints
2025-03-06 22:36:35,492 - INFO - Epoch 209/800 done.
2025-03-06 22:36:35,492 - INFO - Final validation performance:
Loss: 0.542, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:36:35,493 - INFO - Beginning epoch 210/800
2025-03-06 22:36:35,498 - INFO - training batch 1, loss: 0.335, 32/28000 datapoints
2025-03-06 22:36:35,653 - INFO - training batch 51, loss: 0.128, 1632/28000 datapoints
2025-03-06 22:36:35,808 - INFO - training batch 101, loss: 0.177, 3232/28000 datapoints
2025-03-06 22:36:35,962 - INFO - training batch 151, loss: 0.463, 4832/28000 datapoints
2025-03-06 22:36:36,113 - INFO - training batch 201, loss: 0.108, 6432/28000 datapoints
2025-03-06 22:36:36,263 - INFO - training batch 251, loss: 0.457, 8032/28000 datapoints
2025-03-06 22:36:36,415 - INFO - training batch 301, loss: 0.649, 9632/28000 datapoints
2025-03-06 22:36:36,567 - INFO - training batch 351, loss: 0.240, 11232/28000 datapoints
2025-03-06 22:36:36,718 - INFO - training batch 401, loss: 0.550, 12832/28000 datapoints
2025-03-06 22:36:36,870 - INFO - training batch 451, loss: 0.360, 14432/28000 datapoints
2025-03-06 22:36:37,023 - INFO - training batch 501, loss: 0.162, 16032/28000 datapoints
2025-03-06 22:36:37,179 - INFO - training batch 551, loss: 0.372, 17632/28000 datapoints
2025-03-06 22:36:37,332 - INFO - training batch 601, loss: 0.341, 19232/28000 datapoints
2025-03-06 22:36:37,488 - INFO - training batch 651, loss: 0.078, 20832/28000 datapoints
2025-03-06 22:36:37,653 - INFO - training batch 701, loss: 0.276, 22432/28000 datapoints
2025-03-06 22:36:37,804 - INFO - training batch 751, loss: 0.225, 24032/28000 datapoints
2025-03-06 22:36:37,969 - INFO - training batch 801, loss: 0.126, 25632/28000 datapoints
2025-03-06 22:36:38,135 - INFO - training batch 851, loss: 0.398, 27232/28000 datapoints
2025-03-06 22:36:38,209 - INFO - validation batch 1, loss: 0.080, 32/6976 datapoints
2025-03-06 22:36:38,256 - INFO - validation batch 51, loss: 1.284, 1632/6976 datapoints
2025-03-06 22:36:38,304 - INFO - validation batch 101, loss: 0.361, 3232/6976 datapoints
2025-03-06 22:36:38,359 - INFO - validation batch 151, loss: 0.400, 4832/6976 datapoints
2025-03-06 22:36:38,407 - INFO - validation batch 201, loss: 0.582, 6432/6976 datapoints
2025-03-06 22:36:38,424 - INFO - Epoch 210/800 done.
2025-03-06 22:36:38,424 - INFO - Final validation performance:
Loss: 0.541, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:38,424 - INFO - Beginning epoch 211/800
2025-03-06 22:36:38,429 - INFO - training batch 1, loss: 0.334, 32/28000 datapoints
2025-03-06 22:36:38,587 - INFO - training batch 51, loss: 0.127, 1632/28000 datapoints
2025-03-06 22:36:38,737 - INFO - training batch 101, loss: 0.176, 3232/28000 datapoints
2025-03-06 22:36:38,891 - INFO - training batch 151, loss: 0.460, 4832/28000 datapoints
2025-03-06 22:36:39,045 - INFO - training batch 201, loss: 0.107, 6432/28000 datapoints
2025-03-06 22:36:39,199 - INFO - training batch 251, loss: 0.456, 8032/28000 datapoints
2025-03-06 22:36:39,353 - INFO - training batch 301, loss: 0.648, 9632/28000 datapoints
2025-03-06 22:36:39,507 - INFO - training batch 351, loss: 0.239, 11232/28000 datapoints
2025-03-06 22:36:39,659 - INFO - training batch 401, loss: 0.545, 12832/28000 datapoints
2025-03-06 22:36:39,811 - INFO - training batch 451, loss: 0.359, 14432/28000 datapoints
2025-03-06 22:36:39,972 - INFO - training batch 501, loss: 0.161, 16032/28000 datapoints
2025-03-06 22:36:40,125 - INFO - training batch 551, loss: 0.371, 17632/28000 datapoints
2025-03-06 22:36:40,282 - INFO - training batch 601, loss: 0.338, 19232/28000 datapoints
2025-03-06 22:36:40,443 - INFO - training batch 651, loss: 0.077, 20832/28000 datapoints
2025-03-06 22:36:40,599 - INFO - training batch 701, loss: 0.275, 22432/28000 datapoints
2025-03-06 22:36:40,752 - INFO - training batch 751, loss: 0.223, 24032/28000 datapoints
2025-03-06 22:36:40,912 - INFO - training batch 801, loss: 0.125, 25632/28000 datapoints
2025-03-06 22:36:41,070 - INFO - training batch 851, loss: 0.394, 27232/28000 datapoints
2025-03-06 22:36:41,151 - INFO - validation batch 1, loss: 0.080, 32/6976 datapoints
2025-03-06 22:36:41,203 - INFO - validation batch 51, loss: 1.284, 1632/6976 datapoints
2025-03-06 22:36:41,255 - INFO - validation batch 101, loss: 0.361, 3232/6976 datapoints
2025-03-06 22:36:41,306 - INFO - validation batch 151, loss: 0.402, 4832/6976 datapoints
2025-03-06 22:36:41,360 - INFO - validation batch 201, loss: 0.583, 6432/6976 datapoints
2025-03-06 22:36:41,379 - INFO - Epoch 211/800 done.
2025-03-06 22:36:41,379 - INFO - Final validation performance:
Loss: 0.542, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:41,380 - INFO - Beginning epoch 212/800
2025-03-06 22:36:41,384 - INFO - training batch 1, loss: 0.332, 32/28000 datapoints
2025-03-06 22:36:41,545 - INFO - training batch 51, loss: 0.127, 1632/28000 datapoints
2025-03-06 22:36:41,699 - INFO - training batch 101, loss: 0.175, 3232/28000 datapoints
2025-03-06 22:36:41,857 - INFO - training batch 151, loss: 0.456, 4832/28000 datapoints
2025-03-06 22:36:42,014 - INFO - training batch 201, loss: 0.106, 6432/28000 datapoints
2025-03-06 22:36:42,175 - INFO - training batch 251, loss: 0.455, 8032/28000 datapoints
2025-03-06 22:36:42,335 - INFO - training batch 301, loss: 0.646, 9632/28000 datapoints
2025-03-06 22:36:42,491 - INFO - training batch 351, loss: 0.237, 11232/28000 datapoints
2025-03-06 22:36:42,644 - INFO - training batch 401, loss: 0.541, 12832/28000 datapoints
2025-03-06 22:36:42,798 - INFO - training batch 451, loss: 0.358, 14432/28000 datapoints
2025-03-06 22:36:42,956 - INFO - training batch 501, loss: 0.161, 16032/28000 datapoints
2025-03-06 22:36:43,111 - INFO - training batch 551, loss: 0.368, 17632/28000 datapoints
2025-03-06 22:36:43,270 - INFO - training batch 601, loss: 0.334, 19232/28000 datapoints
2025-03-06 22:36:43,428 - INFO - training batch 651, loss: 0.076, 20832/28000 datapoints
2025-03-06 22:36:43,599 - INFO - training batch 701, loss: 0.275, 22432/28000 datapoints
2025-03-06 22:36:43,765 - INFO - training batch 751, loss: 0.222, 24032/28000 datapoints
2025-03-06 22:36:43,920 - INFO - training batch 801, loss: 0.123, 25632/28000 datapoints
2025-03-06 22:36:44,077 - INFO - training batch 851, loss: 0.390, 27232/28000 datapoints
2025-03-06 22:36:44,154 - INFO - validation batch 1, loss: 0.079, 32/6976 datapoints
2025-03-06 22:36:44,206 - INFO - validation batch 51, loss: 1.285, 1632/6976 datapoints
2025-03-06 22:36:44,258 - INFO - validation batch 101, loss: 0.361, 3232/6976 datapoints
2025-03-06 22:36:44,318 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 22:36:44,379 - INFO - validation batch 201, loss: 0.584, 6432/6976 datapoints
2025-03-06 22:36:44,400 - INFO - Epoch 212/800 done.
2025-03-06 22:36:44,400 - INFO - Final validation performance:
Loss: 0.542, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:44,401 - INFO - Beginning epoch 213/800
2025-03-06 22:36:44,405 - INFO - training batch 1, loss: 0.331, 32/28000 datapoints
2025-03-06 22:36:44,568 - INFO - training batch 51, loss: 0.126, 1632/28000 datapoints
2025-03-06 22:36:44,723 - INFO - training batch 101, loss: 0.174, 3232/28000 datapoints
2025-03-06 22:36:44,879 - INFO - training batch 151, loss: 0.452, 4832/28000 datapoints
2025-03-06 22:36:45,039 - INFO - training batch 201, loss: 0.106, 6432/28000 datapoints
2025-03-06 22:36:45,196 - INFO - training batch 251, loss: 0.455, 8032/28000 datapoints
2025-03-06 22:36:45,357 - INFO - training batch 301, loss: 0.646, 9632/28000 datapoints
2025-03-06 22:36:45,513 - INFO - training batch 351, loss: 0.236, 11232/28000 datapoints
2025-03-06 22:36:45,671 - INFO - training batch 401, loss: 0.538, 12832/28000 datapoints
2025-03-06 22:36:45,827 - INFO - training batch 451, loss: 0.356, 14432/28000 datapoints
2025-03-06 22:36:45,985 - INFO - training batch 501, loss: 0.159, 16032/28000 datapoints
2025-03-06 22:36:46,139 - INFO - training batch 551, loss: 0.365, 17632/28000 datapoints
2025-03-06 22:36:46,296 - INFO - training batch 601, loss: 0.330, 19232/28000 datapoints
2025-03-06 22:36:46,452 - INFO - training batch 651, loss: 0.074, 20832/28000 datapoints
2025-03-06 22:36:46,607 - INFO - training batch 701, loss: 0.274, 22432/28000 datapoints
2025-03-06 22:36:46,761 - INFO - training batch 751, loss: 0.219, 24032/28000 datapoints
2025-03-06 22:36:46,916 - INFO - training batch 801, loss: 0.122, 25632/28000 datapoints
2025-03-06 22:36:47,076 - INFO - training batch 851, loss: 0.387, 27232/28000 datapoints
2025-03-06 22:36:47,158 - INFO - validation batch 1, loss: 0.079, 32/6976 datapoints
2025-03-06 22:36:47,210 - INFO - validation batch 51, loss: 1.285, 1632/6976 datapoints
2025-03-06 22:36:47,262 - INFO - validation batch 101, loss: 0.361, 3232/6976 datapoints
2025-03-06 22:36:47,316 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 22:36:47,369 - INFO - validation batch 201, loss: 0.585, 6432/6976 datapoints
2025-03-06 22:36:47,388 - INFO - Epoch 213/800 done.
2025-03-06 22:36:47,389 - INFO - Final validation performance:
Loss: 0.542, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:47,389 - INFO - Beginning epoch 214/800
2025-03-06 22:36:47,394 - INFO - training batch 1, loss: 0.330, 32/28000 datapoints
2025-03-06 22:36:47,550 - INFO - training batch 51, loss: 0.124, 1632/28000 datapoints
2025-03-06 22:36:47,701 - INFO - training batch 101, loss: 0.173, 3232/28000 datapoints
2025-03-06 22:36:47,854 - INFO - training batch 151, loss: 0.446, 4832/28000 datapoints
2025-03-06 22:36:48,011 - INFO - training batch 201, loss: 0.105, 6432/28000 datapoints
2025-03-06 22:36:48,162 - INFO - training batch 251, loss: 0.454, 8032/28000 datapoints
2025-03-06 22:36:48,313 - INFO - training batch 301, loss: 0.645, 9632/28000 datapoints
2025-03-06 22:36:48,465 - INFO - training batch 351, loss: 0.235, 11232/28000 datapoints
2025-03-06 22:36:48,615 - INFO - training batch 401, loss: 0.533, 12832/28000 datapoints
2025-03-06 22:36:48,766 - INFO - training batch 451, loss: 0.355, 14432/28000 datapoints
2025-03-06 22:36:48,919 - INFO - training batch 501, loss: 0.160, 16032/28000 datapoints
2025-03-06 22:36:49,075 - INFO - training batch 551, loss: 0.364, 17632/28000 datapoints
2025-03-06 22:36:49,230 - INFO - training batch 601, loss: 0.328, 19232/28000 datapoints
2025-03-06 22:36:49,382 - INFO - training batch 651, loss: 0.074, 20832/28000 datapoints
2025-03-06 22:36:49,534 - INFO - training batch 701, loss: 0.273, 22432/28000 datapoints
2025-03-06 22:36:49,684 - INFO - training batch 751, loss: 0.220, 24032/28000 datapoints
2025-03-06 22:36:49,835 - INFO - training batch 801, loss: 0.121, 25632/28000 datapoints
2025-03-06 22:36:49,989 - INFO - training batch 851, loss: 0.382, 27232/28000 datapoints
2025-03-06 22:36:50,063 - INFO - validation batch 1, loss: 0.078, 32/6976 datapoints
2025-03-06 22:36:50,111 - INFO - validation batch 51, loss: 1.286, 1632/6976 datapoints
2025-03-06 22:36:50,159 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 22:36:50,208 - INFO - validation batch 151, loss: 0.400, 4832/6976 datapoints
2025-03-06 22:36:50,255 - INFO - validation batch 201, loss: 0.587, 6432/6976 datapoints
2025-03-06 22:36:50,271 - INFO - Epoch 214/800 done.
2025-03-06 22:36:50,272 - INFO - Final validation performance:
Loss: 0.543, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:36:50,272 - INFO - Beginning epoch 215/800
2025-03-06 22:36:50,276 - INFO - training batch 1, loss: 0.329, 32/28000 datapoints
2025-03-06 22:36:50,433 - INFO - training batch 51, loss: 0.123, 1632/28000 datapoints
2025-03-06 22:36:50,601 - INFO - training batch 101, loss: 0.173, 3232/28000 datapoints
2025-03-06 22:36:50,753 - INFO - training batch 151, loss: 0.442, 4832/28000 datapoints
2025-03-06 22:36:50,905 - INFO - training batch 201, loss: 0.104, 6432/28000 datapoints
2025-03-06 22:36:51,077 - INFO - training batch 251, loss: 0.453, 8032/28000 datapoints
2025-03-06 22:36:51,235 - INFO - training batch 301, loss: 0.644, 9632/28000 datapoints
2025-03-06 22:36:51,389 - INFO - training batch 351, loss: 0.234, 11232/28000 datapoints
2025-03-06 22:36:51,542 - INFO - training batch 401, loss: 0.528, 12832/28000 datapoints
2025-03-06 22:36:51,694 - INFO - training batch 451, loss: 0.354, 14432/28000 datapoints
2025-03-06 22:36:51,845 - INFO - training batch 501, loss: 0.157, 16032/28000 datapoints
2025-03-06 22:36:52,001 - INFO - training batch 551, loss: 0.362, 17632/28000 datapoints
2025-03-06 22:36:52,154 - INFO - training batch 601, loss: 0.324, 19232/28000 datapoints
2025-03-06 22:36:52,308 - INFO - training batch 651, loss: 0.073, 20832/28000 datapoints
2025-03-06 22:36:52,459 - INFO - training batch 701, loss: 0.272, 22432/28000 datapoints
2025-03-06 22:36:52,611 - INFO - training batch 751, loss: 0.218, 24032/28000 datapoints
2025-03-06 22:36:52,762 - INFO - training batch 801, loss: 0.120, 25632/28000 datapoints
2025-03-06 22:36:52,912 - INFO - training batch 851, loss: 0.378, 27232/28000 datapoints
2025-03-06 22:36:52,991 - INFO - validation batch 1, loss: 0.078, 32/6976 datapoints
2025-03-06 22:36:53,040 - INFO - validation batch 51, loss: 1.287, 1632/6976 datapoints
2025-03-06 22:36:53,086 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 22:36:53,133 - INFO - validation batch 151, loss: 0.400, 4832/6976 datapoints
2025-03-06 22:36:53,187 - INFO - validation batch 201, loss: 0.587, 6432/6976 datapoints
2025-03-06 22:36:53,203 - INFO - Epoch 215/800 done.
2025-03-06 22:36:53,204 - INFO - Final validation performance:
Loss: 0.543, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:53,204 - INFO - Beginning epoch 216/800
2025-03-06 22:36:53,209 - INFO - training batch 1, loss: 0.328, 32/28000 datapoints
2025-03-06 22:36:53,362 - INFO - training batch 51, loss: 0.123, 1632/28000 datapoints
2025-03-06 22:36:53,515 - INFO - training batch 101, loss: 0.172, 3232/28000 datapoints
2025-03-06 22:36:53,676 - INFO - training batch 151, loss: 0.436, 4832/28000 datapoints
2025-03-06 22:36:53,844 - INFO - training batch 201, loss: 0.103, 6432/28000 datapoints
2025-03-06 22:36:53,998 - INFO - training batch 251, loss: 0.453, 8032/28000 datapoints
2025-03-06 22:36:54,150 - INFO - training batch 301, loss: 0.642, 9632/28000 datapoints
2025-03-06 22:36:54,301 - INFO - training batch 351, loss: 0.232, 11232/28000 datapoints
2025-03-06 22:36:54,453 - INFO - training batch 401, loss: 0.525, 12832/28000 datapoints
2025-03-06 22:36:54,606 - INFO - training batch 451, loss: 0.353, 14432/28000 datapoints
2025-03-06 22:36:54,757 - INFO - training batch 501, loss: 0.156, 16032/28000 datapoints
2025-03-06 22:36:54,908 - INFO - training batch 551, loss: 0.360, 17632/28000 datapoints
2025-03-06 22:36:55,062 - INFO - training batch 601, loss: 0.321, 19232/28000 datapoints
2025-03-06 22:36:55,222 - INFO - training batch 651, loss: 0.072, 20832/28000 datapoints
2025-03-06 22:36:55,373 - INFO - training batch 701, loss: 0.271, 22432/28000 datapoints
2025-03-06 22:36:55,525 - INFO - training batch 751, loss: 0.217, 24032/28000 datapoints
2025-03-06 22:36:55,679 - INFO - training batch 801, loss: 0.119, 25632/28000 datapoints
2025-03-06 22:36:55,829 - INFO - training batch 851, loss: 0.374, 27232/28000 datapoints
2025-03-06 22:36:55,903 - INFO - validation batch 1, loss: 0.077, 32/6976 datapoints
2025-03-06 22:36:55,954 - INFO - validation batch 51, loss: 1.287, 1632/6976 datapoints
2025-03-06 22:36:56,002 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 22:36:56,051 - INFO - validation batch 151, loss: 0.400, 4832/6976 datapoints
2025-03-06 22:36:56,098 - INFO - validation batch 201, loss: 0.588, 6432/6976 datapoints
2025-03-06 22:36:56,115 - INFO - Epoch 216/800 done.
2025-03-06 22:36:56,115 - INFO - Final validation performance:
Loss: 0.543, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:56,115 - INFO - Beginning epoch 217/800
2025-03-06 22:36:56,119 - INFO - training batch 1, loss: 0.327, 32/28000 datapoints
2025-03-06 22:36:56,271 - INFO - training batch 51, loss: 0.121, 1632/28000 datapoints
2025-03-06 22:36:56,424 - INFO - training batch 101, loss: 0.171, 3232/28000 datapoints
2025-03-06 22:36:56,589 - INFO - training batch 151, loss: 0.431, 4832/28000 datapoints
2025-03-06 22:36:56,742 - INFO - training batch 201, loss: 0.102, 6432/28000 datapoints
2025-03-06 22:36:56,893 - INFO - training batch 251, loss: 0.453, 8032/28000 datapoints
2025-03-06 22:36:57,051 - INFO - training batch 301, loss: 0.641, 9632/28000 datapoints
2025-03-06 22:36:57,209 - INFO - training batch 351, loss: 0.230, 11232/28000 datapoints
2025-03-06 22:36:57,367 - INFO - training batch 401, loss: 0.522, 12832/28000 datapoints
2025-03-06 22:36:57,525 - INFO - training batch 451, loss: 0.352, 14432/28000 datapoints
2025-03-06 22:36:57,677 - INFO - training batch 501, loss: 0.156, 16032/28000 datapoints
2025-03-06 22:36:57,829 - INFO - training batch 551, loss: 0.357, 17632/28000 datapoints
2025-03-06 22:36:57,983 - INFO - training batch 601, loss: 0.319, 19232/28000 datapoints
2025-03-06 22:36:58,135 - INFO - training batch 651, loss: 0.071, 20832/28000 datapoints
2025-03-06 22:36:58,286 - INFO - training batch 701, loss: 0.271, 22432/28000 datapoints
2025-03-06 22:36:58,435 - INFO - training batch 751, loss: 0.214, 24032/28000 datapoints
2025-03-06 22:36:58,587 - INFO - training batch 801, loss: 0.118, 25632/28000 datapoints
2025-03-06 22:36:58,739 - INFO - training batch 851, loss: 0.369, 27232/28000 datapoints
2025-03-06 22:36:58,817 - INFO - validation batch 1, loss: 0.077, 32/6976 datapoints
2025-03-06 22:36:58,864 - INFO - validation batch 51, loss: 1.288, 1632/6976 datapoints
2025-03-06 22:36:58,913 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 22:36:58,965 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 22:36:59,013 - INFO - validation batch 201, loss: 0.589, 6432/6976 datapoints
2025-03-06 22:36:59,030 - INFO - Epoch 217/800 done.
2025-03-06 22:36:59,030 - INFO - Final validation performance:
Loss: 0.543, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:36:59,031 - INFO - Beginning epoch 218/800
2025-03-06 22:36:59,035 - INFO - training batch 1, loss: 0.326, 32/28000 datapoints
2025-03-06 22:36:59,199 - INFO - training batch 51, loss: 0.121, 1632/28000 datapoints
2025-03-06 22:36:59,350 - INFO - training batch 101, loss: 0.170, 3232/28000 datapoints
2025-03-06 22:36:59,504 - INFO - training batch 151, loss: 0.426, 4832/28000 datapoints
2025-03-06 22:36:59,657 - INFO - training batch 201, loss: 0.101, 6432/28000 datapoints
2025-03-06 22:36:59,807 - INFO - training batch 251, loss: 0.452, 8032/28000 datapoints
2025-03-06 22:36:59,965 - INFO - training batch 301, loss: 0.640, 9632/28000 datapoints
2025-03-06 22:37:00,121 - INFO - training batch 351, loss: 0.228, 11232/28000 datapoints
2025-03-06 22:37:00,276 - INFO - training batch 401, loss: 0.518, 12832/28000 datapoints
2025-03-06 22:37:00,432 - INFO - training batch 451, loss: 0.350, 14432/28000 datapoints
2025-03-06 22:37:00,595 - INFO - training batch 501, loss: 0.155, 16032/28000 datapoints
2025-03-06 22:37:00,751 - INFO - training batch 551, loss: 0.355, 17632/28000 datapoints
2025-03-06 22:37:00,907 - INFO - training batch 601, loss: 0.316, 19232/28000 datapoints
2025-03-06 22:37:01,070 - INFO - training batch 651, loss: 0.070, 20832/28000 datapoints
2025-03-06 22:37:01,232 - INFO - training batch 701, loss: 0.270, 22432/28000 datapoints
2025-03-06 22:37:01,386 - INFO - training batch 751, loss: 0.215, 24032/28000 datapoints
2025-03-06 22:37:01,542 - INFO - training batch 801, loss: 0.116, 25632/28000 datapoints
2025-03-06 22:37:01,701 - INFO - training batch 851, loss: 0.368, 27232/28000 datapoints
2025-03-06 22:37:01,780 - INFO - validation batch 1, loss: 0.076, 32/6976 datapoints
2025-03-06 22:37:01,832 - INFO - validation batch 51, loss: 1.290, 1632/6976 datapoints
2025-03-06 22:37:01,884 - INFO - validation batch 101, loss: 0.363, 3232/6976 datapoints
2025-03-06 22:37:01,935 - INFO - validation batch 151, loss: 0.400, 4832/6976 datapoints
2025-03-06 22:37:01,989 - INFO - validation batch 201, loss: 0.589, 6432/6976 datapoints
2025-03-06 22:37:02,008 - INFO - Epoch 218/800 done.
2025-03-06 22:37:02,012 - INFO - Final validation performance:
Loss: 0.544, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:37:02,013 - INFO - Beginning epoch 219/800
2025-03-06 22:37:02,017 - INFO - training batch 1, loss: 0.326, 32/28000 datapoints
2025-03-06 22:37:02,186 - INFO - training batch 51, loss: 0.119, 1632/28000 datapoints
2025-03-06 22:37:02,338 - INFO - training batch 101, loss: 0.169, 3232/28000 datapoints
2025-03-06 22:37:02,490 - INFO - training batch 151, loss: 0.422, 4832/28000 datapoints
2025-03-06 22:37:02,658 - INFO - training batch 201, loss: 0.100, 6432/28000 datapoints
2025-03-06 22:37:02,808 - INFO - training batch 251, loss: 0.452, 8032/28000 datapoints
2025-03-06 22:37:02,960 - INFO - training batch 301, loss: 0.639, 9632/28000 datapoints
2025-03-06 22:37:03,124 - INFO - training batch 351, loss: 0.227, 11232/28000 datapoints
2025-03-06 22:37:03,280 - INFO - training batch 401, loss: 0.513, 12832/28000 datapoints
2025-03-06 22:37:03,435 - INFO - training batch 451, loss: 0.349, 14432/28000 datapoints
2025-03-06 22:37:03,589 - INFO - training batch 501, loss: 0.154, 16032/28000 datapoints
2025-03-06 22:37:03,743 - INFO - training batch 551, loss: 0.353, 17632/28000 datapoints
2025-03-06 22:37:03,917 - INFO - training batch 601, loss: 0.313, 19232/28000 datapoints
2025-03-06 22:37:04,072 - INFO - training batch 651, loss: 0.069, 20832/28000 datapoints
2025-03-06 22:37:04,223 - INFO - training batch 701, loss: 0.269, 22432/28000 datapoints
2025-03-06 22:37:04,374 - INFO - training batch 751, loss: 0.214, 24032/28000 datapoints
2025-03-06 22:37:04,526 - INFO - training batch 801, loss: 0.115, 25632/28000 datapoints
2025-03-06 22:37:04,677 - INFO - training batch 851, loss: 0.363, 27232/28000 datapoints
2025-03-06 22:37:04,751 - INFO - validation batch 1, loss: 0.076, 32/6976 datapoints
2025-03-06 22:37:04,801 - INFO - validation batch 51, loss: 1.291, 1632/6976 datapoints
2025-03-06 22:37:04,849 - INFO - validation batch 101, loss: 0.363, 3232/6976 datapoints
2025-03-06 22:37:04,896 - INFO - validation batch 151, loss: 0.400, 4832/6976 datapoints
2025-03-06 22:37:04,946 - INFO - validation batch 201, loss: 0.591, 6432/6976 datapoints
2025-03-06 22:37:04,962 - INFO - Epoch 219/800 done.
2025-03-06 22:37:04,962 - INFO - Final validation performance:
Loss: 0.544, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:37:04,963 - INFO - Beginning epoch 220/800
2025-03-06 22:37:04,967 - INFO - training batch 1, loss: 0.324, 32/28000 datapoints
2025-03-06 22:37:05,120 - INFO - training batch 51, loss: 0.119, 1632/28000 datapoints
2025-03-06 22:37:05,283 - INFO - training batch 101, loss: 0.169, 3232/28000 datapoints
2025-03-06 22:37:05,435 - INFO - training batch 151, loss: 0.416, 4832/28000 datapoints
2025-03-06 22:37:05,590 - INFO - training batch 201, loss: 0.099, 6432/28000 datapoints
2025-03-06 22:37:05,742 - INFO - training batch 251, loss: 0.451, 8032/28000 datapoints
2025-03-06 22:37:05,893 - INFO - training batch 301, loss: 0.637, 9632/28000 datapoints
2025-03-06 22:37:06,046 - INFO - training batch 351, loss: 0.227, 11232/28000 datapoints
2025-03-06 22:37:06,197 - INFO - training batch 401, loss: 0.509, 12832/28000 datapoints
2025-03-06 22:37:06,347 - INFO - training batch 451, loss: 0.348, 14432/28000 datapoints
2025-03-06 22:37:06,497 - INFO - training batch 501, loss: 0.154, 16032/28000 datapoints
2025-03-06 22:37:06,651 - INFO - training batch 551, loss: 0.351, 17632/28000 datapoints
2025-03-06 22:37:06,802 - INFO - training batch 601, loss: 0.311, 19232/28000 datapoints
2025-03-06 22:37:06,954 - INFO - training batch 651, loss: 0.068, 20832/28000 datapoints
2025-03-06 22:37:07,104 - INFO - training batch 701, loss: 0.268, 22432/28000 datapoints
2025-03-06 22:37:07,259 - INFO - training batch 751, loss: 0.211, 24032/28000 datapoints
2025-03-06 22:37:07,408 - INFO - training batch 801, loss: 0.114, 25632/28000 datapoints
2025-03-06 22:37:07,557 - INFO - training batch 851, loss: 0.357, 27232/28000 datapoints
2025-03-06 22:37:07,632 - INFO - validation batch 1, loss: 0.076, 32/6976 datapoints
2025-03-06 22:37:07,680 - INFO - validation batch 51, loss: 1.294, 1632/6976 datapoints
2025-03-06 22:37:07,727 - INFO - validation batch 101, loss: 0.363, 3232/6976 datapoints
2025-03-06 22:37:07,775 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 22:37:07,822 - INFO - validation batch 201, loss: 0.592, 6432/6976 datapoints
2025-03-06 22:37:07,839 - INFO - Epoch 220/800 done.
2025-03-06 22:37:07,839 - INFO - Final validation performance:
Loss: 0.545, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:37:07,840 - INFO - Beginning epoch 221/800
2025-03-06 22:37:07,844 - INFO - training batch 1, loss: 0.323, 32/28000 datapoints
2025-03-06 22:37:07,999 - INFO - training batch 51, loss: 0.116, 1632/28000 datapoints
2025-03-06 22:37:08,150 - INFO - training batch 101, loss: 0.168, 3232/28000 datapoints
2025-03-06 22:37:08,304 - INFO - training batch 151, loss: 0.412, 4832/28000 datapoints
2025-03-06 22:37:08,456 - INFO - training batch 201, loss: 0.098, 6432/28000 datapoints
2025-03-06 22:37:08,620 - INFO - training batch 251, loss: 0.450, 8032/28000 datapoints
2025-03-06 22:37:08,774 - INFO - training batch 301, loss: 0.636, 9632/28000 datapoints
2025-03-06 22:37:08,925 - INFO - training batch 351, loss: 0.226, 11232/28000 datapoints
2025-03-06 22:37:09,083 - INFO - training batch 401, loss: 0.505, 12832/28000 datapoints
2025-03-06 22:37:09,244 - INFO - training batch 451, loss: 0.347, 14432/28000 datapoints
2025-03-06 22:37:09,398 - INFO - training batch 501, loss: 0.153, 16032/28000 datapoints
2025-03-06 22:37:09,556 - INFO - training batch 551, loss: 0.349, 17632/28000 datapoints
2025-03-06 22:37:09,708 - INFO - training batch 601, loss: 0.309, 19232/28000 datapoints
2025-03-06 22:37:09,860 - INFO - training batch 651, loss: 0.067, 20832/28000 datapoints
2025-03-06 22:37:10,012 - INFO - training batch 701, loss: 0.267, 22432/28000 datapoints
2025-03-06 22:37:10,162 - INFO - training batch 751, loss: 0.211, 24032/28000 datapoints
2025-03-06 22:37:10,312 - INFO - training batch 801, loss: 0.113, 25632/28000 datapoints
2025-03-06 22:37:10,463 - INFO - training batch 851, loss: 0.354, 27232/28000 datapoints
2025-03-06 22:37:10,537 - INFO - validation batch 1, loss: 0.075, 32/6976 datapoints
2025-03-06 22:37:10,585 - INFO - validation batch 51, loss: 1.296, 1632/6976 datapoints
2025-03-06 22:37:10,632 - INFO - validation batch 101, loss: 0.364, 3232/6976 datapoints
2025-03-06 22:37:10,680 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 22:37:10,728 - INFO - validation batch 201, loss: 0.593, 6432/6976 datapoints
2025-03-06 22:37:10,745 - INFO - Epoch 221/800 done.
2025-03-06 22:37:10,745 - INFO - Final validation performance:
Loss: 0.546, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:37:10,746 - INFO - Beginning epoch 222/800
2025-03-06 22:37:10,750 - INFO - training batch 1, loss: 0.322, 32/28000 datapoints
2025-03-06 22:37:10,903 - INFO - training batch 51, loss: 0.116, 1632/28000 datapoints
2025-03-06 22:37:11,060 - INFO - training batch 101, loss: 0.167, 3232/28000 datapoints
2025-03-06 22:37:11,214 - INFO - training batch 151, loss: 0.406, 4832/28000 datapoints
2025-03-06 22:37:11,371 - INFO - training batch 201, loss: 0.097, 6432/28000 datapoints
2025-03-06 22:37:11,521 - INFO - training batch 251, loss: 0.450, 8032/28000 datapoints
2025-03-06 22:37:11,671 - INFO - training batch 301, loss: 0.636, 9632/28000 datapoints
2025-03-06 22:37:11,822 - INFO - training batch 351, loss: 0.224, 11232/28000 datapoints
2025-03-06 22:37:11,976 - INFO - training batch 401, loss: 0.501, 12832/28000 datapoints
2025-03-06 22:37:12,126 - INFO - training batch 451, loss: 0.345, 14432/28000 datapoints
2025-03-06 22:37:12,279 - INFO - training batch 501, loss: 0.152, 16032/28000 datapoints
2025-03-06 22:37:12,430 - INFO - training batch 551, loss: 0.347, 17632/28000 datapoints
2025-03-06 22:37:12,588 - INFO - training batch 601, loss: 0.306, 19232/28000 datapoints
2025-03-06 22:37:12,742 - INFO - training batch 651, loss: 0.067, 20832/28000 datapoints
2025-03-06 22:37:12,894 - INFO - training batch 701, loss: 0.266, 22432/28000 datapoints
2025-03-06 22:37:13,048 - INFO - training batch 751, loss: 0.210, 24032/28000 datapoints
2025-03-06 22:37:13,202 - INFO - training batch 801, loss: 0.112, 25632/28000 datapoints
2025-03-06 22:37:13,355 - INFO - training batch 851, loss: 0.350, 27232/28000 datapoints
2025-03-06 22:37:13,430 - INFO - validation batch 1, loss: 0.075, 32/6976 datapoints
2025-03-06 22:37:13,476 - INFO - validation batch 51, loss: 1.297, 1632/6976 datapoints
2025-03-06 22:37:13,525 - INFO - validation batch 101, loss: 0.364, 3232/6976 datapoints
2025-03-06 22:37:13,572 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 22:37:13,619 - INFO - validation batch 201, loss: 0.594, 6432/6976 datapoints
2025-03-06 22:37:13,636 - INFO - Epoch 222/800 done.
2025-03-06 22:37:13,637 - INFO - Final validation performance:
Loss: 0.546, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:37:13,637 - INFO - Beginning epoch 223/800
2025-03-06 22:37:13,641 - INFO - training batch 1, loss: 0.321, 32/28000 datapoints
2025-03-06 22:37:13,798 - INFO - training batch 51, loss: 0.114, 1632/28000 datapoints
2025-03-06 22:37:13,978 - INFO - training batch 101, loss: 0.166, 3232/28000 datapoints
2025-03-06 22:37:14,129 - INFO - training batch 151, loss: 0.402, 4832/28000 datapoints
2025-03-06 22:37:14,285 - INFO - training batch 201, loss: 0.096, 6432/28000 datapoints
2025-03-06 22:37:14,436 - INFO - training batch 251, loss: 0.449, 8032/28000 datapoints
2025-03-06 22:37:14,591 - INFO - training batch 301, loss: 0.634, 9632/28000 datapoints
2025-03-06 22:37:14,821 - INFO - training batch 351, loss: 0.223, 11232/28000 datapoints
2025-03-06 22:37:14,974 - INFO - training batch 401, loss: 0.497, 12832/28000 datapoints
2025-03-06 22:37:15,132 - INFO - training batch 451, loss: 0.345, 14432/28000 datapoints
2025-03-06 22:37:15,293 - INFO - training batch 501, loss: 0.151, 16032/28000 datapoints
2025-03-06 22:37:15,447 - INFO - training batch 551, loss: 0.345, 17632/28000 datapoints
2025-03-06 22:37:15,603 - INFO - training batch 601, loss: 0.304, 19232/28000 datapoints
2025-03-06 22:37:15,755 - INFO - training batch 651, loss: 0.066, 20832/28000 datapoints
2025-03-06 22:37:15,907 - INFO - training batch 701, loss: 0.266, 22432/28000 datapoints
2025-03-06 22:37:16,060 - INFO - training batch 751, loss: 0.208, 24032/28000 datapoints
2025-03-06 22:37:16,211 - INFO - training batch 801, loss: 0.110, 25632/28000 datapoints
2025-03-06 22:37:16,362 - INFO - training batch 851, loss: 0.346, 27232/28000 datapoints
2025-03-06 22:37:16,436 - INFO - validation batch 1, loss: 0.074, 32/6976 datapoints
2025-03-06 22:37:16,483 - INFO - validation batch 51, loss: 1.298, 1632/6976 datapoints
2025-03-06 22:37:16,531 - INFO - validation batch 101, loss: 0.365, 3232/6976 datapoints
2025-03-06 22:37:16,579 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 22:37:16,626 - INFO - validation batch 201, loss: 0.595, 6432/6976 datapoints
2025-03-06 22:37:16,642 - INFO - Epoch 223/800 done.
2025-03-06 22:37:16,642 - INFO - Final validation performance:
Loss: 0.547, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:37:16,643 - INFO - Beginning epoch 224/800
2025-03-06 22:37:16,647 - INFO - training batch 1, loss: 0.320, 32/28000 datapoints
2025-03-06 22:37:16,803 - INFO - training batch 51, loss: 0.114, 1632/28000 datapoints
2025-03-06 22:37:16,959 - INFO - training batch 101, loss: 0.165, 3232/28000 datapoints
2025-03-06 22:37:17,111 - INFO - training batch 151, loss: 0.397, 4832/28000 datapoints
2025-03-06 22:37:17,262 - INFO - training batch 201, loss: 0.095, 6432/28000 datapoints
2025-03-06 22:37:17,419 - INFO - training batch 251, loss: 0.448, 8032/28000 datapoints
2025-03-06 22:37:17,570 - INFO - training batch 301, loss: 0.634, 9632/28000 datapoints
2025-03-06 22:37:17,720 - INFO - training batch 351, loss: 0.223, 11232/28000 datapoints
2025-03-06 22:37:17,873 - INFO - training batch 401, loss: 0.493, 12832/28000 datapoints
2025-03-06 22:37:18,025 - INFO - training batch 451, loss: 0.344, 14432/28000 datapoints
2025-03-06 22:37:18,175 - INFO - training batch 501, loss: 0.151, 16032/28000 datapoints
2025-03-06 22:37:18,327 - INFO - training batch 551, loss: 0.343, 17632/28000 datapoints
2025-03-06 22:37:18,478 - INFO - training batch 601, loss: 0.300, 19232/28000 datapoints
2025-03-06 22:37:18,631 - INFO - training batch 651, loss: 0.065, 20832/28000 datapoints
2025-03-06 22:37:18,780 - INFO - training batch 701, loss: 0.264, 22432/28000 datapoints
2025-03-06 22:37:18,930 - INFO - training batch 751, loss: 0.208, 24032/28000 datapoints
2025-03-06 22:37:19,083 - INFO - training batch 801, loss: 0.110, 25632/28000 datapoints
2025-03-06 22:37:19,232 - INFO - training batch 851, loss: 0.343, 27232/28000 datapoints
2025-03-06 22:37:19,308 - INFO - validation batch 1, loss: 0.074, 32/6976 datapoints
2025-03-06 22:37:19,355 - INFO - validation batch 51, loss: 1.301, 1632/6976 datapoints
2025-03-06 22:37:19,404 - INFO - validation batch 101, loss: 0.365, 3232/6976 datapoints
2025-03-06 22:37:19,451 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 22:37:19,500 - INFO - validation batch 201, loss: 0.597, 6432/6976 datapoints
2025-03-06 22:37:19,516 - INFO - Epoch 224/800 done.
2025-03-06 22:37:19,516 - INFO - Final validation performance:
Loss: 0.548, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:37:19,517 - INFO - Beginning epoch 225/800
2025-03-06 22:37:19,521 - INFO - training batch 1, loss: 0.319, 32/28000 datapoints
2025-03-06 22:37:19,673 - INFO - training batch 51, loss: 0.112, 1632/28000 datapoints
2025-03-06 22:37:19,824 - INFO - training batch 101, loss: 0.165, 3232/28000 datapoints
2025-03-06 22:37:19,982 - INFO - training batch 151, loss: 0.393, 4832/28000 datapoints
2025-03-06 22:37:20,141 - INFO - training batch 201, loss: 0.094, 6432/28000 datapoints
2025-03-06 22:37:20,298 - INFO - training batch 251, loss: 0.447, 8032/28000 datapoints
2025-03-06 22:37:20,456 - INFO - training batch 301, loss: 0.632, 9632/28000 datapoints
2025-03-06 22:37:20,611 - INFO - training batch 351, loss: 0.221, 11232/28000 datapoints
2025-03-06 22:37:20,775 - INFO - training batch 401, loss: 0.489, 12832/28000 datapoints
2025-03-06 22:37:20,933 - INFO - training batch 451, loss: 0.343, 14432/28000 datapoints
2025-03-06 22:37:21,092 - INFO - training batch 501, loss: 0.150, 16032/28000 datapoints
2025-03-06 22:37:21,254 - INFO - training batch 551, loss: 0.340, 17632/28000 datapoints
2025-03-06 22:37:21,418 - INFO - training batch 601, loss: 0.298, 19232/28000 datapoints
2025-03-06 22:37:21,574 - INFO - training batch 651, loss: 0.064, 20832/28000 datapoints
2025-03-06 22:37:21,735 - INFO - training batch 701, loss: 0.263, 22432/28000 datapoints
2025-03-06 22:37:21,889 - INFO - training batch 751, loss: 0.207, 24032/28000 datapoints
2025-03-06 22:37:22,045 - INFO - training batch 801, loss: 0.108, 25632/28000 datapoints
2025-03-06 22:37:22,201 - INFO - training batch 851, loss: 0.338, 27232/28000 datapoints
2025-03-06 22:37:22,280 - INFO - validation batch 1, loss: 0.073, 32/6976 datapoints
2025-03-06 22:37:22,332 - INFO - validation batch 51, loss: 1.304, 1632/6976 datapoints
2025-03-06 22:37:22,383 - INFO - validation batch 101, loss: 0.365, 3232/6976 datapoints
2025-03-06 22:37:22,436 - INFO - validation batch 151, loss: 0.402, 4832/6976 datapoints
2025-03-06 22:37:22,488 - INFO - validation batch 201, loss: 0.597, 6432/6976 datapoints
2025-03-06 22:37:22,507 - INFO - Epoch 225/800 done.
2025-03-06 22:37:22,507 - INFO - Final validation performance:
Loss: 0.548, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:37:22,508 - INFO - Beginning epoch 226/800
2025-03-06 22:37:22,512 - INFO - training batch 1, loss: 0.317, 32/28000 datapoints
2025-03-06 22:37:22,666 - INFO - training batch 51, loss: 0.111, 1632/28000 datapoints
2025-03-06 22:37:22,819 - INFO - training batch 101, loss: 0.163, 3232/28000 datapoints
2025-03-06 22:37:22,976 - INFO - training batch 151, loss: 0.387, 4832/28000 datapoints
2025-03-06 22:37:23,127 - INFO - training batch 201, loss: 0.093, 6432/28000 datapoints
2025-03-06 22:37:23,277 - INFO - training batch 251, loss: 0.447, 8032/28000 datapoints
2025-03-06 22:37:23,433 - INFO - training batch 301, loss: 0.631, 9632/28000 datapoints
2025-03-06 22:37:23,584 - INFO - training batch 351, loss: 0.219, 11232/28000 datapoints
2025-03-06 22:37:23,735 - INFO - training batch 401, loss: 0.484, 12832/28000 datapoints
2025-03-06 22:37:23,886 - INFO - training batch 451, loss: 0.342, 14432/28000 datapoints
2025-03-06 22:37:24,066 - INFO - training batch 501, loss: 0.149, 16032/28000 datapoints
2025-03-06 22:37:24,218 - INFO - training batch 551, loss: 0.338, 17632/28000 datapoints
2025-03-06 22:37:24,371 - INFO - training batch 601, loss: 0.296, 19232/28000 datapoints
2025-03-06 22:37:24,522 - INFO - training batch 651, loss: 0.063, 20832/28000 datapoints
2025-03-06 22:37:24,675 - INFO - training batch 701, loss: 0.262, 22432/28000 datapoints
2025-03-06 22:37:24,826 - INFO - training batch 751, loss: 0.204, 24032/28000 datapoints
2025-03-06 22:37:24,978 - INFO - training batch 801, loss: 0.107, 25632/28000 datapoints
2025-03-06 22:37:25,128 - INFO - training batch 851, loss: 0.335, 27232/28000 datapoints
2025-03-06 22:37:25,202 - INFO - validation batch 1, loss: 0.073, 32/6976 datapoints
2025-03-06 22:37:25,261 - INFO - validation batch 51, loss: 1.305, 1632/6976 datapoints
2025-03-06 22:37:25,312 - INFO - validation batch 101, loss: 0.365, 3232/6976 datapoints
2025-03-06 22:37:25,360 - INFO - validation batch 151, loss: 0.404, 4832/6976 datapoints
2025-03-06 22:37:25,408 - INFO - validation batch 201, loss: 0.598, 6432/6976 datapoints
2025-03-06 22:37:25,424 - INFO - Epoch 226/800 done.
2025-03-06 22:37:25,424 - INFO - Final validation performance:
Loss: 0.549, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:37:25,425 - INFO - Beginning epoch 227/800
2025-03-06 22:37:25,429 - INFO - training batch 1, loss: 0.317, 32/28000 datapoints
2025-03-06 22:37:25,585 - INFO - training batch 51, loss: 0.111, 1632/28000 datapoints
2025-03-06 22:37:25,739 - INFO - training batch 101, loss: 0.163, 3232/28000 datapoints
2025-03-06 22:37:25,890 - INFO - training batch 151, loss: 0.383, 4832/28000 datapoints
2025-03-06 22:37:26,044 - INFO - training batch 201, loss: 0.092, 6432/28000 datapoints
2025-03-06 22:37:26,194 - INFO - training batch 251, loss: 0.447, 8032/28000 datapoints
2025-03-06 22:37:26,345 - INFO - training batch 301, loss: 0.630, 9632/28000 datapoints
2025-03-06 22:37:26,497 - INFO - training batch 351, loss: 0.218, 11232/28000 datapoints
2025-03-06 22:37:26,648 - INFO - training batch 401, loss: 0.482, 12832/28000 datapoints
2025-03-06 22:37:26,799 - INFO - training batch 451, loss: 0.341, 14432/28000 datapoints
2025-03-06 22:37:26,967 - INFO - training batch 501, loss: 0.149, 16032/28000 datapoints
2025-03-06 22:37:27,119 - INFO - training batch 551, loss: 0.336, 17632/28000 datapoints
2025-03-06 22:37:27,272 - INFO - training batch 601, loss: 0.293, 19232/28000 datapoints
2025-03-06 22:37:27,433 - INFO - training batch 651, loss: 0.062, 20832/28000 datapoints
2025-03-06 22:37:27,587 - INFO - training batch 701, loss: 0.261, 22432/28000 datapoints
2025-03-06 22:37:27,743 - INFO - training batch 751, loss: 0.205, 24032/28000 datapoints
2025-03-06 22:37:27,894 - INFO - training batch 801, loss: 0.106, 25632/28000 datapoints
2025-03-06 22:37:28,048 - INFO - training batch 851, loss: 0.331, 27232/28000 datapoints
2025-03-06 22:37:28,122 - INFO - validation batch 1, loss: 0.073, 32/6976 datapoints
2025-03-06 22:37:28,171 - INFO - validation batch 51, loss: 1.306, 1632/6976 datapoints
2025-03-06 22:37:28,219 - INFO - validation batch 101, loss: 0.366, 3232/6976 datapoints
2025-03-06 22:37:28,266 - INFO - validation batch 151, loss: 0.402, 4832/6976 datapoints
2025-03-06 22:37:28,313 - INFO - validation batch 201, loss: 0.600, 6432/6976 datapoints
2025-03-06 22:37:28,329 - INFO - Epoch 227/800 done.
2025-03-06 22:37:28,330 - INFO - Final validation performance:
Loss: 0.549, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:37:28,330 - INFO - Beginning epoch 228/800
2025-03-06 22:37:28,335 - INFO - training batch 1, loss: 0.315, 32/28000 datapoints
2025-03-06 22:37:28,491 - INFO - training batch 51, loss: 0.108, 1632/28000 datapoints
2025-03-06 22:37:28,645 - INFO - training batch 101, loss: 0.162, 3232/28000 datapoints
2025-03-06 22:37:28,796 - INFO - training batch 151, loss: 0.377, 4832/28000 datapoints
2025-03-06 22:37:28,949 - INFO - training batch 201, loss: 0.091, 6432/28000 datapoints
2025-03-06 22:37:29,102 - INFO - training batch 251, loss: 0.446, 8032/28000 datapoints
2025-03-06 22:37:29,253 - INFO - training batch 301, loss: 0.628, 9632/28000 datapoints
2025-03-06 22:37:29,409 - INFO - training batch 351, loss: 0.216, 11232/28000 datapoints
2025-03-06 22:37:29,563 - INFO - training batch 401, loss: 0.477, 12832/28000 datapoints
2025-03-06 22:37:29,714 - INFO - training batch 451, loss: 0.340, 14432/28000 datapoints
2025-03-06 22:37:29,865 - INFO - training batch 501, loss: 0.148, 16032/28000 datapoints
2025-03-06 22:37:30,020 - INFO - training batch 551, loss: 0.334, 17632/28000 datapoints
2025-03-06 22:37:30,171 - INFO - training batch 601, loss: 0.291, 19232/28000 datapoints
2025-03-06 22:37:30,324 - INFO - training batch 651, loss: 0.061, 20832/28000 datapoints
2025-03-06 22:37:30,475 - INFO - training batch 701, loss: 0.260, 22432/28000 datapoints
2025-03-06 22:37:30,628 - INFO - training batch 751, loss: 0.204, 24032/28000 datapoints
2025-03-06 22:37:30,778 - INFO - training batch 801, loss: 0.105, 25632/28000 datapoints
2025-03-06 22:37:30,938 - INFO - training batch 851, loss: 0.327, 27232/28000 datapoints
2025-03-06 22:37:31,016 - INFO - validation batch 1, loss: 0.073, 32/6976 datapoints
2025-03-06 22:37:31,067 - INFO - validation batch 51, loss: 1.308, 1632/6976 datapoints
2025-03-06 22:37:31,116 - INFO - validation batch 101, loss: 0.367, 3232/6976 datapoints
2025-03-06 22:37:31,163 - INFO - validation batch 151, loss: 0.403, 4832/6976 datapoints
2025-03-06 22:37:31,210 - INFO - validation batch 201, loss: 0.600, 6432/6976 datapoints
2025-03-06 22:37:31,226 - INFO - Epoch 228/800 done.
2025-03-06 22:37:31,226 - INFO - Final validation performance:
Loss: 0.550, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:37:31,227 - INFO - Beginning epoch 229/800
2025-03-06 22:37:31,232 - INFO - training batch 1, loss: 0.314, 32/28000 datapoints
2025-03-06 22:37:31,392 - INFO - training batch 51, loss: 0.107, 1632/28000 datapoints
2025-03-06 22:37:31,547 - INFO - training batch 101, loss: 0.161, 3232/28000 datapoints
2025-03-06 22:37:31,701 - INFO - training batch 151, loss: 0.372, 4832/28000 datapoints
2025-03-06 22:37:31,851 - INFO - training batch 201, loss: 0.090, 6432/28000 datapoints
2025-03-06 22:37:32,046 - INFO - training batch 251, loss: 0.446, 8032/28000 datapoints
2025-03-06 22:37:32,199 - INFO - training batch 301, loss: 0.627, 9632/28000 datapoints
2025-03-06 22:37:32,353 - INFO - training batch 351, loss: 0.215, 11232/28000 datapoints
2025-03-06 22:37:32,502 - INFO - training batch 401, loss: 0.472, 12832/28000 datapoints
2025-03-06 22:37:32,655 - INFO - training batch 451, loss: 0.339, 14432/28000 datapoints
2025-03-06 22:37:32,808 - INFO - training batch 501, loss: 0.147, 16032/28000 datapoints
2025-03-06 22:37:32,980 - INFO - training batch 551, loss: 0.332, 17632/28000 datapoints
2025-03-06 22:37:33,144 - INFO - training batch 601, loss: 0.289, 19232/28000 datapoints
2025-03-06 22:37:33,297 - INFO - training batch 651, loss: 0.060, 20832/28000 datapoints
2025-03-06 22:37:33,451 - INFO - training batch 701, loss: 0.259, 22432/28000 datapoints
2025-03-06 22:37:33,611 - INFO - training batch 751, loss: 0.201, 24032/28000 datapoints
2025-03-06 22:37:33,764 - INFO - training batch 801, loss: 0.105, 25632/28000 datapoints
2025-03-06 22:37:33,919 - INFO - training batch 851, loss: 0.321, 27232/28000 datapoints
2025-03-06 22:37:33,996 - INFO - validation batch 1, loss: 0.072, 32/6976 datapoints
2025-03-06 22:37:34,068 - INFO - validation batch 51, loss: 1.309, 1632/6976 datapoints
2025-03-06 22:37:34,129 - INFO - validation batch 101, loss: 0.367, 3232/6976 datapoints
2025-03-06 22:37:34,178 - INFO - validation batch 151, loss: 0.403, 4832/6976 datapoints
2025-03-06 22:37:34,225 - INFO - validation batch 201, loss: 0.602, 6432/6976 datapoints
2025-03-06 22:37:34,242 - INFO - Epoch 229/800 done.
2025-03-06 22:37:34,242 - INFO - Final validation performance:
Loss: 0.551, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:37:34,242 - INFO - Beginning epoch 230/800
2025-03-06 22:37:34,247 - INFO - training batch 1, loss: 0.312, 32/28000 datapoints
2025-03-06 22:37:34,401 - INFO - training batch 51, loss: 0.107, 1632/28000 datapoints
2025-03-06 22:37:34,556 - INFO - training batch 101, loss: 0.161, 3232/28000 datapoints
2025-03-06 22:37:34,708 - INFO - training batch 151, loss: 0.364, 4832/28000 datapoints
2025-03-06 22:37:34,859 - INFO - training batch 201, loss: 0.089, 6432/28000 datapoints
2025-03-06 22:37:35,013 - INFO - training batch 251, loss: 0.445, 8032/28000 datapoints
2025-03-06 22:37:35,168 - INFO - training batch 301, loss: 0.626, 9632/28000 datapoints
2025-03-06 22:37:35,323 - INFO - training batch 351, loss: 0.215, 11232/28000 datapoints
2025-03-06 22:37:35,480 - INFO - training batch 401, loss: 0.470, 12832/28000 datapoints
2025-03-06 22:37:35,633 - INFO - training batch 451, loss: 0.338, 14432/28000 datapoints
2025-03-06 22:37:35,787 - INFO - training batch 501, loss: 0.147, 16032/28000 datapoints
2025-03-06 22:37:35,940 - INFO - training batch 551, loss: 0.330, 17632/28000 datapoints
2025-03-06 22:37:36,095 - INFO - training batch 601, loss: 0.285, 19232/28000 datapoints
2025-03-06 22:37:36,247 - INFO - training batch 651, loss: 0.060, 20832/28000 datapoints
2025-03-06 22:37:36,399 - INFO - training batch 701, loss: 0.259, 22432/28000 datapoints
2025-03-06 22:37:36,552 - INFO - training batch 751, loss: 0.202, 24032/28000 datapoints
2025-03-06 22:37:36,705 - INFO - training batch 801, loss: 0.103, 25632/28000 datapoints
2025-03-06 22:37:36,856 - INFO - training batch 851, loss: 0.321, 27232/28000 datapoints
2025-03-06 22:37:36,929 - INFO - validation batch 1, loss: 0.072, 32/6976 datapoints
2025-03-06 22:37:36,980 - INFO - validation batch 51, loss: 1.310, 1632/6976 datapoints
2025-03-06 22:37:37,027 - INFO - validation batch 101, loss: 0.368, 3232/6976 datapoints
2025-03-06 22:37:37,076 - INFO - validation batch 151, loss: 0.403, 4832/6976 datapoints
2025-03-06 22:37:37,124 - INFO - validation batch 201, loss: 0.603, 6432/6976 datapoints
2025-03-06 22:37:37,140 - INFO - Epoch 230/800 done.
2025-03-06 22:37:37,141 - INFO - Final validation performance:
Loss: 0.551, top-1 acc: 0.875top-5 acc: 0.875
2025-03-06 22:37:37,141 - INFO - Beginning epoch 231/800
2025-03-06 22:37:37,146 - INFO - training batch 1, loss: 0.313, 32/28000 datapoints
2025-03-06 22:37:37,297 - INFO - training batch 51, loss: 0.105, 1632/28000 datapoints
2025-03-06 22:37:37,452 - INFO - training batch 101, loss: 0.160, 3232/28000 datapoints
2025-03-06 22:37:37,605 - INFO - training batch 151, loss: 0.361, 4832/28000 datapoints
2025-03-06 22:37:37,756 - INFO - training batch 201, loss: 0.088, 6432/28000 datapoints
2025-03-06 22:37:37,908 - INFO - training batch 251, loss: 0.445, 8032/28000 datapoints
2025-03-06 22:37:38,076 - INFO - training batch 301, loss: 0.625, 9632/28000 datapoints
2025-03-06 22:37:38,234 - INFO - training batch 351, loss: 0.213, 11232/28000 datapoints
2025-03-06 22:37:38,385 - INFO - training batch 401, loss: 0.464, 12832/28000 datapoints
2025-03-06 22:37:38,536 - INFO - training batch 451, loss: 0.337, 14432/28000 datapoints
2025-03-06 22:37:38,688 - INFO - training batch 501, loss: 0.146, 16032/28000 datapoints
2025-03-06 22:37:38,840 - INFO - training batch 551, loss: 0.327, 17632/28000 datapoints
2025-03-06 22:37:38,994 - INFO - training batch 601, loss: 0.283, 19232/28000 datapoints
2025-03-06 22:37:39,160 - INFO - training batch 651, loss: 0.059, 20832/28000 datapoints
2025-03-06 22:37:39,312 - INFO - training batch 701, loss: 0.257, 22432/28000 datapoints
2025-03-06 22:37:39,468 - INFO - training batch 751, loss: 0.201, 24032/28000 datapoints
2025-03-06 22:37:39,631 - INFO - training batch 801, loss: 0.102, 25632/28000 datapoints
2025-03-06 22:37:39,784 - INFO - training batch 851, loss: 0.317, 27232/28000 datapoints
2025-03-06 22:37:39,858 - INFO - validation batch 1, loss: 0.072, 32/6976 datapoints
2025-03-06 22:37:39,907 - INFO - validation batch 51, loss: 1.312, 1632/6976 datapoints
2025-03-06 22:37:39,964 - INFO - validation batch 101, loss: 0.369, 3232/6976 datapoints
2025-03-06 22:37:40,014 - INFO - validation batch 151, loss: 0.404, 4832/6976 datapoints
2025-03-06 22:37:40,067 - INFO - validation batch 201, loss: 0.605, 6432/6976 datapoints
2025-03-06 22:37:40,087 - INFO - Epoch 231/800 done.
2025-03-06 22:37:40,087 - INFO - Final validation performance:
Loss: 0.552, top-1 acc: 0.875top-5 acc: 0.875
2025-03-06 22:37:40,087 - INFO - Beginning epoch 232/800
2025-03-06 22:37:40,093 - INFO - training batch 1, loss: 0.311, 32/28000 datapoints
2025-03-06 22:37:40,248 - INFO - training batch 51, loss: 0.104, 1632/28000 datapoints
2025-03-06 22:37:40,402 - INFO - training batch 101, loss: 0.159, 3232/28000 datapoints
2025-03-06 22:37:40,553 - INFO - training batch 151, loss: 0.356, 4832/28000 datapoints
2025-03-06 22:37:40,707 - INFO - training batch 201, loss: 0.087, 6432/28000 datapoints
2025-03-06 22:37:40,858 - INFO - training batch 251, loss: 0.444, 8032/28000 datapoints
2025-03-06 22:37:41,011 - INFO - training batch 301, loss: 0.624, 9632/28000 datapoints
2025-03-06 22:37:41,166 - INFO - training batch 351, loss: 0.212, 11232/28000 datapoints
2025-03-06 22:37:41,317 - INFO - training batch 401, loss: 0.459, 12832/28000 datapoints
2025-03-06 22:37:41,474 - INFO - training batch 451, loss: 0.335, 14432/28000 datapoints
2025-03-06 22:37:41,627 - INFO - training batch 501, loss: 0.146, 16032/28000 datapoints
2025-03-06 22:37:41,780 - INFO - training batch 551, loss: 0.326, 17632/28000 datapoints
2025-03-06 22:37:41,932 - INFO - training batch 601, loss: 0.281, 19232/28000 datapoints
2025-03-06 22:37:42,086 - INFO - training batch 651, loss: 0.058, 20832/28000 datapoints
2025-03-06 22:37:42,239 - INFO - training batch 701, loss: 0.257, 22432/28000 datapoints
2025-03-06 22:37:42,393 - INFO - training batch 751, loss: 0.198, 24032/28000 datapoints
2025-03-06 22:37:42,543 - INFO - training batch 801, loss: 0.101, 25632/28000 datapoints
2025-03-06 22:37:42,696 - INFO - training batch 851, loss: 0.314, 27232/28000 datapoints
2025-03-06 22:37:42,769 - INFO - validation batch 1, loss: 0.072, 32/6976 datapoints
2025-03-06 22:37:42,818 - INFO - validation batch 51, loss: 1.312, 1632/6976 datapoints
2025-03-06 22:37:42,865 - INFO - validation batch 101, loss: 0.371, 3232/6976 datapoints
2025-03-06 22:37:42,913 - INFO - validation batch 151, loss: 0.404, 4832/6976 datapoints
2025-03-06 22:37:42,963 - INFO - validation batch 201, loss: 0.605, 6432/6976 datapoints
2025-03-06 22:37:42,982 - INFO - Epoch 232/800 done.
2025-03-06 22:37:42,982 - INFO - Final validation performance:
Loss: 0.553, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:37:42,983 - INFO - Beginning epoch 233/800
2025-03-06 22:37:42,987 - INFO - training batch 1, loss: 0.310, 32/28000 datapoints
2025-03-06 22:37:43,139 - INFO - training batch 51, loss: 0.104, 1632/28000 datapoints
2025-03-06 22:37:43,293 - INFO - training batch 101, loss: 0.158, 3232/28000 datapoints
2025-03-06 22:37:43,453 - INFO - training batch 151, loss: 0.351, 4832/28000 datapoints
2025-03-06 22:37:43,604 - INFO - training batch 201, loss: 0.086, 6432/28000 datapoints
2025-03-06 22:37:43,759 - INFO - training batch 251, loss: 0.443, 8032/28000 datapoints
2025-03-06 22:37:43,909 - INFO - training batch 301, loss: 0.622, 9632/28000 datapoints
2025-03-06 22:37:44,070 - INFO - training batch 351, loss: 0.212, 11232/28000 datapoints
2025-03-06 22:37:44,251 - INFO - training batch 401, loss: 0.455, 12832/28000 datapoints
2025-03-06 22:37:44,401 - INFO - training batch 451, loss: 0.335, 14432/28000 datapoints
2025-03-06 22:37:44,552 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-06 22:37:44,719 - INFO - training batch 551, loss: 0.323, 17632/28000 datapoints
2025-03-06 22:37:44,873 - INFO - training batch 601, loss: 0.278, 19232/28000 datapoints
2025-03-06 22:37:45,028 - INFO - training batch 651, loss: 0.057, 20832/28000 datapoints
2025-03-06 22:37:45,182 - INFO - training batch 701, loss: 0.256, 22432/28000 datapoints
2025-03-06 22:37:45,351 - INFO - training batch 751, loss: 0.199, 24032/28000 datapoints
2025-03-06 22:37:45,505 - INFO - training batch 801, loss: 0.100, 25632/28000 datapoints
2025-03-06 22:37:45,659 - INFO - training batch 851, loss: 0.311, 27232/28000 datapoints
2025-03-06 22:37:45,741 - INFO - validation batch 1, loss: 0.071, 32/6976 datapoints
2025-03-06 22:37:45,791 - INFO - validation batch 51, loss: 1.315, 1632/6976 datapoints
2025-03-06 22:37:45,839 - INFO - validation batch 101, loss: 0.370, 3232/6976 datapoints
2025-03-06 22:37:45,890 - INFO - validation batch 151, loss: 0.403, 4832/6976 datapoints
2025-03-06 22:37:45,938 - INFO - validation batch 201, loss: 0.606, 6432/6976 datapoints
2025-03-06 22:37:45,958 - INFO - Epoch 233/800 done.
2025-03-06 22:37:45,958 - INFO - Final validation performance:
Loss: 0.553, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:37:45,958 - INFO - Beginning epoch 234/800
2025-03-06 22:37:45,963 - INFO - training batch 1, loss: 0.309, 32/28000 datapoints
2025-03-06 22:37:46,119 - INFO - training batch 51, loss: 0.102, 1632/28000 datapoints
2025-03-06 22:37:46,273 - INFO - training batch 101, loss: 0.157, 3232/28000 datapoints
2025-03-06 22:37:46,426 - INFO - training batch 151, loss: 0.348, 4832/28000 datapoints
2025-03-06 22:37:46,577 - INFO - training batch 201, loss: 0.086, 6432/28000 datapoints
2025-03-06 22:37:46,729 - INFO - training batch 251, loss: 0.442, 8032/28000 datapoints
2025-03-06 22:37:46,880 - INFO - training batch 301, loss: 0.622, 9632/28000 datapoints
2025-03-06 22:37:47,034 - INFO - training batch 351, loss: 0.212, 11232/28000 datapoints
2025-03-06 22:37:47,186 - INFO - training batch 401, loss: 0.451, 12832/28000 datapoints
2025-03-06 22:37:47,342 - INFO - training batch 451, loss: 0.333, 14432/28000 datapoints
2025-03-06 22:37:47,510 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-06 22:37:47,663 - INFO - training batch 551, loss: 0.320, 17632/28000 datapoints
2025-03-06 22:37:47,816 - INFO - training batch 601, loss: 0.274, 19232/28000 datapoints
2025-03-06 22:37:47,971 - INFO - training batch 651, loss: 0.057, 20832/28000 datapoints
2025-03-06 22:37:48,121 - INFO - training batch 701, loss: 0.255, 22432/28000 datapoints
2025-03-06 22:37:48,273 - INFO - training batch 751, loss: 0.197, 24032/28000 datapoints
2025-03-06 22:37:48,424 - INFO - training batch 801, loss: 0.099, 25632/28000 datapoints
2025-03-06 22:37:48,574 - INFO - training batch 851, loss: 0.308, 27232/28000 datapoints
2025-03-06 22:37:48,649 - INFO - validation batch 1, loss: 0.071, 32/6976 datapoints
2025-03-06 22:37:48,696 - INFO - validation batch 51, loss: 1.318, 1632/6976 datapoints
2025-03-06 22:37:48,745 - INFO - validation batch 101, loss: 0.371, 3232/6976 datapoints
2025-03-06 22:37:48,793 - INFO - validation batch 151, loss: 0.403, 4832/6976 datapoints
2025-03-06 22:37:48,840 - INFO - validation batch 201, loss: 0.607, 6432/6976 datapoints
2025-03-06 22:37:48,857 - INFO - Epoch 234/800 done.
2025-03-06 22:37:48,857 - INFO - Final validation performance:
Loss: 0.554, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:37:48,857 - INFO - Beginning epoch 235/800
2025-03-06 22:37:48,862 - INFO - training batch 1, loss: 0.308, 32/28000 datapoints
2025-03-06 22:37:49,017 - INFO - training batch 51, loss: 0.100, 1632/28000 datapoints
2025-03-06 22:37:49,167 - INFO - training batch 101, loss: 0.157, 3232/28000 datapoints
2025-03-06 22:37:49,321 - INFO - training batch 151, loss: 0.345, 4832/28000 datapoints
2025-03-06 22:37:49,475 - INFO - training batch 201, loss: 0.085, 6432/28000 datapoints
2025-03-06 22:37:49,625 - INFO - training batch 251, loss: 0.443, 8032/28000 datapoints
2025-03-06 22:37:49,780 - INFO - training batch 301, loss: 0.620, 9632/28000 datapoints
2025-03-06 22:37:49,931 - INFO - training batch 351, loss: 0.210, 11232/28000 datapoints
2025-03-06 22:37:50,086 - INFO - training batch 401, loss: 0.446, 12832/28000 datapoints
2025-03-06 22:37:50,239 - INFO - training batch 451, loss: 0.332, 14432/28000 datapoints
2025-03-06 22:37:50,393 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-06 22:37:50,546 - INFO - training batch 551, loss: 0.319, 17632/28000 datapoints
2025-03-06 22:37:50,699 - INFO - training batch 601, loss: 0.272, 19232/28000 datapoints
2025-03-06 22:37:50,852 - INFO - training batch 651, loss: 0.056, 20832/28000 datapoints
2025-03-06 22:37:51,004 - INFO - training batch 701, loss: 0.254, 22432/28000 datapoints
2025-03-06 22:37:51,167 - INFO - training batch 751, loss: 0.196, 24032/28000 datapoints
2025-03-06 22:37:51,319 - INFO - training batch 801, loss: 0.099, 25632/28000 datapoints
2025-03-06 22:37:51,485 - INFO - training batch 851, loss: 0.306, 27232/28000 datapoints
2025-03-06 22:37:51,563 - INFO - validation batch 1, loss: 0.071, 32/6976 datapoints
2025-03-06 22:37:51,610 - INFO - validation batch 51, loss: 1.320, 1632/6976 datapoints
2025-03-06 22:37:51,659 - INFO - validation batch 101, loss: 0.372, 3232/6976 datapoints
2025-03-06 22:37:51,708 - INFO - validation batch 151, loss: 0.403, 4832/6976 datapoints
2025-03-06 22:37:51,755 - INFO - validation batch 201, loss: 0.609, 6432/6976 datapoints
2025-03-06 22:37:51,771 - INFO - Epoch 235/800 done.
2025-03-06 22:37:51,772 - INFO - Final validation performance:
Loss: 0.555, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:37:51,772 - INFO - Beginning epoch 236/800
2025-03-06 22:37:51,777 - INFO - training batch 1, loss: 0.306, 32/28000 datapoints
2025-03-06 22:37:51,935 - INFO - training batch 51, loss: 0.100, 1632/28000 datapoints
2025-03-06 22:37:52,089 - INFO - training batch 101, loss: 0.157, 3232/28000 datapoints
2025-03-06 22:37:52,242 - INFO - training batch 151, loss: 0.341, 4832/28000 datapoints
2025-03-06 22:37:52,395 - INFO - training batch 201, loss: 0.084, 6432/28000 datapoints
2025-03-06 22:37:52,546 - INFO - training batch 251, loss: 0.443, 8032/28000 datapoints
2025-03-06 22:37:52,697 - INFO - training batch 301, loss: 0.619, 9632/28000 datapoints
2025-03-06 22:37:52,850 - INFO - training batch 351, loss: 0.210, 11232/28000 datapoints
2025-03-06 22:37:53,003 - INFO - training batch 401, loss: 0.442, 12832/28000 datapoints
2025-03-06 22:37:53,153 - INFO - training batch 451, loss: 0.331, 14432/28000 datapoints
2025-03-06 22:37:53,305 - INFO - training batch 501, loss: 0.144, 16032/28000 datapoints
2025-03-06 22:37:53,461 - INFO - training batch 551, loss: 0.317, 17632/28000 datapoints
2025-03-06 22:37:53,617 - INFO - training batch 601, loss: 0.269, 19232/28000 datapoints
2025-03-06 22:37:53,768 - INFO - training batch 651, loss: 0.055, 20832/28000 datapoints
2025-03-06 22:37:53,920 - INFO - training batch 701, loss: 0.254, 22432/28000 datapoints
2025-03-06 22:37:54,072 - INFO - training batch 751, loss: 0.193, 24032/28000 datapoints
2025-03-06 22:37:54,226 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 22:37:54,397 - INFO - training batch 851, loss: 0.303, 27232/28000 datapoints
2025-03-06 22:37:54,473 - INFO - validation batch 1, loss: 0.070, 32/6976 datapoints
2025-03-06 22:37:54,521 - INFO - validation batch 51, loss: 1.320, 1632/6976 datapoints
2025-03-06 22:37:54,569 - INFO - validation batch 101, loss: 0.373, 3232/6976 datapoints
2025-03-06 22:37:54,617 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 22:37:54,664 - INFO - validation batch 201, loss: 0.609, 6432/6976 datapoints
2025-03-06 22:37:54,683 - INFO - Epoch 236/800 done.
2025-03-06 22:37:54,683 - INFO - Final validation performance:
Loss: 0.556, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:37:54,684 - INFO - Beginning epoch 237/800
2025-03-06 22:37:54,688 - INFO - training batch 1, loss: 0.306, 32/28000 datapoints
2025-03-06 22:37:54,843 - INFO - training batch 51, loss: 0.099, 1632/28000 datapoints
2025-03-06 22:37:54,997 - INFO - training batch 101, loss: 0.155, 3232/28000 datapoints
2025-03-06 22:37:55,148 - INFO - training batch 151, loss: 0.336, 4832/28000 datapoints
2025-03-06 22:37:55,305 - INFO - training batch 201, loss: 0.083, 6432/28000 datapoints
2025-03-06 22:37:55,462 - INFO - training batch 251, loss: 0.442, 8032/28000 datapoints
2025-03-06 22:37:55,614 - INFO - training batch 301, loss: 0.619, 9632/28000 datapoints
2025-03-06 22:37:55,768 - INFO - training batch 351, loss: 0.208, 11232/28000 datapoints
2025-03-06 22:37:55,920 - INFO - training batch 401, loss: 0.438, 12832/28000 datapoints
2025-03-06 22:37:56,075 - INFO - training batch 451, loss: 0.330, 14432/28000 datapoints
2025-03-06 22:37:56,228 - INFO - training batch 501, loss: 0.143, 16032/28000 datapoints
2025-03-06 22:37:56,381 - INFO - training batch 551, loss: 0.314, 17632/28000 datapoints
2025-03-06 22:37:56,533 - INFO - training batch 601, loss: 0.268, 19232/28000 datapoints
2025-03-06 22:37:56,684 - INFO - training batch 651, loss: 0.055, 20832/28000 datapoints
2025-03-06 22:37:56,836 - INFO - training batch 701, loss: 0.252, 22432/28000 datapoints
2025-03-06 22:37:56,991 - INFO - training batch 751, loss: 0.193, 24032/28000 datapoints
2025-03-06 22:37:57,141 - INFO - training batch 801, loss: 0.096, 25632/28000 datapoints
2025-03-06 22:37:57,296 - INFO - training batch 851, loss: 0.300, 27232/28000 datapoints
2025-03-06 22:37:57,373 - INFO - validation batch 1, loss: 0.070, 32/6976 datapoints
2025-03-06 22:37:57,423 - INFO - validation batch 51, loss: 1.323, 1632/6976 datapoints
2025-03-06 22:37:57,471 - INFO - validation batch 101, loss: 0.374, 3232/6976 datapoints
2025-03-06 22:37:57,518 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 22:37:57,565 - INFO - validation batch 201, loss: 0.611, 6432/6976 datapoints
2025-03-06 22:37:57,581 - INFO - Epoch 237/800 done.
2025-03-06 22:37:57,581 - INFO - Final validation performance:
Loss: 0.557, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:37:57,582 - INFO - Beginning epoch 238/800
2025-03-06 22:37:57,586 - INFO - training batch 1, loss: 0.304, 32/28000 datapoints
2025-03-06 22:37:57,756 - INFO - training batch 51, loss: 0.097, 1632/28000 datapoints
2025-03-06 22:37:57,932 - INFO - training batch 101, loss: 0.154, 3232/28000 datapoints
2025-03-06 22:37:58,091 - INFO - training batch 151, loss: 0.328, 4832/28000 datapoints
2025-03-06 22:37:58,246 - INFO - training batch 201, loss: 0.080, 6432/28000 datapoints
2025-03-06 22:37:58,404 - INFO - training batch 251, loss: 0.441, 8032/28000 datapoints
2025-03-06 22:37:58,560 - INFO - training batch 301, loss: 0.620, 9632/28000 datapoints
2025-03-06 22:37:58,716 - INFO - training batch 351, loss: 0.208, 11232/28000 datapoints
2025-03-06 22:37:58,870 - INFO - training batch 401, loss: 0.435, 12832/28000 datapoints
2025-03-06 22:37:59,025 - INFO - training batch 451, loss: 0.330, 14432/28000 datapoints
2025-03-06 22:37:59,176 - INFO - training batch 501, loss: 0.142, 16032/28000 datapoints
2025-03-06 22:37:59,329 - INFO - training batch 551, loss: 0.313, 17632/28000 datapoints
2025-03-06 22:37:59,485 - INFO - training batch 601, loss: 0.267, 19232/28000 datapoints
2025-03-06 22:37:59,637 - INFO - training batch 651, loss: 0.054, 20832/28000 datapoints
2025-03-06 22:37:59,791 - INFO - training batch 701, loss: 0.252, 22432/28000 datapoints
2025-03-06 22:37:59,944 - INFO - training batch 751, loss: 0.192, 24032/28000 datapoints
2025-03-06 22:38:00,097 - INFO - training batch 801, loss: 0.096, 25632/28000 datapoints
2025-03-06 22:38:00,252 - INFO - training batch 851, loss: 0.296, 27232/28000 datapoints
2025-03-06 22:38:00,330 - INFO - validation batch 1, loss: 0.070, 32/6976 datapoints
2025-03-06 22:38:00,379 - INFO - validation batch 51, loss: 1.327, 1632/6976 datapoints
2025-03-06 22:38:00,432 - INFO - validation batch 101, loss: 0.374, 3232/6976 datapoints
2025-03-06 22:38:00,481 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 22:38:00,533 - INFO - validation batch 201, loss: 0.612, 6432/6976 datapoints
2025-03-06 22:38:00,551 - INFO - Epoch 238/800 done.
2025-03-06 22:38:00,551 - INFO - Final validation performance:
Loss: 0.558, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:00,552 - INFO - Beginning epoch 239/800
2025-03-06 22:38:00,556 - INFO - training batch 1, loss: 0.302, 32/28000 datapoints
2025-03-06 22:38:00,719 - INFO - training batch 51, loss: 0.096, 1632/28000 datapoints
2025-03-06 22:38:00,876 - INFO - training batch 101, loss: 0.154, 3232/28000 datapoints
2025-03-06 22:38:01,038 - INFO - training batch 151, loss: 0.326, 4832/28000 datapoints
2025-03-06 22:38:01,197 - INFO - training batch 201, loss: 0.081, 6432/28000 datapoints
2025-03-06 22:38:01,353 - INFO - training batch 251, loss: 0.440, 8032/28000 datapoints
2025-03-06 22:38:01,517 - INFO - training batch 301, loss: 0.619, 9632/28000 datapoints
2025-03-06 22:38:01,672 - INFO - training batch 351, loss: 0.208, 11232/28000 datapoints
2025-03-06 22:38:01,829 - INFO - training batch 401, loss: 0.430, 12832/28000 datapoints
2025-03-06 22:38:01,988 - INFO - training batch 451, loss: 0.328, 14432/28000 datapoints
2025-03-06 22:38:02,142 - INFO - training batch 501, loss: 0.142, 16032/28000 datapoints
2025-03-06 22:38:02,300 - INFO - training batch 551, loss: 0.311, 17632/28000 datapoints
2025-03-06 22:38:02,457 - INFO - training batch 601, loss: 0.265, 19232/28000 datapoints
2025-03-06 22:38:02,614 - INFO - training batch 651, loss: 0.053, 20832/28000 datapoints
2025-03-06 22:38:02,771 - INFO - training batch 701, loss: 0.251, 22432/28000 datapoints
2025-03-06 22:38:02,929 - INFO - training batch 751, loss: 0.191, 24032/28000 datapoints
2025-03-06 22:38:03,088 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-06 22:38:03,242 - INFO - training batch 851, loss: 0.294, 27232/28000 datapoints
2025-03-06 22:38:03,320 - INFO - validation batch 1, loss: 0.070, 32/6976 datapoints
2025-03-06 22:38:03,378 - INFO - validation batch 51, loss: 1.327, 1632/6976 datapoints
2025-03-06 22:38:03,430 - INFO - validation batch 101, loss: 0.375, 3232/6976 datapoints
2025-03-06 22:38:03,486 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 22:38:03,538 - INFO - validation batch 201, loss: 0.612, 6432/6976 datapoints
2025-03-06 22:38:03,555 - INFO - Epoch 239/800 done.
2025-03-06 22:38:03,555 - INFO - Final validation performance:
Loss: 0.558, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:03,556 - INFO - Beginning epoch 240/800
2025-03-06 22:38:03,560 - INFO - training batch 1, loss: 0.301, 32/28000 datapoints
2025-03-06 22:38:03,729 - INFO - training batch 51, loss: 0.095, 1632/28000 datapoints
2025-03-06 22:38:03,882 - INFO - training batch 101, loss: 0.153, 3232/28000 datapoints
2025-03-06 22:38:04,038 - INFO - training batch 151, loss: 0.320, 4832/28000 datapoints
2025-03-06 22:38:04,197 - INFO - training batch 201, loss: 0.079, 6432/28000 datapoints
2025-03-06 22:38:04,368 - INFO - training batch 251, loss: 0.440, 8032/28000 datapoints
2025-03-06 22:38:04,534 - INFO - training batch 301, loss: 0.619, 9632/28000 datapoints
2025-03-06 22:38:04,683 - INFO - training batch 351, loss: 0.206, 11232/28000 datapoints
2025-03-06 22:38:04,837 - INFO - training batch 401, loss: 0.427, 12832/28000 datapoints
2025-03-06 22:38:04,995 - INFO - training batch 451, loss: 0.326, 14432/28000 datapoints
2025-03-06 22:38:05,146 - INFO - training batch 501, loss: 0.141, 16032/28000 datapoints
2025-03-06 22:38:05,303 - INFO - training batch 551, loss: 0.308, 17632/28000 datapoints
2025-03-06 22:38:05,460 - INFO - training batch 601, loss: 0.261, 19232/28000 datapoints
2025-03-06 22:38:05,614 - INFO - training batch 651, loss: 0.052, 20832/28000 datapoints
2025-03-06 22:38:05,770 - INFO - training batch 701, loss: 0.250, 22432/28000 datapoints
2025-03-06 22:38:05,921 - INFO - training batch 751, loss: 0.190, 24032/28000 datapoints
2025-03-06 22:38:06,076 - INFO - training batch 801, loss: 0.094, 25632/28000 datapoints
2025-03-06 22:38:06,228 - INFO - training batch 851, loss: 0.292, 27232/28000 datapoints
2025-03-06 22:38:06,303 - INFO - validation batch 1, loss: 0.070, 32/6976 datapoints
2025-03-06 22:38:06,352 - INFO - validation batch 51, loss: 1.330, 1632/6976 datapoints
2025-03-06 22:38:06,400 - INFO - validation batch 101, loss: 0.375, 3232/6976 datapoints
2025-03-06 22:38:06,447 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 22:38:06,496 - INFO - validation batch 201, loss: 0.614, 6432/6976 datapoints
2025-03-06 22:38:06,512 - INFO - Epoch 240/800 done.
2025-03-06 22:38:06,513 - INFO - Final validation performance:
Loss: 0.559, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:06,513 - INFO - Beginning epoch 241/800
2025-03-06 22:38:06,517 - INFO - training batch 1, loss: 0.299, 32/28000 datapoints
2025-03-06 22:38:06,671 - INFO - training batch 51, loss: 0.095, 1632/28000 datapoints
2025-03-06 22:38:06,822 - INFO - training batch 101, loss: 0.152, 3232/28000 datapoints
2025-03-06 22:38:06,977 - INFO - training batch 151, loss: 0.311, 4832/28000 datapoints
2025-03-06 22:38:07,128 - INFO - training batch 201, loss: 0.077, 6432/28000 datapoints
2025-03-06 22:38:07,280 - INFO - training batch 251, loss: 0.439, 8032/28000 datapoints
2025-03-06 22:38:07,432 - INFO - training batch 301, loss: 0.618, 9632/28000 datapoints
2025-03-06 22:38:07,588 - INFO - training batch 351, loss: 0.205, 11232/28000 datapoints
2025-03-06 22:38:07,739 - INFO - training batch 401, loss: 0.422, 12832/28000 datapoints
2025-03-06 22:38:07,893 - INFO - training batch 451, loss: 0.325, 14432/28000 datapoints
2025-03-06 22:38:08,049 - INFO - training batch 501, loss: 0.141, 16032/28000 datapoints
2025-03-06 22:38:08,201 - INFO - training batch 551, loss: 0.307, 17632/28000 datapoints
2025-03-06 22:38:08,353 - INFO - training batch 601, loss: 0.258, 19232/28000 datapoints
2025-03-06 22:38:08,505 - INFO - training batch 651, loss: 0.052, 20832/28000 datapoints
2025-03-06 22:38:08,656 - INFO - training batch 701, loss: 0.250, 22432/28000 datapoints
2025-03-06 22:38:08,810 - INFO - training batch 751, loss: 0.186, 24032/28000 datapoints
2025-03-06 22:38:08,963 - INFO - training batch 801, loss: 0.093, 25632/28000 datapoints
2025-03-06 22:38:09,113 - INFO - training batch 851, loss: 0.289, 27232/28000 datapoints
2025-03-06 22:38:09,188 - INFO - validation batch 1, loss: 0.069, 32/6976 datapoints
2025-03-06 22:38:09,236 - INFO - validation batch 51, loss: 1.332, 1632/6976 datapoints
2025-03-06 22:38:09,283 - INFO - validation batch 101, loss: 0.376, 3232/6976 datapoints
2025-03-06 22:38:09,332 - INFO - validation batch 151, loss: 0.408, 4832/6976 datapoints
2025-03-06 22:38:09,384 - INFO - validation batch 201, loss: 0.615, 6432/6976 datapoints
2025-03-06 22:38:09,405 - INFO - Epoch 241/800 done.
2025-03-06 22:38:09,405 - INFO - Final validation performance:
Loss: 0.560, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:09,406 - INFO - Beginning epoch 242/800
2025-03-06 22:38:09,410 - INFO - training batch 1, loss: 0.297, 32/28000 datapoints
2025-03-06 22:38:09,567 - INFO - training batch 51, loss: 0.094, 1632/28000 datapoints
2025-03-06 22:38:09,732 - INFO - training batch 101, loss: 0.151, 3232/28000 datapoints
2025-03-06 22:38:09,886 - INFO - training batch 151, loss: 0.306, 4832/28000 datapoints
2025-03-06 22:38:10,051 - INFO - training batch 201, loss: 0.077, 6432/28000 datapoints
2025-03-06 22:38:10,207 - INFO - training batch 251, loss: 0.438, 8032/28000 datapoints
2025-03-06 22:38:10,363 - INFO - training batch 301, loss: 0.617, 9632/28000 datapoints
2025-03-06 22:38:10,518 - INFO - training batch 351, loss: 0.206, 11232/28000 datapoints
2025-03-06 22:38:10,671 - INFO - training batch 401, loss: 0.418, 12832/28000 datapoints
2025-03-06 22:38:10,822 - INFO - training batch 451, loss: 0.324, 14432/28000 datapoints
2025-03-06 22:38:10,977 - INFO - training batch 501, loss: 0.140, 16032/28000 datapoints
2025-03-06 22:38:11,129 - INFO - training batch 551, loss: 0.305, 17632/28000 datapoints
2025-03-06 22:38:11,286 - INFO - training batch 601, loss: 0.256, 19232/28000 datapoints
2025-03-06 22:38:11,439 - INFO - training batch 651, loss: 0.051, 20832/28000 datapoints
2025-03-06 22:38:11,594 - INFO - training batch 701, loss: 0.249, 22432/28000 datapoints
2025-03-06 22:38:11,743 - INFO - training batch 751, loss: 0.187, 24032/28000 datapoints
2025-03-06 22:38:11,895 - INFO - training batch 801, loss: 0.092, 25632/28000 datapoints
2025-03-06 22:38:12,047 - INFO - training batch 851, loss: 0.286, 27232/28000 datapoints
2025-03-06 22:38:12,124 - INFO - validation batch 1, loss: 0.069, 32/6976 datapoints
2025-03-06 22:38:12,173 - INFO - validation batch 51, loss: 1.335, 1632/6976 datapoints
2025-03-06 22:38:12,220 - INFO - validation batch 101, loss: 0.376, 3232/6976 datapoints
2025-03-06 22:38:12,268 - INFO - validation batch 151, loss: 0.408, 4832/6976 datapoints
2025-03-06 22:38:12,316 - INFO - validation batch 201, loss: 0.616, 6432/6976 datapoints
2025-03-06 22:38:12,332 - INFO - Epoch 242/800 done.
2025-03-06 22:38:12,332 - INFO - Final validation performance:
Loss: 0.561, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:12,333 - INFO - Beginning epoch 243/800
2025-03-06 22:38:12,337 - INFO - training batch 1, loss: 0.296, 32/28000 datapoints
2025-03-06 22:38:12,493 - INFO - training batch 51, loss: 0.093, 1632/28000 datapoints
2025-03-06 22:38:12,645 - INFO - training batch 101, loss: 0.151, 3232/28000 datapoints
2025-03-06 22:38:12,802 - INFO - training batch 151, loss: 0.302, 4832/28000 datapoints
2025-03-06 22:38:12,955 - INFO - training batch 201, loss: 0.076, 6432/28000 datapoints
2025-03-06 22:38:13,108 - INFO - training batch 251, loss: 0.438, 8032/28000 datapoints
2025-03-06 22:38:13,259 - INFO - training batch 301, loss: 0.616, 9632/28000 datapoints
2025-03-06 22:38:13,410 - INFO - training batch 351, loss: 0.205, 11232/28000 datapoints
2025-03-06 22:38:13,566 - INFO - training batch 401, loss: 0.414, 12832/28000 datapoints
2025-03-06 22:38:13,723 - INFO - training batch 451, loss: 0.323, 14432/28000 datapoints
2025-03-06 22:38:13,875 - INFO - training batch 501, loss: 0.139, 16032/28000 datapoints
2025-03-06 22:38:14,030 - INFO - training batch 551, loss: 0.302, 17632/28000 datapoints
2025-03-06 22:38:14,194 - INFO - training batch 601, loss: 0.252, 19232/28000 datapoints
2025-03-06 22:38:14,346 - INFO - training batch 651, loss: 0.050, 20832/28000 datapoints
2025-03-06 22:38:14,521 - INFO - training batch 701, loss: 0.248, 22432/28000 datapoints
2025-03-06 22:38:14,672 - INFO - training batch 751, loss: 0.186, 24032/28000 datapoints
2025-03-06 22:38:14,824 - INFO - training batch 801, loss: 0.092, 25632/28000 datapoints
2025-03-06 22:38:14,979 - INFO - training batch 851, loss: 0.284, 27232/28000 datapoints
2025-03-06 22:38:15,054 - INFO - validation batch 1, loss: 0.069, 32/6976 datapoints
2025-03-06 22:38:15,102 - INFO - validation batch 51, loss: 1.336, 1632/6976 datapoints
2025-03-06 22:38:15,149 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-06 22:38:15,200 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 22:38:15,247 - INFO - validation batch 201, loss: 0.619, 6432/6976 datapoints
2025-03-06 22:38:15,263 - INFO - Epoch 243/800 done.
2025-03-06 22:38:15,263 - INFO - Final validation performance:
Loss: 0.562, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:15,263 - INFO - Beginning epoch 244/800
2025-03-06 22:38:15,268 - INFO - training batch 1, loss: 0.294, 32/28000 datapoints
2025-03-06 22:38:15,423 - INFO - training batch 51, loss: 0.091, 1632/28000 datapoints
2025-03-06 22:38:15,576 - INFO - training batch 101, loss: 0.150, 3232/28000 datapoints
2025-03-06 22:38:15,746 - INFO - training batch 151, loss: 0.298, 4832/28000 datapoints
2025-03-06 22:38:15,900 - INFO - training batch 201, loss: 0.075, 6432/28000 datapoints
2025-03-06 22:38:16,054 - INFO - training batch 251, loss: 0.437, 8032/28000 datapoints
2025-03-06 22:38:16,231 - INFO - training batch 301, loss: 0.616, 9632/28000 datapoints
2025-03-06 22:38:16,414 - INFO - training batch 351, loss: 0.203, 11232/28000 datapoints
2025-03-06 22:38:16,595 - INFO - training batch 401, loss: 0.409, 12832/28000 datapoints
2025-03-06 22:38:16,769 - INFO - training batch 451, loss: 0.323, 14432/28000 datapoints
2025-03-06 22:38:16,928 - INFO - training batch 501, loss: 0.140, 16032/28000 datapoints
2025-03-06 22:38:17,084 - INFO - training batch 551, loss: 0.300, 17632/28000 datapoints
2025-03-06 22:38:17,238 - INFO - training batch 601, loss: 0.249, 19232/28000 datapoints
2025-03-06 22:38:17,392 - INFO - training batch 651, loss: 0.050, 20832/28000 datapoints
2025-03-06 22:38:17,548 - INFO - training batch 701, loss: 0.247, 22432/28000 datapoints
2025-03-06 22:38:17,698 - INFO - training batch 751, loss: 0.185, 24032/28000 datapoints
2025-03-06 22:38:17,850 - INFO - training batch 801, loss: 0.091, 25632/28000 datapoints
2025-03-06 22:38:18,002 - INFO - training batch 851, loss: 0.281, 27232/28000 datapoints
2025-03-06 22:38:18,082 - INFO - validation batch 1, loss: 0.069, 32/6976 datapoints
2025-03-06 22:38:18,129 - INFO - validation batch 51, loss: 1.339, 1632/6976 datapoints
2025-03-06 22:38:18,181 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-06 22:38:18,228 - INFO - validation batch 151, loss: 0.408, 4832/6976 datapoints
2025-03-06 22:38:18,275 - INFO - validation batch 201, loss: 0.620, 6432/6976 datapoints
2025-03-06 22:38:18,292 - INFO - Epoch 244/800 done.
2025-03-06 22:38:18,292 - INFO - Final validation performance:
Loss: 0.563, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:18,292 - INFO - Beginning epoch 245/800
2025-03-06 22:38:18,296 - INFO - training batch 1, loss: 0.293, 32/28000 datapoints
2025-03-06 22:38:18,451 - INFO - training batch 51, loss: 0.090, 1632/28000 datapoints
2025-03-06 22:38:18,602 - INFO - training batch 101, loss: 0.149, 3232/28000 datapoints
2025-03-06 22:38:18,756 - INFO - training batch 151, loss: 0.293, 4832/28000 datapoints
2025-03-06 22:38:18,908 - INFO - training batch 201, loss: 0.075, 6432/28000 datapoints
2025-03-06 22:38:19,060 - INFO - training batch 251, loss: 0.436, 8032/28000 datapoints
2025-03-06 22:38:19,213 - INFO - training batch 301, loss: 0.614, 9632/28000 datapoints
2025-03-06 22:38:19,364 - INFO - training batch 351, loss: 0.204, 11232/28000 datapoints
2025-03-06 22:38:19,517 - INFO - training batch 401, loss: 0.406, 12832/28000 datapoints
2025-03-06 22:38:19,668 - INFO - training batch 451, loss: 0.322, 14432/28000 datapoints
2025-03-06 22:38:19,821 - INFO - training batch 501, loss: 0.140, 16032/28000 datapoints
2025-03-06 22:38:19,976 - INFO - training batch 551, loss: 0.297, 17632/28000 datapoints
2025-03-06 22:38:20,127 - INFO - training batch 601, loss: 0.246, 19232/28000 datapoints
2025-03-06 22:38:20,279 - INFO - training batch 651, loss: 0.049, 20832/28000 datapoints
2025-03-06 22:38:20,438 - INFO - training batch 701, loss: 0.246, 22432/28000 datapoints
2025-03-06 22:38:20,592 - INFO - training batch 751, loss: 0.184, 24032/28000 datapoints
2025-03-06 22:38:20,748 - INFO - training batch 801, loss: 0.090, 25632/28000 datapoints
2025-03-06 22:38:20,902 - INFO - training batch 851, loss: 0.279, 27232/28000 datapoints
2025-03-06 22:38:20,981 - INFO - validation batch 1, loss: 0.069, 32/6976 datapoints
2025-03-06 22:38:21,033 - INFO - validation batch 51, loss: 1.342, 1632/6976 datapoints
2025-03-06 22:38:21,083 - INFO - validation batch 101, loss: 0.379, 3232/6976 datapoints
2025-03-06 22:38:21,133 - INFO - validation batch 151, loss: 0.408, 4832/6976 datapoints
2025-03-06 22:38:21,191 - INFO - validation batch 201, loss: 0.621, 6432/6976 datapoints
2025-03-06 22:38:21,211 - INFO - Epoch 245/800 done.
2025-03-06 22:38:21,211 - INFO - Final validation performance:
Loss: 0.564, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:21,212 - INFO - Beginning epoch 246/800
2025-03-06 22:38:21,217 - INFO - training batch 1, loss: 0.291, 32/28000 datapoints
2025-03-06 22:38:21,370 - INFO - training batch 51, loss: 0.090, 1632/28000 datapoints
2025-03-06 22:38:21,525 - INFO - training batch 101, loss: 0.148, 3232/28000 datapoints
2025-03-06 22:38:21,686 - INFO - training batch 151, loss: 0.293, 4832/28000 datapoints
2025-03-06 22:38:21,845 - INFO - training batch 201, loss: 0.074, 6432/28000 datapoints
2025-03-06 22:38:21,999 - INFO - training batch 251, loss: 0.436, 8032/28000 datapoints
2025-03-06 22:38:22,156 - INFO - training batch 301, loss: 0.615, 9632/28000 datapoints
2025-03-06 22:38:22,312 - INFO - training batch 351, loss: 0.202, 11232/28000 datapoints
2025-03-06 22:38:22,466 - INFO - training batch 401, loss: 0.403, 12832/28000 datapoints
2025-03-06 22:38:22,622 - INFO - training batch 451, loss: 0.321, 14432/28000 datapoints
2025-03-06 22:38:22,773 - INFO - training batch 501, loss: 0.138, 16032/28000 datapoints
2025-03-06 22:38:22,925 - INFO - training batch 551, loss: 0.295, 17632/28000 datapoints
2025-03-06 22:38:23,078 - INFO - training batch 601, loss: 0.246, 19232/28000 datapoints
2025-03-06 22:38:23,230 - INFO - training batch 651, loss: 0.049, 20832/28000 datapoints
2025-03-06 22:38:23,382 - INFO - training batch 701, loss: 0.246, 22432/28000 datapoints
2025-03-06 22:38:23,535 - INFO - training batch 751, loss: 0.180, 24032/28000 datapoints
2025-03-06 22:38:23,685 - INFO - training batch 801, loss: 0.089, 25632/28000 datapoints
2025-03-06 22:38:23,839 - INFO - training batch 851, loss: 0.276, 27232/28000 datapoints
2025-03-06 22:38:23,913 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:38:23,964 - INFO - validation batch 51, loss: 1.344, 1632/6976 datapoints
2025-03-06 22:38:24,013 - INFO - validation batch 101, loss: 0.379, 3232/6976 datapoints
2025-03-06 22:38:24,060 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-06 22:38:24,108 - INFO - validation batch 201, loss: 0.622, 6432/6976 datapoints
2025-03-06 22:38:24,124 - INFO - Epoch 246/800 done.
2025-03-06 22:38:24,124 - INFO - Final validation performance:
Loss: 0.565, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:24,124 - INFO - Beginning epoch 247/800
2025-03-06 22:38:24,129 - INFO - training batch 1, loss: 0.289, 32/28000 datapoints
2025-03-06 22:38:24,287 - INFO - training batch 51, loss: 0.088, 1632/28000 datapoints
2025-03-06 22:38:24,439 - INFO - training batch 101, loss: 0.147, 3232/28000 datapoints
2025-03-06 22:38:24,618 - INFO - training batch 151, loss: 0.285, 4832/28000 datapoints
2025-03-06 22:38:24,773 - INFO - training batch 201, loss: 0.073, 6432/28000 datapoints
2025-03-06 22:38:24,925 - INFO - training batch 251, loss: 0.435, 8032/28000 datapoints
2025-03-06 22:38:25,080 - INFO - training batch 301, loss: 0.613, 9632/28000 datapoints
2025-03-06 22:38:25,236 - INFO - training batch 351, loss: 0.202, 11232/28000 datapoints
2025-03-06 22:38:25,389 - INFO - training batch 401, loss: 0.397, 12832/28000 datapoints
2025-03-06 22:38:25,538 - INFO - training batch 451, loss: 0.319, 14432/28000 datapoints
2025-03-06 22:38:25,695 - INFO - training batch 501, loss: 0.139, 16032/28000 datapoints
2025-03-06 22:38:25,848 - INFO - training batch 551, loss: 0.293, 17632/28000 datapoints
2025-03-06 22:38:26,003 - INFO - training batch 601, loss: 0.242, 19232/28000 datapoints
2025-03-06 22:38:26,156 - INFO - training batch 651, loss: 0.048, 20832/28000 datapoints
2025-03-06 22:38:26,308 - INFO - training batch 701, loss: 0.245, 22432/28000 datapoints
2025-03-06 22:38:26,460 - INFO - training batch 751, loss: 0.181, 24032/28000 datapoints
2025-03-06 22:38:26,613 - INFO - training batch 801, loss: 0.088, 25632/28000 datapoints
2025-03-06 22:38:26,764 - INFO - training batch 851, loss: 0.272, 27232/28000 datapoints
2025-03-06 22:38:26,839 - INFO - validation batch 1, loss: 0.069, 32/6976 datapoints
2025-03-06 22:38:26,886 - INFO - validation batch 51, loss: 1.347, 1632/6976 datapoints
2025-03-06 22:38:26,933 - INFO - validation batch 101, loss: 0.380, 3232/6976 datapoints
2025-03-06 22:38:26,984 - INFO - validation batch 151, loss: 0.409, 4832/6976 datapoints
2025-03-06 22:38:27,031 - INFO - validation batch 201, loss: 0.623, 6432/6976 datapoints
2025-03-06 22:38:27,048 - INFO - Epoch 247/800 done.
2025-03-06 22:38:27,049 - INFO - Final validation performance:
Loss: 0.566, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:27,049 - INFO - Beginning epoch 248/800
2025-03-06 22:38:27,054 - INFO - training batch 1, loss: 0.287, 32/28000 datapoints
2025-03-06 22:38:27,208 - INFO - training batch 51, loss: 0.087, 1632/28000 datapoints
2025-03-06 22:38:27,362 - INFO - training batch 101, loss: 0.147, 3232/28000 datapoints
2025-03-06 22:38:27,514 - INFO - training batch 151, loss: 0.282, 4832/28000 datapoints
2025-03-06 22:38:27,679 - INFO - training batch 201, loss: 0.073, 6432/28000 datapoints
2025-03-06 22:38:27,836 - INFO - training batch 251, loss: 0.435, 8032/28000 datapoints
2025-03-06 22:38:27,992 - INFO - training batch 301, loss: 0.614, 9632/28000 datapoints
2025-03-06 22:38:28,142 - INFO - training batch 351, loss: 0.200, 11232/28000 datapoints
2025-03-06 22:38:28,303 - INFO - training batch 401, loss: 0.394, 12832/28000 datapoints
2025-03-06 22:38:28,458 - INFO - training batch 451, loss: 0.318, 14432/28000 datapoints
2025-03-06 22:38:28,614 - INFO - training batch 501, loss: 0.137, 16032/28000 datapoints
2025-03-06 22:38:28,766 - INFO - training batch 551, loss: 0.291, 17632/28000 datapoints
2025-03-06 22:38:28,922 - INFO - training batch 601, loss: 0.240, 19232/28000 datapoints
2025-03-06 22:38:29,078 - INFO - training batch 651, loss: 0.047, 20832/28000 datapoints
2025-03-06 22:38:29,230 - INFO - training batch 701, loss: 0.245, 22432/28000 datapoints
2025-03-06 22:38:29,381 - INFO - training batch 751, loss: 0.179, 24032/28000 datapoints
2025-03-06 22:38:29,531 - INFO - training batch 801, loss: 0.087, 25632/28000 datapoints
2025-03-06 22:38:29,685 - INFO - training batch 851, loss: 0.270, 27232/28000 datapoints
2025-03-06 22:38:29,761 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:38:29,809 - INFO - validation batch 51, loss: 1.350, 1632/6976 datapoints
2025-03-06 22:38:29,858 - INFO - validation batch 101, loss: 0.381, 3232/6976 datapoints
2025-03-06 22:38:29,905 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-06 22:38:29,956 - INFO - validation batch 201, loss: 0.625, 6432/6976 datapoints
2025-03-06 22:38:29,973 - INFO - Epoch 248/800 done.
2025-03-06 22:38:29,973 - INFO - Final validation performance:
Loss: 0.567, top-1 acc: 0.875top-5 acc: 0.875
2025-03-06 22:38:29,974 - INFO - Beginning epoch 249/800
2025-03-06 22:38:29,978 - INFO - training batch 1, loss: 0.285, 32/28000 datapoints
2025-03-06 22:38:30,130 - INFO - training batch 51, loss: 0.087, 1632/28000 datapoints
2025-03-06 22:38:30,282 - INFO - training batch 101, loss: 0.146, 3232/28000 datapoints
2025-03-06 22:38:30,442 - INFO - training batch 151, loss: 0.279, 4832/28000 datapoints
2025-03-06 22:38:30,596 - INFO - training batch 201, loss: 0.073, 6432/28000 datapoints
2025-03-06 22:38:30,746 - INFO - training batch 251, loss: 0.434, 8032/28000 datapoints
2025-03-06 22:38:30,897 - INFO - training batch 301, loss: 0.612, 9632/28000 datapoints
2025-03-06 22:38:31,050 - INFO - training batch 351, loss: 0.199, 11232/28000 datapoints
2025-03-06 22:38:31,201 - INFO - training batch 401, loss: 0.390, 12832/28000 datapoints
2025-03-06 22:38:31,368 - INFO - training batch 451, loss: 0.317, 14432/28000 datapoints
2025-03-06 22:38:31,523 - INFO - training batch 501, loss: 0.136, 16032/28000 datapoints
2025-03-06 22:38:31,681 - INFO - training batch 551, loss: 0.289, 17632/28000 datapoints
2025-03-06 22:38:31,834 - INFO - training batch 601, loss: 0.238, 19232/28000 datapoints
2025-03-06 22:38:31,991 - INFO - training batch 651, loss: 0.047, 20832/28000 datapoints
2025-03-06 22:38:32,142 - INFO - training batch 701, loss: 0.244, 22432/28000 datapoints
2025-03-06 22:38:32,296 - INFO - training batch 751, loss: 0.178, 24032/28000 datapoints
2025-03-06 22:38:32,489 - INFO - training batch 801, loss: 0.086, 25632/28000 datapoints
2025-03-06 22:38:32,641 - INFO - training batch 851, loss: 0.267, 27232/28000 datapoints
2025-03-06 22:38:32,715 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:38:32,765 - INFO - validation batch 51, loss: 1.353, 1632/6976 datapoints
2025-03-06 22:38:32,812 - INFO - validation batch 101, loss: 0.381, 3232/6976 datapoints
2025-03-06 22:38:32,863 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-06 22:38:32,910 - INFO - validation batch 201, loss: 0.626, 6432/6976 datapoints
2025-03-06 22:38:32,926 - INFO - Epoch 249/800 done.
2025-03-06 22:38:32,926 - INFO - Final validation performance:
Loss: 0.568, top-1 acc: 0.875top-5 acc: 0.875
2025-03-06 22:38:32,927 - INFO - Beginning epoch 250/800
2025-03-06 22:38:32,931 - INFO - training batch 1, loss: 0.283, 32/28000 datapoints
2025-03-06 22:38:33,086 - INFO - training batch 51, loss: 0.085, 1632/28000 datapoints
2025-03-06 22:38:33,238 - INFO - training batch 101, loss: 0.145, 3232/28000 datapoints
2025-03-06 22:38:33,392 - INFO - training batch 151, loss: 0.276, 4832/28000 datapoints
2025-03-06 22:38:33,545 - INFO - training batch 201, loss: 0.072, 6432/28000 datapoints
2025-03-06 22:38:33,707 - INFO - training batch 251, loss: 0.434, 8032/28000 datapoints
2025-03-06 22:38:33,864 - INFO - training batch 301, loss: 0.612, 9632/28000 datapoints
2025-03-06 22:38:34,017 - INFO - training batch 351, loss: 0.199, 11232/28000 datapoints
2025-03-06 22:38:34,173 - INFO - training batch 401, loss: 0.385, 12832/28000 datapoints
2025-03-06 22:38:34,334 - INFO - training batch 451, loss: 0.317, 14432/28000 datapoints
2025-03-06 22:38:34,496 - INFO - training batch 501, loss: 0.137, 16032/28000 datapoints
2025-03-06 22:38:34,669 - INFO - training batch 551, loss: 0.287, 17632/28000 datapoints
2025-03-06 22:38:34,831 - INFO - training batch 601, loss: 0.236, 19232/28000 datapoints
2025-03-06 22:38:34,987 - INFO - training batch 651, loss: 0.046, 20832/28000 datapoints
2025-03-06 22:38:35,137 - INFO - training batch 701, loss: 0.243, 22432/28000 datapoints
2025-03-06 22:38:35,295 - INFO - training batch 751, loss: 0.177, 24032/28000 datapoints
2025-03-06 22:38:35,449 - INFO - training batch 801, loss: 0.086, 25632/28000 datapoints
2025-03-06 22:38:35,602 - INFO - training batch 851, loss: 0.264, 27232/28000 datapoints
2025-03-06 22:38:35,679 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:38:35,726 - INFO - validation batch 51, loss: 1.356, 1632/6976 datapoints
2025-03-06 22:38:35,773 - INFO - validation batch 101, loss: 0.382, 3232/6976 datapoints
2025-03-06 22:38:35,820 - INFO - validation batch 151, loss: 0.411, 4832/6976 datapoints
2025-03-06 22:38:35,870 - INFO - validation batch 201, loss: 0.628, 6432/6976 datapoints
2025-03-06 22:38:35,887 - INFO - Epoch 250/800 done.
2025-03-06 22:38:35,888 - INFO - Final validation performance:
Loss: 0.569, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:35,888 - INFO - Beginning epoch 251/800
2025-03-06 22:38:35,892 - INFO - training batch 1, loss: 0.282, 32/28000 datapoints
2025-03-06 22:38:36,050 - INFO - training batch 51, loss: 0.084, 1632/28000 datapoints
2025-03-06 22:38:36,202 - INFO - training batch 101, loss: 0.145, 3232/28000 datapoints
2025-03-06 22:38:36,358 - INFO - training batch 151, loss: 0.273, 4832/28000 datapoints
2025-03-06 22:38:36,508 - INFO - training batch 201, loss: 0.071, 6432/28000 datapoints
2025-03-06 22:38:36,658 - INFO - training batch 251, loss: 0.433, 8032/28000 datapoints
2025-03-06 22:38:36,809 - INFO - training batch 301, loss: 0.610, 9632/28000 datapoints
2025-03-06 22:38:36,964 - INFO - training batch 351, loss: 0.197, 11232/28000 datapoints
2025-03-06 22:38:37,115 - INFO - training batch 401, loss: 0.381, 12832/28000 datapoints
2025-03-06 22:38:37,265 - INFO - training batch 451, loss: 0.315, 14432/28000 datapoints
2025-03-06 22:38:37,417 - INFO - training batch 501, loss: 0.136, 16032/28000 datapoints
2025-03-06 22:38:37,570 - INFO - training batch 551, loss: 0.286, 17632/28000 datapoints
2025-03-06 22:38:37,724 - INFO - training batch 601, loss: 0.234, 19232/28000 datapoints
2025-03-06 22:38:37,876 - INFO - training batch 651, loss: 0.045, 20832/28000 datapoints
2025-03-06 22:38:38,039 - INFO - training batch 701, loss: 0.243, 22432/28000 datapoints
2025-03-06 22:38:38,190 - INFO - training batch 751, loss: 0.175, 24032/28000 datapoints
2025-03-06 22:38:38,340 - INFO - training batch 801, loss: 0.085, 25632/28000 datapoints
2025-03-06 22:38:38,492 - INFO - training batch 851, loss: 0.261, 27232/28000 datapoints
2025-03-06 22:38:38,566 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:38:38,614 - INFO - validation batch 51, loss: 1.358, 1632/6976 datapoints
2025-03-06 22:38:38,662 - INFO - validation batch 101, loss: 0.383, 3232/6976 datapoints
2025-03-06 22:38:38,709 - INFO - validation batch 151, loss: 0.411, 4832/6976 datapoints
2025-03-06 22:38:38,758 - INFO - validation batch 201, loss: 0.629, 6432/6976 datapoints
2025-03-06 22:38:38,774 - INFO - Epoch 251/800 done.
2025-03-06 22:38:38,774 - INFO - Final validation performance:
Loss: 0.570, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:38,775 - INFO - Beginning epoch 252/800
2025-03-06 22:38:38,779 - INFO - training batch 1, loss: 0.280, 32/28000 datapoints
2025-03-06 22:38:38,935 - INFO - training batch 51, loss: 0.084, 1632/28000 datapoints
2025-03-06 22:38:39,088 - INFO - training batch 101, loss: 0.145, 3232/28000 datapoints
2025-03-06 22:38:39,241 - INFO - training batch 151, loss: 0.270, 4832/28000 datapoints
2025-03-06 22:38:39,397 - INFO - training batch 201, loss: 0.071, 6432/28000 datapoints
2025-03-06 22:38:39,548 - INFO - training batch 251, loss: 0.433, 8032/28000 datapoints
2025-03-06 22:38:39,702 - INFO - training batch 301, loss: 0.610, 9632/28000 datapoints
2025-03-06 22:38:39,870 - INFO - training batch 351, loss: 0.197, 11232/28000 datapoints
2025-03-06 22:38:40,027 - INFO - training batch 401, loss: 0.378, 12832/28000 datapoints
2025-03-06 22:38:40,183 - INFO - training batch 451, loss: 0.314, 14432/28000 datapoints
2025-03-06 22:38:40,337 - INFO - training batch 501, loss: 0.135, 16032/28000 datapoints
2025-03-06 22:38:40,511 - INFO - training batch 551, loss: 0.283, 17632/28000 datapoints
2025-03-06 22:38:40,670 - INFO - training batch 601, loss: 0.232, 19232/28000 datapoints
2025-03-06 22:38:40,824 - INFO - training batch 651, loss: 0.045, 20832/28000 datapoints
2025-03-06 22:38:40,983 - INFO - training batch 701, loss: 0.242, 22432/28000 datapoints
2025-03-06 22:38:41,137 - INFO - training batch 751, loss: 0.174, 24032/28000 datapoints
2025-03-06 22:38:41,296 - INFO - training batch 801, loss: 0.084, 25632/28000 datapoints
2025-03-06 22:38:41,452 - INFO - training batch 851, loss: 0.260, 27232/28000 datapoints
2025-03-06 22:38:41,531 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:38:41,584 - INFO - validation batch 51, loss: 1.361, 1632/6976 datapoints
2025-03-06 22:38:41,640 - INFO - validation batch 101, loss: 0.384, 3232/6976 datapoints
2025-03-06 22:38:41,691 - INFO - validation batch 151, loss: 0.412, 4832/6976 datapoints
2025-03-06 22:38:41,739 - INFO - validation batch 201, loss: 0.631, 6432/6976 datapoints
2025-03-06 22:38:41,756 - INFO - Epoch 252/800 done.
2025-03-06 22:38:41,756 - INFO - Final validation performance:
Loss: 0.571, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:41,756 - INFO - Beginning epoch 253/800
2025-03-06 22:38:41,761 - INFO - training batch 1, loss: 0.278, 32/28000 datapoints
2025-03-06 22:38:41,916 - INFO - training batch 51, loss: 0.082, 1632/28000 datapoints
2025-03-06 22:38:42,072 - INFO - training batch 101, loss: 0.144, 3232/28000 datapoints
2025-03-06 22:38:42,225 - INFO - training batch 151, loss: 0.262, 4832/28000 datapoints
2025-03-06 22:38:42,377 - INFO - training batch 201, loss: 0.070, 6432/28000 datapoints
2025-03-06 22:38:42,527 - INFO - training batch 251, loss: 0.432, 8032/28000 datapoints
2025-03-06 22:38:42,678 - INFO - training batch 301, loss: 0.608, 9632/28000 datapoints
2025-03-06 22:38:42,828 - INFO - training batch 351, loss: 0.196, 11232/28000 datapoints
2025-03-06 22:38:42,984 - INFO - training batch 401, loss: 0.375, 12832/28000 datapoints
2025-03-06 22:38:43,134 - INFO - training batch 451, loss: 0.313, 14432/28000 datapoints
2025-03-06 22:38:43,285 - INFO - training batch 501, loss: 0.136, 16032/28000 datapoints
2025-03-06 22:38:43,437 - INFO - training batch 551, loss: 0.281, 17632/28000 datapoints
2025-03-06 22:38:43,590 - INFO - training batch 601, loss: 0.229, 19232/28000 datapoints
2025-03-06 22:38:43,745 - INFO - training batch 651, loss: 0.044, 20832/28000 datapoints
2025-03-06 22:38:43,894 - INFO - training batch 701, loss: 0.241, 22432/28000 datapoints
2025-03-06 22:38:44,050 - INFO - training batch 751, loss: 0.171, 24032/28000 datapoints
2025-03-06 22:38:44,208 - INFO - training batch 801, loss: 0.082, 25632/28000 datapoints
2025-03-06 22:38:44,360 - INFO - training batch 851, loss: 0.258, 27232/28000 datapoints
2025-03-06 22:38:44,435 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:38:44,483 - INFO - validation batch 51, loss: 1.362, 1632/6976 datapoints
2025-03-06 22:38:44,530 - INFO - validation batch 101, loss: 0.386, 3232/6976 datapoints
2025-03-06 22:38:44,578 - INFO - validation batch 151, loss: 0.412, 4832/6976 datapoints
2025-03-06 22:38:44,625 - INFO - validation batch 201, loss: 0.633, 6432/6976 datapoints
2025-03-06 22:38:44,642 - INFO - Epoch 253/800 done.
2025-03-06 22:38:44,642 - INFO - Final validation performance:
Loss: 0.572, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:44,643 - INFO - Beginning epoch 254/800
2025-03-06 22:38:44,647 - INFO - training batch 1, loss: 0.276, 32/28000 datapoints
2025-03-06 22:38:44,823 - INFO - training batch 51, loss: 0.082, 1632/28000 datapoints
2025-03-06 22:38:44,984 - INFO - training batch 101, loss: 0.143, 3232/28000 datapoints
2025-03-06 22:38:45,135 - INFO - training batch 151, loss: 0.259, 4832/28000 datapoints
2025-03-06 22:38:45,292 - INFO - training batch 201, loss: 0.069, 6432/28000 datapoints
2025-03-06 22:38:45,445 - INFO - training batch 251, loss: 0.432, 8032/28000 datapoints
2025-03-06 22:38:45,598 - INFO - training batch 301, loss: 0.606, 9632/28000 datapoints
2025-03-06 22:38:45,758 - INFO - training batch 351, loss: 0.195, 11232/28000 datapoints
2025-03-06 22:38:45,926 - INFO - training batch 401, loss: 0.371, 12832/28000 datapoints
2025-03-06 22:38:46,082 - INFO - training batch 451, loss: 0.312, 14432/28000 datapoints
2025-03-06 22:38:46,240 - INFO - training batch 501, loss: 0.135, 16032/28000 datapoints
2025-03-06 22:38:46,396 - INFO - training batch 551, loss: 0.280, 17632/28000 datapoints
2025-03-06 22:38:46,554 - INFO - training batch 601, loss: 0.228, 19232/28000 datapoints
2025-03-06 22:38:46,713 - INFO - training batch 651, loss: 0.044, 20832/28000 datapoints
2025-03-06 22:38:46,864 - INFO - training batch 701, loss: 0.240, 22432/28000 datapoints
2025-03-06 22:38:47,018 - INFO - training batch 751, loss: 0.172, 24032/28000 datapoints
2025-03-06 22:38:47,168 - INFO - training batch 801, loss: 0.082, 25632/28000 datapoints
2025-03-06 22:38:47,318 - INFO - training batch 851, loss: 0.255, 27232/28000 datapoints
2025-03-06 22:38:47,394 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:38:47,444 - INFO - validation batch 51, loss: 1.368, 1632/6976 datapoints
2025-03-06 22:38:47,492 - INFO - validation batch 101, loss: 0.387, 3232/6976 datapoints
2025-03-06 22:38:47,541 - INFO - validation batch 151, loss: 0.412, 4832/6976 datapoints
2025-03-06 22:38:47,590 - INFO - validation batch 201, loss: 0.634, 6432/6976 datapoints
2025-03-06 22:38:47,606 - INFO - Epoch 254/800 done.
2025-03-06 22:38:47,606 - INFO - Final validation performance:
Loss: 0.574, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:47,607 - INFO - Beginning epoch 255/800
2025-03-06 22:38:47,611 - INFO - training batch 1, loss: 0.274, 32/28000 datapoints
2025-03-06 22:38:47,770 - INFO - training batch 51, loss: 0.081, 1632/28000 datapoints
2025-03-06 22:38:47,923 - INFO - training batch 101, loss: 0.143, 3232/28000 datapoints
2025-03-06 22:38:48,082 - INFO - training batch 151, loss: 0.255, 4832/28000 datapoints
2025-03-06 22:38:48,235 - INFO - training batch 201, loss: 0.068, 6432/28000 datapoints
2025-03-06 22:38:48,386 - INFO - training batch 251, loss: 0.432, 8032/28000 datapoints
2025-03-06 22:38:48,538 - INFO - training batch 301, loss: 0.606, 9632/28000 datapoints
2025-03-06 22:38:48,688 - INFO - training batch 351, loss: 0.195, 11232/28000 datapoints
2025-03-06 22:38:48,838 - INFO - training batch 401, loss: 0.367, 12832/28000 datapoints
2025-03-06 22:38:48,991 - INFO - training batch 451, loss: 0.312, 14432/28000 datapoints
2025-03-06 22:38:49,143 - INFO - training batch 501, loss: 0.134, 16032/28000 datapoints
2025-03-06 22:38:49,295 - INFO - training batch 551, loss: 0.277, 17632/28000 datapoints
2025-03-06 22:38:49,446 - INFO - training batch 601, loss: 0.227, 19232/28000 datapoints
2025-03-06 22:38:49,598 - INFO - training batch 651, loss: 0.043, 20832/28000 datapoints
2025-03-06 22:38:49,751 - INFO - training batch 701, loss: 0.240, 22432/28000 datapoints
2025-03-06 22:38:49,902 - INFO - training batch 751, loss: 0.170, 24032/28000 datapoints
2025-03-06 22:38:50,057 - INFO - training batch 801, loss: 0.081, 25632/28000 datapoints
2025-03-06 22:38:50,206 - INFO - training batch 851, loss: 0.253, 27232/28000 datapoints
2025-03-06 22:38:50,282 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:38:50,329 - INFO - validation batch 51, loss: 1.371, 1632/6976 datapoints
2025-03-06 22:38:50,377 - INFO - validation batch 101, loss: 0.388, 3232/6976 datapoints
2025-03-06 22:38:50,425 - INFO - validation batch 151, loss: 0.412, 4832/6976 datapoints
2025-03-06 22:38:50,471 - INFO - validation batch 201, loss: 0.636, 6432/6976 datapoints
2025-03-06 22:38:50,488 - INFO - Epoch 255/800 done.
2025-03-06 22:38:50,488 - INFO - Final validation performance:
Loss: 0.575, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:50,488 - INFO - Beginning epoch 256/800
2025-03-06 22:38:50,492 - INFO - training batch 1, loss: 0.272, 32/28000 datapoints
2025-03-06 22:38:50,648 - INFO - training batch 51, loss: 0.081, 1632/28000 datapoints
2025-03-06 22:38:50,799 - INFO - training batch 101, loss: 0.142, 3232/28000 datapoints
2025-03-06 22:38:50,953 - INFO - training batch 151, loss: 0.250, 4832/28000 datapoints
2025-03-06 22:38:51,142 - INFO - training batch 201, loss: 0.067, 6432/28000 datapoints
2025-03-06 22:38:51,295 - INFO - training batch 251, loss: 0.431, 8032/28000 datapoints
2025-03-06 22:38:51,447 - INFO - training batch 301, loss: 0.604, 9632/28000 datapoints
2025-03-06 22:38:51,600 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 22:38:51,754 - INFO - training batch 401, loss: 0.363, 12832/28000 datapoints
2025-03-06 22:38:51,920 - INFO - training batch 451, loss: 0.311, 14432/28000 datapoints
2025-03-06 22:38:52,077 - INFO - training batch 501, loss: 0.133, 16032/28000 datapoints
2025-03-06 22:38:52,229 - INFO - training batch 551, loss: 0.275, 17632/28000 datapoints
2025-03-06 22:38:52,387 - INFO - training batch 601, loss: 0.224, 19232/28000 datapoints
2025-03-06 22:38:52,543 - INFO - training batch 651, loss: 0.042, 20832/28000 datapoints
2025-03-06 22:38:52,697 - INFO - training batch 701, loss: 0.239, 22432/28000 datapoints
2025-03-06 22:38:52,854 - INFO - training batch 751, loss: 0.169, 24032/28000 datapoints
2025-03-06 22:38:53,006 - INFO - training batch 801, loss: 0.080, 25632/28000 datapoints
2025-03-06 22:38:53,160 - INFO - training batch 851, loss: 0.252, 27232/28000 datapoints
2025-03-06 22:38:53,234 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:38:53,282 - INFO - validation batch 51, loss: 1.374, 1632/6976 datapoints
2025-03-06 22:38:53,329 - INFO - validation batch 101, loss: 0.389, 3232/6976 datapoints
2025-03-06 22:38:53,383 - INFO - validation batch 151, loss: 0.414, 4832/6976 datapoints
2025-03-06 22:38:53,441 - INFO - validation batch 201, loss: 0.638, 6432/6976 datapoints
2025-03-06 22:38:53,462 - INFO - Epoch 256/800 done.
2025-03-06 22:38:53,462 - INFO - Final validation performance:
Loss: 0.576, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:53,462 - INFO - Beginning epoch 257/800
2025-03-06 22:38:53,467 - INFO - training batch 1, loss: 0.270, 32/28000 datapoints
2025-03-06 22:38:53,632 - INFO - training batch 51, loss: 0.079, 1632/28000 datapoints
2025-03-06 22:38:53,786 - INFO - training batch 101, loss: 0.142, 3232/28000 datapoints
2025-03-06 22:38:53,937 - INFO - training batch 151, loss: 0.246, 4832/28000 datapoints
2025-03-06 22:38:54,091 - INFO - training batch 201, loss: 0.067, 6432/28000 datapoints
2025-03-06 22:38:54,244 - INFO - training batch 251, loss: 0.431, 8032/28000 datapoints
2025-03-06 22:38:54,398 - INFO - training batch 301, loss: 0.602, 9632/28000 datapoints
2025-03-06 22:38:54,548 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 22:38:54,700 - INFO - training batch 401, loss: 0.359, 12832/28000 datapoints
2025-03-06 22:38:54,863 - INFO - training batch 451, loss: 0.311, 14432/28000 datapoints
2025-03-06 22:38:55,032 - INFO - training batch 501, loss: 0.134, 16032/28000 datapoints
2025-03-06 22:38:55,185 - INFO - training batch 551, loss: 0.273, 17632/28000 datapoints
2025-03-06 22:38:55,342 - INFO - training batch 601, loss: 0.223, 19232/28000 datapoints
2025-03-06 22:38:55,496 - INFO - training batch 651, loss: 0.042, 20832/28000 datapoints
2025-03-06 22:38:55,651 - INFO - training batch 701, loss: 0.238, 22432/28000 datapoints
2025-03-06 22:38:55,804 - INFO - training batch 751, loss: 0.168, 24032/28000 datapoints
2025-03-06 22:38:55,958 - INFO - training batch 801, loss: 0.080, 25632/28000 datapoints
2025-03-06 22:38:56,109 - INFO - training batch 851, loss: 0.249, 27232/28000 datapoints
2025-03-06 22:38:56,186 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:38:56,234 - INFO - validation batch 51, loss: 1.378, 1632/6976 datapoints
2025-03-06 22:38:56,281 - INFO - validation batch 101, loss: 0.389, 3232/6976 datapoints
2025-03-06 22:38:56,330 - INFO - validation batch 151, loss: 0.415, 4832/6976 datapoints
2025-03-06 22:38:56,378 - INFO - validation batch 201, loss: 0.640, 6432/6976 datapoints
2025-03-06 22:38:56,394 - INFO - Epoch 257/800 done.
2025-03-06 22:38:56,394 - INFO - Final validation performance:
Loss: 0.578, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:56,395 - INFO - Beginning epoch 258/800
2025-03-06 22:38:56,399 - INFO - training batch 1, loss: 0.268, 32/28000 datapoints
2025-03-06 22:38:56,554 - INFO - training batch 51, loss: 0.078, 1632/28000 datapoints
2025-03-06 22:38:56,709 - INFO - training batch 101, loss: 0.141, 3232/28000 datapoints
2025-03-06 22:38:56,859 - INFO - training batch 151, loss: 0.244, 4832/28000 datapoints
2025-03-06 22:38:57,013 - INFO - training batch 201, loss: 0.066, 6432/28000 datapoints
2025-03-06 22:38:57,163 - INFO - training batch 251, loss: 0.430, 8032/28000 datapoints
2025-03-06 22:38:57,314 - INFO - training batch 301, loss: 0.602, 9632/28000 datapoints
2025-03-06 22:38:57,464 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 22:38:57,614 - INFO - training batch 401, loss: 0.356, 12832/28000 datapoints
2025-03-06 22:38:57,770 - INFO - training batch 451, loss: 0.310, 14432/28000 datapoints
2025-03-06 22:38:57,922 - INFO - training batch 501, loss: 0.133, 16032/28000 datapoints
2025-03-06 22:38:58,091 - INFO - training batch 551, loss: 0.271, 17632/28000 datapoints
2025-03-06 22:38:58,244 - INFO - training batch 601, loss: 0.220, 19232/28000 datapoints
2025-03-06 22:38:58,400 - INFO - training batch 651, loss: 0.041, 20832/28000 datapoints
2025-03-06 22:38:58,554 - INFO - training batch 701, loss: 0.237, 22432/28000 datapoints
2025-03-06 22:38:58,708 - INFO - training batch 751, loss: 0.167, 24032/28000 datapoints
2025-03-06 22:38:58,865 - INFO - training batch 801, loss: 0.079, 25632/28000 datapoints
2025-03-06 22:38:59,017 - INFO - training batch 851, loss: 0.248, 27232/28000 datapoints
2025-03-06 22:38:59,091 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:38:59,139 - INFO - validation batch 51, loss: 1.382, 1632/6976 datapoints
2025-03-06 22:38:59,188 - INFO - validation batch 101, loss: 0.391, 3232/6976 datapoints
2025-03-06 22:38:59,236 - INFO - validation batch 151, loss: 0.416, 4832/6976 datapoints
2025-03-06 22:38:59,285 - INFO - validation batch 201, loss: 0.641, 6432/6976 datapoints
2025-03-06 22:38:59,305 - INFO - Epoch 258/800 done.
2025-03-06 22:38:59,305 - INFO - Final validation performance:
Loss: 0.579, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:38:59,305 - INFO - Beginning epoch 259/800
2025-03-06 22:38:59,310 - INFO - training batch 1, loss: 0.266, 32/28000 datapoints
2025-03-06 22:38:59,462 - INFO - training batch 51, loss: 0.078, 1632/28000 datapoints
2025-03-06 22:38:59,615 - INFO - training batch 101, loss: 0.141, 3232/28000 datapoints
2025-03-06 22:38:59,774 - INFO - training batch 151, loss: 0.239, 4832/28000 datapoints
2025-03-06 22:38:59,924 - INFO - training batch 201, loss: 0.066, 6432/28000 datapoints
2025-03-06 22:39:00,079 - INFO - training batch 251, loss: 0.430, 8032/28000 datapoints
2025-03-06 22:39:00,238 - INFO - training batch 301, loss: 0.599, 9632/28000 datapoints
2025-03-06 22:39:00,391 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 22:39:00,548 - INFO - training batch 401, loss: 0.352, 12832/28000 datapoints
2025-03-06 22:39:00,704 - INFO - training batch 451, loss: 0.310, 14432/28000 datapoints
2025-03-06 22:39:00,859 - INFO - training batch 501, loss: 0.132, 16032/28000 datapoints
2025-03-06 22:39:01,019 - INFO - training batch 551, loss: 0.269, 17632/28000 datapoints
2025-03-06 22:39:01,175 - INFO - training batch 601, loss: 0.218, 19232/28000 datapoints
2025-03-06 22:39:01,342 - INFO - training batch 651, loss: 0.041, 20832/28000 datapoints
2025-03-06 22:39:01,499 - INFO - training batch 701, loss: 0.236, 22432/28000 datapoints
2025-03-06 22:39:01,655 - INFO - training batch 751, loss: 0.166, 24032/28000 datapoints
2025-03-06 22:39:01,817 - INFO - training batch 801, loss: 0.078, 25632/28000 datapoints
2025-03-06 22:39:01,975 - INFO - training batch 851, loss: 0.245, 27232/28000 datapoints
2025-03-06 22:39:02,055 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:39:02,107 - INFO - validation batch 51, loss: 1.384, 1632/6976 datapoints
2025-03-06 22:39:02,160 - INFO - validation batch 101, loss: 0.392, 3232/6976 datapoints
2025-03-06 22:39:02,215 - INFO - validation batch 151, loss: 0.416, 4832/6976 datapoints
2025-03-06 22:39:02,267 - INFO - validation batch 201, loss: 0.643, 6432/6976 datapoints
2025-03-06 22:39:02,286 - INFO - Epoch 259/800 done.
2025-03-06 22:39:02,286 - INFO - Final validation performance:
Loss: 0.581, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:39:02,287 - INFO - Beginning epoch 260/800
2025-03-06 22:39:02,291 - INFO - training batch 1, loss: 0.265, 32/28000 datapoints
2025-03-06 22:39:02,453 - INFO - training batch 51, loss: 0.077, 1632/28000 datapoints
2025-03-06 22:39:02,608 - INFO - training batch 101, loss: 0.140, 3232/28000 datapoints
2025-03-06 22:39:02,769 - INFO - training batch 151, loss: 0.237, 4832/28000 datapoints
2025-03-06 22:39:02,924 - INFO - training batch 201, loss: 0.065, 6432/28000 datapoints
2025-03-06 22:39:03,085 - INFO - training batch 251, loss: 0.429, 8032/28000 datapoints
2025-03-06 22:39:03,240 - INFO - training batch 301, loss: 0.600, 9632/28000 datapoints
2025-03-06 22:39:03,395 - INFO - training batch 351, loss: 0.192, 11232/28000 datapoints
2025-03-06 22:39:03,550 - INFO - training batch 401, loss: 0.348, 12832/28000 datapoints
2025-03-06 22:39:03,711 - INFO - training batch 451, loss: 0.309, 14432/28000 datapoints
2025-03-06 22:39:03,871 - INFO - training batch 501, loss: 0.131, 16032/28000 datapoints
2025-03-06 22:39:04,032 - INFO - training batch 551, loss: 0.267, 17632/28000 datapoints
2025-03-06 22:39:04,209 - INFO - training batch 601, loss: 0.218, 19232/28000 datapoints
2025-03-06 22:39:04,367 - INFO - training batch 651, loss: 0.040, 20832/28000 datapoints
2025-03-06 22:39:04,524 - INFO - training batch 701, loss: 0.235, 22432/28000 datapoints
2025-03-06 22:39:04,683 - INFO - training batch 751, loss: 0.165, 24032/28000 datapoints
2025-03-06 22:39:04,841 - INFO - training batch 801, loss: 0.077, 25632/28000 datapoints
2025-03-06 22:39:05,024 - INFO - training batch 851, loss: 0.243, 27232/28000 datapoints
2025-03-06 22:39:05,104 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:39:05,156 - INFO - validation batch 51, loss: 1.390, 1632/6976 datapoints
2025-03-06 22:39:05,217 - INFO - validation batch 101, loss: 0.393, 3232/6976 datapoints
2025-03-06 22:39:05,270 - INFO - validation batch 151, loss: 0.418, 4832/6976 datapoints
2025-03-06 22:39:05,322 - INFO - validation batch 201, loss: 0.643, 6432/6976 datapoints
2025-03-06 22:39:05,342 - INFO - Epoch 260/800 done.
2025-03-06 22:39:05,342 - INFO - Final validation performance:
Loss: 0.582, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:39:05,343 - INFO - Beginning epoch 261/800
2025-03-06 22:39:05,348 - INFO - training batch 1, loss: 0.263, 32/28000 datapoints
2025-03-06 22:39:05,509 - INFO - training batch 51, loss: 0.076, 1632/28000 datapoints
2025-03-06 22:39:05,667 - INFO - training batch 101, loss: 0.139, 3232/28000 datapoints
2025-03-06 22:39:05,828 - INFO - training batch 151, loss: 0.234, 4832/28000 datapoints
2025-03-06 22:39:05,984 - INFO - training batch 201, loss: 0.064, 6432/28000 datapoints
2025-03-06 22:39:06,138 - INFO - training batch 251, loss: 0.429, 8032/28000 datapoints
2025-03-06 22:39:06,310 - INFO - training batch 301, loss: 0.599, 9632/28000 datapoints
2025-03-06 22:39:06,466 - INFO - training batch 351, loss: 0.192, 11232/28000 datapoints
2025-03-06 22:39:06,623 - INFO - training batch 401, loss: 0.344, 12832/28000 datapoints
2025-03-06 22:39:06,778 - INFO - training batch 451, loss: 0.308, 14432/28000 datapoints
2025-03-06 22:39:06,933 - INFO - training batch 501, loss: 0.131, 16032/28000 datapoints
2025-03-06 22:39:07,092 - INFO - training batch 551, loss: 0.265, 17632/28000 datapoints
2025-03-06 22:39:07,246 - INFO - training batch 601, loss: 0.216, 19232/28000 datapoints
2025-03-06 22:39:07,403 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 22:39:07,557 - INFO - training batch 701, loss: 0.234, 22432/28000 datapoints
2025-03-06 22:39:07,711 - INFO - training batch 751, loss: 0.162, 24032/28000 datapoints
2025-03-06 22:39:07,871 - INFO - training batch 801, loss: 0.076, 25632/28000 datapoints
2025-03-06 22:39:08,028 - INFO - training batch 851, loss: 0.241, 27232/28000 datapoints
2025-03-06 22:39:08,107 - INFO - validation batch 1, loss: 0.067, 32/6976 datapoints
2025-03-06 22:39:08,159 - INFO - validation batch 51, loss: 1.390, 1632/6976 datapoints
2025-03-06 22:39:08,213 - INFO - validation batch 101, loss: 0.395, 3232/6976 datapoints
2025-03-06 22:39:08,267 - INFO - validation batch 151, loss: 0.419, 4832/6976 datapoints
2025-03-06 22:39:08,320 - INFO - validation batch 201, loss: 0.646, 6432/6976 datapoints
2025-03-06 22:39:08,339 - INFO - Epoch 261/800 done.
2025-03-06 22:39:08,339 - INFO - Final validation performance:
Loss: 0.584, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:39:08,339 - INFO - Beginning epoch 262/800
2025-03-06 22:39:08,344 - INFO - training batch 1, loss: 0.263, 32/28000 datapoints
2025-03-06 22:39:08,505 - INFO - training batch 51, loss: 0.076, 1632/28000 datapoints
2025-03-06 22:39:08,659 - INFO - training batch 101, loss: 0.139, 3232/28000 datapoints
2025-03-06 22:39:08,816 - INFO - training batch 151, loss: 0.230, 4832/28000 datapoints
2025-03-06 22:39:08,972 - INFO - training batch 201, loss: 0.063, 6432/28000 datapoints
2025-03-06 22:39:09,126 - INFO - training batch 251, loss: 0.429, 8032/28000 datapoints
2025-03-06 22:39:09,280 - INFO - training batch 301, loss: 0.598, 9632/28000 datapoints
2025-03-06 22:39:09,441 - INFO - training batch 351, loss: 0.192, 11232/28000 datapoints
2025-03-06 22:39:09,594 - INFO - training batch 401, loss: 0.341, 12832/28000 datapoints
2025-03-06 22:39:09,753 - INFO - training batch 451, loss: 0.307, 14432/28000 datapoints
2025-03-06 22:39:09,908 - INFO - training batch 501, loss: 0.130, 16032/28000 datapoints
2025-03-06 22:39:10,092 - INFO - training batch 551, loss: 0.262, 17632/28000 datapoints
2025-03-06 22:39:10,258 - INFO - training batch 601, loss: 0.213, 19232/28000 datapoints
2025-03-06 22:39:10,421 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 22:39:10,574 - INFO - training batch 701, loss: 0.233, 22432/28000 datapoints
2025-03-06 22:39:10,735 - INFO - training batch 751, loss: 0.161, 24032/28000 datapoints
2025-03-06 22:39:10,893 - INFO - training batch 801, loss: 0.076, 25632/28000 datapoints
2025-03-06 22:39:11,050 - INFO - training batch 851, loss: 0.240, 27232/28000 datapoints
2025-03-06 22:39:11,131 - INFO - validation batch 1, loss: 0.067, 32/6976 datapoints
2025-03-06 22:39:11,184 - INFO - validation batch 51, loss: 1.395, 1632/6976 datapoints
2025-03-06 22:39:11,237 - INFO - validation batch 101, loss: 0.395, 3232/6976 datapoints
2025-03-06 22:39:11,289 - INFO - validation batch 151, loss: 0.420, 4832/6976 datapoints
2025-03-06 22:39:11,346 - INFO - validation batch 201, loss: 0.648, 6432/6976 datapoints
2025-03-06 22:39:11,364 - INFO - Epoch 262/800 done.
2025-03-06 22:39:11,364 - INFO - Final validation performance:
Loss: 0.585, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:39:11,364 - INFO - Beginning epoch 263/800
2025-03-06 22:39:11,369 - INFO - training batch 1, loss: 0.260, 32/28000 datapoints
2025-03-06 22:39:11,526 - INFO - training batch 51, loss: 0.075, 1632/28000 datapoints
2025-03-06 22:39:11,684 - INFO - training batch 101, loss: 0.139, 3232/28000 datapoints
2025-03-06 22:39:11,845 - INFO - training batch 151, loss: 0.226, 4832/28000 datapoints
2025-03-06 22:39:12,000 - INFO - training batch 201, loss: 0.062, 6432/28000 datapoints
2025-03-06 22:39:12,154 - INFO - training batch 251, loss: 0.428, 8032/28000 datapoints
2025-03-06 22:39:12,311 - INFO - training batch 301, loss: 0.598, 9632/28000 datapoints
2025-03-06 22:39:12,467 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:39:12,622 - INFO - training batch 401, loss: 0.336, 12832/28000 datapoints
2025-03-06 22:39:12,780 - INFO - training batch 451, loss: 0.307, 14432/28000 datapoints
2025-03-06 22:39:12,937 - INFO - training batch 501, loss: 0.130, 16032/28000 datapoints
2025-03-06 22:39:13,097 - INFO - training batch 551, loss: 0.260, 17632/28000 datapoints
2025-03-06 22:39:13,252 - INFO - training batch 601, loss: 0.212, 19232/28000 datapoints
2025-03-06 22:39:13,408 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 22:39:13,566 - INFO - training batch 701, loss: 0.233, 22432/28000 datapoints
2025-03-06 22:39:13,721 - INFO - training batch 751, loss: 0.160, 24032/28000 datapoints
2025-03-06 22:39:13,880 - INFO - training batch 801, loss: 0.075, 25632/28000 datapoints
2025-03-06 22:39:14,036 - INFO - training batch 851, loss: 0.239, 27232/28000 datapoints
2025-03-06 22:39:14,114 - INFO - validation batch 1, loss: 0.067, 32/6976 datapoints
2025-03-06 22:39:14,167 - INFO - validation batch 51, loss: 1.399, 1632/6976 datapoints
2025-03-06 22:39:14,219 - INFO - validation batch 101, loss: 0.397, 3232/6976 datapoints
2025-03-06 22:39:14,272 - INFO - validation batch 151, loss: 0.419, 4832/6976 datapoints
2025-03-06 22:39:14,323 - INFO - validation batch 201, loss: 0.653, 6432/6976 datapoints
2025-03-06 22:39:14,342 - INFO - Epoch 263/800 done.
2025-03-06 22:39:14,342 - INFO - Final validation performance:
Loss: 0.587, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:39:14,343 - INFO - Beginning epoch 264/800
2025-03-06 22:39:14,349 - INFO - training batch 1, loss: 0.259, 32/28000 datapoints
2025-03-06 22:39:14,512 - INFO - training batch 51, loss: 0.075, 1632/28000 datapoints
2025-03-06 22:39:14,671 - INFO - training batch 101, loss: 0.139, 3232/28000 datapoints
2025-03-06 22:39:14,826 - INFO - training batch 151, loss: 0.222, 4832/28000 datapoints
2025-03-06 22:39:14,983 - INFO - training batch 201, loss: 0.062, 6432/28000 datapoints
2025-03-06 22:39:15,163 - INFO - training batch 251, loss: 0.428, 8032/28000 datapoints
2025-03-06 22:39:15,322 - INFO - training batch 301, loss: 0.594, 9632/28000 datapoints
2025-03-06 22:39:15,479 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:39:15,633 - INFO - training batch 401, loss: 0.331, 12832/28000 datapoints
2025-03-06 22:39:15,794 - INFO - training batch 451, loss: 0.307, 14432/28000 datapoints
2025-03-06 22:39:15,953 - INFO - training batch 501, loss: 0.130, 16032/28000 datapoints
2025-03-06 22:39:16,110 - INFO - training batch 551, loss: 0.259, 17632/28000 datapoints
2025-03-06 22:39:16,264 - INFO - training batch 601, loss: 0.210, 19232/28000 datapoints
2025-03-06 22:39:16,428 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 22:39:16,589 - INFO - training batch 701, loss: 0.232, 22432/28000 datapoints
2025-03-06 22:39:16,752 - INFO - training batch 751, loss: 0.156, 24032/28000 datapoints
2025-03-06 22:39:16,914 - INFO - training batch 801, loss: 0.074, 25632/28000 datapoints
2025-03-06 22:39:17,076 - INFO - training batch 851, loss: 0.236, 27232/28000 datapoints
2025-03-06 22:39:17,155 - INFO - validation batch 1, loss: 0.067, 32/6976 datapoints
2025-03-06 22:39:17,209 - INFO - validation batch 51, loss: 1.402, 1632/6976 datapoints
2025-03-06 22:39:17,262 - INFO - validation batch 101, loss: 0.398, 3232/6976 datapoints
2025-03-06 22:39:17,315 - INFO - validation batch 151, loss: 0.421, 4832/6976 datapoints
2025-03-06 22:39:17,369 - INFO - validation batch 201, loss: 0.655, 6432/6976 datapoints
2025-03-06 22:39:17,387 - INFO - Epoch 264/800 done.
2025-03-06 22:39:17,387 - INFO - Final validation performance:
Loss: 0.589, top-1 acc: 0.875top-5 acc: 0.875
2025-03-06 22:39:17,388 - INFO - Beginning epoch 265/800
2025-03-06 22:39:17,392 - INFO - training batch 1, loss: 0.257, 32/28000 datapoints
2025-03-06 22:39:17,556 - INFO - training batch 51, loss: 0.074, 1632/28000 datapoints
2025-03-06 22:39:17,709 - INFO - training batch 101, loss: 0.137, 3232/28000 datapoints
2025-03-06 22:39:17,866 - INFO - training batch 151, loss: 0.217, 4832/28000 datapoints
2025-03-06 22:39:18,024 - INFO - training batch 201, loss: 0.061, 6432/28000 datapoints
2025-03-06 22:39:18,180 - INFO - training batch 251, loss: 0.429, 8032/28000 datapoints
2025-03-06 22:39:18,335 - INFO - training batch 301, loss: 0.595, 9632/28000 datapoints
2025-03-06 22:39:18,491 - INFO - training batch 351, loss: 0.190, 11232/28000 datapoints
2025-03-06 22:39:18,649 - INFO - training batch 401, loss: 0.329, 12832/28000 datapoints
2025-03-06 22:39:18,803 - INFO - training batch 451, loss: 0.306, 14432/28000 datapoints
2025-03-06 22:39:18,964 - INFO - training batch 501, loss: 0.130, 16032/28000 datapoints
2025-03-06 22:39:19,120 - INFO - training batch 551, loss: 0.257, 17632/28000 datapoints
2025-03-06 22:39:19,274 - INFO - training batch 601, loss: 0.209, 19232/28000 datapoints
2025-03-06 22:39:19,432 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-06 22:39:19,587 - INFO - training batch 701, loss: 0.231, 22432/28000 datapoints
2025-03-06 22:39:19,742 - INFO - training batch 751, loss: 0.157, 24032/28000 datapoints
2025-03-06 22:39:19,900 - INFO - training batch 801, loss: 0.073, 25632/28000 datapoints
2025-03-06 22:39:20,060 - INFO - training batch 851, loss: 0.234, 27232/28000 datapoints
2025-03-06 22:39:20,138 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:39:20,190 - INFO - validation batch 51, loss: 1.407, 1632/6976 datapoints
2025-03-06 22:39:20,242 - INFO - validation batch 101, loss: 0.399, 3232/6976 datapoints
2025-03-06 22:39:20,294 - INFO - validation batch 151, loss: 0.421, 4832/6976 datapoints
2025-03-06 22:39:20,341 - INFO - validation batch 201, loss: 0.655, 6432/6976 datapoints
2025-03-06 22:39:20,358 - INFO - Epoch 265/800 done.
2025-03-06 22:39:20,358 - INFO - Final validation performance:
Loss: 0.590, top-1 acc: 0.875top-5 acc: 0.875
2025-03-06 22:39:20,358 - INFO - Beginning epoch 266/800
2025-03-06 22:39:20,364 - INFO - training batch 1, loss: 0.255, 32/28000 datapoints
2025-03-06 22:39:20,521 - INFO - training batch 51, loss: 0.073, 1632/28000 datapoints
2025-03-06 22:39:20,674 - INFO - training batch 101, loss: 0.137, 3232/28000 datapoints
2025-03-06 22:39:20,832 - INFO - training batch 151, loss: 0.214, 4832/28000 datapoints
2025-03-06 22:39:20,989 - INFO - training batch 201, loss: 0.060, 6432/28000 datapoints
2025-03-06 22:39:21,144 - INFO - training batch 251, loss: 0.427, 8032/28000 datapoints
2025-03-06 22:39:21,299 - INFO - training batch 301, loss: 0.593, 9632/28000 datapoints
2025-03-06 22:39:21,462 - INFO - training batch 351, loss: 0.190, 11232/28000 datapoints
2025-03-06 22:39:21,619 - INFO - training batch 401, loss: 0.325, 12832/28000 datapoints
2025-03-06 22:39:21,775 - INFO - training batch 451, loss: 0.305, 14432/28000 datapoints
2025-03-06 22:39:21,933 - INFO - training batch 501, loss: 0.128, 16032/28000 datapoints
2025-03-06 22:39:22,092 - INFO - training batch 551, loss: 0.255, 17632/28000 datapoints
2025-03-06 22:39:22,248 - INFO - training batch 601, loss: 0.207, 19232/28000 datapoints
2025-03-06 22:39:22,405 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-06 22:39:22,560 - INFO - training batch 701, loss: 0.230, 22432/28000 datapoints
2025-03-06 22:39:22,729 - INFO - training batch 751, loss: 0.156, 24032/28000 datapoints
2025-03-06 22:39:22,885 - INFO - training batch 801, loss: 0.072, 25632/28000 datapoints
2025-03-06 22:39:23,053 - INFO - training batch 851, loss: 0.232, 27232/28000 datapoints
2025-03-06 22:39:23,132 - INFO - validation batch 1, loss: 0.067, 32/6976 datapoints
2025-03-06 22:39:23,188 - INFO - validation batch 51, loss: 1.411, 1632/6976 datapoints
2025-03-06 22:39:23,239 - INFO - validation batch 101, loss: 0.399, 3232/6976 datapoints
2025-03-06 22:39:23,287 - INFO - validation batch 151, loss: 0.423, 4832/6976 datapoints
2025-03-06 22:39:23,334 - INFO - validation batch 201, loss: 0.656, 6432/6976 datapoints
2025-03-06 22:39:23,351 - INFO - Epoch 266/800 done.
2025-03-06 22:39:23,351 - INFO - Final validation performance:
Loss: 0.591, top-1 acc: 0.875top-5 acc: 0.875
2025-03-06 22:39:23,352 - INFO - Beginning epoch 267/800
2025-03-06 22:39:23,356 - INFO - training batch 1, loss: 0.253, 32/28000 datapoints
2025-03-06 22:39:23,514 - INFO - training batch 51, loss: 0.073, 1632/28000 datapoints
2025-03-06 22:39:23,669 - INFO - training batch 101, loss: 0.137, 3232/28000 datapoints
2025-03-06 22:39:23,823 - INFO - training batch 151, loss: 0.208, 4832/28000 datapoints
2025-03-06 22:39:23,976 - INFO - training batch 201, loss: 0.059, 6432/28000 datapoints
2025-03-06 22:39:24,128 - INFO - training batch 251, loss: 0.428, 8032/28000 datapoints
2025-03-06 22:39:24,280 - INFO - training batch 301, loss: 0.591, 9632/28000 datapoints
2025-03-06 22:39:24,432 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:39:24,584 - INFO - training batch 401, loss: 0.321, 12832/28000 datapoints
2025-03-06 22:39:24,734 - INFO - training batch 451, loss: 0.305, 14432/28000 datapoints
2025-03-06 22:39:24,888 - INFO - training batch 501, loss: 0.128, 16032/28000 datapoints
2025-03-06 22:39:25,044 - INFO - training batch 551, loss: 0.252, 17632/28000 datapoints
2025-03-06 22:39:25,227 - INFO - training batch 601, loss: 0.206, 19232/28000 datapoints
2025-03-06 22:39:25,379 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 22:39:25,532 - INFO - training batch 701, loss: 0.229, 22432/28000 datapoints
2025-03-06 22:39:25,685 - INFO - training batch 751, loss: 0.155, 24032/28000 datapoints
2025-03-06 22:39:25,838 - INFO - training batch 801, loss: 0.072, 25632/28000 datapoints
2025-03-06 22:39:25,993 - INFO - training batch 851, loss: 0.231, 27232/28000 datapoints
2025-03-06 22:39:26,068 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:39:26,116 - INFO - validation batch 51, loss: 1.416, 1632/6976 datapoints
2025-03-06 22:39:26,164 - INFO - validation batch 101, loss: 0.401, 3232/6976 datapoints
2025-03-06 22:39:26,212 - INFO - validation batch 151, loss: 0.423, 4832/6976 datapoints
2025-03-06 22:39:26,262 - INFO - validation batch 201, loss: 0.662, 6432/6976 datapoints
2025-03-06 22:39:26,282 - INFO - Epoch 267/800 done.
2025-03-06 22:39:26,282 - INFO - Final validation performance:
Loss: 0.594, top-1 acc: 0.875top-5 acc: 0.875
2025-03-06 22:39:26,283 - INFO - Beginning epoch 268/800
2025-03-06 22:39:26,287 - INFO - training batch 1, loss: 0.251, 32/28000 datapoints
2025-03-06 22:39:26,441 - INFO - training batch 51, loss: 0.072, 1632/28000 datapoints
2025-03-06 22:39:26,596 - INFO - training batch 101, loss: 0.136, 3232/28000 datapoints
2025-03-06 22:39:26,747 - INFO - training batch 151, loss: 0.208, 4832/28000 datapoints
2025-03-06 22:39:26,900 - INFO - training batch 201, loss: 0.059, 6432/28000 datapoints
2025-03-06 22:39:27,053 - INFO - training batch 251, loss: 0.428, 8032/28000 datapoints
2025-03-06 22:39:27,204 - INFO - training batch 301, loss: 0.591, 9632/28000 datapoints
2025-03-06 22:39:27,354 - INFO - training batch 351, loss: 0.190, 11232/28000 datapoints
2025-03-06 22:39:27,506 - INFO - training batch 401, loss: 0.318, 12832/28000 datapoints
2025-03-06 22:39:27,659 - INFO - training batch 451, loss: 0.304, 14432/28000 datapoints
2025-03-06 22:39:27,811 - INFO - training batch 501, loss: 0.128, 16032/28000 datapoints
2025-03-06 22:39:27,970 - INFO - training batch 551, loss: 0.250, 17632/28000 datapoints
2025-03-06 22:39:28,123 - INFO - training batch 601, loss: 0.204, 19232/28000 datapoints
2025-03-06 22:39:28,277 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 22:39:28,429 - INFO - training batch 701, loss: 0.229, 22432/28000 datapoints
2025-03-06 22:39:28,580 - INFO - training batch 751, loss: 0.154, 24032/28000 datapoints
2025-03-06 22:39:28,735 - INFO - training batch 801, loss: 0.071, 25632/28000 datapoints
2025-03-06 22:39:28,899 - INFO - training batch 851, loss: 0.229, 27232/28000 datapoints
2025-03-06 22:39:28,976 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:39:29,023 - INFO - validation batch 51, loss: 1.420, 1632/6976 datapoints
2025-03-06 22:39:29,073 - INFO - validation batch 101, loss: 0.402, 3232/6976 datapoints
2025-03-06 22:39:29,120 - INFO - validation batch 151, loss: 0.423, 4832/6976 datapoints
2025-03-06 22:39:29,174 - INFO - validation batch 201, loss: 0.664, 6432/6976 datapoints
2025-03-06 22:39:29,191 - INFO - Epoch 268/800 done.
2025-03-06 22:39:29,191 - INFO - Final validation performance:
Loss: 0.595, top-1 acc: 0.875top-5 acc: 0.875
2025-03-06 22:39:29,192 - INFO - Beginning epoch 269/800
2025-03-06 22:39:29,196 - INFO - training batch 1, loss: 0.249, 32/28000 datapoints
2025-03-06 22:39:29,353 - INFO - training batch 51, loss: 0.071, 1632/28000 datapoints
2025-03-06 22:39:29,507 - INFO - training batch 101, loss: 0.136, 3232/28000 datapoints
2025-03-06 22:39:29,662 - INFO - training batch 151, loss: 0.204, 4832/28000 datapoints
2025-03-06 22:39:29,812 - INFO - training batch 201, loss: 0.058, 6432/28000 datapoints
2025-03-06 22:39:29,972 - INFO - training batch 251, loss: 0.427, 8032/28000 datapoints
2025-03-06 22:39:30,127 - INFO - training batch 301, loss: 0.589, 9632/28000 datapoints
2025-03-06 22:39:30,279 - INFO - training batch 351, loss: 0.190, 11232/28000 datapoints
2025-03-06 22:39:30,432 - INFO - training batch 401, loss: 0.313, 12832/28000 datapoints
2025-03-06 22:39:30,584 - INFO - training batch 451, loss: 0.303, 14432/28000 datapoints
2025-03-06 22:39:30,737 - INFO - training batch 501, loss: 0.127, 16032/28000 datapoints
2025-03-06 22:39:30,890 - INFO - training batch 551, loss: 0.249, 17632/28000 datapoints
2025-03-06 22:39:31,044 - INFO - training batch 601, loss: 0.203, 19232/28000 datapoints
2025-03-06 22:39:31,198 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 22:39:31,348 - INFO - training batch 701, loss: 0.227, 22432/28000 datapoints
2025-03-06 22:39:31,504 - INFO - training batch 751, loss: 0.152, 24032/28000 datapoints
2025-03-06 22:39:31,664 - INFO - training batch 801, loss: 0.071, 25632/28000 datapoints
2025-03-06 22:39:31,819 - INFO - training batch 851, loss: 0.227, 27232/28000 datapoints
2025-03-06 22:39:31,896 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:39:31,944 - INFO - validation batch 51, loss: 1.425, 1632/6976 datapoints
2025-03-06 22:39:31,993 - INFO - validation batch 101, loss: 0.403, 3232/6976 datapoints
2025-03-06 22:39:32,041 - INFO - validation batch 151, loss: 0.425, 4832/6976 datapoints
2025-03-06 22:39:32,091 - INFO - validation batch 201, loss: 0.665, 6432/6976 datapoints
2025-03-06 22:39:32,108 - INFO - Epoch 269/800 done.
2025-03-06 22:39:32,109 - INFO - Final validation performance:
Loss: 0.597, top-1 acc: 0.875top-5 acc: 0.875
2025-03-06 22:39:32,109 - INFO - Beginning epoch 270/800
2025-03-06 22:39:32,114 - INFO - training batch 1, loss: 0.247, 32/28000 datapoints
2025-03-06 22:39:32,269 - INFO - training batch 51, loss: 0.071, 1632/28000 datapoints
2025-03-06 22:39:32,420 - INFO - training batch 101, loss: 0.135, 3232/28000 datapoints
2025-03-06 22:39:32,572 - INFO - training batch 151, loss: 0.201, 4832/28000 datapoints
2025-03-06 22:39:32,758 - INFO - training batch 201, loss: 0.058, 6432/28000 datapoints
2025-03-06 22:39:32,921 - INFO - training batch 251, loss: 0.427, 8032/28000 datapoints
2025-03-06 22:39:33,074 - INFO - training batch 301, loss: 0.588, 9632/28000 datapoints
2025-03-06 22:39:33,226 - INFO - training batch 351, loss: 0.190, 11232/28000 datapoints
2025-03-06 22:39:33,377 - INFO - training batch 401, loss: 0.310, 12832/28000 datapoints
2025-03-06 22:39:33,527 - INFO - training batch 451, loss: 0.302, 14432/28000 datapoints
2025-03-06 22:39:33,679 - INFO - training batch 501, loss: 0.127, 16032/28000 datapoints
2025-03-06 22:39:33,832 - INFO - training batch 551, loss: 0.247, 17632/28000 datapoints
2025-03-06 22:39:33,989 - INFO - training batch 601, loss: 0.202, 19232/28000 datapoints
2025-03-06 22:39:34,143 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 22:39:34,295 - INFO - training batch 701, loss: 0.226, 22432/28000 datapoints
2025-03-06 22:39:34,446 - INFO - training batch 751, loss: 0.149, 24032/28000 datapoints
2025-03-06 22:39:34,598 - INFO - training batch 801, loss: 0.070, 25632/28000 datapoints
2025-03-06 22:39:34,750 - INFO - training batch 851, loss: 0.226, 27232/28000 datapoints
2025-03-06 22:39:34,824 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:39:34,872 - INFO - validation batch 51, loss: 1.429, 1632/6976 datapoints
2025-03-06 22:39:34,920 - INFO - validation batch 101, loss: 0.404, 3232/6976 datapoints
2025-03-06 22:39:34,971 - INFO - validation batch 151, loss: 0.427, 4832/6976 datapoints
2025-03-06 22:39:35,026 - INFO - validation batch 201, loss: 0.668, 6432/6976 datapoints
2025-03-06 22:39:35,056 - INFO - Epoch 270/800 done.
2025-03-06 22:39:35,056 - INFO - Final validation performance:
Loss: 0.599, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:39:35,057 - INFO - Beginning epoch 271/800
2025-03-06 22:39:35,062 - INFO - training batch 1, loss: 0.246, 32/28000 datapoints
2025-03-06 22:39:35,239 - INFO - training batch 51, loss: 0.070, 1632/28000 datapoints
2025-03-06 22:39:35,408 - INFO - training batch 101, loss: 0.134, 3232/28000 datapoints
2025-03-06 22:39:35,561 - INFO - training batch 151, loss: 0.195, 4832/28000 datapoints
2025-03-06 22:39:35,715 - INFO - training batch 201, loss: 0.057, 6432/28000 datapoints
2025-03-06 22:39:35,870 - INFO - training batch 251, loss: 0.427, 8032/28000 datapoints
2025-03-06 22:39:36,025 - INFO - training batch 301, loss: 0.586, 9632/28000 datapoints
2025-03-06 22:39:36,177 - INFO - training batch 351, loss: 0.190, 11232/28000 datapoints
2025-03-06 22:39:36,328 - INFO - training batch 401, loss: 0.307, 12832/28000 datapoints
2025-03-06 22:39:36,479 - INFO - training batch 451, loss: 0.302, 14432/28000 datapoints
2025-03-06 22:39:36,633 - INFO - training batch 501, loss: 0.127, 16032/28000 datapoints
2025-03-06 22:39:36,786 - INFO - training batch 551, loss: 0.246, 17632/28000 datapoints
2025-03-06 22:39:36,937 - INFO - training batch 601, loss: 0.202, 19232/28000 datapoints
2025-03-06 22:39:37,091 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 22:39:37,243 - INFO - training batch 701, loss: 0.225, 22432/28000 datapoints
2025-03-06 22:39:37,393 - INFO - training batch 751, loss: 0.150, 24032/28000 datapoints
2025-03-06 22:39:37,543 - INFO - training batch 801, loss: 0.069, 25632/28000 datapoints
2025-03-06 22:39:37,694 - INFO - training batch 851, loss: 0.224, 27232/28000 datapoints
2025-03-06 22:39:37,769 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:39:37,817 - INFO - validation batch 51, loss: 1.435, 1632/6976 datapoints
2025-03-06 22:39:37,867 - INFO - validation batch 101, loss: 0.406, 3232/6976 datapoints
2025-03-06 22:39:37,914 - INFO - validation batch 151, loss: 0.427, 4832/6976 datapoints
2025-03-06 22:39:37,975 - INFO - validation batch 201, loss: 0.669, 6432/6976 datapoints
2025-03-06 22:39:37,992 - INFO - Epoch 271/800 done.
2025-03-06 22:39:37,992 - INFO - Final validation performance:
Loss: 0.601, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:39:37,992 - INFO - Beginning epoch 272/800
2025-03-06 22:39:37,996 - INFO - training batch 1, loss: 0.244, 32/28000 datapoints
2025-03-06 22:39:38,153 - INFO - training batch 51, loss: 0.070, 1632/28000 datapoints
2025-03-06 22:39:38,305 - INFO - training batch 101, loss: 0.134, 3232/28000 datapoints
2025-03-06 22:39:38,457 - INFO - training batch 151, loss: 0.192, 4832/28000 datapoints
2025-03-06 22:39:38,608 - INFO - training batch 201, loss: 0.057, 6432/28000 datapoints
2025-03-06 22:39:38,760 - INFO - training batch 251, loss: 0.426, 8032/28000 datapoints
2025-03-06 22:39:38,911 - INFO - training batch 301, loss: 0.585, 9632/28000 datapoints
2025-03-06 22:39:39,063 - INFO - training batch 351, loss: 0.190, 11232/28000 datapoints
2025-03-06 22:39:39,214 - INFO - training batch 401, loss: 0.303, 12832/28000 datapoints
2025-03-06 22:39:39,368 - INFO - training batch 451, loss: 0.300, 14432/28000 datapoints
2025-03-06 22:39:39,522 - INFO - training batch 501, loss: 0.126, 16032/28000 datapoints
2025-03-06 22:39:39,675 - INFO - training batch 551, loss: 0.244, 17632/28000 datapoints
2025-03-06 22:39:39,826 - INFO - training batch 601, loss: 0.198, 19232/28000 datapoints
2025-03-06 22:39:39,984 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 22:39:40,137 - INFO - training batch 701, loss: 0.224, 22432/28000 datapoints
2025-03-06 22:39:40,289 - INFO - training batch 751, loss: 0.149, 24032/28000 datapoints
2025-03-06 22:39:40,440 - INFO - training batch 801, loss: 0.068, 25632/28000 datapoints
2025-03-06 22:39:40,593 - INFO - training batch 851, loss: 0.222, 27232/28000 datapoints
2025-03-06 22:39:40,669 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:39:40,720 - INFO - validation batch 51, loss: 1.442, 1632/6976 datapoints
2025-03-06 22:39:40,768 - INFO - validation batch 101, loss: 0.408, 3232/6976 datapoints
2025-03-06 22:39:40,816 - INFO - validation batch 151, loss: 0.428, 4832/6976 datapoints
2025-03-06 22:39:40,867 - INFO - validation batch 201, loss: 0.671, 6432/6976 datapoints
2025-03-06 22:39:40,886 - INFO - Epoch 272/800 done.
2025-03-06 22:39:40,887 - INFO - Final validation performance:
Loss: 0.603, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:39:40,887 - INFO - Beginning epoch 273/800
2025-03-06 22:39:40,891 - INFO - training batch 1, loss: 0.242, 32/28000 datapoints
2025-03-06 22:39:41,066 - INFO - training batch 51, loss: 0.070, 1632/28000 datapoints
2025-03-06 22:39:41,227 - INFO - training batch 101, loss: 0.133, 3232/28000 datapoints
2025-03-06 22:39:41,385 - INFO - training batch 151, loss: 0.190, 4832/28000 datapoints
2025-03-06 22:39:41,552 - INFO - training batch 201, loss: 0.056, 6432/28000 datapoints
2025-03-06 22:39:41,714 - INFO - training batch 251, loss: 0.425, 8032/28000 datapoints
2025-03-06 22:39:41,877 - INFO - training batch 301, loss: 0.583, 9632/28000 datapoints
2025-03-06 22:39:42,038 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 22:39:42,195 - INFO - training batch 401, loss: 0.298, 12832/28000 datapoints
2025-03-06 22:39:42,349 - INFO - training batch 451, loss: 0.299, 14432/28000 datapoints
2025-03-06 22:39:42,505 - INFO - training batch 501, loss: 0.125, 16032/28000 datapoints
2025-03-06 22:39:42,661 - INFO - training batch 551, loss: 0.242, 17632/28000 datapoints
2025-03-06 22:39:42,820 - INFO - training batch 601, loss: 0.198, 19232/28000 datapoints
2025-03-06 22:39:42,979 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 22:39:43,136 - INFO - training batch 701, loss: 0.224, 22432/28000 datapoints
2025-03-06 22:39:43,292 - INFO - training batch 751, loss: 0.147, 24032/28000 datapoints
2025-03-06 22:39:43,447 - INFO - training batch 801, loss: 0.068, 25632/28000 datapoints
2025-03-06 22:39:43,603 - INFO - training batch 851, loss: 0.220, 27232/28000 datapoints
2025-03-06 22:39:43,680 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-06 22:39:43,734 - INFO - validation batch 51, loss: 1.444, 1632/6976 datapoints
2025-03-06 22:39:43,786 - INFO - validation batch 101, loss: 0.408, 3232/6976 datapoints
2025-03-06 22:39:43,838 - INFO - validation batch 151, loss: 0.430, 4832/6976 datapoints
2025-03-06 22:39:43,893 - INFO - validation batch 201, loss: 0.672, 6432/6976 datapoints
2025-03-06 22:39:43,911 - INFO - Epoch 273/800 done.
2025-03-06 22:39:43,911 - INFO - Final validation performance:
Loss: 0.605, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:39:43,912 - INFO - Beginning epoch 274/800
2025-03-06 22:39:43,916 - INFO - training batch 1, loss: 0.240, 32/28000 datapoints
2025-03-06 22:39:44,076 - INFO - training batch 51, loss: 0.069, 1632/28000 datapoints
2025-03-06 22:39:44,234 - INFO - training batch 101, loss: 0.132, 3232/28000 datapoints
2025-03-06 22:39:44,390 - INFO - training batch 151, loss: 0.186, 4832/28000 datapoints
2025-03-06 22:39:44,548 - INFO - training batch 201, loss: 0.055, 6432/28000 datapoints
2025-03-06 22:39:44,704 - INFO - training batch 251, loss: 0.425, 8032/28000 datapoints
2025-03-06 22:39:44,860 - INFO - training batch 301, loss: 0.582, 9632/28000 datapoints
2025-03-06 22:39:45,019 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 22:39:45,181 - INFO - training batch 401, loss: 0.296, 12832/28000 datapoints
2025-03-06 22:39:45,359 - INFO - training batch 451, loss: 0.299, 14432/28000 datapoints
2025-03-06 22:39:45,525 - INFO - training batch 501, loss: 0.125, 16032/28000 datapoints
2025-03-06 22:39:45,685 - INFO - training batch 551, loss: 0.240, 17632/28000 datapoints
2025-03-06 22:39:45,840 - INFO - training batch 601, loss: 0.196, 19232/28000 datapoints
2025-03-06 22:39:46,001 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 22:39:46,156 - INFO - training batch 701, loss: 0.222, 22432/28000 datapoints
2025-03-06 22:39:46,312 - INFO - training batch 751, loss: 0.144, 24032/28000 datapoints
2025-03-06 22:39:46,477 - INFO - training batch 801, loss: 0.067, 25632/28000 datapoints
2025-03-06 22:39:46,632 - INFO - training batch 851, loss: 0.219, 27232/28000 datapoints
2025-03-06 22:39:46,710 - INFO - validation batch 1, loss: 0.069, 32/6976 datapoints
2025-03-06 22:39:46,762 - INFO - validation batch 51, loss: 1.450, 1632/6976 datapoints
2025-03-06 22:39:46,818 - INFO - validation batch 101, loss: 0.411, 3232/6976 datapoints
2025-03-06 22:39:46,872 - INFO - validation batch 151, loss: 0.433, 4832/6976 datapoints
2025-03-06 22:39:46,923 - INFO - validation batch 201, loss: 0.676, 6432/6976 datapoints
2025-03-06 22:39:46,943 - INFO - Epoch 274/800 done.
2025-03-06 22:39:46,943 - INFO - Final validation performance:
Loss: 0.608, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:39:46,944 - INFO - Beginning epoch 275/800
2025-03-06 22:39:46,951 - INFO - training batch 1, loss: 0.239, 32/28000 datapoints
2025-03-06 22:39:47,105 - INFO - training batch 51, loss: 0.068, 1632/28000 datapoints
2025-03-06 22:39:47,269 - INFO - training batch 101, loss: 0.131, 3232/28000 datapoints
2025-03-06 22:39:47,428 - INFO - training batch 151, loss: 0.181, 4832/28000 datapoints
2025-03-06 22:39:47,582 - INFO - training batch 201, loss: 0.055, 6432/28000 datapoints
2025-03-06 22:39:47,740 - INFO - training batch 251, loss: 0.424, 8032/28000 datapoints
2025-03-06 22:39:47,902 - INFO - training batch 301, loss: 0.580, 9632/28000 datapoints
2025-03-06 22:39:48,059 - INFO - training batch 351, loss: 0.190, 11232/28000 datapoints
2025-03-06 22:39:48,216 - INFO - training batch 401, loss: 0.292, 12832/28000 datapoints
2025-03-06 22:39:48,367 - INFO - training batch 451, loss: 0.298, 14432/28000 datapoints
2025-03-06 22:39:48,519 - INFO - training batch 501, loss: 0.124, 16032/28000 datapoints
2025-03-06 22:39:48,672 - INFO - training batch 551, loss: 0.239, 17632/28000 datapoints
2025-03-06 22:39:48,826 - INFO - training batch 601, loss: 0.196, 19232/28000 datapoints
2025-03-06 22:39:48,980 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 22:39:49,131 - INFO - training batch 701, loss: 0.222, 22432/28000 datapoints
2025-03-06 22:39:49,352 - INFO - training batch 751, loss: 0.145, 24032/28000 datapoints
2025-03-06 22:39:49,504 - INFO - training batch 801, loss: 0.066, 25632/28000 datapoints
2025-03-06 22:39:49,665 - INFO - training batch 851, loss: 0.217, 27232/28000 datapoints
2025-03-06 22:39:49,739 - INFO - validation batch 1, loss: 0.069, 32/6976 datapoints
2025-03-06 22:39:49,790 - INFO - validation batch 51, loss: 1.456, 1632/6976 datapoints
2025-03-06 22:39:49,837 - INFO - validation batch 101, loss: 0.411, 3232/6976 datapoints
2025-03-06 22:39:49,886 - INFO - validation batch 151, loss: 0.435, 4832/6976 datapoints
2025-03-06 22:39:49,936 - INFO - validation batch 201, loss: 0.676, 6432/6976 datapoints
2025-03-06 22:39:49,957 - INFO - Epoch 275/800 done.
2025-03-06 22:39:49,957 - INFO - Final validation performance:
Loss: 0.609, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:39:49,957 - INFO - Beginning epoch 276/800
2025-03-06 22:39:49,962 - INFO - training batch 1, loss: 0.237, 32/28000 datapoints
2025-03-06 22:39:50,114 - INFO - training batch 51, loss: 0.067, 1632/28000 datapoints
2025-03-06 22:39:50,268 - INFO - training batch 101, loss: 0.131, 3232/28000 datapoints
2025-03-06 22:39:50,425 - INFO - training batch 151, loss: 0.178, 4832/28000 datapoints
2025-03-06 22:39:50,577 - INFO - training batch 201, loss: 0.054, 6432/28000 datapoints
2025-03-06 22:39:50,728 - INFO - training batch 251, loss: 0.423, 8032/28000 datapoints
2025-03-06 22:39:50,881 - INFO - training batch 301, loss: 0.579, 9632/28000 datapoints
2025-03-06 22:39:51,041 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 22:39:51,192 - INFO - training batch 401, loss: 0.288, 12832/28000 datapoints
2025-03-06 22:39:51,344 - INFO - training batch 451, loss: 0.297, 14432/28000 datapoints
2025-03-06 22:39:51,501 - INFO - training batch 501, loss: 0.124, 16032/28000 datapoints
2025-03-06 22:39:51,654 - INFO - training batch 551, loss: 0.237, 17632/28000 datapoints
2025-03-06 22:39:51,808 - INFO - training batch 601, loss: 0.195, 19232/28000 datapoints
2025-03-06 22:39:51,967 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 22:39:52,117 - INFO - training batch 701, loss: 0.220, 22432/28000 datapoints
2025-03-06 22:39:52,270 - INFO - training batch 751, loss: 0.143, 24032/28000 datapoints
2025-03-06 22:39:52,422 - INFO - training batch 801, loss: 0.066, 25632/28000 datapoints
2025-03-06 22:39:52,573 - INFO - training batch 851, loss: 0.216, 27232/28000 datapoints
2025-03-06 22:39:52,647 - INFO - validation batch 1, loss: 0.069, 32/6976 datapoints
2025-03-06 22:39:52,695 - INFO - validation batch 51, loss: 1.464, 1632/6976 datapoints
2025-03-06 22:39:52,742 - INFO - validation batch 101, loss: 0.411, 3232/6976 datapoints
2025-03-06 22:39:52,789 - INFO - validation batch 151, loss: 0.437, 4832/6976 datapoints
2025-03-06 22:39:52,838 - INFO - validation batch 201, loss: 0.679, 6432/6976 datapoints
2025-03-06 22:39:52,855 - INFO - Epoch 276/800 done.
2025-03-06 22:39:52,855 - INFO - Final validation performance:
Loss: 0.612, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:39:52,856 - INFO - Beginning epoch 277/800
2025-03-06 22:39:52,860 - INFO - training batch 1, loss: 0.235, 32/28000 datapoints
2025-03-06 22:39:53,018 - INFO - training batch 51, loss: 0.067, 1632/28000 datapoints
2025-03-06 22:39:53,169 - INFO - training batch 101, loss: 0.130, 3232/28000 datapoints
2025-03-06 22:39:53,321 - INFO - training batch 151, loss: 0.176, 4832/28000 datapoints
2025-03-06 22:39:53,490 - INFO - training batch 201, loss: 0.053, 6432/28000 datapoints
2025-03-06 22:39:53,642 - INFO - training batch 251, loss: 0.423, 8032/28000 datapoints
2025-03-06 22:39:53,794 - INFO - training batch 301, loss: 0.578, 9632/28000 datapoints
2025-03-06 22:39:54,011 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 22:39:54,167 - INFO - training batch 401, loss: 0.285, 12832/28000 datapoints
2025-03-06 22:39:54,322 - INFO - training batch 451, loss: 0.296, 14432/28000 datapoints
2025-03-06 22:39:54,478 - INFO - training batch 501, loss: 0.123, 16032/28000 datapoints
2025-03-06 22:39:54,631 - INFO - training batch 551, loss: 0.235, 17632/28000 datapoints
2025-03-06 22:39:54,783 - INFO - training batch 601, loss: 0.193, 19232/28000 datapoints
2025-03-06 22:39:54,936 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 22:39:55,089 - INFO - training batch 701, loss: 0.219, 22432/28000 datapoints
2025-03-06 22:39:55,244 - INFO - training batch 751, loss: 0.140, 24032/28000 datapoints
2025-03-06 22:39:55,402 - INFO - training batch 801, loss: 0.065, 25632/28000 datapoints
2025-03-06 22:39:55,576 - INFO - training batch 851, loss: 0.214, 27232/28000 datapoints
2025-03-06 22:39:55,653 - INFO - validation batch 1, loss: 0.069, 32/6976 datapoints
2025-03-06 22:39:55,702 - INFO - validation batch 51, loss: 1.467, 1632/6976 datapoints
2025-03-06 22:39:55,749 - INFO - validation batch 101, loss: 0.413, 3232/6976 datapoints
2025-03-06 22:39:55,797 - INFO - validation batch 151, loss: 0.439, 4832/6976 datapoints
2025-03-06 22:39:55,846 - INFO - validation batch 201, loss: 0.680, 6432/6976 datapoints
2025-03-06 22:39:55,863 - INFO - Epoch 277/800 done.
2025-03-06 22:39:55,863 - INFO - Final validation performance:
Loss: 0.614, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:39:55,863 - INFO - Beginning epoch 278/800
2025-03-06 22:39:55,868 - INFO - training batch 1, loss: 0.234, 32/28000 datapoints
2025-03-06 22:39:56,033 - INFO - training batch 51, loss: 0.067, 1632/28000 datapoints
2025-03-06 22:39:56,186 - INFO - training batch 101, loss: 0.130, 3232/28000 datapoints
2025-03-06 22:39:56,339 - INFO - training batch 151, loss: 0.174, 4832/28000 datapoints
2025-03-06 22:39:56,491 - INFO - training batch 201, loss: 0.053, 6432/28000 datapoints
2025-03-06 22:39:56,645 - INFO - training batch 251, loss: 0.422, 8032/28000 datapoints
2025-03-06 22:39:56,799 - INFO - training batch 301, loss: 0.577, 9632/28000 datapoints
2025-03-06 22:39:56,975 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 22:39:57,125 - INFO - training batch 401, loss: 0.281, 12832/28000 datapoints
2025-03-06 22:39:57,277 - INFO - training batch 451, loss: 0.295, 14432/28000 datapoints
2025-03-06 22:39:57,429 - INFO - training batch 501, loss: 0.122, 16032/28000 datapoints
2025-03-06 22:39:57,585 - INFO - training batch 551, loss: 0.234, 17632/28000 datapoints
2025-03-06 22:39:57,736 - INFO - training batch 601, loss: 0.191, 19232/28000 datapoints
2025-03-06 22:39:57,888 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 22:39:58,045 - INFO - training batch 701, loss: 0.218, 22432/28000 datapoints
2025-03-06 22:39:58,194 - INFO - training batch 751, loss: 0.140, 24032/28000 datapoints
2025-03-06 22:39:58,344 - INFO - training batch 801, loss: 0.064, 25632/28000 datapoints
2025-03-06 22:39:58,495 - INFO - training batch 851, loss: 0.212, 27232/28000 datapoints
2025-03-06 22:39:58,570 - INFO - validation batch 1, loss: 0.069, 32/6976 datapoints
2025-03-06 22:39:58,618 - INFO - validation batch 51, loss: 1.474, 1632/6976 datapoints
2025-03-06 22:39:58,666 - INFO - validation batch 101, loss: 0.414, 3232/6976 datapoints
2025-03-06 22:39:58,714 - INFO - validation batch 151, loss: 0.441, 4832/6976 datapoints
2025-03-06 22:39:58,761 - INFO - validation batch 201, loss: 0.682, 6432/6976 datapoints
2025-03-06 22:39:58,778 - INFO - Epoch 278/800 done.
2025-03-06 22:39:58,778 - INFO - Final validation performance:
Loss: 0.616, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:39:58,779 - INFO - Beginning epoch 279/800
2025-03-06 22:39:58,783 - INFO - training batch 1, loss: 0.231, 32/28000 datapoints
2025-03-06 22:39:58,938 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 22:39:59,096 - INFO - training batch 101, loss: 0.129, 3232/28000 datapoints
2025-03-06 22:39:59,248 - INFO - training batch 151, loss: 0.170, 4832/28000 datapoints
2025-03-06 22:39:59,405 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-06 22:39:59,567 - INFO - training batch 251, loss: 0.422, 8032/28000 datapoints
2025-03-06 22:39:59,718 - INFO - training batch 301, loss: 0.575, 9632/28000 datapoints
2025-03-06 22:39:59,878 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 22:40:00,039 - INFO - training batch 401, loss: 0.278, 12832/28000 datapoints
2025-03-06 22:40:00,193 - INFO - training batch 451, loss: 0.294, 14432/28000 datapoints
2025-03-06 22:40:00,347 - INFO - training batch 501, loss: 0.122, 16032/28000 datapoints
2025-03-06 22:40:00,507 - INFO - training batch 551, loss: 0.233, 17632/28000 datapoints
2025-03-06 22:40:00,659 - INFO - training batch 601, loss: 0.189, 19232/28000 datapoints
2025-03-06 22:40:00,812 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 22:40:00,971 - INFO - training batch 701, loss: 0.216, 22432/28000 datapoints
2025-03-06 22:40:01,126 - INFO - training batch 751, loss: 0.138, 24032/28000 datapoints
2025-03-06 22:40:01,281 - INFO - training batch 801, loss: 0.064, 25632/28000 datapoints
2025-03-06 22:40:01,437 - INFO - training batch 851, loss: 0.211, 27232/28000 datapoints
2025-03-06 22:40:01,520 - INFO - validation batch 1, loss: 0.070, 32/6976 datapoints
2025-03-06 22:40:01,573 - INFO - validation batch 51, loss: 1.479, 1632/6976 datapoints
2025-03-06 22:40:01,624 - INFO - validation batch 101, loss: 0.416, 3232/6976 datapoints
2025-03-06 22:40:01,680 - INFO - validation batch 151, loss: 0.443, 4832/6976 datapoints
2025-03-06 22:40:01,734 - INFO - validation batch 201, loss: 0.686, 6432/6976 datapoints
2025-03-06 22:40:01,755 - INFO - Epoch 279/800 done.
2025-03-06 22:40:01,755 - INFO - Final validation performance:
Loss: 0.619, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:40:01,756 - INFO - Beginning epoch 280/800
2025-03-06 22:40:01,760 - INFO - training batch 1, loss: 0.229, 32/28000 datapoints
2025-03-06 22:40:01,916 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 22:40:02,087 - INFO - training batch 101, loss: 0.129, 3232/28000 datapoints
2025-03-06 22:40:02,245 - INFO - training batch 151, loss: 0.167, 4832/28000 datapoints
2025-03-06 22:40:02,402 - INFO - training batch 201, loss: 0.051, 6432/28000 datapoints
2025-03-06 22:40:02,560 - INFO - training batch 251, loss: 0.422, 8032/28000 datapoints
2025-03-06 22:40:02,714 - INFO - training batch 301, loss: 0.575, 9632/28000 datapoints
2025-03-06 22:40:02,869 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:40:03,028 - INFO - training batch 401, loss: 0.275, 12832/28000 datapoints
2025-03-06 22:40:03,184 - INFO - training batch 451, loss: 0.294, 14432/28000 datapoints
2025-03-06 22:40:03,342 - INFO - training batch 501, loss: 0.122, 16032/28000 datapoints
2025-03-06 22:40:03,498 - INFO - training batch 551, loss: 0.231, 17632/28000 datapoints
2025-03-06 22:40:03,655 - INFO - training batch 601, loss: 0.188, 19232/28000 datapoints
2025-03-06 22:40:03,810 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 22:40:03,971 - INFO - training batch 701, loss: 0.215, 22432/28000 datapoints
2025-03-06 22:40:04,131 - INFO - training batch 751, loss: 0.136, 24032/28000 datapoints
2025-03-06 22:40:04,284 - INFO - training batch 801, loss: 0.063, 25632/28000 datapoints
2025-03-06 22:40:04,439 - INFO - training batch 851, loss: 0.209, 27232/28000 datapoints
2025-03-06 22:40:04,518 - INFO - validation batch 1, loss: 0.070, 32/6976 datapoints
2025-03-06 22:40:04,571 - INFO - validation batch 51, loss: 1.484, 1632/6976 datapoints
2025-03-06 22:40:04,624 - INFO - validation batch 101, loss: 0.417, 3232/6976 datapoints
2025-03-06 22:40:04,677 - INFO - validation batch 151, loss: 0.445, 4832/6976 datapoints
2025-03-06 22:40:04,729 - INFO - validation batch 201, loss: 0.686, 6432/6976 datapoints
2025-03-06 22:40:04,750 - INFO - Epoch 280/800 done.
2025-03-06 22:40:04,750 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:40:04,750 - INFO - Beginning epoch 281/800
2025-03-06 22:40:04,755 - INFO - training batch 1, loss: 0.229, 32/28000 datapoints
2025-03-06 22:40:04,912 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 22:40:05,073 - INFO - training batch 101, loss: 0.128, 3232/28000 datapoints
2025-03-06 22:40:05,237 - INFO - training batch 151, loss: 0.162, 4832/28000 datapoints
2025-03-06 22:40:05,396 - INFO - training batch 201, loss: 0.051, 6432/28000 datapoints
2025-03-06 22:40:05,592 - INFO - training batch 251, loss: 0.420, 8032/28000 datapoints
2025-03-06 22:40:05,751 - INFO - training batch 301, loss: 0.573, 9632/28000 datapoints
2025-03-06 22:40:05,914 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:40:06,077 - INFO - training batch 401, loss: 0.271, 12832/28000 datapoints
2025-03-06 22:40:06,233 - INFO - training batch 451, loss: 0.293, 14432/28000 datapoints
2025-03-06 22:40:06,394 - INFO - training batch 501, loss: 0.121, 16032/28000 datapoints
2025-03-06 22:40:06,553 - INFO - training batch 551, loss: 0.230, 17632/28000 datapoints
2025-03-06 22:40:06,709 - INFO - training batch 601, loss: 0.187, 19232/28000 datapoints
2025-03-06 22:40:06,864 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 22:40:07,022 - INFO - training batch 701, loss: 0.214, 22432/28000 datapoints
2025-03-06 22:40:07,177 - INFO - training batch 751, loss: 0.136, 24032/28000 datapoints
2025-03-06 22:40:07,332 - INFO - training batch 801, loss: 0.062, 25632/28000 datapoints
2025-03-06 22:40:07,486 - INFO - training batch 851, loss: 0.208, 27232/28000 datapoints
2025-03-06 22:40:07,566 - INFO - validation batch 1, loss: 0.070, 32/6976 datapoints
2025-03-06 22:40:07,618 - INFO - validation batch 51, loss: 1.492, 1632/6976 datapoints
2025-03-06 22:40:07,668 - INFO - validation batch 101, loss: 0.418, 3232/6976 datapoints
2025-03-06 22:40:07,719 - INFO - validation batch 151, loss: 0.447, 4832/6976 datapoints
2025-03-06 22:40:07,773 - INFO - validation batch 201, loss: 0.688, 6432/6976 datapoints
2025-03-06 22:40:07,791 - INFO - Epoch 281/800 done.
2025-03-06 22:40:07,791 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.874top-5 acc: 0.874
2025-03-06 22:40:07,792 - INFO - Beginning epoch 282/800
2025-03-06 22:40:07,797 - INFO - training batch 1, loss: 0.227, 32/28000 datapoints
2025-03-06 22:40:07,954 - INFO - training batch 51, loss: 0.064, 1632/28000 datapoints
2025-03-06 22:40:08,111 - INFO - training batch 101, loss: 0.128, 3232/28000 datapoints
2025-03-06 22:40:08,263 - INFO - training batch 151, loss: 0.162, 4832/28000 datapoints
2025-03-06 22:40:08,417 - INFO - training batch 201, loss: 0.050, 6432/28000 datapoints
2025-03-06 22:40:08,571 - INFO - training batch 251, loss: 0.420, 8032/28000 datapoints
2025-03-06 22:40:08,724 - INFO - training batch 301, loss: 0.573, 9632/28000 datapoints
2025-03-06 22:40:08,874 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:40:09,028 - INFO - training batch 401, loss: 0.269, 12832/28000 datapoints
2025-03-06 22:40:09,180 - INFO - training batch 451, loss: 0.292, 14432/28000 datapoints
2025-03-06 22:40:09,330 - INFO - training batch 501, loss: 0.121, 16032/28000 datapoints
2025-03-06 22:40:09,488 - INFO - training batch 551, loss: 0.228, 17632/28000 datapoints
2025-03-06 22:40:09,640 - INFO - training batch 601, loss: 0.186, 19232/28000 datapoints
2025-03-06 22:40:09,793 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 22:40:09,948 - INFO - training batch 701, loss: 0.213, 22432/28000 datapoints
2025-03-06 22:40:10,104 - INFO - training batch 751, loss: 0.133, 24032/28000 datapoints
2025-03-06 22:40:10,254 - INFO - training batch 801, loss: 0.062, 25632/28000 datapoints
2025-03-06 22:40:10,409 - INFO - training batch 851, loss: 0.207, 27232/28000 datapoints
2025-03-06 22:40:10,486 - INFO - validation batch 1, loss: 0.071, 32/6976 datapoints
2025-03-06 22:40:10,533 - INFO - validation batch 51, loss: 1.495, 1632/6976 datapoints
2025-03-06 22:40:10,582 - INFO - validation batch 101, loss: 0.420, 3232/6976 datapoints
2025-03-06 22:40:10,630 - INFO - validation batch 151, loss: 0.451, 4832/6976 datapoints
2025-03-06 22:40:10,678 - INFO - validation batch 201, loss: 0.691, 6432/6976 datapoints
2025-03-06 22:40:10,695 - INFO - Epoch 282/800 done.
2025-03-06 22:40:10,695 - INFO - Final validation performance:
Loss: 0.626, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:40:10,696 - INFO - Beginning epoch 283/800
2025-03-06 22:40:10,700 - INFO - training batch 1, loss: 0.225, 32/28000 datapoints
2025-03-06 22:40:10,855 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-06 22:40:11,007 - INFO - training batch 101, loss: 0.127, 3232/28000 datapoints
2025-03-06 22:40:11,162 - INFO - training batch 151, loss: 0.158, 4832/28000 datapoints
2025-03-06 22:40:11,314 - INFO - training batch 201, loss: 0.050, 6432/28000 datapoints
2025-03-06 22:40:11,475 - INFO - training batch 251, loss: 0.420, 8032/28000 datapoints
2025-03-06 22:40:11,638 - INFO - training batch 301, loss: 0.569, 9632/28000 datapoints
2025-03-06 22:40:11,790 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:40:11,949 - INFO - training batch 401, loss: 0.265, 12832/28000 datapoints
2025-03-06 22:40:12,110 - INFO - training batch 451, loss: 0.291, 14432/28000 datapoints
2025-03-06 22:40:12,267 - INFO - training batch 501, loss: 0.120, 16032/28000 datapoints
2025-03-06 22:40:12,423 - INFO - training batch 551, loss: 0.227, 17632/28000 datapoints
2025-03-06 22:40:12,576 - INFO - training batch 601, loss: 0.183, 19232/28000 datapoints
2025-03-06 22:40:12,729 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 22:40:12,879 - INFO - training batch 701, loss: 0.212, 22432/28000 datapoints
2025-03-06 22:40:13,033 - INFO - training batch 751, loss: 0.134, 24032/28000 datapoints
2025-03-06 22:40:13,184 - INFO - training batch 801, loss: 0.061, 25632/28000 datapoints
2025-03-06 22:40:13,337 - INFO - training batch 851, loss: 0.206, 27232/28000 datapoints
2025-03-06 22:40:13,413 - INFO - validation batch 1, loss: 0.071, 32/6976 datapoints
2025-03-06 22:40:13,461 - INFO - validation batch 51, loss: 1.505, 1632/6976 datapoints
2025-03-06 22:40:13,509 - INFO - validation batch 101, loss: 0.419, 3232/6976 datapoints
2025-03-06 22:40:13,557 - INFO - validation batch 151, loss: 0.452, 4832/6976 datapoints
2025-03-06 22:40:13,605 - INFO - validation batch 201, loss: 0.692, 6432/6976 datapoints
2025-03-06 22:40:13,623 - INFO - Epoch 283/800 done.
2025-03-06 22:40:13,623 - INFO - Final validation performance:
Loss: 0.628, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:40:13,624 - INFO - Beginning epoch 284/800
2025-03-06 22:40:13,628 - INFO - training batch 1, loss: 0.222, 32/28000 datapoints
2025-03-06 22:40:13,783 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-06 22:40:13,934 - INFO - training batch 101, loss: 0.127, 3232/28000 datapoints
2025-03-06 22:40:14,094 - INFO - training batch 151, loss: 0.156, 4832/28000 datapoints
2025-03-06 22:40:14,246 - INFO - training batch 201, loss: 0.049, 6432/28000 datapoints
2025-03-06 22:40:14,398 - INFO - training batch 251, loss: 0.419, 8032/28000 datapoints
2025-03-06 22:40:14,549 - INFO - training batch 301, loss: 0.568, 9632/28000 datapoints
2025-03-06 22:40:14,701 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:40:14,853 - INFO - training batch 401, loss: 0.262, 12832/28000 datapoints
2025-03-06 22:40:15,006 - INFO - training batch 451, loss: 0.291, 14432/28000 datapoints
2025-03-06 22:40:15,157 - INFO - training batch 501, loss: 0.120, 16032/28000 datapoints
2025-03-06 22:40:15,318 - INFO - training batch 551, loss: 0.224, 17632/28000 datapoints
2025-03-06 22:40:15,471 - INFO - training batch 601, loss: 0.182, 19232/28000 datapoints
2025-03-06 22:40:15,643 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 22:40:15,805 - INFO - training batch 701, loss: 0.210, 22432/28000 datapoints
2025-03-06 22:40:15,958 - INFO - training batch 751, loss: 0.134, 24032/28000 datapoints
2025-03-06 22:40:16,113 - INFO - training batch 801, loss: 0.061, 25632/28000 datapoints
2025-03-06 22:40:16,265 - INFO - training batch 851, loss: 0.204, 27232/28000 datapoints
2025-03-06 22:40:16,340 - INFO - validation batch 1, loss: 0.071, 32/6976 datapoints
2025-03-06 22:40:16,387 - INFO - validation batch 51, loss: 1.509, 1632/6976 datapoints
2025-03-06 22:40:16,436 - INFO - validation batch 101, loss: 0.421, 3232/6976 datapoints
2025-03-06 22:40:16,483 - INFO - validation batch 151, loss: 0.452, 4832/6976 datapoints
2025-03-06 22:40:16,531 - INFO - validation batch 201, loss: 0.696, 6432/6976 datapoints
2025-03-06 22:40:16,547 - INFO - Epoch 284/800 done.
2025-03-06 22:40:16,547 - INFO - Final validation performance:
Loss: 0.630, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:40:16,548 - INFO - Beginning epoch 285/800
2025-03-06 22:40:16,552 - INFO - training batch 1, loss: 0.221, 32/28000 datapoints
2025-03-06 22:40:16,709 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-06 22:40:16,862 - INFO - training batch 101, loss: 0.126, 3232/28000 datapoints
2025-03-06 22:40:17,016 - INFO - training batch 151, loss: 0.153, 4832/28000 datapoints
2025-03-06 22:40:17,169 - INFO - training batch 201, loss: 0.049, 6432/28000 datapoints
2025-03-06 22:40:17,320 - INFO - training batch 251, loss: 0.419, 8032/28000 datapoints
2025-03-06 22:40:17,474 - INFO - training batch 301, loss: 0.566, 9632/28000 datapoints
2025-03-06 22:40:17,638 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:40:17,791 - INFO - training batch 401, loss: 0.258, 12832/28000 datapoints
2025-03-06 22:40:17,943 - INFO - training batch 451, loss: 0.289, 14432/28000 datapoints
2025-03-06 22:40:18,107 - INFO - training batch 501, loss: 0.119, 16032/28000 datapoints
2025-03-06 22:40:18,266 - INFO - training batch 551, loss: 0.223, 17632/28000 datapoints
2025-03-06 22:40:18,423 - INFO - training batch 601, loss: 0.180, 19232/28000 datapoints
2025-03-06 22:40:18,584 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 22:40:18,738 - INFO - training batch 701, loss: 0.210, 22432/28000 datapoints
2025-03-06 22:40:18,890 - INFO - training batch 751, loss: 0.129, 24032/28000 datapoints
2025-03-06 22:40:19,042 - INFO - training batch 801, loss: 0.060, 25632/28000 datapoints
2025-03-06 22:40:19,194 - INFO - training batch 851, loss: 0.203, 27232/28000 datapoints
2025-03-06 22:40:19,269 - INFO - validation batch 1, loss: 0.071, 32/6976 datapoints
2025-03-06 22:40:19,316 - INFO - validation batch 51, loss: 1.514, 1632/6976 datapoints
2025-03-06 22:40:19,364 - INFO - validation batch 101, loss: 0.422, 3232/6976 datapoints
2025-03-06 22:40:19,412 - INFO - validation batch 151, loss: 0.456, 4832/6976 datapoints
2025-03-06 22:40:19,460 - INFO - validation batch 201, loss: 0.697, 6432/6976 datapoints
2025-03-06 22:40:19,476 - INFO - Epoch 285/800 done.
2025-03-06 22:40:19,476 - INFO - Final validation performance:
Loss: 0.632, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:40:19,476 - INFO - Beginning epoch 286/800
2025-03-06 22:40:19,481 - INFO - training batch 1, loss: 0.220, 32/28000 datapoints
2025-03-06 22:40:19,635 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 22:40:19,789 - INFO - training batch 101, loss: 0.125, 3232/28000 datapoints
2025-03-06 22:40:19,941 - INFO - training batch 151, loss: 0.152, 4832/28000 datapoints
2025-03-06 22:40:20,102 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-06 22:40:20,256 - INFO - training batch 251, loss: 0.419, 8032/28000 datapoints
2025-03-06 22:40:20,410 - INFO - training batch 301, loss: 0.566, 9632/28000 datapoints
2025-03-06 22:40:20,563 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:40:20,715 - INFO - training batch 401, loss: 0.256, 12832/28000 datapoints
2025-03-06 22:40:20,868 - INFO - training batch 451, loss: 0.289, 14432/28000 datapoints
2025-03-06 22:40:21,028 - INFO - training batch 501, loss: 0.119, 16032/28000 datapoints
2025-03-06 22:40:21,184 - INFO - training batch 551, loss: 0.221, 17632/28000 datapoints
2025-03-06 22:40:21,343 - INFO - training batch 601, loss: 0.180, 19232/28000 datapoints
2025-03-06 22:40:21,499 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 22:40:21,658 - INFO - training batch 701, loss: 0.209, 22432/28000 datapoints
2025-03-06 22:40:21,814 - INFO - training batch 751, loss: 0.130, 24032/28000 datapoints
2025-03-06 22:40:21,970 - INFO - training batch 801, loss: 0.059, 25632/28000 datapoints
2025-03-06 22:40:22,129 - INFO - training batch 851, loss: 0.201, 27232/28000 datapoints
2025-03-06 22:40:22,208 - INFO - validation batch 1, loss: 0.072, 32/6976 datapoints
2025-03-06 22:40:22,261 - INFO - validation batch 51, loss: 1.522, 1632/6976 datapoints
2025-03-06 22:40:22,313 - INFO - validation batch 101, loss: 0.424, 3232/6976 datapoints
2025-03-06 22:40:22,366 - INFO - validation batch 151, loss: 0.456, 4832/6976 datapoints
2025-03-06 22:40:22,420 - INFO - validation batch 201, loss: 0.701, 6432/6976 datapoints
2025-03-06 22:40:22,439 - INFO - Epoch 286/800 done.
2025-03-06 22:40:22,440 - INFO - Final validation performance:
Loss: 0.635, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:40:22,440 - INFO - Beginning epoch 287/800
2025-03-06 22:40:22,445 - INFO - training batch 1, loss: 0.218, 32/28000 datapoints
2025-03-06 22:40:22,600 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 22:40:22,754 - INFO - training batch 101, loss: 0.125, 3232/28000 datapoints
2025-03-06 22:40:22,906 - INFO - training batch 151, loss: 0.148, 4832/28000 datapoints
2025-03-06 22:40:23,060 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-06 22:40:23,210 - INFO - training batch 251, loss: 0.418, 8032/28000 datapoints
2025-03-06 22:40:23,364 - INFO - training batch 301, loss: 0.563, 9632/28000 datapoints
2025-03-06 22:40:23,514 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:40:23,681 - INFO - training batch 401, loss: 0.252, 12832/28000 datapoints
2025-03-06 22:40:23,833 - INFO - training batch 451, loss: 0.288, 14432/28000 datapoints
2025-03-06 22:40:23,988 - INFO - training batch 501, loss: 0.119, 16032/28000 datapoints
2025-03-06 22:40:24,150 - INFO - training batch 551, loss: 0.220, 17632/28000 datapoints
2025-03-06 22:40:24,311 - INFO - training batch 601, loss: 0.178, 19232/28000 datapoints
2025-03-06 22:40:24,465 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 22:40:24,618 - INFO - training batch 701, loss: 0.207, 22432/28000 datapoints
2025-03-06 22:40:24,770 - INFO - training batch 751, loss: 0.126, 24032/28000 datapoints
2025-03-06 22:40:24,922 - INFO - training batch 801, loss: 0.059, 25632/28000 datapoints
2025-03-06 22:40:25,076 - INFO - training batch 851, loss: 0.200, 27232/28000 datapoints
2025-03-06 22:40:25,151 - INFO - validation batch 1, loss: 0.072, 32/6976 datapoints
2025-03-06 22:40:25,198 - INFO - validation batch 51, loss: 1.526, 1632/6976 datapoints
2025-03-06 22:40:25,252 - INFO - validation batch 101, loss: 0.426, 3232/6976 datapoints
2025-03-06 22:40:25,301 - INFO - validation batch 151, loss: 0.460, 4832/6976 datapoints
2025-03-06 22:40:25,349 - INFO - validation batch 201, loss: 0.703, 6432/6976 datapoints
2025-03-06 22:40:25,367 - INFO - Epoch 287/800 done.
2025-03-06 22:40:25,367 - INFO - Final validation performance:
Loss: 0.637, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 22:40:25,368 - INFO - Beginning epoch 288/800
2025-03-06 22:40:25,372 - INFO - training batch 1, loss: 0.216, 32/28000 datapoints
2025-03-06 22:40:25,530 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 22:40:25,695 - INFO - training batch 101, loss: 0.124, 3232/28000 datapoints
2025-03-06 22:40:25,866 - INFO - training batch 151, loss: 0.146, 4832/28000 datapoints
2025-03-06 22:40:26,022 - INFO - training batch 201, loss: 0.047, 6432/28000 datapoints
2025-03-06 22:40:26,180 - INFO - training batch 251, loss: 0.417, 8032/28000 datapoints
2025-03-06 22:40:26,333 - INFO - training batch 301, loss: 0.564, 9632/28000 datapoints
2025-03-06 22:40:26,484 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:40:26,636 - INFO - training batch 401, loss: 0.249, 12832/28000 datapoints
2025-03-06 22:40:26,789 - INFO - training batch 451, loss: 0.287, 14432/28000 datapoints
2025-03-06 22:40:26,942 - INFO - training batch 501, loss: 0.117, 16032/28000 datapoints
2025-03-06 22:40:27,097 - INFO - training batch 551, loss: 0.219, 17632/28000 datapoints
2025-03-06 22:40:27,251 - INFO - training batch 601, loss: 0.176, 19232/28000 datapoints
2025-03-06 22:40:27,404 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 22:40:27,555 - INFO - training batch 701, loss: 0.206, 22432/28000 datapoints
2025-03-06 22:40:27,706 - INFO - training batch 751, loss: 0.129, 24032/28000 datapoints
2025-03-06 22:40:27,858 - INFO - training batch 801, loss: 0.058, 25632/28000 datapoints
2025-03-06 22:40:28,012 - INFO - training batch 851, loss: 0.199, 27232/28000 datapoints
2025-03-06 22:40:28,089 - INFO - validation batch 1, loss: 0.073, 32/6976 datapoints
2025-03-06 22:40:28,136 - INFO - validation batch 51, loss: 1.536, 1632/6976 datapoints
2025-03-06 22:40:28,184 - INFO - validation batch 101, loss: 0.425, 3232/6976 datapoints
2025-03-06 22:40:28,232 - INFO - validation batch 151, loss: 0.462, 4832/6976 datapoints
2025-03-06 22:40:28,279 - INFO - validation batch 201, loss: 0.702, 6432/6976 datapoints
2025-03-06 22:40:28,295 - INFO - Epoch 288/800 done.
2025-03-06 22:40:28,296 - INFO - Final validation performance:
Loss: 0.640, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:40:28,296 - INFO - Beginning epoch 289/800
2025-03-06 22:40:28,300 - INFO - training batch 1, loss: 0.213, 32/28000 datapoints
2025-03-06 22:40:28,456 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 22:40:28,609 - INFO - training batch 101, loss: 0.124, 3232/28000 datapoints
2025-03-06 22:40:28,761 - INFO - training batch 151, loss: 0.145, 4832/28000 datapoints
2025-03-06 22:40:28,913 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-06 22:40:29,067 - INFO - training batch 251, loss: 0.416, 8032/28000 datapoints
2025-03-06 22:40:29,217 - INFO - training batch 301, loss: 0.561, 9632/28000 datapoints
2025-03-06 22:40:29,369 - INFO - training batch 351, loss: 0.192, 11232/28000 datapoints
2025-03-06 22:40:29,520 - INFO - training batch 401, loss: 0.245, 12832/28000 datapoints
2025-03-06 22:40:29,675 - INFO - training batch 451, loss: 0.287, 14432/28000 datapoints
2025-03-06 22:40:29,833 - INFO - training batch 501, loss: 0.117, 16032/28000 datapoints
2025-03-06 22:40:29,991 - INFO - training batch 551, loss: 0.217, 17632/28000 datapoints
2025-03-06 22:40:30,152 - INFO - training batch 601, loss: 0.173, 19232/28000 datapoints
2025-03-06 22:40:30,306 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 22:40:30,463 - INFO - training batch 701, loss: 0.205, 22432/28000 datapoints
2025-03-06 22:40:30,619 - INFO - training batch 751, loss: 0.126, 24032/28000 datapoints
2025-03-06 22:40:30,770 - INFO - training batch 801, loss: 0.057, 25632/28000 datapoints
2025-03-06 22:40:30,923 - INFO - training batch 851, loss: 0.197, 27232/28000 datapoints
2025-03-06 22:40:31,001 - INFO - validation batch 1, loss: 0.073, 32/6976 datapoints
2025-03-06 22:40:31,051 - INFO - validation batch 51, loss: 1.539, 1632/6976 datapoints
2025-03-06 22:40:31,098 - INFO - validation batch 101, loss: 0.428, 3232/6976 datapoints
2025-03-06 22:40:31,147 - INFO - validation batch 151, loss: 0.463, 4832/6976 datapoints
2025-03-06 22:40:31,194 - INFO - validation batch 201, loss: 0.706, 6432/6976 datapoints
2025-03-06 22:40:31,210 - INFO - Epoch 289/800 done.
2025-03-06 22:40:31,211 - INFO - Final validation performance:
Loss: 0.642, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:40:31,212 - INFO - Beginning epoch 290/800
2025-03-06 22:40:31,216 - INFO - training batch 1, loss: 0.213, 32/28000 datapoints
2025-03-06 22:40:31,375 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 22:40:31,526 - INFO - training batch 101, loss: 0.123, 3232/28000 datapoints
2025-03-06 22:40:31,686 - INFO - training batch 151, loss: 0.140, 4832/28000 datapoints
2025-03-06 22:40:31,837 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-06 22:40:32,010 - INFO - training batch 251, loss: 0.416, 8032/28000 datapoints
2025-03-06 22:40:32,204 - INFO - training batch 301, loss: 0.561, 9632/28000 datapoints
2025-03-06 22:40:32,358 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 22:40:32,511 - INFO - training batch 401, loss: 0.243, 12832/28000 datapoints
2025-03-06 22:40:32,663 - INFO - training batch 451, loss: 0.286, 14432/28000 datapoints
2025-03-06 22:40:32,815 - INFO - training batch 501, loss: 0.116, 16032/28000 datapoints
2025-03-06 22:40:32,979 - INFO - training batch 551, loss: 0.216, 17632/28000 datapoints
2025-03-06 22:40:33,165 - INFO - training batch 601, loss: 0.171, 19232/28000 datapoints
2025-03-06 22:40:33,316 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 22:40:33,479 - INFO - training batch 701, loss: 0.204, 22432/28000 datapoints
2025-03-06 22:40:33,633 - INFO - training batch 751, loss: 0.126, 24032/28000 datapoints
2025-03-06 22:40:33,783 - INFO - training batch 801, loss: 0.057, 25632/28000 datapoints
2025-03-06 22:40:33,936 - INFO - training batch 851, loss: 0.196, 27232/28000 datapoints
2025-03-06 22:40:34,013 - INFO - validation batch 1, loss: 0.073, 32/6976 datapoints
2025-03-06 22:40:34,060 - INFO - validation batch 51, loss: 1.549, 1632/6976 datapoints
2025-03-06 22:40:34,109 - INFO - validation batch 101, loss: 0.428, 3232/6976 datapoints
2025-03-06 22:40:34,156 - INFO - validation batch 151, loss: 0.467, 4832/6976 datapoints
2025-03-06 22:40:34,206 - INFO - validation batch 201, loss: 0.704, 6432/6976 datapoints
2025-03-06 22:40:34,222 - INFO - Epoch 290/800 done.
2025-03-06 22:40:34,222 - INFO - Final validation performance:
Loss: 0.644, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:40:34,222 - INFO - Beginning epoch 291/800
2025-03-06 22:40:34,227 - INFO - training batch 1, loss: 0.210, 32/28000 datapoints
2025-03-06 22:40:34,385 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-06 22:40:34,537 - INFO - training batch 101, loss: 0.123, 3232/28000 datapoints
2025-03-06 22:40:34,688 - INFO - training batch 151, loss: 0.138, 4832/28000 datapoints
2025-03-06 22:40:34,840 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-06 22:40:34,995 - INFO - training batch 251, loss: 0.414, 8032/28000 datapoints
2025-03-06 22:40:35,145 - INFO - training batch 301, loss: 0.557, 9632/28000 datapoints
2025-03-06 22:40:35,302 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 22:40:35,458 - INFO - training batch 401, loss: 0.240, 12832/28000 datapoints
2025-03-06 22:40:35,612 - INFO - training batch 451, loss: 0.286, 14432/28000 datapoints
2025-03-06 22:40:35,800 - INFO - training batch 501, loss: 0.117, 16032/28000 datapoints
2025-03-06 22:40:35,981 - INFO - training batch 551, loss: 0.214, 17632/28000 datapoints
2025-03-06 22:40:36,135 - INFO - training batch 601, loss: 0.170, 19232/28000 datapoints
2025-03-06 22:40:36,293 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 22:40:36,449 - INFO - training batch 701, loss: 0.203, 22432/28000 datapoints
2025-03-06 22:40:36,610 - INFO - training batch 751, loss: 0.123, 24032/28000 datapoints
2025-03-06 22:40:36,765 - INFO - training batch 801, loss: 0.056, 25632/28000 datapoints
2025-03-06 22:40:36,917 - INFO - training batch 851, loss: 0.196, 27232/28000 datapoints
2025-03-06 22:40:36,994 - INFO - validation batch 1, loss: 0.074, 32/6976 datapoints
2025-03-06 22:40:37,043 - INFO - validation batch 51, loss: 1.554, 1632/6976 datapoints
2025-03-06 22:40:37,091 - INFO - validation batch 101, loss: 0.431, 3232/6976 datapoints
2025-03-06 22:40:37,137 - INFO - validation batch 151, loss: 0.469, 4832/6976 datapoints
2025-03-06 22:40:37,187 - INFO - validation batch 201, loss: 0.709, 6432/6976 datapoints
2025-03-06 22:40:37,203 - INFO - Epoch 291/800 done.
2025-03-06 22:40:37,203 - INFO - Final validation performance:
Loss: 0.647, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:40:37,204 - INFO - Beginning epoch 292/800
2025-03-06 22:40:37,208 - INFO - training batch 1, loss: 0.210, 32/28000 datapoints
2025-03-06 22:40:37,362 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-06 22:40:37,519 - INFO - training batch 101, loss: 0.123, 3232/28000 datapoints
2025-03-06 22:40:37,669 - INFO - training batch 151, loss: 0.136, 4832/28000 datapoints
2025-03-06 22:40:37,821 - INFO - training batch 201, loss: 0.045, 6432/28000 datapoints
2025-03-06 22:40:37,989 - INFO - training batch 251, loss: 0.413, 8032/28000 datapoints
2025-03-06 22:40:38,144 - INFO - training batch 301, loss: 0.558, 9632/28000 datapoints
2025-03-06 22:40:38,296 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 22:40:38,449 - INFO - training batch 401, loss: 0.237, 12832/28000 datapoints
2025-03-06 22:40:38,600 - INFO - training batch 451, loss: 0.285, 14432/28000 datapoints
2025-03-06 22:40:38,752 - INFO - training batch 501, loss: 0.116, 16032/28000 datapoints
2025-03-06 22:40:38,906 - INFO - training batch 551, loss: 0.213, 17632/28000 datapoints
2025-03-06 22:40:39,062 - INFO - training batch 601, loss: 0.169, 19232/28000 datapoints
2025-03-06 22:40:39,212 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 22:40:39,363 - INFO - training batch 701, loss: 0.202, 22432/28000 datapoints
2025-03-06 22:40:39,518 - INFO - training batch 751, loss: 0.122, 24032/28000 datapoints
2025-03-06 22:40:39,669 - INFO - training batch 801, loss: 0.055, 25632/28000 datapoints
2025-03-06 22:40:39,820 - INFO - training batch 851, loss: 0.194, 27232/28000 datapoints
2025-03-06 22:40:39,895 - INFO - validation batch 1, loss: 0.074, 32/6976 datapoints
2025-03-06 22:40:39,943 - INFO - validation batch 51, loss: 1.563, 1632/6976 datapoints
2025-03-06 22:40:39,995 - INFO - validation batch 101, loss: 0.432, 3232/6976 datapoints
2025-03-06 22:40:40,042 - INFO - validation batch 151, loss: 0.472, 4832/6976 datapoints
2025-03-06 22:40:40,091 - INFO - validation batch 201, loss: 0.712, 6432/6976 datapoints
2025-03-06 22:40:40,108 - INFO - Epoch 292/800 done.
2025-03-06 22:40:40,108 - INFO - Final validation performance:
Loss: 0.650, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:40:40,108 - INFO - Beginning epoch 293/800
2025-03-06 22:40:40,113 - INFO - training batch 1, loss: 0.207, 32/28000 datapoints
2025-03-06 22:40:40,268 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-06 22:40:40,423 - INFO - training batch 101, loss: 0.122, 3232/28000 datapoints
2025-03-06 22:40:40,577 - INFO - training batch 151, loss: 0.133, 4832/28000 datapoints
2025-03-06 22:40:40,728 - INFO - training batch 201, loss: 0.045, 6432/28000 datapoints
2025-03-06 22:40:40,879 - INFO - training batch 251, loss: 0.413, 8032/28000 datapoints
2025-03-06 22:40:41,040 - INFO - training batch 301, loss: 0.555, 9632/28000 datapoints
2025-03-06 22:40:41,196 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 22:40:41,350 - INFO - training batch 401, loss: 0.234, 12832/28000 datapoints
2025-03-06 22:40:41,510 - INFO - training batch 451, loss: 0.284, 14432/28000 datapoints
2025-03-06 22:40:41,672 - INFO - training batch 501, loss: 0.115, 16032/28000 datapoints
2025-03-06 22:40:41,829 - INFO - training batch 551, loss: 0.212, 17632/28000 datapoints
2025-03-06 22:40:42,003 - INFO - training batch 601, loss: 0.168, 19232/28000 datapoints
2025-03-06 22:40:42,163 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 22:40:42,320 - INFO - training batch 701, loss: 0.200, 22432/28000 datapoints
2025-03-06 22:40:42,483 - INFO - training batch 751, loss: 0.122, 24032/28000 datapoints
2025-03-06 22:40:42,643 - INFO - training batch 801, loss: 0.055, 25632/28000 datapoints
2025-03-06 22:40:42,800 - INFO - training batch 851, loss: 0.194, 27232/28000 datapoints
2025-03-06 22:40:42,882 - INFO - validation batch 1, loss: 0.074, 32/6976 datapoints
2025-03-06 22:40:42,934 - INFO - validation batch 51, loss: 1.570, 1632/6976 datapoints
2025-03-06 22:40:42,990 - INFO - validation batch 101, loss: 0.433, 3232/6976 datapoints
2025-03-06 22:40:43,043 - INFO - validation batch 151, loss: 0.474, 4832/6976 datapoints
2025-03-06 22:40:43,095 - INFO - validation batch 201, loss: 0.713, 6432/6976 datapoints
2025-03-06 22:40:43,112 - INFO - Epoch 293/800 done.
2025-03-06 22:40:43,113 - INFO - Final validation performance:
Loss: 0.653, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:40:43,113 - INFO - Beginning epoch 294/800
2025-03-06 22:40:43,117 - INFO - training batch 1, loss: 0.206, 32/28000 datapoints
2025-03-06 22:40:43,271 - INFO - training batch 51, loss: 0.058, 1632/28000 datapoints
2025-03-06 22:40:43,421 - INFO - training batch 101, loss: 0.122, 3232/28000 datapoints
2025-03-06 22:40:43,577 - INFO - training batch 151, loss: 0.132, 4832/28000 datapoints
2025-03-06 22:40:43,729 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-06 22:40:43,881 - INFO - training batch 251, loss: 0.413, 8032/28000 datapoints
2025-03-06 22:40:44,035 - INFO - training batch 301, loss: 0.553, 9632/28000 datapoints
2025-03-06 22:40:44,190 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 22:40:44,341 - INFO - training batch 401, loss: 0.231, 12832/28000 datapoints
2025-03-06 22:40:44,492 - INFO - training batch 451, loss: 0.282, 14432/28000 datapoints
2025-03-06 22:40:44,646 - INFO - training batch 501, loss: 0.115, 16032/28000 datapoints
2025-03-06 22:40:44,800 - INFO - training batch 551, loss: 0.210, 17632/28000 datapoints
2025-03-06 22:40:44,957 - INFO - training batch 601, loss: 0.166, 19232/28000 datapoints
2025-03-06 22:40:45,110 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 22:40:45,268 - INFO - training batch 701, loss: 0.200, 22432/28000 datapoints
2025-03-06 22:40:45,418 - INFO - training batch 751, loss: 0.120, 24032/28000 datapoints
2025-03-06 22:40:45,573 - INFO - training batch 801, loss: 0.054, 25632/28000 datapoints
2025-03-06 22:40:45,726 - INFO - training batch 851, loss: 0.192, 27232/28000 datapoints
2025-03-06 22:40:45,802 - INFO - validation batch 1, loss: 0.075, 32/6976 datapoints
2025-03-06 22:40:45,853 - INFO - validation batch 51, loss: 1.578, 1632/6976 datapoints
2025-03-06 22:40:45,920 - INFO - validation batch 101, loss: 0.435, 3232/6976 datapoints
2025-03-06 22:40:45,982 - INFO - validation batch 151, loss: 0.476, 4832/6976 datapoints
2025-03-06 22:40:46,031 - INFO - validation batch 201, loss: 0.716, 6432/6976 datapoints
2025-03-06 22:40:46,047 - INFO - Epoch 294/800 done.
2025-03-06 22:40:46,047 - INFO - Final validation performance:
Loss: 0.656, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 22:40:46,048 - INFO - Beginning epoch 295/800
2025-03-06 22:40:46,052 - INFO - training batch 1, loss: 0.204, 32/28000 datapoints
2025-03-06 22:40:46,209 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-06 22:40:46,366 - INFO - training batch 101, loss: 0.121, 3232/28000 datapoints
2025-03-06 22:40:46,517 - INFO - training batch 151, loss: 0.128, 4832/28000 datapoints
2025-03-06 22:40:46,672 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-06 22:40:46,824 - INFO - training batch 251, loss: 0.412, 8032/28000 datapoints
2025-03-06 22:40:46,979 - INFO - training batch 301, loss: 0.551, 9632/28000 datapoints
2025-03-06 22:40:47,131 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 22:40:47,283 - INFO - training batch 401, loss: 0.229, 12832/28000 datapoints
2025-03-06 22:40:47,435 - INFO - training batch 451, loss: 0.282, 14432/28000 datapoints
2025-03-06 22:40:47,588 - INFO - training batch 501, loss: 0.116, 16032/28000 datapoints
2025-03-06 22:40:47,744 - INFO - training batch 551, loss: 0.208, 17632/28000 datapoints
2025-03-06 22:40:47,900 - INFO - training batch 601, loss: 0.165, 19232/28000 datapoints
2025-03-06 22:40:48,063 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 22:40:48,223 - INFO - training batch 701, loss: 0.198, 22432/28000 datapoints
2025-03-06 22:40:48,373 - INFO - training batch 751, loss: 0.120, 24032/28000 datapoints
2025-03-06 22:40:48,524 - INFO - training batch 801, loss: 0.054, 25632/28000 datapoints
2025-03-06 22:40:48,683 - INFO - training batch 851, loss: 0.191, 27232/28000 datapoints
2025-03-06 22:40:48,760 - INFO - validation batch 1, loss: 0.075, 32/6976 datapoints
2025-03-06 22:40:48,810 - INFO - validation batch 51, loss: 1.586, 1632/6976 datapoints
2025-03-06 22:40:48,858 - INFO - validation batch 101, loss: 0.436, 3232/6976 datapoints
2025-03-06 22:40:48,905 - INFO - validation batch 151, loss: 0.477, 4832/6976 datapoints
2025-03-06 22:40:48,955 - INFO - validation batch 201, loss: 0.717, 6432/6976 datapoints
2025-03-06 22:40:48,972 - INFO - Epoch 295/800 done.
2025-03-06 22:40:48,972 - INFO - Final validation performance:
Loss: 0.658, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:40:48,973 - INFO - Beginning epoch 296/800
2025-03-06 22:40:48,977 - INFO - training batch 1, loss: 0.202, 32/28000 datapoints
2025-03-06 22:40:49,136 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-06 22:40:49,287 - INFO - training batch 101, loss: 0.121, 3232/28000 datapoints
2025-03-06 22:40:49,441 - INFO - training batch 151, loss: 0.127, 4832/28000 datapoints
2025-03-06 22:40:49,592 - INFO - training batch 201, loss: 0.043, 6432/28000 datapoints
2025-03-06 22:40:49,742 - INFO - training batch 251, loss: 0.410, 8032/28000 datapoints
2025-03-06 22:40:49,894 - INFO - training batch 301, loss: 0.549, 9632/28000 datapoints
2025-03-06 22:40:50,048 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 22:40:50,203 - INFO - training batch 401, loss: 0.226, 12832/28000 datapoints
2025-03-06 22:40:50,354 - INFO - training batch 451, loss: 0.281, 14432/28000 datapoints
2025-03-06 22:40:50,507 - INFO - training batch 501, loss: 0.115, 16032/28000 datapoints
2025-03-06 22:40:50,661 - INFO - training batch 551, loss: 0.208, 17632/28000 datapoints
2025-03-06 22:40:50,814 - INFO - training batch 601, loss: 0.162, 19232/28000 datapoints
2025-03-06 22:40:50,966 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 22:40:51,136 - INFO - training batch 701, loss: 0.197, 22432/28000 datapoints
2025-03-06 22:40:51,284 - INFO - training batch 751, loss: 0.117, 24032/28000 datapoints
2025-03-06 22:40:51,435 - INFO - training batch 801, loss: 0.053, 25632/28000 datapoints
2025-03-06 22:40:51,586 - INFO - training batch 851, loss: 0.190, 27232/28000 datapoints
2025-03-06 22:40:51,669 - INFO - validation batch 1, loss: 0.075, 32/6976 datapoints
2025-03-06 22:40:51,717 - INFO - validation batch 51, loss: 1.592, 1632/6976 datapoints
2025-03-06 22:40:51,765 - INFO - validation batch 101, loss: 0.437, 3232/6976 datapoints
2025-03-06 22:40:51,812 - INFO - validation batch 151, loss: 0.482, 4832/6976 datapoints
2025-03-06 22:40:51,861 - INFO - validation batch 201, loss: 0.717, 6432/6976 datapoints
2025-03-06 22:40:51,877 - INFO - Epoch 296/800 done.
2025-03-06 22:40:51,877 - INFO - Final validation performance:
Loss: 0.661, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:40:51,878 - INFO - Beginning epoch 297/800
2025-03-06 22:40:51,882 - INFO - training batch 1, loss: 0.201, 32/28000 datapoints
2025-03-06 22:40:52,038 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-06 22:40:52,195 - INFO - training batch 101, loss: 0.121, 3232/28000 datapoints
2025-03-06 22:40:52,348 - INFO - training batch 151, loss: 0.126, 4832/28000 datapoints
2025-03-06 22:40:52,498 - INFO - training batch 201, loss: 0.043, 6432/28000 datapoints
2025-03-06 22:40:52,651 - INFO - training batch 251, loss: 0.411, 8032/28000 datapoints
2025-03-06 22:40:52,802 - INFO - training batch 301, loss: 0.546, 9632/28000 datapoints
2025-03-06 22:40:52,955 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 22:40:53,107 - INFO - training batch 401, loss: 0.223, 12832/28000 datapoints
2025-03-06 22:40:53,259 - INFO - training batch 451, loss: 0.280, 14432/28000 datapoints
2025-03-06 22:40:53,410 - INFO - training batch 501, loss: 0.115, 16032/28000 datapoints
2025-03-06 22:40:53,563 - INFO - training batch 551, loss: 0.205, 17632/28000 datapoints
2025-03-06 22:40:53,715 - INFO - training batch 601, loss: 0.162, 19232/28000 datapoints
2025-03-06 22:40:53,867 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 22:40:54,021 - INFO - training batch 701, loss: 0.196, 22432/28000 datapoints
2025-03-06 22:40:54,172 - INFO - training batch 751, loss: 0.118, 24032/28000 datapoints
2025-03-06 22:40:54,340 - INFO - training batch 801, loss: 0.052, 25632/28000 datapoints
2025-03-06 22:40:54,491 - INFO - training batch 851, loss: 0.189, 27232/28000 datapoints
2025-03-06 22:40:54,565 - INFO - validation batch 1, loss: 0.076, 32/6976 datapoints
2025-03-06 22:40:54,613 - INFO - validation batch 51, loss: 1.601, 1632/6976 datapoints
2025-03-06 22:40:54,662 - INFO - validation batch 101, loss: 0.438, 3232/6976 datapoints
2025-03-06 22:40:54,709 - INFO - validation batch 151, loss: 0.482, 4832/6976 datapoints
2025-03-06 22:40:54,758 - INFO - validation batch 201, loss: 0.719, 6432/6976 datapoints
2025-03-06 22:40:54,774 - INFO - Epoch 297/800 done.
2025-03-06 22:40:54,774 - INFO - Final validation performance:
Loss: 0.663, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:40:54,775 - INFO - Beginning epoch 298/800
2025-03-06 22:40:54,780 - INFO - training batch 1, loss: 0.199, 32/28000 datapoints
2025-03-06 22:40:54,937 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 22:40:55,093 - INFO - training batch 101, loss: 0.121, 3232/28000 datapoints
2025-03-06 22:40:55,252 - INFO - training batch 151, loss: 0.123, 4832/28000 datapoints
2025-03-06 22:40:55,403 - INFO - training batch 201, loss: 0.042, 6432/28000 datapoints
2025-03-06 22:40:55,555 - INFO - training batch 251, loss: 0.409, 8032/28000 datapoints
2025-03-06 22:40:55,712 - INFO - training batch 301, loss: 0.544, 9632/28000 datapoints
2025-03-06 22:40:55,863 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 22:40:56,037 - INFO - training batch 401, loss: 0.221, 12832/28000 datapoints
2025-03-06 22:40:56,197 - INFO - training batch 451, loss: 0.280, 14432/28000 datapoints
2025-03-06 22:40:56,351 - INFO - training batch 501, loss: 0.114, 16032/28000 datapoints
2025-03-06 22:40:56,504 - INFO - training batch 551, loss: 0.204, 17632/28000 datapoints
2025-03-06 22:40:56,660 - INFO - training batch 601, loss: 0.162, 19232/28000 datapoints
2025-03-06 22:40:56,812 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 22:40:56,964 - INFO - training batch 701, loss: 0.195, 22432/28000 datapoints
2025-03-06 22:40:57,114 - INFO - training batch 751, loss: 0.115, 24032/28000 datapoints
2025-03-06 22:40:57,265 - INFO - training batch 801, loss: 0.052, 25632/28000 datapoints
2025-03-06 22:40:57,414 - INFO - training batch 851, loss: 0.188, 27232/28000 datapoints
2025-03-06 22:40:57,488 - INFO - validation batch 1, loss: 0.076, 32/6976 datapoints
2025-03-06 22:40:57,543 - INFO - validation batch 51, loss: 1.605, 1632/6976 datapoints
2025-03-06 22:40:57,592 - INFO - validation batch 101, loss: 0.441, 3232/6976 datapoints
2025-03-06 22:40:57,640 - INFO - validation batch 151, loss: 0.485, 4832/6976 datapoints
2025-03-06 22:40:57,688 - INFO - validation batch 201, loss: 0.722, 6432/6976 datapoints
2025-03-06 22:40:57,704 - INFO - Epoch 298/800 done.
2025-03-06 22:40:57,705 - INFO - Final validation performance:
Loss: 0.666, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:40:57,705 - INFO - Beginning epoch 299/800
2025-03-06 22:40:57,710 - INFO - training batch 1, loss: 0.198, 32/28000 datapoints
2025-03-06 22:40:57,861 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 22:40:58,013 - INFO - training batch 101, loss: 0.120, 3232/28000 datapoints
2025-03-06 22:40:58,171 - INFO - training batch 151, loss: 0.121, 4832/28000 datapoints
2025-03-06 22:40:58,325 - INFO - training batch 201, loss: 0.042, 6432/28000 datapoints
2025-03-06 22:40:58,475 - INFO - training batch 251, loss: 0.408, 8032/28000 datapoints
2025-03-06 22:40:58,627 - INFO - training batch 301, loss: 0.543, 9632/28000 datapoints
2025-03-06 22:40:58,778 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 22:40:58,940 - INFO - training batch 401, loss: 0.218, 12832/28000 datapoints
2025-03-06 22:40:59,099 - INFO - training batch 451, loss: 0.279, 14432/28000 datapoints
2025-03-06 22:40:59,259 - INFO - training batch 501, loss: 0.114, 16032/28000 datapoints
2025-03-06 22:40:59,415 - INFO - training batch 551, loss: 0.202, 17632/28000 datapoints
2025-03-06 22:40:59,571 - INFO - training batch 601, loss: 0.158, 19232/28000 datapoints
2025-03-06 22:40:59,727 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 22:40:59,884 - INFO - training batch 701, loss: 0.193, 22432/28000 datapoints
2025-03-06 22:41:00,044 - INFO - training batch 751, loss: 0.115, 24032/28000 datapoints
2025-03-06 22:41:00,197 - INFO - training batch 801, loss: 0.051, 25632/28000 datapoints
2025-03-06 22:41:00,351 - INFO - training batch 851, loss: 0.187, 27232/28000 datapoints
2025-03-06 22:41:00,439 - INFO - validation batch 1, loss: 0.076, 32/6976 datapoints
2025-03-06 22:41:00,490 - INFO - validation batch 51, loss: 1.614, 1632/6976 datapoints
2025-03-06 22:41:00,539 - INFO - validation batch 101, loss: 0.441, 3232/6976 datapoints
2025-03-06 22:41:00,589 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 22:41:00,637 - INFO - validation batch 201, loss: 0.725, 6432/6976 datapoints
2025-03-06 22:41:00,653 - INFO - Epoch 299/800 done.
2025-03-06 22:41:00,654 - INFO - Final validation performance:
Loss: 0.668, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:41:00,654 - INFO - Beginning epoch 300/800
2025-03-06 22:41:00,658 - INFO - training batch 1, loss: 0.195, 32/28000 datapoints
2025-03-06 22:41:00,818 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-06 22:41:00,978 - INFO - training batch 101, loss: 0.120, 3232/28000 datapoints
2025-03-06 22:41:01,133 - INFO - training batch 151, loss: 0.118, 4832/28000 datapoints
2025-03-06 22:41:01,291 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-06 22:41:01,442 - INFO - training batch 251, loss: 0.406, 8032/28000 datapoints
2025-03-06 22:41:01,601 - INFO - training batch 301, loss: 0.539, 9632/28000 datapoints
2025-03-06 22:41:01,759 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 22:41:01,917 - INFO - training batch 401, loss: 0.214, 12832/28000 datapoints
2025-03-06 22:41:02,080 - INFO - training batch 451, loss: 0.277, 14432/28000 datapoints
2025-03-06 22:41:02,248 - INFO - training batch 501, loss: 0.114, 16032/28000 datapoints
2025-03-06 22:41:02,408 - INFO - training batch 551, loss: 0.201, 17632/28000 datapoints
2025-03-06 22:41:02,565 - INFO - training batch 601, loss: 0.158, 19232/28000 datapoints
2025-03-06 22:41:02,724 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 22:41:02,881 - INFO - training batch 701, loss: 0.192, 22432/28000 datapoints
2025-03-06 22:41:03,038 - INFO - training batch 751, loss: 0.114, 24032/28000 datapoints
2025-03-06 22:41:03,193 - INFO - training batch 801, loss: 0.051, 25632/28000 datapoints
2025-03-06 22:41:03,348 - INFO - training batch 851, loss: 0.185, 27232/28000 datapoints
2025-03-06 22:41:03,427 - INFO - validation batch 1, loss: 0.077, 32/6976 datapoints
2025-03-06 22:41:03,478 - INFO - validation batch 51, loss: 1.621, 1632/6976 datapoints
2025-03-06 22:41:03,530 - INFO - validation batch 101, loss: 0.444, 3232/6976 datapoints
2025-03-06 22:41:03,585 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 22:41:03,638 - INFO - validation batch 201, loss: 0.725, 6432/6976 datapoints
2025-03-06 22:41:03,658 - INFO - Epoch 300/800 done.
2025-03-06 22:41:03,658 - INFO - Final validation performance:
Loss: 0.671, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:03,659 - INFO - Beginning epoch 301/800
2025-03-06 22:41:03,663 - INFO - training batch 1, loss: 0.194, 32/28000 datapoints
2025-03-06 22:41:03,825 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-06 22:41:03,984 - INFO - training batch 101, loss: 0.119, 3232/28000 datapoints
2025-03-06 22:41:04,140 - INFO - training batch 151, loss: 0.115, 4832/28000 datapoints
2025-03-06 22:41:04,299 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-06 22:41:04,458 - INFO - training batch 251, loss: 0.407, 8032/28000 datapoints
2025-03-06 22:41:04,617 - INFO - training batch 301, loss: 0.538, 9632/28000 datapoints
2025-03-06 22:41:04,774 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 22:41:04,930 - INFO - training batch 401, loss: 0.213, 12832/28000 datapoints
2025-03-06 22:41:05,088 - INFO - training batch 451, loss: 0.277, 14432/28000 datapoints
2025-03-06 22:41:05,249 - INFO - training batch 501, loss: 0.114, 16032/28000 datapoints
2025-03-06 22:41:05,408 - INFO - training batch 551, loss: 0.199, 17632/28000 datapoints
2025-03-06 22:41:05,565 - INFO - training batch 601, loss: 0.157, 19232/28000 datapoints
2025-03-06 22:41:05,723 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 22:41:05,881 - INFO - training batch 701, loss: 0.191, 22432/28000 datapoints
2025-03-06 22:41:06,041 - INFO - training batch 751, loss: 0.113, 24032/28000 datapoints
2025-03-06 22:41:06,220 - INFO - training batch 801, loss: 0.050, 25632/28000 datapoints
2025-03-06 22:41:06,379 - INFO - training batch 851, loss: 0.185, 27232/28000 datapoints
2025-03-06 22:41:06,458 - INFO - validation batch 1, loss: 0.077, 32/6976 datapoints
2025-03-06 22:41:06,509 - INFO - validation batch 51, loss: 1.629, 1632/6976 datapoints
2025-03-06 22:41:06,575 - INFO - validation batch 101, loss: 0.445, 3232/6976 datapoints
2025-03-06 22:41:06,641 - INFO - validation batch 151, loss: 0.489, 4832/6976 datapoints
2025-03-06 22:41:06,698 - INFO - validation batch 201, loss: 0.728, 6432/6976 datapoints
2025-03-06 22:41:06,714 - INFO - Epoch 301/800 done.
2025-03-06 22:41:06,714 - INFO - Final validation performance:
Loss: 0.674, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:06,715 - INFO - Beginning epoch 302/800
2025-03-06 22:41:06,719 - INFO - training batch 1, loss: 0.192, 32/28000 datapoints
2025-03-06 22:41:06,888 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-06 22:41:07,046 - INFO - training batch 101, loss: 0.119, 3232/28000 datapoints
2025-03-06 22:41:07,201 - INFO - training batch 151, loss: 0.115, 4832/28000 datapoints
2025-03-06 22:41:07,357 - INFO - training batch 201, loss: 0.040, 6432/28000 datapoints
2025-03-06 22:41:07,512 - INFO - training batch 251, loss: 0.405, 8032/28000 datapoints
2025-03-06 22:41:07,667 - INFO - training batch 301, loss: 0.536, 9632/28000 datapoints
2025-03-06 22:41:07,826 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 22:41:07,986 - INFO - training batch 401, loss: 0.211, 12832/28000 datapoints
2025-03-06 22:41:08,142 - INFO - training batch 451, loss: 0.276, 14432/28000 datapoints
2025-03-06 22:41:08,301 - INFO - training batch 501, loss: 0.113, 16032/28000 datapoints
2025-03-06 22:41:08,459 - INFO - training batch 551, loss: 0.198, 17632/28000 datapoints
2025-03-06 22:41:08,614 - INFO - training batch 601, loss: 0.156, 19232/28000 datapoints
2025-03-06 22:41:08,769 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 22:41:08,927 - INFO - training batch 701, loss: 0.190, 22432/28000 datapoints
2025-03-06 22:41:09,086 - INFO - training batch 751, loss: 0.111, 24032/28000 datapoints
2025-03-06 22:41:09,243 - INFO - training batch 801, loss: 0.050, 25632/28000 datapoints
2025-03-06 22:41:09,403 - INFO - training batch 851, loss: 0.184, 27232/28000 datapoints
2025-03-06 22:41:09,480 - INFO - validation batch 1, loss: 0.077, 32/6976 datapoints
2025-03-06 22:41:09,532 - INFO - validation batch 51, loss: 1.636, 1632/6976 datapoints
2025-03-06 22:41:09,584 - INFO - validation batch 101, loss: 0.446, 3232/6976 datapoints
2025-03-06 22:41:09,636 - INFO - validation batch 151, loss: 0.493, 4832/6976 datapoints
2025-03-06 22:41:09,688 - INFO - validation batch 201, loss: 0.730, 6432/6976 datapoints
2025-03-06 22:41:09,708 - INFO - Epoch 302/800 done.
2025-03-06 22:41:09,709 - INFO - Final validation performance:
Loss: 0.676, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:09,709 - INFO - Beginning epoch 303/800
2025-03-06 22:41:09,713 - INFO - training batch 1, loss: 0.191, 32/28000 datapoints
2025-03-06 22:41:09,873 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-06 22:41:10,034 - INFO - training batch 101, loss: 0.119, 3232/28000 datapoints
2025-03-06 22:41:10,188 - INFO - training batch 151, loss: 0.111, 4832/28000 datapoints
2025-03-06 22:41:10,350 - INFO - training batch 201, loss: 0.040, 6432/28000 datapoints
2025-03-06 22:41:10,506 - INFO - training batch 251, loss: 0.404, 8032/28000 datapoints
2025-03-06 22:41:10,664 - INFO - training batch 301, loss: 0.532, 9632/28000 datapoints
2025-03-06 22:41:10,820 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 22:41:10,978 - INFO - training batch 401, loss: 0.207, 12832/28000 datapoints
2025-03-06 22:41:11,132 - INFO - training batch 451, loss: 0.275, 14432/28000 datapoints
2025-03-06 22:41:11,288 - INFO - training batch 501, loss: 0.112, 16032/28000 datapoints
2025-03-06 22:41:11,446 - INFO - training batch 551, loss: 0.196, 17632/28000 datapoints
2025-03-06 22:41:11,604 - INFO - training batch 601, loss: 0.153, 19232/28000 datapoints
2025-03-06 22:41:11,763 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 22:41:11,919 - INFO - training batch 701, loss: 0.189, 22432/28000 datapoints
2025-03-06 22:41:12,076 - INFO - training batch 751, loss: 0.111, 24032/28000 datapoints
2025-03-06 22:41:12,232 - INFO - training batch 801, loss: 0.049, 25632/28000 datapoints
2025-03-06 22:41:12,393 - INFO - training batch 851, loss: 0.182, 27232/28000 datapoints
2025-03-06 22:41:12,471 - INFO - validation batch 1, loss: 0.078, 32/6976 datapoints
2025-03-06 22:41:12,524 - INFO - validation batch 51, loss: 1.645, 1632/6976 datapoints
2025-03-06 22:41:12,575 - INFO - validation batch 101, loss: 0.449, 3232/6976 datapoints
2025-03-06 22:41:12,627 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 22:41:12,680 - INFO - validation batch 201, loss: 0.733, 6432/6976 datapoints
2025-03-06 22:41:12,701 - INFO - Epoch 303/800 done.
2025-03-06 22:41:12,701 - INFO - Final validation performance:
Loss: 0.680, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:12,701 - INFO - Beginning epoch 304/800
2025-03-06 22:41:12,706 - INFO - training batch 1, loss: 0.189, 32/28000 datapoints
2025-03-06 22:41:12,881 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-06 22:41:13,037 - INFO - training batch 101, loss: 0.118, 3232/28000 datapoints
2025-03-06 22:41:13,193 - INFO - training batch 151, loss: 0.111, 4832/28000 datapoints
2025-03-06 22:41:13,359 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-06 22:41:13,517 - INFO - training batch 251, loss: 0.403, 8032/28000 datapoints
2025-03-06 22:41:13,676 - INFO - training batch 301, loss: 0.531, 9632/28000 datapoints
2025-03-06 22:41:13,859 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 22:41:14,030 - INFO - training batch 401, loss: 0.206, 12832/28000 datapoints
2025-03-06 22:41:14,185 - INFO - training batch 451, loss: 0.274, 14432/28000 datapoints
2025-03-06 22:41:14,345 - INFO - training batch 501, loss: 0.112, 16032/28000 datapoints
2025-03-06 22:41:14,500 - INFO - training batch 551, loss: 0.195, 17632/28000 datapoints
2025-03-06 22:41:14,658 - INFO - training batch 601, loss: 0.151, 19232/28000 datapoints
2025-03-06 22:41:14,815 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 22:41:14,973 - INFO - training batch 701, loss: 0.188, 22432/28000 datapoints
2025-03-06 22:41:15,127 - INFO - training batch 751, loss: 0.109, 24032/28000 datapoints
2025-03-06 22:41:15,286 - INFO - training batch 801, loss: 0.049, 25632/28000 datapoints
2025-03-06 22:41:15,443 - INFO - training batch 851, loss: 0.180, 27232/28000 datapoints
2025-03-06 22:41:15,521 - INFO - validation batch 1, loss: 0.078, 32/6976 datapoints
2025-03-06 22:41:15,575 - INFO - validation batch 51, loss: 1.652, 1632/6976 datapoints
2025-03-06 22:41:15,628 - INFO - validation batch 101, loss: 0.450, 3232/6976 datapoints
2025-03-06 22:41:15,683 - INFO - validation batch 151, loss: 0.498, 4832/6976 datapoints
2025-03-06 22:41:15,737 - INFO - validation batch 201, loss: 0.734, 6432/6976 datapoints
2025-03-06 22:41:15,756 - INFO - Epoch 304/800 done.
2025-03-06 22:41:15,756 - INFO - Final validation performance:
Loss: 0.682, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:41:15,757 - INFO - Beginning epoch 305/800
2025-03-06 22:41:15,761 - INFO - training batch 1, loss: 0.188, 32/28000 datapoints
2025-03-06 22:41:15,920 - INFO - training batch 51, loss: 0.053, 1632/28000 datapoints
2025-03-06 22:41:16,086 - INFO - training batch 101, loss: 0.118, 3232/28000 datapoints
2025-03-06 22:41:16,267 - INFO - training batch 151, loss: 0.110, 4832/28000 datapoints
2025-03-06 22:41:16,426 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-06 22:41:16,581 - INFO - training batch 251, loss: 0.403, 8032/28000 datapoints
2025-03-06 22:41:16,736 - INFO - training batch 301, loss: 0.529, 9632/28000 datapoints
2025-03-06 22:41:16,900 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 22:41:17,060 - INFO - training batch 401, loss: 0.204, 12832/28000 datapoints
2025-03-06 22:41:17,216 - INFO - training batch 451, loss: 0.274, 14432/28000 datapoints
2025-03-06 22:41:17,373 - INFO - training batch 501, loss: 0.111, 16032/28000 datapoints
2025-03-06 22:41:17,531 - INFO - training batch 551, loss: 0.192, 17632/28000 datapoints
2025-03-06 22:41:17,687 - INFO - training batch 601, loss: 0.150, 19232/28000 datapoints
2025-03-06 22:41:17,848 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 22:41:18,007 - INFO - training batch 701, loss: 0.186, 22432/28000 datapoints
2025-03-06 22:41:18,165 - INFO - training batch 751, loss: 0.109, 24032/28000 datapoints
2025-03-06 22:41:18,323 - INFO - training batch 801, loss: 0.048, 25632/28000 datapoints
2025-03-06 22:41:18,496 - INFO - training batch 851, loss: 0.180, 27232/28000 datapoints
2025-03-06 22:41:18,573 - INFO - validation batch 1, loss: 0.078, 32/6976 datapoints
2025-03-06 22:41:18,629 - INFO - validation batch 51, loss: 1.663, 1632/6976 datapoints
2025-03-06 22:41:18,681 - INFO - validation batch 101, loss: 0.450, 3232/6976 datapoints
2025-03-06 22:41:18,733 - INFO - validation batch 151, loss: 0.503, 4832/6976 datapoints
2025-03-06 22:41:18,787 - INFO - validation batch 201, loss: 0.735, 6432/6976 datapoints
2025-03-06 22:41:18,807 - INFO - Epoch 305/800 done.
2025-03-06 22:41:18,807 - INFO - Final validation performance:
Loss: 0.686, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 22:41:18,808 - INFO - Beginning epoch 306/800
2025-03-06 22:41:18,813 - INFO - training batch 1, loss: 0.185, 32/28000 datapoints
2025-03-06 22:41:18,988 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-06 22:41:19,170 - INFO - training batch 101, loss: 0.115, 3232/28000 datapoints
2025-03-06 22:41:19,335 - INFO - training batch 151, loss: 0.103, 4832/28000 datapoints
2025-03-06 22:41:19,495 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-06 22:41:19,654 - INFO - training batch 251, loss: 0.402, 8032/28000 datapoints
2025-03-06 22:41:19,812 - INFO - training batch 301, loss: 0.524, 9632/28000 datapoints
2025-03-06 22:41:19,974 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 22:41:20,127 - INFO - training batch 401, loss: 0.201, 12832/28000 datapoints
2025-03-06 22:41:20,282 - INFO - training batch 451, loss: 0.272, 14432/28000 datapoints
2025-03-06 22:41:20,444 - INFO - training batch 501, loss: 0.110, 16032/28000 datapoints
2025-03-06 22:41:20,605 - INFO - training batch 551, loss: 0.191, 17632/28000 datapoints
2025-03-06 22:41:20,763 - INFO - training batch 601, loss: 0.149, 19232/28000 datapoints
2025-03-06 22:41:20,919 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 22:41:21,078 - INFO - training batch 701, loss: 0.185, 22432/28000 datapoints
2025-03-06 22:41:21,236 - INFO - training batch 751, loss: 0.107, 24032/28000 datapoints
2025-03-06 22:41:21,393 - INFO - training batch 801, loss: 0.048, 25632/28000 datapoints
2025-03-06 22:41:21,548 - INFO - training batch 851, loss: 0.179, 27232/28000 datapoints
2025-03-06 22:41:21,627 - INFO - validation batch 1, loss: 0.079, 32/6976 datapoints
2025-03-06 22:41:21,683 - INFO - validation batch 51, loss: 1.671, 1632/6976 datapoints
2025-03-06 22:41:21,742 - INFO - validation batch 101, loss: 0.453, 3232/6976 datapoints
2025-03-06 22:41:21,796 - INFO - validation batch 151, loss: 0.504, 4832/6976 datapoints
2025-03-06 22:41:21,844 - INFO - validation batch 201, loss: 0.738, 6432/6976 datapoints
2025-03-06 22:41:21,860 - INFO - Epoch 306/800 done.
2025-03-06 22:41:21,860 - INFO - Final validation performance:
Loss: 0.689, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:21,861 - INFO - Beginning epoch 307/800
2025-03-06 22:41:21,865 - INFO - training batch 1, loss: 0.184, 32/28000 datapoints
2025-03-06 22:41:22,024 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-06 22:41:22,177 - INFO - training batch 101, loss: 0.115, 3232/28000 datapoints
2025-03-06 22:41:22,333 - INFO - training batch 151, loss: 0.100, 4832/28000 datapoints
2025-03-06 22:41:22,486 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-06 22:41:22,638 - INFO - training batch 251, loss: 0.401, 8032/28000 datapoints
2025-03-06 22:41:22,791 - INFO - training batch 301, loss: 0.523, 9632/28000 datapoints
2025-03-06 22:41:22,943 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 22:41:23,101 - INFO - training batch 401, loss: 0.200, 12832/28000 datapoints
2025-03-06 22:41:23,251 - INFO - training batch 451, loss: 0.272, 14432/28000 datapoints
2025-03-06 22:41:23,402 - INFO - training batch 501, loss: 0.110, 16032/28000 datapoints
2025-03-06 22:41:23,556 - INFO - training batch 551, loss: 0.189, 17632/28000 datapoints
2025-03-06 22:41:23,708 - INFO - training batch 601, loss: 0.147, 19232/28000 datapoints
2025-03-06 22:41:23,861 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 22:41:24,015 - INFO - training batch 701, loss: 0.184, 22432/28000 datapoints
2025-03-06 22:41:24,167 - INFO - training batch 751, loss: 0.108, 24032/28000 datapoints
2025-03-06 22:41:24,324 - INFO - training batch 801, loss: 0.047, 25632/28000 datapoints
2025-03-06 22:41:24,476 - INFO - training batch 851, loss: 0.178, 27232/28000 datapoints
2025-03-06 22:41:24,551 - INFO - validation batch 1, loss: 0.079, 32/6976 datapoints
2025-03-06 22:41:24,599 - INFO - validation batch 51, loss: 1.680, 1632/6976 datapoints
2025-03-06 22:41:24,647 - INFO - validation batch 101, loss: 0.453, 3232/6976 datapoints
2025-03-06 22:41:24,695 - INFO - validation batch 151, loss: 0.506, 4832/6976 datapoints
2025-03-06 22:41:24,743 - INFO - validation batch 201, loss: 0.740, 6432/6976 datapoints
2025-03-06 22:41:24,760 - INFO - Epoch 307/800 done.
2025-03-06 22:41:24,760 - INFO - Final validation performance:
Loss: 0.692, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:24,761 - INFO - Beginning epoch 308/800
2025-03-06 22:41:24,765 - INFO - training batch 1, loss: 0.181, 32/28000 datapoints
2025-03-06 22:41:24,918 - INFO - training batch 51, loss: 0.053, 1632/28000 datapoints
2025-03-06 22:41:25,076 - INFO - training batch 101, loss: 0.114, 3232/28000 datapoints
2025-03-06 22:41:25,247 - INFO - training batch 151, loss: 0.101, 4832/28000 datapoints
2025-03-06 22:41:25,400 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-06 22:41:25,557 - INFO - training batch 251, loss: 0.398, 8032/28000 datapoints
2025-03-06 22:41:25,715 - INFO - training batch 301, loss: 0.520, 9632/28000 datapoints
2025-03-06 22:41:25,870 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 22:41:26,029 - INFO - training batch 401, loss: 0.198, 12832/28000 datapoints
2025-03-06 22:41:26,181 - INFO - training batch 451, loss: 0.270, 14432/28000 datapoints
2025-03-06 22:41:26,360 - INFO - training batch 501, loss: 0.109, 16032/28000 datapoints
2025-03-06 22:41:26,512 - INFO - training batch 551, loss: 0.187, 17632/28000 datapoints
2025-03-06 22:41:26,664 - INFO - training batch 601, loss: 0.146, 19232/28000 datapoints
2025-03-06 22:41:26,820 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 22:41:26,973 - INFO - training batch 701, loss: 0.183, 22432/28000 datapoints
2025-03-06 22:41:27,124 - INFO - training batch 751, loss: 0.105, 24032/28000 datapoints
2025-03-06 22:41:27,276 - INFO - training batch 801, loss: 0.046, 25632/28000 datapoints
2025-03-06 22:41:27,428 - INFO - training batch 851, loss: 0.177, 27232/28000 datapoints
2025-03-06 22:41:27,502 - INFO - validation batch 1, loss: 0.080, 32/6976 datapoints
2025-03-06 22:41:27,549 - INFO - validation batch 51, loss: 1.686, 1632/6976 datapoints
2025-03-06 22:41:27,600 - INFO - validation batch 101, loss: 0.454, 3232/6976 datapoints
2025-03-06 22:41:27,647 - INFO - validation batch 151, loss: 0.509, 4832/6976 datapoints
2025-03-06 22:41:27,695 - INFO - validation batch 201, loss: 0.741, 6432/6976 datapoints
2025-03-06 22:41:27,717 - INFO - Epoch 308/800 done.
2025-03-06 22:41:27,717 - INFO - Final validation performance:
Loss: 0.694, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:27,718 - INFO - Beginning epoch 309/800
2025-03-06 22:41:27,722 - INFO - training batch 1, loss: 0.181, 32/28000 datapoints
2025-03-06 22:41:27,879 - INFO - training batch 51, loss: 0.053, 1632/28000 datapoints
2025-03-06 22:41:28,032 - INFO - training batch 101, loss: 0.114, 3232/28000 datapoints
2025-03-06 22:41:28,188 - INFO - training batch 151, loss: 0.102, 4832/28000 datapoints
2025-03-06 22:41:28,346 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-06 22:41:28,507 - INFO - training batch 251, loss: 0.400, 8032/28000 datapoints
2025-03-06 22:41:28,659 - INFO - training batch 301, loss: 0.520, 9632/28000 datapoints
2025-03-06 22:41:28,812 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 22:41:28,967 - INFO - training batch 401, loss: 0.194, 12832/28000 datapoints
2025-03-06 22:41:29,120 - INFO - training batch 451, loss: 0.269, 14432/28000 datapoints
2025-03-06 22:41:29,273 - INFO - training batch 501, loss: 0.109, 16032/28000 datapoints
2025-03-06 22:41:29,426 - INFO - training batch 551, loss: 0.186, 17632/28000 datapoints
2025-03-06 22:41:29,577 - INFO - training batch 601, loss: 0.144, 19232/28000 datapoints
2025-03-06 22:41:29,729 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 22:41:29,880 - INFO - training batch 701, loss: 0.182, 22432/28000 datapoints
2025-03-06 22:41:30,032 - INFO - training batch 751, loss: 0.105, 24032/28000 datapoints
2025-03-06 22:41:30,184 - INFO - training batch 801, loss: 0.046, 25632/28000 datapoints
2025-03-06 22:41:30,339 - INFO - training batch 851, loss: 0.176, 27232/28000 datapoints
2025-03-06 22:41:30,414 - INFO - validation batch 1, loss: 0.080, 32/6976 datapoints
2025-03-06 22:41:30,462 - INFO - validation batch 51, loss: 1.695, 1632/6976 datapoints
2025-03-06 22:41:30,510 - INFO - validation batch 101, loss: 0.458, 3232/6976 datapoints
2025-03-06 22:41:30,557 - INFO - validation batch 151, loss: 0.511, 4832/6976 datapoints
2025-03-06 22:41:30,607 - INFO - validation batch 201, loss: 0.744, 6432/6976 datapoints
2025-03-06 22:41:30,624 - INFO - Epoch 309/800 done.
2025-03-06 22:41:30,624 - INFO - Final validation performance:
Loss: 0.698, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:30,624 - INFO - Beginning epoch 310/800
2025-03-06 22:41:30,628 - INFO - training batch 1, loss: 0.179, 32/28000 datapoints
2025-03-06 22:41:30,784 - INFO - training batch 51, loss: 0.053, 1632/28000 datapoints
2025-03-06 22:41:30,935 - INFO - training batch 101, loss: 0.113, 3232/28000 datapoints
2025-03-06 22:41:31,091 - INFO - training batch 151, loss: 0.096, 4832/28000 datapoints
2025-03-06 22:41:31,258 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-06 22:41:31,409 - INFO - training batch 251, loss: 0.397, 8032/28000 datapoints
2025-03-06 22:41:31,560 - INFO - training batch 301, loss: 0.516, 9632/28000 datapoints
2025-03-06 22:41:31,721 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:41:31,880 - INFO - training batch 401, loss: 0.193, 12832/28000 datapoints
2025-03-06 22:41:32,035 - INFO - training batch 451, loss: 0.269, 14432/28000 datapoints
2025-03-06 22:41:32,198 - INFO - training batch 501, loss: 0.109, 16032/28000 datapoints
2025-03-06 22:41:32,362 - INFO - training batch 551, loss: 0.185, 17632/28000 datapoints
2025-03-06 22:41:32,516 - INFO - training batch 601, loss: 0.143, 19232/28000 datapoints
2025-03-06 22:41:32,672 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 22:41:32,825 - INFO - training batch 701, loss: 0.181, 22432/28000 datapoints
2025-03-06 22:41:32,979 - INFO - training batch 751, loss: 0.104, 24032/28000 datapoints
2025-03-06 22:41:33,133 - INFO - training batch 801, loss: 0.045, 25632/28000 datapoints
2025-03-06 22:41:33,306 - INFO - training batch 851, loss: 0.175, 27232/28000 datapoints
2025-03-06 22:41:33,401 - INFO - validation batch 1, loss: 0.080, 32/6976 datapoints
2025-03-06 22:41:33,451 - INFO - validation batch 51, loss: 1.704, 1632/6976 datapoints
2025-03-06 22:41:33,498 - INFO - validation batch 101, loss: 0.459, 3232/6976 datapoints
2025-03-06 22:41:33,545 - INFO - validation batch 151, loss: 0.513, 4832/6976 datapoints
2025-03-06 22:41:33,594 - INFO - validation batch 201, loss: 0.748, 6432/6976 datapoints
2025-03-06 22:41:33,611 - INFO - Epoch 310/800 done.
2025-03-06 22:41:33,611 - INFO - Final validation performance:
Loss: 0.701, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:33,612 - INFO - Beginning epoch 311/800
2025-03-06 22:41:33,618 - INFO - training batch 1, loss: 0.178, 32/28000 datapoints
2025-03-06 22:41:33,775 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-06 22:41:33,926 - INFO - training batch 101, loss: 0.112, 3232/28000 datapoints
2025-03-06 22:41:34,080 - INFO - training batch 151, loss: 0.095, 4832/28000 datapoints
2025-03-06 22:41:34,232 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-06 22:41:34,388 - INFO - training batch 251, loss: 0.396, 8032/28000 datapoints
2025-03-06 22:41:34,539 - INFO - training batch 301, loss: 0.513, 9632/28000 datapoints
2025-03-06 22:41:34,692 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 22:41:34,845 - INFO - training batch 401, loss: 0.191, 12832/28000 datapoints
2025-03-06 22:41:34,998 - INFO - training batch 451, loss: 0.268, 14432/28000 datapoints
2025-03-06 22:41:35,150 - INFO - training batch 501, loss: 0.109, 16032/28000 datapoints
2025-03-06 22:41:35,308 - INFO - training batch 551, loss: 0.182, 17632/28000 datapoints
2025-03-06 22:41:35,461 - INFO - training batch 601, loss: 0.142, 19232/28000 datapoints
2025-03-06 22:41:35,613 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 22:41:35,770 - INFO - training batch 701, loss: 0.180, 22432/28000 datapoints
2025-03-06 22:41:35,921 - INFO - training batch 751, loss: 0.102, 24032/28000 datapoints
2025-03-06 22:41:36,074 - INFO - training batch 801, loss: 0.045, 25632/28000 datapoints
2025-03-06 22:41:36,226 - INFO - training batch 851, loss: 0.173, 27232/28000 datapoints
2025-03-06 22:41:36,301 - INFO - validation batch 1, loss: 0.081, 32/6976 datapoints
2025-03-06 22:41:36,354 - INFO - validation batch 51, loss: 1.710, 1632/6976 datapoints
2025-03-06 22:41:36,425 - INFO - validation batch 101, loss: 0.461, 3232/6976 datapoints
2025-03-06 22:41:36,478 - INFO - validation batch 151, loss: 0.515, 4832/6976 datapoints
2025-03-06 22:41:36,525 - INFO - validation batch 201, loss: 0.748, 6432/6976 datapoints
2025-03-06 22:41:36,542 - INFO - Epoch 311/800 done.
2025-03-06 22:41:36,542 - INFO - Final validation performance:
Loss: 0.703, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:36,543 - INFO - Beginning epoch 312/800
2025-03-06 22:41:36,547 - INFO - training batch 1, loss: 0.176, 32/28000 datapoints
2025-03-06 22:41:36,704 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-06 22:41:36,857 - INFO - training batch 101, loss: 0.112, 3232/28000 datapoints
2025-03-06 22:41:37,014 - INFO - training batch 151, loss: 0.093, 4832/28000 datapoints
2025-03-06 22:41:37,178 - INFO - training batch 201, loss: 0.036, 6432/28000 datapoints
2025-03-06 22:41:37,343 - INFO - training batch 251, loss: 0.393, 8032/28000 datapoints
2025-03-06 22:41:37,495 - INFO - training batch 301, loss: 0.509, 9632/28000 datapoints
2025-03-06 22:41:37,651 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 22:41:37,811 - INFO - training batch 401, loss: 0.189, 12832/28000 datapoints
2025-03-06 22:41:37,973 - INFO - training batch 451, loss: 0.266, 14432/28000 datapoints
2025-03-06 22:41:38,131 - INFO - training batch 501, loss: 0.109, 16032/28000 datapoints
2025-03-06 22:41:38,285 - INFO - training batch 551, loss: 0.182, 17632/28000 datapoints
2025-03-06 22:41:38,456 - INFO - training batch 601, loss: 0.140, 19232/28000 datapoints
2025-03-06 22:41:38,615 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:41:38,766 - INFO - training batch 701, loss: 0.178, 22432/28000 datapoints
2025-03-06 22:41:38,918 - INFO - training batch 751, loss: 0.103, 24032/28000 datapoints
2025-03-06 22:41:39,076 - INFO - training batch 801, loss: 0.044, 25632/28000 datapoints
2025-03-06 22:41:39,231 - INFO - training batch 851, loss: 0.172, 27232/28000 datapoints
2025-03-06 22:41:39,306 - INFO - validation batch 1, loss: 0.081, 32/6976 datapoints
2025-03-06 22:41:39,356 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 22:41:39,408 - INFO - validation batch 101, loss: 0.463, 3232/6976 datapoints
2025-03-06 22:41:39,455 - INFO - validation batch 151, loss: 0.517, 4832/6976 datapoints
2025-03-06 22:41:39,502 - INFO - validation batch 201, loss: 0.755, 6432/6976 datapoints
2025-03-06 22:41:39,518 - INFO - Epoch 312/800 done.
2025-03-06 22:41:39,518 - INFO - Final validation performance:
Loss: 0.707, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:39,519 - INFO - Beginning epoch 313/800
2025-03-06 22:41:39,523 - INFO - training batch 1, loss: 0.174, 32/28000 datapoints
2025-03-06 22:41:39,676 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 22:41:39,831 - INFO - training batch 101, loss: 0.112, 3232/28000 datapoints
2025-03-06 22:41:39,985 - INFO - training batch 151, loss: 0.092, 4832/28000 datapoints
2025-03-06 22:41:40,137 - INFO - training batch 201, loss: 0.036, 6432/28000 datapoints
2025-03-06 22:41:40,293 - INFO - training batch 251, loss: 0.393, 8032/28000 datapoints
2025-03-06 22:41:40,450 - INFO - training batch 301, loss: 0.508, 9632/28000 datapoints
2025-03-06 22:41:40,604 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:41:40,775 - INFO - training batch 401, loss: 0.186, 12832/28000 datapoints
2025-03-06 22:41:40,927 - INFO - training batch 451, loss: 0.266, 14432/28000 datapoints
2025-03-06 22:41:41,081 - INFO - training batch 501, loss: 0.109, 16032/28000 datapoints
2025-03-06 22:41:41,236 - INFO - training batch 551, loss: 0.180, 17632/28000 datapoints
2025-03-06 22:41:41,389 - INFO - training batch 601, loss: 0.139, 19232/28000 datapoints
2025-03-06 22:41:41,546 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:41:41,699 - INFO - training batch 701, loss: 0.178, 22432/28000 datapoints
2025-03-06 22:41:41,864 - INFO - training batch 751, loss: 0.099, 24032/28000 datapoints
2025-03-06 22:41:42,021 - INFO - training batch 801, loss: 0.044, 25632/28000 datapoints
2025-03-06 22:41:42,180 - INFO - training batch 851, loss: 0.171, 27232/28000 datapoints
2025-03-06 22:41:42,261 - INFO - validation batch 1, loss: 0.082, 32/6976 datapoints
2025-03-06 22:41:42,313 - INFO - validation batch 51, loss: 1.727, 1632/6976 datapoints
2025-03-06 22:41:42,365 - INFO - validation batch 101, loss: 0.466, 3232/6976 datapoints
2025-03-06 22:41:42,421 - INFO - validation batch 151, loss: 0.521, 4832/6976 datapoints
2025-03-06 22:41:42,474 - INFO - validation batch 201, loss: 0.754, 6432/6976 datapoints
2025-03-06 22:41:42,493 - INFO - Epoch 313/800 done.
2025-03-06 22:41:42,493 - INFO - Final validation performance:
Loss: 0.710, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:42,494 - INFO - Beginning epoch 314/800
2025-03-06 22:41:42,499 - INFO - training batch 1, loss: 0.173, 32/28000 datapoints
2025-03-06 22:41:42,652 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 22:41:42,807 - INFO - training batch 101, loss: 0.111, 3232/28000 datapoints
2025-03-06 22:41:42,961 - INFO - training batch 151, loss: 0.092, 4832/28000 datapoints
2025-03-06 22:41:43,114 - INFO - training batch 201, loss: 0.036, 6432/28000 datapoints
2025-03-06 22:41:43,282 - INFO - training batch 251, loss: 0.392, 8032/28000 datapoints
2025-03-06 22:41:43,434 - INFO - training batch 301, loss: 0.505, 9632/28000 datapoints
2025-03-06 22:41:43,587 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 22:41:43,740 - INFO - training batch 401, loss: 0.184, 12832/28000 datapoints
2025-03-06 22:41:43,898 - INFO - training batch 451, loss: 0.264, 14432/28000 datapoints
2025-03-06 22:41:44,059 - INFO - training batch 501, loss: 0.108, 16032/28000 datapoints
2025-03-06 22:41:44,213 - INFO - training batch 551, loss: 0.179, 17632/28000 datapoints
2025-03-06 22:41:44,370 - INFO - training batch 601, loss: 0.137, 19232/28000 datapoints
2025-03-06 22:41:44,524 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:41:44,675 - INFO - training batch 701, loss: 0.176, 22432/28000 datapoints
2025-03-06 22:41:44,829 - INFO - training batch 751, loss: 0.100, 24032/28000 datapoints
2025-03-06 22:41:44,981 - INFO - training batch 801, loss: 0.043, 25632/28000 datapoints
2025-03-06 22:41:45,133 - INFO - training batch 851, loss: 0.171, 27232/28000 datapoints
2025-03-06 22:41:45,215 - INFO - validation batch 1, loss: 0.082, 32/6976 datapoints
2025-03-06 22:41:45,262 - INFO - validation batch 51, loss: 1.736, 1632/6976 datapoints
2025-03-06 22:41:45,313 - INFO - validation batch 101, loss: 0.468, 3232/6976 datapoints
2025-03-06 22:41:45,360 - INFO - validation batch 151, loss: 0.521, 4832/6976 datapoints
2025-03-06 22:41:45,411 - INFO - validation batch 201, loss: 0.758, 6432/6976 datapoints
2025-03-06 22:41:45,427 - INFO - Epoch 314/800 done.
2025-03-06 22:41:45,427 - INFO - Final validation performance:
Loss: 0.713, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:45,428 - INFO - Beginning epoch 315/800
2025-03-06 22:41:45,432 - INFO - training batch 1, loss: 0.171, 32/28000 datapoints
2025-03-06 22:41:45,585 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 22:41:45,741 - INFO - training batch 101, loss: 0.110, 3232/28000 datapoints
2025-03-06 22:41:45,897 - INFO - training batch 151, loss: 0.091, 4832/28000 datapoints
2025-03-06 22:41:46,052 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 22:41:46,206 - INFO - training batch 251, loss: 0.391, 8032/28000 datapoints
2025-03-06 22:41:46,357 - INFO - training batch 301, loss: 0.501, 9632/28000 datapoints
2025-03-06 22:41:46,539 - INFO - training batch 351, loss: 0.192, 11232/28000 datapoints
2025-03-06 22:41:46,690 - INFO - training batch 401, loss: 0.182, 12832/28000 datapoints
2025-03-06 22:41:46,845 - INFO - training batch 451, loss: 0.264, 14432/28000 datapoints
2025-03-06 22:41:46,999 - INFO - training batch 501, loss: 0.108, 16032/28000 datapoints
2025-03-06 22:41:47,152 - INFO - training batch 551, loss: 0.177, 17632/28000 datapoints
2025-03-06 22:41:47,304 - INFO - training batch 601, loss: 0.135, 19232/28000 datapoints
2025-03-06 22:41:47,465 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 22:41:47,614 - INFO - training batch 701, loss: 0.175, 22432/28000 datapoints
2025-03-06 22:41:47,765 - INFO - training batch 751, loss: 0.100, 24032/28000 datapoints
2025-03-06 22:41:47,916 - INFO - training batch 801, loss: 0.043, 25632/28000 datapoints
2025-03-06 22:41:48,070 - INFO - training batch 851, loss: 0.169, 27232/28000 datapoints
2025-03-06 22:41:48,147 - INFO - validation batch 1, loss: 0.082, 32/6976 datapoints
2025-03-06 22:41:48,194 - INFO - validation batch 51, loss: 1.746, 1632/6976 datapoints
2025-03-06 22:41:48,241 - INFO - validation batch 101, loss: 0.470, 3232/6976 datapoints
2025-03-06 22:41:48,288 - INFO - validation batch 151, loss: 0.523, 4832/6976 datapoints
2025-03-06 22:41:48,337 - INFO - validation batch 201, loss: 0.760, 6432/6976 datapoints
2025-03-06 22:41:48,354 - INFO - Epoch 315/800 done.
2025-03-06 22:41:48,354 - INFO - Final validation performance:
Loss: 0.716, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:48,354 - INFO - Beginning epoch 316/800
2025-03-06 22:41:48,358 - INFO - training batch 1, loss: 0.169, 32/28000 datapoints
2025-03-06 22:41:48,513 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 22:41:48,664 - INFO - training batch 101, loss: 0.109, 3232/28000 datapoints
2025-03-06 22:41:48,817 - INFO - training batch 151, loss: 0.087, 4832/28000 datapoints
2025-03-06 22:41:48,974 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 22:41:49,125 - INFO - training batch 251, loss: 0.388, 8032/28000 datapoints
2025-03-06 22:41:49,289 - INFO - training batch 301, loss: 0.499, 9632/28000 datapoints
2025-03-06 22:41:49,441 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:41:49,591 - INFO - training batch 401, loss: 0.180, 12832/28000 datapoints
2025-03-06 22:41:49,746 - INFO - training batch 451, loss: 0.263, 14432/28000 datapoints
2025-03-06 22:41:49,904 - INFO - training batch 501, loss: 0.107, 16032/28000 datapoints
2025-03-06 22:41:50,061 - INFO - training batch 551, loss: 0.176, 17632/28000 datapoints
2025-03-06 22:41:50,217 - INFO - training batch 601, loss: 0.136, 19232/28000 datapoints
2025-03-06 22:41:50,371 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:41:50,524 - INFO - training batch 701, loss: 0.174, 22432/28000 datapoints
2025-03-06 22:41:50,674 - INFO - training batch 751, loss: 0.097, 24032/28000 datapoints
2025-03-06 22:41:50,825 - INFO - training batch 801, loss: 0.042, 25632/28000 datapoints
2025-03-06 22:41:50,981 - INFO - training batch 851, loss: 0.168, 27232/28000 datapoints
2025-03-06 22:41:51,066 - INFO - validation batch 1, loss: 0.082, 32/6976 datapoints
2025-03-06 22:41:51,113 - INFO - validation batch 51, loss: 1.753, 1632/6976 datapoints
2025-03-06 22:41:51,162 - INFO - validation batch 101, loss: 0.472, 3232/6976 datapoints
2025-03-06 22:41:51,211 - INFO - validation batch 151, loss: 0.527, 4832/6976 datapoints
2025-03-06 22:41:51,261 - INFO - validation batch 201, loss: 0.763, 6432/6976 datapoints
2025-03-06 22:41:51,278 - INFO - Epoch 316/800 done.
2025-03-06 22:41:51,278 - INFO - Final validation performance:
Loss: 0.719, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:51,278 - INFO - Beginning epoch 317/800
2025-03-06 22:41:51,283 - INFO - training batch 1, loss: 0.167, 32/28000 datapoints
2025-03-06 22:41:51,438 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 22:41:51,591 - INFO - training batch 101, loss: 0.109, 3232/28000 datapoints
2025-03-06 22:41:51,743 - INFO - training batch 151, loss: 0.087, 4832/28000 datapoints
2025-03-06 22:41:51,903 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 22:41:52,056 - INFO - training batch 251, loss: 0.388, 8032/28000 datapoints
2025-03-06 22:41:52,208 - INFO - training batch 301, loss: 0.495, 9632/28000 datapoints
2025-03-06 22:41:52,359 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 22:41:52,514 - INFO - training batch 401, loss: 0.179, 12832/28000 datapoints
2025-03-06 22:41:52,665 - INFO - training batch 451, loss: 0.261, 14432/28000 datapoints
2025-03-06 22:41:52,819 - INFO - training batch 501, loss: 0.107, 16032/28000 datapoints
2025-03-06 22:41:52,975 - INFO - training batch 551, loss: 0.174, 17632/28000 datapoints
2025-03-06 22:41:53,127 - INFO - training batch 601, loss: 0.133, 19232/28000 datapoints
2025-03-06 22:41:53,280 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:41:53,432 - INFO - training batch 701, loss: 0.173, 22432/28000 datapoints
2025-03-06 22:41:53,583 - INFO - training batch 751, loss: 0.097, 24032/28000 datapoints
2025-03-06 22:41:53,734 - INFO - training batch 801, loss: 0.042, 25632/28000 datapoints
2025-03-06 22:41:53,892 - INFO - training batch 851, loss: 0.167, 27232/28000 datapoints
2025-03-06 22:41:53,971 - INFO - validation batch 1, loss: 0.083, 32/6976 datapoints
2025-03-06 22:41:54,018 - INFO - validation batch 51, loss: 1.763, 1632/6976 datapoints
2025-03-06 22:41:54,065 - INFO - validation batch 101, loss: 0.473, 3232/6976 datapoints
2025-03-06 22:41:54,116 - INFO - validation batch 151, loss: 0.530, 4832/6976 datapoints
2025-03-06 22:41:54,164 - INFO - validation batch 201, loss: 0.767, 6432/6976 datapoints
2025-03-06 22:41:54,181 - INFO - Epoch 317/800 done.
2025-03-06 22:41:54,181 - INFO - Final validation performance:
Loss: 0.723, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:54,181 - INFO - Beginning epoch 318/800
2025-03-06 22:41:54,185 - INFO - training batch 1, loss: 0.165, 32/28000 datapoints
2025-03-06 22:41:54,344 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-06 22:41:54,504 - INFO - training batch 101, loss: 0.109, 3232/28000 datapoints
2025-03-06 22:41:54,656 - INFO - training batch 151, loss: 0.087, 4832/28000 datapoints
2025-03-06 22:41:54,807 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-06 22:41:54,961 - INFO - training batch 251, loss: 0.387, 8032/28000 datapoints
2025-03-06 22:41:55,111 - INFO - training batch 301, loss: 0.493, 9632/28000 datapoints
2025-03-06 22:41:55,270 - INFO - training batch 351, loss: 0.190, 11232/28000 datapoints
2025-03-06 22:41:55,438 - INFO - training batch 401, loss: 0.176, 12832/28000 datapoints
2025-03-06 22:41:55,587 - INFO - training batch 451, loss: 0.260, 14432/28000 datapoints
2025-03-06 22:41:55,742 - INFO - training batch 501, loss: 0.106, 16032/28000 datapoints
2025-03-06 22:41:55,901 - INFO - training batch 551, loss: 0.173, 17632/28000 datapoints
2025-03-06 22:41:56,063 - INFO - training batch 601, loss: 0.133, 19232/28000 datapoints
2025-03-06 22:41:56,216 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 22:41:56,371 - INFO - training batch 701, loss: 0.171, 22432/28000 datapoints
2025-03-06 22:41:56,525 - INFO - training batch 751, loss: 0.094, 24032/28000 datapoints
2025-03-06 22:41:56,702 - INFO - training batch 801, loss: 0.041, 25632/28000 datapoints
2025-03-06 22:41:56,855 - INFO - training batch 851, loss: 0.166, 27232/28000 datapoints
2025-03-06 22:41:56,930 - INFO - validation batch 1, loss: 0.083, 32/6976 datapoints
2025-03-06 22:41:56,981 - INFO - validation batch 51, loss: 1.771, 1632/6976 datapoints
2025-03-06 22:41:57,028 - INFO - validation batch 101, loss: 0.474, 3232/6976 datapoints
2025-03-06 22:41:57,076 - INFO - validation batch 151, loss: 0.533, 4832/6976 datapoints
2025-03-06 22:41:57,125 - INFO - validation batch 201, loss: 0.767, 6432/6976 datapoints
2025-03-06 22:41:57,141 - INFO - Epoch 318/800 done.
2025-03-06 22:41:57,141 - INFO - Final validation performance:
Loss: 0.726, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:41:57,142 - INFO - Beginning epoch 319/800
2025-03-06 22:41:57,146 - INFO - training batch 1, loss: 0.164, 32/28000 datapoints
2025-03-06 22:41:57,302 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-06 22:41:57,457 - INFO - training batch 101, loss: 0.108, 3232/28000 datapoints
2025-03-06 22:41:57,608 - INFO - training batch 151, loss: 0.085, 4832/28000 datapoints
2025-03-06 22:41:57,759 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-06 22:41:57,911 - INFO - training batch 251, loss: 0.385, 8032/28000 datapoints
2025-03-06 22:41:58,066 - INFO - training batch 301, loss: 0.491, 9632/28000 datapoints
2025-03-06 22:41:58,219 - INFO - training batch 351, loss: 0.190, 11232/28000 datapoints
2025-03-06 22:41:58,371 - INFO - training batch 401, loss: 0.175, 12832/28000 datapoints
2025-03-06 22:41:58,526 - INFO - training batch 451, loss: 0.260, 14432/28000 datapoints
2025-03-06 22:41:58,680 - INFO - training batch 501, loss: 0.106, 16032/28000 datapoints
2025-03-06 22:41:58,832 - INFO - training batch 551, loss: 0.172, 17632/28000 datapoints
2025-03-06 22:41:58,991 - INFO - training batch 601, loss: 0.131, 19232/28000 datapoints
2025-03-06 22:41:59,142 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:41:59,292 - INFO - training batch 701, loss: 0.169, 22432/28000 datapoints
2025-03-06 22:41:59,444 - INFO - training batch 751, loss: 0.095, 24032/28000 datapoints
2025-03-06 22:41:59,596 - INFO - training batch 801, loss: 0.041, 25632/28000 datapoints
2025-03-06 22:41:59,746 - INFO - training batch 851, loss: 0.165, 27232/28000 datapoints
2025-03-06 22:41:59,820 - INFO - validation batch 1, loss: 0.083, 32/6976 datapoints
2025-03-06 22:41:59,868 - INFO - validation batch 51, loss: 1.782, 1632/6976 datapoints
2025-03-06 22:41:59,916 - INFO - validation batch 101, loss: 0.477, 3232/6976 datapoints
2025-03-06 22:41:59,966 - INFO - validation batch 151, loss: 0.535, 4832/6976 datapoints
2025-03-06 22:42:00,016 - INFO - validation batch 201, loss: 0.772, 6432/6976 datapoints
2025-03-06 22:42:00,032 - INFO - Epoch 319/800 done.
2025-03-06 22:42:00,032 - INFO - Final validation performance:
Loss: 0.730, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:00,033 - INFO - Beginning epoch 320/800
2025-03-06 22:42:00,038 - INFO - training batch 1, loss: 0.162, 32/28000 datapoints
2025-03-06 22:42:00,191 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 22:42:00,342 - INFO - training batch 101, loss: 0.108, 3232/28000 datapoints
2025-03-06 22:42:00,500 - INFO - training batch 151, loss: 0.083, 4832/28000 datapoints
2025-03-06 22:42:00,652 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 22:42:00,811 - INFO - training batch 251, loss: 0.383, 8032/28000 datapoints
2025-03-06 22:42:00,967 - INFO - training batch 301, loss: 0.488, 9632/28000 datapoints
2025-03-06 22:42:01,118 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 22:42:01,270 - INFO - training batch 401, loss: 0.173, 12832/28000 datapoints
2025-03-06 22:42:01,435 - INFO - training batch 451, loss: 0.258, 14432/28000 datapoints
2025-03-06 22:42:01,597 - INFO - training batch 501, loss: 0.105, 16032/28000 datapoints
2025-03-06 22:42:01,753 - INFO - training batch 551, loss: 0.170, 17632/28000 datapoints
2025-03-06 22:42:01,923 - INFO - training batch 601, loss: 0.130, 19232/28000 datapoints
2025-03-06 22:42:02,088 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:42:02,248 - INFO - training batch 701, loss: 0.168, 22432/28000 datapoints
2025-03-06 22:42:02,409 - INFO - training batch 751, loss: 0.092, 24032/28000 datapoints
2025-03-06 22:42:02,569 - INFO - training batch 801, loss: 0.040, 25632/28000 datapoints
2025-03-06 22:42:02,731 - INFO - training batch 851, loss: 0.164, 27232/28000 datapoints
2025-03-06 22:42:02,813 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 22:42:02,866 - INFO - validation batch 51, loss: 1.790, 1632/6976 datapoints
2025-03-06 22:42:02,920 - INFO - validation batch 101, loss: 0.480, 3232/6976 datapoints
2025-03-06 22:42:02,974 - INFO - validation batch 151, loss: 0.539, 4832/6976 datapoints
2025-03-06 22:42:03,030 - INFO - validation batch 201, loss: 0.775, 6432/6976 datapoints
2025-03-06 22:42:03,050 - INFO - Epoch 320/800 done.
2025-03-06 22:42:03,050 - INFO - Final validation performance:
Loss: 0.733, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:03,051 - INFO - Beginning epoch 321/800
2025-03-06 22:42:03,055 - INFO - training batch 1, loss: 0.160, 32/28000 datapoints
2025-03-06 22:42:03,221 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 22:42:03,377 - INFO - training batch 101, loss: 0.106, 3232/28000 datapoints
2025-03-06 22:42:03,533 - INFO - training batch 151, loss: 0.082, 4832/28000 datapoints
2025-03-06 22:42:03,688 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 22:42:03,846 - INFO - training batch 251, loss: 0.380, 8032/28000 datapoints
2025-03-06 22:42:04,006 - INFO - training batch 301, loss: 0.485, 9632/28000 datapoints
2025-03-06 22:42:04,161 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 22:42:04,318 - INFO - training batch 401, loss: 0.172, 12832/28000 datapoints
2025-03-06 22:42:04,478 - INFO - training batch 451, loss: 0.257, 14432/28000 datapoints
2025-03-06 22:42:04,634 - INFO - training batch 501, loss: 0.105, 16032/28000 datapoints
2025-03-06 22:42:04,790 - INFO - training batch 551, loss: 0.168, 17632/28000 datapoints
2025-03-06 22:42:04,959 - INFO - training batch 601, loss: 0.130, 19232/28000 datapoints
2025-03-06 22:42:05,116 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:42:05,279 - INFO - training batch 701, loss: 0.167, 22432/28000 datapoints
2025-03-06 22:42:05,436 - INFO - training batch 751, loss: 0.093, 24032/28000 datapoints
2025-03-06 22:42:05,591 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-06 22:42:05,749 - INFO - training batch 851, loss: 0.163, 27232/28000 datapoints
2025-03-06 22:42:05,828 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 22:42:05,881 - INFO - validation batch 51, loss: 1.801, 1632/6976 datapoints
2025-03-06 22:42:05,934 - INFO - validation batch 101, loss: 0.480, 3232/6976 datapoints
2025-03-06 22:42:05,990 - INFO - validation batch 151, loss: 0.541, 4832/6976 datapoints
2025-03-06 22:42:06,044 - INFO - validation batch 201, loss: 0.778, 6432/6976 datapoints
2025-03-06 22:42:06,062 - INFO - Epoch 321/800 done.
2025-03-06 22:42:06,063 - INFO - Final validation performance:
Loss: 0.737, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:42:06,063 - INFO - Beginning epoch 322/800
2025-03-06 22:42:06,068 - INFO - training batch 1, loss: 0.158, 32/28000 datapoints
2025-03-06 22:42:06,236 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 22:42:06,393 - INFO - training batch 101, loss: 0.106, 3232/28000 datapoints
2025-03-06 22:42:06,554 - INFO - training batch 151, loss: 0.082, 4832/28000 datapoints
2025-03-06 22:42:06,737 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 22:42:06,898 - INFO - training batch 251, loss: 0.381, 8032/28000 datapoints
2025-03-06 22:42:07,058 - INFO - training batch 301, loss: 0.483, 9632/28000 datapoints
2025-03-06 22:42:07,213 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 22:42:07,369 - INFO - training batch 401, loss: 0.170, 12832/28000 datapoints
2025-03-06 22:42:07,532 - INFO - training batch 451, loss: 0.256, 14432/28000 datapoints
2025-03-06 22:42:07,693 - INFO - training batch 501, loss: 0.105, 16032/28000 datapoints
2025-03-06 22:42:07,849 - INFO - training batch 551, loss: 0.167, 17632/28000 datapoints
2025-03-06 22:42:08,010 - INFO - training batch 601, loss: 0.128, 19232/28000 datapoints
2025-03-06 22:42:08,177 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 22:42:08,335 - INFO - training batch 701, loss: 0.165, 22432/28000 datapoints
2025-03-06 22:42:08,495 - INFO - training batch 751, loss: 0.090, 24032/28000 datapoints
2025-03-06 22:42:08,651 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-06 22:42:08,806 - INFO - training batch 851, loss: 0.162, 27232/28000 datapoints
2025-03-06 22:42:08,885 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 22:42:08,934 - INFO - validation batch 51, loss: 1.807, 1632/6976 datapoints
2025-03-06 22:42:08,984 - INFO - validation batch 101, loss: 0.483, 3232/6976 datapoints
2025-03-06 22:42:09,032 - INFO - validation batch 151, loss: 0.545, 4832/6976 datapoints
2025-03-06 22:42:09,080 - INFO - validation batch 201, loss: 0.779, 6432/6976 datapoints
2025-03-06 22:42:09,097 - INFO - Epoch 322/800 done.
2025-03-06 22:42:09,097 - INFO - Final validation performance:
Loss: 0.740, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:42:09,098 - INFO - Beginning epoch 323/800
2025-03-06 22:42:09,102 - INFO - training batch 1, loss: 0.157, 32/28000 datapoints
2025-03-06 22:42:09,257 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 22:42:09,414 - INFO - training batch 101, loss: 0.105, 3232/28000 datapoints
2025-03-06 22:42:09,570 - INFO - training batch 151, loss: 0.079, 4832/28000 datapoints
2025-03-06 22:42:09,728 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 22:42:09,882 - INFO - training batch 251, loss: 0.379, 8032/28000 datapoints
2025-03-06 22:42:10,049 - INFO - training batch 301, loss: 0.480, 9632/28000 datapoints
2025-03-06 22:42:10,232 - INFO - training batch 351, loss: 0.188, 11232/28000 datapoints
2025-03-06 22:42:10,412 - INFO - training batch 401, loss: 0.168, 12832/28000 datapoints
2025-03-06 22:42:10,566 - INFO - training batch 451, loss: 0.255, 14432/28000 datapoints
2025-03-06 22:42:10,719 - INFO - training batch 501, loss: 0.104, 16032/28000 datapoints
2025-03-06 22:42:10,874 - INFO - training batch 551, loss: 0.166, 17632/28000 datapoints
2025-03-06 22:42:11,031 - INFO - training batch 601, loss: 0.124, 19232/28000 datapoints
2025-03-06 22:42:11,183 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:42:11,334 - INFO - training batch 701, loss: 0.164, 22432/28000 datapoints
2025-03-06 22:42:11,485 - INFO - training batch 751, loss: 0.092, 24032/28000 datapoints
2025-03-06 22:42:11,637 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-06 22:42:11,788 - INFO - training batch 851, loss: 0.161, 27232/28000 datapoints
2025-03-06 22:42:11,865 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 22:42:11,914 - INFO - validation batch 51, loss: 1.818, 1632/6976 datapoints
2025-03-06 22:42:11,967 - INFO - validation batch 101, loss: 0.485, 3232/6976 datapoints
2025-03-06 22:42:12,013 - INFO - validation batch 151, loss: 0.546, 4832/6976 datapoints
2025-03-06 22:42:12,061 - INFO - validation batch 201, loss: 0.782, 6432/6976 datapoints
2025-03-06 22:42:12,077 - INFO - Epoch 323/800 done.
2025-03-06 22:42:12,077 - INFO - Final validation performance:
Loss: 0.743, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:42:12,078 - INFO - Beginning epoch 324/800
2025-03-06 22:42:12,082 - INFO - training batch 1, loss: 0.154, 32/28000 datapoints
2025-03-06 22:42:12,239 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 22:42:12,393 - INFO - training batch 101, loss: 0.105, 3232/28000 datapoints
2025-03-06 22:42:12,548 - INFO - training batch 151, loss: 0.079, 4832/28000 datapoints
2025-03-06 22:42:12,699 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-06 22:42:12,850 - INFO - training batch 251, loss: 0.375, 8032/28000 datapoints
2025-03-06 22:42:13,005 - INFO - training batch 301, loss: 0.478, 9632/28000 datapoints
2025-03-06 22:42:13,157 - INFO - training batch 351, loss: 0.187, 11232/28000 datapoints
2025-03-06 22:42:13,308 - INFO - training batch 401, loss: 0.167, 12832/28000 datapoints
2025-03-06 22:42:13,460 - INFO - training batch 451, loss: 0.254, 14432/28000 datapoints
2025-03-06 22:42:13,625 - INFO - training batch 501, loss: 0.104, 16032/28000 datapoints
2025-03-06 22:42:13,785 - INFO - training batch 551, loss: 0.163, 17632/28000 datapoints
2025-03-06 22:42:13,942 - INFO - training batch 601, loss: 0.125, 19232/28000 datapoints
2025-03-06 22:42:14,107 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:42:14,262 - INFO - training batch 701, loss: 0.163, 22432/28000 datapoints
2025-03-06 22:42:14,416 - INFO - training batch 751, loss: 0.088, 24032/28000 datapoints
2025-03-06 22:42:14,571 - INFO - training batch 801, loss: 0.038, 25632/28000 datapoints
2025-03-06 22:42:14,723 - INFO - training batch 851, loss: 0.158, 27232/28000 datapoints
2025-03-06 22:42:14,799 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 22:42:14,847 - INFO - validation batch 51, loss: 1.827, 1632/6976 datapoints
2025-03-06 22:42:14,895 - INFO - validation batch 101, loss: 0.487, 3232/6976 datapoints
2025-03-06 22:42:14,943 - INFO - validation batch 151, loss: 0.548, 4832/6976 datapoints
2025-03-06 22:42:14,993 - INFO - validation batch 201, loss: 0.786, 6432/6976 datapoints
2025-03-06 22:42:15,009 - INFO - Epoch 324/800 done.
2025-03-06 22:42:15,009 - INFO - Final validation performance:
Loss: 0.747, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:42:15,010 - INFO - Beginning epoch 325/800
2025-03-06 22:42:15,014 - INFO - training batch 1, loss: 0.152, 32/28000 datapoints
2025-03-06 22:42:15,172 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 22:42:15,329 - INFO - training batch 101, loss: 0.104, 3232/28000 datapoints
2025-03-06 22:42:15,482 - INFO - training batch 151, loss: 0.078, 4832/28000 datapoints
2025-03-06 22:42:15,632 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-06 22:42:15,789 - INFO - training batch 251, loss: 0.376, 8032/28000 datapoints
2025-03-06 22:42:15,943 - INFO - training batch 301, loss: 0.476, 9632/28000 datapoints
2025-03-06 22:42:16,096 - INFO - training batch 351, loss: 0.187, 11232/28000 datapoints
2025-03-06 22:42:16,247 - INFO - training batch 401, loss: 0.166, 12832/28000 datapoints
2025-03-06 22:42:16,400 - INFO - training batch 451, loss: 0.253, 14432/28000 datapoints
2025-03-06 22:42:16,556 - INFO - training batch 501, loss: 0.103, 16032/28000 datapoints
2025-03-06 22:42:16,709 - INFO - training batch 551, loss: 0.163, 17632/28000 datapoints
2025-03-06 22:42:16,887 - INFO - training batch 601, loss: 0.124, 19232/28000 datapoints
2025-03-06 22:42:17,041 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:42:17,194 - INFO - training batch 701, loss: 0.161, 22432/28000 datapoints
2025-03-06 22:42:17,344 - INFO - training batch 751, loss: 0.089, 24032/28000 datapoints
2025-03-06 22:42:17,496 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-06 22:42:17,646 - INFO - training batch 851, loss: 0.159, 27232/28000 datapoints
2025-03-06 22:42:17,721 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 22:42:17,768 - INFO - validation batch 51, loss: 1.834, 1632/6976 datapoints
2025-03-06 22:42:17,815 - INFO - validation batch 101, loss: 0.490, 3232/6976 datapoints
2025-03-06 22:42:17,865 - INFO - validation batch 151, loss: 0.553, 4832/6976 datapoints
2025-03-06 22:42:17,917 - INFO - validation batch 201, loss: 0.790, 6432/6976 datapoints
2025-03-06 22:42:17,934 - INFO - Epoch 325/800 done.
2025-03-06 22:42:17,934 - INFO - Final validation performance:
Loss: 0.750, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:17,934 - INFO - Beginning epoch 326/800
2025-03-06 22:42:17,939 - INFO - training batch 1, loss: 0.152, 32/28000 datapoints
2025-03-06 22:42:18,094 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 22:42:18,249 - INFO - training batch 101, loss: 0.103, 3232/28000 datapoints
2025-03-06 22:42:18,400 - INFO - training batch 151, loss: 0.076, 4832/28000 datapoints
2025-03-06 22:42:18,554 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 22:42:18,707 - INFO - training batch 251, loss: 0.374, 8032/28000 datapoints
2025-03-06 22:42:18,861 - INFO - training batch 301, loss: 0.474, 9632/28000 datapoints
2025-03-06 22:42:19,014 - INFO - training batch 351, loss: 0.187, 11232/28000 datapoints
2025-03-06 22:42:19,166 - INFO - training batch 401, loss: 0.164, 12832/28000 datapoints
2025-03-06 22:42:19,318 - INFO - training batch 451, loss: 0.252, 14432/28000 datapoints
2025-03-06 22:42:19,470 - INFO - training batch 501, loss: 0.103, 16032/28000 datapoints
2025-03-06 22:42:19,625 - INFO - training batch 551, loss: 0.161, 17632/28000 datapoints
2025-03-06 22:42:19,791 - INFO - training batch 601, loss: 0.123, 19232/28000 datapoints
2025-03-06 22:42:19,944 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 22:42:20,099 - INFO - training batch 701, loss: 0.160, 22432/28000 datapoints
2025-03-06 22:42:20,261 - INFO - training batch 751, loss: 0.087, 24032/28000 datapoints
2025-03-06 22:42:20,416 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-06 22:42:20,576 - INFO - training batch 851, loss: 0.156, 27232/28000 datapoints
2025-03-06 22:42:20,650 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 22:42:20,699 - INFO - validation batch 51, loss: 1.845, 1632/6976 datapoints
2025-03-06 22:42:20,748 - INFO - validation batch 101, loss: 0.490, 3232/6976 datapoints
2025-03-06 22:42:20,795 - INFO - validation batch 151, loss: 0.555, 4832/6976 datapoints
2025-03-06 22:42:20,842 - INFO - validation batch 201, loss: 0.792, 6432/6976 datapoints
2025-03-06 22:42:20,859 - INFO - Epoch 326/800 done.
2025-03-06 22:42:20,859 - INFO - Final validation performance:
Loss: 0.754, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:20,860 - INFO - Beginning epoch 327/800
2025-03-06 22:42:20,864 - INFO - training batch 1, loss: 0.150, 32/28000 datapoints
2025-03-06 22:42:21,021 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 22:42:21,175 - INFO - training batch 101, loss: 0.102, 3232/28000 datapoints
2025-03-06 22:42:21,329 - INFO - training batch 151, loss: 0.077, 4832/28000 datapoints
2025-03-06 22:42:21,481 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 22:42:21,632 - INFO - training batch 251, loss: 0.373, 8032/28000 datapoints
2025-03-06 22:42:21,862 - INFO - training batch 301, loss: 0.470, 9632/28000 datapoints
2025-03-06 22:42:22,024 - INFO - training batch 351, loss: 0.186, 11232/28000 datapoints
2025-03-06 22:42:22,187 - INFO - training batch 401, loss: 0.163, 12832/28000 datapoints
2025-03-06 22:42:22,346 - INFO - training batch 451, loss: 0.250, 14432/28000 datapoints
2025-03-06 22:42:22,502 - INFO - training batch 501, loss: 0.102, 16032/28000 datapoints
2025-03-06 22:42:22,661 - INFO - training batch 551, loss: 0.161, 17632/28000 datapoints
2025-03-06 22:42:22,817 - INFO - training batch 601, loss: 0.121, 19232/28000 datapoints
2025-03-06 22:42:22,978 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 22:42:23,134 - INFO - training batch 701, loss: 0.159, 22432/28000 datapoints
2025-03-06 22:42:23,288 - INFO - training batch 751, loss: 0.087, 24032/28000 datapoints
2025-03-06 22:42:23,443 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-06 22:42:23,600 - INFO - training batch 851, loss: 0.156, 27232/28000 datapoints
2025-03-06 22:42:23,678 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 22:42:23,730 - INFO - validation batch 51, loss: 1.856, 1632/6976 datapoints
2025-03-06 22:42:23,785 - INFO - validation batch 101, loss: 0.491, 3232/6976 datapoints
2025-03-06 22:42:23,834 - INFO - validation batch 151, loss: 0.556, 4832/6976 datapoints
2025-03-06 22:42:23,885 - INFO - validation batch 201, loss: 0.798, 6432/6976 datapoints
2025-03-06 22:42:23,902 - INFO - Epoch 327/800 done.
2025-03-06 22:42:23,902 - INFO - Final validation performance:
Loss: 0.757, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:23,903 - INFO - Beginning epoch 328/800
2025-03-06 22:42:23,907 - INFO - training batch 1, loss: 0.148, 32/28000 datapoints
2025-03-06 22:42:24,063 - INFO - training batch 51, loss: 0.047, 1632/28000 datapoints
2025-03-06 22:42:24,214 - INFO - training batch 101, loss: 0.102, 3232/28000 datapoints
2025-03-06 22:42:24,367 - INFO - training batch 151, loss: 0.073, 4832/28000 datapoints
2025-03-06 22:42:24,518 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 22:42:24,674 - INFO - training batch 251, loss: 0.370, 8032/28000 datapoints
2025-03-06 22:42:24,825 - INFO - training batch 301, loss: 0.468, 9632/28000 datapoints
2025-03-06 22:42:24,981 - INFO - training batch 351, loss: 0.186, 11232/28000 datapoints
2025-03-06 22:42:25,133 - INFO - training batch 401, loss: 0.162, 12832/28000 datapoints
2025-03-06 22:42:25,289 - INFO - training batch 451, loss: 0.249, 14432/28000 datapoints
2025-03-06 22:42:25,444 - INFO - training batch 501, loss: 0.102, 16032/28000 datapoints
2025-03-06 22:42:25,598 - INFO - training batch 551, loss: 0.158, 17632/28000 datapoints
2025-03-06 22:42:25,752 - INFO - training batch 601, loss: 0.120, 19232/28000 datapoints
2025-03-06 22:42:25,922 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 22:42:26,077 - INFO - training batch 701, loss: 0.158, 22432/28000 datapoints
2025-03-06 22:42:26,229 - INFO - training batch 751, loss: 0.084, 24032/28000 datapoints
2025-03-06 22:42:26,390 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-06 22:42:26,544 - INFO - training batch 851, loss: 0.154, 27232/28000 datapoints
2025-03-06 22:42:26,622 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 22:42:26,673 - INFO - validation batch 51, loss: 1.866, 1632/6976 datapoints
2025-03-06 22:42:26,721 - INFO - validation batch 101, loss: 0.492, 3232/6976 datapoints
2025-03-06 22:42:26,769 - INFO - validation batch 151, loss: 0.560, 4832/6976 datapoints
2025-03-06 22:42:26,816 - INFO - validation batch 201, loss: 0.799, 6432/6976 datapoints
2025-03-06 22:42:26,842 - INFO - Epoch 328/800 done.
2025-03-06 22:42:26,842 - INFO - Final validation performance:
Loss: 0.761, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:26,843 - INFO - Beginning epoch 329/800
2025-03-06 22:42:26,848 - INFO - training batch 1, loss: 0.146, 32/28000 datapoints
2025-03-06 22:42:27,024 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 22:42:27,177 - INFO - training batch 101, loss: 0.102, 3232/28000 datapoints
2025-03-06 22:42:27,328 - INFO - training batch 151, loss: 0.071, 4832/28000 datapoints
2025-03-06 22:42:27,483 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 22:42:27,634 - INFO - training batch 251, loss: 0.367, 8032/28000 datapoints
2025-03-06 22:42:27,786 - INFO - training batch 301, loss: 0.465, 9632/28000 datapoints
2025-03-06 22:42:27,938 - INFO - training batch 351, loss: 0.184, 11232/28000 datapoints
2025-03-06 22:42:28,094 - INFO - training batch 401, loss: 0.161, 12832/28000 datapoints
2025-03-06 22:42:28,247 - INFO - training batch 451, loss: 0.248, 14432/28000 datapoints
2025-03-06 22:42:28,402 - INFO - training batch 501, loss: 0.101, 16032/28000 datapoints
2025-03-06 22:42:28,555 - INFO - training batch 551, loss: 0.158, 17632/28000 datapoints
2025-03-06 22:42:28,708 - INFO - training batch 601, loss: 0.117, 19232/28000 datapoints
2025-03-06 22:42:28,860 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 22:42:29,015 - INFO - training batch 701, loss: 0.156, 22432/28000 datapoints
2025-03-06 22:42:29,166 - INFO - training batch 751, loss: 0.086, 24032/28000 datapoints
2025-03-06 22:42:29,316 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-06 22:42:29,469 - INFO - training batch 851, loss: 0.153, 27232/28000 datapoints
2025-03-06 22:42:29,543 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 22:42:29,591 - INFO - validation batch 51, loss: 1.875, 1632/6976 datapoints
2025-03-06 22:42:29,638 - INFO - validation batch 101, loss: 0.494, 3232/6976 datapoints
2025-03-06 22:42:29,711 - INFO - validation batch 151, loss: 0.562, 4832/6976 datapoints
2025-03-06 22:42:29,759 - INFO - validation batch 201, loss: 0.805, 6432/6976 datapoints
2025-03-06 22:42:29,775 - INFO - Epoch 329/800 done.
2025-03-06 22:42:29,775 - INFO - Final validation performance:
Loss: 0.764, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:29,776 - INFO - Beginning epoch 330/800
2025-03-06 22:42:29,780 - INFO - training batch 1, loss: 0.145, 32/28000 datapoints
2025-03-06 22:42:29,935 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 22:42:30,091 - INFO - training batch 101, loss: 0.100, 3232/28000 datapoints
2025-03-06 22:42:30,243 - INFO - training batch 151, loss: 0.072, 4832/28000 datapoints
2025-03-06 22:42:30,396 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 22:42:30,547 - INFO - training batch 251, loss: 0.367, 8032/28000 datapoints
2025-03-06 22:42:30,704 - INFO - training batch 301, loss: 0.464, 9632/28000 datapoints
2025-03-06 22:42:30,855 - INFO - training batch 351, loss: 0.184, 11232/28000 datapoints
2025-03-06 22:42:31,011 - INFO - training batch 401, loss: 0.159, 12832/28000 datapoints
2025-03-06 22:42:31,163 - INFO - training batch 451, loss: 0.246, 14432/28000 datapoints
2025-03-06 22:42:31,315 - INFO - training batch 501, loss: 0.101, 16032/28000 datapoints
2025-03-06 22:42:31,469 - INFO - training batch 551, loss: 0.155, 17632/28000 datapoints
2025-03-06 22:42:31,623 - INFO - training batch 601, loss: 0.116, 19232/28000 datapoints
2025-03-06 22:42:31,774 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 22:42:31,929 - INFO - training batch 701, loss: 0.155, 22432/28000 datapoints
2025-03-06 22:42:32,101 - INFO - training batch 751, loss: 0.083, 24032/28000 datapoints
2025-03-06 22:42:32,253 - INFO - training batch 801, loss: 0.035, 25632/28000 datapoints
2025-03-06 22:42:32,405 - INFO - training batch 851, loss: 0.152, 27232/28000 datapoints
2025-03-06 22:42:32,481 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 22:42:32,529 - INFO - validation batch 51, loss: 1.883, 1632/6976 datapoints
2025-03-06 22:42:32,584 - INFO - validation batch 101, loss: 0.497, 3232/6976 datapoints
2025-03-06 22:42:32,647 - INFO - validation batch 151, loss: 0.567, 4832/6976 datapoints
2025-03-06 22:42:32,695 - INFO - validation batch 201, loss: 0.808, 6432/6976 datapoints
2025-03-06 22:42:32,711 - INFO - Epoch 330/800 done.
2025-03-06 22:42:32,711 - INFO - Final validation performance:
Loss: 0.769, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:32,712 - INFO - Beginning epoch 331/800
2025-03-06 22:42:32,716 - INFO - training batch 1, loss: 0.143, 32/28000 datapoints
2025-03-06 22:42:32,874 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 22:42:33,035 - INFO - training batch 101, loss: 0.100, 3232/28000 datapoints
2025-03-06 22:42:33,191 - INFO - training batch 151, loss: 0.068, 4832/28000 datapoints
2025-03-06 22:42:33,346 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 22:42:33,500 - INFO - training batch 251, loss: 0.364, 8032/28000 datapoints
2025-03-06 22:42:33,661 - INFO - training batch 301, loss: 0.462, 9632/28000 datapoints
2025-03-06 22:42:33,847 - INFO - training batch 351, loss: 0.183, 11232/28000 datapoints
2025-03-06 22:42:34,002 - INFO - training batch 401, loss: 0.158, 12832/28000 datapoints
2025-03-06 22:42:34,154 - INFO - training batch 451, loss: 0.245, 14432/28000 datapoints
2025-03-06 22:42:34,307 - INFO - training batch 501, loss: 0.100, 16032/28000 datapoints
2025-03-06 22:42:34,462 - INFO - training batch 551, loss: 0.154, 17632/28000 datapoints
2025-03-06 22:42:34,617 - INFO - training batch 601, loss: 0.115, 19232/28000 datapoints
2025-03-06 22:42:34,772 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 22:42:34,931 - INFO - training batch 701, loss: 0.154, 22432/28000 datapoints
2025-03-06 22:42:35,087 - INFO - training batch 751, loss: 0.083, 24032/28000 datapoints
2025-03-06 22:42:35,244 - INFO - training batch 801, loss: 0.034, 25632/28000 datapoints
2025-03-06 22:42:35,397 - INFO - training batch 851, loss: 0.151, 27232/28000 datapoints
2025-03-06 22:42:35,472 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 22:42:35,521 - INFO - validation batch 51, loss: 1.894, 1632/6976 datapoints
2025-03-06 22:42:35,568 - INFO - validation batch 101, loss: 0.497, 3232/6976 datapoints
2025-03-06 22:42:35,616 - INFO - validation batch 151, loss: 0.571, 4832/6976 datapoints
2025-03-06 22:42:35,667 - INFO - validation batch 201, loss: 0.813, 6432/6976 datapoints
2025-03-06 22:42:35,684 - INFO - Epoch 331/800 done.
2025-03-06 22:42:35,684 - INFO - Final validation performance:
Loss: 0.772, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:35,685 - INFO - Beginning epoch 332/800
2025-03-06 22:42:35,689 - INFO - training batch 1, loss: 0.142, 32/28000 datapoints
2025-03-06 22:42:35,843 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 22:42:36,005 - INFO - training batch 101, loss: 0.099, 3232/28000 datapoints
2025-03-06 22:42:36,156 - INFO - training batch 151, loss: 0.069, 4832/28000 datapoints
2025-03-06 22:42:36,307 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 22:42:36,460 - INFO - training batch 251, loss: 0.363, 8032/28000 datapoints
2025-03-06 22:42:36,618 - INFO - training batch 301, loss: 0.459, 9632/28000 datapoints
2025-03-06 22:42:36,771 - INFO - training batch 351, loss: 0.184, 11232/28000 datapoints
2025-03-06 22:42:36,928 - INFO - training batch 401, loss: 0.157, 12832/28000 datapoints
2025-03-06 22:42:37,120 - INFO - training batch 451, loss: 0.244, 14432/28000 datapoints
2025-03-06 22:42:37,273 - INFO - training batch 501, loss: 0.100, 16032/28000 datapoints
2025-03-06 22:42:37,427 - INFO - training batch 551, loss: 0.152, 17632/28000 datapoints
2025-03-06 22:42:37,581 - INFO - training batch 601, loss: 0.115, 19232/28000 datapoints
2025-03-06 22:42:37,733 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 22:42:37,885 - INFO - training batch 701, loss: 0.151, 22432/28000 datapoints
2025-03-06 22:42:38,055 - INFO - training batch 751, loss: 0.082, 24032/28000 datapoints
2025-03-06 22:42:38,212 - INFO - training batch 801, loss: 0.034, 25632/28000 datapoints
2025-03-06 22:42:38,400 - INFO - training batch 851, loss: 0.150, 27232/28000 datapoints
2025-03-06 22:42:38,475 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 22:42:38,525 - INFO - validation batch 51, loss: 1.902, 1632/6976 datapoints
2025-03-06 22:42:38,573 - INFO - validation batch 101, loss: 0.499, 3232/6976 datapoints
2025-03-06 22:42:38,622 - INFO - validation batch 151, loss: 0.571, 4832/6976 datapoints
2025-03-06 22:42:38,728 - INFO - validation batch 201, loss: 0.815, 6432/6976 datapoints
2025-03-06 22:42:38,772 - INFO - Epoch 332/800 done.
2025-03-06 22:42:38,773 - INFO - Final validation performance:
Loss: 0.775, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:38,774 - INFO - Beginning epoch 333/800
2025-03-06 22:42:38,782 - INFO - training batch 1, loss: 0.140, 32/28000 datapoints
2025-03-06 22:42:38,959 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 22:42:39,117 - INFO - training batch 101, loss: 0.098, 3232/28000 datapoints
2025-03-06 22:42:39,271 - INFO - training batch 151, loss: 0.069, 4832/28000 datapoints
2025-03-06 22:42:39,426 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 22:42:39,578 - INFO - training batch 251, loss: 0.362, 8032/28000 datapoints
2025-03-06 22:42:39,730 - INFO - training batch 301, loss: 0.456, 9632/28000 datapoints
2025-03-06 22:42:39,883 - INFO - training batch 351, loss: 0.183, 11232/28000 datapoints
2025-03-06 22:42:40,038 - INFO - training batch 401, loss: 0.155, 12832/28000 datapoints
2025-03-06 22:42:40,190 - INFO - training batch 451, loss: 0.243, 14432/28000 datapoints
2025-03-06 22:42:40,343 - INFO - training batch 501, loss: 0.100, 16032/28000 datapoints
2025-03-06 22:42:40,497 - INFO - training batch 551, loss: 0.151, 17632/28000 datapoints
2025-03-06 22:42:40,652 - INFO - training batch 601, loss: 0.113, 19232/28000 datapoints
2025-03-06 22:42:40,805 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 22:42:40,961 - INFO - training batch 701, loss: 0.150, 22432/28000 datapoints
2025-03-06 22:42:41,115 - INFO - training batch 751, loss: 0.080, 24032/28000 datapoints
2025-03-06 22:42:41,266 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-06 22:42:41,418 - INFO - training batch 851, loss: 0.149, 27232/28000 datapoints
2025-03-06 22:42:41,492 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 22:42:41,540 - INFO - validation batch 51, loss: 1.913, 1632/6976 datapoints
2025-03-06 22:42:41,589 - INFO - validation batch 101, loss: 0.500, 3232/6976 datapoints
2025-03-06 22:42:41,636 - INFO - validation batch 151, loss: 0.578, 4832/6976 datapoints
2025-03-06 22:42:41,683 - INFO - validation batch 201, loss: 0.819, 6432/6976 datapoints
2025-03-06 22:42:41,700 - INFO - Epoch 333/800 done.
2025-03-06 22:42:41,700 - INFO - Final validation performance:
Loss: 0.779, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:41,701 - INFO - Beginning epoch 334/800
2025-03-06 22:42:41,705 - INFO - training batch 1, loss: 0.139, 32/28000 datapoints
2025-03-06 22:42:41,871 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 22:42:42,033 - INFO - training batch 101, loss: 0.098, 3232/28000 datapoints
2025-03-06 22:42:42,191 - INFO - training batch 151, loss: 0.067, 4832/28000 datapoints
2025-03-06 22:42:42,348 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 22:42:42,506 - INFO - training batch 251, loss: 0.360, 8032/28000 datapoints
2025-03-06 22:42:42,664 - INFO - training batch 301, loss: 0.453, 9632/28000 datapoints
2025-03-06 22:42:42,819 - INFO - training batch 351, loss: 0.182, 11232/28000 datapoints
2025-03-06 22:42:42,976 - INFO - training batch 401, loss: 0.154, 12832/28000 datapoints
2025-03-06 22:42:43,131 - INFO - training batch 451, loss: 0.241, 14432/28000 datapoints
2025-03-06 22:42:43,287 - INFO - training batch 501, loss: 0.099, 16032/28000 datapoints
2025-03-06 22:42:43,444 - INFO - training batch 551, loss: 0.149, 17632/28000 datapoints
2025-03-06 22:42:43,600 - INFO - training batch 601, loss: 0.110, 19232/28000 datapoints
2025-03-06 22:42:43,754 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 22:42:43,909 - INFO - training batch 701, loss: 0.149, 22432/28000 datapoints
2025-03-06 22:42:44,067 - INFO - training batch 751, loss: 0.079, 24032/28000 datapoints
2025-03-06 22:42:44,224 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-06 22:42:44,384 - INFO - training batch 851, loss: 0.148, 27232/28000 datapoints
2025-03-06 22:42:44,477 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 22:42:44,530 - INFO - validation batch 51, loss: 1.925, 1632/6976 datapoints
2025-03-06 22:42:44,583 - INFO - validation batch 101, loss: 0.502, 3232/6976 datapoints
2025-03-06 22:42:44,641 - INFO - validation batch 151, loss: 0.580, 4832/6976 datapoints
2025-03-06 22:42:44,694 - INFO - validation batch 201, loss: 0.821, 6432/6976 datapoints
2025-03-06 22:42:44,713 - INFO - Epoch 334/800 done.
2025-03-06 22:42:44,713 - INFO - Final validation performance:
Loss: 0.783, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:44,714 - INFO - Beginning epoch 335/800
2025-03-06 22:42:44,719 - INFO - training batch 1, loss: 0.138, 32/28000 datapoints
2025-03-06 22:42:44,880 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 22:42:45,043 - INFO - training batch 101, loss: 0.097, 3232/28000 datapoints
2025-03-06 22:42:45,204 - INFO - training batch 151, loss: 0.065, 4832/28000 datapoints
2025-03-06 22:42:45,369 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 22:42:45,526 - INFO - training batch 251, loss: 0.358, 8032/28000 datapoints
2025-03-06 22:42:45,686 - INFO - training batch 301, loss: 0.451, 9632/28000 datapoints
2025-03-06 22:42:45,840 - INFO - training batch 351, loss: 0.183, 11232/28000 datapoints
2025-03-06 22:42:45,999 - INFO - training batch 401, loss: 0.152, 12832/28000 datapoints
2025-03-06 22:42:46,154 - INFO - training batch 451, loss: 0.241, 14432/28000 datapoints
2025-03-06 22:42:46,312 - INFO - training batch 501, loss: 0.099, 16032/28000 datapoints
2025-03-06 22:42:46,471 - INFO - training batch 551, loss: 0.147, 17632/28000 datapoints
2025-03-06 22:42:46,632 - INFO - training batch 601, loss: 0.110, 19232/28000 datapoints
2025-03-06 22:42:46,793 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 22:42:46,948 - INFO - training batch 701, loss: 0.147, 22432/28000 datapoints
2025-03-06 22:42:47,143 - INFO - training batch 751, loss: 0.078, 24032/28000 datapoints
2025-03-06 22:42:47,309 - INFO - training batch 801, loss: 0.032, 25632/28000 datapoints
2025-03-06 22:42:47,467 - INFO - training batch 851, loss: 0.147, 27232/28000 datapoints
2025-03-06 22:42:47,546 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 22:42:47,602 - INFO - validation batch 51, loss: 1.935, 1632/6976 datapoints
2025-03-06 22:42:47,660 - INFO - validation batch 101, loss: 0.503, 3232/6976 datapoints
2025-03-06 22:42:47,718 - INFO - validation batch 151, loss: 0.583, 4832/6976 datapoints
2025-03-06 22:42:47,769 - INFO - validation batch 201, loss: 0.825, 6432/6976 datapoints
2025-03-06 22:42:47,786 - INFO - Epoch 335/800 done.
2025-03-06 22:42:47,786 - INFO - Final validation performance:
Loss: 0.787, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:47,787 - INFO - Beginning epoch 336/800
2025-03-06 22:42:47,793 - INFO - training batch 1, loss: 0.136, 32/28000 datapoints
2025-03-06 22:42:47,949 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 22:42:48,104 - INFO - training batch 101, loss: 0.097, 3232/28000 datapoints
2025-03-06 22:42:48,258 - INFO - training batch 151, loss: 0.063, 4832/28000 datapoints
2025-03-06 22:42:48,416 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 22:42:48,569 - INFO - training batch 251, loss: 0.356, 8032/28000 datapoints
2025-03-06 22:42:48,724 - INFO - training batch 301, loss: 0.450, 9632/28000 datapoints
2025-03-06 22:42:48,874 - INFO - training batch 351, loss: 0.181, 11232/28000 datapoints
2025-03-06 22:42:49,027 - INFO - training batch 401, loss: 0.152, 12832/28000 datapoints
2025-03-06 22:42:49,181 - INFO - training batch 451, loss: 0.239, 14432/28000 datapoints
2025-03-06 22:42:49,333 - INFO - training batch 501, loss: 0.098, 16032/28000 datapoints
2025-03-06 22:42:49,492 - INFO - training batch 551, loss: 0.146, 17632/28000 datapoints
2025-03-06 22:42:49,645 - INFO - training batch 601, loss: 0.108, 19232/28000 datapoints
2025-03-06 22:42:49,796 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 22:42:49,946 - INFO - training batch 701, loss: 0.145, 22432/28000 datapoints
2025-03-06 22:42:50,099 - INFO - training batch 751, loss: 0.079, 24032/28000 datapoints
2025-03-06 22:42:50,252 - INFO - training batch 801, loss: 0.032, 25632/28000 datapoints
2025-03-06 22:42:50,406 - INFO - training batch 851, loss: 0.146, 27232/28000 datapoints
2025-03-06 22:42:50,481 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 22:42:50,527 - INFO - validation batch 51, loss: 1.946, 1632/6976 datapoints
2025-03-06 22:42:50,579 - INFO - validation batch 101, loss: 0.504, 3232/6976 datapoints
2025-03-06 22:42:50,639 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 22:42:50,698 - INFO - validation batch 201, loss: 0.828, 6432/6976 datapoints
2025-03-06 22:42:50,714 - INFO - Epoch 336/800 done.
2025-03-06 22:42:50,714 - INFO - Final validation performance:
Loss: 0.790, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:50,715 - INFO - Beginning epoch 337/800
2025-03-06 22:42:50,719 - INFO - training batch 1, loss: 0.134, 32/28000 datapoints
2025-03-06 22:42:50,874 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 22:42:51,035 - INFO - training batch 101, loss: 0.095, 3232/28000 datapoints
2025-03-06 22:42:51,226 - INFO - training batch 151, loss: 0.064, 4832/28000 datapoints
2025-03-06 22:42:51,385 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 22:42:51,538 - INFO - training batch 251, loss: 0.354, 8032/28000 datapoints
2025-03-06 22:42:51,691 - INFO - training batch 301, loss: 0.447, 9632/28000 datapoints
2025-03-06 22:42:51,845 - INFO - training batch 351, loss: 0.180, 11232/28000 datapoints
2025-03-06 22:42:52,006 - INFO - training batch 401, loss: 0.151, 12832/28000 datapoints
2025-03-06 22:42:52,159 - INFO - training batch 451, loss: 0.238, 14432/28000 datapoints
2025-03-06 22:42:52,313 - INFO - training batch 501, loss: 0.097, 16032/28000 datapoints
2025-03-06 22:42:52,467 - INFO - training batch 551, loss: 0.144, 17632/28000 datapoints
2025-03-06 22:42:52,618 - INFO - training batch 601, loss: 0.106, 19232/28000 datapoints
2025-03-06 22:42:52,774 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 22:42:52,924 - INFO - training batch 701, loss: 0.144, 22432/28000 datapoints
2025-03-06 22:42:53,082 - INFO - training batch 751, loss: 0.075, 24032/28000 datapoints
2025-03-06 22:42:53,236 - INFO - training batch 801, loss: 0.032, 25632/28000 datapoints
2025-03-06 22:42:53,389 - INFO - training batch 851, loss: 0.145, 27232/28000 datapoints
2025-03-06 22:42:53,463 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 22:42:53,510 - INFO - validation batch 51, loss: 1.956, 1632/6976 datapoints
2025-03-06 22:42:53,559 - INFO - validation batch 101, loss: 0.507, 3232/6976 datapoints
2025-03-06 22:42:53,608 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-06 22:42:53,654 - INFO - validation batch 201, loss: 0.832, 6432/6976 datapoints
2025-03-06 22:42:53,672 - INFO - Epoch 337/800 done.
2025-03-06 22:42:53,672 - INFO - Final validation performance:
Loss: 0.794, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:53,672 - INFO - Beginning epoch 338/800
2025-03-06 22:42:53,677 - INFO - training batch 1, loss: 0.134, 32/28000 datapoints
2025-03-06 22:42:53,832 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 22:42:53,987 - INFO - training batch 101, loss: 0.095, 3232/28000 datapoints
2025-03-06 22:42:54,139 - INFO - training batch 151, loss: 0.063, 4832/28000 datapoints
2025-03-06 22:42:54,290 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 22:42:54,442 - INFO - training batch 251, loss: 0.351, 8032/28000 datapoints
2025-03-06 22:42:54,596 - INFO - training batch 301, loss: 0.445, 9632/28000 datapoints
2025-03-06 22:42:54,751 - INFO - training batch 351, loss: 0.179, 11232/28000 datapoints
2025-03-06 22:42:54,904 - INFO - training batch 401, loss: 0.149, 12832/28000 datapoints
2025-03-06 22:42:55,057 - INFO - training batch 451, loss: 0.236, 14432/28000 datapoints
2025-03-06 22:42:55,215 - INFO - training batch 501, loss: 0.097, 16032/28000 datapoints
2025-03-06 22:42:55,369 - INFO - training batch 551, loss: 0.143, 17632/28000 datapoints
2025-03-06 22:42:55,521 - INFO - training batch 601, loss: 0.104, 19232/28000 datapoints
2025-03-06 22:42:55,675 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 22:42:55,828 - INFO - training batch 701, loss: 0.142, 22432/28000 datapoints
2025-03-06 22:42:55,982 - INFO - training batch 751, loss: 0.076, 24032/28000 datapoints
2025-03-06 22:42:56,134 - INFO - training batch 801, loss: 0.031, 25632/28000 datapoints
2025-03-06 22:42:56,289 - INFO - training batch 851, loss: 0.144, 27232/28000 datapoints
2025-03-06 22:42:56,365 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 22:42:56,414 - INFO - validation batch 51, loss: 1.967, 1632/6976 datapoints
2025-03-06 22:42:56,462 - INFO - validation batch 101, loss: 0.508, 3232/6976 datapoints
2025-03-06 22:42:56,509 - INFO - validation batch 151, loss: 0.594, 4832/6976 datapoints
2025-03-06 22:42:56,557 - INFO - validation batch 201, loss: 0.835, 6432/6976 datapoints
2025-03-06 22:42:56,574 - INFO - Epoch 338/800 done.
2025-03-06 22:42:56,574 - INFO - Final validation performance:
Loss: 0.798, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:56,575 - INFO - Beginning epoch 339/800
2025-03-06 22:42:56,579 - INFO - training batch 1, loss: 0.132, 32/28000 datapoints
2025-03-06 22:42:56,749 - INFO - training batch 51, loss: 0.044, 1632/28000 datapoints
2025-03-06 22:42:56,905 - INFO - training batch 101, loss: 0.094, 3232/28000 datapoints
2025-03-06 22:42:57,060 - INFO - training batch 151, loss: 0.061, 4832/28000 datapoints
2025-03-06 22:42:57,242 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 22:42:57,406 - INFO - training batch 251, loss: 0.350, 8032/28000 datapoints
2025-03-06 22:42:57,563 - INFO - training batch 301, loss: 0.442, 9632/28000 datapoints
2025-03-06 22:42:57,713 - INFO - training batch 351, loss: 0.180, 11232/28000 datapoints
2025-03-06 22:42:57,865 - INFO - training batch 401, loss: 0.147, 12832/28000 datapoints
2025-03-06 22:42:58,018 - INFO - training batch 451, loss: 0.235, 14432/28000 datapoints
2025-03-06 22:42:58,170 - INFO - training batch 501, loss: 0.097, 16032/28000 datapoints
2025-03-06 22:42:58,325 - INFO - training batch 551, loss: 0.141, 17632/28000 datapoints
2025-03-06 22:42:58,477 - INFO - training batch 601, loss: 0.102, 19232/28000 datapoints
2025-03-06 22:42:58,629 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 22:42:58,783 - INFO - training batch 701, loss: 0.140, 22432/28000 datapoints
2025-03-06 22:42:58,938 - INFO - training batch 751, loss: 0.074, 24032/28000 datapoints
2025-03-06 22:42:59,091 - INFO - training batch 801, loss: 0.031, 25632/28000 datapoints
2025-03-06 22:42:59,244 - INFO - training batch 851, loss: 0.142, 27232/28000 datapoints
2025-03-06 22:42:59,320 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 22:42:59,367 - INFO - validation batch 51, loss: 1.977, 1632/6976 datapoints
2025-03-06 22:42:59,414 - INFO - validation batch 101, loss: 0.509, 3232/6976 datapoints
2025-03-06 22:42:59,462 - INFO - validation batch 151, loss: 0.596, 4832/6976 datapoints
2025-03-06 22:42:59,510 - INFO - validation batch 201, loss: 0.838, 6432/6976 datapoints
2025-03-06 22:42:59,527 - INFO - Epoch 339/800 done.
2025-03-06 22:42:59,527 - INFO - Final validation performance:
Loss: 0.802, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:42:59,528 - INFO - Beginning epoch 340/800
2025-03-06 22:42:59,532 - INFO - training batch 1, loss: 0.131, 32/28000 datapoints
2025-03-06 22:42:59,684 - INFO - training batch 51, loss: 0.044, 1632/28000 datapoints
2025-03-06 22:42:59,840 - INFO - training batch 101, loss: 0.093, 3232/28000 datapoints
2025-03-06 22:42:59,993 - INFO - training batch 151, loss: 0.060, 4832/28000 datapoints
2025-03-06 22:43:00,148 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 22:43:00,302 - INFO - training batch 251, loss: 0.349, 8032/28000 datapoints
2025-03-06 22:43:00,457 - INFO - training batch 301, loss: 0.440, 9632/28000 datapoints
2025-03-06 22:43:00,609 - INFO - training batch 351, loss: 0.179, 11232/28000 datapoints
2025-03-06 22:43:00,764 - INFO - training batch 401, loss: 0.147, 12832/28000 datapoints
2025-03-06 22:43:00,916 - INFO - training batch 451, loss: 0.233, 14432/28000 datapoints
2025-03-06 22:43:01,070 - INFO - training batch 501, loss: 0.096, 16032/28000 datapoints
2025-03-06 22:43:01,224 - INFO - training batch 551, loss: 0.140, 17632/28000 datapoints
2025-03-06 22:43:01,377 - INFO - training batch 601, loss: 0.102, 19232/28000 datapoints
2025-03-06 22:43:01,530 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 22:43:01,682 - INFO - training batch 701, loss: 0.138, 22432/28000 datapoints
2025-03-06 22:43:01,836 - INFO - training batch 751, loss: 0.074, 24032/28000 datapoints
2025-03-06 22:43:01,995 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-06 22:43:02,154 - INFO - training batch 851, loss: 0.142, 27232/28000 datapoints
2025-03-06 22:43:02,232 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 22:43:02,283 - INFO - validation batch 51, loss: 1.987, 1632/6976 datapoints
2025-03-06 22:43:02,336 - INFO - validation batch 101, loss: 0.511, 3232/6976 datapoints
2025-03-06 22:43:02,390 - INFO - validation batch 151, loss: 0.599, 4832/6976 datapoints
2025-03-06 22:43:02,442 - INFO - validation batch 201, loss: 0.844, 6432/6976 datapoints
2025-03-06 22:43:02,461 - INFO - Epoch 340/800 done.
2025-03-06 22:43:02,462 - INFO - Final validation performance:
Loss: 0.806, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:43:02,462 - INFO - Beginning epoch 341/800
2025-03-06 22:43:02,467 - INFO - training batch 1, loss: 0.129, 32/28000 datapoints
2025-03-06 22:43:02,637 - INFO - training batch 51, loss: 0.044, 1632/28000 datapoints
2025-03-06 22:43:02,810 - INFO - training batch 101, loss: 0.093, 3232/28000 datapoints
2025-03-06 22:43:02,972 - INFO - training batch 151, loss: 0.059, 4832/28000 datapoints
2025-03-06 22:43:03,134 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 22:43:03,295 - INFO - training batch 251, loss: 0.347, 8032/28000 datapoints
2025-03-06 22:43:03,457 - INFO - training batch 301, loss: 0.439, 9632/28000 datapoints
2025-03-06 22:43:03,618 - INFO - training batch 351, loss: 0.179, 11232/28000 datapoints
2025-03-06 22:43:03,774 - INFO - training batch 401, loss: 0.145, 12832/28000 datapoints
2025-03-06 22:43:03,930 - INFO - training batch 451, loss: 0.232, 14432/28000 datapoints
2025-03-06 22:43:04,088 - INFO - training batch 501, loss: 0.096, 16032/28000 datapoints
2025-03-06 22:43:04,245 - INFO - training batch 551, loss: 0.138, 17632/28000 datapoints
2025-03-06 22:43:04,406 - INFO - training batch 601, loss: 0.101, 19232/28000 datapoints
2025-03-06 22:43:04,562 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 22:43:04,715 - INFO - training batch 701, loss: 0.136, 22432/28000 datapoints
2025-03-06 22:43:04,878 - INFO - training batch 751, loss: 0.072, 24032/28000 datapoints
2025-03-06 22:43:05,038 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-06 22:43:05,203 - INFO - training batch 851, loss: 0.139, 27232/28000 datapoints
2025-03-06 22:43:05,291 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 22:43:05,343 - INFO - validation batch 51, loss: 1.998, 1632/6976 datapoints
2025-03-06 22:43:05,398 - INFO - validation batch 101, loss: 0.514, 3232/6976 datapoints
2025-03-06 22:43:05,451 - INFO - validation batch 151, loss: 0.604, 4832/6976 datapoints
2025-03-06 22:43:05,504 - INFO - validation batch 201, loss: 0.845, 6432/6976 datapoints
2025-03-06 22:43:05,520 - INFO - Epoch 341/800 done.
2025-03-06 22:43:05,521 - INFO - Final validation performance:
Loss: 0.810, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:43:05,521 - INFO - Beginning epoch 342/800
2025-03-06 22:43:05,526 - INFO - training batch 1, loss: 0.128, 32/28000 datapoints
2025-03-06 22:43:05,686 - INFO - training batch 51, loss: 0.044, 1632/28000 datapoints
2025-03-06 22:43:05,842 - INFO - training batch 101, loss: 0.092, 3232/28000 datapoints
2025-03-06 22:43:06,003 - INFO - training batch 151, loss: 0.058, 4832/28000 datapoints
2025-03-06 22:43:06,160 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 22:43:06,319 - INFO - training batch 251, loss: 0.345, 8032/28000 datapoints
2025-03-06 22:43:06,475 - INFO - training batch 301, loss: 0.437, 9632/28000 datapoints
2025-03-06 22:43:06,631 - INFO - training batch 351, loss: 0.178, 11232/28000 datapoints
2025-03-06 22:43:06,789 - INFO - training batch 401, loss: 0.144, 12832/28000 datapoints
2025-03-06 22:43:06,947 - INFO - training batch 451, loss: 0.231, 14432/28000 datapoints
2025-03-06 22:43:07,105 - INFO - training batch 501, loss: 0.096, 16032/28000 datapoints
2025-03-06 22:43:07,262 - INFO - training batch 551, loss: 0.136, 17632/28000 datapoints
2025-03-06 22:43:07,448 - INFO - training batch 601, loss: 0.098, 19232/28000 datapoints
2025-03-06 22:43:07,604 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 22:43:07,759 - INFO - training batch 701, loss: 0.134, 22432/28000 datapoints
2025-03-06 22:43:07,912 - INFO - training batch 751, loss: 0.072, 24032/28000 datapoints
2025-03-06 22:43:08,072 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-06 22:43:08,228 - INFO - training batch 851, loss: 0.139, 27232/28000 datapoints
2025-03-06 22:43:08,309 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 22:43:08,375 - INFO - validation batch 51, loss: 2.010, 1632/6976 datapoints
2025-03-06 22:43:08,428 - INFO - validation batch 101, loss: 0.513, 3232/6976 datapoints
2025-03-06 22:43:08,481 - INFO - validation batch 151, loss: 0.608, 4832/6976 datapoints
2025-03-06 22:43:08,532 - INFO - validation batch 201, loss: 0.851, 6432/6976 datapoints
2025-03-06 22:43:08,553 - INFO - Epoch 342/800 done.
2025-03-06 22:43:08,553 - INFO - Final validation performance:
Loss: 0.814, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:43:08,554 - INFO - Beginning epoch 343/800
2025-03-06 22:43:08,558 - INFO - training batch 1, loss: 0.126, 32/28000 datapoints
2025-03-06 22:43:08,714 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 22:43:08,885 - INFO - training batch 101, loss: 0.091, 3232/28000 datapoints
2025-03-06 22:43:09,050 - INFO - training batch 151, loss: 0.057, 4832/28000 datapoints
2025-03-06 22:43:09,207 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 22:43:09,365 - INFO - training batch 251, loss: 0.342, 8032/28000 datapoints
2025-03-06 22:43:09,530 - INFO - training batch 301, loss: 0.434, 9632/28000 datapoints
2025-03-06 22:43:09,688 - INFO - training batch 351, loss: 0.177, 11232/28000 datapoints
2025-03-06 22:43:09,850 - INFO - training batch 401, loss: 0.143, 12832/28000 datapoints
2025-03-06 22:43:10,011 - INFO - training batch 451, loss: 0.230, 14432/28000 datapoints
2025-03-06 22:43:10,169 - INFO - training batch 501, loss: 0.094, 16032/28000 datapoints
2025-03-06 22:43:10,334 - INFO - training batch 551, loss: 0.135, 17632/28000 datapoints
2025-03-06 22:43:10,492 - INFO - training batch 601, loss: 0.097, 19232/28000 datapoints
2025-03-06 22:43:10,648 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 22:43:10,806 - INFO - training batch 701, loss: 0.131, 22432/28000 datapoints
2025-03-06 22:43:10,966 - INFO - training batch 751, loss: 0.072, 24032/28000 datapoints
2025-03-06 22:43:11,124 - INFO - training batch 801, loss: 0.029, 25632/28000 datapoints
2025-03-06 22:43:11,280 - INFO - training batch 851, loss: 0.137, 27232/28000 datapoints
2025-03-06 22:43:11,364 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 22:43:11,418 - INFO - validation batch 51, loss: 2.022, 1632/6976 datapoints
2025-03-06 22:43:11,475 - INFO - validation batch 101, loss: 0.515, 3232/6976 datapoints
2025-03-06 22:43:11,531 - INFO - validation batch 151, loss: 0.608, 4832/6976 datapoints
2025-03-06 22:43:11,590 - INFO - validation batch 201, loss: 0.854, 6432/6976 datapoints
2025-03-06 22:43:11,611 - INFO - Epoch 343/800 done.
2025-03-06 22:43:11,612 - INFO - Final validation performance:
Loss: 0.817, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 22:43:11,612 - INFO - Beginning epoch 344/800
2025-03-06 22:43:11,616 - INFO - training batch 1, loss: 0.125, 32/28000 datapoints
2025-03-06 22:43:11,774 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 22:43:11,932 - INFO - training batch 101, loss: 0.092, 3232/28000 datapoints
2025-03-06 22:43:12,096 - INFO - training batch 151, loss: 0.056, 4832/28000 datapoints
2025-03-06 22:43:12,251 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:43:12,432 - INFO - training batch 251, loss: 0.341, 8032/28000 datapoints
2025-03-06 22:43:12,598 - INFO - training batch 301, loss: 0.433, 9632/28000 datapoints
2025-03-06 22:43:12,760 - INFO - training batch 351, loss: 0.177, 11232/28000 datapoints
2025-03-06 22:43:12,914 - INFO - training batch 401, loss: 0.143, 12832/28000 datapoints
2025-03-06 22:43:13,073 - INFO - training batch 451, loss: 0.229, 14432/28000 datapoints
2025-03-06 22:43:13,230 - INFO - training batch 501, loss: 0.094, 16032/28000 datapoints
2025-03-06 22:43:13,389 - INFO - training batch 551, loss: 0.133, 17632/28000 datapoints
2025-03-06 22:43:13,545 - INFO - training batch 601, loss: 0.095, 19232/28000 datapoints
2025-03-06 22:43:13,702 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 22:43:13,857 - INFO - training batch 701, loss: 0.129, 22432/28000 datapoints
2025-03-06 22:43:14,014 - INFO - training batch 751, loss: 0.069, 24032/28000 datapoints
2025-03-06 22:43:14,171 - INFO - training batch 801, loss: 0.029, 25632/28000 datapoints
2025-03-06 22:43:14,327 - INFO - training batch 851, loss: 0.137, 27232/28000 datapoints
2025-03-06 22:43:14,406 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 22:43:14,458 - INFO - validation batch 51, loss: 2.031, 1632/6976 datapoints
2025-03-06 22:43:14,511 - INFO - validation batch 101, loss: 0.517, 3232/6976 datapoints
2025-03-06 22:43:14,566 - INFO - validation batch 151, loss: 0.614, 4832/6976 datapoints
2025-03-06 22:43:14,618 - INFO - validation batch 201, loss: 0.858, 6432/6976 datapoints
2025-03-06 22:43:14,635 - INFO - Epoch 344/800 done.
2025-03-06 22:43:14,635 - INFO - Final validation performance:
Loss: 0.822, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:43:14,635 - INFO - Beginning epoch 345/800
2025-03-06 22:43:14,640 - INFO - training batch 1, loss: 0.124, 32/28000 datapoints
2025-03-06 22:43:14,801 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 22:43:14,976 - INFO - training batch 101, loss: 0.091, 3232/28000 datapoints
2025-03-06 22:43:15,133 - INFO - training batch 151, loss: 0.056, 4832/28000 datapoints
2025-03-06 22:43:15,295 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:43:15,459 - INFO - training batch 251, loss: 0.338, 8032/28000 datapoints
2025-03-06 22:43:15,623 - INFO - training batch 301, loss: 0.431, 9632/28000 datapoints
2025-03-06 22:43:15,786 - INFO - training batch 351, loss: 0.177, 11232/28000 datapoints
2025-03-06 22:43:15,941 - INFO - training batch 401, loss: 0.141, 12832/28000 datapoints
2025-03-06 22:43:16,101 - INFO - training batch 451, loss: 0.228, 14432/28000 datapoints
2025-03-06 22:43:16,260 - INFO - training batch 501, loss: 0.093, 16032/28000 datapoints
2025-03-06 22:43:16,423 - INFO - training batch 551, loss: 0.131, 17632/28000 datapoints
2025-03-06 22:43:16,580 - INFO - training batch 601, loss: 0.094, 19232/28000 datapoints
2025-03-06 22:43:16,738 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 22:43:16,897 - INFO - training batch 701, loss: 0.128, 22432/28000 datapoints
2025-03-06 22:43:17,054 - INFO - training batch 751, loss: 0.069, 24032/28000 datapoints
2025-03-06 22:43:17,209 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-06 22:43:17,367 - INFO - training batch 851, loss: 0.134, 27232/28000 datapoints
2025-03-06 22:43:17,472 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 22:43:17,526 - INFO - validation batch 51, loss: 2.044, 1632/6976 datapoints
2025-03-06 22:43:17,584 - INFO - validation batch 101, loss: 0.518, 3232/6976 datapoints
2025-03-06 22:43:17,636 - INFO - validation batch 151, loss: 0.618, 4832/6976 datapoints
2025-03-06 22:43:17,687 - INFO - validation batch 201, loss: 0.862, 6432/6976 datapoints
2025-03-06 22:43:17,707 - INFO - Epoch 345/800 done.
2025-03-06 22:43:17,707 - INFO - Final validation performance:
Loss: 0.826, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:43:17,708 - INFO - Beginning epoch 346/800
2025-03-06 22:43:17,712 - INFO - training batch 1, loss: 0.122, 32/28000 datapoints
2025-03-06 22:43:17,875 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 22:43:18,061 - INFO - training batch 101, loss: 0.090, 3232/28000 datapoints
2025-03-06 22:43:18,246 - INFO - training batch 151, loss: 0.055, 4832/28000 datapoints
2025-03-06 22:43:18,424 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:43:18,603 - INFO - training batch 251, loss: 0.337, 8032/28000 datapoints
2025-03-06 22:43:18,760 - INFO - training batch 301, loss: 0.429, 9632/28000 datapoints
2025-03-06 22:43:18,924 - INFO - training batch 351, loss: 0.176, 11232/28000 datapoints
2025-03-06 22:43:19,084 - INFO - training batch 401, loss: 0.140, 12832/28000 datapoints
2025-03-06 22:43:19,240 - INFO - training batch 451, loss: 0.227, 14432/28000 datapoints
2025-03-06 22:43:19,398 - INFO - training batch 501, loss: 0.092, 16032/28000 datapoints
2025-03-06 22:43:19,555 - INFO - training batch 551, loss: 0.130, 17632/28000 datapoints
2025-03-06 22:43:19,712 - INFO - training batch 601, loss: 0.092, 19232/28000 datapoints
2025-03-06 22:43:19,873 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 22:43:20,030 - INFO - training batch 701, loss: 0.126, 22432/28000 datapoints
2025-03-06 22:43:20,187 - INFO - training batch 751, loss: 0.067, 24032/28000 datapoints
2025-03-06 22:43:20,346 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-06 22:43:20,503 - INFO - training batch 851, loss: 0.134, 27232/28000 datapoints
2025-03-06 22:43:20,583 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 22:43:20,634 - INFO - validation batch 51, loss: 2.054, 1632/6976 datapoints
2025-03-06 22:43:20,686 - INFO - validation batch 101, loss: 0.520, 3232/6976 datapoints
2025-03-06 22:43:20,740 - INFO - validation batch 151, loss: 0.621, 4832/6976 datapoints
2025-03-06 22:43:20,795 - INFO - validation batch 201, loss: 0.866, 6432/6976 datapoints
2025-03-06 22:43:20,814 - INFO - Epoch 346/800 done.
2025-03-06 22:43:20,814 - INFO - Final validation performance:
Loss: 0.830, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:43:20,814 - INFO - Beginning epoch 347/800
2025-03-06 22:43:20,819 - INFO - training batch 1, loss: 0.121, 32/28000 datapoints
2025-03-06 22:43:20,995 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 22:43:21,153 - INFO - training batch 101, loss: 0.089, 3232/28000 datapoints
2025-03-06 22:43:21,311 - INFO - training batch 151, loss: 0.053, 4832/28000 datapoints
2025-03-06 22:43:21,474 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:43:21,635 - INFO - training batch 251, loss: 0.335, 8032/28000 datapoints
2025-03-06 22:43:21,794 - INFO - training batch 301, loss: 0.428, 9632/28000 datapoints
2025-03-06 22:43:21,954 - INFO - training batch 351, loss: 0.177, 11232/28000 datapoints
2025-03-06 22:43:22,115 - INFO - training batch 401, loss: 0.139, 12832/28000 datapoints
2025-03-06 22:43:22,274 - INFO - training batch 451, loss: 0.226, 14432/28000 datapoints
2025-03-06 22:43:22,433 - INFO - training batch 501, loss: 0.092, 16032/28000 datapoints
2025-03-06 22:43:22,593 - INFO - training batch 551, loss: 0.128, 17632/28000 datapoints
2025-03-06 22:43:22,749 - INFO - training batch 601, loss: 0.091, 19232/28000 datapoints
2025-03-06 22:43:22,909 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 22:43:23,067 - INFO - training batch 701, loss: 0.123, 22432/28000 datapoints
2025-03-06 22:43:23,223 - INFO - training batch 751, loss: 0.068, 24032/28000 datapoints
2025-03-06 22:43:23,380 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-06 22:43:23,538 - INFO - training batch 851, loss: 0.131, 27232/28000 datapoints
2025-03-06 22:43:23,618 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 22:43:23,669 - INFO - validation batch 51, loss: 2.068, 1632/6976 datapoints
2025-03-06 22:43:23,724 - INFO - validation batch 101, loss: 0.521, 3232/6976 datapoints
2025-03-06 22:43:23,776 - INFO - validation batch 151, loss: 0.624, 4832/6976 datapoints
2025-03-06 22:43:23,829 - INFO - validation batch 201, loss: 0.871, 6432/6976 datapoints
2025-03-06 22:43:23,849 - INFO - Epoch 347/800 done.
2025-03-06 22:43:23,849 - INFO - Final validation performance:
Loss: 0.835, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:43:23,850 - INFO - Beginning epoch 348/800
2025-03-06 22:43:23,856 - INFO - training batch 1, loss: 0.118, 32/28000 datapoints
2025-03-06 22:43:24,017 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 22:43:24,175 - INFO - training batch 101, loss: 0.088, 3232/28000 datapoints
2025-03-06 22:43:24,328 - INFO - training batch 151, loss: 0.053, 4832/28000 datapoints
2025-03-06 22:43:24,480 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:43:24,635 - INFO - training batch 251, loss: 0.333, 8032/28000 datapoints
2025-03-06 22:43:24,788 - INFO - training batch 301, loss: 0.425, 9632/28000 datapoints
2025-03-06 22:43:24,943 - INFO - training batch 351, loss: 0.174, 11232/28000 datapoints
2025-03-06 22:43:25,095 - INFO - training batch 401, loss: 0.138, 12832/28000 datapoints
2025-03-06 22:43:25,255 - INFO - training batch 451, loss: 0.224, 14432/28000 datapoints
2025-03-06 22:43:25,411 - INFO - training batch 501, loss: 0.091, 16032/28000 datapoints
2025-03-06 22:43:25,564 - INFO - training batch 551, loss: 0.126, 17632/28000 datapoints
2025-03-06 22:43:25,720 - INFO - training batch 601, loss: 0.091, 19232/28000 datapoints
2025-03-06 22:43:25,874 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 22:43:26,028 - INFO - training batch 701, loss: 0.121, 22432/28000 datapoints
2025-03-06 22:43:26,179 - INFO - training batch 751, loss: 0.065, 24032/28000 datapoints
2025-03-06 22:43:26,332 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-06 22:43:26,485 - INFO - training batch 851, loss: 0.131, 27232/28000 datapoints
2025-03-06 22:43:26,562 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 22:43:26,611 - INFO - validation batch 51, loss: 2.077, 1632/6976 datapoints
2025-03-06 22:43:26,659 - INFO - validation batch 101, loss: 0.523, 3232/6976 datapoints
2025-03-06 22:43:26,706 - INFO - validation batch 151, loss: 0.628, 4832/6976 datapoints
2025-03-06 22:43:26,753 - INFO - validation batch 201, loss: 0.874, 6432/6976 datapoints
2025-03-06 22:43:26,770 - INFO - Epoch 348/800 done.
2025-03-06 22:43:26,770 - INFO - Final validation performance:
Loss: 0.838, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:43:26,771 - INFO - Beginning epoch 349/800
2025-03-06 22:43:26,775 - INFO - training batch 1, loss: 0.118, 32/28000 datapoints
2025-03-06 22:43:26,932 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 22:43:27,087 - INFO - training batch 101, loss: 0.088, 3232/28000 datapoints
2025-03-06 22:43:27,253 - INFO - training batch 151, loss: 0.051, 4832/28000 datapoints
2025-03-06 22:43:27,405 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:43:27,587 - INFO - training batch 251, loss: 0.330, 8032/28000 datapoints
2025-03-06 22:43:27,746 - INFO - training batch 301, loss: 0.423, 9632/28000 datapoints
2025-03-06 22:43:27,901 - INFO - training batch 351, loss: 0.174, 11232/28000 datapoints
2025-03-06 22:43:28,058 - INFO - training batch 401, loss: 0.138, 12832/28000 datapoints
2025-03-06 22:43:28,212 - INFO - training batch 451, loss: 0.223, 14432/28000 datapoints
2025-03-06 22:43:28,366 - INFO - training batch 501, loss: 0.091, 16032/28000 datapoints
2025-03-06 22:43:28,518 - INFO - training batch 551, loss: 0.124, 17632/28000 datapoints
2025-03-06 22:43:28,670 - INFO - training batch 601, loss: 0.088, 19232/28000 datapoints
2025-03-06 22:43:28,826 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 22:43:28,980 - INFO - training batch 701, loss: 0.121, 22432/28000 datapoints
2025-03-06 22:43:29,133 - INFO - training batch 751, loss: 0.065, 24032/28000 datapoints
2025-03-06 22:43:29,286 - INFO - training batch 801, loss: 0.027, 25632/28000 datapoints
2025-03-06 22:43:29,438 - INFO - training batch 851, loss: 0.129, 27232/28000 datapoints
2025-03-06 22:43:29,514 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 22:43:29,561 - INFO - validation batch 51, loss: 2.092, 1632/6976 datapoints
2025-03-06 22:43:29,610 - INFO - validation batch 101, loss: 0.522, 3232/6976 datapoints
2025-03-06 22:43:29,658 - INFO - validation batch 151, loss: 0.633, 4832/6976 datapoints
2025-03-06 22:43:29,707 - INFO - validation batch 201, loss: 0.877, 6432/6976 datapoints
2025-03-06 22:43:29,724 - INFO - Epoch 349/800 done.
2025-03-06 22:43:29,724 - INFO - Final validation performance:
Loss: 0.842, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:43:29,724 - INFO - Beginning epoch 350/800
2025-03-06 22:43:29,728 - INFO - training batch 1, loss: 0.116, 32/28000 datapoints
2025-03-06 22:43:29,882 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 22:43:30,037 - INFO - training batch 101, loss: 0.087, 3232/28000 datapoints
2025-03-06 22:43:30,189 - INFO - training batch 151, loss: 0.050, 4832/28000 datapoints
2025-03-06 22:43:30,345 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:43:30,498 - INFO - training batch 251, loss: 0.328, 8032/28000 datapoints
2025-03-06 22:43:30,650 - INFO - training batch 301, loss: 0.422, 9632/28000 datapoints
2025-03-06 22:43:30,804 - INFO - training batch 351, loss: 0.175, 11232/28000 datapoints
2025-03-06 22:43:30,962 - INFO - training batch 401, loss: 0.136, 12832/28000 datapoints
2025-03-06 22:43:31,113 - INFO - training batch 451, loss: 0.222, 14432/28000 datapoints
2025-03-06 22:43:31,267 - INFO - training batch 501, loss: 0.090, 16032/28000 datapoints
2025-03-06 22:43:31,420 - INFO - training batch 551, loss: 0.123, 17632/28000 datapoints
2025-03-06 22:43:31,573 - INFO - training batch 601, loss: 0.088, 19232/28000 datapoints
2025-03-06 22:43:31,725 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 22:43:31,878 - INFO - training batch 701, loss: 0.118, 22432/28000 datapoints
2025-03-06 22:43:32,031 - INFO - training batch 751, loss: 0.065, 24032/28000 datapoints
2025-03-06 22:43:32,188 - INFO - training batch 801, loss: 0.027, 25632/28000 datapoints
2025-03-06 22:43:32,343 - INFO - training batch 851, loss: 0.128, 27232/28000 datapoints
2025-03-06 22:43:32,418 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 22:43:32,465 - INFO - validation batch 51, loss: 2.104, 1632/6976 datapoints
2025-03-06 22:43:32,512 - INFO - validation batch 101, loss: 0.524, 3232/6976 datapoints
2025-03-06 22:43:32,559 - INFO - validation batch 151, loss: 0.635, 4832/6976 datapoints
2025-03-06 22:43:32,606 - INFO - validation batch 201, loss: 0.886, 6432/6976 datapoints
2025-03-06 22:43:32,623 - INFO - Epoch 350/800 done.
2025-03-06 22:43:32,623 - INFO - Final validation performance:
Loss: 0.848, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:43:32,623 - INFO - Beginning epoch 351/800
2025-03-06 22:43:32,628 - INFO - training batch 1, loss: 0.114, 32/28000 datapoints
2025-03-06 22:43:32,782 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 22:43:32,949 - INFO - training batch 101, loss: 0.085, 3232/28000 datapoints
2025-03-06 22:43:33,105 - INFO - training batch 151, loss: 0.050, 4832/28000 datapoints
2025-03-06 22:43:33,275 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:43:33,432 - INFO - training batch 251, loss: 0.326, 8032/28000 datapoints
2025-03-06 22:43:33,592 - INFO - training batch 301, loss: 0.420, 9632/28000 datapoints
2025-03-06 22:43:33,747 - INFO - training batch 351, loss: 0.173, 11232/28000 datapoints
2025-03-06 22:43:33,906 - INFO - training batch 401, loss: 0.134, 12832/28000 datapoints
2025-03-06 22:43:34,103 - INFO - training batch 451, loss: 0.220, 14432/28000 datapoints
2025-03-06 22:43:34,264 - INFO - training batch 501, loss: 0.090, 16032/28000 datapoints
2025-03-06 22:43:34,419 - INFO - training batch 551, loss: 0.122, 17632/28000 datapoints
2025-03-06 22:43:34,571 - INFO - training batch 601, loss: 0.084, 19232/28000 datapoints
2025-03-06 22:43:34,724 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 22:43:34,878 - INFO - training batch 701, loss: 0.117, 22432/28000 datapoints
2025-03-06 22:43:35,034 - INFO - training batch 751, loss: 0.063, 24032/28000 datapoints
2025-03-06 22:43:35,190 - INFO - training batch 801, loss: 0.026, 25632/28000 datapoints
2025-03-06 22:43:35,349 - INFO - training batch 851, loss: 0.126, 27232/28000 datapoints
2025-03-06 22:43:35,426 - INFO - validation batch 1, loss: 0.090, 32/6976 datapoints
2025-03-06 22:43:35,474 - INFO - validation batch 51, loss: 2.113, 1632/6976 datapoints
2025-03-06 22:43:35,524 - INFO - validation batch 101, loss: 0.526, 3232/6976 datapoints
2025-03-06 22:43:35,571 - INFO - validation batch 151, loss: 0.639, 4832/6976 datapoints
2025-03-06 22:43:35,619 - INFO - validation batch 201, loss: 0.889, 6432/6976 datapoints
2025-03-06 22:43:35,635 - INFO - Epoch 351/800 done.
2025-03-06 22:43:35,635 - INFO - Final validation performance:
Loss: 0.851, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:43:35,635 - INFO - Beginning epoch 352/800
2025-03-06 22:43:35,640 - INFO - training batch 1, loss: 0.113, 32/28000 datapoints
2025-03-06 22:43:35,801 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 22:43:35,956 - INFO - training batch 101, loss: 0.085, 3232/28000 datapoints
2025-03-06 22:43:36,108 - INFO - training batch 151, loss: 0.048, 4832/28000 datapoints
2025-03-06 22:43:36,259 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:43:36,416 - INFO - training batch 251, loss: 0.324, 8032/28000 datapoints
2025-03-06 22:43:36,568 - INFO - training batch 301, loss: 0.418, 9632/28000 datapoints
2025-03-06 22:43:36,720 - INFO - training batch 351, loss: 0.173, 11232/28000 datapoints
2025-03-06 22:43:36,878 - INFO - training batch 401, loss: 0.134, 12832/28000 datapoints
2025-03-06 22:43:37,033 - INFO - training batch 451, loss: 0.220, 14432/28000 datapoints
2025-03-06 22:43:37,185 - INFO - training batch 501, loss: 0.089, 16032/28000 datapoints
2025-03-06 22:43:37,339 - INFO - training batch 551, loss: 0.119, 17632/28000 datapoints
2025-03-06 22:43:37,490 - INFO - training batch 601, loss: 0.084, 19232/28000 datapoints
2025-03-06 22:43:37,662 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 22:43:37,821 - INFO - training batch 701, loss: 0.113, 22432/28000 datapoints
2025-03-06 22:43:37,989 - INFO - training batch 751, loss: 0.063, 24032/28000 datapoints
2025-03-06 22:43:38,182 - INFO - training batch 801, loss: 0.026, 25632/28000 datapoints
2025-03-06 22:43:38,336 - INFO - training batch 851, loss: 0.125, 27232/28000 datapoints
2025-03-06 22:43:38,411 - INFO - validation batch 1, loss: 0.090, 32/6976 datapoints
2025-03-06 22:43:38,459 - INFO - validation batch 51, loss: 2.127, 1632/6976 datapoints
2025-03-06 22:43:38,507 - INFO - validation batch 101, loss: 0.527, 3232/6976 datapoints
2025-03-06 22:43:38,553 - INFO - validation batch 151, loss: 0.643, 4832/6976 datapoints
2025-03-06 22:43:38,602 - INFO - validation batch 201, loss: 0.892, 6432/6976 datapoints
2025-03-06 22:43:38,618 - INFO - Epoch 352/800 done.
2025-03-06 22:43:38,618 - INFO - Final validation performance:
Loss: 0.856, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:43:38,619 - INFO - Beginning epoch 353/800
2025-03-06 22:43:38,623 - INFO - training batch 1, loss: 0.111, 32/28000 datapoints
2025-03-06 22:43:38,775 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 22:43:38,932 - INFO - training batch 101, loss: 0.085, 3232/28000 datapoints
2025-03-06 22:43:39,088 - INFO - training batch 151, loss: 0.048, 4832/28000 datapoints
2025-03-06 22:43:39,251 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:43:39,413 - INFO - training batch 251, loss: 0.321, 8032/28000 datapoints
2025-03-06 22:43:39,566 - INFO - training batch 301, loss: 0.416, 9632/28000 datapoints
2025-03-06 22:43:39,724 - INFO - training batch 351, loss: 0.172, 11232/28000 datapoints
2025-03-06 22:43:39,878 - INFO - training batch 401, loss: 0.132, 12832/28000 datapoints
2025-03-06 22:43:40,035 - INFO - training batch 451, loss: 0.217, 14432/28000 datapoints
2025-03-06 22:43:40,194 - INFO - training batch 501, loss: 0.088, 16032/28000 datapoints
2025-03-06 22:43:40,348 - INFO - training batch 551, loss: 0.118, 17632/28000 datapoints
2025-03-06 22:43:40,500 - INFO - training batch 601, loss: 0.082, 19232/28000 datapoints
2025-03-06 22:43:40,652 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 22:43:40,805 - INFO - training batch 701, loss: 0.113, 22432/28000 datapoints
2025-03-06 22:43:40,963 - INFO - training batch 751, loss: 0.061, 24032/28000 datapoints
2025-03-06 22:43:41,115 - INFO - training batch 801, loss: 0.026, 25632/28000 datapoints
2025-03-06 22:43:41,267 - INFO - training batch 851, loss: 0.123, 27232/28000 datapoints
2025-03-06 22:43:41,345 - INFO - validation batch 1, loss: 0.090, 32/6976 datapoints
2025-03-06 22:43:41,394 - INFO - validation batch 51, loss: 2.137, 1632/6976 datapoints
2025-03-06 22:43:41,442 - INFO - validation batch 101, loss: 0.528, 3232/6976 datapoints
2025-03-06 22:43:41,489 - INFO - validation batch 151, loss: 0.648, 4832/6976 datapoints
2025-03-06 22:43:41,537 - INFO - validation batch 201, loss: 0.897, 6432/6976 datapoints
2025-03-06 22:43:41,553 - INFO - Epoch 353/800 done.
2025-03-06 22:43:41,553 - INFO - Final validation performance:
Loss: 0.860, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:43:41,554 - INFO - Beginning epoch 354/800
2025-03-06 22:43:41,558 - INFO - training batch 1, loss: 0.110, 32/28000 datapoints
2025-03-06 22:43:41,711 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:43:41,866 - INFO - training batch 101, loss: 0.084, 3232/28000 datapoints
2025-03-06 22:43:42,028 - INFO - training batch 151, loss: 0.047, 4832/28000 datapoints
2025-03-06 22:43:42,186 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:43:42,343 - INFO - training batch 251, loss: 0.317, 8032/28000 datapoints
2025-03-06 22:43:42,500 - INFO - training batch 301, loss: 0.414, 9632/28000 datapoints
2025-03-06 22:43:42,657 - INFO - training batch 351, loss: 0.171, 11232/28000 datapoints
2025-03-06 22:43:42,813 - INFO - training batch 401, loss: 0.132, 12832/28000 datapoints
2025-03-06 22:43:42,976 - INFO - training batch 451, loss: 0.217, 14432/28000 datapoints
2025-03-06 22:43:43,131 - INFO - training batch 501, loss: 0.086, 16032/28000 datapoints
2025-03-06 22:43:43,290 - INFO - training batch 551, loss: 0.116, 17632/28000 datapoints
2025-03-06 22:43:43,448 - INFO - training batch 601, loss: 0.082, 19232/28000 datapoints
2025-03-06 22:43:43,604 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 22:43:43,760 - INFO - training batch 701, loss: 0.110, 22432/28000 datapoints
2025-03-06 22:43:43,916 - INFO - training batch 751, loss: 0.060, 24032/28000 datapoints
2025-03-06 22:43:44,074 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-06 22:43:44,231 - INFO - training batch 851, loss: 0.122, 27232/28000 datapoints
2025-03-06 22:43:44,310 - INFO - validation batch 1, loss: 0.090, 32/6976 datapoints
2025-03-06 22:43:44,363 - INFO - validation batch 51, loss: 2.153, 1632/6976 datapoints
2025-03-06 22:43:44,416 - INFO - validation batch 101, loss: 0.528, 3232/6976 datapoints
2025-03-06 22:43:44,469 - INFO - validation batch 151, loss: 0.649, 4832/6976 datapoints
2025-03-06 22:43:44,521 - INFO - validation batch 201, loss: 0.903, 6432/6976 datapoints
2025-03-06 22:43:44,537 - INFO - Epoch 354/800 done.
2025-03-06 22:43:44,537 - INFO - Final validation performance:
Loss: 0.865, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:43:44,538 - INFO - Beginning epoch 355/800
2025-03-06 22:43:44,543 - INFO - training batch 1, loss: 0.109, 32/28000 datapoints
2025-03-06 22:43:44,703 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:43:44,855 - INFO - training batch 101, loss: 0.084, 3232/28000 datapoints
2025-03-06 22:43:45,014 - INFO - training batch 151, loss: 0.046, 4832/28000 datapoints
2025-03-06 22:43:45,171 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:43:45,346 - INFO - training batch 251, loss: 0.315, 8032/28000 datapoints
2025-03-06 22:43:45,500 - INFO - training batch 301, loss: 0.413, 9632/28000 datapoints
2025-03-06 22:43:45,652 - INFO - training batch 351, loss: 0.170, 11232/28000 datapoints
2025-03-06 22:43:45,816 - INFO - training batch 401, loss: 0.131, 12832/28000 datapoints
2025-03-06 22:43:45,975 - INFO - training batch 451, loss: 0.216, 14432/28000 datapoints
2025-03-06 22:43:46,127 - INFO - training batch 501, loss: 0.086, 16032/28000 datapoints
2025-03-06 22:43:46,285 - INFO - training batch 551, loss: 0.114, 17632/28000 datapoints
2025-03-06 22:43:46,441 - INFO - training batch 601, loss: 0.081, 19232/28000 datapoints
2025-03-06 22:43:46,595 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 22:43:46,745 - INFO - training batch 701, loss: 0.109, 22432/28000 datapoints
2025-03-06 22:43:46,902 - INFO - training batch 751, loss: 0.060, 24032/28000 datapoints
2025-03-06 22:43:47,060 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-06 22:43:47,211 - INFO - training batch 851, loss: 0.121, 27232/28000 datapoints
2025-03-06 22:43:47,287 - INFO - validation batch 1, loss: 0.091, 32/6976 datapoints
2025-03-06 22:43:47,335 - INFO - validation batch 51, loss: 2.164, 1632/6976 datapoints
2025-03-06 22:43:47,384 - INFO - validation batch 101, loss: 0.529, 3232/6976 datapoints
2025-03-06 22:43:47,435 - INFO - validation batch 151, loss: 0.650, 4832/6976 datapoints
2025-03-06 22:43:47,483 - INFO - validation batch 201, loss: 0.907, 6432/6976 datapoints
2025-03-06 22:43:47,499 - INFO - Epoch 355/800 done.
2025-03-06 22:43:47,500 - INFO - Final validation performance:
Loss: 0.868, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 22:43:47,500 - INFO - Beginning epoch 356/800
2025-03-06 22:43:47,504 - INFO - training batch 1, loss: 0.108, 32/28000 datapoints
2025-03-06 22:43:47,659 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:43:47,842 - INFO - training batch 101, loss: 0.083, 3232/28000 datapoints
2025-03-06 22:43:47,999 - INFO - training batch 151, loss: 0.045, 4832/28000 datapoints
2025-03-06 22:43:48,149 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:43:48,309 - INFO - training batch 251, loss: 0.313, 8032/28000 datapoints
2025-03-06 22:43:48,463 - INFO - training batch 301, loss: 0.411, 9632/28000 datapoints
2025-03-06 22:43:48,614 - INFO - training batch 351, loss: 0.170, 11232/28000 datapoints
2025-03-06 22:43:48,765 - INFO - training batch 401, loss: 0.130, 12832/28000 datapoints
2025-03-06 22:43:48,920 - INFO - training batch 451, loss: 0.215, 14432/28000 datapoints
2025-03-06 22:43:49,076 - INFO - training batch 501, loss: 0.085, 16032/28000 datapoints
2025-03-06 22:43:49,229 - INFO - training batch 551, loss: 0.112, 17632/28000 datapoints
2025-03-06 22:43:49,386 - INFO - training batch 601, loss: 0.078, 19232/28000 datapoints
2025-03-06 22:43:49,539 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 22:43:49,691 - INFO - training batch 701, loss: 0.106, 22432/28000 datapoints
2025-03-06 22:43:49,845 - INFO - training batch 751, loss: 0.058, 24032/28000 datapoints
2025-03-06 22:43:50,000 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-06 22:43:50,150 - INFO - training batch 851, loss: 0.119, 27232/28000 datapoints
2025-03-06 22:43:50,227 - INFO - validation batch 1, loss: 0.092, 32/6976 datapoints
2025-03-06 22:43:50,273 - INFO - validation batch 51, loss: 2.177, 1632/6976 datapoints
2025-03-06 22:43:50,320 - INFO - validation batch 101, loss: 0.530, 3232/6976 datapoints
2025-03-06 22:43:50,368 - INFO - validation batch 151, loss: 0.657, 4832/6976 datapoints
2025-03-06 22:43:50,416 - INFO - validation batch 201, loss: 0.912, 6432/6976 datapoints
2025-03-06 22:43:50,432 - INFO - Epoch 356/800 done.
2025-03-06 22:43:50,432 - INFO - Final validation performance:
Loss: 0.873, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:43:50,433 - INFO - Beginning epoch 357/800
2025-03-06 22:43:50,437 - INFO - training batch 1, loss: 0.106, 32/28000 datapoints
2025-03-06 22:43:50,593 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:43:50,744 - INFO - training batch 101, loss: 0.081, 3232/28000 datapoints
2025-03-06 22:43:50,897 - INFO - training batch 151, loss: 0.045, 4832/28000 datapoints
2025-03-06 22:43:51,064 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 22:43:51,222 - INFO - training batch 251, loss: 0.311, 8032/28000 datapoints
2025-03-06 22:43:51,381 - INFO - training batch 301, loss: 0.409, 9632/28000 datapoints
2025-03-06 22:43:51,534 - INFO - training batch 351, loss: 0.170, 11232/28000 datapoints
2025-03-06 22:43:51,690 - INFO - training batch 401, loss: 0.129, 12832/28000 datapoints
2025-03-06 22:43:51,844 - INFO - training batch 451, loss: 0.214, 14432/28000 datapoints
2025-03-06 22:43:52,004 - INFO - training batch 501, loss: 0.084, 16032/28000 datapoints
2025-03-06 22:43:52,159 - INFO - training batch 551, loss: 0.111, 17632/28000 datapoints
2025-03-06 22:43:52,316 - INFO - training batch 601, loss: 0.077, 19232/28000 datapoints
2025-03-06 22:43:52,467 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 22:43:52,619 - INFO - training batch 701, loss: 0.105, 22432/28000 datapoints
2025-03-06 22:43:52,771 - INFO - training batch 751, loss: 0.058, 24032/28000 datapoints
2025-03-06 22:43:52,925 - INFO - training batch 801, loss: 0.024, 25632/28000 datapoints
2025-03-06 22:43:53,080 - INFO - training batch 851, loss: 0.118, 27232/28000 datapoints
2025-03-06 22:43:53,155 - INFO - validation batch 1, loss: 0.092, 32/6976 datapoints
2025-03-06 22:43:53,204 - INFO - validation batch 51, loss: 2.189, 1632/6976 datapoints
2025-03-06 22:43:53,251 - INFO - validation batch 101, loss: 0.528, 3232/6976 datapoints
2025-03-06 22:43:53,298 - INFO - validation batch 151, loss: 0.662, 4832/6976 datapoints
2025-03-06 22:43:53,347 - INFO - validation batch 201, loss: 0.915, 6432/6976 datapoints
2025-03-06 22:43:53,365 - INFO - Epoch 357/800 done.
2025-03-06 22:43:53,365 - INFO - Final validation performance:
Loss: 0.877, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:43:53,366 - INFO - Beginning epoch 358/800
2025-03-06 22:43:53,370 - INFO - training batch 1, loss: 0.104, 32/28000 datapoints
2025-03-06 22:43:53,526 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:43:53,679 - INFO - training batch 101, loss: 0.080, 3232/28000 datapoints
2025-03-06 22:43:53,831 - INFO - training batch 151, loss: 0.044, 4832/28000 datapoints
2025-03-06 22:43:53,985 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:43:54,138 - INFO - training batch 251, loss: 0.306, 8032/28000 datapoints
2025-03-06 22:43:54,289 - INFO - training batch 301, loss: 0.408, 9632/28000 datapoints
2025-03-06 22:43:54,441 - INFO - training batch 351, loss: 0.168, 11232/28000 datapoints
2025-03-06 22:43:54,594 - INFO - training batch 401, loss: 0.128, 12832/28000 datapoints
2025-03-06 22:43:54,746 - INFO - training batch 451, loss: 0.212, 14432/28000 datapoints
2025-03-06 22:43:54,909 - INFO - training batch 501, loss: 0.083, 16032/28000 datapoints
2025-03-06 22:43:55,080 - INFO - training batch 551, loss: 0.109, 17632/28000 datapoints
2025-03-06 22:43:55,241 - INFO - training batch 601, loss: 0.077, 19232/28000 datapoints
2025-03-06 22:43:55,393 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 22:43:55,546 - INFO - training batch 701, loss: 0.102, 22432/28000 datapoints
2025-03-06 22:43:55,700 - INFO - training batch 751, loss: 0.057, 24032/28000 datapoints
2025-03-06 22:43:55,854 - INFO - training batch 801, loss: 0.024, 25632/28000 datapoints
2025-03-06 22:43:56,009 - INFO - training batch 851, loss: 0.116, 27232/28000 datapoints
2025-03-06 22:43:56,087 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 22:43:56,134 - INFO - validation batch 51, loss: 2.202, 1632/6976 datapoints
2025-03-06 22:43:56,182 - INFO - validation batch 101, loss: 0.532, 3232/6976 datapoints
2025-03-06 22:43:56,229 - INFO - validation batch 151, loss: 0.664, 4832/6976 datapoints
2025-03-06 22:43:56,277 - INFO - validation batch 201, loss: 0.922, 6432/6976 datapoints
2025-03-06 22:43:56,293 - INFO - Epoch 358/800 done.
2025-03-06 22:43:56,293 - INFO - Final validation performance:
Loss: 0.883, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:43:56,294 - INFO - Beginning epoch 359/800
2025-03-06 22:43:56,298 - INFO - training batch 1, loss: 0.103, 32/28000 datapoints
2025-03-06 22:43:56,462 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:43:56,616 - INFO - training batch 101, loss: 0.080, 3232/28000 datapoints
2025-03-06 22:43:56,770 - INFO - training batch 151, loss: 0.044, 4832/28000 datapoints
2025-03-06 22:43:56,922 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:43:57,079 - INFO - training batch 251, loss: 0.302, 8032/28000 datapoints
2025-03-06 22:43:57,239 - INFO - training batch 301, loss: 0.405, 9632/28000 datapoints
2025-03-06 22:43:57,404 - INFO - training batch 351, loss: 0.167, 11232/28000 datapoints
2025-03-06 22:43:57,557 - INFO - training batch 401, loss: 0.126, 12832/28000 datapoints
2025-03-06 22:43:57,710 - INFO - training batch 451, loss: 0.212, 14432/28000 datapoints
2025-03-06 22:43:57,899 - INFO - training batch 501, loss: 0.083, 16032/28000 datapoints
2025-03-06 22:43:58,061 - INFO - training batch 551, loss: 0.107, 17632/28000 datapoints
2025-03-06 22:43:58,217 - INFO - training batch 601, loss: 0.076, 19232/28000 datapoints
2025-03-06 22:43:58,369 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 22:43:58,519 - INFO - training batch 701, loss: 0.102, 22432/28000 datapoints
2025-03-06 22:43:58,672 - INFO - training batch 751, loss: 0.056, 24032/28000 datapoints
2025-03-06 22:43:58,827 - INFO - training batch 801, loss: 0.024, 25632/28000 datapoints
2025-03-06 22:43:58,986 - INFO - training batch 851, loss: 0.113, 27232/28000 datapoints
2025-03-06 22:43:59,062 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 22:43:59,110 - INFO - validation batch 51, loss: 2.213, 1632/6976 datapoints
2025-03-06 22:43:59,157 - INFO - validation batch 101, loss: 0.533, 3232/6976 datapoints
2025-03-06 22:43:59,208 - INFO - validation batch 151, loss: 0.666, 4832/6976 datapoints
2025-03-06 22:43:59,256 - INFO - validation batch 201, loss: 0.925, 6432/6976 datapoints
2025-03-06 22:43:59,272 - INFO - Epoch 359/800 done.
2025-03-06 22:43:59,272 - INFO - Final validation performance:
Loss: 0.886, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:43:59,273 - INFO - Beginning epoch 360/800
2025-03-06 22:43:59,277 - INFO - training batch 1, loss: 0.101, 32/28000 datapoints
2025-03-06 22:43:59,430 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:43:59,584 - INFO - training batch 101, loss: 0.079, 3232/28000 datapoints
2025-03-06 22:43:59,736 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-06 22:43:59,888 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:00,043 - INFO - training batch 251, loss: 0.301, 8032/28000 datapoints
2025-03-06 22:44:00,199 - INFO - training batch 301, loss: 0.403, 9632/28000 datapoints
2025-03-06 22:44:00,351 - INFO - training batch 351, loss: 0.168, 11232/28000 datapoints
2025-03-06 22:44:00,502 - INFO - training batch 401, loss: 0.125, 12832/28000 datapoints
2025-03-06 22:44:00,657 - INFO - training batch 451, loss: 0.211, 14432/28000 datapoints
2025-03-06 22:44:00,812 - INFO - training batch 501, loss: 0.082, 16032/28000 datapoints
2025-03-06 22:44:00,970 - INFO - training batch 551, loss: 0.106, 17632/28000 datapoints
2025-03-06 22:44:01,123 - INFO - training batch 601, loss: 0.074, 19232/28000 datapoints
2025-03-06 22:44:01,274 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 22:44:01,425 - INFO - training batch 701, loss: 0.099, 22432/28000 datapoints
2025-03-06 22:44:01,579 - INFO - training batch 751, loss: 0.055, 24032/28000 datapoints
2025-03-06 22:44:01,731 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-06 22:44:01,884 - INFO - training batch 851, loss: 0.113, 27232/28000 datapoints
2025-03-06 22:44:01,963 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 22:44:02,019 - INFO - validation batch 51, loss: 2.226, 1632/6976 datapoints
2025-03-06 22:44:02,074 - INFO - validation batch 101, loss: 0.533, 3232/6976 datapoints
2025-03-06 22:44:02,125 - INFO - validation batch 151, loss: 0.674, 4832/6976 datapoints
2025-03-06 22:44:02,176 - INFO - validation batch 201, loss: 0.931, 6432/6976 datapoints
2025-03-06 22:44:02,193 - INFO - Epoch 360/800 done.
2025-03-06 22:44:02,193 - INFO - Final validation performance:
Loss: 0.892, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:44:02,194 - INFO - Beginning epoch 361/800
2025-03-06 22:44:02,199 - INFO - training batch 1, loss: 0.100, 32/28000 datapoints
2025-03-06 22:44:02,366 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:02,526 - INFO - training batch 101, loss: 0.079, 3232/28000 datapoints
2025-03-06 22:44:02,686 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-06 22:44:02,840 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:03,006 - INFO - training batch 251, loss: 0.298, 8032/28000 datapoints
2025-03-06 22:44:03,161 - INFO - training batch 301, loss: 0.402, 9632/28000 datapoints
2025-03-06 22:44:03,318 - INFO - training batch 351, loss: 0.165, 11232/28000 datapoints
2025-03-06 22:44:03,489 - INFO - training batch 401, loss: 0.124, 12832/28000 datapoints
2025-03-06 22:44:03,647 - INFO - training batch 451, loss: 0.209, 14432/28000 datapoints
2025-03-06 22:44:03,815 - INFO - training batch 501, loss: 0.082, 16032/28000 datapoints
2025-03-06 22:44:03,978 - INFO - training batch 551, loss: 0.104, 17632/28000 datapoints
2025-03-06 22:44:04,134 - INFO - training batch 601, loss: 0.073, 19232/28000 datapoints
2025-03-06 22:44:04,292 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 22:44:04,447 - INFO - training batch 701, loss: 0.098, 22432/28000 datapoints
2025-03-06 22:44:04,606 - INFO - training batch 751, loss: 0.054, 24032/28000 datapoints
2025-03-06 22:44:04,765 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-06 22:44:04,921 - INFO - training batch 851, loss: 0.111, 27232/28000 datapoints
2025-03-06 22:44:05,005 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 22:44:05,056 - INFO - validation batch 51, loss: 2.238, 1632/6976 datapoints
2025-03-06 22:44:05,108 - INFO - validation batch 101, loss: 0.535, 3232/6976 datapoints
2025-03-06 22:44:05,162 - INFO - validation batch 151, loss: 0.678, 4832/6976 datapoints
2025-03-06 22:44:05,221 - INFO - validation batch 201, loss: 0.935, 6432/6976 datapoints
2025-03-06 22:44:05,238 - INFO - Epoch 361/800 done.
2025-03-06 22:44:05,239 - INFO - Final validation performance:
Loss: 0.896, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:44:05,239 - INFO - Beginning epoch 362/800
2025-03-06 22:44:05,245 - INFO - training batch 1, loss: 0.099, 32/28000 datapoints
2025-03-06 22:44:05,402 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:05,553 - INFO - training batch 101, loss: 0.077, 3232/28000 datapoints
2025-03-06 22:44:05,714 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-06 22:44:05,874 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:06,029 - INFO - training batch 251, loss: 0.293, 8032/28000 datapoints
2025-03-06 22:44:06,182 - INFO - training batch 301, loss: 0.399, 9632/28000 datapoints
2025-03-06 22:44:06,333 - INFO - training batch 351, loss: 0.164, 11232/28000 datapoints
2025-03-06 22:44:06,485 - INFO - training batch 401, loss: 0.124, 12832/28000 datapoints
2025-03-06 22:44:06,637 - INFO - training batch 451, loss: 0.208, 14432/28000 datapoints
2025-03-06 22:44:06,792 - INFO - training batch 501, loss: 0.081, 16032/28000 datapoints
2025-03-06 22:44:06,944 - INFO - training batch 551, loss: 0.102, 17632/28000 datapoints
2025-03-06 22:44:07,103 - INFO - training batch 601, loss: 0.071, 19232/28000 datapoints
2025-03-06 22:44:07,255 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 22:44:07,406 - INFO - training batch 701, loss: 0.095, 22432/28000 datapoints
2025-03-06 22:44:07,558 - INFO - training batch 751, loss: 0.053, 24032/28000 datapoints
2025-03-06 22:44:07,711 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-06 22:44:07,868 - INFO - training batch 851, loss: 0.110, 27232/28000 datapoints
2025-03-06 22:44:07,968 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 22:44:08,019 - INFO - validation batch 51, loss: 2.251, 1632/6976 datapoints
2025-03-06 22:44:08,067 - INFO - validation batch 101, loss: 0.535, 3232/6976 datapoints
2025-03-06 22:44:08,114 - INFO - validation batch 151, loss: 0.679, 4832/6976 datapoints
2025-03-06 22:44:08,161 - INFO - validation batch 201, loss: 0.940, 6432/6976 datapoints
2025-03-06 22:44:08,179 - INFO - Epoch 362/800 done.
2025-03-06 22:44:08,180 - INFO - Final validation performance:
Loss: 0.900, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:44:08,180 - INFO - Beginning epoch 363/800
2025-03-06 22:44:08,185 - INFO - training batch 1, loss: 0.097, 32/28000 datapoints
2025-03-06 22:44:08,339 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:08,493 - INFO - training batch 101, loss: 0.076, 3232/28000 datapoints
2025-03-06 22:44:08,643 - INFO - training batch 151, loss: 0.041, 4832/28000 datapoints
2025-03-06 22:44:08,797 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:08,949 - INFO - training batch 251, loss: 0.292, 8032/28000 datapoints
2025-03-06 22:44:09,107 - INFO - training batch 301, loss: 0.396, 9632/28000 datapoints
2025-03-06 22:44:09,259 - INFO - training batch 351, loss: 0.164, 11232/28000 datapoints
2025-03-06 22:44:09,420 - INFO - training batch 401, loss: 0.123, 12832/28000 datapoints
2025-03-06 22:44:09,585 - INFO - training batch 451, loss: 0.207, 14432/28000 datapoints
2025-03-06 22:44:09,740 - INFO - training batch 501, loss: 0.080, 16032/28000 datapoints
2025-03-06 22:44:09,894 - INFO - training batch 551, loss: 0.100, 17632/28000 datapoints
2025-03-06 22:44:10,057 - INFO - training batch 601, loss: 0.071, 19232/28000 datapoints
2025-03-06 22:44:10,217 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 22:44:10,374 - INFO - training batch 701, loss: 0.091, 22432/28000 datapoints
2025-03-06 22:44:10,530 - INFO - training batch 751, loss: 0.054, 24032/28000 datapoints
2025-03-06 22:44:10,682 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-06 22:44:10,837 - INFO - training batch 851, loss: 0.107, 27232/28000 datapoints
2025-03-06 22:44:10,912 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 22:44:10,965 - INFO - validation batch 51, loss: 2.264, 1632/6976 datapoints
2025-03-06 22:44:11,026 - INFO - validation batch 101, loss: 0.537, 3232/6976 datapoints
2025-03-06 22:44:11,084 - INFO - validation batch 151, loss: 0.683, 4832/6976 datapoints
2025-03-06 22:44:11,150 - INFO - validation batch 201, loss: 0.945, 6432/6976 datapoints
2025-03-06 22:44:11,167 - INFO - Epoch 363/800 done.
2025-03-06 22:44:11,167 - INFO - Final validation performance:
Loss: 0.904, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:44:11,168 - INFO - Beginning epoch 364/800
2025-03-06 22:44:11,173 - INFO - training batch 1, loss: 0.095, 32/28000 datapoints
2025-03-06 22:44:11,332 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:11,486 - INFO - training batch 101, loss: 0.076, 3232/28000 datapoints
2025-03-06 22:44:11,638 - INFO - training batch 151, loss: 0.039, 4832/28000 datapoints
2025-03-06 22:44:11,793 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:11,945 - INFO - training batch 251, loss: 0.287, 8032/28000 datapoints
2025-03-06 22:44:12,101 - INFO - training batch 301, loss: 0.395, 9632/28000 datapoints
2025-03-06 22:44:12,256 - INFO - training batch 351, loss: 0.163, 11232/28000 datapoints
2025-03-06 22:44:12,412 - INFO - training batch 401, loss: 0.121, 12832/28000 datapoints
2025-03-06 22:44:12,563 - INFO - training batch 451, loss: 0.206, 14432/28000 datapoints
2025-03-06 22:44:12,716 - INFO - training batch 501, loss: 0.080, 16032/28000 datapoints
2025-03-06 22:44:12,870 - INFO - training batch 551, loss: 0.098, 17632/28000 datapoints
2025-03-06 22:44:13,032 - INFO - training batch 601, loss: 0.070, 19232/28000 datapoints
2025-03-06 22:44:13,183 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 22:44:13,336 - INFO - training batch 701, loss: 0.092, 22432/28000 datapoints
2025-03-06 22:44:13,488 - INFO - training batch 751, loss: 0.051, 24032/28000 datapoints
2025-03-06 22:44:13,640 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-06 22:44:13,793 - INFO - training batch 851, loss: 0.105, 27232/28000 datapoints
2025-03-06 22:44:13,868 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 22:44:13,915 - INFO - validation batch 51, loss: 2.278, 1632/6976 datapoints
2025-03-06 22:44:13,965 - INFO - validation batch 101, loss: 0.537, 3232/6976 datapoints
2025-03-06 22:44:14,013 - INFO - validation batch 151, loss: 0.684, 4832/6976 datapoints
2025-03-06 22:44:14,060 - INFO - validation batch 201, loss: 0.949, 6432/6976 datapoints
2025-03-06 22:44:14,077 - INFO - Epoch 364/800 done.
2025-03-06 22:44:14,077 - INFO - Final validation performance:
Loss: 0.909, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:44:14,077 - INFO - Beginning epoch 365/800
2025-03-06 22:44:14,082 - INFO - training batch 1, loss: 0.094, 32/28000 datapoints
2025-03-06 22:44:14,235 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:14,402 - INFO - training batch 101, loss: 0.075, 3232/28000 datapoints
2025-03-06 22:44:14,554 - INFO - training batch 151, loss: 0.039, 4832/28000 datapoints
2025-03-06 22:44:14,707 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:14,861 - INFO - training batch 251, loss: 0.286, 8032/28000 datapoints
2025-03-06 22:44:15,019 - INFO - training batch 301, loss: 0.391, 9632/28000 datapoints
2025-03-06 22:44:15,170 - INFO - training batch 351, loss: 0.161, 11232/28000 datapoints
2025-03-06 22:44:15,328 - INFO - training batch 401, loss: 0.122, 12832/28000 datapoints
2025-03-06 22:44:15,480 - INFO - training batch 451, loss: 0.205, 14432/28000 datapoints
2025-03-06 22:44:15,653 - INFO - training batch 501, loss: 0.079, 16032/28000 datapoints
2025-03-06 22:44:15,809 - INFO - training batch 551, loss: 0.097, 17632/28000 datapoints
2025-03-06 22:44:15,965 - INFO - training batch 601, loss: 0.068, 19232/28000 datapoints
2025-03-06 22:44:16,127 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 22:44:16,282 - INFO - training batch 701, loss: 0.087, 22432/28000 datapoints
2025-03-06 22:44:16,435 - INFO - training batch 751, loss: 0.052, 24032/28000 datapoints
2025-03-06 22:44:16,595 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-06 22:44:16,747 - INFO - training batch 851, loss: 0.104, 27232/28000 datapoints
2025-03-06 22:44:16,824 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 22:44:16,871 - INFO - validation batch 51, loss: 2.290, 1632/6976 datapoints
2025-03-06 22:44:16,918 - INFO - validation batch 101, loss: 0.538, 3232/6976 datapoints
2025-03-06 22:44:16,971 - INFO - validation batch 151, loss: 0.686, 4832/6976 datapoints
2025-03-06 22:44:17,021 - INFO - validation batch 201, loss: 0.956, 6432/6976 datapoints
2025-03-06 22:44:17,037 - INFO - Epoch 365/800 done.
2025-03-06 22:44:17,037 - INFO - Final validation performance:
Loss: 0.913, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:44:17,038 - INFO - Beginning epoch 366/800
2025-03-06 22:44:17,042 - INFO - training batch 1, loss: 0.092, 32/28000 datapoints
2025-03-06 22:44:17,199 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:17,353 - INFO - training batch 101, loss: 0.074, 3232/28000 datapoints
2025-03-06 22:44:17,506 - INFO - training batch 151, loss: 0.038, 4832/28000 datapoints
2025-03-06 22:44:17,660 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:17,814 - INFO - training batch 251, loss: 0.282, 8032/28000 datapoints
2025-03-06 22:44:17,968 - INFO - training batch 301, loss: 0.388, 9632/28000 datapoints
2025-03-06 22:44:18,152 - INFO - training batch 351, loss: 0.161, 11232/28000 datapoints
2025-03-06 22:44:18,306 - INFO - training batch 401, loss: 0.120, 12832/28000 datapoints
2025-03-06 22:44:18,461 - INFO - training batch 451, loss: 0.205, 14432/28000 datapoints
2025-03-06 22:44:18,615 - INFO - training batch 501, loss: 0.078, 16032/28000 datapoints
2025-03-06 22:44:18,768 - INFO - training batch 551, loss: 0.095, 17632/28000 datapoints
2025-03-06 22:44:18,922 - INFO - training batch 601, loss: 0.067, 19232/28000 datapoints
2025-03-06 22:44:19,082 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 22:44:19,233 - INFO - training batch 701, loss: 0.087, 22432/28000 datapoints
2025-03-06 22:44:19,386 - INFO - training batch 751, loss: 0.050, 24032/28000 datapoints
2025-03-06 22:44:19,539 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-06 22:44:19,692 - INFO - training batch 851, loss: 0.103, 27232/28000 datapoints
2025-03-06 22:44:19,772 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 22:44:19,821 - INFO - validation batch 51, loss: 2.302, 1632/6976 datapoints
2025-03-06 22:44:19,869 - INFO - validation batch 101, loss: 0.536, 3232/6976 datapoints
2025-03-06 22:44:19,916 - INFO - validation batch 151, loss: 0.693, 4832/6976 datapoints
2025-03-06 22:44:19,967 - INFO - validation batch 201, loss: 0.960, 6432/6976 datapoints
2025-03-06 22:44:19,984 - INFO - Epoch 366/800 done.
2025-03-06 22:44:19,984 - INFO - Final validation performance:
Loss: 0.917, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:44:19,984 - INFO - Beginning epoch 367/800
2025-03-06 22:44:19,989 - INFO - training batch 1, loss: 0.092, 32/28000 datapoints
2025-03-06 22:44:20,144 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:20,299 - INFO - training batch 101, loss: 0.072, 3232/28000 datapoints
2025-03-06 22:44:20,453 - INFO - training batch 151, loss: 0.038, 4832/28000 datapoints
2025-03-06 22:44:20,606 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:20,759 - INFO - training batch 251, loss: 0.279, 8032/28000 datapoints
2025-03-06 22:44:20,913 - INFO - training batch 301, loss: 0.385, 9632/28000 datapoints
2025-03-06 22:44:21,079 - INFO - training batch 351, loss: 0.159, 11232/28000 datapoints
2025-03-06 22:44:21,231 - INFO - training batch 401, loss: 0.120, 12832/28000 datapoints
2025-03-06 22:44:21,385 - INFO - training batch 451, loss: 0.203, 14432/28000 datapoints
2025-03-06 22:44:21,539 - INFO - training batch 501, loss: 0.078, 16032/28000 datapoints
2025-03-06 22:44:21,709 - INFO - training batch 551, loss: 0.093, 17632/28000 datapoints
2025-03-06 22:44:21,864 - INFO - training batch 601, loss: 0.066, 19232/28000 datapoints
2025-03-06 22:44:22,019 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 22:44:22,180 - INFO - training batch 701, loss: 0.084, 22432/28000 datapoints
2025-03-06 22:44:22,348 - INFO - training batch 751, loss: 0.050, 24032/28000 datapoints
2025-03-06 22:44:22,509 - INFO - training batch 801, loss: 0.021, 25632/28000 datapoints
2025-03-06 22:44:22,663 - INFO - training batch 851, loss: 0.101, 27232/28000 datapoints
2025-03-06 22:44:22,741 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 22:44:22,793 - INFO - validation batch 51, loss: 2.317, 1632/6976 datapoints
2025-03-06 22:44:22,845 - INFO - validation batch 101, loss: 0.538, 3232/6976 datapoints
2025-03-06 22:44:22,896 - INFO - validation batch 151, loss: 0.697, 4832/6976 datapoints
2025-03-06 22:44:22,948 - INFO - validation batch 201, loss: 0.965, 6432/6976 datapoints
2025-03-06 22:44:22,970 - INFO - Epoch 367/800 done.
2025-03-06 22:44:22,970 - INFO - Final validation performance:
Loss: 0.922, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:44:22,971 - INFO - Beginning epoch 368/800
2025-03-06 22:44:22,975 - INFO - training batch 1, loss: 0.090, 32/28000 datapoints
2025-03-06 22:44:23,142 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:23,299 - INFO - training batch 101, loss: 0.072, 3232/28000 datapoints
2025-03-06 22:44:23,458 - INFO - training batch 151, loss: 0.037, 4832/28000 datapoints
2025-03-06 22:44:23,614 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:23,771 - INFO - training batch 251, loss: 0.276, 8032/28000 datapoints
2025-03-06 22:44:23,930 - INFO - training batch 301, loss: 0.384, 9632/28000 datapoints
2025-03-06 22:44:24,089 - INFO - training batch 351, loss: 0.157, 11232/28000 datapoints
2025-03-06 22:44:24,246 - INFO - training batch 401, loss: 0.117, 12832/28000 datapoints
2025-03-06 22:44:24,401 - INFO - training batch 451, loss: 0.203, 14432/28000 datapoints
2025-03-06 22:44:24,559 - INFO - training batch 501, loss: 0.078, 16032/28000 datapoints
2025-03-06 22:44:24,716 - INFO - training batch 551, loss: 0.091, 17632/28000 datapoints
2025-03-06 22:44:24,877 - INFO - training batch 601, loss: 0.066, 19232/28000 datapoints
2025-03-06 22:44:25,034 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 22:44:25,196 - INFO - training batch 701, loss: 0.082, 22432/28000 datapoints
2025-03-06 22:44:25,355 - INFO - training batch 751, loss: 0.049, 24032/28000 datapoints
2025-03-06 22:44:25,513 - INFO - training batch 801, loss: 0.021, 25632/28000 datapoints
2025-03-06 22:44:25,672 - INFO - training batch 851, loss: 0.100, 27232/28000 datapoints
2025-03-06 22:44:25,755 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 22:44:25,809 - INFO - validation batch 51, loss: 2.333, 1632/6976 datapoints
2025-03-06 22:44:25,875 - INFO - validation batch 101, loss: 0.540, 3232/6976 datapoints
2025-03-06 22:44:25,944 - INFO - validation batch 151, loss: 0.702, 4832/6976 datapoints
2025-03-06 22:44:26,000 - INFO - validation batch 201, loss: 0.971, 6432/6976 datapoints
2025-03-06 22:44:26,018 - INFO - Epoch 368/800 done.
2025-03-06 22:44:26,018 - INFO - Final validation performance:
Loss: 0.928, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:44:26,019 - INFO - Beginning epoch 369/800
2025-03-06 22:44:26,023 - INFO - training batch 1, loss: 0.089, 32/28000 datapoints
2025-03-06 22:44:26,181 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:26,337 - INFO - training batch 101, loss: 0.071, 3232/28000 datapoints
2025-03-06 22:44:26,496 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-06 22:44:26,653 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:26,810 - INFO - training batch 251, loss: 0.273, 8032/28000 datapoints
2025-03-06 22:44:26,968 - INFO - training batch 301, loss: 0.381, 9632/28000 datapoints
2025-03-06 22:44:27,136 - INFO - training batch 351, loss: 0.156, 11232/28000 datapoints
2025-03-06 22:44:27,292 - INFO - training batch 401, loss: 0.117, 12832/28000 datapoints
2025-03-06 22:44:27,449 - INFO - training batch 451, loss: 0.201, 14432/28000 datapoints
2025-03-06 22:44:27,608 - INFO - training batch 501, loss: 0.076, 16032/28000 datapoints
2025-03-06 22:44:27,778 - INFO - training batch 551, loss: 0.089, 17632/28000 datapoints
2025-03-06 22:44:27,940 - INFO - training batch 601, loss: 0.063, 19232/28000 datapoints
2025-03-06 22:44:28,100 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 22:44:28,290 - INFO - training batch 701, loss: 0.081, 22432/28000 datapoints
2025-03-06 22:44:28,451 - INFO - training batch 751, loss: 0.048, 24032/28000 datapoints
2025-03-06 22:44:28,611 - INFO - training batch 801, loss: 0.021, 25632/28000 datapoints
2025-03-06 22:44:28,767 - INFO - training batch 851, loss: 0.098, 27232/28000 datapoints
2025-03-06 22:44:28,848 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 22:44:28,900 - INFO - validation batch 51, loss: 2.345, 1632/6976 datapoints
2025-03-06 22:44:28,953 - INFO - validation batch 101, loss: 0.540, 3232/6976 datapoints
2025-03-06 22:44:29,008 - INFO - validation batch 151, loss: 0.705, 4832/6976 datapoints
2025-03-06 22:44:29,060 - INFO - validation batch 201, loss: 0.976, 6432/6976 datapoints
2025-03-06 22:44:29,079 - INFO - Epoch 369/800 done.
2025-03-06 22:44:29,079 - INFO - Final validation performance:
Loss: 0.932, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:44:29,080 - INFO - Beginning epoch 370/800
2025-03-06 22:44:29,084 - INFO - training batch 1, loss: 0.088, 32/28000 datapoints
2025-03-06 22:44:29,243 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:29,399 - INFO - training batch 101, loss: 0.070, 3232/28000 datapoints
2025-03-06 22:44:29,559 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-06 22:44:29,718 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:29,875 - INFO - training batch 251, loss: 0.270, 8032/28000 datapoints
2025-03-06 22:44:30,034 - INFO - training batch 301, loss: 0.377, 9632/28000 datapoints
2025-03-06 22:44:30,193 - INFO - training batch 351, loss: 0.155, 11232/28000 datapoints
2025-03-06 22:44:30,348 - INFO - training batch 401, loss: 0.115, 12832/28000 datapoints
2025-03-06 22:44:30,506 - INFO - training batch 451, loss: 0.201, 14432/28000 datapoints
2025-03-06 22:44:30,663 - INFO - training batch 501, loss: 0.076, 16032/28000 datapoints
2025-03-06 22:44:30,819 - INFO - training batch 551, loss: 0.089, 17632/28000 datapoints
2025-03-06 22:44:30,981 - INFO - training batch 601, loss: 0.062, 19232/28000 datapoints
2025-03-06 22:44:31,140 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 22:44:31,294 - INFO - training batch 701, loss: 0.078, 22432/28000 datapoints
2025-03-06 22:44:31,451 - INFO - training batch 751, loss: 0.049, 24032/28000 datapoints
2025-03-06 22:44:31,608 - INFO - training batch 801, loss: 0.021, 25632/28000 datapoints
2025-03-06 22:44:31,763 - INFO - training batch 851, loss: 0.096, 27232/28000 datapoints
2025-03-06 22:44:31,842 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 22:44:31,895 - INFO - validation batch 51, loss: 2.359, 1632/6976 datapoints
2025-03-06 22:44:31,949 - INFO - validation batch 101, loss: 0.540, 3232/6976 datapoints
2025-03-06 22:44:32,004 - INFO - validation batch 151, loss: 0.704, 4832/6976 datapoints
2025-03-06 22:44:32,055 - INFO - validation batch 201, loss: 0.982, 6432/6976 datapoints
2025-03-06 22:44:32,071 - INFO - Epoch 370/800 done.
2025-03-06 22:44:32,071 - INFO - Final validation performance:
Loss: 0.936, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:44:32,072 - INFO - Beginning epoch 371/800
2025-03-06 22:44:32,077 - INFO - training batch 1, loss: 0.086, 32/28000 datapoints
2025-03-06 22:44:32,240 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:32,403 - INFO - training batch 101, loss: 0.070, 3232/28000 datapoints
2025-03-06 22:44:32,559 - INFO - training batch 151, loss: 0.035, 4832/28000 datapoints
2025-03-06 22:44:32,717 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:32,872 - INFO - training batch 251, loss: 0.267, 8032/28000 datapoints
2025-03-06 22:44:33,090 - INFO - training batch 301, loss: 0.377, 9632/28000 datapoints
2025-03-06 22:44:33,253 - INFO - training batch 351, loss: 0.153, 11232/28000 datapoints
2025-03-06 22:44:33,422 - INFO - training batch 401, loss: 0.115, 12832/28000 datapoints
2025-03-06 22:44:33,582 - INFO - training batch 451, loss: 0.200, 14432/28000 datapoints
2025-03-06 22:44:33,743 - INFO - training batch 501, loss: 0.075, 16032/28000 datapoints
2025-03-06 22:44:33,912 - INFO - training batch 551, loss: 0.086, 17632/28000 datapoints
2025-03-06 22:44:34,076 - INFO - training batch 601, loss: 0.062, 19232/28000 datapoints
2025-03-06 22:44:34,233 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 22:44:34,503 - INFO - training batch 701, loss: 0.078, 22432/28000 datapoints
2025-03-06 22:44:34,666 - INFO - training batch 751, loss: 0.046, 24032/28000 datapoints
2025-03-06 22:44:34,825 - INFO - training batch 801, loss: 0.021, 25632/28000 datapoints
2025-03-06 22:44:34,985 - INFO - training batch 851, loss: 0.095, 27232/28000 datapoints
2025-03-06 22:44:35,069 - INFO - validation batch 1, loss: 0.099, 32/6976 datapoints
2025-03-06 22:44:35,123 - INFO - validation batch 51, loss: 2.371, 1632/6976 datapoints
2025-03-06 22:44:35,175 - INFO - validation batch 101, loss: 0.544, 3232/6976 datapoints
2025-03-06 22:44:35,233 - INFO - validation batch 151, loss: 0.712, 4832/6976 datapoints
2025-03-06 22:44:35,288 - INFO - validation batch 201, loss: 0.987, 6432/6976 datapoints
2025-03-06 22:44:35,308 - INFO - Epoch 371/800 done.
2025-03-06 22:44:35,308 - INFO - Final validation performance:
Loss: 0.942, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:44:35,309 - INFO - Beginning epoch 372/800
2025-03-06 22:44:35,313 - INFO - training batch 1, loss: 0.086, 32/28000 datapoints
2025-03-06 22:44:35,476 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:35,633 - INFO - training batch 101, loss: 0.068, 3232/28000 datapoints
2025-03-06 22:44:35,792 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-06 22:44:35,953 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:36,117 - INFO - training batch 251, loss: 0.264, 8032/28000 datapoints
2025-03-06 22:44:36,273 - INFO - training batch 301, loss: 0.373, 9632/28000 datapoints
2025-03-06 22:44:36,429 - INFO - training batch 351, loss: 0.153, 11232/28000 datapoints
2025-03-06 22:44:36,587 - INFO - training batch 401, loss: 0.113, 12832/28000 datapoints
2025-03-06 22:44:36,743 - INFO - training batch 451, loss: 0.198, 14432/28000 datapoints
2025-03-06 22:44:36,901 - INFO - training batch 501, loss: 0.074, 16032/28000 datapoints
2025-03-06 22:44:37,061 - INFO - training batch 551, loss: 0.085, 17632/28000 datapoints
2025-03-06 22:44:37,222 - INFO - training batch 601, loss: 0.060, 19232/28000 datapoints
2025-03-06 22:44:37,378 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 22:44:37,532 - INFO - training batch 701, loss: 0.075, 22432/28000 datapoints
2025-03-06 22:44:37,688 - INFO - training batch 751, loss: 0.046, 24032/28000 datapoints
2025-03-06 22:44:37,843 - INFO - training batch 801, loss: 0.020, 25632/28000 datapoints
2025-03-06 22:44:38,012 - INFO - training batch 851, loss: 0.095, 27232/28000 datapoints
2025-03-06 22:44:38,092 - INFO - validation batch 1, loss: 0.099, 32/6976 datapoints
2025-03-06 22:44:38,139 - INFO - validation batch 51, loss: 2.384, 1632/6976 datapoints
2025-03-06 22:44:38,187 - INFO - validation batch 101, loss: 0.544, 3232/6976 datapoints
2025-03-06 22:44:38,254 - INFO - validation batch 151, loss: 0.717, 4832/6976 datapoints
2025-03-06 22:44:38,316 - INFO - validation batch 201, loss: 0.993, 6432/6976 datapoints
2025-03-06 22:44:38,332 - INFO - Epoch 372/800 done.
2025-03-06 22:44:38,332 - INFO - Final validation performance:
Loss: 0.947, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:44:38,333 - INFO - Beginning epoch 373/800
2025-03-06 22:44:38,337 - INFO - training batch 1, loss: 0.084, 32/28000 datapoints
2025-03-06 22:44:38,492 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:38,648 - INFO - training batch 101, loss: 0.067, 3232/28000 datapoints
2025-03-06 22:44:38,801 - INFO - training batch 151, loss: 0.033, 4832/28000 datapoints
2025-03-06 22:44:38,952 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:39,112 - INFO - training batch 251, loss: 0.260, 8032/28000 datapoints
2025-03-06 22:44:39,265 - INFO - training batch 301, loss: 0.370, 9632/28000 datapoints
2025-03-06 22:44:39,423 - INFO - training batch 351, loss: 0.152, 11232/28000 datapoints
2025-03-06 22:44:39,575 - INFO - training batch 401, loss: 0.112, 12832/28000 datapoints
2025-03-06 22:44:39,728 - INFO - training batch 451, loss: 0.198, 14432/28000 datapoints
2025-03-06 22:44:39,882 - INFO - training batch 501, loss: 0.073, 16032/28000 datapoints
2025-03-06 22:44:40,055 - INFO - training batch 551, loss: 0.083, 17632/28000 datapoints
2025-03-06 22:44:40,208 - INFO - training batch 601, loss: 0.059, 19232/28000 datapoints
2025-03-06 22:44:40,361 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 22:44:40,522 - INFO - training batch 701, loss: 0.072, 22432/28000 datapoints
2025-03-06 22:44:40,680 - INFO - training batch 751, loss: 0.046, 24032/28000 datapoints
2025-03-06 22:44:40,836 - INFO - training batch 801, loss: 0.020, 25632/28000 datapoints
2025-03-06 22:44:40,994 - INFO - training batch 851, loss: 0.092, 27232/28000 datapoints
2025-03-06 22:44:41,070 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 22:44:41,122 - INFO - validation batch 51, loss: 2.396, 1632/6976 datapoints
2025-03-06 22:44:41,171 - INFO - validation batch 101, loss: 0.544, 3232/6976 datapoints
2025-03-06 22:44:41,219 - INFO - validation batch 151, loss: 0.719, 4832/6976 datapoints
2025-03-06 22:44:41,266 - INFO - validation batch 201, loss: 1.000, 6432/6976 datapoints
2025-03-06 22:44:41,283 - INFO - Epoch 373/800 done.
2025-03-06 22:44:41,284 - INFO - Final validation performance:
Loss: 0.951, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 22:44:41,284 - INFO - Beginning epoch 374/800
2025-03-06 22:44:41,288 - INFO - training batch 1, loss: 0.083, 32/28000 datapoints
2025-03-06 22:44:41,444 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:41,601 - INFO - training batch 101, loss: 0.066, 3232/28000 datapoints
2025-03-06 22:44:41,754 - INFO - training batch 151, loss: 0.033, 4832/28000 datapoints
2025-03-06 22:44:41,907 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:42,063 - INFO - training batch 251, loss: 0.257, 8032/28000 datapoints
2025-03-06 22:44:42,215 - INFO - training batch 301, loss: 0.368, 9632/28000 datapoints
2025-03-06 22:44:42,368 - INFO - training batch 351, loss: 0.151, 11232/28000 datapoints
2025-03-06 22:44:42,532 - INFO - training batch 401, loss: 0.111, 12832/28000 datapoints
2025-03-06 22:44:42,691 - INFO - training batch 451, loss: 0.196, 14432/28000 datapoints
2025-03-06 22:44:42,847 - INFO - training batch 501, loss: 0.073, 16032/28000 datapoints
2025-03-06 22:44:43,006 - INFO - training batch 551, loss: 0.083, 17632/28000 datapoints
2025-03-06 22:44:43,165 - INFO - training batch 601, loss: 0.059, 19232/28000 datapoints
2025-03-06 22:44:43,322 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 22:44:43,479 - INFO - training batch 701, loss: 0.072, 22432/28000 datapoints
2025-03-06 22:44:43,636 - INFO - training batch 751, loss: 0.044, 24032/28000 datapoints
2025-03-06 22:44:43,791 - INFO - training batch 801, loss: 0.020, 25632/28000 datapoints
2025-03-06 22:44:43,948 - INFO - training batch 851, loss: 0.090, 27232/28000 datapoints
2025-03-06 22:44:44,031 - INFO - validation batch 1, loss: 0.100, 32/6976 datapoints
2025-03-06 22:44:44,082 - INFO - validation batch 51, loss: 2.409, 1632/6976 datapoints
2025-03-06 22:44:44,137 - INFO - validation batch 101, loss: 0.544, 3232/6976 datapoints
2025-03-06 22:44:44,190 - INFO - validation batch 151, loss: 0.724, 4832/6976 datapoints
2025-03-06 22:44:44,241 - INFO - validation batch 201, loss: 1.005, 6432/6976 datapoints
2025-03-06 22:44:44,262 - INFO - Epoch 374/800 done.
2025-03-06 22:44:44,263 - INFO - Final validation performance:
Loss: 0.956, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:44:44,263 - INFO - Beginning epoch 375/800
2025-03-06 22:44:44,267 - INFO - training batch 1, loss: 0.082, 32/28000 datapoints
2025-03-06 22:44:44,425 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:44,581 - INFO - training batch 101, loss: 0.066, 3232/28000 datapoints
2025-03-06 22:44:44,739 - INFO - training batch 151, loss: 0.033, 4832/28000 datapoints
2025-03-06 22:44:44,897 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:45,056 - INFO - training batch 251, loss: 0.254, 8032/28000 datapoints
2025-03-06 22:44:45,216 - INFO - training batch 301, loss: 0.363, 9632/28000 datapoints
2025-03-06 22:44:45,379 - INFO - training batch 351, loss: 0.151, 11232/28000 datapoints
2025-03-06 22:44:45,535 - INFO - training batch 401, loss: 0.110, 12832/28000 datapoints
2025-03-06 22:44:45,695 - INFO - training batch 451, loss: 0.194, 14432/28000 datapoints
2025-03-06 22:44:45,853 - INFO - training batch 501, loss: 0.072, 16032/28000 datapoints
2025-03-06 22:44:46,013 - INFO - training batch 551, loss: 0.081, 17632/28000 datapoints
2025-03-06 22:44:46,183 - INFO - training batch 601, loss: 0.057, 19232/28000 datapoints
2025-03-06 22:44:46,339 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:44:46,494 - INFO - training batch 701, loss: 0.070, 22432/28000 datapoints
2025-03-06 22:44:46,661 - INFO - training batch 751, loss: 0.044, 24032/28000 datapoints
2025-03-06 22:44:46,821 - INFO - training batch 801, loss: 0.020, 25632/28000 datapoints
2025-03-06 22:44:46,979 - INFO - training batch 851, loss: 0.090, 27232/28000 datapoints
2025-03-06 22:44:47,061 - INFO - validation batch 1, loss: 0.100, 32/6976 datapoints
2025-03-06 22:44:47,113 - INFO - validation batch 51, loss: 2.419, 1632/6976 datapoints
2025-03-06 22:44:47,168 - INFO - validation batch 101, loss: 0.548, 3232/6976 datapoints
2025-03-06 22:44:47,221 - INFO - validation batch 151, loss: 0.731, 4832/6976 datapoints
2025-03-06 22:44:47,275 - INFO - validation batch 201, loss: 1.016, 6432/6976 datapoints
2025-03-06 22:44:47,294 - INFO - Epoch 375/800 done.
2025-03-06 22:44:47,294 - INFO - Final validation performance:
Loss: 0.963, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:44:47,295 - INFO - Beginning epoch 376/800
2025-03-06 22:44:47,300 - INFO - training batch 1, loss: 0.081, 32/28000 datapoints
2025-03-06 22:44:47,457 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:47,611 - INFO - training batch 101, loss: 0.065, 3232/28000 datapoints
2025-03-06 22:44:47,767 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-06 22:44:47,919 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:48,075 - INFO - training batch 251, loss: 0.252, 8032/28000 datapoints
2025-03-06 22:44:48,230 - INFO - training batch 301, loss: 0.360, 9632/28000 datapoints
2025-03-06 22:44:48,410 - INFO - training batch 351, loss: 0.147, 11232/28000 datapoints
2025-03-06 22:44:48,561 - INFO - training batch 401, loss: 0.108, 12832/28000 datapoints
2025-03-06 22:44:48,716 - INFO - training batch 451, loss: 0.194, 14432/28000 datapoints
2025-03-06 22:44:48,869 - INFO - training batch 501, loss: 0.070, 16032/28000 datapoints
2025-03-06 22:44:49,025 - INFO - training batch 551, loss: 0.080, 17632/28000 datapoints
2025-03-06 22:44:49,181 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-06 22:44:49,334 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:44:49,488 - INFO - training batch 701, loss: 0.069, 22432/28000 datapoints
2025-03-06 22:44:49,640 - INFO - training batch 751, loss: 0.044, 24032/28000 datapoints
2025-03-06 22:44:49,795 - INFO - training batch 801, loss: 0.019, 25632/28000 datapoints
2025-03-06 22:44:49,950 - INFO - training batch 851, loss: 0.087, 27232/28000 datapoints
2025-03-06 22:44:50,029 - INFO - validation batch 1, loss: 0.101, 32/6976 datapoints
2025-03-06 22:44:50,075 - INFO - validation batch 51, loss: 2.435, 1632/6976 datapoints
2025-03-06 22:44:50,123 - INFO - validation batch 101, loss: 0.548, 3232/6976 datapoints
2025-03-06 22:44:50,170 - INFO - validation batch 151, loss: 0.729, 4832/6976 datapoints
2025-03-06 22:44:50,220 - INFO - validation batch 201, loss: 1.018, 6432/6976 datapoints
2025-03-06 22:44:50,238 - INFO - Epoch 376/800 done.
2025-03-06 22:44:50,238 - INFO - Final validation performance:
Loss: 0.966, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:44:50,239 - INFO - Beginning epoch 377/800
2025-03-06 22:44:50,243 - INFO - training batch 1, loss: 0.079, 32/28000 datapoints
2025-03-06 22:44:50,399 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:50,553 - INFO - training batch 101, loss: 0.064, 3232/28000 datapoints
2025-03-06 22:44:50,707 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-06 22:44:50,863 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:44:51,023 - INFO - training batch 251, loss: 0.247, 8032/28000 datapoints
2025-03-06 22:44:51,187 - INFO - training batch 301, loss: 0.359, 9632/28000 datapoints
2025-03-06 22:44:51,342 - INFO - training batch 351, loss: 0.147, 11232/28000 datapoints
2025-03-06 22:44:51,495 - INFO - training batch 401, loss: 0.107, 12832/28000 datapoints
2025-03-06 22:44:51,650 - INFO - training batch 451, loss: 0.194, 14432/28000 datapoints
2025-03-06 22:44:51,805 - INFO - training batch 501, loss: 0.069, 16032/28000 datapoints
2025-03-06 22:44:51,961 - INFO - training batch 551, loss: 0.078, 17632/28000 datapoints
2025-03-06 22:44:52,114 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-06 22:44:52,281 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:44:52,436 - INFO - training batch 701, loss: 0.065, 22432/28000 datapoints
2025-03-06 22:44:52,590 - INFO - training batch 751, loss: 0.044, 24032/28000 datapoints
2025-03-06 22:44:52,747 - INFO - training batch 801, loss: 0.019, 25632/28000 datapoints
2025-03-06 22:44:52,905 - INFO - training batch 851, loss: 0.086, 27232/28000 datapoints
2025-03-06 22:44:52,984 - INFO - validation batch 1, loss: 0.101, 32/6976 datapoints
2025-03-06 22:44:53,031 - INFO - validation batch 51, loss: 2.448, 1632/6976 datapoints
2025-03-06 22:44:53,083 - INFO - validation batch 101, loss: 0.549, 3232/6976 datapoints
2025-03-06 22:44:53,141 - INFO - validation batch 151, loss: 0.734, 4832/6976 datapoints
2025-03-06 22:44:53,193 - INFO - validation batch 201, loss: 1.026, 6432/6976 datapoints
2025-03-06 22:44:53,210 - INFO - Epoch 377/800 done.
2025-03-06 22:44:53,210 - INFO - Final validation performance:
Loss: 0.972, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:44:53,210 - INFO - Beginning epoch 378/800
2025-03-06 22:44:53,215 - INFO - training batch 1, loss: 0.078, 32/28000 datapoints
2025-03-06 22:44:53,371 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:53,524 - INFO - training batch 101, loss: 0.063, 3232/28000 datapoints
2025-03-06 22:44:53,677 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-06 22:44:53,833 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:44:53,988 - INFO - training batch 251, loss: 0.242, 8032/28000 datapoints
2025-03-06 22:44:54,140 - INFO - training batch 301, loss: 0.355, 9632/28000 datapoints
2025-03-06 22:44:54,295 - INFO - training batch 351, loss: 0.146, 11232/28000 datapoints
2025-03-06 22:44:54,450 - INFO - training batch 401, loss: 0.107, 12832/28000 datapoints
2025-03-06 22:44:54,603 - INFO - training batch 451, loss: 0.192, 14432/28000 datapoints
2025-03-06 22:44:54,756 - INFO - training batch 501, loss: 0.069, 16032/28000 datapoints
2025-03-06 22:44:54,911 - INFO - training batch 551, loss: 0.077, 17632/28000 datapoints
2025-03-06 22:44:55,067 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-06 22:44:55,239 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:44:55,394 - INFO - training batch 701, loss: 0.065, 22432/28000 datapoints
2025-03-06 22:44:55,549 - INFO - training batch 751, loss: 0.041, 24032/28000 datapoints
2025-03-06 22:44:55,704 - INFO - training batch 801, loss: 0.019, 25632/28000 datapoints
2025-03-06 22:44:55,859 - INFO - training batch 851, loss: 0.086, 27232/28000 datapoints
2025-03-06 22:44:55,936 - INFO - validation batch 1, loss: 0.102, 32/6976 datapoints
2025-03-06 22:44:55,987 - INFO - validation batch 51, loss: 2.459, 1632/6976 datapoints
2025-03-06 22:44:56,034 - INFO - validation batch 101, loss: 0.549, 3232/6976 datapoints
2025-03-06 22:44:56,081 - INFO - validation batch 151, loss: 0.737, 4832/6976 datapoints
2025-03-06 22:44:56,129 - INFO - validation batch 201, loss: 1.032, 6432/6976 datapoints
2025-03-06 22:44:56,145 - INFO - Epoch 378/800 done.
2025-03-06 22:44:56,145 - INFO - Final validation performance:
Loss: 0.976, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:44:56,146 - INFO - Beginning epoch 379/800
2025-03-06 22:44:56,150 - INFO - training batch 1, loss: 0.078, 32/28000 datapoints
2025-03-06 22:44:56,306 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:56,461 - INFO - training batch 101, loss: 0.062, 3232/28000 datapoints
2025-03-06 22:44:56,629 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-06 22:44:56,785 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:44:56,937 - INFO - training batch 251, loss: 0.240, 8032/28000 datapoints
2025-03-06 22:44:57,094 - INFO - training batch 301, loss: 0.350, 9632/28000 datapoints
2025-03-06 22:44:57,249 - INFO - training batch 351, loss: 0.146, 11232/28000 datapoints
2025-03-06 22:44:57,403 - INFO - training batch 401, loss: 0.106, 12832/28000 datapoints
2025-03-06 22:44:57,556 - INFO - training batch 451, loss: 0.191, 14432/28000 datapoints
2025-03-06 22:44:57,708 - INFO - training batch 501, loss: 0.068, 16032/28000 datapoints
2025-03-06 22:44:57,864 - INFO - training batch 551, loss: 0.075, 17632/28000 datapoints
2025-03-06 22:44:58,018 - INFO - training batch 601, loss: 0.052, 19232/28000 datapoints
2025-03-06 22:44:58,170 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:44:58,324 - INFO - training batch 701, loss: 0.063, 22432/28000 datapoints
2025-03-06 22:44:58,521 - INFO - training batch 751, loss: 0.041, 24032/28000 datapoints
2025-03-06 22:44:58,675 - INFO - training batch 801, loss: 0.019, 25632/28000 datapoints
2025-03-06 22:44:58,828 - INFO - training batch 851, loss: 0.084, 27232/28000 datapoints
2025-03-06 22:44:58,915 - INFO - validation batch 1, loss: 0.103, 32/6976 datapoints
2025-03-06 22:44:58,967 - INFO - validation batch 51, loss: 2.473, 1632/6976 datapoints
2025-03-06 22:44:59,015 - INFO - validation batch 101, loss: 0.548, 3232/6976 datapoints
2025-03-06 22:44:59,069 - INFO - validation batch 151, loss: 0.743, 4832/6976 datapoints
2025-03-06 22:44:59,117 - INFO - validation batch 201, loss: 1.035, 6432/6976 datapoints
2025-03-06 22:44:59,133 - INFO - Epoch 379/800 done.
2025-03-06 22:44:59,133 - INFO - Final validation performance:
Loss: 0.981, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:44:59,134 - INFO - Beginning epoch 380/800
2025-03-06 22:44:59,138 - INFO - training batch 1, loss: 0.076, 32/28000 datapoints
2025-03-06 22:44:59,370 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:44:59,525 - INFO - training batch 101, loss: 0.061, 3232/28000 datapoints
2025-03-06 22:44:59,679 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-06 22:44:59,831 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:00,010 - INFO - training batch 251, loss: 0.237, 8032/28000 datapoints
2025-03-06 22:45:00,172 - INFO - training batch 301, loss: 0.346, 9632/28000 datapoints
2025-03-06 22:45:00,326 - INFO - training batch 351, loss: 0.144, 11232/28000 datapoints
2025-03-06 22:45:00,480 - INFO - training batch 401, loss: 0.103, 12832/28000 datapoints
2025-03-06 22:45:00,632 - INFO - training batch 451, loss: 0.191, 14432/28000 datapoints
2025-03-06 22:45:00,788 - INFO - training batch 501, loss: 0.067, 16032/28000 datapoints
2025-03-06 22:45:00,944 - INFO - training batch 551, loss: 0.074, 17632/28000 datapoints
2025-03-06 22:45:01,101 - INFO - training batch 601, loss: 0.050, 19232/28000 datapoints
2025-03-06 22:45:01,258 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:45:01,413 - INFO - training batch 701, loss: 0.062, 22432/28000 datapoints
2025-03-06 22:45:01,568 - INFO - training batch 751, loss: 0.040, 24032/28000 datapoints
2025-03-06 22:45:01,721 - INFO - training batch 801, loss: 0.019, 25632/28000 datapoints
2025-03-06 22:45:01,874 - INFO - training batch 851, loss: 0.082, 27232/28000 datapoints
2025-03-06 22:45:01,950 - INFO - validation batch 1, loss: 0.104, 32/6976 datapoints
2025-03-06 22:45:02,002 - INFO - validation batch 51, loss: 2.487, 1632/6976 datapoints
2025-03-06 22:45:02,049 - INFO - validation batch 101, loss: 0.551, 3232/6976 datapoints
2025-03-06 22:45:02,096 - INFO - validation batch 151, loss: 0.747, 4832/6976 datapoints
2025-03-06 22:45:02,143 - INFO - validation batch 201, loss: 1.044, 6432/6976 datapoints
2025-03-06 22:45:02,160 - INFO - Epoch 380/800 done.
2025-03-06 22:45:02,160 - INFO - Final validation performance:
Loss: 0.986, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:45:02,160 - INFO - Beginning epoch 381/800
2025-03-06 22:45:02,165 - INFO - training batch 1, loss: 0.075, 32/28000 datapoints
2025-03-06 22:45:02,320 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:45:02,481 - INFO - training batch 101, loss: 0.060, 3232/28000 datapoints
2025-03-06 22:45:02,667 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 22:45:02,821 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:45:02,983 - INFO - training batch 251, loss: 0.233, 8032/28000 datapoints
2025-03-06 22:45:03,141 - INFO - training batch 301, loss: 0.343, 9632/28000 datapoints
2025-03-06 22:45:03,306 - INFO - training batch 351, loss: 0.143, 11232/28000 datapoints
2025-03-06 22:45:03,468 - INFO - training batch 401, loss: 0.104, 12832/28000 datapoints
2025-03-06 22:45:03,628 - INFO - training batch 451, loss: 0.189, 14432/28000 datapoints
2025-03-06 22:45:03,787 - INFO - training batch 501, loss: 0.067, 16032/28000 datapoints
2025-03-06 22:45:03,947 - INFO - training batch 551, loss: 0.072, 17632/28000 datapoints
2025-03-06 22:45:04,106 - INFO - training batch 601, loss: 0.050, 19232/28000 datapoints
2025-03-06 22:45:04,260 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:45:04,418 - INFO - training batch 701, loss: 0.060, 22432/28000 datapoints
2025-03-06 22:45:04,576 - INFO - training batch 751, loss: 0.042, 24032/28000 datapoints
2025-03-06 22:45:04,745 - INFO - training batch 801, loss: 0.019, 25632/28000 datapoints
2025-03-06 22:45:04,900 - INFO - training batch 851, loss: 0.080, 27232/28000 datapoints
2025-03-06 22:45:04,982 - INFO - validation batch 1, loss: 0.105, 32/6976 datapoints
2025-03-06 22:45:05,036 - INFO - validation batch 51, loss: 2.505, 1632/6976 datapoints
2025-03-06 22:45:05,095 - INFO - validation batch 101, loss: 0.551, 3232/6976 datapoints
2025-03-06 22:45:05,149 - INFO - validation batch 151, loss: 0.750, 4832/6976 datapoints
2025-03-06 22:45:05,206 - INFO - validation batch 201, loss: 1.047, 6432/6976 datapoints
2025-03-06 22:45:05,226 - INFO - Epoch 381/800 done.
2025-03-06 22:45:05,226 - INFO - Final validation performance:
Loss: 0.992, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:45:05,227 - INFO - Beginning epoch 382/800
2025-03-06 22:45:05,233 - INFO - training batch 1, loss: 0.074, 32/28000 datapoints
2025-03-06 22:45:05,397 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:45:05,561 - INFO - training batch 101, loss: 0.060, 3232/28000 datapoints
2025-03-06 22:45:05,721 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 22:45:05,878 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:06,038 - INFO - training batch 251, loss: 0.230, 8032/28000 datapoints
2025-03-06 22:45:06,199 - INFO - training batch 301, loss: 0.341, 9632/28000 datapoints
2025-03-06 22:45:06,355 - INFO - training batch 351, loss: 0.141, 11232/28000 datapoints
2025-03-06 22:45:06,512 - INFO - training batch 401, loss: 0.102, 12832/28000 datapoints
2025-03-06 22:45:06,671 - INFO - training batch 451, loss: 0.188, 14432/28000 datapoints
2025-03-06 22:45:06,829 - INFO - training batch 501, loss: 0.065, 16032/28000 datapoints
2025-03-06 22:45:06,990 - INFO - training batch 551, loss: 0.071, 17632/28000 datapoints
2025-03-06 22:45:07,146 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 22:45:07,307 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:45:07,466 - INFO - training batch 701, loss: 0.058, 22432/28000 datapoints
2025-03-06 22:45:07,624 - INFO - training batch 751, loss: 0.039, 24032/28000 datapoints
2025-03-06 22:45:07,780 - INFO - training batch 801, loss: 0.018, 25632/28000 datapoints
2025-03-06 22:45:07,936 - INFO - training batch 851, loss: 0.079, 27232/28000 datapoints
2025-03-06 22:45:08,019 - INFO - validation batch 1, loss: 0.104, 32/6976 datapoints
2025-03-06 22:45:08,071 - INFO - validation batch 51, loss: 2.513, 1632/6976 datapoints
2025-03-06 22:45:08,122 - INFO - validation batch 101, loss: 0.552, 3232/6976 datapoints
2025-03-06 22:45:08,175 - INFO - validation batch 151, loss: 0.756, 4832/6976 datapoints
2025-03-06 22:45:08,226 - INFO - validation batch 201, loss: 1.054, 6432/6976 datapoints
2025-03-06 22:45:08,245 - INFO - Epoch 382/800 done.
2025-03-06 22:45:08,245 - INFO - Final validation performance:
Loss: 0.996, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:45:08,246 - INFO - Beginning epoch 383/800
2025-03-06 22:45:08,250 - INFO - training batch 1, loss: 0.073, 32/28000 datapoints
2025-03-06 22:45:08,413 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:45:08,600 - INFO - training batch 101, loss: 0.060, 3232/28000 datapoints
2025-03-06 22:45:08,756 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 22:45:08,912 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:09,073 - INFO - training batch 251, loss: 0.227, 8032/28000 datapoints
2025-03-06 22:45:09,228 - INFO - training batch 301, loss: 0.338, 9632/28000 datapoints
2025-03-06 22:45:09,392 - INFO - training batch 351, loss: 0.139, 11232/28000 datapoints
2025-03-06 22:45:09,550 - INFO - training batch 401, loss: 0.101, 12832/28000 datapoints
2025-03-06 22:45:09,706 - INFO - training batch 451, loss: 0.187, 14432/28000 datapoints
2025-03-06 22:45:09,863 - INFO - training batch 501, loss: 0.065, 16032/28000 datapoints
2025-03-06 22:45:10,026 - INFO - training batch 551, loss: 0.069, 17632/28000 datapoints
2025-03-06 22:45:10,185 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 22:45:10,342 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:45:10,501 - INFO - training batch 701, loss: 0.058, 22432/28000 datapoints
2025-03-06 22:45:10,657 - INFO - training batch 751, loss: 0.038, 24032/28000 datapoints
2025-03-06 22:45:10,824 - INFO - training batch 801, loss: 0.018, 25632/28000 datapoints
2025-03-06 22:45:10,993 - INFO - training batch 851, loss: 0.079, 27232/28000 datapoints
2025-03-06 22:45:11,074 - INFO - validation batch 1, loss: 0.105, 32/6976 datapoints
2025-03-06 22:45:11,126 - INFO - validation batch 51, loss: 2.526, 1632/6976 datapoints
2025-03-06 22:45:11,178 - INFO - validation batch 101, loss: 0.549, 3232/6976 datapoints
2025-03-06 22:45:11,237 - INFO - validation batch 151, loss: 0.763, 4832/6976 datapoints
2025-03-06 22:45:11,294 - INFO - validation batch 201, loss: 1.059, 6432/6976 datapoints
2025-03-06 22:45:11,314 - INFO - Epoch 383/800 done.
2025-03-06 22:45:11,314 - INFO - Final validation performance:
Loss: 1.000, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:45:11,315 - INFO - Beginning epoch 384/800
2025-03-06 22:45:11,319 - INFO - training batch 1, loss: 0.072, 32/28000 datapoints
2025-03-06 22:45:11,479 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:45:11,641 - INFO - training batch 101, loss: 0.058, 3232/28000 datapoints
2025-03-06 22:45:11,799 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 22:45:11,957 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:45:12,117 - INFO - training batch 251, loss: 0.222, 8032/28000 datapoints
2025-03-06 22:45:12,275 - INFO - training batch 301, loss: 0.333, 9632/28000 datapoints
2025-03-06 22:45:12,431 - INFO - training batch 351, loss: 0.139, 11232/28000 datapoints
2025-03-06 22:45:12,589 - INFO - training batch 401, loss: 0.099, 12832/28000 datapoints
2025-03-06 22:45:12,747 - INFO - training batch 451, loss: 0.186, 14432/28000 datapoints
2025-03-06 22:45:12,903 - INFO - training batch 501, loss: 0.064, 16032/28000 datapoints
2025-03-06 22:45:13,063 - INFO - training batch 551, loss: 0.068, 17632/28000 datapoints
2025-03-06 22:45:13,231 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-06 22:45:13,391 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:45:13,551 - INFO - training batch 701, loss: 0.057, 22432/28000 datapoints
2025-03-06 22:45:13,709 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-06 22:45:13,865 - INFO - training batch 801, loss: 0.018, 25632/28000 datapoints
2025-03-06 22:45:14,029 - INFO - training batch 851, loss: 0.077, 27232/28000 datapoints
2025-03-06 22:45:14,111 - INFO - validation batch 1, loss: 0.106, 32/6976 datapoints
2025-03-06 22:45:14,163 - INFO - validation batch 51, loss: 2.542, 1632/6976 datapoints
2025-03-06 22:45:14,214 - INFO - validation batch 101, loss: 0.550, 3232/6976 datapoints
2025-03-06 22:45:14,266 - INFO - validation batch 151, loss: 0.766, 4832/6976 datapoints
2025-03-06 22:45:14,318 - INFO - validation batch 201, loss: 1.067, 6432/6976 datapoints
2025-03-06 22:45:14,335 - INFO - Epoch 384/800 done.
2025-03-06 22:45:14,335 - INFO - Final validation performance:
Loss: 1.006, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 22:45:14,335 - INFO - Beginning epoch 385/800
2025-03-06 22:45:14,340 - INFO - training batch 1, loss: 0.072, 32/28000 datapoints
2025-03-06 22:45:14,500 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:45:14,659 - INFO - training batch 101, loss: 0.058, 3232/28000 datapoints
2025-03-06 22:45:14,817 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-06 22:45:14,976 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:45:15,132 - INFO - training batch 251, loss: 0.220, 8032/28000 datapoints
2025-03-06 22:45:15,294 - INFO - training batch 301, loss: 0.329, 9632/28000 datapoints
2025-03-06 22:45:15,451 - INFO - training batch 351, loss: 0.136, 11232/28000 datapoints
2025-03-06 22:45:15,614 - INFO - training batch 401, loss: 0.097, 12832/28000 datapoints
2025-03-06 22:45:15,779 - INFO - training batch 451, loss: 0.185, 14432/28000 datapoints
2025-03-06 22:45:15,937 - INFO - training batch 501, loss: 0.063, 16032/28000 datapoints
2025-03-06 22:45:16,098 - INFO - training batch 551, loss: 0.067, 17632/28000 datapoints
2025-03-06 22:45:16,254 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 22:45:16,409 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 22:45:16,570 - INFO - training batch 701, loss: 0.056, 22432/28000 datapoints
2025-03-06 22:45:16,728 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-06 22:45:16,885 - INFO - training batch 801, loss: 0.017, 25632/28000 datapoints
2025-03-06 22:45:17,053 - INFO - training batch 851, loss: 0.075, 27232/28000 datapoints
2025-03-06 22:45:17,136 - INFO - validation batch 1, loss: 0.107, 32/6976 datapoints
2025-03-06 22:45:17,190 - INFO - validation batch 51, loss: 2.558, 1632/6976 datapoints
2025-03-06 22:45:17,241 - INFO - validation batch 101, loss: 0.554, 3232/6976 datapoints
2025-03-06 22:45:17,295 - INFO - validation batch 151, loss: 0.772, 4832/6976 datapoints
2025-03-06 22:45:17,348 - INFO - validation batch 201, loss: 1.070, 6432/6976 datapoints
2025-03-06 22:45:17,366 - INFO - Epoch 385/800 done.
2025-03-06 22:45:17,367 - INFO - Final validation performance:
Loss: 1.012, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 22:45:17,367 - INFO - Beginning epoch 386/800
2025-03-06 22:45:17,371 - INFO - training batch 1, loss: 0.070, 32/28000 datapoints
2025-03-06 22:45:17,538 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:45:17,698 - INFO - training batch 101, loss: 0.057, 3232/28000 datapoints
2025-03-06 22:45:17,856 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-06 22:45:18,016 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 22:45:18,172 - INFO - training batch 251, loss: 0.217, 8032/28000 datapoints
2025-03-06 22:45:18,329 - INFO - training batch 301, loss: 0.325, 9632/28000 datapoints
2025-03-06 22:45:18,487 - INFO - training batch 351, loss: 0.135, 11232/28000 datapoints
2025-03-06 22:45:18,662 - INFO - training batch 401, loss: 0.097, 12832/28000 datapoints
2025-03-06 22:45:18,826 - INFO - training batch 451, loss: 0.185, 14432/28000 datapoints
2025-03-06 22:45:18,988 - INFO - training batch 501, loss: 0.063, 16032/28000 datapoints
2025-03-06 22:45:19,149 - INFO - training batch 551, loss: 0.065, 17632/28000 datapoints
2025-03-06 22:45:19,311 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 22:45:19,467 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:45:19,624 - INFO - training batch 701, loss: 0.055, 22432/28000 datapoints
2025-03-06 22:45:19,780 - INFO - training batch 751, loss: 0.038, 24032/28000 datapoints
2025-03-06 22:45:19,937 - INFO - training batch 801, loss: 0.017, 25632/28000 datapoints
2025-03-06 22:45:20,098 - INFO - training batch 851, loss: 0.074, 27232/28000 datapoints
2025-03-06 22:45:20,179 - INFO - validation batch 1, loss: 0.108, 32/6976 datapoints
2025-03-06 22:45:20,230 - INFO - validation batch 51, loss: 2.574, 1632/6976 datapoints
2025-03-06 22:45:20,282 - INFO - validation batch 101, loss: 0.554, 3232/6976 datapoints
2025-03-06 22:45:20,336 - INFO - validation batch 151, loss: 0.773, 4832/6976 datapoints
2025-03-06 22:45:20,387 - INFO - validation batch 201, loss: 1.076, 6432/6976 datapoints
2025-03-06 22:45:20,408 - INFO - Epoch 386/800 done.
2025-03-06 22:45:20,408 - INFO - Final validation performance:
Loss: 1.017, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 22:45:20,408 - INFO - Beginning epoch 387/800
2025-03-06 22:45:20,413 - INFO - training batch 1, loss: 0.069, 32/28000 datapoints
2025-03-06 22:45:20,571 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:45:20,737 - INFO - training batch 101, loss: 0.056, 3232/28000 datapoints
2025-03-06 22:45:20,893 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 22:45:21,053 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:21,210 - INFO - training batch 251, loss: 0.211, 8032/28000 datapoints
2025-03-06 22:45:21,369 - INFO - training batch 301, loss: 0.319, 9632/28000 datapoints
2025-03-06 22:45:21,526 - INFO - training batch 351, loss: 0.138, 11232/28000 datapoints
2025-03-06 22:45:21,685 - INFO - training batch 401, loss: 0.096, 12832/28000 datapoints
2025-03-06 22:45:21,840 - INFO - training batch 451, loss: 0.182, 14432/28000 datapoints
2025-03-06 22:45:22,001 - INFO - training batch 501, loss: 0.062, 16032/28000 datapoints
2025-03-06 22:45:22,160 - INFO - training batch 551, loss: 0.064, 17632/28000 datapoints
2025-03-06 22:45:22,317 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 22:45:22,472 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:45:22,637 - INFO - training batch 701, loss: 0.052, 22432/28000 datapoints
2025-03-06 22:45:22,794 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-06 22:45:22,952 - INFO - training batch 801, loss: 0.017, 25632/28000 datapoints
2025-03-06 22:45:23,112 - INFO - training batch 851, loss: 0.074, 27232/28000 datapoints
2025-03-06 22:45:23,195 - INFO - validation batch 1, loss: 0.108, 32/6976 datapoints
2025-03-06 22:45:23,256 - INFO - validation batch 51, loss: 2.586, 1632/6976 datapoints
2025-03-06 22:45:23,314 - INFO - validation batch 101, loss: 0.554, 3232/6976 datapoints
2025-03-06 22:45:23,368 - INFO - validation batch 151, loss: 0.783, 4832/6976 datapoints
2025-03-06 22:45:23,421 - INFO - validation batch 201, loss: 1.083, 6432/6976 datapoints
2025-03-06 22:45:23,438 - INFO - Epoch 387/800 done.
2025-03-06 22:45:23,438 - INFO - Final validation performance:
Loss: 1.023, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 22:45:23,438 - INFO - Beginning epoch 388/800
2025-03-06 22:45:23,443 - INFO - training batch 1, loss: 0.069, 32/28000 datapoints
2025-03-06 22:45:23,603 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:45:23,762 - INFO - training batch 101, loss: 0.056, 3232/28000 datapoints
2025-03-06 22:45:23,918 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 22:45:24,076 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:24,232 - INFO - training batch 251, loss: 0.209, 8032/28000 datapoints
2025-03-06 22:45:24,392 - INFO - training batch 301, loss: 0.316, 9632/28000 datapoints
2025-03-06 22:45:24,548 - INFO - training batch 351, loss: 0.135, 11232/28000 datapoints
2025-03-06 22:45:24,704 - INFO - training batch 401, loss: 0.094, 12832/28000 datapoints
2025-03-06 22:45:24,861 - INFO - training batch 451, loss: 0.182, 14432/28000 datapoints
2025-03-06 22:45:25,020 - INFO - training batch 501, loss: 0.061, 16032/28000 datapoints
2025-03-06 22:45:25,179 - INFO - training batch 551, loss: 0.062, 17632/28000 datapoints
2025-03-06 22:45:25,344 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-06 22:45:25,502 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:45:25,663 - INFO - training batch 701, loss: 0.052, 22432/28000 datapoints
2025-03-06 22:45:25,818 - INFO - training batch 751, loss: 0.035, 24032/28000 datapoints
2025-03-06 22:45:25,981 - INFO - training batch 801, loss: 0.017, 25632/28000 datapoints
2025-03-06 22:45:26,137 - INFO - training batch 851, loss: 0.073, 27232/28000 datapoints
2025-03-06 22:45:26,217 - INFO - validation batch 1, loss: 0.109, 32/6976 datapoints
2025-03-06 22:45:26,268 - INFO - validation batch 51, loss: 2.605, 1632/6976 datapoints
2025-03-06 22:45:26,320 - INFO - validation batch 101, loss: 0.557, 3232/6976 datapoints
2025-03-06 22:45:26,371 - INFO - validation batch 151, loss: 0.787, 4832/6976 datapoints
2025-03-06 22:45:26,425 - INFO - validation batch 201, loss: 1.088, 6432/6976 datapoints
2025-03-06 22:45:26,442 - INFO - Epoch 388/800 done.
2025-03-06 22:45:26,443 - INFO - Final validation performance:
Loss: 1.029, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:45:26,443 - INFO - Beginning epoch 389/800
2025-03-06 22:45:26,449 - INFO - training batch 1, loss: 0.068, 32/28000 datapoints
2025-03-06 22:45:26,613 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:45:26,774 - INFO - training batch 101, loss: 0.055, 3232/28000 datapoints
2025-03-06 22:45:26,930 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 22:45:27,088 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:27,245 - INFO - training batch 251, loss: 0.206, 8032/28000 datapoints
2025-03-06 22:45:27,407 - INFO - training batch 301, loss: 0.311, 9632/28000 datapoints
2025-03-06 22:45:27,568 - INFO - training batch 351, loss: 0.134, 11232/28000 datapoints
2025-03-06 22:45:27,727 - INFO - training batch 401, loss: 0.093, 12832/28000 datapoints
2025-03-06 22:45:27,885 - INFO - training batch 451, loss: 0.181, 14432/28000 datapoints
2025-03-06 22:45:28,045 - INFO - training batch 501, loss: 0.060, 16032/28000 datapoints
2025-03-06 22:45:28,204 - INFO - training batch 551, loss: 0.061, 17632/28000 datapoints
2025-03-06 22:45:28,364 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 22:45:28,522 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:45:28,686 - INFO - training batch 701, loss: 0.051, 22432/28000 datapoints
2025-03-06 22:45:28,872 - INFO - training batch 751, loss: 0.034, 24032/28000 datapoints
2025-03-06 22:45:29,031 - INFO - training batch 801, loss: 0.017, 25632/28000 datapoints
2025-03-06 22:45:29,191 - INFO - training batch 851, loss: 0.072, 27232/28000 datapoints
2025-03-06 22:45:29,272 - INFO - validation batch 1, loss: 0.108, 32/6976 datapoints
2025-03-06 22:45:29,324 - INFO - validation batch 51, loss: 2.618, 1632/6976 datapoints
2025-03-06 22:45:29,381 - INFO - validation batch 101, loss: 0.558, 3232/6976 datapoints
2025-03-06 22:45:29,434 - INFO - validation batch 151, loss: 0.791, 4832/6976 datapoints
2025-03-06 22:45:29,497 - INFO - validation batch 201, loss: 1.098, 6432/6976 datapoints
2025-03-06 22:45:29,517 - INFO - Epoch 389/800 done.
2025-03-06 22:45:29,518 - INFO - Final validation performance:
Loss: 1.034, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:45:29,518 - INFO - Beginning epoch 390/800
2025-03-06 22:45:29,523 - INFO - training batch 1, loss: 0.067, 32/28000 datapoints
2025-03-06 22:45:29,688 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 22:45:29,846 - INFO - training batch 101, loss: 0.055, 3232/28000 datapoints
2025-03-06 22:45:30,006 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-06 22:45:30,163 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:30,323 - INFO - training batch 251, loss: 0.203, 8032/28000 datapoints
2025-03-06 22:45:30,481 - INFO - training batch 301, loss: 0.309, 9632/28000 datapoints
2025-03-06 22:45:30,638 - INFO - training batch 351, loss: 0.130, 11232/28000 datapoints
2025-03-06 22:45:30,795 - INFO - training batch 401, loss: 0.092, 12832/28000 datapoints
2025-03-06 22:45:30,955 - INFO - training batch 451, loss: 0.179, 14432/28000 datapoints
2025-03-06 22:45:31,114 - INFO - training batch 501, loss: 0.059, 16032/28000 datapoints
2025-03-06 22:45:31,276 - INFO - training batch 551, loss: 0.059, 17632/28000 datapoints
2025-03-06 22:45:31,439 - INFO - training batch 601, loss: 0.043, 19232/28000 datapoints
2025-03-06 22:45:31,596 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:45:31,756 - INFO - training batch 701, loss: 0.050, 22432/28000 datapoints
2025-03-06 22:45:31,912 - INFO - training batch 751, loss: 0.035, 24032/28000 datapoints
2025-03-06 22:45:32,072 - INFO - training batch 801, loss: 0.017, 25632/28000 datapoints
2025-03-06 22:45:32,229 - INFO - training batch 851, loss: 0.071, 27232/28000 datapoints
2025-03-06 22:45:32,310 - INFO - validation batch 1, loss: 0.108, 32/6976 datapoints
2025-03-06 22:45:32,361 - INFO - validation batch 51, loss: 2.639, 1632/6976 datapoints
2025-03-06 22:45:32,413 - INFO - validation batch 101, loss: 0.554, 3232/6976 datapoints
2025-03-06 22:45:32,465 - INFO - validation batch 151, loss: 0.791, 4832/6976 datapoints
2025-03-06 22:45:32,518 - INFO - validation batch 201, loss: 1.104, 6432/6976 datapoints
2025-03-06 22:45:32,535 - INFO - Epoch 390/800 done.
2025-03-06 22:45:32,535 - INFO - Final validation performance:
Loss: 1.039, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:45:32,536 - INFO - Beginning epoch 391/800
2025-03-06 22:45:32,540 - INFO - training batch 1, loss: 0.066, 32/28000 datapoints
2025-03-06 22:45:32,703 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 22:45:32,863 - INFO - training batch 101, loss: 0.054, 3232/28000 datapoints
2025-03-06 22:45:33,022 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-06 22:45:33,185 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:33,344 - INFO - training batch 251, loss: 0.199, 8032/28000 datapoints
2025-03-06 22:45:33,506 - INFO - training batch 301, loss: 0.301, 9632/28000 datapoints
2025-03-06 22:45:33,672 - INFO - training batch 351, loss: 0.131, 11232/28000 datapoints
2025-03-06 22:45:33,836 - INFO - training batch 401, loss: 0.091, 12832/28000 datapoints
2025-03-06 22:45:33,996 - INFO - training batch 451, loss: 0.178, 14432/28000 datapoints
2025-03-06 22:45:34,154 - INFO - training batch 501, loss: 0.058, 16032/28000 datapoints
2025-03-06 22:45:34,318 - INFO - training batch 551, loss: 0.058, 17632/28000 datapoints
2025-03-06 22:45:34,475 - INFO - training batch 601, loss: 0.043, 19232/28000 datapoints
2025-03-06 22:45:34,633 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:45:34,838 - INFO - training batch 701, loss: 0.049, 22432/28000 datapoints
2025-03-06 22:45:35,011 - INFO - training batch 751, loss: 0.033, 24032/28000 datapoints
2025-03-06 22:45:35,171 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-06 22:45:35,335 - INFO - training batch 851, loss: 0.070, 27232/28000 datapoints
2025-03-06 22:45:35,419 - INFO - validation batch 1, loss: 0.109, 32/6976 datapoints
2025-03-06 22:45:35,470 - INFO - validation batch 51, loss: 2.649, 1632/6976 datapoints
2025-03-06 22:45:35,521 - INFO - validation batch 101, loss: 0.556, 3232/6976 datapoints
2025-03-06 22:45:35,576 - INFO - validation batch 151, loss: 0.800, 4832/6976 datapoints
2025-03-06 22:45:35,631 - INFO - validation batch 201, loss: 1.112, 6432/6976 datapoints
2025-03-06 22:45:35,651 - INFO - Epoch 391/800 done.
2025-03-06 22:45:35,651 - INFO - Final validation performance:
Loss: 1.045, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:45:35,652 - INFO - Beginning epoch 392/800
2025-03-06 22:45:35,658 - INFO - training batch 1, loss: 0.066, 32/28000 datapoints
2025-03-06 22:45:35,840 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 22:45:36,008 - INFO - training batch 101, loss: 0.054, 3232/28000 datapoints
2025-03-06 22:45:36,167 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-06 22:45:36,333 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:36,493 - INFO - training batch 251, loss: 0.195, 8032/28000 datapoints
2025-03-06 22:45:36,665 - INFO - training batch 301, loss: 0.297, 9632/28000 datapoints
2025-03-06 22:45:36,822 - INFO - training batch 351, loss: 0.129, 11232/28000 datapoints
2025-03-06 22:45:36,981 - INFO - training batch 401, loss: 0.089, 12832/28000 datapoints
2025-03-06 22:45:37,141 - INFO - training batch 451, loss: 0.178, 14432/28000 datapoints
2025-03-06 22:45:37,299 - INFO - training batch 501, loss: 0.057, 16032/28000 datapoints
2025-03-06 22:45:37,462 - INFO - training batch 551, loss: 0.056, 17632/28000 datapoints
2025-03-06 22:45:37,621 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-06 22:45:37,778 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:45:37,937 - INFO - training batch 701, loss: 0.048, 22432/28000 datapoints
2025-03-06 22:45:38,108 - INFO - training batch 751, loss: 0.032, 24032/28000 datapoints
2025-03-06 22:45:38,267 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-06 22:45:38,426 - INFO - training batch 851, loss: 0.069, 27232/28000 datapoints
2025-03-06 22:45:38,507 - INFO - validation batch 1, loss: 0.109, 32/6976 datapoints
2025-03-06 22:45:38,558 - INFO - validation batch 51, loss: 2.666, 1632/6976 datapoints
2025-03-06 22:45:38,610 - INFO - validation batch 101, loss: 0.555, 3232/6976 datapoints
2025-03-06 22:45:38,662 - INFO - validation batch 151, loss: 0.808, 4832/6976 datapoints
2025-03-06 22:45:38,714 - INFO - validation batch 201, loss: 1.117, 6432/6976 datapoints
2025-03-06 22:45:38,731 - INFO - Epoch 392/800 done.
2025-03-06 22:45:38,731 - INFO - Final validation performance:
Loss: 1.051, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:45:38,732 - INFO - Beginning epoch 393/800
2025-03-06 22:45:38,736 - INFO - training batch 1, loss: 0.064, 32/28000 datapoints
2025-03-06 22:45:38,934 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 22:45:39,093 - INFO - training batch 101, loss: 0.052, 3232/28000 datapoints
2025-03-06 22:45:39,256 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-06 22:45:39,421 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:39,578 - INFO - training batch 251, loss: 0.193, 8032/28000 datapoints
2025-03-06 22:45:39,734 - INFO - training batch 301, loss: 0.290, 9632/28000 datapoints
2025-03-06 22:45:39,893 - INFO - training batch 351, loss: 0.127, 11232/28000 datapoints
2025-03-06 22:45:40,054 - INFO - training batch 401, loss: 0.088, 12832/28000 datapoints
2025-03-06 22:45:40,213 - INFO - training batch 451, loss: 0.176, 14432/28000 datapoints
2025-03-06 22:45:40,374 - INFO - training batch 501, loss: 0.057, 16032/28000 datapoints
2025-03-06 22:45:40,532 - INFO - training batch 551, loss: 0.055, 17632/28000 datapoints
2025-03-06 22:45:40,690 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-06 22:45:40,848 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:45:41,010 - INFO - training batch 701, loss: 0.047, 22432/28000 datapoints
2025-03-06 22:45:41,171 - INFO - training batch 751, loss: 0.031, 24032/28000 datapoints
2025-03-06 22:45:41,331 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-06 22:45:41,492 - INFO - training batch 851, loss: 0.067, 27232/28000 datapoints
2025-03-06 22:45:41,572 - INFO - validation batch 1, loss: 0.110, 32/6976 datapoints
2025-03-06 22:45:41,625 - INFO - validation batch 51, loss: 2.684, 1632/6976 datapoints
2025-03-06 22:45:41,682 - INFO - validation batch 101, loss: 0.554, 3232/6976 datapoints
2025-03-06 22:45:41,734 - INFO - validation batch 151, loss: 0.812, 4832/6976 datapoints
2025-03-06 22:45:41,788 - INFO - validation batch 201, loss: 1.126, 6432/6976 datapoints
2025-03-06 22:45:41,809 - INFO - Epoch 393/800 done.
2025-03-06 22:45:41,809 - INFO - Final validation performance:
Loss: 1.057, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:45:41,810 - INFO - Beginning epoch 394/800
2025-03-06 22:45:41,814 - INFO - training batch 1, loss: 0.064, 32/28000 datapoints
2025-03-06 22:45:41,991 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 22:45:42,148 - INFO - training batch 101, loss: 0.052, 3232/28000 datapoints
2025-03-06 22:45:42,312 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-06 22:45:42,477 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:42,636 - INFO - training batch 251, loss: 0.190, 8032/28000 datapoints
2025-03-06 22:45:42,799 - INFO - training batch 301, loss: 0.287, 9632/28000 datapoints
2025-03-06 22:45:42,961 - INFO - training batch 351, loss: 0.127, 11232/28000 datapoints
2025-03-06 22:45:43,121 - INFO - training batch 401, loss: 0.086, 12832/28000 datapoints
2025-03-06 22:45:43,279 - INFO - training batch 451, loss: 0.174, 14432/28000 datapoints
2025-03-06 22:45:43,443 - INFO - training batch 501, loss: 0.056, 16032/28000 datapoints
2025-03-06 22:45:43,602 - INFO - training batch 551, loss: 0.054, 17632/28000 datapoints
2025-03-06 22:45:43,759 - INFO - training batch 601, loss: 0.040, 19232/28000 datapoints
2025-03-06 22:45:43,923 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:45:44,086 - INFO - training batch 701, loss: 0.046, 22432/28000 datapoints
2025-03-06 22:45:44,245 - INFO - training batch 751, loss: 0.032, 24032/28000 datapoints
2025-03-06 22:45:44,406 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-06 22:45:44,564 - INFO - training batch 851, loss: 0.065, 27232/28000 datapoints
2025-03-06 22:45:44,644 - INFO - validation batch 1, loss: 0.109, 32/6976 datapoints
2025-03-06 22:45:44,697 - INFO - validation batch 51, loss: 2.704, 1632/6976 datapoints
2025-03-06 22:45:44,749 - INFO - validation batch 101, loss: 0.554, 3232/6976 datapoints
2025-03-06 22:45:44,801 - INFO - validation batch 151, loss: 0.810, 4832/6976 datapoints
2025-03-06 22:45:44,853 - INFO - validation batch 201, loss: 1.132, 6432/6976 datapoints
2025-03-06 22:45:44,871 - INFO - Epoch 394/800 done.
2025-03-06 22:45:44,871 - INFO - Final validation performance:
Loss: 1.062, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:45:44,872 - INFO - Beginning epoch 395/800
2025-03-06 22:45:44,879 - INFO - training batch 1, loss: 0.063, 32/28000 datapoints
2025-03-06 22:45:45,043 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 22:45:45,201 - INFO - training batch 101, loss: 0.051, 3232/28000 datapoints
2025-03-06 22:45:45,367 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-06 22:45:45,529 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:45,688 - INFO - training batch 251, loss: 0.186, 8032/28000 datapoints
2025-03-06 22:45:45,847 - INFO - training batch 301, loss: 0.282, 9632/28000 datapoints
2025-03-06 22:45:46,008 - INFO - training batch 351, loss: 0.125, 11232/28000 datapoints
2025-03-06 22:45:46,167 - INFO - training batch 401, loss: 0.084, 12832/28000 datapoints
2025-03-06 22:45:46,325 - INFO - training batch 451, loss: 0.173, 14432/28000 datapoints
2025-03-06 22:45:46,485 - INFO - training batch 501, loss: 0.055, 16032/28000 datapoints
2025-03-06 22:45:46,645 - INFO - training batch 551, loss: 0.052, 17632/28000 datapoints
2025-03-06 22:45:46,803 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-06 22:45:46,965 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:45:47,125 - INFO - training batch 701, loss: 0.044, 22432/28000 datapoints
2025-03-06 22:45:47,282 - INFO - training batch 751, loss: 0.030, 24032/28000 datapoints
2025-03-06 22:45:47,445 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-06 22:45:47,605 - INFO - training batch 851, loss: 0.065, 27232/28000 datapoints
2025-03-06 22:45:47,685 - INFO - validation batch 1, loss: 0.110, 32/6976 datapoints
2025-03-06 22:45:47,737 - INFO - validation batch 51, loss: 2.718, 1632/6976 datapoints
2025-03-06 22:45:47,789 - INFO - validation batch 101, loss: 0.558, 3232/6976 datapoints
2025-03-06 22:45:47,840 - INFO - validation batch 151, loss: 0.822, 4832/6976 datapoints
2025-03-06 22:45:47,892 - INFO - validation batch 201, loss: 1.138, 6432/6976 datapoints
2025-03-06 22:45:47,914 - INFO - Epoch 395/800 done.
2025-03-06 22:45:47,915 - INFO - Final validation performance:
Loss: 1.069, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:45:47,915 - INFO - Beginning epoch 396/800
2025-03-06 22:45:47,920 - INFO - training batch 1, loss: 0.063, 32/28000 datapoints
2025-03-06 22:45:48,081 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 22:45:48,252 - INFO - training batch 101, loss: 0.051, 3232/28000 datapoints
2025-03-06 22:45:48,410 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 22:45:48,569 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:48,735 - INFO - training batch 251, loss: 0.181, 8032/28000 datapoints
2025-03-06 22:45:48,898 - INFO - training batch 301, loss: 0.274, 9632/28000 datapoints
2025-03-06 22:45:49,103 - INFO - training batch 351, loss: 0.123, 11232/28000 datapoints
2025-03-06 22:45:49,262 - INFO - training batch 401, loss: 0.083, 12832/28000 datapoints
2025-03-06 22:45:49,420 - INFO - training batch 451, loss: 0.172, 14432/28000 datapoints
2025-03-06 22:45:49,580 - INFO - training batch 501, loss: 0.054, 16032/28000 datapoints
2025-03-06 22:45:49,739 - INFO - training batch 551, loss: 0.051, 17632/28000 datapoints
2025-03-06 22:45:49,897 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-06 22:45:50,058 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:45:50,217 - INFO - training batch 701, loss: 0.044, 22432/28000 datapoints
2025-03-06 22:45:50,374 - INFO - training batch 751, loss: 0.030, 24032/28000 datapoints
2025-03-06 22:45:50,532 - INFO - training batch 801, loss: 0.015, 25632/28000 datapoints
2025-03-06 22:45:50,691 - INFO - training batch 851, loss: 0.064, 27232/28000 datapoints
2025-03-06 22:45:50,771 - INFO - validation batch 1, loss: 0.111, 32/6976 datapoints
2025-03-06 22:45:50,823 - INFO - validation batch 51, loss: 2.735, 1632/6976 datapoints
2025-03-06 22:45:50,876 - INFO - validation batch 101, loss: 0.558, 3232/6976 datapoints
2025-03-06 22:45:50,928 - INFO - validation batch 151, loss: 0.828, 4832/6976 datapoints
2025-03-06 22:45:50,984 - INFO - validation batch 201, loss: 1.145, 6432/6976 datapoints
2025-03-06 22:45:51,004 - INFO - Epoch 396/800 done.
2025-03-06 22:45:51,005 - INFO - Final validation performance:
Loss: 1.075, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:45:51,005 - INFO - Beginning epoch 397/800
2025-03-06 22:45:51,011 - INFO - training batch 1, loss: 0.061, 32/28000 datapoints
2025-03-06 22:45:51,176 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 22:45:51,331 - INFO - training batch 101, loss: 0.050, 3232/28000 datapoints
2025-03-06 22:45:51,490 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 22:45:51,645 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:51,798 - INFO - training batch 251, loss: 0.179, 8032/28000 datapoints
2025-03-06 22:45:51,953 - INFO - training batch 301, loss: 0.268, 9632/28000 datapoints
2025-03-06 22:45:52,111 - INFO - training batch 351, loss: 0.123, 11232/28000 datapoints
2025-03-06 22:45:52,266 - INFO - training batch 401, loss: 0.082, 12832/28000 datapoints
2025-03-06 22:45:52,421 - INFO - training batch 451, loss: 0.171, 14432/28000 datapoints
2025-03-06 22:45:52,576 - INFO - training batch 501, loss: 0.054, 16032/28000 datapoints
2025-03-06 22:45:52,734 - INFO - training batch 551, loss: 0.050, 17632/28000 datapoints
2025-03-06 22:45:52,888 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-06 22:45:53,044 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:45:53,201 - INFO - training batch 701, loss: 0.042, 22432/28000 datapoints
2025-03-06 22:45:53,353 - INFO - training batch 751, loss: 0.030, 24032/28000 datapoints
2025-03-06 22:45:53,513 - INFO - training batch 801, loss: 0.015, 25632/28000 datapoints
2025-03-06 22:45:53,667 - INFO - training batch 851, loss: 0.064, 27232/28000 datapoints
2025-03-06 22:45:53,743 - INFO - validation batch 1, loss: 0.111, 32/6976 datapoints
2025-03-06 22:45:53,790 - INFO - validation batch 51, loss: 2.754, 1632/6976 datapoints
2025-03-06 22:45:53,837 - INFO - validation batch 101, loss: 0.558, 3232/6976 datapoints
2025-03-06 22:45:53,885 - INFO - validation batch 151, loss: 0.834, 4832/6976 datapoints
2025-03-06 22:45:53,932 - INFO - validation batch 201, loss: 1.156, 6432/6976 datapoints
2025-03-06 22:45:53,948 - INFO - Epoch 397/800 done.
2025-03-06 22:45:53,948 - INFO - Final validation performance:
Loss: 1.083, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:45:53,949 - INFO - Beginning epoch 398/800
2025-03-06 22:45:53,953 - INFO - training batch 1, loss: 0.062, 32/28000 datapoints
2025-03-06 22:45:54,143 - INFO - training batch 51, loss: 0.039, 1632/28000 datapoints
2025-03-06 22:45:54,312 - INFO - training batch 101, loss: 0.050, 3232/28000 datapoints
2025-03-06 22:45:54,466 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 22:45:54,622 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:54,780 - INFO - training batch 251, loss: 0.177, 8032/28000 datapoints
2025-03-06 22:45:54,935 - INFO - training batch 301, loss: 0.264, 9632/28000 datapoints
2025-03-06 22:45:55,096 - INFO - training batch 351, loss: 0.121, 11232/28000 datapoints
2025-03-06 22:45:55,257 - INFO - training batch 401, loss: 0.080, 12832/28000 datapoints
2025-03-06 22:45:55,417 - INFO - training batch 451, loss: 0.170, 14432/28000 datapoints
2025-03-06 22:45:55,577 - INFO - training batch 501, loss: 0.053, 16032/28000 datapoints
2025-03-06 22:45:55,735 - INFO - training batch 551, loss: 0.049, 17632/28000 datapoints
2025-03-06 22:45:55,890 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-06 22:45:56,047 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:45:56,204 - INFO - training batch 701, loss: 0.043, 22432/28000 datapoints
2025-03-06 22:45:56,357 - INFO - training batch 751, loss: 0.029, 24032/28000 datapoints
2025-03-06 22:45:56,515 - INFO - training batch 801, loss: 0.015, 25632/28000 datapoints
2025-03-06 22:45:56,670 - INFO - training batch 851, loss: 0.062, 27232/28000 datapoints
2025-03-06 22:45:56,744 - INFO - validation batch 1, loss: 0.112, 32/6976 datapoints
2025-03-06 22:45:56,794 - INFO - validation batch 51, loss: 2.769, 1632/6976 datapoints
2025-03-06 22:45:56,842 - INFO - validation batch 101, loss: 0.555, 3232/6976 datapoints
2025-03-06 22:45:56,890 - INFO - validation batch 151, loss: 0.832, 4832/6976 datapoints
2025-03-06 22:45:56,938 - INFO - validation batch 201, loss: 1.164, 6432/6976 datapoints
2025-03-06 22:45:56,955 - INFO - Epoch 398/800 done.
2025-03-06 22:45:56,955 - INFO - Final validation performance:
Loss: 1.086, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:45:56,955 - INFO - Beginning epoch 399/800
2025-03-06 22:45:56,961 - INFO - training batch 1, loss: 0.061, 32/28000 datapoints
2025-03-06 22:45:57,119 - INFO - training batch 51, loss: 0.039, 1632/28000 datapoints
2025-03-06 22:45:57,276 - INFO - training batch 101, loss: 0.049, 3232/28000 datapoints
2025-03-06 22:45:57,429 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 22:45:57,588 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 22:45:57,741 - INFO - training batch 251, loss: 0.175, 8032/28000 datapoints
2025-03-06 22:45:57,895 - INFO - training batch 301, loss: 0.258, 9632/28000 datapoints
2025-03-06 22:45:58,051 - INFO - training batch 351, loss: 0.119, 11232/28000 datapoints
2025-03-06 22:45:58,205 - INFO - training batch 401, loss: 0.080, 12832/28000 datapoints
2025-03-06 22:45:58,361 - INFO - training batch 451, loss: 0.168, 14432/28000 datapoints
2025-03-06 22:45:58,523 - INFO - training batch 501, loss: 0.052, 16032/28000 datapoints
2025-03-06 22:45:58,679 - INFO - training batch 551, loss: 0.048, 17632/28000 datapoints
2025-03-06 22:45:58,836 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-06 22:45:58,992 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:45:59,180 - INFO - training batch 701, loss: 0.042, 22432/28000 datapoints
2025-03-06 22:45:59,334 - INFO - training batch 751, loss: 0.028, 24032/28000 datapoints
2025-03-06 22:45:59,492 - INFO - training batch 801, loss: 0.015, 25632/28000 datapoints
2025-03-06 22:45:59,645 - INFO - training batch 851, loss: 0.060, 27232/28000 datapoints
2025-03-06 22:45:59,720 - INFO - validation batch 1, loss: 0.113, 32/6976 datapoints
2025-03-06 22:45:59,768 - INFO - validation batch 51, loss: 2.789, 1632/6976 datapoints
2025-03-06 22:45:59,815 - INFO - validation batch 101, loss: 0.557, 3232/6976 datapoints
2025-03-06 22:45:59,863 - INFO - validation batch 151, loss: 0.841, 4832/6976 datapoints
2025-03-06 22:45:59,911 - INFO - validation batch 201, loss: 1.172, 6432/6976 datapoints
2025-03-06 22:45:59,927 - INFO - Epoch 399/800 done.
2025-03-06 22:45:59,927 - INFO - Final validation performance:
Loss: 1.094, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:45:59,927 - INFO - Beginning epoch 400/800
2025-03-06 22:45:59,932 - INFO - training batch 1, loss: 0.060, 32/28000 datapoints
2025-03-06 22:46:00,091 - INFO - training batch 51, loss: 0.039, 1632/28000 datapoints
2025-03-06 22:46:00,255 - INFO - training batch 101, loss: 0.048, 3232/28000 datapoints
2025-03-06 22:46:00,424 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 22:46:00,580 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 22:46:00,731 - INFO - training batch 251, loss: 0.169, 8032/28000 datapoints
2025-03-06 22:46:00,891 - INFO - training batch 301, loss: 0.251, 9632/28000 datapoints
2025-03-06 22:46:01,052 - INFO - training batch 351, loss: 0.118, 11232/28000 datapoints
2025-03-06 22:46:01,211 - INFO - training batch 401, loss: 0.078, 12832/28000 datapoints
2025-03-06 22:46:01,365 - INFO - training batch 451, loss: 0.167, 14432/28000 datapoints
2025-03-06 22:46:01,523 - INFO - training batch 501, loss: 0.050, 16032/28000 datapoints
2025-03-06 22:46:01,679 - INFO - training batch 551, loss: 0.047, 17632/28000 datapoints
2025-03-06 22:46:01,832 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-06 22:46:01,992 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:46:02,149 - INFO - training batch 701, loss: 0.041, 22432/28000 datapoints
2025-03-06 22:46:02,305 - INFO - training batch 751, loss: 0.028, 24032/28000 datapoints
2025-03-06 22:46:02,459 - INFO - training batch 801, loss: 0.015, 25632/28000 datapoints
2025-03-06 22:46:02,615 - INFO - training batch 851, loss: 0.059, 27232/28000 datapoints
2025-03-06 22:46:02,690 - INFO - validation batch 1, loss: 0.111, 32/6976 datapoints
2025-03-06 22:46:02,741 - INFO - validation batch 51, loss: 2.809, 1632/6976 datapoints
2025-03-06 22:46:02,788 - INFO - validation batch 101, loss: 0.553, 3232/6976 datapoints
2025-03-06 22:46:02,835 - INFO - validation batch 151, loss: 0.844, 4832/6976 datapoints
2025-03-06 22:46:02,888 - INFO - validation batch 201, loss: 1.193, 6432/6976 datapoints
2025-03-06 22:46:02,906 - INFO - Epoch 400/800 done.
2025-03-06 22:46:02,906 - INFO - Final validation performance:
Loss: 1.102, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 22:46:02,907 - INFO - Beginning epoch 401/800
2025-03-06 22:46:02,912 - INFO - training batch 1, loss: 0.059, 32/28000 datapoints
2025-03-06 22:46:03,084 - INFO - training batch 51, loss: 0.039, 1632/28000 datapoints
2025-03-06 22:46:03,242 - INFO - training batch 101, loss: 0.047, 3232/28000 datapoints
2025-03-06 22:46:03,400 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 22:46:03,570 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 22:46:03,732 - INFO - training batch 251, loss: 0.166, 8032/28000 datapoints
2025-03-06 22:46:03,890 - INFO - training batch 301, loss: 0.243, 9632/28000 datapoints
2025-03-06 22:46:04,050 - INFO - training batch 351, loss: 0.115, 11232/28000 datapoints
2025-03-06 22:46:04,209 - INFO - training batch 401, loss: 0.075, 12832/28000 datapoints
2025-03-06 22:46:04,368 - INFO - training batch 451, loss: 0.165, 14432/28000 datapoints
2025-03-06 22:46:04,532 - INFO - training batch 501, loss: 0.050, 16032/28000 datapoints
2025-03-06 22:46:04,691 - INFO - training batch 551, loss: 0.046, 17632/28000 datapoints
2025-03-06 22:46:04,850 - INFO - training batch 601, loss: 0.035, 19232/28000 datapoints
2025-03-06 22:46:05,010 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:46:05,169 - INFO - training batch 701, loss: 0.039, 22432/28000 datapoints
2025-03-06 22:46:05,333 - INFO - training batch 751, loss: 0.028, 24032/28000 datapoints
2025-03-06 22:46:05,491 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-06 22:46:05,653 - INFO - training batch 851, loss: 0.058, 27232/28000 datapoints
2025-03-06 22:46:05,732 - INFO - validation batch 1, loss: 0.113, 32/6976 datapoints
2025-03-06 22:46:05,786 - INFO - validation batch 51, loss: 2.833, 1632/6976 datapoints
2025-03-06 22:46:05,839 - INFO - validation batch 101, loss: 0.553, 3232/6976 datapoints
2025-03-06 22:46:05,891 - INFO - validation batch 151, loss: 0.844, 4832/6976 datapoints
2025-03-06 22:46:05,944 - INFO - validation batch 201, loss: 1.196, 6432/6976 datapoints
2025-03-06 22:46:05,967 - INFO - Epoch 401/800 done.
2025-03-06 22:46:05,967 - INFO - Final validation performance:
Loss: 1.108, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:46:05,968 - INFO - Beginning epoch 402/800
2025-03-06 22:46:05,973 - INFO - training batch 1, loss: 0.058, 32/28000 datapoints
2025-03-06 22:46:06,140 - INFO - training batch 51, loss: 0.038, 1632/28000 datapoints
2025-03-06 22:46:06,298 - INFO - training batch 101, loss: 0.047, 3232/28000 datapoints
2025-03-06 22:46:06,455 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-06 22:46:06,639 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 22:46:06,799 - INFO - training batch 251, loss: 0.163, 8032/28000 datapoints
2025-03-06 22:46:06,968 - INFO - training batch 301, loss: 0.238, 9632/28000 datapoints
2025-03-06 22:46:07,133 - INFO - training batch 351, loss: 0.114, 11232/28000 datapoints
2025-03-06 22:46:07,292 - INFO - training batch 401, loss: 0.075, 12832/28000 datapoints
2025-03-06 22:46:07,453 - INFO - training batch 451, loss: 0.164, 14432/28000 datapoints
2025-03-06 22:46:07,613 - INFO - training batch 501, loss: 0.049, 16032/28000 datapoints
2025-03-06 22:46:07,773 - INFO - training batch 551, loss: 0.044, 17632/28000 datapoints
2025-03-06 22:46:07,931 - INFO - training batch 601, loss: 0.034, 19232/28000 datapoints
2025-03-06 22:46:08,090 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:46:08,251 - INFO - training batch 701, loss: 0.039, 22432/28000 datapoints
2025-03-06 22:46:08,410 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-06 22:46:08,567 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-06 22:46:08,726 - INFO - training batch 851, loss: 0.059, 27232/28000 datapoints
2025-03-06 22:46:08,805 - INFO - validation batch 1, loss: 0.113, 32/6976 datapoints
2025-03-06 22:46:08,856 - INFO - validation batch 51, loss: 2.845, 1632/6976 datapoints
2025-03-06 22:46:08,908 - INFO - validation batch 101, loss: 0.558, 3232/6976 datapoints
2025-03-06 22:46:08,962 - INFO - validation batch 151, loss: 0.858, 4832/6976 datapoints
2025-03-06 22:46:09,015 - INFO - validation batch 201, loss: 1.207, 6432/6976 datapoints
2025-03-06 22:46:09,031 - INFO - Epoch 402/800 done.
2025-03-06 22:46:09,032 - INFO - Final validation performance:
Loss: 1.116, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:46:09,032 - INFO - Beginning epoch 403/800
2025-03-06 22:46:09,036 - INFO - training batch 1, loss: 0.059, 32/28000 datapoints
2025-03-06 22:46:09,221 - INFO - training batch 51, loss: 0.038, 1632/28000 datapoints
2025-03-06 22:46:09,381 - INFO - training batch 101, loss: 0.046, 3232/28000 datapoints
2025-03-06 22:46:09,542 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-06 22:46:09,703 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 22:46:09,859 - INFO - training batch 251, loss: 0.161, 8032/28000 datapoints
2025-03-06 22:46:10,020 - INFO - training batch 301, loss: 0.232, 9632/28000 datapoints
2025-03-06 22:46:10,179 - INFO - training batch 351, loss: 0.112, 11232/28000 datapoints
2025-03-06 22:46:10,338 - INFO - training batch 401, loss: 0.073, 12832/28000 datapoints
2025-03-06 22:46:10,497 - INFO - training batch 451, loss: 0.162, 14432/28000 datapoints
2025-03-06 22:46:10,655 - INFO - training batch 501, loss: 0.048, 16032/28000 datapoints
2025-03-06 22:46:10,816 - INFO - training batch 551, loss: 0.043, 17632/28000 datapoints
2025-03-06 22:46:10,977 - INFO - training batch 601, loss: 0.034, 19232/28000 datapoints
2025-03-06 22:46:11,134 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:46:11,294 - INFO - training batch 701, loss: 0.038, 22432/28000 datapoints
2025-03-06 22:46:11,450 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-06 22:46:11,613 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-06 22:46:11,772 - INFO - training batch 851, loss: 0.057, 27232/28000 datapoints
2025-03-06 22:46:11,852 - INFO - validation batch 1, loss: 0.114, 32/6976 datapoints
2025-03-06 22:46:11,905 - INFO - validation batch 51, loss: 2.867, 1632/6976 datapoints
2025-03-06 22:46:11,955 - INFO - validation batch 101, loss: 0.553, 3232/6976 datapoints
2025-03-06 22:46:12,007 - INFO - validation batch 151, loss: 0.855, 4832/6976 datapoints
2025-03-06 22:46:12,063 - INFO - validation batch 201, loss: 1.214, 6432/6976 datapoints
2025-03-06 22:46:12,080 - INFO - Epoch 403/800 done.
2025-03-06 22:46:12,080 - INFO - Final validation performance:
Loss: 1.121, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:46:12,080 - INFO - Beginning epoch 404/800
2025-03-06 22:46:12,085 - INFO - training batch 1, loss: 0.057, 32/28000 datapoints
2025-03-06 22:46:12,243 - INFO - training batch 51, loss: 0.037, 1632/28000 datapoints
2025-03-06 22:46:12,397 - INFO - training batch 101, loss: 0.045, 3232/28000 datapoints
2025-03-06 22:46:12,565 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-06 22:46:12,727 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 22:46:12,881 - INFO - training batch 251, loss: 0.157, 8032/28000 datapoints
2025-03-06 22:46:13,046 - INFO - training batch 301, loss: 0.226, 9632/28000 datapoints
2025-03-06 22:46:13,204 - INFO - training batch 351, loss: 0.110, 11232/28000 datapoints
2025-03-06 22:46:13,378 - INFO - training batch 401, loss: 0.071, 12832/28000 datapoints
2025-03-06 22:46:13,538 - INFO - training batch 451, loss: 0.162, 14432/28000 datapoints
2025-03-06 22:46:13,693 - INFO - training batch 501, loss: 0.048, 16032/28000 datapoints
2025-03-06 22:46:13,852 - INFO - training batch 551, loss: 0.043, 17632/28000 datapoints
2025-03-06 22:46:14,010 - INFO - training batch 601, loss: 0.034, 19232/28000 datapoints
2025-03-06 22:46:14,163 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 22:46:14,318 - INFO - training batch 701, loss: 0.038, 22432/28000 datapoints
2025-03-06 22:46:14,471 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-06 22:46:14,625 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-06 22:46:14,781 - INFO - training batch 851, loss: 0.055, 27232/28000 datapoints
2025-03-06 22:46:14,857 - INFO - validation batch 1, loss: 0.115, 32/6976 datapoints
2025-03-06 22:46:14,904 - INFO - validation batch 51, loss: 2.888, 1632/6976 datapoints
2025-03-06 22:46:14,954 - INFO - validation batch 101, loss: 0.553, 3232/6976 datapoints
2025-03-06 22:46:15,006 - INFO - validation batch 151, loss: 0.860, 4832/6976 datapoints
2025-03-06 22:46:15,053 - INFO - validation batch 201, loss: 1.203, 6432/6976 datapoints
2025-03-06 22:46:15,069 - INFO - Epoch 404/800 done.
2025-03-06 22:46:15,069 - INFO - Final validation performance:
Loss: 1.124, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:46:15,070 - INFO - Beginning epoch 405/800
2025-03-06 22:46:15,074 - INFO - training batch 1, loss: 0.056, 32/28000 datapoints
2025-03-06 22:46:15,239 - INFO - training batch 51, loss: 0.037, 1632/28000 datapoints
2025-03-06 22:46:15,393 - INFO - training batch 101, loss: 0.045, 3232/28000 datapoints
2025-03-06 22:46:15,551 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 22:46:15,707 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 22:46:15,863 - INFO - training batch 251, loss: 0.154, 8032/28000 datapoints
2025-03-06 22:46:16,020 - INFO - training batch 301, loss: 0.219, 9632/28000 datapoints
2025-03-06 22:46:16,177 - INFO - training batch 351, loss: 0.107, 11232/28000 datapoints
2025-03-06 22:46:16,333 - INFO - training batch 401, loss: 0.070, 12832/28000 datapoints
2025-03-06 22:46:16,491 - INFO - training batch 451, loss: 0.160, 14432/28000 datapoints
2025-03-06 22:46:16,646 - INFO - training batch 501, loss: 0.046, 16032/28000 datapoints
2025-03-06 22:46:16,802 - INFO - training batch 551, loss: 0.042, 17632/28000 datapoints
2025-03-06 22:46:16,960 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-06 22:46:17,116 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:46:17,271 - INFO - training batch 701, loss: 0.035, 22432/28000 datapoints
2025-03-06 22:46:17,424 - INFO - training batch 751, loss: 0.025, 24032/28000 datapoints
2025-03-06 22:46:17,593 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-06 22:46:17,748 - INFO - training batch 851, loss: 0.054, 27232/28000 datapoints
2025-03-06 22:46:17,827 - INFO - validation batch 1, loss: 0.115, 32/6976 datapoints
2025-03-06 22:46:17,874 - INFO - validation batch 51, loss: 2.908, 1632/6976 datapoints
2025-03-06 22:46:17,921 - INFO - validation batch 101, loss: 0.553, 3232/6976 datapoints
2025-03-06 22:46:17,971 - INFO - validation batch 151, loss: 0.866, 4832/6976 datapoints
2025-03-06 22:46:18,019 - INFO - validation batch 201, loss: 1.232, 6432/6976 datapoints
2025-03-06 22:46:18,035 - INFO - Epoch 405/800 done.
2025-03-06 22:46:18,035 - INFO - Final validation performance:
Loss: 1.135, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:46:18,036 - INFO - Beginning epoch 406/800
2025-03-06 22:46:18,040 - INFO - training batch 1, loss: 0.057, 32/28000 datapoints
2025-03-06 22:46:18,197 - INFO - training batch 51, loss: 0.037, 1632/28000 datapoints
2025-03-06 22:46:18,353 - INFO - training batch 101, loss: 0.044, 3232/28000 datapoints
2025-03-06 22:46:18,508 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 22:46:18,676 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 22:46:18,831 - INFO - training batch 251, loss: 0.152, 8032/28000 datapoints
2025-03-06 22:46:18,987 - INFO - training batch 301, loss: 0.214, 9632/28000 datapoints
2025-03-06 22:46:19,148 - INFO - training batch 351, loss: 0.107, 11232/28000 datapoints
2025-03-06 22:46:19,330 - INFO - training batch 401, loss: 0.071, 12832/28000 datapoints
2025-03-06 22:46:19,494 - INFO - training batch 451, loss: 0.158, 14432/28000 datapoints
2025-03-06 22:46:19,650 - INFO - training batch 501, loss: 0.046, 16032/28000 datapoints
2025-03-06 22:46:19,805 - INFO - training batch 551, loss: 0.041, 17632/28000 datapoints
2025-03-06 22:46:19,963 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-06 22:46:20,115 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:46:20,271 - INFO - training batch 701, loss: 0.036, 22432/28000 datapoints
2025-03-06 22:46:20,428 - INFO - training batch 751, loss: 0.024, 24032/28000 datapoints
2025-03-06 22:46:20,580 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-06 22:46:20,734 - INFO - training batch 851, loss: 0.054, 27232/28000 datapoints
2025-03-06 22:46:20,811 - INFO - validation batch 1, loss: 0.118, 32/6976 datapoints
2025-03-06 22:46:20,859 - INFO - validation batch 51, loss: 2.927, 1632/6976 datapoints
2025-03-06 22:46:20,907 - INFO - validation batch 101, loss: 0.555, 3232/6976 datapoints
2025-03-06 22:46:20,954 - INFO - validation batch 151, loss: 0.872, 4832/6976 datapoints
2025-03-06 22:46:21,005 - INFO - validation batch 201, loss: 1.217, 6432/6976 datapoints
2025-03-06 22:46:21,021 - INFO - Epoch 406/800 done.
2025-03-06 22:46:21,022 - INFO - Final validation performance:
Loss: 1.138, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 22:46:21,022 - INFO - Beginning epoch 407/800
2025-03-06 22:46:21,026 - INFO - training batch 1, loss: 0.056, 32/28000 datapoints
2025-03-06 22:46:21,184 - INFO - training batch 51, loss: 0.037, 1632/28000 datapoints
2025-03-06 22:46:21,340 - INFO - training batch 101, loss: 0.043, 3232/28000 datapoints
2025-03-06 22:46:21,493 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 22:46:21,650 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 22:46:21,808 - INFO - training batch 251, loss: 0.147, 8032/28000 datapoints
2025-03-06 22:46:21,967 - INFO - training batch 301, loss: 0.205, 9632/28000 datapoints
2025-03-06 22:46:22,123 - INFO - training batch 351, loss: 0.103, 11232/28000 datapoints
2025-03-06 22:46:22,278 - INFO - training batch 401, loss: 0.066, 12832/28000 datapoints
2025-03-06 22:46:22,435 - INFO - training batch 451, loss: 0.156, 14432/28000 datapoints
2025-03-06 22:46:22,590 - INFO - training batch 501, loss: 0.045, 16032/28000 datapoints
2025-03-06 22:46:22,748 - INFO - training batch 551, loss: 0.040, 17632/28000 datapoints
2025-03-06 22:46:22,912 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-06 22:46:23,072 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:46:23,230 - INFO - training batch 701, loss: 0.035, 22432/28000 datapoints
2025-03-06 22:46:23,393 - INFO - training batch 751, loss: 0.024, 24032/28000 datapoints
2025-03-06 22:46:23,555 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-06 22:46:23,718 - INFO - training batch 851, loss: 0.052, 27232/28000 datapoints
2025-03-06 22:46:23,798 - INFO - validation batch 1, loss: 0.118, 32/6976 datapoints
2025-03-06 22:46:23,853 - INFO - validation batch 51, loss: 2.952, 1632/6976 datapoints
2025-03-06 22:46:23,905 - INFO - validation batch 101, loss: 0.552, 3232/6976 datapoints
2025-03-06 22:46:23,953 - INFO - validation batch 151, loss: 0.869, 4832/6976 datapoints
2025-03-06 22:46:24,005 - INFO - validation batch 201, loss: 1.249, 6432/6976 datapoints
2025-03-06 22:46:24,021 - INFO - Epoch 407/800 done.
2025-03-06 22:46:24,022 - INFO - Final validation performance:
Loss: 1.148, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:46:24,022 - INFO - Beginning epoch 408/800
2025-03-06 22:46:24,026 - INFO - training batch 1, loss: 0.055, 32/28000 datapoints
2025-03-06 22:46:24,182 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-06 22:46:24,339 - INFO - training batch 101, loss: 0.043, 3232/28000 datapoints
2025-03-06 22:46:24,494 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 22:46:24,667 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 22:46:24,823 - INFO - training batch 251, loss: 0.142, 8032/28000 datapoints
2025-03-06 22:46:24,983 - INFO - training batch 301, loss: 0.199, 9632/28000 datapoints
2025-03-06 22:46:25,146 - INFO - training batch 351, loss: 0.101, 11232/28000 datapoints
2025-03-06 22:46:25,310 - INFO - training batch 401, loss: 0.066, 12832/28000 datapoints
2025-03-06 22:46:25,472 - INFO - training batch 451, loss: 0.154, 14432/28000 datapoints
2025-03-06 22:46:25,630 - INFO - training batch 501, loss: 0.045, 16032/28000 datapoints
2025-03-06 22:46:25,789 - INFO - training batch 551, loss: 0.039, 17632/28000 datapoints
2025-03-06 22:46:25,944 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-06 22:46:26,100 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:46:26,255 - INFO - training batch 701, loss: 0.035, 22432/28000 datapoints
2025-03-06 22:46:26,418 - INFO - training batch 751, loss: 0.023, 24032/28000 datapoints
2025-03-06 22:46:26,577 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-06 22:46:26,733 - INFO - training batch 851, loss: 0.052, 27232/28000 datapoints
2025-03-06 22:46:26,810 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 22:46:26,859 - INFO - validation batch 51, loss: 2.970, 1632/6976 datapoints
2025-03-06 22:46:26,906 - INFO - validation batch 101, loss: 0.552, 3232/6976 datapoints
2025-03-06 22:46:26,954 - INFO - validation batch 151, loss: 0.881, 4832/6976 datapoints
2025-03-06 22:46:27,009 - INFO - validation batch 201, loss: 1.239, 6432/6976 datapoints
2025-03-06 22:46:27,026 - INFO - Epoch 408/800 done.
2025-03-06 22:46:27,026 - INFO - Final validation performance:
Loss: 1.152, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:46:27,026 - INFO - Beginning epoch 409/800
2025-03-06 22:46:27,031 - INFO - training batch 1, loss: 0.054, 32/28000 datapoints
2025-03-06 22:46:27,188 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-06 22:46:27,341 - INFO - training batch 101, loss: 0.042, 3232/28000 datapoints
2025-03-06 22:46:27,500 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 22:46:27,657 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 22:46:27,808 - INFO - training batch 251, loss: 0.140, 8032/28000 datapoints
2025-03-06 22:46:27,967 - INFO - training batch 301, loss: 0.193, 9632/28000 datapoints
2025-03-06 22:46:28,123 - INFO - training batch 351, loss: 0.099, 11232/28000 datapoints
2025-03-06 22:46:28,277 - INFO - training batch 401, loss: 0.065, 12832/28000 datapoints
2025-03-06 22:46:28,433 - INFO - training batch 451, loss: 0.153, 14432/28000 datapoints
2025-03-06 22:46:28,601 - INFO - training batch 501, loss: 0.044, 16032/28000 datapoints
2025-03-06 22:46:28,756 - INFO - training batch 551, loss: 0.038, 17632/28000 datapoints
2025-03-06 22:46:28,911 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-06 22:46:29,091 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:46:29,289 - INFO - training batch 701, loss: 0.033, 22432/28000 datapoints
2025-03-06 22:46:29,493 - INFO - training batch 751, loss: 0.023, 24032/28000 datapoints
2025-03-06 22:46:29,649 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-06 22:46:29,804 - INFO - training batch 851, loss: 0.051, 27232/28000 datapoints
2025-03-06 22:46:29,880 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 22:46:29,928 - INFO - validation batch 51, loss: 2.988, 1632/6976 datapoints
2025-03-06 22:46:29,978 - INFO - validation batch 101, loss: 0.551, 3232/6976 datapoints
2025-03-06 22:46:30,026 - INFO - validation batch 151, loss: 0.887, 4832/6976 datapoints
2025-03-06 22:46:30,074 - INFO - validation batch 201, loss: 1.244, 6432/6976 datapoints
2025-03-06 22:46:30,090 - INFO - Epoch 409/800 done.
2025-03-06 22:46:30,090 - INFO - Final validation performance:
Loss: 1.158, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:46:30,091 - INFO - Beginning epoch 410/800
2025-03-06 22:46:30,095 - INFO - training batch 1, loss: 0.053, 32/28000 datapoints
2025-03-06 22:46:30,251 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-06 22:46:30,408 - INFO - training batch 101, loss: 0.042, 3232/28000 datapoints
2025-03-06 22:46:30,561 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 22:46:30,731 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 22:46:30,885 - INFO - training batch 251, loss: 0.139, 8032/28000 datapoints
2025-03-06 22:46:31,042 - INFO - training batch 301, loss: 0.190, 9632/28000 datapoints
2025-03-06 22:46:31,205 - INFO - training batch 351, loss: 0.096, 11232/28000 datapoints
2025-03-06 22:46:31,365 - INFO - training batch 401, loss: 0.064, 12832/28000 datapoints
2025-03-06 22:46:31,526 - INFO - training batch 451, loss: 0.150, 14432/28000 datapoints
2025-03-06 22:46:31,684 - INFO - training batch 501, loss: 0.043, 16032/28000 datapoints
2025-03-06 22:46:31,840 - INFO - training batch 551, loss: 0.037, 17632/28000 datapoints
2025-03-06 22:46:32,001 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-06 22:46:32,153 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:46:32,310 - INFO - training batch 701, loss: 0.033, 22432/28000 datapoints
2025-03-06 22:46:32,464 - INFO - training batch 751, loss: 0.022, 24032/28000 datapoints
2025-03-06 22:46:32,655 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-06 22:46:32,834 - INFO - training batch 851, loss: 0.050, 27232/28000 datapoints
2025-03-06 22:46:32,920 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 22:46:32,971 - INFO - validation batch 51, loss: 3.011, 1632/6976 datapoints
2025-03-06 22:46:33,020 - INFO - validation batch 101, loss: 0.552, 3232/6976 datapoints
2025-03-06 22:46:33,067 - INFO - validation batch 151, loss: 0.883, 4832/6976 datapoints
2025-03-06 22:46:33,117 - INFO - validation batch 201, loss: 1.258, 6432/6976 datapoints
2025-03-06 22:46:33,133 - INFO - Epoch 410/800 done.
2025-03-06 22:46:33,134 - INFO - Final validation performance:
Loss: 1.165, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:46:33,134 - INFO - Beginning epoch 411/800
2025-03-06 22:46:33,138 - INFO - training batch 1, loss: 0.053, 32/28000 datapoints
2025-03-06 22:46:33,299 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-06 22:46:33,460 - INFO - training batch 101, loss: 0.041, 3232/28000 datapoints
2025-03-06 22:46:33,618 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 22:46:33,772 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 22:46:33,925 - INFO - training batch 251, loss: 0.135, 8032/28000 datapoints
2025-03-06 22:46:34,083 - INFO - training batch 301, loss: 0.181, 9632/28000 datapoints
2025-03-06 22:46:34,245 - INFO - training batch 351, loss: 0.094, 11232/28000 datapoints
2025-03-06 22:46:34,399 - INFO - training batch 401, loss: 0.062, 12832/28000 datapoints
2025-03-06 22:46:34,561 - INFO - training batch 451, loss: 0.148, 14432/28000 datapoints
2025-03-06 22:46:34,716 - INFO - training batch 501, loss: 0.043, 16032/28000 datapoints
2025-03-06 22:46:34,873 - INFO - training batch 551, loss: 0.037, 17632/28000 datapoints
2025-03-06 22:46:35,031 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-06 22:46:35,198 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:46:35,397 - INFO - training batch 701, loss: 0.032, 22432/28000 datapoints
2025-03-06 22:46:35,551 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-06 22:46:35,717 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 22:46:35,873 - INFO - training batch 851, loss: 0.048, 27232/28000 datapoints
2025-03-06 22:46:35,948 - INFO - validation batch 1, loss: 0.122, 32/6976 datapoints
2025-03-06 22:46:35,999 - INFO - validation batch 51, loss: 3.034, 1632/6976 datapoints
2025-03-06 22:46:36,048 - INFO - validation batch 101, loss: 0.549, 3232/6976 datapoints
2025-03-06 22:46:36,095 - INFO - validation batch 151, loss: 0.889, 4832/6976 datapoints
2025-03-06 22:46:36,144 - INFO - validation batch 201, loss: 1.267, 6432/6976 datapoints
2025-03-06 22:46:36,161 - INFO - Epoch 411/800 done.
2025-03-06 22:46:36,161 - INFO - Final validation performance:
Loss: 1.172, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:46:36,161 - INFO - Beginning epoch 412/800
2025-03-06 22:46:36,166 - INFO - training batch 1, loss: 0.051, 32/28000 datapoints
2025-03-06 22:46:36,325 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-06 22:46:36,480 - INFO - training batch 101, loss: 0.040, 3232/28000 datapoints
2025-03-06 22:46:36,648 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 22:46:36,808 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 22:46:36,969 - INFO - training batch 251, loss: 0.130, 8032/28000 datapoints
2025-03-06 22:46:37,129 - INFO - training batch 301, loss: 0.178, 9632/28000 datapoints
2025-03-06 22:46:37,290 - INFO - training batch 351, loss: 0.093, 11232/28000 datapoints
2025-03-06 22:46:37,447 - INFO - training batch 401, loss: 0.061, 12832/28000 datapoints
2025-03-06 22:46:37,610 - INFO - training batch 451, loss: 0.148, 14432/28000 datapoints
2025-03-06 22:46:37,769 - INFO - training batch 501, loss: 0.042, 16032/28000 datapoints
2025-03-06 22:46:37,926 - INFO - training batch 551, loss: 0.036, 17632/28000 datapoints
2025-03-06 22:46:38,098 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 22:46:38,255 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:46:38,411 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-06 22:46:38,567 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-06 22:46:38,721 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 22:46:38,875 - INFO - training batch 851, loss: 0.047, 27232/28000 datapoints
2025-03-06 22:46:38,951 - INFO - validation batch 1, loss: 0.122, 32/6976 datapoints
2025-03-06 22:46:39,004 - INFO - validation batch 51, loss: 3.059, 1632/6976 datapoints
2025-03-06 22:46:39,051 - INFO - validation batch 101, loss: 0.551, 3232/6976 datapoints
2025-03-06 22:46:39,103 - INFO - validation batch 151, loss: 0.899, 4832/6976 datapoints
2025-03-06 22:46:39,163 - INFO - validation batch 201, loss: 1.298, 6432/6976 datapoints
2025-03-06 22:46:39,185 - INFO - Epoch 412/800 done.
2025-03-06 22:46:39,186 - INFO - Final validation performance:
Loss: 1.186, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 22:46:39,186 - INFO - Beginning epoch 413/800
2025-03-06 22:46:39,191 - INFO - training batch 1, loss: 0.051, 32/28000 datapoints
2025-03-06 22:46:39,360 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-06 22:46:39,557 - INFO - training batch 101, loss: 0.041, 3232/28000 datapoints
2025-03-06 22:46:39,715 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 22:46:39,869 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 22:46:40,028 - INFO - training batch 251, loss: 0.126, 8032/28000 datapoints
2025-03-06 22:46:40,181 - INFO - training batch 301, loss: 0.170, 9632/28000 datapoints
2025-03-06 22:46:40,336 - INFO - training batch 351, loss: 0.091, 11232/28000 datapoints
2025-03-06 22:46:40,491 - INFO - training batch 401, loss: 0.059, 12832/28000 datapoints
2025-03-06 22:46:40,650 - INFO - training batch 451, loss: 0.146, 14432/28000 datapoints
2025-03-06 22:46:40,804 - INFO - training batch 501, loss: 0.042, 16032/28000 datapoints
2025-03-06 22:46:40,961 - INFO - training batch 551, loss: 0.034, 17632/28000 datapoints
2025-03-06 22:46:41,116 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 22:46:41,271 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:46:41,425 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-06 22:46:41,579 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-06 22:46:41,736 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 22:46:41,892 - INFO - training batch 851, loss: 0.046, 27232/28000 datapoints
2025-03-06 22:46:41,970 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 22:46:42,017 - INFO - validation batch 51, loss: 3.081, 1632/6976 datapoints
2025-03-06 22:46:42,068 - INFO - validation batch 101, loss: 0.549, 3232/6976 datapoints
2025-03-06 22:46:42,115 - INFO - validation batch 151, loss: 0.896, 4832/6976 datapoints
2025-03-06 22:46:42,164 - INFO - validation batch 201, loss: 1.288, 6432/6976 datapoints
2025-03-06 22:46:42,181 - INFO - Epoch 413/800 done.
2025-03-06 22:46:42,181 - INFO - Final validation performance:
Loss: 1.187, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:46:42,181 - INFO - Beginning epoch 414/800
2025-03-06 22:46:42,186 - INFO - training batch 1, loss: 0.051, 32/28000 datapoints
2025-03-06 22:46:42,345 - INFO - training batch 51, loss: 0.034, 1632/28000 datapoints
2025-03-06 22:46:42,498 - INFO - training batch 101, loss: 0.040, 3232/28000 datapoints
2025-03-06 22:46:42,667 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 22:46:42,825 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 22:46:42,989 - INFO - training batch 251, loss: 0.124, 8032/28000 datapoints
2025-03-06 22:46:43,157 - INFO - training batch 301, loss: 0.162, 9632/28000 datapoints
2025-03-06 22:46:43,321 - INFO - training batch 351, loss: 0.086, 11232/28000 datapoints
2025-03-06 22:46:43,479 - INFO - training batch 401, loss: 0.058, 12832/28000 datapoints
2025-03-06 22:46:43,654 - INFO - training batch 451, loss: 0.142, 14432/28000 datapoints
2025-03-06 22:46:43,813 - INFO - training batch 501, loss: 0.041, 16032/28000 datapoints
2025-03-06 22:46:43,977 - INFO - training batch 551, loss: 0.034, 17632/28000 datapoints
2025-03-06 22:46:44,137 - INFO - training batch 601, loss: 0.028, 19232/28000 datapoints
2025-03-06 22:46:44,294 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:46:44,454 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-06 22:46:44,611 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-06 22:46:44,769 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 22:46:44,929 - INFO - training batch 851, loss: 0.045, 27232/28000 datapoints
2025-03-06 22:46:45,012 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 22:46:45,065 - INFO - validation batch 51, loss: 3.099, 1632/6976 datapoints
2025-03-06 22:46:45,117 - INFO - validation batch 101, loss: 0.551, 3232/6976 datapoints
2025-03-06 22:46:45,169 - INFO - validation batch 151, loss: 0.903, 4832/6976 datapoints
2025-03-06 22:46:45,225 - INFO - validation batch 201, loss: 1.297, 6432/6976 datapoints
2025-03-06 22:46:45,246 - INFO - Epoch 414/800 done.
2025-03-06 22:46:45,246 - INFO - Final validation performance:
Loss: 1.195, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:46:45,247 - INFO - Beginning epoch 415/800
2025-03-06 22:46:45,252 - INFO - training batch 1, loss: 0.050, 32/28000 datapoints
2025-03-06 22:46:45,412 - INFO - training batch 51, loss: 0.034, 1632/28000 datapoints
2025-03-06 22:46:45,565 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-06 22:46:45,728 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 22:46:45,884 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 22:46:46,042 - INFO - training batch 251, loss: 0.121, 8032/28000 datapoints
2025-03-06 22:46:46,198 - INFO - training batch 301, loss: 0.158, 9632/28000 datapoints
2025-03-06 22:46:46,355 - INFO - training batch 351, loss: 0.086, 11232/28000 datapoints
2025-03-06 22:46:46,509 - INFO - training batch 401, loss: 0.055, 12832/28000 datapoints
2025-03-06 22:46:46,667 - INFO - training batch 451, loss: 0.141, 14432/28000 datapoints
2025-03-06 22:46:46,822 - INFO - training batch 501, loss: 0.040, 16032/28000 datapoints
2025-03-06 22:46:46,980 - INFO - training batch 551, loss: 0.033, 17632/28000 datapoints
2025-03-06 22:46:47,136 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 22:46:47,292 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:46:47,448 - INFO - training batch 701, loss: 0.029, 22432/28000 datapoints
2025-03-06 22:46:47,604 - INFO - training batch 751, loss: 0.020, 24032/28000 datapoints
2025-03-06 22:46:47,760 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 22:46:47,915 - INFO - training batch 851, loss: 0.045, 27232/28000 datapoints
2025-03-06 22:46:47,994 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 22:46:48,043 - INFO - validation batch 51, loss: 3.124, 1632/6976 datapoints
2025-03-06 22:46:48,091 - INFO - validation batch 101, loss: 0.551, 3232/6976 datapoints
2025-03-06 22:46:48,138 - INFO - validation batch 151, loss: 0.910, 4832/6976 datapoints
2025-03-06 22:46:48,187 - INFO - validation batch 201, loss: 1.305, 6432/6976 datapoints
2025-03-06 22:46:48,204 - INFO - Epoch 415/800 done.
2025-03-06 22:46:48,204 - INFO - Final validation performance:
Loss: 1.203, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:46:48,204 - INFO - Beginning epoch 416/800
2025-03-06 22:46:48,209 - INFO - training batch 1, loss: 0.050, 32/28000 datapoints
2025-03-06 22:46:48,366 - INFO - training batch 51, loss: 0.033, 1632/28000 datapoints
2025-03-06 22:46:48,520 - INFO - training batch 101, loss: 0.038, 3232/28000 datapoints
2025-03-06 22:46:48,699 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 22:46:48,854 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 22:46:49,009 - INFO - training batch 251, loss: 0.119, 8032/28000 datapoints
2025-03-06 22:46:49,172 - INFO - training batch 301, loss: 0.153, 9632/28000 datapoints
2025-03-06 22:46:49,331 - INFO - training batch 351, loss: 0.082, 11232/28000 datapoints
2025-03-06 22:46:49,489 - INFO - training batch 401, loss: 0.055, 12832/28000 datapoints
2025-03-06 22:46:49,676 - INFO - training batch 451, loss: 0.140, 14432/28000 datapoints
2025-03-06 22:46:49,833 - INFO - training batch 501, loss: 0.040, 16032/28000 datapoints
2025-03-06 22:46:49,992 - INFO - training batch 551, loss: 0.032, 17632/28000 datapoints
2025-03-06 22:46:50,146 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 22:46:50,298 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:46:50,456 - INFO - training batch 701, loss: 0.030, 22432/28000 datapoints
2025-03-06 22:46:50,608 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-06 22:46:50,762 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 22:46:50,918 - INFO - training batch 851, loss: 0.043, 27232/28000 datapoints
2025-03-06 22:46:50,996 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 22:46:51,053 - INFO - validation batch 51, loss: 3.147, 1632/6976 datapoints
2025-03-06 22:46:51,101 - INFO - validation batch 101, loss: 0.553, 3232/6976 datapoints
2025-03-06 22:46:51,151 - INFO - validation batch 151, loss: 0.911, 4832/6976 datapoints
2025-03-06 22:46:51,199 - INFO - validation batch 201, loss: 1.335, 6432/6976 datapoints
2025-03-06 22:46:51,218 - INFO - Epoch 416/800 done.
2025-03-06 22:46:51,218 - INFO - Final validation performance:
Loss: 1.214, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:46:51,219 - INFO - Beginning epoch 417/800
2025-03-06 22:46:51,223 - INFO - training batch 1, loss: 0.048, 32/28000 datapoints
2025-03-06 22:46:51,380 - INFO - training batch 51, loss: 0.033, 1632/28000 datapoints
2025-03-06 22:46:51,534 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-06 22:46:51,696 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 22:46:51,851 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 22:46:52,006 - INFO - training batch 251, loss: 0.115, 8032/28000 datapoints
2025-03-06 22:46:52,162 - INFO - training batch 301, loss: 0.146, 9632/28000 datapoints
2025-03-06 22:46:52,323 - INFO - training batch 351, loss: 0.081, 11232/28000 datapoints
2025-03-06 22:46:52,478 - INFO - training batch 401, loss: 0.053, 12832/28000 datapoints
2025-03-06 22:46:52,635 - INFO - training batch 451, loss: 0.136, 14432/28000 datapoints
2025-03-06 22:46:52,792 - INFO - training batch 501, loss: 0.039, 16032/28000 datapoints
2025-03-06 22:46:52,952 - INFO - training batch 551, loss: 0.032, 17632/28000 datapoints
2025-03-06 22:46:53,109 - INFO - training batch 601, loss: 0.028, 19232/28000 datapoints
2025-03-06 22:46:53,263 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:46:53,426 - INFO - training batch 701, loss: 0.028, 22432/28000 datapoints
2025-03-06 22:46:53,583 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-06 22:46:53,741 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 22:46:53,897 - INFO - training batch 851, loss: 0.043, 27232/28000 datapoints
2025-03-06 22:46:53,976 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 22:46:54,024 - INFO - validation batch 51, loss: 3.169, 1632/6976 datapoints
2025-03-06 22:46:54,071 - INFO - validation batch 101, loss: 0.547, 3232/6976 datapoints
2025-03-06 22:46:54,119 - INFO - validation batch 151, loss: 0.915, 4832/6976 datapoints
2025-03-06 22:46:54,168 - INFO - validation batch 201, loss: 1.329, 6432/6976 datapoints
2025-03-06 22:46:54,184 - INFO - Epoch 417/800 done.
2025-03-06 22:46:54,184 - INFO - Final validation performance:
Loss: 1.217, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:46:54,185 - INFO - Beginning epoch 418/800
2025-03-06 22:46:54,189 - INFO - training batch 1, loss: 0.049, 32/28000 datapoints
2025-03-06 22:46:54,345 - INFO - training batch 51, loss: 0.033, 1632/28000 datapoints
2025-03-06 22:46:54,499 - INFO - training batch 101, loss: 0.037, 3232/28000 datapoints
2025-03-06 22:46:54,664 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 22:46:54,826 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 22:46:54,981 - INFO - training batch 251, loss: 0.113, 8032/28000 datapoints
2025-03-06 22:46:55,143 - INFO - training batch 301, loss: 0.139, 9632/28000 datapoints
2025-03-06 22:46:55,307 - INFO - training batch 351, loss: 0.079, 11232/28000 datapoints
2025-03-06 22:46:55,465 - INFO - training batch 401, loss: 0.052, 12832/28000 datapoints
2025-03-06 22:46:55,625 - INFO - training batch 451, loss: 0.134, 14432/28000 datapoints
2025-03-06 22:46:55,787 - INFO - training batch 501, loss: 0.039, 16032/28000 datapoints
2025-03-06 22:46:55,945 - INFO - training batch 551, loss: 0.031, 17632/28000 datapoints
2025-03-06 22:46:56,104 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 22:46:56,258 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:46:56,414 - INFO - training batch 701, loss: 0.028, 22432/28000 datapoints
2025-03-06 22:46:56,568 - INFO - training batch 751, loss: 0.018, 24032/28000 datapoints
2025-03-06 22:46:56,723 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 22:46:56,882 - INFO - training batch 851, loss: 0.042, 27232/28000 datapoints
2025-03-06 22:46:56,957 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 22:46:57,006 - INFO - validation batch 51, loss: 3.193, 1632/6976 datapoints
2025-03-06 22:46:57,055 - INFO - validation batch 101, loss: 0.542, 3232/6976 datapoints
2025-03-06 22:46:57,102 - INFO - validation batch 151, loss: 0.919, 4832/6976 datapoints
2025-03-06 22:46:57,150 - INFO - validation batch 201, loss: 1.337, 6432/6976 datapoints
2025-03-06 22:46:57,167 - INFO - Epoch 418/800 done.
2025-03-06 22:46:57,167 - INFO - Final validation performance:
Loss: 1.224, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:46:57,168 - INFO - Beginning epoch 419/800
2025-03-06 22:46:57,172 - INFO - training batch 1, loss: 0.048, 32/28000 datapoints
2025-03-06 22:46:57,336 - INFO - training batch 51, loss: 0.032, 1632/28000 datapoints
2025-03-06 22:46:57,491 - INFO - training batch 101, loss: 0.037, 3232/28000 datapoints
2025-03-06 22:46:57,648 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 22:46:57,807 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 22:46:57,964 - INFO - training batch 251, loss: 0.109, 8032/28000 datapoints
2025-03-06 22:46:58,118 - INFO - training batch 301, loss: 0.132, 9632/28000 datapoints
2025-03-06 22:46:58,274 - INFO - training batch 351, loss: 0.074, 11232/28000 datapoints
2025-03-06 22:46:58,430 - INFO - training batch 401, loss: 0.052, 12832/28000 datapoints
2025-03-06 22:46:58,588 - INFO - training batch 451, loss: 0.132, 14432/28000 datapoints
2025-03-06 22:46:58,743 - INFO - training batch 501, loss: 0.038, 16032/28000 datapoints
2025-03-06 22:46:58,901 - INFO - training batch 551, loss: 0.030, 17632/28000 datapoints
2025-03-06 22:46:59,057 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 22:46:59,212 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:46:59,368 - INFO - training batch 701, loss: 0.028, 22432/28000 datapoints
2025-03-06 22:46:59,522 - INFO - training batch 751, loss: 0.017, 24032/28000 datapoints
2025-03-06 22:46:59,683 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 22:46:59,867 - INFO - training batch 851, loss: 0.041, 27232/28000 datapoints
2025-03-06 22:46:59,942 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 22:46:59,991 - INFO - validation batch 51, loss: 3.214, 1632/6976 datapoints
2025-03-06 22:47:00,040 - INFO - validation batch 101, loss: 0.546, 3232/6976 datapoints
2025-03-06 22:47:00,087 - INFO - validation batch 151, loss: 0.926, 4832/6976 datapoints
2025-03-06 22:47:00,135 - INFO - validation batch 201, loss: 1.368, 6432/6976 datapoints
2025-03-06 22:47:00,151 - INFO - Epoch 419/800 done.
2025-03-06 22:47:00,151 - INFO - Final validation performance:
Loss: 1.236, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:47:00,151 - INFO - Beginning epoch 420/800
2025-03-06 22:47:00,156 - INFO - training batch 1, loss: 0.046, 32/28000 datapoints
2025-03-06 22:47:00,321 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-06 22:47:00,479 - INFO - training batch 101, loss: 0.037, 3232/28000 datapoints
2025-03-06 22:47:00,633 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-06 22:47:00,805 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 22:47:00,962 - INFO - training batch 251, loss: 0.107, 8032/28000 datapoints
2025-03-06 22:47:01,125 - INFO - training batch 301, loss: 0.128, 9632/28000 datapoints
2025-03-06 22:47:01,285 - INFO - training batch 351, loss: 0.074, 11232/28000 datapoints
2025-03-06 22:47:01,441 - INFO - training batch 401, loss: 0.052, 12832/28000 datapoints
2025-03-06 22:47:01,603 - INFO - training batch 451, loss: 0.129, 14432/28000 datapoints
2025-03-06 22:47:01,762 - INFO - training batch 501, loss: 0.038, 16032/28000 datapoints
2025-03-06 22:47:01,923 - INFO - training batch 551, loss: 0.029, 17632/28000 datapoints
2025-03-06 22:47:02,084 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 22:47:02,240 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:47:02,398 - INFO - training batch 701, loss: 0.027, 22432/28000 datapoints
2025-03-06 22:47:02,552 - INFO - training batch 751, loss: 0.018, 24032/28000 datapoints
2025-03-06 22:47:02,707 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 22:47:02,864 - INFO - training batch 851, loss: 0.040, 27232/28000 datapoints
2025-03-06 22:47:02,942 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 22:47:02,999 - INFO - validation batch 51, loss: 3.243, 1632/6976 datapoints
2025-03-06 22:47:03,054 - INFO - validation batch 101, loss: 0.548, 3232/6976 datapoints
2025-03-06 22:47:03,102 - INFO - validation batch 151, loss: 0.923, 4832/6976 datapoints
2025-03-06 22:47:03,154 - INFO - validation batch 201, loss: 1.378, 6432/6976 datapoints
2025-03-06 22:47:03,172 - INFO - Epoch 420/800 done.
2025-03-06 22:47:03,172 - INFO - Final validation performance:
Loss: 1.244, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:47:03,172 - INFO - Beginning epoch 421/800
2025-03-06 22:47:03,177 - INFO - training batch 1, loss: 0.047, 32/28000 datapoints
2025-03-06 22:47:03,341 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-06 22:47:03,503 - INFO - training batch 101, loss: 0.036, 3232/28000 datapoints
2025-03-06 22:47:03,665 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-06 22:47:03,829 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 22:47:03,993 - INFO - training batch 251, loss: 0.104, 8032/28000 datapoints
2025-03-06 22:47:04,158 - INFO - training batch 301, loss: 0.120, 9632/28000 datapoints
2025-03-06 22:47:04,321 - INFO - training batch 351, loss: 0.070, 11232/28000 datapoints
2025-03-06 22:47:04,480 - INFO - training batch 401, loss: 0.049, 12832/28000 datapoints
2025-03-06 22:47:04,641 - INFO - training batch 451, loss: 0.126, 14432/28000 datapoints
2025-03-06 22:47:04,802 - INFO - training batch 501, loss: 0.037, 16032/28000 datapoints
2025-03-06 22:47:04,970 - INFO - training batch 551, loss: 0.029, 17632/28000 datapoints
2025-03-06 22:47:05,128 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-06 22:47:05,295 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:47:05,456 - INFO - training batch 701, loss: 0.026, 22432/28000 datapoints
2025-03-06 22:47:05,615 - INFO - training batch 751, loss: 0.017, 24032/28000 datapoints
2025-03-06 22:47:05,778 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 22:47:05,939 - INFO - training batch 851, loss: 0.039, 27232/28000 datapoints
2025-03-06 22:47:06,021 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 22:47:06,072 - INFO - validation batch 51, loss: 3.274, 1632/6976 datapoints
2025-03-06 22:47:06,126 - INFO - validation batch 101, loss: 0.546, 3232/6976 datapoints
2025-03-06 22:47:06,178 - INFO - validation batch 151, loss: 0.918, 4832/6976 datapoints
2025-03-06 22:47:06,232 - INFO - validation batch 201, loss: 1.390, 6432/6976 datapoints
2025-03-06 22:47:06,252 - INFO - Epoch 421/800 done.
2025-03-06 22:47:06,252 - INFO - Final validation performance:
Loss: 1.251, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:47:06,253 - INFO - Beginning epoch 422/800
2025-03-06 22:47:06,257 - INFO - training batch 1, loss: 0.045, 32/28000 datapoints
2025-03-06 22:47:06,420 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-06 22:47:06,575 - INFO - training batch 101, loss: 0.036, 3232/28000 datapoints
2025-03-06 22:47:06,743 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-06 22:47:06,904 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 22:47:07,069 - INFO - training batch 251, loss: 0.102, 8032/28000 datapoints
2025-03-06 22:47:07,230 - INFO - training batch 301, loss: 0.117, 9632/28000 datapoints
2025-03-06 22:47:07,394 - INFO - training batch 351, loss: 0.068, 11232/28000 datapoints
2025-03-06 22:47:07,554 - INFO - training batch 401, loss: 0.048, 12832/28000 datapoints
2025-03-06 22:47:07,714 - INFO - training batch 451, loss: 0.124, 14432/28000 datapoints
2025-03-06 22:47:07,873 - INFO - training batch 501, loss: 0.036, 16032/28000 datapoints
2025-03-06 22:47:08,033 - INFO - training batch 551, loss: 0.028, 17632/28000 datapoints
2025-03-06 22:47:08,189 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-06 22:47:08,343 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:47:08,500 - INFO - training batch 701, loss: 0.027, 22432/28000 datapoints
2025-03-06 22:47:08,655 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 22:47:08,811 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:47:08,973 - INFO - training batch 851, loss: 0.038, 27232/28000 datapoints
2025-03-06 22:47:09,048 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 22:47:09,096 - INFO - validation batch 51, loss: 3.294, 1632/6976 datapoints
2025-03-06 22:47:09,143 - INFO - validation batch 101, loss: 0.538, 3232/6976 datapoints
2025-03-06 22:47:09,192 - INFO - validation batch 151, loss: 0.927, 4832/6976 datapoints
2025-03-06 22:47:09,239 - INFO - validation batch 201, loss: 1.399, 6432/6976 datapoints
2025-03-06 22:47:09,256 - INFO - Epoch 422/800 done.
2025-03-06 22:47:09,256 - INFO - Final validation performance:
Loss: 1.258, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:47:09,256 - INFO - Beginning epoch 423/800
2025-03-06 22:47:09,260 - INFO - training batch 1, loss: 0.046, 32/28000 datapoints
2025-03-06 22:47:09,429 - INFO - training batch 51, loss: 0.030, 1632/28000 datapoints
2025-03-06 22:47:09,583 - INFO - training batch 101, loss: 0.034, 3232/28000 datapoints
2025-03-06 22:47:09,737 - INFO - training batch 151, loss: 0.013, 4832/28000 datapoints
2025-03-06 22:47:09,923 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 22:47:10,081 - INFO - training batch 251, loss: 0.099, 8032/28000 datapoints
2025-03-06 22:47:10,236 - INFO - training batch 301, loss: 0.109, 9632/28000 datapoints
2025-03-06 22:47:10,417 - INFO - training batch 351, loss: 0.066, 11232/28000 datapoints
2025-03-06 22:47:10,584 - INFO - training batch 401, loss: 0.047, 12832/28000 datapoints
2025-03-06 22:47:10,741 - INFO - training batch 451, loss: 0.122, 14432/28000 datapoints
2025-03-06 22:47:10,900 - INFO - training batch 501, loss: 0.035, 16032/28000 datapoints
2025-03-06 22:47:11,060 - INFO - training batch 551, loss: 0.027, 17632/28000 datapoints
2025-03-06 22:47:11,214 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-06 22:47:11,369 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:47:11,525 - INFO - training batch 701, loss: 0.026, 22432/28000 datapoints
2025-03-06 22:47:11,680 - INFO - training batch 751, loss: 0.017, 24032/28000 datapoints
2025-03-06 22:47:11,837 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 22:47:11,997 - INFO - training batch 851, loss: 0.037, 27232/28000 datapoints
2025-03-06 22:47:12,073 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 22:47:12,120 - INFO - validation batch 51, loss: 3.324, 1632/6976 datapoints
2025-03-06 22:47:12,168 - INFO - validation batch 101, loss: 0.544, 3232/6976 datapoints
2025-03-06 22:47:12,217 - INFO - validation batch 151, loss: 0.933, 4832/6976 datapoints
2025-03-06 22:47:12,265 - INFO - validation batch 201, loss: 1.410, 6432/6976 datapoints
2025-03-06 22:47:12,281 - INFO - Epoch 423/800 done.
2025-03-06 22:47:12,282 - INFO - Final validation performance:
Loss: 1.268, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:47:12,282 - INFO - Beginning epoch 424/800
2025-03-06 22:47:12,286 - INFO - training batch 1, loss: 0.045, 32/28000 datapoints
2025-03-06 22:47:12,447 - INFO - training batch 51, loss: 0.030, 1632/28000 datapoints
2025-03-06 22:47:12,602 - INFO - training batch 101, loss: 0.036, 3232/28000 datapoints
2025-03-06 22:47:12,757 - INFO - training batch 151, loss: 0.013, 4832/28000 datapoints
2025-03-06 22:47:12,926 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 22:47:13,090 - INFO - training batch 251, loss: 0.094, 8032/28000 datapoints
2025-03-06 22:47:13,245 - INFO - training batch 301, loss: 0.104, 9632/28000 datapoints
2025-03-06 22:47:13,416 - INFO - training batch 351, loss: 0.061, 11232/28000 datapoints
2025-03-06 22:47:13,580 - INFO - training batch 401, loss: 0.048, 12832/28000 datapoints
2025-03-06 22:47:13,750 - INFO - training batch 451, loss: 0.117, 14432/28000 datapoints
2025-03-06 22:47:13,910 - INFO - training batch 501, loss: 0.036, 16032/28000 datapoints
2025-03-06 22:47:14,069 - INFO - training batch 551, loss: 0.026, 17632/28000 datapoints
2025-03-06 22:47:14,223 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-06 22:47:14,378 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:47:14,535 - INFO - training batch 701, loss: 0.026, 22432/28000 datapoints
2025-03-06 22:47:14,692 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 22:47:14,847 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:47:15,007 - INFO - training batch 851, loss: 0.038, 27232/28000 datapoints
2025-03-06 22:47:15,082 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 22:47:15,129 - INFO - validation batch 51, loss: 3.336, 1632/6976 datapoints
2025-03-06 22:47:15,178 - INFO - validation batch 101, loss: 0.541, 3232/6976 datapoints
2025-03-06 22:47:15,232 - INFO - validation batch 151, loss: 0.941, 4832/6976 datapoints
2025-03-06 22:47:15,284 - INFO - validation batch 201, loss: 1.407, 6432/6976 datapoints
2025-03-06 22:47:15,302 - INFO - Epoch 424/800 done.
2025-03-06 22:47:15,302 - INFO - Final validation performance:
Loss: 1.272, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:47:15,302 - INFO - Beginning epoch 425/800
2025-03-06 22:47:15,307 - INFO - training batch 1, loss: 0.046, 32/28000 datapoints
2025-03-06 22:47:15,468 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-06 22:47:15,626 - INFO - training batch 101, loss: 0.034, 3232/28000 datapoints
2025-03-06 22:47:15,785 - INFO - training batch 151, loss: 0.013, 4832/28000 datapoints
2025-03-06 22:47:15,947 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 22:47:16,104 - INFO - training batch 251, loss: 0.094, 8032/28000 datapoints
2025-03-06 22:47:16,259 - INFO - training batch 301, loss: 0.099, 9632/28000 datapoints
2025-03-06 22:47:16,417 - INFO - training batch 351, loss: 0.063, 11232/28000 datapoints
2025-03-06 22:47:16,573 - INFO - training batch 401, loss: 0.045, 12832/28000 datapoints
2025-03-06 22:47:16,729 - INFO - training batch 451, loss: 0.116, 14432/28000 datapoints
2025-03-06 22:47:16,898 - INFO - training batch 501, loss: 0.035, 16032/28000 datapoints
2025-03-06 22:47:17,059 - INFO - training batch 551, loss: 0.026, 17632/28000 datapoints
2025-03-06 22:47:17,213 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 22:47:17,369 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:47:17,527 - INFO - training batch 701, loss: 0.025, 22432/28000 datapoints
2025-03-06 22:47:17,682 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 22:47:17,841 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:47:18,000 - INFO - training batch 851, loss: 0.036, 27232/28000 datapoints
2025-03-06 22:47:18,075 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 22:47:18,124 - INFO - validation batch 51, loss: 3.371, 1632/6976 datapoints
2025-03-06 22:47:18,171 - INFO - validation batch 101, loss: 0.538, 3232/6976 datapoints
2025-03-06 22:47:18,220 - INFO - validation batch 151, loss: 0.943, 4832/6976 datapoints
2025-03-06 22:47:18,269 - INFO - validation batch 201, loss: 1.416, 6432/6976 datapoints
2025-03-06 22:47:18,286 - INFO - Epoch 425/800 done.
2025-03-06 22:47:18,286 - INFO - Final validation performance:
Loss: 1.281, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:47:18,286 - INFO - Beginning epoch 426/800
2025-03-06 22:47:18,291 - INFO - training batch 1, loss: 0.044, 32/28000 datapoints
2025-03-06 22:47:18,452 - INFO - training batch 51, loss: 0.028, 1632/28000 datapoints
2025-03-06 22:47:18,609 - INFO - training batch 101, loss: 0.033, 3232/28000 datapoints
2025-03-06 22:47:18,761 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 22:47:18,932 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 22:47:19,090 - INFO - training batch 251, loss: 0.092, 8032/28000 datapoints
2025-03-06 22:47:19,246 - INFO - training batch 301, loss: 0.094, 9632/28000 datapoints
2025-03-06 22:47:19,401 - INFO - training batch 351, loss: 0.059, 11232/28000 datapoints
2025-03-06 22:47:19,563 - INFO - training batch 401, loss: 0.043, 12832/28000 datapoints
2025-03-06 22:47:19,722 - INFO - training batch 451, loss: 0.112, 14432/28000 datapoints
2025-03-06 22:47:19,892 - INFO - training batch 501, loss: 0.035, 16032/28000 datapoints
2025-03-06 22:47:20,074 - INFO - training batch 551, loss: 0.025, 17632/28000 datapoints
2025-03-06 22:47:20,229 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 22:47:20,385 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:47:20,545 - INFO - training batch 701, loss: 0.026, 22432/28000 datapoints
2025-03-06 22:47:20,700 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-06 22:47:20,856 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:47:21,017 - INFO - training batch 851, loss: 0.035, 27232/28000 datapoints
2025-03-06 22:47:21,093 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 22:47:21,140 - INFO - validation batch 51, loss: 3.392, 1632/6976 datapoints
2025-03-06 22:47:21,187 - INFO - validation batch 101, loss: 0.538, 3232/6976 datapoints
2025-03-06 22:47:21,235 - INFO - validation batch 151, loss: 0.950, 4832/6976 datapoints
2025-03-06 22:47:21,282 - INFO - validation batch 201, loss: 1.429, 6432/6976 datapoints
2025-03-06 22:47:21,299 - INFO - Epoch 426/800 done.
2025-03-06 22:47:21,300 - INFO - Final validation performance:
Loss: 1.289, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:47:21,300 - INFO - Beginning epoch 427/800
2025-03-06 22:47:21,304 - INFO - training batch 1, loss: 0.045, 32/28000 datapoints
2025-03-06 22:47:21,464 - INFO - training batch 51, loss: 0.028, 1632/28000 datapoints
2025-03-06 22:47:21,622 - INFO - training batch 101, loss: 0.033, 3232/28000 datapoints
2025-03-06 22:47:21,777 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 22:47:21,937 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 22:47:22,096 - INFO - training batch 251, loss: 0.088, 8032/28000 datapoints
2025-03-06 22:47:22,254 - INFO - training batch 301, loss: 0.086, 9632/28000 datapoints
2025-03-06 22:47:22,409 - INFO - training batch 351, loss: 0.056, 11232/28000 datapoints
2025-03-06 22:47:22,568 - INFO - training batch 401, loss: 0.044, 12832/28000 datapoints
2025-03-06 22:47:22,728 - INFO - training batch 451, loss: 0.109, 14432/28000 datapoints
2025-03-06 22:47:22,885 - INFO - training batch 501, loss: 0.034, 16032/28000 datapoints
2025-03-06 22:47:23,055 - INFO - training batch 551, loss: 0.025, 17632/28000 datapoints
2025-03-06 22:47:23,213 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 22:47:23,372 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:47:23,532 - INFO - training batch 701, loss: 0.024, 22432/28000 datapoints
2025-03-06 22:47:23,694 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-06 22:47:23,857 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:47:24,020 - INFO - training batch 851, loss: 0.034, 27232/28000 datapoints
2025-03-06 22:47:24,098 - INFO - validation batch 1, loss: 0.139, 32/6976 datapoints
2025-03-06 22:47:24,151 - INFO - validation batch 51, loss: 3.429, 1632/6976 datapoints
2025-03-06 22:47:24,199 - INFO - validation batch 101, loss: 0.535, 3232/6976 datapoints
2025-03-06 22:47:24,247 - INFO - validation batch 151, loss: 0.946, 4832/6976 datapoints
2025-03-06 22:47:24,294 - INFO - validation batch 201, loss: 1.453, 6432/6976 datapoints
2025-03-06 22:47:24,310 - INFO - Epoch 427/800 done.
2025-03-06 22:47:24,311 - INFO - Final validation performance:
Loss: 1.301, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:47:24,311 - INFO - Beginning epoch 428/800
2025-03-06 22:47:24,316 - INFO - training batch 1, loss: 0.042, 32/28000 datapoints
2025-03-06 22:47:24,472 - INFO - training batch 51, loss: 0.028, 1632/28000 datapoints
2025-03-06 22:47:24,630 - INFO - training batch 101, loss: 0.033, 3232/28000 datapoints
2025-03-06 22:47:24,784 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 22:47:24,958 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 22:47:25,116 - INFO - training batch 251, loss: 0.088, 8032/28000 datapoints
2025-03-06 22:47:25,278 - INFO - training batch 301, loss: 0.083, 9632/28000 datapoints
2025-03-06 22:47:25,442 - INFO - training batch 351, loss: 0.054, 11232/28000 datapoints
2025-03-06 22:47:25,604 - INFO - training batch 401, loss: 0.041, 12832/28000 datapoints
2025-03-06 22:47:25,766 - INFO - training batch 451, loss: 0.105, 14432/28000 datapoints
2025-03-06 22:47:25,926 - INFO - training batch 501, loss: 0.033, 16032/28000 datapoints
2025-03-06 22:47:26,089 - INFO - training batch 551, loss: 0.024, 17632/28000 datapoints
2025-03-06 22:47:26,246 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 22:47:26,402 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:47:26,559 - INFO - training batch 701, loss: 0.025, 22432/28000 datapoints
2025-03-06 22:47:26,714 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-06 22:47:26,870 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:47:27,031 - INFO - training batch 851, loss: 0.034, 27232/28000 datapoints
2025-03-06 22:47:27,108 - INFO - validation batch 1, loss: 0.140, 32/6976 datapoints
2025-03-06 22:47:27,155 - INFO - validation batch 51, loss: 3.446, 1632/6976 datapoints
2025-03-06 22:47:27,202 - INFO - validation batch 101, loss: 0.535, 3232/6976 datapoints
2025-03-06 22:47:27,250 - INFO - validation batch 151, loss: 0.962, 4832/6976 datapoints
2025-03-06 22:47:27,299 - INFO - validation batch 201, loss: 1.445, 6432/6976 datapoints
2025-03-06 22:47:27,316 - INFO - Epoch 428/800 done.
2025-03-06 22:47:27,316 - INFO - Final validation performance:
Loss: 1.305, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:47:27,316 - INFO - Beginning epoch 429/800
2025-03-06 22:47:27,320 - INFO - training batch 1, loss: 0.043, 32/28000 datapoints
2025-03-06 22:47:27,482 - INFO - training batch 51, loss: 0.028, 1632/28000 datapoints
2025-03-06 22:47:27,642 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 22:47:27,798 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 22:47:27,958 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 22:47:28,124 - INFO - training batch 251, loss: 0.083, 8032/28000 datapoints
2025-03-06 22:47:28,283 - INFO - training batch 301, loss: 0.077, 9632/28000 datapoints
2025-03-06 22:47:28,439 - INFO - training batch 351, loss: 0.053, 11232/28000 datapoints
2025-03-06 22:47:28,597 - INFO - training batch 401, loss: 0.041, 12832/28000 datapoints
2025-03-06 22:47:28,753 - INFO - training batch 451, loss: 0.102, 14432/28000 datapoints
2025-03-06 22:47:28,909 - INFO - training batch 501, loss: 0.032, 16032/28000 datapoints
2025-03-06 22:47:29,071 - INFO - training batch 551, loss: 0.025, 17632/28000 datapoints
2025-03-06 22:47:29,226 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 22:47:29,382 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:47:29,537 - INFO - training batch 701, loss: 0.024, 22432/28000 datapoints
2025-03-06 22:47:29,694 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 22:47:29,852 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:47:30,025 - INFO - training batch 851, loss: 0.034, 27232/28000 datapoints
2025-03-06 22:47:30,115 - INFO - validation batch 1, loss: 0.144, 32/6976 datapoints
2025-03-06 22:47:30,163 - INFO - validation batch 51, loss: 3.464, 1632/6976 datapoints
2025-03-06 22:47:30,211 - INFO - validation batch 101, loss: 0.528, 3232/6976 datapoints
2025-03-06 22:47:30,258 - INFO - validation batch 151, loss: 0.971, 4832/6976 datapoints
2025-03-06 22:47:30,307 - INFO - validation batch 201, loss: 1.456, 6432/6976 datapoints
2025-03-06 22:47:30,323 - INFO - Epoch 429/800 done.
2025-03-06 22:47:30,324 - INFO - Final validation performance:
Loss: 1.313, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:47:30,324 - INFO - Beginning epoch 430/800
2025-03-06 22:47:30,328 - INFO - training batch 1, loss: 0.044, 32/28000 datapoints
2025-03-06 22:47:30,486 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-06 22:47:30,646 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-06 22:47:30,801 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 22:47:30,970 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 22:47:31,134 - INFO - training batch 251, loss: 0.083, 8032/28000 datapoints
2025-03-06 22:47:31,296 - INFO - training batch 301, loss: 0.074, 9632/28000 datapoints
2025-03-06 22:47:31,458 - INFO - training batch 351, loss: 0.054, 11232/28000 datapoints
2025-03-06 22:47:31,618 - INFO - training batch 401, loss: 0.038, 12832/28000 datapoints
2025-03-06 22:47:31,778 - INFO - training batch 451, loss: 0.103, 14432/28000 datapoints
2025-03-06 22:47:31,941 - INFO - training batch 501, loss: 0.032, 16032/28000 datapoints
2025-03-06 22:47:32,103 - INFO - training batch 551, loss: 0.024, 17632/28000 datapoints
2025-03-06 22:47:32,259 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 22:47:32,416 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:47:32,573 - INFO - training batch 701, loss: 0.023, 22432/28000 datapoints
2025-03-06 22:47:32,730 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 22:47:32,887 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:47:33,048 - INFO - training batch 851, loss: 0.031, 27232/28000 datapoints
2025-03-06 22:47:33,130 - INFO - validation batch 1, loss: 0.142, 32/6976 datapoints
2025-03-06 22:47:33,177 - INFO - validation batch 51, loss: 3.509, 1632/6976 datapoints
2025-03-06 22:47:33,224 - INFO - validation batch 101, loss: 0.527, 3232/6976 datapoints
2025-03-06 22:47:33,272 - INFO - validation batch 151, loss: 0.965, 4832/6976 datapoints
2025-03-06 22:47:33,319 - INFO - validation batch 201, loss: 1.488, 6432/6976 datapoints
2025-03-06 22:47:33,335 - INFO - Epoch 430/800 done.
2025-03-06 22:47:33,335 - INFO - Final validation performance:
Loss: 1.326, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:47:33,336 - INFO - Beginning epoch 431/800
2025-03-06 22:47:33,340 - INFO - training batch 1, loss: 0.040, 32/28000 datapoints
2025-03-06 22:47:33,496 - INFO - training batch 51, loss: 0.026, 1632/28000 datapoints
2025-03-06 22:47:33,656 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-06 22:47:33,810 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 22:47:33,976 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 22:47:34,133 - INFO - training batch 251, loss: 0.080, 8032/28000 datapoints
2025-03-06 22:47:34,291 - INFO - training batch 301, loss: 0.071, 9632/28000 datapoints
2025-03-06 22:47:34,446 - INFO - training batch 351, loss: 0.048, 11232/28000 datapoints
2025-03-06 22:47:34,609 - INFO - training batch 401, loss: 0.040, 12832/28000 datapoints
2025-03-06 22:47:34,767 - INFO - training batch 451, loss: 0.095, 14432/28000 datapoints
2025-03-06 22:47:34,923 - INFO - training batch 501, loss: 0.032, 16032/28000 datapoints
2025-03-06 22:47:35,091 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-06 22:47:35,257 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-06 22:47:35,415 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:47:35,573 - INFO - training batch 701, loss: 0.023, 22432/28000 datapoints
2025-03-06 22:47:35,766 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-06 22:47:35,939 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:47:36,099 - INFO - training batch 851, loss: 0.032, 27232/28000 datapoints
2025-03-06 22:47:36,176 - INFO - validation batch 1, loss: 0.143, 32/6976 datapoints
2025-03-06 22:47:36,223 - INFO - validation batch 51, loss: 3.523, 1632/6976 datapoints
2025-03-06 22:47:36,270 - INFO - validation batch 101, loss: 0.524, 3232/6976 datapoints
2025-03-06 22:47:36,318 - INFO - validation batch 151, loss: 0.982, 4832/6976 datapoints
2025-03-06 22:47:36,366 - INFO - validation batch 201, loss: 1.484, 6432/6976 datapoints
2025-03-06 22:47:36,382 - INFO - Epoch 431/800 done.
2025-03-06 22:47:36,382 - INFO - Final validation performance:
Loss: 1.331, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:47:36,383 - INFO - Beginning epoch 432/800
2025-03-06 22:47:36,387 - INFO - training batch 1, loss: 0.043, 32/28000 datapoints
2025-03-06 22:47:36,544 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-06 22:47:36,704 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-06 22:47:36,859 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 22:47:37,031 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 22:47:37,189 - INFO - training batch 251, loss: 0.078, 8032/28000 datapoints
2025-03-06 22:47:37,348 - INFO - training batch 301, loss: 0.065, 9632/28000 datapoints
2025-03-06 22:47:37,509 - INFO - training batch 351, loss: 0.048, 11232/28000 datapoints
2025-03-06 22:47:37,669 - INFO - training batch 401, loss: 0.039, 12832/28000 datapoints
2025-03-06 22:47:37,832 - INFO - training batch 451, loss: 0.093, 14432/28000 datapoints
2025-03-06 22:47:38,010 - INFO - training batch 501, loss: 0.031, 16032/28000 datapoints
2025-03-06 22:47:38,170 - INFO - training batch 551, loss: 0.023, 17632/28000 datapoints
2025-03-06 22:47:38,327 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 22:47:38,484 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:47:38,642 - INFO - training batch 701, loss: 0.023, 22432/28000 datapoints
2025-03-06 22:47:38,798 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-06 22:47:38,954 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:47:39,112 - INFO - training batch 851, loss: 0.031, 27232/28000 datapoints
2025-03-06 22:47:39,261 - INFO - validation batch 1, loss: 0.145, 32/6976 datapoints
2025-03-06 22:47:39,308 - INFO - validation batch 51, loss: 3.555, 1632/6976 datapoints
2025-03-06 22:47:39,359 - INFO - validation batch 101, loss: 0.519, 3232/6976 datapoints
2025-03-06 22:47:39,412 - INFO - validation batch 151, loss: 0.975, 4832/6976 datapoints
2025-03-06 22:47:39,461 - INFO - validation batch 201, loss: 1.492, 6432/6976 datapoints
2025-03-06 22:47:39,477 - INFO - Epoch 432/800 done.
2025-03-06 22:47:39,477 - INFO - Final validation performance:
Loss: 1.337, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:47:39,478 - INFO - Beginning epoch 433/800
2025-03-06 22:47:39,482 - INFO - training batch 1, loss: 0.041, 32/28000 datapoints
2025-03-06 22:47:39,640 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-06 22:47:39,797 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-06 22:47:39,958 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 22:47:40,169 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 22:47:40,373 - INFO - training batch 251, loss: 0.075, 8032/28000 datapoints
2025-03-06 22:47:40,531 - INFO - training batch 301, loss: 0.064, 9632/28000 datapoints
2025-03-06 22:47:40,690 - INFO - training batch 351, loss: 0.045, 11232/28000 datapoints
2025-03-06 22:47:40,846 - INFO - training batch 401, loss: 0.036, 12832/28000 datapoints
2025-03-06 22:47:41,007 - INFO - training batch 451, loss: 0.090, 14432/28000 datapoints
2025-03-06 22:47:41,165 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-06 22:47:41,323 - INFO - training batch 551, loss: 0.022, 17632/28000 datapoints
2025-03-06 22:47:41,477 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-06 22:47:41,635 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:47:41,792 - INFO - training batch 701, loss: 0.024, 22432/28000 datapoints
2025-03-06 22:47:41,950 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 22:47:42,109 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:47:42,266 - INFO - training batch 851, loss: 0.030, 27232/28000 datapoints
2025-03-06 22:47:42,345 - INFO - validation batch 1, loss: 0.149, 32/6976 datapoints
2025-03-06 22:47:42,392 - INFO - validation batch 51, loss: 3.575, 1632/6976 datapoints
2025-03-06 22:47:42,439 - INFO - validation batch 101, loss: 0.517, 3232/6976 datapoints
2025-03-06 22:47:42,487 - INFO - validation batch 151, loss: 1.006, 4832/6976 datapoints
2025-03-06 22:47:42,534 - INFO - validation batch 201, loss: 1.509, 6432/6976 datapoints
2025-03-06 22:47:42,552 - INFO - Epoch 433/800 done.
2025-03-06 22:47:42,552 - INFO - Final validation performance:
Loss: 1.351, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:47:42,552 - INFO - Beginning epoch 434/800
2025-03-06 22:47:42,557 - INFO - training batch 1, loss: 0.041, 32/28000 datapoints
2025-03-06 22:47:42,714 - INFO - training batch 51, loss: 0.026, 1632/28000 datapoints
2025-03-06 22:47:42,872 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 22:47:43,046 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 22:47:43,217 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 22:47:43,377 - INFO - training batch 251, loss: 0.075, 8032/28000 datapoints
2025-03-06 22:47:43,543 - INFO - training batch 301, loss: 0.060, 9632/28000 datapoints
2025-03-06 22:47:43,713 - INFO - training batch 351, loss: 0.044, 11232/28000 datapoints
2025-03-06 22:47:43,877 - INFO - training batch 401, loss: 0.036, 12832/28000 datapoints
2025-03-06 22:47:44,047 - INFO - training batch 451, loss: 0.087, 14432/28000 datapoints
2025-03-06 22:47:44,207 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-06 22:47:44,369 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-06 22:47:44,526 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-06 22:47:44,687 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:47:44,847 - INFO - training batch 701, loss: 0.022, 22432/28000 datapoints
2025-03-06 22:47:45,010 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 22:47:45,177 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:47:45,343 - INFO - training batch 851, loss: 0.030, 27232/28000 datapoints
2025-03-06 22:47:45,423 - INFO - validation batch 1, loss: 0.145, 32/6976 datapoints
2025-03-06 22:47:45,477 - INFO - validation batch 51, loss: 3.602, 1632/6976 datapoints
2025-03-06 22:47:45,529 - INFO - validation batch 101, loss: 0.515, 3232/6976 datapoints
2025-03-06 22:47:45,582 - INFO - validation batch 151, loss: 1.003, 4832/6976 datapoints
2025-03-06 22:47:45,637 - INFO - validation batch 201, loss: 1.521, 6432/6976 datapoints
2025-03-06 22:47:45,657 - INFO - Epoch 434/800 done.
2025-03-06 22:47:45,657 - INFO - Final validation performance:
Loss: 1.357, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:47:45,657 - INFO - Beginning epoch 435/800
2025-03-06 22:47:45,663 - INFO - training batch 1, loss: 0.040, 32/28000 datapoints
2025-03-06 22:47:45,825 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-06 22:47:45,986 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 22:47:46,146 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 22:47:46,302 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 22:47:46,459 - INFO - training batch 251, loss: 0.072, 8032/28000 datapoints
2025-03-06 22:47:46,618 - INFO - training batch 301, loss: 0.057, 9632/28000 datapoints
2025-03-06 22:47:46,775 - INFO - training batch 351, loss: 0.043, 11232/28000 datapoints
2025-03-06 22:47:46,932 - INFO - training batch 401, loss: 0.035, 12832/28000 datapoints
2025-03-06 22:47:47,105 - INFO - training batch 451, loss: 0.082, 14432/28000 datapoints
2025-03-06 22:47:47,273 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-06 22:47:47,434 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-06 22:47:47,591 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-06 22:47:47,748 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:47:47,908 - INFO - training batch 701, loss: 0.022, 22432/28000 datapoints
2025-03-06 22:47:48,065 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 22:47:48,223 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:47:48,383 - INFO - training batch 851, loss: 0.029, 27232/28000 datapoints
2025-03-06 22:47:48,461 - INFO - validation batch 1, loss: 0.148, 32/6976 datapoints
2025-03-06 22:47:48,508 - INFO - validation batch 51, loss: 3.629, 1632/6976 datapoints
2025-03-06 22:47:48,556 - INFO - validation batch 101, loss: 0.511, 3232/6976 datapoints
2025-03-06 22:47:48,604 - INFO - validation batch 151, loss: 1.007, 4832/6976 datapoints
2025-03-06 22:47:48,653 - INFO - validation batch 201, loss: 1.536, 6432/6976 datapoints
2025-03-06 22:47:48,670 - INFO - Epoch 435/800 done.
2025-03-06 22:47:48,670 - INFO - Final validation performance:
Loss: 1.366, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:47:48,670 - INFO - Beginning epoch 436/800
2025-03-06 22:47:48,675 - INFO - training batch 1, loss: 0.040, 32/28000 datapoints
2025-03-06 22:47:48,831 - INFO - training batch 51, loss: 0.024, 1632/28000 datapoints
2025-03-06 22:47:49,003 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 22:47:49,168 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 22:47:49,325 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 22:47:49,489 - INFO - training batch 251, loss: 0.069, 8032/28000 datapoints
2025-03-06 22:47:49,652 - INFO - training batch 301, loss: 0.053, 9632/28000 datapoints
2025-03-06 22:47:49,816 - INFO - training batch 351, loss: 0.041, 11232/28000 datapoints
2025-03-06 22:47:50,011 - INFO - training batch 401, loss: 0.034, 12832/28000 datapoints
2025-03-06 22:47:50,168 - INFO - training batch 451, loss: 0.079, 14432/28000 datapoints
2025-03-06 22:47:50,359 - INFO - training batch 501, loss: 0.029, 16032/28000 datapoints
2025-03-06 22:47:50,517 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-06 22:47:50,674 - INFO - training batch 601, loss: 0.018, 19232/28000 datapoints
2025-03-06 22:47:50,830 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:47:50,989 - INFO - training batch 701, loss: 0.023, 22432/28000 datapoints
2025-03-06 22:47:51,153 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 22:47:51,310 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:47:51,470 - INFO - training batch 851, loss: 0.028, 27232/28000 datapoints
2025-03-06 22:47:51,554 - INFO - validation batch 1, loss: 0.149, 32/6976 datapoints
2025-03-06 22:47:51,605 - INFO - validation batch 51, loss: 3.664, 1632/6976 datapoints
2025-03-06 22:47:51,654 - INFO - validation batch 101, loss: 0.506, 3232/6976 datapoints
2025-03-06 22:47:51,702 - INFO - validation batch 151, loss: 1.009, 4832/6976 datapoints
2025-03-06 22:47:51,749 - INFO - validation batch 201, loss: 1.542, 6432/6976 datapoints
2025-03-06 22:47:51,765 - INFO - Epoch 436/800 done.
2025-03-06 22:47:51,766 - INFO - Final validation performance:
Loss: 1.374, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:47:51,766 - INFO - Beginning epoch 437/800
2025-03-06 22:47:51,770 - INFO - training batch 1, loss: 0.039, 32/28000 datapoints
2025-03-06 22:47:51,935 - INFO - training batch 51, loss: 0.024, 1632/28000 datapoints
2025-03-06 22:47:52,092 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 22:47:52,251 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-06 22:47:52,410 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 22:47:52,566 - INFO - training batch 251, loss: 0.070, 8032/28000 datapoints
2025-03-06 22:47:52,727 - INFO - training batch 301, loss: 0.054, 9632/28000 datapoints
2025-03-06 22:47:52,888 - INFO - training batch 351, loss: 0.042, 11232/28000 datapoints
2025-03-06 22:47:53,052 - INFO - training batch 401, loss: 0.033, 12832/28000 datapoints
2025-03-06 22:47:53,232 - INFO - training batch 451, loss: 0.077, 14432/28000 datapoints
2025-03-06 22:47:53,391 - INFO - training batch 501, loss: 0.028, 16032/28000 datapoints
2025-03-06 22:47:53,550 - INFO - training batch 551, loss: 0.020, 17632/28000 datapoints
2025-03-06 22:47:53,710 - INFO - training batch 601, loss: 0.018, 19232/28000 datapoints
2025-03-06 22:47:53,870 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:47:54,033 - INFO - training batch 701, loss: 0.021, 22432/28000 datapoints
2025-03-06 22:47:54,188 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 22:47:54,344 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:47:54,503 - INFO - training batch 851, loss: 0.027, 27232/28000 datapoints
2025-03-06 22:47:54,580 - INFO - validation batch 1, loss: 0.148, 32/6976 datapoints
2025-03-06 22:47:54,627 - INFO - validation batch 51, loss: 3.698, 1632/6976 datapoints
2025-03-06 22:47:54,675 - INFO - validation batch 101, loss: 0.507, 3232/6976 datapoints
2025-03-06 22:47:54,723 - INFO - validation batch 151, loss: 1.010, 4832/6976 datapoints
2025-03-06 22:47:54,770 - INFO - validation batch 201, loss: 1.560, 6432/6976 datapoints
2025-03-06 22:47:54,786 - INFO - Epoch 437/800 done.
2025-03-06 22:47:54,787 - INFO - Final validation performance:
Loss: 1.385, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:47:54,787 - INFO - Beginning epoch 438/800
2025-03-06 22:47:54,791 - INFO - training batch 1, loss: 0.038, 32/28000 datapoints
2025-03-06 22:47:54,951 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-06 22:47:55,120 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 22:47:55,284 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-06 22:47:55,452 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 22:47:55,617 - INFO - training batch 251, loss: 0.066, 8032/28000 datapoints
2025-03-06 22:47:55,779 - INFO - training batch 301, loss: 0.050, 9632/28000 datapoints
2025-03-06 22:47:55,944 - INFO - training batch 351, loss: 0.037, 11232/28000 datapoints
2025-03-06 22:47:56,110 - INFO - training batch 401, loss: 0.032, 12832/28000 datapoints
2025-03-06 22:47:56,267 - INFO - training batch 451, loss: 0.071, 14432/28000 datapoints
2025-03-06 22:47:56,424 - INFO - training batch 501, loss: 0.028, 16032/28000 datapoints
2025-03-06 22:47:56,583 - INFO - training batch 551, loss: 0.020, 17632/28000 datapoints
2025-03-06 22:47:56,740 - INFO - training batch 601, loss: 0.018, 19232/28000 datapoints
2025-03-06 22:47:56,897 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:47:57,056 - INFO - training batch 701, loss: 0.022, 22432/28000 datapoints
2025-03-06 22:47:57,213 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-06 22:47:57,371 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:47:57,530 - INFO - training batch 851, loss: 0.027, 27232/28000 datapoints
2025-03-06 22:47:57,606 - INFO - validation batch 1, loss: 0.152, 32/6976 datapoints
2025-03-06 22:47:57,654 - INFO - validation batch 51, loss: 3.721, 1632/6976 datapoints
2025-03-06 22:47:57,702 - INFO - validation batch 101, loss: 0.498, 3232/6976 datapoints
2025-03-06 22:47:57,750 - INFO - validation batch 151, loss: 1.020, 4832/6976 datapoints
2025-03-06 22:47:57,798 - INFO - validation batch 201, loss: 1.583, 6432/6976 datapoints
2025-03-06 22:47:57,814 - INFO - Epoch 438/800 done.
2025-03-06 22:47:57,814 - INFO - Final validation performance:
Loss: 1.395, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:47:57,815 - INFO - Beginning epoch 439/800
2025-03-06 22:47:57,819 - INFO - training batch 1, loss: 0.039, 32/28000 datapoints
2025-03-06 22:47:57,982 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-06 22:47:58,139 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 22:47:58,297 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-06 22:47:58,458 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 22:47:58,618 - INFO - training batch 251, loss: 0.065, 8032/28000 datapoints
2025-03-06 22:47:58,778 - INFO - training batch 301, loss: 0.048, 9632/28000 datapoints
2025-03-06 22:47:58,937 - INFO - training batch 351, loss: 0.036, 11232/28000 datapoints
2025-03-06 22:47:59,096 - INFO - training batch 401, loss: 0.031, 12832/28000 datapoints
2025-03-06 22:47:59,254 - INFO - training batch 451, loss: 0.071, 14432/28000 datapoints
2025-03-06 22:47:59,412 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-06 22:47:59,569 - INFO - training batch 551, loss: 0.020, 17632/28000 datapoints
2025-03-06 22:47:59,727 - INFO - training batch 601, loss: 0.018, 19232/28000 datapoints
2025-03-06 22:47:59,881 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:48:00,048 - INFO - training batch 701, loss: 0.020, 22432/28000 datapoints
2025-03-06 22:48:00,204 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-06 22:48:00,379 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:48:00,543 - INFO - training batch 851, loss: 0.026, 27232/28000 datapoints
2025-03-06 22:48:00,619 - INFO - validation batch 1, loss: 0.150, 32/6976 datapoints
2025-03-06 22:48:00,672 - INFO - validation batch 51, loss: 3.753, 1632/6976 datapoints
2025-03-06 22:48:00,721 - INFO - validation batch 101, loss: 0.502, 3232/6976 datapoints
2025-03-06 22:48:00,768 - INFO - validation batch 151, loss: 1.024, 4832/6976 datapoints
2025-03-06 22:48:00,818 - INFO - validation batch 201, loss: 1.600, 6432/6976 datapoints
2025-03-06 22:48:00,834 - INFO - Epoch 439/800 done.
2025-03-06 22:48:00,835 - INFO - Final validation performance:
Loss: 1.406, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:48:00,835 - INFO - Beginning epoch 440/800
2025-03-06 22:48:00,839 - INFO - training batch 1, loss: 0.037, 32/28000 datapoints
2025-03-06 22:48:01,007 - INFO - training batch 51, loss: 0.022, 1632/28000 datapoints
2025-03-06 22:48:01,181 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 22:48:01,338 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-06 22:48:01,495 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 22:48:01,663 - INFO - training batch 251, loss: 0.062, 8032/28000 datapoints
2025-03-06 22:48:01,827 - INFO - training batch 301, loss: 0.045, 9632/28000 datapoints
2025-03-06 22:48:01,998 - INFO - training batch 351, loss: 0.035, 11232/28000 datapoints
2025-03-06 22:48:02,162 - INFO - training batch 401, loss: 0.030, 12832/28000 datapoints
2025-03-06 22:48:02,321 - INFO - training batch 451, loss: 0.065, 14432/28000 datapoints
2025-03-06 22:48:02,480 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-06 22:48:02,639 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-06 22:48:02,798 - INFO - training batch 601, loss: 0.018, 19232/28000 datapoints
2025-03-06 22:48:02,955 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:48:03,115 - INFO - training batch 701, loss: 0.022, 22432/28000 datapoints
2025-03-06 22:48:03,275 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 22:48:03,442 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:48:03,605 - INFO - training batch 851, loss: 0.025, 27232/28000 datapoints
2025-03-06 22:48:03,685 - INFO - validation batch 1, loss: 0.157, 32/6976 datapoints
2025-03-06 22:48:03,736 - INFO - validation batch 51, loss: 3.774, 1632/6976 datapoints
2025-03-06 22:48:03,789 - INFO - validation batch 101, loss: 0.496, 3232/6976 datapoints
2025-03-06 22:48:03,839 - INFO - validation batch 151, loss: 1.048, 4832/6976 datapoints
2025-03-06 22:48:03,892 - INFO - validation batch 201, loss: 1.604, 6432/6976 datapoints
2025-03-06 22:48:03,909 - INFO - Epoch 440/800 done.
2025-03-06 22:48:03,909 - INFO - Final validation performance:
Loss: 1.416, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:48:03,910 - INFO - Beginning epoch 441/800
2025-03-06 22:48:03,916 - INFO - training batch 1, loss: 0.038, 32/28000 datapoints
2025-03-06 22:48:04,091 - INFO - training batch 51, loss: 0.021, 1632/28000 datapoints
2025-03-06 22:48:04,251 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-06 22:48:04,416 - INFO - training batch 151, loss: 0.008, 4832/28000 datapoints
2025-03-06 22:48:04,580 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 22:48:04,747 - INFO - training batch 251, loss: 0.064, 8032/28000 datapoints
2025-03-06 22:48:04,912 - INFO - training batch 301, loss: 0.044, 9632/28000 datapoints
2025-03-06 22:48:05,077 - INFO - training batch 351, loss: 0.035, 11232/28000 datapoints
2025-03-06 22:48:05,244 - INFO - training batch 401, loss: 0.030, 12832/28000 datapoints
2025-03-06 22:48:05,406 - INFO - training batch 451, loss: 0.063, 14432/28000 datapoints
2025-03-06 22:48:05,568 - INFO - training batch 501, loss: 0.026, 16032/28000 datapoints
2025-03-06 22:48:05,736 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-06 22:48:05,897 - INFO - training batch 601, loss: 0.018, 19232/28000 datapoints
2025-03-06 22:48:06,063 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 22:48:06,225 - INFO - training batch 701, loss: 0.020, 22432/28000 datapoints
2025-03-06 22:48:06,385 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 22:48:06,547 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:48:06,710 - INFO - training batch 851, loss: 0.025, 27232/28000 datapoints
2025-03-06 22:48:06,790 - INFO - validation batch 1, loss: 0.151, 32/6976 datapoints
2025-03-06 22:48:06,844 - INFO - validation batch 51, loss: 3.813, 1632/6976 datapoints
2025-03-06 22:48:06,897 - INFO - validation batch 101, loss: 0.493, 3232/6976 datapoints
2025-03-06 22:48:06,949 - INFO - validation batch 151, loss: 1.030, 4832/6976 datapoints
2025-03-06 22:48:07,004 - INFO - validation batch 201, loss: 1.616, 6432/6976 datapoints
2025-03-06 22:48:07,022 - INFO - Epoch 441/800 done.
2025-03-06 22:48:07,022 - INFO - Final validation performance:
Loss: 1.421, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:48:07,023 - INFO - Beginning epoch 442/800
2025-03-06 22:48:07,027 - INFO - training batch 1, loss: 0.038, 32/28000 datapoints
2025-03-06 22:48:07,192 - INFO - training batch 51, loss: 0.021, 1632/28000 datapoints
2025-03-06 22:48:07,368 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-06 22:48:07,532 - INFO - training batch 151, loss: 0.008, 4832/28000 datapoints
2025-03-06 22:48:07,694 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 22:48:07,864 - INFO - training batch 251, loss: 0.059, 8032/28000 datapoints
2025-03-06 22:48:08,036 - INFO - training batch 301, loss: 0.044, 9632/28000 datapoints
2025-03-06 22:48:08,198 - INFO - training batch 351, loss: 0.032, 11232/28000 datapoints
2025-03-06 22:48:08,367 - INFO - training batch 401, loss: 0.030, 12832/28000 datapoints
2025-03-06 22:48:08,531 - INFO - training batch 451, loss: 0.059, 14432/28000 datapoints
2025-03-06 22:48:08,694 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-06 22:48:08,856 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-06 22:48:09,019 - INFO - training batch 601, loss: 0.017, 19232/28000 datapoints
2025-03-06 22:48:09,180 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:48:09,342 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-06 22:48:09,505 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 22:48:09,668 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:48:09,832 - INFO - training batch 851, loss: 0.025, 27232/28000 datapoints
2025-03-06 22:48:09,912 - INFO - validation batch 1, loss: 0.154, 32/6976 datapoints
2025-03-06 22:48:09,965 - INFO - validation batch 51, loss: 3.833, 1632/6976 datapoints
2025-03-06 22:48:10,021 - INFO - validation batch 101, loss: 0.490, 3232/6976 datapoints
2025-03-06 22:48:10,072 - INFO - validation batch 151, loss: 1.040, 4832/6976 datapoints
2025-03-06 22:48:10,125 - INFO - validation batch 201, loss: 1.630, 6432/6976 datapoints
2025-03-06 22:48:10,141 - INFO - Epoch 442/800 done.
2025-03-06 22:48:10,141 - INFO - Final validation performance:
Loss: 1.430, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:48:10,142 - INFO - Beginning epoch 443/800
2025-03-06 22:48:10,149 - INFO - training batch 1, loss: 0.037, 32/28000 datapoints
2025-03-06 22:48:10,314 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-06 22:48:10,500 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 22:48:10,664 - INFO - training batch 151, loss: 0.008, 4832/28000 datapoints
2025-03-06 22:48:10,827 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 22:48:10,990 - INFO - training batch 251, loss: 0.056, 8032/28000 datapoints
2025-03-06 22:48:11,156 - INFO - training batch 301, loss: 0.041, 9632/28000 datapoints
2025-03-06 22:48:11,317 - INFO - training batch 351, loss: 0.031, 11232/28000 datapoints
2025-03-06 22:48:11,476 - INFO - training batch 401, loss: 0.028, 12832/28000 datapoints
2025-03-06 22:48:11,638 - INFO - training batch 451, loss: 0.058, 14432/28000 datapoints
2025-03-06 22:48:11,802 - INFO - training batch 501, loss: 0.025, 16032/28000 datapoints
2025-03-06 22:48:11,965 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 22:48:12,128 - INFO - training batch 601, loss: 0.018, 19232/28000 datapoints
2025-03-06 22:48:12,290 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:48:12,453 - INFO - training batch 701, loss: 0.020, 22432/28000 datapoints
2025-03-06 22:48:12,613 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 22:48:12,774 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:48:12,936 - INFO - training batch 851, loss: 0.023, 27232/28000 datapoints
2025-03-06 22:48:13,018 - INFO - validation batch 1, loss: 0.162, 32/6976 datapoints
2025-03-06 22:48:13,070 - INFO - validation batch 51, loss: 3.877, 1632/6976 datapoints
2025-03-06 22:48:13,122 - INFO - validation batch 101, loss: 0.489, 3232/6976 datapoints
2025-03-06 22:48:13,175 - INFO - validation batch 151, loss: 1.054, 4832/6976 datapoints
2025-03-06 22:48:13,233 - INFO - validation batch 201, loss: 1.659, 6432/6976 datapoints
2025-03-06 22:48:13,252 - INFO - Epoch 443/800 done.
2025-03-06 22:48:13,252 - INFO - Final validation performance:
Loss: 1.448, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:48:13,253 - INFO - Beginning epoch 444/800
2025-03-06 22:48:13,258 - INFO - training batch 1, loss: 0.038, 32/28000 datapoints
2025-03-06 22:48:13,438 - INFO - training batch 51, loss: 0.019, 1632/28000 datapoints
2025-03-06 22:48:13,604 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 22:48:13,777 - INFO - training batch 151, loss: 0.008, 4832/28000 datapoints
2025-03-06 22:48:13,939 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 22:48:14,106 - INFO - training batch 251, loss: 0.057, 8032/28000 datapoints
2025-03-06 22:48:14,303 - INFO - training batch 301, loss: 0.041, 9632/28000 datapoints
2025-03-06 22:48:14,460 - INFO - training batch 351, loss: 0.029, 11232/28000 datapoints
2025-03-06 22:48:14,616 - INFO - training batch 401, loss: 0.028, 12832/28000 datapoints
2025-03-06 22:48:14,779 - INFO - training batch 451, loss: 0.053, 14432/28000 datapoints
2025-03-06 22:48:14,937 - INFO - training batch 501, loss: 0.023, 16032/28000 datapoints
2025-03-06 22:48:15,097 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-06 22:48:15,261 - INFO - training batch 601, loss: 0.017, 19232/28000 datapoints
2025-03-06 22:48:15,430 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:48:15,590 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-06 22:48:15,752 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 22:48:15,912 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:48:16,078 - INFO - training batch 851, loss: 0.023, 27232/28000 datapoints
2025-03-06 22:48:16,156 - INFO - validation batch 1, loss: 0.154, 32/6976 datapoints
2025-03-06 22:48:16,204 - INFO - validation batch 51, loss: 3.888, 1632/6976 datapoints
2025-03-06 22:48:16,255 - INFO - validation batch 101, loss: 0.488, 3232/6976 datapoints
2025-03-06 22:48:16,302 - INFO - validation batch 151, loss: 1.064, 4832/6976 datapoints
2025-03-06 22:48:16,350 - INFO - validation batch 201, loss: 1.667, 6432/6976 datapoints
2025-03-06 22:48:16,366 - INFO - Epoch 444/800 done.
2025-03-06 22:48:16,366 - INFO - Final validation performance:
Loss: 1.452, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:48:16,367 - INFO - Beginning epoch 445/800
2025-03-06 22:48:16,372 - INFO - training batch 1, loss: 0.036, 32/28000 datapoints
2025-03-06 22:48:16,533 - INFO - training batch 51, loss: 0.019, 1632/28000 datapoints
2025-03-06 22:48:16,689 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 22:48:16,852 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-06 22:48:17,010 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 22:48:17,168 - INFO - training batch 251, loss: 0.055, 8032/28000 datapoints
2025-03-06 22:48:17,335 - INFO - training batch 301, loss: 0.041, 9632/28000 datapoints
2025-03-06 22:48:17,496 - INFO - training batch 351, loss: 0.033, 11232/28000 datapoints
2025-03-06 22:48:17,654 - INFO - training batch 401, loss: 0.026, 12832/28000 datapoints
2025-03-06 22:48:17,814 - INFO - training batch 451, loss: 0.054, 14432/28000 datapoints
2025-03-06 22:48:17,976 - INFO - training batch 501, loss: 0.026, 16032/28000 datapoints
2025-03-06 22:48:18,138 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 22:48:18,296 - INFO - training batch 601, loss: 0.017, 19232/28000 datapoints
2025-03-06 22:48:18,453 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:48:18,615 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-06 22:48:18,776 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 22:48:18,934 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:48:19,096 - INFO - training batch 851, loss: 0.023, 27232/28000 datapoints
2025-03-06 22:48:19,173 - INFO - validation batch 1, loss: 0.161, 32/6976 datapoints
2025-03-06 22:48:19,221 - INFO - validation batch 51, loss: 3.929, 1632/6976 datapoints
2025-03-06 22:48:19,270 - INFO - validation batch 101, loss: 0.481, 3232/6976 datapoints
2025-03-06 22:48:19,317 - INFO - validation batch 151, loss: 1.068, 4832/6976 datapoints
2025-03-06 22:48:19,365 - INFO - validation batch 201, loss: 1.676, 6432/6976 datapoints
2025-03-06 22:48:19,381 - INFO - Epoch 445/800 done.
2025-03-06 22:48:19,381 - INFO - Final validation performance:
Loss: 1.463, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:48:19,382 - INFO - Beginning epoch 446/800
2025-03-06 22:48:19,386 - INFO - training batch 1, loss: 0.037, 32/28000 datapoints
2025-03-06 22:48:19,561 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-06 22:48:19,719 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 22:48:19,893 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-06 22:48:20,090 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 22:48:20,291 - INFO - training batch 251, loss: 0.054, 8032/28000 datapoints
2025-03-06 22:48:20,478 - INFO - training batch 301, loss: 0.039, 9632/28000 datapoints
2025-03-06 22:48:20,680 - INFO - training batch 351, loss: 0.027, 11232/28000 datapoints
2025-03-06 22:48:20,851 - INFO - training batch 401, loss: 0.026, 12832/28000 datapoints
2025-03-06 22:48:21,014 - INFO - training batch 451, loss: 0.047, 14432/28000 datapoints
2025-03-06 22:48:21,172 - INFO - training batch 501, loss: 0.025, 16032/28000 datapoints
2025-03-06 22:48:21,331 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 22:48:21,488 - INFO - training batch 601, loss: 0.017, 19232/28000 datapoints
2025-03-06 22:48:21,647 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:48:21,806 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-06 22:48:21,975 - INFO - training batch 751, loss: 0.009, 24032/28000 datapoints
2025-03-06 22:48:22,137 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:48:22,299 - INFO - training batch 851, loss: 0.022, 27232/28000 datapoints
2025-03-06 22:48:22,379 - INFO - validation batch 1, loss: 0.160, 32/6976 datapoints
2025-03-06 22:48:22,427 - INFO - validation batch 51, loss: 3.942, 1632/6976 datapoints
2025-03-06 22:48:22,476 - INFO - validation batch 101, loss: 0.476, 3232/6976 datapoints
2025-03-06 22:48:22,526 - INFO - validation batch 151, loss: 1.092, 4832/6976 datapoints
2025-03-06 22:48:22,574 - INFO - validation batch 201, loss: 1.698, 6432/6976 datapoints
2025-03-06 22:48:22,590 - INFO - Epoch 446/800 done.
2025-03-06 22:48:22,591 - INFO - Final validation performance:
Loss: 1.474, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:48:22,591 - INFO - Beginning epoch 447/800
2025-03-06 22:48:22,595 - INFO - training batch 1, loss: 0.035, 32/28000 datapoints
2025-03-06 22:48:22,753 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-06 22:48:22,915 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 22:48:23,077 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-06 22:48:23,235 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 22:48:23,399 - INFO - training batch 251, loss: 0.052, 8032/28000 datapoints
2025-03-06 22:48:23,569 - INFO - training batch 301, loss: 0.037, 9632/28000 datapoints
2025-03-06 22:48:23,734 - INFO - training batch 351, loss: 0.022, 11232/28000 datapoints
2025-03-06 22:48:23,897 - INFO - training batch 401, loss: 0.026, 12832/28000 datapoints
2025-03-06 22:48:24,066 - INFO - training batch 451, loss: 0.044, 14432/28000 datapoints
2025-03-06 22:48:24,229 - INFO - training batch 501, loss: 0.024, 16032/28000 datapoints
2025-03-06 22:48:24,396 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 22:48:24,556 - INFO - training batch 601, loss: 0.014, 19232/28000 datapoints
2025-03-06 22:48:24,716 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:48:24,880 - INFO - training batch 701, loss: 0.017, 22432/28000 datapoints
2025-03-06 22:48:25,042 - INFO - training batch 751, loss: 0.009, 24032/28000 datapoints
2025-03-06 22:48:25,209 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:48:25,377 - INFO - training batch 851, loss: 0.022, 27232/28000 datapoints
2025-03-06 22:48:25,458 - INFO - validation batch 1, loss: 0.161, 32/6976 datapoints
2025-03-06 22:48:25,510 - INFO - validation batch 51, loss: 3.950, 1632/6976 datapoints
2025-03-06 22:48:25,558 - INFO - validation batch 101, loss: 0.476, 3232/6976 datapoints
2025-03-06 22:48:25,617 - INFO - validation batch 151, loss: 1.088, 4832/6976 datapoints
2025-03-06 22:48:25,676 - INFO - validation batch 201, loss: 1.719, 6432/6976 datapoints
2025-03-06 22:48:25,693 - INFO - Epoch 447/800 done.
2025-03-06 22:48:25,693 - INFO - Final validation performance:
Loss: 1.479, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:48:25,694 - INFO - Beginning epoch 448/800
2025-03-06 22:48:25,698 - INFO - training batch 1, loss: 0.036, 32/28000 datapoints
2025-03-06 22:48:25,864 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 22:48:26,024 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 22:48:26,187 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-06 22:48:26,345 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 22:48:26,505 - INFO - training batch 251, loss: 0.052, 8032/28000 datapoints
2025-03-06 22:48:26,666 - INFO - training batch 301, loss: 0.036, 9632/28000 datapoints
2025-03-06 22:48:26,826 - INFO - training batch 351, loss: 0.034, 11232/28000 datapoints
2025-03-06 22:48:26,986 - INFO - training batch 401, loss: 0.023, 12832/28000 datapoints
2025-03-06 22:48:27,145 - INFO - training batch 451, loss: 0.048, 14432/28000 datapoints
2025-03-06 22:48:27,305 - INFO - training batch 501, loss: 0.023, 16032/28000 datapoints
2025-03-06 22:48:27,464 - INFO - training batch 551, loss: 0.017, 17632/28000 datapoints
2025-03-06 22:48:27,628 - INFO - training batch 601, loss: 0.017, 19232/28000 datapoints
2025-03-06 22:48:27,788 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:48:27,949 - INFO - training batch 701, loss: 0.020, 22432/28000 datapoints
2025-03-06 22:48:28,112 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:48:28,271 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:48:28,434 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-06 22:48:28,512 - INFO - validation batch 1, loss: 0.159, 32/6976 datapoints
2025-03-06 22:48:28,559 - INFO - validation batch 51, loss: 4.022, 1632/6976 datapoints
2025-03-06 22:48:28,606 - INFO - validation batch 101, loss: 0.464, 3232/6976 datapoints
2025-03-06 22:48:28,653 - INFO - validation batch 151, loss: 1.095, 4832/6976 datapoints
2025-03-06 22:48:28,701 - INFO - validation batch 201, loss: 1.729, 6432/6976 datapoints
2025-03-06 22:48:28,717 - INFO - Epoch 448/800 done.
2025-03-06 22:48:28,717 - INFO - Final validation performance:
Loss: 1.494, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:48:28,717 - INFO - Beginning epoch 449/800
2025-03-06 22:48:28,722 - INFO - training batch 1, loss: 0.034, 32/28000 datapoints
2025-03-06 22:48:28,891 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-06 22:48:29,050 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-06 22:48:29,209 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-06 22:48:29,367 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:48:29,524 - INFO - training batch 251, loss: 0.061, 8032/28000 datapoints
2025-03-06 22:48:29,686 - INFO - training batch 301, loss: 0.048, 9632/28000 datapoints
2025-03-06 22:48:29,843 - INFO - training batch 351, loss: 0.044, 11232/28000 datapoints
2025-03-06 22:48:30,005 - INFO - training batch 401, loss: 0.045, 12832/28000 datapoints
2025-03-06 22:48:30,167 - INFO - training batch 451, loss: 0.066, 14432/28000 datapoints
2025-03-06 22:48:30,325 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-06 22:48:30,484 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 22:48:30,652 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-06 22:48:30,827 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:48:30,989 - INFO - training batch 701, loss: 0.016, 22432/28000 datapoints
2025-03-06 22:48:31,147 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-06 22:48:31,306 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:48:31,469 - INFO - training batch 851, loss: 0.022, 27232/28000 datapoints
2025-03-06 22:48:31,547 - INFO - validation batch 1, loss: 0.171, 32/6976 datapoints
2025-03-06 22:48:31,594 - INFO - validation batch 51, loss: 4.090, 1632/6976 datapoints
2025-03-06 22:48:31,643 - INFO - validation batch 101, loss: 0.507, 3232/6976 datapoints
2025-03-06 22:48:31,690 - INFO - validation batch 151, loss: 1.052, 4832/6976 datapoints
2025-03-06 22:48:31,737 - INFO - validation batch 201, loss: 1.795, 6432/6976 datapoints
2025-03-06 22:48:31,753 - INFO - Epoch 449/800 done.
2025-03-06 22:48:31,754 - INFO - Final validation performance:
Loss: 1.523, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:48:31,754 - INFO - Beginning epoch 450/800
2025-03-06 22:48:31,758 - INFO - training batch 1, loss: 0.026, 32/28000 datapoints
2025-03-06 22:48:31,931 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-06 22:48:32,096 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 22:48:32,255 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-06 22:48:32,424 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:48:32,588 - INFO - training batch 251, loss: 0.060, 8032/28000 datapoints
2025-03-06 22:48:32,752 - INFO - training batch 301, loss: 0.060, 9632/28000 datapoints
2025-03-06 22:48:32,919 - INFO - training batch 351, loss: 0.031, 11232/28000 datapoints
2025-03-06 22:48:33,085 - INFO - training batch 401, loss: 0.033, 12832/28000 datapoints
2025-03-06 22:48:33,244 - INFO - training batch 451, loss: 0.036, 14432/28000 datapoints
2025-03-06 22:48:33,410 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 22:48:33,566 - INFO - training batch 551, loss: 0.048, 17632/28000 datapoints
2025-03-06 22:48:33,726 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-06 22:48:33,885 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:48:34,050 - INFO - training batch 701, loss: 0.015, 22432/28000 datapoints
2025-03-06 22:48:34,211 - INFO - training batch 751, loss: 0.018, 24032/28000 datapoints
2025-03-06 22:48:34,370 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:48:34,535 - INFO - training batch 851, loss: 0.024, 27232/28000 datapoints
2025-03-06 22:48:34,613 - INFO - validation batch 1, loss: 0.151, 32/6976 datapoints
2025-03-06 22:48:34,661 - INFO - validation batch 51, loss: 4.052, 1632/6976 datapoints
2025-03-06 22:48:34,708 - INFO - validation batch 101, loss: 0.545, 3232/6976 datapoints
2025-03-06 22:48:34,755 - INFO - validation batch 151, loss: 0.977, 4832/6976 datapoints
2025-03-06 22:48:34,803 - INFO - validation batch 201, loss: 1.858, 6432/6976 datapoints
2025-03-06 22:48:34,819 - INFO - Epoch 450/800 done.
2025-03-06 22:48:34,819 - INFO - Final validation performance:
Loss: 1.517, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:48:34,820 - INFO - Beginning epoch 451/800
2025-03-06 22:48:34,824 - INFO - training batch 1, loss: 0.026, 32/28000 datapoints
2025-03-06 22:48:34,999 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 22:48:35,155 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 22:48:35,324 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:48:35,489 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 22:48:35,651 - INFO - training batch 251, loss: 0.050, 8032/28000 datapoints
2025-03-06 22:48:35,816 - INFO - training batch 301, loss: 0.053, 9632/28000 datapoints
2025-03-06 22:48:36,003 - INFO - training batch 351, loss: 0.019, 11232/28000 datapoints
2025-03-06 22:48:36,186 - INFO - training batch 401, loss: 0.020, 12832/28000 datapoints
2025-03-06 22:48:36,344 - INFO - training batch 451, loss: 0.037, 14432/28000 datapoints
2025-03-06 22:48:36,504 - INFO - training batch 501, loss: 0.016, 16032/28000 datapoints
2025-03-06 22:48:36,665 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 22:48:36,822 - INFO - training batch 601, loss: 0.015, 19232/28000 datapoints
2025-03-06 22:48:36,985 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:48:37,143 - INFO - training batch 701, loss: 0.016, 22432/28000 datapoints
2025-03-06 22:48:37,301 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-06 22:48:37,461 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:48:37,623 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-06 22:48:37,700 - INFO - validation batch 1, loss: 0.190, 32/6976 datapoints
2025-03-06 22:48:37,747 - INFO - validation batch 51, loss: 3.971, 1632/6976 datapoints
2025-03-06 22:48:37,795 - INFO - validation batch 101, loss: 0.516, 3232/6976 datapoints
2025-03-06 22:48:37,843 - INFO - validation batch 151, loss: 1.037, 4832/6976 datapoints
2025-03-06 22:48:37,891 - INFO - validation batch 201, loss: 1.822, 6432/6976 datapoints
2025-03-06 22:48:37,908 - INFO - Epoch 451/800 done.
2025-03-06 22:48:37,908 - INFO - Final validation performance:
Loss: 1.507, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:48:37,908 - INFO - Beginning epoch 452/800
2025-03-06 22:48:37,913 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-06 22:48:38,106 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 22:48:38,267 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 22:48:38,428 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:48:38,592 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 22:48:38,755 - INFO - training batch 251, loss: 0.047, 8032/28000 datapoints
2025-03-06 22:48:38,923 - INFO - training batch 301, loss: 0.047, 9632/28000 datapoints
2025-03-06 22:48:39,093 - INFO - training batch 351, loss: 0.019, 11232/28000 datapoints
2025-03-06 22:48:39,251 - INFO - training batch 401, loss: 0.028, 12832/28000 datapoints
2025-03-06 22:48:39,417 - INFO - training batch 451, loss: 0.050, 14432/28000 datapoints
2025-03-06 22:48:39,578 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-06 22:48:39,735 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 22:48:39,894 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-06 22:48:40,057 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:48:40,219 - INFO - training batch 701, loss: 0.015, 22432/28000 datapoints
2025-03-06 22:48:40,378 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 22:48:40,537 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:48:40,701 - INFO - training batch 851, loss: 0.022, 27232/28000 datapoints
2025-03-06 22:48:40,801 - INFO - validation batch 1, loss: 0.160, 32/6976 datapoints
2025-03-06 22:48:40,856 - INFO - validation batch 51, loss: 4.062, 1632/6976 datapoints
2025-03-06 22:48:40,904 - INFO - validation batch 101, loss: 0.518, 3232/6976 datapoints
2025-03-06 22:48:40,952 - INFO - validation batch 151, loss: 1.031, 4832/6976 datapoints
2025-03-06 22:48:41,004 - INFO - validation batch 201, loss: 1.808, 6432/6976 datapoints
2025-03-06 22:48:41,020 - INFO - Epoch 452/800 done.
2025-03-06 22:48:41,020 - INFO - Final validation performance:
Loss: 1.516, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:48:41,021 - INFO - Beginning epoch 453/800
2025-03-06 22:48:41,025 - INFO - training batch 1, loss: 0.030, 32/28000 datapoints
2025-03-06 22:48:41,187 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 22:48:41,342 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 22:48:41,505 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:48:41,669 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 22:48:41,836 - INFO - training batch 251, loss: 0.047, 8032/28000 datapoints
2025-03-06 22:48:42,003 - INFO - training batch 301, loss: 0.038, 9632/28000 datapoints
2025-03-06 22:48:42,165 - INFO - training batch 351, loss: 0.027, 11232/28000 datapoints
2025-03-06 22:48:42,324 - INFO - training batch 401, loss: 0.028, 12832/28000 datapoints
2025-03-06 22:48:42,482 - INFO - training batch 451, loss: 0.043, 14432/28000 datapoints
2025-03-06 22:48:42,643 - INFO - training batch 501, loss: 0.018, 16032/28000 datapoints
2025-03-06 22:48:42,800 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 22:48:42,960 - INFO - training batch 601, loss: 0.017, 19232/28000 datapoints
2025-03-06 22:48:43,121 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:48:43,281 - INFO - training batch 701, loss: 0.015, 22432/28000 datapoints
2025-03-06 22:48:43,446 - INFO - training batch 751, loss: 0.009, 24032/28000 datapoints
2025-03-06 22:48:43,613 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:48:43,777 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-06 22:48:43,859 - INFO - validation batch 1, loss: 0.161, 32/6976 datapoints
2025-03-06 22:48:43,908 - INFO - validation batch 51, loss: 4.056, 1632/6976 datapoints
2025-03-06 22:48:43,961 - INFO - validation batch 101, loss: 0.489, 3232/6976 datapoints
2025-03-06 22:48:44,017 - INFO - validation batch 151, loss: 1.094, 4832/6976 datapoints
2025-03-06 22:48:44,070 - INFO - validation batch 201, loss: 1.783, 6432/6976 datapoints
2025-03-06 22:48:44,088 - INFO - Epoch 453/800 done.
2025-03-06 22:48:44,088 - INFO - Final validation performance:
Loss: 1.517, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:48:44,089 - INFO - Beginning epoch 454/800
2025-03-06 22:48:44,093 - INFO - training batch 1, loss: 0.032, 32/28000 datapoints
2025-03-06 22:48:44,282 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 22:48:44,442 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 22:48:44,607 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-06 22:48:44,783 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 22:48:44,954 - INFO - training batch 251, loss: 0.050, 8032/28000 datapoints
2025-03-06 22:48:45,129 - INFO - training batch 301, loss: 0.033, 9632/28000 datapoints
2025-03-06 22:48:45,297 - INFO - training batch 351, loss: 0.029, 11232/28000 datapoints
2025-03-06 22:48:45,460 - INFO - training batch 401, loss: 0.023, 12832/28000 datapoints
2025-03-06 22:48:45,622 - INFO - training batch 451, loss: 0.039, 14432/28000 datapoints
2025-03-06 22:48:45,787 - INFO - training batch 501, loss: 0.019, 16032/28000 datapoints
2025-03-06 22:48:45,950 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-06 22:48:46,131 - INFO - training batch 601, loss: 0.017, 19232/28000 datapoints
2025-03-06 22:48:46,300 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:48:46,464 - INFO - training batch 701, loss: 0.017, 22432/28000 datapoints
2025-03-06 22:48:46,628 - INFO - training batch 751, loss: 0.009, 24032/28000 datapoints
2025-03-06 22:48:46,790 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:48:46,955 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-06 22:48:47,046 - INFO - validation batch 1, loss: 0.157, 32/6976 datapoints
2025-03-06 22:48:47,100 - INFO - validation batch 51, loss: 4.041, 1632/6976 datapoints
2025-03-06 22:48:47,152 - INFO - validation batch 101, loss: 0.482, 3232/6976 datapoints
2025-03-06 22:48:47,205 - INFO - validation batch 151, loss: 1.115, 4832/6976 datapoints
2025-03-06 22:48:47,258 - INFO - validation batch 201, loss: 1.787, 6432/6976 datapoints
2025-03-06 22:48:47,276 - INFO - Epoch 454/800 done.
2025-03-06 22:48:47,277 - INFO - Final validation performance:
Loss: 1.517, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:48:47,277 - INFO - Beginning epoch 455/800
2025-03-06 22:48:47,282 - INFO - training batch 1, loss: 0.034, 32/28000 datapoints
2025-03-06 22:48:47,452 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 22:48:47,619 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 22:48:47,791 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-06 22:48:47,951 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 22:48:48,125 - INFO - training batch 251, loss: 0.045, 8032/28000 datapoints
2025-03-06 22:48:48,295 - INFO - training batch 301, loss: 0.029, 9632/28000 datapoints
2025-03-06 22:48:48,457 - INFO - training batch 351, loss: 0.026, 11232/28000 datapoints
2025-03-06 22:48:48,620 - INFO - training batch 401, loss: 0.023, 12832/28000 datapoints
2025-03-06 22:48:48,784 - INFO - training batch 451, loss: 0.039, 14432/28000 datapoints
2025-03-06 22:48:48,947 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-06 22:48:49,115 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-06 22:48:49,277 - INFO - training batch 601, loss: 0.016, 19232/28000 datapoints
2025-03-06 22:48:49,441 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:48:49,604 - INFO - training batch 701, loss: 0.018, 22432/28000 datapoints
2025-03-06 22:48:49,768 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:48:49,929 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:48:50,100 - INFO - training batch 851, loss: 0.019, 27232/28000 datapoints
2025-03-06 22:48:50,187 - INFO - validation batch 1, loss: 0.160, 32/6976 datapoints
2025-03-06 22:48:50,239 - INFO - validation batch 51, loss: 4.090, 1632/6976 datapoints
2025-03-06 22:48:50,291 - INFO - validation batch 101, loss: 0.488, 3232/6976 datapoints
2025-03-06 22:48:50,343 - INFO - validation batch 151, loss: 1.133, 4832/6976 datapoints
2025-03-06 22:48:50,399 - INFO - validation batch 201, loss: 1.807, 6432/6976 datapoints
2025-03-06 22:48:50,424 - INFO - Epoch 455/800 done.
2025-03-06 22:48:50,424 - INFO - Final validation performance:
Loss: 1.535, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:48:50,425 - INFO - Beginning epoch 456/800
2025-03-06 22:48:50,430 - INFO - training batch 1, loss: 0.033, 32/28000 datapoints
2025-03-06 22:48:50,608 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 22:48:50,768 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 22:48:50,965 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:48:51,138 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 22:48:51,304 - INFO - training batch 251, loss: 0.044, 8032/28000 datapoints
2025-03-06 22:48:51,469 - INFO - training batch 301, loss: 0.027, 9632/28000 datapoints
2025-03-06 22:48:51,634 - INFO - training batch 351, loss: 0.022, 11232/28000 datapoints
2025-03-06 22:48:51,797 - INFO - training batch 401, loss: 0.022, 12832/28000 datapoints
2025-03-06 22:48:51,959 - INFO - training batch 451, loss: 0.034, 14432/28000 datapoints
2025-03-06 22:48:52,128 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-06 22:48:52,297 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 22:48:52,461 - INFO - training batch 601, loss: 0.013, 19232/28000 datapoints
2025-03-06 22:48:52,623 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:48:52,787 - INFO - training batch 701, loss: 0.018, 22432/28000 datapoints
2025-03-06 22:48:52,950 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-06 22:48:53,117 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:48:53,283 - INFO - training batch 851, loss: 0.017, 27232/28000 datapoints
2025-03-06 22:48:53,372 - INFO - validation batch 1, loss: 0.155, 32/6976 datapoints
2025-03-06 22:48:53,424 - INFO - validation batch 51, loss: 4.107, 1632/6976 datapoints
2025-03-06 22:48:53,476 - INFO - validation batch 101, loss: 0.469, 3232/6976 datapoints
2025-03-06 22:48:53,530 - INFO - validation batch 151, loss: 1.154, 4832/6976 datapoints
2025-03-06 22:48:53,584 - INFO - validation batch 201, loss: 1.811, 6432/6976 datapoints
2025-03-06 22:48:53,601 - INFO - Epoch 456/800 done.
2025-03-06 22:48:53,601 - INFO - Final validation performance:
Loss: 1.539, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:48:53,602 - INFO - Beginning epoch 457/800
2025-03-06 22:48:53,607 - INFO - training batch 1, loss: 0.034, 32/28000 datapoints
2025-03-06 22:48:53,779 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 22:48:53,940 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 22:48:54,112 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:48:54,279 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 22:48:54,445 - INFO - training batch 251, loss: 0.043, 8032/28000 datapoints
2025-03-06 22:48:54,612 - INFO - training batch 301, loss: 0.025, 9632/28000 datapoints
2025-03-06 22:48:54,774 - INFO - training batch 351, loss: 0.019, 11232/28000 datapoints
2025-03-06 22:48:54,937 - INFO - training batch 401, loss: 0.020, 12832/28000 datapoints
2025-03-06 22:48:55,102 - INFO - training batch 451, loss: 0.035, 14432/28000 datapoints
2025-03-06 22:48:55,271 - INFO - training batch 501, loss: 0.019, 16032/28000 datapoints
2025-03-06 22:48:55,435 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 22:48:55,597 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-06 22:48:55,765 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:48:55,933 - INFO - training batch 701, loss: 0.016, 22432/28000 datapoints
2025-03-06 22:48:56,100 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:48:56,266 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:48:56,432 - INFO - training batch 851, loss: 0.019, 27232/28000 datapoints
2025-03-06 22:48:56,514 - INFO - validation batch 1, loss: 0.150, 32/6976 datapoints
2025-03-06 22:48:56,565 - INFO - validation batch 51, loss: 4.169, 1632/6976 datapoints
2025-03-06 22:48:56,629 - INFO - validation batch 101, loss: 0.471, 3232/6976 datapoints
2025-03-06 22:48:56,689 - INFO - validation batch 151, loss: 1.178, 4832/6976 datapoints
2025-03-06 22:48:56,741 - INFO - validation batch 201, loss: 1.824, 6432/6976 datapoints
2025-03-06 22:48:56,761 - INFO - Epoch 457/800 done.
2025-03-06 22:48:56,761 - INFO - Final validation performance:
Loss: 1.558, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:48:56,762 - INFO - Beginning epoch 458/800
2025-03-06 22:48:56,767 - INFO - training batch 1, loss: 0.032, 32/28000 datapoints
2025-03-06 22:48:56,934 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 22:48:57,094 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-06 22:48:57,257 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:48:57,415 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 22:48:57,575 - INFO - training batch 251, loss: 0.041, 8032/28000 datapoints
2025-03-06 22:48:57,739 - INFO - training batch 301, loss: 0.025, 9632/28000 datapoints
2025-03-06 22:48:57,898 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-06 22:48:58,060 - INFO - training batch 401, loss: 0.024, 12832/28000 datapoints
2025-03-06 22:48:58,224 - INFO - training batch 451, loss: 0.029, 14432/28000 datapoints
2025-03-06 22:48:58,386 - INFO - training batch 501, loss: 0.021, 16032/28000 datapoints
2025-03-06 22:48:58,545 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 22:48:58,705 - INFO - training batch 601, loss: 0.013, 19232/28000 datapoints
2025-03-06 22:48:58,868 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:48:59,032 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-06 22:48:59,193 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-06 22:48:59,354 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:48:59,515 - INFO - training batch 851, loss: 0.018, 27232/28000 datapoints
2025-03-06 22:48:59,594 - INFO - validation batch 1, loss: 0.150, 32/6976 datapoints
2025-03-06 22:48:59,641 - INFO - validation batch 51, loss: 4.164, 1632/6976 datapoints
2025-03-06 22:48:59,690 - INFO - validation batch 101, loss: 0.465, 3232/6976 datapoints
2025-03-06 22:48:59,739 - INFO - validation batch 151, loss: 1.156, 4832/6976 datapoints
2025-03-06 22:48:59,787 - INFO - validation batch 201, loss: 1.830, 6432/6976 datapoints
2025-03-06 22:48:59,803 - INFO - Epoch 458/800 done.
2025-03-06 22:48:59,803 - INFO - Final validation performance:
Loss: 1.553, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:48:59,804 - INFO - Beginning epoch 459/800
2025-03-06 22:48:59,808 - INFO - training batch 1, loss: 0.031, 32/28000 datapoints
2025-03-06 22:48:59,973 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 22:49:00,131 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 22:49:00,294 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:49:00,452 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 22:49:00,612 - INFO - training batch 251, loss: 0.040, 8032/28000 datapoints
2025-03-06 22:49:00,777 - INFO - training batch 301, loss: 0.045, 9632/28000 datapoints
2025-03-06 22:49:00,937 - INFO - training batch 351, loss: 0.035, 11232/28000 datapoints
2025-03-06 22:49:01,124 - INFO - training batch 401, loss: 0.093, 12832/28000 datapoints
2025-03-06 22:49:01,285 - INFO - training batch 451, loss: 0.028, 14432/28000 datapoints
2025-03-06 22:49:01,444 - INFO - training batch 501, loss: 0.022, 16032/28000 datapoints
2025-03-06 22:49:01,603 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 22:49:01,762 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:49:01,922 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:49:02,087 - INFO - training batch 701, loss: 0.025, 22432/28000 datapoints
2025-03-06 22:49:02,251 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 22:49:02,412 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:49:02,573 - INFO - training batch 851, loss: 0.058, 27232/28000 datapoints
2025-03-06 22:49:02,652 - INFO - validation batch 1, loss: 0.101, 32/6976 datapoints
2025-03-06 22:49:02,701 - INFO - validation batch 51, loss: 4.122, 1632/6976 datapoints
2025-03-06 22:49:02,749 - INFO - validation batch 101, loss: 0.457, 3232/6976 datapoints
2025-03-06 22:49:02,798 - INFO - validation batch 151, loss: 1.234, 4832/6976 datapoints
2025-03-06 22:49:02,848 - INFO - validation batch 201, loss: 1.927, 6432/6976 datapoints
2025-03-06 22:49:02,868 - INFO - Epoch 459/800 done.
2025-03-06 22:49:02,868 - INFO - Final validation performance:
Loss: 1.568, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:49:02,869 - INFO - Beginning epoch 460/800
2025-03-06 22:49:02,874 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-06 22:49:03,046 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 22:49:03,203 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 22:49:03,372 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:49:03,530 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-06 22:49:03,691 - INFO - training batch 251, loss: 0.042, 8032/28000 datapoints
2025-03-06 22:49:03,867 - INFO - training batch 301, loss: 0.026, 9632/28000 datapoints
2025-03-06 22:49:04,033 - INFO - training batch 351, loss: 0.039, 11232/28000 datapoints
2025-03-06 22:49:04,195 - INFO - training batch 401, loss: 0.018, 12832/28000 datapoints
2025-03-06 22:49:04,363 - INFO - training batch 451, loss: 0.040, 14432/28000 datapoints
2025-03-06 22:49:04,527 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 22:49:04,690 - INFO - training batch 551, loss: 0.023, 17632/28000 datapoints
2025-03-06 22:49:04,855 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-06 22:49:05,029 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:49:05,195 - INFO - training batch 701, loss: 0.015, 22432/28000 datapoints
2025-03-06 22:49:05,369 - INFO - training batch 751, loss: 0.100, 24032/28000 datapoints
2025-03-06 22:49:05,532 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:49:05,701 - INFO - training batch 851, loss: 0.023, 27232/28000 datapoints
2025-03-06 22:49:05,783 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 22:49:05,834 - INFO - validation batch 51, loss: 4.258, 1632/6976 datapoints
2025-03-06 22:49:05,887 - INFO - validation batch 101, loss: 0.456, 3232/6976 datapoints
2025-03-06 22:49:05,939 - INFO - validation batch 151, loss: 1.133, 4832/6976 datapoints
2025-03-06 22:49:05,994 - INFO - validation batch 201, loss: 2.037, 6432/6976 datapoints
2025-03-06 22:49:06,014 - INFO - Epoch 460/800 done.
2025-03-06 22:49:06,015 - INFO - Final validation performance:
Loss: 1.601, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:49:06,015 - INFO - Beginning epoch 461/800
2025-03-06 22:49:06,019 - INFO - training batch 1, loss: 0.027, 32/28000 datapoints
2025-03-06 22:49:06,186 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 22:49:06,353 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-06 22:49:06,517 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:49:06,680 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 22:49:06,847 - INFO - training batch 251, loss: 0.070, 8032/28000 datapoints
2025-03-06 22:49:07,015 - INFO - training batch 301, loss: 0.018, 9632/28000 datapoints
2025-03-06 22:49:07,176 - INFO - training batch 351, loss: 0.027, 11232/28000 datapoints
2025-03-06 22:49:07,340 - INFO - training batch 401, loss: 0.024, 12832/28000 datapoints
2025-03-06 22:49:07,504 - INFO - training batch 451, loss: 0.034, 14432/28000 datapoints
2025-03-06 22:49:07,666 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 22:49:07,832 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 22:49:07,998 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-06 22:49:08,161 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:49:08,331 - INFO - training batch 701, loss: 0.013, 22432/28000 datapoints
2025-03-06 22:49:08,493 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-06 22:49:08,657 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:49:08,823 - INFO - training batch 851, loss: 0.018, 27232/28000 datapoints
2025-03-06 22:49:08,907 - INFO - validation batch 1, loss: 0.202, 32/6976 datapoints
2025-03-06 22:49:08,957 - INFO - validation batch 51, loss: 4.290, 1632/6976 datapoints
2025-03-06 22:49:09,008 - INFO - validation batch 101, loss: 0.501, 3232/6976 datapoints
2025-03-06 22:49:09,055 - INFO - validation batch 151, loss: 1.116, 4832/6976 datapoints
2025-03-06 22:49:09,109 - INFO - validation batch 201, loss: 2.009, 6432/6976 datapoints
2025-03-06 22:49:09,130 - INFO - Epoch 461/800 done.
2025-03-06 22:49:09,130 - INFO - Final validation performance:
Loss: 1.624, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:49:09,131 - INFO - Beginning epoch 462/800
2025-03-06 22:49:09,136 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-06 22:49:09,305 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 22:49:09,474 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 22:49:09,634 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:49:09,793 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 22:49:09,957 - INFO - training batch 251, loss: 0.046, 8032/28000 datapoints
2025-03-06 22:49:10,122 - INFO - training batch 301, loss: 0.016, 9632/28000 datapoints
2025-03-06 22:49:10,284 - INFO - training batch 351, loss: 0.034, 11232/28000 datapoints
2025-03-06 22:49:10,444 - INFO - training batch 401, loss: 0.021, 12832/28000 datapoints
2025-03-06 22:49:10,603 - INFO - training batch 451, loss: 0.031, 14432/28000 datapoints
2025-03-06 22:49:10,761 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 22:49:10,923 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 22:49:11,102 - INFO - training batch 601, loss: 0.015, 19232/28000 datapoints
2025-03-06 22:49:11,267 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:49:11,429 - INFO - training batch 701, loss: 0.013, 22432/28000 datapoints
2025-03-06 22:49:11,589 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 22:49:11,749 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:49:11,911 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-06 22:49:11,994 - INFO - validation batch 1, loss: 0.174, 32/6976 datapoints
2025-03-06 22:49:12,043 - INFO - validation batch 51, loss: 4.269, 1632/6976 datapoints
2025-03-06 22:49:12,116 - INFO - validation batch 101, loss: 0.500, 3232/6976 datapoints
2025-03-06 22:49:12,165 - INFO - validation batch 151, loss: 1.122, 4832/6976 datapoints
2025-03-06 22:49:12,213 - INFO - validation batch 201, loss: 1.953, 6432/6976 datapoints
2025-03-06 22:49:12,229 - INFO - Epoch 462/800 done.
2025-03-06 22:49:12,229 - INFO - Final validation performance:
Loss: 1.604, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:49:12,229 - INFO - Beginning epoch 463/800
2025-03-06 22:49:12,234 - INFO - training batch 1, loss: 0.025, 32/28000 datapoints
2025-03-06 22:49:12,402 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 22:49:12,558 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 22:49:12,718 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:49:12,877 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 22:49:13,044 - INFO - training batch 251, loss: 0.041, 8032/28000 datapoints
2025-03-06 22:49:13,206 - INFO - training batch 301, loss: 0.018, 9632/28000 datapoints
2025-03-06 22:49:13,364 - INFO - training batch 351, loss: 0.023, 11232/28000 datapoints
2025-03-06 22:49:13,529 - INFO - training batch 401, loss: 0.020, 12832/28000 datapoints
2025-03-06 22:49:13,688 - INFO - training batch 451, loss: 0.028, 14432/28000 datapoints
2025-03-06 22:49:13,850 - INFO - training batch 501, loss: 0.016, 16032/28000 datapoints
2025-03-06 22:49:14,016 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 22:49:14,174 - INFO - training batch 601, loss: 0.018, 19232/28000 datapoints
2025-03-06 22:49:14,335 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:49:14,498 - INFO - training batch 701, loss: 0.014, 22432/28000 datapoints
2025-03-06 22:49:14,660 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:49:14,819 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:49:14,984 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-06 22:49:15,062 - INFO - validation batch 1, loss: 0.184, 32/6976 datapoints
2025-03-06 22:49:15,109 - INFO - validation batch 51, loss: 4.276, 1632/6976 datapoints
2025-03-06 22:49:15,157 - INFO - validation batch 101, loss: 0.490, 3232/6976 datapoints
2025-03-06 22:49:15,209 - INFO - validation batch 151, loss: 1.132, 4832/6976 datapoints
2025-03-06 22:49:15,258 - INFO - validation batch 201, loss: 1.928, 6432/6976 datapoints
2025-03-06 22:49:15,274 - INFO - Epoch 463/800 done.
2025-03-06 22:49:15,275 - INFO - Final validation performance:
Loss: 1.602, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:49:15,275 - INFO - Beginning epoch 464/800
2025-03-06 22:49:15,279 - INFO - training batch 1, loss: 0.027, 32/28000 datapoints
2025-03-06 22:49:15,454 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 22:49:15,615 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 22:49:15,780 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:49:15,950 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 22:49:16,125 - INFO - training batch 251, loss: 0.039, 8032/28000 datapoints
2025-03-06 22:49:16,297 - INFO - training batch 301, loss: 0.018, 9632/28000 datapoints
2025-03-06 22:49:16,456 - INFO - training batch 351, loss: 0.019, 11232/28000 datapoints
2025-03-06 22:49:16,616 - INFO - training batch 401, loss: 0.016, 12832/28000 datapoints
2025-03-06 22:49:16,775 - INFO - training batch 451, loss: 0.026, 14432/28000 datapoints
2025-03-06 22:49:16,938 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-06 22:49:17,110 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 22:49:17,269 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-06 22:49:17,429 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:49:17,593 - INFO - training batch 701, loss: 0.017, 22432/28000 datapoints
2025-03-06 22:49:17,754 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:49:17,915 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:49:18,081 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-06 22:49:18,159 - INFO - validation batch 1, loss: 0.184, 32/6976 datapoints
2025-03-06 22:49:18,207 - INFO - validation batch 51, loss: 4.279, 1632/6976 datapoints
2025-03-06 22:49:18,255 - INFO - validation batch 101, loss: 0.474, 3232/6976 datapoints
2025-03-06 22:49:18,305 - INFO - validation batch 151, loss: 1.151, 4832/6976 datapoints
2025-03-06 22:49:18,352 - INFO - validation batch 201, loss: 1.918, 6432/6976 datapoints
2025-03-06 22:49:18,369 - INFO - Epoch 464/800 done.
2025-03-06 22:49:18,369 - INFO - Final validation performance:
Loss: 1.601, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:49:18,370 - INFO - Beginning epoch 465/800
2025-03-06 22:49:18,374 - INFO - training batch 1, loss: 0.027, 32/28000 datapoints
2025-03-06 22:49:18,539 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 22:49:18,698 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 22:49:18,858 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:49:19,024 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 22:49:19,188 - INFO - training batch 251, loss: 0.039, 8032/28000 datapoints
2025-03-06 22:49:19,351 - INFO - training batch 301, loss: 0.019, 9632/28000 datapoints
2025-03-06 22:49:19,513 - INFO - training batch 351, loss: 0.019, 11232/28000 datapoints
2025-03-06 22:49:19,673 - INFO - training batch 401, loss: 0.017, 12832/28000 datapoints
2025-03-06 22:49:19,832 - INFO - training batch 451, loss: 0.028, 14432/28000 datapoints
2025-03-06 22:49:19,999 - INFO - training batch 501, loss: 0.016, 16032/28000 datapoints
2025-03-06 22:49:20,161 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 22:49:20,326 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 22:49:20,487 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:49:20,650 - INFO - training batch 701, loss: 0.016, 22432/28000 datapoints
2025-03-06 22:49:20,810 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:49:20,975 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:49:21,142 - INFO - training batch 851, loss: 0.016, 27232/28000 datapoints
2025-03-06 22:49:21,244 - INFO - validation batch 1, loss: 0.180, 32/6976 datapoints
2025-03-06 22:49:21,295 - INFO - validation batch 51, loss: 4.325, 1632/6976 datapoints
2025-03-06 22:49:21,344 - INFO - validation batch 101, loss: 0.463, 3232/6976 datapoints
2025-03-06 22:49:21,391 - INFO - validation batch 151, loss: 1.166, 4832/6976 datapoints
2025-03-06 22:49:21,439 - INFO - validation batch 201, loss: 1.915, 6432/6976 datapoints
2025-03-06 22:49:21,456 - INFO - Epoch 465/800 done.
2025-03-06 22:49:21,456 - INFO - Final validation performance:
Loss: 1.610, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:49:21,457 - INFO - Beginning epoch 466/800
2025-03-06 22:49:21,461 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-06 22:49:21,634 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 22:49:21,805 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 22:49:21,969 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:49:22,137 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:49:22,312 - INFO - training batch 251, loss: 0.038, 8032/28000 datapoints
2025-03-06 22:49:22,480 - INFO - training batch 301, loss: 0.018, 9632/28000 datapoints
2025-03-06 22:49:22,640 - INFO - training batch 351, loss: 0.017, 11232/28000 datapoints
2025-03-06 22:49:22,800 - INFO - training batch 401, loss: 0.015, 12832/28000 datapoints
2025-03-06 22:49:22,959 - INFO - training batch 451, loss: 0.026, 14432/28000 datapoints
2025-03-06 22:49:23,126 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-06 22:49:23,289 - INFO - training batch 551, loss: 0.017, 17632/28000 datapoints
2025-03-06 22:49:23,453 - INFO - training batch 601, loss: 0.012, 19232/28000 datapoints
2025-03-06 22:49:23,615 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:49:23,776 - INFO - training batch 701, loss: 0.021, 22432/28000 datapoints
2025-03-06 22:49:23,945 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:49:24,114 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:49:24,280 - INFO - training batch 851, loss: 0.016, 27232/28000 datapoints
2025-03-06 22:49:24,367 - INFO - validation batch 1, loss: 0.162, 32/6976 datapoints
2025-03-06 22:49:24,419 - INFO - validation batch 51, loss: 4.338, 1632/6976 datapoints
2025-03-06 22:49:24,469 - INFO - validation batch 101, loss: 0.457, 3232/6976 datapoints
2025-03-06 22:49:24,525 - INFO - validation batch 151, loss: 1.170, 4832/6976 datapoints
2025-03-06 22:49:24,577 - INFO - validation batch 201, loss: 1.919, 6432/6976 datapoints
2025-03-06 22:49:24,593 - INFO - Epoch 466/800 done.
2025-03-06 22:49:24,593 - INFO - Final validation performance:
Loss: 1.609, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:49:24,594 - INFO - Beginning epoch 467/800
2025-03-06 22:49:24,598 - INFO - training batch 1, loss: 0.027, 32/28000 datapoints
2025-03-06 22:49:24,765 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 22:49:24,933 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 22:49:25,102 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:49:25,272 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 22:49:25,441 - INFO - training batch 251, loss: 0.038, 8032/28000 datapoints
2025-03-06 22:49:25,608 - INFO - training batch 301, loss: 0.019, 9632/28000 datapoints
2025-03-06 22:49:25,772 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-06 22:49:25,936 - INFO - training batch 401, loss: 0.023, 12832/28000 datapoints
2025-03-06 22:49:26,162 - INFO - training batch 451, loss: 0.022, 14432/28000 datapoints
2025-03-06 22:49:26,332 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 22:49:26,498 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 22:49:26,663 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-06 22:49:26,825 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:49:26,993 - INFO - training batch 701, loss: 0.011, 22432/28000 datapoints
2025-03-06 22:49:27,159 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-06 22:49:27,326 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:49:27,491 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-06 22:49:27,574 - INFO - validation batch 1, loss: 0.154, 32/6976 datapoints
2025-03-06 22:49:27,625 - INFO - validation batch 51, loss: 4.307, 1632/6976 datapoints
2025-03-06 22:49:27,678 - INFO - validation batch 101, loss: 0.464, 3232/6976 datapoints
2025-03-06 22:49:27,731 - INFO - validation batch 151, loss: 1.244, 4832/6976 datapoints
2025-03-06 22:49:27,782 - INFO - validation batch 201, loss: 1.958, 6432/6976 datapoints
2025-03-06 22:49:27,800 - INFO - Epoch 467/800 done.
2025-03-06 22:49:27,801 - INFO - Final validation performance:
Loss: 1.625, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:49:27,801 - INFO - Beginning epoch 468/800
2025-03-06 22:49:27,807 - INFO - training batch 1, loss: 0.031, 32/28000 datapoints
2025-03-06 22:49:27,998 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 22:49:28,166 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 22:49:28,334 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:49:28,503 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 22:49:28,677 - INFO - training batch 251, loss: 0.041, 8032/28000 datapoints
2025-03-06 22:49:28,848 - INFO - training batch 301, loss: 0.024, 9632/28000 datapoints
2025-03-06 22:49:29,016 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-06 22:49:29,180 - INFO - training batch 401, loss: 0.016, 12832/28000 datapoints
2025-03-06 22:49:29,345 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-06 22:49:29,510 - INFO - training batch 501, loss: 0.016, 16032/28000 datapoints
2025-03-06 22:49:29,676 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 22:49:29,839 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-06 22:49:30,008 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:49:30,179 - INFO - training batch 701, loss: 0.011, 22432/28000 datapoints
2025-03-06 22:49:30,348 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:49:30,515 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:49:30,682 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-06 22:49:30,765 - INFO - validation batch 1, loss: 0.168, 32/6976 datapoints
2025-03-06 22:49:30,817 - INFO - validation batch 51, loss: 4.412, 1632/6976 datapoints
2025-03-06 22:49:30,869 - INFO - validation batch 101, loss: 0.464, 3232/6976 datapoints
2025-03-06 22:49:30,922 - INFO - validation batch 151, loss: 1.186, 4832/6976 datapoints
2025-03-06 22:49:30,977 - INFO - validation batch 201, loss: 1.973, 6432/6976 datapoints
2025-03-06 22:49:30,993 - INFO - Epoch 468/800 done.
2025-03-06 22:49:30,993 - INFO - Final validation performance:
Loss: 1.641, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:49:30,994 - INFO - Beginning epoch 469/800
2025-03-06 22:49:30,998 - INFO - training batch 1, loss: 0.027, 32/28000 datapoints
2025-03-06 22:49:31,170 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 22:49:31,361 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 22:49:31,529 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:49:31,696 - INFO - training batch 201, loss: 0.130, 6432/28000 datapoints
2025-03-06 22:49:31,861 - INFO - training batch 251, loss: 0.046, 8032/28000 datapoints
2025-03-06 22:49:32,031 - INFO - training batch 301, loss: 0.089, 9632/28000 datapoints
2025-03-06 22:49:32,195 - INFO - training batch 351, loss: 0.024, 11232/28000 datapoints
2025-03-06 22:49:32,364 - INFO - training batch 401, loss: 0.021, 12832/28000 datapoints
2025-03-06 22:49:32,528 - INFO - training batch 451, loss: 0.047, 14432/28000 datapoints
2025-03-06 22:49:32,695 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 22:49:32,862 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 22:49:33,028 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-06 22:49:33,193 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:49:33,361 - INFO - training batch 701, loss: 0.014, 22432/28000 datapoints
2025-03-06 22:49:33,528 - INFO - training batch 751, loss: 0.025, 24032/28000 datapoints
2025-03-06 22:49:33,696 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:49:33,861 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-06 22:49:33,943 - INFO - validation batch 1, loss: 0.168, 32/6976 datapoints
2025-03-06 22:49:33,998 - INFO - validation batch 51, loss: 4.527, 1632/6976 datapoints
2025-03-06 22:49:34,056 - INFO - validation batch 101, loss: 0.495, 3232/6976 datapoints
2025-03-06 22:49:34,117 - INFO - validation batch 151, loss: 1.106, 4832/6976 datapoints
2025-03-06 22:49:34,172 - INFO - validation batch 201, loss: 2.161, 6432/6976 datapoints
2025-03-06 22:49:34,190 - INFO - Epoch 469/800 done.
2025-03-06 22:49:34,191 - INFO - Final validation performance:
Loss: 1.691, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:49:34,191 - INFO - Beginning epoch 470/800
2025-03-06 22:49:34,195 - INFO - training batch 1, loss: 0.026, 32/28000 datapoints
2025-03-06 22:49:34,372 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 22:49:34,538 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-06 22:49:34,707 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:49:34,874 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 22:49:35,044 - INFO - training batch 251, loss: 0.039, 8032/28000 datapoints
2025-03-06 22:49:35,214 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-06 22:49:35,398 - INFO - training batch 351, loss: 0.023, 11232/28000 datapoints
2025-03-06 22:49:35,567 - INFO - training batch 401, loss: 0.020, 12832/28000 datapoints
2025-03-06 22:49:35,739 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-06 22:49:35,907 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 22:49:36,076 - INFO - training batch 551, loss: 0.161, 17632/28000 datapoints
2025-03-06 22:49:36,243 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:49:36,453 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:49:36,619 - INFO - training batch 701, loss: 0.014, 22432/28000 datapoints
2025-03-06 22:49:36,795 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-06 22:49:36,961 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:49:37,130 - INFO - training batch 851, loss: 0.013, 27232/28000 datapoints
2025-03-06 22:49:37,216 - INFO - validation batch 1, loss: 0.145, 32/6976 datapoints
2025-03-06 22:49:37,268 - INFO - validation batch 51, loss: 4.494, 1632/6976 datapoints
2025-03-06 22:49:37,319 - INFO - validation batch 101, loss: 0.530, 3232/6976 datapoints
2025-03-06 22:49:37,370 - INFO - validation batch 151, loss: 1.102, 4832/6976 datapoints
2025-03-06 22:49:37,425 - INFO - validation batch 201, loss: 2.102, 6432/6976 datapoints
2025-03-06 22:49:37,441 - INFO - Epoch 470/800 done.
2025-03-06 22:49:37,441 - INFO - Final validation performance:
Loss: 1.675, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:49:37,442 - INFO - Beginning epoch 471/800
2025-03-06 22:49:37,447 - INFO - training batch 1, loss: 0.027, 32/28000 datapoints
2025-03-06 22:49:37,614 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 22:49:37,778 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 22:49:37,944 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:49:38,142 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 22:49:38,343 - INFO - training batch 251, loss: 0.041, 8032/28000 datapoints
2025-03-06 22:49:38,515 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-06 22:49:38,679 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-06 22:49:38,843 - INFO - training batch 401, loss: 0.015, 12832/28000 datapoints
2025-03-06 22:49:39,011 - INFO - training batch 451, loss: 0.022, 14432/28000 datapoints
2025-03-06 22:49:39,178 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 22:49:39,346 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 22:49:39,513 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-06 22:49:39,680 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:49:39,856 - INFO - training batch 701, loss: 0.012, 22432/28000 datapoints
2025-03-06 22:49:40,028 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-06 22:49:40,198 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:49:40,382 - INFO - training batch 851, loss: 0.018, 27232/28000 datapoints
2025-03-06 22:49:40,464 - INFO - validation batch 1, loss: 0.165, 32/6976 datapoints
2025-03-06 22:49:40,516 - INFO - validation batch 51, loss: 4.430, 1632/6976 datapoints
2025-03-06 22:49:40,567 - INFO - validation batch 101, loss: 0.507, 3232/6976 datapoints
2025-03-06 22:49:40,620 - INFO - validation batch 151, loss: 1.200, 4832/6976 datapoints
2025-03-06 22:49:40,673 - INFO - validation batch 201, loss: 2.106, 6432/6976 datapoints
2025-03-06 22:49:40,691 - INFO - Epoch 471/800 done.
2025-03-06 22:49:40,691 - INFO - Final validation performance:
Loss: 1.682, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:49:40,692 - INFO - Beginning epoch 472/800
2025-03-06 22:49:40,697 - INFO - training batch 1, loss: 0.023, 32/28000 datapoints
2025-03-06 22:49:40,868 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 22:49:41,036 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-06 22:49:41,204 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:49:41,386 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 22:49:41,571 - INFO - training batch 251, loss: 0.036, 8032/28000 datapoints
2025-03-06 22:49:41,740 - INFO - training batch 301, loss: 0.015, 9632/28000 datapoints
2025-03-06 22:49:41,916 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-06 22:49:42,086 - INFO - training batch 401, loss: 0.016, 12832/28000 datapoints
2025-03-06 22:49:42,254 - INFO - training batch 451, loss: 0.024, 14432/28000 datapoints
2025-03-06 22:49:42,425 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 22:49:42,590 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 22:49:42,754 - INFO - training batch 601, loss: 0.012, 19232/28000 datapoints
2025-03-06 22:49:42,920 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:49:43,088 - INFO - training batch 701, loss: 0.011, 22432/28000 datapoints
2025-03-06 22:49:43,253 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-06 22:49:43,422 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:49:43,591 - INFO - training batch 851, loss: 0.014, 27232/28000 datapoints
2025-03-06 22:49:43,673 - INFO - validation batch 1, loss: 0.178, 32/6976 datapoints
2025-03-06 22:49:43,726 - INFO - validation batch 51, loss: 4.481, 1632/6976 datapoints
2025-03-06 22:49:43,780 - INFO - validation batch 101, loss: 0.501, 3232/6976 datapoints
2025-03-06 22:49:43,834 - INFO - validation batch 151, loss: 1.174, 4832/6976 datapoints
2025-03-06 22:49:43,888 - INFO - validation batch 201, loss: 2.070, 6432/6976 datapoints
2025-03-06 22:49:43,907 - INFO - Epoch 472/800 done.
2025-03-06 22:49:43,908 - INFO - Final validation performance:
Loss: 1.681, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:49:43,908 - INFO - Beginning epoch 473/800
2025-03-06 22:49:43,913 - INFO - training batch 1, loss: 0.022, 32/28000 datapoints
2025-03-06 22:49:44,084 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 22:49:44,247 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 22:49:44,413 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:49:44,573 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 22:49:44,744 - INFO - training batch 251, loss: 0.036, 8032/28000 datapoints
2025-03-06 22:49:44,910 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-06 22:49:45,072 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-06 22:49:45,234 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 22:49:45,398 - INFO - training batch 451, loss: 0.021, 14432/28000 datapoints
2025-03-06 22:49:45,561 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 22:49:45,726 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:49:45,888 - INFO - training batch 601, loss: 0.012, 19232/28000 datapoints
2025-03-06 22:49:46,053 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:49:46,216 - INFO - training batch 701, loss: 0.016, 22432/28000 datapoints
2025-03-06 22:49:46,381 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:49:46,562 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:49:46,724 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-06 22:49:46,804 - INFO - validation batch 1, loss: 0.174, 32/6976 datapoints
2025-03-06 22:49:46,852 - INFO - validation batch 51, loss: 4.470, 1632/6976 datapoints
2025-03-06 22:49:46,899 - INFO - validation batch 101, loss: 0.470, 3232/6976 datapoints
2025-03-06 22:49:46,946 - INFO - validation batch 151, loss: 1.197, 4832/6976 datapoints
2025-03-06 22:49:47,000 - INFO - validation batch 201, loss: 2.053, 6432/6976 datapoints
2025-03-06 22:49:47,019 - INFO - Epoch 473/800 done.
2025-03-06 22:49:47,019 - INFO - Final validation performance:
Loss: 1.673, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:49:47,020 - INFO - Beginning epoch 474/800
2025-03-06 22:49:47,024 - INFO - training batch 1, loss: 0.026, 32/28000 datapoints
2025-03-06 22:49:47,194 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 22:49:47,358 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 22:49:47,521 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:49:47,683 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:49:47,849 - INFO - training batch 251, loss: 0.032, 8032/28000 datapoints
2025-03-06 22:49:48,018 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-06 22:49:48,177 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-06 22:49:48,339 - INFO - training batch 401, loss: 0.015, 12832/28000 datapoints
2025-03-06 22:49:48,502 - INFO - training batch 451, loss: 0.022, 14432/28000 datapoints
2025-03-06 22:49:48,668 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 22:49:48,833 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 22:49:48,998 - INFO - training batch 601, loss: 0.012, 19232/28000 datapoints
2025-03-06 22:49:49,164 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:49:49,332 - INFO - training batch 701, loss: 0.075, 22432/28000 datapoints
2025-03-06 22:49:49,494 - INFO - training batch 751, loss: 0.059, 24032/28000 datapoints
2025-03-06 22:49:49,657 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:49:49,820 - INFO - training batch 851, loss: 0.071, 27232/28000 datapoints
2025-03-06 22:49:49,900 - INFO - validation batch 1, loss: 0.221, 32/6976 datapoints
2025-03-06 22:49:49,948 - INFO - validation batch 51, loss: 4.466, 1632/6976 datapoints
2025-03-06 22:49:50,000 - INFO - validation batch 101, loss: 0.609, 3232/6976 datapoints
2025-03-06 22:49:50,047 - INFO - validation batch 151, loss: 1.316, 4832/6976 datapoints
2025-03-06 22:49:50,095 - INFO - validation batch 201, loss: 1.899, 6432/6976 datapoints
2025-03-06 22:49:50,111 - INFO - Epoch 474/800 done.
2025-03-06 22:49:50,112 - INFO - Final validation performance:
Loss: 1.702, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:49:50,112 - INFO - Beginning epoch 475/800
2025-03-06 22:49:50,117 - INFO - training batch 1, loss: 0.014, 32/28000 datapoints
2025-03-06 22:49:50,282 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-06 22:49:50,450 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 22:49:50,613 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 22:49:50,775 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 22:49:50,941 - INFO - training batch 251, loss: 0.057, 8032/28000 datapoints
2025-03-06 22:49:51,116 - INFO - training batch 301, loss: 0.028, 9632/28000 datapoints
2025-03-06 22:49:51,277 - INFO - training batch 351, loss: 0.018, 11232/28000 datapoints
2025-03-06 22:49:51,442 - INFO - training batch 401, loss: 0.014, 12832/28000 datapoints
2025-03-06 22:49:51,628 - INFO - training batch 451, loss: 0.028, 14432/28000 datapoints
2025-03-06 22:49:51,792 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:49:51,954 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-06 22:49:52,120 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:49:52,286 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:49:52,455 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-06 22:49:52,616 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:49:52,798 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:49:52,962 - INFO - training batch 851, loss: 0.017, 27232/28000 datapoints
2025-03-06 22:49:53,044 - INFO - validation batch 1, loss: 0.194, 32/6976 datapoints
2025-03-06 22:49:53,092 - INFO - validation batch 51, loss: 4.632, 1632/6976 datapoints
2025-03-06 22:49:53,143 - INFO - validation batch 101, loss: 0.558, 3232/6976 datapoints
2025-03-06 22:49:53,195 - INFO - validation batch 151, loss: 1.098, 4832/6976 datapoints
2025-03-06 22:49:53,244 - INFO - validation batch 201, loss: 2.117, 6432/6976 datapoints
2025-03-06 22:49:53,261 - INFO - Epoch 475/800 done.
2025-03-06 22:49:53,261 - INFO - Final validation performance:
Loss: 1.720, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:49:53,262 - INFO - Beginning epoch 476/800
2025-03-06 22:49:53,266 - INFO - training batch 1, loss: 0.022, 32/28000 datapoints
2025-03-06 22:49:53,439 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 22:49:53,606 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 22:49:53,772 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:49:53,933 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 22:49:54,102 - INFO - training batch 251, loss: 0.039, 8032/28000 datapoints
2025-03-06 22:49:54,267 - INFO - training batch 301, loss: 0.015, 9632/28000 datapoints
2025-03-06 22:49:54,432 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-06 22:49:54,595 - INFO - training batch 401, loss: 0.023, 12832/28000 datapoints
2025-03-06 22:49:54,756 - INFO - training batch 451, loss: 0.021, 14432/28000 datapoints
2025-03-06 22:49:54,921 - INFO - training batch 501, loss: 0.016, 16032/28000 datapoints
2025-03-06 22:49:55,091 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 22:49:55,260 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:49:55,427 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:49:55,590 - INFO - training batch 701, loss: 0.010, 22432/28000 datapoints
2025-03-06 22:49:55,755 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:49:55,926 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:49:56,091 - INFO - training batch 851, loss: 0.013, 27232/28000 datapoints
2025-03-06 22:49:56,171 - INFO - validation batch 1, loss: 0.186, 32/6976 datapoints
2025-03-06 22:49:56,219 - INFO - validation batch 51, loss: 4.751, 1632/6976 datapoints
2025-03-06 22:49:56,267 - INFO - validation batch 101, loss: 0.531, 3232/6976 datapoints
2025-03-06 22:49:56,315 - INFO - validation batch 151, loss: 1.144, 4832/6976 datapoints
2025-03-06 22:49:56,363 - INFO - validation batch 201, loss: 2.078, 6432/6976 datapoints
2025-03-06 22:49:56,380 - INFO - Epoch 476/800 done.
2025-03-06 22:49:56,380 - INFO - Final validation performance:
Loss: 1.738, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:49:56,380 - INFO - Beginning epoch 477/800
2025-03-06 22:49:56,385 - INFO - training batch 1, loss: 0.025, 32/28000 datapoints
2025-03-06 22:49:56,555 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:49:56,717 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 22:49:56,882 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:49:57,046 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:49:57,213 - INFO - training batch 251, loss: 0.032, 8032/28000 datapoints
2025-03-06 22:49:57,379 - INFO - training batch 301, loss: 0.023, 9632/28000 datapoints
2025-03-06 22:49:57,540 - INFO - training batch 351, loss: 0.015, 11232/28000 datapoints
2025-03-06 22:49:57,703 - INFO - training batch 401, loss: 0.014, 12832/28000 datapoints
2025-03-06 22:49:57,864 - INFO - training batch 451, loss: 0.027, 14432/28000 datapoints
2025-03-06 22:49:58,034 - INFO - training batch 501, loss: 0.016, 16032/28000 datapoints
2025-03-06 22:49:58,197 - INFO - training batch 551, loss: 0.017, 17632/28000 datapoints
2025-03-06 22:49:58,359 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-06 22:49:58,525 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:49:58,689 - INFO - training batch 701, loss: 0.010, 22432/28000 datapoints
2025-03-06 22:49:58,858 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 22:49:59,035 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:49:59,195 - INFO - training batch 851, loss: 0.014, 27232/28000 datapoints
2025-03-06 22:49:59,274 - INFO - validation batch 1, loss: 0.180, 32/6976 datapoints
2025-03-06 22:49:59,322 - INFO - validation batch 51, loss: 4.698, 1632/6976 datapoints
2025-03-06 22:49:59,371 - INFO - validation batch 101, loss: 0.552, 3232/6976 datapoints
2025-03-06 22:49:59,428 - INFO - validation batch 151, loss: 1.135, 4832/6976 datapoints
2025-03-06 22:49:59,478 - INFO - validation batch 201, loss: 2.050, 6432/6976 datapoints
2025-03-06 22:49:59,494 - INFO - Epoch 477/800 done.
2025-03-06 22:49:59,494 - INFO - Final validation performance:
Loss: 1.723, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:49:59,495 - INFO - Beginning epoch 478/800
2025-03-06 22:49:59,499 - INFO - training batch 1, loss: 0.023, 32/28000 datapoints
2025-03-06 22:49:59,667 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 22:49:59,832 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 22:50:00,003 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:50:00,166 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:50:00,332 - INFO - training batch 251, loss: 0.033, 8032/28000 datapoints
2025-03-06 22:50:00,502 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-06 22:50:00,663 - INFO - training batch 351, loss: 0.013, 11232/28000 datapoints
2025-03-06 22:50:00,826 - INFO - training batch 401, loss: 0.015, 12832/28000 datapoints
2025-03-06 22:50:00,989 - INFO - training batch 451, loss: 0.019, 14432/28000 datapoints
2025-03-06 22:50:01,155 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 22:50:01,322 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-06 22:50:01,485 - INFO - training batch 601, loss: 0.009, 19232/28000 datapoints
2025-03-06 22:50:01,677 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:50:01,841 - INFO - training batch 701, loss: 0.011, 22432/28000 datapoints
2025-03-06 22:50:02,005 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:50:02,169 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:50:02,331 - INFO - training batch 851, loss: 0.013, 27232/28000 datapoints
2025-03-06 22:50:02,411 - INFO - validation batch 1, loss: 0.199, 32/6976 datapoints
2025-03-06 22:50:02,461 - INFO - validation batch 51, loss: 4.666, 1632/6976 datapoints
2025-03-06 22:50:02,510 - INFO - validation batch 101, loss: 0.503, 3232/6976 datapoints
2025-03-06 22:50:02,557 - INFO - validation batch 151, loss: 1.124, 4832/6976 datapoints
2025-03-06 22:50:02,605 - INFO - validation batch 201, loss: 2.073, 6432/6976 datapoints
2025-03-06 22:50:02,622 - INFO - Epoch 478/800 done.
2025-03-06 22:50:02,622 - INFO - Final validation performance:
Loss: 1.713, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:50:02,623 - INFO - Beginning epoch 479/800
2025-03-06 22:50:02,627 - INFO - training batch 1, loss: 0.020, 32/28000 datapoints
2025-03-06 22:50:02,792 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 22:50:02,956 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-06 22:50:03,124 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:50:03,286 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:50:03,454 - INFO - training batch 251, loss: 0.036, 8032/28000 datapoints
2025-03-06 22:50:03,626 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-06 22:50:03,787 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-06 22:50:03,951 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 22:50:04,124 - INFO - training batch 451, loss: 0.018, 14432/28000 datapoints
2025-03-06 22:50:04,293 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 22:50:04,467 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:50:04,634 - INFO - training batch 601, loss: 0.016, 19232/28000 datapoints
2025-03-06 22:50:04,804 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:50:04,974 - INFO - training batch 701, loss: 0.025, 22432/28000 datapoints
2025-03-06 22:50:05,155 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-06 22:50:05,333 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 22:50:05,502 - INFO - training batch 851, loss: 0.061, 27232/28000 datapoints
2025-03-06 22:50:05,597 - INFO - validation batch 1, loss: 0.299, 32/6976 datapoints
2025-03-06 22:50:05,654 - INFO - validation batch 51, loss: 4.896, 1632/6976 datapoints
2025-03-06 22:50:05,714 - INFO - validation batch 101, loss: 0.523, 3232/6976 datapoints
2025-03-06 22:50:05,770 - INFO - validation batch 151, loss: 1.210, 4832/6976 datapoints
2025-03-06 22:50:05,822 - INFO - validation batch 201, loss: 2.047, 6432/6976 datapoints
2025-03-06 22:50:05,839 - INFO - Epoch 479/800 done.
2025-03-06 22:50:05,839 - INFO - Final validation performance:
Loss: 1.795, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:50:05,839 - INFO - Beginning epoch 480/800
2025-03-06 22:50:05,844 - INFO - training batch 1, loss: 0.040, 32/28000 datapoints
2025-03-06 22:50:06,019 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 22:50:06,187 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 22:50:06,359 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:50:06,530 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 22:50:06,702 - INFO - training batch 251, loss: 0.048, 8032/28000 datapoints
2025-03-06 22:50:06,873 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:50:07,040 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-06 22:50:07,205 - INFO - training batch 401, loss: 0.039, 12832/28000 datapoints
2025-03-06 22:50:07,370 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-06 22:50:07,538 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-06 22:50:07,712 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-06 22:50:07,882 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:50:08,054 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:50:08,223 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:50:08,388 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-06 22:50:08,560 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:50:08,726 - INFO - training batch 851, loss: 0.023, 27232/28000 datapoints
2025-03-06 22:50:08,812 - INFO - validation batch 1, loss: 0.248, 32/6976 datapoints
2025-03-06 22:50:08,864 - INFO - validation batch 51, loss: 4.693, 1632/6976 datapoints
2025-03-06 22:50:08,916 - INFO - validation batch 101, loss: 0.521, 3232/6976 datapoints
2025-03-06 22:50:08,969 - INFO - validation batch 151, loss: 1.091, 4832/6976 datapoints
2025-03-06 22:50:09,020 - INFO - validation batch 201, loss: 2.144, 6432/6976 datapoints
2025-03-06 22:50:09,037 - INFO - Epoch 480/800 done.
2025-03-06 22:50:09,037 - INFO - Final validation performance:
Loss: 1.739, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:50:09,038 - INFO - Beginning epoch 481/800
2025-03-06 22:50:09,042 - INFO - training batch 1, loss: 0.023, 32/28000 datapoints
2025-03-06 22:50:09,214 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:50:09,381 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 22:50:09,551 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:50:09,716 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 22:50:09,889 - INFO - training batch 251, loss: 0.038, 8032/28000 datapoints
2025-03-06 22:50:10,068 - INFO - training batch 301, loss: 0.017, 9632/28000 datapoints
2025-03-06 22:50:10,240 - INFO - training batch 351, loss: 0.019, 11232/28000 datapoints
2025-03-06 22:50:10,414 - INFO - training batch 401, loss: 0.017, 12832/28000 datapoints
2025-03-06 22:50:10,586 - INFO - training batch 451, loss: 0.029, 14432/28000 datapoints
2025-03-06 22:50:10,755 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 22:50:10,921 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 22:50:11,091 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:50:11,274 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:50:11,445 - INFO - training batch 701, loss: 0.010, 22432/28000 datapoints
2025-03-06 22:50:11,613 - INFO - training batch 751, loss: 0.009, 24032/28000 datapoints
2025-03-06 22:50:11,810 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:50:11,982 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:50:12,068 - INFO - validation batch 1, loss: 0.212, 32/6976 datapoints
2025-03-06 22:50:12,122 - INFO - validation batch 51, loss: 4.596, 1632/6976 datapoints
2025-03-06 22:50:12,174 - INFO - validation batch 101, loss: 0.575, 3232/6976 datapoints
2025-03-06 22:50:12,228 - INFO - validation batch 151, loss: 1.197, 4832/6976 datapoints
2025-03-06 22:50:12,281 - INFO - validation batch 201, loss: 2.007, 6432/6976 datapoints
2025-03-06 22:50:12,297 - INFO - Epoch 481/800 done.
2025-03-06 22:50:12,297 - INFO - Final validation performance:
Loss: 1.717, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:50:12,298 - INFO - Beginning epoch 482/800
2025-03-06 22:50:12,303 - INFO - training batch 1, loss: 0.018, 32/28000 datapoints
2025-03-06 22:50:12,474 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-06 22:50:12,645 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 22:50:12,817 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:50:12,986 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 22:50:13,156 - INFO - training batch 251, loss: 0.034, 8032/28000 datapoints
2025-03-06 22:50:13,328 - INFO - training batch 301, loss: 0.018, 9632/28000 datapoints
2025-03-06 22:50:13,493 - INFO - training batch 351, loss: 0.016, 11232/28000 datapoints
2025-03-06 22:50:13,663 - INFO - training batch 401, loss: 0.018, 12832/28000 datapoints
2025-03-06 22:50:13,830 - INFO - training batch 451, loss: 0.023, 14432/28000 datapoints
2025-03-06 22:50:13,999 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 22:50:14,169 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 22:50:14,338 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-06 22:50:14,508 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:50:14,677 - INFO - training batch 701, loss: 0.010, 22432/28000 datapoints
2025-03-06 22:50:14,842 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:50:15,012 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:50:15,178 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-06 22:50:15,267 - INFO - validation batch 1, loss: 0.182, 32/6976 datapoints
2025-03-06 22:50:15,319 - INFO - validation batch 51, loss: 4.676, 1632/6976 datapoints
2025-03-06 22:50:15,374 - INFO - validation batch 101, loss: 0.567, 3232/6976 datapoints
2025-03-06 22:50:15,426 - INFO - validation batch 151, loss: 1.128, 4832/6976 datapoints
2025-03-06 22:50:15,478 - INFO - validation batch 201, loss: 2.144, 6432/6976 datapoints
2025-03-06 22:50:15,494 - INFO - Epoch 482/800 done.
2025-03-06 22:50:15,494 - INFO - Final validation performance:
Loss: 1.739, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:50:15,495 - INFO - Beginning epoch 483/800
2025-03-06 22:50:15,500 - INFO - training batch 1, loss: 0.019, 32/28000 datapoints
2025-03-06 22:50:15,677 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:50:15,845 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-06 22:50:16,021 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:50:16,193 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 22:50:16,365 - INFO - training batch 251, loss: 0.028, 8032/28000 datapoints
2025-03-06 22:50:16,559 - INFO - training batch 301, loss: 0.016, 9632/28000 datapoints
2025-03-06 22:50:16,726 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-06 22:50:16,892 - INFO - training batch 401, loss: 0.015, 12832/28000 datapoints
2025-03-06 22:50:17,059 - INFO - training batch 451, loss: 0.021, 14432/28000 datapoints
2025-03-06 22:50:17,228 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 22:50:17,409 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 22:50:17,582 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-06 22:50:17,750 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:50:17,926 - INFO - training batch 701, loss: 0.010, 22432/28000 datapoints
2025-03-06 22:50:18,099 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:50:18,274 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:50:18,438 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-06 22:50:18,526 - INFO - validation batch 1, loss: 0.204, 32/6976 datapoints
2025-03-06 22:50:18,577 - INFO - validation batch 51, loss: 4.729, 1632/6976 datapoints
2025-03-06 22:50:18,631 - INFO - validation batch 101, loss: 0.548, 3232/6976 datapoints
2025-03-06 22:50:18,683 - INFO - validation batch 151, loss: 1.137, 4832/6976 datapoints
2025-03-06 22:50:18,735 - INFO - validation batch 201, loss: 2.122, 6432/6976 datapoints
2025-03-06 22:50:18,752 - INFO - Epoch 483/800 done.
2025-03-06 22:50:18,753 - INFO - Final validation performance:
Loss: 1.748, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:50:18,753 - INFO - Beginning epoch 484/800
2025-03-06 22:50:18,758 - INFO - training batch 1, loss: 0.018, 32/28000 datapoints
2025-03-06 22:50:18,933 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:50:19,104 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-06 22:50:19,277 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:50:19,444 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:50:19,615 - INFO - training batch 251, loss: 0.028, 8032/28000 datapoints
2025-03-06 22:50:19,860 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-06 22:50:20,029 - INFO - training batch 351, loss: 0.013, 11232/28000 datapoints
2025-03-06 22:50:20,192 - INFO - training batch 401, loss: 0.015, 12832/28000 datapoints
2025-03-06 22:50:20,362 - INFO - training batch 451, loss: 0.019, 14432/28000 datapoints
2025-03-06 22:50:20,536 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 22:50:20,706 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:50:20,876 - INFO - training batch 601, loss: 0.012, 19232/28000 datapoints
2025-03-06 22:50:21,046 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:50:21,218 - INFO - training batch 701, loss: 0.012, 22432/28000 datapoints
2025-03-06 22:50:21,385 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:50:21,555 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:50:21,721 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-06 22:50:21,828 - INFO - validation batch 1, loss: 0.198, 32/6976 datapoints
2025-03-06 22:50:21,881 - INFO - validation batch 51, loss: 4.733, 1632/6976 datapoints
2025-03-06 22:50:21,934 - INFO - validation batch 101, loss: 0.522, 3232/6976 datapoints
2025-03-06 22:50:21,988 - INFO - validation batch 151, loss: 1.193, 4832/6976 datapoints
2025-03-06 22:50:22,040 - INFO - validation batch 201, loss: 2.108, 6432/6976 datapoints
2025-03-06 22:50:22,060 - INFO - Epoch 484/800 done.
2025-03-06 22:50:22,060 - INFO - Final validation performance:
Loss: 1.751, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:50:22,061 - INFO - Beginning epoch 485/800
2025-03-06 22:50:22,067 - INFO - training batch 1, loss: 0.022, 32/28000 datapoints
2025-03-06 22:50:22,233 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:50:22,399 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 22:50:22,570 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:50:22,733 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:50:22,900 - INFO - training batch 251, loss: 0.030, 8032/28000 datapoints
2025-03-06 22:50:23,073 - INFO - training batch 301, loss: 0.015, 9632/28000 datapoints
2025-03-06 22:50:23,234 - INFO - training batch 351, loss: 0.019, 11232/28000 datapoints
2025-03-06 22:50:23,398 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 22:50:23,574 - INFO - training batch 451, loss: 0.023, 14432/28000 datapoints
2025-03-06 22:50:23,743 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 22:50:23,916 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-06 22:50:24,094 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-06 22:50:24,266 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:50:24,437 - INFO - training batch 701, loss: 0.017, 22432/28000 datapoints
2025-03-06 22:50:24,604 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:50:24,773 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:50:24,939 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-06 22:50:25,034 - INFO - validation batch 1, loss: 0.235, 32/6976 datapoints
2025-03-06 22:50:25,087 - INFO - validation batch 51, loss: 4.789, 1632/6976 datapoints
2025-03-06 22:50:25,139 - INFO - validation batch 101, loss: 0.527, 3232/6976 datapoints
2025-03-06 22:50:25,191 - INFO - validation batch 151, loss: 1.220, 4832/6976 datapoints
2025-03-06 22:50:25,250 - INFO - validation batch 201, loss: 2.139, 6432/6976 datapoints
2025-03-06 22:50:25,272 - INFO - Epoch 485/800 done.
2025-03-06 22:50:25,272 - INFO - Final validation performance:
Loss: 1.782, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:50:25,272 - INFO - Beginning epoch 486/800
2025-03-06 22:50:25,276 - INFO - training batch 1, loss: 0.020, 32/28000 datapoints
2025-03-06 22:50:25,455 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:50:25,622 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-06 22:50:25,796 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-06 22:50:25,966 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:50:26,136 - INFO - training batch 251, loss: 0.027, 8032/28000 datapoints
2025-03-06 22:50:26,307 - INFO - training batch 301, loss: 0.023, 9632/28000 datapoints
2025-03-06 22:50:26,476 - INFO - training batch 351, loss: 0.051, 11232/28000 datapoints
2025-03-06 22:50:26,645 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:50:26,812 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-06 22:50:26,984 - INFO - training batch 501, loss: 0.021, 16032/28000 datapoints
2025-03-06 22:50:27,152 - INFO - training batch 551, loss: 0.089, 17632/28000 datapoints
2025-03-06 22:50:27,319 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:50:27,487 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:50:27,656 - INFO - training batch 701, loss: 0.012, 22432/28000 datapoints
2025-03-06 22:50:27,820 - INFO - training batch 751, loss: 0.028, 24032/28000 datapoints
2025-03-06 22:50:27,994 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:50:28,159 - INFO - training batch 851, loss: 0.016, 27232/28000 datapoints
2025-03-06 22:50:28,244 - INFO - validation batch 1, loss: 0.148, 32/6976 datapoints
2025-03-06 22:50:28,295 - INFO - validation batch 51, loss: 5.043, 1632/6976 datapoints
2025-03-06 22:50:28,349 - INFO - validation batch 101, loss: 0.639, 3232/6976 datapoints
2025-03-06 22:50:28,400 - INFO - validation batch 151, loss: 1.137, 4832/6976 datapoints
2025-03-06 22:50:28,453 - INFO - validation batch 201, loss: 2.282, 6432/6976 datapoints
2025-03-06 22:50:28,474 - INFO - Epoch 486/800 done.
2025-03-06 22:50:28,474 - INFO - Final validation performance:
Loss: 1.850, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:50:28,475 - INFO - Beginning epoch 487/800
2025-03-06 22:50:28,479 - INFO - training batch 1, loss: 0.020, 32/28000 datapoints
2025-03-06 22:50:28,653 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 22:50:28,821 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-06 22:50:28,997 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:50:29,164 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 22:50:29,335 - INFO - training batch 251, loss: 0.035, 8032/28000 datapoints
2025-03-06 22:50:29,518 - INFO - training batch 301, loss: 0.040, 9632/28000 datapoints
2025-03-06 22:50:29,687 - INFO - training batch 351, loss: 0.035, 11232/28000 datapoints
2025-03-06 22:50:29,851 - INFO - training batch 401, loss: 0.014, 12832/28000 datapoints
2025-03-06 22:50:30,029 - INFO - training batch 451, loss: 0.014, 14432/28000 datapoints
2025-03-06 22:50:30,202 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 22:50:30,375 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:50:30,568 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-06 22:50:30,744 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:50:30,916 - INFO - training batch 701, loss: 0.010, 22432/28000 datapoints
2025-03-06 22:50:31,082 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:50:31,253 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:50:31,423 - INFO - training batch 851, loss: 0.013, 27232/28000 datapoints
2025-03-06 22:50:31,508 - INFO - validation batch 1, loss: 0.219, 32/6976 datapoints
2025-03-06 22:50:31,562 - INFO - validation batch 51, loss: 5.011, 1632/6976 datapoints
2025-03-06 22:50:31,615 - INFO - validation batch 101, loss: 0.638, 3232/6976 datapoints
2025-03-06 22:50:31,667 - INFO - validation batch 151, loss: 1.154, 4832/6976 datapoints
2025-03-06 22:50:31,719 - INFO - validation batch 201, loss: 2.228, 6432/6976 datapoints
2025-03-06 22:50:31,736 - INFO - Epoch 487/800 done.
2025-03-06 22:50:31,736 - INFO - Final validation performance:
Loss: 1.850, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:50:31,737 - INFO - Beginning epoch 488/800
2025-03-06 22:50:31,741 - INFO - training batch 1, loss: 0.017, 32/28000 datapoints
2025-03-06 22:50:31,942 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 22:50:32,119 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 22:50:32,290 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:50:32,459 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 22:50:32,633 - INFO - training batch 251, loss: 0.029, 8032/28000 datapoints
2025-03-06 22:50:32,805 - INFO - training batch 301, loss: 0.016, 9632/28000 datapoints
2025-03-06 22:50:32,976 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-06 22:50:33,141 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:50:33,306 - INFO - training batch 451, loss: 0.019, 14432/28000 datapoints
2025-03-06 22:50:33,476 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 22:50:33,653 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 22:50:33,821 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-06 22:50:33,992 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:50:34,160 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:50:34,326 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:50:34,496 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:50:34,666 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:50:34,751 - INFO - validation batch 1, loss: 0.233, 32/6976 datapoints
2025-03-06 22:50:34,803 - INFO - validation batch 51, loss: 5.009, 1632/6976 datapoints
2025-03-06 22:50:34,856 - INFO - validation batch 101, loss: 0.610, 3232/6976 datapoints
2025-03-06 22:50:34,912 - INFO - validation batch 151, loss: 1.164, 4832/6976 datapoints
2025-03-06 22:50:34,960 - INFO - validation batch 201, loss: 2.197, 6432/6976 datapoints
2025-03-06 22:50:34,980 - INFO - Epoch 488/800 done.
2025-03-06 22:50:34,980 - INFO - Final validation performance:
Loss: 1.843, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:50:34,980 - INFO - Beginning epoch 489/800
2025-03-06 22:50:34,985 - INFO - training batch 1, loss: 0.014, 32/28000 datapoints
2025-03-06 22:50:35,153 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:50:35,323 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 22:50:35,503 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:50:35,690 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:50:35,861 - INFO - training batch 251, loss: 0.026, 8032/28000 datapoints
2025-03-06 22:50:36,038 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-06 22:50:36,206 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-06 22:50:36,374 - INFO - training batch 401, loss: 0.012, 12832/28000 datapoints
2025-03-06 22:50:36,541 - INFO - training batch 451, loss: 0.015, 14432/28000 datapoints
2025-03-06 22:50:36,755 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:50:36,928 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-06 22:50:37,094 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-06 22:50:37,258 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:50:37,424 - INFO - training batch 701, loss: 0.013, 22432/28000 datapoints
2025-03-06 22:50:37,603 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:50:37,770 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:50:37,935 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:50:38,032 - INFO - validation batch 1, loss: 0.235, 32/6976 datapoints
2025-03-06 22:50:38,081 - INFO - validation batch 51, loss: 4.993, 1632/6976 datapoints
2025-03-06 22:50:38,128 - INFO - validation batch 101, loss: 0.541, 3232/6976 datapoints
2025-03-06 22:50:38,175 - INFO - validation batch 151, loss: 1.203, 4832/6976 datapoints
2025-03-06 22:50:38,225 - INFO - validation batch 201, loss: 2.163, 6432/6976 datapoints
2025-03-06 22:50:38,241 - INFO - Epoch 489/800 done.
2025-03-06 22:50:38,241 - INFO - Final validation performance:
Loss: 1.827, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:50:38,242 - INFO - Beginning epoch 490/800
2025-03-06 22:50:38,246 - INFO - training batch 1, loss: 0.018, 32/28000 datapoints
2025-03-06 22:50:38,413 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-06 22:50:38,580 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 22:50:38,753 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:50:38,918 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:50:39,087 - INFO - training batch 251, loss: 0.025, 8032/28000 datapoints
2025-03-06 22:50:39,254 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:50:39,422 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-06 22:50:39,585 - INFO - training batch 401, loss: 0.014, 12832/28000 datapoints
2025-03-06 22:50:39,747 - INFO - training batch 451, loss: 0.015, 14432/28000 datapoints
2025-03-06 22:50:39,914 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 22:50:40,085 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-06 22:50:40,249 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-06 22:50:40,416 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:50:40,584 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-06 22:50:40,748 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:50:40,920 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:50:41,088 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-06 22:50:41,171 - INFO - validation batch 1, loss: 0.212, 32/6976 datapoints
2025-03-06 22:50:41,218 - INFO - validation batch 51, loss: 4.977, 1632/6976 datapoints
2025-03-06 22:50:41,267 - INFO - validation batch 101, loss: 0.526, 3232/6976 datapoints
2025-03-06 22:50:41,314 - INFO - validation batch 151, loss: 1.276, 4832/6976 datapoints
2025-03-06 22:50:41,363 - INFO - validation batch 201, loss: 2.177, 6432/6976 datapoints
2025-03-06 22:50:41,379 - INFO - Epoch 490/800 done.
2025-03-06 22:50:41,380 - INFO - Final validation performance:
Loss: 1.834, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:50:41,380 - INFO - Beginning epoch 491/800
2025-03-06 22:50:41,385 - INFO - training batch 1, loss: 0.021, 32/28000 datapoints
2025-03-06 22:50:41,554 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 22:50:41,736 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 22:50:41,905 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:50:42,108 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:50:42,278 - INFO - training batch 251, loss: 0.023, 8032/28000 datapoints
2025-03-06 22:50:42,451 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-06 22:50:42,621 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-06 22:50:42,782 - INFO - training batch 401, loss: 0.012, 12832/28000 datapoints
2025-03-06 22:50:42,946 - INFO - training batch 451, loss: 0.015, 14432/28000 datapoints
2025-03-06 22:50:43,116 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:50:43,282 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-06 22:50:43,446 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-06 22:50:43,613 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:50:43,784 - INFO - training batch 701, loss: 0.010, 22432/28000 datapoints
2025-03-06 22:50:43,947 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:50:44,122 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:50:44,291 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-06 22:50:44,376 - INFO - validation batch 1, loss: 0.208, 32/6976 datapoints
2025-03-06 22:50:44,430 - INFO - validation batch 51, loss: 5.002, 1632/6976 datapoints
2025-03-06 22:50:44,482 - INFO - validation batch 101, loss: 0.523, 3232/6976 datapoints
2025-03-06 22:50:44,534 - INFO - validation batch 151, loss: 1.315, 4832/6976 datapoints
2025-03-06 22:50:44,585 - INFO - validation batch 201, loss: 2.193, 6432/6976 datapoints
2025-03-06 22:50:44,604 - INFO - Epoch 491/800 done.
2025-03-06 22:50:44,604 - INFO - Final validation performance:
Loss: 1.848, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:50:44,605 - INFO - Beginning epoch 492/800
2025-03-06 22:50:44,609 - INFO - training batch 1, loss: 0.020, 32/28000 datapoints
2025-03-06 22:50:44,781 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 22:50:44,946 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 22:50:45,122 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:50:45,293 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-06 22:50:45,462 - INFO - training batch 251, loss: 0.027, 8032/28000 datapoints
2025-03-06 22:50:45,634 - INFO - training batch 301, loss: 0.015, 9632/28000 datapoints
2025-03-06 22:50:45,800 - INFO - training batch 351, loss: 0.063, 11232/28000 datapoints
2025-03-06 22:50:45,961 - INFO - training batch 401, loss: 0.309, 12832/28000 datapoints
2025-03-06 22:50:46,130 - INFO - training batch 451, loss: 0.033, 14432/28000 datapoints
2025-03-06 22:50:46,297 - INFO - training batch 501, loss: 0.042, 16032/28000 datapoints
2025-03-06 22:50:46,464 - INFO - training batch 551, loss: 0.079, 17632/28000 datapoints
2025-03-06 22:50:46,630 - INFO - training batch 601, loss: 0.006, 19232/28000 datapoints
2025-03-06 22:50:46,795 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:50:46,962 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:50:47,131 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 22:50:47,297 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:50:47,461 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-06 22:50:47,545 - INFO - validation batch 1, loss: 0.191, 32/6976 datapoints
2025-03-06 22:50:47,593 - INFO - validation batch 51, loss: 5.107, 1632/6976 datapoints
2025-03-06 22:50:47,641 - INFO - validation batch 101, loss: 0.612, 3232/6976 datapoints
2025-03-06 22:50:47,689 - INFO - validation batch 151, loss: 1.405, 4832/6976 datapoints
2025-03-06 22:50:47,737 - INFO - validation batch 201, loss: 2.224, 6432/6976 datapoints
2025-03-06 22:50:47,753 - INFO - Epoch 492/800 done.
2025-03-06 22:50:47,754 - INFO - Final validation performance:
Loss: 1.908, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:50:47,754 - INFO - Beginning epoch 493/800
2025-03-06 22:50:47,758 - INFO - training batch 1, loss: 0.024, 32/28000 datapoints
2025-03-06 22:50:47,938 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 22:50:48,107 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-06 22:50:48,275 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:50:48,452 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-06 22:50:48,622 - INFO - training batch 251, loss: 0.042, 8032/28000 datapoints
2025-03-06 22:50:48,799 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:50:48,963 - INFO - training batch 351, loss: 0.010, 11232/28000 datapoints
2025-03-06 22:50:49,130 - INFO - training batch 401, loss: 0.023, 12832/28000 datapoints
2025-03-06 22:50:49,293 - INFO - training batch 451, loss: 0.014, 14432/28000 datapoints
2025-03-06 22:50:49,458 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:50:49,626 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 22:50:49,790 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:50:49,956 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:50:50,139 - INFO - training batch 701, loss: 0.010, 22432/28000 datapoints
2025-03-06 22:50:50,302 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:50:50,471 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:50:50,636 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-06 22:50:50,721 - INFO - validation batch 1, loss: 0.220, 32/6976 datapoints
2025-03-06 22:50:50,769 - INFO - validation batch 51, loss: 5.048, 1632/6976 datapoints
2025-03-06 22:50:50,817 - INFO - validation batch 101, loss: 0.641, 3232/6976 datapoints
2025-03-06 22:50:50,864 - INFO - validation batch 151, loss: 1.161, 4832/6976 datapoints
2025-03-06 22:50:50,912 - INFO - validation batch 201, loss: 2.404, 6432/6976 datapoints
2025-03-06 22:50:50,929 - INFO - Epoch 493/800 done.
2025-03-06 22:50:50,929 - INFO - Final validation performance:
Loss: 1.895, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:50:50,929 - INFO - Beginning epoch 494/800
2025-03-06 22:50:50,934 - INFO - training batch 1, loss: 0.039, 32/28000 datapoints
2025-03-06 22:50:51,133 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-06 22:50:51,300 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 22:50:51,470 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:50:51,636 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 22:50:51,802 - INFO - training batch 251, loss: 0.036, 8032/28000 datapoints
2025-03-06 22:50:51,974 - INFO - training batch 301, loss: 0.016, 9632/28000 datapoints
2025-03-06 22:50:52,167 - INFO - training batch 351, loss: 0.010, 11232/28000 datapoints
2025-03-06 22:50:52,332 - INFO - training batch 401, loss: 0.014, 12832/28000 datapoints
2025-03-06 22:50:52,495 - INFO - training batch 451, loss: 0.018, 14432/28000 datapoints
2025-03-06 22:50:52,666 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 22:50:52,832 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 22:50:52,999 - INFO - training batch 601, loss: 0.006, 19232/28000 datapoints
2025-03-06 22:50:53,167 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:50:53,335 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:50:53,497 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:50:53,666 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-06 22:50:53,831 - INFO - training batch 851, loss: 0.024, 27232/28000 datapoints
2025-03-06 22:50:53,915 - INFO - validation batch 1, loss: 0.102, 32/6976 datapoints
2025-03-06 22:50:53,962 - INFO - validation batch 51, loss: 5.003, 1632/6976 datapoints
2025-03-06 22:50:54,012 - INFO - validation batch 101, loss: 0.588, 3232/6976 datapoints
2025-03-06 22:50:54,059 - INFO - validation batch 151, loss: 1.264, 4832/6976 datapoints
2025-03-06 22:50:54,112 - INFO - validation batch 201, loss: 2.201, 6432/6976 datapoints
2025-03-06 22:50:54,136 - INFO - Epoch 494/800 done.
2025-03-06 22:50:54,137 - INFO - Final validation performance:
Loss: 1.831, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:50:54,137 - INFO - Beginning epoch 495/800
2025-03-06 22:50:54,142 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-06 22:50:54,312 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:50:54,476 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 22:50:54,652 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:50:54,821 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 22:50:54,989 - INFO - training batch 251, loss: 0.028, 8032/28000 datapoints
2025-03-06 22:50:55,161 - INFO - training batch 301, loss: 0.020, 9632/28000 datapoints
2025-03-06 22:50:55,329 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-06 22:50:55,491 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:50:55,657 - INFO - training batch 451, loss: 0.016, 14432/28000 datapoints
2025-03-06 22:50:55,825 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:50:55,994 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-06 22:50:56,170 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:50:56,338 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:50:56,511 - INFO - training batch 701, loss: 0.032, 22432/28000 datapoints
2025-03-06 22:50:56,676 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:50:56,846 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:50:57,012 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:50:57,094 - INFO - validation batch 1, loss: 0.181, 32/6976 datapoints
2025-03-06 22:50:57,142 - INFO - validation batch 51, loss: 4.970, 1632/6976 datapoints
2025-03-06 22:50:57,190 - INFO - validation batch 101, loss: 0.632, 3232/6976 datapoints
2025-03-06 22:50:57,237 - INFO - validation batch 151, loss: 1.320, 4832/6976 datapoints
2025-03-06 22:50:57,284 - INFO - validation batch 201, loss: 2.271, 6432/6976 datapoints
2025-03-06 22:50:57,300 - INFO - Epoch 495/800 done.
2025-03-06 22:50:57,300 - INFO - Final validation performance:
Loss: 1.875, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:50:57,301 - INFO - Beginning epoch 496/800
2025-03-06 22:50:57,305 - INFO - training batch 1, loss: 0.023, 32/28000 datapoints
2025-03-06 22:50:57,474 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-06 22:50:57,639 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:50:57,812 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:50:57,979 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 22:50:58,146 - INFO - training batch 251, loss: 0.038, 8032/28000 datapoints
2025-03-06 22:50:58,318 - INFO - training batch 301, loss: 0.016, 9632/28000 datapoints
2025-03-06 22:50:58,483 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-06 22:50:58,647 - INFO - training batch 401, loss: 0.012, 12832/28000 datapoints
2025-03-06 22:50:58,815 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-06 22:50:58,991 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:50:59,168 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 22:50:59,341 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-06 22:50:59,517 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:50:59,691 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:50:59,861 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:51:00,038 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:51:00,208 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:51:00,293 - INFO - validation batch 1, loss: 0.255, 32/6976 datapoints
2025-03-06 22:51:00,345 - INFO - validation batch 51, loss: 5.079, 1632/6976 datapoints
2025-03-06 22:51:00,392 - INFO - validation batch 101, loss: 0.634, 3232/6976 datapoints
2025-03-06 22:51:00,439 - INFO - validation batch 151, loss: 1.238, 4832/6976 datapoints
2025-03-06 22:51:00,487 - INFO - validation batch 201, loss: 2.268, 6432/6976 datapoints
2025-03-06 22:51:00,504 - INFO - Epoch 496/800 done.
2025-03-06 22:51:00,504 - INFO - Final validation performance:
Loss: 1.895, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:51:00,505 - INFO - Beginning epoch 497/800
2025-03-06 22:51:00,509 - INFO - training batch 1, loss: 0.014, 32/28000 datapoints
2025-03-06 22:51:00,678 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:51:00,848 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:51:01,019 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:51:01,185 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:51:01,352 - INFO - training batch 251, loss: 0.023, 8032/28000 datapoints
2025-03-06 22:51:01,525 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-06 22:51:01,690 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-06 22:51:01,854 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:51:02,022 - INFO - training batch 451, loss: 0.015, 14432/28000 datapoints
2025-03-06 22:51:02,196 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:51:02,383 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:51:02,550 - INFO - training batch 601, loss: 0.009, 19232/28000 datapoints
2025-03-06 22:51:02,721 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:51:02,892 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:51:03,057 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:51:03,227 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:51:03,392 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:51:03,475 - INFO - validation batch 1, loss: 0.253, 32/6976 datapoints
2025-03-06 22:51:03,525 - INFO - validation batch 51, loss: 5.055, 1632/6976 datapoints
2025-03-06 22:51:03,572 - INFO - validation batch 101, loss: 0.600, 3232/6976 datapoints
2025-03-06 22:51:03,620 - INFO - validation batch 151, loss: 1.266, 4832/6976 datapoints
2025-03-06 22:51:03,667 - INFO - validation batch 201, loss: 2.258, 6432/6976 datapoints
2025-03-06 22:51:03,684 - INFO - Epoch 497/800 done.
2025-03-06 22:51:03,684 - INFO - Final validation performance:
Loss: 1.886, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:51:03,685 - INFO - Beginning epoch 498/800
2025-03-06 22:51:03,689 - INFO - training batch 1, loss: 0.016, 32/28000 datapoints
2025-03-06 22:51:03,866 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:51:04,034 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-06 22:51:04,205 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-06 22:51:04,378 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:51:04,548 - INFO - training batch 251, loss: 0.019, 8032/28000 datapoints
2025-03-06 22:51:04,725 - INFO - training batch 301, loss: 0.015, 9632/28000 datapoints
2025-03-06 22:51:04,894 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:51:05,065 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:51:05,233 - INFO - training batch 451, loss: 0.015, 14432/28000 datapoints
2025-03-06 22:51:05,408 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 22:51:05,579 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-06 22:51:05,758 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-06 22:51:05,931 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:51:06,108 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:51:06,277 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:51:06,452 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:51:06,635 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:51:06,727 - INFO - validation batch 1, loss: 0.251, 32/6976 datapoints
2025-03-06 22:51:06,778 - INFO - validation batch 51, loss: 5.094, 1632/6976 datapoints
2025-03-06 22:51:06,831 - INFO - validation batch 101, loss: 0.598, 3232/6976 datapoints
2025-03-06 22:51:06,883 - INFO - validation batch 151, loss: 1.302, 4832/6976 datapoints
2025-03-06 22:51:06,935 - INFO - validation batch 201, loss: 2.268, 6432/6976 datapoints
2025-03-06 22:51:06,952 - INFO - Epoch 498/800 done.
2025-03-06 22:51:06,952 - INFO - Final validation performance:
Loss: 1.903, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:51:06,953 - INFO - Beginning epoch 499/800
2025-03-06 22:51:06,958 - INFO - training batch 1, loss: 0.016, 32/28000 datapoints
2025-03-06 22:51:07,135 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-06 22:51:07,302 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:51:07,479 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:51:07,646 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:51:07,813 - INFO - training batch 251, loss: 0.017, 8032/28000 datapoints
2025-03-06 22:51:07,987 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-06 22:51:08,151 - INFO - training batch 351, loss: 0.016, 11232/28000 datapoints
2025-03-06 22:51:08,317 - INFO - training batch 401, loss: 0.295, 12832/28000 datapoints
2025-03-06 22:51:08,482 - INFO - training batch 451, loss: 0.013, 14432/28000 datapoints
2025-03-06 22:51:08,667 - INFO - training batch 501, loss: 0.019, 16032/28000 datapoints
2025-03-06 22:51:08,840 - INFO - training batch 551, loss: 0.031, 17632/28000 datapoints
2025-03-06 22:51:09,007 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:51:09,176 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:51:09,347 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:51:09,516 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:51:09,685 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:51:09,851 - INFO - training batch 851, loss: 0.012, 27232/28000 datapoints
2025-03-06 22:51:09,935 - INFO - validation batch 1, loss: 0.214, 32/6976 datapoints
2025-03-06 22:51:09,985 - INFO - validation batch 51, loss: 5.117, 1632/6976 datapoints
2025-03-06 22:51:10,033 - INFO - validation batch 101, loss: 0.675, 3232/6976 datapoints
2025-03-06 22:51:10,080 - INFO - validation batch 151, loss: 1.280, 4832/6976 datapoints
2025-03-06 22:51:10,132 - INFO - validation batch 201, loss: 2.477, 6432/6976 datapoints
2025-03-06 22:51:10,148 - INFO - Epoch 499/800 done.
2025-03-06 22:51:10,148 - INFO - Final validation performance:
Loss: 1.953, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:51:10,149 - INFO - Beginning epoch 500/800
2025-03-06 22:51:10,153 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-06 22:51:10,323 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 22:51:10,490 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:51:10,661 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:51:10,831 - INFO - training batch 201, loss: 0.112, 6432/28000 datapoints
2025-03-06 22:51:10,998 - INFO - training batch 251, loss: 0.095, 8032/28000 datapoints
2025-03-06 22:51:11,168 - INFO - training batch 301, loss: 0.038, 9632/28000 datapoints
2025-03-06 22:51:11,336 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:51:11,508 - INFO - training batch 401, loss: 0.019, 12832/28000 datapoints
2025-03-06 22:51:11,677 - INFO - training batch 451, loss: 0.016, 14432/28000 datapoints
2025-03-06 22:51:11,845 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:51:12,015 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 22:51:12,180 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:51:12,373 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:51:12,546 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-06 22:51:12,712 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 22:51:12,900 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-06 22:51:13,067 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-06 22:51:13,152 - INFO - validation batch 1, loss: 0.234, 32/6976 datapoints
2025-03-06 22:51:13,200 - INFO - validation batch 51, loss: 5.083, 1632/6976 datapoints
2025-03-06 22:51:13,256 - INFO - validation batch 101, loss: 0.687, 3232/6976 datapoints
2025-03-06 22:51:13,307 - INFO - validation batch 151, loss: 1.330, 4832/6976 datapoints
2025-03-06 22:51:13,354 - INFO - validation batch 201, loss: 2.335, 6432/6976 datapoints
2025-03-06 22:51:13,372 - INFO - Epoch 500/800 done.
2025-03-06 22:51:13,372 - INFO - Final validation performance:
Loss: 1.933, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:51:13,373 - INFO - Beginning epoch 501/800
2025-03-06 22:51:13,377 - INFO - training batch 1, loss: 0.023, 32/28000 datapoints
2025-03-06 22:51:13,550 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:51:13,716 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-06 22:51:13,893 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:51:14,062 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:51:14,228 - INFO - training batch 251, loss: 0.032, 8032/28000 datapoints
2025-03-06 22:51:14,399 - INFO - training batch 301, loss: 0.017, 9632/28000 datapoints
2025-03-06 22:51:14,564 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-06 22:51:14,730 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:51:14,896 - INFO - training batch 451, loss: 0.016, 14432/28000 datapoints
2025-03-06 22:51:15,067 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 22:51:15,236 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 22:51:15,408 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:51:15,574 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:51:15,748 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:51:15,913 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:51:16,083 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:51:16,248 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:51:16,334 - INFO - validation batch 1, loss: 0.233, 32/6976 datapoints
2025-03-06 22:51:16,381 - INFO - validation batch 51, loss: 5.075, 1632/6976 datapoints
2025-03-06 22:51:16,431 - INFO - validation batch 101, loss: 0.672, 3232/6976 datapoints
2025-03-06 22:51:16,479 - INFO - validation batch 151, loss: 1.315, 4832/6976 datapoints
2025-03-06 22:51:16,526 - INFO - validation batch 201, loss: 2.365, 6432/6976 datapoints
2025-03-06 22:51:16,543 - INFO - Epoch 501/800 done.
2025-03-06 22:51:16,543 - INFO - Final validation performance:
Loss: 1.932, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:51:16,543 - INFO - Beginning epoch 502/800
2025-03-06 22:51:16,548 - INFO - training batch 1, loss: 0.017, 32/28000 datapoints
2025-03-06 22:51:16,716 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:51:16,887 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:51:17,063 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:51:17,229 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:51:17,397 - INFO - training batch 251, loss: 0.021, 8032/28000 datapoints
2025-03-06 22:51:17,570 - INFO - training batch 301, loss: 0.022, 9632/28000 datapoints
2025-03-06 22:51:17,736 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:51:17,918 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:51:18,087 - INFO - training batch 451, loss: 0.013, 14432/28000 datapoints
2025-03-06 22:51:18,275 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 22:51:18,444 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-06 22:51:18,610 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:51:18,779 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:51:18,961 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:51:19,131 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:51:19,300 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:51:19,470 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:51:19,558 - INFO - validation batch 1, loss: 0.239, 32/6976 datapoints
2025-03-06 22:51:19,606 - INFO - validation batch 51, loss: 5.154, 1632/6976 datapoints
2025-03-06 22:51:19,657 - INFO - validation batch 101, loss: 0.660, 3232/6976 datapoints
2025-03-06 22:51:19,705 - INFO - validation batch 151, loss: 1.347, 4832/6976 datapoints
2025-03-06 22:51:19,752 - INFO - validation batch 201, loss: 2.349, 6432/6976 datapoints
2025-03-06 22:51:19,768 - INFO - Epoch 502/800 done.
2025-03-06 22:51:19,768 - INFO - Final validation performance:
Loss: 1.950, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:51:19,769 - INFO - Beginning epoch 503/800
2025-03-06 22:51:19,773 - INFO - training batch 1, loss: 0.014, 32/28000 datapoints
2025-03-06 22:51:19,946 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:51:20,116 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:51:20,287 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:51:20,454 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-06 22:51:20,620 - INFO - training batch 251, loss: 0.017, 8032/28000 datapoints
2025-03-06 22:51:20,795 - INFO - training batch 301, loss: 0.019, 9632/28000 datapoints
2025-03-06 22:51:20,962 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:51:21,128 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:51:21,295 - INFO - training batch 451, loss: 0.013, 14432/28000 datapoints
2025-03-06 22:51:21,464 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 22:51:21,634 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-06 22:51:21,804 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-06 22:51:21,974 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:51:22,147 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:51:22,312 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:51:22,508 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:51:22,673 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:51:22,760 - INFO - validation batch 1, loss: 0.231, 32/6976 datapoints
2025-03-06 22:51:22,807 - INFO - validation batch 51, loss: 5.179, 1632/6976 datapoints
2025-03-06 22:51:22,857 - INFO - validation batch 101, loss: 0.637, 3232/6976 datapoints
2025-03-06 22:51:22,905 - INFO - validation batch 151, loss: 1.408, 4832/6976 datapoints
2025-03-06 22:51:22,952 - INFO - validation batch 201, loss: 2.319, 6432/6976 datapoints
2025-03-06 22:51:22,973 - INFO - Epoch 503/800 done.
2025-03-06 22:51:22,974 - INFO - Final validation performance:
Loss: 1.955, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:51:22,975 - INFO - Beginning epoch 504/800
2025-03-06 22:51:22,979 - INFO - training batch 1, loss: 0.016, 32/28000 datapoints
2025-03-06 22:51:23,147 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-06 22:51:23,317 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:51:23,493 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:51:23,664 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:51:23,835 - INFO - training batch 251, loss: 0.016, 8032/28000 datapoints
2025-03-06 22:51:24,011 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:51:24,182 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:51:24,347 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:51:24,521 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-06 22:51:24,693 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 22:51:24,866 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-06 22:51:25,039 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-06 22:51:25,226 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:51:25,406 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:51:25,575 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:51:25,755 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:51:25,928 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:51:26,020 - INFO - validation batch 1, loss: 0.212, 32/6976 datapoints
2025-03-06 22:51:26,075 - INFO - validation batch 51, loss: 5.186, 1632/6976 datapoints
2025-03-06 22:51:26,130 - INFO - validation batch 101, loss: 0.627, 3232/6976 datapoints
2025-03-06 22:51:26,182 - INFO - validation batch 151, loss: 1.451, 4832/6976 datapoints
2025-03-06 22:51:26,235 - INFO - validation batch 201, loss: 2.339, 6432/6976 datapoints
2025-03-06 22:51:26,251 - INFO - Epoch 504/800 done.
2025-03-06 22:51:26,251 - INFO - Final validation performance:
Loss: 1.963, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:51:26,252 - INFO - Beginning epoch 505/800
2025-03-06 22:51:26,257 - INFO - training batch 1, loss: 0.017, 32/28000 datapoints
2025-03-06 22:51:26,431 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-06 22:51:26,600 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:51:26,783 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:51:26,950 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-06 22:51:27,125 - INFO - training batch 251, loss: 0.015, 8032/28000 datapoints
2025-03-06 22:51:27,298 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:51:27,466 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:51:27,631 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:51:27,798 - INFO - training batch 451, loss: 0.016, 14432/28000 datapoints
2025-03-06 22:51:27,967 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:51:28,175 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:51:28,347 - INFO - training batch 601, loss: 0.181, 19232/28000 datapoints
2025-03-06 22:51:28,519 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:51:28,690 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:51:28,857 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:51:29,030 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-06 22:51:29,192 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-06 22:51:29,276 - INFO - validation batch 1, loss: 0.203, 32/6976 datapoints
2025-03-06 22:51:29,324 - INFO - validation batch 51, loss: 5.372, 1632/6976 datapoints
2025-03-06 22:51:29,376 - INFO - validation batch 101, loss: 0.711, 3232/6976 datapoints
2025-03-06 22:51:29,428 - INFO - validation batch 151, loss: 1.371, 4832/6976 datapoints
2025-03-06 22:51:29,479 - INFO - validation batch 201, loss: 2.526, 6432/6976 datapoints
2025-03-06 22:51:29,496 - INFO - Epoch 505/800 done.
2025-03-06 22:51:29,496 - INFO - Final validation performance:
Loss: 2.037, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 22:51:29,497 - INFO - Beginning epoch 506/800
2025-03-06 22:51:29,501 - INFO - training batch 1, loss: 0.012, 32/28000 datapoints
2025-03-06 22:51:29,672 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-06 22:51:29,842 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 22:51:30,019 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:51:30,194 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:51:30,364 - INFO - training batch 251, loss: 0.027, 8032/28000 datapoints
2025-03-06 22:51:30,535 - INFO - training batch 301, loss: 0.024, 9632/28000 datapoints
2025-03-06 22:51:30,705 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:51:30,878 - INFO - training batch 401, loss: 0.018, 12832/28000 datapoints
2025-03-06 22:51:31,052 - INFO - training batch 451, loss: 0.117, 14432/28000 datapoints
2025-03-06 22:51:31,230 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 22:51:31,407 - INFO - training batch 551, loss: 0.038, 17632/28000 datapoints
2025-03-06 22:51:31,576 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:51:31,746 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:51:31,924 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:51:32,094 - INFO - training batch 751, loss: 0.069, 24032/28000 datapoints
2025-03-06 22:51:32,265 - INFO - training batch 801, loss: 0.017, 25632/28000 datapoints
2025-03-06 22:51:32,431 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:51:32,539 - INFO - validation batch 1, loss: 0.114, 32/6976 datapoints
2025-03-06 22:51:32,596 - INFO - validation batch 51, loss: 5.369, 1632/6976 datapoints
2025-03-06 22:51:32,645 - INFO - validation batch 101, loss: 0.715, 3232/6976 datapoints
2025-03-06 22:51:32,695 - INFO - validation batch 151, loss: 1.315, 4832/6976 datapoints
2025-03-06 22:51:32,744 - INFO - validation batch 201, loss: 2.645, 6432/6976 datapoints
2025-03-06 22:51:32,760 - INFO - Epoch 506/800 done.
2025-03-06 22:51:32,760 - INFO - Final validation performance:
Loss: 2.032, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:51:32,761 - INFO - Beginning epoch 507/800
2025-03-06 22:51:32,765 - INFO - training batch 1, loss: 0.029, 32/28000 datapoints
2025-03-06 22:51:32,937 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-06 22:51:33,109 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 22:51:33,281 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:51:33,451 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:51:33,621 - INFO - training batch 251, loss: 0.054, 8032/28000 datapoints
2025-03-06 22:51:33,796 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:51:33,967 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-06 22:51:34,133 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:51:34,302 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-06 22:51:34,470 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 22:51:34,639 - INFO - training batch 551, loss: 0.017, 17632/28000 datapoints
2025-03-06 22:51:34,809 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:51:34,980 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:51:35,153 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:51:35,327 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:51:35,497 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:51:35,663 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:51:35,751 - INFO - validation batch 1, loss: 0.182, 32/6976 datapoints
2025-03-06 22:51:35,803 - INFO - validation batch 51, loss: 5.434, 1632/6976 datapoints
2025-03-06 22:51:35,851 - INFO - validation batch 101, loss: 0.688, 3232/6976 datapoints
2025-03-06 22:51:35,898 - INFO - validation batch 151, loss: 1.244, 4832/6976 datapoints
2025-03-06 22:51:35,960 - INFO - validation batch 201, loss: 2.470, 6432/6976 datapoints
2025-03-06 22:51:35,981 - INFO - Epoch 507/800 done.
2025-03-06 22:51:35,981 - INFO - Final validation performance:
Loss: 2.004, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:51:35,982 - INFO - Beginning epoch 508/800
2025-03-06 22:51:35,987 - INFO - training batch 1, loss: 0.017, 32/28000 datapoints
2025-03-06 22:51:36,158 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:51:36,327 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 22:51:36,499 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:51:36,669 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:51:36,840 - INFO - training batch 251, loss: 0.021, 8032/28000 datapoints
2025-03-06 22:51:37,023 - INFO - training batch 301, loss: 0.015, 9632/28000 datapoints
2025-03-06 22:51:37,231 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-06 22:51:37,410 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:51:37,582 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-06 22:51:37,762 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:51:37,932 - INFO - training batch 551, loss: 0.025, 17632/28000 datapoints
2025-03-06 22:51:38,128 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:51:38,300 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:51:38,483 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-06 22:51:38,649 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:51:38,817 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:51:38,988 - INFO - training batch 851, loss: 0.016, 27232/28000 datapoints
2025-03-06 22:51:39,074 - INFO - validation batch 1, loss: 0.074, 32/6976 datapoints
2025-03-06 22:51:39,123 - INFO - validation batch 51, loss: 5.856, 1632/6976 datapoints
2025-03-06 22:51:39,173 - INFO - validation batch 101, loss: 0.704, 3232/6976 datapoints
2025-03-06 22:51:39,220 - INFO - validation batch 151, loss: 1.326, 4832/6976 datapoints
2025-03-06 22:51:39,268 - INFO - validation batch 201, loss: 2.622, 6432/6976 datapoints
2025-03-06 22:51:39,284 - INFO - Epoch 508/800 done.
2025-03-06 22:51:39,285 - INFO - Final validation performance:
Loss: 2.116, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 22:51:39,285 - INFO - Beginning epoch 509/800
2025-03-06 22:51:39,290 - INFO - training batch 1, loss: 0.034, 32/28000 datapoints
2025-03-06 22:51:39,464 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 22:51:39,635 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-06 22:51:39,812 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:51:39,984 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 22:51:40,177 - INFO - training batch 251, loss: 0.027, 8032/28000 datapoints
2025-03-06 22:51:40,356 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-06 22:51:40,525 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-06 22:51:40,694 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:51:40,870 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-06 22:51:41,042 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 22:51:41,208 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 22:51:41,373 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:51:41,542 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:51:41,716 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-06 22:51:41,885 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:51:42,064 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:51:42,238 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:51:42,336 - INFO - validation batch 1, loss: 0.161, 32/6976 datapoints
2025-03-06 22:51:42,389 - INFO - validation batch 51, loss: 5.553, 1632/6976 datapoints
2025-03-06 22:51:42,436 - INFO - validation batch 101, loss: 0.750, 3232/6976 datapoints
2025-03-06 22:51:42,484 - INFO - validation batch 151, loss: 1.262, 4832/6976 datapoints
2025-03-06 22:51:42,531 - INFO - validation batch 201, loss: 2.497, 6432/6976 datapoints
2025-03-06 22:51:42,549 - INFO - Epoch 509/800 done.
2025-03-06 22:51:42,549 - INFO - Final validation performance:
Loss: 2.045, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:51:42,550 - INFO - Beginning epoch 510/800
2025-03-06 22:51:42,554 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 22:51:42,753 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:51:42,925 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 22:51:43,100 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:51:43,276 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 22:51:43,452 - INFO - training batch 251, loss: 0.022, 8032/28000 datapoints
2025-03-06 22:51:43,624 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-06 22:51:43,801 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:51:43,978 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:51:44,147 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-06 22:51:44,331 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-06 22:51:44,501 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-06 22:51:44,672 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:51:44,851 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:51:45,027 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:51:45,198 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:51:45,377 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:51:45,549 - INFO - training batch 851, loss: 0.013, 27232/28000 datapoints
2025-03-06 22:51:45,637 - INFO - validation batch 1, loss: 0.247, 32/6976 datapoints
2025-03-06 22:51:45,694 - INFO - validation batch 51, loss: 5.663, 1632/6976 datapoints
2025-03-06 22:51:45,747 - INFO - validation batch 101, loss: 0.777, 3232/6976 datapoints
2025-03-06 22:51:45,801 - INFO - validation batch 151, loss: 1.289, 4832/6976 datapoints
2025-03-06 22:51:45,855 - INFO - validation batch 201, loss: 2.451, 6432/6976 datapoints
2025-03-06 22:51:45,876 - INFO - Epoch 510/800 done.
2025-03-06 22:51:45,876 - INFO - Final validation performance:
Loss: 2.086, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:51:45,877 - INFO - Beginning epoch 511/800
2025-03-06 22:51:45,881 - INFO - training batch 1, loss: 0.013, 32/28000 datapoints
2025-03-06 22:51:46,062 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:51:46,235 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 22:51:46,410 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:51:46,583 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-06 22:51:46,756 - INFO - training batch 251, loss: 0.024, 8032/28000 datapoints
2025-03-06 22:51:46,936 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:51:47,110 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:51:47,282 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:51:47,456 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-06 22:51:47,630 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:51:47,802 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 22:51:47,975 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:51:48,147 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:51:48,324 - INFO - training batch 701, loss: 0.010, 22432/28000 datapoints
2025-03-06 22:51:48,495 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:51:48,667 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:51:48,837 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:51:48,931 - INFO - validation batch 1, loss: 0.209, 32/6976 datapoints
2025-03-06 22:51:48,989 - INFO - validation batch 51, loss: 5.606, 1632/6976 datapoints
2025-03-06 22:51:49,042 - INFO - validation batch 101, loss: 0.789, 3232/6976 datapoints
2025-03-06 22:51:49,094 - INFO - validation batch 151, loss: 1.320, 4832/6976 datapoints
2025-03-06 22:51:49,146 - INFO - validation batch 201, loss: 2.460, 6432/6976 datapoints
2025-03-06 22:51:49,165 - INFO - Epoch 511/800 done.
2025-03-06 22:51:49,165 - INFO - Final validation performance:
Loss: 2.077, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:51:49,166 - INFO - Beginning epoch 512/800
2025-03-06 22:51:49,171 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-06 22:51:49,351 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-06 22:51:49,523 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 22:51:49,711 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:51:49,884 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:51:50,064 - INFO - training batch 251, loss: 0.017, 8032/28000 datapoints
2025-03-06 22:51:50,246 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-06 22:51:50,425 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:51:50,596 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:51:50,770 - INFO - training batch 451, loss: 0.013, 14432/28000 datapoints
2025-03-06 22:51:50,948 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:51:51,129 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-06 22:51:51,302 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:51:51,474 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:51:51,648 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:51:51,822 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:51:51,998 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:51:52,167 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:51:52,256 - INFO - validation batch 1, loss: 0.232, 32/6976 datapoints
2025-03-06 22:51:52,309 - INFO - validation batch 51, loss: 5.560, 1632/6976 datapoints
2025-03-06 22:51:52,363 - INFO - validation batch 101, loss: 0.729, 3232/6976 datapoints
2025-03-06 22:51:52,415 - INFO - validation batch 151, loss: 1.306, 4832/6976 datapoints
2025-03-06 22:51:52,466 - INFO - validation batch 201, loss: 2.441, 6432/6976 datapoints
2025-03-06 22:51:52,483 - INFO - Epoch 512/800 done.
2025-03-06 22:51:52,483 - INFO - Final validation performance:
Loss: 2.054, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:51:52,484 - INFO - Beginning epoch 513/800
2025-03-06 22:51:52,488 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 22:51:52,659 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:51:52,856 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 22:51:53,031 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 22:51:53,197 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:51:53,366 - INFO - training batch 251, loss: 0.027, 8032/28000 datapoints
2025-03-06 22:51:53,539 - INFO - training batch 301, loss: 0.103, 9632/28000 datapoints
2025-03-06 22:51:53,711 - INFO - training batch 351, loss: 0.034, 11232/28000 datapoints
2025-03-06 22:51:53,883 - INFO - training batch 401, loss: 0.052, 12832/28000 datapoints
2025-03-06 22:51:54,059 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-06 22:51:54,227 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-06 22:51:54,395 - INFO - training batch 551, loss: 0.023, 17632/28000 datapoints
2025-03-06 22:51:54,560 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:51:54,729 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:51:54,902 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-06 22:51:55,072 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-06 22:51:55,241 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:51:55,413 - INFO - training batch 851, loss: 0.045, 27232/28000 datapoints
2025-03-06 22:51:55,499 - INFO - validation batch 1, loss: 0.215, 32/6976 datapoints
2025-03-06 22:51:55,547 - INFO - validation batch 51, loss: 5.529, 1632/6976 datapoints
2025-03-06 22:51:55,594 - INFO - validation batch 101, loss: 0.705, 3232/6976 datapoints
2025-03-06 22:51:55,642 - INFO - validation batch 151, loss: 1.375, 4832/6976 datapoints
2025-03-06 22:51:55,694 - INFO - validation batch 201, loss: 2.664, 6432/6976 datapoints
2025-03-06 22:51:55,711 - INFO - Epoch 513/800 done.
2025-03-06 22:51:55,712 - INFO - Final validation performance:
Loss: 2.097, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:51:55,712 - INFO - Beginning epoch 514/800
2025-03-06 22:51:55,717 - INFO - training batch 1, loss: 0.027, 32/28000 datapoints
2025-03-06 22:51:55,905 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:51:56,076 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:51:56,255 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-06 22:51:56,428 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 22:51:56,596 - INFO - training batch 251, loss: 0.032, 8032/28000 datapoints
2025-03-06 22:51:56,773 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:51:56,947 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:51:57,117 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:51:57,292 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-06 22:51:57,464 - INFO - training batch 501, loss: 0.018, 16032/28000 datapoints
2025-03-06 22:51:57,633 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-06 22:51:57,800 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:51:57,972 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:51:58,144 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-06 22:51:58,310 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:51:58,483 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:51:58,650 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:51:58,736 - INFO - validation batch 1, loss: 0.197, 32/6976 datapoints
2025-03-06 22:51:58,784 - INFO - validation batch 51, loss: 5.445, 1632/6976 datapoints
2025-03-06 22:51:58,832 - INFO - validation batch 101, loss: 0.776, 3232/6976 datapoints
2025-03-06 22:51:58,883 - INFO - validation batch 151, loss: 1.332, 4832/6976 datapoints
2025-03-06 22:51:58,934 - INFO - validation batch 201, loss: 2.570, 6432/6976 datapoints
2025-03-06 22:51:58,951 - INFO - Epoch 514/800 done.
2025-03-06 22:51:58,951 - INFO - Final validation performance:
Loss: 2.064, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:51:58,952 - INFO - Beginning epoch 515/800
2025-03-06 22:51:58,956 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-06 22:51:59,127 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:51:59,297 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:51:59,475 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:51:59,644 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-06 22:51:59,813 - INFO - training batch 251, loss: 0.026, 8032/28000 datapoints
2025-03-06 22:51:59,990 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-06 22:52:00,159 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:52:00,326 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:52:00,499 - INFO - training batch 451, loss: 0.016, 14432/28000 datapoints
2025-03-06 22:52:00,668 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 22:52:00,836 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 22:52:01,008 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:52:01,176 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:52:01,351 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:52:01,520 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:52:01,689 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:52:01,857 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:52:01,945 - INFO - validation batch 1, loss: 0.208, 32/6976 datapoints
2025-03-06 22:52:02,000 - INFO - validation batch 51, loss: 5.518, 1632/6976 datapoints
2025-03-06 22:52:02,056 - INFO - validation batch 101, loss: 0.764, 3232/6976 datapoints
2025-03-06 22:52:02,110 - INFO - validation batch 151, loss: 1.341, 4832/6976 datapoints
2025-03-06 22:52:02,158 - INFO - validation batch 201, loss: 2.553, 6432/6976 datapoints
2025-03-06 22:52:02,174 - INFO - Epoch 515/800 done.
2025-03-06 22:52:02,175 - INFO - Final validation performance:
Loss: 2.077, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:52:02,175 - INFO - Beginning epoch 516/800
2025-03-06 22:52:02,180 - INFO - training batch 1, loss: 0.012, 32/28000 datapoints
2025-03-06 22:52:02,350 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:52:02,529 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-06 22:52:02,702 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:52:02,898 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:52:03,074 - INFO - training batch 251, loss: 0.016, 8032/28000 datapoints
2025-03-06 22:52:03,245 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-06 22:52:03,416 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:52:03,584 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:52:03,754 - INFO - training batch 451, loss: 0.014, 14432/28000 datapoints
2025-03-06 22:52:03,929 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:52:04,101 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-06 22:52:04,268 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:52:04,440 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:52:04,611 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:52:04,782 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:52:04,963 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:52:05,133 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:52:05,222 - INFO - validation batch 1, loss: 0.211, 32/6976 datapoints
2025-03-06 22:52:05,280 - INFO - validation batch 51, loss: 5.533, 1632/6976 datapoints
2025-03-06 22:52:05,332 - INFO - validation batch 101, loss: 0.727, 3232/6976 datapoints
2025-03-06 22:52:05,381 - INFO - validation batch 151, loss: 1.388, 4832/6976 datapoints
2025-03-06 22:52:05,434 - INFO - validation batch 201, loss: 2.537, 6432/6976 datapoints
2025-03-06 22:52:05,456 - INFO - Epoch 516/800 done.
2025-03-06 22:52:05,456 - INFO - Final validation performance:
Loss: 2.079, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:52:05,457 - INFO - Beginning epoch 517/800
2025-03-06 22:52:05,462 - INFO - training batch 1, loss: 0.013, 32/28000 datapoints
2025-03-06 22:52:05,641 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:52:05,822 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-06 22:52:06,008 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:52:06,180 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:52:06,352 - INFO - training batch 251, loss: 0.012, 8032/28000 datapoints
2025-03-06 22:52:06,528 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:52:06,700 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:52:06,871 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:52:07,066 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-06 22:52:07,267 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:52:07,472 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-06 22:52:07,644 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:52:07,818 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:52:07,996 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:52:08,168 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:52:08,344 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:52:08,515 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-06 22:52:08,604 - INFO - validation batch 1, loss: 0.196, 32/6976 datapoints
2025-03-06 22:52:08,655 - INFO - validation batch 51, loss: 5.581, 1632/6976 datapoints
2025-03-06 22:52:08,708 - INFO - validation batch 101, loss: 0.671, 3232/6976 datapoints
2025-03-06 22:52:08,761 - INFO - validation batch 151, loss: 1.482, 4832/6976 datapoints
2025-03-06 22:52:08,812 - INFO - validation batch 201, loss: 2.526, 6432/6976 datapoints
2025-03-06 22:52:08,829 - INFO - Epoch 517/800 done.
2025-03-06 22:52:08,829 - INFO - Final validation performance:
Loss: 2.091, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:52:08,830 - INFO - Beginning epoch 518/800
2025-03-06 22:52:08,835 - INFO - training batch 1, loss: 0.016, 32/28000 datapoints
2025-03-06 22:52:09,014 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:52:09,187 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-06 22:52:09,367 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:52:09,538 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-06 22:52:09,704 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-06 22:52:09,875 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-06 22:52:10,048 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:52:10,216 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:52:10,388 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-06 22:52:10,558 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:52:10,725 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-06 22:52:10,892 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:52:11,068 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:52:11,237 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:52:11,405 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:52:11,575 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:52:11,741 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:52:11,827 - INFO - validation batch 1, loss: 0.209, 32/6976 datapoints
2025-03-06 22:52:11,876 - INFO - validation batch 51, loss: 5.583, 1632/6976 datapoints
2025-03-06 22:52:11,925 - INFO - validation batch 101, loss: 0.633, 3232/6976 datapoints
2025-03-06 22:52:11,975 - INFO - validation batch 151, loss: 1.456, 4832/6976 datapoints
2025-03-06 22:52:12,022 - INFO - validation batch 201, loss: 2.537, 6432/6976 datapoints
2025-03-06 22:52:12,041 - INFO - Epoch 518/800 done.
2025-03-06 22:52:12,041 - INFO - Final validation performance:
Loss: 2.084, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:52:12,042 - INFO - Beginning epoch 519/800
2025-03-06 22:52:12,046 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-06 22:52:12,217 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 22:52:12,392 - INFO - training batch 101, loss: 0.114, 3232/28000 datapoints
2025-03-06 22:52:12,561 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 22:52:12,731 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-06 22:52:12,919 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-06 22:52:13,107 - INFO - training batch 301, loss: 0.104, 9632/28000 datapoints
2025-03-06 22:52:13,280 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:52:13,446 - INFO - training batch 401, loss: 0.033, 12832/28000 datapoints
2025-03-06 22:52:13,619 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:52:13,788 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:52:13,961 - INFO - training batch 551, loss: 0.024, 17632/28000 datapoints
2025-03-06 22:52:14,134 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:52:14,302 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:52:14,477 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:52:14,644 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:52:14,812 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 22:52:14,982 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:52:15,068 - INFO - validation batch 1, loss: 0.201, 32/6976 datapoints
2025-03-06 22:52:15,116 - INFO - validation batch 51, loss: 5.457, 1632/6976 datapoints
2025-03-06 22:52:15,164 - INFO - validation batch 101, loss: 0.801, 3232/6976 datapoints
2025-03-06 22:52:15,212 - INFO - validation batch 151, loss: 1.509, 4832/6976 datapoints
2025-03-06 22:52:15,266 - INFO - validation batch 201, loss: 2.695, 6432/6976 datapoints
2025-03-06 22:52:15,283 - INFO - Epoch 519/800 done.
2025-03-06 22:52:15,283 - INFO - Final validation performance:
Loss: 2.133, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 22:52:15,283 - INFO - Beginning epoch 520/800
2025-03-06 22:52:15,288 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-06 22:52:15,460 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:52:15,633 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:52:15,806 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:52:15,977 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 22:52:16,147 - INFO - training batch 251, loss: 0.021, 8032/28000 datapoints
2025-03-06 22:52:16,325 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-06 22:52:16,498 - INFO - training batch 351, loss: 0.010, 11232/28000 datapoints
2025-03-06 22:52:16,667 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:52:16,842 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:52:17,016 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:52:17,185 - INFO - training batch 551, loss: 0.026, 17632/28000 datapoints
2025-03-06 22:52:17,353 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:52:17,521 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:52:17,697 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:52:17,864 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 22:52:18,039 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:52:18,214 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:52:18,299 - INFO - validation batch 1, loss: 0.169, 32/6976 datapoints
2025-03-06 22:52:18,347 - INFO - validation batch 51, loss: 5.667, 1632/6976 datapoints
2025-03-06 22:52:18,394 - INFO - validation batch 101, loss: 0.695, 3232/6976 datapoints
2025-03-06 22:52:18,442 - INFO - validation batch 151, loss: 1.696, 4832/6976 datapoints
2025-03-06 22:52:18,489 - INFO - validation batch 201, loss: 2.621, 6432/6976 datapoints
2025-03-06 22:52:18,506 - INFO - Epoch 520/800 done.
2025-03-06 22:52:18,506 - INFO - Final validation performance:
Loss: 2.170, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:52:18,506 - INFO - Beginning epoch 521/800
2025-03-06 22:52:18,511 - INFO - training batch 1, loss: 0.030, 32/28000 datapoints
2025-03-06 22:52:18,687 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 22:52:18,858 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-06 22:52:19,035 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:52:19,214 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 22:52:19,383 - INFO - training batch 251, loss: 0.019, 8032/28000 datapoints
2025-03-06 22:52:19,557 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-06 22:52:19,727 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-06 22:52:19,892 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:52:20,067 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:52:20,238 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:52:20,407 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 22:52:20,590 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:52:20,759 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:52:20,933 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:52:21,115 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:52:21,286 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:52:21,454 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:52:21,541 - INFO - validation batch 1, loss: 0.240, 32/6976 datapoints
2025-03-06 22:52:21,590 - INFO - validation batch 51, loss: 5.604, 1632/6976 datapoints
2025-03-06 22:52:21,639 - INFO - validation batch 101, loss: 0.875, 3232/6976 datapoints
2025-03-06 22:52:21,687 - INFO - validation batch 151, loss: 1.448, 4832/6976 datapoints
2025-03-06 22:52:21,735 - INFO - validation batch 201, loss: 2.662, 6432/6976 datapoints
2025-03-06 22:52:21,751 - INFO - Epoch 521/800 done.
2025-03-06 22:52:21,752 - INFO - Final validation performance:
Loss: 2.166, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:52:21,752 - INFO - Beginning epoch 522/800
2025-03-06 22:52:21,756 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 22:52:21,932 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:52:22,104 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:52:22,279 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:52:22,448 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:52:22,620 - INFO - training batch 251, loss: 0.017, 8032/28000 datapoints
2025-03-06 22:52:22,791 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:52:22,963 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-06 22:52:23,164 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:52:23,337 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-06 22:52:23,506 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:52:23,678 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-06 22:52:23,844 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:52:24,023 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:52:24,197 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:52:24,365 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:52:24,535 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:52:24,703 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:52:24,789 - INFO - validation batch 1, loss: 0.243, 32/6976 datapoints
2025-03-06 22:52:24,840 - INFO - validation batch 51, loss: 5.598, 1632/6976 datapoints
2025-03-06 22:52:24,895 - INFO - validation batch 101, loss: 0.825, 3232/6976 datapoints
2025-03-06 22:52:24,948 - INFO - validation batch 151, loss: 1.452, 4832/6976 datapoints
2025-03-06 22:52:25,002 - INFO - validation batch 201, loss: 2.645, 6432/6976 datapoints
2025-03-06 22:52:25,021 - INFO - Epoch 522/800 done.
2025-03-06 22:52:25,021 - INFO - Final validation performance:
Loss: 2.152, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:52:25,022 - INFO - Beginning epoch 523/800
2025-03-06 22:52:25,026 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-06 22:52:25,211 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:52:25,391 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:52:25,567 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:52:25,744 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:52:25,918 - INFO - training batch 251, loss: 0.014, 8032/28000 datapoints
2025-03-06 22:52:26,097 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-06 22:52:26,272 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:52:26,445 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:52:26,631 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:52:26,811 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:52:26,986 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:52:27,166 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:52:27,341 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:52:27,521 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:52:27,700 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:52:27,871 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:52:28,044 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:52:28,136 - INFO - validation batch 1, loss: 0.244, 32/6976 datapoints
2025-03-06 22:52:28,187 - INFO - validation batch 51, loss: 5.624, 1632/6976 datapoints
2025-03-06 22:52:28,242 - INFO - validation batch 101, loss: 0.796, 3232/6976 datapoints
2025-03-06 22:52:28,296 - INFO - validation batch 151, loss: 1.461, 4832/6976 datapoints
2025-03-06 22:52:28,347 - INFO - validation batch 201, loss: 2.637, 6432/6976 datapoints
2025-03-06 22:52:28,368 - INFO - Epoch 523/800 done.
2025-03-06 22:52:28,369 - INFO - Final validation performance:
Loss: 2.153, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:52:28,369 - INFO - Beginning epoch 524/800
2025-03-06 22:52:28,374 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-06 22:52:28,553 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:52:28,732 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:52:28,907 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:52:29,090 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:52:29,266 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:52:29,438 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:52:29,612 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:52:29,784 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:52:29,963 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-06 22:52:30,138 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:52:30,316 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:52:30,487 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:52:30,662 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:52:30,840 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:52:31,016 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:52:31,189 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:52:31,360 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:52:31,449 - INFO - validation batch 1, loss: 0.231, 32/6976 datapoints
2025-03-06 22:52:31,502 - INFO - validation batch 51, loss: 5.610, 1632/6976 datapoints
2025-03-06 22:52:31,555 - INFO - validation batch 101, loss: 0.741, 3232/6976 datapoints
2025-03-06 22:52:31,607 - INFO - validation batch 151, loss: 1.525, 4832/6976 datapoints
2025-03-06 22:52:31,662 - INFO - validation batch 201, loss: 2.620, 6432/6976 datapoints
2025-03-06 22:52:31,681 - INFO - Epoch 524/800 done.
2025-03-06 22:52:31,681 - INFO - Final validation performance:
Loss: 2.145, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:52:31,682 - INFO - Beginning epoch 525/800
2025-03-06 22:52:31,687 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 22:52:31,865 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:52:32,045 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:52:32,221 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:52:32,397 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-06 22:52:32,570 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:52:32,760 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:52:32,937 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-06 22:52:33,127 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 22:52:33,318 - INFO - training batch 451, loss: 0.020, 14432/28000 datapoints
2025-03-06 22:52:33,493 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:52:33,667 - INFO - training batch 551, loss: 0.020, 17632/28000 datapoints
2025-03-06 22:52:33,837 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:52:34,018 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:52:34,193 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:52:34,366 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:52:34,539 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-06 22:52:34,708 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:52:34,798 - INFO - validation batch 1, loss: 0.269, 32/6976 datapoints
2025-03-06 22:52:34,851 - INFO - validation batch 51, loss: 5.878, 1632/6976 datapoints
2025-03-06 22:52:34,903 - INFO - validation batch 101, loss: 0.757, 3232/6976 datapoints
2025-03-06 22:52:34,955 - INFO - validation batch 151, loss: 1.299, 4832/6976 datapoints
2025-03-06 22:52:35,010 - INFO - validation batch 201, loss: 2.553, 6432/6976 datapoints
2025-03-06 22:52:35,030 - INFO - Epoch 525/800 done.
2025-03-06 22:52:35,030 - INFO - Final validation performance:
Loss: 2.151, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:52:35,030 - INFO - Beginning epoch 526/800
2025-03-06 22:52:35,035 - INFO - training batch 1, loss: 0.017, 32/28000 datapoints
2025-03-06 22:52:35,218 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:52:35,403 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:52:35,577 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:52:35,755 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 22:52:35,931 - INFO - training batch 251, loss: 0.038, 8032/28000 datapoints
2025-03-06 22:52:36,111 - INFO - training batch 301, loss: 0.035, 9632/28000 datapoints
2025-03-06 22:52:36,288 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:52:36,482 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 22:52:36,660 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-06 22:52:36,834 - INFO - training batch 501, loss: 0.025, 16032/28000 datapoints
2025-03-06 22:52:37,008 - INFO - training batch 551, loss: 0.049, 17632/28000 datapoints
2025-03-06 22:52:37,182 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:52:37,356 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:52:37,571 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:52:37,746 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:52:37,919 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:52:38,108 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:52:38,216 - INFO - validation batch 1, loss: 0.245, 32/6976 datapoints
2025-03-06 22:52:38,268 - INFO - validation batch 51, loss: 5.778, 1632/6976 datapoints
2025-03-06 22:52:38,321 - INFO - validation batch 101, loss: 0.688, 3232/6976 datapoints
2025-03-06 22:52:38,374 - INFO - validation batch 151, loss: 1.469, 4832/6976 datapoints
2025-03-06 22:52:38,428 - INFO - validation batch 201, loss: 2.741, 6432/6976 datapoints
2025-03-06 22:52:38,445 - INFO - Epoch 526/800 done.
2025-03-06 22:52:38,445 - INFO - Final validation performance:
Loss: 2.184, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:52:38,446 - INFO - Beginning epoch 527/800
2025-03-06 22:52:38,450 - INFO - training batch 1, loss: 0.023, 32/28000 datapoints
2025-03-06 22:52:38,628 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:52:38,820 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:52:39,001 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:52:39,185 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:52:39,365 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-06 22:52:39,560 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:52:39,739 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:52:39,912 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-06 22:52:40,093 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-06 22:52:40,270 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 22:52:40,444 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-06 22:52:40,619 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:52:40,792 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:52:40,966 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:52:41,146 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:52:41,315 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:52:41,486 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:52:41,576 - INFO - validation batch 1, loss: 0.262, 32/6976 datapoints
2025-03-06 22:52:41,627 - INFO - validation batch 51, loss: 5.674, 1632/6976 datapoints
2025-03-06 22:52:41,681 - INFO - validation batch 101, loss: 0.712, 3232/6976 datapoints
2025-03-06 22:52:41,734 - INFO - validation batch 151, loss: 1.525, 4832/6976 datapoints
2025-03-06 22:52:41,785 - INFO - validation batch 201, loss: 2.763, 6432/6976 datapoints
2025-03-06 22:52:41,801 - INFO - Epoch 527/800 done.
2025-03-06 22:52:41,801 - INFO - Final validation performance:
Loss: 2.187, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:52:41,802 - INFO - Beginning epoch 528/800
2025-03-06 22:52:41,807 - INFO - training batch 1, loss: 0.016, 32/28000 datapoints
2025-03-06 22:52:41,988 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:52:42,165 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:52:42,339 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:52:42,515 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:52:42,690 - INFO - training batch 251, loss: 0.016, 8032/28000 datapoints
2025-03-06 22:52:42,866 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:52:43,047 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:52:43,230 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:52:43,428 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:52:43,601 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:52:43,775 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-06 22:52:43,949 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:52:44,128 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:52:44,304 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:52:44,478 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:52:44,648 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:52:44,816 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:52:44,911 - INFO - validation batch 1, loss: 0.091, 32/6976 datapoints
2025-03-06 22:52:44,980 - INFO - validation batch 51, loss: 5.586, 1632/6976 datapoints
2025-03-06 22:52:45,034 - INFO - validation batch 101, loss: 0.731, 3232/6976 datapoints
2025-03-06 22:52:45,086 - INFO - validation batch 151, loss: 1.856, 4832/6976 datapoints
2025-03-06 22:52:45,142 - INFO - validation batch 201, loss: 2.694, 6432/6976 datapoints
2025-03-06 22:52:45,160 - INFO - Epoch 528/800 done.
2025-03-06 22:52:45,160 - INFO - Final validation performance:
Loss: 2.192, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:52:45,161 - INFO - Beginning epoch 529/800
2025-03-06 22:52:45,166 - INFO - training batch 1, loss: 0.042, 32/28000 datapoints
2025-03-06 22:52:45,346 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:52:45,523 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:52:45,696 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:52:45,867 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:52:46,042 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-06 22:52:46,213 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:52:46,387 - INFO - training batch 351, loss: 0.013, 11232/28000 datapoints
2025-03-06 22:52:46,557 - INFO - training batch 401, loss: 0.015, 12832/28000 datapoints
2025-03-06 22:52:46,733 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-06 22:52:46,904 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:52:47,075 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:52:47,248 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:52:47,419 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:52:47,593 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:52:47,762 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:52:47,932 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:52:48,102 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:52:48,189 - INFO - validation batch 1, loss: 0.206, 32/6976 datapoints
2025-03-06 22:52:48,238 - INFO - validation batch 51, loss: 5.757, 1632/6976 datapoints
2025-03-06 22:52:48,286 - INFO - validation batch 101, loss: 0.761, 3232/6976 datapoints
2025-03-06 22:52:48,333 - INFO - validation batch 151, loss: 1.451, 4832/6976 datapoints
2025-03-06 22:52:48,381 - INFO - validation batch 201, loss: 2.729, 6432/6976 datapoints
2025-03-06 22:52:48,397 - INFO - Epoch 529/800 done.
2025-03-06 22:52:48,397 - INFO - Final validation performance:
Loss: 2.181, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:52:48,397 - INFO - Beginning epoch 530/800
2025-03-06 22:52:48,402 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-06 22:52:48,577 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:52:48,751 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:52:48,920 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:52:49,092 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:52:49,266 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-06 22:52:49,440 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-06 22:52:49,617 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:52:49,787 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:52:49,961 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:52:50,135 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 22:52:50,303 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-06 22:52:50,482 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:52:50,653 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:52:50,823 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:52:50,996 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:52:51,187 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:52:51,357 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:52:51,443 - INFO - validation batch 1, loss: 0.215, 32/6976 datapoints
2025-03-06 22:52:51,491 - INFO - validation batch 51, loss: 5.822, 1632/6976 datapoints
2025-03-06 22:52:51,542 - INFO - validation batch 101, loss: 0.800, 3232/6976 datapoints
2025-03-06 22:52:51,589 - INFO - validation batch 151, loss: 1.429, 4832/6976 datapoints
2025-03-06 22:52:51,644 - INFO - validation batch 201, loss: 2.724, 6432/6976 datapoints
2025-03-06 22:52:51,662 - INFO - Epoch 530/800 done.
2025-03-06 22:52:51,662 - INFO - Final validation performance:
Loss: 2.198, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:52:51,663 - INFO - Beginning epoch 531/800
2025-03-06 22:52:51,667 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-06 22:52:51,846 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:52:52,026 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:52:52,199 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:52:52,369 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-06 22:52:52,541 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-06 22:52:52,710 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:52:52,885 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:52:53,058 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:52:53,242 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-06 22:52:53,443 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:52:53,616 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:52:53,784 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:52:53,956 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:52:54,137 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:52:54,308 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:52:54,479 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:52:54,646 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:52:54,733 - INFO - validation batch 1, loss: 0.219, 32/6976 datapoints
2025-03-06 22:52:54,781 - INFO - validation batch 51, loss: 5.833, 1632/6976 datapoints
2025-03-06 22:52:54,828 - INFO - validation batch 101, loss: 0.791, 3232/6976 datapoints
2025-03-06 22:52:54,876 - INFO - validation batch 151, loss: 1.441, 4832/6976 datapoints
2025-03-06 22:52:54,923 - INFO - validation batch 201, loss: 2.731, 6432/6976 datapoints
2025-03-06 22:52:54,940 - INFO - Epoch 531/800 done.
2025-03-06 22:52:54,940 - INFO - Final validation performance:
Loss: 2.203, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:52:54,940 - INFO - Beginning epoch 532/800
2025-03-06 22:52:54,945 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-06 22:52:55,123 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:52:55,305 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:52:55,476 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:52:55,649 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-06 22:52:55,823 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:52:55,998 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-06 22:52:56,174 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:52:56,344 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:52:56,520 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:52:56,690 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:52:56,859 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:52:57,028 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:52:57,202 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:52:57,386 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:52:57,558 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:52:57,729 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:52:57,905 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:52:57,998 - INFO - validation batch 1, loss: 0.191, 32/6976 datapoints
2025-03-06 22:52:58,045 - INFO - validation batch 51, loss: 5.810, 1632/6976 datapoints
2025-03-06 22:52:58,094 - INFO - validation batch 101, loss: 0.747, 3232/6976 datapoints
2025-03-06 22:52:58,142 - INFO - validation batch 151, loss: 1.563, 4832/6976 datapoints
2025-03-06 22:52:58,192 - INFO - validation batch 201, loss: 2.723, 6432/6976 datapoints
2025-03-06 22:52:58,214 - INFO - Epoch 532/800 done.
2025-03-06 22:52:58,214 - INFO - Final validation performance:
Loss: 2.207, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:52:58,215 - INFO - Beginning epoch 533/800
2025-03-06 22:52:58,219 - INFO - training batch 1, loss: 0.011, 32/28000 datapoints
2025-03-06 22:52:58,394 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:52:58,573 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:52:58,749 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:52:58,924 - INFO - training batch 201, loss: 0.144, 6432/28000 datapoints
2025-03-06 22:52:59,098 - INFO - training batch 251, loss: 0.024, 8032/28000 datapoints
2025-03-06 22:52:59,271 - INFO - training batch 301, loss: 0.085, 9632/28000 datapoints
2025-03-06 22:52:59,446 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:52:59,616 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-06 22:52:59,789 - INFO - training batch 451, loss: 0.074, 14432/28000 datapoints
2025-03-06 22:52:59,959 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:53:00,133 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 22:53:00,301 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:53:00,471 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:53:00,643 - INFO - training batch 701, loss: 0.011, 22432/28000 datapoints
2025-03-06 22:53:00,814 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:53:00,988 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:53:01,159 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:53:01,249 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 22:53:01,296 - INFO - validation batch 51, loss: 5.822, 1632/6976 datapoints
2025-03-06 22:53:01,345 - INFO - validation batch 101, loss: 0.807, 3232/6976 datapoints
2025-03-06 22:53:01,392 - INFO - validation batch 151, loss: 1.508, 4832/6976 datapoints
2025-03-06 22:53:01,440 - INFO - validation batch 201, loss: 2.756, 6432/6976 datapoints
2025-03-06 22:53:01,456 - INFO - Epoch 533/800 done.
2025-03-06 22:53:01,456 - INFO - Final validation performance:
Loss: 2.205, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:53:01,457 - INFO - Beginning epoch 534/800
2025-03-06 22:53:01,461 - INFO - training batch 1, loss: 0.011, 32/28000 datapoints
2025-03-06 22:53:01,637 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:53:01,813 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:53:01,988 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:53:02,159 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:53:02,330 - INFO - training batch 251, loss: 0.014, 8032/28000 datapoints
2025-03-06 22:53:02,500 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:53:02,679 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:53:02,847 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-06 22:53:03,025 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:53:03,198 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 22:53:03,367 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 22:53:03,576 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:53:03,749 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:53:03,924 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:53:04,110 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 22:53:04,284 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:53:04,453 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:53:04,543 - INFO - validation batch 1, loss: 0.234, 32/6976 datapoints
2025-03-06 22:53:04,591 - INFO - validation batch 51, loss: 5.925, 1632/6976 datapoints
2025-03-06 22:53:04,641 - INFO - validation batch 101, loss: 0.803, 3232/6976 datapoints
2025-03-06 22:53:04,688 - INFO - validation batch 151, loss: 1.265, 4832/6976 datapoints
2025-03-06 22:53:04,736 - INFO - validation batch 201, loss: 2.747, 6432/6976 datapoints
2025-03-06 22:53:04,752 - INFO - Epoch 534/800 done.
2025-03-06 22:53:04,752 - INFO - Final validation performance:
Loss: 2.195, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:53:04,753 - INFO - Beginning epoch 535/800
2025-03-06 22:53:04,757 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 22:53:04,929 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:53:05,116 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:53:05,308 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:53:05,483 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-06 22:53:05,661 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-06 22:53:05,836 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:53:06,023 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:53:06,201 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:53:06,382 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:53:06,558 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:53:06,805 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-06 22:53:06,979 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:53:07,156 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:53:07,335 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:53:07,509 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:53:07,683 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:53:07,855 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:53:07,944 - INFO - validation batch 1, loss: 0.230, 32/6976 datapoints
2025-03-06 22:53:07,999 - INFO - validation batch 51, loss: 5.861, 1632/6976 datapoints
2025-03-06 22:53:08,052 - INFO - validation batch 101, loss: 0.826, 3232/6976 datapoints
2025-03-06 22:53:08,106 - INFO - validation batch 151, loss: 1.487, 4832/6976 datapoints
2025-03-06 22:53:08,155 - INFO - validation batch 201, loss: 2.842, 6432/6976 datapoints
2025-03-06 22:53:08,172 - INFO - Epoch 535/800 done.
2025-03-06 22:53:08,172 - INFO - Final validation performance:
Loss: 2.249, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:53:08,172 - INFO - Beginning epoch 536/800
2025-03-06 22:53:08,177 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 22:53:08,354 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:53:08,530 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:53:08,701 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:53:08,874 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:53:09,048 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-06 22:53:09,219 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:53:09,398 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:53:09,590 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:53:09,771 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:53:09,940 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:53:10,118 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:53:10,292 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:53:10,468 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:53:10,644 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:53:10,815 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:53:10,990 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:53:11,162 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:53:11,251 - INFO - validation batch 1, loss: 0.223, 32/6976 datapoints
2025-03-06 22:53:11,300 - INFO - validation batch 51, loss: 5.877, 1632/6976 datapoints
2025-03-06 22:53:11,347 - INFO - validation batch 101, loss: 0.814, 3232/6976 datapoints
2025-03-06 22:53:11,396 - INFO - validation batch 151, loss: 1.501, 4832/6976 datapoints
2025-03-06 22:53:11,444 - INFO - validation batch 201, loss: 2.814, 6432/6976 datapoints
2025-03-06 22:53:11,460 - INFO - Epoch 536/800 done.
2025-03-06 22:53:11,460 - INFO - Final validation performance:
Loss: 2.246, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:53:11,461 - INFO - Beginning epoch 537/800
2025-03-06 22:53:11,465 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-06 22:53:11,640 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:53:11,817 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:53:11,991 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:53:12,161 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:53:12,335 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-06 22:53:12,505 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:53:12,682 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:53:12,852 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:53:13,031 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-06 22:53:13,200 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 22:53:13,375 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:53:13,567 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:53:13,747 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:53:13,921 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:53:14,095 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:53:14,271 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:53:14,441 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:53:14,527 - INFO - validation batch 1, loss: 0.198, 32/6976 datapoints
2025-03-06 22:53:14,574 - INFO - validation batch 51, loss: 5.857, 1632/6976 datapoints
2025-03-06 22:53:14,624 - INFO - validation batch 101, loss: 0.778, 3232/6976 datapoints
2025-03-06 22:53:14,671 - INFO - validation batch 151, loss: 1.564, 4832/6976 datapoints
2025-03-06 22:53:14,718 - INFO - validation batch 201, loss: 2.801, 6432/6976 datapoints
2025-03-06 22:53:14,735 - INFO - Epoch 537/800 done.
2025-03-06 22:53:14,735 - INFO - Final validation performance:
Loss: 2.240, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:53:14,736 - INFO - Beginning epoch 538/800
2025-03-06 22:53:14,740 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-06 22:53:14,915 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:53:15,093 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:53:15,272 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:53:15,443 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:53:15,623 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:53:15,799 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:53:15,981 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:53:16,156 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:53:16,339 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-06 22:53:16,517 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:53:16,689 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:53:16,858 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:53:17,040 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:53:17,211 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:53:17,385 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:53:17,557 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:53:17,726 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:53:17,815 - INFO - validation batch 1, loss: 0.184, 32/6976 datapoints
2025-03-06 22:53:17,862 - INFO - validation batch 51, loss: 5.963, 1632/6976 datapoints
2025-03-06 22:53:17,912 - INFO - validation batch 101, loss: 0.728, 3232/6976 datapoints
2025-03-06 22:53:17,960 - INFO - validation batch 151, loss: 1.636, 4832/6976 datapoints
2025-03-06 22:53:18,011 - INFO - validation batch 201, loss: 2.786, 6432/6976 datapoints
2025-03-06 22:53:18,027 - INFO - Epoch 538/800 done.
2025-03-06 22:53:18,028 - INFO - Final validation performance:
Loss: 2.259, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:53:18,028 - INFO - Beginning epoch 539/800
2025-03-06 22:53:18,033 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-06 22:53:18,210 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:53:18,386 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 22:53:18,558 - INFO - training batch 151, loss: 0.097, 4832/28000 datapoints
2025-03-06 22:53:18,730 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:53:18,911 - INFO - training batch 251, loss: 0.027, 8032/28000 datapoints
2025-03-06 22:53:19,081 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-06 22:53:19,263 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:53:19,435 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:53:19,609 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:53:19,779 - INFO - training batch 501, loss: 0.018, 16032/28000 datapoints
2025-03-06 22:53:19,952 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:53:20,122 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:53:20,293 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:53:20,467 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:53:20,636 - INFO - training batch 751, loss: 0.061, 24032/28000 datapoints
2025-03-06 22:53:20,807 - INFO - training batch 801, loss: 0.015, 25632/28000 datapoints
2025-03-06 22:53:20,980 - INFO - training batch 851, loss: 0.014, 27232/28000 datapoints
2025-03-06 22:53:21,087 - INFO - validation batch 1, loss: 0.157, 32/6976 datapoints
2025-03-06 22:53:21,134 - INFO - validation batch 51, loss: 6.002, 1632/6976 datapoints
2025-03-06 22:53:21,182 - INFO - validation batch 101, loss: 0.871, 3232/6976 datapoints
2025-03-06 22:53:21,229 - INFO - validation batch 151, loss: 1.467, 4832/6976 datapoints
2025-03-06 22:53:21,280 - INFO - validation batch 201, loss: 2.880, 6432/6976 datapoints
2025-03-06 22:53:21,296 - INFO - Epoch 539/800 done.
2025-03-06 22:53:21,297 - INFO - Final validation performance:
Loss: 2.275, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:53:21,297 - INFO - Beginning epoch 540/800
2025-03-06 22:53:21,301 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-06 22:53:21,497 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:53:21,700 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:53:21,887 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:53:22,083 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:53:22,295 - INFO - training batch 251, loss: 0.034, 8032/28000 datapoints
2025-03-06 22:53:22,488 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:53:22,691 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-06 22:53:22,874 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:53:23,066 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:53:23,261 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:53:23,458 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:53:23,670 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:53:23,873 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:53:24,071 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:53:24,257 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:53:24,433 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:53:24,603 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:53:24,691 - INFO - validation batch 1, loss: 0.172, 32/6976 datapoints
2025-03-06 22:53:24,738 - INFO - validation batch 51, loss: 5.835, 1632/6976 datapoints
2025-03-06 22:53:24,785 - INFO - validation batch 101, loss: 0.860, 3232/6976 datapoints
2025-03-06 22:53:24,832 - INFO - validation batch 151, loss: 1.542, 4832/6976 datapoints
2025-03-06 22:53:24,880 - INFO - validation batch 201, loss: 2.878, 6432/6976 datapoints
2025-03-06 22:53:24,896 - INFO - Epoch 540/800 done.
2025-03-06 22:53:24,896 - INFO - Final validation performance:
Loss: 2.258, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:53:24,897 - INFO - Beginning epoch 541/800
2025-03-06 22:53:24,901 - INFO - training batch 1, loss: 0.013, 32/28000 datapoints
2025-03-06 22:53:25,084 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:53:25,272 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:53:25,447 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:53:25,621 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:53:25,800 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:53:25,981 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:53:26,162 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:53:26,337 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:53:26,519 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:53:26,695 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:53:26,871 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 22:53:27,049 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:53:27,228 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:53:27,407 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:53:27,582 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:53:27,758 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:53:27,948 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:53:28,040 - INFO - validation batch 1, loss: 0.195, 32/6976 datapoints
2025-03-06 22:53:28,093 - INFO - validation batch 51, loss: 5.905, 1632/6976 datapoints
2025-03-06 22:53:28,146 - INFO - validation batch 101, loss: 0.845, 3232/6976 datapoints
2025-03-06 22:53:28,203 - INFO - validation batch 151, loss: 1.534, 4832/6976 datapoints
2025-03-06 22:53:28,258 - INFO - validation batch 201, loss: 2.842, 6432/6976 datapoints
2025-03-06 22:53:28,279 - INFO - Epoch 541/800 done.
2025-03-06 22:53:28,280 - INFO - Final validation performance:
Loss: 2.264, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:53:28,280 - INFO - Beginning epoch 542/800
2025-03-06 22:53:28,285 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-06 22:53:28,466 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:53:28,657 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:53:28,832 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:53:29,011 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:53:29,189 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-06 22:53:29,366 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:53:29,552 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:53:29,728 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:53:29,906 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:53:30,085 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:53:30,262 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:53:30,435 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:53:30,622 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:53:30,797 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:53:30,974 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:53:31,158 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:53:31,334 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:53:31,425 - INFO - validation batch 1, loss: 0.200, 32/6976 datapoints
2025-03-06 22:53:31,476 - INFO - validation batch 51, loss: 5.965, 1632/6976 datapoints
2025-03-06 22:53:31,527 - INFO - validation batch 101, loss: 0.828, 3232/6976 datapoints
2025-03-06 22:53:31,582 - INFO - validation batch 151, loss: 1.588, 4832/6976 datapoints
2025-03-06 22:53:31,635 - INFO - validation batch 201, loss: 2.814, 6432/6976 datapoints
2025-03-06 22:53:31,652 - INFO - Epoch 542/800 done.
2025-03-06 22:53:31,652 - INFO - Final validation performance:
Loss: 2.279, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:53:31,652 - INFO - Beginning epoch 543/800
2025-03-06 22:53:31,658 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-06 22:53:31,836 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:53:32,020 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:53:32,195 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:53:32,368 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:53:32,546 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-06 22:53:32,721 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:53:32,903 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:53:33,083 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:53:33,261 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:53:33,439 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:53:33,616 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:53:33,814 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:53:33,998 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:53:34,192 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:53:34,367 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:53:34,551 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:53:34,729 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:53:34,819 - INFO - validation batch 1, loss: 0.185, 32/6976 datapoints
2025-03-06 22:53:34,876 - INFO - validation batch 51, loss: 5.958, 1632/6976 datapoints
2025-03-06 22:53:34,928 - INFO - validation batch 101, loss: 0.799, 3232/6976 datapoints
2025-03-06 22:53:34,982 - INFO - validation batch 151, loss: 1.656, 4832/6976 datapoints
2025-03-06 22:53:35,035 - INFO - validation batch 201, loss: 2.815, 6432/6976 datapoints
2025-03-06 22:53:35,051 - INFO - Epoch 543/800 done.
2025-03-06 22:53:35,051 - INFO - Final validation performance:
Loss: 2.283, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:53:35,052 - INFO - Beginning epoch 544/800
2025-03-06 22:53:35,057 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-06 22:53:35,240 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:53:35,430 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:53:35,607 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:53:35,782 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:53:35,960 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 22:53:36,136 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:53:36,322 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:53:36,501 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:53:36,687 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:53:36,868 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:53:37,047 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:53:37,223 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:53:37,403 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:53:37,580 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:53:37,755 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:53:37,969 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:53:38,154 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:53:38,242 - INFO - validation batch 1, loss: 0.173, 32/6976 datapoints
2025-03-06 22:53:38,294 - INFO - validation batch 51, loss: 6.014, 1632/6976 datapoints
2025-03-06 22:53:38,346 - INFO - validation batch 101, loss: 0.751, 3232/6976 datapoints
2025-03-06 22:53:38,401 - INFO - validation batch 151, loss: 1.711, 4832/6976 datapoints
2025-03-06 22:53:38,454 - INFO - validation batch 201, loss: 2.822, 6432/6976 datapoints
2025-03-06 22:53:38,475 - INFO - Epoch 544/800 done.
2025-03-06 22:53:38,476 - INFO - Final validation performance:
Loss: 2.294, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:53:38,476 - INFO - Beginning epoch 545/800
2025-03-06 22:53:38,481 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-06 22:53:38,661 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:53:38,845 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:53:39,023 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:53:39,199 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:53:39,381 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:53:39,556 - INFO - training batch 301, loss: 0.336, 9632/28000 datapoints
2025-03-06 22:53:39,737 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:53:39,912 - INFO - training batch 401, loss: 0.027, 12832/28000 datapoints
2025-03-06 22:53:40,107 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:53:40,288 - INFO - training batch 501, loss: 0.176, 16032/28000 datapoints
2025-03-06 22:53:40,463 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 22:53:40,639 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 22:53:40,830 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:53:41,015 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:53:41,192 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:53:41,371 - INFO - training batch 801, loss: 0.045, 25632/28000 datapoints
2025-03-06 22:53:41,545 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:53:41,634 - INFO - validation batch 1, loss: 0.113, 32/6976 datapoints
2025-03-06 22:53:41,690 - INFO - validation batch 51, loss: 5.644, 1632/6976 datapoints
2025-03-06 22:53:41,743 - INFO - validation batch 101, loss: 1.023, 3232/6976 datapoints
2025-03-06 22:53:41,797 - INFO - validation batch 151, loss: 2.064, 4832/6976 datapoints
2025-03-06 22:53:41,851 - INFO - validation batch 201, loss: 2.903, 6432/6976 datapoints
2025-03-06 22:53:41,872 - INFO - Epoch 545/800 done.
2025-03-06 22:53:41,872 - INFO - Final validation performance:
Loss: 2.350, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 22:53:41,872 - INFO - Beginning epoch 546/800
2025-03-06 22:53:41,878 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-06 22:53:42,065 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:53:42,250 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:53:42,429 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:53:42,602 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:53:42,779 - INFO - training batch 251, loss: 0.023, 8032/28000 datapoints
2025-03-06 22:53:42,954 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:53:43,141 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:53:43,318 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:53:43,500 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:53:43,676 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:53:43,880 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-06 22:53:44,070 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:53:44,257 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:53:44,433 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:53:44,617 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:53:44,795 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:53:44,969 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:53:45,058 - INFO - validation batch 1, loss: 0.290, 32/6976 datapoints
2025-03-06 22:53:45,112 - INFO - validation batch 51, loss: 5.772, 1632/6976 datapoints
2025-03-06 22:53:45,165 - INFO - validation batch 101, loss: 0.867, 3232/6976 datapoints
2025-03-06 22:53:45,220 - INFO - validation batch 151, loss: 1.654, 4832/6976 datapoints
2025-03-06 22:53:45,281 - INFO - validation batch 201, loss: 2.845, 6432/6976 datapoints
2025-03-06 22:53:45,299 - INFO - Epoch 546/800 done.
2025-03-06 22:53:45,299 - INFO - Final validation performance:
Loss: 2.286, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:53:45,299 - INFO - Beginning epoch 547/800
2025-03-06 22:53:45,304 - INFO - training batch 1, loss: 0.014, 32/28000 datapoints
2025-03-06 22:53:45,485 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:53:45,667 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:53:45,846 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:53:46,021 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:53:46,213 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-06 22:53:46,391 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:53:46,586 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-06 22:53:46,767 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:53:46,950 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:53:47,128 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:53:47,307 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-06 22:53:47,486 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:53:47,668 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:53:47,847 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:53:48,025 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:53:48,201 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:53:48,377 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:53:48,466 - INFO - validation batch 1, loss: 0.243, 32/6976 datapoints
2025-03-06 22:53:48,519 - INFO - validation batch 51, loss: 5.830, 1632/6976 datapoints
2025-03-06 22:53:48,568 - INFO - validation batch 101, loss: 0.852, 3232/6976 datapoints
2025-03-06 22:53:48,617 - INFO - validation batch 151, loss: 1.669, 4832/6976 datapoints
2025-03-06 22:53:48,665 - INFO - validation batch 201, loss: 2.837, 6432/6976 datapoints
2025-03-06 22:53:48,681 - INFO - Epoch 547/800 done.
2025-03-06 22:53:48,681 - INFO - Final validation performance:
Loss: 2.286, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:53:48,682 - INFO - Beginning epoch 548/800
2025-03-06 22:53:48,687 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 22:53:48,867 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:53:49,047 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:53:49,222 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:53:49,396 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:53:49,569 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-06 22:53:49,739 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:53:49,923 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:53:50,099 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:53:50,273 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:53:50,448 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:53:50,620 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:53:50,792 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:53:50,968 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:53:51,151 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:53:51,322 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:53:51,498 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:53:51,673 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:53:51,757 - INFO - validation batch 1, loss: 0.231, 32/6976 datapoints
2025-03-06 22:53:51,806 - INFO - validation batch 51, loss: 5.902, 1632/6976 datapoints
2025-03-06 22:53:51,854 - INFO - validation batch 101, loss: 0.845, 3232/6976 datapoints
2025-03-06 22:53:51,902 - INFO - validation batch 151, loss: 1.691, 4832/6976 datapoints
2025-03-06 22:53:51,949 - INFO - validation batch 201, loss: 2.833, 6432/6976 datapoints
2025-03-06 22:53:51,965 - INFO - Epoch 548/800 done.
2025-03-06 22:53:51,965 - INFO - Final validation performance:
Loss: 2.301, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:53:51,966 - INFO - Beginning epoch 549/800
2025-03-06 22:53:51,973 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-06 22:53:52,157 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:53:52,345 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:53:52,518 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:53:52,694 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:53:52,871 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:53:53,047 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:53:53,228 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:53:53,406 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:53:53,583 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:53:53,757 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:53:53,946 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:53:54,141 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:53:54,322 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:53:54,498 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:53:54,670 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:53:54,844 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:53:55,019 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:53:55,103 - INFO - validation batch 1, loss: 0.221, 32/6976 datapoints
2025-03-06 22:53:55,151 - INFO - validation batch 51, loss: 5.940, 1632/6976 datapoints
2025-03-06 22:53:55,198 - INFO - validation batch 101, loss: 0.827, 3232/6976 datapoints
2025-03-06 22:53:55,248 - INFO - validation batch 151, loss: 1.747, 4832/6976 datapoints
2025-03-06 22:53:55,300 - INFO - validation batch 201, loss: 2.847, 6432/6976 datapoints
2025-03-06 22:53:55,316 - INFO - Epoch 549/800 done.
2025-03-06 22:53:55,316 - INFO - Final validation performance:
Loss: 2.316, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:53:55,317 - INFO - Beginning epoch 550/800
2025-03-06 22:53:55,321 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:53:55,502 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:53:55,686 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:53:55,859 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:53:56,033 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:53:56,207 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 22:53:56,378 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:53:56,559 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:53:56,733 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:53:56,909 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:53:57,084 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:53:57,259 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:53:57,434 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:53:57,609 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:53:57,782 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:53:57,952 - INFO - training batch 751, loss: 0.030, 24032/28000 datapoints
2025-03-06 22:53:58,133 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:53:58,305 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:53:58,402 - INFO - validation batch 1, loss: 0.108, 32/6976 datapoints
2025-03-06 22:53:58,450 - INFO - validation batch 51, loss: 5.755, 1632/6976 datapoints
2025-03-06 22:53:58,498 - INFO - validation batch 101, loss: 0.815, 3232/6976 datapoints
2025-03-06 22:53:58,546 - INFO - validation batch 151, loss: 2.054, 4832/6976 datapoints
2025-03-06 22:53:58,594 - INFO - validation batch 201, loss: 3.212, 6432/6976 datapoints
2025-03-06 22:53:58,611 - INFO - Epoch 550/800 done.
2025-03-06 22:53:58,611 - INFO - Final validation performance:
Loss: 2.389, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:53:58,612 - INFO - Beginning epoch 551/800
2025-03-06 22:53:58,616 - INFO - training batch 1, loss: 0.013, 32/28000 datapoints
2025-03-06 22:53:58,792 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:53:58,984 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:53:59,164 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:53:59,339 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:53:59,520 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-06 22:53:59,690 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:53:59,872 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-06 22:54:00,051 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:54:00,226 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:54:00,401 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:54:00,576 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-06 22:54:00,749 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:54:00,924 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:54:01,101 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-06 22:54:01,274 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-06 22:54:01,449 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:54:01,622 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:54:01,710 - INFO - validation batch 1, loss: 0.266, 32/6976 datapoints
2025-03-06 22:54:01,758 - INFO - validation batch 51, loss: 6.108, 1632/6976 datapoints
2025-03-06 22:54:01,805 - INFO - validation batch 101, loss: 0.964, 3232/6976 datapoints
2025-03-06 22:54:01,853 - INFO - validation batch 151, loss: 1.554, 4832/6976 datapoints
2025-03-06 22:54:01,900 - INFO - validation batch 201, loss: 3.045, 6432/6976 datapoints
2025-03-06 22:54:01,917 - INFO - Epoch 551/800 done.
2025-03-06 22:54:01,917 - INFO - Final validation performance:
Loss: 2.388, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:54:01,918 - INFO - Beginning epoch 552/800
2025-03-06 22:54:01,922 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:54:02,102 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:54:02,281 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:54:02,454 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:02,626 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:54:02,802 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:54:02,976 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:54:03,159 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:54:03,331 - INFO - training batch 401, loss: 0.018, 12832/28000 datapoints
2025-03-06 22:54:03,510 - INFO - training batch 451, loss: 0.011, 14432/28000 datapoints
2025-03-06 22:54:03,684 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-06 22:54:03,859 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:54:04,041 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:54:04,241 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:54:04,425 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:54:04,601 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:04,774 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:54:04,946 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:54:05,037 - INFO - validation batch 1, loss: 0.301, 32/6976 datapoints
2025-03-06 22:54:05,084 - INFO - validation batch 51, loss: 6.033, 1632/6976 datapoints
2025-03-06 22:54:05,131 - INFO - validation batch 101, loss: 0.956, 3232/6976 datapoints
2025-03-06 22:54:05,179 - INFO - validation batch 151, loss: 1.593, 4832/6976 datapoints
2025-03-06 22:54:05,227 - INFO - validation batch 201, loss: 3.064, 6432/6976 datapoints
2025-03-06 22:54:05,246 - INFO - Epoch 552/800 done.
2025-03-06 22:54:05,246 - INFO - Final validation performance:
Loss: 2.389, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:54:05,247 - INFO - Beginning epoch 553/800
2025-03-06 22:54:05,251 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:54:05,441 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:54:05,626 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:54:05,803 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:05,979 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:54:06,159 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-06 22:54:06,336 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:54:06,523 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:54:06,705 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:54:06,888 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:54:07,070 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:54:07,247 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:54:07,425 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:54:07,610 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:54:07,787 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:54:07,964 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:08,143 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:54:08,319 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:54:08,408 - INFO - validation batch 1, loss: 0.261, 32/6976 datapoints
2025-03-06 22:54:08,460 - INFO - validation batch 51, loss: 6.008, 1632/6976 datapoints
2025-03-06 22:54:08,511 - INFO - validation batch 101, loss: 0.939, 3232/6976 datapoints
2025-03-06 22:54:08,565 - INFO - validation batch 151, loss: 1.646, 4832/6976 datapoints
2025-03-06 22:54:08,619 - INFO - validation batch 201, loss: 3.009, 6432/6976 datapoints
2025-03-06 22:54:08,637 - INFO - Epoch 553/800 done.
2025-03-06 22:54:08,637 - INFO - Final validation performance:
Loss: 2.373, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:54:08,637 - INFO - Beginning epoch 554/800
2025-03-06 22:54:08,642 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:54:08,823 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:54:09,007 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:54:09,183 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:09,360 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:54:09,542 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:54:09,720 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-06 22:54:09,907 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:54:10,088 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:54:10,267 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:54:10,444 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:54:10,631 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:54:10,809 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:54:10,991 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:54:11,167 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:54:11,343 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:11,522 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:54:11,701 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:54:11,790 - INFO - validation batch 1, loss: 0.245, 32/6976 datapoints
2025-03-06 22:54:11,842 - INFO - validation batch 51, loss: 6.014, 1632/6976 datapoints
2025-03-06 22:54:11,895 - INFO - validation batch 101, loss: 0.913, 3232/6976 datapoints
2025-03-06 22:54:11,946 - INFO - validation batch 151, loss: 1.678, 4832/6976 datapoints
2025-03-06 22:54:12,000 - INFO - validation batch 201, loss: 2.974, 6432/6976 datapoints
2025-03-06 22:54:12,019 - INFO - Epoch 554/800 done.
2025-03-06 22:54:12,020 - INFO - Final validation performance:
Loss: 2.365, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:54:12,020 - INFO - Beginning epoch 555/800
2025-03-06 22:54:12,026 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:54:12,205 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:54:12,387 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:54:12,559 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:12,731 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:54:12,913 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 22:54:13,116 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:54:13,298 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:54:13,475 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:54:13,651 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:54:13,823 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:54:14,001 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:54:14,195 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:54:14,387 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:54:14,560 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:54:14,732 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:14,905 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:54:15,079 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:54:15,164 - INFO - validation batch 1, loss: 0.242, 32/6976 datapoints
2025-03-06 22:54:15,211 - INFO - validation batch 51, loss: 6.059, 1632/6976 datapoints
2025-03-06 22:54:15,269 - INFO - validation batch 101, loss: 0.877, 3232/6976 datapoints
2025-03-06 22:54:15,319 - INFO - validation batch 151, loss: 1.721, 4832/6976 datapoints
2025-03-06 22:54:15,366 - INFO - validation batch 201, loss: 2.978, 6432/6976 datapoints
2025-03-06 22:54:15,382 - INFO - Epoch 555/800 done.
2025-03-06 22:54:15,383 - INFO - Final validation performance:
Loss: 2.375, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:54:15,383 - INFO - Beginning epoch 556/800
2025-03-06 22:54:15,387 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:54:15,565 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:54:15,749 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:54:15,922 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:16,094 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:54:16,269 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 22:54:16,439 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:54:16,620 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:54:16,807 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:54:16,985 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:54:17,158 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:54:17,334 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:54:17,510 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:54:17,689 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:54:17,863 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:54:18,037 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:18,212 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:54:18,386 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:54:18,471 - INFO - validation batch 1, loss: 0.241, 32/6976 datapoints
2025-03-06 22:54:18,519 - INFO - validation batch 51, loss: 6.137, 1632/6976 datapoints
2025-03-06 22:54:18,568 - INFO - validation batch 101, loss: 0.832, 3232/6976 datapoints
2025-03-06 22:54:18,616 - INFO - validation batch 151, loss: 1.757, 4832/6976 datapoints
2025-03-06 22:54:18,665 - INFO - validation batch 201, loss: 3.023, 6432/6976 datapoints
2025-03-06 22:54:18,682 - INFO - Epoch 556/800 done.
2025-03-06 22:54:18,682 - INFO - Final validation performance:
Loss: 2.398, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:54:18,683 - INFO - Beginning epoch 557/800
2025-03-06 22:54:18,687 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-06 22:54:18,867 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:54:19,047 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:54:19,222 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:19,395 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:54:19,575 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 22:54:19,744 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:54:19,927 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:54:20,106 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:54:20,282 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:54:20,457 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:54:20,631 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:54:20,805 - INFO - training batch 601, loss: 0.095, 19232/28000 datapoints
2025-03-06 22:54:20,982 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 22:54:21,159 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:54:21,329 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:21,507 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:54:21,683 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:54:21,775 - INFO - validation batch 1, loss: 0.175, 32/6976 datapoints
2025-03-06 22:54:21,823 - INFO - validation batch 51, loss: 5.997, 1632/6976 datapoints
2025-03-06 22:54:21,873 - INFO - validation batch 101, loss: 0.922, 3232/6976 datapoints
2025-03-06 22:54:21,920 - INFO - validation batch 151, loss: 2.802, 4832/6976 datapoints
2025-03-06 22:54:21,967 - INFO - validation batch 201, loss: 3.316, 6432/6976 datapoints
2025-03-06 22:54:21,987 - INFO - Epoch 557/800 done.
2025-03-06 22:54:21,987 - INFO - Final validation performance:
Loss: 2.642, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 22:54:21,987 - INFO - Beginning epoch 558/800
2025-03-06 22:54:21,992 - INFO - training batch 1, loss: 0.019, 32/28000 datapoints
2025-03-06 22:54:22,169 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 22:54:22,353 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:54:22,525 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:22,697 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 22:54:22,875 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-06 22:54:23,046 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:54:23,228 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:54:23,402 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:54:23,577 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:54:23,753 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:54:23,929 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 22:54:24,108 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:54:24,312 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:54:24,496 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:54:24,668 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:24,842 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:54:25,017 - INFO - training batch 851, loss: 0.012, 27232/28000 datapoints
2025-03-06 22:54:25,103 - INFO - validation batch 1, loss: 0.297, 32/6976 datapoints
2025-03-06 22:54:25,150 - INFO - validation batch 51, loss: 6.364, 1632/6976 datapoints
2025-03-06 22:54:25,200 - INFO - validation batch 101, loss: 0.911, 3232/6976 datapoints
2025-03-06 22:54:25,252 - INFO - validation batch 151, loss: 1.736, 4832/6976 datapoints
2025-03-06 22:54:25,299 - INFO - validation batch 201, loss: 3.161, 6432/6976 datapoints
2025-03-06 22:54:25,315 - INFO - Epoch 558/800 done.
2025-03-06 22:54:25,316 - INFO - Final validation performance:
Loss: 2.494, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:54:25,316 - INFO - Beginning epoch 559/800
2025-03-06 22:54:25,320 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-06 22:54:25,507 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:54:25,692 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:54:25,868 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:26,101 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:54:26,280 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-06 22:54:26,457 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:54:26,648 - INFO - training batch 351, loss: 0.010, 11232/28000 datapoints
2025-03-06 22:54:26,826 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:54:27,003 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:54:27,179 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:54:27,360 - INFO - training batch 551, loss: 0.032, 17632/28000 datapoints
2025-03-06 22:54:27,538 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:54:27,719 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:54:27,899 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:54:28,076 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:28,256 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:54:28,433 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:54:28,522 - INFO - validation batch 1, loss: 0.271, 32/6976 datapoints
2025-03-06 22:54:28,575 - INFO - validation batch 51, loss: 6.330, 1632/6976 datapoints
2025-03-06 22:54:28,628 - INFO - validation batch 101, loss: 0.935, 3232/6976 datapoints
2025-03-06 22:54:28,681 - INFO - validation batch 151, loss: 1.603, 4832/6976 datapoints
2025-03-06 22:54:28,735 - INFO - validation batch 201, loss: 3.203, 6432/6976 datapoints
2025-03-06 22:54:28,753 - INFO - Epoch 559/800 done.
2025-03-06 22:54:28,753 - INFO - Final validation performance:
Loss: 2.468, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:54:28,753 - INFO - Beginning epoch 560/800
2025-03-06 22:54:28,759 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-06 22:54:28,941 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:54:29,123 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:54:29,323 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:29,498 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:54:29,684 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:54:29,862 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:54:30,079 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:54:30,304 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:54:30,517 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:54:30,726 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:54:30,907 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 22:54:31,105 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:54:31,283 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:54:31,463 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:54:31,646 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:31,835 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:54:32,018 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:54:32,106 - INFO - validation batch 1, loss: 0.178, 32/6976 datapoints
2025-03-06 22:54:32,157 - INFO - validation batch 51, loss: 6.261, 1632/6976 datapoints
2025-03-06 22:54:32,210 - INFO - validation batch 101, loss: 0.799, 3232/6976 datapoints
2025-03-06 22:54:32,262 - INFO - validation batch 151, loss: 1.665, 4832/6976 datapoints
2025-03-06 22:54:32,317 - INFO - validation batch 201, loss: 3.081, 6432/6976 datapoints
2025-03-06 22:54:32,335 - INFO - Epoch 560/800 done.
2025-03-06 22:54:32,336 - INFO - Final validation performance:
Loss: 2.397, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:54:32,336 - INFO - Beginning epoch 561/800
2025-03-06 22:54:32,342 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-06 22:54:32,528 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:54:32,710 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-06 22:54:32,889 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:33,068 - INFO - training batch 201, loss: 0.097, 6432/28000 datapoints
2025-03-06 22:54:33,250 - INFO - training batch 251, loss: 0.150, 8032/28000 datapoints
2025-03-06 22:54:33,426 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:54:33,617 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:54:33,796 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:54:33,977 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:54:34,155 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:54:34,338 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:54:34,546 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:54:34,725 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:54:34,904 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:54:35,087 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:54:35,284 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:54:35,465 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:54:35,558 - INFO - validation batch 1, loss: 0.268, 32/6976 datapoints
2025-03-06 22:54:35,611 - INFO - validation batch 51, loss: 6.376, 1632/6976 datapoints
2025-03-06 22:54:35,673 - INFO - validation batch 101, loss: 0.845, 3232/6976 datapoints
2025-03-06 22:54:35,730 - INFO - validation batch 151, loss: 1.552, 4832/6976 datapoints
2025-03-06 22:54:35,783 - INFO - validation batch 201, loss: 3.087, 6432/6976 datapoints
2025-03-06 22:54:35,800 - INFO - Epoch 561/800 done.
2025-03-06 22:54:35,800 - INFO - Final validation performance:
Loss: 2.426, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:54:35,801 - INFO - Beginning epoch 562/800
2025-03-06 22:54:35,806 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:54:35,996 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:54:36,175 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:54:36,353 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:36,527 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:54:36,713 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-06 22:54:36,887 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:54:37,078 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-06 22:54:37,269 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:54:37,451 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:54:37,631 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 22:54:37,810 - INFO - training batch 551, loss: 0.023, 17632/28000 datapoints
2025-03-06 22:54:38,007 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:54:38,186 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:54:38,406 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:54:38,598 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:38,777 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:54:38,954 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:54:39,045 - INFO - validation batch 1, loss: 0.250, 32/6976 datapoints
2025-03-06 22:54:39,097 - INFO - validation batch 51, loss: 6.407, 1632/6976 datapoints
2025-03-06 22:54:39,149 - INFO - validation batch 101, loss: 0.918, 3232/6976 datapoints
2025-03-06 22:54:39,202 - INFO - validation batch 151, loss: 1.546, 4832/6976 datapoints
2025-03-06 22:54:39,257 - INFO - validation batch 201, loss: 3.084, 6432/6976 datapoints
2025-03-06 22:54:39,278 - INFO - Epoch 562/800 done.
2025-03-06 22:54:39,278 - INFO - Final validation performance:
Loss: 2.441, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:54:39,279 - INFO - Beginning epoch 563/800
2025-03-06 22:54:39,283 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:54:39,470 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:54:39,656 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:54:39,834 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:40,010 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:54:40,189 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-06 22:54:40,362 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:54:40,552 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:54:40,733 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:54:40,911 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:54:41,089 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:54:41,268 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:54:41,462 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:54:41,644 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:54:41,830 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:54:42,015 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:42,194 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:54:42,375 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:54:42,465 - INFO - validation batch 1, loss: 0.251, 32/6976 datapoints
2025-03-06 22:54:42,523 - INFO - validation batch 51, loss: 6.391, 1632/6976 datapoints
2025-03-06 22:54:42,575 - INFO - validation batch 101, loss: 0.916, 3232/6976 datapoints
2025-03-06 22:54:42,627 - INFO - validation batch 151, loss: 1.606, 4832/6976 datapoints
2025-03-06 22:54:42,679 - INFO - validation batch 201, loss: 3.052, 6432/6976 datapoints
2025-03-06 22:54:42,695 - INFO - Epoch 563/800 done.
2025-03-06 22:54:42,695 - INFO - Final validation performance:
Loss: 2.443, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:54:42,696 - INFO - Beginning epoch 564/800
2025-03-06 22:54:42,701 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:54:42,885 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:54:43,069 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:54:43,244 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:43,417 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:54:43,601 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:54:43,781 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:54:43,969 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:54:44,154 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:54:44,335 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:54:44,544 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:54:44,726 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:54:44,910 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:54:45,095 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:54:45,278 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:54:45,457 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:45,638 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:54:45,816 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:54:45,906 - INFO - validation batch 1, loss: 0.253, 32/6976 datapoints
2025-03-06 22:54:45,959 - INFO - validation batch 51, loss: 6.384, 1632/6976 datapoints
2025-03-06 22:54:46,016 - INFO - validation batch 101, loss: 0.919, 3232/6976 datapoints
2025-03-06 22:54:46,068 - INFO - validation batch 151, loss: 1.633, 4832/6976 datapoints
2025-03-06 22:54:46,117 - INFO - validation batch 201, loss: 3.055, 6432/6976 datapoints
2025-03-06 22:54:46,134 - INFO - Epoch 564/800 done.
2025-03-06 22:54:46,134 - INFO - Final validation performance:
Loss: 2.449, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:54:46,134 - INFO - Beginning epoch 565/800
2025-03-06 22:54:46,139 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:54:46,316 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:54:46,493 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:54:46,669 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:46,841 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:54:47,020 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 22:54:47,192 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:54:47,381 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:54:47,564 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:54:47,743 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:54:47,931 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:54:48,112 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:54:48,294 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:54:48,472 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:54:48,648 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:54:48,819 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:48,996 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:54:49,170 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:54:49,255 - INFO - validation batch 1, loss: 0.251, 32/6976 datapoints
2025-03-06 22:54:49,303 - INFO - validation batch 51, loss: 6.372, 1632/6976 datapoints
2025-03-06 22:54:49,350 - INFO - validation batch 101, loss: 0.904, 3232/6976 datapoints
2025-03-06 22:54:49,398 - INFO - validation batch 151, loss: 1.669, 4832/6976 datapoints
2025-03-06 22:54:49,446 - INFO - validation batch 201, loss: 3.066, 6432/6976 datapoints
2025-03-06 22:54:49,465 - INFO - Epoch 565/800 done.
2025-03-06 22:54:49,465 - INFO - Final validation performance:
Loss: 2.452, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:54:49,466 - INFO - Beginning epoch 566/800
2025-03-06 22:54:49,470 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:54:49,657 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:54:49,836 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:54:50,018 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:50,191 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:54:50,370 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 22:54:50,540 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:54:50,730 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:54:50,909 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:54:51,095 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:54:51,269 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:54:51,445 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:54:51,625 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:54:51,805 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:54:51,984 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:54:52,176 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:52,352 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:54:52,527 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:54:52,612 - INFO - validation batch 1, loss: 0.233, 32/6976 datapoints
2025-03-06 22:54:52,659 - INFO - validation batch 51, loss: 6.382, 1632/6976 datapoints
2025-03-06 22:54:52,706 - INFO - validation batch 101, loss: 0.856, 3232/6976 datapoints
2025-03-06 22:54:52,754 - INFO - validation batch 151, loss: 1.745, 4832/6976 datapoints
2025-03-06 22:54:52,802 - INFO - validation batch 201, loss: 3.077, 6432/6976 datapoints
2025-03-06 22:54:52,819 - INFO - Epoch 566/800 done.
2025-03-06 22:54:52,819 - INFO - Final validation performance:
Loss: 2.459, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:54:52,820 - INFO - Beginning epoch 567/800
2025-03-06 22:54:52,825 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:54:53,007 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:54:53,189 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:54:53,369 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:54:53,552 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:54:53,735 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:54:53,913 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:54:54,103 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:54:54,285 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:54:54,461 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:54:54,664 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:54:54,842 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:54:55,022 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:54:55,201 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:54:55,380 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:54:55,552 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:55,734 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:54:55,908 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:54:55,996 - INFO - validation batch 1, loss: 0.216, 32/6976 datapoints
2025-03-06 22:54:56,043 - INFO - validation batch 51, loss: 6.360, 1632/6976 datapoints
2025-03-06 22:54:56,091 - INFO - validation batch 101, loss: 0.798, 3232/6976 datapoints
2025-03-06 22:54:56,141 - INFO - validation batch 151, loss: 1.884, 4832/6976 datapoints
2025-03-06 22:54:56,189 - INFO - validation batch 201, loss: 3.084, 6432/6976 datapoints
2025-03-06 22:54:56,205 - INFO - Epoch 567/800 done.
2025-03-06 22:54:56,205 - INFO - Final validation performance:
Loss: 2.468, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:54:56,206 - INFO - Beginning epoch 568/800
2025-03-06 22:54:56,210 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:54:56,390 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 22:54:56,568 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-06 22:54:56,752 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 22:54:56,925 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 22:54:57,106 - INFO - training batch 251, loss: 0.020, 8032/28000 datapoints
2025-03-06 22:54:57,281 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-06 22:54:57,463 - INFO - training batch 351, loss: 0.024, 11232/28000 datapoints
2025-03-06 22:54:57,645 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:54:57,819 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:54:57,997 - INFO - training batch 501, loss: 0.038, 16032/28000 datapoints
2025-03-06 22:54:58,175 - INFO - training batch 551, loss: 0.022, 17632/28000 datapoints
2025-03-06 22:54:58,351 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:54:58,528 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:54:58,705 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-06 22:54:58,880 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:54:59,060 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-06 22:54:59,238 - INFO - training batch 851, loss: 0.017, 27232/28000 datapoints
2025-03-06 22:54:59,325 - INFO - validation batch 1, loss: 0.245, 32/6976 datapoints
2025-03-06 22:54:59,373 - INFO - validation batch 51, loss: 6.375, 1632/6976 datapoints
2025-03-06 22:54:59,421 - INFO - validation batch 101, loss: 0.877, 3232/6976 datapoints
2025-03-06 22:54:59,468 - INFO - validation batch 151, loss: 1.819, 4832/6976 datapoints
2025-03-06 22:54:59,517 - INFO - validation batch 201, loss: 3.001, 6432/6976 datapoints
2025-03-06 22:54:59,533 - INFO - Epoch 568/800 done.
2025-03-06 22:54:59,533 - INFO - Final validation performance:
Loss: 2.463, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:54:59,534 - INFO - Beginning epoch 569/800
2025-03-06 22:54:59,539 - INFO - training batch 1, loss: 0.019, 32/28000 datapoints
2025-03-06 22:54:59,735 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:54:59,912 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:55:00,105 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:55:00,285 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:55:00,468 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:55:00,641 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-06 22:55:00,825 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:55:01,006 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:55:01,181 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:55:01,357 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:55:01,533 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:55:01,713 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:55:01,890 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:02,070 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:55:02,244 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-06 22:55:02,424 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:55:02,597 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 22:55:02,681 - INFO - validation batch 1, loss: 0.321, 32/6976 datapoints
2025-03-06 22:55:02,730 - INFO - validation batch 51, loss: 6.498, 1632/6976 datapoints
2025-03-06 22:55:02,777 - INFO - validation batch 101, loss: 0.959, 3232/6976 datapoints
2025-03-06 22:55:02,825 - INFO - validation batch 151, loss: 1.681, 4832/6976 datapoints
2025-03-06 22:55:02,873 - INFO - validation batch 201, loss: 3.134, 6432/6976 datapoints
2025-03-06 22:55:02,890 - INFO - Epoch 569/800 done.
2025-03-06 22:55:02,891 - INFO - Final validation performance:
Loss: 2.519, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:55:02,891 - INFO - Beginning epoch 570/800
2025-03-06 22:55:02,896 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-06 22:55:03,077 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:55:03,255 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:55:03,429 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:55:03,602 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:55:03,786 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 22:55:03,960 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:55:04,146 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:55:04,328 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:55:04,505 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:55:04,692 - INFO - training batch 501, loss: 0.029, 16032/28000 datapoints
2025-03-06 22:55:04,890 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:55:05,069 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:55:05,250 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:05,429 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:55:05,599 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:55:05,790 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:55:05,981 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:55:06,073 - INFO - validation batch 1, loss: 0.278, 32/6976 datapoints
2025-03-06 22:55:06,123 - INFO - validation batch 51, loss: 6.388, 1632/6976 datapoints
2025-03-06 22:55:06,175 - INFO - validation batch 101, loss: 0.962, 3232/6976 datapoints
2025-03-06 22:55:06,227 - INFO - validation batch 151, loss: 1.490, 4832/6976 datapoints
2025-03-06 22:55:06,278 - INFO - validation batch 201, loss: 3.422, 6432/6976 datapoints
2025-03-06 22:55:06,301 - INFO - Epoch 570/800 done.
2025-03-06 22:55:06,301 - INFO - Final validation performance:
Loss: 2.508, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:55:06,302 - INFO - Beginning epoch 571/800
2025-03-06 22:55:06,307 - INFO - training batch 1, loss: 0.029, 32/28000 datapoints
2025-03-06 22:55:06,499 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:55:06,682 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-06 22:55:06,867 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:55:07,046 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:55:07,231 - INFO - training batch 251, loss: 0.019, 8032/28000 datapoints
2025-03-06 22:55:07,413 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:55:07,597 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-06 22:55:07,781 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:55:07,965 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:55:08,144 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:55:08,326 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:55:08,507 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:55:08,689 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:08,870 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 22:55:09,047 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:55:09,228 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:55:09,409 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:55:09,500 - INFO - validation batch 1, loss: 0.277, 32/6976 datapoints
2025-03-06 22:55:09,552 - INFO - validation batch 51, loss: 6.247, 1632/6976 datapoints
2025-03-06 22:55:09,604 - INFO - validation batch 101, loss: 0.910, 3232/6976 datapoints
2025-03-06 22:55:09,657 - INFO - validation batch 151, loss: 1.615, 4832/6976 datapoints
2025-03-06 22:55:09,712 - INFO - validation batch 201, loss: 3.290, 6432/6976 datapoints
2025-03-06 22:55:09,734 - INFO - Epoch 571/800 done.
2025-03-06 22:55:09,734 - INFO - Final validation performance:
Loss: 2.468, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:55:09,734 - INFO - Beginning epoch 572/800
2025-03-06 22:55:09,739 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-06 22:55:09,925 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:55:10,108 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:55:10,287 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:55:10,466 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:55:10,647 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 22:55:10,821 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 22:55:11,012 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:55:11,193 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:55:11,374 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:55:11,554 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:55:11,737 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:55:11,916 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:55:12,114 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:12,295 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:55:12,480 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:55:12,666 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:55:12,844 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:55:12,941 - INFO - validation batch 1, loss: 0.282, 32/6976 datapoints
2025-03-06 22:55:12,994 - INFO - validation batch 51, loss: 6.312, 1632/6976 datapoints
2025-03-06 22:55:13,045 - INFO - validation batch 101, loss: 0.930, 3232/6976 datapoints
2025-03-06 22:55:13,099 - INFO - validation batch 151, loss: 1.619, 4832/6976 datapoints
2025-03-06 22:55:13,151 - INFO - validation batch 201, loss: 3.174, 6432/6976 datapoints
2025-03-06 22:55:13,172 - INFO - Epoch 572/800 done.
2025-03-06 22:55:13,172 - INFO - Final validation performance:
Loss: 2.463, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:55:13,173 - INFO - Beginning epoch 573/800
2025-03-06 22:55:13,179 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-06 22:55:13,359 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:55:13,539 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:55:13,719 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:55:13,892 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:55:14,074 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 22:55:14,248 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:55:14,431 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:55:14,614 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:55:14,811 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:55:14,998 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:55:15,174 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:55:15,360 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:55:15,539 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:15,721 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:55:15,895 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:55:16,076 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:55:16,256 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:55:16,347 - INFO - validation batch 1, loss: 0.264, 32/6976 datapoints
2025-03-06 22:55:16,400 - INFO - validation batch 51, loss: 6.353, 1632/6976 datapoints
2025-03-06 22:55:16,453 - INFO - validation batch 101, loss: 0.938, 3232/6976 datapoints
2025-03-06 22:55:16,505 - INFO - validation batch 151, loss: 1.677, 4832/6976 datapoints
2025-03-06 22:55:16,558 - INFO - validation batch 201, loss: 3.193, 6432/6976 datapoints
2025-03-06 22:55:16,579 - INFO - Epoch 573/800 done.
2025-03-06 22:55:16,579 - INFO - Final validation performance:
Loss: 2.485, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:55:16,579 - INFO - Beginning epoch 574/800
2025-03-06 22:55:16,584 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:55:16,767 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:55:16,949 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:55:17,128 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:55:17,302 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:55:17,485 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 22:55:17,666 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:55:17,858 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:55:18,045 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:55:18,239 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:55:18,419 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:55:18,603 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:55:18,789 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:55:18,978 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:19,158 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:55:19,337 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:55:19,519 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:55:19,697 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:55:19,790 - INFO - validation batch 1, loss: 0.257, 32/6976 datapoints
2025-03-06 22:55:19,841 - INFO - validation batch 51, loss: 6.397, 1632/6976 datapoints
2025-03-06 22:55:19,895 - INFO - validation batch 101, loss: 0.931, 3232/6976 datapoints
2025-03-06 22:55:19,949 - INFO - validation batch 151, loss: 1.708, 4832/6976 datapoints
2025-03-06 22:55:20,004 - INFO - validation batch 201, loss: 3.198, 6432/6976 datapoints
2025-03-06 22:55:20,023 - INFO - Epoch 574/800 done.
2025-03-06 22:55:20,023 - INFO - Final validation performance:
Loss: 2.498, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:55:20,024 - INFO - Beginning epoch 575/800
2025-03-06 22:55:20,029 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:55:20,213 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:55:20,394 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:55:20,576 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:55:20,754 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:55:20,939 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:55:21,119 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:55:21,305 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:55:21,489 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:55:21,672 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:55:21,855 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:55:22,036 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:55:22,216 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:55:22,397 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:22,578 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:55:22,757 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:55:22,942 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:55:23,125 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:55:23,215 - INFO - validation batch 1, loss: 0.246, 32/6976 datapoints
2025-03-06 22:55:23,267 - INFO - validation batch 51, loss: 6.433, 1632/6976 datapoints
2025-03-06 22:55:23,318 - INFO - validation batch 101, loss: 0.902, 3232/6976 datapoints
2025-03-06 22:55:23,369 - INFO - validation batch 151, loss: 1.769, 4832/6976 datapoints
2025-03-06 22:55:23,418 - INFO - validation batch 201, loss: 3.174, 6432/6976 datapoints
2025-03-06 22:55:23,434 - INFO - Epoch 575/800 done.
2025-03-06 22:55:23,434 - INFO - Final validation performance:
Loss: 2.505, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:55:23,435 - INFO - Beginning epoch 576/800
2025-03-06 22:55:23,440 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:55:23,621 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:55:23,801 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:55:23,980 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:55:24,161 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:55:24,345 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:55:24,519 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:55:24,714 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:55:24,912 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:55:25,104 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:55:25,284 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:55:25,460 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:55:25,642 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:55:25,825 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:26,009 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:55:26,182 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:55:26,362 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:55:26,536 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:55:26,624 - INFO - validation batch 1, loss: 0.245, 32/6976 datapoints
2025-03-06 22:55:26,672 - INFO - validation batch 51, loss: 6.492, 1632/6976 datapoints
2025-03-06 22:55:26,719 - INFO - validation batch 101, loss: 0.880, 3232/6976 datapoints
2025-03-06 22:55:26,767 - INFO - validation batch 151, loss: 1.826, 4832/6976 datapoints
2025-03-06 22:55:26,816 - INFO - validation batch 201, loss: 3.247, 6432/6976 datapoints
2025-03-06 22:55:26,833 - INFO - Epoch 576/800 done.
2025-03-06 22:55:26,833 - INFO - Final validation performance:
Loss: 2.538, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:55:26,833 - INFO - Beginning epoch 577/800
2025-03-06 22:55:26,838 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:55:27,023 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:55:27,198 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-06 22:55:27,374 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:55:27,548 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:55:27,730 - INFO - training batch 251, loss: 0.198, 8032/28000 datapoints
2025-03-06 22:55:27,910 - INFO - training batch 301, loss: 0.046, 9632/28000 datapoints
2025-03-06 22:55:28,094 - INFO - training batch 351, loss: 0.056, 11232/28000 datapoints
2025-03-06 22:55:28,269 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:55:28,444 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:55:28,619 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-06 22:55:28,797 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 22:55:28,977 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:55:29,155 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:29,333 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 22:55:29,506 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:55:29,687 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 22:55:29,866 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:55:29,953 - INFO - validation batch 1, loss: 0.137, 32/6976 datapoints
2025-03-06 22:55:30,003 - INFO - validation batch 51, loss: 6.585, 1632/6976 datapoints
2025-03-06 22:55:30,053 - INFO - validation batch 101, loss: 0.932, 3232/6976 datapoints
2025-03-06 22:55:30,100 - INFO - validation batch 151, loss: 1.539, 4832/6976 datapoints
2025-03-06 22:55:30,148 - INFO - validation batch 201, loss: 3.379, 6432/6976 datapoints
2025-03-06 22:55:30,164 - INFO - Epoch 577/800 done.
2025-03-06 22:55:30,164 - INFO - Final validation performance:
Loss: 2.514, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:55:30,165 - INFO - Beginning epoch 578/800
2025-03-06 22:55:30,169 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:55:30,365 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:55:30,544 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:55:30,733 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-06 22:55:30,913 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:55:31,097 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 22:55:31,275 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:55:31,455 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:55:31,632 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:55:31,815 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:55:31,993 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:55:32,168 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:55:32,346 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:55:32,523 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:32,707 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:55:32,880 - INFO - training batch 751, loss: 0.024, 24032/28000 datapoints
2025-03-06 22:55:33,063 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 22:55:33,236 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:55:33,325 - INFO - validation batch 1, loss: 0.167, 32/6976 datapoints
2025-03-06 22:55:33,372 - INFO - validation batch 51, loss: 6.791, 1632/6976 datapoints
2025-03-06 22:55:33,419 - INFO - validation batch 101, loss: 1.106, 3232/6976 datapoints
2025-03-06 22:55:33,468 - INFO - validation batch 151, loss: 1.550, 4832/6976 datapoints
2025-03-06 22:55:33,516 - INFO - validation batch 201, loss: 3.311, 6432/6976 datapoints
2025-03-06 22:55:33,532 - INFO - Epoch 578/800 done.
2025-03-06 22:55:33,532 - INFO - Final validation performance:
Loss: 2.585, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:55:33,533 - INFO - Beginning epoch 579/800
2025-03-06 22:55:33,537 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:55:33,721 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:55:33,899 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:55:34,079 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:55:34,253 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:55:34,432 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 22:55:34,608 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:55:34,805 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:55:35,001 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:55:35,193 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:55:35,372 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 22:55:35,548 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:55:35,730 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:55:35,911 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:36,093 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:55:36,274 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:55:36,466 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:55:36,653 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:55:36,748 - INFO - validation batch 1, loss: 0.211, 32/6976 datapoints
2025-03-06 22:55:36,808 - INFO - validation batch 51, loss: 6.814, 1632/6976 datapoints
2025-03-06 22:55:36,877 - INFO - validation batch 101, loss: 1.071, 3232/6976 datapoints
2025-03-06 22:55:36,932 - INFO - validation batch 151, loss: 1.609, 4832/6976 datapoints
2025-03-06 22:55:36,987 - INFO - validation batch 201, loss: 3.335, 6432/6976 datapoints
2025-03-06 22:55:37,004 - INFO - Epoch 579/800 done.
2025-03-06 22:55:37,004 - INFO - Final validation performance:
Loss: 2.608, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:55:37,005 - INFO - Beginning epoch 580/800
2025-03-06 22:55:37,009 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 22:55:37,205 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:55:37,385 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:55:37,564 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:55:37,757 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:55:37,942 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 22:55:38,140 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:55:38,327 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:55:38,508 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:55:38,692 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:55:38,922 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:55:39,104 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:55:39,289 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:55:39,475 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:39,655 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:55:39,835 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:55:40,023 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:55:40,201 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:55:40,292 - INFO - validation batch 1, loss: 0.229, 32/6976 datapoints
2025-03-06 22:55:40,344 - INFO - validation batch 51, loss: 6.741, 1632/6976 datapoints
2025-03-06 22:55:40,395 - INFO - validation batch 101, loss: 1.048, 3232/6976 datapoints
2025-03-06 22:55:40,447 - INFO - validation batch 151, loss: 1.683, 4832/6976 datapoints
2025-03-06 22:55:40,499 - INFO - validation batch 201, loss: 3.220, 6432/6976 datapoints
2025-03-06 22:55:40,519 - INFO - Epoch 580/800 done.
2025-03-06 22:55:40,519 - INFO - Final validation performance:
Loss: 2.584, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:55:40,520 - INFO - Beginning epoch 581/800
2025-03-06 22:55:40,525 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-06 22:55:40,708 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:55:40,885 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:55:41,065 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:55:41,240 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:55:41,419 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 22:55:41,595 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:55:41,782 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:55:41,965 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:55:42,146 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:55:42,322 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:55:42,495 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:55:42,685 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:55:42,867 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:43,049 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:55:43,229 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:55:43,411 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:55:43,589 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:55:43,676 - INFO - validation batch 1, loss: 0.202, 32/6976 datapoints
2025-03-06 22:55:43,725 - INFO - validation batch 51, loss: 6.761, 1632/6976 datapoints
2025-03-06 22:55:43,773 - INFO - validation batch 101, loss: 1.021, 3232/6976 datapoints
2025-03-06 22:55:43,823 - INFO - validation batch 151, loss: 1.694, 4832/6976 datapoints
2025-03-06 22:55:43,870 - INFO - validation batch 201, loss: 3.250, 6432/6976 datapoints
2025-03-06 22:55:43,886 - INFO - Epoch 581/800 done.
2025-03-06 22:55:43,887 - INFO - Final validation performance:
Loss: 2.585, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:55:43,887 - INFO - Beginning epoch 582/800
2025-03-06 22:55:43,892 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:55:44,073 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:55:44,254 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:55:44,431 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:55:44,606 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:55:44,788 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:55:44,966 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:55:45,181 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:55:45,367 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:55:45,551 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:55:45,733 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:55:45,918 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:55:46,100 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:55:46,279 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:46,456 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:55:46,630 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:55:46,812 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:55:46,990 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:55:47,078 - INFO - validation batch 1, loss: 0.195, 32/6976 datapoints
2025-03-06 22:55:47,125 - INFO - validation batch 51, loss: 6.759, 1632/6976 datapoints
2025-03-06 22:55:47,173 - INFO - validation batch 101, loss: 0.997, 3232/6976 datapoints
2025-03-06 22:55:47,220 - INFO - validation batch 151, loss: 1.730, 4832/6976 datapoints
2025-03-06 22:55:47,269 - INFO - validation batch 201, loss: 3.246, 6432/6976 datapoints
2025-03-06 22:55:47,287 - INFO - Epoch 582/800 done.
2025-03-06 22:55:47,287 - INFO - Final validation performance:
Loss: 2.585, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:55:47,288 - INFO - Beginning epoch 583/800
2025-03-06 22:55:47,292 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:55:47,471 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:55:47,648 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:55:47,832 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:55:48,010 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:55:48,190 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:55:48,367 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:55:48,552 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:55:48,737 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:55:48,926 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:55:49,104 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:55:49,289 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:55:49,472 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:55:49,653 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:49,843 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:55:50,022 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:55:50,205 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:55:50,381 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:55:50,468 - INFO - validation batch 1, loss: 0.203, 32/6976 datapoints
2025-03-06 22:55:50,515 - INFO - validation batch 51, loss: 6.811, 1632/6976 datapoints
2025-03-06 22:55:50,562 - INFO - validation batch 101, loss: 0.965, 3232/6976 datapoints
2025-03-06 22:55:50,611 - INFO - validation batch 151, loss: 1.744, 4832/6976 datapoints
2025-03-06 22:55:50,658 - INFO - validation batch 201, loss: 3.232, 6432/6976 datapoints
2025-03-06 22:55:50,674 - INFO - Epoch 583/800 done.
2025-03-06 22:55:50,674 - INFO - Final validation performance:
Loss: 2.591, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:55:50,675 - INFO - Beginning epoch 584/800
2025-03-06 22:55:50,679 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:55:50,864 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:55:51,050 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:55:51,231 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:55:51,410 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:55:51,590 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:55:51,770 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:55:51,959 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:55:52,142 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:55:52,325 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:55:52,500 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:55:52,675 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:55:52,857 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:55:53,038 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:53,218 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:55:53,394 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:55:53,576 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:55:53,753 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:55:53,844 - INFO - validation batch 1, loss: 0.199, 32/6976 datapoints
2025-03-06 22:55:53,891 - INFO - validation batch 51, loss: 6.838, 1632/6976 datapoints
2025-03-06 22:55:53,938 - INFO - validation batch 101, loss: 0.924, 3232/6976 datapoints
2025-03-06 22:55:53,989 - INFO - validation batch 151, loss: 1.651, 4832/6976 datapoints
2025-03-06 22:55:54,054 - INFO - validation batch 201, loss: 3.221, 6432/6976 datapoints
2025-03-06 22:55:54,084 - INFO - Epoch 584/800 done.
2025-03-06 22:55:54,084 - INFO - Final validation performance:
Loss: 2.567, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:55:54,084 - INFO - Beginning epoch 585/800
2025-03-06 22:55:54,089 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:55:54,270 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-06 22:55:54,557 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:55:54,733 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:55:54,939 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-06 22:55:55,126 - INFO - training batch 251, loss: 0.014, 8032/28000 datapoints
2025-03-06 22:55:55,344 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:55:55,530 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:55:55,717 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:55:55,898 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:55:56,078 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:55:56,257 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:55:56,436 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:55:56,618 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:55:56,802 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:55:56,993 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:55:57,177 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 22:55:57,357 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:55:57,449 - INFO - validation batch 1, loss: 0.427, 32/6976 datapoints
2025-03-06 22:55:57,502 - INFO - validation batch 51, loss: 7.140, 1632/6976 datapoints
2025-03-06 22:55:57,554 - INFO - validation batch 101, loss: 0.871, 3232/6976 datapoints
2025-03-06 22:55:57,606 - INFO - validation batch 151, loss: 1.475, 4832/6976 datapoints
2025-03-06 22:55:57,658 - INFO - validation batch 201, loss: 3.215, 6432/6976 datapoints
2025-03-06 22:55:57,678 - INFO - Epoch 585/800 done.
2025-03-06 22:55:57,679 - INFO - Final validation performance:
Loss: 2.626, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:55:57,679 - INFO - Beginning epoch 586/800
2025-03-06 22:55:57,684 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-06 22:55:57,871 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 22:55:58,059 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:55:58,241 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:55:58,420 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:55:58,607 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:55:58,788 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:55:58,982 - INFO - training batch 351, loss: 0.024, 11232/28000 datapoints
2025-03-06 22:55:59,163 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:55:59,347 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 22:55:59,527 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:55:59,705 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-06 22:55:59,889 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:56:00,074 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:00,257 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:56:00,438 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-06 22:56:00,621 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 22:56:00,801 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:56:00,895 - INFO - validation batch 1, loss: 0.277, 32/6976 datapoints
2025-03-06 22:56:00,947 - INFO - validation batch 51, loss: 7.222, 1632/6976 datapoints
2025-03-06 22:56:01,004 - INFO - validation batch 101, loss: 1.044, 3232/6976 datapoints
2025-03-06 22:56:01,067 - INFO - validation batch 151, loss: 1.560, 4832/6976 datapoints
2025-03-06 22:56:01,129 - INFO - validation batch 201, loss: 3.292, 6432/6976 datapoints
2025-03-06 22:56:01,146 - INFO - Epoch 586/800 done.
2025-03-06 22:56:01,146 - INFO - Final validation performance:
Loss: 2.679, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:56:01,146 - INFO - Beginning epoch 587/800
2025-03-06 22:56:01,151 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:56:01,334 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:56:01,521 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:56:01,706 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:56:01,891 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:56:02,081 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:56:02,264 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:56:02,451 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:56:02,633 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:56:02,814 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:56:02,993 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:56:03,175 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-06 22:56:03,357 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:56:03,539 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:03,721 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:56:03,902 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:56:04,086 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:56:04,267 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 22:56:04,359 - INFO - validation batch 1, loss: 0.153, 32/6976 datapoints
2025-03-06 22:56:04,410 - INFO - validation batch 51, loss: 6.887, 1632/6976 datapoints
2025-03-06 22:56:04,463 - INFO - validation batch 101, loss: 0.961, 3232/6976 datapoints
2025-03-06 22:56:04,515 - INFO - validation batch 151, loss: 1.839, 4832/6976 datapoints
2025-03-06 22:56:04,568 - INFO - validation batch 201, loss: 3.040, 6432/6976 datapoints
2025-03-06 22:56:04,587 - INFO - Epoch 587/800 done.
2025-03-06 22:56:04,587 - INFO - Final validation performance:
Loss: 2.576, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:56:04,588 - INFO - Beginning epoch 588/800
2025-03-06 22:56:04,593 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:56:04,781 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:56:04,964 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:56:05,151 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-06 22:56:05,364 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:56:05,553 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:56:05,739 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:56:05,932 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:56:06,119 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:56:06,305 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:56:06,486 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 22:56:06,667 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:56:06,852 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:56:07,037 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 22:56:07,220 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:56:07,403 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:56:07,585 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:56:07,771 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:56:07,864 - INFO - validation batch 1, loss: 0.249, 32/6976 datapoints
2025-03-06 22:56:07,920 - INFO - validation batch 51, loss: 7.191, 1632/6976 datapoints
2025-03-06 22:56:07,973 - INFO - validation batch 101, loss: 1.027, 3232/6976 datapoints
2025-03-06 22:56:08,025 - INFO - validation batch 151, loss: 1.591, 4832/6976 datapoints
2025-03-06 22:56:08,072 - INFO - validation batch 201, loss: 3.121, 6432/6976 datapoints
2025-03-06 22:56:08,089 - INFO - Epoch 588/800 done.
2025-03-06 22:56:08,089 - INFO - Final validation performance:
Loss: 2.636, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:56:08,090 - INFO - Beginning epoch 589/800
2025-03-06 22:56:08,094 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:56:08,280 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:56:08,455 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:56:08,637 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:56:08,813 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:56:08,998 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:56:09,181 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-06 22:56:09,365 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:56:09,550 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:56:09,731 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:56:09,912 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:56:10,089 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:56:10,270 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:56:10,448 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:10,627 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:56:10,805 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:56:10,987 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:56:11,166 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:56:11,254 - INFO - validation batch 1, loss: 0.210, 32/6976 datapoints
2025-03-06 22:56:11,301 - INFO - validation batch 51, loss: 7.114, 1632/6976 datapoints
2025-03-06 22:56:11,350 - INFO - validation batch 101, loss: 1.037, 3232/6976 datapoints
2025-03-06 22:56:11,397 - INFO - validation batch 151, loss: 1.643, 4832/6976 datapoints
2025-03-06 22:56:11,444 - INFO - validation batch 201, loss: 3.183, 6432/6976 datapoints
2025-03-06 22:56:11,460 - INFO - Epoch 589/800 done.
2025-03-06 22:56:11,460 - INFO - Final validation performance:
Loss: 2.637, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:56:11,461 - INFO - Beginning epoch 590/800
2025-03-06 22:56:11,465 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:56:11,646 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:56:11,825 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:56:12,011 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:56:12,190 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 22:56:12,376 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:56:12,555 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:56:12,740 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:56:12,925 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:56:13,108 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:56:13,287 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:56:13,464 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:56:13,644 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:56:13,840 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:14,038 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:56:14,217 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:56:14,398 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:56:14,575 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:56:14,662 - INFO - validation batch 1, loss: 0.200, 32/6976 datapoints
2025-03-06 22:56:14,711 - INFO - validation batch 51, loss: 6.955, 1632/6976 datapoints
2025-03-06 22:56:14,758 - INFO - validation batch 101, loss: 1.029, 3232/6976 datapoints
2025-03-06 22:56:14,805 - INFO - validation batch 151, loss: 1.745, 4832/6976 datapoints
2025-03-06 22:56:14,858 - INFO - validation batch 201, loss: 3.222, 6432/6976 datapoints
2025-03-06 22:56:14,875 - INFO - Epoch 590/800 done.
2025-03-06 22:56:14,875 - INFO - Final validation performance:
Loss: 2.630, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:56:14,875 - INFO - Beginning epoch 591/800
2025-03-06 22:56:14,881 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:56:15,068 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:56:15,248 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:56:15,457 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:56:15,642 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:56:15,829 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:56:16,015 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:56:16,200 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:56:16,393 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:56:16,584 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:56:16,767 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:56:16,955 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:56:17,142 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:56:17,325 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:17,507 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:56:17,691 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:56:17,878 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:56:18,064 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:56:18,157 - INFO - validation batch 1, loss: 0.186, 32/6976 datapoints
2025-03-06 22:56:18,211 - INFO - validation batch 51, loss: 6.901, 1632/6976 datapoints
2025-03-06 22:56:18,266 - INFO - validation batch 101, loss: 1.010, 3232/6976 datapoints
2025-03-06 22:56:18,319 - INFO - validation batch 151, loss: 1.793, 4832/6976 datapoints
2025-03-06 22:56:18,372 - INFO - validation batch 201, loss: 3.250, 6432/6976 datapoints
2025-03-06 22:56:18,388 - INFO - Epoch 591/800 done.
2025-03-06 22:56:18,389 - INFO - Final validation performance:
Loss: 2.628, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:56:18,389 - INFO - Beginning epoch 592/800
2025-03-06 22:56:18,394 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:56:18,575 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:56:18,751 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:56:18,935 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:56:19,115 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:56:19,300 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:56:19,486 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:56:19,671 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:56:19,853 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:56:20,040 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:56:20,219 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:56:20,399 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:56:20,581 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:56:20,757 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:20,939 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:56:21,121 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:56:21,305 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:56:21,483 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:56:21,571 - INFO - validation batch 1, loss: 0.198, 32/6976 datapoints
2025-03-06 22:56:21,620 - INFO - validation batch 51, loss: 6.970, 1632/6976 datapoints
2025-03-06 22:56:21,667 - INFO - validation batch 101, loss: 0.989, 3232/6976 datapoints
2025-03-06 22:56:21,714 - INFO - validation batch 151, loss: 1.819, 4832/6976 datapoints
2025-03-06 22:56:21,763 - INFO - validation batch 201, loss: 3.252, 6432/6976 datapoints
2025-03-06 22:56:21,779 - INFO - Epoch 592/800 done.
2025-03-06 22:56:21,779 - INFO - Final validation performance:
Loss: 2.646, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:56:21,780 - INFO - Beginning epoch 593/800
2025-03-06 22:56:21,784 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:56:21,972 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:56:22,150 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:56:22,332 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:56:22,511 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 22:56:22,694 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:56:22,876 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:56:23,065 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:56:23,247 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:56:23,428 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:56:23,606 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:56:23,783 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:56:23,968 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:56:24,147 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:24,330 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:56:24,518 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:56:24,700 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:56:24,903 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:56:25,001 - INFO - validation batch 1, loss: 0.172, 32/6976 datapoints
2025-03-06 22:56:25,050 - INFO - validation batch 51, loss: 6.997, 1632/6976 datapoints
2025-03-06 22:56:25,100 - INFO - validation batch 101, loss: 0.920, 3232/6976 datapoints
2025-03-06 22:56:25,147 - INFO - validation batch 151, loss: 1.976, 4832/6976 datapoints
2025-03-06 22:56:25,194 - INFO - validation batch 201, loss: 3.216, 6432/6976 datapoints
2025-03-06 22:56:25,211 - INFO - Epoch 593/800 done.
2025-03-06 22:56:25,211 - INFO - Final validation performance:
Loss: 2.656, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:56:25,211 - INFO - Beginning epoch 594/800
2025-03-06 22:56:25,216 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:56:25,418 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:56:25,621 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:56:25,804 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:56:25,990 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:56:26,175 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:56:26,358 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:56:26,545 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:56:26,726 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:56:26,907 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:56:27,087 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:56:27,267 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:56:27,449 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:56:27,625 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:27,806 - INFO - training batch 701, loss: 0.124, 22432/28000 datapoints
2025-03-06 22:56:28,000 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 22:56:28,186 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-06 22:56:28,364 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-06 22:56:28,453 - INFO - validation batch 1, loss: 0.118, 32/6976 datapoints
2025-03-06 22:56:28,501 - INFO - validation batch 51, loss: 6.745, 1632/6976 datapoints
2025-03-06 22:56:28,549 - INFO - validation batch 101, loss: 0.751, 3232/6976 datapoints
2025-03-06 22:56:28,597 - INFO - validation batch 151, loss: 2.065, 4832/6976 datapoints
2025-03-06 22:56:28,644 - INFO - validation batch 201, loss: 3.487, 6432/6976 datapoints
2025-03-06 22:56:28,660 - INFO - Epoch 594/800 done.
2025-03-06 22:56:28,660 - INFO - Final validation performance:
Loss: 2.633, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:56:28,661 - INFO - Beginning epoch 595/800
2025-03-06 22:56:28,666 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:56:28,850 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 22:56:29,033 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:56:29,219 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:56:29,402 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:56:29,585 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-06 22:56:29,764 - INFO - training batch 301, loss: 0.021, 9632/28000 datapoints
2025-03-06 22:56:29,948 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 22:56:30,133 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:56:30,313 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:56:30,503 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:56:30,683 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-06 22:56:30,864 - INFO - training batch 601, loss: 0.015, 19232/28000 datapoints
2025-03-06 22:56:31,046 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:31,239 - INFO - training batch 701, loss: 0.010, 22432/28000 datapoints
2025-03-06 22:56:31,420 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:56:31,610 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:56:31,791 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:56:31,881 - INFO - validation batch 1, loss: 0.198, 32/6976 datapoints
2025-03-06 22:56:31,931 - INFO - validation batch 51, loss: 6.852, 1632/6976 datapoints
2025-03-06 22:56:31,981 - INFO - validation batch 101, loss: 0.953, 3232/6976 datapoints
2025-03-06 22:56:32,032 - INFO - validation batch 151, loss: 1.761, 4832/6976 datapoints
2025-03-06 22:56:32,080 - INFO - validation batch 201, loss: 3.539, 6432/6976 datapoints
2025-03-06 22:56:32,096 - INFO - Epoch 595/800 done.
2025-03-06 22:56:32,096 - INFO - Final validation performance:
Loss: 2.661, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:56:32,097 - INFO - Beginning epoch 596/800
2025-03-06 22:56:32,101 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:56:32,285 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:56:32,465 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:56:32,648 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:56:32,827 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 22:56:33,018 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 22:56:33,202 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:56:33,387 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:56:33,568 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:56:33,749 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:56:33,927 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:56:34,112 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:56:34,294 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-06 22:56:34,476 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 22:56:34,657 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:56:34,836 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:56:35,026 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:56:35,206 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-06 22:56:35,296 - INFO - validation batch 1, loss: 0.334, 32/6976 datapoints
2025-03-06 22:56:35,345 - INFO - validation batch 51, loss: 6.805, 1632/6976 datapoints
2025-03-06 22:56:35,395 - INFO - validation batch 101, loss: 1.030, 3232/6976 datapoints
2025-03-06 22:56:35,445 - INFO - validation batch 151, loss: 1.670, 4832/6976 datapoints
2025-03-06 22:56:35,494 - INFO - validation batch 201, loss: 3.321, 6432/6976 datapoints
2025-03-06 22:56:35,510 - INFO - Epoch 596/800 done.
2025-03-06 22:56:35,510 - INFO - Final validation performance:
Loss: 2.632, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:56:35,511 - INFO - Beginning epoch 597/800
2025-03-06 22:56:35,516 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:56:35,728 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:56:35,906 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:56:36,096 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:56:36,274 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:56:36,459 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:56:36,648 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 22:56:36,838 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:56:37,041 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 22:56:37,227 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:56:37,411 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 22:56:37,596 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:56:37,783 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:56:37,966 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:38,171 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:56:38,373 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:56:38,562 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:56:38,743 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 22:56:38,835 - INFO - validation batch 1, loss: 0.244, 32/6976 datapoints
2025-03-06 22:56:38,888 - INFO - validation batch 51, loss: 6.804, 1632/6976 datapoints
2025-03-06 22:56:38,939 - INFO - validation batch 101, loss: 0.942, 3232/6976 datapoints
2025-03-06 22:56:38,993 - INFO - validation batch 151, loss: 1.560, 4832/6976 datapoints
2025-03-06 22:56:39,047 - INFO - validation batch 201, loss: 3.495, 6432/6976 datapoints
2025-03-06 22:56:39,064 - INFO - Epoch 597/800 done.
2025-03-06 22:56:39,065 - INFO - Final validation performance:
Loss: 2.609, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:56:39,065 - INFO - Beginning epoch 598/800
2025-03-06 22:56:39,071 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:56:39,266 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:56:39,484 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:56:39,669 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:56:39,848 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-06 22:56:40,052 - INFO - training batch 251, loss: 0.052, 8032/28000 datapoints
2025-03-06 22:56:40,236 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:56:40,426 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:56:40,608 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:56:40,788 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:56:41,020 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:56:41,244 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:56:41,429 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:56:41,615 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:41,799 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:56:41,988 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:56:42,175 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:56:42,356 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:56:42,444 - INFO - validation batch 1, loss: 0.231, 32/6976 datapoints
2025-03-06 22:56:42,492 - INFO - validation batch 51, loss: 7.132, 1632/6976 datapoints
2025-03-06 22:56:42,540 - INFO - validation batch 101, loss: 1.000, 3232/6976 datapoints
2025-03-06 22:56:42,588 - INFO - validation batch 151, loss: 1.651, 4832/6976 datapoints
2025-03-06 22:56:42,636 - INFO - validation batch 201, loss: 3.537, 6432/6976 datapoints
2025-03-06 22:56:42,652 - INFO - Epoch 598/800 done.
2025-03-06 22:56:42,652 - INFO - Final validation performance:
Loss: 2.710, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:56:42,653 - INFO - Beginning epoch 599/800
2025-03-06 22:56:42,658 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-06 22:56:42,843 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:56:43,027 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:56:43,226 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:56:43,406 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:56:43,589 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:56:43,773 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:56:43,965 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:56:44,167 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:56:44,351 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:56:44,531 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:56:44,716 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:56:44,897 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:56:45,080 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:45,269 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:56:45,453 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:56:45,637 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:56:45,846 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:56:45,936 - INFO - validation batch 1, loss: 0.237, 32/6976 datapoints
2025-03-06 22:56:45,986 - INFO - validation batch 51, loss: 7.072, 1632/6976 datapoints
2025-03-06 22:56:46,035 - INFO - validation batch 101, loss: 0.964, 3232/6976 datapoints
2025-03-06 22:56:46,084 - INFO - validation batch 151, loss: 1.762, 4832/6976 datapoints
2025-03-06 22:56:46,134 - INFO - validation batch 201, loss: 3.381, 6432/6976 datapoints
2025-03-06 22:56:46,151 - INFO - Epoch 599/800 done.
2025-03-06 22:56:46,151 - INFO - Final validation performance:
Loss: 2.683, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:56:46,151 - INFO - Beginning epoch 600/800
2025-03-06 22:56:46,156 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:56:46,343 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:56:46,525 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:56:46,709 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:56:46,893 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:56:47,089 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:56:47,277 - INFO - training batch 301, loss: 0.089, 9632/28000 datapoints
2025-03-06 22:56:47,473 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 22:56:47,655 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:56:47,835 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:56:48,016 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 22:56:48,197 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-06 22:56:48,376 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:56:48,554 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:48,732 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:56:48,909 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:56:49,094 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:56:49,274 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:56:49,365 - INFO - validation batch 1, loss: 0.316, 32/6976 datapoints
2025-03-06 22:56:49,416 - INFO - validation batch 51, loss: 7.140, 1632/6976 datapoints
2025-03-06 22:56:49,463 - INFO - validation batch 101, loss: 0.877, 3232/6976 datapoints
2025-03-06 22:56:49,510 - INFO - validation batch 151, loss: 1.677, 4832/6976 datapoints
2025-03-06 22:56:49,557 - INFO - validation batch 201, loss: 3.398, 6432/6976 datapoints
2025-03-06 22:56:49,573 - INFO - Epoch 600/800 done.
2025-03-06 22:56:49,574 - INFO - Final validation performance:
Loss: 2.682, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:56:49,574 - INFO - Beginning epoch 601/800
2025-03-06 22:56:49,579 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:56:49,763 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:56:49,941 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:56:50,129 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:56:50,307 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-06 22:56:50,493 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:56:50,676 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:56:50,862 - INFO - training batch 351, loss: 0.028, 11232/28000 datapoints
2025-03-06 22:56:51,045 - INFO - training batch 401, loss: 0.010, 12832/28000 datapoints
2025-03-06 22:56:51,229 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:56:51,409 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 22:56:51,588 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:56:51,768 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:56:51,946 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:52,132 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:56:52,315 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:56:52,499 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:56:52,678 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-06 22:56:52,767 - INFO - validation batch 1, loss: 0.267, 32/6976 datapoints
2025-03-06 22:56:52,815 - INFO - validation batch 51, loss: 7.289, 1632/6976 datapoints
2025-03-06 22:56:52,862 - INFO - validation batch 101, loss: 1.008, 3232/6976 datapoints
2025-03-06 22:56:52,910 - INFO - validation batch 151, loss: 1.647, 4832/6976 datapoints
2025-03-06 22:56:52,958 - INFO - validation batch 201, loss: 3.224, 6432/6976 datapoints
2025-03-06 22:56:52,978 - INFO - Epoch 601/800 done.
2025-03-06 22:56:52,978 - INFO - Final validation performance:
Loss: 2.687, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:56:52,979 - INFO - Beginning epoch 602/800
2025-03-06 22:56:52,984 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:56:53,169 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:56:53,349 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:56:53,530 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:56:53,709 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:56:53,893 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:56:54,082 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:56:54,270 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:56:54,454 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 22:56:54,634 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:56:54,813 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:56:54,991 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:56:55,179 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:56:55,367 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:55,548 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:56:55,731 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-06 22:56:55,937 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:56:56,123 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:56:56,212 - INFO - validation batch 1, loss: 0.258, 32/6976 datapoints
2025-03-06 22:56:56,261 - INFO - validation batch 51, loss: 7.282, 1632/6976 datapoints
2025-03-06 22:56:56,308 - INFO - validation batch 101, loss: 1.007, 3232/6976 datapoints
2025-03-06 22:56:56,358 - INFO - validation batch 151, loss: 1.687, 4832/6976 datapoints
2025-03-06 22:56:56,407 - INFO - validation batch 201, loss: 3.250, 6432/6976 datapoints
2025-03-06 22:56:56,425 - INFO - Epoch 602/800 done.
2025-03-06 22:56:56,425 - INFO - Final validation performance:
Loss: 2.697, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:56:56,425 - INFO - Beginning epoch 603/800
2025-03-06 22:56:56,430 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 22:56:56,613 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:56:56,797 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:56:56,988 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:56:57,169 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:56:57,363 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:56:57,550 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:56:57,740 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:56:57,923 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:56:58,114 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:56:58,296 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:56:58,476 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:56:58,659 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:56:58,842 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:56:59,030 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:56:59,213 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:56:59,406 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:56:59,588 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:56:59,682 - INFO - validation batch 1, loss: 0.208, 32/6976 datapoints
2025-03-06 22:56:59,733 - INFO - validation batch 51, loss: 7.204, 1632/6976 datapoints
2025-03-06 22:56:59,786 - INFO - validation batch 101, loss: 1.036, 3232/6976 datapoints
2025-03-06 22:56:59,839 - INFO - validation batch 151, loss: 1.743, 4832/6976 datapoints
2025-03-06 22:56:59,892 - INFO - validation batch 201, loss: 3.316, 6432/6976 datapoints
2025-03-06 22:56:59,909 - INFO - Epoch 603/800 done.
2025-03-06 22:56:59,909 - INFO - Final validation performance:
Loss: 2.701, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:56:59,909 - INFO - Beginning epoch 604/800
2025-03-06 22:56:59,915 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:57:00,109 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:57:00,292 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:57:00,478 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:57:00,660 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:57:00,849 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:57:01,038 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:57:01,227 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:57:01,411 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:57:01,594 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:57:01,776 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:57:01,957 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:57:02,154 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:57:02,338 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:02,524 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:57:02,707 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:57:02,896 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:57:03,081 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:57:03,174 - INFO - validation batch 1, loss: 0.203, 32/6976 datapoints
2025-03-06 22:57:03,226 - INFO - validation batch 51, loss: 7.159, 1632/6976 datapoints
2025-03-06 22:57:03,279 - INFO - validation batch 101, loss: 1.021, 3232/6976 datapoints
2025-03-06 22:57:03,334 - INFO - validation batch 151, loss: 1.809, 4832/6976 datapoints
2025-03-06 22:57:03,387 - INFO - validation batch 201, loss: 3.355, 6432/6976 datapoints
2025-03-06 22:57:03,405 - INFO - Epoch 604/800 done.
2025-03-06 22:57:03,405 - INFO - Final validation performance:
Loss: 2.709, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:57:03,406 - INFO - Beginning epoch 605/800
2025-03-06 22:57:03,410 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:57:03,598 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:57:03,777 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:57:03,968 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:57:04,156 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:57:04,345 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:57:04,533 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:57:04,723 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:57:04,908 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:57:05,096 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:57:05,286 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:57:05,470 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:57:05,654 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:57:05,837 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:06,050 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:57:06,238 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:57:06,425 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:57:06,608 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:57:06,702 - INFO - validation batch 1, loss: 0.200, 32/6976 datapoints
2025-03-06 22:57:06,754 - INFO - validation batch 51, loss: 7.125, 1632/6976 datapoints
2025-03-06 22:57:06,806 - INFO - validation batch 101, loss: 0.997, 3232/6976 datapoints
2025-03-06 22:57:06,858 - INFO - validation batch 151, loss: 1.852, 4832/6976 datapoints
2025-03-06 22:57:06,914 - INFO - validation batch 201, loss: 3.374, 6432/6976 datapoints
2025-03-06 22:57:06,934 - INFO - Epoch 605/800 done.
2025-03-06 22:57:06,934 - INFO - Final validation performance:
Loss: 2.709, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:57:06,934 - INFO - Beginning epoch 606/800
2025-03-06 22:57:06,939 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:57:07,160 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:57:07,390 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:57:07,579 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:57:07,765 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:57:07,955 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:57:08,151 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:57:08,365 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:57:08,556 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:57:08,741 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:57:08,934 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:57:09,125 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:57:09,314 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:57:09,504 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:09,689 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:57:09,881 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:57:10,072 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:57:10,257 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:57:10,352 - INFO - validation batch 1, loss: 0.216, 32/6976 datapoints
2025-03-06 22:57:10,408 - INFO - validation batch 51, loss: 7.171, 1632/6976 datapoints
2025-03-06 22:57:10,461 - INFO - validation batch 101, loss: 0.974, 3232/6976 datapoints
2025-03-06 22:57:10,514 - INFO - validation batch 151, loss: 1.912, 4832/6976 datapoints
2025-03-06 22:57:10,566 - INFO - validation batch 201, loss: 3.376, 6432/6976 datapoints
2025-03-06 22:57:10,586 - INFO - Epoch 606/800 done.
2025-03-06 22:57:10,587 - INFO - Final validation performance:
Loss: 2.730, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:57:10,587 - INFO - Beginning epoch 607/800
2025-03-06 22:57:10,592 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:57:10,777 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:57:10,962 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:57:11,162 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:57:11,352 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:57:11,542 - INFO - training batch 251, loss: 0.116, 8032/28000 datapoints
2025-03-06 22:57:11,733 - INFO - training batch 301, loss: 0.038, 9632/28000 datapoints
2025-03-06 22:57:11,926 - INFO - training batch 351, loss: 0.070, 11232/28000 datapoints
2025-03-06 22:57:12,114 - INFO - training batch 401, loss: 0.012, 12832/28000 datapoints
2025-03-06 22:57:12,302 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-06 22:57:12,485 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:57:12,668 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:57:12,858 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:57:13,061 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:13,245 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-06 22:57:13,432 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:57:13,621 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:57:13,835 - INFO - training batch 851, loss: 0.013, 27232/28000 datapoints
2025-03-06 22:57:13,928 - INFO - validation batch 1, loss: 0.195, 32/6976 datapoints
2025-03-06 22:57:13,985 - INFO - validation batch 51, loss: 7.100, 1632/6976 datapoints
2025-03-06 22:57:14,036 - INFO - validation batch 101, loss: 1.113, 3232/6976 datapoints
2025-03-06 22:57:14,089 - INFO - validation batch 151, loss: 1.453, 4832/6976 datapoints
2025-03-06 22:57:14,140 - INFO - validation batch 201, loss: 3.519, 6432/6976 datapoints
2025-03-06 22:57:14,165 - INFO - Epoch 607/800 done.
2025-03-06 22:57:14,165 - INFO - Final validation performance:
Loss: 2.676, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:57:14,165 - INFO - Beginning epoch 608/800
2025-03-06 22:57:14,170 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:57:14,367 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 22:57:14,557 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-06 22:57:14,736 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:57:14,925 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:57:15,127 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 22:57:15,330 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:57:15,515 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:57:15,699 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:57:15,884 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:57:16,088 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:57:16,275 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:57:16,459 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:57:16,637 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:16,827 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:57:17,022 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-06 22:57:17,206 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:57:17,390 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:57:17,490 - INFO - validation batch 1, loss: 0.193, 32/6976 datapoints
2025-03-06 22:57:17,542 - INFO - validation batch 51, loss: 7.128, 1632/6976 datapoints
2025-03-06 22:57:17,594 - INFO - validation batch 101, loss: 1.111, 3232/6976 datapoints
2025-03-06 22:57:17,649 - INFO - validation batch 151, loss: 1.735, 4832/6976 datapoints
2025-03-06 22:57:17,701 - INFO - validation batch 201, loss: 3.385, 6432/6976 datapoints
2025-03-06 22:57:17,720 - INFO - Epoch 608/800 done.
2025-03-06 22:57:17,720 - INFO - Final validation performance:
Loss: 2.710, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:57:17,720 - INFO - Beginning epoch 609/800
2025-03-06 22:57:17,726 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:57:17,919 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:57:18,106 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:57:18,302 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:57:18,485 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:57:18,689 - INFO - training batch 251, loss: 0.050, 8032/28000 datapoints
2025-03-06 22:57:18,875 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 22:57:19,066 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:57:19,256 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:57:19,444 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:57:19,629 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:57:19,809 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:57:19,996 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:57:20,182 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:20,365 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:57:20,571 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:57:20,766 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:57:20,949 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:57:21,047 - INFO - validation batch 1, loss: 0.264, 32/6976 datapoints
2025-03-06 22:57:21,103 - INFO - validation batch 51, loss: 7.418, 1632/6976 datapoints
2025-03-06 22:57:21,158 - INFO - validation batch 101, loss: 1.156, 3232/6976 datapoints
2025-03-06 22:57:21,211 - INFO - validation batch 151, loss: 1.778, 4832/6976 datapoints
2025-03-06 22:57:21,269 - INFO - validation batch 201, loss: 3.272, 6432/6976 datapoints
2025-03-06 22:57:21,289 - INFO - Epoch 609/800 done.
2025-03-06 22:57:21,290 - INFO - Final validation performance:
Loss: 2.778, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:57:21,290 - INFO - Beginning epoch 610/800
2025-03-06 22:57:21,296 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:57:21,501 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-06 22:57:21,691 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:57:21,885 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:57:22,072 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:57:22,266 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:57:22,456 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-06 22:57:22,648 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:57:22,834 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:57:23,022 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 22:57:23,217 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:57:23,397 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:57:23,584 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:57:23,764 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:23,950 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:57:24,138 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:57:24,326 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:57:24,514 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:57:24,609 - INFO - validation batch 1, loss: 0.230, 32/6976 datapoints
2025-03-06 22:57:24,661 - INFO - validation batch 51, loss: 7.288, 1632/6976 datapoints
2025-03-06 22:57:24,714 - INFO - validation batch 101, loss: 1.128, 3232/6976 datapoints
2025-03-06 22:57:24,767 - INFO - validation batch 151, loss: 1.785, 4832/6976 datapoints
2025-03-06 22:57:24,820 - INFO - validation batch 201, loss: 3.318, 6432/6976 datapoints
2025-03-06 22:57:24,839 - INFO - Epoch 610/800 done.
2025-03-06 22:57:24,840 - INFO - Final validation performance:
Loss: 2.750, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:57:24,840 - INFO - Beginning epoch 611/800
2025-03-06 22:57:24,845 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:57:25,035 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:57:25,240 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:57:25,432 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:57:25,619 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:57:25,810 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:57:26,004 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:57:26,224 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:57:26,407 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:57:26,596 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:57:26,792 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:57:26,973 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:57:27,161 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:57:27,350 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:27,537 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:57:27,730 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:57:27,914 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:57:28,100 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:57:28,195 - INFO - validation batch 1, loss: 0.192, 32/6976 datapoints
2025-03-06 22:57:28,251 - INFO - validation batch 51, loss: 7.228, 1632/6976 datapoints
2025-03-06 22:57:28,303 - INFO - validation batch 101, loss: 1.098, 3232/6976 datapoints
2025-03-06 22:57:28,356 - INFO - validation batch 151, loss: 1.846, 4832/6976 datapoints
2025-03-06 22:57:28,410 - INFO - validation batch 201, loss: 3.321, 6432/6976 datapoints
2025-03-06 22:57:28,430 - INFO - Epoch 611/800 done.
2025-03-06 22:57:28,430 - INFO - Final validation performance:
Loss: 2.737, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:57:28,431 - INFO - Beginning epoch 612/800
2025-03-06 22:57:28,436 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:57:28,628 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:57:28,807 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:57:28,999 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:57:29,187 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:57:29,378 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:57:29,570 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:57:29,760 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:57:29,944 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:57:30,132 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:57:30,318 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:57:30,501 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:57:30,687 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:57:30,869 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:31,058 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:57:31,251 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:57:31,436 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:57:31,620 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:57:31,715 - INFO - validation batch 1, loss: 0.172, 32/6976 datapoints
2025-03-06 22:57:31,767 - INFO - validation batch 51, loss: 7.161, 1632/6976 datapoints
2025-03-06 22:57:31,819 - INFO - validation batch 101, loss: 1.068, 3232/6976 datapoints
2025-03-06 22:57:31,872 - INFO - validation batch 151, loss: 1.918, 4832/6976 datapoints
2025-03-06 22:57:31,920 - INFO - validation batch 201, loss: 3.341, 6432/6976 datapoints
2025-03-06 22:57:31,937 - INFO - Epoch 612/800 done.
2025-03-06 22:57:31,937 - INFO - Final validation performance:
Loss: 2.732, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:57:31,937 - INFO - Beginning epoch 613/800
2025-03-06 22:57:31,942 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:57:32,130 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:57:32,314 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:57:32,499 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:57:32,688 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:57:32,888 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:57:33,078 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:57:33,267 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:57:33,457 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:57:33,644 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:57:33,832 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:57:34,014 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:57:34,198 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:57:34,378 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:34,562 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:57:34,749 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:57:34,932 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:57:35,120 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:57:35,211 - INFO - validation batch 1, loss: 0.164, 32/6976 datapoints
2025-03-06 22:57:35,274 - INFO - validation batch 51, loss: 7.150, 1632/6976 datapoints
2025-03-06 22:57:35,322 - INFO - validation batch 101, loss: 1.036, 3232/6976 datapoints
2025-03-06 22:57:35,370 - INFO - validation batch 151, loss: 1.972, 4832/6976 datapoints
2025-03-06 22:57:35,419 - INFO - validation batch 201, loss: 3.367, 6432/6976 datapoints
2025-03-06 22:57:35,436 - INFO - Epoch 613/800 done.
2025-03-06 22:57:35,436 - INFO - Final validation performance:
Loss: 2.738, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:57:35,437 - INFO - Beginning epoch 614/800
2025-03-06 22:57:35,441 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:57:35,628 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:57:35,808 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:57:35,995 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:57:36,178 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:57:36,393 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:57:36,582 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:57:36,770 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:57:36,957 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:57:37,149 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:57:37,337 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:57:37,520 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:57:37,707 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:57:37,892 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:38,094 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:57:38,286 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:57:38,472 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:57:38,669 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:57:38,777 - INFO - validation batch 1, loss: 0.176, 32/6976 datapoints
2025-03-06 22:57:38,830 - INFO - validation batch 51, loss: 7.175, 1632/6976 datapoints
2025-03-06 22:57:38,885 - INFO - validation batch 101, loss: 0.983, 3232/6976 datapoints
2025-03-06 22:57:38,937 - INFO - validation batch 151, loss: 2.038, 4832/6976 datapoints
2025-03-06 22:57:38,993 - INFO - validation batch 201, loss: 3.387, 6432/6976 datapoints
2025-03-06 22:57:39,012 - INFO - Epoch 614/800 done.
2025-03-06 22:57:39,013 - INFO - Final validation performance:
Loss: 2.752, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:57:39,014 - INFO - Beginning epoch 615/800
2025-03-06 22:57:39,020 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:57:39,212 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:57:39,404 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:57:39,598 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:57:39,814 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:57:40,013 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:57:40,203 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:57:40,398 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:57:40,584 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:57:40,771 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:57:40,956 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:57:41,141 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:57:41,329 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 22:57:41,512 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:41,697 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:57:41,882 - INFO - training batch 751, loss: 0.463, 24032/28000 datapoints
2025-03-06 22:57:42,074 - INFO - training batch 801, loss: 0.050, 25632/28000 datapoints
2025-03-06 22:57:42,260 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-06 22:57:42,356 - INFO - validation batch 1, loss: 0.278, 32/6976 datapoints
2025-03-06 22:57:42,408 - INFO - validation batch 51, loss: 6.985, 1632/6976 datapoints
2025-03-06 22:57:42,461 - INFO - validation batch 101, loss: 0.738, 3232/6976 datapoints
2025-03-06 22:57:42,515 - INFO - validation batch 151, loss: 2.143, 4832/6976 datapoints
2025-03-06 22:57:42,570 - INFO - validation batch 201, loss: 3.181, 6432/6976 datapoints
2025-03-06 22:57:42,590 - INFO - Epoch 615/800 done.
2025-03-06 22:57:42,590 - INFO - Final validation performance:
Loss: 2.665, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:57:42,591 - INFO - Beginning epoch 616/800
2025-03-06 22:57:42,596 - INFO - training batch 1, loss: 0.070, 32/28000 datapoints
2025-03-06 22:57:42,790 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:57:42,973 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:57:43,165 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 22:57:43,353 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 22:57:43,548 - INFO - training batch 251, loss: 0.012, 8032/28000 datapoints
2025-03-06 22:57:43,739 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:57:43,930 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 22:57:44,116 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:57:44,308 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:57:44,490 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:57:44,675 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 22:57:44,866 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:57:45,052 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:45,245 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:57:45,445 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:57:45,634 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:57:45,831 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:57:45,929 - INFO - validation batch 1, loss: 0.394, 32/6976 datapoints
2025-03-06 22:57:45,983 - INFO - validation batch 51, loss: 7.495, 1632/6976 datapoints
2025-03-06 22:57:46,035 - INFO - validation batch 101, loss: 1.017, 3232/6976 datapoints
2025-03-06 22:57:46,087 - INFO - validation batch 151, loss: 1.828, 4832/6976 datapoints
2025-03-06 22:57:46,143 - INFO - validation batch 201, loss: 3.269, 6432/6976 datapoints
2025-03-06 22:57:46,159 - INFO - Epoch 616/800 done.
2025-03-06 22:57:46,159 - INFO - Final validation performance:
Loss: 2.801, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:57:46,160 - INFO - Beginning epoch 617/800
2025-03-06 22:57:46,165 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:57:46,382 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:57:46,568 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 22:57:46,758 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:57:46,948 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:57:47,141 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:57:47,335 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:57:47,525 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:57:47,713 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-06 22:57:47,905 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:57:48,091 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 22:57:48,282 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:57:48,471 - INFO - training batch 601, loss: 0.181, 19232/28000 datapoints
2025-03-06 22:57:48,657 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:48,842 - INFO - training batch 701, loss: 0.010, 22432/28000 datapoints
2025-03-06 22:57:49,032 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:57:49,227 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:57:49,411 - INFO - training batch 851, loss: 0.025, 27232/28000 datapoints
2025-03-06 22:57:49,520 - INFO - validation batch 1, loss: 0.266, 32/6976 datapoints
2025-03-06 22:57:49,585 - INFO - validation batch 51, loss: 7.611, 1632/6976 datapoints
2025-03-06 22:57:49,636 - INFO - validation batch 101, loss: 1.057, 3232/6976 datapoints
2025-03-06 22:57:49,688 - INFO - validation batch 151, loss: 2.151, 4832/6976 datapoints
2025-03-06 22:57:49,740 - INFO - validation batch 201, loss: 3.540, 6432/6976 datapoints
2025-03-06 22:57:49,756 - INFO - Epoch 617/800 done.
2025-03-06 22:57:49,756 - INFO - Final validation performance:
Loss: 2.925, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 22:57:49,757 - INFO - Beginning epoch 618/800
2025-03-06 22:57:49,761 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-06 22:57:49,953 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 22:57:50,134 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:57:50,329 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:57:50,519 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 22:57:50,708 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-06 22:57:50,901 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:57:51,105 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 22:57:51,292 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:57:51,494 - INFO - training batch 451, loss: 0.022, 14432/28000 datapoints
2025-03-06 22:57:51,683 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:57:51,873 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:57:52,067 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:57:52,254 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:52,442 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:57:52,631 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:57:52,815 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:57:53,005 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:57:53,130 - INFO - validation batch 1, loss: 0.334, 32/6976 datapoints
2025-03-06 22:57:53,183 - INFO - validation batch 51, loss: 7.662, 1632/6976 datapoints
2025-03-06 22:57:53,237 - INFO - validation batch 101, loss: 1.016, 3232/6976 datapoints
2025-03-06 22:57:53,294 - INFO - validation batch 151, loss: 1.609, 4832/6976 datapoints
2025-03-06 22:57:53,347 - INFO - validation batch 201, loss: 3.337, 6432/6976 datapoints
2025-03-06 22:57:53,364 - INFO - Epoch 618/800 done.
2025-03-06 22:57:53,365 - INFO - Final validation performance:
Loss: 2.791, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:57:53,365 - INFO - Beginning epoch 619/800
2025-03-06 22:57:53,371 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:57:53,561 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:57:53,743 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:57:53,928 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:57:54,117 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:57:54,309 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:57:54,497 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:57:54,681 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:57:54,862 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:57:55,050 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:57:55,236 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 22:57:55,425 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:57:55,609 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:57:55,790 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:55,973 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:57:56,165 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:57:56,356 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:57:56,565 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:57:56,657 - INFO - validation batch 1, loss: 0.294, 32/6976 datapoints
2025-03-06 22:57:56,706 - INFO - validation batch 51, loss: 7.530, 1632/6976 datapoints
2025-03-06 22:57:56,754 - INFO - validation batch 101, loss: 1.074, 3232/6976 datapoints
2025-03-06 22:57:56,802 - INFO - validation batch 151, loss: 1.690, 4832/6976 datapoints
2025-03-06 22:57:56,850 - INFO - validation batch 201, loss: 3.321, 6432/6976 datapoints
2025-03-06 22:57:56,867 - INFO - Epoch 619/800 done.
2025-03-06 22:57:56,867 - INFO - Final validation performance:
Loss: 2.782, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:57:56,867 - INFO - Beginning epoch 620/800
2025-03-06 22:57:56,872 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:57:57,082 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:57:57,260 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:57:57,466 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:57:57,655 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:57:57,851 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:57:58,052 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:57:58,252 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:57:58,440 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:57:58,630 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:57:58,817 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 22:57:59,011 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:57:59,200 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:57:59,383 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:57:59,571 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:57:59,764 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:57:59,951 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:58:00,140 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:58:00,235 - INFO - validation batch 1, loss: 0.253, 32/6976 datapoints
2025-03-06 22:58:00,286 - INFO - validation batch 51, loss: 7.435, 1632/6976 datapoints
2025-03-06 22:58:00,341 - INFO - validation batch 101, loss: 1.026, 3232/6976 datapoints
2025-03-06 22:58:00,394 - INFO - validation batch 151, loss: 1.753, 4832/6976 datapoints
2025-03-06 22:58:00,446 - INFO - validation batch 201, loss: 3.366, 6432/6976 datapoints
2025-03-06 22:58:00,462 - INFO - Epoch 620/800 done.
2025-03-06 22:58:00,462 - INFO - Final validation performance:
Loss: 2.766, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:58:00,463 - INFO - Beginning epoch 621/800
2025-03-06 22:58:00,469 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:58:00,666 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:58:00,846 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:58:01,038 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:58:01,230 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:58:01,429 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:58:01,623 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:58:01,814 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:58:02,004 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:58:02,192 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:58:02,381 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:58:02,563 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:58:02,751 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:58:02,932 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:03,123 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:58:03,318 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:03,505 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:58:03,706 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:58:03,801 - INFO - validation batch 1, loss: 0.280, 32/6976 datapoints
2025-03-06 22:58:03,854 - INFO - validation batch 51, loss: 7.456, 1632/6976 datapoints
2025-03-06 22:58:03,907 - INFO - validation batch 101, loss: 1.041, 3232/6976 datapoints
2025-03-06 22:58:03,959 - INFO - validation batch 151, loss: 1.808, 4832/6976 datapoints
2025-03-06 22:58:04,015 - INFO - validation batch 201, loss: 3.364, 6432/6976 datapoints
2025-03-06 22:58:04,038 - INFO - Epoch 621/800 done.
2025-03-06 22:58:04,039 - INFO - Final validation performance:
Loss: 2.790, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:58:04,039 - INFO - Beginning epoch 622/800
2025-03-06 22:58:04,044 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:58:04,238 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:58:04,418 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:58:04,612 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:58:04,801 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:58:04,994 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:58:05,189 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:58:05,388 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:58:05,575 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:58:05,767 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:58:05,951 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:58:06,140 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:58:06,331 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:58:06,522 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:06,728 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:58:06,917 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:07,111 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:58:07,295 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:58:07,390 - INFO - validation batch 1, loss: 0.263, 32/6976 datapoints
2025-03-06 22:58:07,442 - INFO - validation batch 51, loss: 7.415, 1632/6976 datapoints
2025-03-06 22:58:07,494 - INFO - validation batch 101, loss: 1.043, 3232/6976 datapoints
2025-03-06 22:58:07,547 - INFO - validation batch 151, loss: 1.889, 4832/6976 datapoints
2025-03-06 22:58:07,600 - INFO - validation batch 201, loss: 3.403, 6432/6976 datapoints
2025-03-06 22:58:07,617 - INFO - Epoch 622/800 done.
2025-03-06 22:58:07,617 - INFO - Final validation performance:
Loss: 2.802, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:58:07,618 - INFO - Beginning epoch 623/800
2025-03-06 22:58:07,623 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:58:07,819 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:58:08,000 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:58:08,192 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:58:08,388 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:58:08,581 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:58:08,781 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:58:08,971 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:58:09,158 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:58:09,344 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:58:09,538 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:58:09,723 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:58:09,912 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:58:10,099 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:10,287 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:58:10,477 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:10,665 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:58:10,847 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:58:10,942 - INFO - validation batch 1, loss: 0.246, 32/6976 datapoints
2025-03-06 22:58:10,996 - INFO - validation batch 51, loss: 7.399, 1632/6976 datapoints
2025-03-06 22:58:11,048 - INFO - validation batch 101, loss: 1.049, 3232/6976 datapoints
2025-03-06 22:58:11,099 - INFO - validation batch 151, loss: 1.937, 4832/6976 datapoints
2025-03-06 22:58:11,153 - INFO - validation batch 201, loss: 3.437, 6432/6976 datapoints
2025-03-06 22:58:11,172 - INFO - Epoch 623/800 done.
2025-03-06 22:58:11,172 - INFO - Final validation performance:
Loss: 2.813, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:58:11,173 - INFO - Beginning epoch 624/800
2025-03-06 22:58:11,178 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:58:11,369 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:58:11,544 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:58:11,734 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:58:11,920 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:58:12,114 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:58:12,308 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:58:12,501 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:58:12,685 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:58:12,868 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:58:13,050 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:58:13,233 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:58:13,420 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:58:13,600 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:13,789 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:58:13,989 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:14,174 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:58:14,355 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:58:14,448 - INFO - validation batch 1, loss: 0.242, 32/6976 datapoints
2025-03-06 22:58:14,497 - INFO - validation batch 51, loss: 7.454, 1632/6976 datapoints
2025-03-06 22:58:14,545 - INFO - validation batch 101, loss: 1.047, 3232/6976 datapoints
2025-03-06 22:58:14,593 - INFO - validation batch 151, loss: 1.978, 4832/6976 datapoints
2025-03-06 22:58:14,640 - INFO - validation batch 201, loss: 3.462, 6432/6976 datapoints
2025-03-06 22:58:14,658 - INFO - Epoch 624/800 done.
2025-03-06 22:58:14,658 - INFO - Final validation performance:
Loss: 2.837, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:58:14,659 - INFO - Beginning epoch 625/800
2025-03-06 22:58:14,664 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:58:14,850 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:58:15,035 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:58:15,241 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 22:58:15,430 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:58:15,616 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 22:58:15,807 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 22:58:16,005 - INFO - training batch 351, loss: 0.038, 11232/28000 datapoints
2025-03-06 22:58:16,206 - INFO - training batch 401, loss: 0.010, 12832/28000 datapoints
2025-03-06 22:58:16,397 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 22:58:16,581 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:58:16,785 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:58:16,966 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:58:17,160 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:17,345 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 22:58:17,533 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:17,720 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 22:58:17,904 - INFO - training batch 851, loss: 0.013, 27232/28000 datapoints
2025-03-06 22:58:18,001 - INFO - validation batch 1, loss: 0.187, 32/6976 datapoints
2025-03-06 22:58:18,053 - INFO - validation batch 51, loss: 7.437, 1632/6976 datapoints
2025-03-06 22:58:18,104 - INFO - validation batch 101, loss: 1.262, 3232/6976 datapoints
2025-03-06 22:58:18,159 - INFO - validation batch 151, loss: 1.635, 4832/6976 datapoints
2025-03-06 22:58:18,217 - INFO - validation batch 201, loss: 3.815, 6432/6976 datapoints
2025-03-06 22:58:18,237 - INFO - Epoch 625/800 done.
2025-03-06 22:58:18,237 - INFO - Final validation performance:
Loss: 2.867, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:58:18,238 - INFO - Beginning epoch 626/800
2025-03-06 22:58:18,243 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 22:58:18,440 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-06 22:58:18,620 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 22:58:18,814 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:58:19,007 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 22:58:19,203 - INFO - training batch 251, loss: 0.025, 8032/28000 datapoints
2025-03-06 22:58:19,396 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:58:19,585 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:58:19,772 - INFO - training batch 401, loss: 0.010, 12832/28000 datapoints
2025-03-06 22:58:19,961 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:58:20,150 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:58:20,335 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 22:58:20,527 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:58:20,712 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:20,898 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:58:21,092 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:21,277 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:58:21,460 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:58:21,556 - INFO - validation batch 1, loss: 0.339, 32/6976 datapoints
2025-03-06 22:58:21,609 - INFO - validation batch 51, loss: 7.852, 1632/6976 datapoints
2025-03-06 22:58:21,661 - INFO - validation batch 101, loss: 1.238, 3232/6976 datapoints
2025-03-06 22:58:21,716 - INFO - validation batch 151, loss: 1.671, 4832/6976 datapoints
2025-03-06 22:58:21,771 - INFO - validation batch 201, loss: 3.453, 6432/6976 datapoints
2025-03-06 22:58:21,791 - INFO - Epoch 626/800 done.
2025-03-06 22:58:21,791 - INFO - Final validation performance:
Loss: 2.911, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:58:21,792 - INFO - Beginning epoch 627/800
2025-03-06 22:58:21,796 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 22:58:21,990 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 22:58:22,173 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:58:22,362 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:58:22,558 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:58:22,750 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:58:22,944 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:58:23,137 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:58:23,348 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:58:23,571 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:58:23,779 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:58:23,993 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:58:24,183 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:58:24,369 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:24,559 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:58:24,753 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:24,937 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:58:25,124 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:58:25,220 - INFO - validation batch 1, loss: 0.335, 32/6976 datapoints
2025-03-06 22:58:25,285 - INFO - validation batch 51, loss: 7.765, 1632/6976 datapoints
2025-03-06 22:58:25,340 - INFO - validation batch 101, loss: 1.216, 3232/6976 datapoints
2025-03-06 22:58:25,399 - INFO - validation batch 151, loss: 1.715, 4832/6976 datapoints
2025-03-06 22:58:25,454 - INFO - validation batch 201, loss: 3.456, 6432/6976 datapoints
2025-03-06 22:58:25,474 - INFO - Epoch 627/800 done.
2025-03-06 22:58:25,474 - INFO - Final validation performance:
Loss: 2.898, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:58:25,475 - INFO - Beginning epoch 628/800
2025-03-06 22:58:25,480 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:58:25,666 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:58:25,849 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:58:26,039 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:58:26,226 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:58:26,421 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:58:26,609 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:58:26,820 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:58:27,006 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:58:27,206 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:58:27,390 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:58:27,570 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 22:58:27,754 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:58:27,935 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:28,124 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:58:28,312 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:28,496 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:58:28,677 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:58:28,769 - INFO - validation batch 1, loss: 0.321, 32/6976 datapoints
2025-03-06 22:58:28,818 - INFO - validation batch 51, loss: 7.749, 1632/6976 datapoints
2025-03-06 22:58:28,866 - INFO - validation batch 101, loss: 1.229, 3232/6976 datapoints
2025-03-06 22:58:28,913 - INFO - validation batch 151, loss: 1.748, 4832/6976 datapoints
2025-03-06 22:58:28,961 - INFO - validation batch 201, loss: 3.485, 6432/6976 datapoints
2025-03-06 22:58:28,978 - INFO - Epoch 628/800 done.
2025-03-06 22:58:28,978 - INFO - Final validation performance:
Loss: 2.906, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:58:28,978 - INFO - Beginning epoch 629/800
2025-03-06 22:58:28,986 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:58:29,171 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 22:58:29,352 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:58:29,536 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:58:29,723 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:58:29,914 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:58:30,106 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:58:30,293 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:58:30,480 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:58:30,664 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:58:30,848 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:58:31,030 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:58:31,213 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:58:31,401 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:31,586 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:58:31,773 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:31,956 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:58:32,142 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:58:32,235 - INFO - validation batch 1, loss: 0.307, 32/6976 datapoints
2025-03-06 22:58:32,284 - INFO - validation batch 51, loss: 7.685, 1632/6976 datapoints
2025-03-06 22:58:32,332 - INFO - validation batch 101, loss: 1.203, 3232/6976 datapoints
2025-03-06 22:58:32,381 - INFO - validation batch 151, loss: 1.813, 4832/6976 datapoints
2025-03-06 22:58:32,429 - INFO - validation batch 201, loss: 3.487, 6432/6976 datapoints
2025-03-06 22:58:32,448 - INFO - Epoch 629/800 done.
2025-03-06 22:58:32,448 - INFO - Final validation performance:
Loss: 2.899, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:58:32,449 - INFO - Beginning epoch 630/800
2025-03-06 22:58:32,454 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:58:32,638 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:58:32,817 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:58:33,007 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:58:33,192 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:58:33,384 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:58:33,574 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:58:33,767 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:58:33,950 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:58:34,139 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:58:34,329 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:58:34,516 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:58:34,699 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:58:34,881 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:35,069 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:58:35,260 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:35,446 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:58:35,629 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:58:35,722 - INFO - validation batch 1, loss: 0.288, 32/6976 datapoints
2025-03-06 22:58:35,770 - INFO - validation batch 51, loss: 7.649, 1632/6976 datapoints
2025-03-06 22:58:35,818 - INFO - validation batch 101, loss: 1.178, 3232/6976 datapoints
2025-03-06 22:58:35,866 - INFO - validation batch 151, loss: 1.895, 4832/6976 datapoints
2025-03-06 22:58:35,915 - INFO - validation batch 201, loss: 3.497, 6432/6976 datapoints
2025-03-06 22:58:35,932 - INFO - Epoch 630/800 done.
2025-03-06 22:58:35,932 - INFO - Final validation performance:
Loss: 2.901, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:58:35,932 - INFO - Beginning epoch 631/800
2025-03-06 22:58:35,937 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:58:36,126 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:58:36,301 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:58:36,494 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:58:36,684 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:58:36,896 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:58:37,093 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:58:37,286 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:58:37,475 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:58:37,662 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:58:37,849 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:58:38,050 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:58:38,239 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:58:38,427 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:38,618 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:58:38,804 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:38,995 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:58:39,187 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:58:39,283 - INFO - validation batch 1, loss: 0.269, 32/6976 datapoints
2025-03-06 22:58:39,334 - INFO - validation batch 51, loss: 7.606, 1632/6976 datapoints
2025-03-06 22:58:39,387 - INFO - validation batch 101, loss: 1.148, 3232/6976 datapoints
2025-03-06 22:58:39,447 - INFO - validation batch 151, loss: 1.969, 4832/6976 datapoints
2025-03-06 22:58:39,504 - INFO - validation batch 201, loss: 3.537, 6432/6976 datapoints
2025-03-06 22:58:39,524 - INFO - Epoch 631/800 done.
2025-03-06 22:58:39,524 - INFO - Final validation performance:
Loss: 2.906, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:58:39,525 - INFO - Beginning epoch 632/800
2025-03-06 22:58:39,531 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:58:39,723 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:58:39,900 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:58:40,094 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:58:40,324 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:58:40,519 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:58:40,709 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:58:40,899 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:58:41,092 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:58:41,276 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:58:41,458 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:58:41,640 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:58:41,825 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:58:42,010 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:42,193 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:58:42,381 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:42,568 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:58:42,749 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:58:42,840 - INFO - validation batch 1, loss: 0.265, 32/6976 datapoints
2025-03-06 22:58:42,888 - INFO - validation batch 51, loss: 7.626, 1632/6976 datapoints
2025-03-06 22:58:42,935 - INFO - validation batch 101, loss: 1.109, 3232/6976 datapoints
2025-03-06 22:58:42,986 - INFO - validation batch 151, loss: 2.029, 4832/6976 datapoints
2025-03-06 22:58:43,033 - INFO - validation batch 201, loss: 3.574, 6432/6976 datapoints
2025-03-06 22:58:43,049 - INFO - Epoch 632/800 done.
2025-03-06 22:58:43,050 - INFO - Final validation performance:
Loss: 2.921, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:58:43,050 - INFO - Beginning epoch 633/800
2025-03-06 22:58:43,055 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:58:43,240 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:58:43,418 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:58:43,606 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:58:43,794 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:58:43,990 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:58:44,187 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:58:44,376 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:58:44,562 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:58:44,744 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:58:44,927 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:58:45,119 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:58:45,310 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:58:45,494 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:45,684 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:58:45,873 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:46,063 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:58:46,252 - INFO - training batch 851, loss: 0.025, 27232/28000 datapoints
2025-03-06 22:58:46,341 - INFO - validation batch 1, loss: 1.039, 32/6976 datapoints
2025-03-06 22:58:46,388 - INFO - validation batch 51, loss: 9.268, 1632/6976 datapoints
2025-03-06 22:58:46,437 - INFO - validation batch 101, loss: 1.040, 3232/6976 datapoints
2025-03-06 22:58:46,485 - INFO - validation batch 151, loss: 0.566, 4832/6976 datapoints
2025-03-06 22:58:46,534 - INFO - validation batch 201, loss: 3.812, 6432/6976 datapoints
2025-03-06 22:58:46,553 - INFO - Epoch 633/800 done.
2025-03-06 22:58:46,553 - INFO - Final validation performance:
Loss: 3.145, top-1 acc: 0.841top-5 acc: 0.841
2025-03-06 22:58:46,627 - INFO - Beginning epoch 634/800
2025-03-06 22:58:46,632 - INFO - training batch 1, loss: 0.180, 32/28000 datapoints
2025-03-06 22:58:46,817 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 22:58:47,045 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:58:47,273 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 22:58:47,479 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 22:58:47,671 - INFO - training batch 251, loss: 0.056, 8032/28000 datapoints
2025-03-06 22:58:47,865 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 22:58:48,055 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:58:48,239 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 22:58:48,426 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:58:48,611 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:58:48,793 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:58:48,986 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-06 22:58:49,171 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:49,357 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 22:58:49,546 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:49,734 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:58:49,925 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:58:50,023 - INFO - validation batch 1, loss: 0.383, 32/6976 datapoints
2025-03-06 22:58:50,071 - INFO - validation batch 51, loss: 8.086, 1632/6976 datapoints
2025-03-06 22:58:50,120 - INFO - validation batch 101, loss: 1.281, 3232/6976 datapoints
2025-03-06 22:58:50,171 - INFO - validation batch 151, loss: 1.835, 4832/6976 datapoints
2025-03-06 22:58:50,220 - INFO - validation batch 201, loss: 3.666, 6432/6976 datapoints
2025-03-06 22:58:50,236 - INFO - Epoch 634/800 done.
2025-03-06 22:58:50,237 - INFO - Final validation performance:
Loss: 3.050, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 22:58:50,237 - INFO - Beginning epoch 635/800
2025-03-06 22:58:50,242 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 22:58:50,432 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 22:58:50,617 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:58:50,805 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 22:58:51,004 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 22:58:51,200 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:58:51,402 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-06 22:58:51,589 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:58:51,775 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:58:51,961 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:58:52,147 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:58:52,334 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:58:52,523 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:58:52,703 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:52,890 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:58:53,079 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:53,264 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:58:53,446 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:58:53,538 - INFO - validation batch 1, loss: 0.344, 32/6976 datapoints
2025-03-06 22:58:53,585 - INFO - validation batch 51, loss: 7.878, 1632/6976 datapoints
2025-03-06 22:58:53,633 - INFO - validation batch 101, loss: 1.197, 3232/6976 datapoints
2025-03-06 22:58:53,681 - INFO - validation batch 151, loss: 1.822, 4832/6976 datapoints
2025-03-06 22:58:53,730 - INFO - validation batch 201, loss: 3.672, 6432/6976 datapoints
2025-03-06 22:58:53,748 - INFO - Epoch 635/800 done.
2025-03-06 22:58:53,748 - INFO - Final validation performance:
Loss: 2.983, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:58:53,749 - INFO - Beginning epoch 636/800
2025-03-06 22:58:53,754 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:58:53,941 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:58:54,125 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-06 22:58:54,314 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:58:54,501 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 22:58:54,693 - INFO - training batch 251, loss: 0.019, 8032/28000 datapoints
2025-03-06 22:58:54,879 - INFO - training batch 301, loss: 0.019, 9632/28000 datapoints
2025-03-06 22:58:55,067 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-06 22:58:55,255 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:58:55,442 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:58:55,631 - INFO - training batch 501, loss: 0.026, 16032/28000 datapoints
2025-03-06 22:58:55,818 - INFO - training batch 551, loss: 0.028, 17632/28000 datapoints
2025-03-06 22:58:56,014 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 22:58:56,236 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:58:56,457 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:58:56,646 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:58:56,833 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:58:57,028 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:58:57,145 - INFO - validation batch 1, loss: 0.405, 32/6976 datapoints
2025-03-06 22:58:57,194 - INFO - validation batch 51, loss: 7.724, 1632/6976 datapoints
2025-03-06 22:58:57,242 - INFO - validation batch 101, loss: 1.235, 3232/6976 datapoints
2025-03-06 22:58:57,289 - INFO - validation batch 151, loss: 2.066, 4832/6976 datapoints
2025-03-06 22:58:57,342 - INFO - validation batch 201, loss: 3.784, 6432/6976 datapoints
2025-03-06 22:58:57,358 - INFO - Epoch 636/800 done.
2025-03-06 22:58:57,359 - INFO - Final validation performance:
Loss: 3.043, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:58:57,359 - INFO - Beginning epoch 637/800
2025-03-06 22:58:57,364 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:58:57,561 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:58:57,748 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:58:57,937 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:58:58,133 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:58:58,330 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:58:58,528 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:58:58,722 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-06 22:58:58,913 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:58:59,102 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:58:59,292 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:58:59,478 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:58:59,671 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:58:59,855 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:00,047 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:59:00,237 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:59:00,424 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:59:00,611 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:59:00,708 - INFO - validation batch 1, loss: 0.373, 32/6976 datapoints
2025-03-06 22:59:00,761 - INFO - validation batch 51, loss: 7.988, 1632/6976 datapoints
2025-03-06 22:59:00,813 - INFO - validation batch 101, loss: 1.217, 3232/6976 datapoints
2025-03-06 22:59:00,864 - INFO - validation batch 151, loss: 1.934, 4832/6976 datapoints
2025-03-06 22:59:00,917 - INFO - validation batch 201, loss: 3.581, 6432/6976 datapoints
2025-03-06 22:59:00,939 - INFO - Epoch 637/800 done.
2025-03-06 22:59:00,939 - INFO - Final validation performance:
Loss: 3.018, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:59:00,939 - INFO - Beginning epoch 638/800
2025-03-06 22:59:00,944 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:59:01,140 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:59:01,327 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:59:01,519 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:59:01,715 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:59:01,906 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:59:02,105 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:59:02,299 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-06 22:59:02,488 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:59:02,680 - INFO - training batch 451, loss: 0.014, 14432/28000 datapoints
2025-03-06 22:59:02,867 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 22:59:03,054 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:59:03,244 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:59:03,427 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:03,620 - INFO - training batch 701, loss: 0.039, 22432/28000 datapoints
2025-03-06 22:59:03,810 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:59:04,001 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:59:04,192 - INFO - training batch 851, loss: 0.014, 27232/28000 datapoints
2025-03-06 22:59:04,289 - INFO - validation batch 1, loss: 0.293, 32/6976 datapoints
2025-03-06 22:59:04,341 - INFO - validation batch 51, loss: 8.078, 1632/6976 datapoints
2025-03-06 22:59:04,394 - INFO - validation batch 101, loss: 1.303, 3232/6976 datapoints
2025-03-06 22:59:04,447 - INFO - validation batch 151, loss: 2.043, 4832/6976 datapoints
2025-03-06 22:59:04,500 - INFO - validation batch 201, loss: 3.463, 6432/6976 datapoints
2025-03-06 22:59:04,518 - INFO - Epoch 638/800 done.
2025-03-06 22:59:04,519 - INFO - Final validation performance:
Loss: 3.036, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:59:04,519 - INFO - Beginning epoch 639/800
2025-03-06 22:59:04,525 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:59:04,724 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:59:04,912 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:59:05,106 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:59:05,303 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:59:05,495 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 22:59:05,698 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:59:05,890 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:59:06,079 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-06 22:59:06,268 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:59:06,457 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:59:06,651 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:59:06,838 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:59:07,024 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:07,240 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:59:07,432 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:59:07,621 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:59:07,808 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:59:07,903 - INFO - validation batch 1, loss: 0.303, 32/6976 datapoints
2025-03-06 22:59:07,955 - INFO - validation batch 51, loss: 8.027, 1632/6976 datapoints
2025-03-06 22:59:08,010 - INFO - validation batch 101, loss: 1.259, 3232/6976 datapoints
2025-03-06 22:59:08,064 - INFO - validation batch 151, loss: 1.961, 4832/6976 datapoints
2025-03-06 22:59:08,115 - INFO - validation batch 201, loss: 3.364, 6432/6976 datapoints
2025-03-06 22:59:08,135 - INFO - Epoch 639/800 done.
2025-03-06 22:59:08,136 - INFO - Final validation performance:
Loss: 2.983, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 22:59:08,136 - INFO - Beginning epoch 640/800
2025-03-06 22:59:08,141 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:59:08,337 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:59:08,523 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:59:08,719 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:59:08,913 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:59:09,106 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:59:09,309 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:59:09,505 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:59:09,693 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:59:09,884 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:59:10,076 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:59:10,266 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:59:10,457 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:59:10,643 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:10,832 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:59:11,037 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:59:11,225 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:59:11,411 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:59:11,507 - INFO - validation batch 1, loss: 0.286, 32/6976 datapoints
2025-03-06 22:59:11,558 - INFO - validation batch 51, loss: 7.934, 1632/6976 datapoints
2025-03-06 22:59:11,612 - INFO - validation batch 101, loss: 1.198, 3232/6976 datapoints
2025-03-06 22:59:11,665 - INFO - validation batch 151, loss: 2.045, 4832/6976 datapoints
2025-03-06 22:59:11,717 - INFO - validation batch 201, loss: 3.282, 6432/6976 datapoints
2025-03-06 22:59:11,738 - INFO - Epoch 640/800 done.
2025-03-06 22:59:11,738 - INFO - Final validation performance:
Loss: 2.949, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:59:11,739 - INFO - Beginning epoch 641/800
2025-03-06 22:59:11,744 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:59:11,937 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:59:12,124 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:59:12,319 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:59:12,516 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:59:12,711 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:59:12,909 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:59:13,104 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:59:13,290 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:59:13,479 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:59:13,668 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:59:13,857 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:59:14,052 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:59:14,267 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:14,460 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:59:14,653 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:59:14,839 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:59:15,030 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:59:15,123 - INFO - validation batch 1, loss: 0.280, 32/6976 datapoints
2025-03-06 22:59:15,175 - INFO - validation batch 51, loss: 7.921, 1632/6976 datapoints
2025-03-06 22:59:15,231 - INFO - validation batch 101, loss: 1.196, 3232/6976 datapoints
2025-03-06 22:59:15,281 - INFO - validation batch 151, loss: 2.071, 4832/6976 datapoints
2025-03-06 22:59:15,329 - INFO - validation batch 201, loss: 3.387, 6432/6976 datapoints
2025-03-06 22:59:15,345 - INFO - Epoch 641/800 done.
2025-03-06 22:59:15,346 - INFO - Final validation performance:
Loss: 2.971, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:59:15,346 - INFO - Beginning epoch 642/800
2025-03-06 22:59:15,351 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:59:15,544 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:59:15,731 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:59:15,921 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:59:16,115 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:59:16,304 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:59:16,497 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:59:16,690 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:59:16,873 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:59:17,066 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:59:17,274 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:59:17,461 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:59:17,655 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:59:17,840 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:18,035 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:59:18,225 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:59:18,416 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:59:18,601 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:59:18,698 - INFO - validation batch 1, loss: 0.260, 32/6976 datapoints
2025-03-06 22:59:18,748 - INFO - validation batch 51, loss: 7.879, 1632/6976 datapoints
2025-03-06 22:59:18,799 - INFO - validation batch 101, loss: 1.177, 3232/6976 datapoints
2025-03-06 22:59:18,851 - INFO - validation batch 151, loss: 2.118, 4832/6976 datapoints
2025-03-06 22:59:18,905 - INFO - validation batch 201, loss: 3.434, 6432/6976 datapoints
2025-03-06 22:59:18,924 - INFO - Epoch 642/800 done.
2025-03-06 22:59:18,925 - INFO - Final validation performance:
Loss: 2.974, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:59:18,925 - INFO - Beginning epoch 643/800
2025-03-06 22:59:18,931 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:59:19,122 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:59:19,306 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:59:19,501 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:59:19,695 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:59:19,889 - INFO - training batch 251, loss: 0.055, 8032/28000 datapoints
2025-03-06 22:59:20,081 - INFO - training batch 301, loss: 0.128, 9632/28000 datapoints
2025-03-06 22:59:20,268 - INFO - training batch 351, loss: 0.017, 11232/28000 datapoints
2025-03-06 22:59:20,450 - INFO - training batch 401, loss: 0.157, 12832/28000 datapoints
2025-03-06 22:59:20,638 - INFO - training batch 451, loss: 0.129, 14432/28000 datapoints
2025-03-06 22:59:20,821 - INFO - training batch 501, loss: 0.105, 16032/28000 datapoints
2025-03-06 22:59:21,010 - INFO - training batch 551, loss: 0.020, 17632/28000 datapoints
2025-03-06 22:59:21,196 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-06 22:59:21,382 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:21,574 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:59:21,761 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 22:59:21,953 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 22:59:22,140 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 22:59:22,234 - INFO - validation batch 1, loss: 0.172, 32/6976 datapoints
2025-03-06 22:59:22,282 - INFO - validation batch 51, loss: 7.960, 1632/6976 datapoints
2025-03-06 22:59:22,331 - INFO - validation batch 101, loss: 1.313, 3232/6976 datapoints
2025-03-06 22:59:22,378 - INFO - validation batch 151, loss: 2.003, 4832/6976 datapoints
2025-03-06 22:59:22,427 - INFO - validation batch 201, loss: 3.844, 6432/6976 datapoints
2025-03-06 22:59:22,445 - INFO - Epoch 643/800 done.
2025-03-06 22:59:22,445 - INFO - Final validation performance:
Loss: 3.058, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:59:22,446 - INFO - Beginning epoch 644/800
2025-03-06 22:59:22,450 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:59:22,640 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:59:22,822 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:59:23,017 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:59:23,210 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:59:23,402 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-06 22:59:23,596 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:59:23,784 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:59:23,962 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:59:24,149 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 22:59:24,334 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:59:24,521 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 22:59:24,709 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:59:24,891 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:25,080 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:59:25,271 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:59:25,460 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:59:25,647 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 22:59:25,742 - INFO - validation batch 1, loss: 0.320, 32/6976 datapoints
2025-03-06 22:59:25,790 - INFO - validation batch 51, loss: 8.343, 1632/6976 datapoints
2025-03-06 22:59:25,837 - INFO - validation batch 101, loss: 1.340, 3232/6976 datapoints
2025-03-06 22:59:25,884 - INFO - validation batch 151, loss: 1.696, 4832/6976 datapoints
2025-03-06 22:59:25,932 - INFO - validation batch 201, loss: 3.536, 6432/6976 datapoints
2025-03-06 22:59:25,948 - INFO - Epoch 644/800 done.
2025-03-06 22:59:25,949 - INFO - Final validation performance:
Loss: 3.047, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:59:25,949 - INFO - Beginning epoch 645/800
2025-03-06 22:59:25,954 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:59:26,146 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:59:26,328 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-06 22:59:26,518 - INFO - training batch 151, loss: 0.045, 4832/28000 datapoints
2025-03-06 22:59:26,709 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:59:26,898 - INFO - training batch 251, loss: 0.042, 8032/28000 datapoints
2025-03-06 22:59:27,093 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:59:27,281 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:59:27,487 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:59:27,671 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:59:27,856 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:59:28,046 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:59:28,234 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:59:28,419 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:28,607 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:59:28,796 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:59:28,982 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 22:59:29,167 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:59:29,259 - INFO - validation batch 1, loss: 0.319, 32/6976 datapoints
2025-03-06 22:59:29,310 - INFO - validation batch 51, loss: 8.058, 1632/6976 datapoints
2025-03-06 22:59:29,358 - INFO - validation batch 101, loss: 1.305, 3232/6976 datapoints
2025-03-06 22:59:29,404 - INFO - validation batch 151, loss: 1.719, 4832/6976 datapoints
2025-03-06 22:59:29,453 - INFO - validation batch 201, loss: 3.577, 6432/6976 datapoints
2025-03-06 22:59:29,471 - INFO - Epoch 645/800 done.
2025-03-06 22:59:29,472 - INFO - Final validation performance:
Loss: 2.995, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:59:29,472 - INFO - Beginning epoch 646/800
2025-03-06 22:59:29,477 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:59:29,667 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:59:29,852 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:59:30,044 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:59:30,235 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:59:30,427 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 22:59:30,621 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:59:30,811 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:59:31,028 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 22:59:31,341 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:59:31,534 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:59:31,772 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:59:31,958 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:59:32,144 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:32,331 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:59:32,516 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:59:32,708 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:59:32,890 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:59:32,985 - INFO - validation batch 1, loss: 0.303, 32/6976 datapoints
2025-03-06 22:59:33,033 - INFO - validation batch 51, loss: 8.181, 1632/6976 datapoints
2025-03-06 22:59:33,082 - INFO - validation batch 101, loss: 1.256, 3232/6976 datapoints
2025-03-06 22:59:33,128 - INFO - validation batch 151, loss: 1.802, 4832/6976 datapoints
2025-03-06 22:59:33,176 - INFO - validation batch 201, loss: 3.478, 6432/6976 datapoints
2025-03-06 22:59:33,192 - INFO - Epoch 646/800 done.
2025-03-06 22:59:33,192 - INFO - Final validation performance:
Loss: 3.004, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:59:33,193 - INFO - Beginning epoch 647/800
2025-03-06 22:59:33,198 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:59:33,385 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:59:33,568 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:59:33,761 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:59:33,954 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:59:34,147 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:59:34,340 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:59:34,534 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:59:34,717 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:59:34,902 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 22:59:35,091 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:59:35,280 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 22:59:35,467 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:59:35,659 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:35,853 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:59:36,045 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:59:36,234 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:59:36,422 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:59:36,519 - INFO - validation batch 1, loss: 0.284, 32/6976 datapoints
2025-03-06 22:59:36,571 - INFO - validation batch 51, loss: 8.114, 1632/6976 datapoints
2025-03-06 22:59:36,623 - INFO - validation batch 101, loss: 1.222, 3232/6976 datapoints
2025-03-06 22:59:36,676 - INFO - validation batch 151, loss: 1.863, 4832/6976 datapoints
2025-03-06 22:59:36,727 - INFO - validation batch 201, loss: 3.464, 6432/6976 datapoints
2025-03-06 22:59:36,744 - INFO - Epoch 647/800 done.
2025-03-06 22:59:36,744 - INFO - Final validation performance:
Loss: 2.989, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:59:36,744 - INFO - Beginning epoch 648/800
2025-03-06 22:59:36,749 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:59:36,936 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:59:37,122 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:59:37,315 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:59:37,529 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:59:37,722 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 22:59:37,920 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:59:38,134 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:59:38,315 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 22:59:38,504 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:59:38,692 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:59:38,882 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:59:39,075 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:59:39,262 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:39,455 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:59:39,658 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:59:39,850 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:59:40,044 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:59:40,143 - INFO - validation batch 1, loss: 0.268, 32/6976 datapoints
2025-03-06 22:59:40,197 - INFO - validation batch 51, loss: 8.078, 1632/6976 datapoints
2025-03-06 22:59:40,249 - INFO - validation batch 101, loss: 1.206, 3232/6976 datapoints
2025-03-06 22:59:40,301 - INFO - validation batch 151, loss: 1.935, 4832/6976 datapoints
2025-03-06 22:59:40,355 - INFO - validation batch 201, loss: 3.494, 6432/6976 datapoints
2025-03-06 22:59:40,373 - INFO - Epoch 648/800 done.
2025-03-06 22:59:40,373 - INFO - Final validation performance:
Loss: 2.996, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:59:40,374 - INFO - Beginning epoch 649/800
2025-03-06 22:59:40,379 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:59:40,580 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:59:40,800 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:59:40,992 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 22:59:41,186 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:59:41,377 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:59:41,573 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:59:41,765 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:59:41,944 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:59:42,131 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:59:42,319 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:59:42,504 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:59:42,692 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:59:42,877 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:43,066 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:59:43,252 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:59:43,438 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:59:43,620 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:59:43,715 - INFO - validation batch 1, loss: 0.263, 32/6976 datapoints
2025-03-06 22:59:43,763 - INFO - validation batch 51, loss: 8.041, 1632/6976 datapoints
2025-03-06 22:59:43,810 - INFO - validation batch 101, loss: 1.190, 3232/6976 datapoints
2025-03-06 22:59:43,857 - INFO - validation batch 151, loss: 1.981, 4832/6976 datapoints
2025-03-06 22:59:43,905 - INFO - validation batch 201, loss: 3.502, 6432/6976 datapoints
2025-03-06 22:59:43,921 - INFO - Epoch 649/800 done.
2025-03-06 22:59:43,921 - INFO - Final validation performance:
Loss: 2.995, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:59:43,922 - INFO - Beginning epoch 650/800
2025-03-06 22:59:43,927 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:59:44,117 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:59:44,301 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:59:44,495 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:59:44,687 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:59:44,883 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:59:45,078 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:59:45,272 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:59:45,453 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:59:45,641 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:59:45,840 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:59:46,025 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:59:46,213 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:59:46,397 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:46,584 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:59:46,772 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:59:46,956 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:59:47,143 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:59:47,237 - INFO - validation batch 1, loss: 0.263, 32/6976 datapoints
2025-03-06 22:59:47,284 - INFO - validation batch 51, loss: 8.000, 1632/6976 datapoints
2025-03-06 22:59:47,332 - INFO - validation batch 101, loss: 1.164, 3232/6976 datapoints
2025-03-06 22:59:47,380 - INFO - validation batch 151, loss: 2.029, 4832/6976 datapoints
2025-03-06 22:59:47,428 - INFO - validation batch 201, loss: 3.535, 6432/6976 datapoints
2025-03-06 22:59:47,444 - INFO - Epoch 650/800 done.
2025-03-06 22:59:47,444 - INFO - Final validation performance:
Loss: 2.998, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 22:59:47,445 - INFO - Beginning epoch 651/800
2025-03-06 22:59:47,450 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 22:59:47,662 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:59:47,847 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:59:48,041 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:59:48,233 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:59:48,427 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:59:48,623 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:59:48,817 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:59:48,997 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:59:49,182 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:59:49,365 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:59:49,550 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:59:49,737 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 22:59:49,931 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:50,119 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 22:59:50,305 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:59:50,492 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 22:59:50,675 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 22:59:50,771 - INFO - validation batch 1, loss: 0.263, 32/6976 datapoints
2025-03-06 22:59:50,819 - INFO - validation batch 51, loss: 7.971, 1632/6976 datapoints
2025-03-06 22:59:50,866 - INFO - validation batch 101, loss: 1.128, 3232/6976 datapoints
2025-03-06 22:59:50,913 - INFO - validation batch 151, loss: 2.101, 4832/6976 datapoints
2025-03-06 22:59:50,961 - INFO - validation batch 201, loss: 3.565, 6432/6976 datapoints
2025-03-06 22:59:50,977 - INFO - Epoch 651/800 done.
2025-03-06 22:59:50,977 - INFO - Final validation performance:
Loss: 3.005, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:59:50,978 - INFO - Beginning epoch 652/800
2025-03-06 22:59:50,984 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:59:51,180 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 22:59:51,364 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 22:59:51,557 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:59:51,751 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 22:59:51,942 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:59:52,138 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 22:59:52,329 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 22:59:52,508 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 22:59:52,696 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 22:59:52,887 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 22:59:53,075 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 22:59:53,267 - INFO - training batch 601, loss: 1.232, 19232/28000 datapoints
2025-03-06 22:59:53,457 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:53,639 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 22:59:53,824 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 22:59:54,016 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:59:54,203 - INFO - training batch 851, loss: 0.072, 27232/28000 datapoints
2025-03-06 22:59:54,295 - INFO - validation batch 1, loss: 0.269, 32/6976 datapoints
2025-03-06 22:59:54,344 - INFO - validation batch 51, loss: 7.432, 1632/6976 datapoints
2025-03-06 22:59:54,391 - INFO - validation batch 101, loss: 1.060, 3232/6976 datapoints
2025-03-06 22:59:54,439 - INFO - validation batch 151, loss: 2.289, 4832/6976 datapoints
2025-03-06 22:59:54,487 - INFO - validation batch 201, loss: 3.055, 6432/6976 datapoints
2025-03-06 22:59:54,504 - INFO - Epoch 652/800 done.
2025-03-06 22:59:54,504 - INFO - Final validation performance:
Loss: 2.821, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 22:59:54,505 - INFO - Beginning epoch 653/800
2025-03-06 22:59:54,509 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 22:59:54,693 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 22:59:54,883 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-06 22:59:55,078 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:59:55,274 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 22:59:55,467 - INFO - training batch 251, loss: 0.096, 8032/28000 datapoints
2025-03-06 22:59:55,660 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 22:59:55,853 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 22:59:56,039 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 22:59:56,224 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 22:59:56,412 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 22:59:56,598 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 22:59:56,788 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 22:59:56,976 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 22:59:57,163 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 22:59:57,348 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 22:59:57,534 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-06 22:59:57,745 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 22:59:57,838 - INFO - validation batch 1, loss: 0.334, 32/6976 datapoints
2025-03-06 22:59:57,891 - INFO - validation batch 51, loss: 8.651, 1632/6976 datapoints
2025-03-06 22:59:57,943 - INFO - validation batch 101, loss: 1.381, 3232/6976 datapoints
2025-03-06 22:59:57,996 - INFO - validation batch 151, loss: 2.140, 4832/6976 datapoints
2025-03-06 22:59:58,048 - INFO - validation batch 201, loss: 3.451, 6432/6976 datapoints
2025-03-06 22:59:58,064 - INFO - Epoch 653/800 done.
2025-03-06 22:59:58,064 - INFO - Final validation performance:
Loss: 3.192, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 22:59:58,065 - INFO - Beginning epoch 654/800
2025-03-06 22:59:58,070 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 22:59:58,266 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 22:59:58,460 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 22:59:58,653 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 22:59:58,854 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 22:59:59,054 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 22:59:59,261 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 22:59:59,457 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 22:59:59,645 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 22:59:59,830 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:00:00,024 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:00,218 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 23:00:00,429 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:00:00,617 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:00,808 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:00:01,001 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:00:01,190 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:00:01,377 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 23:00:01,474 - INFO - validation batch 1, loss: 0.302, 32/6976 datapoints
2025-03-06 23:00:01,526 - INFO - validation batch 51, loss: 8.452, 1632/6976 datapoints
2025-03-06 23:00:01,577 - INFO - validation batch 101, loss: 1.193, 3232/6976 datapoints
2025-03-06 23:00:01,634 - INFO - validation batch 151, loss: 2.040, 4832/6976 datapoints
2025-03-06 23:00:01,689 - INFO - validation batch 201, loss: 3.354, 6432/6976 datapoints
2025-03-06 23:00:01,705 - INFO - Epoch 654/800 done.
2025-03-06 23:00:01,705 - INFO - Final validation performance:
Loss: 3.068, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:00:01,706 - INFO - Beginning epoch 655/800
2025-03-06 23:00:01,711 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 23:00:01,902 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 23:00:02,093 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:00:02,291 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:00:02,489 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:00:02,686 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:00:02,885 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:00:03,082 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 23:00:03,269 - INFO - training batch 401, loss: 0.042, 12832/28000 datapoints
2025-03-06 23:00:03,461 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-06 23:00:03,650 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:03,841 - INFO - training batch 551, loss: 0.037, 17632/28000 datapoints
2025-03-06 23:00:04,036 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:00:04,227 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:04,412 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-06 23:00:04,605 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:00:04,796 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:00:04,986 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 23:00:05,083 - INFO - validation batch 1, loss: 0.269, 32/6976 datapoints
2025-03-06 23:00:05,134 - INFO - validation batch 51, loss: 8.591, 1632/6976 datapoints
2025-03-06 23:00:05,193 - INFO - validation batch 101, loss: 1.323, 3232/6976 datapoints
2025-03-06 23:00:05,250 - INFO - validation batch 151, loss: 1.930, 4832/6976 datapoints
2025-03-06 23:00:05,304 - INFO - validation batch 201, loss: 3.278, 6432/6976 datapoints
2025-03-06 23:00:05,323 - INFO - Epoch 655/800 done.
2025-03-06 23:00:05,323 - INFO - Final validation performance:
Loss: 3.078, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:00:05,324 - INFO - Beginning epoch 656/800
2025-03-06 23:00:05,329 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:00:05,520 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:00:05,709 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:00:05,907 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:00:06,104 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:00:06,311 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:00:06,512 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:00:06,701 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:00:06,884 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 23:00:07,077 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:00:07,271 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:07,461 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:00:07,656 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:00:07,859 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:08,050 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:00:08,236 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:00:08,422 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:00:08,610 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 23:00:08,705 - INFO - validation batch 1, loss: 0.277, 32/6976 datapoints
2025-03-06 23:00:08,753 - INFO - validation batch 51, loss: 8.368, 1632/6976 datapoints
2025-03-06 23:00:08,804 - INFO - validation batch 101, loss: 1.228, 3232/6976 datapoints
2025-03-06 23:00:08,851 - INFO - validation batch 151, loss: 2.036, 4832/6976 datapoints
2025-03-06 23:00:08,899 - INFO - validation batch 201, loss: 3.339, 6432/6976 datapoints
2025-03-06 23:00:08,915 - INFO - Epoch 656/800 done.
2025-03-06 23:00:08,915 - INFO - Final validation performance:
Loss: 3.050, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:00:08,915 - INFO - Beginning epoch 657/800
2025-03-06 23:00:08,920 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:00:09,111 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:00:09,292 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:00:09,490 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:00:09,690 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:00:09,885 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:00:10,085 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:00:10,276 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:00:10,456 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:00:10,642 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:00:10,831 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:11,027 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:00:11,213 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:00:11,400 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:11,588 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:00:11,775 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:00:11,960 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:00:12,150 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 23:00:12,244 - INFO - validation batch 1, loss: 0.278, 32/6976 datapoints
2025-03-06 23:00:12,293 - INFO - validation batch 51, loss: 8.371, 1632/6976 datapoints
2025-03-06 23:00:12,340 - INFO - validation batch 101, loss: 1.223, 3232/6976 datapoints
2025-03-06 23:00:12,388 - INFO - validation batch 151, loss: 2.092, 4832/6976 datapoints
2025-03-06 23:00:12,436 - INFO - validation batch 201, loss: 3.353, 6432/6976 datapoints
2025-03-06 23:00:12,452 - INFO - Epoch 657/800 done.
2025-03-06 23:00:12,452 - INFO - Final validation performance:
Loss: 3.063, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:00:12,452 - INFO - Beginning epoch 658/800
2025-03-06 23:00:12,457 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:00:12,660 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:00:12,847 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:00:13,047 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:00:13,246 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:00:13,443 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:00:13,639 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:00:13,830 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:00:14,014 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:00:14,200 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:00:14,386 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:14,572 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:00:14,760 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:00:14,950 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:15,139 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:00:15,329 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:00:15,513 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:00:15,702 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 23:00:15,799 - INFO - validation batch 1, loss: 0.269, 32/6976 datapoints
2025-03-06 23:00:15,847 - INFO - validation batch 51, loss: 8.353, 1632/6976 datapoints
2025-03-06 23:00:15,895 - INFO - validation batch 101, loss: 1.221, 3232/6976 datapoints
2025-03-06 23:00:15,943 - INFO - validation batch 151, loss: 2.139, 4832/6976 datapoints
2025-03-06 23:00:15,995 - INFO - validation batch 201, loss: 3.384, 6432/6976 datapoints
2025-03-06 23:00:16,011 - INFO - Epoch 658/800 done.
2025-03-06 23:00:16,011 - INFO - Final validation performance:
Loss: 3.073, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:00:16,012 - INFO - Beginning epoch 659/800
2025-03-06 23:00:16,017 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:00:16,209 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:00:16,392 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:00:16,586 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:00:16,779 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:00:16,973 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:00:17,171 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:00:17,366 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:00:17,545 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:00:17,734 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:00:17,947 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:18,139 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:00:18,329 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:00:18,520 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:18,712 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:00:18,920 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:00:19,109 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:00:19,304 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:00:19,402 - INFO - validation batch 1, loss: 0.255, 32/6976 datapoints
2025-03-06 23:00:19,456 - INFO - validation batch 51, loss: 8.321, 1632/6976 datapoints
2025-03-06 23:00:19,509 - INFO - validation batch 101, loss: 1.220, 3232/6976 datapoints
2025-03-06 23:00:19,562 - INFO - validation batch 151, loss: 2.187, 4832/6976 datapoints
2025-03-06 23:00:19,616 - INFO - validation batch 201, loss: 3.399, 6432/6976 datapoints
2025-03-06 23:00:19,642 - INFO - Epoch 659/800 done.
2025-03-06 23:00:19,642 - INFO - Final validation performance:
Loss: 3.077, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:00:19,643 - INFO - Beginning epoch 660/800
2025-03-06 23:00:19,647 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:00:19,846 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:00:20,036 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:00:20,233 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:00:20,430 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:00:20,630 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:00:20,829 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:00:21,030 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:00:21,215 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:00:21,402 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:00:21,592 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:21,783 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:00:21,974 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:00:22,168 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:22,358 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:00:22,547 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:00:22,738 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:00:22,930 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:00:23,029 - INFO - validation batch 1, loss: 0.246, 32/6976 datapoints
2025-03-06 23:00:23,081 - INFO - validation batch 51, loss: 8.275, 1632/6976 datapoints
2025-03-06 23:00:23,132 - INFO - validation batch 101, loss: 1.213, 3232/6976 datapoints
2025-03-06 23:00:23,185 - INFO - validation batch 151, loss: 2.229, 4832/6976 datapoints
2025-03-06 23:00:23,237 - INFO - validation batch 201, loss: 3.427, 6432/6976 datapoints
2025-03-06 23:00:23,254 - INFO - Epoch 660/800 done.
2025-03-06 23:00:23,254 - INFO - Final validation performance:
Loss: 3.078, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:00:23,254 - INFO - Beginning epoch 661/800
2025-03-06 23:00:23,259 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:00:23,451 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:00:23,643 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:00:23,845 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:00:24,046 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:00:24,241 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:00:24,439 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:00:24,635 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:00:24,842 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:00:25,036 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:00:25,229 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:25,427 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:00:25,627 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:00:25,827 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:26,022 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:00:26,213 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:00:26,403 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:00:26,592 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:00:26,688 - INFO - validation batch 1, loss: 0.240, 32/6976 datapoints
2025-03-06 23:00:26,741 - INFO - validation batch 51, loss: 8.232, 1632/6976 datapoints
2025-03-06 23:00:26,793 - INFO - validation batch 101, loss: 1.186, 3232/6976 datapoints
2025-03-06 23:00:26,847 - INFO - validation batch 151, loss: 2.260, 4832/6976 datapoints
2025-03-06 23:00:26,901 - INFO - validation batch 201, loss: 3.488, 6432/6976 datapoints
2025-03-06 23:00:26,918 - INFO - Epoch 661/800 done.
2025-03-06 23:00:26,918 - INFO - Final validation performance:
Loss: 3.081, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:00:26,919 - INFO - Beginning epoch 662/800
2025-03-06 23:00:26,925 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:00:27,122 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:00:27,313 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:00:27,514 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:00:27,714 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:00:27,933 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:00:28,135 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:00:28,331 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:00:28,517 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:00:28,706 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:00:28,902 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:29,095 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:00:29,289 - INFO - training batch 601, loss: 0.015, 19232/28000 datapoints
2025-03-06 23:00:29,487 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:29,684 - INFO - training batch 701, loss: 0.017, 22432/28000 datapoints
2025-03-06 23:00:29,874 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:00:30,070 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 23:00:30,256 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 23:00:30,356 - INFO - validation batch 1, loss: 0.245, 32/6976 datapoints
2025-03-06 23:00:30,408 - INFO - validation batch 51, loss: 8.134, 1632/6976 datapoints
2025-03-06 23:00:30,460 - INFO - validation batch 101, loss: 1.182, 3232/6976 datapoints
2025-03-06 23:00:30,513 - INFO - validation batch 151, loss: 2.256, 4832/6976 datapoints
2025-03-06 23:00:30,566 - INFO - validation batch 201, loss: 3.899, 6432/6976 datapoints
2025-03-06 23:00:30,586 - INFO - Epoch 662/800 done.
2025-03-06 23:00:30,587 - INFO - Final validation performance:
Loss: 3.143, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:00:30,587 - INFO - Beginning epoch 663/800
2025-03-06 23:00:30,592 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 23:00:30,792 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 23:00:30,992 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:00:31,187 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:00:31,397 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 23:00:31,595 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:00:31,796 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:00:31,997 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:00:32,182 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:00:32,374 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 23:00:32,566 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:32,759 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 23:00:32,956 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:00:33,151 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:33,337 - INFO - training batch 701, loss: 0.011, 22432/28000 datapoints
2025-03-06 23:00:33,526 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:00:33,721 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 23:00:33,911 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:00:34,013 - INFO - validation batch 1, loss: 0.388, 32/6976 datapoints
2025-03-06 23:00:34,066 - INFO - validation batch 51, loss: 8.628, 1632/6976 datapoints
2025-03-06 23:00:34,117 - INFO - validation batch 101, loss: 1.281, 3232/6976 datapoints
2025-03-06 23:00:34,170 - INFO - validation batch 151, loss: 1.737, 4832/6976 datapoints
2025-03-06 23:00:34,222 - INFO - validation batch 201, loss: 4.033, 6432/6976 datapoints
2025-03-06 23:00:34,242 - INFO - Epoch 663/800 done.
2025-03-06 23:00:34,243 - INFO - Final validation performance:
Loss: 3.213, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:00:34,243 - INFO - Beginning epoch 664/800
2025-03-06 23:00:34,248 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 23:00:34,444 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:00:34,636 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:00:34,836 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:00:35,037 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 23:00:35,241 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 23:00:35,439 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:00:35,633 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:00:35,828 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 23:00:36,022 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:00:36,213 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:36,403 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:00:36,594 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:00:36,785 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:36,977 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:00:37,189 - INFO - training batch 751, loss: 0.102, 24032/28000 datapoints
2025-03-06 23:00:37,381 - INFO - training batch 801, loss: 0.018, 25632/28000 datapoints
2025-03-06 23:00:37,579 - INFO - training batch 851, loss: 0.021, 27232/28000 datapoints
2025-03-06 23:00:37,683 - INFO - validation batch 1, loss: 0.306, 32/6976 datapoints
2025-03-06 23:00:37,735 - INFO - validation batch 51, loss: 7.870, 1632/6976 datapoints
2025-03-06 23:00:37,786 - INFO - validation batch 101, loss: 0.926, 3232/6976 datapoints
2025-03-06 23:00:37,839 - INFO - validation batch 151, loss: 2.413, 4832/6976 datapoints
2025-03-06 23:00:37,897 - INFO - validation batch 201, loss: 3.263, 6432/6976 datapoints
2025-03-06 23:00:37,922 - INFO - Epoch 664/800 done.
2025-03-06 23:00:37,922 - INFO - Final validation performance:
Loss: 2.956, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:00:37,923 - INFO - Beginning epoch 665/800
2025-03-06 23:00:37,929 - INFO - training batch 1, loss: 0.013, 32/28000 datapoints
2025-03-06 23:00:38,155 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:00:38,342 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:00:38,539 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-06 23:00:38,737 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:00:38,938 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-06 23:00:39,141 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 23:00:39,332 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:00:39,521 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:00:39,709 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 23:00:39,899 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:40,102 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:00:40,297 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:00:40,487 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:40,678 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:00:40,870 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:00:41,095 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:00:41,295 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:00:41,395 - INFO - validation batch 1, loss: 0.336, 32/6976 datapoints
2025-03-06 23:00:41,448 - INFO - validation batch 51, loss: 8.295, 1632/6976 datapoints
2025-03-06 23:00:41,500 - INFO - validation batch 101, loss: 1.195, 3232/6976 datapoints
2025-03-06 23:00:41,551 - INFO - validation batch 151, loss: 1.907, 4832/6976 datapoints
2025-03-06 23:00:41,604 - INFO - validation batch 201, loss: 3.733, 6432/6976 datapoints
2025-03-06 23:00:41,621 - INFO - Epoch 665/800 done.
2025-03-06 23:00:41,622 - INFO - Final validation performance:
Loss: 3.093, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:00:41,622 - INFO - Beginning epoch 666/800
2025-03-06 23:00:41,628 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:00:41,820 - INFO - training batch 51, loss: 0.213, 1632/28000 datapoints
2025-03-06 23:00:42,010 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:00:42,204 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:00:42,399 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:00:42,594 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-06 23:00:42,790 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:00:42,987 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 23:00:43,179 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-06 23:00:43,369 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:00:43,558 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:43,744 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:00:43,939 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:00:44,133 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:44,322 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:00:44,510 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:00:44,697 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:00:44,882 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:00:44,980 - INFO - validation batch 1, loss: 0.408, 32/6976 datapoints
2025-03-06 23:00:45,031 - INFO - validation batch 51, loss: 8.706, 1632/6976 datapoints
2025-03-06 23:00:45,079 - INFO - validation batch 101, loss: 1.196, 3232/6976 datapoints
2025-03-06 23:00:45,126 - INFO - validation batch 151, loss: 1.815, 4832/6976 datapoints
2025-03-06 23:00:45,174 - INFO - validation batch 201, loss: 3.620, 6432/6976 datapoints
2025-03-06 23:00:45,190 - INFO - Epoch 666/800 done.
2025-03-06 23:00:45,190 - INFO - Final validation performance:
Loss: 3.149, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:00:45,191 - INFO - Beginning epoch 667/800
2025-03-06 23:00:45,196 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:00:45,386 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:00:45,573 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:00:45,775 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:00:45,972 - INFO - training batch 201, loss: 0.050, 6432/28000 datapoints
2025-03-06 23:00:46,169 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-06 23:00:46,363 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:00:46,558 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 23:00:46,743 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 23:00:46,930 - INFO - training batch 451, loss: 0.019, 14432/28000 datapoints
2025-03-06 23:00:47,125 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-06 23:00:47,315 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:00:47,505 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:00:47,692 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:47,879 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:00:48,090 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:00:48,277 - INFO - training batch 801, loss: 0.053, 25632/28000 datapoints
2025-03-06 23:00:48,464 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 23:00:48,557 - INFO - validation batch 1, loss: 0.233, 32/6976 datapoints
2025-03-06 23:00:48,605 - INFO - validation batch 51, loss: 7.929, 1632/6976 datapoints
2025-03-06 23:00:48,652 - INFO - validation batch 101, loss: 0.963, 3232/6976 datapoints
2025-03-06 23:00:48,700 - INFO - validation batch 151, loss: 2.514, 4832/6976 datapoints
2025-03-06 23:00:48,747 - INFO - validation batch 201, loss: 3.702, 6432/6976 datapoints
2025-03-06 23:00:48,764 - INFO - Epoch 667/800 done.
2025-03-06 23:00:48,764 - INFO - Final validation performance:
Loss: 3.068, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:00:48,764 - INFO - Beginning epoch 668/800
2025-03-06 23:00:48,769 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 23:00:48,964 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:00:49,151 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:00:49,350 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:00:49,550 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 23:00:49,745 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:00:49,948 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 23:00:50,148 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 23:00:50,333 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:00:50,518 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 23:00:50,704 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:50,894 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 23:00:51,117 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:00:51,333 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:51,544 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:00:51,730 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:00:51,919 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 23:00:52,108 - INFO - training batch 851, loss: 0.127, 27232/28000 datapoints
2025-03-06 23:00:52,203 - INFO - validation batch 1, loss: 0.300, 32/6976 datapoints
2025-03-06 23:00:52,250 - INFO - validation batch 51, loss: 8.269, 1632/6976 datapoints
2025-03-06 23:00:52,298 - INFO - validation batch 101, loss: 1.062, 3232/6976 datapoints
2025-03-06 23:00:52,349 - INFO - validation batch 151, loss: 2.399, 4832/6976 datapoints
2025-03-06 23:00:52,397 - INFO - validation batch 201, loss: 3.223, 6432/6976 datapoints
2025-03-06 23:00:52,414 - INFO - Epoch 668/800 done.
2025-03-06 23:00:52,414 - INFO - Final validation performance:
Loss: 3.050, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:00:52,414 - INFO - Beginning epoch 669/800
2025-03-06 23:00:52,419 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 23:00:52,609 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 23:00:52,796 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:00:52,995 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:00:53,189 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 23:00:53,382 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 23:00:53,580 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:00:53,769 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:00:53,953 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:00:54,142 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-06 23:00:54,330 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:54,521 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:00:54,713 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:00:54,900 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:55,112 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:00:55,334 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:00:55,548 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:00:55,780 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:00:55,875 - INFO - validation batch 1, loss: 0.347, 32/6976 datapoints
2025-03-06 23:00:55,923 - INFO - validation batch 51, loss: 8.627, 1632/6976 datapoints
2025-03-06 23:00:55,971 - INFO - validation batch 101, loss: 1.173, 3232/6976 datapoints
2025-03-06 23:00:56,022 - INFO - validation batch 151, loss: 1.870, 4832/6976 datapoints
2025-03-06 23:00:56,072 - INFO - validation batch 201, loss: 3.700, 6432/6976 datapoints
2025-03-06 23:00:56,091 - INFO - Epoch 669/800 done.
2025-03-06 23:00:56,092 - INFO - Final validation performance:
Loss: 3.143, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:00:56,092 - INFO - Beginning epoch 670/800
2025-03-06 23:00:56,101 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 23:00:56,292 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:00:56,477 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:00:56,674 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:00:56,869 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:00:57,070 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 23:00:57,266 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:00:57,458 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:00:57,642 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:00:57,829 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:00:58,022 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:00:58,240 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-06 23:00:58,431 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:00:58,621 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:00:58,812 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:00:59,020 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:00:59,223 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:00:59,420 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:00:59,517 - INFO - validation batch 1, loss: 0.398, 32/6976 datapoints
2025-03-06 23:00:59,570 - INFO - validation batch 51, loss: 8.470, 1632/6976 datapoints
2025-03-06 23:00:59,623 - INFO - validation batch 101, loss: 1.145, 3232/6976 datapoints
2025-03-06 23:00:59,677 - INFO - validation batch 151, loss: 1.943, 4832/6976 datapoints
2025-03-06 23:00:59,729 - INFO - validation batch 201, loss: 3.467, 6432/6976 datapoints
2025-03-06 23:00:59,748 - INFO - Epoch 670/800 done.
2025-03-06 23:00:59,748 - INFO - Final validation performance:
Loss: 3.084, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:00:59,749 - INFO - Beginning epoch 671/800
2025-03-06 23:00:59,754 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 23:00:59,946 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:01:00,139 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:01:00,333 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:01:00,533 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:01:00,730 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:01:00,929 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:01:01,128 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:01:01,314 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:01:01,502 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:01:01,692 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:01:01,897 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:01:02,093 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:01:02,293 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:01:02,488 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:01:02,684 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:01:02,874 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:01:03,069 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:01:03,166 - INFO - validation batch 1, loss: 0.376, 32/6976 datapoints
2025-03-06 23:01:03,217 - INFO - validation batch 51, loss: 8.440, 1632/6976 datapoints
2025-03-06 23:01:03,268 - INFO - validation batch 101, loss: 1.133, 3232/6976 datapoints
2025-03-06 23:01:03,321 - INFO - validation batch 151, loss: 1.952, 4832/6976 datapoints
2025-03-06 23:01:03,373 - INFO - validation batch 201, loss: 3.502, 6432/6976 datapoints
2025-03-06 23:01:03,394 - INFO - Epoch 671/800 done.
2025-03-06 23:01:03,394 - INFO - Final validation performance:
Loss: 3.081, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:01:03,395 - INFO - Beginning epoch 672/800
2025-03-06 23:01:03,399 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:01:03,593 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:01:03,784 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:01:03,979 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:01:04,184 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:01:04,381 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:01:04,580 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:01:04,774 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:01:04,960 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:01:05,154 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:01:05,349 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:01:05,540 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:01:05,735 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:01:05,931 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:01:06,125 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:01:06,316 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:01:06,509 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:01:06,701 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:01:06,797 - INFO - validation batch 1, loss: 0.357, 32/6976 datapoints
2025-03-06 23:01:06,848 - INFO - validation batch 51, loss: 8.410, 1632/6976 datapoints
2025-03-06 23:01:06,901 - INFO - validation batch 101, loss: 1.135, 3232/6976 datapoints
2025-03-06 23:01:06,953 - INFO - validation batch 151, loss: 2.026, 4832/6976 datapoints
2025-03-06 23:01:07,006 - INFO - validation batch 201, loss: 3.471, 6432/6976 datapoints
2025-03-06 23:01:07,028 - INFO - Epoch 672/800 done.
2025-03-06 23:01:07,028 - INFO - Final validation performance:
Loss: 3.080, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:01:07,029 - INFO - Beginning epoch 673/800
2025-03-06 23:01:07,035 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:01:07,228 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:01:07,412 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:01:07,605 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:01:07,810 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:01:08,012 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:01:08,216 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:01:08,431 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:01:08,619 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:01:08,807 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:01:08,996 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:01:09,187 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:01:09,374 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:01:09,568 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:01:09,774 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:01:09,964 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:01:10,158 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:01:10,349 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:01:10,443 - INFO - validation batch 1, loss: 0.334, 32/6976 datapoints
2025-03-06 23:01:10,493 - INFO - validation batch 51, loss: 8.365, 1632/6976 datapoints
2025-03-06 23:01:10,540 - INFO - validation batch 101, loss: 1.131, 3232/6976 datapoints
2025-03-06 23:01:10,589 - INFO - validation batch 151, loss: 2.109, 4832/6976 datapoints
2025-03-06 23:01:10,637 - INFO - validation batch 201, loss: 3.488, 6432/6976 datapoints
2025-03-06 23:01:10,654 - INFO - Epoch 673/800 done.
2025-03-06 23:01:10,654 - INFO - Final validation performance:
Loss: 3.086, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:01:10,654 - INFO - Beginning epoch 674/800
2025-03-06 23:01:10,659 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:01:10,850 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:01:11,042 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:01:11,235 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:01:11,430 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:01:11,624 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:01:11,820 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:01:12,015 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:01:12,200 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:01:12,385 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:01:12,571 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:01:12,759 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:01:12,949 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:01:13,141 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:01:13,330 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:01:13,519 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:01:13,708 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:01:13,894 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:01:13,990 - INFO - validation batch 1, loss: 0.314, 32/6976 datapoints
2025-03-06 23:01:14,037 - INFO - validation batch 51, loss: 8.349, 1632/6976 datapoints
2025-03-06 23:01:14,091 - INFO - validation batch 101, loss: 1.135, 3232/6976 datapoints
2025-03-06 23:01:14,149 - INFO - validation batch 151, loss: 2.169, 4832/6976 datapoints
2025-03-06 23:01:14,200 - INFO - validation batch 201, loss: 3.502, 6432/6976 datapoints
2025-03-06 23:01:14,217 - INFO - Epoch 674/800 done.
2025-03-06 23:01:14,217 - INFO - Final validation performance:
Loss: 3.094, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:01:14,217 - INFO - Beginning epoch 675/800
2025-03-06 23:01:14,222 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:01:14,410 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:01:14,601 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:01:14,795 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:01:14,991 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:01:15,189 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:01:15,391 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:01:15,583 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:01:15,768 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:01:15,956 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:01:16,145 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:01:16,333 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:01:16,524 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:01:16,712 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:01:16,898 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:01:17,090 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:01:17,280 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:01:17,469 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:01:17,563 - INFO - validation batch 1, loss: 0.306, 32/6976 datapoints
2025-03-06 23:01:17,610 - INFO - validation batch 51, loss: 8.374, 1632/6976 datapoints
2025-03-06 23:01:17,658 - INFO - validation batch 101, loss: 1.122, 3232/6976 datapoints
2025-03-06 23:01:17,709 - INFO - validation batch 151, loss: 2.216, 4832/6976 datapoints
2025-03-06 23:01:17,756 - INFO - validation batch 201, loss: 3.520, 6432/6976 datapoints
2025-03-06 23:01:17,774 - INFO - Epoch 675/800 done.
2025-03-06 23:01:17,774 - INFO - Final validation performance:
Loss: 3.108, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:01:17,775 - INFO - Beginning epoch 676/800
2025-03-06 23:01:17,780 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:01:17,977 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:01:18,167 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:01:18,390 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:01:18,590 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:01:18,835 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:01:19,063 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:01:19,272 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:01:19,462 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:01:19,658 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:01:19,865 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:01:20,074 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 23:01:20,279 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-06 23:01:20,640 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 23:01:20,854 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:01:21,059 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:01:21,271 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 23:01:21,470 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:01:21,578 - INFO - validation batch 1, loss: 0.294, 32/6976 datapoints
2025-03-06 23:01:21,632 - INFO - validation batch 51, loss: 7.646, 1632/6976 datapoints
2025-03-06 23:01:21,687 - INFO - validation batch 101, loss: 1.227, 3232/6976 datapoints
2025-03-06 23:01:21,744 - INFO - validation batch 151, loss: 2.346, 4832/6976 datapoints
2025-03-06 23:01:21,802 - INFO - validation batch 201, loss: 3.678, 6432/6976 datapoints
2025-03-06 23:01:21,820 - INFO - Epoch 676/800 done.
2025-03-06 23:01:21,820 - INFO - Final validation performance:
Loss: 3.038, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:01:21,820 - INFO - Beginning epoch 677/800
2025-03-06 23:01:21,829 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 23:01:22,032 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:01:22,238 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-06 23:01:22,435 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:01:22,647 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-06 23:01:22,850 - INFO - training batch 251, loss: 0.017, 8032/28000 datapoints
2025-03-06 23:01:23,065 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-06 23:01:23,262 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:01:23,463 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:01:23,659 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:01:23,853 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:01:24,054 - INFO - training batch 551, loss: 0.042, 17632/28000 datapoints
2025-03-06 23:01:24,256 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-06 23:01:24,459 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:01:24,651 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:01:24,859 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:01:25,059 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:01:25,268 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:01:25,368 - INFO - validation batch 1, loss: 0.507, 32/6976 datapoints
2025-03-06 23:01:25,419 - INFO - validation batch 51, loss: 8.540, 1632/6976 datapoints
2025-03-06 23:01:25,476 - INFO - validation batch 101, loss: 1.265, 3232/6976 datapoints
2025-03-06 23:01:25,529 - INFO - validation batch 151, loss: 2.062, 4832/6976 datapoints
2025-03-06 23:01:25,577 - INFO - validation batch 201, loss: 3.344, 6432/6976 datapoints
2025-03-06 23:01:25,599 - INFO - Epoch 677/800 done.
2025-03-06 23:01:25,599 - INFO - Final validation performance:
Loss: 3.144, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:01:25,600 - INFO - Beginning epoch 678/800
2025-03-06 23:01:25,606 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 23:01:25,819 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:01:26,044 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:01:26,249 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 23:01:26,458 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:01:26,670 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-06 23:01:26,887 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:01:27,096 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:01:27,308 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 23:01:27,514 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:01:27,720 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:01:27,941 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 23:01:28,163 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:01:28,372 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:01:28,612 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:01:28,832 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 23:01:29,056 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-06 23:01:29,270 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:01:29,377 - INFO - validation batch 1, loss: 0.529, 32/6976 datapoints
2025-03-06 23:01:29,429 - INFO - validation batch 51, loss: 8.140, 1632/6976 datapoints
2025-03-06 23:01:29,496 - INFO - validation batch 101, loss: 1.268, 3232/6976 datapoints
2025-03-06 23:01:29,550 - INFO - validation batch 151, loss: 2.205, 4832/6976 datapoints
2025-03-06 23:01:29,601 - INFO - validation batch 201, loss: 3.631, 6432/6976 datapoints
2025-03-06 23:01:29,618 - INFO - Epoch 678/800 done.
2025-03-06 23:01:29,618 - INFO - Final validation performance:
Loss: 3.155, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:01:29,619 - INFO - Beginning epoch 679/800
2025-03-06 23:01:29,625 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:01:29,847 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:01:30,054 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:01:30,257 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:01:30,464 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:01:30,661 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 23:01:30,867 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 23:01:31,067 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 23:01:31,262 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:01:31,460 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 23:01:31,655 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:01:31,858 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:01:32,064 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 23:01:32,270 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:01:32,465 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:01:32,669 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:01:32,867 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:01:33,063 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:01:33,157 - INFO - validation batch 1, loss: 0.533, 32/6976 datapoints
2025-03-06 23:01:33,208 - INFO - validation batch 51, loss: 8.379, 1632/6976 datapoints
2025-03-06 23:01:33,272 - INFO - validation batch 101, loss: 1.246, 3232/6976 datapoints
2025-03-06 23:01:33,320 - INFO - validation batch 151, loss: 1.997, 4832/6976 datapoints
2025-03-06 23:01:33,367 - INFO - validation batch 201, loss: 3.566, 6432/6976 datapoints
2025-03-06 23:01:33,383 - INFO - Epoch 679/800 done.
2025-03-06 23:01:33,384 - INFO - Final validation performance:
Loss: 3.144, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:01:33,384 - INFO - Beginning epoch 680/800
2025-03-06 23:01:33,389 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 23:01:33,595 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:01:33,790 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:01:33,996 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:01:34,217 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:01:34,415 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 23:01:34,624 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:01:34,821 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 23:01:35,016 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 23:01:35,219 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:01:35,420 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-06 23:01:35,621 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:01:35,824 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-06 23:01:36,032 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:01:36,225 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:01:36,448 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:01:36,657 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 23:01:36,932 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:01:37,030 - INFO - validation batch 1, loss: 0.405, 32/6976 datapoints
2025-03-06 23:01:37,138 - INFO - validation batch 51, loss: 8.682, 1632/6976 datapoints
2025-03-06 23:01:37,234 - INFO - validation batch 101, loss: 1.081, 3232/6976 datapoints
2025-03-06 23:01:37,304 - INFO - validation batch 151, loss: 2.175, 4832/6976 datapoints
2025-03-06 23:01:37,352 - INFO - validation batch 201, loss: 3.694, 6432/6976 datapoints
2025-03-06 23:01:37,368 - INFO - Epoch 680/800 done.
2025-03-06 23:01:37,369 - INFO - Final validation performance:
Loss: 3.207, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:01:37,369 - INFO - Beginning epoch 681/800
2025-03-06 23:01:37,374 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 23:01:37,640 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 23:01:38,196 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:01:38,653 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 23:01:38,956 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:01:39,316 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 23:01:39,758 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:01:40,081 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-06 23:01:40,413 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 23:01:40,806 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 23:01:41,157 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-06 23:01:41,417 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 23:01:41,792 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:01:42,099 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:01:42,408 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:01:42,703 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:01:42,996 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:01:43,269 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:01:43,411 - INFO - validation batch 1, loss: 0.521, 32/6976 datapoints
2025-03-06 23:01:43,480 - INFO - validation batch 51, loss: 8.691, 1632/6976 datapoints
2025-03-06 23:01:43,538 - INFO - validation batch 101, loss: 1.266, 3232/6976 datapoints
2025-03-06 23:01:43,594 - INFO - validation batch 151, loss: 1.914, 4832/6976 datapoints
2025-03-06 23:01:43,652 - INFO - validation batch 201, loss: 3.622, 6432/6976 datapoints
2025-03-06 23:01:43,677 - INFO - Epoch 681/800 done.
2025-03-06 23:01:43,678 - INFO - Final validation performance:
Loss: 3.203, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:01:43,679 - INFO - Beginning epoch 682/800
2025-03-06 23:01:43,688 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:01:43,898 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:01:44,325 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:01:44,553 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:01:44,758 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:01:44,946 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 23:01:45,142 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:01:45,341 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 23:01:45,527 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:01:45,717 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:01:45,906 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:01:46,103 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:01:46,288 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:01:46,474 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:01:46,661 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:01:46,849 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:01:47,036 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:01:47,228 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:01:47,324 - INFO - validation batch 1, loss: 0.476, 32/6976 datapoints
2025-03-06 23:01:47,372 - INFO - validation batch 51, loss: 8.867, 1632/6976 datapoints
2025-03-06 23:01:47,420 - INFO - validation batch 101, loss: 1.304, 3232/6976 datapoints
2025-03-06 23:01:47,468 - INFO - validation batch 151, loss: 1.869, 4832/6976 datapoints
2025-03-06 23:01:47,515 - INFO - validation batch 201, loss: 3.665, 6432/6976 datapoints
2025-03-06 23:01:47,532 - INFO - Epoch 682/800 done.
2025-03-06 23:01:47,533 - INFO - Final validation performance:
Loss: 3.236, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:01:47,533 - INFO - Beginning epoch 683/800
2025-03-06 23:01:47,538 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:01:47,727 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:01:47,918 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:01:48,118 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:01:48,316 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:01:48,518 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:01:48,742 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:01:48,936 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:01:49,124 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:01:49,314 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:01:49,503 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:01:49,691 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:01:49,880 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:01:50,074 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:01:50,261 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:01:50,453 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:01:50,646 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:01:50,832 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:01:50,928 - INFO - validation batch 1, loss: 0.441, 32/6976 datapoints
2025-03-06 23:01:50,975 - INFO - validation batch 51, loss: 8.813, 1632/6976 datapoints
2025-03-06 23:01:51,034 - INFO - validation batch 101, loss: 1.268, 3232/6976 datapoints
2025-03-06 23:01:51,082 - INFO - validation batch 151, loss: 1.919, 4832/6976 datapoints
2025-03-06 23:01:51,129 - INFO - validation batch 201, loss: 3.625, 6432/6976 datapoints
2025-03-06 23:01:51,146 - INFO - Epoch 683/800 done.
2025-03-06 23:01:51,146 - INFO - Final validation performance:
Loss: 3.213, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:01:51,146 - INFO - Beginning epoch 684/800
2025-03-06 23:01:51,151 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:01:51,340 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:01:51,530 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:01:51,723 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:01:51,920 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:01:52,119 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:01:52,319 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:01:52,511 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:01:52,693 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:01:52,881 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:01:53,069 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:01:53,261 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:01:53,451 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:01:53,642 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:01:53,827 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:01:54,021 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:01:54,211 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:01:54,397 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:01:54,491 - INFO - validation batch 1, loss: 0.419, 32/6976 datapoints
2025-03-06 23:01:54,539 - INFO - validation batch 51, loss: 8.754, 1632/6976 datapoints
2025-03-06 23:01:54,587 - INFO - validation batch 101, loss: 1.227, 3232/6976 datapoints
2025-03-06 23:01:54,635 - INFO - validation batch 151, loss: 1.987, 4832/6976 datapoints
2025-03-06 23:01:54,682 - INFO - validation batch 201, loss: 3.632, 6432/6976 datapoints
2025-03-06 23:01:54,698 - INFO - Epoch 684/800 done.
2025-03-06 23:01:54,698 - INFO - Final validation performance:
Loss: 3.204, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:01:54,699 - INFO - Beginning epoch 685/800
2025-03-06 23:01:54,704 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:01:54,896 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:01:55,085 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:01:55,284 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:01:55,483 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:01:55,674 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:01:55,878 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:01:56,074 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:01:56,261 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:01:56,456 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:01:56,647 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:01:56,836 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:01:57,027 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:01:57,223 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:01:57,411 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:01:57,600 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:01:57,788 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:01:57,973 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:01:58,068 - INFO - validation batch 1, loss: 0.391, 32/6976 datapoints
2025-03-06 23:01:58,116 - INFO - validation batch 51, loss: 8.681, 1632/6976 datapoints
2025-03-06 23:01:58,163 - INFO - validation batch 101, loss: 1.188, 3232/6976 datapoints
2025-03-06 23:01:58,210 - INFO - validation batch 151, loss: 2.065, 4832/6976 datapoints
2025-03-06 23:01:58,257 - INFO - validation batch 201, loss: 3.636, 6432/6976 datapoints
2025-03-06 23:01:58,274 - INFO - Epoch 685/800 done.
2025-03-06 23:01:58,275 - INFO - Final validation performance:
Loss: 3.192, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:01:58,275 - INFO - Beginning epoch 686/800
2025-03-06 23:01:58,280 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:01:58,472 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:01:58,660 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:01:58,883 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:01:59,087 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:01:59,300 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:01:59,569 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:01:59,766 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:01:59,965 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:02:00,166 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:02:00,359 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:02:00,552 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:02:00,751 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:02:00,954 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:01,155 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:02:01,352 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:02:01,544 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:02:01,733 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:02:01,828 - INFO - validation batch 1, loss: 0.369, 32/6976 datapoints
2025-03-06 23:02:01,882 - INFO - validation batch 51, loss: 8.609, 1632/6976 datapoints
2025-03-06 23:02:01,935 - INFO - validation batch 101, loss: 1.146, 3232/6976 datapoints
2025-03-06 23:02:01,985 - INFO - validation batch 151, loss: 2.149, 4832/6976 datapoints
2025-03-06 23:02:02,036 - INFO - validation batch 201, loss: 3.637, 6432/6976 datapoints
2025-03-06 23:02:02,052 - INFO - Epoch 686/800 done.
2025-03-06 23:02:02,053 - INFO - Final validation performance:
Loss: 3.182, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:02:02,053 - INFO - Beginning epoch 687/800
2025-03-06 23:02:02,058 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:02:02,248 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:02:02,436 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:02:02,632 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:02:02,829 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:02:03,023 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:02:03,227 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:02:03,421 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:02:03,605 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:02:03,791 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:02:03,981 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:02:04,174 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:02:04,366 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:02:04,558 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:04,748 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:02:04,937 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:02:05,126 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:02:05,320 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:02:05,414 - INFO - validation batch 1, loss: 0.360, 32/6976 datapoints
2025-03-06 23:02:05,463 - INFO - validation batch 51, loss: 8.562, 1632/6976 datapoints
2025-03-06 23:02:05,511 - INFO - validation batch 101, loss: 1.109, 3232/6976 datapoints
2025-03-06 23:02:05,559 - INFO - validation batch 151, loss: 2.230, 4832/6976 datapoints
2025-03-06 23:02:05,606 - INFO - validation batch 201, loss: 3.669, 6432/6976 datapoints
2025-03-06 23:02:05,623 - INFO - Epoch 687/800 done.
2025-03-06 23:02:05,623 - INFO - Final validation performance:
Loss: 3.186, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:02:05,624 - INFO - Beginning epoch 688/800
2025-03-06 23:02:05,629 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:02:05,819 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:02:06,015 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:02:06,213 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:02:06,409 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:02:06,601 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:02:06,799 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:02:06,996 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:02:07,183 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:02:07,380 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:02:07,572 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:02:07,764 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:02:07,956 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:02:08,151 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:08,339 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:02:08,530 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:02:08,724 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:02:08,932 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:02:09,028 - INFO - validation batch 1, loss: 0.343, 32/6976 datapoints
2025-03-06 23:02:09,077 - INFO - validation batch 51, loss: 8.540, 1632/6976 datapoints
2025-03-06 23:02:09,125 - INFO - validation batch 101, loss: 1.088, 3232/6976 datapoints
2025-03-06 23:02:09,172 - INFO - validation batch 151, loss: 2.378, 4832/6976 datapoints
2025-03-06 23:02:09,219 - INFO - validation batch 201, loss: 3.711, 6432/6976 datapoints
2025-03-06 23:02:09,236 - INFO - Epoch 688/800 done.
2025-03-06 23:02:09,236 - INFO - Final validation performance:
Loss: 3.212, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:02:09,237 - INFO - Beginning epoch 689/800
2025-03-06 23:02:09,244 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:02:09,435 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:02:09,626 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:02:09,822 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:02:10,024 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:02:10,212 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:02:10,415 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:02:10,615 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:02:10,799 - INFO - training batch 401, loss: 0.885, 12832/28000 datapoints
2025-03-06 23:02:10,994 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:02:11,183 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:02:11,378 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 23:02:11,569 - INFO - training batch 601, loss: 0.035, 19232/28000 datapoints
2025-03-06 23:02:11,766 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:11,957 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-06 23:02:12,151 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:02:12,342 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 23:02:12,529 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:02:12,625 - INFO - validation batch 1, loss: 0.347, 32/6976 datapoints
2025-03-06 23:02:12,672 - INFO - validation batch 51, loss: 9.231, 1632/6976 datapoints
2025-03-06 23:02:12,720 - INFO - validation batch 101, loss: 1.315, 3232/6976 datapoints
2025-03-06 23:02:12,767 - INFO - validation batch 151, loss: 2.059, 4832/6976 datapoints
2025-03-06 23:02:12,815 - INFO - validation batch 201, loss: 4.120, 6432/6976 datapoints
2025-03-06 23:02:12,832 - INFO - Epoch 689/800 done.
2025-03-06 23:02:12,832 - INFO - Final validation performance:
Loss: 3.415, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:02:12,833 - INFO - Beginning epoch 690/800
2025-03-06 23:02:12,838 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 23:02:13,025 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 23:02:13,215 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:02:13,417 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:02:13,615 - INFO - training batch 201, loss: 0.053, 6432/28000 datapoints
2025-03-06 23:02:13,804 - INFO - training batch 251, loss: 0.252, 8032/28000 datapoints
2025-03-06 23:02:14,013 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:02:14,207 - INFO - training batch 351, loss: 0.016, 11232/28000 datapoints
2025-03-06 23:02:14,393 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:02:14,581 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 23:02:14,772 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:02:14,965 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:02:15,160 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:02:15,359 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:15,551 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:02:15,745 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:02:15,938 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:02:16,128 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:02:16,225 - INFO - validation batch 1, loss: 0.464, 32/6976 datapoints
2025-03-06 23:02:16,272 - INFO - validation batch 51, loss: 8.923, 1632/6976 datapoints
2025-03-06 23:02:16,320 - INFO - validation batch 101, loss: 1.428, 3232/6976 datapoints
2025-03-06 23:02:16,367 - INFO - validation batch 151, loss: 2.291, 4832/6976 datapoints
2025-03-06 23:02:16,417 - INFO - validation batch 201, loss: 4.208, 6432/6976 datapoints
2025-03-06 23:02:16,433 - INFO - Epoch 690/800 done.
2025-03-06 23:02:16,433 - INFO - Final validation performance:
Loss: 3.463, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:02:16,434 - INFO - Beginning epoch 691/800
2025-03-06 23:02:16,439 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-06 23:02:16,626 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:02:16,813 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:02:17,010 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:02:17,204 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:02:17,397 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 23:02:17,595 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-06 23:02:17,789 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 23:02:17,972 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:02:18,162 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:02:18,350 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:02:18,543 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:02:18,733 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:02:18,935 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:19,148 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-06 23:02:19,341 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 23:02:19,535 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:02:19,726 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:02:19,825 - INFO - validation batch 1, loss: 0.296, 32/6976 datapoints
2025-03-06 23:02:19,879 - INFO - validation batch 51, loss: 8.581, 1632/6976 datapoints
2025-03-06 23:02:19,931 - INFO - validation batch 101, loss: 1.108, 3232/6976 datapoints
2025-03-06 23:02:19,984 - INFO - validation batch 151, loss: 1.989, 4832/6976 datapoints
2025-03-06 23:02:20,037 - INFO - validation batch 201, loss: 3.635, 6432/6976 datapoints
2025-03-06 23:02:20,053 - INFO - Epoch 691/800 done.
2025-03-06 23:02:20,053 - INFO - Final validation performance:
Loss: 3.122, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:02:20,054 - INFO - Beginning epoch 692/800
2025-03-06 23:02:20,058 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 23:02:20,246 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:02:20,440 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:02:20,656 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:02:20,918 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:02:21,132 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:02:21,348 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:02:21,542 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:02:21,738 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:02:21,934 - INFO - training batch 451, loss: 0.377, 14432/28000 datapoints
2025-03-06 23:02:22,133 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 23:02:22,336 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:02:22,541 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:02:22,744 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:22,946 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:02:23,147 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:02:23,348 - INFO - training batch 801, loss: 0.035, 25632/28000 datapoints
2025-03-06 23:02:23,540 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-06 23:02:23,639 - INFO - validation batch 1, loss: 0.370, 32/6976 datapoints
2025-03-06 23:02:23,690 - INFO - validation batch 51, loss: 8.566, 1632/6976 datapoints
2025-03-06 23:02:23,741 - INFO - validation batch 101, loss: 1.372, 3232/6976 datapoints
2025-03-06 23:02:23,791 - INFO - validation batch 151, loss: 1.903, 4832/6976 datapoints
2025-03-06 23:02:23,842 - INFO - validation batch 201, loss: 3.906, 6432/6976 datapoints
2025-03-06 23:02:23,858 - INFO - Epoch 692/800 done.
2025-03-06 23:02:23,858 - INFO - Final validation performance:
Loss: 3.223, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:02:23,859 - INFO - Beginning epoch 693/800
2025-03-06 23:02:23,864 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 23:02:24,064 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:02:24,259 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:02:24,450 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:02:24,645 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:02:24,837 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:02:25,037 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:02:25,231 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:02:25,421 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:02:25,611 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:02:25,803 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:02:25,995 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-06 23:02:26,187 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:02:26,379 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:26,566 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:02:26,756 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:02:26,947 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:02:27,137 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 23:02:27,233 - INFO - validation batch 1, loss: 0.402, 32/6976 datapoints
2025-03-06 23:02:27,284 - INFO - validation batch 51, loss: 8.729, 1632/6976 datapoints
2025-03-06 23:02:27,335 - INFO - validation batch 101, loss: 1.261, 3232/6976 datapoints
2025-03-06 23:02:27,382 - INFO - validation batch 151, loss: 1.914, 4832/6976 datapoints
2025-03-06 23:02:27,430 - INFO - validation batch 201, loss: 3.802, 6432/6976 datapoints
2025-03-06 23:02:27,446 - INFO - Epoch 693/800 done.
2025-03-06 23:02:27,446 - INFO - Final validation performance:
Loss: 3.222, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:02:27,447 - INFO - Beginning epoch 694/800
2025-03-06 23:02:27,451 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 23:02:27,639 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:02:27,833 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:02:28,026 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:02:28,219 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:02:28,412 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:02:28,610 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:02:28,799 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:02:28,988 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:02:29,206 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:02:29,400 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:02:29,590 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:02:29,778 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:02:29,969 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:30,160 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:02:30,349 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:02:30,538 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:02:30,723 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:02:30,818 - INFO - validation batch 1, loss: 0.409, 32/6976 datapoints
2025-03-06 23:02:30,865 - INFO - validation batch 51, loss: 8.798, 1632/6976 datapoints
2025-03-06 23:02:30,913 - INFO - validation batch 101, loss: 1.240, 3232/6976 datapoints
2025-03-06 23:02:30,960 - INFO - validation batch 151, loss: 1.917, 4832/6976 datapoints
2025-03-06 23:02:31,011 - INFO - validation batch 201, loss: 3.725, 6432/6976 datapoints
2025-03-06 23:02:31,035 - INFO - Epoch 694/800 done.
2025-03-06 23:02:31,038 - INFO - Final validation performance:
Loss: 3.218, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:02:31,038 - INFO - Beginning epoch 695/800
2025-03-06 23:02:31,062 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 23:02:31,265 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:02:31,459 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:02:31,654 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:02:31,847 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:02:32,039 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:02:32,237 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:02:32,429 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:02:32,612 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:02:32,801 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:02:32,992 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:02:33,183 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:02:33,375 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:02:33,567 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:33,757 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:02:33,948 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:02:34,140 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:02:34,326 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:02:34,419 - INFO - validation batch 1, loss: 0.405, 32/6976 datapoints
2025-03-06 23:02:34,467 - INFO - validation batch 51, loss: 8.802, 1632/6976 datapoints
2025-03-06 23:02:34,515 - INFO - validation batch 101, loss: 1.235, 3232/6976 datapoints
2025-03-06 23:02:34,562 - INFO - validation batch 151, loss: 1.988, 4832/6976 datapoints
2025-03-06 23:02:34,612 - INFO - validation batch 201, loss: 3.727, 6432/6976 datapoints
2025-03-06 23:02:34,629 - INFO - Epoch 695/800 done.
2025-03-06 23:02:34,629 - INFO - Final validation performance:
Loss: 3.231, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:02:34,630 - INFO - Beginning epoch 696/800
2025-03-06 23:02:34,634 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:02:34,824 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:02:35,015 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:02:35,208 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:02:35,425 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:02:35,620 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:02:35,838 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:02:36,050 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:02:36,246 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:02:36,444 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:02:36,642 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:02:36,841 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:02:37,038 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:02:37,235 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:37,442 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:02:37,638 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:02:37,835 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:02:38,057 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:02:38,151 - INFO - validation batch 1, loss: 0.395, 32/6976 datapoints
2025-03-06 23:02:38,199 - INFO - validation batch 51, loss: 8.819, 1632/6976 datapoints
2025-03-06 23:02:38,247 - INFO - validation batch 101, loss: 1.217, 3232/6976 datapoints
2025-03-06 23:02:38,295 - INFO - validation batch 151, loss: 2.050, 4832/6976 datapoints
2025-03-06 23:02:38,343 - INFO - validation batch 201, loss: 3.730, 6432/6976 datapoints
2025-03-06 23:02:38,361 - INFO - Epoch 696/800 done.
2025-03-06 23:02:38,361 - INFO - Final validation performance:
Loss: 3.242, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:02:38,361 - INFO - Beginning epoch 697/800
2025-03-06 23:02:38,366 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:02:38,555 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:02:38,744 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:02:38,944 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:02:39,152 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:02:39,372 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:02:39,576 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:02:39,770 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:02:39,967 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:02:40,166 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:02:40,358 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:02:40,556 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:02:40,748 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:02:40,956 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:41,150 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:02:41,342 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:02:41,544 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:02:41,734 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:02:41,831 - INFO - validation batch 1, loss: 0.383, 32/6976 datapoints
2025-03-06 23:02:41,888 - INFO - validation batch 51, loss: 8.806, 1632/6976 datapoints
2025-03-06 23:02:41,965 - INFO - validation batch 101, loss: 1.195, 3232/6976 datapoints
2025-03-06 23:02:42,035 - INFO - validation batch 151, loss: 2.120, 4832/6976 datapoints
2025-03-06 23:02:42,088 - INFO - validation batch 201, loss: 3.732, 6432/6976 datapoints
2025-03-06 23:02:42,105 - INFO - Epoch 697/800 done.
2025-03-06 23:02:42,105 - INFO - Final validation performance:
Loss: 3.247, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:02:42,106 - INFO - Beginning epoch 698/800
2025-03-06 23:02:42,110 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:02:42,303 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:02:42,505 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:02:42,701 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:02:42,899 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:02:43,098 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:02:43,300 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:02:43,500 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:02:43,689 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:02:43,882 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:02:44,077 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:02:44,272 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:02:44,468 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:02:44,663 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:44,856 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:02:45,065 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:02:45,264 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:02:45,459 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:02:45,554 - INFO - validation batch 1, loss: 0.358, 32/6976 datapoints
2025-03-06 23:02:45,606 - INFO - validation batch 51, loss: 8.761, 1632/6976 datapoints
2025-03-06 23:02:45,660 - INFO - validation batch 101, loss: 1.170, 3232/6976 datapoints
2025-03-06 23:02:45,714 - INFO - validation batch 151, loss: 2.217, 4832/6976 datapoints
2025-03-06 23:02:45,767 - INFO - validation batch 201, loss: 3.745, 6432/6976 datapoints
2025-03-06 23:02:45,786 - INFO - Epoch 698/800 done.
2025-03-06 23:02:45,786 - INFO - Final validation performance:
Loss: 3.250, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:02:45,787 - INFO - Beginning epoch 699/800
2025-03-06 23:02:45,792 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:02:45,985 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:02:46,177 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:02:46,375 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:02:46,571 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:02:46,764 - INFO - training batch 251, loss: 0.018, 8032/28000 datapoints
2025-03-06 23:02:46,963 - INFO - training batch 301, loss: 0.088, 9632/28000 datapoints
2025-03-06 23:02:47,152 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:02:47,342 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:02:47,537 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 23:02:47,727 - INFO - training batch 501, loss: 0.101, 16032/28000 datapoints
2025-03-06 23:02:47,916 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-06 23:02:48,112 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-06 23:02:48,304 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:48,490 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 23:02:48,679 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 23:02:48,871 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:02:49,067 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 23:02:49,163 - INFO - validation batch 1, loss: 0.249, 32/6976 datapoints
2025-03-06 23:02:49,210 - INFO - validation batch 51, loss: 8.495, 1632/6976 datapoints
2025-03-06 23:02:49,277 - INFO - validation batch 101, loss: 1.098, 3232/6976 datapoints
2025-03-06 23:02:49,339 - INFO - validation batch 151, loss: 2.166, 4832/6976 datapoints
2025-03-06 23:02:49,386 - INFO - validation batch 201, loss: 3.919, 6432/6976 datapoints
2025-03-06 23:02:49,406 - INFO - Epoch 699/800 done.
2025-03-06 23:02:49,406 - INFO - Final validation performance:
Loss: 3.185, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:02:49,407 - INFO - Beginning epoch 700/800
2025-03-06 23:02:49,412 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 23:02:49,604 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:02:49,793 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:02:49,985 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:02:50,183 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:02:50,377 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:02:50,575 - INFO - training batch 301, loss: 0.018, 9632/28000 datapoints
2025-03-06 23:02:50,766 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 23:02:50,949 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:02:51,148 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:02:51,340 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 23:02:51,532 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:02:51,721 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:02:51,911 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:52,106 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:02:52,296 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:02:52,486 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:02:52,675 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-06 23:02:52,770 - INFO - validation batch 1, loss: 0.219, 32/6976 datapoints
2025-03-06 23:02:52,817 - INFO - validation batch 51, loss: 8.615, 1632/6976 datapoints
2025-03-06 23:02:52,866 - INFO - validation batch 101, loss: 1.185, 3232/6976 datapoints
2025-03-06 23:02:52,913 - INFO - validation batch 151, loss: 1.939, 4832/6976 datapoints
2025-03-06 23:02:52,964 - INFO - validation batch 201, loss: 3.864, 6432/6976 datapoints
2025-03-06 23:02:52,984 - INFO - Epoch 700/800 done.
2025-03-06 23:02:52,984 - INFO - Final validation performance:
Loss: 3.164, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:02:52,985 - INFO - Beginning epoch 701/800
2025-03-06 23:02:52,991 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:02:53,182 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:02:53,370 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:02:53,572 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:02:53,767 - INFO - training batch 201, loss: 0.056, 6432/28000 datapoints
2025-03-06 23:02:53,958 - INFO - training batch 251, loss: 0.033, 8032/28000 datapoints
2025-03-06 23:02:54,160 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 23:02:54,353 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:02:54,538 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:02:54,728 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 23:02:54,920 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:02:55,116 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 23:02:55,309 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 23:02:55,503 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 23:02:55,697 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:02:55,884 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:02:56,080 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:02:56,267 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:02:56,365 - INFO - validation batch 1, loss: 0.368, 32/6976 datapoints
2025-03-06 23:02:56,412 - INFO - validation batch 51, loss: 8.863, 1632/6976 datapoints
2025-03-06 23:02:56,459 - INFO - validation batch 101, loss: 1.328, 3232/6976 datapoints
2025-03-06 23:02:56,506 - INFO - validation batch 151, loss: 1.957, 4832/6976 datapoints
2025-03-06 23:02:56,554 - INFO - validation batch 201, loss: 3.877, 6432/6976 datapoints
2025-03-06 23:02:56,570 - INFO - Epoch 701/800 done.
2025-03-06 23:02:56,570 - INFO - Final validation performance:
Loss: 3.279, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:02:56,570 - INFO - Beginning epoch 702/800
2025-03-06 23:02:56,577 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 23:02:56,765 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:02:56,956 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:02:57,152 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:02:57,350 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:02:57,549 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:02:57,748 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:02:57,941 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:02:58,131 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:02:58,325 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:02:58,514 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:02:58,707 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:02:58,899 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:02:59,097 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:02:59,290 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:02:59,507 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:02:59,707 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:02:59,896 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:03:00,008 - INFO - validation batch 1, loss: 0.325, 32/6976 datapoints
2025-03-06 23:03:00,063 - INFO - validation batch 51, loss: 8.901, 1632/6976 datapoints
2025-03-06 23:03:00,118 - INFO - validation batch 101, loss: 1.269, 3232/6976 datapoints
2025-03-06 23:03:00,172 - INFO - validation batch 151, loss: 2.019, 4832/6976 datapoints
2025-03-06 23:03:00,228 - INFO - validation batch 201, loss: 3.926, 6432/6976 datapoints
2025-03-06 23:03:00,247 - INFO - Epoch 702/800 done.
2025-03-06 23:03:00,247 - INFO - Final validation performance:
Loss: 3.288, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:03:00,248 - INFO - Beginning epoch 703/800
2025-03-06 23:03:00,252 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 23:03:00,442 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:03:00,638 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:03:00,833 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:03:01,034 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:03:01,232 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:03:01,433 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:03:01,630 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:03:01,819 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:03:02,011 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:03:02,212 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:03:02,407 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:03:02,601 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:03:02,796 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:02,991 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:03:03,183 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:03:03,381 - INFO - training batch 801, loss: 0.054, 25632/28000 datapoints
2025-03-06 23:03:03,578 - INFO - training batch 851, loss: 0.085, 27232/28000 datapoints
2025-03-06 23:03:03,681 - INFO - validation batch 1, loss: 0.304, 32/6976 datapoints
2025-03-06 23:03:03,731 - INFO - validation batch 51, loss: 7.907, 1632/6976 datapoints
2025-03-06 23:03:03,779 - INFO - validation batch 101, loss: 0.703, 3232/6976 datapoints
2025-03-06 23:03:03,828 - INFO - validation batch 151, loss: 2.424, 4832/6976 datapoints
2025-03-06 23:03:03,875 - INFO - validation batch 201, loss: 3.227, 6432/6976 datapoints
2025-03-06 23:03:03,891 - INFO - Epoch 703/800 done.
2025-03-06 23:03:03,891 - INFO - Final validation performance:
Loss: 2.913, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 23:03:03,892 - INFO - Beginning epoch 704/800
2025-03-06 23:03:03,897 - INFO - training batch 1, loss: 0.243, 32/28000 datapoints
2025-03-06 23:03:04,083 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 23:03:04,276 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:03:04,472 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 23:03:04,669 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:03:04,861 - INFO - training batch 251, loss: 0.043, 8032/28000 datapoints
2025-03-06 23:03:05,063 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:03:05,253 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 23:03:05,443 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 23:03:05,633 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-06 23:03:05,826 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:03:06,027 - INFO - training batch 551, loss: 0.084, 17632/28000 datapoints
2025-03-06 23:03:06,216 - INFO - training batch 601, loss: 0.242, 19232/28000 datapoints
2025-03-06 23:03:06,414 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:06,596 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 23:03:06,786 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:03:06,977 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:03:07,166 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 23:03:07,263 - INFO - validation batch 1, loss: 0.242, 32/6976 datapoints
2025-03-06 23:03:07,311 - INFO - validation batch 51, loss: 8.064, 1632/6976 datapoints
2025-03-06 23:03:07,360 - INFO - validation batch 101, loss: 1.084, 3232/6976 datapoints
2025-03-06 23:03:07,408 - INFO - validation batch 151, loss: 2.476, 4832/6976 datapoints
2025-03-06 23:03:07,455 - INFO - validation batch 201, loss: 3.863, 6432/6976 datapoints
2025-03-06 23:03:07,475 - INFO - Epoch 704/800 done.
2025-03-06 23:03:07,475 - INFO - Final validation performance:
Loss: 3.146, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:03:07,475 - INFO - Beginning epoch 705/800
2025-03-06 23:03:07,480 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-06 23:03:07,667 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:03:07,858 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:03:08,052 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:03:08,254 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 23:03:08,448 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:03:08,655 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:03:08,846 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:03:09,031 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:03:09,221 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:03:09,417 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 23:03:09,640 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:03:09,828 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:03:10,023 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:10,210 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:03:10,400 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:03:10,593 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:03:10,780 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 23:03:10,879 - INFO - validation batch 1, loss: 0.351, 32/6976 datapoints
2025-03-06 23:03:10,927 - INFO - validation batch 51, loss: 8.731, 1632/6976 datapoints
2025-03-06 23:03:10,974 - INFO - validation batch 101, loss: 1.224, 3232/6976 datapoints
2025-03-06 23:03:11,025 - INFO - validation batch 151, loss: 1.930, 4832/6976 datapoints
2025-03-06 23:03:11,074 - INFO - validation batch 201, loss: 3.828, 6432/6976 datapoints
2025-03-06 23:03:11,090 - INFO - Epoch 705/800 done.
2025-03-06 23:03:11,090 - INFO - Final validation performance:
Loss: 3.213, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:03:11,091 - INFO - Beginning epoch 706/800
2025-03-06 23:03:11,096 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 23:03:11,283 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:03:11,476 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:03:11,684 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:03:11,879 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:03:12,072 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:03:12,272 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:03:12,465 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:03:12,649 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:03:12,836 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 23:03:13,029 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:03:13,220 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:03:13,408 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:03:13,605 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:13,794 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:03:13,986 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:03:14,178 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:03:14,364 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 23:03:14,460 - INFO - validation batch 1, loss: 0.335, 32/6976 datapoints
2025-03-06 23:03:14,508 - INFO - validation batch 51, loss: 8.726, 1632/6976 datapoints
2025-03-06 23:03:14,556 - INFO - validation batch 101, loss: 1.263, 3232/6976 datapoints
2025-03-06 23:03:14,603 - INFO - validation batch 151, loss: 2.003, 4832/6976 datapoints
2025-03-06 23:03:14,652 - INFO - validation batch 201, loss: 3.862, 6432/6976 datapoints
2025-03-06 23:03:14,669 - INFO - Epoch 706/800 done.
2025-03-06 23:03:14,669 - INFO - Final validation performance:
Loss: 3.238, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:03:14,669 - INFO - Beginning epoch 707/800
2025-03-06 23:03:14,674 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:03:14,861 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:03:15,054 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:03:15,253 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:03:15,451 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:03:15,645 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:03:15,852 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:03:16,043 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:03:16,228 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:03:16,422 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:03:16,613 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:03:16,832 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:03:17,022 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:03:17,213 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:17,414 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:03:17,614 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:03:17,811 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:03:18,006 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:03:18,101 - INFO - validation batch 1, loss: 0.343, 32/6976 datapoints
2025-03-06 23:03:18,149 - INFO - validation batch 51, loss: 8.754, 1632/6976 datapoints
2025-03-06 23:03:18,196 - INFO - validation batch 101, loss: 1.245, 3232/6976 datapoints
2025-03-06 23:03:18,245 - INFO - validation batch 151, loss: 2.040, 4832/6976 datapoints
2025-03-06 23:03:18,293 - INFO - validation batch 201, loss: 3.864, 6432/6976 datapoints
2025-03-06 23:03:18,309 - INFO - Epoch 707/800 done.
2025-03-06 23:03:18,309 - INFO - Final validation performance:
Loss: 3.249, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:03:18,310 - INFO - Beginning epoch 708/800
2025-03-06 23:03:18,314 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:03:18,503 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:03:18,696 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:03:18,891 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:03:19,099 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:03:19,296 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:03:19,501 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:03:19,723 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:03:19,913 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:03:20,109 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:03:20,305 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:03:20,500 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:03:20,695 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:03:20,893 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:21,087 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:03:21,283 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:03:21,478 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:03:21,669 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:03:21,767 - INFO - validation batch 1, loss: 0.338, 32/6976 datapoints
2025-03-06 23:03:21,820 - INFO - validation batch 51, loss: 8.749, 1632/6976 datapoints
2025-03-06 23:03:21,872 - INFO - validation batch 101, loss: 1.225, 3232/6976 datapoints
2025-03-06 23:03:21,925 - INFO - validation batch 151, loss: 2.105, 4832/6976 datapoints
2025-03-06 23:03:21,979 - INFO - validation batch 201, loss: 3.865, 6432/6976 datapoints
2025-03-06 23:03:22,000 - INFO - Epoch 708/800 done.
2025-03-06 23:03:22,000 - INFO - Final validation performance:
Loss: 3.256, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:03:22,001 - INFO - Beginning epoch 709/800
2025-03-06 23:03:22,005 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:03:22,197 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:03:22,396 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:03:22,593 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:03:22,814 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:03:23,016 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:03:23,226 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:03:23,424 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:03:23,625 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:03:23,818 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:03:24,018 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:03:24,213 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:03:24,406 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:03:24,604 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:24,796 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:03:24,993 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:03:25,198 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:03:25,429 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:03:25,543 - INFO - validation batch 1, loss: 0.327, 32/6976 datapoints
2025-03-06 23:03:25,603 - INFO - validation batch 51, loss: 8.725, 1632/6976 datapoints
2025-03-06 23:03:25,662 - INFO - validation batch 101, loss: 1.207, 3232/6976 datapoints
2025-03-06 23:03:25,721 - INFO - validation batch 151, loss: 2.168, 4832/6976 datapoints
2025-03-06 23:03:25,792 - INFO - validation batch 201, loss: 3.857, 6432/6976 datapoints
2025-03-06 23:03:25,814 - INFO - Epoch 709/800 done.
2025-03-06 23:03:25,814 - INFO - Final validation performance:
Loss: 3.257, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:03:25,814 - INFO - Beginning epoch 710/800
2025-03-06 23:03:25,820 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:03:26,019 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:03:26,215 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:03:26,419 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:03:26,624 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:03:26,821 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:03:27,028 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:03:27,224 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:03:27,411 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:03:27,608 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:03:27,801 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:03:28,002 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:03:28,196 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:03:28,392 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:28,583 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:03:28,779 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:03:28,975 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:03:29,184 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:03:29,282 - INFO - validation batch 1, loss: 0.309, 32/6976 datapoints
2025-03-06 23:03:29,333 - INFO - validation batch 51, loss: 8.686, 1632/6976 datapoints
2025-03-06 23:03:29,384 - INFO - validation batch 101, loss: 1.195, 3232/6976 datapoints
2025-03-06 23:03:29,437 - INFO - validation batch 151, loss: 2.225, 4832/6976 datapoints
2025-03-06 23:03:29,487 - INFO - validation batch 201, loss: 3.850, 6432/6976 datapoints
2025-03-06 23:03:29,504 - INFO - Epoch 710/800 done.
2025-03-06 23:03:29,504 - INFO - Final validation performance:
Loss: 3.253, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:03:29,505 - INFO - Beginning epoch 711/800
2025-03-06 23:03:29,510 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:03:29,725 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:03:29,918 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:03:30,116 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:03:30,311 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:03:30,505 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:03:30,710 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:03:30,903 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:03:31,089 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:03:31,277 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:03:31,467 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:03:31,664 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:03:31,856 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:03:32,049 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:32,238 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:03:32,430 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:03:32,622 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:03:32,809 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:03:32,904 - INFO - validation batch 1, loss: 0.296, 32/6976 datapoints
2025-03-06 23:03:32,953 - INFO - validation batch 51, loss: 8.666, 1632/6976 datapoints
2025-03-06 23:03:33,006 - INFO - validation batch 101, loss: 1.178, 3232/6976 datapoints
2025-03-06 23:03:33,054 - INFO - validation batch 151, loss: 2.256, 4832/6976 datapoints
2025-03-06 23:03:33,102 - INFO - validation batch 201, loss: 3.859, 6432/6976 datapoints
2025-03-06 23:03:33,118 - INFO - Epoch 711/800 done.
2025-03-06 23:03:33,118 - INFO - Final validation performance:
Loss: 3.251, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:03:33,119 - INFO - Beginning epoch 712/800
2025-03-06 23:03:33,123 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:03:33,309 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:03:33,502 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:03:33,701 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:03:33,898 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:03:34,093 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:03:34,293 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:03:34,484 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:03:34,669 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:03:34,856 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:03:35,050 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:03:35,257 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:03:35,449 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:03:35,647 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:35,843 - INFO - training batch 701, loss: 0.036, 22432/28000 datapoints
2025-03-06 23:03:36,040 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:03:36,239 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:03:36,426 - INFO - training batch 851, loss: 0.169, 27232/28000 datapoints
2025-03-06 23:03:36,528 - INFO - validation batch 1, loss: 0.318, 32/6976 datapoints
2025-03-06 23:03:36,575 - INFO - validation batch 51, loss: 9.150, 1632/6976 datapoints
2025-03-06 23:03:36,622 - INFO - validation batch 101, loss: 1.404, 3232/6976 datapoints
2025-03-06 23:03:36,671 - INFO - validation batch 151, loss: 1.900, 4832/6976 datapoints
2025-03-06 23:03:36,719 - INFO - validation batch 201, loss: 3.714, 6432/6976 datapoints
2025-03-06 23:03:36,735 - INFO - Epoch 712/800 done.
2025-03-06 23:03:36,735 - INFO - Final validation performance:
Loss: 3.297, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:03:36,736 - INFO - Beginning epoch 713/800
2025-03-06 23:03:36,741 - INFO - training batch 1, loss: 0.020, 32/28000 datapoints
2025-03-06 23:03:36,931 - INFO - training batch 51, loss: 0.044, 1632/28000 datapoints
2025-03-06 23:03:37,122 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 23:03:37,317 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 23:03:37,510 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:03:37,706 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:03:37,907 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 23:03:38,119 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:03:38,307 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:03:38,501 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:03:38,691 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 23:03:38,890 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 23:03:39,089 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:03:39,288 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:39,484 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:03:39,683 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:03:39,906 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:03:40,104 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:03:40,210 - INFO - validation batch 1, loss: 0.397, 32/6976 datapoints
2025-03-06 23:03:40,263 - INFO - validation batch 51, loss: 8.840, 1632/6976 datapoints
2025-03-06 23:03:40,314 - INFO - validation batch 101, loss: 1.329, 3232/6976 datapoints
2025-03-06 23:03:40,368 - INFO - validation batch 151, loss: 2.098, 4832/6976 datapoints
2025-03-06 23:03:40,424 - INFO - validation batch 201, loss: 3.804, 6432/6976 datapoints
2025-03-06 23:03:40,445 - INFO - Epoch 713/800 done.
2025-03-06 23:03:40,446 - INFO - Final validation performance:
Loss: 3.294, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:03:40,446 - INFO - Beginning epoch 714/800
2025-03-06 23:03:40,451 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:03:40,644 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-06 23:03:40,839 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:03:41,042 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:03:41,258 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 23:03:41,459 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:03:41,665 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:03:41,872 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:03:42,065 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:03:42,263 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:03:42,494 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:03:42,691 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-06 23:03:42,886 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:03:43,085 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:43,277 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:03:43,472 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:03:43,670 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:03:43,865 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:03:43,962 - INFO - validation batch 1, loss: 0.410, 32/6976 datapoints
2025-03-06 23:03:44,016 - INFO - validation batch 51, loss: 9.065, 1632/6976 datapoints
2025-03-06 23:03:44,071 - INFO - validation batch 101, loss: 1.429, 3232/6976 datapoints
2025-03-06 23:03:44,123 - INFO - validation batch 151, loss: 1.944, 4832/6976 datapoints
2025-03-06 23:03:44,176 - INFO - validation batch 201, loss: 4.019, 6432/6976 datapoints
2025-03-06 23:03:44,196 - INFO - Epoch 714/800 done.
2025-03-06 23:03:44,196 - INFO - Final validation performance:
Loss: 3.374, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:03:44,197 - INFO - Beginning epoch 715/800
2025-03-06 23:03:44,202 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:03:44,396 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:03:44,592 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:03:44,794 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:03:44,997 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:03:45,191 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:03:45,398 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:03:45,592 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:03:45,788 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:03:45,982 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:03:46,181 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:03:46,377 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:03:46,572 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:03:46,770 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:46,965 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:03:47,162 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:03:47,371 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 23:03:47,573 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 23:03:47,672 - INFO - validation batch 1, loss: 0.299, 32/6976 datapoints
2025-03-06 23:03:47,728 - INFO - validation batch 51, loss: 8.354, 1632/6976 datapoints
2025-03-06 23:03:47,783 - INFO - validation batch 101, loss: 1.098, 3232/6976 datapoints
2025-03-06 23:03:47,843 - INFO - validation batch 151, loss: 2.748, 4832/6976 datapoints
2025-03-06 23:03:47,897 - INFO - validation batch 201, loss: 3.649, 6432/6976 datapoints
2025-03-06 23:03:47,914 - INFO - Epoch 715/800 done.
2025-03-06 23:03:47,914 - INFO - Final validation performance:
Loss: 3.230, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:03:47,915 - INFO - Beginning epoch 716/800
2025-03-06 23:03:47,920 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-06 23:03:48,122 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-06 23:03:48,319 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:03:48,521 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:03:48,722 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 23:03:48,919 - INFO - training batch 251, loss: 0.034, 8032/28000 datapoints
2025-03-06 23:03:49,126 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 23:03:49,321 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:03:49,510 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:03:49,704 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:03:49,926 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-06 23:03:50,123 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 23:03:50,318 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:03:50,516 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:50,706 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:03:50,905 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:03:51,109 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:03:51,302 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:03:51,397 - INFO - validation batch 1, loss: 0.282, 32/6976 datapoints
2025-03-06 23:03:51,449 - INFO - validation batch 51, loss: 8.766, 1632/6976 datapoints
2025-03-06 23:03:51,501 - INFO - validation batch 101, loss: 1.102, 3232/6976 datapoints
2025-03-06 23:03:51,552 - INFO - validation batch 151, loss: 2.012, 4832/6976 datapoints
2025-03-06 23:03:51,604 - INFO - validation batch 201, loss: 3.839, 6432/6976 datapoints
2025-03-06 23:03:51,620 - INFO - Epoch 716/800 done.
2025-03-06 23:03:51,620 - INFO - Final validation performance:
Loss: 3.200, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:03:51,621 - INFO - Beginning epoch 717/800
2025-03-06 23:03:51,627 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 23:03:51,822 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-06 23:03:52,018 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:03:52,215 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 23:03:52,417 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 23:03:52,612 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:03:52,815 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:03:53,009 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:03:53,196 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 23:03:53,389 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:03:53,596 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:03:53,794 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 23:03:54,001 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:03:54,202 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:54,401 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 23:03:54,595 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:03:54,791 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:03:54,985 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:03:55,083 - INFO - validation batch 1, loss: 0.243, 32/6976 datapoints
2025-03-06 23:03:55,134 - INFO - validation batch 51, loss: 8.825, 1632/6976 datapoints
2025-03-06 23:03:55,186 - INFO - validation batch 101, loss: 1.197, 3232/6976 datapoints
2025-03-06 23:03:55,243 - INFO - validation batch 151, loss: 2.404, 4832/6976 datapoints
2025-03-06 23:03:55,297 - INFO - validation batch 201, loss: 3.964, 6432/6976 datapoints
2025-03-06 23:03:55,314 - INFO - Epoch 717/800 done.
2025-03-06 23:03:55,314 - INFO - Final validation performance:
Loss: 3.327, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:03:55,315 - INFO - Beginning epoch 718/800
2025-03-06 23:03:55,320 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 23:03:55,514 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:03:55,715 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:03:55,914 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:03:56,117 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:03:56,314 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:03:56,522 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 23:03:56,718 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:03:56,908 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:03:57,106 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:03:57,300 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:03:57,497 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:03:57,694 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:03:57,892 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:03:58,088 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:03:58,284 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:03:58,478 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:03:58,672 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:03:58,768 - INFO - validation batch 1, loss: 0.298, 32/6976 datapoints
2025-03-06 23:03:58,822 - INFO - validation batch 51, loss: 8.854, 1632/6976 datapoints
2025-03-06 23:03:58,878 - INFO - validation batch 101, loss: 1.238, 3232/6976 datapoints
2025-03-06 23:03:58,931 - INFO - validation batch 151, loss: 2.035, 4832/6976 datapoints
2025-03-06 23:03:58,985 - INFO - validation batch 201, loss: 3.856, 6432/6976 datapoints
2025-03-06 23:03:59,004 - INFO - Epoch 718/800 done.
2025-03-06 23:03:59,005 - INFO - Final validation performance:
Loss: 3.256, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:03:59,005 - INFO - Beginning epoch 719/800
2025-03-06 23:03:59,010 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:03:59,200 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:03:59,399 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:03:59,603 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:03:59,809 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:04:00,049 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:04:00,263 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:04:00,465 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:04:00,652 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:04:00,851 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:04:01,048 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:04:01,243 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:04:01,436 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:04:01,635 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:01,831 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:04:02,030 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:04:02,224 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:04:02,421 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:04:02,537 - INFO - validation batch 1, loss: 0.298, 32/6976 datapoints
2025-03-06 23:04:02,589 - INFO - validation batch 51, loss: 8.799, 1632/6976 datapoints
2025-03-06 23:04:02,636 - INFO - validation batch 101, loss: 1.223, 3232/6976 datapoints
2025-03-06 23:04:02,685 - INFO - validation batch 151, loss: 2.072, 4832/6976 datapoints
2025-03-06 23:04:02,732 - INFO - validation batch 201, loss: 3.854, 6432/6976 datapoints
2025-03-06 23:04:02,749 - INFO - Epoch 719/800 done.
2025-03-06 23:04:02,749 - INFO - Final validation performance:
Loss: 3.249, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:04:02,749 - INFO - Beginning epoch 720/800
2025-03-06 23:04:02,754 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:04:02,947 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:04:03,142 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:04:03,335 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:04:03,531 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:04:03,728 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:04:03,931 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:04:04,126 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:04:04,313 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:04:04,505 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:04:04,696 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:04:04,888 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:04:05,083 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:04:05,283 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:05,475 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:04:05,668 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:04:05,874 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:04:06,075 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:04:06,171 - INFO - validation batch 1, loss: 0.300, 32/6976 datapoints
2025-03-06 23:04:06,223 - INFO - validation batch 51, loss: 8.761, 1632/6976 datapoints
2025-03-06 23:04:06,273 - INFO - validation batch 101, loss: 1.220, 3232/6976 datapoints
2025-03-06 23:04:06,327 - INFO - validation batch 151, loss: 2.113, 4832/6976 datapoints
2025-03-06 23:04:06,376 - INFO - validation batch 201, loss: 3.855, 6432/6976 datapoints
2025-03-06 23:04:06,392 - INFO - Epoch 720/800 done.
2025-03-06 23:04:06,392 - INFO - Final validation performance:
Loss: 3.250, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:04:06,393 - INFO - Beginning epoch 721/800
2025-03-06 23:04:06,397 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:04:06,591 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:04:06,788 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:04:06,983 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:04:07,180 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:04:07,371 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:04:07,576 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:04:07,772 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:04:07,960 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:04:08,155 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:04:08,376 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:04:08,570 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:04:08,760 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:04:08,959 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:09,152 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:04:09,348 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:04:09,544 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:04:09,739 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:04:09,832 - INFO - validation batch 1, loss: 0.294, 32/6976 datapoints
2025-03-06 23:04:09,878 - INFO - validation batch 51, loss: 8.730, 1632/6976 datapoints
2025-03-06 23:04:09,929 - INFO - validation batch 101, loss: 1.216, 3232/6976 datapoints
2025-03-06 23:04:09,978 - INFO - validation batch 151, loss: 2.170, 4832/6976 datapoints
2025-03-06 23:04:10,032 - INFO - validation batch 201, loss: 3.847, 6432/6976 datapoints
2025-03-06 23:04:10,053 - INFO - Epoch 721/800 done.
2025-03-06 23:04:10,053 - INFO - Final validation performance:
Loss: 3.251, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:04:10,053 - INFO - Beginning epoch 722/800
2025-03-06 23:04:10,059 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:04:10,262 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:04:10,455 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:04:10,651 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:04:10,846 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:04:11,041 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:04:11,243 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:04:11,438 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:04:11,629 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:04:11,823 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:04:12,031 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:04:12,223 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:04:12,419 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:04:12,624 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:12,816 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:04:13,011 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:04:13,203 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:04:13,392 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:04:13,484 - INFO - validation batch 1, loss: 0.286, 32/6976 datapoints
2025-03-06 23:04:13,533 - INFO - validation batch 51, loss: 8.699, 1632/6976 datapoints
2025-03-06 23:04:13,580 - INFO - validation batch 101, loss: 1.210, 3232/6976 datapoints
2025-03-06 23:04:13,630 - INFO - validation batch 151, loss: 2.236, 4832/6976 datapoints
2025-03-06 23:04:13,679 - INFO - validation batch 201, loss: 3.833, 6432/6976 datapoints
2025-03-06 23:04:13,696 - INFO - Epoch 722/800 done.
2025-03-06 23:04:13,696 - INFO - Final validation performance:
Loss: 3.253, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:04:13,697 - INFO - Beginning epoch 723/800
2025-03-06 23:04:13,701 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:04:13,891 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:04:14,089 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:04:14,285 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:04:14,481 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:04:14,672 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:04:14,875 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:04:15,075 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:04:15,295 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:04:15,486 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:04:15,677 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:04:15,878 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:04:16,072 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:04:16,268 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:16,456 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:04:16,652 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:04:16,845 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:04:17,039 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:04:17,133 - INFO - validation batch 1, loss: 0.278, 32/6976 datapoints
2025-03-06 23:04:17,181 - INFO - validation batch 51, loss: 8.689, 1632/6976 datapoints
2025-03-06 23:04:17,228 - INFO - validation batch 101, loss: 1.209, 3232/6976 datapoints
2025-03-06 23:04:17,277 - INFO - validation batch 151, loss: 2.302, 4832/6976 datapoints
2025-03-06 23:04:17,324 - INFO - validation batch 201, loss: 3.854, 6432/6976 datapoints
2025-03-06 23:04:17,341 - INFO - Epoch 723/800 done.
2025-03-06 23:04:17,341 - INFO - Final validation performance:
Loss: 3.266, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:04:17,341 - INFO - Beginning epoch 724/800
2025-03-06 23:04:17,346 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:04:17,534 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:04:17,728 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:04:17,927 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:04:18,143 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:04:18,334 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:04:18,543 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:04:18,735 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:04:18,925 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:04:19,119 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:04:19,310 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:04:19,508 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:04:19,703 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:04:19,907 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:20,104 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:04:20,322 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:04:20,521 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:04:20,720 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:04:20,818 - INFO - validation batch 1, loss: 0.245, 32/6976 datapoints
2025-03-06 23:04:20,871 - INFO - validation batch 51, loss: 8.563, 1632/6976 datapoints
2025-03-06 23:04:20,926 - INFO - validation batch 101, loss: 1.167, 3232/6976 datapoints
2025-03-06 23:04:20,980 - INFO - validation batch 151, loss: 2.298, 4832/6976 datapoints
2025-03-06 23:04:21,036 - INFO - validation batch 201, loss: 3.977, 6432/6976 datapoints
2025-03-06 23:04:21,054 - INFO - Epoch 724/800 done.
2025-03-06 23:04:21,054 - INFO - Final validation performance:
Loss: 3.250, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:04:21,055 - INFO - Beginning epoch 725/800
2025-03-06 23:04:21,060 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:04:21,256 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:04:21,451 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:04:21,652 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:04:21,856 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 23:04:22,055 - INFO - training batch 251, loss: 0.146, 8032/28000 datapoints
2025-03-06 23:04:22,253 - INFO - training batch 301, loss: 0.056, 9632/28000 datapoints
2025-03-06 23:04:22,446 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:04:22,642 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:04:22,838 - INFO - training batch 451, loss: 0.041, 14432/28000 datapoints
2025-03-06 23:04:23,038 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:04:23,235 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 23:04:23,431 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:04:23,633 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:23,831 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 23:04:24,030 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-06 23:04:24,235 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 23:04:24,444 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:04:24,546 - INFO - validation batch 1, loss: 0.207, 32/6976 datapoints
2025-03-06 23:04:24,596 - INFO - validation batch 51, loss: 9.065, 1632/6976 datapoints
2025-03-06 23:04:24,653 - INFO - validation batch 101, loss: 1.318, 3232/6976 datapoints
2025-03-06 23:04:24,711 - INFO - validation batch 151, loss: 2.395, 4832/6976 datapoints
2025-03-06 23:04:24,766 - INFO - validation batch 201, loss: 3.703, 6432/6976 datapoints
2025-03-06 23:04:24,786 - INFO - Epoch 725/800 done.
2025-03-06 23:04:24,787 - INFO - Final validation performance:
Loss: 3.338, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:04:24,787 - INFO - Beginning epoch 726/800
2025-03-06 23:04:24,793 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 23:04:24,984 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:04:25,180 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:04:25,382 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:04:25,599 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:04:25,798 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:04:25,999 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:04:26,191 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:04:26,391 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-06 23:04:26,582 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 23:04:26,776 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:04:26,971 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 23:04:27,163 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:04:27,360 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:27,548 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-06 23:04:27,743 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:04:27,940 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:04:28,134 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:04:28,233 - INFO - validation batch 1, loss: 0.254, 32/6976 datapoints
2025-03-06 23:04:28,281 - INFO - validation batch 51, loss: 9.287, 1632/6976 datapoints
2025-03-06 23:04:28,329 - INFO - validation batch 101, loss: 1.295, 3232/6976 datapoints
2025-03-06 23:04:28,377 - INFO - validation batch 151, loss: 2.032, 4832/6976 datapoints
2025-03-06 23:04:28,424 - INFO - validation batch 201, loss: 3.661, 6432/6976 datapoints
2025-03-06 23:04:28,441 - INFO - Epoch 726/800 done.
2025-03-06 23:04:28,442 - INFO - Final validation performance:
Loss: 3.306, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:04:28,442 - INFO - Beginning epoch 727/800
2025-03-06 23:04:28,447 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:04:28,630 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:04:28,826 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:04:29,026 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:04:29,221 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 23:04:29,412 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:04:29,612 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:04:29,815 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:04:30,009 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 23:04:30,202 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 23:04:30,429 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:04:30,625 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-06 23:04:30,817 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:04:31,029 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:31,219 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 23:04:31,420 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:04:31,613 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:04:31,808 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:04:31,905 - INFO - validation batch 1, loss: 0.309, 32/6976 datapoints
2025-03-06 23:04:31,952 - INFO - validation batch 51, loss: 9.279, 1632/6976 datapoints
2025-03-06 23:04:32,002 - INFO - validation batch 101, loss: 1.283, 3232/6976 datapoints
2025-03-06 23:04:32,049 - INFO - validation batch 151, loss: 1.910, 4832/6976 datapoints
2025-03-06 23:04:32,098 - INFO - validation batch 201, loss: 3.695, 6432/6976 datapoints
2025-03-06 23:04:32,114 - INFO - Epoch 727/800 done.
2025-03-06 23:04:32,114 - INFO - Final validation performance:
Loss: 3.295, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:04:32,114 - INFO - Beginning epoch 728/800
2025-03-06 23:04:32,119 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:04:32,307 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:04:32,499 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:04:32,698 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:04:32,895 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 23:04:33,092 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:04:33,291 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:04:33,485 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:04:33,676 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 23:04:33,873 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:04:34,068 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:04:34,261 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:04:34,450 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:04:34,650 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:34,843 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 23:04:35,039 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:04:35,238 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:04:35,430 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:04:35,528 - INFO - validation batch 1, loss: 0.322, 32/6976 datapoints
2025-03-06 23:04:35,576 - INFO - validation batch 51, loss: 9.245, 1632/6976 datapoints
2025-03-06 23:04:35,624 - INFO - validation batch 101, loss: 1.271, 3232/6976 datapoints
2025-03-06 23:04:35,671 - INFO - validation batch 151, loss: 1.934, 4832/6976 datapoints
2025-03-06 23:04:35,723 - INFO - validation batch 201, loss: 3.742, 6432/6976 datapoints
2025-03-06 23:04:35,744 - INFO - Epoch 728/800 done.
2025-03-06 23:04:35,744 - INFO - Final validation performance:
Loss: 3.303, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:04:35,745 - INFO - Beginning epoch 729/800
2025-03-06 23:04:35,749 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:04:35,939 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:04:36,134 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:04:36,332 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:04:36,542 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:04:36,734 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:04:36,943 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:04:37,141 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:04:37,335 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:04:37,528 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:04:37,718 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:04:37,918 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:04:38,126 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:04:38,325 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:38,514 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:04:38,711 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:04:38,907 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:04:39,103 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:04:39,199 - INFO - validation batch 1, loss: 0.321, 32/6976 datapoints
2025-03-06 23:04:39,248 - INFO - validation batch 51, loss: 9.220, 1632/6976 datapoints
2025-03-06 23:04:39,296 - INFO - validation batch 101, loss: 1.254, 3232/6976 datapoints
2025-03-06 23:04:39,347 - INFO - validation batch 151, loss: 1.986, 4832/6976 datapoints
2025-03-06 23:04:39,395 - INFO - validation batch 201, loss: 3.773, 6432/6976 datapoints
2025-03-06 23:04:39,415 - INFO - Epoch 729/800 done.
2025-03-06 23:04:39,415 - INFO - Final validation performance:
Loss: 3.311, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:04:39,421 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:04:39,617 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:04:39,902 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:04:40,105 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:04:40,308 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:04:40,526 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:04:40,734 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:04:40,931 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:04:41,127 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:04:41,321 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:04:41,516 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:04:41,721 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:04:41,920 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:04:42,127 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:42,321 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:04:42,521 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:04:42,750 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:04:42,962 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:04:43,065 - INFO - validation batch 1, loss: 0.313, 32/6976 datapoints
2025-03-06 23:04:43,122 - INFO - validation batch 51, loss: 9.175, 1632/6976 datapoints
2025-03-06 23:04:43,177 - INFO - validation batch 101, loss: 1.245, 3232/6976 datapoints
2025-03-06 23:04:43,231 - INFO - validation batch 151, loss: 2.048, 4832/6976 datapoints
2025-03-06 23:04:43,284 - INFO - validation batch 201, loss: 3.798, 6432/6976 datapoints
2025-03-06 23:04:43,303 - INFO - Epoch 730/800 done.
2025-03-06 23:04:43,303 - INFO - Final validation performance:
Loss: 3.316, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:04:43,304 - INFO - Beginning epoch 731/800
2025-03-06 23:04:43,310 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:04:43,507 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:04:43,703 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:04:43,907 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:04:44,110 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:04:44,304 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:04:44,509 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:04:44,706 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:04:44,900 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:04:45,100 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:04:45,301 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:04:45,500 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:04:45,692 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:04:45,900 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:46,097 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:04:46,301 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:04:46,502 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:04:46,701 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:04:46,802 - INFO - validation batch 1, loss: 0.298, 32/6976 datapoints
2025-03-06 23:04:46,855 - INFO - validation batch 51, loss: 9.106, 1632/6976 datapoints
2025-03-06 23:04:46,906 - INFO - validation batch 101, loss: 1.240, 3232/6976 datapoints
2025-03-06 23:04:46,959 - INFO - validation batch 151, loss: 2.140, 4832/6976 datapoints
2025-03-06 23:04:47,018 - INFO - validation batch 201, loss: 3.818, 6432/6976 datapoints
2025-03-06 23:04:47,037 - INFO - Epoch 731/800 done.
2025-03-06 23:04:47,037 - INFO - Final validation performance:
Loss: 3.320, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:04:47,037 - INFO - Beginning epoch 732/800
2025-03-06 23:04:47,043 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:04:47,239 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:04:47,434 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:04:47,636 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:04:47,836 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:04:48,040 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:04:48,244 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:04:48,441 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:04:48,634 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:04:48,843 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:04:49,040 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:04:49,242 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:04:49,445 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:04:49,651 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:49,848 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:04:50,056 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:04:50,255 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:04:50,456 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:04:50,575 - INFO - validation batch 1, loss: 0.284, 32/6976 datapoints
2025-03-06 23:04:50,628 - INFO - validation batch 51, loss: 9.028, 1632/6976 datapoints
2025-03-06 23:04:50,676 - INFO - validation batch 101, loss: 1.245, 3232/6976 datapoints
2025-03-06 23:04:50,723 - INFO - validation batch 151, loss: 2.232, 4832/6976 datapoints
2025-03-06 23:04:50,771 - INFO - validation batch 201, loss: 3.835, 6432/6976 datapoints
2025-03-06 23:04:50,787 - INFO - Epoch 732/800 done.
2025-03-06 23:04:50,787 - INFO - Final validation performance:
Loss: 3.325, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:04:50,788 - INFO - Beginning epoch 733/800
2025-03-06 23:04:50,793 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:04:50,980 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:04:51,190 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:04:51,389 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:04:51,585 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:04:51,776 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:04:51,980 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:04:52,177 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:04:52,366 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:04:52,556 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:04:52,747 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:04:52,943 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:04:53,138 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:04:53,340 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:53,527 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:04:53,721 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:04:53,917 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:04:54,116 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:04:54,212 - INFO - validation batch 1, loss: 0.277, 32/6976 datapoints
2025-03-06 23:04:54,260 - INFO - validation batch 51, loss: 8.983, 1632/6976 datapoints
2025-03-06 23:04:54,307 - INFO - validation batch 101, loss: 1.253, 3232/6976 datapoints
2025-03-06 23:04:54,354 - INFO - validation batch 151, loss: 2.283, 4832/6976 datapoints
2025-03-06 23:04:54,403 - INFO - validation batch 201, loss: 3.860, 6432/6976 datapoints
2025-03-06 23:04:54,419 - INFO - Epoch 733/800 done.
2025-03-06 23:04:54,420 - INFO - Final validation performance:
Loss: 3.331, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:04:54,420 - INFO - Beginning epoch 734/800
2025-03-06 23:04:54,425 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:04:54,613 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:04:54,804 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:04:55,024 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:04:55,223 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:04:55,415 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:04:55,624 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:04:55,821 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:04:56,022 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:04:56,215 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:04:56,406 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:04:56,599 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:04:56,796 - INFO - training batch 601, loss: 0.520, 19232/28000 datapoints
2025-03-06 23:04:56,996 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:04:57,188 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 23:04:57,380 - INFO - training batch 751, loss: 0.031, 24032/28000 datapoints
2025-03-06 23:04:57,573 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:04:57,766 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-06 23:04:57,865 - INFO - validation batch 1, loss: 0.367, 32/6976 datapoints
2025-03-06 23:04:57,913 - INFO - validation batch 51, loss: 8.169, 1632/6976 datapoints
2025-03-06 23:04:57,963 - INFO - validation batch 101, loss: 1.275, 3232/6976 datapoints
2025-03-06 23:04:58,014 - INFO - validation batch 151, loss: 2.768, 4832/6976 datapoints
2025-03-06 23:04:58,063 - INFO - validation batch 201, loss: 4.141, 6432/6976 datapoints
2025-03-06 23:04:58,079 - INFO - Epoch 734/800 done.
2025-03-06 23:04:58,079 - INFO - Final validation performance:
Loss: 3.344, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:04:58,080 - INFO - Beginning epoch 735/800
2025-03-06 23:04:58,085 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:04:58,274 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:04:58,465 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 23:04:58,664 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:04:58,865 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-06 23:04:59,058 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 23:04:59,260 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 23:04:59,457 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:04:59,651 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 23:04:59,844 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:05:00,053 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:05:00,253 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 23:05:00,454 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:05:00,683 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:05:00,878 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 23:05:01,081 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:05:01,299 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:05:01,494 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:05:01,592 - INFO - validation batch 1, loss: 0.225, 32/6976 datapoints
2025-03-06 23:05:01,646 - INFO - validation batch 51, loss: 8.644, 1632/6976 datapoints
2025-03-06 23:05:01,707 - INFO - validation batch 101, loss: 1.191, 3232/6976 datapoints
2025-03-06 23:05:01,765 - INFO - validation batch 151, loss: 2.219, 4832/6976 datapoints
2025-03-06 23:05:01,819 - INFO - validation batch 201, loss: 3.804, 6432/6976 datapoints
2025-03-06 23:05:01,843 - INFO - Epoch 735/800 done.
2025-03-06 23:05:01,843 - INFO - Final validation performance:
Loss: 3.217, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:05:01,844 - INFO - Beginning epoch 736/800
2025-03-06 23:05:01,849 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:05:02,046 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:05:02,244 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:05:02,443 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:05:02,643 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:05:02,839 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-06 23:05:03,048 - INFO - training batch 301, loss: 0.025, 9632/28000 datapoints
2025-03-06 23:05:03,251 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:05:03,442 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:05:03,642 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:05:03,838 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:05:04,043 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:05:04,246 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:05:04,451 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:05:04,642 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 23:05:04,844 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:05:05,048 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:05:05,250 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:05:05,352 - INFO - validation batch 1, loss: 0.393, 32/6976 datapoints
2025-03-06 23:05:05,403 - INFO - validation batch 51, loss: 9.033, 1632/6976 datapoints
2025-03-06 23:05:05,458 - INFO - validation batch 101, loss: 1.294, 3232/6976 datapoints
2025-03-06 23:05:05,509 - INFO - validation batch 151, loss: 2.198, 4832/6976 datapoints
2025-03-06 23:05:05,562 - INFO - validation batch 201, loss: 3.802, 6432/6976 datapoints
2025-03-06 23:05:05,579 - INFO - Epoch 736/800 done.
2025-03-06 23:05:05,579 - INFO - Final validation performance:
Loss: 3.344, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:05:05,580 - INFO - Beginning epoch 737/800
2025-03-06 23:05:05,585 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:05:05,779 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:05:05,975 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:05:06,181 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:05:06,393 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:05:06,591 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 23:05:06,799 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:05:06,996 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:05:07,190 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 23:05:07,405 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:05:07,596 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:05:07,803 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-06 23:05:08,007 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:05:08,216 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:05:08,412 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:05:08,613 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:05:08,808 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:05:09,008 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:05:09,108 - INFO - validation batch 1, loss: 0.319, 32/6976 datapoints
2025-03-06 23:05:09,160 - INFO - validation batch 51, loss: 9.123, 1632/6976 datapoints
2025-03-06 23:05:09,214 - INFO - validation batch 101, loss: 1.418, 3232/6976 datapoints
2025-03-06 23:05:09,269 - INFO - validation batch 151, loss: 2.031, 4832/6976 datapoints
2025-03-06 23:05:09,320 - INFO - validation batch 201, loss: 3.886, 6432/6976 datapoints
2025-03-06 23:05:09,340 - INFO - Epoch 737/800 done.
2025-03-06 23:05:09,340 - INFO - Final validation performance:
Loss: 3.355, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:05:09,341 - INFO - Beginning epoch 738/800
2025-03-06 23:05:09,346 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:05:09,543 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:05:09,737 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:05:09,939 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:05:10,147 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:05:10,347 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 23:05:10,552 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:05:10,770 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:05:10,964 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:05:11,166 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:05:11,363 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:05:11,562 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:05:11,765 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:05:11,971 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:05:12,171 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 23:05:12,376 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:05:12,572 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-06 23:05:12,771 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:05:12,869 - INFO - validation batch 1, loss: 0.345, 32/6976 datapoints
2025-03-06 23:05:12,920 - INFO - validation batch 51, loss: 9.223, 1632/6976 datapoints
2025-03-06 23:05:12,972 - INFO - validation batch 101, loss: 1.606, 3232/6976 datapoints
2025-03-06 23:05:13,026 - INFO - validation batch 151, loss: 2.295, 4832/6976 datapoints
2025-03-06 23:05:13,080 - INFO - validation batch 201, loss: 4.058, 6432/6976 datapoints
2025-03-06 23:05:13,101 - INFO - Epoch 738/800 done.
2025-03-06 23:05:13,101 - INFO - Final validation performance:
Loss: 3.505, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:05:13,102 - INFO - Beginning epoch 739/800
2025-03-06 23:05:13,107 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:05:13,299 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:05:13,495 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:05:13,707 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:05:13,908 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:05:14,119 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 23:05:14,327 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:05:14,525 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:05:14,717 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:05:14,915 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:05:15,130 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:05:15,353 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:05:15,553 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:05:15,759 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:05:15,953 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:05:16,162 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:05:16,362 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:05:16,559 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:05:16,659 - INFO - validation batch 1, loss: 0.363, 32/6976 datapoints
2025-03-06 23:05:16,710 - INFO - validation batch 51, loss: 9.214, 1632/6976 datapoints
2025-03-06 23:05:16,767 - INFO - validation batch 101, loss: 1.354, 3232/6976 datapoints
2025-03-06 23:05:16,819 - INFO - validation batch 151, loss: 2.110, 4832/6976 datapoints
2025-03-06 23:05:16,870 - INFO - validation batch 201, loss: 3.805, 6432/6976 datapoints
2025-03-06 23:05:16,891 - INFO - Epoch 739/800 done.
2025-03-06 23:05:16,891 - INFO - Final validation performance:
Loss: 3.369, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:05:16,892 - INFO - Beginning epoch 740/800
2025-03-06 23:05:16,897 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:05:17,087 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:05:17,279 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:05:17,477 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:05:17,674 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:05:17,867 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:05:18,075 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:05:18,269 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:05:18,458 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:05:18,652 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:05:18,842 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:05:19,040 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:05:19,236 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:05:19,437 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:05:19,627 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:05:19,842 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:05:20,052 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:05:20,248 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:05:20,356 - INFO - validation batch 1, loss: 0.380, 32/6976 datapoints
2025-03-06 23:05:20,411 - INFO - validation batch 51, loss: 9.299, 1632/6976 datapoints
2025-03-06 23:05:20,464 - INFO - validation batch 101, loss: 1.375, 3232/6976 datapoints
2025-03-06 23:05:20,519 - INFO - validation batch 151, loss: 2.171, 4832/6976 datapoints
2025-03-06 23:05:20,572 - INFO - validation batch 201, loss: 3.826, 6432/6976 datapoints
2025-03-06 23:05:20,593 - INFO - Epoch 740/800 done.
2025-03-06 23:05:20,594 - INFO - Final validation performance:
Loss: 3.410, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:05:20,594 - INFO - Beginning epoch 741/800
2025-03-06 23:05:20,599 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:05:20,809 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:05:21,026 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:05:21,230 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:05:21,433 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:05:21,628 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:05:21,830 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:05:22,031 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:05:22,225 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:05:22,425 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:05:22,618 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:05:22,818 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:05:23,019 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:05:23,224 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:05:23,419 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:05:23,619 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:05:23,820 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:05:24,021 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:05:24,123 - INFO - validation batch 1, loss: 0.369, 32/6976 datapoints
2025-03-06 23:05:24,175 - INFO - validation batch 51, loss: 9.256, 1632/6976 datapoints
2025-03-06 23:05:24,230 - INFO - validation batch 101, loss: 1.359, 3232/6976 datapoints
2025-03-06 23:05:24,283 - INFO - validation batch 151, loss: 2.231, 4832/6976 datapoints
2025-03-06 23:05:24,335 - INFO - validation batch 201, loss: 3.807, 6432/6976 datapoints
2025-03-06 23:05:24,354 - INFO - Epoch 741/800 done.
2025-03-06 23:05:24,355 - INFO - Final validation performance:
Loss: 3.404, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:05:24,355 - INFO - Beginning epoch 742/800
2025-03-06 23:05:24,359 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:05:24,553 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:05:24,748 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:05:24,949 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:05:25,151 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:05:25,353 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:05:25,561 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:05:25,761 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:05:25,965 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:05:26,170 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:05:26,375 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:05:26,581 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:05:26,785 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:05:26,991 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:05:27,188 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:05:27,390 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:05:27,592 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:05:27,788 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:05:27,887 - INFO - validation batch 1, loss: 0.351, 32/6976 datapoints
2025-03-06 23:05:27,942 - INFO - validation batch 51, loss: 9.199, 1632/6976 datapoints
2025-03-06 23:05:27,990 - INFO - validation batch 101, loss: 1.338, 3232/6976 datapoints
2025-03-06 23:05:28,042 - INFO - validation batch 151, loss: 2.314, 4832/6976 datapoints
2025-03-06 23:05:28,092 - INFO - validation batch 201, loss: 3.813, 6432/6976 datapoints
2025-03-06 23:05:28,108 - INFO - Epoch 742/800 done.
2025-03-06 23:05:28,109 - INFO - Final validation performance:
Loss: 3.403, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:05:28,109 - INFO - Beginning epoch 743/800
2025-03-06 23:05:28,114 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:05:28,303 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:05:28,501 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:05:28,698 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:05:28,893 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:05:29,089 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:05:29,290 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:05:29,489 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:05:29,678 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:05:29,870 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:05:30,065 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:05:30,268 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:05:30,465 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:05:30,666 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:05:30,864 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:05:31,081 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:05:31,278 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:05:31,474 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:05:31,571 - INFO - validation batch 1, loss: 0.332, 32/6976 datapoints
2025-03-06 23:05:31,617 - INFO - validation batch 51, loss: 9.149, 1632/6976 datapoints
2025-03-06 23:05:31,665 - INFO - validation batch 101, loss: 1.321, 3232/6976 datapoints
2025-03-06 23:05:31,713 - INFO - validation batch 151, loss: 2.406, 4832/6976 datapoints
2025-03-06 23:05:31,760 - INFO - validation batch 201, loss: 3.832, 6432/6976 datapoints
2025-03-06 23:05:31,776 - INFO - Epoch 743/800 done.
2025-03-06 23:05:31,776 - INFO - Final validation performance:
Loss: 3.408, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:05:31,777 - INFO - Beginning epoch 744/800
2025-03-06 23:05:31,782 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:05:31,971 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:05:32,179 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:05:32,380 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:05:32,583 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:05:32,786 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:05:32,989 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:05:33,186 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:05:33,376 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:05:33,569 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:05:33,759 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:05:33,959 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:05:34,160 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:05:34,362 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:05:34,556 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:05:34,754 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:05:34,952 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:05:35,155 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:05:35,253 - INFO - validation batch 1, loss: 0.327, 32/6976 datapoints
2025-03-06 23:05:35,310 - INFO - validation batch 51, loss: 9.123, 1632/6976 datapoints
2025-03-06 23:05:35,358 - INFO - validation batch 101, loss: 1.296, 3232/6976 datapoints
2025-03-06 23:05:35,406 - INFO - validation batch 151, loss: 2.489, 4832/6976 datapoints
2025-03-06 23:05:35,454 - INFO - validation batch 201, loss: 3.853, 6432/6976 datapoints
2025-03-06 23:05:35,471 - INFO - Epoch 744/800 done.
2025-03-06 23:05:35,471 - INFO - Final validation performance:
Loss: 3.418, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:05:35,472 - INFO - Beginning epoch 745/800
2025-03-06 23:05:35,476 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:05:35,668 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:05:35,863 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:05:36,066 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:05:36,265 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:05:36,458 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:05:36,659 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:05:36,856 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:05:37,049 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:05:37,242 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:05:37,432 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:05:37,632 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:05:37,827 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:05:38,042 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:05:38,254 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:05:38,450 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:05:38,655 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:05:38,854 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:05:38,952 - INFO - validation batch 1, loss: 0.315, 32/6976 datapoints
2025-03-06 23:05:39,002 - INFO - validation batch 51, loss: 9.111, 1632/6976 datapoints
2025-03-06 23:05:39,056 - INFO - validation batch 101, loss: 1.256, 3232/6976 datapoints
2025-03-06 23:05:39,105 - INFO - validation batch 151, loss: 2.602, 4832/6976 datapoints
2025-03-06 23:05:39,153 - INFO - validation batch 201, loss: 3.894, 6432/6976 datapoints
2025-03-06 23:05:39,170 - INFO - Epoch 745/800 done.
2025-03-06 23:05:39,170 - INFO - Final validation performance:
Loss: 3.436, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:05:39,170 - INFO - Beginning epoch 746/800
2025-03-06 23:05:39,175 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:05:39,366 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:05:39,565 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:05:39,769 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:05:39,971 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:05:40,176 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:05:40,378 - INFO - training batch 301, loss: 0.057, 9632/28000 datapoints
2025-03-06 23:05:40,581 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 23:05:40,786 - INFO - training batch 401, loss: 0.047, 12832/28000 datapoints
2025-03-06 23:05:41,008 - INFO - training batch 451, loss: 0.160, 14432/28000 datapoints
2025-03-06 23:05:41,212 - INFO - training batch 501, loss: 0.062, 16032/28000 datapoints
2025-03-06 23:05:41,413 - INFO - training batch 551, loss: 0.534, 17632/28000 datapoints
2025-03-06 23:05:41,612 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:05:41,815 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-06 23:05:42,012 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-06 23:05:42,226 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:05:42,427 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:05:42,626 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:05:42,728 - INFO - validation batch 1, loss: 0.328, 32/6976 datapoints
2025-03-06 23:05:42,781 - INFO - validation batch 51, loss: 9.567, 1632/6976 datapoints
2025-03-06 23:05:42,834 - INFO - validation batch 101, loss: 1.565, 3232/6976 datapoints
2025-03-06 23:05:42,886 - INFO - validation batch 151, loss: 2.148, 4832/6976 datapoints
2025-03-06 23:05:42,937 - INFO - validation batch 201, loss: 4.055, 6432/6976 datapoints
2025-03-06 23:05:42,954 - INFO - Epoch 746/800 done.
2025-03-06 23:05:42,954 - INFO - Final validation performance:
Loss: 3.533, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:05:42,954 - INFO - Beginning epoch 747/800
2025-03-06 23:05:42,959 - INFO - training batch 1, loss: 0.021, 32/28000 datapoints
2025-03-06 23:05:43,180 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:05:43,381 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:05:43,580 - INFO - training batch 151, loss: 0.013, 4832/28000 datapoints
2025-03-06 23:05:43,781 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:05:43,972 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 23:05:44,178 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 23:05:44,383 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 23:05:44,577 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 23:05:44,775 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:05:44,970 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:05:45,174 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:05:45,372 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:05:45,574 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:05:45,770 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 23:05:45,965 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:05:46,168 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:05:46,362 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:05:46,460 - INFO - validation batch 1, loss: 0.395, 32/6976 datapoints
2025-03-06 23:05:46,509 - INFO - validation batch 51, loss: 9.092, 1632/6976 datapoints
2025-03-06 23:05:46,557 - INFO - validation batch 101, loss: 1.442, 3232/6976 datapoints
2025-03-06 23:05:46,605 - INFO - validation batch 151, loss: 2.264, 4832/6976 datapoints
2025-03-06 23:05:46,655 - INFO - validation batch 201, loss: 3.952, 6432/6976 datapoints
2025-03-06 23:05:46,671 - INFO - Epoch 747/800 done.
2025-03-06 23:05:46,672 - INFO - Final validation performance:
Loss: 3.429, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:05:46,672 - INFO - Beginning epoch 748/800
2025-03-06 23:05:46,676 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 23:05:46,865 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:05:47,062 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-06 23:05:47,264 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-06 23:05:47,461 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:05:47,656 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:05:47,857 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:05:48,116 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:05:48,316 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-06 23:05:48,511 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:05:48,700 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:05:48,898 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 23:05:49,093 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:05:49,295 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:05:49,487 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:05:49,684 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:05:49,880 - INFO - training batch 801, loss: 0.048, 25632/28000 datapoints
2025-03-06 23:05:50,073 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:05:50,174 - INFO - validation batch 1, loss: 0.729, 32/6976 datapoints
2025-03-06 23:05:50,222 - INFO - validation batch 51, loss: 9.143, 1632/6976 datapoints
2025-03-06 23:05:50,269 - INFO - validation batch 101, loss: 1.327, 3232/6976 datapoints
2025-03-06 23:05:50,318 - INFO - validation batch 151, loss: 2.626, 4832/6976 datapoints
2025-03-06 23:05:50,367 - INFO - validation batch 201, loss: 4.126, 6432/6976 datapoints
2025-03-06 23:05:50,383 - INFO - Epoch 748/800 done.
2025-03-06 23:05:50,383 - INFO - Final validation performance:
Loss: 3.590, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:05:50,384 - INFO - Beginning epoch 749/800
2025-03-06 23:05:50,388 - INFO - training batch 1, loss: 0.022, 32/28000 datapoints
2025-03-06 23:05:50,589 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:05:50,783 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:05:50,998 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:05:51,231 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:05:51,429 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:05:51,629 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-06 23:05:51,820 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:05:52,012 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-06 23:05:52,212 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:05:52,407 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:05:52,618 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:05:52,816 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:05:53,018 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:05:53,212 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:05:53,406 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:05:53,600 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:05:53,796 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:05:53,892 - INFO - validation batch 1, loss: 0.538, 32/6976 datapoints
2025-03-06 23:05:53,941 - INFO - validation batch 51, loss: 9.235, 1632/6976 datapoints
2025-03-06 23:05:53,989 - INFO - validation batch 101, loss: 1.404, 3232/6976 datapoints
2025-03-06 23:05:54,040 - INFO - validation batch 151, loss: 2.100, 4832/6976 datapoints
2025-03-06 23:05:54,088 - INFO - validation batch 201, loss: 3.977, 6432/6976 datapoints
2025-03-06 23:05:54,104 - INFO - Epoch 749/800 done.
2025-03-06 23:05:54,104 - INFO - Final validation performance:
Loss: 3.451, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:05:54,105 - INFO - Beginning epoch 750/800
2025-03-06 23:05:54,109 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 23:05:54,299 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:05:54,493 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:05:54,691 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:05:54,888 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:05:55,083 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:05:55,291 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:05:55,487 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:05:55,679 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:05:55,876 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:05:56,078 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:05:56,282 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:05:56,478 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:05:56,695 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:05:56,891 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:05:57,094 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:05:57,297 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:05:57,496 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:05:57,595 - INFO - validation batch 1, loss: 0.506, 32/6976 datapoints
2025-03-06 23:05:57,641 - INFO - validation batch 51, loss: 9.134, 1632/6976 datapoints
2025-03-06 23:05:57,688 - INFO - validation batch 101, loss: 1.312, 3232/6976 datapoints
2025-03-06 23:05:57,737 - INFO - validation batch 151, loss: 2.331, 4832/6976 datapoints
2025-03-06 23:05:57,784 - INFO - validation batch 201, loss: 3.902, 6432/6976 datapoints
2025-03-06 23:05:57,800 - INFO - Epoch 750/800 done.
2025-03-06 23:05:57,800 - INFO - Final validation performance:
Loss: 3.437, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:05:57,801 - INFO - Beginning epoch 751/800
2025-03-06 23:05:57,805 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-06 23:05:57,991 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:05:58,188 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:05:58,390 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:05:58,586 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:05:58,779 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:05:58,980 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:05:59,176 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:05:59,371 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:05:59,566 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:05:59,760 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:05:59,958 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:06:00,165 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:06:00,375 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:00,571 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:06:00,772 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:06:00,971 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:06:01,182 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:06:01,299 - INFO - validation batch 1, loss: 0.469, 32/6976 datapoints
2025-03-06 23:06:01,353 - INFO - validation batch 51, loss: 9.075, 1632/6976 datapoints
2025-03-06 23:06:01,403 - INFO - validation batch 101, loss: 1.373, 3232/6976 datapoints
2025-03-06 23:06:01,455 - INFO - validation batch 151, loss: 2.355, 4832/6976 datapoints
2025-03-06 23:06:01,508 - INFO - validation batch 201, loss: 3.980, 6432/6976 datapoints
2025-03-06 23:06:01,525 - INFO - Epoch 751/800 done.
2025-03-06 23:06:01,525 - INFO - Final validation performance:
Loss: 3.450, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:06:01,525 - INFO - Beginning epoch 752/800
2025-03-06 23:06:01,530 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:06:01,721 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:06:01,918 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:06:02,122 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:02,325 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:06:02,522 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:06:02,742 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:06:02,940 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:06:03,141 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:06:03,345 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:06:03,549 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:06:03,755 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:06:03,954 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:06:04,165 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:04,364 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:06:04,567 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:06:04,766 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:06:04,967 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:06:05,071 - INFO - validation batch 1, loss: 0.472, 32/6976 datapoints
2025-03-06 23:06:05,123 - INFO - validation batch 51, loss: 9.132, 1632/6976 datapoints
2025-03-06 23:06:05,183 - INFO - validation batch 101, loss: 1.365, 3232/6976 datapoints
2025-03-06 23:06:05,239 - INFO - validation batch 151, loss: 2.345, 4832/6976 datapoints
2025-03-06 23:06:05,300 - INFO - validation batch 201, loss: 3.957, 6432/6976 datapoints
2025-03-06 23:06:05,316 - INFO - Epoch 752/800 done.
2025-03-06 23:06:05,316 - INFO - Final validation performance:
Loss: 3.454, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:06:05,317 - INFO - Beginning epoch 753/800
2025-03-06 23:06:05,324 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:06:05,514 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:06:05,715 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:06:05,920 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:06,122 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:06:06,325 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:06:06,530 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:06:06,728 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:06:06,928 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:06:07,126 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:06:07,325 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:06:07,527 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:06:07,726 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:06:07,934 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:08,135 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:06:08,341 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:06:08,542 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:06:08,740 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:06:08,846 - INFO - validation batch 1, loss: 0.459, 32/6976 datapoints
2025-03-06 23:06:08,905 - INFO - validation batch 51, loss: 9.146, 1632/6976 datapoints
2025-03-06 23:06:08,961 - INFO - validation batch 101, loss: 1.345, 3232/6976 datapoints
2025-03-06 23:06:09,016 - INFO - validation batch 151, loss: 2.379, 4832/6976 datapoints
2025-03-06 23:06:09,069 - INFO - validation batch 201, loss: 3.944, 6432/6976 datapoints
2025-03-06 23:06:09,088 - INFO - Epoch 753/800 done.
2025-03-06 23:06:09,089 - INFO - Final validation performance:
Loss: 3.454, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:06:09,089 - INFO - Beginning epoch 754/800
2025-03-06 23:06:09,095 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:06:09,282 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:06:09,486 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:06:09,686 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:09,882 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:06:10,076 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:06:10,282 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:06:10,478 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:06:10,669 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:06:10,862 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:06:11,058 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:06:11,265 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:06:11,481 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:06:11,688 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:11,880 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:06:12,087 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:06:12,288 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:06:12,487 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:06:12,590 - INFO - validation batch 1, loss: 0.433, 32/6976 datapoints
2025-03-06 23:06:12,640 - INFO - validation batch 51, loss: 9.148, 1632/6976 datapoints
2025-03-06 23:06:12,689 - INFO - validation batch 101, loss: 1.318, 3232/6976 datapoints
2025-03-06 23:06:12,737 - INFO - validation batch 151, loss: 2.446, 4832/6976 datapoints
2025-03-06 23:06:12,785 - INFO - validation batch 201, loss: 3.932, 6432/6976 datapoints
2025-03-06 23:06:12,801 - INFO - Epoch 754/800 done.
2025-03-06 23:06:12,801 - INFO - Final validation performance:
Loss: 3.455, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:06:12,802 - INFO - Beginning epoch 755/800
2025-03-06 23:06:12,806 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:06:12,997 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:06:13,193 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:06:13,393 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:13,589 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:06:13,781 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:06:13,982 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:06:14,178 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:06:14,373 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:06:14,570 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:06:14,762 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:06:14,963 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:06:15,164 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:06:15,373 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:15,566 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:06:15,767 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:06:15,965 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:06:16,164 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:06:16,265 - INFO - validation batch 1, loss: 0.415, 32/6976 datapoints
2025-03-06 23:06:16,313 - INFO - validation batch 51, loss: 9.180, 1632/6976 datapoints
2025-03-06 23:06:16,360 - INFO - validation batch 101, loss: 1.290, 3232/6976 datapoints
2025-03-06 23:06:16,408 - INFO - validation batch 151, loss: 2.512, 4832/6976 datapoints
2025-03-06 23:06:16,458 - INFO - validation batch 201, loss: 3.927, 6432/6976 datapoints
2025-03-06 23:06:16,474 - INFO - Epoch 755/800 done.
2025-03-06 23:06:16,474 - INFO - Final validation performance:
Loss: 3.465, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:06:16,475 - INFO - Beginning epoch 756/800
2025-03-06 23:06:16,479 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:06:16,666 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:06:16,858 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:06:17,063 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:17,260 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:06:17,452 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:06:17,652 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 23:06:17,847 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:06:18,042 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:06:18,237 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:06:18,432 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:06:18,635 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:06:18,829 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:06:19,036 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:19,227 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:06:19,432 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:06:19,630 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:06:19,827 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:06:19,924 - INFO - validation batch 1, loss: 0.397, 32/6976 datapoints
2025-03-06 23:06:19,971 - INFO - validation batch 51, loss: 9.173, 1632/6976 datapoints
2025-03-06 23:06:20,022 - INFO - validation batch 101, loss: 1.271, 3232/6976 datapoints
2025-03-06 23:06:20,076 - INFO - validation batch 151, loss: 2.562, 4832/6976 datapoints
2025-03-06 23:06:20,129 - INFO - validation batch 201, loss: 3.957, 6432/6976 datapoints
2025-03-06 23:06:20,150 - INFO - Epoch 756/800 done.
2025-03-06 23:06:20,150 - INFO - Final validation performance:
Loss: 3.472, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:06:20,151 - INFO - Beginning epoch 757/800
2025-03-06 23:06:20,155 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:06:20,352 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:06:20,553 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:06:20,757 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:20,957 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:06:21,160 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:06:21,371 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 23:06:21,585 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:06:21,782 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:06:21,978 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:06:22,176 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:06:22,382 - INFO - training batch 551, loss: 0.259, 17632/28000 datapoints
2025-03-06 23:06:22,579 - INFO - training batch 601, loss: 0.146, 19232/28000 datapoints
2025-03-06 23:06:22,784 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:22,982 - INFO - training batch 701, loss: 0.015, 22432/28000 datapoints
2025-03-06 23:06:23,189 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:06:23,391 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:06:23,592 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:06:23,694 - INFO - validation batch 1, loss: 0.475, 32/6976 datapoints
2025-03-06 23:06:23,747 - INFO - validation batch 51, loss: 9.612, 1632/6976 datapoints
2025-03-06 23:06:23,798 - INFO - validation batch 101, loss: 1.349, 3232/6976 datapoints
2025-03-06 23:06:23,851 - INFO - validation batch 151, loss: 2.204, 4832/6976 datapoints
2025-03-06 23:06:23,904 - INFO - validation batch 201, loss: 3.912, 6432/6976 datapoints
2025-03-06 23:06:23,921 - INFO - Epoch 757/800 done.
2025-03-06 23:06:23,921 - INFO - Final validation performance:
Loss: 3.510, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:06:23,921 - INFO - Beginning epoch 758/800
2025-03-06 23:06:23,926 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:06:24,125 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:06:24,322 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:06:24,536 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:24,734 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:06:24,929 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-06 23:06:25,135 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 23:06:25,337 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:06:25,538 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:06:25,745 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:06:25,947 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:06:26,150 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:06:26,347 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:06:26,558 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:26,754 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-06 23:06:26,957 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:06:27,160 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:06:27,360 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:06:27,461 - INFO - validation batch 1, loss: 0.470, 32/6976 datapoints
2025-03-06 23:06:27,511 - INFO - validation batch 51, loss: 9.575, 1632/6976 datapoints
2025-03-06 23:06:27,564 - INFO - validation batch 101, loss: 1.358, 3232/6976 datapoints
2025-03-06 23:06:27,617 - INFO - validation batch 151, loss: 2.096, 4832/6976 datapoints
2025-03-06 23:06:27,668 - INFO - validation batch 201, loss: 3.863, 6432/6976 datapoints
2025-03-06 23:06:27,686 - INFO - Epoch 758/800 done.
2025-03-06 23:06:27,687 - INFO - Final validation performance:
Loss: 3.473, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:06:27,687 - INFO - Beginning epoch 759/800
2025-03-06 23:06:27,692 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:06:27,882 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:06:28,075 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:06:28,277 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:28,476 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:06:28,671 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:06:28,871 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:06:29,065 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:06:29,258 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:06:29,455 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 23:06:29,652 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:06:29,850 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:06:30,045 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:06:30,250 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:30,446 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 23:06:30,645 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:06:30,841 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:06:31,038 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:06:31,137 - INFO - validation batch 1, loss: 0.478, 32/6976 datapoints
2025-03-06 23:06:31,185 - INFO - validation batch 51, loss: 9.428, 1632/6976 datapoints
2025-03-06 23:06:31,233 - INFO - validation batch 101, loss: 1.403, 3232/6976 datapoints
2025-03-06 23:06:31,280 - INFO - validation batch 151, loss: 2.171, 4832/6976 datapoints
2025-03-06 23:06:31,327 - INFO - validation batch 201, loss: 3.750, 6432/6976 datapoints
2025-03-06 23:06:31,343 - INFO - Epoch 759/800 done.
2025-03-06 23:06:31,344 - INFO - Final validation performance:
Loss: 3.446, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:06:31,344 - INFO - Beginning epoch 760/800
2025-03-06 23:06:31,349 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:06:31,556 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:06:31,751 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:06:31,950 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:32,150 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:06:32,344 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:06:32,548 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:06:32,742 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-06 23:06:32,933 - INFO - training batch 401, loss: 0.032, 12832/28000 datapoints
2025-03-06 23:06:33,139 - INFO - training batch 451, loss: 0.024, 14432/28000 datapoints
2025-03-06 23:06:33,336 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:06:33,534 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:06:33,734 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:06:33,938 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:34,136 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 23:06:34,341 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:06:34,542 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-06 23:06:34,738 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:06:34,835 - INFO - validation batch 1, loss: 0.467, 32/6976 datapoints
2025-03-06 23:06:34,882 - INFO - validation batch 51, loss: 9.092, 1632/6976 datapoints
2025-03-06 23:06:34,933 - INFO - validation batch 101, loss: 1.317, 3232/6976 datapoints
2025-03-06 23:06:34,981 - INFO - validation batch 151, loss: 2.179, 4832/6976 datapoints
2025-03-06 23:06:35,043 - INFO - validation batch 201, loss: 3.943, 6432/6976 datapoints
2025-03-06 23:06:35,064 - INFO - Epoch 760/800 done.
2025-03-06 23:06:35,065 - INFO - Final validation performance:
Loss: 3.400, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:06:35,065 - INFO - Beginning epoch 761/800
2025-03-06 23:06:35,070 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:06:35,306 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:06:35,554 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:06:35,754 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:35,950 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:06:36,146 - INFO - training batch 251, loss: 0.160, 8032/28000 datapoints
2025-03-06 23:06:36,349 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-06 23:06:36,545 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:06:36,741 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:06:36,935 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 23:06:37,130 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:06:37,329 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:06:37,525 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:06:37,730 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:37,923 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:06:38,149 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:06:38,349 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-06 23:06:38,548 - INFO - training batch 851, loss: 0.124, 27232/28000 datapoints
2025-03-06 23:06:38,645 - INFO - validation batch 1, loss: 0.444, 32/6976 datapoints
2025-03-06 23:06:38,692 - INFO - validation batch 51, loss: 8.892, 1632/6976 datapoints
2025-03-06 23:06:38,741 - INFO - validation batch 101, loss: 1.415, 3232/6976 datapoints
2025-03-06 23:06:38,789 - INFO - validation batch 151, loss: 2.449, 4832/6976 datapoints
2025-03-06 23:06:38,836 - INFO - validation batch 201, loss: 4.196, 6432/6976 datapoints
2025-03-06 23:06:38,853 - INFO - Epoch 761/800 done.
2025-03-06 23:06:38,853 - INFO - Final validation performance:
Loss: 3.479, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:06:38,853 - INFO - Beginning epoch 762/800
2025-03-06 23:06:38,858 - INFO - training batch 1, loss: 0.014, 32/28000 datapoints
2025-03-06 23:06:39,049 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:06:39,240 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:06:39,443 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:39,644 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:06:39,836 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:06:40,037 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:06:40,230 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:06:40,436 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:06:40,633 - INFO - training batch 451, loss: 0.019, 14432/28000 datapoints
2025-03-06 23:06:40,832 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-06 23:06:41,030 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:06:41,232 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:06:41,441 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:41,663 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:06:41,870 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:06:42,074 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:06:42,278 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:06:42,382 - INFO - validation batch 1, loss: 0.433, 32/6976 datapoints
2025-03-06 23:06:42,435 - INFO - validation batch 51, loss: 8.438, 1632/6976 datapoints
2025-03-06 23:06:42,500 - INFO - validation batch 101, loss: 1.369, 3232/6976 datapoints
2025-03-06 23:06:42,552 - INFO - validation batch 151, loss: 2.400, 4832/6976 datapoints
2025-03-06 23:06:42,605 - INFO - validation batch 201, loss: 3.744, 6432/6976 datapoints
2025-03-06 23:06:42,621 - INFO - Epoch 762/800 done.
2025-03-06 23:06:42,621 - INFO - Final validation performance:
Loss: 3.277, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:06:42,622 - INFO - Beginning epoch 763/800
2025-03-06 23:06:42,627 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-06 23:06:42,827 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:06:43,028 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:06:43,260 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:43,457 - INFO - training batch 201, loss: 0.071, 6432/28000 datapoints
2025-03-06 23:06:43,687 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-06 23:06:43,889 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:06:44,088 - INFO - training batch 351, loss: 0.019, 11232/28000 datapoints
2025-03-06 23:06:44,286 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-06 23:06:44,486 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 23:06:44,686 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 23:06:44,889 - INFO - training batch 551, loss: 0.030, 17632/28000 datapoints
2025-03-06 23:06:45,092 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:06:45,304 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:45,504 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:06:45,706 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:06:45,908 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:06:46,112 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:06:46,214 - INFO - validation batch 1, loss: 0.477, 32/6976 datapoints
2025-03-06 23:06:46,266 - INFO - validation batch 51, loss: 9.415, 1632/6976 datapoints
2025-03-06 23:06:46,319 - INFO - validation batch 101, loss: 1.535, 3232/6976 datapoints
2025-03-06 23:06:46,375 - INFO - validation batch 151, loss: 2.216, 4832/6976 datapoints
2025-03-06 23:06:46,429 - INFO - validation batch 201, loss: 3.718, 6432/6976 datapoints
2025-03-06 23:06:46,446 - INFO - Epoch 763/800 done.
2025-03-06 23:06:46,446 - INFO - Final validation performance:
Loss: 3.472, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:06:46,447 - INFO - Beginning epoch 764/800
2025-03-06 23:06:46,452 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:06:46,644 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:06:46,840 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:06:47,044 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:47,240 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:06:47,433 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:06:47,637 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:06:47,831 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 23:06:48,029 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 23:06:48,221 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:06:48,418 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:06:48,617 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:06:48,811 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:06:49,017 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:49,212 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:06:49,410 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:06:49,604 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:06:49,800 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:06:49,899 - INFO - validation batch 1, loss: 0.541, 32/6976 datapoints
2025-03-06 23:06:49,947 - INFO - validation batch 51, loss: 9.445, 1632/6976 datapoints
2025-03-06 23:06:49,996 - INFO - validation batch 101, loss: 1.638, 3232/6976 datapoints
2025-03-06 23:06:50,046 - INFO - validation batch 151, loss: 2.216, 4832/6976 datapoints
2025-03-06 23:06:50,094 - INFO - validation batch 201, loss: 3.613, 6432/6976 datapoints
2025-03-06 23:06:50,110 - INFO - Epoch 764/800 done.
2025-03-06 23:06:50,111 - INFO - Final validation performance:
Loss: 3.491, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:06:50,111 - INFO - Beginning epoch 765/800
2025-03-06 23:06:50,116 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:06:50,304 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:06:50,505 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:06:50,701 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:50,899 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 23:06:51,103 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 23:06:51,306 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:06:51,502 - INFO - training batch 351, loss: 0.010, 11232/28000 datapoints
2025-03-06 23:06:51,714 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:06:51,921 - INFO - training batch 451, loss: 0.016, 14432/28000 datapoints
2025-03-06 23:06:52,121 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-06 23:06:52,320 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:06:52,519 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:06:52,735 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:52,928 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:06:53,130 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:06:53,327 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:06:53,525 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 23:06:53,623 - INFO - validation batch 1, loss: 0.345, 32/6976 datapoints
2025-03-06 23:06:53,671 - INFO - validation batch 51, loss: 8.738, 1632/6976 datapoints
2025-03-06 23:06:53,719 - INFO - validation batch 101, loss: 1.141, 3232/6976 datapoints
2025-03-06 23:06:53,766 - INFO - validation batch 151, loss: 2.370, 4832/6976 datapoints
2025-03-06 23:06:53,823 - INFO - validation batch 201, loss: 3.443, 6432/6976 datapoints
2025-03-06 23:06:53,839 - INFO - Epoch 765/800 done.
2025-03-06 23:06:53,840 - INFO - Final validation performance:
Loss: 3.207, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:06:53,840 - INFO - Beginning epoch 766/800
2025-03-06 23:06:53,845 - INFO - training batch 1, loss: 0.033, 32/28000 datapoints
2025-03-06 23:06:54,038 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:06:54,232 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:06:54,434 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:54,632 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:06:54,826 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:06:55,030 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:06:55,225 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:06:55,426 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:06:55,621 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-06 23:06:55,817 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:06:56,020 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:06:56,213 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:06:56,418 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:06:56,616 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:06:56,815 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:06:57,020 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:06:57,218 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:06:57,315 - INFO - validation batch 1, loss: 0.685, 32/6976 datapoints
2025-03-06 23:06:57,362 - INFO - validation batch 51, loss: 9.334, 1632/6976 datapoints
2025-03-06 23:06:57,410 - INFO - validation batch 101, loss: 1.484, 3232/6976 datapoints
2025-03-06 23:06:57,458 - INFO - validation batch 151, loss: 2.009, 4832/6976 datapoints
2025-03-06 23:06:57,506 - INFO - validation batch 201, loss: 3.580, 6432/6976 datapoints
2025-03-06 23:06:57,522 - INFO - Epoch 766/800 done.
2025-03-06 23:06:57,522 - INFO - Final validation performance:
Loss: 3.418, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:06:57,523 - INFO - Beginning epoch 767/800
2025-03-06 23:06:57,527 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 23:06:57,715 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:06:57,910 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:06:58,116 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:06:58,315 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:06:58,511 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:06:58,714 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:06:58,910 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:06:59,107 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:06:59,301 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:06:59,494 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:06:59,694 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:06:59,886 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:07:00,092 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:00,287 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:07:00,494 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:07:00,694 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:07:00,892 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:07:00,996 - INFO - validation batch 1, loss: 0.673, 32/6976 datapoints
2025-03-06 23:07:01,046 - INFO - validation batch 51, loss: 9.438, 1632/6976 datapoints
2025-03-06 23:07:01,097 - INFO - validation batch 101, loss: 1.504, 3232/6976 datapoints
2025-03-06 23:07:01,146 - INFO - validation batch 151, loss: 2.058, 4832/6976 datapoints
2025-03-06 23:07:01,197 - INFO - validation batch 201, loss: 3.654, 6432/6976 datapoints
2025-03-06 23:07:01,213 - INFO - Epoch 767/800 done.
2025-03-06 23:07:01,213 - INFO - Final validation performance:
Loss: 3.465, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:07:01,214 - INFO - Beginning epoch 768/800
2025-03-06 23:07:01,219 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 23:07:01,411 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:07:01,611 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:07:01,837 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:07:02,041 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:07:02,237 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:07:02,444 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:07:02,642 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:07:02,839 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:07:03,040 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:07:03,237 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:07:03,440 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:07:03,637 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:07:03,846 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:04,047 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:07:04,252 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:07:04,450 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:07:04,650 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:07:04,752 - INFO - validation batch 1, loss: 0.640, 32/6976 datapoints
2025-03-06 23:07:04,804 - INFO - validation batch 51, loss: 9.443, 1632/6976 datapoints
2025-03-06 23:07:04,857 - INFO - validation batch 101, loss: 1.478, 3232/6976 datapoints
2025-03-06 23:07:04,910 - INFO - validation batch 151, loss: 2.124, 4832/6976 datapoints
2025-03-06 23:07:04,962 - INFO - validation batch 201, loss: 3.649, 6432/6976 datapoints
2025-03-06 23:07:04,979 - INFO - Epoch 768/800 done.
2025-03-06 23:07:04,979 - INFO - Final validation performance:
Loss: 3.467, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:07:04,979 - INFO - Beginning epoch 769/800
2025-03-06 23:07:04,985 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 23:07:05,184 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:07:05,389 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:07:05,597 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:07:05,801 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:07:06,000 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:07:06,208 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:07:06,404 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:07:06,605 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:07:06,803 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:07:07,007 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:07:07,214 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:07:07,411 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:07:07,621 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:07,817 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:07:08,022 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:07:08,227 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:07:08,426 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:07:08,532 - INFO - validation batch 1, loss: 0.607, 32/6976 datapoints
2025-03-06 23:07:08,584 - INFO - validation batch 51, loss: 9.437, 1632/6976 datapoints
2025-03-06 23:07:08,639 - INFO - validation batch 101, loss: 1.459, 3232/6976 datapoints
2025-03-06 23:07:08,690 - INFO - validation batch 151, loss: 2.195, 4832/6976 datapoints
2025-03-06 23:07:08,739 - INFO - validation batch 201, loss: 3.678, 6432/6976 datapoints
2025-03-06 23:07:08,755 - INFO - Epoch 769/800 done.
2025-03-06 23:07:08,755 - INFO - Final validation performance:
Loss: 3.475, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:07:08,755 - INFO - Beginning epoch 770/800
2025-03-06 23:07:08,760 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 23:07:08,946 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:07:09,145 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:07:09,343 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:07:09,544 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:07:09,740 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:07:09,941 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:07:10,136 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:07:10,332 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:07:10,532 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:07:10,727 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:07:10,926 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:07:11,122 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:07:11,326 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:11,517 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:07:11,721 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:07:11,939 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:07:12,139 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:07:12,240 - INFO - validation batch 1, loss: 0.569, 32/6976 datapoints
2025-03-06 23:07:12,288 - INFO - validation batch 51, loss: 9.422, 1632/6976 datapoints
2025-03-06 23:07:12,336 - INFO - validation batch 101, loss: 1.441, 3232/6976 datapoints
2025-03-06 23:07:12,382 - INFO - validation batch 151, loss: 2.282, 4832/6976 datapoints
2025-03-06 23:07:12,429 - INFO - validation batch 201, loss: 3.702, 6432/6976 datapoints
2025-03-06 23:07:12,445 - INFO - Epoch 770/800 done.
2025-03-06 23:07:12,445 - INFO - Final validation performance:
Loss: 3.484, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:07:12,446 - INFO - Beginning epoch 771/800
2025-03-06 23:07:12,450 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 23:07:12,648 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:07:12,842 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:07:13,043 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:07:13,242 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:07:13,435 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:07:13,635 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:07:13,829 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:07:14,026 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:07:14,222 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:07:14,414 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:07:14,616 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:07:14,811 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:07:15,017 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:15,211 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:07:15,417 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:07:15,616 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:07:15,816 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:07:15,913 - INFO - validation batch 1, loss: 0.527, 32/6976 datapoints
2025-03-06 23:07:15,961 - INFO - validation batch 51, loss: 9.397, 1632/6976 datapoints
2025-03-06 23:07:16,011 - INFO - validation batch 101, loss: 1.427, 3232/6976 datapoints
2025-03-06 23:07:16,058 - INFO - validation batch 151, loss: 2.369, 4832/6976 datapoints
2025-03-06 23:07:16,105 - INFO - validation batch 201, loss: 3.729, 6432/6976 datapoints
2025-03-06 23:07:16,122 - INFO - Epoch 771/800 done.
2025-03-06 23:07:16,122 - INFO - Final validation performance:
Loss: 3.490, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:07:16,123 - INFO - Beginning epoch 772/800
2025-03-06 23:07:16,127 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 23:07:16,315 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:07:16,510 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:07:16,716 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:07:16,912 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:07:17,113 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:07:17,313 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:07:17,505 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:07:17,703 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:07:17,900 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:07:18,097 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:07:18,299 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:07:18,495 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:07:18,702 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:18,897 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:07:19,100 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:07:19,298 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:07:19,496 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:07:19,595 - INFO - validation batch 1, loss: 0.491, 32/6976 datapoints
2025-03-06 23:07:19,642 - INFO - validation batch 51, loss: 9.370, 1632/6976 datapoints
2025-03-06 23:07:19,690 - INFO - validation batch 101, loss: 1.417, 3232/6976 datapoints
2025-03-06 23:07:19,740 - INFO - validation batch 151, loss: 2.444, 4832/6976 datapoints
2025-03-06 23:07:19,789 - INFO - validation batch 201, loss: 3.771, 6432/6976 datapoints
2025-03-06 23:07:19,806 - INFO - Epoch 772/800 done.
2025-03-06 23:07:19,806 - INFO - Final validation performance:
Loss: 3.499, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:07:19,807 - INFO - Beginning epoch 773/800
2025-03-06 23:07:19,811 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 23:07:19,999 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:07:20,194 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:07:20,397 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:07:20,603 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:07:20,803 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:07:21,009 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:07:21,205 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:07:21,404 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:07:21,602 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:07:21,802 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:07:22,024 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:07:22,226 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:07:22,434 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:22,633 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:07:22,841 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:07:23,045 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:07:23,247 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:07:23,349 - INFO - validation batch 1, loss: 0.473, 32/6976 datapoints
2025-03-06 23:07:23,401 - INFO - validation batch 51, loss: 9.349, 1632/6976 datapoints
2025-03-06 23:07:23,452 - INFO - validation batch 101, loss: 1.385, 3232/6976 datapoints
2025-03-06 23:07:23,505 - INFO - validation batch 151, loss: 2.537, 4832/6976 datapoints
2025-03-06 23:07:23,557 - INFO - validation batch 201, loss: 3.817, 6432/6976 datapoints
2025-03-06 23:07:23,573 - INFO - Epoch 773/800 done.
2025-03-06 23:07:23,573 - INFO - Final validation performance:
Loss: 3.512, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:07:23,574 - INFO - Beginning epoch 774/800
2025-03-06 23:07:23,578 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:07:23,772 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:07:23,969 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:07:24,179 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:07:24,378 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:07:24,578 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:07:24,783 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:07:24,979 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:07:25,178 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:07:25,382 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:07:25,582 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:07:25,788 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:07:25,986 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:07:26,196 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:26,395 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:07:26,601 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:07:26,804 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:07:27,007 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:07:27,114 - INFO - validation batch 1, loss: 0.474, 32/6976 datapoints
2025-03-06 23:07:27,166 - INFO - validation batch 51, loss: 9.278, 1632/6976 datapoints
2025-03-06 23:07:27,219 - INFO - validation batch 101, loss: 1.278, 3232/6976 datapoints
2025-03-06 23:07:27,272 - INFO - validation batch 151, loss: 2.642, 4832/6976 datapoints
2025-03-06 23:07:27,325 - INFO - validation batch 201, loss: 3.803, 6432/6976 datapoints
2025-03-06 23:07:27,343 - INFO - Epoch 774/800 done.
2025-03-06 23:07:27,344 - INFO - Final validation performance:
Loss: 3.495, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:07:27,344 - INFO - Beginning epoch 775/800
2025-03-06 23:07:27,350 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:07:27,548 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:07:27,746 - INFO - training batch 101, loss: 0.131, 3232/28000 datapoints
2025-03-06 23:07:27,947 - INFO - training batch 151, loss: 0.093, 4832/28000 datapoints
2025-03-06 23:07:28,155 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:07:28,353 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:07:28,564 - INFO - training batch 301, loss: 0.022, 9632/28000 datapoints
2025-03-06 23:07:28,759 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-06 23:07:28,960 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:07:29,159 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-06 23:07:29,358 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:07:29,557 - INFO - training batch 551, loss: 0.093, 17632/28000 datapoints
2025-03-06 23:07:29,757 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-06 23:07:29,965 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:30,166 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:07:30,370 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-06 23:07:30,570 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:07:30,774 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-06 23:07:30,880 - INFO - validation batch 1, loss: 0.628, 32/6976 datapoints
2025-03-06 23:07:30,931 - INFO - validation batch 51, loss: 9.104, 1632/6976 datapoints
2025-03-06 23:07:30,983 - INFO - validation batch 101, loss: 1.471, 3232/6976 datapoints
2025-03-06 23:07:31,038 - INFO - validation batch 151, loss: 2.094, 4832/6976 datapoints
2025-03-06 23:07:31,089 - INFO - validation batch 201, loss: 3.883, 6432/6976 datapoints
2025-03-06 23:07:31,108 - INFO - Epoch 775/800 done.
2025-03-06 23:07:31,108 - INFO - Final validation performance:
Loss: 3.436, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:07:31,109 - INFO - Beginning epoch 776/800
2025-03-06 23:07:31,113 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:07:31,307 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:07:31,503 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:07:31,707 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:07:31,909 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-06 23:07:32,122 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 23:07:32,330 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:07:32,524 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:07:32,726 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:07:32,928 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:07:33,131 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-06 23:07:33,329 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:07:33,527 - INFO - training batch 601, loss: 0.245, 19232/28000 datapoints
2025-03-06 23:07:33,732 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:33,928 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:07:34,132 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-06 23:07:34,330 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:07:34,535 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:07:34,638 - INFO - validation batch 1, loss: 0.571, 32/6976 datapoints
2025-03-06 23:07:34,689 - INFO - validation batch 51, loss: 8.544, 1632/6976 datapoints
2025-03-06 23:07:34,742 - INFO - validation batch 101, loss: 1.359, 3232/6976 datapoints
2025-03-06 23:07:34,791 - INFO - validation batch 151, loss: 2.451, 4832/6976 datapoints
2025-03-06 23:07:34,840 - INFO - validation batch 201, loss: 3.962, 6432/6976 datapoints
2025-03-06 23:07:34,856 - INFO - Epoch 776/800 done.
2025-03-06 23:07:34,856 - INFO - Final validation performance:
Loss: 3.377, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:07:34,857 - INFO - Beginning epoch 777/800
2025-03-06 23:07:34,862 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-06 23:07:35,053 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:07:35,248 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:07:35,455 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:07:35,653 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:07:35,847 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:07:36,053 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:07:36,249 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 23:07:36,522 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:07:36,722 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:07:36,922 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:07:37,127 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:07:37,322 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:07:37,525 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:37,720 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:07:37,919 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:07:38,167 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:07:38,415 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:07:38,514 - INFO - validation batch 1, loss: 0.552, 32/6976 datapoints
2025-03-06 23:07:38,563 - INFO - validation batch 51, loss: 9.271, 1632/6976 datapoints
2025-03-06 23:07:38,613 - INFO - validation batch 101, loss: 1.553, 3232/6976 datapoints
2025-03-06 23:07:38,661 - INFO - validation batch 151, loss: 2.113, 4832/6976 datapoints
2025-03-06 23:07:38,713 - INFO - validation batch 201, loss: 4.089, 6432/6976 datapoints
2025-03-06 23:07:38,733 - INFO - Epoch 777/800 done.
2025-03-06 23:07:38,734 - INFO - Final validation performance:
Loss: 3.516, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:07:38,734 - INFO - Beginning epoch 778/800
2025-03-06 23:07:38,738 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:07:38,926 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:07:39,123 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:07:39,324 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:07:39,524 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:07:39,717 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:07:39,918 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 23:07:40,113 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 23:07:40,308 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:07:40,505 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:07:40,705 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:07:40,910 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:07:41,111 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:07:41,320 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:41,519 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:07:41,725 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:07:41,928 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:07:42,136 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:07:42,265 - INFO - validation batch 1, loss: 0.538, 32/6976 datapoints
2025-03-06 23:07:42,317 - INFO - validation batch 51, loss: 9.105, 1632/6976 datapoints
2025-03-06 23:07:42,369 - INFO - validation batch 101, loss: 1.528, 3232/6976 datapoints
2025-03-06 23:07:42,422 - INFO - validation batch 151, loss: 2.062, 4832/6976 datapoints
2025-03-06 23:07:42,474 - INFO - validation batch 201, loss: 4.014, 6432/6976 datapoints
2025-03-06 23:07:42,493 - INFO - Epoch 778/800 done.
2025-03-06 23:07:42,493 - INFO - Final validation performance:
Loss: 3.449, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:07:42,493 - INFO - Beginning epoch 779/800
2025-03-06 23:07:42,499 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:07:42,690 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:07:42,897 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:07:43,106 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:07:43,304 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:07:43,499 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:07:43,702 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:07:43,902 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:07:44,129 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:07:44,324 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:07:44,522 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:07:44,726 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:07:44,925 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:07:45,133 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:45,330 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:07:45,531 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:07:45,732 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:07:45,932 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:07:46,032 - INFO - validation batch 1, loss: 0.525, 32/6976 datapoints
2025-03-06 23:07:46,081 - INFO - validation batch 51, loss: 9.117, 1632/6976 datapoints
2025-03-06 23:07:46,130 - INFO - validation batch 101, loss: 1.447, 3232/6976 datapoints
2025-03-06 23:07:46,178 - INFO - validation batch 151, loss: 2.094, 4832/6976 datapoints
2025-03-06 23:07:46,225 - INFO - validation batch 201, loss: 3.986, 6432/6976 datapoints
2025-03-06 23:07:46,241 - INFO - Epoch 779/800 done.
2025-03-06 23:07:46,241 - INFO - Final validation performance:
Loss: 3.434, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:07:46,242 - INFO - Beginning epoch 780/800
2025-03-06 23:07:46,247 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:07:46,435 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:07:46,630 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:07:46,833 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:07:47,034 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:07:47,233 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:07:47,433 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:07:47,630 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:07:47,847 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:07:48,046 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:07:48,246 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:07:48,461 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:07:48,663 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:07:48,866 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:49,062 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:07:49,264 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:07:49,461 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:07:49,660 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:07:49,765 - INFO - validation batch 1, loss: 0.537, 32/6976 datapoints
2025-03-06 23:07:49,817 - INFO - validation batch 51, loss: 9.147, 1632/6976 datapoints
2025-03-06 23:07:49,865 - INFO - validation batch 101, loss: 1.426, 3232/6976 datapoints
2025-03-06 23:07:49,913 - INFO - validation batch 151, loss: 2.105, 4832/6976 datapoints
2025-03-06 23:07:49,962 - INFO - validation batch 201, loss: 4.007, 6432/6976 datapoints
2025-03-06 23:07:49,978 - INFO - Epoch 780/800 done.
2025-03-06 23:07:49,978 - INFO - Final validation performance:
Loss: 3.445, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:07:49,979 - INFO - Beginning epoch 781/800
2025-03-06 23:07:49,983 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:07:50,175 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:07:50,369 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:07:50,571 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:07:50,773 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:07:50,968 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:07:51,176 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:07:51,370 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:07:51,572 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:07:51,771 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:07:51,971 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:07:52,174 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:07:52,396 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:07:52,600 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:52,797 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:07:52,998 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:07:53,198 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:07:53,397 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:07:53,496 - INFO - validation batch 1, loss: 0.529, 32/6976 datapoints
2025-03-06 23:07:53,543 - INFO - validation batch 51, loss: 9.162, 1632/6976 datapoints
2025-03-06 23:07:53,591 - INFO - validation batch 101, loss: 1.415, 3232/6976 datapoints
2025-03-06 23:07:53,637 - INFO - validation batch 151, loss: 2.120, 4832/6976 datapoints
2025-03-06 23:07:53,686 - INFO - validation batch 201, loss: 4.019, 6432/6976 datapoints
2025-03-06 23:07:53,703 - INFO - Epoch 781/800 done.
2025-03-06 23:07:53,703 - INFO - Final validation performance:
Loss: 3.449, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 23:07:53,703 - INFO - Beginning epoch 782/800
2025-03-06 23:07:53,707 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:07:53,895 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:07:54,089 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:07:54,293 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:07:54,492 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:07:54,689 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:07:54,890 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 23:07:55,089 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:07:55,289 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:07:55,486 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:07:55,682 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:07:55,887 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:07:56,084 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:07:56,289 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:07:56,482 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:07:56,685 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:07:56,883 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:07:57,086 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:07:57,187 - INFO - validation batch 1, loss: 0.516, 32/6976 datapoints
2025-03-06 23:07:57,237 - INFO - validation batch 51, loss: 9.163, 1632/6976 datapoints
2025-03-06 23:07:57,284 - INFO - validation batch 101, loss: 1.400, 3232/6976 datapoints
2025-03-06 23:07:57,331 - INFO - validation batch 151, loss: 2.157, 4832/6976 datapoints
2025-03-06 23:07:57,378 - INFO - validation batch 201, loss: 4.011, 6432/6976 datapoints
2025-03-06 23:07:57,394 - INFO - Epoch 782/800 done.
2025-03-06 23:07:57,395 - INFO - Final validation performance:
Loss: 3.450, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:07:57,395 - INFO - Beginning epoch 783/800
2025-03-06 23:07:57,399 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:07:57,585 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:07:57,780 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:07:57,980 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:07:58,186 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:07:58,383 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:07:58,583 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 23:07:58,784 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:07:58,986 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:07:59,185 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:07:59,382 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:07:59,582 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:07:59,779 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:07:59,986 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:08:00,184 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:08:00,386 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:00,586 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:08:00,789 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:08:00,888 - INFO - validation batch 1, loss: 0.488, 32/6976 datapoints
2025-03-06 23:08:00,943 - INFO - validation batch 51, loss: 9.152, 1632/6976 datapoints
2025-03-06 23:08:00,998 - INFO - validation batch 101, loss: 1.381, 3232/6976 datapoints
2025-03-06 23:08:01,051 - INFO - validation batch 151, loss: 2.229, 4832/6976 datapoints
2025-03-06 23:08:01,101 - INFO - validation batch 201, loss: 3.997, 6432/6976 datapoints
2025-03-06 23:08:01,117 - INFO - Epoch 783/800 done.
2025-03-06 23:08:01,118 - INFO - Final validation performance:
Loss: 3.449, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:08:01,118 - INFO - Beginning epoch 784/800
2025-03-06 23:08:01,123 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:08:01,320 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:08:01,516 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:08:01,723 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:08:01,924 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:08:02,128 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:08:02,332 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 23:08:02,552 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:08:02,755 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:08:02,956 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:08:03,160 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:08:03,367 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:08:03,568 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:08:03,775 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:08:03,972 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:08:04,182 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:04,387 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:08:04,590 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:08:04,693 - INFO - validation batch 1, loss: 0.456, 32/6976 datapoints
2025-03-06 23:08:04,747 - INFO - validation batch 51, loss: 9.137, 1632/6976 datapoints
2025-03-06 23:08:04,796 - INFO - validation batch 101, loss: 1.357, 3232/6976 datapoints
2025-03-06 23:08:04,844 - INFO - validation batch 151, loss: 2.315, 4832/6976 datapoints
2025-03-06 23:08:04,891 - INFO - validation batch 201, loss: 3.970, 6432/6976 datapoints
2025-03-06 23:08:04,908 - INFO - Epoch 784/800 done.
2025-03-06 23:08:04,908 - INFO - Final validation performance:
Loss: 3.447, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:08:04,908 - INFO - Beginning epoch 785/800
2025-03-06 23:08:04,913 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:08:05,104 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:08:05,303 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:08:05,508 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:08:05,708 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:08:05,907 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:08:06,112 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 23:08:06,306 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:08:06,502 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:08:06,702 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:08:06,901 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-06 23:08:07,106 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:08:07,311 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:08:07,516 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:08:07,710 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:08:07,929 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:08,133 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:08:08,334 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:08:08,434 - INFO - validation batch 1, loss: 0.430, 32/6976 datapoints
2025-03-06 23:08:08,481 - INFO - validation batch 51, loss: 9.185, 1632/6976 datapoints
2025-03-06 23:08:08,529 - INFO - validation batch 101, loss: 1.342, 3232/6976 datapoints
2025-03-06 23:08:08,576 - INFO - validation batch 151, loss: 2.413, 4832/6976 datapoints
2025-03-06 23:08:08,623 - INFO - validation batch 201, loss: 3.956, 6432/6976 datapoints
2025-03-06 23:08:08,640 - INFO - Epoch 785/800 done.
2025-03-06 23:08:08,640 - INFO - Final validation performance:
Loss: 3.465, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:08:08,640 - INFO - Beginning epoch 786/800
2025-03-06 23:08:08,645 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:08:08,839 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:08:09,039 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:08:09,243 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:08:09,442 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:08:09,640 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:08:09,840 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 23:08:10,039 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:08:10,236 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:08:10,439 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:08:10,633 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:08:10,839 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:08:11,036 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:08:11,242 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:08:11,436 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:08:11,638 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:11,840 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:08:12,036 - INFO - training batch 851, loss: 0.240, 27232/28000 datapoints
2025-03-06 23:08:12,135 - INFO - validation batch 1, loss: 0.417, 32/6976 datapoints
2025-03-06 23:08:12,192 - INFO - validation batch 51, loss: 8.321, 1632/6976 datapoints
2025-03-06 23:08:12,252 - INFO - validation batch 101, loss: 1.113, 3232/6976 datapoints
2025-03-06 23:08:12,305 - INFO - validation batch 151, loss: 3.008, 4832/6976 datapoints
2025-03-06 23:08:12,353 - INFO - validation batch 201, loss: 4.276, 6432/6976 datapoints
2025-03-06 23:08:12,369 - INFO - Epoch 786/800 done.
2025-03-06 23:08:12,369 - INFO - Final validation performance:
Loss: 3.427, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 23:08:12,370 - INFO - Beginning epoch 787/800
2025-03-06 23:08:12,375 - INFO - training batch 1, loss: 0.011, 32/28000 datapoints
2025-03-06 23:08:12,596 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:08:12,794 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-06 23:08:13,008 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 23:08:13,205 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:08:13,405 - INFO - training batch 251, loss: 0.017, 8032/28000 datapoints
2025-03-06 23:08:13,606 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-06 23:08:13,806 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:08:14,005 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:08:14,203 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:08:14,399 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:08:14,597 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:08:14,796 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-06 23:08:15,005 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 23:08:15,201 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 23:08:15,408 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:15,607 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:08:15,809 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:08:15,908 - INFO - validation batch 1, loss: 0.473, 32/6976 datapoints
2025-03-06 23:08:15,956 - INFO - validation batch 51, loss: 9.140, 1632/6976 datapoints
2025-03-06 23:08:16,006 - INFO - validation batch 101, loss: 1.578, 3232/6976 datapoints
2025-03-06 23:08:16,054 - INFO - validation batch 151, loss: 1.780, 4832/6976 datapoints
2025-03-06 23:08:16,103 - INFO - validation batch 201, loss: 3.976, 6432/6976 datapoints
2025-03-06 23:08:16,120 - INFO - Epoch 787/800 done.
2025-03-06 23:08:16,120 - INFO - Final validation performance:
Loss: 3.389, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:08:16,121 - INFO - Beginning epoch 788/800
2025-03-06 23:08:16,126 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 23:08:16,317 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:08:16,509 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:08:16,711 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:08:16,911 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:08:17,111 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-06 23:08:17,317 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:08:17,514 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 23:08:17,710 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-06 23:08:17,908 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:08:18,108 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:08:18,314 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:08:18,520 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:08:18,738 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:08:18,948 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:08:19,157 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:19,361 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:08:19,561 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:08:19,657 - INFO - validation batch 1, loss: 0.545, 32/6976 datapoints
2025-03-06 23:08:19,705 - INFO - validation batch 51, loss: 9.087, 1632/6976 datapoints
2025-03-06 23:08:19,753 - INFO - validation batch 101, loss: 1.373, 3232/6976 datapoints
2025-03-06 23:08:19,800 - INFO - validation batch 151, loss: 1.929, 4832/6976 datapoints
2025-03-06 23:08:19,848 - INFO - validation batch 201, loss: 3.976, 6432/6976 datapoints
2025-03-06 23:08:19,865 - INFO - Epoch 788/800 done.
2025-03-06 23:08:19,865 - INFO - Final validation performance:
Loss: 3.382, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:08:19,865 - INFO - Beginning epoch 789/800
2025-03-06 23:08:19,870 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:08:20,091 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:08:20,314 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:08:20,517 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:08:20,714 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:08:20,917 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-06 23:08:21,126 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-06 23:08:21,327 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:08:21,529 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:08:21,732 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-06 23:08:21,935 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:08:22,150 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:08:22,351 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-06 23:08:22,561 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:08:22,782 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:08:22,988 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:23,196 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:08:23,400 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:08:23,500 - INFO - validation batch 1, loss: 0.294, 32/6976 datapoints
2025-03-06 23:08:23,552 - INFO - validation batch 51, loss: 8.715, 1632/6976 datapoints
2025-03-06 23:08:23,604 - INFO - validation batch 101, loss: 1.319, 3232/6976 datapoints
2025-03-06 23:08:23,658 - INFO - validation batch 151, loss: 2.193, 4832/6976 datapoints
2025-03-06 23:08:23,710 - INFO - validation batch 201, loss: 4.148, 6432/6976 datapoints
2025-03-06 23:08:23,727 - INFO - Epoch 789/800 done.
2025-03-06 23:08:23,727 - INFO - Final validation performance:
Loss: 3.334, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 23:08:23,728 - INFO - Beginning epoch 790/800
2025-03-06 23:08:23,733 - INFO - training batch 1, loss: 0.012, 32/28000 datapoints
2025-03-06 23:08:23,970 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:08:24,222 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:08:24,467 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:08:24,671 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:08:24,874 - INFO - training batch 251, loss: 0.014, 8032/28000 datapoints
2025-03-06 23:08:25,090 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-06 23:08:25,302 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 23:08:25,527 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:08:25,732 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:08:25,935 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:08:26,147 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:08:26,357 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:08:26,601 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:08:26,826 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-06 23:08:27,063 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:27,275 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-06 23:08:27,482 - INFO - training batch 851, loss: 0.019, 27232/28000 datapoints
2025-03-06 23:08:27,588 - INFO - validation batch 1, loss: 0.232, 32/6976 datapoints
2025-03-06 23:08:27,642 - INFO - validation batch 51, loss: 8.984, 1632/6976 datapoints
2025-03-06 23:08:27,691 - INFO - validation batch 101, loss: 1.530, 3232/6976 datapoints
2025-03-06 23:08:27,739 - INFO - validation batch 151, loss: 2.233, 4832/6976 datapoints
2025-03-06 23:08:27,789 - INFO - validation batch 201, loss: 4.104, 6432/6976 datapoints
2025-03-06 23:08:27,806 - INFO - Epoch 790/800 done.
2025-03-06 23:08:27,806 - INFO - Final validation performance:
Loss: 3.417, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:08:27,806 - INFO - Beginning epoch 791/800
2025-03-06 23:08:27,811 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-06 23:08:28,024 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:08:28,223 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:08:28,425 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:08:28,622 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:08:28,822 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-06 23:08:29,028 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-06 23:08:29,222 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-06 23:08:29,417 - INFO - training batch 401, loss: 0.030, 12832/28000 datapoints
2025-03-06 23:08:29,610 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:08:29,807 - INFO - training batch 501, loss: 0.032, 16032/28000 datapoints
2025-03-06 23:08:30,012 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 23:08:30,211 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:08:30,413 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:08:30,616 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:08:30,825 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:31,027 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:08:31,235 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-06 23:08:31,338 - INFO - validation batch 1, loss: 0.639, 32/6976 datapoints
2025-03-06 23:08:31,385 - INFO - validation batch 51, loss: 9.378, 1632/6976 datapoints
2025-03-06 23:08:31,433 - INFO - validation batch 101, loss: 1.125, 3232/6976 datapoints
2025-03-06 23:08:31,482 - INFO - validation batch 151, loss: 2.126, 4832/6976 datapoints
2025-03-06 23:08:31,535 - INFO - validation batch 201, loss: 3.784, 6432/6976 datapoints
2025-03-06 23:08:31,551 - INFO - Epoch 791/800 done.
2025-03-06 23:08:31,551 - INFO - Final validation performance:
Loss: 3.410, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:08:31,552 - INFO - Beginning epoch 792/800
2025-03-06 23:08:31,556 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:08:31,749 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:08:31,945 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:08:32,160 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-06 23:08:32,357 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-06 23:08:32,548 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-06 23:08:32,780 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:08:32,979 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-06 23:08:33,178 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-06 23:08:33,372 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:08:33,567 - INFO - training batch 501, loss: 0.106, 16032/28000 datapoints
2025-03-06 23:08:33,772 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-06 23:08:33,975 - INFO - training batch 601, loss: 0.056, 19232/28000 datapoints
2025-03-06 23:08:34,182 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:08:34,378 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-06 23:08:34,580 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:34,777 - INFO - training batch 801, loss: 0.020, 25632/28000 datapoints
2025-03-06 23:08:34,980 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-06 23:08:35,082 - INFO - validation batch 1, loss: 0.344, 32/6976 datapoints
2025-03-06 23:08:35,132 - INFO - validation batch 51, loss: 9.291, 1632/6976 datapoints
2025-03-06 23:08:35,182 - INFO - validation batch 101, loss: 1.434, 3232/6976 datapoints
2025-03-06 23:08:35,230 - INFO - validation batch 151, loss: 2.077, 4832/6976 datapoints
2025-03-06 23:08:35,286 - INFO - validation batch 201, loss: 4.786, 6432/6976 datapoints
2025-03-06 23:08:35,304 - INFO - Epoch 792/800 done.
2025-03-06 23:08:35,304 - INFO - Final validation performance:
Loss: 3.587, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 23:08:35,304 - INFO - Beginning epoch 793/800
2025-03-06 23:08:35,309 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:08:35,498 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:08:35,692 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-06 23:08:35,895 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-06 23:08:36,096 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-06 23:08:36,291 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:08:36,490 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:08:36,698 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-06 23:08:36,900 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:08:37,096 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-06 23:08:37,304 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:08:37,508 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:08:37,705 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:08:37,915 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:08:38,137 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:08:38,342 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:38,540 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:08:38,740 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-06 23:08:38,840 - INFO - validation batch 1, loss: 0.479, 32/6976 datapoints
2025-03-06 23:08:38,890 - INFO - validation batch 51, loss: 9.575, 1632/6976 datapoints
2025-03-06 23:08:38,937 - INFO - validation batch 101, loss: 1.363, 3232/6976 datapoints
2025-03-06 23:08:38,986 - INFO - validation batch 151, loss: 1.838, 4832/6976 datapoints
2025-03-06 23:08:39,037 - INFO - validation batch 201, loss: 3.846, 6432/6976 datapoints
2025-03-06 23:08:39,054 - INFO - Epoch 793/800 done.
2025-03-06 23:08:39,055 - INFO - Final validation performance:
Loss: 3.420, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:08:39,055 - INFO - Beginning epoch 794/800
2025-03-06 23:08:39,060 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:08:39,257 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-06 23:08:39,452 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:08:39,655 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:08:39,855 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-06 23:08:40,067 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:08:40,314 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-06 23:08:40,540 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:08:40,737 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:08:40,935 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:08:41,143 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:08:41,348 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:08:41,547 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:08:41,758 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:08:41,959 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:08:42,171 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:42,376 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:08:42,579 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:08:42,679 - INFO - validation batch 1, loss: 0.487, 32/6976 datapoints
2025-03-06 23:08:42,731 - INFO - validation batch 51, loss: 9.618, 1632/6976 datapoints
2025-03-06 23:08:42,803 - INFO - validation batch 101, loss: 1.412, 3232/6976 datapoints
2025-03-06 23:08:42,871 - INFO - validation batch 151, loss: 1.938, 4832/6976 datapoints
2025-03-06 23:08:42,924 - INFO - validation batch 201, loss: 3.970, 6432/6976 datapoints
2025-03-06 23:08:42,943 - INFO - Epoch 794/800 done.
2025-03-06 23:08:42,944 - INFO - Final validation performance:
Loss: 3.485, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:08:42,944 - INFO - Beginning epoch 795/800
2025-03-06 23:08:42,949 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:08:43,157 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:08:43,361 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:08:43,576 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:08:43,776 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:08:43,978 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:08:44,183 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:08:44,393 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:08:44,615 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:08:44,811 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:08:45,023 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:08:45,225 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-06 23:08:45,430 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:08:45,637 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:08:45,833 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:08:46,040 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:46,239 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:08:46,446 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:08:46,544 - INFO - validation batch 1, loss: 0.472, 32/6976 datapoints
2025-03-06 23:08:46,593 - INFO - validation batch 51, loss: 9.537, 1632/6976 datapoints
2025-03-06 23:08:46,641 - INFO - validation batch 101, loss: 1.412, 3232/6976 datapoints
2025-03-06 23:08:46,690 - INFO - validation batch 151, loss: 1.931, 4832/6976 datapoints
2025-03-06 23:08:46,738 - INFO - validation batch 201, loss: 3.988, 6432/6976 datapoints
2025-03-06 23:08:46,757 - INFO - Epoch 795/800 done.
2025-03-06 23:08:46,758 - INFO - Final validation performance:
Loss: 3.468, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:08:46,758 - INFO - Beginning epoch 796/800
2025-03-06 23:08:46,763 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:08:46,957 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:08:47,154 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:08:47,364 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:08:47,557 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:08:47,751 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:08:47,953 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:08:48,149 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:08:48,348 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:08:48,543 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:08:48,740 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:08:48,946 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:08:49,155 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:08:49,366 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:08:49,561 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-06 23:08:49,772 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:49,972 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:08:50,179 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:08:50,279 - INFO - validation batch 1, loss: 0.459, 32/6976 datapoints
2025-03-06 23:08:50,328 - INFO - validation batch 51, loss: 9.543, 1632/6976 datapoints
2025-03-06 23:08:50,378 - INFO - validation batch 101, loss: 1.404, 3232/6976 datapoints
2025-03-06 23:08:50,426 - INFO - validation batch 151, loss: 2.003, 4832/6976 datapoints
2025-03-06 23:08:50,474 - INFO - validation batch 201, loss: 3.990, 6432/6976 datapoints
2025-03-06 23:08:50,491 - INFO - Epoch 796/800 done.
2025-03-06 23:08:50,491 - INFO - Final validation performance:
Loss: 3.480, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:08:50,491 - INFO - Beginning epoch 797/800
2025-03-06 23:08:50,496 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:08:50,685 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-06 23:08:50,884 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:08:51,096 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:08:51,302 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:08:51,499 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:08:51,698 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:08:51,895 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:08:52,095 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:08:52,292 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:08:52,493 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:08:52,693 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:08:52,909 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:08:53,128 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:08:53,324 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:08:53,531 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:53,730 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:08:53,933 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:08:54,033 - INFO - validation batch 1, loss: 0.451, 32/6976 datapoints
2025-03-06 23:08:54,082 - INFO - validation batch 51, loss: 9.540, 1632/6976 datapoints
2025-03-06 23:08:54,129 - INFO - validation batch 101, loss: 1.403, 3232/6976 datapoints
2025-03-06 23:08:54,177 - INFO - validation batch 151, loss: 2.046, 4832/6976 datapoints
2025-03-06 23:08:54,227 - INFO - validation batch 201, loss: 3.992, 6432/6976 datapoints
2025-03-06 23:08:54,244 - INFO - Epoch 797/800 done.
2025-03-06 23:08:54,244 - INFO - Final validation performance:
Loss: 3.487, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:08:54,244 - INFO - Beginning epoch 798/800
2025-03-06 23:08:54,249 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:08:54,443 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:08:54,634 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:08:54,834 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:08:55,034 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:08:55,245 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:08:55,449 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:08:55,651 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:08:55,853 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-06 23:08:56,057 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:08:56,254 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:08:56,454 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:08:56,654 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:08:56,858 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:08:57,056 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:08:57,260 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:08:57,469 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:08:57,670 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:08:57,767 - INFO - validation batch 1, loss: 0.431, 32/6976 datapoints
2025-03-06 23:08:57,815 - INFO - validation batch 51, loss: 9.512, 1632/6976 datapoints
2025-03-06 23:08:57,863 - INFO - validation batch 101, loss: 1.404, 3232/6976 datapoints
2025-03-06 23:08:57,912 - INFO - validation batch 151, loss: 2.105, 4832/6976 datapoints
2025-03-06 23:08:57,960 - INFO - validation batch 201, loss: 3.998, 6432/6976 datapoints
2025-03-06 23:08:57,976 - INFO - Epoch 798/800 done.
2025-03-06 23:08:57,977 - INFO - Final validation performance:
Loss: 3.490, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 23:08:57,977 - INFO - Beginning epoch 799/800
2025-03-06 23:08:57,982 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-06 23:08:58,175 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:08:58,371 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-06 23:08:58,576 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:08:58,770 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:08:58,973 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:08:59,179 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:08:59,378 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:08:59,575 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:08:59,771 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:08:59,967 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:09:00,170 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:09:00,371 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:09:00,577 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:09:00,769 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:09:00,975 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:09:01,183 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:09:01,390 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:09:01,503 - INFO - validation batch 1, loss: 0.408, 32/6976 datapoints
2025-03-06 23:09:01,566 - INFO - validation batch 51, loss: 9.485, 1632/6976 datapoints
2025-03-06 23:09:01,618 - INFO - validation batch 101, loss: 1.407, 3232/6976 datapoints
2025-03-06 23:09:01,666 - INFO - validation batch 151, loss: 2.177, 4832/6976 datapoints
2025-03-06 23:09:01,717 - INFO - validation batch 201, loss: 3.997, 6432/6976 datapoints
2025-03-06 23:09:01,734 - INFO - Epoch 799/800 done.
2025-03-06 23:09:01,735 - INFO - Final validation performance:
Loss: 3.495, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:09:01,735 - INFO - Beginning epoch 800/800
2025-03-06 23:09:01,740 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-06 23:09:01,942 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-06 23:09:02,144 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-06 23:09:02,352 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-06 23:09:02,550 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-06 23:09:02,750 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-06 23:09:02,961 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-06 23:09:03,186 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-06 23:09:03,387 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-06 23:09:03,590 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-06 23:09:03,791 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-06 23:09:03,999 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-06 23:09:04,200 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-06 23:09:04,412 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-06 23:09:04,610 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-06 23:09:04,816 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-06 23:09:05,022 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-06 23:09:05,229 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-06 23:09:05,337 - INFO - validation batch 1, loss: 0.395, 32/6976 datapoints
2025-03-06 23:09:05,391 - INFO - validation batch 51, loss: 9.482, 1632/6976 datapoints
2025-03-06 23:09:05,443 - INFO - validation batch 101, loss: 1.412, 3232/6976 datapoints
2025-03-06 23:09:05,497 - INFO - validation batch 151, loss: 2.250, 4832/6976 datapoints
2025-03-06 23:09:05,551 - INFO - validation batch 201, loss: 3.996, 6432/6976 datapoints
2025-03-06 23:09:05,567 - INFO - Epoch 800/800 done.
2025-03-06 23:09:05,567 - INFO - Final validation performance:
Loss: 3.507, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 23:09:05,568 - INFO - Finished training in 2599.87 seconds.
2025-03-06 23:09:05,568 - INFO - Model trained in {train_time:.2f} s
2025-03-06 23:09:05,569 - INFO - Evaluating model...
2025-03-06 23:09:05,570 - INFO - validation batch 1, loss: 0.395, 32/6976 datapoints
2025-03-06 23:09:05,621 - INFO - validation batch 51, loss: 9.482, 1632/6976 datapoints
2025-03-06 23:09:05,672 - INFO - validation batch 101, loss: 1.412, 3232/6976 datapoints
2025-03-06 23:09:05,727 - INFO - validation batch 151, loss: 2.250, 4832/6976 datapoints
2025-03-06 23:09:05,780 - INFO - validation batch 201, loss: 3.996, 6432/6976 datapoints
2025-03-06 23:09:05,801 - INFO - Done evaluating.
2025-03-06 23:09:05,801 - INFO - Average final validation loss: 3.507
2025-03-06 23:09:05,801 - INFO - Saving...
2025-03-06 23:09:11,533 - INFO - Done saving.
2025-03-06 23:09:11,534 - INFO - Successfully completed hyperparameter combination 4 of 4