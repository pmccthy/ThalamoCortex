2025-03-06 20:38:01,948 - INFO - Running hyperparameter combination 1 of 4
2025-03-06 20:38:01,948 - INFO - 0_CTCNet_TC_multi_pre_activation_reciprocal
2025-03-06 20:38:01,948 - INFO - Loading data...
2025-03-06 20:38:03,051 - INFO - Done loading.
2025-03-06 20:38:03,051 - INFO - Building model and optimiser...
2025-03-06 20:38:03,069 - INFO - =================================================================
Layer (type:depth-idx)                   Param #
=================================================================
├─Sequential: 1-1                        --
|    └─Linear: 2-1                       2,064
|    └─ReLU: 2-2                         --
├─Linear: 1-2                            1,088
├─Linear: 1-3                            1,088
├─CortexWithThalamicMultiPreAct: 1-4     --
|    └─Linear: 2-3                       100,416
|    └─ReLU: 2-4                         --
├─CortexWithThalamicMultiPreAct: 1-5     --
|    └─Linear: 2-5                       4,160
|    └─ReLU: 2-6                         --
├─Sequential: 1-6                        --
|    └─Linear: 2-7                       650
=================================================================
Total params: 109,466
Trainable params: 109,466
Non-trainable params: 0
=================================================================
2025-03-06 20:38:03,071 - INFO - Done.
2025-03-06 20:38:03,071 - INFO - Training...
2025-03-06 20:38:03,071 - INFO - Beginning epoch 1/800
2025-03-06 20:38:03,094 - INFO - training batch 1, loss: 2.327, 32/28000 datapoints
2025-03-06 20:38:03,252 - INFO - training batch 51, loss: 2.315, 1632/28000 datapoints
2025-03-06 20:38:03,386 - INFO - training batch 101, loss: 2.300, 3232/28000 datapoints
2025-03-06 20:38:03,538 - INFO - training batch 151, loss: 2.293, 4832/28000 datapoints
2025-03-06 20:38:03,663 - INFO - training batch 201, loss: 2.282, 6432/28000 datapoints
2025-03-06 20:38:03,790 - INFO - training batch 251, loss: 2.289, 8032/28000 datapoints
2025-03-06 20:38:03,917 - INFO - training batch 301, loss: 2.299, 9632/28000 datapoints
2025-03-06 20:38:04,082 - INFO - training batch 351, loss: 2.303, 11232/28000 datapoints
2025-03-06 20:38:04,212 - INFO - training batch 401, loss: 2.298, 12832/28000 datapoints
2025-03-06 20:38:04,334 - INFO - training batch 451, loss: 2.315, 14432/28000 datapoints
2025-03-06 20:38:04,465 - INFO - training batch 501, loss: 2.293, 16032/28000 datapoints
2025-03-06 20:38:04,600 - INFO - training batch 551, loss: 2.299, 17632/28000 datapoints
2025-03-06 20:38:04,726 - INFO - training batch 601, loss: 2.296, 19232/28000 datapoints
2025-03-06 20:38:04,846 - INFO - training batch 651, loss: 2.323, 20832/28000 datapoints
2025-03-06 20:38:04,976 - INFO - training batch 701, loss: 2.288, 22432/28000 datapoints
2025-03-06 20:38:05,107 - INFO - training batch 751, loss: 2.311, 24032/28000 datapoints
2025-03-06 20:38:05,231 - INFO - training batch 801, loss: 2.287, 25632/28000 datapoints
2025-03-06 20:38:05,352 - INFO - training batch 851, loss: 2.291, 27232/28000 datapoints
2025-03-06 20:38:05,418 - INFO - validation batch 1, loss: 2.311, 32/6976 datapoints
2025-03-06 20:38:05,471 - INFO - validation batch 51, loss: 2.306, 1632/6976 datapoints
2025-03-06 20:38:05,522 - INFO - validation batch 101, loss: 2.314, 3232/6976 datapoints
2025-03-06 20:38:05,572 - INFO - validation batch 151, loss: 2.326, 4832/6976 datapoints
2025-03-06 20:38:05,622 - INFO - validation batch 201, loss: 2.313, 6432/6976 datapoints
2025-03-06 20:38:05,642 - INFO - Epoch 1/800 done.
2025-03-06 20:38:05,643 - INFO - Final validation performance:
Loss: 2.314, top-1 acc: 0.101top-5 acc: 0.101
2025-03-06 20:38:05,644 - INFO - Beginning epoch 2/800
2025-03-06 20:38:05,647 - INFO - training batch 1, loss: 2.327, 32/28000 datapoints
2025-03-06 20:38:05,778 - INFO - training batch 51, loss: 2.314, 1632/28000 datapoints
2025-03-06 20:38:05,901 - INFO - training batch 101, loss: 2.300, 3232/28000 datapoints
2025-03-06 20:38:06,036 - INFO - training batch 151, loss: 2.293, 4832/28000 datapoints
2025-03-06 20:38:06,169 - INFO - training batch 201, loss: 2.281, 6432/28000 datapoints
2025-03-06 20:38:06,294 - INFO - training batch 251, loss: 2.288, 8032/28000 datapoints
2025-03-06 20:38:06,419 - INFO - training batch 301, loss: 2.299, 9632/28000 datapoints
2025-03-06 20:38:06,545 - INFO - training batch 351, loss: 2.303, 11232/28000 datapoints
2025-03-06 20:38:06,672 - INFO - training batch 401, loss: 2.297, 12832/28000 datapoints
2025-03-06 20:38:06,794 - INFO - training batch 451, loss: 2.314, 14432/28000 datapoints
2025-03-06 20:38:06,924 - INFO - training batch 501, loss: 2.292, 16032/28000 datapoints
2025-03-06 20:38:07,050 - INFO - training batch 551, loss: 2.299, 17632/28000 datapoints
2025-03-06 20:38:07,176 - INFO - training batch 601, loss: 2.296, 19232/28000 datapoints
2025-03-06 20:38:07,302 - INFO - training batch 651, loss: 2.322, 20832/28000 datapoints
2025-03-06 20:38:07,425 - INFO - training batch 701, loss: 2.287, 22432/28000 datapoints
2025-03-06 20:38:07,559 - INFO - training batch 751, loss: 2.310, 24032/28000 datapoints
2025-03-06 20:38:07,695 - INFO - training batch 801, loss: 2.287, 25632/28000 datapoints
2025-03-06 20:38:07,818 - INFO - training batch 851, loss: 2.291, 27232/28000 datapoints
2025-03-06 20:38:07,881 - INFO - validation batch 1, loss: 2.310, 32/6976 datapoints
2025-03-06 20:38:07,927 - INFO - validation batch 51, loss: 2.306, 1632/6976 datapoints
2025-03-06 20:38:07,975 - INFO - validation batch 101, loss: 2.313, 3232/6976 datapoints
2025-03-06 20:38:08,025 - INFO - validation batch 151, loss: 2.325, 4832/6976 datapoints
2025-03-06 20:38:08,071 - INFO - validation batch 201, loss: 2.311, 6432/6976 datapoints
2025-03-06 20:38:08,087 - INFO - Epoch 2/800 done.
2025-03-06 20:38:08,087 - INFO - Final validation performance:
Loss: 2.313, top-1 acc: 0.101top-5 acc: 0.101
2025-03-06 20:38:08,088 - INFO - Beginning epoch 3/800
2025-03-06 20:38:08,091 - INFO - training batch 1, loss: 2.326, 32/28000 datapoints
2025-03-06 20:38:08,216 - INFO - training batch 51, loss: 2.313, 1632/28000 datapoints
2025-03-06 20:38:08,340 - INFO - training batch 101, loss: 2.298, 3232/28000 datapoints
2025-03-06 20:38:08,464 - INFO - training batch 151, loss: 2.292, 4832/28000 datapoints
2025-03-06 20:38:08,591 - INFO - training batch 201, loss: 2.280, 6432/28000 datapoints
2025-03-06 20:38:08,714 - INFO - training batch 251, loss: 2.287, 8032/28000 datapoints
2025-03-06 20:38:08,834 - INFO - training batch 301, loss: 2.298, 9632/28000 datapoints
2025-03-06 20:38:08,956 - INFO - training batch 351, loss: 2.302, 11232/28000 datapoints
2025-03-06 20:38:09,084 - INFO - training batch 401, loss: 2.296, 12832/28000 datapoints
2025-03-06 20:38:09,217 - INFO - training batch 451, loss: 2.312, 14432/28000 datapoints
2025-03-06 20:38:09,337 - INFO - training batch 501, loss: 2.291, 16032/28000 datapoints
2025-03-06 20:38:09,457 - INFO - training batch 551, loss: 2.297, 17632/28000 datapoints
2025-03-06 20:38:09,580 - INFO - training batch 601, loss: 2.295, 19232/28000 datapoints
2025-03-06 20:38:09,715 - INFO - training batch 651, loss: 2.320, 20832/28000 datapoints
2025-03-06 20:38:09,839 - INFO - training batch 701, loss: 2.286, 22432/28000 datapoints
2025-03-06 20:38:09,961 - INFO - training batch 751, loss: 2.309, 24032/28000 datapoints
2025-03-06 20:38:10,090 - INFO - training batch 801, loss: 2.286, 25632/28000 datapoints
2025-03-06 20:38:10,210 - INFO - training batch 851, loss: 2.290, 27232/28000 datapoints
2025-03-06 20:38:10,270 - INFO - validation batch 1, loss: 2.309, 32/6976 datapoints
2025-03-06 20:38:10,315 - INFO - validation batch 51, loss: 2.304, 1632/6976 datapoints
2025-03-06 20:38:10,359 - INFO - validation batch 101, loss: 2.311, 3232/6976 datapoints
2025-03-06 20:38:10,404 - INFO - validation batch 151, loss: 2.324, 4832/6976 datapoints
2025-03-06 20:38:10,449 - INFO - validation batch 201, loss: 2.308, 6432/6976 datapoints
2025-03-06 20:38:10,465 - INFO - Epoch 3/800 done.
2025-03-06 20:38:10,465 - INFO - Final validation performance:
Loss: 2.311, top-1 acc: 0.101top-5 acc: 0.101
2025-03-06 20:38:10,466 - INFO - Beginning epoch 4/800
2025-03-06 20:38:10,469 - INFO - training batch 1, loss: 2.325, 32/28000 datapoints
2025-03-06 20:38:10,597 - INFO - training batch 51, loss: 2.312, 1632/28000 datapoints
2025-03-06 20:38:10,723 - INFO - training batch 101, loss: 2.296, 3232/28000 datapoints
2025-03-06 20:38:10,846 - INFO - training batch 151, loss: 2.292, 4832/28000 datapoints
2025-03-06 20:38:10,971 - INFO - training batch 201, loss: 2.279, 6432/28000 datapoints
2025-03-06 20:38:11,091 - INFO - training batch 251, loss: 2.286, 8032/28000 datapoints
2025-03-06 20:38:11,214 - INFO - training batch 301, loss: 2.296, 9632/28000 datapoints
2025-03-06 20:38:11,334 - INFO - training batch 351, loss: 2.301, 11232/28000 datapoints
2025-03-06 20:38:11,456 - INFO - training batch 401, loss: 2.295, 12832/28000 datapoints
2025-03-06 20:38:11,580 - INFO - training batch 451, loss: 2.310, 14432/28000 datapoints
2025-03-06 20:38:11,704 - INFO - training batch 501, loss: 2.288, 16032/28000 datapoints
2025-03-06 20:38:11,824 - INFO - training batch 551, loss: 2.294, 17632/28000 datapoints
2025-03-06 20:38:11,943 - INFO - training batch 601, loss: 2.294, 19232/28000 datapoints
2025-03-06 20:38:12,071 - INFO - training batch 651, loss: 2.316, 20832/28000 datapoints
2025-03-06 20:38:12,189 - INFO - training batch 701, loss: 2.282, 22432/28000 datapoints
2025-03-06 20:38:12,310 - INFO - training batch 751, loss: 2.306, 24032/28000 datapoints
2025-03-06 20:38:12,429 - INFO - training batch 801, loss: 2.284, 25632/28000 datapoints
2025-03-06 20:38:12,553 - INFO - training batch 851, loss: 2.288, 27232/28000 datapoints
2025-03-06 20:38:12,613 - INFO - validation batch 1, loss: 2.306, 32/6976 datapoints
2025-03-06 20:38:12,787 - INFO - validation batch 51, loss: 2.302, 1632/6976 datapoints
2025-03-06 20:38:12,832 - INFO - validation batch 101, loss: 2.308, 3232/6976 datapoints
2025-03-06 20:38:12,876 - INFO - validation batch 151, loss: 2.322, 4832/6976 datapoints
2025-03-06 20:38:12,920 - INFO - validation batch 201, loss: 2.302, 6432/6976 datapoints
2025-03-06 20:38:12,935 - INFO - Epoch 4/800 done.
2025-03-06 20:38:12,935 - INFO - Final validation performance:
Loss: 2.308, top-1 acc: 0.102top-5 acc: 0.102
2025-03-06 20:38:12,936 - INFO - Beginning epoch 5/800
2025-03-06 20:38:12,939 - INFO - training batch 1, loss: 2.323, 32/28000 datapoints
2025-03-06 20:38:13,062 - INFO - training batch 51, loss: 2.309, 1632/28000 datapoints
2025-03-06 20:38:13,187 - INFO - training batch 101, loss: 2.292, 3232/28000 datapoints
2025-03-06 20:38:13,309 - INFO - training batch 151, loss: 2.290, 4832/28000 datapoints
2025-03-06 20:38:13,427 - INFO - training batch 201, loss: 2.275, 6432/28000 datapoints
2025-03-06 20:38:13,552 - INFO - training batch 251, loss: 2.284, 8032/28000 datapoints
2025-03-06 20:38:13,679 - INFO - training batch 301, loss: 2.291, 9632/28000 datapoints
2025-03-06 20:38:13,801 - INFO - training batch 351, loss: 2.298, 11232/28000 datapoints
2025-03-06 20:38:13,922 - INFO - training batch 401, loss: 2.291, 12832/28000 datapoints
2025-03-06 20:38:14,064 - INFO - training batch 451, loss: 2.304, 14432/28000 datapoints
2025-03-06 20:38:14,198 - INFO - training batch 501, loss: 2.282, 16032/28000 datapoints
2025-03-06 20:38:14,319 - INFO - training batch 551, loss: 2.288, 17632/28000 datapoints
2025-03-06 20:38:14,442 - INFO - training batch 601, loss: 2.290, 19232/28000 datapoints
2025-03-06 20:38:14,563 - INFO - training batch 651, loss: 2.309, 20832/28000 datapoints
2025-03-06 20:38:14,686 - INFO - training batch 701, loss: 2.276, 22432/28000 datapoints
2025-03-06 20:38:14,808 - INFO - training batch 751, loss: 2.300, 24032/28000 datapoints
2025-03-06 20:38:14,931 - INFO - training batch 801, loss: 2.281, 25632/28000 datapoints
2025-03-06 20:38:15,059 - INFO - training batch 851, loss: 2.283, 27232/28000 datapoints
2025-03-06 20:38:15,123 - INFO - validation batch 1, loss: 2.300, 32/6976 datapoints
2025-03-06 20:38:15,170 - INFO - validation batch 51, loss: 2.296, 1632/6976 datapoints
2025-03-06 20:38:15,214 - INFO - validation batch 101, loss: 2.300, 3232/6976 datapoints
2025-03-06 20:38:15,259 - INFO - validation batch 151, loss: 2.319, 4832/6976 datapoints
2025-03-06 20:38:15,305 - INFO - validation batch 201, loss: 2.288, 6432/6976 datapoints
2025-03-06 20:38:15,320 - INFO - Epoch 5/800 done.
2025-03-06 20:38:15,320 - INFO - Final validation performance:
Loss: 2.301, top-1 acc: 0.145top-5 acc: 0.145
2025-03-06 20:38:15,321 - INFO - Beginning epoch 6/800
2025-03-06 20:38:15,324 - INFO - training batch 1, loss: 2.319, 32/28000 datapoints
2025-03-06 20:38:15,451 - INFO - training batch 51, loss: 2.303, 1632/28000 datapoints
2025-03-06 20:38:15,574 - INFO - training batch 101, loss: 2.283, 3232/28000 datapoints
2025-03-06 20:38:15,701 - INFO - training batch 151, loss: 2.287, 4832/28000 datapoints
2025-03-06 20:38:15,827 - INFO - training batch 201, loss: 2.266, 6432/28000 datapoints
2025-03-06 20:38:15,949 - INFO - training batch 251, loss: 2.279, 8032/28000 datapoints
2025-03-06 20:38:16,092 - INFO - training batch 301, loss: 2.280, 9632/28000 datapoints
2025-03-06 20:38:16,223 - INFO - training batch 351, loss: 2.292, 11232/28000 datapoints
2025-03-06 20:38:16,345 - INFO - training batch 401, loss: 2.282, 12832/28000 datapoints
2025-03-06 20:38:16,465 - INFO - training batch 451, loss: 2.290, 14432/28000 datapoints
2025-03-06 20:38:16,595 - INFO - training batch 501, loss: 2.267, 16032/28000 datapoints
2025-03-06 20:38:16,723 - INFO - training batch 551, loss: 2.271, 17632/28000 datapoints
2025-03-06 20:38:16,844 - INFO - training batch 601, loss: 2.279, 19232/28000 datapoints
2025-03-06 20:38:16,970 - INFO - training batch 651, loss: 2.290, 20832/28000 datapoints
2025-03-06 20:38:17,100 - INFO - training batch 701, loss: 2.255, 22432/28000 datapoints
2025-03-06 20:38:17,258 - INFO - training batch 751, loss: 2.280, 24032/28000 datapoints
2025-03-06 20:38:17,402 - INFO - training batch 801, loss: 2.270, 25632/28000 datapoints
2025-03-06 20:38:17,526 - INFO - training batch 851, loss: 2.266, 27232/28000 datapoints
2025-03-06 20:38:17,587 - INFO - validation batch 1, loss: 2.281, 32/6976 datapoints
2025-03-06 20:38:17,637 - INFO - validation batch 51, loss: 2.280, 1632/6976 datapoints
2025-03-06 20:38:17,684 - INFO - validation batch 101, loss: 2.275, 3232/6976 datapoints
2025-03-06 20:38:17,746 - INFO - validation batch 151, loss: 2.312, 4832/6976 datapoints
2025-03-06 20:38:17,804 - INFO - validation batch 201, loss: 2.241, 6432/6976 datapoints
2025-03-06 20:38:17,821 - INFO - Epoch 6/800 done.
2025-03-06 20:38:17,821 - INFO - Final validation performance:
Loss: 2.278, top-1 acc: 0.217top-5 acc: 0.217
2025-03-06 20:38:17,822 - INFO - Beginning epoch 7/800
2025-03-06 20:38:17,825 - INFO - training batch 1, loss: 2.307, 32/28000 datapoints
2025-03-06 20:38:17,949 - INFO - training batch 51, loss: 2.286, 1632/28000 datapoints
2025-03-06 20:38:18,079 - INFO - training batch 101, loss: 2.253, 3232/28000 datapoints
2025-03-06 20:38:18,208 - INFO - training batch 151, loss: 2.279, 4832/28000 datapoints
2025-03-06 20:38:18,332 - INFO - training batch 201, loss: 2.231, 6432/28000 datapoints
2025-03-06 20:38:18,455 - INFO - training batch 251, loss: 2.264, 8032/28000 datapoints
2025-03-06 20:38:18,584 - INFO - training batch 301, loss: 2.243, 9632/28000 datapoints
2025-03-06 20:38:18,724 - INFO - training batch 351, loss: 2.268, 11232/28000 datapoints
2025-03-06 20:38:18,851 - INFO - training batch 401, loss: 2.249, 12832/28000 datapoints
2025-03-06 20:38:18,975 - INFO - training batch 451, loss: 2.251, 14432/28000 datapoints
2025-03-06 20:38:19,106 - INFO - training batch 501, loss: 2.214, 16032/28000 datapoints
2025-03-06 20:38:19,234 - INFO - training batch 551, loss: 2.215, 17632/28000 datapoints
2025-03-06 20:38:19,357 - INFO - training batch 601, loss: 2.242, 19232/28000 datapoints
2025-03-06 20:38:19,482 - INFO - training batch 651, loss: 2.236, 20832/28000 datapoints
2025-03-06 20:38:19,612 - INFO - training batch 701, loss: 2.186, 22432/28000 datapoints
2025-03-06 20:38:19,737 - INFO - training batch 751, loss: 2.227, 24032/28000 datapoints
2025-03-06 20:38:19,858 - INFO - training batch 801, loss: 2.234, 25632/28000 datapoints
2025-03-06 20:38:19,990 - INFO - training batch 851, loss: 2.208, 27232/28000 datapoints
2025-03-06 20:38:20,062 - INFO - validation batch 1, loss: 2.225, 32/6976 datapoints
2025-03-06 20:38:20,109 - INFO - validation batch 51, loss: 2.234, 1632/6976 datapoints
2025-03-06 20:38:20,157 - INFO - validation batch 101, loss: 2.207, 3232/6976 datapoints
2025-03-06 20:38:20,205 - INFO - validation batch 151, loss: 2.306, 4832/6976 datapoints
2025-03-06 20:38:20,256 - INFO - validation batch 201, loss: 2.119, 6432/6976 datapoints
2025-03-06 20:38:20,273 - INFO - Epoch 7/800 done.
2025-03-06 20:38:20,273 - INFO - Final validation performance:
Loss: 2.218, top-1 acc: 0.247top-5 acc: 0.247
2025-03-06 20:38:20,274 - INFO - Beginning epoch 8/800
2025-03-06 20:38:20,278 - INFO - training batch 1, loss: 2.279, 32/28000 datapoints
2025-03-06 20:38:20,404 - INFO - training batch 51, loss: 2.251, 1632/28000 datapoints
2025-03-06 20:38:20,520 - INFO - training batch 101, loss: 2.165, 3232/28000 datapoints
2025-03-06 20:38:20,643 - INFO - training batch 151, loss: 2.250, 4832/28000 datapoints
2025-03-06 20:38:20,758 - INFO - training batch 201, loss: 2.137, 6432/28000 datapoints
2025-03-06 20:38:20,875 - INFO - training batch 251, loss: 2.227, 8032/28000 datapoints
2025-03-06 20:38:20,991 - INFO - training batch 301, loss: 2.166, 9632/28000 datapoints
2025-03-06 20:38:21,128 - INFO - training batch 351, loss: 2.207, 11232/28000 datapoints
2025-03-06 20:38:21,267 - INFO - training batch 401, loss: 2.172, 12832/28000 datapoints
2025-03-06 20:38:21,385 - INFO - training batch 451, loss: 2.178, 14432/28000 datapoints
2025-03-06 20:38:21,501 - INFO - training batch 501, loss: 2.100, 16032/28000 datapoints
2025-03-06 20:38:21,617 - INFO - training batch 551, loss: 2.106, 17632/28000 datapoints
2025-03-06 20:38:21,736 - INFO - training batch 601, loss: 2.161, 19232/28000 datapoints
2025-03-06 20:38:21,854 - INFO - training batch 651, loss: 2.148, 20832/28000 datapoints
2025-03-06 20:38:21,971 - INFO - training batch 701, loss: 2.047, 22432/28000 datapoints
2025-03-06 20:38:22,092 - INFO - training batch 751, loss: 2.138, 24032/28000 datapoints
2025-03-06 20:38:22,210 - INFO - training batch 801, loss: 2.154, 25632/28000 datapoints
2025-03-06 20:38:22,325 - INFO - training batch 851, loss: 2.094, 27232/28000 datapoints
2025-03-06 20:38:22,383 - INFO - validation batch 1, loss: 2.115, 32/6976 datapoints
2025-03-06 20:38:22,426 - INFO - validation batch 51, loss: 2.148, 1632/6976 datapoints
2025-03-06 20:38:22,472 - INFO - validation batch 101, loss: 2.087, 3232/6976 datapoints
2025-03-06 20:38:22,517 - INFO - validation batch 151, loss: 2.291, 4832/6976 datapoints
2025-03-06 20:38:22,561 - INFO - validation batch 201, loss: 1.968, 6432/6976 datapoints
2025-03-06 20:38:22,576 - INFO - Epoch 8/800 done.
2025-03-06 20:38:22,576 - INFO - Final validation performance:
Loss: 2.122, top-1 acc: 0.289top-5 acc: 0.289
2025-03-06 20:38:22,577 - INFO - Beginning epoch 9/800
2025-03-06 20:38:22,580 - INFO - training batch 1, loss: 2.232, 32/28000 datapoints
2025-03-06 20:38:22,709 - INFO - training batch 51, loss: 2.197, 1632/28000 datapoints
2025-03-06 20:38:22,826 - INFO - training batch 101, loss: 2.014, 3232/28000 datapoints
2025-03-06 20:38:22,943 - INFO - training batch 151, loss: 2.172, 4832/28000 datapoints
2025-03-06 20:38:23,061 - INFO - training batch 201, loss: 2.018, 6432/28000 datapoints
2025-03-06 20:38:23,181 - INFO - training batch 251, loss: 2.165, 8032/28000 datapoints
2025-03-06 20:38:23,300 - INFO - training batch 301, loss: 2.084, 9632/28000 datapoints
2025-03-06 20:38:23,416 - INFO - training batch 351, loss: 2.098, 11232/28000 datapoints
2025-03-06 20:38:23,532 - INFO - training batch 401, loss: 2.072, 12832/28000 datapoints
2025-03-06 20:38:23,657 - INFO - training batch 451, loss: 2.087, 14432/28000 datapoints
2025-03-06 20:38:23,774 - INFO - training batch 501, loss: 1.943, 16032/28000 datapoints
2025-03-06 20:38:23,901 - INFO - training batch 551, loss: 1.977, 17632/28000 datapoints
2025-03-06 20:38:24,017 - INFO - training batch 601, loss: 2.037, 19232/28000 datapoints
2025-03-06 20:38:24,155 - INFO - training batch 651, loss: 2.036, 20832/28000 datapoints
2025-03-06 20:38:24,283 - INFO - training batch 701, loss: 1.877, 22432/28000 datapoints
2025-03-06 20:38:24,399 - INFO - training batch 751, loss: 2.023, 24032/28000 datapoints
2025-03-06 20:38:24,514 - INFO - training batch 801, loss: 2.039, 25632/28000 datapoints
2025-03-06 20:38:24,631 - INFO - training batch 851, loss: 1.956, 27232/28000 datapoints
2025-03-06 20:38:24,690 - INFO - validation batch 1, loss: 1.967, 32/6976 datapoints
2025-03-06 20:38:24,735 - INFO - validation batch 51, loss: 2.034, 1632/6976 datapoints
2025-03-06 20:38:24,778 - INFO - validation batch 101, loss: 1.930, 3232/6976 datapoints
2025-03-06 20:38:24,821 - INFO - validation batch 151, loss: 2.238, 4832/6976 datapoints
2025-03-06 20:38:24,864 - INFO - validation batch 201, loss: 1.821, 6432/6976 datapoints
2025-03-06 20:38:24,882 - INFO - Epoch 9/800 done.
2025-03-06 20:38:24,882 - INFO - Final validation performance:
Loss: 1.998, top-1 acc: 0.350top-5 acc: 0.350
2025-03-06 20:38:24,882 - INFO - Beginning epoch 10/800
2025-03-06 20:38:24,886 - INFO - training batch 1, loss: 2.156, 32/28000 datapoints
2025-03-06 20:38:25,005 - INFO - training batch 51, loss: 2.121, 1632/28000 datapoints
2025-03-06 20:38:25,122 - INFO - training batch 101, loss: 1.826, 3232/28000 datapoints
2025-03-06 20:38:25,242 - INFO - training batch 151, loss: 2.064, 4832/28000 datapoints
2025-03-06 20:38:25,357 - INFO - training batch 201, loss: 1.922, 6432/28000 datapoints
2025-03-06 20:38:25,474 - INFO - training batch 251, loss: 2.078, 8032/28000 datapoints
2025-03-06 20:38:25,605 - INFO - training batch 301, loss: 2.015, 9632/28000 datapoints
2025-03-06 20:38:25,726 - INFO - training batch 351, loss: 1.978, 11232/28000 datapoints
2025-03-06 20:38:25,842 - INFO - training batch 401, loss: 1.983, 12832/28000 datapoints
2025-03-06 20:38:25,964 - INFO - training batch 451, loss: 1.988, 14432/28000 datapoints
2025-03-06 20:38:26,091 - INFO - training batch 501, loss: 1.782, 16032/28000 datapoints
2025-03-06 20:38:26,211 - INFO - training batch 551, loss: 1.866, 17632/28000 datapoints
2025-03-06 20:38:26,333 - INFO - training batch 601, loss: 1.903, 19232/28000 datapoints
2025-03-06 20:38:26,449 - INFO - training batch 651, loss: 1.906, 20832/28000 datapoints
2025-03-06 20:38:26,565 - INFO - training batch 701, loss: 1.720, 22432/28000 datapoints
2025-03-06 20:38:26,683 - INFO - training batch 751, loss: 1.908, 24032/28000 datapoints
2025-03-06 20:38:26,802 - INFO - training batch 801, loss: 1.905, 25632/28000 datapoints
2025-03-06 20:38:26,917 - INFO - training batch 851, loss: 1.817, 27232/28000 datapoints
2025-03-06 20:38:26,975 - INFO - validation batch 1, loss: 1.800, 32/6976 datapoints
2025-03-06 20:38:27,018 - INFO - validation batch 51, loss: 1.925, 1632/6976 datapoints
2025-03-06 20:38:27,065 - INFO - validation batch 101, loss: 1.778, 3232/6976 datapoints
2025-03-06 20:38:27,108 - INFO - validation batch 151, loss: 2.169, 4832/6976 datapoints
2025-03-06 20:38:27,151 - INFO - validation batch 201, loss: 1.681, 6432/6976 datapoints
2025-03-06 20:38:27,167 - INFO - Epoch 10/800 done.
2025-03-06 20:38:27,167 - INFO - Final validation performance:
Loss: 1.871, top-1 acc: 0.382top-5 acc: 0.382
2025-03-06 20:38:27,168 - INFO - Beginning epoch 11/800
2025-03-06 20:38:27,171 - INFO - training batch 1, loss: 2.080, 32/28000 datapoints
2025-03-06 20:38:27,293 - INFO - training batch 51, loss: 2.045, 1632/28000 datapoints
2025-03-06 20:38:27,409 - INFO - training batch 101, loss: 1.665, 3232/28000 datapoints
2025-03-06 20:38:27,527 - INFO - training batch 151, loss: 1.981, 4832/28000 datapoints
2025-03-06 20:38:27,648 - INFO - training batch 201, loss: 1.852, 6432/28000 datapoints
2025-03-06 20:38:27,767 - INFO - training batch 251, loss: 1.999, 8032/28000 datapoints
2025-03-06 20:38:27,883 - INFO - training batch 301, loss: 1.953, 9632/28000 datapoints
2025-03-06 20:38:28,002 - INFO - training batch 351, loss: 1.897, 11232/28000 datapoints
2025-03-06 20:38:28,125 - INFO - training batch 401, loss: 1.918, 12832/28000 datapoints
2025-03-06 20:38:28,243 - INFO - training batch 451, loss: 1.905, 14432/28000 datapoints
2025-03-06 20:38:28,364 - INFO - training batch 501, loss: 1.642, 16032/28000 datapoints
2025-03-06 20:38:28,480 - INFO - training batch 551, loss: 1.786, 17632/28000 datapoints
2025-03-06 20:38:28,596 - INFO - training batch 601, loss: 1.800, 19232/28000 datapoints
2025-03-06 20:38:28,715 - INFO - training batch 651, loss: 1.791, 20832/28000 datapoints
2025-03-06 20:38:28,832 - INFO - training batch 701, loss: 1.601, 22432/28000 datapoints
2025-03-06 20:38:28,947 - INFO - training batch 751, loss: 1.824, 24032/28000 datapoints
2025-03-06 20:38:29,065 - INFO - training batch 801, loss: 1.794, 25632/28000 datapoints
2025-03-06 20:38:29,182 - INFO - training batch 851, loss: 1.714, 27232/28000 datapoints
2025-03-06 20:38:29,240 - INFO - validation batch 1, loss: 1.659, 32/6976 datapoints
2025-03-06 20:38:29,284 - INFO - validation batch 51, loss: 1.847, 1632/6976 datapoints
2025-03-06 20:38:29,327 - INFO - validation batch 101, loss: 1.670, 3232/6976 datapoints
2025-03-06 20:38:29,370 - INFO - validation batch 151, loss: 2.125, 4832/6976 datapoints
2025-03-06 20:38:29,414 - INFO - validation batch 201, loss: 1.574, 6432/6976 datapoints
2025-03-06 20:38:29,429 - INFO - Epoch 11/800 done.
2025-03-06 20:38:29,429 - INFO - Final validation performance:
Loss: 1.775, top-1 acc: 0.402top-5 acc: 0.402
2025-03-06 20:38:29,429 - INFO - Beginning epoch 12/800
2025-03-06 20:38:29,433 - INFO - training batch 1, loss: 2.032, 32/28000 datapoints
2025-03-06 20:38:29,551 - INFO - training batch 51, loss: 1.997, 1632/28000 datapoints
2025-03-06 20:38:29,670 - INFO - training batch 101, loss: 1.562, 3232/28000 datapoints
2025-03-06 20:38:29,789 - INFO - training batch 151, loss: 1.929, 4832/28000 datapoints
2025-03-06 20:38:29,907 - INFO - training batch 201, loss: 1.809, 6432/28000 datapoints
2025-03-06 20:38:30,026 - INFO - training batch 251, loss: 1.941, 8032/28000 datapoints
2025-03-06 20:38:30,151 - INFO - training batch 301, loss: 1.905, 9632/28000 datapoints
2025-03-06 20:38:30,271 - INFO - training batch 351, loss: 1.851, 11232/28000 datapoints
2025-03-06 20:38:30,388 - INFO - training batch 401, loss: 1.873, 12832/28000 datapoints
2025-03-06 20:38:30,516 - INFO - training batch 451, loss: 1.846, 14432/28000 datapoints
2025-03-06 20:38:30,641 - INFO - training batch 501, loss: 1.540, 16032/28000 datapoints
2025-03-06 20:38:30,760 - INFO - training batch 551, loss: 1.735, 17632/28000 datapoints
2025-03-06 20:38:30,881 - INFO - training batch 601, loss: 1.734, 19232/28000 datapoints
2025-03-06 20:38:31,012 - INFO - training batch 651, loss: 1.706, 20832/28000 datapoints
2025-03-06 20:38:31,136 - INFO - training batch 701, loss: 1.522, 22432/28000 datapoints
2025-03-06 20:38:31,256 - INFO - training batch 751, loss: 1.772, 24032/28000 datapoints
2025-03-06 20:38:31,374 - INFO - training batch 801, loss: 1.713, 25632/28000 datapoints
2025-03-06 20:38:31,496 - INFO - training batch 851, loss: 1.646, 27232/28000 datapoints
2025-03-06 20:38:31,567 - INFO - validation batch 1, loss: 1.551, 32/6976 datapoints
2025-03-06 20:38:31,613 - INFO - validation batch 51, loss: 1.797, 1632/6976 datapoints
2025-03-06 20:38:31,663 - INFO - validation batch 101, loss: 1.596, 3232/6976 datapoints
2025-03-06 20:38:31,709 - INFO - validation batch 151, loss: 2.100, 4832/6976 datapoints
2025-03-06 20:38:31,753 - INFO - validation batch 201, loss: 1.496, 6432/6976 datapoints
2025-03-06 20:38:31,769 - INFO - Epoch 12/800 done.
2025-03-06 20:38:31,769 - INFO - Final validation performance:
Loss: 1.708, top-1 acc: 0.418top-5 acc: 0.418
2025-03-06 20:38:31,770 - INFO - Beginning epoch 13/800
2025-03-06 20:38:31,774 - INFO - training batch 1, loss: 2.003, 32/28000 datapoints
2025-03-06 20:38:31,904 - INFO - training batch 51, loss: 1.970, 1632/28000 datapoints
2025-03-06 20:38:32,032 - INFO - training batch 101, loss: 1.501, 3232/28000 datapoints
2025-03-06 20:38:32,163 - INFO - training batch 151, loss: 1.899, 4832/28000 datapoints
2025-03-06 20:38:32,284 - INFO - training batch 201, loss: 1.783, 6432/28000 datapoints
2025-03-06 20:38:32,405 - INFO - training batch 251, loss: 1.896, 8032/28000 datapoints
2025-03-06 20:38:32,528 - INFO - training batch 301, loss: 1.866, 9632/28000 datapoints
2025-03-06 20:38:32,652 - INFO - training batch 351, loss: 1.820, 11232/28000 datapoints
2025-03-06 20:38:32,775 - INFO - training batch 401, loss: 1.840, 12832/28000 datapoints
2025-03-06 20:38:32,897 - INFO - training batch 451, loss: 1.804, 14432/28000 datapoints
2025-03-06 20:38:33,018 - INFO - training batch 501, loss: 1.470, 16032/28000 datapoints
2025-03-06 20:38:33,140 - INFO - training batch 551, loss: 1.699, 17632/28000 datapoints
2025-03-06 20:38:33,265 - INFO - training batch 601, loss: 1.691, 19232/28000 datapoints
2025-03-06 20:38:33,386 - INFO - training batch 651, loss: 1.643, 20832/28000 datapoints
2025-03-06 20:38:33,504 - INFO - training batch 701, loss: 1.471, 22432/28000 datapoints
2025-03-06 20:38:33,623 - INFO - training batch 751, loss: 1.739, 24032/28000 datapoints
2025-03-06 20:38:33,746 - INFO - training batch 801, loss: 1.656, 25632/28000 datapoints
2025-03-06 20:38:33,869 - INFO - training batch 851, loss: 1.600, 27232/28000 datapoints
2025-03-06 20:38:33,931 - INFO - validation batch 1, loss: 1.471, 32/6976 datapoints
2025-03-06 20:38:33,977 - INFO - validation batch 51, loss: 1.764, 1632/6976 datapoints
2025-03-06 20:38:34,024 - INFO - validation batch 101, loss: 1.544, 3232/6976 datapoints
2025-03-06 20:38:34,068 - INFO - validation batch 151, loss: 2.081, 4832/6976 datapoints
2025-03-06 20:38:34,116 - INFO - validation batch 201, loss: 1.437, 6432/6976 datapoints
2025-03-06 20:38:34,131 - INFO - Epoch 13/800 done.
2025-03-06 20:38:34,131 - INFO - Final validation performance:
Loss: 1.659, top-1 acc: 0.430top-5 acc: 0.430
2025-03-06 20:38:34,132 - INFO - Beginning epoch 14/800
2025-03-06 20:38:34,135 - INFO - training batch 1, loss: 1.982, 32/28000 datapoints
2025-03-06 20:38:34,279 - INFO - training batch 51, loss: 1.952, 1632/28000 datapoints
2025-03-06 20:38:34,398 - INFO - training batch 101, loss: 1.462, 3232/28000 datapoints
2025-03-06 20:38:34,514 - INFO - training batch 151, loss: 1.879, 4832/28000 datapoints
2025-03-06 20:38:34,632 - INFO - training batch 201, loss: 1.766, 6432/28000 datapoints
2025-03-06 20:38:34,751 - INFO - training batch 251, loss: 1.856, 8032/28000 datapoints
2025-03-06 20:38:34,868 - INFO - training batch 301, loss: 1.833, 9632/28000 datapoints
2025-03-06 20:38:34,993 - INFO - training batch 351, loss: 1.795, 11232/28000 datapoints
2025-03-06 20:38:35,111 - INFO - training batch 401, loss: 1.812, 12832/28000 datapoints
2025-03-06 20:38:35,228 - INFO - training batch 451, loss: 1.770, 14432/28000 datapoints
2025-03-06 20:38:35,344 - INFO - training batch 501, loss: 1.421, 16032/28000 datapoints
2025-03-06 20:38:35,461 - INFO - training batch 551, loss: 1.674, 17632/28000 datapoints
2025-03-06 20:38:35,578 - INFO - training batch 601, loss: 1.661, 19232/28000 datapoints
2025-03-06 20:38:35,699 - INFO - training batch 651, loss: 1.592, 20832/28000 datapoints
2025-03-06 20:38:35,817 - INFO - training batch 701, loss: 1.435, 22432/28000 datapoints
2025-03-06 20:38:35,936 - INFO - training batch 751, loss: 1.717, 24032/28000 datapoints
2025-03-06 20:38:36,050 - INFO - training batch 801, loss: 1.613, 25632/28000 datapoints
2025-03-06 20:38:36,174 - INFO - training batch 851, loss: 1.568, 27232/28000 datapoints
2025-03-06 20:38:36,231 - INFO - validation batch 1, loss: 1.411, 32/6976 datapoints
2025-03-06 20:38:36,276 - INFO - validation batch 51, loss: 1.741, 1632/6976 datapoints
2025-03-06 20:38:36,318 - INFO - validation batch 101, loss: 1.508, 3232/6976 datapoints
2025-03-06 20:38:36,363 - INFO - validation batch 151, loss: 2.064, 4832/6976 datapoints
2025-03-06 20:38:36,405 - INFO - validation batch 201, loss: 1.388, 6432/6976 datapoints
2025-03-06 20:38:36,420 - INFO - Epoch 14/800 done.
2025-03-06 20:38:36,420 - INFO - Final validation performance:
Loss: 1.622, top-1 acc: 0.438top-5 acc: 0.438
2025-03-06 20:38:36,421 - INFO - Beginning epoch 15/800
2025-03-06 20:38:36,424 - INFO - training batch 1, loss: 1.964, 32/28000 datapoints
2025-03-06 20:38:36,541 - INFO - training batch 51, loss: 1.938, 1632/28000 datapoints
2025-03-06 20:38:36,663 - INFO - training batch 101, loss: 1.434, 3232/28000 datapoints
2025-03-06 20:38:36,782 - INFO - training batch 151, loss: 1.864, 4832/28000 datapoints
2025-03-06 20:38:36,901 - INFO - training batch 201, loss: 1.751, 6432/28000 datapoints
2025-03-06 20:38:37,018 - INFO - training batch 251, loss: 1.818, 8032/28000 datapoints
2025-03-06 20:38:37,134 - INFO - training batch 301, loss: 1.804, 9632/28000 datapoints
2025-03-06 20:38:37,252 - INFO - training batch 351, loss: 1.772, 11232/28000 datapoints
2025-03-06 20:38:37,368 - INFO - training batch 401, loss: 1.785, 12832/28000 datapoints
2025-03-06 20:38:37,484 - INFO - training batch 451, loss: 1.739, 14432/28000 datapoints
2025-03-06 20:38:37,617 - INFO - training batch 501, loss: 1.385, 16032/28000 datapoints
2025-03-06 20:38:37,781 - INFO - training batch 551, loss: 1.653, 17632/28000 datapoints
2025-03-06 20:38:37,901 - INFO - training batch 601, loss: 1.637, 19232/28000 datapoints
2025-03-06 20:38:38,026 - INFO - training batch 651, loss: 1.549, 20832/28000 datapoints
2025-03-06 20:38:38,154 - INFO - training batch 701, loss: 1.409, 22432/28000 datapoints
2025-03-06 20:38:38,282 - INFO - training batch 751, loss: 1.701, 24032/28000 datapoints
2025-03-06 20:38:38,405 - INFO - training batch 801, loss: 1.578, 25632/28000 datapoints
2025-03-06 20:38:38,522 - INFO - training batch 851, loss: 1.543, 27232/28000 datapoints
2025-03-06 20:38:38,579 - INFO - validation batch 1, loss: 1.363, 32/6976 datapoints
2025-03-06 20:38:38,624 - INFO - validation batch 51, loss: 1.725, 1632/6976 datapoints
2025-03-06 20:38:38,671 - INFO - validation batch 101, loss: 1.482, 3232/6976 datapoints
2025-03-06 20:38:38,714 - INFO - validation batch 151, loss: 2.046, 4832/6976 datapoints
2025-03-06 20:38:38,756 - INFO - validation batch 201, loss: 1.345, 6432/6976 datapoints
2025-03-06 20:38:38,771 - INFO - Epoch 15/800 done.
2025-03-06 20:38:38,771 - INFO - Final validation performance:
Loss: 1.592, top-1 acc: 0.446top-5 acc: 0.446
2025-03-06 20:38:38,772 - INFO - Beginning epoch 16/800
2025-03-06 20:38:38,776 - INFO - training batch 1, loss: 1.946, 32/28000 datapoints
2025-03-06 20:38:38,898 - INFO - training batch 51, loss: 1.923, 1632/28000 datapoints
2025-03-06 20:38:39,016 - INFO - training batch 101, loss: 1.411, 3232/28000 datapoints
2025-03-06 20:38:39,138 - INFO - training batch 151, loss: 1.852, 4832/28000 datapoints
2025-03-06 20:38:39,256 - INFO - training batch 201, loss: 1.737, 6432/28000 datapoints
2025-03-06 20:38:39,372 - INFO - training batch 251, loss: 1.782, 8032/28000 datapoints
2025-03-06 20:38:39,490 - INFO - training batch 301, loss: 1.777, 9632/28000 datapoints
2025-03-06 20:38:39,606 - INFO - training batch 351, loss: 1.751, 11232/28000 datapoints
2025-03-06 20:38:39,726 - INFO - training batch 401, loss: 1.760, 12832/28000 datapoints
2025-03-06 20:38:39,844 - INFO - training batch 451, loss: 1.712, 14432/28000 datapoints
2025-03-06 20:38:39,961 - INFO - training batch 501, loss: 1.358, 16032/28000 datapoints
2025-03-06 20:38:40,096 - INFO - training batch 551, loss: 1.634, 17632/28000 datapoints
2025-03-06 20:38:40,217 - INFO - training batch 601, loss: 1.617, 19232/28000 datapoints
2025-03-06 20:38:40,334 - INFO - training batch 651, loss: 1.512, 20832/28000 datapoints
2025-03-06 20:38:40,452 - INFO - training batch 701, loss: 1.388, 22432/28000 datapoints
2025-03-06 20:38:40,570 - INFO - training batch 751, loss: 1.688, 24032/28000 datapoints
2025-03-06 20:38:40,689 - INFO - training batch 801, loss: 1.548, 25632/28000 datapoints
2025-03-06 20:38:40,807 - INFO - training batch 851, loss: 1.524, 27232/28000 datapoints
2025-03-06 20:38:40,865 - INFO - validation batch 1, loss: 1.325, 32/6976 datapoints
2025-03-06 20:38:40,909 - INFO - validation batch 51, loss: 1.713, 1632/6976 datapoints
2025-03-06 20:38:40,952 - INFO - validation batch 101, loss: 1.463, 3232/6976 datapoints
2025-03-06 20:38:40,996 - INFO - validation batch 151, loss: 2.029, 4832/6976 datapoints
2025-03-06 20:38:41,040 - INFO - validation batch 201, loss: 1.307, 6432/6976 datapoints
2025-03-06 20:38:41,055 - INFO - Epoch 16/800 done.
2025-03-06 20:38:41,055 - INFO - Final validation performance:
Loss: 1.567, top-1 acc: 0.451top-5 acc: 0.451
2025-03-06 20:38:41,055 - INFO - Beginning epoch 17/800
2025-03-06 20:38:41,059 - INFO - training batch 1, loss: 1.929, 32/28000 datapoints
2025-03-06 20:38:41,178 - INFO - training batch 51, loss: 1.906, 1632/28000 datapoints
2025-03-06 20:38:41,296 - INFO - training batch 101, loss: 1.392, 3232/28000 datapoints
2025-03-06 20:38:41,411 - INFO - training batch 151, loss: 1.842, 4832/28000 datapoints
2025-03-06 20:38:41,530 - INFO - training batch 201, loss: 1.723, 6432/28000 datapoints
2025-03-06 20:38:41,648 - INFO - training batch 251, loss: 1.747, 8032/28000 datapoints
2025-03-06 20:38:41,767 - INFO - training batch 301, loss: 1.753, 9632/28000 datapoints
2025-03-06 20:38:41,884 - INFO - training batch 351, loss: 1.732, 11232/28000 datapoints
2025-03-06 20:38:42,001 - INFO - training batch 401, loss: 1.737, 12832/28000 datapoints
2025-03-06 20:38:42,122 - INFO - training batch 451, loss: 1.688, 14432/28000 datapoints
2025-03-06 20:38:42,240 - INFO - training batch 501, loss: 1.336, 16032/28000 datapoints
2025-03-06 20:38:42,367 - INFO - training batch 551, loss: 1.617, 17632/28000 datapoints
2025-03-06 20:38:42,485 - INFO - training batch 601, loss: 1.601, 19232/28000 datapoints
2025-03-06 20:38:42,602 - INFO - training batch 651, loss: 1.478, 20832/28000 datapoints
2025-03-06 20:38:42,721 - INFO - training batch 701, loss: 1.370, 22432/28000 datapoints
2025-03-06 20:38:42,838 - INFO - training batch 751, loss: 1.678, 24032/28000 datapoints
2025-03-06 20:38:42,955 - INFO - training batch 801, loss: 1.523, 25632/28000 datapoints
2025-03-06 20:38:43,075 - INFO - training batch 851, loss: 1.508, 27232/28000 datapoints
2025-03-06 20:38:43,134 - INFO - validation batch 1, loss: 1.292, 32/6976 datapoints
2025-03-06 20:38:43,178 - INFO - validation batch 51, loss: 1.705, 1632/6976 datapoints
2025-03-06 20:38:43,221 - INFO - validation batch 101, loss: 1.449, 3232/6976 datapoints
2025-03-06 20:38:43,265 - INFO - validation batch 151, loss: 2.013, 4832/6976 datapoints
2025-03-06 20:38:43,309 - INFO - validation batch 201, loss: 1.273, 6432/6976 datapoints
2025-03-06 20:38:43,323 - INFO - Epoch 17/800 done.
2025-03-06 20:38:43,323 - INFO - Final validation performance:
Loss: 1.547, top-1 acc: 0.456top-5 acc: 0.456
2025-03-06 20:38:43,324 - INFO - Beginning epoch 18/800
2025-03-06 20:38:43,327 - INFO - training batch 1, loss: 1.913, 32/28000 datapoints
2025-03-06 20:38:43,446 - INFO - training batch 51, loss: 1.890, 1632/28000 datapoints
2025-03-06 20:38:43,579 - INFO - training batch 101, loss: 1.375, 3232/28000 datapoints
2025-03-06 20:38:43,703 - INFO - training batch 151, loss: 1.833, 4832/28000 datapoints
2025-03-06 20:38:43,820 - INFO - training batch 201, loss: 1.710, 6432/28000 datapoints
2025-03-06 20:38:43,934 - INFO - training batch 251, loss: 1.715, 8032/28000 datapoints
2025-03-06 20:38:44,078 - INFO - training batch 301, loss: 1.730, 9632/28000 datapoints
2025-03-06 20:38:44,208 - INFO - training batch 351, loss: 1.714, 11232/28000 datapoints
2025-03-06 20:38:44,350 - INFO - training batch 401, loss: 1.715, 12832/28000 datapoints
2025-03-06 20:38:44,476 - INFO - training batch 451, loss: 1.666, 14432/28000 datapoints
2025-03-06 20:38:44,609 - INFO - training batch 501, loss: 1.319, 16032/28000 datapoints
2025-03-06 20:38:44,749 - INFO - training batch 551, loss: 1.602, 17632/28000 datapoints
2025-03-06 20:38:44,889 - INFO - training batch 601, loss: 1.588, 19232/28000 datapoints
2025-03-06 20:38:45,006 - INFO - training batch 651, loss: 1.448, 20832/28000 datapoints
2025-03-06 20:38:45,159 - INFO - training batch 701, loss: 1.354, 22432/28000 datapoints
2025-03-06 20:38:45,287 - INFO - training batch 751, loss: 1.670, 24032/28000 datapoints
2025-03-06 20:38:45,403 - INFO - training batch 801, loss: 1.500, 25632/28000 datapoints
2025-03-06 20:38:45,523 - INFO - training batch 851, loss: 1.495, 27232/28000 datapoints
2025-03-06 20:38:45,581 - INFO - validation batch 1, loss: 1.264, 32/6976 datapoints
2025-03-06 20:38:45,624 - INFO - validation batch 51, loss: 1.700, 1632/6976 datapoints
2025-03-06 20:38:45,676 - INFO - validation batch 101, loss: 1.439, 3232/6976 datapoints
2025-03-06 20:38:45,721 - INFO - validation batch 151, loss: 1.997, 4832/6976 datapoints
2025-03-06 20:38:45,789 - INFO - validation batch 201, loss: 1.243, 6432/6976 datapoints
2025-03-06 20:38:45,808 - INFO - Epoch 18/800 done.
2025-03-06 20:38:45,808 - INFO - Final validation performance:
Loss: 1.529, top-1 acc: 0.460top-5 acc: 0.460
2025-03-06 20:38:45,809 - INFO - Beginning epoch 19/800
2025-03-06 20:38:45,812 - INFO - training batch 1, loss: 1.897, 32/28000 datapoints
2025-03-06 20:38:45,933 - INFO - training batch 51, loss: 1.875, 1632/28000 datapoints
2025-03-06 20:38:46,193 - INFO - training batch 101, loss: 1.359, 3232/28000 datapoints
2025-03-06 20:38:46,312 - INFO - training batch 151, loss: 1.824, 4832/28000 datapoints
2025-03-06 20:38:46,429 - INFO - training batch 201, loss: 1.698, 6432/28000 datapoints
2025-03-06 20:38:46,546 - INFO - training batch 251, loss: 1.684, 8032/28000 datapoints
2025-03-06 20:38:46,667 - INFO - training batch 301, loss: 1.710, 9632/28000 datapoints
2025-03-06 20:38:46,783 - INFO - training batch 351, loss: 1.699, 11232/28000 datapoints
2025-03-06 20:38:46,901 - INFO - training batch 401, loss: 1.694, 12832/28000 datapoints
2025-03-06 20:38:47,017 - INFO - training batch 451, loss: 1.646, 14432/28000 datapoints
2025-03-06 20:38:47,136 - INFO - training batch 501, loss: 1.305, 16032/28000 datapoints
2025-03-06 20:38:47,253 - INFO - training batch 551, loss: 1.588, 17632/28000 datapoints
2025-03-06 20:38:47,370 - INFO - training batch 601, loss: 1.578, 19232/28000 datapoints
2025-03-06 20:38:47,485 - INFO - training batch 651, loss: 1.421, 20832/28000 datapoints
2025-03-06 20:38:47,602 - INFO - training batch 701, loss: 1.340, 22432/28000 datapoints
2025-03-06 20:38:47,722 - INFO - training batch 751, loss: 1.663, 24032/28000 datapoints
2025-03-06 20:38:47,842 - INFO - training batch 801, loss: 1.479, 25632/28000 datapoints
2025-03-06 20:38:47,960 - INFO - training batch 851, loss: 1.483, 27232/28000 datapoints
2025-03-06 20:38:48,018 - INFO - validation batch 1, loss: 1.239, 32/6976 datapoints
2025-03-06 20:38:48,062 - INFO - validation batch 51, loss: 1.698, 1632/6976 datapoints
2025-03-06 20:38:48,104 - INFO - validation batch 101, loss: 1.431, 3232/6976 datapoints
2025-03-06 20:38:48,155 - INFO - validation batch 151, loss: 1.981, 4832/6976 datapoints
2025-03-06 20:38:48,219 - INFO - validation batch 201, loss: 1.215, 6432/6976 datapoints
2025-03-06 20:38:48,234 - INFO - Epoch 19/800 done.
2025-03-06 20:38:48,234 - INFO - Final validation performance:
Loss: 1.513, top-1 acc: 0.463top-5 acc: 0.463
2025-03-06 20:38:48,235 - INFO - Beginning epoch 20/800
2025-03-06 20:38:48,238 - INFO - training batch 1, loss: 1.882, 32/28000 datapoints
2025-03-06 20:38:48,362 - INFO - training batch 51, loss: 1.859, 1632/28000 datapoints
2025-03-06 20:38:48,479 - INFO - training batch 101, loss: 1.344, 3232/28000 datapoints
2025-03-06 20:38:48,596 - INFO - training batch 151, loss: 1.817, 4832/28000 datapoints
2025-03-06 20:38:48,718 - INFO - training batch 201, loss: 1.686, 6432/28000 datapoints
2025-03-06 20:38:48,835 - INFO - training batch 251, loss: 1.655, 8032/28000 datapoints
2025-03-06 20:38:48,951 - INFO - training batch 301, loss: 1.692, 9632/28000 datapoints
2025-03-06 20:38:49,070 - INFO - training batch 351, loss: 1.685, 11232/28000 datapoints
2025-03-06 20:38:49,186 - INFO - training batch 401, loss: 1.675, 12832/28000 datapoints
2025-03-06 20:38:49,303 - INFO - training batch 451, loss: 1.627, 14432/28000 datapoints
2025-03-06 20:38:49,418 - INFO - training batch 501, loss: 1.294, 16032/28000 datapoints
2025-03-06 20:38:49,536 - INFO - training batch 551, loss: 1.576, 17632/28000 datapoints
2025-03-06 20:38:49,670 - INFO - training batch 601, loss: 1.570, 19232/28000 datapoints
2025-03-06 20:38:49,788 - INFO - training batch 651, loss: 1.396, 20832/28000 datapoints
2025-03-06 20:38:49,906 - INFO - training batch 701, loss: 1.328, 22432/28000 datapoints
2025-03-06 20:38:50,025 - INFO - training batch 751, loss: 1.658, 24032/28000 datapoints
2025-03-06 20:38:50,150 - INFO - training batch 801, loss: 1.460, 25632/28000 datapoints
2025-03-06 20:38:50,279 - INFO - training batch 851, loss: 1.473, 27232/28000 datapoints
2025-03-06 20:38:50,337 - INFO - validation batch 1, loss: 1.217, 32/6976 datapoints
2025-03-06 20:38:50,381 - INFO - validation batch 51, loss: 1.698, 1632/6976 datapoints
2025-03-06 20:38:50,424 - INFO - validation batch 101, loss: 1.426, 3232/6976 datapoints
2025-03-06 20:38:50,470 - INFO - validation batch 151, loss: 1.965, 4832/6976 datapoints
2025-03-06 20:38:50,516 - INFO - validation batch 201, loss: 1.190, 6432/6976 datapoints
2025-03-06 20:38:50,531 - INFO - Epoch 20/800 done.
2025-03-06 20:38:50,531 - INFO - Final validation performance:
Loss: 1.499, top-1 acc: 0.466top-5 acc: 0.466
2025-03-06 20:38:50,531 - INFO - Beginning epoch 21/800
2025-03-06 20:38:50,535 - INFO - training batch 1, loss: 1.867, 32/28000 datapoints
2025-03-06 20:38:50,658 - INFO - training batch 51, loss: 1.844, 1632/28000 datapoints
2025-03-06 20:38:50,777 - INFO - training batch 101, loss: 1.331, 3232/28000 datapoints
2025-03-06 20:38:50,893 - INFO - training batch 151, loss: 1.811, 4832/28000 datapoints
2025-03-06 20:38:51,009 - INFO - training batch 201, loss: 1.676, 6432/28000 datapoints
2025-03-06 20:38:51,127 - INFO - training batch 251, loss: 1.628, 8032/28000 datapoints
2025-03-06 20:38:51,246 - INFO - training batch 301, loss: 1.676, 9632/28000 datapoints
2025-03-06 20:38:51,361 - INFO - training batch 351, loss: 1.672, 11232/28000 datapoints
2025-03-06 20:38:51,485 - INFO - training batch 401, loss: 1.658, 12832/28000 datapoints
2025-03-06 20:38:51,608 - INFO - training batch 451, loss: 1.611, 14432/28000 datapoints
2025-03-06 20:38:51,731 - INFO - training batch 501, loss: 1.286, 16032/28000 datapoints
2025-03-06 20:38:51,852 - INFO - training batch 551, loss: 1.565, 17632/28000 datapoints
2025-03-06 20:38:51,974 - INFO - training batch 601, loss: 1.563, 19232/28000 datapoints
2025-03-06 20:38:52,098 - INFO - training batch 651, loss: 1.373, 20832/28000 datapoints
2025-03-06 20:38:52,225 - INFO - training batch 701, loss: 1.317, 22432/28000 datapoints
2025-03-06 20:38:52,348 - INFO - training batch 751, loss: 1.653, 24032/28000 datapoints
2025-03-06 20:38:52,471 - INFO - training batch 801, loss: 1.443, 25632/28000 datapoints
2025-03-06 20:38:52,590 - INFO - training batch 851, loss: 1.465, 27232/28000 datapoints
2025-03-06 20:38:52,654 - INFO - validation batch 1, loss: 1.198, 32/6976 datapoints
2025-03-06 20:38:52,702 - INFO - validation batch 51, loss: 1.698, 1632/6976 datapoints
2025-03-06 20:38:52,750 - INFO - validation batch 101, loss: 1.422, 3232/6976 datapoints
2025-03-06 20:38:52,797 - INFO - validation batch 151, loss: 1.950, 4832/6976 datapoints
2025-03-06 20:38:52,846 - INFO - validation batch 201, loss: 1.167, 6432/6976 datapoints
2025-03-06 20:38:52,861 - INFO - Epoch 21/800 done.
2025-03-06 20:38:52,861 - INFO - Final validation performance:
Loss: 1.487, top-1 acc: 0.469top-5 acc: 0.469
2025-03-06 20:38:52,862 - INFO - Beginning epoch 22/800
2025-03-06 20:38:52,866 - INFO - training batch 1, loss: 1.854, 32/28000 datapoints
2025-03-06 20:38:52,992 - INFO - training batch 51, loss: 1.830, 1632/28000 datapoints
2025-03-06 20:38:53,118 - INFO - training batch 101, loss: 1.319, 3232/28000 datapoints
2025-03-06 20:38:53,248 - INFO - training batch 151, loss: 1.806, 4832/28000 datapoints
2025-03-06 20:38:53,370 - INFO - training batch 201, loss: 1.667, 6432/28000 datapoints
2025-03-06 20:38:53,491 - INFO - training batch 251, loss: 1.603, 8032/28000 datapoints
2025-03-06 20:38:53,611 - INFO - training batch 301, loss: 1.661, 9632/28000 datapoints
2025-03-06 20:38:53,735 - INFO - training batch 351, loss: 1.660, 11232/28000 datapoints
2025-03-06 20:38:53,857 - INFO - training batch 401, loss: 1.642, 12832/28000 datapoints
2025-03-06 20:38:53,980 - INFO - training batch 451, loss: 1.596, 14432/28000 datapoints
2025-03-06 20:38:54,101 - INFO - training batch 501, loss: 1.280, 16032/28000 datapoints
2025-03-06 20:38:54,229 - INFO - training batch 551, loss: 1.555, 17632/28000 datapoints
2025-03-06 20:38:54,351 - INFO - training batch 601, loss: 1.556, 19232/28000 datapoints
2025-03-06 20:38:54,500 - INFO - training batch 651, loss: 1.352, 20832/28000 datapoints
2025-03-06 20:38:54,623 - INFO - training batch 701, loss: 1.307, 22432/28000 datapoints
2025-03-06 20:38:54,746 - INFO - training batch 751, loss: 1.649, 24032/28000 datapoints
2025-03-06 20:38:54,871 - INFO - training batch 801, loss: 1.427, 25632/28000 datapoints
2025-03-06 20:38:54,993 - INFO - training batch 851, loss: 1.457, 27232/28000 datapoints
2025-03-06 20:38:55,054 - INFO - validation batch 1, loss: 1.180, 32/6976 datapoints
2025-03-06 20:38:55,103 - INFO - validation batch 51, loss: 1.700, 1632/6976 datapoints
2025-03-06 20:38:55,152 - INFO - validation batch 101, loss: 1.419, 3232/6976 datapoints
2025-03-06 20:38:55,201 - INFO - validation batch 151, loss: 1.936, 4832/6976 datapoints
2025-03-06 20:38:55,251 - INFO - validation batch 201, loss: 1.147, 6432/6976 datapoints
2025-03-06 20:38:55,266 - INFO - Epoch 22/800 done.
2025-03-06 20:38:55,266 - INFO - Final validation performance:
Loss: 1.477, top-1 acc: 0.470top-5 acc: 0.470
2025-03-06 20:38:55,267 - INFO - Beginning epoch 23/800
2025-03-06 20:38:55,271 - INFO - training batch 1, loss: 1.841, 32/28000 datapoints
2025-03-06 20:38:55,397 - INFO - training batch 51, loss: 1.816, 1632/28000 datapoints
2025-03-06 20:38:55,520 - INFO - training batch 101, loss: 1.307, 3232/28000 datapoints
2025-03-06 20:38:55,645 - INFO - training batch 151, loss: 1.801, 4832/28000 datapoints
2025-03-06 20:38:55,780 - INFO - training batch 201, loss: 1.659, 6432/28000 datapoints
2025-03-06 20:38:55,905 - INFO - training batch 251, loss: 1.578, 8032/28000 datapoints
2025-03-06 20:38:56,025 - INFO - training batch 301, loss: 1.648, 9632/28000 datapoints
2025-03-06 20:38:56,146 - INFO - training batch 351, loss: 1.649, 11232/28000 datapoints
2025-03-06 20:38:56,282 - INFO - training batch 401, loss: 1.627, 12832/28000 datapoints
2025-03-06 20:38:56,407 - INFO - training batch 451, loss: 1.581, 14432/28000 datapoints
2025-03-06 20:38:56,529 - INFO - training batch 501, loss: 1.276, 16032/28000 datapoints
2025-03-06 20:38:56,657 - INFO - training batch 551, loss: 1.546, 17632/28000 datapoints
2025-03-06 20:38:56,779 - INFO - training batch 601, loss: 1.551, 19232/28000 datapoints
2025-03-06 20:38:56,901 - INFO - training batch 651, loss: 1.334, 20832/28000 datapoints
2025-03-06 20:38:57,021 - INFO - training batch 701, loss: 1.298, 22432/28000 datapoints
2025-03-06 20:38:57,141 - INFO - training batch 751, loss: 1.645, 24032/28000 datapoints
2025-03-06 20:38:57,264 - INFO - training batch 801, loss: 1.412, 25632/28000 datapoints
2025-03-06 20:38:57,384 - INFO - training batch 851, loss: 1.451, 27232/28000 datapoints
2025-03-06 20:38:57,447 - INFO - validation batch 1, loss: 1.165, 32/6976 datapoints
2025-03-06 20:38:57,495 - INFO - validation batch 51, loss: 1.703, 1632/6976 datapoints
2025-03-06 20:38:57,544 - INFO - validation batch 101, loss: 1.417, 3232/6976 datapoints
2025-03-06 20:38:57,592 - INFO - validation batch 151, loss: 1.923, 4832/6976 datapoints
2025-03-06 20:38:57,643 - INFO - validation batch 201, loss: 1.127, 6432/6976 datapoints
2025-03-06 20:38:57,658 - INFO - Epoch 23/800 done.
2025-03-06 20:38:57,658 - INFO - Final validation performance:
Loss: 1.467, top-1 acc: 0.472top-5 acc: 0.472
2025-03-06 20:38:57,658 - INFO - Beginning epoch 24/800
2025-03-06 20:38:57,662 - INFO - training batch 1, loss: 1.830, 32/28000 datapoints
2025-03-06 20:38:57,787 - INFO - training batch 51, loss: 1.803, 1632/28000 datapoints
2025-03-06 20:38:57,908 - INFO - training batch 101, loss: 1.296, 3232/28000 datapoints
2025-03-06 20:38:58,030 - INFO - training batch 151, loss: 1.797, 4832/28000 datapoints
2025-03-06 20:38:58,153 - INFO - training batch 201, loss: 1.651, 6432/28000 datapoints
2025-03-06 20:38:58,280 - INFO - training batch 251, loss: 1.556, 8032/28000 datapoints
2025-03-06 20:38:58,406 - INFO - training batch 301, loss: 1.638, 9632/28000 datapoints
2025-03-06 20:38:58,528 - INFO - training batch 351, loss: 1.638, 11232/28000 datapoints
2025-03-06 20:38:58,651 - INFO - training batch 401, loss: 1.613, 12832/28000 datapoints
2025-03-06 20:38:58,771 - INFO - training batch 451, loss: 1.569, 14432/28000 datapoints
2025-03-06 20:38:58,892 - INFO - training batch 501, loss: 1.273, 16032/28000 datapoints
2025-03-06 20:38:59,015 - INFO - training batch 551, loss: 1.538, 17632/28000 datapoints
2025-03-06 20:38:59,137 - INFO - training batch 601, loss: 1.545, 19232/28000 datapoints
2025-03-06 20:38:59,260 - INFO - training batch 651, loss: 1.317, 20832/28000 datapoints
2025-03-06 20:38:59,380 - INFO - training batch 701, loss: 1.290, 22432/28000 datapoints
2025-03-06 20:38:59,502 - INFO - training batch 751, loss: 1.642, 24032/28000 datapoints
2025-03-06 20:38:59,622 - INFO - training batch 801, loss: 1.399, 25632/28000 datapoints
2025-03-06 20:38:59,745 - INFO - training batch 851, loss: 1.446, 27232/28000 datapoints
2025-03-06 20:38:59,806 - INFO - validation batch 1, loss: 1.150, 32/6976 datapoints
2025-03-06 20:38:59,855 - INFO - validation batch 51, loss: 1.707, 1632/6976 datapoints
2025-03-06 20:38:59,902 - INFO - validation batch 101, loss: 1.416, 3232/6976 datapoints
2025-03-06 20:38:59,949 - INFO - validation batch 151, loss: 1.911, 4832/6976 datapoints
2025-03-06 20:38:59,996 - INFO - validation batch 201, loss: 1.111, 6432/6976 datapoints
2025-03-06 20:39:00,013 - INFO - Epoch 24/800 done.
2025-03-06 20:39:00,013 - INFO - Final validation performance:
Loss: 1.459, top-1 acc: 0.472top-5 acc: 0.472
2025-03-06 20:39:00,014 - INFO - Beginning epoch 25/800
2025-03-06 20:39:00,018 - INFO - training batch 1, loss: 1.819, 32/28000 datapoints
2025-03-06 20:39:00,143 - INFO - training batch 51, loss: 1.789, 1632/28000 datapoints
2025-03-06 20:39:00,270 - INFO - training batch 101, loss: 1.285, 3232/28000 datapoints
2025-03-06 20:39:00,392 - INFO - training batch 151, loss: 1.794, 4832/28000 datapoints
2025-03-06 20:39:00,513 - INFO - training batch 201, loss: 1.644, 6432/28000 datapoints
2025-03-06 20:39:00,636 - INFO - training batch 251, loss: 1.536, 8032/28000 datapoints
2025-03-06 20:39:00,757 - INFO - training batch 301, loss: 1.628, 9632/28000 datapoints
2025-03-06 20:39:00,879 - INFO - training batch 351, loss: 1.628, 11232/28000 datapoints
2025-03-06 20:39:01,000 - INFO - training batch 401, loss: 1.601, 12832/28000 datapoints
2025-03-06 20:39:01,121 - INFO - training batch 451, loss: 1.557, 14432/28000 datapoints
2025-03-06 20:39:01,243 - INFO - training batch 501, loss: 1.271, 16032/28000 datapoints
2025-03-06 20:39:01,370 - INFO - training batch 551, loss: 1.530, 17632/28000 datapoints
2025-03-06 20:39:01,490 - INFO - training batch 601, loss: 1.540, 19232/28000 datapoints
2025-03-06 20:39:01,610 - INFO - training batch 651, loss: 1.301, 20832/28000 datapoints
2025-03-06 20:39:01,732 - INFO - training batch 701, loss: 1.282, 22432/28000 datapoints
2025-03-06 20:39:01,857 - INFO - training batch 751, loss: 1.639, 24032/28000 datapoints
2025-03-06 20:39:01,987 - INFO - training batch 801, loss: 1.386, 25632/28000 datapoints
2025-03-06 20:39:02,111 - INFO - training batch 851, loss: 1.440, 27232/28000 datapoints
2025-03-06 20:39:02,175 - INFO - validation batch 1, loss: 1.138, 32/6976 datapoints
2025-03-06 20:39:02,226 - INFO - validation batch 51, loss: 1.710, 1632/6976 datapoints
2025-03-06 20:39:02,278 - INFO - validation batch 101, loss: 1.415, 3232/6976 datapoints
2025-03-06 20:39:02,326 - INFO - validation batch 151, loss: 1.899, 4832/6976 datapoints
2025-03-06 20:39:02,371 - INFO - validation batch 201, loss: 1.094, 6432/6976 datapoints
2025-03-06 20:39:02,386 - INFO - Epoch 25/800 done.
2025-03-06 20:39:02,387 - INFO - Final validation performance:
Loss: 1.451, top-1 acc: 0.475top-5 acc: 0.475
2025-03-06 20:39:02,387 - INFO - Beginning epoch 26/800
2025-03-06 20:39:02,391 - INFO - training batch 1, loss: 1.809, 32/28000 datapoints
2025-03-06 20:39:02,511 - INFO - training batch 51, loss: 1.776, 1632/28000 datapoints
2025-03-06 20:39:02,629 - INFO - training batch 101, loss: 1.275, 3232/28000 datapoints
2025-03-06 20:39:02,749 - INFO - training batch 151, loss: 1.791, 4832/28000 datapoints
2025-03-06 20:39:02,870 - INFO - training batch 201, loss: 1.637, 6432/28000 datapoints
2025-03-06 20:39:02,989 - INFO - training batch 251, loss: 1.516, 8032/28000 datapoints
2025-03-06 20:39:03,107 - INFO - training batch 301, loss: 1.619, 9632/28000 datapoints
2025-03-06 20:39:03,227 - INFO - training batch 351, loss: 1.619, 11232/28000 datapoints
2025-03-06 20:39:03,348 - INFO - training batch 401, loss: 1.590, 12832/28000 datapoints
2025-03-06 20:39:03,467 - INFO - training batch 451, loss: 1.546, 14432/28000 datapoints
2025-03-06 20:39:03,584 - INFO - training batch 501, loss: 1.268, 16032/28000 datapoints
2025-03-06 20:39:03,704 - INFO - training batch 551, loss: 1.523, 17632/28000 datapoints
2025-03-06 20:39:03,834 - INFO - training batch 601, loss: 1.536, 19232/28000 datapoints
2025-03-06 20:39:03,952 - INFO - training batch 651, loss: 1.286, 20832/28000 datapoints
2025-03-06 20:39:04,071 - INFO - training batch 701, loss: 1.275, 22432/28000 datapoints
2025-03-06 20:39:04,188 - INFO - training batch 751, loss: 1.637, 24032/28000 datapoints
2025-03-06 20:39:04,311 - INFO - training batch 801, loss: 1.374, 25632/28000 datapoints
2025-03-06 20:39:04,435 - INFO - training batch 851, loss: 1.435, 27232/28000 datapoints
2025-03-06 20:39:04,506 - INFO - validation batch 1, loss: 1.126, 32/6976 datapoints
2025-03-06 20:39:04,576 - INFO - validation batch 51, loss: 1.714, 1632/6976 datapoints
2025-03-06 20:39:04,621 - INFO - validation batch 101, loss: 1.414, 3232/6976 datapoints
2025-03-06 20:39:04,676 - INFO - validation batch 151, loss: 1.888, 4832/6976 datapoints
2025-03-06 20:39:04,719 - INFO - validation batch 201, loss: 1.079, 6432/6976 datapoints
2025-03-06 20:39:04,734 - INFO - Epoch 26/800 done.
2025-03-06 20:39:04,734 - INFO - Final validation performance:
Loss: 1.444, top-1 acc: 0.478top-5 acc: 0.478
2025-03-06 20:39:04,735 - INFO - Beginning epoch 27/800
2025-03-06 20:39:04,738 - INFO - training batch 1, loss: 1.798, 32/28000 datapoints
2025-03-06 20:39:04,864 - INFO - training batch 51, loss: 1.764, 1632/28000 datapoints
2025-03-06 20:39:04,990 - INFO - training batch 101, loss: 1.265, 3232/28000 datapoints
2025-03-06 20:39:05,155 - INFO - training batch 151, loss: 1.788, 4832/28000 datapoints
2025-03-06 20:39:05,318 - INFO - training batch 201, loss: 1.630, 6432/28000 datapoints
2025-03-06 20:39:05,447 - INFO - training batch 251, loss: 1.498, 8032/28000 datapoints
2025-03-06 20:39:05,566 - INFO - training batch 301, loss: 1.611, 9632/28000 datapoints
2025-03-06 20:39:05,687 - INFO - training batch 351, loss: 1.609, 11232/28000 datapoints
2025-03-06 20:39:05,806 - INFO - training batch 401, loss: 1.579, 12832/28000 datapoints
2025-03-06 20:39:05,925 - INFO - training batch 451, loss: 1.536, 14432/28000 datapoints
2025-03-06 20:39:06,043 - INFO - training batch 501, loss: 1.266, 16032/28000 datapoints
2025-03-06 20:39:06,172 - INFO - training batch 551, loss: 1.516, 17632/28000 datapoints
2025-03-06 20:39:06,300 - INFO - training batch 601, loss: 1.533, 19232/28000 datapoints
2025-03-06 20:39:06,419 - INFO - training batch 651, loss: 1.272, 20832/28000 datapoints
2025-03-06 20:39:06,536 - INFO - training batch 701, loss: 1.269, 22432/28000 datapoints
2025-03-06 20:39:06,655 - INFO - training batch 751, loss: 1.636, 24032/28000 datapoints
2025-03-06 20:39:06,771 - INFO - training batch 801, loss: 1.364, 25632/28000 datapoints
2025-03-06 20:39:06,890 - INFO - training batch 851, loss: 1.430, 27232/28000 datapoints
2025-03-06 20:39:06,948 - INFO - validation batch 1, loss: 1.116, 32/6976 datapoints
2025-03-06 20:39:06,990 - INFO - validation batch 51, loss: 1.717, 1632/6976 datapoints
2025-03-06 20:39:07,034 - INFO - validation batch 101, loss: 1.414, 3232/6976 datapoints
2025-03-06 20:39:07,080 - INFO - validation batch 151, loss: 1.878, 4832/6976 datapoints
2025-03-06 20:39:07,123 - INFO - validation batch 201, loss: 1.065, 6432/6976 datapoints
2025-03-06 20:39:07,138 - INFO - Epoch 27/800 done.
2025-03-06 20:39:07,138 - INFO - Final validation performance:
Loss: 1.438, top-1 acc: 0.480top-5 acc: 0.480
2025-03-06 20:39:07,139 - INFO - Beginning epoch 28/800
2025-03-06 20:39:07,142 - INFO - training batch 1, loss: 1.790, 32/28000 datapoints
2025-03-06 20:39:07,265 - INFO - training batch 51, loss: 1.753, 1632/28000 datapoints
2025-03-06 20:39:07,385 - INFO - training batch 101, loss: 1.256, 3232/28000 datapoints
2025-03-06 20:39:07,503 - INFO - training batch 151, loss: 1.784, 4832/28000 datapoints
2025-03-06 20:39:07,620 - INFO - training batch 201, loss: 1.623, 6432/28000 datapoints
2025-03-06 20:39:07,742 - INFO - training batch 251, loss: 1.482, 8032/28000 datapoints
2025-03-06 20:39:07,865 - INFO - training batch 301, loss: 1.604, 9632/28000 datapoints
2025-03-06 20:39:07,997 - INFO - training batch 351, loss: 1.600, 11232/28000 datapoints
2025-03-06 20:39:08,115 - INFO - training batch 401, loss: 1.570, 12832/28000 datapoints
2025-03-06 20:39:08,235 - INFO - training batch 451, loss: 1.527, 14432/28000 datapoints
2025-03-06 20:39:08,366 - INFO - training batch 501, loss: 1.264, 16032/28000 datapoints
2025-03-06 20:39:08,491 - INFO - training batch 551, loss: 1.511, 17632/28000 datapoints
2025-03-06 20:39:08,608 - INFO - training batch 601, loss: 1.529, 19232/28000 datapoints
2025-03-06 20:39:08,731 - INFO - training batch 651, loss: 1.260, 20832/28000 datapoints
2025-03-06 20:39:08,849 - INFO - training batch 701, loss: 1.263, 22432/28000 datapoints
2025-03-06 20:39:08,967 - INFO - training batch 751, loss: 1.635, 24032/28000 datapoints
2025-03-06 20:39:09,086 - INFO - training batch 801, loss: 1.354, 25632/28000 datapoints
2025-03-06 20:39:09,205 - INFO - training batch 851, loss: 1.425, 27232/28000 datapoints
2025-03-06 20:39:09,264 - INFO - validation batch 1, loss: 1.105, 32/6976 datapoints
2025-03-06 20:39:09,308 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 20:39:09,352 - INFO - validation batch 101, loss: 1.415, 3232/6976 datapoints
2025-03-06 20:39:09,398 - INFO - validation batch 151, loss: 1.868, 4832/6976 datapoints
2025-03-06 20:39:09,442 - INFO - validation batch 201, loss: 1.052, 6432/6976 datapoints
2025-03-06 20:39:09,458 - INFO - Epoch 28/800 done.
2025-03-06 20:39:09,458 - INFO - Final validation performance:
Loss: 1.432, top-1 acc: 0.482top-5 acc: 0.482
2025-03-06 20:39:09,458 - INFO - Beginning epoch 29/800
2025-03-06 20:39:09,462 - INFO - training batch 1, loss: 1.780, 32/28000 datapoints
2025-03-06 20:39:09,581 - INFO - training batch 51, loss: 1.742, 1632/28000 datapoints
2025-03-06 20:39:09,701 - INFO - training batch 101, loss: 1.247, 3232/28000 datapoints
2025-03-06 20:39:09,817 - INFO - training batch 151, loss: 1.780, 4832/28000 datapoints
2025-03-06 20:39:09,949 - INFO - training batch 201, loss: 1.616, 6432/28000 datapoints
2025-03-06 20:39:10,068 - INFO - training batch 251, loss: 1.466, 8032/28000 datapoints
2025-03-06 20:39:10,184 - INFO - training batch 301, loss: 1.598, 9632/28000 datapoints
2025-03-06 20:39:10,308 - INFO - training batch 351, loss: 1.591, 11232/28000 datapoints
2025-03-06 20:39:10,426 - INFO - training batch 401, loss: 1.561, 12832/28000 datapoints
2025-03-06 20:39:10,543 - INFO - training batch 451, loss: 1.519, 14432/28000 datapoints
2025-03-06 20:39:10,664 - INFO - training batch 501, loss: 1.262, 16032/28000 datapoints
2025-03-06 20:39:10,782 - INFO - training batch 551, loss: 1.505, 17632/28000 datapoints
2025-03-06 20:39:10,902 - INFO - training batch 601, loss: 1.526, 19232/28000 datapoints
2025-03-06 20:39:11,019 - INFO - training batch 651, loss: 1.248, 20832/28000 datapoints
2025-03-06 20:39:11,136 - INFO - training batch 701, loss: 1.258, 22432/28000 datapoints
2025-03-06 20:39:11,252 - INFO - training batch 751, loss: 1.632, 24032/28000 datapoints
2025-03-06 20:39:11,371 - INFO - training batch 801, loss: 1.345, 25632/28000 datapoints
2025-03-06 20:39:11,491 - INFO - training batch 851, loss: 1.421, 27232/28000 datapoints
2025-03-06 20:39:11,552 - INFO - validation batch 1, loss: 1.096, 32/6976 datapoints
2025-03-06 20:39:11,600 - INFO - validation batch 51, loss: 1.723, 1632/6976 datapoints
2025-03-06 20:39:11,651 - INFO - validation batch 101, loss: 1.415, 3232/6976 datapoints
2025-03-06 20:39:11,698 - INFO - validation batch 151, loss: 1.859, 4832/6976 datapoints
2025-03-06 20:39:11,745 - INFO - validation batch 201, loss: 1.040, 6432/6976 datapoints
2025-03-06 20:39:11,760 - INFO - Epoch 29/800 done.
2025-03-06 20:39:11,760 - INFO - Final validation performance:
Loss: 1.427, top-1 acc: 0.484top-5 acc: 0.484
2025-03-06 20:39:11,761 - INFO - Beginning epoch 30/800
2025-03-06 20:39:11,764 - INFO - training batch 1, loss: 1.771, 32/28000 datapoints
2025-03-06 20:39:11,887 - INFO - training batch 51, loss: 1.733, 1632/28000 datapoints
2025-03-06 20:39:12,011 - INFO - training batch 101, loss: 1.239, 3232/28000 datapoints
2025-03-06 20:39:12,131 - INFO - training batch 151, loss: 1.775, 4832/28000 datapoints
2025-03-06 20:39:12,251 - INFO - training batch 201, loss: 1.611, 6432/28000 datapoints
2025-03-06 20:39:12,378 - INFO - training batch 251, loss: 1.452, 8032/28000 datapoints
2025-03-06 20:39:12,499 - INFO - training batch 301, loss: 1.592, 9632/28000 datapoints
2025-03-06 20:39:12,619 - INFO - training batch 351, loss: 1.582, 11232/28000 datapoints
2025-03-06 20:39:12,740 - INFO - training batch 401, loss: 1.553, 12832/28000 datapoints
2025-03-06 20:39:12,860 - INFO - training batch 451, loss: 1.511, 14432/28000 datapoints
2025-03-06 20:39:12,983 - INFO - training batch 501, loss: 1.260, 16032/28000 datapoints
2025-03-06 20:39:13,104 - INFO - training batch 551, loss: 1.500, 17632/28000 datapoints
2025-03-06 20:39:13,226 - INFO - training batch 601, loss: 1.522, 19232/28000 datapoints
2025-03-06 20:39:13,349 - INFO - training batch 651, loss: 1.238, 20832/28000 datapoints
2025-03-06 20:39:13,470 - INFO - training batch 701, loss: 1.253, 22432/28000 datapoints
2025-03-06 20:39:13,592 - INFO - training batch 751, loss: 1.629, 24032/28000 datapoints
2025-03-06 20:39:13,715 - INFO - training batch 801, loss: 1.337, 25632/28000 datapoints
2025-03-06 20:39:13,835 - INFO - training batch 851, loss: 1.417, 27232/28000 datapoints
2025-03-06 20:39:13,894 - INFO - validation batch 1, loss: 1.087, 32/6976 datapoints
2025-03-06 20:39:13,944 - INFO - validation batch 51, loss: 1.726, 1632/6976 datapoints
2025-03-06 20:39:13,991 - INFO - validation batch 101, loss: 1.415, 3232/6976 datapoints
2025-03-06 20:39:14,051 - INFO - validation batch 151, loss: 1.850, 4832/6976 datapoints
2025-03-06 20:39:14,103 - INFO - validation batch 201, loss: 1.029, 6432/6976 datapoints
2025-03-06 20:39:14,120 - INFO - Epoch 30/800 done.
2025-03-06 20:39:14,120 - INFO - Final validation performance:
Loss: 1.421, top-1 acc: 0.485top-5 acc: 0.485
2025-03-06 20:39:14,121 - INFO - Beginning epoch 31/800
2025-03-06 20:39:14,125 - INFO - training batch 1, loss: 1.762, 32/28000 datapoints
2025-03-06 20:39:14,250 - INFO - training batch 51, loss: 1.723, 1632/28000 datapoints
2025-03-06 20:39:14,373 - INFO - training batch 101, loss: 1.231, 3232/28000 datapoints
2025-03-06 20:39:14,512 - INFO - training batch 151, loss: 1.771, 4832/28000 datapoints
2025-03-06 20:39:14,671 - INFO - training batch 201, loss: 1.605, 6432/28000 datapoints
2025-03-06 20:39:14,791 - INFO - training batch 251, loss: 1.439, 8032/28000 datapoints
2025-03-06 20:39:14,913 - INFO - training batch 301, loss: 1.586, 9632/28000 datapoints
2025-03-06 20:39:15,031 - INFO - training batch 351, loss: 1.575, 11232/28000 datapoints
2025-03-06 20:39:15,149 - INFO - training batch 401, loss: 1.545, 12832/28000 datapoints
2025-03-06 20:39:15,270 - INFO - training batch 451, loss: 1.504, 14432/28000 datapoints
2025-03-06 20:39:15,387 - INFO - training batch 501, loss: 1.258, 16032/28000 datapoints
2025-03-06 20:39:15,508 - INFO - training batch 551, loss: 1.495, 17632/28000 datapoints
2025-03-06 20:39:15,624 - INFO - training batch 601, loss: 1.518, 19232/28000 datapoints
2025-03-06 20:39:15,745 - INFO - training batch 651, loss: 1.228, 20832/28000 datapoints
2025-03-06 20:39:15,862 - INFO - training batch 701, loss: 1.249, 22432/28000 datapoints
2025-03-06 20:39:15,980 - INFO - training batch 751, loss: 1.627, 24032/28000 datapoints
2025-03-06 20:39:16,096 - INFO - training batch 801, loss: 1.329, 25632/28000 datapoints
2025-03-06 20:39:16,212 - INFO - training batch 851, loss: 1.413, 27232/28000 datapoints
2025-03-06 20:39:16,271 - INFO - validation batch 1, loss: 1.079, 32/6976 datapoints
2025-03-06 20:39:16,319 - INFO - validation batch 51, loss: 1.729, 1632/6976 datapoints
2025-03-06 20:39:16,361 - INFO - validation batch 101, loss: 1.415, 3232/6976 datapoints
2025-03-06 20:39:16,405 - INFO - validation batch 151, loss: 1.842, 4832/6976 datapoints
2025-03-06 20:39:16,458 - INFO - validation batch 201, loss: 1.018, 6432/6976 datapoints
2025-03-06 20:39:16,477 - INFO - Epoch 31/800 done.
2025-03-06 20:39:16,477 - INFO - Final validation performance:
Loss: 1.417, top-1 acc: 0.487top-5 acc: 0.487
2025-03-06 20:39:16,477 - INFO - Beginning epoch 32/800
2025-03-06 20:39:16,481 - INFO - training batch 1, loss: 1.754, 32/28000 datapoints
2025-03-06 20:39:16,608 - INFO - training batch 51, loss: 1.714, 1632/28000 datapoints
2025-03-06 20:39:16,727 - INFO - training batch 101, loss: 1.223, 3232/28000 datapoints
2025-03-06 20:39:16,850 - INFO - training batch 151, loss: 1.767, 4832/28000 datapoints
2025-03-06 20:39:16,971 - INFO - training batch 201, loss: 1.600, 6432/28000 datapoints
2025-03-06 20:39:17,088 - INFO - training batch 251, loss: 1.426, 8032/28000 datapoints
2025-03-06 20:39:17,205 - INFO - training batch 301, loss: 1.581, 9632/28000 datapoints
2025-03-06 20:39:17,322 - INFO - training batch 351, loss: 1.568, 11232/28000 datapoints
2025-03-06 20:39:17,441 - INFO - training batch 401, loss: 1.538, 12832/28000 datapoints
2025-03-06 20:39:17,559 - INFO - training batch 451, loss: 1.497, 14432/28000 datapoints
2025-03-06 20:39:17,678 - INFO - training batch 501, loss: 1.257, 16032/28000 datapoints
2025-03-06 20:39:17,795 - INFO - training batch 551, loss: 1.491, 17632/28000 datapoints
2025-03-06 20:39:17,911 - INFO - training batch 601, loss: 1.515, 19232/28000 datapoints
2025-03-06 20:39:18,029 - INFO - training batch 651, loss: 1.218, 20832/28000 datapoints
2025-03-06 20:39:18,147 - INFO - training batch 701, loss: 1.245, 22432/28000 datapoints
2025-03-06 20:39:18,269 - INFO - training batch 751, loss: 1.624, 24032/28000 datapoints
2025-03-06 20:39:18,403 - INFO - training batch 801, loss: 1.322, 25632/28000 datapoints
2025-03-06 20:39:18,528 - INFO - training batch 851, loss: 1.410, 27232/28000 datapoints
2025-03-06 20:39:18,586 - INFO - validation batch 1, loss: 1.071, 32/6976 datapoints
2025-03-06 20:39:18,634 - INFO - validation batch 51, loss: 1.731, 1632/6976 datapoints
2025-03-06 20:39:18,679 - INFO - validation batch 101, loss: 1.415, 3232/6976 datapoints
2025-03-06 20:39:18,723 - INFO - validation batch 151, loss: 1.834, 4832/6976 datapoints
2025-03-06 20:39:18,765 - INFO - validation batch 201, loss: 1.008, 6432/6976 datapoints
2025-03-06 20:39:18,780 - INFO - Epoch 32/800 done.
2025-03-06 20:39:18,780 - INFO - Final validation performance:
Loss: 1.412, top-1 acc: 0.488top-5 acc: 0.488
2025-03-06 20:39:18,780 - INFO - Beginning epoch 33/800
2025-03-06 20:39:18,784 - INFO - training batch 1, loss: 1.745, 32/28000 datapoints
2025-03-06 20:39:18,901 - INFO - training batch 51, loss: 1.706, 1632/28000 datapoints
2025-03-06 20:39:19,021 - INFO - training batch 101, loss: 1.217, 3232/28000 datapoints
2025-03-06 20:39:19,139 - INFO - training batch 151, loss: 1.763, 4832/28000 datapoints
2025-03-06 20:39:19,256 - INFO - training batch 201, loss: 1.595, 6432/28000 datapoints
2025-03-06 20:39:19,374 - INFO - training batch 251, loss: 1.415, 8032/28000 datapoints
2025-03-06 20:39:19,494 - INFO - training batch 301, loss: 1.577, 9632/28000 datapoints
2025-03-06 20:39:19,610 - INFO - training batch 351, loss: 1.561, 11232/28000 datapoints
2025-03-06 20:39:19,731 - INFO - training batch 401, loss: 1.532, 12832/28000 datapoints
2025-03-06 20:39:19,846 - INFO - training batch 451, loss: 1.490, 14432/28000 datapoints
2025-03-06 20:39:19,964 - INFO - training batch 501, loss: 1.256, 16032/28000 datapoints
2025-03-06 20:39:20,087 - INFO - training batch 551, loss: 1.486, 17632/28000 datapoints
2025-03-06 20:39:20,218 - INFO - training batch 601, loss: 1.511, 19232/28000 datapoints
2025-03-06 20:39:20,340 - INFO - training batch 651, loss: 1.209, 20832/28000 datapoints
2025-03-06 20:39:20,467 - INFO - training batch 701, loss: 1.241, 22432/28000 datapoints
2025-03-06 20:39:20,593 - INFO - training batch 751, loss: 1.621, 24032/28000 datapoints
2025-03-06 20:39:20,717 - INFO - training batch 801, loss: 1.315, 25632/28000 datapoints
2025-03-06 20:39:20,834 - INFO - training batch 851, loss: 1.406, 27232/28000 datapoints
2025-03-06 20:39:20,893 - INFO - validation batch 1, loss: 1.064, 32/6976 datapoints
2025-03-06 20:39:20,941 - INFO - validation batch 51, loss: 1.733, 1632/6976 datapoints
2025-03-06 20:39:20,985 - INFO - validation batch 101, loss: 1.415, 3232/6976 datapoints
2025-03-06 20:39:21,030 - INFO - validation batch 151, loss: 1.826, 4832/6976 datapoints
2025-03-06 20:39:21,074 - INFO - validation batch 201, loss: 0.998, 6432/6976 datapoints
2025-03-06 20:39:21,089 - INFO - Epoch 33/800 done.
2025-03-06 20:39:21,089 - INFO - Final validation performance:
Loss: 1.407, top-1 acc: 0.488top-5 acc: 0.488
2025-03-06 20:39:21,090 - INFO - Beginning epoch 34/800
2025-03-06 20:39:21,093 - INFO - training batch 1, loss: 1.738, 32/28000 datapoints
2025-03-06 20:39:21,210 - INFO - training batch 51, loss: 1.697, 1632/28000 datapoints
2025-03-06 20:39:21,327 - INFO - training batch 101, loss: 1.210, 3232/28000 datapoints
2025-03-06 20:39:21,445 - INFO - training batch 151, loss: 1.759, 4832/28000 datapoints
2025-03-06 20:39:21,564 - INFO - training batch 201, loss: 1.589, 6432/28000 datapoints
2025-03-06 20:39:21,683 - INFO - training batch 251, loss: 1.404, 8032/28000 datapoints
2025-03-06 20:39:21,800 - INFO - training batch 301, loss: 1.573, 9632/28000 datapoints
2025-03-06 20:39:21,917 - INFO - training batch 351, loss: 1.555, 11232/28000 datapoints
2025-03-06 20:39:22,035 - INFO - training batch 401, loss: 1.526, 12832/28000 datapoints
2025-03-06 20:39:22,151 - INFO - training batch 451, loss: 1.484, 14432/28000 datapoints
2025-03-06 20:39:22,269 - INFO - training batch 501, loss: 1.255, 16032/28000 datapoints
2025-03-06 20:39:22,391 - INFO - training batch 551, loss: 1.482, 17632/28000 datapoints
2025-03-06 20:39:22,509 - INFO - training batch 601, loss: 1.508, 19232/28000 datapoints
2025-03-06 20:39:22,626 - INFO - training batch 651, loss: 1.201, 20832/28000 datapoints
2025-03-06 20:39:22,746 - INFO - training batch 701, loss: 1.238, 22432/28000 datapoints
2025-03-06 20:39:22,863 - INFO - training batch 751, loss: 1.618, 24032/28000 datapoints
2025-03-06 20:39:22,980 - INFO - training batch 801, loss: 1.308, 25632/28000 datapoints
2025-03-06 20:39:23,098 - INFO - training batch 851, loss: 1.403, 27232/28000 datapoints
2025-03-06 20:39:23,156 - INFO - validation batch 1, loss: 1.058, 32/6976 datapoints
2025-03-06 20:39:23,199 - INFO - validation batch 51, loss: 1.734, 1632/6976 datapoints
2025-03-06 20:39:23,243 - INFO - validation batch 101, loss: 1.414, 3232/6976 datapoints
2025-03-06 20:39:23,288 - INFO - validation batch 151, loss: 1.818, 4832/6976 datapoints
2025-03-06 20:39:23,331 - INFO - validation batch 201, loss: 0.990, 6432/6976 datapoints
2025-03-06 20:39:23,346 - INFO - Epoch 34/800 done.
2025-03-06 20:39:23,347 - INFO - Final validation performance:
Loss: 1.403, top-1 acc: 0.488top-5 acc: 0.488
2025-03-06 20:39:23,347 - INFO - Beginning epoch 35/800
2025-03-06 20:39:23,351 - INFO - training batch 1, loss: 1.730, 32/28000 datapoints
2025-03-06 20:39:23,475 - INFO - training batch 51, loss: 1.690, 1632/28000 datapoints
2025-03-06 20:39:23,594 - INFO - training batch 101, loss: 1.204, 3232/28000 datapoints
2025-03-06 20:39:23,714 - INFO - training batch 151, loss: 1.756, 4832/28000 datapoints
2025-03-06 20:39:23,830 - INFO - training batch 201, loss: 1.584, 6432/28000 datapoints
2025-03-06 20:39:23,946 - INFO - training batch 251, loss: 1.395, 8032/28000 datapoints
2025-03-06 20:39:24,063 - INFO - training batch 301, loss: 1.569, 9632/28000 datapoints
2025-03-06 20:39:24,178 - INFO - training batch 351, loss: 1.549, 11232/28000 datapoints
2025-03-06 20:39:24,296 - INFO - training batch 401, loss: 1.520, 12832/28000 datapoints
2025-03-06 20:39:24,417 - INFO - training batch 451, loss: 1.478, 14432/28000 datapoints
2025-03-06 20:39:24,534 - INFO - training batch 501, loss: 1.254, 16032/28000 datapoints
2025-03-06 20:39:24,655 - INFO - training batch 551, loss: 1.478, 17632/28000 datapoints
2025-03-06 20:39:24,797 - INFO - training batch 601, loss: 1.505, 19232/28000 datapoints
2025-03-06 20:39:24,918 - INFO - training batch 651, loss: 1.193, 20832/28000 datapoints
2025-03-06 20:39:25,037 - INFO - training batch 701, loss: 1.235, 22432/28000 datapoints
2025-03-06 20:39:25,156 - INFO - training batch 751, loss: 1.615, 24032/28000 datapoints
2025-03-06 20:39:25,277 - INFO - training batch 801, loss: 1.302, 25632/28000 datapoints
2025-03-06 20:39:25,403 - INFO - training batch 851, loss: 1.401, 27232/28000 datapoints
2025-03-06 20:39:25,462 - INFO - validation batch 1, loss: 1.051, 32/6976 datapoints
2025-03-06 20:39:25,504 - INFO - validation batch 51, loss: 1.736, 1632/6976 datapoints
2025-03-06 20:39:25,547 - INFO - validation batch 101, loss: 1.413, 3232/6976 datapoints
2025-03-06 20:39:25,592 - INFO - validation batch 151, loss: 1.810, 4832/6976 datapoints
2025-03-06 20:39:25,640 - INFO - validation batch 201, loss: 0.981, 6432/6976 datapoints
2025-03-06 20:39:25,655 - INFO - Epoch 35/800 done.
2025-03-06 20:39:25,655 - INFO - Final validation performance:
Loss: 1.398, top-1 acc: 0.489top-5 acc: 0.489
2025-03-06 20:39:25,656 - INFO - Beginning epoch 36/800
2025-03-06 20:39:25,659 - INFO - training batch 1, loss: 1.722, 32/28000 datapoints
2025-03-06 20:39:25,778 - INFO - training batch 51, loss: 1.682, 1632/28000 datapoints
2025-03-06 20:39:25,896 - INFO - training batch 101, loss: 1.198, 3232/28000 datapoints
2025-03-06 20:39:26,012 - INFO - training batch 151, loss: 1.752, 4832/28000 datapoints
2025-03-06 20:39:26,141 - INFO - training batch 201, loss: 1.579, 6432/28000 datapoints
2025-03-06 20:39:26,264 - INFO - training batch 251, loss: 1.385, 8032/28000 datapoints
2025-03-06 20:39:26,387 - INFO - training batch 301, loss: 1.565, 9632/28000 datapoints
2025-03-06 20:39:26,511 - INFO - training batch 351, loss: 1.543, 11232/28000 datapoints
2025-03-06 20:39:26,633 - INFO - training batch 401, loss: 1.515, 12832/28000 datapoints
2025-03-06 20:39:26,756 - INFO - training batch 451, loss: 1.473, 14432/28000 datapoints
2025-03-06 20:39:26,875 - INFO - training batch 501, loss: 1.253, 16032/28000 datapoints
2025-03-06 20:39:26,993 - INFO - training batch 551, loss: 1.474, 17632/28000 datapoints
2025-03-06 20:39:27,111 - INFO - training batch 601, loss: 1.502, 19232/28000 datapoints
2025-03-06 20:39:27,225 - INFO - training batch 651, loss: 1.186, 20832/28000 datapoints
2025-03-06 20:39:27,341 - INFO - training batch 701, loss: 1.232, 22432/28000 datapoints
2025-03-06 20:39:27,459 - INFO - training batch 751, loss: 1.612, 24032/28000 datapoints
2025-03-06 20:39:27,576 - INFO - training batch 801, loss: 1.296, 25632/28000 datapoints
2025-03-06 20:39:27,696 - INFO - training batch 851, loss: 1.398, 27232/28000 datapoints
2025-03-06 20:39:27,754 - INFO - validation batch 1, loss: 1.046, 32/6976 datapoints
2025-03-06 20:39:27,798 - INFO - validation batch 51, loss: 1.737, 1632/6976 datapoints
2025-03-06 20:39:27,842 - INFO - validation batch 101, loss: 1.413, 3232/6976 datapoints
2025-03-06 20:39:27,885 - INFO - validation batch 151, loss: 1.803, 4832/6976 datapoints
2025-03-06 20:39:27,929 - INFO - validation batch 201, loss: 0.973, 6432/6976 datapoints
2025-03-06 20:39:27,944 - INFO - Epoch 36/800 done.
2025-03-06 20:39:27,944 - INFO - Final validation performance:
Loss: 1.394, top-1 acc: 0.490top-5 acc: 0.490
2025-03-06 20:39:27,944 - INFO - Beginning epoch 37/800
2025-03-06 20:39:27,948 - INFO - training batch 1, loss: 1.714, 32/28000 datapoints
2025-03-06 20:39:28,066 - INFO - training batch 51, loss: 1.675, 1632/28000 datapoints
2025-03-06 20:39:28,185 - INFO - training batch 101, loss: 1.193, 3232/28000 datapoints
2025-03-06 20:39:28,307 - INFO - training batch 151, loss: 1.749, 4832/28000 datapoints
2025-03-06 20:39:28,430 - INFO - training batch 201, loss: 1.574, 6432/28000 datapoints
2025-03-06 20:39:28,553 - INFO - training batch 251, loss: 1.377, 8032/28000 datapoints
2025-03-06 20:39:28,675 - INFO - training batch 301, loss: 1.562, 9632/28000 datapoints
2025-03-06 20:39:28,791 - INFO - training batch 351, loss: 1.538, 11232/28000 datapoints
2025-03-06 20:39:28,908 - INFO - training batch 401, loss: 1.510, 12832/28000 datapoints
2025-03-06 20:39:29,025 - INFO - training batch 451, loss: 1.468, 14432/28000 datapoints
2025-03-06 20:39:29,144 - INFO - training batch 501, loss: 1.252, 16032/28000 datapoints
2025-03-06 20:39:29,261 - INFO - training batch 551, loss: 1.470, 17632/28000 datapoints
2025-03-06 20:39:29,377 - INFO - training batch 601, loss: 1.500, 19232/28000 datapoints
2025-03-06 20:39:29,495 - INFO - training batch 651, loss: 1.179, 20832/28000 datapoints
2025-03-06 20:39:29,612 - INFO - training batch 701, loss: 1.230, 22432/28000 datapoints
2025-03-06 20:39:29,732 - INFO - training batch 751, loss: 1.609, 24032/28000 datapoints
2025-03-06 20:39:29,850 - INFO - training batch 801, loss: 1.290, 25632/28000 datapoints
2025-03-06 20:39:29,966 - INFO - training batch 851, loss: 1.395, 27232/28000 datapoints
2025-03-06 20:39:30,024 - INFO - validation batch 1, loss: 1.041, 32/6976 datapoints
2025-03-06 20:39:30,069 - INFO - validation batch 51, loss: 1.737, 1632/6976 datapoints
2025-03-06 20:39:30,112 - INFO - validation batch 101, loss: 1.412, 3232/6976 datapoints
2025-03-06 20:39:30,157 - INFO - validation batch 151, loss: 1.796, 4832/6976 datapoints
2025-03-06 20:39:30,201 - INFO - validation batch 201, loss: 0.966, 6432/6976 datapoints
2025-03-06 20:39:30,216 - INFO - Epoch 37/800 done.
2025-03-06 20:39:30,216 - INFO - Final validation performance:
Loss: 1.390, top-1 acc: 0.491top-5 acc: 0.491
2025-03-06 20:39:30,216 - INFO - Beginning epoch 38/800
2025-03-06 20:39:30,220 - INFO - training batch 1, loss: 1.707, 32/28000 datapoints
2025-03-06 20:39:30,338 - INFO - training batch 51, loss: 1.669, 1632/28000 datapoints
2025-03-06 20:39:30,458 - INFO - training batch 101, loss: 1.187, 3232/28000 datapoints
2025-03-06 20:39:30,576 - INFO - training batch 151, loss: 1.745, 4832/28000 datapoints
2025-03-06 20:39:30,699 - INFO - training batch 201, loss: 1.569, 6432/28000 datapoints
2025-03-06 20:39:30,820 - INFO - training batch 251, loss: 1.369, 8032/28000 datapoints
2025-03-06 20:39:30,936 - INFO - training batch 301, loss: 1.558, 9632/28000 datapoints
2025-03-06 20:39:31,054 - INFO - training batch 351, loss: 1.533, 11232/28000 datapoints
2025-03-06 20:39:31,172 - INFO - training batch 401, loss: 1.506, 12832/28000 datapoints
2025-03-06 20:39:31,290 - INFO - training batch 451, loss: 1.463, 14432/28000 datapoints
2025-03-06 20:39:31,406 - INFO - training batch 501, loss: 1.252, 16032/28000 datapoints
2025-03-06 20:39:31,525 - INFO - training batch 551, loss: 1.466, 17632/28000 datapoints
2025-03-06 20:39:31,652 - INFO - training batch 601, loss: 1.497, 19232/28000 datapoints
2025-03-06 20:39:31,774 - INFO - training batch 651, loss: 1.172, 20832/28000 datapoints
2025-03-06 20:39:31,894 - INFO - training batch 701, loss: 1.227, 22432/28000 datapoints
2025-03-06 20:39:32,016 - INFO - training batch 751, loss: 1.606, 24032/28000 datapoints
2025-03-06 20:39:32,140 - INFO - training batch 801, loss: 1.285, 25632/28000 datapoints
2025-03-06 20:39:32,279 - INFO - training batch 851, loss: 1.393, 27232/28000 datapoints
2025-03-06 20:39:32,344 - INFO - validation batch 1, loss: 1.036, 32/6976 datapoints
2025-03-06 20:39:32,397 - INFO - validation batch 51, loss: 1.738, 1632/6976 datapoints
2025-03-06 20:39:32,444 - INFO - validation batch 101, loss: 1.410, 3232/6976 datapoints
2025-03-06 20:39:32,493 - INFO - validation batch 151, loss: 1.789, 4832/6976 datapoints
2025-03-06 20:39:32,541 - INFO - validation batch 201, loss: 0.958, 6432/6976 datapoints
2025-03-06 20:39:32,556 - INFO - Epoch 38/800 done.
2025-03-06 20:39:32,556 - INFO - Final validation performance:
Loss: 1.386, top-1 acc: 0.492top-5 acc: 0.492
2025-03-06 20:39:32,557 - INFO - Beginning epoch 39/800
2025-03-06 20:39:32,561 - INFO - training batch 1, loss: 1.701, 32/28000 datapoints
2025-03-06 20:39:32,692 - INFO - training batch 51, loss: 1.662, 1632/28000 datapoints
2025-03-06 20:39:32,814 - INFO - training batch 101, loss: 1.182, 3232/28000 datapoints
2025-03-06 20:39:32,935 - INFO - training batch 151, loss: 1.741, 4832/28000 datapoints
2025-03-06 20:39:33,057 - INFO - training batch 201, loss: 1.564, 6432/28000 datapoints
2025-03-06 20:39:33,179 - INFO - training batch 251, loss: 1.361, 8032/28000 datapoints
2025-03-06 20:39:33,302 - INFO - training batch 301, loss: 1.555, 9632/28000 datapoints
2025-03-06 20:39:33,428 - INFO - training batch 351, loss: 1.528, 11232/28000 datapoints
2025-03-06 20:39:33,549 - INFO - training batch 401, loss: 1.502, 12832/28000 datapoints
2025-03-06 20:39:33,675 - INFO - training batch 451, loss: 1.458, 14432/28000 datapoints
2025-03-06 20:39:33,797 - INFO - training batch 501, loss: 1.251, 16032/28000 datapoints
2025-03-06 20:39:33,916 - INFO - training batch 551, loss: 1.462, 17632/28000 datapoints
2025-03-06 20:39:34,038 - INFO - training batch 601, loss: 1.495, 19232/28000 datapoints
2025-03-06 20:39:34,158 - INFO - training batch 651, loss: 1.165, 20832/28000 datapoints
2025-03-06 20:39:34,281 - INFO - training batch 701, loss: 1.225, 22432/28000 datapoints
2025-03-06 20:39:34,406 - INFO - training batch 751, loss: 1.603, 24032/28000 datapoints
2025-03-06 20:39:34,529 - INFO - training batch 801, loss: 1.280, 25632/28000 datapoints
2025-03-06 20:39:34,654 - INFO - training batch 851, loss: 1.391, 27232/28000 datapoints
2025-03-06 20:39:34,719 - INFO - validation batch 1, loss: 1.031, 32/6976 datapoints
2025-03-06 20:39:34,769 - INFO - validation batch 51, loss: 1.739, 1632/6976 datapoints
2025-03-06 20:39:34,828 - INFO - validation batch 101, loss: 1.410, 3232/6976 datapoints
2025-03-06 20:39:34,894 - INFO - validation batch 151, loss: 1.783, 4832/6976 datapoints
2025-03-06 20:39:34,945 - INFO - validation batch 201, loss: 0.951, 6432/6976 datapoints
2025-03-06 20:39:34,961 - INFO - Epoch 39/800 done.
2025-03-06 20:39:34,961 - INFO - Final validation performance:
Loss: 1.383, top-1 acc: 0.493top-5 acc: 0.493
2025-03-06 20:39:34,961 - INFO - Beginning epoch 40/800
2025-03-06 20:39:34,965 - INFO - training batch 1, loss: 1.694, 32/28000 datapoints
2025-03-06 20:39:35,088 - INFO - training batch 51, loss: 1.656, 1632/28000 datapoints
2025-03-06 20:39:35,211 - INFO - training batch 101, loss: 1.178, 3232/28000 datapoints
2025-03-06 20:39:35,335 - INFO - training batch 151, loss: 1.737, 4832/28000 datapoints
2025-03-06 20:39:35,458 - INFO - training batch 201, loss: 1.560, 6432/28000 datapoints
2025-03-06 20:39:35,580 - INFO - training batch 251, loss: 1.354, 8032/28000 datapoints
2025-03-06 20:39:35,703 - INFO - training batch 301, loss: 1.551, 9632/28000 datapoints
2025-03-06 20:39:35,825 - INFO - training batch 351, loss: 1.523, 11232/28000 datapoints
2025-03-06 20:39:35,946 - INFO - training batch 401, loss: 1.498, 12832/28000 datapoints
2025-03-06 20:39:36,070 - INFO - training batch 451, loss: 1.453, 14432/28000 datapoints
2025-03-06 20:39:36,190 - INFO - training batch 501, loss: 1.251, 16032/28000 datapoints
2025-03-06 20:39:36,313 - INFO - training batch 551, loss: 1.458, 17632/28000 datapoints
2025-03-06 20:39:36,438 - INFO - training batch 601, loss: 1.492, 19232/28000 datapoints
2025-03-06 20:39:36,559 - INFO - training batch 651, loss: 1.160, 20832/28000 datapoints
2025-03-06 20:39:36,683 - INFO - training batch 701, loss: 1.223, 22432/28000 datapoints
2025-03-06 20:39:36,805 - INFO - training batch 751, loss: 1.599, 24032/28000 datapoints
2025-03-06 20:39:36,926 - INFO - training batch 801, loss: 1.275, 25632/28000 datapoints
2025-03-06 20:39:37,049 - INFO - training batch 851, loss: 1.389, 27232/28000 datapoints
2025-03-06 20:39:37,110 - INFO - validation batch 1, loss: 1.027, 32/6976 datapoints
2025-03-06 20:39:37,159 - INFO - validation batch 51, loss: 1.740, 1632/6976 datapoints
2025-03-06 20:39:37,209 - INFO - validation batch 101, loss: 1.409, 3232/6976 datapoints
2025-03-06 20:39:37,259 - INFO - validation batch 151, loss: 1.777, 4832/6976 datapoints
2025-03-06 20:39:37,307 - INFO - validation batch 201, loss: 0.945, 6432/6976 datapoints
2025-03-06 20:39:37,326 - INFO - Epoch 40/800 done.
2025-03-06 20:39:37,326 - INFO - Final validation performance:
Loss: 1.379, top-1 acc: 0.493top-5 acc: 0.493
2025-03-06 20:39:37,327 - INFO - Beginning epoch 41/800
2025-03-06 20:39:37,331 - INFO - training batch 1, loss: 1.687, 32/28000 datapoints
2025-03-06 20:39:37,460 - INFO - training batch 51, loss: 1.651, 1632/28000 datapoints
2025-03-06 20:39:37,581 - INFO - training batch 101, loss: 1.173, 3232/28000 datapoints
2025-03-06 20:39:37,718 - INFO - training batch 151, loss: 1.734, 4832/28000 datapoints
2025-03-06 20:39:37,841 - INFO - training batch 201, loss: 1.557, 6432/28000 datapoints
2025-03-06 20:39:37,962 - INFO - training batch 251, loss: 1.347, 8032/28000 datapoints
2025-03-06 20:39:38,085 - INFO - training batch 301, loss: 1.548, 9632/28000 datapoints
2025-03-06 20:39:38,204 - INFO - training batch 351, loss: 1.518, 11232/28000 datapoints
2025-03-06 20:39:38,339 - INFO - training batch 401, loss: 1.494, 12832/28000 datapoints
2025-03-06 20:39:38,468 - INFO - training batch 451, loss: 1.448, 14432/28000 datapoints
2025-03-06 20:39:38,595 - INFO - training batch 501, loss: 1.251, 16032/28000 datapoints
2025-03-06 20:39:38,720 - INFO - training batch 551, loss: 1.455, 17632/28000 datapoints
2025-03-06 20:39:38,848 - INFO - training batch 601, loss: 1.489, 19232/28000 datapoints
2025-03-06 20:39:38,971 - INFO - training batch 651, loss: 1.154, 20832/28000 datapoints
2025-03-06 20:39:39,103 - INFO - training batch 701, loss: 1.221, 22432/28000 datapoints
2025-03-06 20:39:39,229 - INFO - training batch 751, loss: 1.595, 24032/28000 datapoints
2025-03-06 20:39:39,351 - INFO - training batch 801, loss: 1.270, 25632/28000 datapoints
2025-03-06 20:39:39,472 - INFO - training batch 851, loss: 1.388, 27232/28000 datapoints
2025-03-06 20:39:39,534 - INFO - validation batch 1, loss: 1.022, 32/6976 datapoints
2025-03-06 20:39:39,581 - INFO - validation batch 51, loss: 1.740, 1632/6976 datapoints
2025-03-06 20:39:39,626 - INFO - validation batch 101, loss: 1.408, 3232/6976 datapoints
2025-03-06 20:39:39,672 - INFO - validation batch 151, loss: 1.771, 4832/6976 datapoints
2025-03-06 20:39:39,716 - INFO - validation batch 201, loss: 0.938, 6432/6976 datapoints
2025-03-06 20:39:39,731 - INFO - Epoch 41/800 done.
2025-03-06 20:39:39,731 - INFO - Final validation performance:
Loss: 1.376, top-1 acc: 0.495top-5 acc: 0.495
2025-03-06 20:39:39,732 - INFO - Beginning epoch 42/800
2025-03-06 20:39:39,736 - INFO - training batch 1, loss: 1.681, 32/28000 datapoints
2025-03-06 20:39:39,857 - INFO - training batch 51, loss: 1.646, 1632/28000 datapoints
2025-03-06 20:39:39,973 - INFO - training batch 101, loss: 1.169, 3232/28000 datapoints
2025-03-06 20:39:40,137 - INFO - training batch 151, loss: 1.730, 4832/28000 datapoints
2025-03-06 20:39:40,264 - INFO - training batch 201, loss: 1.552, 6432/28000 datapoints
2025-03-06 20:39:40,388 - INFO - training batch 251, loss: 1.340, 8032/28000 datapoints
2025-03-06 20:39:40,510 - INFO - training batch 301, loss: 1.545, 9632/28000 datapoints
2025-03-06 20:39:40,628 - INFO - training batch 351, loss: 1.514, 11232/28000 datapoints
2025-03-06 20:39:40,750 - INFO - training batch 401, loss: 1.490, 12832/28000 datapoints
2025-03-06 20:39:40,873 - INFO - training batch 451, loss: 1.444, 14432/28000 datapoints
2025-03-06 20:39:40,989 - INFO - training batch 501, loss: 1.250, 16032/28000 datapoints
2025-03-06 20:39:41,107 - INFO - training batch 551, loss: 1.451, 17632/28000 datapoints
2025-03-06 20:39:41,224 - INFO - training batch 601, loss: 1.486, 19232/28000 datapoints
2025-03-06 20:39:41,344 - INFO - training batch 651, loss: 1.149, 20832/28000 datapoints
2025-03-06 20:39:41,463 - INFO - training batch 701, loss: 1.219, 22432/28000 datapoints
2025-03-06 20:39:41,580 - INFO - training batch 751, loss: 1.591, 24032/28000 datapoints
2025-03-06 20:39:41,698 - INFO - training batch 801, loss: 1.266, 25632/28000 datapoints
2025-03-06 20:39:41,816 - INFO - training batch 851, loss: 1.386, 27232/28000 datapoints
2025-03-06 20:39:41,876 - INFO - validation batch 1, loss: 1.019, 32/6976 datapoints
2025-03-06 20:39:41,919 - INFO - validation batch 51, loss: 1.740, 1632/6976 datapoints
2025-03-06 20:39:41,962 - INFO - validation batch 101, loss: 1.406, 3232/6976 datapoints
2025-03-06 20:39:42,005 - INFO - validation batch 151, loss: 1.766, 4832/6976 datapoints
2025-03-06 20:39:42,048 - INFO - validation batch 201, loss: 0.932, 6432/6976 datapoints
2025-03-06 20:39:42,063 - INFO - Epoch 42/800 done.
2025-03-06 20:39:42,063 - INFO - Final validation performance:
Loss: 1.372, top-1 acc: 0.496top-5 acc: 0.496
2025-03-06 20:39:42,063 - INFO - Beginning epoch 43/800
2025-03-06 20:39:42,067 - INFO - training batch 1, loss: 1.675, 32/28000 datapoints
2025-03-06 20:39:42,185 - INFO - training batch 51, loss: 1.640, 1632/28000 datapoints
2025-03-06 20:39:42,306 - INFO - training batch 101, loss: 1.165, 3232/28000 datapoints
2025-03-06 20:39:42,427 - INFO - training batch 151, loss: 1.727, 4832/28000 datapoints
2025-03-06 20:39:42,547 - INFO - training batch 201, loss: 1.548, 6432/28000 datapoints
2025-03-06 20:39:42,667 - INFO - training batch 251, loss: 1.335, 8032/28000 datapoints
2025-03-06 20:39:42,784 - INFO - training batch 301, loss: 1.543, 9632/28000 datapoints
2025-03-06 20:39:42,903 - INFO - training batch 351, loss: 1.511, 11232/28000 datapoints
2025-03-06 20:39:43,021 - INFO - training batch 401, loss: 1.487, 12832/28000 datapoints
2025-03-06 20:39:43,140 - INFO - training batch 451, loss: 1.440, 14432/28000 datapoints
2025-03-06 20:39:43,260 - INFO - training batch 501, loss: 1.250, 16032/28000 datapoints
2025-03-06 20:39:43,379 - INFO - training batch 551, loss: 1.448, 17632/28000 datapoints
2025-03-06 20:39:43,497 - INFO - training batch 601, loss: 1.484, 19232/28000 datapoints
2025-03-06 20:39:43,617 - INFO - training batch 651, loss: 1.144, 20832/28000 datapoints
2025-03-06 20:39:43,737 - INFO - training batch 701, loss: 1.218, 22432/28000 datapoints
2025-03-06 20:39:43,855 - INFO - training batch 751, loss: 1.587, 24032/28000 datapoints
2025-03-06 20:39:43,971 - INFO - training batch 801, loss: 1.261, 25632/28000 datapoints
2025-03-06 20:39:44,087 - INFO - training batch 851, loss: 1.385, 27232/28000 datapoints
2025-03-06 20:39:44,145 - INFO - validation batch 1, loss: 1.015, 32/6976 datapoints
2025-03-06 20:39:44,188 - INFO - validation batch 51, loss: 1.739, 1632/6976 datapoints
2025-03-06 20:39:44,231 - INFO - validation batch 101, loss: 1.405, 3232/6976 datapoints
2025-03-06 20:39:44,275 - INFO - validation batch 151, loss: 1.760, 4832/6976 datapoints
2025-03-06 20:39:44,318 - INFO - validation batch 201, loss: 0.927, 6432/6976 datapoints
2025-03-06 20:39:44,335 - INFO - Epoch 43/800 done.
2025-03-06 20:39:44,335 - INFO - Final validation performance:
Loss: 1.369, top-1 acc: 0.496top-5 acc: 0.496
2025-03-06 20:39:44,336 - INFO - Beginning epoch 44/800
2025-03-06 20:39:44,340 - INFO - training batch 1, loss: 1.668, 32/28000 datapoints
2025-03-06 20:39:44,475 - INFO - training batch 51, loss: 1.635, 1632/28000 datapoints
2025-03-06 20:39:44,602 - INFO - training batch 101, loss: 1.161, 3232/28000 datapoints
2025-03-06 20:39:44,722 - INFO - training batch 151, loss: 1.724, 4832/28000 datapoints
2025-03-06 20:39:44,843 - INFO - training batch 201, loss: 1.545, 6432/28000 datapoints
2025-03-06 20:39:44,999 - INFO - training batch 251, loss: 1.329, 8032/28000 datapoints
2025-03-06 20:39:45,124 - INFO - training batch 301, loss: 1.540, 9632/28000 datapoints
2025-03-06 20:39:45,241 - INFO - training batch 351, loss: 1.507, 11232/28000 datapoints
2025-03-06 20:39:45,364 - INFO - training batch 401, loss: 1.484, 12832/28000 datapoints
2025-03-06 20:39:45,495 - INFO - training batch 451, loss: 1.436, 14432/28000 datapoints
2025-03-06 20:39:45,646 - INFO - training batch 501, loss: 1.250, 16032/28000 datapoints
2025-03-06 20:39:45,764 - INFO - training batch 551, loss: 1.444, 17632/28000 datapoints
2025-03-06 20:39:45,884 - INFO - training batch 601, loss: 1.482, 19232/28000 datapoints
2025-03-06 20:39:46,001 - INFO - training batch 651, loss: 1.139, 20832/28000 datapoints
2025-03-06 20:39:46,119 - INFO - training batch 701, loss: 1.216, 22432/28000 datapoints
2025-03-06 20:39:46,235 - INFO - training batch 751, loss: 1.584, 24032/28000 datapoints
2025-03-06 20:39:46,352 - INFO - training batch 801, loss: 1.257, 25632/28000 datapoints
2025-03-06 20:39:46,477 - INFO - training batch 851, loss: 1.383, 27232/28000 datapoints
2025-03-06 20:39:46,535 - INFO - validation batch 1, loss: 1.011, 32/6976 datapoints
2025-03-06 20:39:46,579 - INFO - validation batch 51, loss: 1.739, 1632/6976 datapoints
2025-03-06 20:39:46,623 - INFO - validation batch 101, loss: 1.403, 3232/6976 datapoints
2025-03-06 20:39:46,672 - INFO - validation batch 151, loss: 1.755, 4832/6976 datapoints
2025-03-06 20:39:46,716 - INFO - validation batch 201, loss: 0.922, 6432/6976 datapoints
2025-03-06 20:39:46,731 - INFO - Epoch 44/800 done.
2025-03-06 20:39:46,731 - INFO - Final validation performance:
Loss: 1.366, top-1 acc: 0.498top-5 acc: 0.498
2025-03-06 20:39:46,732 - INFO - Beginning epoch 45/800
2025-03-06 20:39:46,736 - INFO - training batch 1, loss: 1.662, 32/28000 datapoints
2025-03-06 20:39:46,859 - INFO - training batch 51, loss: 1.630, 1632/28000 datapoints
2025-03-06 20:39:46,975 - INFO - training batch 101, loss: 1.157, 3232/28000 datapoints
2025-03-06 20:39:47,092 - INFO - training batch 151, loss: 1.721, 4832/28000 datapoints
2025-03-06 20:39:47,209 - INFO - training batch 201, loss: 1.541, 6432/28000 datapoints
2025-03-06 20:39:47,328 - INFO - training batch 251, loss: 1.323, 8032/28000 datapoints
2025-03-06 20:39:47,446 - INFO - training batch 301, loss: 1.538, 9632/28000 datapoints
2025-03-06 20:39:47,563 - INFO - training batch 351, loss: 1.502, 11232/28000 datapoints
2025-03-06 20:39:47,685 - INFO - training batch 401, loss: 1.481, 12832/28000 datapoints
2025-03-06 20:39:47,805 - INFO - training batch 451, loss: 1.432, 14432/28000 datapoints
2025-03-06 20:39:47,925 - INFO - training batch 501, loss: 1.250, 16032/28000 datapoints
2025-03-06 20:39:48,042 - INFO - training batch 551, loss: 1.441, 17632/28000 datapoints
2025-03-06 20:39:48,159 - INFO - training batch 601, loss: 1.479, 19232/28000 datapoints
2025-03-06 20:39:48,277 - INFO - training batch 651, loss: 1.134, 20832/28000 datapoints
2025-03-06 20:39:48,394 - INFO - training batch 701, loss: 1.215, 22432/28000 datapoints
2025-03-06 20:39:48,518 - INFO - training batch 751, loss: 1.581, 24032/28000 datapoints
2025-03-06 20:39:48,648 - INFO - training batch 801, loss: 1.253, 25632/28000 datapoints
2025-03-06 20:39:48,777 - INFO - training batch 851, loss: 1.382, 27232/28000 datapoints
2025-03-06 20:39:48,837 - INFO - validation batch 1, loss: 1.008, 32/6976 datapoints
2025-03-06 20:39:48,881 - INFO - validation batch 51, loss: 1.739, 1632/6976 datapoints
2025-03-06 20:39:48,926 - INFO - validation batch 101, loss: 1.402, 3232/6976 datapoints
2025-03-06 20:39:48,970 - INFO - validation batch 151, loss: 1.750, 4832/6976 datapoints
2025-03-06 20:39:49,013 - INFO - validation batch 201, loss: 0.916, 6432/6976 datapoints
2025-03-06 20:39:49,028 - INFO - Epoch 45/800 done.
2025-03-06 20:39:49,028 - INFO - Final validation performance:
Loss: 1.363, top-1 acc: 0.498top-5 acc: 0.498
2025-03-06 20:39:49,028 - INFO - Beginning epoch 46/800
2025-03-06 20:39:49,032 - INFO - training batch 1, loss: 1.657, 32/28000 datapoints
2025-03-06 20:39:49,149 - INFO - training batch 51, loss: 1.626, 1632/28000 datapoints
2025-03-06 20:39:49,266 - INFO - training batch 101, loss: 1.154, 3232/28000 datapoints
2025-03-06 20:39:49,383 - INFO - training batch 151, loss: 1.718, 4832/28000 datapoints
2025-03-06 20:39:49,505 - INFO - training batch 201, loss: 1.538, 6432/28000 datapoints
2025-03-06 20:39:49,621 - INFO - training batch 251, loss: 1.318, 8032/28000 datapoints
2025-03-06 20:39:49,742 - INFO - training batch 301, loss: 1.535, 9632/28000 datapoints
2025-03-06 20:39:49,859 - INFO - training batch 351, loss: 1.498, 11232/28000 datapoints
2025-03-06 20:39:49,977 - INFO - training batch 401, loss: 1.478, 12832/28000 datapoints
2025-03-06 20:39:50,095 - INFO - training batch 451, loss: 1.429, 14432/28000 datapoints
2025-03-06 20:39:50,214 - INFO - training batch 501, loss: 1.250, 16032/28000 datapoints
2025-03-06 20:39:50,331 - INFO - training batch 551, loss: 1.438, 17632/28000 datapoints
2025-03-06 20:39:50,453 - INFO - training batch 601, loss: 1.477, 19232/28000 datapoints
2025-03-06 20:39:50,576 - INFO - training batch 651, loss: 1.130, 20832/28000 datapoints
2025-03-06 20:39:50,709 - INFO - training batch 701, loss: 1.213, 22432/28000 datapoints
2025-03-06 20:39:50,826 - INFO - training batch 751, loss: 1.578, 24032/28000 datapoints
2025-03-06 20:39:50,945 - INFO - training batch 801, loss: 1.249, 25632/28000 datapoints
2025-03-06 20:39:51,068 - INFO - training batch 851, loss: 1.381, 27232/28000 datapoints
2025-03-06 20:39:51,128 - INFO - validation batch 1, loss: 1.004, 32/6976 datapoints
2025-03-06 20:39:51,170 - INFO - validation batch 51, loss: 1.738, 1632/6976 datapoints
2025-03-06 20:39:51,216 - INFO - validation batch 101, loss: 1.402, 3232/6976 datapoints
2025-03-06 20:39:51,261 - INFO - validation batch 151, loss: 1.745, 4832/6976 datapoints
2025-03-06 20:39:51,303 - INFO - validation batch 201, loss: 0.912, 6432/6976 datapoints
2025-03-06 20:39:51,318 - INFO - Epoch 46/800 done.
2025-03-06 20:39:51,318 - INFO - Final validation performance:
Loss: 1.360, top-1 acc: 0.497top-5 acc: 0.497
2025-03-06 20:39:51,319 - INFO - Beginning epoch 47/800
2025-03-06 20:39:51,322 - INFO - training batch 1, loss: 1.650, 32/28000 datapoints
2025-03-06 20:39:51,447 - INFO - training batch 51, loss: 1.621, 1632/28000 datapoints
2025-03-06 20:39:51,567 - INFO - training batch 101, loss: 1.151, 3232/28000 datapoints
2025-03-06 20:39:51,700 - INFO - training batch 151, loss: 1.715, 4832/28000 datapoints
2025-03-06 20:39:51,820 - INFO - training batch 201, loss: 1.535, 6432/28000 datapoints
2025-03-06 20:39:51,942 - INFO - training batch 251, loss: 1.312, 8032/28000 datapoints
2025-03-06 20:39:52,066 - INFO - training batch 301, loss: 1.532, 9632/28000 datapoints
2025-03-06 20:39:52,187 - INFO - training batch 351, loss: 1.494, 11232/28000 datapoints
2025-03-06 20:39:52,312 - INFO - training batch 401, loss: 1.475, 12832/28000 datapoints
2025-03-06 20:39:52,433 - INFO - training batch 451, loss: 1.425, 14432/28000 datapoints
2025-03-06 20:39:52,558 - INFO - training batch 501, loss: 1.250, 16032/28000 datapoints
2025-03-06 20:39:52,685 - INFO - training batch 551, loss: 1.435, 17632/28000 datapoints
2025-03-06 20:39:52,806 - INFO - training batch 601, loss: 1.475, 19232/28000 datapoints
2025-03-06 20:39:52,927 - INFO - training batch 651, loss: 1.126, 20832/28000 datapoints
2025-03-06 20:39:53,051 - INFO - training batch 701, loss: 1.211, 22432/28000 datapoints
2025-03-06 20:39:53,173 - INFO - training batch 751, loss: 1.575, 24032/28000 datapoints
2025-03-06 20:39:53,297 - INFO - training batch 801, loss: 1.245, 25632/28000 datapoints
2025-03-06 20:39:53,419 - INFO - training batch 851, loss: 1.380, 27232/28000 datapoints
2025-03-06 20:39:53,489 - INFO - validation batch 1, loss: 1.001, 32/6976 datapoints
2025-03-06 20:39:53,539 - INFO - validation batch 51, loss: 1.738, 1632/6976 datapoints
2025-03-06 20:39:53,590 - INFO - validation batch 101, loss: 1.400, 3232/6976 datapoints
2025-03-06 20:39:53,641 - INFO - validation batch 151, loss: 1.741, 4832/6976 datapoints
2025-03-06 20:39:53,687 - INFO - validation batch 201, loss: 0.907, 6432/6976 datapoints
2025-03-06 20:39:53,703 - INFO - Epoch 47/800 done.
2025-03-06 20:39:53,703 - INFO - Final validation performance:
Loss: 1.357, top-1 acc: 0.498top-5 acc: 0.498
2025-03-06 20:39:53,703 - INFO - Beginning epoch 48/800
2025-03-06 20:39:53,707 - INFO - training batch 1, loss: 1.645, 32/28000 datapoints
2025-03-06 20:39:53,829 - INFO - training batch 51, loss: 1.617, 1632/28000 datapoints
2025-03-06 20:39:53,953 - INFO - training batch 101, loss: 1.147, 3232/28000 datapoints
2025-03-06 20:39:54,075 - INFO - training batch 151, loss: 1.712, 4832/28000 datapoints
2025-03-06 20:39:54,196 - INFO - training batch 201, loss: 1.532, 6432/28000 datapoints
2025-03-06 20:39:54,316 - INFO - training batch 251, loss: 1.307, 8032/28000 datapoints
2025-03-06 20:39:54,436 - INFO - training batch 301, loss: 1.530, 9632/28000 datapoints
2025-03-06 20:39:54,561 - INFO - training batch 351, loss: 1.490, 11232/28000 datapoints
2025-03-06 20:39:54,684 - INFO - training batch 401, loss: 1.472, 12832/28000 datapoints
2025-03-06 20:39:54,805 - INFO - training batch 451, loss: 1.422, 14432/28000 datapoints
2025-03-06 20:39:54,933 - INFO - training batch 501, loss: 1.249, 16032/28000 datapoints
2025-03-06 20:39:55,083 - INFO - training batch 551, loss: 1.431, 17632/28000 datapoints
2025-03-06 20:39:55,206 - INFO - training batch 601, loss: 1.473, 19232/28000 datapoints
2025-03-06 20:39:55,327 - INFO - training batch 651, loss: 1.122, 20832/28000 datapoints
2025-03-06 20:39:55,449 - INFO - training batch 701, loss: 1.210, 22432/28000 datapoints
2025-03-06 20:39:55,572 - INFO - training batch 751, loss: 1.572, 24032/28000 datapoints
2025-03-06 20:39:55,698 - INFO - training batch 801, loss: 1.242, 25632/28000 datapoints
2025-03-06 20:39:55,820 - INFO - training batch 851, loss: 1.379, 27232/28000 datapoints
2025-03-06 20:39:55,880 - INFO - validation batch 1, loss: 0.998, 32/6976 datapoints
2025-03-06 20:39:55,926 - INFO - validation batch 51, loss: 1.737, 1632/6976 datapoints
2025-03-06 20:39:55,973 - INFO - validation batch 101, loss: 1.399, 3232/6976 datapoints
2025-03-06 20:39:56,017 - INFO - validation batch 151, loss: 1.737, 4832/6976 datapoints
2025-03-06 20:39:56,060 - INFO - validation batch 201, loss: 0.902, 6432/6976 datapoints
2025-03-06 20:39:56,075 - INFO - Epoch 48/800 done.
2025-03-06 20:39:56,075 - INFO - Final validation performance:
Loss: 1.355, top-1 acc: 0.497top-5 acc: 0.497
2025-03-06 20:39:56,076 - INFO - Beginning epoch 49/800
2025-03-06 20:39:56,079 - INFO - training batch 1, loss: 1.639, 32/28000 datapoints
2025-03-06 20:39:56,198 - INFO - training batch 51, loss: 1.613, 1632/28000 datapoints
2025-03-06 20:39:56,315 - INFO - training batch 101, loss: 1.144, 3232/28000 datapoints
2025-03-06 20:39:56,433 - INFO - training batch 151, loss: 1.709, 4832/28000 datapoints
2025-03-06 20:39:56,559 - INFO - training batch 201, loss: 1.529, 6432/28000 datapoints
2025-03-06 20:39:56,695 - INFO - training batch 251, loss: 1.303, 8032/28000 datapoints
2025-03-06 20:39:56,813 - INFO - training batch 301, loss: 1.528, 9632/28000 datapoints
2025-03-06 20:39:56,931 - INFO - training batch 351, loss: 1.486, 11232/28000 datapoints
2025-03-06 20:39:57,049 - INFO - training batch 401, loss: 1.469, 12832/28000 datapoints
2025-03-06 20:39:57,173 - INFO - training batch 451, loss: 1.419, 14432/28000 datapoints
2025-03-06 20:39:57,295 - INFO - training batch 501, loss: 1.250, 16032/28000 datapoints
2025-03-06 20:39:57,412 - INFO - training batch 551, loss: 1.428, 17632/28000 datapoints
2025-03-06 20:39:57,537 - INFO - training batch 601, loss: 1.471, 19232/28000 datapoints
2025-03-06 20:39:57,659 - INFO - training batch 651, loss: 1.118, 20832/28000 datapoints
2025-03-06 20:39:57,775 - INFO - training batch 701, loss: 1.208, 22432/28000 datapoints
2025-03-06 20:39:57,893 - INFO - training batch 751, loss: 1.569, 24032/28000 datapoints
2025-03-06 20:39:58,013 - INFO - training batch 801, loss: 1.238, 25632/28000 datapoints
2025-03-06 20:39:58,130 - INFO - training batch 851, loss: 1.378, 27232/28000 datapoints
2025-03-06 20:39:58,188 - INFO - validation batch 1, loss: 0.996, 32/6976 datapoints
2025-03-06 20:39:58,231 - INFO - validation batch 51, loss: 1.736, 1632/6976 datapoints
2025-03-06 20:39:58,274 - INFO - validation batch 101, loss: 1.398, 3232/6976 datapoints
2025-03-06 20:39:58,318 - INFO - validation batch 151, loss: 1.732, 4832/6976 datapoints
2025-03-06 20:39:58,361 - INFO - validation batch 201, loss: 0.898, 6432/6976 datapoints
2025-03-06 20:39:58,376 - INFO - Epoch 49/800 done.
2025-03-06 20:39:58,376 - INFO - Final validation performance:
Loss: 1.352, top-1 acc: 0.497top-5 acc: 0.497
2025-03-06 20:39:58,377 - INFO - Beginning epoch 50/800
2025-03-06 20:39:58,380 - INFO - training batch 1, loss: 1.634, 32/28000 datapoints
2025-03-06 20:39:58,504 - INFO - training batch 51, loss: 1.609, 1632/28000 datapoints
2025-03-06 20:39:58,629 - INFO - training batch 101, loss: 1.141, 3232/28000 datapoints
2025-03-06 20:39:58,751 - INFO - training batch 151, loss: 1.707, 4832/28000 datapoints
2025-03-06 20:39:58,869 - INFO - training batch 201, loss: 1.526, 6432/28000 datapoints
2025-03-06 20:39:58,988 - INFO - training batch 251, loss: 1.298, 8032/28000 datapoints
2025-03-06 20:39:59,106 - INFO - training batch 301, loss: 1.526, 9632/28000 datapoints
2025-03-06 20:39:59,222 - INFO - training batch 351, loss: 1.482, 11232/28000 datapoints
2025-03-06 20:39:59,340 - INFO - training batch 401, loss: 1.467, 12832/28000 datapoints
2025-03-06 20:39:59,457 - INFO - training batch 451, loss: 1.415, 14432/28000 datapoints
2025-03-06 20:39:59,576 - INFO - training batch 501, loss: 1.250, 16032/28000 datapoints
2025-03-06 20:39:59,697 - INFO - training batch 551, loss: 1.426, 17632/28000 datapoints
2025-03-06 20:39:59,814 - INFO - training batch 601, loss: 1.469, 19232/28000 datapoints
2025-03-06 20:39:59,931 - INFO - training batch 651, loss: 1.114, 20832/28000 datapoints
2025-03-06 20:40:00,051 - INFO - training batch 701, loss: 1.207, 22432/28000 datapoints
2025-03-06 20:40:00,169 - INFO - training batch 751, loss: 1.566, 24032/28000 datapoints
2025-03-06 20:40:00,286 - INFO - training batch 801, loss: 1.234, 25632/28000 datapoints
2025-03-06 20:40:00,402 - INFO - training batch 851, loss: 1.378, 27232/28000 datapoints
2025-03-06 20:40:00,461 - INFO - validation batch 1, loss: 0.993, 32/6976 datapoints
2025-03-06 20:40:00,510 - INFO - validation batch 51, loss: 1.736, 1632/6976 datapoints
2025-03-06 20:40:00,556 - INFO - validation batch 101, loss: 1.396, 3232/6976 datapoints
2025-03-06 20:40:00,600 - INFO - validation batch 151, loss: 1.728, 4832/6976 datapoints
2025-03-06 20:40:00,646 - INFO - validation batch 201, loss: 0.894, 6432/6976 datapoints
2025-03-06 20:40:00,662 - INFO - Epoch 50/800 done.
2025-03-06 20:40:00,662 - INFO - Final validation performance:
Loss: 1.349, top-1 acc: 0.497top-5 acc: 0.497
2025-03-06 20:40:00,663 - INFO - Beginning epoch 51/800
2025-03-06 20:40:00,666 - INFO - training batch 1, loss: 1.629, 32/28000 datapoints
2025-03-06 20:40:00,787 - INFO - training batch 51, loss: 1.606, 1632/28000 datapoints
2025-03-06 20:40:00,904 - INFO - training batch 101, loss: 1.138, 3232/28000 datapoints
2025-03-06 20:40:01,021 - INFO - training batch 151, loss: 1.704, 4832/28000 datapoints
2025-03-06 20:40:01,142 - INFO - training batch 201, loss: 1.523, 6432/28000 datapoints
2025-03-06 20:40:01,267 - INFO - training batch 251, loss: 1.294, 8032/28000 datapoints
2025-03-06 20:40:01,385 - INFO - training batch 301, loss: 1.524, 9632/28000 datapoints
2025-03-06 20:40:01,503 - INFO - training batch 351, loss: 1.478, 11232/28000 datapoints
2025-03-06 20:40:01,623 - INFO - training batch 401, loss: 1.464, 12832/28000 datapoints
2025-03-06 20:40:01,743 - INFO - training batch 451, loss: 1.412, 14432/28000 datapoints
2025-03-06 20:40:01,860 - INFO - training batch 501, loss: 1.250, 16032/28000 datapoints
2025-03-06 20:40:01,980 - INFO - training batch 551, loss: 1.424, 17632/28000 datapoints
2025-03-06 20:40:02,098 - INFO - training batch 601, loss: 1.467, 19232/28000 datapoints
2025-03-06 20:40:02,216 - INFO - training batch 651, loss: 1.111, 20832/28000 datapoints
2025-03-06 20:40:02,331 - INFO - training batch 701, loss: 1.205, 22432/28000 datapoints
2025-03-06 20:40:02,449 - INFO - training batch 751, loss: 1.562, 24032/28000 datapoints
2025-03-06 20:40:02,572 - INFO - training batch 801, loss: 1.231, 25632/28000 datapoints
2025-03-06 20:40:02,692 - INFO - training batch 851, loss: 1.377, 27232/28000 datapoints
2025-03-06 20:40:02,758 - INFO - validation batch 1, loss: 0.990, 32/6976 datapoints
2025-03-06 20:40:02,807 - INFO - validation batch 51, loss: 1.735, 1632/6976 datapoints
2025-03-06 20:40:02,850 - INFO - validation batch 101, loss: 1.395, 3232/6976 datapoints
2025-03-06 20:40:02,894 - INFO - validation batch 151, loss: 1.724, 4832/6976 datapoints
2025-03-06 20:40:02,936 - INFO - validation batch 201, loss: 0.890, 6432/6976 datapoints
2025-03-06 20:40:02,951 - INFO - Epoch 51/800 done.
2025-03-06 20:40:02,952 - INFO - Final validation performance:
Loss: 1.347, top-1 acc: 0.498top-5 acc: 0.498
2025-03-06 20:40:02,952 - INFO - Beginning epoch 52/800
2025-03-06 20:40:02,955 - INFO - training batch 1, loss: 1.624, 32/28000 datapoints
2025-03-06 20:40:03,076 - INFO - training batch 51, loss: 1.602, 1632/28000 datapoints
2025-03-06 20:40:03,199 - INFO - training batch 101, loss: 1.135, 3232/28000 datapoints
2025-03-06 20:40:03,320 - INFO - training batch 151, loss: 1.702, 4832/28000 datapoints
2025-03-06 20:40:03,437 - INFO - training batch 201, loss: 1.520, 6432/28000 datapoints
2025-03-06 20:40:03,555 - INFO - training batch 251, loss: 1.290, 8032/28000 datapoints
2025-03-06 20:40:03,678 - INFO - training batch 301, loss: 1.522, 9632/28000 datapoints
2025-03-06 20:40:03,798 - INFO - training batch 351, loss: 1.475, 11232/28000 datapoints
2025-03-06 20:40:03,917 - INFO - training batch 401, loss: 1.461, 12832/28000 datapoints
2025-03-06 20:40:04,033 - INFO - training batch 451, loss: 1.409, 14432/28000 datapoints
2025-03-06 20:40:04,153 - INFO - training batch 501, loss: 1.250, 16032/28000 datapoints
2025-03-06 20:40:04,271 - INFO - training batch 551, loss: 1.421, 17632/28000 datapoints
2025-03-06 20:40:04,388 - INFO - training batch 601, loss: 1.465, 19232/28000 datapoints
2025-03-06 20:40:04,511 - INFO - training batch 651, loss: 1.107, 20832/28000 datapoints
2025-03-06 20:40:04,631 - INFO - training batch 701, loss: 1.204, 22432/28000 datapoints
2025-03-06 20:40:04,749 - INFO - training batch 751, loss: 1.559, 24032/28000 datapoints
2025-03-06 20:40:04,868 - INFO - training batch 801, loss: 1.228, 25632/28000 datapoints
2025-03-06 20:40:04,989 - INFO - training batch 851, loss: 1.376, 27232/28000 datapoints
2025-03-06 20:40:05,048 - INFO - validation batch 1, loss: 0.988, 32/6976 datapoints
2025-03-06 20:40:05,094 - INFO - validation batch 51, loss: 1.734, 1632/6976 datapoints
2025-03-06 20:40:05,158 - INFO - validation batch 101, loss: 1.394, 3232/6976 datapoints
2025-03-06 20:40:05,211 - INFO - validation batch 151, loss: 1.720, 4832/6976 datapoints
2025-03-06 20:40:05,255 - INFO - validation batch 201, loss: 0.887, 6432/6976 datapoints
2025-03-06 20:40:05,272 - INFO - Epoch 52/800 done.
2025-03-06 20:40:05,272 - INFO - Final validation performance:
Loss: 1.344, top-1 acc: 0.499top-5 acc: 0.499
2025-03-06 20:40:05,272 - INFO - Beginning epoch 53/800
2025-03-06 20:40:05,276 - INFO - training batch 1, loss: 1.619, 32/28000 datapoints
2025-03-06 20:40:05,393 - INFO - training batch 51, loss: 1.599, 1632/28000 datapoints
2025-03-06 20:40:05,511 - INFO - training batch 101, loss: 1.132, 3232/28000 datapoints
2025-03-06 20:40:05,636 - INFO - training batch 151, loss: 1.699, 4832/28000 datapoints
2025-03-06 20:40:05,754 - INFO - training batch 201, loss: 1.518, 6432/28000 datapoints
2025-03-06 20:40:05,873 - INFO - training batch 251, loss: 1.286, 8032/28000 datapoints
2025-03-06 20:40:05,990 - INFO - training batch 301, loss: 1.521, 9632/28000 datapoints
2025-03-06 20:40:06,105 - INFO - training batch 351, loss: 1.471, 11232/28000 datapoints
2025-03-06 20:40:06,225 - INFO - training batch 401, loss: 1.459, 12832/28000 datapoints
2025-03-06 20:40:06,343 - INFO - training batch 451, loss: 1.406, 14432/28000 datapoints
2025-03-06 20:40:06,460 - INFO - training batch 501, loss: 1.249, 16032/28000 datapoints
2025-03-06 20:40:06,583 - INFO - training batch 551, loss: 1.419, 17632/28000 datapoints
2025-03-06 20:40:06,705 - INFO - training batch 601, loss: 1.463, 19232/28000 datapoints
2025-03-06 20:40:06,823 - INFO - training batch 651, loss: 1.104, 20832/28000 datapoints
2025-03-06 20:40:06,941 - INFO - training batch 701, loss: 1.203, 22432/28000 datapoints
2025-03-06 20:40:07,059 - INFO - training batch 751, loss: 1.557, 24032/28000 datapoints
2025-03-06 20:40:07,178 - INFO - training batch 801, loss: 1.224, 25632/28000 datapoints
2025-03-06 20:40:07,295 - INFO - training batch 851, loss: 1.376, 27232/28000 datapoints
2025-03-06 20:40:07,353 - INFO - validation batch 1, loss: 0.985, 32/6976 datapoints
2025-03-06 20:40:07,397 - INFO - validation batch 51, loss: 1.733, 1632/6976 datapoints
2025-03-06 20:40:07,441 - INFO - validation batch 101, loss: 1.392, 3232/6976 datapoints
2025-03-06 20:40:07,485 - INFO - validation batch 151, loss: 1.716, 4832/6976 datapoints
2025-03-06 20:40:07,528 - INFO - validation batch 201, loss: 0.884, 6432/6976 datapoints
2025-03-06 20:40:07,544 - INFO - Epoch 53/800 done.
2025-03-06 20:40:07,544 - INFO - Final validation performance:
Loss: 1.342, top-1 acc: 0.500top-5 acc: 0.500
2025-03-06 20:40:07,544 - INFO - Beginning epoch 54/800
2025-03-06 20:40:07,548 - INFO - training batch 1, loss: 1.614, 32/28000 datapoints
2025-03-06 20:40:07,675 - INFO - training batch 51, loss: 1.595, 1632/28000 datapoints
2025-03-06 20:40:07,791 - INFO - training batch 101, loss: 1.130, 3232/28000 datapoints
2025-03-06 20:40:07,912 - INFO - training batch 151, loss: 1.697, 4832/28000 datapoints
2025-03-06 20:40:08,031 - INFO - training batch 201, loss: 1.515, 6432/28000 datapoints
2025-03-06 20:40:08,149 - INFO - training batch 251, loss: 1.282, 8032/28000 datapoints
2025-03-06 20:40:08,268 - INFO - training batch 301, loss: 1.519, 9632/28000 datapoints
2025-03-06 20:40:08,383 - INFO - training batch 351, loss: 1.467, 11232/28000 datapoints
2025-03-06 20:40:08,501 - INFO - training batch 401, loss: 1.456, 12832/28000 datapoints
2025-03-06 20:40:08,627 - INFO - training batch 451, loss: 1.404, 14432/28000 datapoints
2025-03-06 20:40:08,750 - INFO - training batch 501, loss: 1.249, 16032/28000 datapoints
2025-03-06 20:40:08,881 - INFO - training batch 551, loss: 1.416, 17632/28000 datapoints
2025-03-06 20:40:08,998 - INFO - training batch 601, loss: 1.461, 19232/28000 datapoints
2025-03-06 20:40:09,126 - INFO - training batch 651, loss: 1.100, 20832/28000 datapoints
2025-03-06 20:40:09,252 - INFO - training batch 701, loss: 1.202, 22432/28000 datapoints
2025-03-06 20:40:09,373 - INFO - training batch 751, loss: 1.554, 24032/28000 datapoints
2025-03-06 20:40:09,489 - INFO - training batch 801, loss: 1.221, 25632/28000 datapoints
2025-03-06 20:40:09,611 - INFO - training batch 851, loss: 1.375, 27232/28000 datapoints
2025-03-06 20:40:09,674 - INFO - validation batch 1, loss: 0.984, 32/6976 datapoints
2025-03-06 20:40:09,717 - INFO - validation batch 51, loss: 1.732, 1632/6976 datapoints
2025-03-06 20:40:09,760 - INFO - validation batch 101, loss: 1.390, 3232/6976 datapoints
2025-03-06 20:40:09,803 - INFO - validation batch 151, loss: 1.713, 4832/6976 datapoints
2025-03-06 20:40:09,848 - INFO - validation batch 201, loss: 0.880, 6432/6976 datapoints
2025-03-06 20:40:09,863 - INFO - Epoch 54/800 done.
2025-03-06 20:40:09,863 - INFO - Final validation performance:
Loss: 1.340, top-1 acc: 0.500top-5 acc: 0.500
2025-03-06 20:40:09,864 - INFO - Beginning epoch 55/800
2025-03-06 20:40:09,867 - INFO - training batch 1, loss: 1.609, 32/28000 datapoints
2025-03-06 20:40:09,985 - INFO - training batch 51, loss: 1.592, 1632/28000 datapoints
2025-03-06 20:40:10,103 - INFO - training batch 101, loss: 1.127, 3232/28000 datapoints
2025-03-06 20:40:10,225 - INFO - training batch 151, loss: 1.695, 4832/28000 datapoints
2025-03-06 20:40:10,341 - INFO - training batch 201, loss: 1.512, 6432/28000 datapoints
2025-03-06 20:40:10,461 - INFO - training batch 251, loss: 1.279, 8032/28000 datapoints
2025-03-06 20:40:10,582 - INFO - training batch 301, loss: 1.518, 9632/28000 datapoints
2025-03-06 20:40:10,706 - INFO - training batch 351, loss: 1.464, 11232/28000 datapoints
2025-03-06 20:40:10,823 - INFO - training batch 401, loss: 1.454, 12832/28000 datapoints
2025-03-06 20:40:10,940 - INFO - training batch 451, loss: 1.401, 14432/28000 datapoints
2025-03-06 20:40:11,059 - INFO - training batch 501, loss: 1.249, 16032/28000 datapoints
2025-03-06 20:40:11,179 - INFO - training batch 551, loss: 1.413, 17632/28000 datapoints
2025-03-06 20:40:11,297 - INFO - training batch 601, loss: 1.459, 19232/28000 datapoints
2025-03-06 20:40:11,413 - INFO - training batch 651, loss: 1.097, 20832/28000 datapoints
2025-03-06 20:40:11,530 - INFO - training batch 701, loss: 1.200, 22432/28000 datapoints
2025-03-06 20:40:11,651 - INFO - training batch 751, loss: 1.551, 24032/28000 datapoints
2025-03-06 20:40:11,776 - INFO - training batch 801, loss: 1.218, 25632/28000 datapoints
2025-03-06 20:40:11,898 - INFO - training batch 851, loss: 1.374, 27232/28000 datapoints
2025-03-06 20:40:11,957 - INFO - validation batch 1, loss: 0.982, 32/6976 datapoints
2025-03-06 20:40:12,005 - INFO - validation batch 51, loss: 1.731, 1632/6976 datapoints
2025-03-06 20:40:12,053 - INFO - validation batch 101, loss: 1.388, 3232/6976 datapoints
2025-03-06 20:40:12,100 - INFO - validation batch 151, loss: 1.709, 4832/6976 datapoints
2025-03-06 20:40:12,146 - INFO - validation batch 201, loss: 0.877, 6432/6976 datapoints
2025-03-06 20:40:12,161 - INFO - Epoch 55/800 done.
2025-03-06 20:40:12,161 - INFO - Final validation performance:
Loss: 1.338, top-1 acc: 0.499top-5 acc: 0.499
2025-03-06 20:40:12,162 - INFO - Beginning epoch 56/800
2025-03-06 20:40:12,165 - INFO - training batch 1, loss: 1.605, 32/28000 datapoints
2025-03-06 20:40:12,294 - INFO - training batch 51, loss: 1.589, 1632/28000 datapoints
2025-03-06 20:40:12,414 - INFO - training batch 101, loss: 1.124, 3232/28000 datapoints
2025-03-06 20:40:12,537 - INFO - training batch 151, loss: 1.694, 4832/28000 datapoints
2025-03-06 20:40:12,667 - INFO - training batch 201, loss: 1.509, 6432/28000 datapoints
2025-03-06 20:40:12,790 - INFO - training batch 251, loss: 1.276, 8032/28000 datapoints
2025-03-06 20:40:12,912 - INFO - training batch 301, loss: 1.516, 9632/28000 datapoints
2025-03-06 20:40:13,034 - INFO - training batch 351, loss: 1.460, 11232/28000 datapoints
2025-03-06 20:40:13,155 - INFO - training batch 401, loss: 1.452, 12832/28000 datapoints
2025-03-06 20:40:13,280 - INFO - training batch 451, loss: 1.398, 14432/28000 datapoints
2025-03-06 20:40:13,402 - INFO - training batch 501, loss: 1.249, 16032/28000 datapoints
2025-03-06 20:40:13,522 - INFO - training batch 551, loss: 1.410, 17632/28000 datapoints
2025-03-06 20:40:13,648 - INFO - training batch 601, loss: 1.458, 19232/28000 datapoints
2025-03-06 20:40:13,771 - INFO - training batch 651, loss: 1.094, 20832/28000 datapoints
2025-03-06 20:40:13,893 - INFO - training batch 701, loss: 1.199, 22432/28000 datapoints
2025-03-06 20:40:14,013 - INFO - training batch 751, loss: 1.548, 24032/28000 datapoints
2025-03-06 20:40:14,134 - INFO - training batch 801, loss: 1.215, 25632/28000 datapoints
2025-03-06 20:40:14,257 - INFO - training batch 851, loss: 1.373, 27232/28000 datapoints
2025-03-06 20:40:14,318 - INFO - validation batch 1, loss: 0.980, 32/6976 datapoints
2025-03-06 20:40:14,367 - INFO - validation batch 51, loss: 1.730, 1632/6976 datapoints
2025-03-06 20:40:14,415 - INFO - validation batch 101, loss: 1.386, 3232/6976 datapoints
2025-03-06 20:40:14,462 - INFO - validation batch 151, loss: 1.706, 4832/6976 datapoints
2025-03-06 20:40:14,510 - INFO - validation batch 201, loss: 0.874, 6432/6976 datapoints
2025-03-06 20:40:14,527 - INFO - Epoch 56/800 done.
2025-03-06 20:40:14,527 - INFO - Final validation performance:
Loss: 1.335, top-1 acc: 0.500top-5 acc: 0.500
2025-03-06 20:40:14,527 - INFO - Beginning epoch 57/800
2025-03-06 20:40:14,532 - INFO - training batch 1, loss: 1.600, 32/28000 datapoints
2025-03-06 20:40:14,657 - INFO - training batch 51, loss: 1.586, 1632/28000 datapoints
2025-03-06 20:40:14,781 - INFO - training batch 101, loss: 1.122, 3232/28000 datapoints
2025-03-06 20:40:14,917 - INFO - training batch 151, loss: 1.692, 4832/28000 datapoints
2025-03-06 20:40:15,036 - INFO - training batch 201, loss: 1.506, 6432/28000 datapoints
2025-03-06 20:40:15,155 - INFO - training batch 251, loss: 1.272, 8032/28000 datapoints
2025-03-06 20:40:15,312 - INFO - training batch 301, loss: 1.515, 9632/28000 datapoints
2025-03-06 20:40:15,431 - INFO - training batch 351, loss: 1.457, 11232/28000 datapoints
2025-03-06 20:40:15,549 - INFO - training batch 401, loss: 1.450, 12832/28000 datapoints
2025-03-06 20:40:15,675 - INFO - training batch 451, loss: 1.396, 14432/28000 datapoints
2025-03-06 20:40:15,795 - INFO - training batch 501, loss: 1.249, 16032/28000 datapoints
2025-03-06 20:40:15,913 - INFO - training batch 551, loss: 1.407, 17632/28000 datapoints
2025-03-06 20:40:16,030 - INFO - training batch 601, loss: 1.456, 19232/28000 datapoints
2025-03-06 20:40:16,148 - INFO - training batch 651, loss: 1.091, 20832/28000 datapoints
2025-03-06 20:40:16,264 - INFO - training batch 701, loss: 1.198, 22432/28000 datapoints
2025-03-06 20:40:16,382 - INFO - training batch 751, loss: 1.545, 24032/28000 datapoints
2025-03-06 20:40:16,499 - INFO - training batch 801, loss: 1.212, 25632/28000 datapoints
2025-03-06 20:40:16,620 - INFO - training batch 851, loss: 1.373, 27232/28000 datapoints
2025-03-06 20:40:16,682 - INFO - validation batch 1, loss: 0.978, 32/6976 datapoints
2025-03-06 20:40:16,727 - INFO - validation batch 51, loss: 1.729, 1632/6976 datapoints
2025-03-06 20:40:16,773 - INFO - validation batch 101, loss: 1.385, 3232/6976 datapoints
2025-03-06 20:40:16,816 - INFO - validation batch 151, loss: 1.703, 4832/6976 datapoints
2025-03-06 20:40:16,859 - INFO - validation batch 201, loss: 0.871, 6432/6976 datapoints
2025-03-06 20:40:16,874 - INFO - Epoch 57/800 done.
2025-03-06 20:40:16,874 - INFO - Final validation performance:
Loss: 1.333, top-1 acc: 0.500top-5 acc: 0.500
2025-03-06 20:40:16,875 - INFO - Beginning epoch 58/800
2025-03-06 20:40:16,878 - INFO - training batch 1, loss: 1.596, 32/28000 datapoints
2025-03-06 20:40:17,003 - INFO - training batch 51, loss: 1.583, 1632/28000 datapoints
2025-03-06 20:40:17,120 - INFO - training batch 101, loss: 1.119, 3232/28000 datapoints
2025-03-06 20:40:17,238 - INFO - training batch 151, loss: 1.690, 4832/28000 datapoints
2025-03-06 20:40:17,359 - INFO - training batch 201, loss: 1.503, 6432/28000 datapoints
2025-03-06 20:40:17,476 - INFO - training batch 251, loss: 1.269, 8032/28000 datapoints
2025-03-06 20:40:17,593 - INFO - training batch 301, loss: 1.514, 9632/28000 datapoints
2025-03-06 20:40:17,713 - INFO - training batch 351, loss: 1.454, 11232/28000 datapoints
2025-03-06 20:40:17,831 - INFO - training batch 401, loss: 1.448, 12832/28000 datapoints
2025-03-06 20:40:17,948 - INFO - training batch 451, loss: 1.393, 14432/28000 datapoints
2025-03-06 20:40:18,066 - INFO - training batch 501, loss: 1.248, 16032/28000 datapoints
2025-03-06 20:40:18,183 - INFO - training batch 551, loss: 1.404, 17632/28000 datapoints
2025-03-06 20:40:18,304 - INFO - training batch 601, loss: 1.454, 19232/28000 datapoints
2025-03-06 20:40:18,422 - INFO - training batch 651, loss: 1.088, 20832/28000 datapoints
2025-03-06 20:40:18,538 - INFO - training batch 701, loss: 1.197, 22432/28000 datapoints
2025-03-06 20:40:18,670 - INFO - training batch 751, loss: 1.542, 24032/28000 datapoints
2025-03-06 20:40:18,792 - INFO - training batch 801, loss: 1.209, 25632/28000 datapoints
2025-03-06 20:40:18,909 - INFO - training batch 851, loss: 1.372, 27232/28000 datapoints
2025-03-06 20:40:18,966 - INFO - validation batch 1, loss: 0.976, 32/6976 datapoints
2025-03-06 20:40:19,010 - INFO - validation batch 51, loss: 1.728, 1632/6976 datapoints
2025-03-06 20:40:19,054 - INFO - validation batch 101, loss: 1.383, 3232/6976 datapoints
2025-03-06 20:40:19,097 - INFO - validation batch 151, loss: 1.700, 4832/6976 datapoints
2025-03-06 20:40:19,144 - INFO - validation batch 201, loss: 0.869, 6432/6976 datapoints
2025-03-06 20:40:19,160 - INFO - Epoch 58/800 done.
2025-03-06 20:40:19,160 - INFO - Final validation performance:
Loss: 1.331, top-1 acc: 0.500top-5 acc: 0.500
2025-03-06 20:40:19,160 - INFO - Beginning epoch 59/800
2025-03-06 20:40:19,164 - INFO - training batch 1, loss: 1.591, 32/28000 datapoints
2025-03-06 20:40:19,284 - INFO - training batch 51, loss: 1.580, 1632/28000 datapoints
2025-03-06 20:40:19,404 - INFO - training batch 101, loss: 1.117, 3232/28000 datapoints
2025-03-06 20:40:19,522 - INFO - training batch 151, loss: 1.688, 4832/28000 datapoints
2025-03-06 20:40:19,643 - INFO - training batch 201, loss: 1.500, 6432/28000 datapoints
2025-03-06 20:40:19,779 - INFO - training batch 251, loss: 1.267, 8032/28000 datapoints
2025-03-06 20:40:19,896 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 20:40:20,014 - INFO - training batch 351, loss: 1.450, 11232/28000 datapoints
2025-03-06 20:40:20,130 - INFO - training batch 401, loss: 1.446, 12832/28000 datapoints
2025-03-06 20:40:20,247 - INFO - training batch 451, loss: 1.391, 14432/28000 datapoints
2025-03-06 20:40:20,365 - INFO - training batch 501, loss: 1.249, 16032/28000 datapoints
2025-03-06 20:40:20,483 - INFO - training batch 551, loss: 1.402, 17632/28000 datapoints
2025-03-06 20:40:20,604 - INFO - training batch 601, loss: 1.453, 19232/28000 datapoints
2025-03-06 20:40:20,726 - INFO - training batch 651, loss: 1.085, 20832/28000 datapoints
2025-03-06 20:40:20,854 - INFO - training batch 701, loss: 1.195, 22432/28000 datapoints
2025-03-06 20:40:20,986 - INFO - training batch 751, loss: 1.539, 24032/28000 datapoints
2025-03-06 20:40:21,104 - INFO - training batch 801, loss: 1.207, 25632/28000 datapoints
2025-03-06 20:40:21,221 - INFO - training batch 851, loss: 1.372, 27232/28000 datapoints
2025-03-06 20:40:21,281 - INFO - validation batch 1, loss: 0.975, 32/6976 datapoints
2025-03-06 20:40:21,333 - INFO - validation batch 51, loss: 1.727, 1632/6976 datapoints
2025-03-06 20:40:21,376 - INFO - validation batch 101, loss: 1.381, 3232/6976 datapoints
2025-03-06 20:40:21,421 - INFO - validation batch 151, loss: 1.697, 4832/6976 datapoints
2025-03-06 20:40:21,465 - INFO - validation batch 201, loss: 0.866, 6432/6976 datapoints
2025-03-06 20:40:21,481 - INFO - Epoch 59/800 done.
2025-03-06 20:40:21,482 - INFO - Final validation performance:
Loss: 1.329, top-1 acc: 0.500top-5 acc: 0.500
2025-03-06 20:40:21,482 - INFO - Beginning epoch 60/800
2025-03-06 20:40:21,485 - INFO - training batch 1, loss: 1.587, 32/28000 datapoints
2025-03-06 20:40:21,606 - INFO - training batch 51, loss: 1.578, 1632/28000 datapoints
2025-03-06 20:40:21,727 - INFO - training batch 101, loss: 1.115, 3232/28000 datapoints
2025-03-06 20:40:21,851 - INFO - training batch 151, loss: 1.686, 4832/28000 datapoints
2025-03-06 20:40:21,970 - INFO - training batch 201, loss: 1.498, 6432/28000 datapoints
2025-03-06 20:40:22,087 - INFO - training batch 251, loss: 1.263, 8032/28000 datapoints
2025-03-06 20:40:22,202 - INFO - training batch 301, loss: 1.511, 9632/28000 datapoints
2025-03-06 20:40:22,319 - INFO - training batch 351, loss: 1.446, 11232/28000 datapoints
2025-03-06 20:40:22,434 - INFO - training batch 401, loss: 1.443, 12832/28000 datapoints
2025-03-06 20:40:22,551 - INFO - training batch 451, loss: 1.389, 14432/28000 datapoints
2025-03-06 20:40:22,676 - INFO - training batch 501, loss: 1.249, 16032/28000 datapoints
2025-03-06 20:40:22,796 - INFO - training batch 551, loss: 1.399, 17632/28000 datapoints
2025-03-06 20:40:22,913 - INFO - training batch 601, loss: 1.451, 19232/28000 datapoints
2025-03-06 20:40:23,030 - INFO - training batch 651, loss: 1.083, 20832/28000 datapoints
2025-03-06 20:40:23,149 - INFO - training batch 701, loss: 1.194, 22432/28000 datapoints
2025-03-06 20:40:23,265 - INFO - training batch 751, loss: 1.536, 24032/28000 datapoints
2025-03-06 20:40:23,384 - INFO - training batch 801, loss: 1.204, 25632/28000 datapoints
2025-03-06 20:40:23,502 - INFO - training batch 851, loss: 1.372, 27232/28000 datapoints
2025-03-06 20:40:23,559 - INFO - validation batch 1, loss: 0.973, 32/6976 datapoints
2025-03-06 20:40:23,602 - INFO - validation batch 51, loss: 1.726, 1632/6976 datapoints
2025-03-06 20:40:23,650 - INFO - validation batch 101, loss: 1.379, 3232/6976 datapoints
2025-03-06 20:40:23,694 - INFO - validation batch 151, loss: 1.694, 4832/6976 datapoints
2025-03-06 20:40:23,742 - INFO - validation batch 201, loss: 0.863, 6432/6976 datapoints
2025-03-06 20:40:23,759 - INFO - Epoch 60/800 done.
2025-03-06 20:40:23,759 - INFO - Final validation performance:
Loss: 1.327, top-1 acc: 0.500top-5 acc: 0.500
2025-03-06 20:40:23,760 - INFO - Beginning epoch 61/800
2025-03-06 20:40:23,763 - INFO - training batch 1, loss: 1.582, 32/28000 datapoints
2025-03-06 20:40:23,885 - INFO - training batch 51, loss: 1.575, 1632/28000 datapoints
2025-03-06 20:40:24,002 - INFO - training batch 101, loss: 1.112, 3232/28000 datapoints
2025-03-06 20:40:24,119 - INFO - training batch 151, loss: 1.685, 4832/28000 datapoints
2025-03-06 20:40:24,238 - INFO - training batch 201, loss: 1.495, 6432/28000 datapoints
2025-03-06 20:40:24,358 - INFO - training batch 251, loss: 1.261, 8032/28000 datapoints
2025-03-06 20:40:24,475 - INFO - training batch 301, loss: 1.509, 9632/28000 datapoints
2025-03-06 20:40:24,596 - INFO - training batch 351, loss: 1.443, 11232/28000 datapoints
2025-03-06 20:40:24,717 - INFO - training batch 401, loss: 1.441, 12832/28000 datapoints
2025-03-06 20:40:24,835 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 20:40:24,958 - INFO - training batch 501, loss: 1.248, 16032/28000 datapoints
2025-03-06 20:40:25,077 - INFO - training batch 551, loss: 1.397, 17632/28000 datapoints
2025-03-06 20:40:25,195 - INFO - training batch 601, loss: 1.449, 19232/28000 datapoints
2025-03-06 20:40:25,320 - INFO - training batch 651, loss: 1.080, 20832/28000 datapoints
2025-03-06 20:40:25,456 - INFO - training batch 701, loss: 1.193, 22432/28000 datapoints
2025-03-06 20:40:25,573 - INFO - training batch 751, loss: 1.533, 24032/28000 datapoints
2025-03-06 20:40:25,695 - INFO - training batch 801, loss: 1.201, 25632/28000 datapoints
2025-03-06 20:40:25,814 - INFO - training batch 851, loss: 1.371, 27232/28000 datapoints
2025-03-06 20:40:25,874 - INFO - validation batch 1, loss: 0.972, 32/6976 datapoints
2025-03-06 20:40:25,918 - INFO - validation batch 51, loss: 1.725, 1632/6976 datapoints
2025-03-06 20:40:25,960 - INFO - validation batch 101, loss: 1.377, 3232/6976 datapoints
2025-03-06 20:40:26,003 - INFO - validation batch 151, loss: 1.692, 4832/6976 datapoints
2025-03-06 20:40:26,045 - INFO - validation batch 201, loss: 0.861, 6432/6976 datapoints
2025-03-06 20:40:26,060 - INFO - Epoch 61/800 done.
2025-03-06 20:40:26,061 - INFO - Final validation performance:
Loss: 1.325, top-1 acc: 0.501top-5 acc: 0.501
2025-03-06 20:40:26,061 - INFO - Beginning epoch 62/800
2025-03-06 20:40:26,064 - INFO - training batch 1, loss: 1.577, 32/28000 datapoints
2025-03-06 20:40:26,182 - INFO - training batch 51, loss: 1.573, 1632/28000 datapoints
2025-03-06 20:40:26,300 - INFO - training batch 101, loss: 1.110, 3232/28000 datapoints
2025-03-06 20:40:26,420 - INFO - training batch 151, loss: 1.683, 4832/28000 datapoints
2025-03-06 20:40:26,538 - INFO - training batch 201, loss: 1.492, 6432/28000 datapoints
2025-03-06 20:40:26,663 - INFO - training batch 251, loss: 1.258, 8032/28000 datapoints
2025-03-06 20:40:26,781 - INFO - training batch 301, loss: 1.508, 9632/28000 datapoints
2025-03-06 20:40:26,912 - INFO - training batch 351, loss: 1.440, 11232/28000 datapoints
2025-03-06 20:40:27,034 - INFO - training batch 401, loss: 1.439, 12832/28000 datapoints
2025-03-06 20:40:27,151 - INFO - training batch 451, loss: 1.384, 14432/28000 datapoints
2025-03-06 20:40:27,269 - INFO - training batch 501, loss: 1.248, 16032/28000 datapoints
2025-03-06 20:40:27,395 - INFO - training batch 551, loss: 1.394, 17632/28000 datapoints
2025-03-06 20:40:27,515 - INFO - training batch 601, loss: 1.447, 19232/28000 datapoints
2025-03-06 20:40:27,640 - INFO - training batch 651, loss: 1.077, 20832/28000 datapoints
2025-03-06 20:40:27,759 - INFO - training batch 701, loss: 1.191, 22432/28000 datapoints
2025-03-06 20:40:27,883 - INFO - training batch 751, loss: 1.530, 24032/28000 datapoints
2025-03-06 20:40:27,999 - INFO - training batch 801, loss: 1.199, 25632/28000 datapoints
2025-03-06 20:40:28,115 - INFO - training batch 851, loss: 1.371, 27232/28000 datapoints
2025-03-06 20:40:28,172 - INFO - validation batch 1, loss: 0.970, 32/6976 datapoints
2025-03-06 20:40:28,215 - INFO - validation batch 51, loss: 1.724, 1632/6976 datapoints
2025-03-06 20:40:28,259 - INFO - validation batch 101, loss: 1.374, 3232/6976 datapoints
2025-03-06 20:40:28,305 - INFO - validation batch 151, loss: 1.689, 4832/6976 datapoints
2025-03-06 20:40:28,348 - INFO - validation batch 201, loss: 0.859, 6432/6976 datapoints
2025-03-06 20:40:28,363 - INFO - Epoch 62/800 done.
2025-03-06 20:40:28,364 - INFO - Final validation performance:
Loss: 1.323, top-1 acc: 0.501top-5 acc: 0.501
2025-03-06 20:40:28,364 - INFO - Beginning epoch 63/800
2025-03-06 20:40:28,368 - INFO - training batch 1, loss: 1.573, 32/28000 datapoints
2025-03-06 20:40:28,489 - INFO - training batch 51, loss: 1.570, 1632/28000 datapoints
2025-03-06 20:40:28,611 - INFO - training batch 101, loss: 1.108, 3232/28000 datapoints
2025-03-06 20:40:28,737 - INFO - training batch 151, loss: 1.680, 4832/28000 datapoints
2025-03-06 20:40:28,855 - INFO - training batch 201, loss: 1.489, 6432/28000 datapoints
2025-03-06 20:40:28,972 - INFO - training batch 251, loss: 1.255, 8032/28000 datapoints
2025-03-06 20:40:29,088 - INFO - training batch 301, loss: 1.507, 9632/28000 datapoints
2025-03-06 20:40:29,205 - INFO - training batch 351, loss: 1.437, 11232/28000 datapoints
2025-03-06 20:40:29,323 - INFO - training batch 401, loss: 1.437, 12832/28000 datapoints
2025-03-06 20:40:29,444 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 20:40:29,561 - INFO - training batch 501, loss: 1.248, 16032/28000 datapoints
2025-03-06 20:40:29,681 - INFO - training batch 551, loss: 1.392, 17632/28000 datapoints
2025-03-06 20:40:29,799 - INFO - training batch 601, loss: 1.446, 19232/28000 datapoints
2025-03-06 20:40:29,917 - INFO - training batch 651, loss: 1.075, 20832/28000 datapoints
2025-03-06 20:40:30,035 - INFO - training batch 701, loss: 1.190, 22432/28000 datapoints
2025-03-06 20:40:30,150 - INFO - training batch 751, loss: 1.527, 24032/28000 datapoints
2025-03-06 20:40:30,267 - INFO - training batch 801, loss: 1.196, 25632/28000 datapoints
2025-03-06 20:40:30,385 - INFO - training batch 851, loss: 1.370, 27232/28000 datapoints
2025-03-06 20:40:30,445 - INFO - validation batch 1, loss: 0.969, 32/6976 datapoints
2025-03-06 20:40:30,487 - INFO - validation batch 51, loss: 1.723, 1632/6976 datapoints
2025-03-06 20:40:30,530 - INFO - validation batch 101, loss: 1.372, 3232/6976 datapoints
2025-03-06 20:40:30,573 - INFO - validation batch 151, loss: 1.686, 4832/6976 datapoints
2025-03-06 20:40:30,619 - INFO - validation batch 201, loss: 0.856, 6432/6976 datapoints
2025-03-06 20:40:30,636 - INFO - Epoch 63/800 done.
2025-03-06 20:40:30,636 - INFO - Final validation performance:
Loss: 1.321, top-1 acc: 0.502top-5 acc: 0.502
2025-03-06 20:40:30,637 - INFO - Beginning epoch 64/800
2025-03-06 20:40:30,640 - INFO - training batch 1, loss: 1.568, 32/28000 datapoints
2025-03-06 20:40:30,760 - INFO - training batch 51, loss: 1.567, 1632/28000 datapoints
2025-03-06 20:40:30,879 - INFO - training batch 101, loss: 1.105, 3232/28000 datapoints
2025-03-06 20:40:30,998 - INFO - training batch 151, loss: 1.679, 4832/28000 datapoints
2025-03-06 20:40:31,117 - INFO - training batch 201, loss: 1.486, 6432/28000 datapoints
2025-03-06 20:40:31,240 - INFO - training batch 251, loss: 1.252, 8032/28000 datapoints
2025-03-06 20:40:31,357 - INFO - training batch 301, loss: 1.506, 9632/28000 datapoints
2025-03-06 20:40:31,488 - INFO - training batch 351, loss: 1.434, 11232/28000 datapoints
2025-03-06 20:40:31,606 - INFO - training batch 401, loss: 1.435, 12832/28000 datapoints
2025-03-06 20:40:31,734 - INFO - training batch 451, loss: 1.380, 14432/28000 datapoints
2025-03-06 20:40:31,856 - INFO - training batch 501, loss: 1.248, 16032/28000 datapoints
2025-03-06 20:40:31,978 - INFO - training batch 551, loss: 1.389, 17632/28000 datapoints
2025-03-06 20:40:32,100 - INFO - training batch 601, loss: 1.444, 19232/28000 datapoints
2025-03-06 20:40:32,223 - INFO - training batch 651, loss: 1.072, 20832/28000 datapoints
2025-03-06 20:40:32,346 - INFO - training batch 701, loss: 1.189, 22432/28000 datapoints
2025-03-06 20:40:32,469 - INFO - training batch 751, loss: 1.524, 24032/28000 datapoints
2025-03-06 20:40:32,592 - INFO - training batch 801, loss: 1.193, 25632/28000 datapoints
2025-03-06 20:40:32,721 - INFO - training batch 851, loss: 1.370, 27232/28000 datapoints
2025-03-06 20:40:32,782 - INFO - validation batch 1, loss: 0.968, 32/6976 datapoints
2025-03-06 20:40:32,828 - INFO - validation batch 51, loss: 1.721, 1632/6976 datapoints
2025-03-06 20:40:32,873 - INFO - validation batch 101, loss: 1.369, 3232/6976 datapoints
2025-03-06 20:40:32,916 - INFO - validation batch 151, loss: 1.683, 4832/6976 datapoints
2025-03-06 20:40:32,962 - INFO - validation batch 201, loss: 0.854, 6432/6976 datapoints
2025-03-06 20:40:32,976 - INFO - Epoch 64/800 done.
2025-03-06 20:40:32,976 - INFO - Final validation performance:
Loss: 1.319, top-1 acc: 0.502top-5 acc: 0.502
2025-03-06 20:40:32,977 - INFO - Beginning epoch 65/800
2025-03-06 20:40:32,981 - INFO - training batch 1, loss: 1.564, 32/28000 datapoints
2025-03-06 20:40:33,118 - INFO - training batch 51, loss: 1.565, 1632/28000 datapoints
2025-03-06 20:40:33,237 - INFO - training batch 101, loss: 1.103, 3232/28000 datapoints
2025-03-06 20:40:33,352 - INFO - training batch 151, loss: 1.677, 4832/28000 datapoints
2025-03-06 20:40:33,472 - INFO - training batch 201, loss: 1.483, 6432/28000 datapoints
2025-03-06 20:40:33,590 - INFO - training batch 251, loss: 1.249, 8032/28000 datapoints
2025-03-06 20:40:33,712 - INFO - training batch 301, loss: 1.504, 9632/28000 datapoints
2025-03-06 20:40:33,841 - INFO - training batch 351, loss: 1.430, 11232/28000 datapoints
2025-03-06 20:40:33,965 - INFO - training batch 401, loss: 1.433, 12832/28000 datapoints
2025-03-06 20:40:34,083 - INFO - training batch 451, loss: 1.378, 14432/28000 datapoints
2025-03-06 20:40:34,204 - INFO - training batch 501, loss: 1.247, 16032/28000 datapoints
2025-03-06 20:40:34,323 - INFO - training batch 551, loss: 1.386, 17632/28000 datapoints
2025-03-06 20:40:34,446 - INFO - training batch 601, loss: 1.442, 19232/28000 datapoints
2025-03-06 20:40:34,605 - INFO - training batch 651, loss: 1.070, 20832/28000 datapoints
2025-03-06 20:40:34,732 - INFO - training batch 701, loss: 1.188, 22432/28000 datapoints
2025-03-06 20:40:34,853 - INFO - training batch 751, loss: 1.521, 24032/28000 datapoints
2025-03-06 20:40:34,976 - INFO - training batch 801, loss: 1.190, 25632/28000 datapoints
2025-03-06 20:40:35,096 - INFO - training batch 851, loss: 1.369, 27232/28000 datapoints
2025-03-06 20:40:35,155 - INFO - validation batch 1, loss: 0.967, 32/6976 datapoints
2025-03-06 20:40:35,199 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 20:40:35,243 - INFO - validation batch 101, loss: 1.367, 3232/6976 datapoints
2025-03-06 20:40:35,288 - INFO - validation batch 151, loss: 1.681, 4832/6976 datapoints
2025-03-06 20:40:35,333 - INFO - validation batch 201, loss: 0.852, 6432/6976 datapoints
2025-03-06 20:40:35,348 - INFO - Epoch 65/800 done.
2025-03-06 20:40:35,348 - INFO - Final validation performance:
Loss: 1.317, top-1 acc: 0.503top-5 acc: 0.503
2025-03-06 20:40:35,349 - INFO - Beginning epoch 66/800
2025-03-06 20:40:35,352 - INFO - training batch 1, loss: 1.559, 32/28000 datapoints
2025-03-06 20:40:35,500 - INFO - training batch 51, loss: 1.563, 1632/28000 datapoints
2025-03-06 20:40:35,619 - INFO - training batch 101, loss: 1.100, 3232/28000 datapoints
2025-03-06 20:40:35,741 - INFO - training batch 151, loss: 1.675, 4832/28000 datapoints
2025-03-06 20:40:35,860 - INFO - training batch 201, loss: 1.479, 6432/28000 datapoints
2025-03-06 20:40:35,980 - INFO - training batch 251, loss: 1.246, 8032/28000 datapoints
2025-03-06 20:40:36,097 - INFO - training batch 301, loss: 1.503, 9632/28000 datapoints
2025-03-06 20:40:36,214 - INFO - training batch 351, loss: 1.427, 11232/28000 datapoints
2025-03-06 20:40:36,332 - INFO - training batch 401, loss: 1.431, 12832/28000 datapoints
2025-03-06 20:40:36,449 - INFO - training batch 451, loss: 1.377, 14432/28000 datapoints
2025-03-06 20:40:36,568 - INFO - training batch 501, loss: 1.247, 16032/28000 datapoints
2025-03-06 20:40:36,700 - INFO - training batch 551, loss: 1.384, 17632/28000 datapoints
2025-03-06 20:40:36,817 - INFO - training batch 601, loss: 1.441, 19232/28000 datapoints
2025-03-06 20:40:36,935 - INFO - training batch 651, loss: 1.067, 20832/28000 datapoints
2025-03-06 20:40:37,054 - INFO - training batch 701, loss: 1.186, 22432/28000 datapoints
2025-03-06 20:40:37,171 - INFO - training batch 751, loss: 1.518, 24032/28000 datapoints
2025-03-06 20:40:37,288 - INFO - training batch 801, loss: 1.187, 25632/28000 datapoints
2025-03-06 20:40:37,408 - INFO - training batch 851, loss: 1.369, 27232/28000 datapoints
2025-03-06 20:40:37,466 - INFO - validation batch 1, loss: 0.965, 32/6976 datapoints
2025-03-06 20:40:37,508 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 20:40:37,553 - INFO - validation batch 101, loss: 1.365, 3232/6976 datapoints
2025-03-06 20:40:37,597 - INFO - validation batch 151, loss: 1.679, 4832/6976 datapoints
2025-03-06 20:40:37,655 - INFO - validation batch 201, loss: 0.850, 6432/6976 datapoints
2025-03-06 20:40:37,671 - INFO - Epoch 66/800 done.
2025-03-06 20:40:37,671 - INFO - Final validation performance:
Loss: 1.316, top-1 acc: 0.503top-5 acc: 0.503
2025-03-06 20:40:37,671 - INFO - Beginning epoch 67/800
2025-03-06 20:40:37,675 - INFO - training batch 1, loss: 1.554, 32/28000 datapoints
2025-03-06 20:40:37,794 - INFO - training batch 51, loss: 1.561, 1632/28000 datapoints
2025-03-06 20:40:37,913 - INFO - training batch 101, loss: 1.098, 3232/28000 datapoints
2025-03-06 20:40:38,032 - INFO - training batch 151, loss: 1.673, 4832/28000 datapoints
2025-03-06 20:40:38,152 - INFO - training batch 201, loss: 1.476, 6432/28000 datapoints
2025-03-06 20:40:38,270 - INFO - training batch 251, loss: 1.242, 8032/28000 datapoints
2025-03-06 20:40:38,388 - INFO - training batch 301, loss: 1.501, 9632/28000 datapoints
2025-03-06 20:40:38,504 - INFO - training batch 351, loss: 1.423, 11232/28000 datapoints
2025-03-06 20:40:38,624 - INFO - training batch 401, loss: 1.429, 12832/28000 datapoints
2025-03-06 20:40:38,761 - INFO - training batch 451, loss: 1.376, 14432/28000 datapoints
2025-03-06 20:40:38,888 - INFO - training batch 501, loss: 1.246, 16032/28000 datapoints
2025-03-06 20:40:39,005 - INFO - training batch 551, loss: 1.382, 17632/28000 datapoints
2025-03-06 20:40:39,139 - INFO - training batch 601, loss: 1.439, 19232/28000 datapoints
2025-03-06 20:40:39,262 - INFO - training batch 651, loss: 1.064, 20832/28000 datapoints
2025-03-06 20:40:39,379 - INFO - training batch 701, loss: 1.185, 22432/28000 datapoints
2025-03-06 20:40:39,496 - INFO - training batch 751, loss: 1.515, 24032/28000 datapoints
2025-03-06 20:40:39,622 - INFO - training batch 801, loss: 1.184, 25632/28000 datapoints
2025-03-06 20:40:39,748 - INFO - training batch 851, loss: 1.368, 27232/28000 datapoints
2025-03-06 20:40:39,806 - INFO - validation batch 1, loss: 0.964, 32/6976 datapoints
2025-03-06 20:40:39,850 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 20:40:39,893 - INFO - validation batch 101, loss: 1.363, 3232/6976 datapoints
2025-03-06 20:40:39,942 - INFO - validation batch 151, loss: 1.677, 4832/6976 datapoints
2025-03-06 20:40:39,985 - INFO - validation batch 201, loss: 0.848, 6432/6976 datapoints
2025-03-06 20:40:40,000 - INFO - Epoch 67/800 done.
2025-03-06 20:40:40,000 - INFO - Final validation performance:
Loss: 1.314, top-1 acc: 0.503top-5 acc: 0.503
2025-03-06 20:40:40,001 - INFO - Beginning epoch 68/800
2025-03-06 20:40:40,005 - INFO - training batch 1, loss: 1.549, 32/28000 datapoints
2025-03-06 20:40:40,134 - INFO - training batch 51, loss: 1.560, 1632/28000 datapoints
2025-03-06 20:40:40,250 - INFO - training batch 101, loss: 1.096, 3232/28000 datapoints
2025-03-06 20:40:40,369 - INFO - training batch 151, loss: 1.671, 4832/28000 datapoints
2025-03-06 20:40:40,486 - INFO - training batch 201, loss: 1.473, 6432/28000 datapoints
2025-03-06 20:40:40,604 - INFO - training batch 251, loss: 1.239, 8032/28000 datapoints
2025-03-06 20:40:40,731 - INFO - training batch 301, loss: 1.500, 9632/28000 datapoints
2025-03-06 20:40:40,850 - INFO - training batch 351, loss: 1.419, 11232/28000 datapoints
2025-03-06 20:40:40,968 - INFO - training batch 401, loss: 1.427, 12832/28000 datapoints
2025-03-06 20:40:41,087 - INFO - training batch 451, loss: 1.374, 14432/28000 datapoints
2025-03-06 20:40:41,205 - INFO - training batch 501, loss: 1.246, 16032/28000 datapoints
2025-03-06 20:40:41,325 - INFO - training batch 551, loss: 1.380, 17632/28000 datapoints
2025-03-06 20:40:41,443 - INFO - training batch 601, loss: 1.438, 19232/28000 datapoints
2025-03-06 20:40:41,561 - INFO - training batch 651, loss: 1.062, 20832/28000 datapoints
2025-03-06 20:40:41,683 - INFO - training batch 701, loss: 1.183, 22432/28000 datapoints
2025-03-06 20:40:41,802 - INFO - training batch 751, loss: 1.512, 24032/28000 datapoints
2025-03-06 20:40:41,921 - INFO - training batch 801, loss: 1.181, 25632/28000 datapoints
2025-03-06 20:40:42,040 - INFO - training batch 851, loss: 1.367, 27232/28000 datapoints
2025-03-06 20:40:42,100 - INFO - validation batch 1, loss: 0.963, 32/6976 datapoints
2025-03-06 20:40:42,144 - INFO - validation batch 51, loss: 1.718, 1632/6976 datapoints
2025-03-06 20:40:42,187 - INFO - validation batch 101, loss: 1.360, 3232/6976 datapoints
2025-03-06 20:40:42,232 - INFO - validation batch 151, loss: 1.674, 4832/6976 datapoints
2025-03-06 20:40:42,275 - INFO - validation batch 201, loss: 0.846, 6432/6976 datapoints
2025-03-06 20:40:42,290 - INFO - Epoch 68/800 done.
2025-03-06 20:40:42,290 - INFO - Final validation performance:
Loss: 1.312, top-1 acc: 0.504top-5 acc: 0.504
2025-03-06 20:40:42,291 - INFO - Beginning epoch 69/800
2025-03-06 20:40:42,294 - INFO - training batch 1, loss: 1.544, 32/28000 datapoints
2025-03-06 20:40:42,414 - INFO - training batch 51, loss: 1.558, 1632/28000 datapoints
2025-03-06 20:40:42,530 - INFO - training batch 101, loss: 1.093, 3232/28000 datapoints
2025-03-06 20:40:42,657 - INFO - training batch 151, loss: 1.669, 4832/28000 datapoints
2025-03-06 20:40:42,776 - INFO - training batch 201, loss: 1.470, 6432/28000 datapoints
2025-03-06 20:40:42,894 - INFO - training batch 251, loss: 1.235, 8032/28000 datapoints
2025-03-06 20:40:43,012 - INFO - training batch 301, loss: 1.498, 9632/28000 datapoints
2025-03-06 20:40:43,132 - INFO - training batch 351, loss: 1.415, 11232/28000 datapoints
2025-03-06 20:40:43,251 - INFO - training batch 401, loss: 1.425, 12832/28000 datapoints
2025-03-06 20:40:43,369 - INFO - training batch 451, loss: 1.373, 14432/28000 datapoints
2025-03-06 20:40:43,486 - INFO - training batch 501, loss: 1.246, 16032/28000 datapoints
2025-03-06 20:40:43,605 - INFO - training batch 551, loss: 1.379, 17632/28000 datapoints
2025-03-06 20:40:43,728 - INFO - training batch 601, loss: 1.436, 19232/28000 datapoints
2025-03-06 20:40:43,856 - INFO - training batch 651, loss: 1.059, 20832/28000 datapoints
2025-03-06 20:40:43,978 - INFO - training batch 701, loss: 1.182, 22432/28000 datapoints
2025-03-06 20:40:44,112 - INFO - training batch 751, loss: 1.509, 24032/28000 datapoints
2025-03-06 20:40:44,237 - INFO - training batch 801, loss: 1.178, 25632/28000 datapoints
2025-03-06 20:40:44,361 - INFO - training batch 851, loss: 1.366, 27232/28000 datapoints
2025-03-06 20:40:44,421 - INFO - validation batch 1, loss: 0.961, 32/6976 datapoints
2025-03-06 20:40:44,468 - INFO - validation batch 51, loss: 1.717, 1632/6976 datapoints
2025-03-06 20:40:44,512 - INFO - validation batch 101, loss: 1.357, 3232/6976 datapoints
2025-03-06 20:40:44,556 - INFO - validation batch 151, loss: 1.673, 4832/6976 datapoints
2025-03-06 20:40:44,599 - INFO - validation batch 201, loss: 0.845, 6432/6976 datapoints
2025-03-06 20:40:44,614 - INFO - Epoch 69/800 done.
2025-03-06 20:40:44,614 - INFO - Final validation performance:
Loss: 1.311, top-1 acc: 0.504top-5 acc: 0.504
2025-03-06 20:40:44,615 - INFO - Beginning epoch 70/800
2025-03-06 20:40:44,622 - INFO - training batch 1, loss: 1.538, 32/28000 datapoints
2025-03-06 20:40:44,758 - INFO - training batch 51, loss: 1.555, 1632/28000 datapoints
2025-03-06 20:40:44,876 - INFO - training batch 101, loss: 1.091, 3232/28000 datapoints
2025-03-06 20:40:45,004 - INFO - training batch 151, loss: 1.666, 4832/28000 datapoints
2025-03-06 20:40:45,123 - INFO - training batch 201, loss: 1.467, 6432/28000 datapoints
2025-03-06 20:40:45,256 - INFO - training batch 251, loss: 1.231, 8032/28000 datapoints
2025-03-06 20:40:45,375 - INFO - training batch 301, loss: 1.497, 9632/28000 datapoints
2025-03-06 20:40:45,501 - INFO - training batch 351, loss: 1.411, 11232/28000 datapoints
2025-03-06 20:40:45,646 - INFO - training batch 401, loss: 1.423, 12832/28000 datapoints
2025-03-06 20:40:45,784 - INFO - training batch 451, loss: 1.372, 14432/28000 datapoints
2025-03-06 20:40:45,935 - INFO - training batch 501, loss: 1.245, 16032/28000 datapoints
2025-03-06 20:40:46,059 - INFO - training batch 551, loss: 1.376, 17632/28000 datapoints
2025-03-06 20:40:46,178 - INFO - training batch 601, loss: 1.434, 19232/28000 datapoints
2025-03-06 20:40:46,296 - INFO - training batch 651, loss: 1.056, 20832/28000 datapoints
2025-03-06 20:40:46,413 - INFO - training batch 701, loss: 1.180, 22432/28000 datapoints
2025-03-06 20:40:46,530 - INFO - training batch 751, loss: 1.505, 24032/28000 datapoints
2025-03-06 20:40:46,648 - INFO - training batch 801, loss: 1.176, 25632/28000 datapoints
2025-03-06 20:40:46,771 - INFO - training batch 851, loss: 1.366, 27232/28000 datapoints
2025-03-06 20:40:46,828 - INFO - validation batch 1, loss: 0.960, 32/6976 datapoints
2025-03-06 20:40:46,872 - INFO - validation batch 51, loss: 1.715, 1632/6976 datapoints
2025-03-06 20:40:46,916 - INFO - validation batch 101, loss: 1.354, 3232/6976 datapoints
2025-03-06 20:40:46,959 - INFO - validation batch 151, loss: 1.671, 4832/6976 datapoints
2025-03-06 20:40:47,002 - INFO - validation batch 201, loss: 0.843, 6432/6976 datapoints
2025-03-06 20:40:47,018 - INFO - Epoch 70/800 done.
2025-03-06 20:40:47,018 - INFO - Final validation performance:
Loss: 1.309, top-1 acc: 0.504top-5 acc: 0.504
2025-03-06 20:40:47,019 - INFO - Beginning epoch 71/800
2025-03-06 20:40:47,022 - INFO - training batch 1, loss: 1.532, 32/28000 datapoints
2025-03-06 20:40:47,141 - INFO - training batch 51, loss: 1.553, 1632/28000 datapoints
2025-03-06 20:40:47,262 - INFO - training batch 101, loss: 1.089, 3232/28000 datapoints
2025-03-06 20:40:47,379 - INFO - training batch 151, loss: 1.663, 4832/28000 datapoints
2025-03-06 20:40:47,495 - INFO - training batch 201, loss: 1.463, 6432/28000 datapoints
2025-03-06 20:40:47,613 - INFO - training batch 251, loss: 1.228, 8032/28000 datapoints
2025-03-06 20:40:47,735 - INFO - training batch 301, loss: 1.494, 9632/28000 datapoints
2025-03-06 20:40:47,854 - INFO - training batch 351, loss: 1.407, 11232/28000 datapoints
2025-03-06 20:40:47,973 - INFO - training batch 401, loss: 1.421, 12832/28000 datapoints
2025-03-06 20:40:48,090 - INFO - training batch 451, loss: 1.370, 14432/28000 datapoints
2025-03-06 20:40:48,208 - INFO - training batch 501, loss: 1.245, 16032/28000 datapoints
2025-03-06 20:40:48,326 - INFO - training batch 551, loss: 1.375, 17632/28000 datapoints
2025-03-06 20:40:48,445 - INFO - training batch 601, loss: 1.433, 19232/28000 datapoints
2025-03-06 20:40:48,562 - INFO - training batch 651, loss: 1.054, 20832/28000 datapoints
2025-03-06 20:40:48,691 - INFO - training batch 701, loss: 1.179, 22432/28000 datapoints
2025-03-06 20:40:48,811 - INFO - training batch 751, loss: 1.502, 24032/28000 datapoints
2025-03-06 20:40:48,928 - INFO - training batch 801, loss: 1.172, 25632/28000 datapoints
2025-03-06 20:40:49,046 - INFO - training batch 851, loss: 1.365, 27232/28000 datapoints
2025-03-06 20:40:49,104 - INFO - validation batch 1, loss: 0.957, 32/6976 datapoints
2025-03-06 20:40:49,147 - INFO - validation batch 51, loss: 1.713, 1632/6976 datapoints
2025-03-06 20:40:49,192 - INFO - validation batch 101, loss: 1.352, 3232/6976 datapoints
2025-03-06 20:40:49,235 - INFO - validation batch 151, loss: 1.669, 4832/6976 datapoints
2025-03-06 20:40:49,278 - INFO - validation batch 201, loss: 0.841, 6432/6976 datapoints
2025-03-06 20:40:49,293 - INFO - Epoch 71/800 done.
2025-03-06 20:40:49,293 - INFO - Final validation performance:
Loss: 1.307, top-1 acc: 0.505top-5 acc: 0.505
2025-03-06 20:40:49,294 - INFO - Beginning epoch 72/800
2025-03-06 20:40:49,297 - INFO - training batch 1, loss: 1.526, 32/28000 datapoints
2025-03-06 20:40:49,416 - INFO - training batch 51, loss: 1.550, 1632/28000 datapoints
2025-03-06 20:40:49,537 - INFO - training batch 101, loss: 1.086, 3232/28000 datapoints
2025-03-06 20:40:49,662 - INFO - training batch 151, loss: 1.661, 4832/28000 datapoints
2025-03-06 20:40:49,786 - INFO - training batch 201, loss: 1.459, 6432/28000 datapoints
2025-03-06 20:40:49,904 - INFO - training batch 251, loss: 1.224, 8032/28000 datapoints
2025-03-06 20:40:50,025 - INFO - training batch 301, loss: 1.492, 9632/28000 datapoints
2025-03-06 20:40:50,142 - INFO - training batch 351, loss: 1.403, 11232/28000 datapoints
2025-03-06 20:40:50,261 - INFO - training batch 401, loss: 1.420, 12832/28000 datapoints
2025-03-06 20:40:50,383 - INFO - training batch 451, loss: 1.368, 14432/28000 datapoints
2025-03-06 20:40:50,501 - INFO - training batch 501, loss: 1.244, 16032/28000 datapoints
2025-03-06 20:40:50,620 - INFO - training batch 551, loss: 1.372, 17632/28000 datapoints
2025-03-06 20:40:50,749 - INFO - training batch 601, loss: 1.432, 19232/28000 datapoints
2025-03-06 20:40:50,869 - INFO - training batch 651, loss: 1.051, 20832/28000 datapoints
2025-03-06 20:40:50,991 - INFO - training batch 701, loss: 1.177, 22432/28000 datapoints
2025-03-06 20:40:51,110 - INFO - training batch 751, loss: 1.499, 24032/28000 datapoints
2025-03-06 20:40:51,229 - INFO - training batch 801, loss: 1.169, 25632/28000 datapoints
2025-03-06 20:40:51,364 - INFO - training batch 851, loss: 1.365, 27232/28000 datapoints
2025-03-06 20:40:51,424 - INFO - validation batch 1, loss: 0.956, 32/6976 datapoints
2025-03-06 20:40:51,468 - INFO - validation batch 51, loss: 1.711, 1632/6976 datapoints
2025-03-06 20:40:51,511 - INFO - validation batch 101, loss: 1.348, 3232/6976 datapoints
2025-03-06 20:40:51,553 - INFO - validation batch 151, loss: 1.667, 4832/6976 datapoints
2025-03-06 20:40:51,597 - INFO - validation batch 201, loss: 0.839, 6432/6976 datapoints
2025-03-06 20:40:51,614 - INFO - Epoch 72/800 done.
2025-03-06 20:40:51,614 - INFO - Final validation performance:
Loss: 1.304, top-1 acc: 0.505top-5 acc: 0.505
2025-03-06 20:40:51,614 - INFO - Beginning epoch 73/800
2025-03-06 20:40:51,618 - INFO - training batch 1, loss: 1.520, 32/28000 datapoints
2025-03-06 20:40:51,746 - INFO - training batch 51, loss: 1.547, 1632/28000 datapoints
2025-03-06 20:40:51,872 - INFO - training batch 101, loss: 1.084, 3232/28000 datapoints
2025-03-06 20:40:51,991 - INFO - training batch 151, loss: 1.658, 4832/28000 datapoints
2025-03-06 20:40:52,108 - INFO - training batch 201, loss: 1.455, 6432/28000 datapoints
2025-03-06 20:40:52,229 - INFO - training batch 251, loss: 1.221, 8032/28000 datapoints
2025-03-06 20:40:52,346 - INFO - training batch 301, loss: 1.489, 9632/28000 datapoints
2025-03-06 20:40:52,464 - INFO - training batch 351, loss: 1.399, 11232/28000 datapoints
2025-03-06 20:40:52,581 - INFO - training batch 401, loss: 1.417, 12832/28000 datapoints
2025-03-06 20:40:52,708 - INFO - training batch 451, loss: 1.366, 14432/28000 datapoints
2025-03-06 20:40:52,829 - INFO - training batch 501, loss: 1.244, 16032/28000 datapoints
2025-03-06 20:40:52,947 - INFO - training batch 551, loss: 1.370, 17632/28000 datapoints
2025-03-06 20:40:53,066 - INFO - training batch 601, loss: 1.432, 19232/28000 datapoints
2025-03-06 20:40:53,183 - INFO - training batch 651, loss: 1.048, 20832/28000 datapoints
2025-03-06 20:40:53,303 - INFO - training batch 701, loss: 1.175, 22432/28000 datapoints
2025-03-06 20:40:53,422 - INFO - training batch 751, loss: 1.495, 24032/28000 datapoints
2025-03-06 20:40:53,540 - INFO - training batch 801, loss: 1.166, 25632/28000 datapoints
2025-03-06 20:40:53,661 - INFO - training batch 851, loss: 1.364, 27232/28000 datapoints
2025-03-06 20:40:53,719 - INFO - validation batch 1, loss: 0.954, 32/6976 datapoints
2025-03-06 20:40:53,768 - INFO - validation batch 51, loss: 1.710, 1632/6976 datapoints
2025-03-06 20:40:53,813 - INFO - validation batch 101, loss: 1.345, 3232/6976 datapoints
2025-03-06 20:40:53,861 - INFO - validation batch 151, loss: 1.665, 4832/6976 datapoints
2025-03-06 20:40:53,905 - INFO - validation batch 201, loss: 0.837, 6432/6976 datapoints
2025-03-06 20:40:53,919 - INFO - Epoch 73/800 done.
2025-03-06 20:40:53,920 - INFO - Final validation performance:
Loss: 1.302, top-1 acc: 0.506top-5 acc: 0.506
2025-03-06 20:40:53,920 - INFO - Beginning epoch 74/800
2025-03-06 20:40:53,923 - INFO - training batch 1, loss: 1.515, 32/28000 datapoints
2025-03-06 20:40:54,045 - INFO - training batch 51, loss: 1.545, 1632/28000 datapoints
2025-03-06 20:40:54,163 - INFO - training batch 101, loss: 1.081, 3232/28000 datapoints
2025-03-06 20:40:54,284 - INFO - training batch 151, loss: 1.656, 4832/28000 datapoints
2025-03-06 20:40:54,401 - INFO - training batch 201, loss: 1.450, 6432/28000 datapoints
2025-03-06 20:40:54,519 - INFO - training batch 251, loss: 1.217, 8032/28000 datapoints
2025-03-06 20:40:54,640 - INFO - training batch 301, loss: 1.487, 9632/28000 datapoints
2025-03-06 20:40:54,764 - INFO - training batch 351, loss: 1.394, 11232/28000 datapoints
2025-03-06 20:40:54,887 - INFO - training batch 401, loss: 1.415, 12832/28000 datapoints
2025-03-06 20:40:55,008 - INFO - training batch 451, loss: 1.364, 14432/28000 datapoints
2025-03-06 20:40:55,128 - INFO - training batch 501, loss: 1.243, 16032/28000 datapoints
2025-03-06 20:40:55,248 - INFO - training batch 551, loss: 1.368, 17632/28000 datapoints
2025-03-06 20:40:55,367 - INFO - training batch 601, loss: 1.431, 19232/28000 datapoints
2025-03-06 20:40:55,487 - INFO - training batch 651, loss: 1.044, 20832/28000 datapoints
2025-03-06 20:40:55,621 - INFO - training batch 701, loss: 1.174, 22432/28000 datapoints
2025-03-06 20:40:55,757 - INFO - training batch 751, loss: 1.492, 24032/28000 datapoints
2025-03-06 20:40:55,879 - INFO - training batch 801, loss: 1.163, 25632/28000 datapoints
2025-03-06 20:40:55,998 - INFO - training batch 851, loss: 1.364, 27232/28000 datapoints
2025-03-06 20:40:56,057 - INFO - validation batch 1, loss: 0.952, 32/6976 datapoints
2025-03-06 20:40:56,101 - INFO - validation batch 51, loss: 1.708, 1632/6976 datapoints
2025-03-06 20:40:56,145 - INFO - validation batch 101, loss: 1.341, 3232/6976 datapoints
2025-03-06 20:40:56,189 - INFO - validation batch 151, loss: 1.662, 4832/6976 datapoints
2025-03-06 20:40:56,233 - INFO - validation batch 201, loss: 0.834, 6432/6976 datapoints
2025-03-06 20:40:56,248 - INFO - Epoch 74/800 done.
2025-03-06 20:40:56,249 - INFO - Final validation performance:
Loss: 1.299, top-1 acc: 0.506top-5 acc: 0.506
2025-03-06 20:40:56,249 - INFO - Beginning epoch 75/800
2025-03-06 20:40:56,253 - INFO - training batch 1, loss: 1.509, 32/28000 datapoints
2025-03-06 20:40:56,375 - INFO - training batch 51, loss: 1.542, 1632/28000 datapoints
2025-03-06 20:40:56,494 - INFO - training batch 101, loss: 1.078, 3232/28000 datapoints
2025-03-06 20:40:56,612 - INFO - training batch 151, loss: 1.653, 4832/28000 datapoints
2025-03-06 20:40:56,738 - INFO - training batch 201, loss: 1.445, 6432/28000 datapoints
2025-03-06 20:40:56,860 - INFO - training batch 251, loss: 1.212, 8032/28000 datapoints
2025-03-06 20:40:56,977 - INFO - training batch 301, loss: 1.484, 9632/28000 datapoints
2025-03-06 20:40:57,096 - INFO - training batch 351, loss: 1.389, 11232/28000 datapoints
2025-03-06 20:40:57,213 - INFO - training batch 401, loss: 1.413, 12832/28000 datapoints
2025-03-06 20:40:57,333 - INFO - training batch 451, loss: 1.362, 14432/28000 datapoints
2025-03-06 20:40:57,466 - INFO - training batch 501, loss: 1.243, 16032/28000 datapoints
2025-03-06 20:40:57,586 - INFO - training batch 551, loss: 1.365, 17632/28000 datapoints
2025-03-06 20:40:57,722 - INFO - training batch 601, loss: 1.430, 19232/28000 datapoints
2025-03-06 20:40:57,879 - INFO - training batch 651, loss: 1.040, 20832/28000 datapoints
2025-03-06 20:40:58,027 - INFO - training batch 701, loss: 1.172, 22432/28000 datapoints
2025-03-06 20:40:58,166 - INFO - training batch 751, loss: 1.489, 24032/28000 datapoints
2025-03-06 20:40:58,323 - INFO - training batch 801, loss: 1.159, 25632/28000 datapoints
2025-03-06 20:40:58,442 - INFO - training batch 851, loss: 1.362, 27232/28000 datapoints
2025-03-06 20:40:58,505 - INFO - validation batch 1, loss: 0.950, 32/6976 datapoints
2025-03-06 20:40:58,551 - INFO - validation batch 51, loss: 1.707, 1632/6976 datapoints
2025-03-06 20:40:58,596 - INFO - validation batch 101, loss: 1.335, 3232/6976 datapoints
2025-03-06 20:40:58,645 - INFO - validation batch 151, loss: 1.659, 4832/6976 datapoints
2025-03-06 20:40:58,690 - INFO - validation batch 201, loss: 0.831, 6432/6976 datapoints
2025-03-06 20:40:58,706 - INFO - Epoch 75/800 done.
2025-03-06 20:40:58,706 - INFO - Final validation performance:
Loss: 1.296, top-1 acc: 0.507top-5 acc: 0.507
2025-03-06 20:40:58,707 - INFO - Beginning epoch 76/800
2025-03-06 20:40:58,711 - INFO - training batch 1, loss: 1.504, 32/28000 datapoints
2025-03-06 20:40:58,845 - INFO - training batch 51, loss: 1.540, 1632/28000 datapoints
2025-03-06 20:40:58,970 - INFO - training batch 101, loss: 1.075, 3232/28000 datapoints
2025-03-06 20:40:59,090 - INFO - training batch 151, loss: 1.650, 4832/28000 datapoints
2025-03-06 20:40:59,207 - INFO - training batch 201, loss: 1.440, 6432/28000 datapoints
2025-03-06 20:40:59,328 - INFO - training batch 251, loss: 1.208, 8032/28000 datapoints
2025-03-06 20:40:59,446 - INFO - training batch 301, loss: 1.481, 9632/28000 datapoints
2025-03-06 20:40:59,564 - INFO - training batch 351, loss: 1.385, 11232/28000 datapoints
2025-03-06 20:40:59,684 - INFO - training batch 401, loss: 1.410, 12832/28000 datapoints
2025-03-06 20:40:59,804 - INFO - training batch 451, loss: 1.359, 14432/28000 datapoints
2025-03-06 20:40:59,928 - INFO - training batch 501, loss: 1.242, 16032/28000 datapoints
2025-03-06 20:41:00,049 - INFO - training batch 551, loss: 1.363, 17632/28000 datapoints
2025-03-06 20:41:00,167 - INFO - training batch 601, loss: 1.429, 19232/28000 datapoints
2025-03-06 20:41:00,286 - INFO - training batch 651, loss: 1.036, 20832/28000 datapoints
2025-03-06 20:41:00,405 - INFO - training batch 701, loss: 1.170, 22432/28000 datapoints
2025-03-06 20:41:00,524 - INFO - training batch 751, loss: 1.486, 24032/28000 datapoints
2025-03-06 20:41:00,643 - INFO - training batch 801, loss: 1.156, 25632/28000 datapoints
2025-03-06 20:41:00,766 - INFO - training batch 851, loss: 1.361, 27232/28000 datapoints
2025-03-06 20:41:00,826 - INFO - validation batch 1, loss: 0.948, 32/6976 datapoints
2025-03-06 20:41:00,872 - INFO - validation batch 51, loss: 1.704, 1632/6976 datapoints
2025-03-06 20:41:00,915 - INFO - validation batch 101, loss: 1.330, 3232/6976 datapoints
2025-03-06 20:41:00,958 - INFO - validation batch 151, loss: 1.655, 4832/6976 datapoints
2025-03-06 20:41:01,003 - INFO - validation batch 201, loss: 0.829, 6432/6976 datapoints
2025-03-06 20:41:01,018 - INFO - Epoch 76/800 done.
2025-03-06 20:41:01,018 - INFO - Final validation performance:
Loss: 1.293, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 20:41:01,018 - INFO - Beginning epoch 77/800
2025-03-06 20:41:01,022 - INFO - training batch 1, loss: 1.497, 32/28000 datapoints
2025-03-06 20:41:01,142 - INFO - training batch 51, loss: 1.538, 1632/28000 datapoints
2025-03-06 20:41:01,260 - INFO - training batch 101, loss: 1.072, 3232/28000 datapoints
2025-03-06 20:41:01,382 - INFO - training batch 151, loss: 1.648, 4832/28000 datapoints
2025-03-06 20:41:01,504 - INFO - training batch 201, loss: 1.435, 6432/28000 datapoints
2025-03-06 20:41:01,623 - INFO - training batch 251, loss: 1.203, 8032/28000 datapoints
2025-03-06 20:41:01,745 - INFO - training batch 301, loss: 1.477, 9632/28000 datapoints
2025-03-06 20:41:01,867 - INFO - training batch 351, loss: 1.381, 11232/28000 datapoints
2025-03-06 20:41:02,005 - INFO - training batch 401, loss: 1.406, 12832/28000 datapoints
2025-03-06 20:41:02,123 - INFO - training batch 451, loss: 1.357, 14432/28000 datapoints
2025-03-06 20:41:02,241 - INFO - training batch 501, loss: 1.242, 16032/28000 datapoints
2025-03-06 20:41:02,360 - INFO - training batch 551, loss: 1.360, 17632/28000 datapoints
2025-03-06 20:41:02,480 - INFO - training batch 601, loss: 1.429, 19232/28000 datapoints
2025-03-06 20:41:02,598 - INFO - training batch 651, loss: 1.032, 20832/28000 datapoints
2025-03-06 20:41:02,722 - INFO - training batch 701, loss: 1.167, 22432/28000 datapoints
2025-03-06 20:41:02,846 - INFO - training batch 751, loss: 1.482, 24032/28000 datapoints
2025-03-06 20:41:02,967 - INFO - training batch 801, loss: 1.153, 25632/28000 datapoints
2025-03-06 20:41:03,086 - INFO - training batch 851, loss: 1.360, 27232/28000 datapoints
2025-03-06 20:41:03,144 - INFO - validation batch 1, loss: 0.946, 32/6976 datapoints
2025-03-06 20:41:03,188 - INFO - validation batch 51, loss: 1.703, 1632/6976 datapoints
2025-03-06 20:41:03,233 - INFO - validation batch 101, loss: 1.324, 3232/6976 datapoints
2025-03-06 20:41:03,277 - INFO - validation batch 151, loss: 1.645, 4832/6976 datapoints
2025-03-06 20:41:03,321 - INFO - validation batch 201, loss: 0.826, 6432/6976 datapoints
2025-03-06 20:41:03,337 - INFO - Epoch 77/800 done.
2025-03-06 20:41:03,338 - INFO - Final validation performance:
Loss: 1.289, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 20:41:03,338 - INFO - Beginning epoch 78/800
2025-03-06 20:41:03,341 - INFO - training batch 1, loss: 1.490, 32/28000 datapoints
2025-03-06 20:41:03,466 - INFO - training batch 51, loss: 1.536, 1632/28000 datapoints
2025-03-06 20:41:03,600 - INFO - training batch 101, loss: 1.070, 3232/28000 datapoints
2025-03-06 20:41:03,722 - INFO - training batch 151, loss: 1.645, 4832/28000 datapoints
2025-03-06 20:41:03,849 - INFO - training batch 201, loss: 1.430, 6432/28000 datapoints
2025-03-06 20:41:03,974 - INFO - training batch 251, loss: 1.197, 8032/28000 datapoints
2025-03-06 20:41:04,107 - INFO - training batch 301, loss: 1.471, 9632/28000 datapoints
2025-03-06 20:41:04,232 - INFO - training batch 351, loss: 1.376, 11232/28000 datapoints
2025-03-06 20:41:04,357 - INFO - training batch 401, loss: 1.402, 12832/28000 datapoints
2025-03-06 20:41:04,487 - INFO - training batch 451, loss: 1.354, 14432/28000 datapoints
2025-03-06 20:41:04,610 - INFO - training batch 501, loss: 1.240, 16032/28000 datapoints
2025-03-06 20:41:04,738 - INFO - training batch 551, loss: 1.356, 17632/28000 datapoints
2025-03-06 20:41:04,870 - INFO - training batch 601, loss: 1.429, 19232/28000 datapoints
2025-03-06 20:41:04,999 - INFO - training batch 651, loss: 1.028, 20832/28000 datapoints
2025-03-06 20:41:05,125 - INFO - training batch 701, loss: 1.165, 22432/28000 datapoints
2025-03-06 20:41:05,248 - INFO - training batch 751, loss: 1.477, 24032/28000 datapoints
2025-03-06 20:41:05,371 - INFO - training batch 801, loss: 1.150, 25632/28000 datapoints
2025-03-06 20:41:05,495 - INFO - training batch 851, loss: 1.356, 27232/28000 datapoints
2025-03-06 20:41:05,556 - INFO - validation batch 1, loss: 0.946, 32/6976 datapoints
2025-03-06 20:41:05,606 - INFO - validation batch 51, loss: 1.703, 1632/6976 datapoints
2025-03-06 20:41:05,656 - INFO - validation batch 101, loss: 1.319, 3232/6976 datapoints
2025-03-06 20:41:05,716 - INFO - validation batch 151, loss: 1.634, 4832/6976 datapoints
2025-03-06 20:41:05,782 - INFO - validation batch 201, loss: 0.822, 6432/6976 datapoints
2025-03-06 20:41:05,796 - INFO - Epoch 78/800 done.
2025-03-06 20:41:05,797 - INFO - Final validation performance:
Loss: 1.285, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 20:41:05,797 - INFO - Beginning epoch 79/800
2025-03-06 20:41:05,801 - INFO - training batch 1, loss: 1.483, 32/28000 datapoints
2025-03-06 20:41:05,929 - INFO - training batch 51, loss: 1.534, 1632/28000 datapoints
2025-03-06 20:41:06,055 - INFO - training batch 101, loss: 1.066, 3232/28000 datapoints
2025-03-06 20:41:06,178 - INFO - training batch 151, loss: 1.645, 4832/28000 datapoints
2025-03-06 20:41:06,303 - INFO - training batch 201, loss: 1.425, 6432/28000 datapoints
2025-03-06 20:41:06,425 - INFO - training batch 251, loss: 1.191, 8032/28000 datapoints
2025-03-06 20:41:06,549 - INFO - training batch 301, loss: 1.462, 9632/28000 datapoints
2025-03-06 20:41:06,676 - INFO - training batch 351, loss: 1.366, 11232/28000 datapoints
2025-03-06 20:41:06,805 - INFO - training batch 401, loss: 1.403, 12832/28000 datapoints
2025-03-06 20:41:06,927 - INFO - training batch 451, loss: 1.350, 14432/28000 datapoints
2025-03-06 20:41:07,052 - INFO - training batch 501, loss: 1.242, 16032/28000 datapoints
2025-03-06 20:41:07,176 - INFO - training batch 551, loss: 1.352, 17632/28000 datapoints
2025-03-06 20:41:07,298 - INFO - training batch 601, loss: 1.425, 19232/28000 datapoints
2025-03-06 20:41:07,422 - INFO - training batch 651, loss: 1.028, 20832/28000 datapoints
2025-03-06 20:41:07,545 - INFO - training batch 701, loss: 1.161, 22432/28000 datapoints
2025-03-06 20:41:07,673 - INFO - training batch 751, loss: 1.471, 24032/28000 datapoints
2025-03-06 20:41:07,797 - INFO - training batch 801, loss: 1.145, 25632/28000 datapoints
2025-03-06 20:41:07,922 - INFO - training batch 851, loss: 1.346, 27232/28000 datapoints
2025-03-06 20:41:07,987 - INFO - validation batch 1, loss: 0.948, 32/6976 datapoints
2025-03-06 20:41:08,033 - INFO - validation batch 51, loss: 1.705, 1632/6976 datapoints
2025-03-06 20:41:08,080 - INFO - validation batch 101, loss: 1.311, 3232/6976 datapoints
2025-03-06 20:41:08,127 - INFO - validation batch 151, loss: 1.623, 4832/6976 datapoints
2025-03-06 20:41:08,173 - INFO - validation batch 201, loss: 0.819, 6432/6976 datapoints
2025-03-06 20:41:08,190 - INFO - Epoch 79/800 done.
2025-03-06 20:41:08,190 - INFO - Final validation performance:
Loss: 1.281, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 20:41:08,190 - INFO - Beginning epoch 80/800
2025-03-06 20:41:08,194 - INFO - training batch 1, loss: 1.478, 32/28000 datapoints
2025-03-06 20:41:08,319 - INFO - training batch 51, loss: 1.536, 1632/28000 datapoints
2025-03-06 20:41:08,443 - INFO - training batch 101, loss: 1.061, 3232/28000 datapoints
2025-03-06 20:41:08,568 - INFO - training batch 151, loss: 1.644, 4832/28000 datapoints
2025-03-06 20:41:08,693 - INFO - training batch 201, loss: 1.416, 6432/28000 datapoints
2025-03-06 20:41:08,824 - INFO - training batch 251, loss: 1.185, 8032/28000 datapoints
2025-03-06 20:41:08,948 - INFO - training batch 301, loss: 1.451, 9632/28000 datapoints
2025-03-06 20:41:09,078 - INFO - training batch 351, loss: 1.356, 11232/28000 datapoints
2025-03-06 20:41:09,201 - INFO - training batch 401, loss: 1.399, 12832/28000 datapoints
2025-03-06 20:41:09,323 - INFO - training batch 451, loss: 1.346, 14432/28000 datapoints
2025-03-06 20:41:09,445 - INFO - training batch 501, loss: 1.241, 16032/28000 datapoints
2025-03-06 20:41:09,568 - INFO - training batch 551, loss: 1.350, 17632/28000 datapoints
2025-03-06 20:41:09,705 - INFO - training batch 601, loss: 1.422, 19232/28000 datapoints
2025-03-06 20:41:09,831 - INFO - training batch 651, loss: 1.025, 20832/28000 datapoints
2025-03-06 20:41:09,954 - INFO - training batch 701, loss: 1.158, 22432/28000 datapoints
2025-03-06 20:41:10,082 - INFO - training batch 751, loss: 1.466, 24032/28000 datapoints
2025-03-06 20:41:10,210 - INFO - training batch 801, loss: 1.141, 25632/28000 datapoints
2025-03-06 20:41:10,335 - INFO - training batch 851, loss: 1.340, 27232/28000 datapoints
2025-03-06 20:41:10,400 - INFO - validation batch 1, loss: 0.947, 32/6976 datapoints
2025-03-06 20:41:10,449 - INFO - validation batch 51, loss: 1.706, 1632/6976 datapoints
2025-03-06 20:41:10,499 - INFO - validation batch 101, loss: 1.303, 3232/6976 datapoints
2025-03-06 20:41:10,547 - INFO - validation batch 151, loss: 1.615, 4832/6976 datapoints
2025-03-06 20:41:10,599 - INFO - validation batch 201, loss: 0.816, 6432/6976 datapoints
2025-03-06 20:41:10,613 - INFO - Epoch 80/800 done.
2025-03-06 20:41:10,614 - INFO - Final validation performance:
Loss: 1.277, top-1 acc: 0.512top-5 acc: 0.512
2025-03-06 20:41:10,614 - INFO - Beginning epoch 81/800
2025-03-06 20:41:10,618 - INFO - training batch 1, loss: 1.472, 32/28000 datapoints
2025-03-06 20:41:10,746 - INFO - training batch 51, loss: 1.536, 1632/28000 datapoints
2025-03-06 20:41:10,877 - INFO - training batch 101, loss: 1.055, 3232/28000 datapoints
2025-03-06 20:41:11,003 - INFO - training batch 151, loss: 1.642, 4832/28000 datapoints
2025-03-06 20:41:11,128 - INFO - training batch 201, loss: 1.410, 6432/28000 datapoints
2025-03-06 20:41:11,252 - INFO - training batch 251, loss: 1.180, 8032/28000 datapoints
2025-03-06 20:41:11,376 - INFO - training batch 301, loss: 1.444, 9632/28000 datapoints
2025-03-06 20:41:11,501 - INFO - training batch 351, loss: 1.349, 11232/28000 datapoints
2025-03-06 20:41:11,623 - INFO - training batch 401, loss: 1.395, 12832/28000 datapoints
2025-03-06 20:41:11,754 - INFO - training batch 451, loss: 1.342, 14432/28000 datapoints
2025-03-06 20:41:11,878 - INFO - training batch 501, loss: 1.241, 16032/28000 datapoints
2025-03-06 20:41:12,003 - INFO - training batch 551, loss: 1.347, 17632/28000 datapoints
2025-03-06 20:41:12,129 - INFO - training batch 601, loss: 1.419, 19232/28000 datapoints
2025-03-06 20:41:12,253 - INFO - training batch 651, loss: 1.022, 20832/28000 datapoints
2025-03-06 20:41:12,376 - INFO - training batch 701, loss: 1.154, 22432/28000 datapoints
2025-03-06 20:41:12,499 - INFO - training batch 751, loss: 1.462, 24032/28000 datapoints
2025-03-06 20:41:12,626 - INFO - training batch 801, loss: 1.136, 25632/28000 datapoints
2025-03-06 20:41:12,751 - INFO - training batch 851, loss: 1.336, 27232/28000 datapoints
2025-03-06 20:41:12,818 - INFO - validation batch 1, loss: 0.945, 32/6976 datapoints
2025-03-06 20:41:12,866 - INFO - validation batch 51, loss: 1.707, 1632/6976 datapoints
2025-03-06 20:41:12,915 - INFO - validation batch 101, loss: 1.296, 3232/6976 datapoints
2025-03-06 20:41:12,961 - INFO - validation batch 151, loss: 1.607, 4832/6976 datapoints
2025-03-06 20:41:13,008 - INFO - validation batch 201, loss: 0.813, 6432/6976 datapoints
2025-03-06 20:41:13,028 - INFO - Epoch 81/800 done.
2025-03-06 20:41:13,028 - INFO - Final validation performance:
Loss: 1.274, top-1 acc: 0.513top-5 acc: 0.513
2025-03-06 20:41:13,030 - INFO - Beginning epoch 82/800
2025-03-06 20:41:13,034 - INFO - training batch 1, loss: 1.465, 32/28000 datapoints
2025-03-06 20:41:13,160 - INFO - training batch 51, loss: 1.535, 1632/28000 datapoints
2025-03-06 20:41:13,284 - INFO - training batch 101, loss: 1.051, 3232/28000 datapoints
2025-03-06 20:41:13,418 - INFO - training batch 151, loss: 1.638, 4832/28000 datapoints
2025-03-06 20:41:13,564 - INFO - training batch 201, loss: 1.405, 6432/28000 datapoints
2025-03-06 20:41:13,698 - INFO - training batch 251, loss: 1.175, 8032/28000 datapoints
2025-03-06 20:41:13,821 - INFO - training batch 301, loss: 1.438, 9632/28000 datapoints
2025-03-06 20:41:13,945 - INFO - training batch 351, loss: 1.341, 11232/28000 datapoints
2025-03-06 20:41:14,070 - INFO - training batch 401, loss: 1.390, 12832/28000 datapoints
2025-03-06 20:41:14,195 - INFO - training batch 451, loss: 1.340, 14432/28000 datapoints
2025-03-06 20:41:14,319 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 20:41:14,444 - INFO - training batch 551, loss: 1.345, 17632/28000 datapoints
2025-03-06 20:41:14,567 - INFO - training batch 601, loss: 1.417, 19232/28000 datapoints
2025-03-06 20:41:14,693 - INFO - training batch 651, loss: 1.018, 20832/28000 datapoints
2025-03-06 20:41:14,821 - INFO - training batch 701, loss: 1.151, 22432/28000 datapoints
2025-03-06 20:41:14,953 - INFO - training batch 751, loss: 1.458, 24032/28000 datapoints
2025-03-06 20:41:15,079 - INFO - training batch 801, loss: 1.132, 25632/28000 datapoints
2025-03-06 20:41:15,204 - INFO - training batch 851, loss: 1.334, 27232/28000 datapoints
2025-03-06 20:41:15,266 - INFO - validation batch 1, loss: 0.943, 32/6976 datapoints
2025-03-06 20:41:15,313 - INFO - validation batch 51, loss: 1.706, 1632/6976 datapoints
2025-03-06 20:41:15,360 - INFO - validation batch 101, loss: 1.290, 3232/6976 datapoints
2025-03-06 20:41:15,407 - INFO - validation batch 151, loss: 1.599, 4832/6976 datapoints
2025-03-06 20:41:15,454 - INFO - validation batch 201, loss: 0.811, 6432/6976 datapoints
2025-03-06 20:41:15,470 - INFO - Epoch 82/800 done.
2025-03-06 20:41:15,470 - INFO - Final validation performance:
Loss: 1.270, top-1 acc: 0.515top-5 acc: 0.515
2025-03-06 20:41:15,471 - INFO - Beginning epoch 83/800
2025-03-06 20:41:15,477 - INFO - training batch 1, loss: 1.458, 32/28000 datapoints
2025-03-06 20:41:15,606 - INFO - training batch 51, loss: 1.534, 1632/28000 datapoints
2025-03-06 20:41:15,733 - INFO - training batch 101, loss: 1.046, 3232/28000 datapoints
2025-03-06 20:41:15,895 - INFO - training batch 151, loss: 1.634, 4832/28000 datapoints
2025-03-06 20:41:16,020 - INFO - training batch 201, loss: 1.399, 6432/28000 datapoints
2025-03-06 20:41:16,143 - INFO - training batch 251, loss: 1.169, 8032/28000 datapoints
2025-03-06 20:41:16,267 - INFO - training batch 301, loss: 1.433, 9632/28000 datapoints
2025-03-06 20:41:16,395 - INFO - training batch 351, loss: 1.336, 11232/28000 datapoints
2025-03-06 20:41:16,523 - INFO - training batch 401, loss: 1.385, 12832/28000 datapoints
2025-03-06 20:41:16,650 - INFO - training batch 451, loss: 1.337, 14432/28000 datapoints
2025-03-06 20:41:16,776 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 20:41:16,905 - INFO - training batch 551, loss: 1.342, 17632/28000 datapoints
2025-03-06 20:41:17,029 - INFO - training batch 601, loss: 1.414, 19232/28000 datapoints
2025-03-06 20:41:17,155 - INFO - training batch 651, loss: 1.013, 20832/28000 datapoints
2025-03-06 20:41:17,281 - INFO - training batch 701, loss: 1.147, 22432/28000 datapoints
2025-03-06 20:41:17,410 - INFO - training batch 751, loss: 1.452, 24032/28000 datapoints
2025-03-06 20:41:17,561 - INFO - training batch 801, loss: 1.128, 25632/28000 datapoints
2025-03-06 20:41:17,714 - INFO - training batch 851, loss: 1.331, 27232/28000 datapoints
2025-03-06 20:41:17,789 - INFO - validation batch 1, loss: 0.941, 32/6976 datapoints
2025-03-06 20:41:17,844 - INFO - validation batch 51, loss: 1.707, 1632/6976 datapoints
2025-03-06 20:41:17,905 - INFO - validation batch 101, loss: 1.283, 3232/6976 datapoints
2025-03-06 20:41:17,962 - INFO - validation batch 151, loss: 1.591, 4832/6976 datapoints
2025-03-06 20:41:18,021 - INFO - validation batch 201, loss: 0.809, 6432/6976 datapoints
2025-03-06 20:41:18,044 - INFO - Epoch 83/800 done.
2025-03-06 20:41:18,044 - INFO - Final validation performance:
Loss: 1.266, top-1 acc: 0.516top-5 acc: 0.516
2025-03-06 20:41:18,045 - INFO - Beginning epoch 84/800
2025-03-06 20:41:18,048 - INFO - training batch 1, loss: 1.449, 32/28000 datapoints
2025-03-06 20:41:18,194 - INFO - training batch 51, loss: 1.532, 1632/28000 datapoints
2025-03-06 20:41:18,350 - INFO - training batch 101, loss: 1.041, 3232/28000 datapoints
2025-03-06 20:41:18,477 - INFO - training batch 151, loss: 1.630, 4832/28000 datapoints
2025-03-06 20:41:18,602 - INFO - training batch 201, loss: 1.393, 6432/28000 datapoints
2025-03-06 20:41:18,726 - INFO - training batch 251, loss: 1.165, 8032/28000 datapoints
2025-03-06 20:41:18,856 - INFO - training batch 301, loss: 1.427, 9632/28000 datapoints
2025-03-06 20:41:18,981 - INFO - training batch 351, loss: 1.330, 11232/28000 datapoints
2025-03-06 20:41:19,105 - INFO - training batch 401, loss: 1.380, 12832/28000 datapoints
2025-03-06 20:41:19,229 - INFO - training batch 451, loss: 1.334, 14432/28000 datapoints
2025-03-06 20:41:19,359 - INFO - training batch 501, loss: 1.232, 16032/28000 datapoints
2025-03-06 20:41:19,483 - INFO - training batch 551, loss: 1.337, 17632/28000 datapoints
2025-03-06 20:41:19,609 - INFO - training batch 601, loss: 1.412, 19232/28000 datapoints
2025-03-06 20:41:19,736 - INFO - training batch 651, loss: 1.007, 20832/28000 datapoints
2025-03-06 20:41:19,860 - INFO - training batch 701, loss: 1.142, 22432/28000 datapoints
2025-03-06 20:41:19,986 - INFO - training batch 751, loss: 1.448, 24032/28000 datapoints
2025-03-06 20:41:20,116 - INFO - training batch 801, loss: 1.122, 25632/28000 datapoints
2025-03-06 20:41:20,239 - INFO - training batch 851, loss: 1.328, 27232/28000 datapoints
2025-03-06 20:41:20,301 - INFO - validation batch 1, loss: 0.939, 32/6976 datapoints
2025-03-06 20:41:20,349 - INFO - validation batch 51, loss: 1.707, 1632/6976 datapoints
2025-03-06 20:41:20,399 - INFO - validation batch 101, loss: 1.277, 3232/6976 datapoints
2025-03-06 20:41:20,449 - INFO - validation batch 151, loss: 1.582, 4832/6976 datapoints
2025-03-06 20:41:20,500 - INFO - validation batch 201, loss: 0.807, 6432/6976 datapoints
2025-03-06 20:41:20,515 - INFO - Epoch 84/800 done.
2025-03-06 20:41:20,515 - INFO - Final validation performance:
Loss: 1.262, top-1 acc: 0.518top-5 acc: 0.518
2025-03-06 20:41:20,516 - INFO - Beginning epoch 85/800
2025-03-06 20:41:20,520 - INFO - training batch 1, loss: 1.440, 32/28000 datapoints
2025-03-06 20:41:20,657 - INFO - training batch 51, loss: 1.530, 1632/28000 datapoints
2025-03-06 20:41:20,781 - INFO - training batch 101, loss: 1.037, 3232/28000 datapoints
2025-03-06 20:41:20,912 - INFO - training batch 151, loss: 1.626, 4832/28000 datapoints
2025-03-06 20:41:21,036 - INFO - training batch 201, loss: 1.387, 6432/28000 datapoints
2025-03-06 20:41:21,165 - INFO - training batch 251, loss: 1.160, 8032/28000 datapoints
2025-03-06 20:41:21,289 - INFO - training batch 301, loss: 1.422, 9632/28000 datapoints
2025-03-06 20:41:21,414 - INFO - training batch 351, loss: 1.324, 11232/28000 datapoints
2025-03-06 20:41:21,537 - INFO - training batch 401, loss: 1.374, 12832/28000 datapoints
2025-03-06 20:41:21,665 - INFO - training batch 451, loss: 1.331, 14432/28000 datapoints
2025-03-06 20:41:21,787 - INFO - training batch 501, loss: 1.228, 16032/28000 datapoints
2025-03-06 20:41:21,926 - INFO - training batch 551, loss: 1.333, 17632/28000 datapoints
2025-03-06 20:41:22,055 - INFO - training batch 601, loss: 1.410, 19232/28000 datapoints
2025-03-06 20:41:22,181 - INFO - training batch 651, loss: 1.001, 20832/28000 datapoints
2025-03-06 20:41:22,306 - INFO - training batch 701, loss: 1.138, 22432/28000 datapoints
2025-03-06 20:41:22,428 - INFO - training batch 751, loss: 1.444, 24032/28000 datapoints
2025-03-06 20:41:22,559 - INFO - training batch 801, loss: 1.116, 25632/28000 datapoints
2025-03-06 20:41:22,686 - INFO - training batch 851, loss: 1.326, 27232/28000 datapoints
2025-03-06 20:41:22,749 - INFO - validation batch 1, loss: 0.937, 32/6976 datapoints
2025-03-06 20:41:22,798 - INFO - validation batch 51, loss: 1.706, 1632/6976 datapoints
2025-03-06 20:41:22,850 - INFO - validation batch 101, loss: 1.271, 3232/6976 datapoints
2025-03-06 20:41:22,898 - INFO - validation batch 151, loss: 1.575, 4832/6976 datapoints
2025-03-06 20:41:22,950 - INFO - validation batch 201, loss: 0.805, 6432/6976 datapoints
2025-03-06 20:41:22,966 - INFO - Epoch 85/800 done.
2025-03-06 20:41:22,966 - INFO - Final validation performance:
Loss: 1.259, top-1 acc: 0.519top-5 acc: 0.519
2025-03-06 20:41:22,967 - INFO - Beginning epoch 86/800
2025-03-06 20:41:22,971 - INFO - training batch 1, loss: 1.432, 32/28000 datapoints
2025-03-06 20:41:23,098 - INFO - training batch 51, loss: 1.528, 1632/28000 datapoints
2025-03-06 20:41:23,225 - INFO - training batch 101, loss: 1.033, 3232/28000 datapoints
2025-03-06 20:41:23,351 - INFO - training batch 151, loss: 1.622, 4832/28000 datapoints
2025-03-06 20:41:23,474 - INFO - training batch 201, loss: 1.381, 6432/28000 datapoints
2025-03-06 20:41:23,597 - INFO - training batch 251, loss: 1.154, 8032/28000 datapoints
2025-03-06 20:41:23,725 - INFO - training batch 301, loss: 1.417, 9632/28000 datapoints
2025-03-06 20:41:23,847 - INFO - training batch 351, loss: 1.315, 11232/28000 datapoints
2025-03-06 20:41:23,971 - INFO - training batch 401, loss: 1.369, 12832/28000 datapoints
2025-03-06 20:41:24,097 - INFO - training batch 451, loss: 1.327, 14432/28000 datapoints
2025-03-06 20:41:24,224 - INFO - training batch 501, loss: 1.222, 16032/28000 datapoints
2025-03-06 20:41:24,346 - INFO - training batch 551, loss: 1.328, 17632/28000 datapoints
2025-03-06 20:41:24,469 - INFO - training batch 601, loss: 1.408, 19232/28000 datapoints
2025-03-06 20:41:24,592 - INFO - training batch 651, loss: 0.994, 20832/28000 datapoints
2025-03-06 20:41:24,720 - INFO - training batch 701, loss: 1.133, 22432/28000 datapoints
2025-03-06 20:41:24,843 - INFO - training batch 751, loss: 1.438, 24032/28000 datapoints
2025-03-06 20:41:24,975 - INFO - training batch 801, loss: 1.111, 25632/28000 datapoints
2025-03-06 20:41:25,099 - INFO - training batch 851, loss: 1.322, 27232/28000 datapoints
2025-03-06 20:41:25,161 - INFO - validation batch 1, loss: 0.934, 32/6976 datapoints
2025-03-06 20:41:25,211 - INFO - validation batch 51, loss: 1.705, 1632/6976 datapoints
2025-03-06 20:41:25,258 - INFO - validation batch 101, loss: 1.266, 3232/6976 datapoints
2025-03-06 20:41:25,308 - INFO - validation batch 151, loss: 1.567, 4832/6976 datapoints
2025-03-06 20:41:25,354 - INFO - validation batch 201, loss: 0.802, 6432/6976 datapoints
2025-03-06 20:41:25,370 - INFO - Epoch 86/800 done.
2025-03-06 20:41:25,371 - INFO - Final validation performance:
Loss: 1.255, top-1 acc: 0.520top-5 acc: 0.520
2025-03-06 20:41:25,371 - INFO - Beginning epoch 87/800
2025-03-06 20:41:25,375 - INFO - training batch 1, loss: 1.424, 32/28000 datapoints
2025-03-06 20:41:25,504 - INFO - training batch 51, loss: 1.526, 1632/28000 datapoints
2025-03-06 20:41:25,627 - INFO - training batch 101, loss: 1.028, 3232/28000 datapoints
2025-03-06 20:41:25,756 - INFO - training batch 151, loss: 1.618, 4832/28000 datapoints
2025-03-06 20:41:25,884 - INFO - training batch 201, loss: 1.375, 6432/28000 datapoints
2025-03-06 20:41:26,033 - INFO - training batch 251, loss: 1.149, 8032/28000 datapoints
2025-03-06 20:41:26,157 - INFO - training batch 301, loss: 1.411, 9632/28000 datapoints
2025-03-06 20:41:26,282 - INFO - training batch 351, loss: 1.307, 11232/28000 datapoints
2025-03-06 20:41:26,405 - INFO - training batch 401, loss: 1.363, 12832/28000 datapoints
2025-03-06 20:41:26,527 - INFO - training batch 451, loss: 1.323, 14432/28000 datapoints
2025-03-06 20:41:26,654 - INFO - training batch 501, loss: 1.216, 16032/28000 datapoints
2025-03-06 20:41:26,777 - INFO - training batch 551, loss: 1.323, 17632/28000 datapoints
2025-03-06 20:41:26,905 - INFO - training batch 601, loss: 1.406, 19232/28000 datapoints
2025-03-06 20:41:27,031 - INFO - training batch 651, loss: 0.987, 20832/28000 datapoints
2025-03-06 20:41:27,154 - INFO - training batch 701, loss: 1.128, 22432/28000 datapoints
2025-03-06 20:41:27,279 - INFO - training batch 751, loss: 1.432, 24032/28000 datapoints
2025-03-06 20:41:27,403 - INFO - training batch 801, loss: 1.104, 25632/28000 datapoints
2025-03-06 20:41:27,527 - INFO - training batch 851, loss: 1.319, 27232/28000 datapoints
2025-03-06 20:41:27,588 - INFO - validation batch 1, loss: 0.931, 32/6976 datapoints
2025-03-06 20:41:27,639 - INFO - validation batch 51, loss: 1.704, 1632/6976 datapoints
2025-03-06 20:41:27,689 - INFO - validation batch 101, loss: 1.261, 3232/6976 datapoints
2025-03-06 20:41:27,737 - INFO - validation batch 151, loss: 1.561, 4832/6976 datapoints
2025-03-06 20:41:27,786 - INFO - validation batch 201, loss: 0.800, 6432/6976 datapoints
2025-03-06 20:41:27,802 - INFO - Epoch 87/800 done.
2025-03-06 20:41:27,802 - INFO - Final validation performance:
Loss: 1.251, top-1 acc: 0.522top-5 acc: 0.522
2025-03-06 20:41:27,802 - INFO - Beginning epoch 88/800
2025-03-06 20:41:27,806 - INFO - training batch 1, loss: 1.417, 32/28000 datapoints
2025-03-06 20:41:27,929 - INFO - training batch 51, loss: 1.523, 1632/28000 datapoints
2025-03-06 20:41:28,070 - INFO - training batch 101, loss: 1.023, 3232/28000 datapoints
2025-03-06 20:41:28,194 - INFO - training batch 151, loss: 1.614, 4832/28000 datapoints
2025-03-06 20:41:28,320 - INFO - training batch 201, loss: 1.368, 6432/28000 datapoints
2025-03-06 20:41:28,454 - INFO - training batch 251, loss: 1.142, 8032/28000 datapoints
2025-03-06 20:41:28,580 - INFO - training batch 301, loss: 1.405, 9632/28000 datapoints
2025-03-06 20:41:28,705 - INFO - training batch 351, loss: 1.298, 11232/28000 datapoints
2025-03-06 20:41:28,839 - INFO - training batch 401, loss: 1.357, 12832/28000 datapoints
2025-03-06 20:41:28,980 - INFO - training batch 451, loss: 1.319, 14432/28000 datapoints
2025-03-06 20:41:29,102 - INFO - training batch 501, loss: 1.211, 16032/28000 datapoints
2025-03-06 20:41:29,227 - INFO - training batch 551, loss: 1.318, 17632/28000 datapoints
2025-03-06 20:41:29,353 - INFO - training batch 601, loss: 1.403, 19232/28000 datapoints
2025-03-06 20:41:29,478 - INFO - training batch 651, loss: 0.980, 20832/28000 datapoints
2025-03-06 20:41:29,601 - INFO - training batch 701, loss: 1.123, 22432/28000 datapoints
2025-03-06 20:41:29,727 - INFO - training batch 751, loss: 1.425, 24032/28000 datapoints
2025-03-06 20:41:29,853 - INFO - training batch 801, loss: 1.098, 25632/28000 datapoints
2025-03-06 20:41:29,978 - INFO - training batch 851, loss: 1.317, 27232/28000 datapoints
2025-03-06 20:41:30,042 - INFO - validation batch 1, loss: 0.927, 32/6976 datapoints
2025-03-06 20:41:30,090 - INFO - validation batch 51, loss: 1.703, 1632/6976 datapoints
2025-03-06 20:41:30,137 - INFO - validation batch 101, loss: 1.255, 3232/6976 datapoints
2025-03-06 20:41:30,186 - INFO - validation batch 151, loss: 1.554, 4832/6976 datapoints
2025-03-06 20:41:30,235 - INFO - validation batch 201, loss: 0.797, 6432/6976 datapoints
2025-03-06 20:41:30,253 - INFO - Epoch 88/800 done.
2025-03-06 20:41:30,253 - INFO - Final validation performance:
Loss: 1.247, top-1 acc: 0.526top-5 acc: 0.526
2025-03-06 20:41:30,253 - INFO - Beginning epoch 89/800
2025-03-06 20:41:30,257 - INFO - training batch 1, loss: 1.407, 32/28000 datapoints
2025-03-06 20:41:30,380 - INFO - training batch 51, loss: 1.520, 1632/28000 datapoints
2025-03-06 20:41:30,504 - INFO - training batch 101, loss: 1.018, 3232/28000 datapoints
2025-03-06 20:41:30,627 - INFO - training batch 151, loss: 1.610, 4832/28000 datapoints
2025-03-06 20:41:30,754 - INFO - training batch 201, loss: 1.364, 6432/28000 datapoints
2025-03-06 20:41:30,893 - INFO - training batch 251, loss: 1.135, 8032/28000 datapoints
2025-03-06 20:41:31,017 - INFO - training batch 301, loss: 1.398, 9632/28000 datapoints
2025-03-06 20:41:31,139 - INFO - training batch 351, loss: 1.289, 11232/28000 datapoints
2025-03-06 20:41:31,262 - INFO - training batch 401, loss: 1.350, 12832/28000 datapoints
2025-03-06 20:41:31,386 - INFO - training batch 451, loss: 1.316, 14432/28000 datapoints
2025-03-06 20:41:31,515 - INFO - training batch 501, loss: 1.205, 16032/28000 datapoints
2025-03-06 20:41:31,699 - INFO - training batch 551, loss: 1.313, 17632/28000 datapoints
2025-03-06 20:41:31,823 - INFO - training batch 601, loss: 1.401, 19232/28000 datapoints
2025-03-06 20:41:31,948 - INFO - training batch 651, loss: 0.972, 20832/28000 datapoints
2025-03-06 20:41:32,080 - INFO - training batch 701, loss: 1.118, 22432/28000 datapoints
2025-03-06 20:41:32,206 - INFO - training batch 751, loss: 1.419, 24032/28000 datapoints
2025-03-06 20:41:32,334 - INFO - training batch 801, loss: 1.092, 25632/28000 datapoints
2025-03-06 20:41:32,456 - INFO - training batch 851, loss: 1.313, 27232/28000 datapoints
2025-03-06 20:41:32,519 - INFO - validation batch 1, loss: 0.923, 32/6976 datapoints
2025-03-06 20:41:32,568 - INFO - validation batch 51, loss: 1.703, 1632/6976 datapoints
2025-03-06 20:41:32,616 - INFO - validation batch 101, loss: 1.248, 3232/6976 datapoints
2025-03-06 20:41:32,665 - INFO - validation batch 151, loss: 1.547, 4832/6976 datapoints
2025-03-06 20:41:32,714 - INFO - validation batch 201, loss: 0.795, 6432/6976 datapoints
2025-03-06 20:41:32,732 - INFO - Epoch 89/800 done.
2025-03-06 20:41:32,732 - INFO - Final validation performance:
Loss: 1.243, top-1 acc: 0.527top-5 acc: 0.527
2025-03-06 20:41:32,733 - INFO - Beginning epoch 90/800
2025-03-06 20:41:32,736 - INFO - training batch 1, loss: 1.399, 32/28000 datapoints
2025-03-06 20:41:32,864 - INFO - training batch 51, loss: 1.517, 1632/28000 datapoints
2025-03-06 20:41:32,991 - INFO - training batch 101, loss: 1.012, 3232/28000 datapoints
2025-03-06 20:41:33,142 - INFO - training batch 151, loss: 1.606, 4832/28000 datapoints
2025-03-06 20:41:33,281 - INFO - training batch 201, loss: 1.360, 6432/28000 datapoints
2025-03-06 20:41:33,405 - INFO - training batch 251, loss: 1.127, 8032/28000 datapoints
2025-03-06 20:41:33,532 - INFO - training batch 301, loss: 1.391, 9632/28000 datapoints
2025-03-06 20:41:33,660 - INFO - training batch 351, loss: 1.279, 11232/28000 datapoints
2025-03-06 20:41:33,784 - INFO - training batch 401, loss: 1.343, 12832/28000 datapoints
2025-03-06 20:41:33,911 - INFO - training batch 451, loss: 1.312, 14432/28000 datapoints
2025-03-06 20:41:34,039 - INFO - training batch 501, loss: 1.200, 16032/28000 datapoints
2025-03-06 20:41:34,177 - INFO - training batch 551, loss: 1.308, 17632/28000 datapoints
2025-03-06 20:41:34,305 - INFO - training batch 601, loss: 1.399, 19232/28000 datapoints
2025-03-06 20:41:34,428 - INFO - training batch 651, loss: 0.964, 20832/28000 datapoints
2025-03-06 20:41:34,558 - INFO - training batch 701, loss: 1.112, 22432/28000 datapoints
2025-03-06 20:41:34,685 - INFO - training batch 751, loss: 1.412, 24032/28000 datapoints
2025-03-06 20:41:34,811 - INFO - training batch 801, loss: 1.087, 25632/28000 datapoints
2025-03-06 20:41:34,947 - INFO - training batch 851, loss: 1.309, 27232/28000 datapoints
2025-03-06 20:41:35,009 - INFO - validation batch 1, loss: 0.919, 32/6976 datapoints
2025-03-06 20:41:35,055 - INFO - validation batch 51, loss: 1.702, 1632/6976 datapoints
2025-03-06 20:41:35,101 - INFO - validation batch 101, loss: 1.242, 3232/6976 datapoints
2025-03-06 20:41:35,147 - INFO - validation batch 151, loss: 1.538, 4832/6976 datapoints
2025-03-06 20:41:35,195 - INFO - validation batch 201, loss: 0.791, 6432/6976 datapoints
2025-03-06 20:41:35,211 - INFO - Epoch 90/800 done.
2025-03-06 20:41:35,211 - INFO - Final validation performance:
Loss: 1.239, top-1 acc: 0.529top-5 acc: 0.529
2025-03-06 20:41:35,211 - INFO - Beginning epoch 91/800
2025-03-06 20:41:35,215 - INFO - training batch 1, loss: 1.390, 32/28000 datapoints
2025-03-06 20:41:35,342 - INFO - training batch 51, loss: 1.513, 1632/28000 datapoints
2025-03-06 20:41:35,468 - INFO - training batch 101, loss: 1.006, 3232/28000 datapoints
2025-03-06 20:41:35,593 - INFO - training batch 151, loss: 1.602, 4832/28000 datapoints
2025-03-06 20:41:35,719 - INFO - training batch 201, loss: 1.356, 6432/28000 datapoints
2025-03-06 20:41:35,846 - INFO - training batch 251, loss: 1.120, 8032/28000 datapoints
2025-03-06 20:41:35,972 - INFO - training batch 301, loss: 1.383, 9632/28000 datapoints
2025-03-06 20:41:36,117 - INFO - training batch 351, loss: 1.269, 11232/28000 datapoints
2025-03-06 20:41:36,238 - INFO - training batch 401, loss: 1.336, 12832/28000 datapoints
2025-03-06 20:41:36,364 - INFO - training batch 451, loss: 1.307, 14432/28000 datapoints
2025-03-06 20:41:36,488 - INFO - training batch 501, loss: 1.194, 16032/28000 datapoints
2025-03-06 20:41:36,610 - INFO - training batch 551, loss: 1.302, 17632/28000 datapoints
2025-03-06 20:41:36,737 - INFO - training batch 601, loss: 1.397, 19232/28000 datapoints
2025-03-06 20:41:36,861 - INFO - training batch 651, loss: 0.956, 20832/28000 datapoints
2025-03-06 20:41:36,989 - INFO - training batch 701, loss: 1.107, 22432/28000 datapoints
2025-03-06 20:41:37,112 - INFO - training batch 751, loss: 1.406, 24032/28000 datapoints
2025-03-06 20:41:37,235 - INFO - training batch 801, loss: 1.081, 25632/28000 datapoints
2025-03-06 20:41:37,358 - INFO - training batch 851, loss: 1.304, 27232/28000 datapoints
2025-03-06 20:41:37,421 - INFO - validation batch 1, loss: 0.914, 32/6976 datapoints
2025-03-06 20:41:37,469 - INFO - validation batch 51, loss: 1.701, 1632/6976 datapoints
2025-03-06 20:41:37,516 - INFO - validation batch 101, loss: 1.235, 3232/6976 datapoints
2025-03-06 20:41:37,565 - INFO - validation batch 151, loss: 1.530, 4832/6976 datapoints
2025-03-06 20:41:37,613 - INFO - validation batch 201, loss: 0.789, 6432/6976 datapoints
2025-03-06 20:41:37,644 - INFO - Epoch 91/800 done.
2025-03-06 20:41:37,645 - INFO - Final validation performance:
Loss: 1.234, top-1 acc: 0.531top-5 acc: 0.531
2025-03-06 20:41:37,645 - INFO - Beginning epoch 92/800
2025-03-06 20:41:37,651 - INFO - training batch 1, loss: 1.379, 32/28000 datapoints
2025-03-06 20:41:37,776 - INFO - training batch 51, loss: 1.509, 1632/28000 datapoints
2025-03-06 20:41:37,906 - INFO - training batch 101, loss: 1.000, 3232/28000 datapoints
2025-03-06 20:41:38,035 - INFO - training batch 151, loss: 1.597, 4832/28000 datapoints
2025-03-06 20:41:38,162 - INFO - training batch 201, loss: 1.352, 6432/28000 datapoints
2025-03-06 20:41:38,287 - INFO - training batch 251, loss: 1.113, 8032/28000 datapoints
2025-03-06 20:41:38,416 - INFO - training batch 301, loss: 1.375, 9632/28000 datapoints
2025-03-06 20:41:38,539 - INFO - training batch 351, loss: 1.259, 11232/28000 datapoints
2025-03-06 20:41:38,663 - INFO - training batch 401, loss: 1.327, 12832/28000 datapoints
2025-03-06 20:41:38,787 - INFO - training batch 451, loss: 1.302, 14432/28000 datapoints
2025-03-06 20:41:38,923 - INFO - training batch 501, loss: 1.187, 16032/28000 datapoints
2025-03-06 20:41:39,048 - INFO - training batch 551, loss: 1.296, 17632/28000 datapoints
2025-03-06 20:41:39,171 - INFO - training batch 601, loss: 1.394, 19232/28000 datapoints
2025-03-06 20:41:39,294 - INFO - training batch 651, loss: 0.948, 20832/28000 datapoints
2025-03-06 20:41:39,420 - INFO - training batch 701, loss: 1.101, 22432/28000 datapoints
2025-03-06 20:41:39,543 - INFO - training batch 751, loss: 1.398, 24032/28000 datapoints
2025-03-06 20:41:39,670 - INFO - training batch 801, loss: 1.075, 25632/28000 datapoints
2025-03-06 20:41:39,794 - INFO - training batch 851, loss: 1.299, 27232/28000 datapoints
2025-03-06 20:41:39,854 - INFO - validation batch 1, loss: 0.909, 32/6976 datapoints
2025-03-06 20:41:39,904 - INFO - validation batch 51, loss: 1.700, 1632/6976 datapoints
2025-03-06 20:41:39,953 - INFO - validation batch 101, loss: 1.229, 3232/6976 datapoints
2025-03-06 20:41:40,001 - INFO - validation batch 151, loss: 1.522, 4832/6976 datapoints
2025-03-06 20:41:40,056 - INFO - validation batch 201, loss: 0.786, 6432/6976 datapoints
2025-03-06 20:41:40,077 - INFO - Epoch 92/800 done.
2025-03-06 20:41:40,077 - INFO - Final validation performance:
Loss: 1.229, top-1 acc: 0.535top-5 acc: 0.535
2025-03-06 20:41:40,077 - INFO - Beginning epoch 93/800
2025-03-06 20:41:40,082 - INFO - training batch 1, loss: 1.369, 32/28000 datapoints
2025-03-06 20:41:40,204 - INFO - training batch 51, loss: 1.505, 1632/28000 datapoints
2025-03-06 20:41:40,339 - INFO - training batch 101, loss: 0.993, 3232/28000 datapoints
2025-03-06 20:41:40,461 - INFO - training batch 151, loss: 1.592, 4832/28000 datapoints
2025-03-06 20:41:40,580 - INFO - training batch 201, loss: 1.348, 6432/28000 datapoints
2025-03-06 20:41:40,710 - INFO - training batch 251, loss: 1.105, 8032/28000 datapoints
2025-03-06 20:41:40,833 - INFO - training batch 301, loss: 1.367, 9632/28000 datapoints
2025-03-06 20:41:40,962 - INFO - training batch 351, loss: 1.249, 11232/28000 datapoints
2025-03-06 20:41:41,085 - INFO - training batch 401, loss: 1.319, 12832/28000 datapoints
2025-03-06 20:41:41,205 - INFO - training batch 451, loss: 1.297, 14432/28000 datapoints
2025-03-06 20:41:41,326 - INFO - training batch 501, loss: 1.180, 16032/28000 datapoints
2025-03-06 20:41:41,447 - INFO - training batch 551, loss: 1.291, 17632/28000 datapoints
2025-03-06 20:41:41,568 - INFO - training batch 601, loss: 1.392, 19232/28000 datapoints
2025-03-06 20:41:41,689 - INFO - training batch 651, loss: 0.939, 20832/28000 datapoints
2025-03-06 20:41:41,810 - INFO - training batch 701, loss: 1.095, 22432/28000 datapoints
2025-03-06 20:41:41,931 - INFO - training batch 751, loss: 1.391, 24032/28000 datapoints
2025-03-06 20:41:42,052 - INFO - training batch 801, loss: 1.068, 25632/28000 datapoints
2025-03-06 20:41:42,171 - INFO - training batch 851, loss: 1.294, 27232/28000 datapoints
2025-03-06 20:41:42,231 - INFO - validation batch 1, loss: 0.904, 32/6976 datapoints
2025-03-06 20:41:42,275 - INFO - validation batch 51, loss: 1.699, 1632/6976 datapoints
2025-03-06 20:41:42,319 - INFO - validation batch 101, loss: 1.223, 3232/6976 datapoints
2025-03-06 20:41:42,363 - INFO - validation batch 151, loss: 1.514, 4832/6976 datapoints
2025-03-06 20:41:42,407 - INFO - validation batch 201, loss: 0.782, 6432/6976 datapoints
2025-03-06 20:41:42,422 - INFO - Epoch 93/800 done.
2025-03-06 20:41:42,422 - INFO - Final validation performance:
Loss: 1.224, top-1 acc: 0.539top-5 acc: 0.539
2025-03-06 20:41:42,423 - INFO - Beginning epoch 94/800
2025-03-06 20:41:42,426 - INFO - training batch 1, loss: 1.359, 32/28000 datapoints
2025-03-06 20:41:42,549 - INFO - training batch 51, loss: 1.500, 1632/28000 datapoints
2025-03-06 20:41:42,670 - INFO - training batch 101, loss: 0.986, 3232/28000 datapoints
2025-03-06 20:41:42,789 - INFO - training batch 151, loss: 1.586, 4832/28000 datapoints
2025-03-06 20:41:42,912 - INFO - training batch 201, loss: 1.342, 6432/28000 datapoints
2025-03-06 20:41:43,037 - INFO - training batch 251, loss: 1.096, 8032/28000 datapoints
2025-03-06 20:41:43,156 - INFO - training batch 301, loss: 1.358, 9632/28000 datapoints
2025-03-06 20:41:43,276 - INFO - training batch 351, loss: 1.238, 11232/28000 datapoints
2025-03-06 20:41:43,398 - INFO - training batch 401, loss: 1.310, 12832/28000 datapoints
2025-03-06 20:41:43,518 - INFO - training batch 451, loss: 1.292, 14432/28000 datapoints
2025-03-06 20:41:43,641 - INFO - training batch 501, loss: 1.173, 16032/28000 datapoints
2025-03-06 20:41:43,761 - INFO - training batch 551, loss: 1.285, 17632/28000 datapoints
2025-03-06 20:41:43,888 - INFO - training batch 601, loss: 1.390, 19232/28000 datapoints
2025-03-06 20:41:44,012 - INFO - training batch 651, loss: 0.928, 20832/28000 datapoints
2025-03-06 20:41:44,138 - INFO - training batch 701, loss: 1.088, 22432/28000 datapoints
2025-03-06 20:41:44,266 - INFO - training batch 751, loss: 1.383, 24032/28000 datapoints
2025-03-06 20:41:44,391 - INFO - training batch 801, loss: 1.062, 25632/28000 datapoints
2025-03-06 20:41:44,519 - INFO - training batch 851, loss: 1.290, 27232/28000 datapoints
2025-03-06 20:41:44,581 - INFO - validation batch 1, loss: 0.899, 32/6976 datapoints
2025-03-06 20:41:44,628 - INFO - validation batch 51, loss: 1.698, 1632/6976 datapoints
2025-03-06 20:41:44,676 - INFO - validation batch 101, loss: 1.216, 3232/6976 datapoints
2025-03-06 20:41:44,719 - INFO - validation batch 151, loss: 1.505, 4832/6976 datapoints
2025-03-06 20:41:44,763 - INFO - validation batch 201, loss: 0.779, 6432/6976 datapoints
2025-03-06 20:41:44,778 - INFO - Epoch 94/800 done.
2025-03-06 20:41:44,778 - INFO - Final validation performance:
Loss: 1.219, top-1 acc: 0.542top-5 acc: 0.542
2025-03-06 20:41:44,779 - INFO - Beginning epoch 95/800
2025-03-06 20:41:44,782 - INFO - training batch 1, loss: 1.348, 32/28000 datapoints
2025-03-06 20:41:44,906 - INFO - training batch 51, loss: 1.495, 1632/28000 datapoints
2025-03-06 20:41:45,036 - INFO - training batch 101, loss: 0.978, 3232/28000 datapoints
2025-03-06 20:41:45,164 - INFO - training batch 151, loss: 1.580, 4832/28000 datapoints
2025-03-06 20:41:45,285 - INFO - training batch 201, loss: 1.336, 6432/28000 datapoints
2025-03-06 20:41:45,406 - INFO - training batch 251, loss: 1.088, 8032/28000 datapoints
2025-03-06 20:41:45,528 - INFO - training batch 301, loss: 1.350, 9632/28000 datapoints
2025-03-06 20:41:45,652 - INFO - training batch 351, loss: 1.227, 11232/28000 datapoints
2025-03-06 20:41:45,776 - INFO - training batch 401, loss: 1.302, 12832/28000 datapoints
2025-03-06 20:41:45,898 - INFO - training batch 451, loss: 1.285, 14432/28000 datapoints
2025-03-06 20:41:46,020 - INFO - training batch 501, loss: 1.165, 16032/28000 datapoints
2025-03-06 20:41:46,166 - INFO - training batch 551, loss: 1.279, 17632/28000 datapoints
2025-03-06 20:41:46,293 - INFO - training batch 601, loss: 1.387, 19232/28000 datapoints
2025-03-06 20:41:46,421 - INFO - training batch 651, loss: 0.918, 20832/28000 datapoints
2025-03-06 20:41:46,543 - INFO - training batch 701, loss: 1.081, 22432/28000 datapoints
2025-03-06 20:41:46,664 - INFO - training batch 751, loss: 1.373, 24032/28000 datapoints
2025-03-06 20:41:46,792 - INFO - training batch 801, loss: 1.055, 25632/28000 datapoints
2025-03-06 20:41:46,914 - INFO - training batch 851, loss: 1.285, 27232/28000 datapoints
2025-03-06 20:41:46,981 - INFO - validation batch 1, loss: 0.894, 32/6976 datapoints
2025-03-06 20:41:47,026 - INFO - validation batch 51, loss: 1.697, 1632/6976 datapoints
2025-03-06 20:41:47,070 - INFO - validation batch 101, loss: 1.209, 3232/6976 datapoints
2025-03-06 20:41:47,114 - INFO - validation batch 151, loss: 1.495, 4832/6976 datapoints
2025-03-06 20:41:47,157 - INFO - validation batch 201, loss: 0.774, 6432/6976 datapoints
2025-03-06 20:41:47,175 - INFO - Epoch 95/800 done.
2025-03-06 20:41:47,176 - INFO - Final validation performance:
Loss: 1.214, top-1 acc: 0.546top-5 acc: 0.546
2025-03-06 20:41:47,176 - INFO - Beginning epoch 96/800
2025-03-06 20:41:47,180 - INFO - training batch 1, loss: 1.339, 32/28000 datapoints
2025-03-06 20:41:47,301 - INFO - training batch 51, loss: 1.489, 1632/28000 datapoints
2025-03-06 20:41:47,421 - INFO - training batch 101, loss: 0.970, 3232/28000 datapoints
2025-03-06 20:41:47,543 - INFO - training batch 151, loss: 1.574, 4832/28000 datapoints
2025-03-06 20:41:47,667 - INFO - training batch 201, loss: 1.329, 6432/28000 datapoints
2025-03-06 20:41:47,788 - INFO - training batch 251, loss: 1.080, 8032/28000 datapoints
2025-03-06 20:41:47,908 - INFO - training batch 301, loss: 1.340, 9632/28000 datapoints
2025-03-06 20:41:48,029 - INFO - training batch 351, loss: 1.216, 11232/28000 datapoints
2025-03-06 20:41:48,151 - INFO - training batch 401, loss: 1.291, 12832/28000 datapoints
2025-03-06 20:41:48,272 - INFO - training batch 451, loss: 1.279, 14432/28000 datapoints
2025-03-06 20:41:48,394 - INFO - training batch 501, loss: 1.159, 16032/28000 datapoints
2025-03-06 20:41:48,513 - INFO - training batch 551, loss: 1.273, 17632/28000 datapoints
2025-03-06 20:41:48,634 - INFO - training batch 601, loss: 1.384, 19232/28000 datapoints
2025-03-06 20:41:48,755 - INFO - training batch 651, loss: 0.909, 20832/28000 datapoints
2025-03-06 20:41:48,880 - INFO - training batch 701, loss: 1.074, 22432/28000 datapoints
2025-03-06 20:41:49,004 - INFO - training batch 751, loss: 1.362, 24032/28000 datapoints
2025-03-06 20:41:49,126 - INFO - training batch 801, loss: 1.048, 25632/28000 datapoints
2025-03-06 20:41:49,246 - INFO - training batch 851, loss: 1.280, 27232/28000 datapoints
2025-03-06 20:41:49,305 - INFO - validation batch 1, loss: 0.888, 32/6976 datapoints
2025-03-06 20:41:49,350 - INFO - validation batch 51, loss: 1.695, 1632/6976 datapoints
2025-03-06 20:41:49,393 - INFO - validation batch 101, loss: 1.202, 3232/6976 datapoints
2025-03-06 20:41:49,438 - INFO - validation batch 151, loss: 1.485, 4832/6976 datapoints
2025-03-06 20:41:49,485 - INFO - validation batch 201, loss: 0.768, 6432/6976 datapoints
2025-03-06 20:41:49,500 - INFO - Epoch 96/800 done.
2025-03-06 20:41:49,500 - INFO - Final validation performance:
Loss: 1.208, top-1 acc: 0.549top-5 acc: 0.549
2025-03-06 20:41:49,501 - INFO - Beginning epoch 97/800
2025-03-06 20:41:49,504 - INFO - training batch 1, loss: 1.328, 32/28000 datapoints
2025-03-06 20:41:49,623 - INFO - training batch 51, loss: 1.482, 1632/28000 datapoints
2025-03-06 20:41:49,746 - INFO - training batch 101, loss: 0.961, 3232/28000 datapoints
2025-03-06 20:41:49,866 - INFO - training batch 151, loss: 1.567, 4832/28000 datapoints
2025-03-06 20:41:49,986 - INFO - training batch 201, loss: 1.321, 6432/28000 datapoints
2025-03-06 20:41:50,110 - INFO - training batch 251, loss: 1.071, 8032/28000 datapoints
2025-03-06 20:41:50,228 - INFO - training batch 301, loss: 1.330, 9632/28000 datapoints
2025-03-06 20:41:50,349 - INFO - training batch 351, loss: 1.207, 11232/28000 datapoints
2025-03-06 20:41:50,472 - INFO - training batch 401, loss: 1.282, 12832/28000 datapoints
2025-03-06 20:41:50,592 - INFO - training batch 451, loss: 1.272, 14432/28000 datapoints
2025-03-06 20:41:50,715 - INFO - training batch 501, loss: 1.151, 16032/28000 datapoints
2025-03-06 20:41:50,843 - INFO - training batch 551, loss: 1.267, 17632/28000 datapoints
2025-03-06 20:41:50,969 - INFO - training batch 601, loss: 1.381, 19232/28000 datapoints
2025-03-06 20:41:51,097 - INFO - training batch 651, loss: 0.898, 20832/28000 datapoints
2025-03-06 20:41:51,216 - INFO - training batch 701, loss: 1.067, 22432/28000 datapoints
2025-03-06 20:41:51,341 - INFO - training batch 751, loss: 1.351, 24032/28000 datapoints
2025-03-06 20:41:51,462 - INFO - training batch 801, loss: 1.041, 25632/28000 datapoints
2025-03-06 20:41:51,594 - INFO - training batch 851, loss: 1.275, 27232/28000 datapoints
2025-03-06 20:41:51,659 - INFO - validation batch 1, loss: 0.882, 32/6976 datapoints
2025-03-06 20:41:51,701 - INFO - validation batch 51, loss: 1.693, 1632/6976 datapoints
2025-03-06 20:41:51,744 - INFO - validation batch 101, loss: 1.194, 3232/6976 datapoints
2025-03-06 20:41:51,789 - INFO - validation batch 151, loss: 1.475, 4832/6976 datapoints
2025-03-06 20:41:51,833 - INFO - validation batch 201, loss: 0.761, 6432/6976 datapoints
2025-03-06 20:41:51,848 - INFO - Epoch 97/800 done.
2025-03-06 20:41:51,848 - INFO - Final validation performance:
Loss: 1.201, top-1 acc: 0.554top-5 acc: 0.554
2025-03-06 20:41:51,849 - INFO - Beginning epoch 98/800
2025-03-06 20:41:51,852 - INFO - training batch 1, loss: 1.318, 32/28000 datapoints
2025-03-06 20:41:51,975 - INFO - training batch 51, loss: 1.473, 1632/28000 datapoints
2025-03-06 20:41:52,098 - INFO - training batch 101, loss: 0.952, 3232/28000 datapoints
2025-03-06 20:41:52,218 - INFO - training batch 151, loss: 1.560, 4832/28000 datapoints
2025-03-06 20:41:52,348 - INFO - training batch 201, loss: 1.313, 6432/28000 datapoints
2025-03-06 20:41:52,473 - INFO - training batch 251, loss: 1.063, 8032/28000 datapoints
2025-03-06 20:41:52,593 - INFO - training batch 301, loss: 1.320, 9632/28000 datapoints
2025-03-06 20:41:52,716 - INFO - training batch 351, loss: 1.196, 11232/28000 datapoints
2025-03-06 20:41:52,843 - INFO - training batch 401, loss: 1.274, 12832/28000 datapoints
2025-03-06 20:41:52,965 - INFO - training batch 451, loss: 1.265, 14432/28000 datapoints
2025-03-06 20:41:53,091 - INFO - training batch 501, loss: 1.142, 16032/28000 datapoints
2025-03-06 20:41:53,220 - INFO - training batch 551, loss: 1.260, 17632/28000 datapoints
2025-03-06 20:41:53,340 - INFO - training batch 601, loss: 1.377, 19232/28000 datapoints
2025-03-06 20:41:53,461 - INFO - training batch 651, loss: 0.888, 20832/28000 datapoints
2025-03-06 20:41:53,584 - INFO - training batch 701, loss: 1.059, 22432/28000 datapoints
2025-03-06 20:41:53,706 - INFO - training batch 751, loss: 1.338, 24032/28000 datapoints
2025-03-06 20:41:53,826 - INFO - training batch 801, loss: 1.034, 25632/28000 datapoints
2025-03-06 20:41:53,948 - INFO - training batch 851, loss: 1.270, 27232/28000 datapoints
2025-03-06 20:41:54,008 - INFO - validation batch 1, loss: 0.876, 32/6976 datapoints
2025-03-06 20:41:54,053 - INFO - validation batch 51, loss: 1.691, 1632/6976 datapoints
2025-03-06 20:41:54,098 - INFO - validation batch 101, loss: 1.187, 3232/6976 datapoints
2025-03-06 20:41:54,148 - INFO - validation batch 151, loss: 1.465, 4832/6976 datapoints
2025-03-06 20:41:54,203 - INFO - validation batch 201, loss: 0.754, 6432/6976 datapoints
2025-03-06 20:41:54,218 - INFO - Epoch 98/800 done.
2025-03-06 20:41:54,218 - INFO - Final validation performance:
Loss: 1.195, top-1 acc: 0.558top-5 acc: 0.558
2025-03-06 20:41:54,219 - INFO - Beginning epoch 99/800
2025-03-06 20:41:54,222 - INFO - training batch 1, loss: 1.309, 32/28000 datapoints
2025-03-06 20:41:54,344 - INFO - training batch 51, loss: 1.464, 1632/28000 datapoints
2025-03-06 20:41:54,465 - INFO - training batch 101, loss: 0.942, 3232/28000 datapoints
2025-03-06 20:41:54,589 - INFO - training batch 151, loss: 1.554, 4832/28000 datapoints
2025-03-06 20:41:54,713 - INFO - training batch 201, loss: 1.307, 6432/28000 datapoints
2025-03-06 20:41:54,835 - INFO - training batch 251, loss: 1.055, 8032/28000 datapoints
2025-03-06 20:41:54,962 - INFO - training batch 301, loss: 1.310, 9632/28000 datapoints
2025-03-06 20:41:55,088 - INFO - training batch 351, loss: 1.186, 11232/28000 datapoints
2025-03-06 20:41:55,208 - INFO - training batch 401, loss: 1.265, 12832/28000 datapoints
2025-03-06 20:41:55,328 - INFO - training batch 451, loss: 1.257, 14432/28000 datapoints
2025-03-06 20:41:55,448 - INFO - training batch 501, loss: 1.136, 16032/28000 datapoints
2025-03-06 20:41:55,568 - INFO - training batch 551, loss: 1.255, 17632/28000 datapoints
2025-03-06 20:41:55,691 - INFO - training batch 601, loss: 1.373, 19232/28000 datapoints
2025-03-06 20:41:55,811 - INFO - training batch 651, loss: 0.880, 20832/28000 datapoints
2025-03-06 20:41:55,932 - INFO - training batch 701, loss: 1.051, 22432/28000 datapoints
2025-03-06 20:41:56,054 - INFO - training batch 751, loss: 1.326, 24032/28000 datapoints
2025-03-06 20:41:56,178 - INFO - training batch 801, loss: 1.027, 25632/28000 datapoints
2025-03-06 20:41:56,324 - INFO - training batch 851, loss: 1.264, 27232/28000 datapoints
2025-03-06 20:41:56,384 - INFO - validation batch 1, loss: 0.870, 32/6976 datapoints
2025-03-06 20:41:56,428 - INFO - validation batch 51, loss: 1.689, 1632/6976 datapoints
2025-03-06 20:41:56,472 - INFO - validation batch 101, loss: 1.179, 3232/6976 datapoints
2025-03-06 20:41:56,516 - INFO - validation batch 151, loss: 1.455, 4832/6976 datapoints
2025-03-06 20:41:56,560 - INFO - validation batch 201, loss: 0.747, 6432/6976 datapoints
2025-03-06 20:41:56,578 - INFO - Epoch 99/800 done.
2025-03-06 20:41:56,578 - INFO - Final validation performance:
Loss: 1.188, top-1 acc: 0.561top-5 acc: 0.561
2025-03-06 20:41:56,578 - INFO - Beginning epoch 100/800
2025-03-06 20:41:56,582 - INFO - training batch 1, loss: 1.299, 32/28000 datapoints
2025-03-06 20:41:56,703 - INFO - training batch 51, loss: 1.454, 1632/28000 datapoints
2025-03-06 20:41:56,823 - INFO - training batch 101, loss: 0.931, 3232/28000 datapoints
2025-03-06 20:41:56,943 - INFO - training batch 151, loss: 1.546, 4832/28000 datapoints
2025-03-06 20:41:57,067 - INFO - training batch 201, loss: 1.298, 6432/28000 datapoints
2025-03-06 20:41:57,189 - INFO - training batch 251, loss: 1.047, 8032/28000 datapoints
2025-03-06 20:41:57,309 - INFO - training batch 301, loss: 1.300, 9632/28000 datapoints
2025-03-06 20:41:57,429 - INFO - training batch 351, loss: 1.174, 11232/28000 datapoints
2025-03-06 20:41:57,549 - INFO - training batch 401, loss: 1.256, 12832/28000 datapoints
2025-03-06 20:41:57,673 - INFO - training batch 451, loss: 1.249, 14432/28000 datapoints
2025-03-06 20:41:57,791 - INFO - training batch 501, loss: 1.127, 16032/28000 datapoints
2025-03-06 20:41:57,912 - INFO - training batch 551, loss: 1.248, 17632/28000 datapoints
2025-03-06 20:41:58,031 - INFO - training batch 601, loss: 1.370, 19232/28000 datapoints
2025-03-06 20:41:58,155 - INFO - training batch 651, loss: 0.870, 20832/28000 datapoints
2025-03-06 20:41:58,273 - INFO - training batch 701, loss: 1.042, 22432/28000 datapoints
2025-03-06 20:41:58,392 - INFO - training batch 751, loss: 1.313, 24032/28000 datapoints
2025-03-06 20:41:58,524 - INFO - training batch 801, loss: 1.021, 25632/28000 datapoints
2025-03-06 20:41:58,652 - INFO - training batch 851, loss: 1.259, 27232/28000 datapoints
2025-03-06 20:41:58,711 - INFO - validation batch 1, loss: 0.864, 32/6976 datapoints
2025-03-06 20:41:58,754 - INFO - validation batch 51, loss: 1.686, 1632/6976 datapoints
2025-03-06 20:41:58,799 - INFO - validation batch 101, loss: 1.171, 3232/6976 datapoints
2025-03-06 20:41:58,844 - INFO - validation batch 151, loss: 1.445, 4832/6976 datapoints
2025-03-06 20:41:58,894 - INFO - validation batch 201, loss: 0.740, 6432/6976 datapoints
2025-03-06 20:41:58,911 - INFO - Epoch 100/800 done.
2025-03-06 20:41:58,911 - INFO - Final validation performance:
Loss: 1.181, top-1 acc: 0.565top-5 acc: 0.565
2025-03-06 20:41:58,912 - INFO - Beginning epoch 101/800
2025-03-06 20:41:58,917 - INFO - training batch 1, loss: 1.289, 32/28000 datapoints
2025-03-06 20:41:59,048 - INFO - training batch 51, loss: 1.444, 1632/28000 datapoints
2025-03-06 20:41:59,171 - INFO - training batch 101, loss: 0.921, 3232/28000 datapoints
2025-03-06 20:41:59,292 - INFO - training batch 151, loss: 1.539, 4832/28000 datapoints
2025-03-06 20:41:59,411 - INFO - training batch 201, loss: 1.291, 6432/28000 datapoints
2025-03-06 20:41:59,531 - INFO - training batch 251, loss: 1.039, 8032/28000 datapoints
2025-03-06 20:41:59,653 - INFO - training batch 301, loss: 1.288, 9632/28000 datapoints
2025-03-06 20:41:59,772 - INFO - training batch 351, loss: 1.164, 11232/28000 datapoints
2025-03-06 20:41:59,892 - INFO - training batch 401, loss: 1.247, 12832/28000 datapoints
2025-03-06 20:42:00,014 - INFO - training batch 451, loss: 1.239, 14432/28000 datapoints
2025-03-06 20:42:00,136 - INFO - training batch 501, loss: 1.120, 16032/28000 datapoints
2025-03-06 20:42:00,256 - INFO - training batch 551, loss: 1.241, 17632/28000 datapoints
2025-03-06 20:42:00,376 - INFO - training batch 601, loss: 1.366, 19232/28000 datapoints
2025-03-06 20:42:00,496 - INFO - training batch 651, loss: 0.859, 20832/28000 datapoints
2025-03-06 20:42:00,615 - INFO - training batch 701, loss: 1.034, 22432/28000 datapoints
2025-03-06 20:42:00,737 - INFO - training batch 751, loss: 1.300, 24032/28000 datapoints
2025-03-06 20:42:00,857 - INFO - training batch 801, loss: 1.015, 25632/28000 datapoints
2025-03-06 20:42:00,977 - INFO - training batch 851, loss: 1.253, 27232/28000 datapoints
2025-03-06 20:42:01,041 - INFO - validation batch 1, loss: 0.857, 32/6976 datapoints
2025-03-06 20:42:01,086 - INFO - validation batch 51, loss: 1.682, 1632/6976 datapoints
2025-03-06 20:42:01,130 - INFO - validation batch 101, loss: 1.163, 3232/6976 datapoints
2025-03-06 20:42:01,173 - INFO - validation batch 151, loss: 1.434, 4832/6976 datapoints
2025-03-06 20:42:01,215 - INFO - validation batch 201, loss: 0.732, 6432/6976 datapoints
2025-03-06 20:42:01,230 - INFO - Epoch 101/800 done.
2025-03-06 20:42:01,230 - INFO - Final validation performance:
Loss: 1.173, top-1 acc: 0.570top-5 acc: 0.570
2025-03-06 20:42:01,231 - INFO - Beginning epoch 102/800
2025-03-06 20:42:01,234 - INFO - training batch 1, loss: 1.279, 32/28000 datapoints
2025-03-06 20:42:01,355 - INFO - training batch 51, loss: 1.433, 1632/28000 datapoints
2025-03-06 20:42:01,475 - INFO - training batch 101, loss: 0.911, 3232/28000 datapoints
2025-03-06 20:42:01,594 - INFO - training batch 151, loss: 1.532, 4832/28000 datapoints
2025-03-06 20:42:01,718 - INFO - training batch 201, loss: 1.282, 6432/28000 datapoints
2025-03-06 20:42:01,838 - INFO - training batch 251, loss: 1.031, 8032/28000 datapoints
2025-03-06 20:42:01,958 - INFO - training batch 301, loss: 1.278, 9632/28000 datapoints
2025-03-06 20:42:02,078 - INFO - training batch 351, loss: 1.154, 11232/28000 datapoints
2025-03-06 20:42:02,199 - INFO - training batch 401, loss: 1.237, 12832/28000 datapoints
2025-03-06 20:42:02,318 - INFO - training batch 451, loss: 1.230, 14432/28000 datapoints
2025-03-06 20:42:02,436 - INFO - training batch 501, loss: 1.112, 16032/28000 datapoints
2025-03-06 20:42:02,555 - INFO - training batch 551, loss: 1.234, 17632/28000 datapoints
2025-03-06 20:42:02,678 - INFO - training batch 601, loss: 1.361, 19232/28000 datapoints
2025-03-06 20:42:02,796 - INFO - training batch 651, loss: 0.849, 20832/28000 datapoints
2025-03-06 20:42:02,916 - INFO - training batch 701, loss: 1.026, 22432/28000 datapoints
2025-03-06 20:42:03,039 - INFO - training batch 751, loss: 1.286, 24032/28000 datapoints
2025-03-06 20:42:03,161 - INFO - training batch 801, loss: 1.009, 25632/28000 datapoints
2025-03-06 20:42:03,281 - INFO - training batch 851, loss: 1.247, 27232/28000 datapoints
2025-03-06 20:42:03,341 - INFO - validation batch 1, loss: 0.850, 32/6976 datapoints
2025-03-06 20:42:03,384 - INFO - validation batch 51, loss: 1.680, 1632/6976 datapoints
2025-03-06 20:42:03,429 - INFO - validation batch 101, loss: 1.154, 3232/6976 datapoints
2025-03-06 20:42:03,472 - INFO - validation batch 151, loss: 1.423, 4832/6976 datapoints
2025-03-06 20:42:03,515 - INFO - validation batch 201, loss: 0.725, 6432/6976 datapoints
2025-03-06 20:42:03,530 - INFO - Epoch 102/800 done.
2025-03-06 20:42:03,530 - INFO - Final validation performance:
Loss: 1.166, top-1 acc: 0.573top-5 acc: 0.573
2025-03-06 20:42:03,530 - INFO - Beginning epoch 103/800
2025-03-06 20:42:03,534 - INFO - training batch 1, loss: 1.268, 32/28000 datapoints
2025-03-06 20:42:03,657 - INFO - training batch 51, loss: 1.422, 1632/28000 datapoints
2025-03-06 20:42:03,779 - INFO - training batch 101, loss: 0.901, 3232/28000 datapoints
2025-03-06 20:42:03,902 - INFO - training batch 151, loss: 1.525, 4832/28000 datapoints
2025-03-06 20:42:04,021 - INFO - training batch 201, loss: 1.273, 6432/28000 datapoints
2025-03-06 20:42:04,142 - INFO - training batch 251, loss: 1.023, 8032/28000 datapoints
2025-03-06 20:42:04,273 - INFO - training batch 301, loss: 1.267, 9632/28000 datapoints
2025-03-06 20:42:04,395 - INFO - training batch 351, loss: 1.143, 11232/28000 datapoints
2025-03-06 20:42:04,520 - INFO - training batch 401, loss: 1.227, 12832/28000 datapoints
2025-03-06 20:42:04,660 - INFO - training batch 451, loss: 1.221, 14432/28000 datapoints
2025-03-06 20:42:04,786 - INFO - training batch 501, loss: 1.102, 16032/28000 datapoints
2025-03-06 20:42:04,920 - INFO - training batch 551, loss: 1.228, 17632/28000 datapoints
2025-03-06 20:42:05,059 - INFO - training batch 601, loss: 1.356, 19232/28000 datapoints
2025-03-06 20:42:05,187 - INFO - training batch 651, loss: 0.838, 20832/28000 datapoints
2025-03-06 20:42:05,310 - INFO - training batch 701, loss: 1.017, 22432/28000 datapoints
2025-03-06 20:42:05,437 - INFO - training batch 751, loss: 1.272, 24032/28000 datapoints
2025-03-06 20:42:05,561 - INFO - training batch 801, loss: 1.003, 25632/28000 datapoints
2025-03-06 20:42:05,686 - INFO - training batch 851, loss: 1.241, 27232/28000 datapoints
2025-03-06 20:42:05,750 - INFO - validation batch 1, loss: 0.843, 32/6976 datapoints
2025-03-06 20:42:05,797 - INFO - validation batch 51, loss: 1.678, 1632/6976 datapoints
2025-03-06 20:42:05,848 - INFO - validation batch 101, loss: 1.145, 3232/6976 datapoints
2025-03-06 20:42:05,904 - INFO - validation batch 151, loss: 1.412, 4832/6976 datapoints
2025-03-06 20:42:05,956 - INFO - validation batch 201, loss: 0.717, 6432/6976 datapoints
2025-03-06 20:42:05,972 - INFO - Epoch 103/800 done.
2025-03-06 20:42:05,972 - INFO - Final validation performance:
Loss: 1.159, top-1 acc: 0.578top-5 acc: 0.578
2025-03-06 20:42:05,973 - INFO - Beginning epoch 104/800
2025-03-06 20:42:05,977 - INFO - training batch 1, loss: 1.258, 32/28000 datapoints
2025-03-06 20:42:06,112 - INFO - training batch 51, loss: 1.410, 1632/28000 datapoints
2025-03-06 20:42:06,240 - INFO - training batch 101, loss: 0.890, 3232/28000 datapoints
2025-03-06 20:42:06,395 - INFO - training batch 151, loss: 1.518, 4832/28000 datapoints
2025-03-06 20:42:06,522 - INFO - training batch 201, loss: 1.264, 6432/28000 datapoints
2025-03-06 20:42:06,648 - INFO - training batch 251, loss: 1.014, 8032/28000 datapoints
2025-03-06 20:42:06,774 - INFO - training batch 301, loss: 1.256, 9632/28000 datapoints
2025-03-06 20:42:06,900 - INFO - training batch 351, loss: 1.132, 11232/28000 datapoints
2025-03-06 20:42:07,026 - INFO - training batch 401, loss: 1.218, 12832/28000 datapoints
2025-03-06 20:42:07,154 - INFO - training batch 451, loss: 1.211, 14432/28000 datapoints
2025-03-06 20:42:07,278 - INFO - training batch 501, loss: 1.092, 16032/28000 datapoints
2025-03-06 20:42:07,402 - INFO - training batch 551, loss: 1.221, 17632/28000 datapoints
2025-03-06 20:42:07,526 - INFO - training batch 601, loss: 1.351, 19232/28000 datapoints
2025-03-06 20:42:07,653 - INFO - training batch 651, loss: 0.827, 20832/28000 datapoints
2025-03-06 20:42:07,779 - INFO - training batch 701, loss: 1.008, 22432/28000 datapoints
2025-03-06 20:42:07,903 - INFO - training batch 751, loss: 1.258, 24032/28000 datapoints
2025-03-06 20:42:08,027 - INFO - training batch 801, loss: 0.997, 25632/28000 datapoints
2025-03-06 20:42:08,150 - INFO - training batch 851, loss: 1.236, 27232/28000 datapoints
2025-03-06 20:42:08,212 - INFO - validation batch 1, loss: 0.836, 32/6976 datapoints
2025-03-06 20:42:08,260 - INFO - validation batch 51, loss: 1.676, 1632/6976 datapoints
2025-03-06 20:42:08,307 - INFO - validation batch 101, loss: 1.136, 3232/6976 datapoints
2025-03-06 20:42:08,354 - INFO - validation batch 151, loss: 1.402, 4832/6976 datapoints
2025-03-06 20:42:08,405 - INFO - validation batch 201, loss: 0.709, 6432/6976 datapoints
2025-03-06 20:42:08,425 - INFO - Epoch 104/800 done.
2025-03-06 20:42:08,425 - INFO - Final validation performance:
Loss: 1.152, top-1 acc: 0.582top-5 acc: 0.582
2025-03-06 20:42:08,425 - INFO - Beginning epoch 105/800
2025-03-06 20:42:08,429 - INFO - training batch 1, loss: 1.247, 32/28000 datapoints
2025-03-06 20:42:08,557 - INFO - training batch 51, loss: 1.398, 1632/28000 datapoints
2025-03-06 20:42:08,682 - INFO - training batch 101, loss: 0.880, 3232/28000 datapoints
2025-03-06 20:42:08,807 - INFO - training batch 151, loss: 1.511, 4832/28000 datapoints
2025-03-06 20:42:08,938 - INFO - training batch 201, loss: 1.254, 6432/28000 datapoints
2025-03-06 20:42:09,071 - INFO - training batch 251, loss: 1.005, 8032/28000 datapoints
2025-03-06 20:42:09,197 - INFO - training batch 301, loss: 1.245, 9632/28000 datapoints
2025-03-06 20:42:09,324 - INFO - training batch 351, loss: 1.119, 11232/28000 datapoints
2025-03-06 20:42:09,450 - INFO - training batch 401, loss: 1.208, 12832/28000 datapoints
2025-03-06 20:42:09,573 - INFO - training batch 451, loss: 1.202, 14432/28000 datapoints
2025-03-06 20:42:09,714 - INFO - training batch 501, loss: 1.082, 16032/28000 datapoints
2025-03-06 20:42:09,857 - INFO - training batch 551, loss: 1.215, 17632/28000 datapoints
2025-03-06 20:42:10,005 - INFO - training batch 601, loss: 1.347, 19232/28000 datapoints
2025-03-06 20:42:10,153 - INFO - training batch 651, loss: 0.817, 20832/28000 datapoints
2025-03-06 20:42:10,278 - INFO - training batch 701, loss: 0.999, 22432/28000 datapoints
2025-03-06 20:42:10,400 - INFO - training batch 751, loss: 1.243, 24032/28000 datapoints
2025-03-06 20:42:10,525 - INFO - training batch 801, loss: 0.991, 25632/28000 datapoints
2025-03-06 20:42:10,652 - INFO - training batch 851, loss: 1.231, 27232/28000 datapoints
2025-03-06 20:42:10,724 - INFO - validation batch 1, loss: 0.829, 32/6976 datapoints
2025-03-06 20:42:10,777 - INFO - validation batch 51, loss: 1.674, 1632/6976 datapoints
2025-03-06 20:42:10,822 - INFO - validation batch 101, loss: 1.127, 3232/6976 datapoints
2025-03-06 20:42:10,873 - INFO - validation batch 151, loss: 1.391, 4832/6976 datapoints
2025-03-06 20:42:10,920 - INFO - validation batch 201, loss: 0.701, 6432/6976 datapoints
2025-03-06 20:42:10,935 - INFO - Epoch 105/800 done.
2025-03-06 20:42:10,935 - INFO - Final validation performance:
Loss: 1.144, top-1 acc: 0.586top-5 acc: 0.586
2025-03-06 20:42:10,935 - INFO - Beginning epoch 106/800
2025-03-06 20:42:10,939 - INFO - training batch 1, loss: 1.237, 32/28000 datapoints
2025-03-06 20:42:11,060 - INFO - training batch 51, loss: 1.385, 1632/28000 datapoints
2025-03-06 20:42:11,189 - INFO - training batch 101, loss: 0.869, 3232/28000 datapoints
2025-03-06 20:42:11,311 - INFO - training batch 151, loss: 1.503, 4832/28000 datapoints
2025-03-06 20:42:11,430 - INFO - training batch 201, loss: 1.243, 6432/28000 datapoints
2025-03-06 20:42:11,550 - INFO - training batch 251, loss: 0.996, 8032/28000 datapoints
2025-03-06 20:42:11,672 - INFO - training batch 301, loss: 1.234, 9632/28000 datapoints
2025-03-06 20:42:11,793 - INFO - training batch 351, loss: 1.106, 11232/28000 datapoints
2025-03-06 20:42:11,914 - INFO - training batch 401, loss: 1.199, 12832/28000 datapoints
2025-03-06 20:42:12,032 - INFO - training batch 451, loss: 1.192, 14432/28000 datapoints
2025-03-06 20:42:12,152 - INFO - training batch 501, loss: 1.072, 16032/28000 datapoints
2025-03-06 20:42:12,272 - INFO - training batch 551, loss: 1.209, 17632/28000 datapoints
2025-03-06 20:42:12,394 - INFO - training batch 601, loss: 1.342, 19232/28000 datapoints
2025-03-06 20:42:12,514 - INFO - training batch 651, loss: 0.807, 20832/28000 datapoints
2025-03-06 20:42:12,634 - INFO - training batch 701, loss: 0.990, 22432/28000 datapoints
2025-03-06 20:42:12,754 - INFO - training batch 751, loss: 1.228, 24032/28000 datapoints
2025-03-06 20:42:12,875 - INFO - training batch 801, loss: 0.985, 25632/28000 datapoints
2025-03-06 20:42:12,995 - INFO - training batch 851, loss: 1.225, 27232/28000 datapoints
2025-03-06 20:42:13,054 - INFO - validation batch 1, loss: 0.821, 32/6976 datapoints
2025-03-06 20:42:13,101 - INFO - validation batch 51, loss: 1.671, 1632/6976 datapoints
2025-03-06 20:42:13,145 - INFO - validation batch 101, loss: 1.118, 3232/6976 datapoints
2025-03-06 20:42:13,190 - INFO - validation batch 151, loss: 1.379, 4832/6976 datapoints
2025-03-06 20:42:13,235 - INFO - validation batch 201, loss: 0.693, 6432/6976 datapoints
2025-03-06 20:42:13,250 - INFO - Epoch 106/800 done.
2025-03-06 20:42:13,251 - INFO - Final validation performance:
Loss: 1.136, top-1 acc: 0.591top-5 acc: 0.591
2025-03-06 20:42:13,251 - INFO - Beginning epoch 107/800
2025-03-06 20:42:13,255 - INFO - training batch 1, loss: 1.226, 32/28000 datapoints
2025-03-06 20:42:13,378 - INFO - training batch 51, loss: 1.372, 1632/28000 datapoints
2025-03-06 20:42:13,500 - INFO - training batch 101, loss: 0.858, 3232/28000 datapoints
2025-03-06 20:42:13,619 - INFO - training batch 151, loss: 1.497, 4832/28000 datapoints
2025-03-06 20:42:13,740 - INFO - training batch 201, loss: 1.232, 6432/28000 datapoints
2025-03-06 20:42:13,860 - INFO - training batch 251, loss: 0.987, 8032/28000 datapoints
2025-03-06 20:42:13,979 - INFO - training batch 301, loss: 1.223, 9632/28000 datapoints
2025-03-06 20:42:14,097 - INFO - training batch 351, loss: 1.093, 11232/28000 datapoints
2025-03-06 20:42:14,217 - INFO - training batch 401, loss: 1.189, 12832/28000 datapoints
2025-03-06 20:42:14,338 - INFO - training batch 451, loss: 1.182, 14432/28000 datapoints
2025-03-06 20:42:14,458 - INFO - training batch 501, loss: 1.062, 16032/28000 datapoints
2025-03-06 20:42:14,578 - INFO - training batch 551, loss: 1.203, 17632/28000 datapoints
2025-03-06 20:42:14,700 - INFO - training batch 601, loss: 1.337, 19232/28000 datapoints
2025-03-06 20:42:14,820 - INFO - training batch 651, loss: 0.796, 20832/28000 datapoints
2025-03-06 20:42:14,947 - INFO - training batch 701, loss: 0.981, 22432/28000 datapoints
2025-03-06 20:42:15,069 - INFO - training batch 751, loss: 1.212, 24032/28000 datapoints
2025-03-06 20:42:15,193 - INFO - training batch 801, loss: 0.978, 25632/28000 datapoints
2025-03-06 20:42:15,311 - INFO - training batch 851, loss: 1.219, 27232/28000 datapoints
2025-03-06 20:42:15,372 - INFO - validation batch 1, loss: 0.813, 32/6976 datapoints
2025-03-06 20:42:15,416 - INFO - validation batch 51, loss: 1.667, 1632/6976 datapoints
2025-03-06 20:42:15,461 - INFO - validation batch 101, loss: 1.108, 3232/6976 datapoints
2025-03-06 20:42:15,508 - INFO - validation batch 151, loss: 1.369, 4832/6976 datapoints
2025-03-06 20:42:15,552 - INFO - validation batch 201, loss: 0.685, 6432/6976 datapoints
2025-03-06 20:42:15,567 - INFO - Epoch 107/800 done.
2025-03-06 20:42:15,567 - INFO - Final validation performance:
Loss: 1.128, top-1 acc: 0.595top-5 acc: 0.595
2025-03-06 20:42:15,568 - INFO - Beginning epoch 108/800
2025-03-06 20:42:15,572 - INFO - training batch 1, loss: 1.216, 32/28000 datapoints
2025-03-06 20:42:15,695 - INFO - training batch 51, loss: 1.359, 1632/28000 datapoints
2025-03-06 20:42:15,815 - INFO - training batch 101, loss: 0.846, 3232/28000 datapoints
2025-03-06 20:42:15,940 - INFO - training batch 151, loss: 1.491, 4832/28000 datapoints
2025-03-06 20:42:16,061 - INFO - training batch 201, loss: 1.219, 6432/28000 datapoints
2025-03-06 20:42:16,180 - INFO - training batch 251, loss: 0.978, 8032/28000 datapoints
2025-03-06 20:42:16,302 - INFO - training batch 301, loss: 1.213, 9632/28000 datapoints
2025-03-06 20:42:16,438 - INFO - training batch 351, loss: 1.080, 11232/28000 datapoints
2025-03-06 20:42:16,572 - INFO - training batch 401, loss: 1.180, 12832/28000 datapoints
2025-03-06 20:42:16,693 - INFO - training batch 451, loss: 1.171, 14432/28000 datapoints
2025-03-06 20:42:16,821 - INFO - training batch 501, loss: 1.050, 16032/28000 datapoints
2025-03-06 20:42:16,945 - INFO - training batch 551, loss: 1.197, 17632/28000 datapoints
2025-03-06 20:42:17,064 - INFO - training batch 601, loss: 1.332, 19232/28000 datapoints
2025-03-06 20:42:17,194 - INFO - training batch 651, loss: 0.784, 20832/28000 datapoints
2025-03-06 20:42:17,316 - INFO - training batch 701, loss: 0.973, 22432/28000 datapoints
2025-03-06 20:42:17,441 - INFO - training batch 751, loss: 1.195, 24032/28000 datapoints
2025-03-06 20:42:17,561 - INFO - training batch 801, loss: 0.967, 25632/28000 datapoints
2025-03-06 20:42:17,688 - INFO - training batch 851, loss: 1.214, 27232/28000 datapoints
2025-03-06 20:42:17,747 - INFO - validation batch 1, loss: 0.805, 32/6976 datapoints
2025-03-06 20:42:17,789 - INFO - validation batch 51, loss: 1.664, 1632/6976 datapoints
2025-03-06 20:42:17,833 - INFO - validation batch 101, loss: 1.097, 3232/6976 datapoints
2025-03-06 20:42:17,877 - INFO - validation batch 151, loss: 1.359, 4832/6976 datapoints
2025-03-06 20:42:17,920 - INFO - validation batch 201, loss: 0.676, 6432/6976 datapoints
2025-03-06 20:42:17,934 - INFO - Epoch 108/800 done.
2025-03-06 20:42:17,935 - INFO - Final validation performance:
Loss: 1.120, top-1 acc: 0.599top-5 acc: 0.599
2025-03-06 20:42:17,935 - INFO - Beginning epoch 109/800
2025-03-06 20:42:17,939 - INFO - training batch 1, loss: 1.205, 32/28000 datapoints
2025-03-06 20:42:18,060 - INFO - training batch 51, loss: 1.346, 1632/28000 datapoints
2025-03-06 20:42:18,180 - INFO - training batch 101, loss: 0.834, 3232/28000 datapoints
2025-03-06 20:42:18,302 - INFO - training batch 151, loss: 1.485, 4832/28000 datapoints
2025-03-06 20:42:18,423 - INFO - training batch 201, loss: 1.205, 6432/28000 datapoints
2025-03-06 20:42:18,545 - INFO - training batch 251, loss: 0.968, 8032/28000 datapoints
2025-03-06 20:42:18,664 - INFO - training batch 301, loss: 1.202, 9632/28000 datapoints
2025-03-06 20:42:18,783 - INFO - training batch 351, loss: 1.067, 11232/28000 datapoints
2025-03-06 20:42:18,905 - INFO - training batch 401, loss: 1.170, 12832/28000 datapoints
2025-03-06 20:42:19,027 - INFO - training batch 451, loss: 1.160, 14432/28000 datapoints
2025-03-06 20:42:19,151 - INFO - training batch 501, loss: 1.040, 16032/28000 datapoints
2025-03-06 20:42:19,273 - INFO - training batch 551, loss: 1.192, 17632/28000 datapoints
2025-03-06 20:42:19,394 - INFO - training batch 601, loss: 1.327, 19232/28000 datapoints
2025-03-06 20:42:19,513 - INFO - training batch 651, loss: 0.773, 20832/28000 datapoints
2025-03-06 20:42:19,637 - INFO - training batch 701, loss: 0.964, 22432/28000 datapoints
2025-03-06 20:42:19,756 - INFO - training batch 751, loss: 1.178, 24032/28000 datapoints
2025-03-06 20:42:19,876 - INFO - training batch 801, loss: 0.955, 25632/28000 datapoints
2025-03-06 20:42:19,996 - INFO - training batch 851, loss: 1.209, 27232/28000 datapoints
2025-03-06 20:42:20,056 - INFO - validation batch 1, loss: 0.797, 32/6976 datapoints
2025-03-06 20:42:20,100 - INFO - validation batch 51, loss: 1.659, 1632/6976 datapoints
2025-03-06 20:42:20,144 - INFO - validation batch 101, loss: 1.086, 3232/6976 datapoints
2025-03-06 20:42:20,188 - INFO - validation batch 151, loss: 1.346, 4832/6976 datapoints
2025-03-06 20:42:20,231 - INFO - validation batch 201, loss: 0.668, 6432/6976 datapoints
2025-03-06 20:42:20,247 - INFO - Epoch 109/800 done.
2025-03-06 20:42:20,247 - INFO - Final validation performance:
Loss: 1.111, top-1 acc: 0.604top-5 acc: 0.604
2025-03-06 20:42:20,248 - INFO - Beginning epoch 110/800
2025-03-06 20:42:20,251 - INFO - training batch 1, loss: 1.194, 32/28000 datapoints
2025-03-06 20:42:20,370 - INFO - training batch 51, loss: 1.333, 1632/28000 datapoints
2025-03-06 20:42:20,492 - INFO - training batch 101, loss: 0.822, 3232/28000 datapoints
2025-03-06 20:42:20,610 - INFO - training batch 151, loss: 1.479, 4832/28000 datapoints
2025-03-06 20:42:20,732 - INFO - training batch 201, loss: 1.191, 6432/28000 datapoints
2025-03-06 20:42:20,850 - INFO - training batch 251, loss: 0.958, 8032/28000 datapoints
2025-03-06 20:42:20,973 - INFO - training batch 301, loss: 1.191, 9632/28000 datapoints
2025-03-06 20:42:21,092 - INFO - training batch 351, loss: 1.053, 11232/28000 datapoints
2025-03-06 20:42:21,219 - INFO - training batch 401, loss: 1.160, 12832/28000 datapoints
2025-03-06 20:42:21,341 - INFO - training batch 451, loss: 1.149, 14432/28000 datapoints
2025-03-06 20:42:21,464 - INFO - training batch 501, loss: 1.030, 16032/28000 datapoints
2025-03-06 20:42:21,594 - INFO - training batch 551, loss: 1.186, 17632/28000 datapoints
2025-03-06 20:42:21,717 - INFO - training batch 601, loss: 1.322, 19232/28000 datapoints
2025-03-06 20:42:21,851 - INFO - training batch 651, loss: 0.762, 20832/28000 datapoints
2025-03-06 20:42:21,971 - INFO - training batch 701, loss: 0.955, 22432/28000 datapoints
2025-03-06 20:42:22,090 - INFO - training batch 751, loss: 1.161, 24032/28000 datapoints
2025-03-06 20:42:22,211 - INFO - training batch 801, loss: 0.942, 25632/28000 datapoints
2025-03-06 20:42:22,330 - INFO - training batch 851, loss: 1.204, 27232/28000 datapoints
2025-03-06 20:42:22,390 - INFO - validation batch 1, loss: 0.789, 32/6976 datapoints
2025-03-06 20:42:22,434 - INFO - validation batch 51, loss: 1.657, 1632/6976 datapoints
2025-03-06 20:42:22,476 - INFO - validation batch 101, loss: 1.074, 3232/6976 datapoints
2025-03-06 20:42:22,520 - INFO - validation batch 151, loss: 1.337, 4832/6976 datapoints
2025-03-06 20:42:22,564 - INFO - validation batch 201, loss: 0.659, 6432/6976 datapoints
2025-03-06 20:42:22,579 - INFO - Epoch 110/800 done.
2025-03-06 20:42:22,579 - INFO - Final validation performance:
Loss: 1.103, top-1 acc: 0.609top-5 acc: 0.609
2025-03-06 20:42:22,579 - INFO - Beginning epoch 111/800
2025-03-06 20:42:22,583 - INFO - training batch 1, loss: 1.183, 32/28000 datapoints
2025-03-06 20:42:22,706 - INFO - training batch 51, loss: 1.320, 1632/28000 datapoints
2025-03-06 20:42:22,835 - INFO - training batch 101, loss: 0.810, 3232/28000 datapoints
2025-03-06 20:42:22,965 - INFO - training batch 151, loss: 1.471, 4832/28000 datapoints
2025-03-06 20:42:23,105 - INFO - training batch 201, loss: 1.176, 6432/28000 datapoints
2025-03-06 20:42:23,229 - INFO - training batch 251, loss: 0.947, 8032/28000 datapoints
2025-03-06 20:42:23,349 - INFO - training batch 301, loss: 1.180, 9632/28000 datapoints
2025-03-06 20:42:23,471 - INFO - training batch 351, loss: 1.042, 11232/28000 datapoints
2025-03-06 20:42:23,599 - INFO - training batch 401, loss: 1.152, 12832/28000 datapoints
2025-03-06 20:42:23,723 - INFO - training batch 451, loss: 1.137, 14432/28000 datapoints
2025-03-06 20:42:23,862 - INFO - training batch 501, loss: 1.019, 16032/28000 datapoints
2025-03-06 20:42:24,003 - INFO - training batch 551, loss: 1.179, 17632/28000 datapoints
2025-03-06 20:42:24,125 - INFO - training batch 601, loss: 1.316, 19232/28000 datapoints
2025-03-06 20:42:24,249 - INFO - training batch 651, loss: 0.751, 20832/28000 datapoints
2025-03-06 20:42:24,376 - INFO - training batch 701, loss: 0.946, 22432/28000 datapoints
2025-03-06 20:42:24,503 - INFO - training batch 751, loss: 1.144, 24032/28000 datapoints
2025-03-06 20:42:24,629 - INFO - training batch 801, loss: 0.930, 25632/28000 datapoints
2025-03-06 20:42:24,756 - INFO - training batch 851, loss: 1.200, 27232/28000 datapoints
2025-03-06 20:42:24,817 - INFO - validation batch 1, loss: 0.781, 32/6976 datapoints
2025-03-06 20:42:24,865 - INFO - validation batch 51, loss: 1.651, 1632/6976 datapoints
2025-03-06 20:42:24,915 - INFO - validation batch 101, loss: 1.062, 3232/6976 datapoints
2025-03-06 20:42:24,962 - INFO - validation batch 151, loss: 1.327, 4832/6976 datapoints
2025-03-06 20:42:25,009 - INFO - validation batch 201, loss: 0.650, 6432/6976 datapoints
2025-03-06 20:42:25,028 - INFO - Epoch 111/800 done.
2025-03-06 20:42:25,028 - INFO - Final validation performance:
Loss: 1.094, top-1 acc: 0.613top-5 acc: 0.613
2025-03-06 20:42:25,029 - INFO - Beginning epoch 112/800
2025-03-06 20:42:25,033 - INFO - training batch 1, loss: 1.172, 32/28000 datapoints
2025-03-06 20:42:25,159 - INFO - training batch 51, loss: 1.306, 1632/28000 datapoints
2025-03-06 20:42:25,281 - INFO - training batch 101, loss: 0.799, 3232/28000 datapoints
2025-03-06 20:42:25,402 - INFO - training batch 151, loss: 1.464, 4832/28000 datapoints
2025-03-06 20:42:25,525 - INFO - training batch 201, loss: 1.161, 6432/28000 datapoints
2025-03-06 20:42:25,648 - INFO - training batch 251, loss: 0.938, 8032/28000 datapoints
2025-03-06 20:42:25,768 - INFO - training batch 301, loss: 1.169, 9632/28000 datapoints
2025-03-06 20:42:25,888 - INFO - training batch 351, loss: 1.030, 11232/28000 datapoints
2025-03-06 20:42:26,009 - INFO - training batch 401, loss: 1.143, 12832/28000 datapoints
2025-03-06 20:42:26,128 - INFO - training batch 451, loss: 1.126, 14432/28000 datapoints
2025-03-06 20:42:26,247 - INFO - training batch 501, loss: 1.010, 16032/28000 datapoints
2025-03-06 20:42:26,369 - INFO - training batch 551, loss: 1.171, 17632/28000 datapoints
2025-03-06 20:42:26,495 - INFO - training batch 601, loss: 1.310, 19232/28000 datapoints
2025-03-06 20:42:26,639 - INFO - training batch 651, loss: 0.740, 20832/28000 datapoints
2025-03-06 20:42:26,758 - INFO - training batch 701, loss: 0.935, 22432/28000 datapoints
2025-03-06 20:42:26,877 - INFO - training batch 751, loss: 1.128, 24032/28000 datapoints
2025-03-06 20:42:27,000 - INFO - training batch 801, loss: 0.917, 25632/28000 datapoints
2025-03-06 20:42:27,118 - INFO - training batch 851, loss: 1.195, 27232/28000 datapoints
2025-03-06 20:42:27,182 - INFO - validation batch 1, loss: 0.772, 32/6976 datapoints
2025-03-06 20:42:27,226 - INFO - validation batch 51, loss: 1.646, 1632/6976 datapoints
2025-03-06 20:42:27,270 - INFO - validation batch 101, loss: 1.050, 3232/6976 datapoints
2025-03-06 20:42:27,314 - INFO - validation batch 151, loss: 1.319, 4832/6976 datapoints
2025-03-06 20:42:27,356 - INFO - validation batch 201, loss: 0.642, 6432/6976 datapoints
2025-03-06 20:42:27,371 - INFO - Epoch 112/800 done.
2025-03-06 20:42:27,372 - INFO - Final validation performance:
Loss: 1.086, top-1 acc: 0.617top-5 acc: 0.617
2025-03-06 20:42:27,372 - INFO - Beginning epoch 113/800
2025-03-06 20:42:27,375 - INFO - training batch 1, loss: 1.163, 32/28000 datapoints
2025-03-06 20:42:27,500 - INFO - training batch 51, loss: 1.292, 1632/28000 datapoints
2025-03-06 20:42:27,620 - INFO - training batch 101, loss: 0.787, 3232/28000 datapoints
2025-03-06 20:42:27,742 - INFO - training batch 151, loss: 1.457, 4832/28000 datapoints
2025-03-06 20:42:27,861 - INFO - training batch 201, loss: 1.145, 6432/28000 datapoints
2025-03-06 20:42:27,980 - INFO - training batch 251, loss: 0.928, 8032/28000 datapoints
2025-03-06 20:42:28,101 - INFO - training batch 301, loss: 1.159, 9632/28000 datapoints
2025-03-06 20:42:28,219 - INFO - training batch 351, loss: 1.018, 11232/28000 datapoints
2025-03-06 20:42:28,338 - INFO - training batch 401, loss: 1.134, 12832/28000 datapoints
2025-03-06 20:42:28,460 - INFO - training batch 451, loss: 1.113, 14432/28000 datapoints
2025-03-06 20:42:28,579 - INFO - training batch 501, loss: 0.999, 16032/28000 datapoints
2025-03-06 20:42:28,721 - INFO - training batch 551, loss: 1.163, 17632/28000 datapoints
2025-03-06 20:42:28,841 - INFO - training batch 601, loss: 1.304, 19232/28000 datapoints
2025-03-06 20:42:28,961 - INFO - training batch 651, loss: 0.730, 20832/28000 datapoints
2025-03-06 20:42:29,094 - INFO - training batch 701, loss: 0.926, 22432/28000 datapoints
2025-03-06 20:42:29,225 - INFO - training batch 751, loss: 1.110, 24032/28000 datapoints
2025-03-06 20:42:29,344 - INFO - training batch 801, loss: 0.905, 25632/28000 datapoints
2025-03-06 20:42:29,467 - INFO - training batch 851, loss: 1.191, 27232/28000 datapoints
2025-03-06 20:42:29,527 - INFO - validation batch 1, loss: 0.764, 32/6976 datapoints
2025-03-06 20:42:29,578 - INFO - validation batch 51, loss: 1.642, 1632/6976 datapoints
2025-03-06 20:42:29,624 - INFO - validation batch 101, loss: 1.037, 3232/6976 datapoints
2025-03-06 20:42:29,671 - INFO - validation batch 151, loss: 1.311, 4832/6976 datapoints
2025-03-06 20:42:29,718 - INFO - validation batch 201, loss: 0.632, 6432/6976 datapoints
2025-03-06 20:42:29,733 - INFO - Epoch 113/800 done.
2025-03-06 20:42:29,733 - INFO - Final validation performance:
Loss: 1.077, top-1 acc: 0.619top-5 acc: 0.619
2025-03-06 20:42:29,734 - INFO - Beginning epoch 114/800
2025-03-06 20:42:29,737 - INFO - training batch 1, loss: 1.153, 32/28000 datapoints
2025-03-06 20:42:29,861 - INFO - training batch 51, loss: 1.279, 1632/28000 datapoints
2025-03-06 20:42:29,981 - INFO - training batch 101, loss: 0.775, 3232/28000 datapoints
2025-03-06 20:42:30,104 - INFO - training batch 151, loss: 1.451, 4832/28000 datapoints
2025-03-06 20:42:30,224 - INFO - training batch 201, loss: 1.129, 6432/28000 datapoints
2025-03-06 20:42:30,344 - INFO - training batch 251, loss: 0.917, 8032/28000 datapoints
2025-03-06 20:42:30,463 - INFO - training batch 301, loss: 1.149, 9632/28000 datapoints
2025-03-06 20:42:30,583 - INFO - training batch 351, loss: 1.007, 11232/28000 datapoints
2025-03-06 20:42:30,703 - INFO - training batch 401, loss: 1.125, 12832/28000 datapoints
2025-03-06 20:42:30,822 - INFO - training batch 451, loss: 1.101, 14432/28000 datapoints
2025-03-06 20:42:30,941 - INFO - training batch 501, loss: 0.987, 16032/28000 datapoints
2025-03-06 20:42:31,062 - INFO - training batch 551, loss: 1.155, 17632/28000 datapoints
2025-03-06 20:42:31,185 - INFO - training batch 601, loss: 1.297, 19232/28000 datapoints
2025-03-06 20:42:31,306 - INFO - training batch 651, loss: 0.719, 20832/28000 datapoints
2025-03-06 20:42:31,427 - INFO - training batch 701, loss: 0.916, 22432/28000 datapoints
2025-03-06 20:42:31,547 - INFO - training batch 751, loss: 1.092, 24032/28000 datapoints
2025-03-06 20:42:31,670 - INFO - training batch 801, loss: 0.892, 25632/28000 datapoints
2025-03-06 20:42:31,789 - INFO - training batch 851, loss: 1.187, 27232/28000 datapoints
2025-03-06 20:42:31,847 - INFO - validation batch 1, loss: 0.755, 32/6976 datapoints
2025-03-06 20:42:31,892 - INFO - validation batch 51, loss: 1.638, 1632/6976 datapoints
2025-03-06 20:42:31,936 - INFO - validation batch 101, loss: 1.025, 3232/6976 datapoints
2025-03-06 20:42:31,979 - INFO - validation batch 151, loss: 1.301, 4832/6976 datapoints
2025-03-06 20:42:32,022 - INFO - validation batch 201, loss: 0.623, 6432/6976 datapoints
2025-03-06 20:42:32,037 - INFO - Epoch 114/800 done.
2025-03-06 20:42:32,037 - INFO - Final validation performance:
Loss: 1.068, top-1 acc: 0.625top-5 acc: 0.625
2025-03-06 20:42:32,037 - INFO - Beginning epoch 115/800
2025-03-06 20:42:32,041 - INFO - training batch 1, loss: 1.142, 32/28000 datapoints
2025-03-06 20:42:32,205 - INFO - training batch 51, loss: 1.264, 1632/28000 datapoints
2025-03-06 20:42:32,325 - INFO - training batch 101, loss: 0.763, 3232/28000 datapoints
2025-03-06 20:42:32,445 - INFO - training batch 151, loss: 1.444, 4832/28000 datapoints
2025-03-06 20:42:32,563 - INFO - training batch 201, loss: 1.111, 6432/28000 datapoints
2025-03-06 20:42:32,686 - INFO - training batch 251, loss: 0.907, 8032/28000 datapoints
2025-03-06 20:42:32,804 - INFO - training batch 301, loss: 1.139, 9632/28000 datapoints
2025-03-06 20:42:32,923 - INFO - training batch 351, loss: 0.994, 11232/28000 datapoints
2025-03-06 20:42:33,043 - INFO - training batch 401, loss: 1.116, 12832/28000 datapoints
2025-03-06 20:42:33,169 - INFO - training batch 451, loss: 1.089, 14432/28000 datapoints
2025-03-06 20:42:33,289 - INFO - training batch 501, loss: 0.976, 16032/28000 datapoints
2025-03-06 20:42:33,406 - INFO - training batch 551, loss: 1.148, 17632/28000 datapoints
2025-03-06 20:42:33,527 - INFO - training batch 601, loss: 1.291, 19232/28000 datapoints
2025-03-06 20:42:33,649 - INFO - training batch 651, loss: 0.709, 20832/28000 datapoints
2025-03-06 20:42:33,767 - INFO - training batch 701, loss: 0.907, 22432/28000 datapoints
2025-03-06 20:42:33,886 - INFO - training batch 751, loss: 1.074, 24032/28000 datapoints
2025-03-06 20:42:34,007 - INFO - training batch 801, loss: 0.880, 25632/28000 datapoints
2025-03-06 20:42:34,127 - INFO - training batch 851, loss: 1.183, 27232/28000 datapoints
2025-03-06 20:42:34,187 - INFO - validation batch 1, loss: 0.747, 32/6976 datapoints
2025-03-06 20:42:34,231 - INFO - validation batch 51, loss: 1.634, 1632/6976 datapoints
2025-03-06 20:42:34,275 - INFO - validation batch 101, loss: 1.012, 3232/6976 datapoints
2025-03-06 20:42:34,319 - INFO - validation batch 151, loss: 1.291, 4832/6976 datapoints
2025-03-06 20:42:34,362 - INFO - validation batch 201, loss: 0.613, 6432/6976 datapoints
2025-03-06 20:42:34,378 - INFO - Epoch 115/800 done.
2025-03-06 20:42:34,378 - INFO - Final validation performance:
Loss: 1.059, top-1 acc: 0.630top-5 acc: 0.630
2025-03-06 20:42:34,378 - INFO - Beginning epoch 116/800
2025-03-06 20:42:34,382 - INFO - training batch 1, loss: 1.132, 32/28000 datapoints
2025-03-06 20:42:34,503 - INFO - training batch 51, loss: 1.249, 1632/28000 datapoints
2025-03-06 20:42:34,626 - INFO - training batch 101, loss: 0.751, 3232/28000 datapoints
2025-03-06 20:42:34,749 - INFO - training batch 151, loss: 1.437, 4832/28000 datapoints
2025-03-06 20:42:34,870 - INFO - training batch 201, loss: 1.093, 6432/28000 datapoints
2025-03-06 20:42:34,994 - INFO - training batch 251, loss: 0.896, 8032/28000 datapoints
2025-03-06 20:42:35,130 - INFO - training batch 301, loss: 1.129, 9632/28000 datapoints
2025-03-06 20:42:35,262 - INFO - training batch 351, loss: 0.982, 11232/28000 datapoints
2025-03-06 20:42:35,382 - INFO - training batch 401, loss: 1.108, 12832/28000 datapoints
2025-03-06 20:42:35,501 - INFO - training batch 451, loss: 1.077, 14432/28000 datapoints
2025-03-06 20:42:35,628 - INFO - training batch 501, loss: 0.964, 16032/28000 datapoints
2025-03-06 20:42:35,756 - INFO - training batch 551, loss: 1.139, 17632/28000 datapoints
2025-03-06 20:42:35,876 - INFO - training batch 601, loss: 1.284, 19232/28000 datapoints
2025-03-06 20:42:36,001 - INFO - training batch 651, loss: 0.698, 20832/28000 datapoints
2025-03-06 20:42:36,124 - INFO - training batch 701, loss: 0.898, 22432/28000 datapoints
2025-03-06 20:42:36,244 - INFO - training batch 751, loss: 1.055, 24032/28000 datapoints
2025-03-06 20:42:36,364 - INFO - training batch 801, loss: 0.867, 25632/28000 datapoints
2025-03-06 20:42:36,488 - INFO - training batch 851, loss: 1.179, 27232/28000 datapoints
2025-03-06 20:42:36,546 - INFO - validation batch 1, loss: 0.738, 32/6976 datapoints
2025-03-06 20:42:36,593 - INFO - validation batch 51, loss: 1.629, 1632/6976 datapoints
2025-03-06 20:42:36,661 - INFO - validation batch 101, loss: 0.998, 3232/6976 datapoints
2025-03-06 20:42:36,706 - INFO - validation batch 151, loss: 1.282, 4832/6976 datapoints
2025-03-06 20:42:36,750 - INFO - validation batch 201, loss: 0.605, 6432/6976 datapoints
2025-03-06 20:42:36,765 - INFO - Epoch 116/800 done.
2025-03-06 20:42:36,765 - INFO - Final validation performance:
Loss: 1.050, top-1 acc: 0.636top-5 acc: 0.636
2025-03-06 20:42:36,766 - INFO - Beginning epoch 117/800
2025-03-06 20:42:36,769 - INFO - training batch 1, loss: 1.123, 32/28000 datapoints
2025-03-06 20:42:36,890 - INFO - training batch 51, loss: 1.233, 1632/28000 datapoints
2025-03-06 20:42:37,011 - INFO - training batch 101, loss: 0.738, 3232/28000 datapoints
2025-03-06 20:42:37,130 - INFO - training batch 151, loss: 1.431, 4832/28000 datapoints
2025-03-06 20:42:37,258 - INFO - training batch 201, loss: 1.074, 6432/28000 datapoints
2025-03-06 20:42:37,377 - INFO - training batch 251, loss: 0.886, 8032/28000 datapoints
2025-03-06 20:42:37,497 - INFO - training batch 301, loss: 1.119, 9632/28000 datapoints
2025-03-06 20:42:37,618 - INFO - training batch 351, loss: 0.968, 11232/28000 datapoints
2025-03-06 20:42:37,759 - INFO - training batch 401, loss: 1.100, 12832/28000 datapoints
2025-03-06 20:42:37,879 - INFO - training batch 451, loss: 1.066, 14432/28000 datapoints
2025-03-06 20:42:38,000 - INFO - training batch 501, loss: 0.953, 16032/28000 datapoints
2025-03-06 20:42:38,123 - INFO - training batch 551, loss: 1.131, 17632/28000 datapoints
2025-03-06 20:42:38,246 - INFO - training batch 601, loss: 1.277, 19232/28000 datapoints
2025-03-06 20:42:38,366 - INFO - training batch 651, loss: 0.687, 20832/28000 datapoints
2025-03-06 20:42:38,487 - INFO - training batch 701, loss: 0.889, 22432/28000 datapoints
2025-03-06 20:42:38,607 - INFO - training batch 751, loss: 1.037, 24032/28000 datapoints
2025-03-06 20:42:38,729 - INFO - training batch 801, loss: 0.855, 25632/28000 datapoints
2025-03-06 20:42:38,849 - INFO - training batch 851, loss: 1.176, 27232/28000 datapoints
2025-03-06 20:42:38,908 - INFO - validation batch 1, loss: 0.730, 32/6976 datapoints
2025-03-06 20:42:38,952 - INFO - validation batch 51, loss: 1.625, 1632/6976 datapoints
2025-03-06 20:42:38,998 - INFO - validation batch 101, loss: 0.985, 3232/6976 datapoints
2025-03-06 20:42:39,049 - INFO - validation batch 151, loss: 1.272, 4832/6976 datapoints
2025-03-06 20:42:39,094 - INFO - validation batch 201, loss: 0.596, 6432/6976 datapoints
2025-03-06 20:42:39,109 - INFO - Epoch 117/800 done.
2025-03-06 20:42:39,109 - INFO - Final validation performance:
Loss: 1.041, top-1 acc: 0.640top-5 acc: 0.640
2025-03-06 20:42:39,110 - INFO - Beginning epoch 118/800
2025-03-06 20:42:39,113 - INFO - training batch 1, loss: 1.113, 32/28000 datapoints
2025-03-06 20:42:39,240 - INFO - training batch 51, loss: 1.217, 1632/28000 datapoints
2025-03-06 20:42:39,360 - INFO - training batch 101, loss: 0.726, 3232/28000 datapoints
2025-03-06 20:42:39,481 - INFO - training batch 151, loss: 1.423, 4832/28000 datapoints
2025-03-06 20:42:39,604 - INFO - training batch 201, loss: 1.054, 6432/28000 datapoints
2025-03-06 20:42:39,728 - INFO - training batch 251, loss: 0.874, 8032/28000 datapoints
2025-03-06 20:42:39,848 - INFO - training batch 301, loss: 1.109, 9632/28000 datapoints
2025-03-06 20:42:39,966 - INFO - training batch 351, loss: 0.955, 11232/28000 datapoints
2025-03-06 20:42:40,092 - INFO - training batch 401, loss: 1.092, 12832/28000 datapoints
2025-03-06 20:42:40,212 - INFO - training batch 451, loss: 1.054, 14432/28000 datapoints
2025-03-06 20:42:40,335 - INFO - training batch 501, loss: 0.940, 16032/28000 datapoints
2025-03-06 20:42:40,453 - INFO - training batch 551, loss: 1.121, 17632/28000 datapoints
2025-03-06 20:42:40,572 - INFO - training batch 601, loss: 1.270, 19232/28000 datapoints
2025-03-06 20:42:40,696 - INFO - training batch 651, loss: 0.676, 20832/28000 datapoints
2025-03-06 20:42:40,816 - INFO - training batch 701, loss: 0.880, 22432/28000 datapoints
2025-03-06 20:42:40,937 - INFO - training batch 751, loss: 1.019, 24032/28000 datapoints
2025-03-06 20:42:41,058 - INFO - training batch 801, loss: 0.844, 25632/28000 datapoints
2025-03-06 20:42:41,178 - INFO - training batch 851, loss: 1.173, 27232/28000 datapoints
2025-03-06 20:42:41,250 - INFO - validation batch 1, loss: 0.721, 32/6976 datapoints
2025-03-06 20:42:41,298 - INFO - validation batch 51, loss: 1.620, 1632/6976 datapoints
2025-03-06 20:42:41,342 - INFO - validation batch 101, loss: 0.970, 3232/6976 datapoints
2025-03-06 20:42:41,385 - INFO - validation batch 151, loss: 1.263, 4832/6976 datapoints
2025-03-06 20:42:41,428 - INFO - validation batch 201, loss: 0.587, 6432/6976 datapoints
2025-03-06 20:42:41,444 - INFO - Epoch 118/800 done.
2025-03-06 20:42:41,444 - INFO - Final validation performance:
Loss: 1.032, top-1 acc: 0.644top-5 acc: 0.644
2025-03-06 20:42:41,444 - INFO - Beginning epoch 119/800
2025-03-06 20:42:41,448 - INFO - training batch 1, loss: 1.103, 32/28000 datapoints
2025-03-06 20:42:41,567 - INFO - training batch 51, loss: 1.201, 1632/28000 datapoints
2025-03-06 20:42:41,695 - INFO - training batch 101, loss: 0.713, 3232/28000 datapoints
2025-03-06 20:42:41,819 - INFO - training batch 151, loss: 1.415, 4832/28000 datapoints
2025-03-06 20:42:41,939 - INFO - training batch 201, loss: 1.036, 6432/28000 datapoints
2025-03-06 20:42:42,060 - INFO - training batch 251, loss: 0.863, 8032/28000 datapoints
2025-03-06 20:42:42,178 - INFO - training batch 301, loss: 1.100, 9632/28000 datapoints
2025-03-06 20:42:42,299 - INFO - training batch 351, loss: 0.942, 11232/28000 datapoints
2025-03-06 20:42:42,419 - INFO - training batch 401, loss: 1.084, 12832/28000 datapoints
2025-03-06 20:42:42,539 - INFO - training batch 451, loss: 1.042, 14432/28000 datapoints
2025-03-06 20:42:42,662 - INFO - training batch 501, loss: 0.928, 16032/28000 datapoints
2025-03-06 20:42:42,782 - INFO - training batch 551, loss: 1.112, 17632/28000 datapoints
2025-03-06 20:42:42,902 - INFO - training batch 601, loss: 1.262, 19232/28000 datapoints
2025-03-06 20:42:43,021 - INFO - training batch 651, loss: 0.666, 20832/28000 datapoints
2025-03-06 20:42:43,141 - INFO - training batch 701, loss: 0.871, 22432/28000 datapoints
2025-03-06 20:42:43,265 - INFO - training batch 751, loss: 1.000, 24032/28000 datapoints
2025-03-06 20:42:43,385 - INFO - training batch 801, loss: 0.833, 25632/28000 datapoints
2025-03-06 20:42:43,507 - INFO - training batch 851, loss: 1.171, 27232/28000 datapoints
2025-03-06 20:42:43,566 - INFO - validation batch 1, loss: 0.712, 32/6976 datapoints
2025-03-06 20:42:43,610 - INFO - validation batch 51, loss: 1.616, 1632/6976 datapoints
2025-03-06 20:42:43,658 - INFO - validation batch 101, loss: 0.956, 3232/6976 datapoints
2025-03-06 20:42:43,702 - INFO - validation batch 151, loss: 1.253, 4832/6976 datapoints
2025-03-06 20:42:43,747 - INFO - validation batch 201, loss: 0.578, 6432/6976 datapoints
2025-03-06 20:42:43,762 - INFO - Epoch 119/800 done.
2025-03-06 20:42:43,762 - INFO - Final validation performance:
Loss: 1.023, top-1 acc: 0.649top-5 acc: 0.649
2025-03-06 20:42:43,763 - INFO - Beginning epoch 120/800
2025-03-06 20:42:43,766 - INFO - training batch 1, loss: 1.092, 32/28000 datapoints
2025-03-06 20:42:43,887 - INFO - training batch 51, loss: 1.185, 1632/28000 datapoints
2025-03-06 20:42:44,007 - INFO - training batch 101, loss: 0.701, 3232/28000 datapoints
2025-03-06 20:42:44,127 - INFO - training batch 151, loss: 1.406, 4832/28000 datapoints
2025-03-06 20:42:44,246 - INFO - training batch 201, loss: 1.017, 6432/28000 datapoints
2025-03-06 20:42:44,366 - INFO - training batch 251, loss: 0.853, 8032/28000 datapoints
2025-03-06 20:42:44,486 - INFO - training batch 301, loss: 1.090, 9632/28000 datapoints
2025-03-06 20:42:44,612 - INFO - training batch 351, loss: 0.930, 11232/28000 datapoints
2025-03-06 20:42:44,740 - INFO - training batch 401, loss: 1.077, 12832/28000 datapoints
2025-03-06 20:42:44,864 - INFO - training batch 451, loss: 1.031, 14432/28000 datapoints
2025-03-06 20:42:44,991 - INFO - training batch 501, loss: 0.915, 16032/28000 datapoints
2025-03-06 20:42:45,118 - INFO - training batch 551, loss: 1.100, 17632/28000 datapoints
2025-03-06 20:42:45,251 - INFO - training batch 601, loss: 1.254, 19232/28000 datapoints
2025-03-06 20:42:45,377 - INFO - training batch 651, loss: 0.656, 20832/28000 datapoints
2025-03-06 20:42:45,509 - INFO - training batch 701, loss: 0.862, 22432/28000 datapoints
2025-03-06 20:42:45,637 - INFO - training batch 751, loss: 0.982, 24032/28000 datapoints
2025-03-06 20:42:45,763 - INFO - training batch 801, loss: 0.822, 25632/28000 datapoints
2025-03-06 20:42:45,886 - INFO - training batch 851, loss: 1.168, 27232/28000 datapoints
2025-03-06 20:42:45,948 - INFO - validation batch 1, loss: 0.704, 32/6976 datapoints
2025-03-06 20:42:45,996 - INFO - validation batch 51, loss: 1.611, 1632/6976 datapoints
2025-03-06 20:42:46,046 - INFO - validation batch 101, loss: 0.942, 3232/6976 datapoints
2025-03-06 20:42:46,096 - INFO - validation batch 151, loss: 1.241, 4832/6976 datapoints
2025-03-06 20:42:46,145 - INFO - validation batch 201, loss: 0.569, 6432/6976 datapoints
2025-03-06 20:42:46,160 - INFO - Epoch 120/800 done.
2025-03-06 20:42:46,160 - INFO - Final validation performance:
Loss: 1.013, top-1 acc: 0.654top-5 acc: 0.654
2025-03-06 20:42:46,161 - INFO - Beginning epoch 121/800
2025-03-06 20:42:46,165 - INFO - training batch 1, loss: 1.082, 32/28000 datapoints
2025-03-06 20:42:46,293 - INFO - training batch 51, loss: 1.168, 1632/28000 datapoints
2025-03-06 20:42:46,419 - INFO - training batch 101, loss: 0.689, 3232/28000 datapoints
2025-03-06 20:42:46,556 - INFO - training batch 151, loss: 1.397, 4832/28000 datapoints
2025-03-06 20:42:46,724 - INFO - training batch 201, loss: 0.997, 6432/28000 datapoints
2025-03-06 20:42:46,862 - INFO - training batch 251, loss: 0.841, 8032/28000 datapoints
2025-03-06 20:42:46,986 - INFO - training batch 301, loss: 1.081, 9632/28000 datapoints
2025-03-06 20:42:47,110 - INFO - training batch 351, loss: 0.919, 11232/28000 datapoints
2025-03-06 20:42:47,237 - INFO - training batch 401, loss: 1.070, 12832/28000 datapoints
2025-03-06 20:42:47,380 - INFO - training batch 451, loss: 1.020, 14432/28000 datapoints
2025-03-06 20:42:47,503 - INFO - training batch 501, loss: 0.902, 16032/28000 datapoints
2025-03-06 20:42:47,629 - INFO - training batch 551, loss: 1.088, 17632/28000 datapoints
2025-03-06 20:42:47,763 - INFO - training batch 601, loss: 1.247, 19232/28000 datapoints
2025-03-06 20:42:47,891 - INFO - training batch 651, loss: 0.647, 20832/28000 datapoints
2025-03-06 20:42:48,017 - INFO - training batch 701, loss: 0.853, 22432/28000 datapoints
2025-03-06 20:42:48,146 - INFO - training batch 751, loss: 0.964, 24032/28000 datapoints
2025-03-06 20:42:48,270 - INFO - training batch 801, loss: 0.810, 25632/28000 datapoints
2025-03-06 20:42:48,394 - INFO - training batch 851, loss: 1.166, 27232/28000 datapoints
2025-03-06 20:42:48,456 - INFO - validation batch 1, loss: 0.696, 32/6976 datapoints
2025-03-06 20:42:48,505 - INFO - validation batch 51, loss: 1.606, 1632/6976 datapoints
2025-03-06 20:42:48,552 - INFO - validation batch 101, loss: 0.928, 3232/6976 datapoints
2025-03-06 20:42:48,599 - INFO - validation batch 151, loss: 1.230, 4832/6976 datapoints
2025-03-06 20:42:48,650 - INFO - validation batch 201, loss: 0.560, 6432/6976 datapoints
2025-03-06 20:42:48,665 - INFO - Epoch 121/800 done.
2025-03-06 20:42:48,665 - INFO - Final validation performance:
Loss: 1.004, top-1 acc: 0.659top-5 acc: 0.659
2025-03-06 20:42:48,665 - INFO - Beginning epoch 122/800
2025-03-06 20:42:48,670 - INFO - training batch 1, loss: 1.071, 32/28000 datapoints
2025-03-06 20:42:48,799 - INFO - training batch 51, loss: 1.152, 1632/28000 datapoints
2025-03-06 20:42:48,922 - INFO - training batch 101, loss: 0.678, 3232/28000 datapoints
2025-03-06 20:42:49,050 - INFO - training batch 151, loss: 1.390, 4832/28000 datapoints
2025-03-06 20:42:49,175 - INFO - training batch 201, loss: 0.976, 6432/28000 datapoints
2025-03-06 20:42:49,303 - INFO - training batch 251, loss: 0.830, 8032/28000 datapoints
2025-03-06 20:42:49,429 - INFO - training batch 301, loss: 1.072, 9632/28000 datapoints
2025-03-06 20:42:49,552 - INFO - training batch 351, loss: 0.908, 11232/28000 datapoints
2025-03-06 20:42:49,682 - INFO - training batch 401, loss: 1.063, 12832/28000 datapoints
2025-03-06 20:42:49,805 - INFO - training batch 451, loss: 1.010, 14432/28000 datapoints
2025-03-06 20:42:49,931 - INFO - training batch 501, loss: 0.890, 16032/28000 datapoints
2025-03-06 20:42:50,054 - INFO - training batch 551, loss: 1.076, 17632/28000 datapoints
2025-03-06 20:42:50,177 - INFO - training batch 601, loss: 1.240, 19232/28000 datapoints
2025-03-06 20:42:50,303 - INFO - training batch 651, loss: 0.637, 20832/28000 datapoints
2025-03-06 20:42:50,427 - INFO - training batch 701, loss: 0.845, 22432/28000 datapoints
2025-03-06 20:42:50,551 - INFO - training batch 751, loss: 0.946, 24032/28000 datapoints
2025-03-06 20:42:50,676 - INFO - training batch 801, loss: 0.799, 25632/28000 datapoints
2025-03-06 20:42:50,798 - INFO - training batch 851, loss: 1.164, 27232/28000 datapoints
2025-03-06 20:42:50,860 - INFO - validation batch 1, loss: 0.687, 32/6976 datapoints
2025-03-06 20:42:50,907 - INFO - validation batch 51, loss: 1.600, 1632/6976 datapoints
2025-03-06 20:42:50,954 - INFO - validation batch 101, loss: 0.913, 3232/6976 datapoints
2025-03-06 20:42:51,001 - INFO - validation batch 151, loss: 1.218, 4832/6976 datapoints
2025-03-06 20:42:51,049 - INFO - validation batch 201, loss: 0.552, 6432/6976 datapoints
2025-03-06 20:42:51,064 - INFO - Epoch 122/800 done.
2025-03-06 20:42:51,064 - INFO - Final validation performance:
Loss: 0.994, top-1 acc: 0.662top-5 acc: 0.662
2025-03-06 20:42:51,064 - INFO - Beginning epoch 123/800
2025-03-06 20:42:51,068 - INFO - training batch 1, loss: 1.062, 32/28000 datapoints
2025-03-06 20:42:51,196 - INFO - training batch 51, loss: 1.136, 1632/28000 datapoints
2025-03-06 20:42:51,327 - INFO - training batch 101, loss: 0.666, 3232/28000 datapoints
2025-03-06 20:42:51,451 - INFO - training batch 151, loss: 1.383, 4832/28000 datapoints
2025-03-06 20:42:51,574 - INFO - training batch 201, loss: 0.956, 6432/28000 datapoints
2025-03-06 20:42:51,706 - INFO - training batch 251, loss: 0.820, 8032/28000 datapoints
2025-03-06 20:42:51,828 - INFO - training batch 301, loss: 1.064, 9632/28000 datapoints
2025-03-06 20:42:51,954 - INFO - training batch 351, loss: 0.897, 11232/28000 datapoints
2025-03-06 20:42:52,076 - INFO - training batch 401, loss: 1.057, 12832/28000 datapoints
2025-03-06 20:42:52,199 - INFO - training batch 451, loss: 1.000, 14432/28000 datapoints
2025-03-06 20:42:52,323 - INFO - training batch 501, loss: 0.877, 16032/28000 datapoints
2025-03-06 20:42:52,447 - INFO - training batch 551, loss: 1.062, 17632/28000 datapoints
2025-03-06 20:42:52,570 - INFO - training batch 601, loss: 1.233, 19232/28000 datapoints
2025-03-06 20:42:52,699 - INFO - training batch 651, loss: 0.627, 20832/28000 datapoints
2025-03-06 20:42:52,824 - INFO - training batch 701, loss: 0.836, 22432/28000 datapoints
2025-03-06 20:42:52,946 - INFO - training batch 751, loss: 0.928, 24032/28000 datapoints
2025-03-06 20:42:53,068 - INFO - training batch 801, loss: 0.789, 25632/28000 datapoints
2025-03-06 20:42:53,199 - INFO - training batch 851, loss: 1.161, 27232/28000 datapoints
2025-03-06 20:42:53,267 - INFO - validation batch 1, loss: 0.680, 32/6976 datapoints
2025-03-06 20:42:53,314 - INFO - validation batch 51, loss: 1.595, 1632/6976 datapoints
2025-03-06 20:42:53,366 - INFO - validation batch 101, loss: 0.898, 3232/6976 datapoints
2025-03-06 20:42:53,420 - INFO - validation batch 151, loss: 1.206, 4832/6976 datapoints
2025-03-06 20:42:53,479 - INFO - validation batch 201, loss: 0.544, 6432/6976 datapoints
2025-03-06 20:42:53,497 - INFO - Epoch 123/800 done.
2025-03-06 20:42:53,497 - INFO - Final validation performance:
Loss: 0.984, top-1 acc: 0.667top-5 acc: 0.667
2025-03-06 20:42:53,498 - INFO - Beginning epoch 124/800
2025-03-06 20:42:53,501 - INFO - training batch 1, loss: 1.052, 32/28000 datapoints
2025-03-06 20:42:53,635 - INFO - training batch 51, loss: 1.120, 1632/28000 datapoints
2025-03-06 20:42:53,758 - INFO - training batch 101, loss: 0.655, 3232/28000 datapoints
2025-03-06 20:42:53,887 - INFO - training batch 151, loss: 1.376, 4832/28000 datapoints
2025-03-06 20:42:54,010 - INFO - training batch 201, loss: 0.934, 6432/28000 datapoints
2025-03-06 20:42:54,134 - INFO - training batch 251, loss: 0.809, 8032/28000 datapoints
2025-03-06 20:42:54,262 - INFO - training batch 301, loss: 1.055, 9632/28000 datapoints
2025-03-06 20:42:54,389 - INFO - training batch 351, loss: 0.887, 11232/28000 datapoints
2025-03-06 20:42:54,511 - INFO - training batch 401, loss: 1.051, 12832/28000 datapoints
2025-03-06 20:42:54,636 - INFO - training batch 451, loss: 0.990, 14432/28000 datapoints
2025-03-06 20:42:54,761 - INFO - training batch 501, loss: 0.865, 16032/28000 datapoints
2025-03-06 20:42:54,884 - INFO - training batch 551, loss: 1.050, 17632/28000 datapoints
2025-03-06 20:42:55,014 - INFO - training batch 601, loss: 1.226, 19232/28000 datapoints
2025-03-06 20:42:55,142 - INFO - training batch 651, loss: 0.619, 20832/28000 datapoints
2025-03-06 20:42:55,272 - INFO - training batch 701, loss: 0.828, 22432/28000 datapoints
2025-03-06 20:42:55,401 - INFO - training batch 751, loss: 0.909, 24032/28000 datapoints
2025-03-06 20:42:55,524 - INFO - training batch 801, loss: 0.778, 25632/28000 datapoints
2025-03-06 20:42:55,650 - INFO - training batch 851, loss: 1.158, 27232/28000 datapoints
2025-03-06 20:42:55,713 - INFO - validation batch 1, loss: 0.672, 32/6976 datapoints
2025-03-06 20:42:55,762 - INFO - validation batch 51, loss: 1.589, 1632/6976 datapoints
2025-03-06 20:42:55,810 - INFO - validation batch 101, loss: 0.882, 3232/6976 datapoints
2025-03-06 20:42:55,856 - INFO - validation batch 151, loss: 1.195, 4832/6976 datapoints
2025-03-06 20:42:55,906 - INFO - validation batch 201, loss: 0.535, 6432/6976 datapoints
2025-03-06 20:42:55,922 - INFO - Epoch 124/800 done.
2025-03-06 20:42:55,922 - INFO - Final validation performance:
Loss: 0.975, top-1 acc: 0.671top-5 acc: 0.671
2025-03-06 20:42:55,923 - INFO - Beginning epoch 125/800
2025-03-06 20:42:55,927 - INFO - training batch 1, loss: 1.042, 32/28000 datapoints
2025-03-06 20:42:56,058 - INFO - training batch 51, loss: 1.104, 1632/28000 datapoints
2025-03-06 20:42:56,184 - INFO - training batch 101, loss: 0.644, 3232/28000 datapoints
2025-03-06 20:42:56,309 - INFO - training batch 151, loss: 1.370, 4832/28000 datapoints
2025-03-06 20:42:56,435 - INFO - training batch 201, loss: 0.913, 6432/28000 datapoints
2025-03-06 20:42:56,560 - INFO - training batch 251, loss: 0.799, 8032/28000 datapoints
2025-03-06 20:42:56,686 - INFO - training batch 301, loss: 1.047, 9632/28000 datapoints
2025-03-06 20:42:56,828 - INFO - training batch 351, loss: 0.876, 11232/28000 datapoints
2025-03-06 20:42:56,963 - INFO - training batch 401, loss: 1.045, 12832/28000 datapoints
2025-03-06 20:42:57,087 - INFO - training batch 451, loss: 0.980, 14432/28000 datapoints
2025-03-06 20:42:57,211 - INFO - training batch 501, loss: 0.852, 16032/28000 datapoints
2025-03-06 20:42:57,339 - INFO - training batch 551, loss: 1.038, 17632/28000 datapoints
2025-03-06 20:42:57,463 - INFO - training batch 601, loss: 1.218, 19232/28000 datapoints
2025-03-06 20:42:57,588 - INFO - training batch 651, loss: 0.608, 20832/28000 datapoints
2025-03-06 20:42:57,715 - INFO - training batch 701, loss: 0.820, 22432/28000 datapoints
2025-03-06 20:42:57,838 - INFO - training batch 751, loss: 0.891, 24032/28000 datapoints
2025-03-06 20:42:57,963 - INFO - training batch 801, loss: 0.768, 25632/28000 datapoints
2025-03-06 20:42:58,086 - INFO - training batch 851, loss: 1.157, 27232/28000 datapoints
2025-03-06 20:42:58,148 - INFO - validation batch 1, loss: 0.664, 32/6976 datapoints
2025-03-06 20:42:58,196 - INFO - validation batch 51, loss: 1.582, 1632/6976 datapoints
2025-03-06 20:42:58,242 - INFO - validation batch 101, loss: 0.867, 3232/6976 datapoints
2025-03-06 20:42:58,289 - INFO - validation batch 151, loss: 1.183, 4832/6976 datapoints
2025-03-06 20:42:58,338 - INFO - validation batch 201, loss: 0.528, 6432/6976 datapoints
2025-03-06 20:42:58,354 - INFO - Epoch 125/800 done.
2025-03-06 20:42:58,354 - INFO - Final validation performance:
Loss: 0.965, top-1 acc: 0.676top-5 acc: 0.676
2025-03-06 20:42:58,354 - INFO - Beginning epoch 126/800
2025-03-06 20:42:58,358 - INFO - training batch 1, loss: 1.033, 32/28000 datapoints
2025-03-06 20:42:58,489 - INFO - training batch 51, loss: 1.088, 1632/28000 datapoints
2025-03-06 20:42:58,615 - INFO - training batch 101, loss: 0.632, 3232/28000 datapoints
2025-03-06 20:42:58,742 - INFO - training batch 151, loss: 1.364, 4832/28000 datapoints
2025-03-06 20:42:58,865 - INFO - training batch 201, loss: 0.890, 6432/28000 datapoints
2025-03-06 20:42:58,992 - INFO - training batch 251, loss: 0.788, 8032/28000 datapoints
2025-03-06 20:42:59,122 - INFO - training batch 301, loss: 1.038, 9632/28000 datapoints
2025-03-06 20:42:59,245 - INFO - training batch 351, loss: 0.866, 11232/28000 datapoints
2025-03-06 20:42:59,374 - INFO - training batch 401, loss: 1.038, 12832/28000 datapoints
2025-03-06 20:42:59,512 - INFO - training batch 451, loss: 0.969, 14432/28000 datapoints
2025-03-06 20:42:59,645 - INFO - training batch 501, loss: 0.839, 16032/28000 datapoints
2025-03-06 20:42:59,771 - INFO - training batch 551, loss: 1.025, 17632/28000 datapoints
2025-03-06 20:42:59,894 - INFO - training batch 601, loss: 1.210, 19232/28000 datapoints
2025-03-06 20:43:00,031 - INFO - training batch 651, loss: 0.598, 20832/28000 datapoints
2025-03-06 20:43:00,157 - INFO - training batch 701, loss: 0.812, 22432/28000 datapoints
2025-03-06 20:43:00,282 - INFO - training batch 751, loss: 0.872, 24032/28000 datapoints
2025-03-06 20:43:00,409 - INFO - training batch 801, loss: 0.758, 25632/28000 datapoints
2025-03-06 20:43:00,545 - INFO - training batch 851, loss: 1.155, 27232/28000 datapoints
2025-03-06 20:43:00,614 - INFO - validation batch 1, loss: 0.657, 32/6976 datapoints
2025-03-06 20:43:00,677 - INFO - validation batch 51, loss: 1.578, 1632/6976 datapoints
2025-03-06 20:43:00,736 - INFO - validation batch 101, loss: 0.850, 3232/6976 datapoints
2025-03-06 20:43:00,800 - INFO - validation batch 151, loss: 1.174, 4832/6976 datapoints
2025-03-06 20:43:00,855 - INFO - validation batch 201, loss: 0.521, 6432/6976 datapoints
2025-03-06 20:43:00,877 - INFO - Epoch 126/800 done.
2025-03-06 20:43:00,877 - INFO - Final validation performance:
Loss: 0.956, top-1 acc: 0.680top-5 acc: 0.680
2025-03-06 20:43:00,878 - INFO - Beginning epoch 127/800
2025-03-06 20:43:00,883 - INFO - training batch 1, loss: 1.024, 32/28000 datapoints
2025-03-06 20:43:01,027 - INFO - training batch 51, loss: 1.072, 1632/28000 datapoints
2025-03-06 20:43:01,158 - INFO - training batch 101, loss: 0.621, 3232/28000 datapoints
2025-03-06 20:43:01,305 - INFO - training batch 151, loss: 1.358, 4832/28000 datapoints
2025-03-06 20:43:01,435 - INFO - training batch 201, loss: 0.869, 6432/28000 datapoints
2025-03-06 20:43:01,556 - INFO - training batch 251, loss: 0.778, 8032/28000 datapoints
2025-03-06 20:43:01,680 - INFO - training batch 301, loss: 1.030, 9632/28000 datapoints
2025-03-06 20:43:01,801 - INFO - training batch 351, loss: 0.856, 11232/28000 datapoints
2025-03-06 20:43:01,925 - INFO - training batch 401, loss: 1.033, 12832/28000 datapoints
2025-03-06 20:43:02,044 - INFO - training batch 451, loss: 0.959, 14432/28000 datapoints
2025-03-06 20:43:02,166 - INFO - training batch 501, loss: 0.825, 16032/28000 datapoints
2025-03-06 20:43:02,291 - INFO - training batch 551, loss: 1.013, 17632/28000 datapoints
2025-03-06 20:43:02,410 - INFO - training batch 601, loss: 1.202, 19232/28000 datapoints
2025-03-06 20:43:02,530 - INFO - training batch 651, loss: 0.589, 20832/28000 datapoints
2025-03-06 20:43:02,651 - INFO - training batch 701, loss: 0.805, 22432/28000 datapoints
2025-03-06 20:43:02,771 - INFO - training batch 751, loss: 0.854, 24032/28000 datapoints
2025-03-06 20:43:02,891 - INFO - training batch 801, loss: 0.748, 25632/28000 datapoints
2025-03-06 20:43:03,012 - INFO - training batch 851, loss: 1.153, 27232/28000 datapoints
2025-03-06 20:43:03,071 - INFO - validation batch 1, loss: 0.649, 32/6976 datapoints
2025-03-06 20:43:03,114 - INFO - validation batch 51, loss: 1.571, 1632/6976 datapoints
2025-03-06 20:43:03,157 - INFO - validation batch 101, loss: 0.835, 3232/6976 datapoints
2025-03-06 20:43:03,202 - INFO - validation batch 151, loss: 1.162, 4832/6976 datapoints
2025-03-06 20:43:03,246 - INFO - validation batch 201, loss: 0.515, 6432/6976 datapoints
2025-03-06 20:43:03,262 - INFO - Epoch 127/800 done.
2025-03-06 20:43:03,262 - INFO - Final validation performance:
Loss: 0.947, top-1 acc: 0.685top-5 acc: 0.685
2025-03-06 20:43:03,262 - INFO - Beginning epoch 128/800
2025-03-06 20:43:03,266 - INFO - training batch 1, loss: 1.016, 32/28000 datapoints
2025-03-06 20:43:03,393 - INFO - training batch 51, loss: 1.056, 1632/28000 datapoints
2025-03-06 20:43:03,517 - INFO - training batch 101, loss: 0.611, 3232/28000 datapoints
2025-03-06 20:43:03,639 - INFO - training batch 151, loss: 1.352, 4832/28000 datapoints
2025-03-06 20:43:03,761 - INFO - training batch 201, loss: 0.847, 6432/28000 datapoints
2025-03-06 20:43:03,879 - INFO - training batch 251, loss: 0.768, 8032/28000 datapoints
2025-03-06 20:43:04,000 - INFO - training batch 301, loss: 1.021, 9632/28000 datapoints
2025-03-06 20:43:04,117 - INFO - training batch 351, loss: 0.845, 11232/28000 datapoints
2025-03-06 20:43:04,239 - INFO - training batch 401, loss: 1.028, 12832/28000 datapoints
2025-03-06 20:43:04,359 - INFO - training batch 451, loss: 0.949, 14432/28000 datapoints
2025-03-06 20:43:04,481 - INFO - training batch 501, loss: 0.812, 16032/28000 datapoints
2025-03-06 20:43:04,607 - INFO - training batch 551, loss: 1.000, 17632/28000 datapoints
2025-03-06 20:43:04,737 - INFO - training batch 601, loss: 1.193, 19232/28000 datapoints
2025-03-06 20:43:04,865 - INFO - training batch 651, loss: 0.580, 20832/28000 datapoints
2025-03-06 20:43:04,993 - INFO - training batch 701, loss: 0.797, 22432/28000 datapoints
2025-03-06 20:43:05,117 - INFO - training batch 751, loss: 0.837, 24032/28000 datapoints
2025-03-06 20:43:05,240 - INFO - training batch 801, loss: 0.738, 25632/28000 datapoints
2025-03-06 20:43:05,368 - INFO - training batch 851, loss: 1.152, 27232/28000 datapoints
2025-03-06 20:43:05,432 - INFO - validation batch 1, loss: 0.642, 32/6976 datapoints
2025-03-06 20:43:05,483 - INFO - validation batch 51, loss: 1.566, 1632/6976 datapoints
2025-03-06 20:43:05,529 - INFO - validation batch 101, loss: 0.820, 3232/6976 datapoints
2025-03-06 20:43:05,573 - INFO - validation batch 151, loss: 1.153, 4832/6976 datapoints
2025-03-06 20:43:05,621 - INFO - validation batch 201, loss: 0.509, 6432/6976 datapoints
2025-03-06 20:43:05,642 - INFO - Epoch 128/800 done.
2025-03-06 20:43:05,642 - INFO - Final validation performance:
Loss: 0.938, top-1 acc: 0.689top-5 acc: 0.689
2025-03-06 20:43:05,643 - INFO - Beginning epoch 129/800
2025-03-06 20:43:05,647 - INFO - training batch 1, loss: 1.007, 32/28000 datapoints
2025-03-06 20:43:05,774 - INFO - training batch 51, loss: 1.040, 1632/28000 datapoints
2025-03-06 20:43:05,893 - INFO - training batch 101, loss: 0.601, 3232/28000 datapoints
2025-03-06 20:43:06,019 - INFO - training batch 151, loss: 1.347, 4832/28000 datapoints
2025-03-06 20:43:06,138 - INFO - training batch 201, loss: 0.826, 6432/28000 datapoints
2025-03-06 20:43:06,259 - INFO - training batch 251, loss: 0.758, 8032/28000 datapoints
2025-03-06 20:43:06,379 - INFO - training batch 301, loss: 1.013, 9632/28000 datapoints
2025-03-06 20:43:06,501 - INFO - training batch 351, loss: 0.834, 11232/28000 datapoints
2025-03-06 20:43:06,620 - INFO - training batch 401, loss: 1.023, 12832/28000 datapoints
2025-03-06 20:43:06,741 - INFO - training batch 451, loss: 0.939, 14432/28000 datapoints
2025-03-06 20:43:06,862 - INFO - training batch 501, loss: 0.800, 16032/28000 datapoints
2025-03-06 20:43:07,014 - INFO - training batch 551, loss: 0.989, 17632/28000 datapoints
2025-03-06 20:43:07,136 - INFO - training batch 601, loss: 1.184, 19232/28000 datapoints
2025-03-06 20:43:07,259 - INFO - training batch 651, loss: 0.572, 20832/28000 datapoints
2025-03-06 20:43:07,384 - INFO - training batch 701, loss: 0.789, 22432/28000 datapoints
2025-03-06 20:43:07,504 - INFO - training batch 751, loss: 0.819, 24032/28000 datapoints
2025-03-06 20:43:07,623 - INFO - training batch 801, loss: 0.729, 25632/28000 datapoints
2025-03-06 20:43:07,748 - INFO - training batch 851, loss: 1.150, 27232/28000 datapoints
2025-03-06 20:43:07,808 - INFO - validation batch 1, loss: 0.635, 32/6976 datapoints
2025-03-06 20:43:07,853 - INFO - validation batch 51, loss: 1.558, 1632/6976 datapoints
2025-03-06 20:43:07,897 - INFO - validation batch 101, loss: 0.804, 3232/6976 datapoints
2025-03-06 20:43:07,941 - INFO - validation batch 151, loss: 1.142, 4832/6976 datapoints
2025-03-06 20:43:07,984 - INFO - validation batch 201, loss: 0.502, 6432/6976 datapoints
2025-03-06 20:43:08,000 - INFO - Epoch 129/800 done.
2025-03-06 20:43:08,001 - INFO - Final validation performance:
Loss: 0.928, top-1 acc: 0.693top-5 acc: 0.693
2025-03-06 20:43:08,001 - INFO - Beginning epoch 130/800
2025-03-06 20:43:08,005 - INFO - training batch 1, loss: 0.999, 32/28000 datapoints
2025-03-06 20:43:08,128 - INFO - training batch 51, loss: 1.024, 1632/28000 datapoints
2025-03-06 20:43:08,249 - INFO - training batch 101, loss: 0.590, 3232/28000 datapoints
2025-03-06 20:43:08,370 - INFO - training batch 151, loss: 1.341, 4832/28000 datapoints
2025-03-06 20:43:08,491 - INFO - training batch 201, loss: 0.807, 6432/28000 datapoints
2025-03-06 20:43:08,614 - INFO - training batch 251, loss: 0.747, 8032/28000 datapoints
2025-03-06 20:43:08,737 - INFO - training batch 301, loss: 1.005, 9632/28000 datapoints
2025-03-06 20:43:08,856 - INFO - training batch 351, loss: 0.824, 11232/28000 datapoints
2025-03-06 20:43:08,975 - INFO - training batch 401, loss: 1.019, 12832/28000 datapoints
2025-03-06 20:43:09,104 - INFO - training batch 451, loss: 0.929, 14432/28000 datapoints
2025-03-06 20:43:09,224 - INFO - training batch 501, loss: 0.787, 16032/28000 datapoints
2025-03-06 20:43:09,346 - INFO - training batch 551, loss: 0.978, 17632/28000 datapoints
2025-03-06 20:43:09,466 - INFO - training batch 601, loss: 1.173, 19232/28000 datapoints
2025-03-06 20:43:09,586 - INFO - training batch 651, loss: 0.564, 20832/28000 datapoints
2025-03-06 20:43:09,711 - INFO - training batch 701, loss: 0.782, 22432/28000 datapoints
2025-03-06 20:43:09,831 - INFO - training batch 751, loss: 0.802, 24032/28000 datapoints
2025-03-06 20:43:09,951 - INFO - training batch 801, loss: 0.719, 25632/28000 datapoints
2025-03-06 20:43:10,073 - INFO - training batch 851, loss: 1.149, 27232/28000 datapoints
2025-03-06 20:43:10,132 - INFO - validation batch 1, loss: 0.628, 32/6976 datapoints
2025-03-06 20:43:10,175 - INFO - validation batch 51, loss: 1.551, 1632/6976 datapoints
2025-03-06 20:43:10,219 - INFO - validation batch 101, loss: 0.790, 3232/6976 datapoints
2025-03-06 20:43:10,262 - INFO - validation batch 151, loss: 1.133, 4832/6976 datapoints
2025-03-06 20:43:10,305 - INFO - validation batch 201, loss: 0.496, 6432/6976 datapoints
2025-03-06 20:43:10,320 - INFO - Epoch 130/800 done.
2025-03-06 20:43:10,320 - INFO - Final validation performance:
Loss: 0.919, top-1 acc: 0.696top-5 acc: 0.696
2025-03-06 20:43:10,321 - INFO - Beginning epoch 131/800
2025-03-06 20:43:10,324 - INFO - training batch 1, loss: 0.991, 32/28000 datapoints
2025-03-06 20:43:10,446 - INFO - training batch 51, loss: 1.009, 1632/28000 datapoints
2025-03-06 20:43:10,567 - INFO - training batch 101, loss: 0.579, 3232/28000 datapoints
2025-03-06 20:43:10,690 - INFO - training batch 151, loss: 1.337, 4832/28000 datapoints
2025-03-06 20:43:10,811 - INFO - training batch 201, loss: 0.788, 6432/28000 datapoints
2025-03-06 20:43:10,932 - INFO - training batch 251, loss: 0.737, 8032/28000 datapoints
2025-03-06 20:43:11,054 - INFO - training batch 301, loss: 0.997, 9632/28000 datapoints
2025-03-06 20:43:11,173 - INFO - training batch 351, loss: 0.814, 11232/28000 datapoints
2025-03-06 20:43:11,295 - INFO - training batch 401, loss: 1.014, 12832/28000 datapoints
2025-03-06 20:43:11,421 - INFO - training batch 451, loss: 0.919, 14432/28000 datapoints
2025-03-06 20:43:11,543 - INFO - training batch 501, loss: 0.775, 16032/28000 datapoints
2025-03-06 20:43:11,666 - INFO - training batch 551, loss: 0.966, 17632/28000 datapoints
2025-03-06 20:43:11,798 - INFO - training batch 601, loss: 1.162, 19232/28000 datapoints
2025-03-06 20:43:11,921 - INFO - training batch 651, loss: 0.556, 20832/28000 datapoints
2025-03-06 20:43:12,039 - INFO - training batch 701, loss: 0.775, 22432/28000 datapoints
2025-03-06 20:43:12,160 - INFO - training batch 751, loss: 0.786, 24032/28000 datapoints
2025-03-06 20:43:12,287 - INFO - training batch 801, loss: 0.710, 25632/28000 datapoints
2025-03-06 20:43:12,409 - INFO - training batch 851, loss: 1.147, 27232/28000 datapoints
2025-03-06 20:43:12,471 - INFO - validation batch 1, loss: 0.621, 32/6976 datapoints
2025-03-06 20:43:12,516 - INFO - validation batch 51, loss: 1.543, 1632/6976 datapoints
2025-03-06 20:43:12,561 - INFO - validation batch 101, loss: 0.776, 3232/6976 datapoints
2025-03-06 20:43:12,604 - INFO - validation batch 151, loss: 1.122, 4832/6976 datapoints
2025-03-06 20:43:12,655 - INFO - validation batch 201, loss: 0.491, 6432/6976 datapoints
2025-03-06 20:43:12,670 - INFO - Epoch 131/800 done.
2025-03-06 20:43:12,670 - INFO - Final validation performance:
Loss: 0.911, top-1 acc: 0.700top-5 acc: 0.700
2025-03-06 20:43:12,671 - INFO - Beginning epoch 132/800
2025-03-06 20:43:12,674 - INFO - training batch 1, loss: 0.984, 32/28000 datapoints
2025-03-06 20:43:12,798 - INFO - training batch 51, loss: 0.993, 1632/28000 datapoints
2025-03-06 20:43:12,918 - INFO - training batch 101, loss: 0.569, 3232/28000 datapoints
2025-03-06 20:43:13,038 - INFO - training batch 151, loss: 1.331, 4832/28000 datapoints
2025-03-06 20:43:13,161 - INFO - training batch 201, loss: 0.770, 6432/28000 datapoints
2025-03-06 20:43:13,280 - INFO - training batch 251, loss: 0.728, 8032/28000 datapoints
2025-03-06 20:43:13,402 - INFO - training batch 301, loss: 0.989, 9632/28000 datapoints
2025-03-06 20:43:13,522 - INFO - training batch 351, loss: 0.804, 11232/28000 datapoints
2025-03-06 20:43:13,647 - INFO - training batch 401, loss: 1.010, 12832/28000 datapoints
2025-03-06 20:43:13,766 - INFO - training batch 451, loss: 0.910, 14432/28000 datapoints
2025-03-06 20:43:13,886 - INFO - training batch 501, loss: 0.762, 16032/28000 datapoints
2025-03-06 20:43:14,005 - INFO - training batch 551, loss: 0.955, 17632/28000 datapoints
2025-03-06 20:43:14,126 - INFO - training batch 601, loss: 1.152, 19232/28000 datapoints
2025-03-06 20:43:14,245 - INFO - training batch 651, loss: 0.547, 20832/28000 datapoints
2025-03-06 20:43:14,364 - INFO - training batch 701, loss: 0.768, 22432/28000 datapoints
2025-03-06 20:43:14,481 - INFO - training batch 751, loss: 0.769, 24032/28000 datapoints
2025-03-06 20:43:14,601 - INFO - training batch 801, loss: 0.700, 25632/28000 datapoints
2025-03-06 20:43:14,722 - INFO - training batch 851, loss: 1.145, 27232/28000 datapoints
2025-03-06 20:43:14,782 - INFO - validation batch 1, loss: 0.614, 32/6976 datapoints
2025-03-06 20:43:14,826 - INFO - validation batch 51, loss: 1.536, 1632/6976 datapoints
2025-03-06 20:43:14,869 - INFO - validation batch 101, loss: 0.761, 3232/6976 datapoints
2025-03-06 20:43:14,916 - INFO - validation batch 151, loss: 1.112, 4832/6976 datapoints
2025-03-06 20:43:14,963 - INFO - validation batch 201, loss: 0.486, 6432/6976 datapoints
2025-03-06 20:43:14,978 - INFO - Epoch 132/800 done.
2025-03-06 20:43:14,978 - INFO - Final validation performance:
Loss: 0.902, top-1 acc: 0.706top-5 acc: 0.706
2025-03-06 20:43:14,979 - INFO - Beginning epoch 133/800
2025-03-06 20:43:14,983 - INFO - training batch 1, loss: 0.977, 32/28000 datapoints
2025-03-06 20:43:15,106 - INFO - training batch 51, loss: 0.978, 1632/28000 datapoints
2025-03-06 20:43:15,225 - INFO - training batch 101, loss: 0.559, 3232/28000 datapoints
2025-03-06 20:43:15,347 - INFO - training batch 151, loss: 1.325, 4832/28000 datapoints
2025-03-06 20:43:15,466 - INFO - training batch 201, loss: 0.754, 6432/28000 datapoints
2025-03-06 20:43:15,592 - INFO - training batch 251, loss: 0.718, 8032/28000 datapoints
2025-03-06 20:43:15,714 - INFO - training batch 301, loss: 0.982, 9632/28000 datapoints
2025-03-06 20:43:15,833 - INFO - training batch 351, loss: 0.792, 11232/28000 datapoints
2025-03-06 20:43:15,953 - INFO - training batch 401, loss: 1.005, 12832/28000 datapoints
2025-03-06 20:43:16,075 - INFO - training batch 451, loss: 0.900, 14432/28000 datapoints
2025-03-06 20:43:16,195 - INFO - training batch 501, loss: 0.749, 16032/28000 datapoints
2025-03-06 20:43:16,317 - INFO - training batch 551, loss: 0.943, 17632/28000 datapoints
2025-03-06 20:43:16,437 - INFO - training batch 601, loss: 1.141, 19232/28000 datapoints
2025-03-06 20:43:16,555 - INFO - training batch 651, loss: 0.539, 20832/28000 datapoints
2025-03-06 20:43:16,678 - INFO - training batch 701, loss: 0.762, 22432/28000 datapoints
2025-03-06 20:43:16,797 - INFO - training batch 751, loss: 0.751, 24032/28000 datapoints
2025-03-06 20:43:16,916 - INFO - training batch 801, loss: 0.691, 25632/28000 datapoints
2025-03-06 20:43:17,057 - INFO - training batch 851, loss: 1.142, 27232/28000 datapoints
2025-03-06 20:43:17,123 - INFO - validation batch 1, loss: 0.607, 32/6976 datapoints
2025-03-06 20:43:17,166 - INFO - validation batch 51, loss: 1.527, 1632/6976 datapoints
2025-03-06 20:43:17,210 - INFO - validation batch 101, loss: 0.747, 3232/6976 datapoints
2025-03-06 20:43:17,255 - INFO - validation batch 151, loss: 1.101, 4832/6976 datapoints
2025-03-06 20:43:17,298 - INFO - validation batch 201, loss: 0.480, 6432/6976 datapoints
2025-03-06 20:43:17,313 - INFO - Epoch 133/800 done.
2025-03-06 20:43:17,313 - INFO - Final validation performance:
Loss: 0.892, top-1 acc: 0.710top-5 acc: 0.710
2025-03-06 20:43:17,314 - INFO - Beginning epoch 134/800
2025-03-06 20:43:17,318 - INFO - training batch 1, loss: 0.970, 32/28000 datapoints
2025-03-06 20:43:17,444 - INFO - training batch 51, loss: 0.964, 1632/28000 datapoints
2025-03-06 20:43:17,562 - INFO - training batch 101, loss: 0.549, 3232/28000 datapoints
2025-03-06 20:43:17,687 - INFO - training batch 151, loss: 1.318, 4832/28000 datapoints
2025-03-06 20:43:17,818 - INFO - training batch 201, loss: 0.738, 6432/28000 datapoints
2025-03-06 20:43:17,938 - INFO - training batch 251, loss: 0.708, 8032/28000 datapoints
2025-03-06 20:43:18,056 - INFO - training batch 301, loss: 0.975, 9632/28000 datapoints
2025-03-06 20:43:18,176 - INFO - training batch 351, loss: 0.780, 11232/28000 datapoints
2025-03-06 20:43:18,303 - INFO - training batch 401, loss: 1.000, 12832/28000 datapoints
2025-03-06 20:43:18,426 - INFO - training batch 451, loss: 0.891, 14432/28000 datapoints
2025-03-06 20:43:18,547 - INFO - training batch 501, loss: 0.738, 16032/28000 datapoints
2025-03-06 20:43:18,673 - INFO - training batch 551, loss: 0.932, 17632/28000 datapoints
2025-03-06 20:43:18,793 - INFO - training batch 601, loss: 1.130, 19232/28000 datapoints
2025-03-06 20:43:18,913 - INFO - training batch 651, loss: 0.531, 20832/28000 datapoints
2025-03-06 20:43:19,032 - INFO - training batch 701, loss: 0.755, 22432/28000 datapoints
2025-03-06 20:43:19,157 - INFO - training batch 751, loss: 0.734, 24032/28000 datapoints
2025-03-06 20:43:19,275 - INFO - training batch 801, loss: 0.683, 25632/28000 datapoints
2025-03-06 20:43:19,399 - INFO - training batch 851, loss: 1.139, 27232/28000 datapoints
2025-03-06 20:43:19,459 - INFO - validation batch 1, loss: 0.600, 32/6976 datapoints
2025-03-06 20:43:19,502 - INFO - validation batch 51, loss: 1.521, 1632/6976 datapoints
2025-03-06 20:43:19,544 - INFO - validation batch 101, loss: 0.732, 3232/6976 datapoints
2025-03-06 20:43:19,587 - INFO - validation batch 151, loss: 1.092, 4832/6976 datapoints
2025-03-06 20:43:19,630 - INFO - validation batch 201, loss: 0.475, 6432/6976 datapoints
2025-03-06 20:43:19,650 - INFO - Epoch 134/800 done.
2025-03-06 20:43:19,651 - INFO - Final validation performance:
Loss: 0.884, top-1 acc: 0.714top-5 acc: 0.714
2025-03-06 20:43:19,651 - INFO - Beginning epoch 135/800
2025-03-06 20:43:19,655 - INFO - training batch 1, loss: 0.963, 32/28000 datapoints
2025-03-06 20:43:19,774 - INFO - training batch 51, loss: 0.949, 1632/28000 datapoints
2025-03-06 20:43:19,895 - INFO - training batch 101, loss: 0.539, 3232/28000 datapoints
2025-03-06 20:43:20,014 - INFO - training batch 151, loss: 1.311, 4832/28000 datapoints
2025-03-06 20:43:20,138 - INFO - training batch 201, loss: 0.722, 6432/28000 datapoints
2025-03-06 20:43:20,260 - INFO - training batch 251, loss: 0.699, 8032/28000 datapoints
2025-03-06 20:43:20,378 - INFO - training batch 301, loss: 0.968, 9632/28000 datapoints
2025-03-06 20:43:20,498 - INFO - training batch 351, loss: 0.769, 11232/28000 datapoints
2025-03-06 20:43:20,617 - INFO - training batch 401, loss: 0.996, 12832/28000 datapoints
2025-03-06 20:43:20,746 - INFO - training batch 451, loss: 0.882, 14432/28000 datapoints
2025-03-06 20:43:20,865 - INFO - training batch 501, loss: 0.726, 16032/28000 datapoints
2025-03-06 20:43:20,987 - INFO - training batch 551, loss: 0.921, 17632/28000 datapoints
2025-03-06 20:43:21,107 - INFO - training batch 601, loss: 1.118, 19232/28000 datapoints
2025-03-06 20:43:21,228 - INFO - training batch 651, loss: 0.522, 20832/28000 datapoints
2025-03-06 20:43:21,347 - INFO - training batch 701, loss: 0.749, 22432/28000 datapoints
2025-03-06 20:43:21,471 - INFO - training batch 751, loss: 0.717, 24032/28000 datapoints
2025-03-06 20:43:21,590 - INFO - training batch 801, loss: 0.675, 25632/28000 datapoints
2025-03-06 20:43:21,714 - INFO - training batch 851, loss: 1.135, 27232/28000 datapoints
2025-03-06 20:43:21,773 - INFO - validation batch 1, loss: 0.593, 32/6976 datapoints
2025-03-06 20:43:21,819 - INFO - validation batch 51, loss: 1.514, 1632/6976 datapoints
2025-03-06 20:43:21,869 - INFO - validation batch 101, loss: 0.718, 3232/6976 datapoints
2025-03-06 20:43:21,915 - INFO - validation batch 151, loss: 1.083, 4832/6976 datapoints
2025-03-06 20:43:21,960 - INFO - validation batch 201, loss: 0.471, 6432/6976 datapoints
2025-03-06 20:43:21,976 - INFO - Epoch 135/800 done.
2025-03-06 20:43:21,976 - INFO - Final validation performance:
Loss: 0.876, top-1 acc: 0.718top-5 acc: 0.718
2025-03-06 20:43:21,977 - INFO - Beginning epoch 136/800
2025-03-06 20:43:21,980 - INFO - training batch 1, loss: 0.957, 32/28000 datapoints
2025-03-06 20:43:22,107 - INFO - training batch 51, loss: 0.934, 1632/28000 datapoints
2025-03-06 20:43:22,228 - INFO - training batch 101, loss: 0.530, 3232/28000 datapoints
2025-03-06 20:43:22,350 - INFO - training batch 151, loss: 1.304, 4832/28000 datapoints
2025-03-06 20:43:22,469 - INFO - training batch 201, loss: 0.708, 6432/28000 datapoints
2025-03-06 20:43:22,588 - INFO - training batch 251, loss: 0.689, 8032/28000 datapoints
2025-03-06 20:43:22,711 - INFO - training batch 301, loss: 0.961, 9632/28000 datapoints
2025-03-06 20:43:22,833 - INFO - training batch 351, loss: 0.758, 11232/28000 datapoints
2025-03-06 20:43:22,951 - INFO - training batch 401, loss: 0.991, 12832/28000 datapoints
2025-03-06 20:43:23,069 - INFO - training batch 451, loss: 0.873, 14432/28000 datapoints
2025-03-06 20:43:23,201 - INFO - training batch 501, loss: 0.715, 16032/28000 datapoints
2025-03-06 20:43:23,337 - INFO - training batch 551, loss: 0.910, 17632/28000 datapoints
2025-03-06 20:43:23,465 - INFO - training batch 601, loss: 1.107, 19232/28000 datapoints
2025-03-06 20:43:23,586 - INFO - training batch 651, loss: 0.515, 20832/28000 datapoints
2025-03-06 20:43:23,709 - INFO - training batch 701, loss: 0.743, 22432/28000 datapoints
2025-03-06 20:43:23,827 - INFO - training batch 751, loss: 0.700, 24032/28000 datapoints
2025-03-06 20:43:23,961 - INFO - training batch 801, loss: 0.666, 25632/28000 datapoints
2025-03-06 20:43:24,081 - INFO - training batch 851, loss: 1.131, 27232/28000 datapoints
2025-03-06 20:43:24,139 - INFO - validation batch 1, loss: 0.586, 32/6976 datapoints
2025-03-06 20:43:24,182 - INFO - validation batch 51, loss: 1.509, 1632/6976 datapoints
2025-03-06 20:43:24,227 - INFO - validation batch 101, loss: 0.703, 3232/6976 datapoints
2025-03-06 20:43:24,270 - INFO - validation batch 151, loss: 1.075, 4832/6976 datapoints
2025-03-06 20:43:24,322 - INFO - validation batch 201, loss: 0.467, 6432/6976 datapoints
2025-03-06 20:43:24,338 - INFO - Epoch 136/800 done.
2025-03-06 20:43:24,339 - INFO - Final validation performance:
Loss: 0.868, top-1 acc: 0.721top-5 acc: 0.721
2025-03-06 20:43:24,339 - INFO - Beginning epoch 137/800
2025-03-06 20:43:24,343 - INFO - training batch 1, loss: 0.950, 32/28000 datapoints
2025-03-06 20:43:24,465 - INFO - training batch 51, loss: 0.919, 1632/28000 datapoints
2025-03-06 20:43:24,597 - INFO - training batch 101, loss: 0.521, 3232/28000 datapoints
2025-03-06 20:43:24,729 - INFO - training batch 151, loss: 1.296, 4832/28000 datapoints
2025-03-06 20:43:24,854 - INFO - training batch 201, loss: 0.694, 6432/28000 datapoints
2025-03-06 20:43:24,987 - INFO - training batch 251, loss: 0.680, 8032/28000 datapoints
2025-03-06 20:43:25,112 - INFO - training batch 301, loss: 0.955, 9632/28000 datapoints
2025-03-06 20:43:25,237 - INFO - training batch 351, loss: 0.748, 11232/28000 datapoints
2025-03-06 20:43:25,359 - INFO - training batch 401, loss: 0.987, 12832/28000 datapoints
2025-03-06 20:43:25,486 - INFO - training batch 451, loss: 0.864, 14432/28000 datapoints
2025-03-06 20:43:25,609 - INFO - training batch 501, loss: 0.704, 16032/28000 datapoints
2025-03-06 20:43:25,739 - INFO - training batch 551, loss: 0.899, 17632/28000 datapoints
2025-03-06 20:43:25,862 - INFO - training batch 601, loss: 1.095, 19232/28000 datapoints
2025-03-06 20:43:25,984 - INFO - training batch 651, loss: 0.507, 20832/28000 datapoints
2025-03-06 20:43:26,108 - INFO - training batch 701, loss: 0.737, 22432/28000 datapoints
2025-03-06 20:43:26,232 - INFO - training batch 751, loss: 0.684, 24032/28000 datapoints
2025-03-06 20:43:26,356 - INFO - training batch 801, loss: 0.658, 25632/28000 datapoints
2025-03-06 20:43:26,480 - INFO - training batch 851, loss: 1.127, 27232/28000 datapoints
2025-03-06 20:43:26,542 - INFO - validation batch 1, loss: 0.579, 32/6976 datapoints
2025-03-06 20:43:26,591 - INFO - validation batch 51, loss: 1.501, 1632/6976 datapoints
2025-03-06 20:43:26,641 - INFO - validation batch 101, loss: 0.688, 3232/6976 datapoints
2025-03-06 20:43:26,690 - INFO - validation batch 151, loss: 1.064, 4832/6976 datapoints
2025-03-06 20:43:26,740 - INFO - validation batch 201, loss: 0.463, 6432/6976 datapoints
2025-03-06 20:43:26,755 - INFO - Epoch 137/800 done.
2025-03-06 20:43:26,756 - INFO - Final validation performance:
Loss: 0.859, top-1 acc: 0.726top-5 acc: 0.726
2025-03-06 20:43:26,756 - INFO - Beginning epoch 138/800
2025-03-06 20:43:26,760 - INFO - training batch 1, loss: 0.945, 32/28000 datapoints
2025-03-06 20:43:26,882 - INFO - training batch 51, loss: 0.905, 1632/28000 datapoints
2025-03-06 20:43:27,006 - INFO - training batch 101, loss: 0.513, 3232/28000 datapoints
2025-03-06 20:43:27,153 - INFO - training batch 151, loss: 1.290, 4832/28000 datapoints
2025-03-06 20:43:27,282 - INFO - training batch 201, loss: 0.682, 6432/28000 datapoints
2025-03-06 20:43:27,413 - INFO - training batch 251, loss: 0.672, 8032/28000 datapoints
2025-03-06 20:43:27,537 - INFO - training batch 301, loss: 0.948, 9632/28000 datapoints
2025-03-06 20:43:27,662 - INFO - training batch 351, loss: 0.738, 11232/28000 datapoints
2025-03-06 20:43:27,788 - INFO - training batch 401, loss: 0.984, 12832/28000 datapoints
2025-03-06 20:43:27,913 - INFO - training batch 451, loss: 0.855, 14432/28000 datapoints
2025-03-06 20:43:28,037 - INFO - training batch 501, loss: 0.693, 16032/28000 datapoints
2025-03-06 20:43:28,158 - INFO - training batch 551, loss: 0.889, 17632/28000 datapoints
2025-03-06 20:43:28,282 - INFO - training batch 601, loss: 1.085, 19232/28000 datapoints
2025-03-06 20:43:28,406 - INFO - training batch 651, loss: 0.499, 20832/28000 datapoints
2025-03-06 20:43:28,530 - INFO - training batch 701, loss: 0.731, 22432/28000 datapoints
2025-03-06 20:43:28,657 - INFO - training batch 751, loss: 0.667, 24032/28000 datapoints
2025-03-06 20:43:28,779 - INFO - training batch 801, loss: 0.650, 25632/28000 datapoints
2025-03-06 20:43:28,903 - INFO - training batch 851, loss: 1.124, 27232/28000 datapoints
2025-03-06 20:43:28,967 - INFO - validation batch 1, loss: 0.571, 32/6976 datapoints
2025-03-06 20:43:29,015 - INFO - validation batch 51, loss: 1.494, 1632/6976 datapoints
2025-03-06 20:43:29,064 - INFO - validation batch 101, loss: 0.674, 3232/6976 datapoints
2025-03-06 20:43:29,111 - INFO - validation batch 151, loss: 1.054, 4832/6976 datapoints
2025-03-06 20:43:29,162 - INFO - validation batch 201, loss: 0.460, 6432/6976 datapoints
2025-03-06 20:43:29,180 - INFO - Epoch 138/800 done.
2025-03-06 20:43:29,180 - INFO - Final validation performance:
Loss: 0.851, top-1 acc: 0.728top-5 acc: 0.728
2025-03-06 20:43:29,181 - INFO - Beginning epoch 139/800
2025-03-06 20:43:29,185 - INFO - training batch 1, loss: 0.938, 32/28000 datapoints
2025-03-06 20:43:29,307 - INFO - training batch 51, loss: 0.889, 1632/28000 datapoints
2025-03-06 20:43:29,432 - INFO - training batch 101, loss: 0.504, 3232/28000 datapoints
2025-03-06 20:43:29,550 - INFO - training batch 151, loss: 1.280, 4832/28000 datapoints
2025-03-06 20:43:29,678 - INFO - training batch 201, loss: 0.670, 6432/28000 datapoints
2025-03-06 20:43:29,824 - INFO - training batch 251, loss: 0.663, 8032/28000 datapoints
2025-03-06 20:43:29,976 - INFO - training batch 301, loss: 0.941, 9632/28000 datapoints
2025-03-06 20:43:30,120 - INFO - training batch 351, loss: 0.729, 11232/28000 datapoints
2025-03-06 20:43:30,238 - INFO - training batch 401, loss: 0.980, 12832/28000 datapoints
2025-03-06 20:43:30,366 - INFO - training batch 451, loss: 0.846, 14432/28000 datapoints
2025-03-06 20:43:30,488 - INFO - training batch 501, loss: 0.681, 16032/28000 datapoints
2025-03-06 20:43:30,609 - INFO - training batch 551, loss: 0.878, 17632/28000 datapoints
2025-03-06 20:43:30,742 - INFO - training batch 601, loss: 1.074, 19232/28000 datapoints
2025-03-06 20:43:30,863 - INFO - training batch 651, loss: 0.491, 20832/28000 datapoints
2025-03-06 20:43:30,982 - INFO - training batch 701, loss: 0.726, 22432/28000 datapoints
2025-03-06 20:43:31,103 - INFO - training batch 751, loss: 0.652, 24032/28000 datapoints
2025-03-06 20:43:31,220 - INFO - training batch 801, loss: 0.642, 25632/28000 datapoints
2025-03-06 20:43:31,340 - INFO - training batch 851, loss: 1.121, 27232/28000 datapoints
2025-03-06 20:43:31,400 - INFO - validation batch 1, loss: 0.563, 32/6976 datapoints
2025-03-06 20:43:31,448 - INFO - validation batch 51, loss: 1.487, 1632/6976 datapoints
2025-03-06 20:43:31,491 - INFO - validation batch 101, loss: 0.660, 3232/6976 datapoints
2025-03-06 20:43:31,534 - INFO - validation batch 151, loss: 1.045, 4832/6976 datapoints
2025-03-06 20:43:31,577 - INFO - validation batch 201, loss: 0.457, 6432/6976 datapoints
2025-03-06 20:43:31,592 - INFO - Epoch 139/800 done.
2025-03-06 20:43:31,593 - INFO - Final validation performance:
Loss: 0.842, top-1 acc: 0.731top-5 acc: 0.731
2025-03-06 20:43:31,593 - INFO - Beginning epoch 140/800
2025-03-06 20:43:31,597 - INFO - training batch 1, loss: 0.932, 32/28000 datapoints
2025-03-06 20:43:31,723 - INFO - training batch 51, loss: 0.872, 1632/28000 datapoints
2025-03-06 20:43:31,854 - INFO - training batch 101, loss: 0.495, 3232/28000 datapoints
2025-03-06 20:43:31,978 - INFO - training batch 151, loss: 1.271, 4832/28000 datapoints
2025-03-06 20:43:32,098 - INFO - training batch 201, loss: 0.659, 6432/28000 datapoints
2025-03-06 20:43:32,216 - INFO - training batch 251, loss: 0.655, 8032/28000 datapoints
2025-03-06 20:43:32,336 - INFO - training batch 301, loss: 0.934, 9632/28000 datapoints
2025-03-06 20:43:32,457 - INFO - training batch 351, loss: 0.720, 11232/28000 datapoints
2025-03-06 20:43:32,577 - INFO - training batch 401, loss: 0.976, 12832/28000 datapoints
2025-03-06 20:43:32,701 - INFO - training batch 451, loss: 0.837, 14432/28000 datapoints
2025-03-06 20:43:32,821 - INFO - training batch 501, loss: 0.671, 16032/28000 datapoints
2025-03-06 20:43:32,941 - INFO - training batch 551, loss: 0.868, 17632/28000 datapoints
2025-03-06 20:43:33,061 - INFO - training batch 601, loss: 1.061, 19232/28000 datapoints
2025-03-06 20:43:33,180 - INFO - training batch 651, loss: 0.483, 20832/28000 datapoints
2025-03-06 20:43:33,300 - INFO - training batch 701, loss: 0.720, 22432/28000 datapoints
2025-03-06 20:43:33,419 - INFO - training batch 751, loss: 0.638, 24032/28000 datapoints
2025-03-06 20:43:33,544 - INFO - training batch 801, loss: 0.634, 25632/28000 datapoints
2025-03-06 20:43:33,666 - INFO - training batch 851, loss: 1.117, 27232/28000 datapoints
2025-03-06 20:43:33,726 - INFO - validation batch 1, loss: 0.555, 32/6976 datapoints
2025-03-06 20:43:33,769 - INFO - validation batch 51, loss: 1.479, 1632/6976 datapoints
2025-03-06 20:43:33,815 - INFO - validation batch 101, loss: 0.646, 3232/6976 datapoints
2025-03-06 20:43:33,859 - INFO - validation batch 151, loss: 1.035, 4832/6976 datapoints
2025-03-06 20:43:33,902 - INFO - validation batch 201, loss: 0.451, 6432/6976 datapoints
2025-03-06 20:43:33,917 - INFO - Epoch 140/800 done.
2025-03-06 20:43:33,917 - INFO - Final validation performance:
Loss: 0.833, top-1 acc: 0.734top-5 acc: 0.734
2025-03-06 20:43:33,918 - INFO - Beginning epoch 141/800
2025-03-06 20:43:33,921 - INFO - training batch 1, loss: 0.926, 32/28000 datapoints
2025-03-06 20:43:34,043 - INFO - training batch 51, loss: 0.857, 1632/28000 datapoints
2025-03-06 20:43:34,161 - INFO - training batch 101, loss: 0.488, 3232/28000 datapoints
2025-03-06 20:43:34,280 - INFO - training batch 151, loss: 1.264, 4832/28000 datapoints
2025-03-06 20:43:34,401 - INFO - training batch 201, loss: 0.648, 6432/28000 datapoints
2025-03-06 20:43:34,522 - INFO - training batch 251, loss: 0.647, 8032/28000 datapoints
2025-03-06 20:43:34,645 - INFO - training batch 301, loss: 0.928, 9632/28000 datapoints
2025-03-06 20:43:34,764 - INFO - training batch 351, loss: 0.711, 11232/28000 datapoints
2025-03-06 20:43:34,894 - INFO - training batch 401, loss: 0.973, 12832/28000 datapoints
2025-03-06 20:43:35,016 - INFO - training batch 451, loss: 0.827, 14432/28000 datapoints
2025-03-06 20:43:35,136 - INFO - training batch 501, loss: 0.661, 16032/28000 datapoints
2025-03-06 20:43:35,256 - INFO - training batch 551, loss: 0.857, 17632/28000 datapoints
2025-03-06 20:43:35,378 - INFO - training batch 601, loss: 1.050, 19232/28000 datapoints
2025-03-06 20:43:35,501 - INFO - training batch 651, loss: 0.476, 20832/28000 datapoints
2025-03-06 20:43:35,621 - INFO - training batch 701, loss: 0.714, 22432/28000 datapoints
2025-03-06 20:43:35,742 - INFO - training batch 751, loss: 0.624, 24032/28000 datapoints
2025-03-06 20:43:35,862 - INFO - training batch 801, loss: 0.627, 25632/28000 datapoints
2025-03-06 20:43:35,983 - INFO - training batch 851, loss: 1.114, 27232/28000 datapoints
2025-03-06 20:43:36,046 - INFO - validation batch 1, loss: 0.548, 32/6976 datapoints
2025-03-06 20:43:36,100 - INFO - validation batch 51, loss: 1.472, 1632/6976 datapoints
2025-03-06 20:43:36,151 - INFO - validation batch 101, loss: 0.633, 3232/6976 datapoints
2025-03-06 20:43:36,193 - INFO - validation batch 151, loss: 1.026, 4832/6976 datapoints
2025-03-06 20:43:36,236 - INFO - validation batch 201, loss: 0.447, 6432/6976 datapoints
2025-03-06 20:43:36,251 - INFO - Epoch 141/800 done.
2025-03-06 20:43:36,251 - INFO - Final validation performance:
Loss: 0.825, top-1 acc: 0.737top-5 acc: 0.737
2025-03-06 20:43:36,252 - INFO - Beginning epoch 142/800
2025-03-06 20:43:36,255 - INFO - training batch 1, loss: 0.919, 32/28000 datapoints
2025-03-06 20:43:36,379 - INFO - training batch 51, loss: 0.840, 1632/28000 datapoints
2025-03-06 20:43:36,503 - INFO - training batch 101, loss: 0.479, 3232/28000 datapoints
2025-03-06 20:43:36,624 - INFO - training batch 151, loss: 1.256, 4832/28000 datapoints
2025-03-06 20:43:36,745 - INFO - training batch 201, loss: 0.638, 6432/28000 datapoints
2025-03-06 20:43:36,866 - INFO - training batch 251, loss: 0.640, 8032/28000 datapoints
2025-03-06 20:43:36,984 - INFO - training batch 301, loss: 0.921, 9632/28000 datapoints
2025-03-06 20:43:37,104 - INFO - training batch 351, loss: 0.703, 11232/28000 datapoints
2025-03-06 20:43:37,252 - INFO - training batch 401, loss: 0.970, 12832/28000 datapoints
2025-03-06 20:43:37,379 - INFO - training batch 451, loss: 0.816, 14432/28000 datapoints
2025-03-06 20:43:37,504 - INFO - training batch 501, loss: 0.650, 16032/28000 datapoints
2025-03-06 20:43:37,625 - INFO - training batch 551, loss: 0.846, 17632/28000 datapoints
2025-03-06 20:43:37,759 - INFO - training batch 601, loss: 1.039, 19232/28000 datapoints
2025-03-06 20:43:37,888 - INFO - training batch 651, loss: 0.469, 20832/28000 datapoints
2025-03-06 20:43:38,012 - INFO - training batch 701, loss: 0.708, 22432/28000 datapoints
2025-03-06 20:43:38,137 - INFO - training batch 751, loss: 0.610, 24032/28000 datapoints
2025-03-06 20:43:38,259 - INFO - training batch 801, loss: 0.620, 25632/28000 datapoints
2025-03-06 20:43:38,379 - INFO - training batch 851, loss: 1.111, 27232/28000 datapoints
2025-03-06 20:43:38,440 - INFO - validation batch 1, loss: 0.539, 32/6976 datapoints
2025-03-06 20:43:38,485 - INFO - validation batch 51, loss: 1.463, 1632/6976 datapoints
2025-03-06 20:43:38,530 - INFO - validation batch 101, loss: 0.619, 3232/6976 datapoints
2025-03-06 20:43:38,575 - INFO - validation batch 151, loss: 1.016, 4832/6976 datapoints
2025-03-06 20:43:38,620 - INFO - validation batch 201, loss: 0.443, 6432/6976 datapoints
2025-03-06 20:43:38,637 - INFO - Epoch 142/800 done.
2025-03-06 20:43:38,638 - INFO - Final validation performance:
Loss: 0.816, top-1 acc: 0.741top-5 acc: 0.741
2025-03-06 20:43:38,638 - INFO - Beginning epoch 143/800
2025-03-06 20:43:38,642 - INFO - training batch 1, loss: 0.914, 32/28000 datapoints
2025-03-06 20:43:38,762 - INFO - training batch 51, loss: 0.824, 1632/28000 datapoints
2025-03-06 20:43:38,883 - INFO - training batch 101, loss: 0.472, 3232/28000 datapoints
2025-03-06 20:43:39,006 - INFO - training batch 151, loss: 1.248, 4832/28000 datapoints
2025-03-06 20:43:39,130 - INFO - training batch 201, loss: 0.628, 6432/28000 datapoints
2025-03-06 20:43:39,254 - INFO - training batch 251, loss: 0.632, 8032/28000 datapoints
2025-03-06 20:43:39,374 - INFO - training batch 301, loss: 0.915, 9632/28000 datapoints
2025-03-06 20:43:39,500 - INFO - training batch 351, loss: 0.695, 11232/28000 datapoints
2025-03-06 20:43:39,620 - INFO - training batch 401, loss: 0.966, 12832/28000 datapoints
2025-03-06 20:43:39,742 - INFO - training batch 451, loss: 0.805, 14432/28000 datapoints
2025-03-06 20:43:39,864 - INFO - training batch 501, loss: 0.640, 16032/28000 datapoints
2025-03-06 20:43:39,984 - INFO - training batch 551, loss: 0.836, 17632/28000 datapoints
2025-03-06 20:43:40,113 - INFO - training batch 601, loss: 1.029, 19232/28000 datapoints
2025-03-06 20:43:40,233 - INFO - training batch 651, loss: 0.462, 20832/28000 datapoints
2025-03-06 20:43:40,351 - INFO - training batch 701, loss: 0.703, 22432/28000 datapoints
2025-03-06 20:43:40,469 - INFO - training batch 751, loss: 0.597, 24032/28000 datapoints
2025-03-06 20:43:40,589 - INFO - training batch 801, loss: 0.613, 25632/28000 datapoints
2025-03-06 20:43:40,711 - INFO - training batch 851, loss: 1.107, 27232/28000 datapoints
2025-03-06 20:43:40,770 - INFO - validation batch 1, loss: 0.531, 32/6976 datapoints
2025-03-06 20:43:40,815 - INFO - validation batch 51, loss: 1.456, 1632/6976 datapoints
2025-03-06 20:43:40,859 - INFO - validation batch 101, loss: 0.607, 3232/6976 datapoints
2025-03-06 20:43:40,904 - INFO - validation batch 151, loss: 1.006, 4832/6976 datapoints
2025-03-06 20:43:40,947 - INFO - validation batch 201, loss: 0.438, 6432/6976 datapoints
2025-03-06 20:43:40,963 - INFO - Epoch 143/800 done.
2025-03-06 20:43:40,963 - INFO - Final validation performance:
Loss: 0.808, top-1 acc: 0.743top-5 acc: 0.743
2025-03-06 20:43:40,963 - INFO - Beginning epoch 144/800
2025-03-06 20:43:40,967 - INFO - training batch 1, loss: 0.908, 32/28000 datapoints
2025-03-06 20:43:41,089 - INFO - training batch 51, loss: 0.808, 1632/28000 datapoints
2025-03-06 20:43:41,208 - INFO - training batch 101, loss: 0.465, 3232/28000 datapoints
2025-03-06 20:43:41,327 - INFO - training batch 151, loss: 1.241, 4832/28000 datapoints
2025-03-06 20:43:41,449 - INFO - training batch 201, loss: 0.618, 6432/28000 datapoints
2025-03-06 20:43:41,572 - INFO - training batch 251, loss: 0.625, 8032/28000 datapoints
2025-03-06 20:43:41,695 - INFO - training batch 301, loss: 0.908, 9632/28000 datapoints
2025-03-06 20:43:41,814 - INFO - training batch 351, loss: 0.688, 11232/28000 datapoints
2025-03-06 20:43:41,934 - INFO - training batch 401, loss: 0.963, 12832/28000 datapoints
2025-03-06 20:43:42,054 - INFO - training batch 451, loss: 0.795, 14432/28000 datapoints
2025-03-06 20:43:42,179 - INFO - training batch 501, loss: 0.630, 16032/28000 datapoints
2025-03-06 20:43:42,305 - INFO - training batch 551, loss: 0.826, 17632/28000 datapoints
2025-03-06 20:43:42,425 - INFO - training batch 601, loss: 1.018, 19232/28000 datapoints
2025-03-06 20:43:42,545 - INFO - training batch 651, loss: 0.456, 20832/28000 datapoints
2025-03-06 20:43:42,675 - INFO - training batch 701, loss: 0.698, 22432/28000 datapoints
2025-03-06 20:43:42,797 - INFO - training batch 751, loss: 0.584, 24032/28000 datapoints
2025-03-06 20:43:42,918 - INFO - training batch 801, loss: 0.606, 25632/28000 datapoints
2025-03-06 20:43:43,042 - INFO - training batch 851, loss: 1.104, 27232/28000 datapoints
2025-03-06 20:43:43,102 - INFO - validation batch 1, loss: 0.523, 32/6976 datapoints
2025-03-06 20:43:43,145 - INFO - validation batch 51, loss: 1.449, 1632/6976 datapoints
2025-03-06 20:43:43,189 - INFO - validation batch 101, loss: 0.596, 3232/6976 datapoints
2025-03-06 20:43:43,231 - INFO - validation batch 151, loss: 0.995, 4832/6976 datapoints
2025-03-06 20:43:43,275 - INFO - validation batch 201, loss: 0.434, 6432/6976 datapoints
2025-03-06 20:43:43,290 - INFO - Epoch 144/800 done.
2025-03-06 20:43:43,290 - INFO - Final validation performance:
Loss: 0.800, top-1 acc: 0.746top-5 acc: 0.746
2025-03-06 20:43:43,291 - INFO - Beginning epoch 145/800
2025-03-06 20:43:43,294 - INFO - training batch 1, loss: 0.903, 32/28000 datapoints
2025-03-06 20:43:43,414 - INFO - training batch 51, loss: 0.793, 1632/28000 datapoints
2025-03-06 20:43:43,541 - INFO - training batch 101, loss: 0.457, 3232/28000 datapoints
2025-03-06 20:43:43,665 - INFO - training batch 151, loss: 1.232, 4832/28000 datapoints
2025-03-06 20:43:43,785 - INFO - training batch 201, loss: 0.609, 6432/28000 datapoints
2025-03-06 20:43:43,905 - INFO - training batch 251, loss: 0.618, 8032/28000 datapoints
2025-03-06 20:43:44,025 - INFO - training batch 301, loss: 0.902, 9632/28000 datapoints
2025-03-06 20:43:44,143 - INFO - training batch 351, loss: 0.681, 11232/28000 datapoints
2025-03-06 20:43:44,261 - INFO - training batch 401, loss: 0.960, 12832/28000 datapoints
2025-03-06 20:43:44,380 - INFO - training batch 451, loss: 0.785, 14432/28000 datapoints
2025-03-06 20:43:44,502 - INFO - training batch 501, loss: 0.621, 16032/28000 datapoints
2025-03-06 20:43:44,624 - INFO - training batch 551, loss: 0.817, 17632/28000 datapoints
2025-03-06 20:43:44,755 - INFO - training batch 601, loss: 1.008, 19232/28000 datapoints
2025-03-06 20:43:44,880 - INFO - training batch 651, loss: 0.449, 20832/28000 datapoints
2025-03-06 20:43:45,012 - INFO - training batch 701, loss: 0.692, 22432/28000 datapoints
2025-03-06 20:43:45,136 - INFO - training batch 751, loss: 0.572, 24032/28000 datapoints
2025-03-06 20:43:45,260 - INFO - training batch 801, loss: 0.599, 25632/28000 datapoints
2025-03-06 20:43:45,384 - INFO - training batch 851, loss: 1.100, 27232/28000 datapoints
2025-03-06 20:43:45,446 - INFO - validation batch 1, loss: 0.516, 32/6976 datapoints
2025-03-06 20:43:45,498 - INFO - validation batch 51, loss: 1.444, 1632/6976 datapoints
2025-03-06 20:43:45,546 - INFO - validation batch 101, loss: 0.585, 3232/6976 datapoints
2025-03-06 20:43:45,593 - INFO - validation batch 151, loss: 0.985, 4832/6976 datapoints
2025-03-06 20:43:45,643 - INFO - validation batch 201, loss: 0.431, 6432/6976 datapoints
2025-03-06 20:43:45,658 - INFO - Epoch 145/800 done.
2025-03-06 20:43:45,658 - INFO - Final validation performance:
Loss: 0.792, top-1 acc: 0.750top-5 acc: 0.750
2025-03-06 20:43:45,658 - INFO - Beginning epoch 146/800
2025-03-06 20:43:45,662 - INFO - training batch 1, loss: 0.897, 32/28000 datapoints
2025-03-06 20:43:45,786 - INFO - training batch 51, loss: 0.778, 1632/28000 datapoints
2025-03-06 20:43:45,918 - INFO - training batch 101, loss: 0.450, 3232/28000 datapoints
2025-03-06 20:43:46,045 - INFO - training batch 151, loss: 1.224, 4832/28000 datapoints
2025-03-06 20:43:46,168 - INFO - training batch 201, loss: 0.600, 6432/28000 datapoints
2025-03-06 20:43:46,290 - INFO - training batch 251, loss: 0.611, 8032/28000 datapoints
2025-03-06 20:43:46,412 - INFO - training batch 301, loss: 0.896, 9632/28000 datapoints
2025-03-06 20:43:46,536 - INFO - training batch 351, loss: 0.673, 11232/28000 datapoints
2025-03-06 20:43:46,666 - INFO - training batch 401, loss: 0.956, 12832/28000 datapoints
2025-03-06 20:43:46,820 - INFO - training batch 451, loss: 0.774, 14432/28000 datapoints
2025-03-06 20:43:46,986 - INFO - training batch 501, loss: 0.612, 16032/28000 datapoints
2025-03-06 20:43:47,142 - INFO - training batch 551, loss: 0.808, 17632/28000 datapoints
2025-03-06 20:43:47,272 - INFO - training batch 601, loss: 0.998, 19232/28000 datapoints
2025-03-06 20:43:47,418 - INFO - training batch 651, loss: 0.442, 20832/28000 datapoints
2025-03-06 20:43:47,548 - INFO - training batch 701, loss: 0.687, 22432/28000 datapoints
2025-03-06 20:43:47,678 - INFO - training batch 751, loss: 0.561, 24032/28000 datapoints
2025-03-06 20:43:47,801 - INFO - training batch 801, loss: 0.592, 25632/28000 datapoints
2025-03-06 20:43:47,923 - INFO - training batch 851, loss: 1.097, 27232/28000 datapoints
2025-03-06 20:43:47,987 - INFO - validation batch 1, loss: 0.508, 32/6976 datapoints
2025-03-06 20:43:48,036 - INFO - validation batch 51, loss: 1.439, 1632/6976 datapoints
2025-03-06 20:43:48,083 - INFO - validation batch 101, loss: 0.574, 3232/6976 datapoints
2025-03-06 20:43:48,129 - INFO - validation batch 151, loss: 0.976, 4832/6976 datapoints
2025-03-06 20:43:48,175 - INFO - validation batch 201, loss: 0.428, 6432/6976 datapoints
2025-03-06 20:43:48,191 - INFO - Epoch 146/800 done.
2025-03-06 20:43:48,191 - INFO - Final validation performance:
Loss: 0.785, top-1 acc: 0.753top-5 acc: 0.753
2025-03-06 20:43:48,192 - INFO - Beginning epoch 147/800
2025-03-06 20:43:48,195 - INFO - training batch 1, loss: 0.892, 32/28000 datapoints
2025-03-06 20:43:48,335 - INFO - training batch 51, loss: 0.764, 1632/28000 datapoints
2025-03-06 20:43:48,455 - INFO - training batch 101, loss: 0.443, 3232/28000 datapoints
2025-03-06 20:43:48,579 - INFO - training batch 151, loss: 1.216, 4832/28000 datapoints
2025-03-06 20:43:48,706 - INFO - training batch 201, loss: 0.591, 6432/28000 datapoints
2025-03-06 20:43:48,830 - INFO - training batch 251, loss: 0.604, 8032/28000 datapoints
2025-03-06 20:43:48,958 - INFO - training batch 301, loss: 0.890, 9632/28000 datapoints
2025-03-06 20:43:49,082 - INFO - training batch 351, loss: 0.669, 11232/28000 datapoints
2025-03-06 20:43:49,205 - INFO - training batch 401, loss: 0.953, 12832/28000 datapoints
2025-03-06 20:43:49,326 - INFO - training batch 451, loss: 0.764, 14432/28000 datapoints
2025-03-06 20:43:49,523 - INFO - training batch 501, loss: 0.603, 16032/28000 datapoints
2025-03-06 20:43:49,647 - INFO - training batch 551, loss: 0.798, 17632/28000 datapoints
2025-03-06 20:43:49,766 - INFO - training batch 601, loss: 0.987, 19232/28000 datapoints
2025-03-06 20:43:49,887 - INFO - training batch 651, loss: 0.434, 20832/28000 datapoints
2025-03-06 20:43:50,006 - INFO - training batch 701, loss: 0.681, 22432/28000 datapoints
2025-03-06 20:43:50,128 - INFO - training batch 751, loss: 0.549, 24032/28000 datapoints
2025-03-06 20:43:50,246 - INFO - training batch 801, loss: 0.586, 25632/28000 datapoints
2025-03-06 20:43:50,365 - INFO - training batch 851, loss: 1.093, 27232/28000 datapoints
2025-03-06 20:43:50,424 - INFO - validation batch 1, loss: 0.500, 32/6976 datapoints
2025-03-06 20:43:50,469 - INFO - validation batch 51, loss: 1.433, 1632/6976 datapoints
2025-03-06 20:43:50,513 - INFO - validation batch 101, loss: 0.563, 3232/6976 datapoints
2025-03-06 20:43:50,558 - INFO - validation batch 151, loss: 0.967, 4832/6976 datapoints
2025-03-06 20:43:50,601 - INFO - validation batch 201, loss: 0.425, 6432/6976 datapoints
2025-03-06 20:43:50,616 - INFO - Epoch 147/800 done.
2025-03-06 20:43:50,616 - INFO - Final validation performance:
Loss: 0.777, top-1 acc: 0.757top-5 acc: 0.757
2025-03-06 20:43:50,617 - INFO - Beginning epoch 148/800
2025-03-06 20:43:50,620 - INFO - training batch 1, loss: 0.888, 32/28000 datapoints
2025-03-06 20:43:50,745 - INFO - training batch 51, loss: 0.750, 1632/28000 datapoints
2025-03-06 20:43:50,867 - INFO - training batch 101, loss: 0.436, 3232/28000 datapoints
2025-03-06 20:43:50,988 - INFO - training batch 151, loss: 1.208, 4832/28000 datapoints
2025-03-06 20:43:51,111 - INFO - training batch 201, loss: 0.582, 6432/28000 datapoints
2025-03-06 20:43:51,231 - INFO - training batch 251, loss: 0.598, 8032/28000 datapoints
2025-03-06 20:43:51,349 - INFO - training batch 301, loss: 0.885, 9632/28000 datapoints
2025-03-06 20:43:51,468 - INFO - training batch 351, loss: 0.665, 11232/28000 datapoints
2025-03-06 20:43:51,593 - INFO - training batch 401, loss: 0.951, 12832/28000 datapoints
2025-03-06 20:43:51,716 - INFO - training batch 451, loss: 0.755, 14432/28000 datapoints
2025-03-06 20:43:51,835 - INFO - training batch 501, loss: 0.594, 16032/28000 datapoints
2025-03-06 20:43:51,957 - INFO - training batch 551, loss: 0.790, 17632/28000 datapoints
2025-03-06 20:43:52,079 - INFO - training batch 601, loss: 0.977, 19232/28000 datapoints
2025-03-06 20:43:52,198 - INFO - training batch 651, loss: 0.427, 20832/28000 datapoints
2025-03-06 20:43:52,319 - INFO - training batch 701, loss: 0.676, 22432/28000 datapoints
2025-03-06 20:43:52,438 - INFO - training batch 751, loss: 0.538, 24032/28000 datapoints
2025-03-06 20:43:52,563 - INFO - training batch 801, loss: 0.579, 25632/28000 datapoints
2025-03-06 20:43:52,691 - INFO - training batch 851, loss: 1.090, 27232/28000 datapoints
2025-03-06 20:43:52,752 - INFO - validation batch 1, loss: 0.491, 32/6976 datapoints
2025-03-06 20:43:52,797 - INFO - validation batch 51, loss: 1.429, 1632/6976 datapoints
2025-03-06 20:43:52,840 - INFO - validation batch 101, loss: 0.552, 3232/6976 datapoints
2025-03-06 20:43:52,885 - INFO - validation batch 151, loss: 0.957, 4832/6976 datapoints
2025-03-06 20:43:52,930 - INFO - validation batch 201, loss: 0.423, 6432/6976 datapoints
2025-03-06 20:43:52,944 - INFO - Epoch 148/800 done.
2025-03-06 20:43:52,945 - INFO - Final validation performance:
Loss: 0.771, top-1 acc: 0.758top-5 acc: 0.758
2025-03-06 20:43:52,945 - INFO - Beginning epoch 149/800
2025-03-06 20:43:52,949 - INFO - training batch 1, loss: 0.883, 32/28000 datapoints
2025-03-06 20:43:53,075 - INFO - training batch 51, loss: 0.736, 1632/28000 datapoints
2025-03-06 20:43:53,196 - INFO - training batch 101, loss: 0.430, 3232/28000 datapoints
2025-03-06 20:43:53,318 - INFO - training batch 151, loss: 1.201, 4832/28000 datapoints
2025-03-06 20:43:53,437 - INFO - training batch 201, loss: 0.574, 6432/28000 datapoints
2025-03-06 20:43:53,563 - INFO - training batch 251, loss: 0.592, 8032/28000 datapoints
2025-03-06 20:43:53,693 - INFO - training batch 301, loss: 0.880, 9632/28000 datapoints
2025-03-06 20:43:53,812 - INFO - training batch 351, loss: 0.661, 11232/28000 datapoints
2025-03-06 20:43:53,931 - INFO - training batch 401, loss: 0.948, 12832/28000 datapoints
2025-03-06 20:43:54,052 - INFO - training batch 451, loss: 0.745, 14432/28000 datapoints
2025-03-06 20:43:54,173 - INFO - training batch 501, loss: 0.585, 16032/28000 datapoints
2025-03-06 20:43:54,300 - INFO - training batch 551, loss: 0.781, 17632/28000 datapoints
2025-03-06 20:43:54,423 - INFO - training batch 601, loss: 0.967, 19232/28000 datapoints
2025-03-06 20:43:54,542 - INFO - training batch 651, loss: 0.420, 20832/28000 datapoints
2025-03-06 20:43:54,667 - INFO - training batch 701, loss: 0.670, 22432/28000 datapoints
2025-03-06 20:43:54,795 - INFO - training batch 751, loss: 0.527, 24032/28000 datapoints
2025-03-06 20:43:54,932 - INFO - training batch 801, loss: 0.573, 25632/28000 datapoints
2025-03-06 20:43:55,120 - INFO - training batch 851, loss: 1.086, 27232/28000 datapoints
2025-03-06 20:43:55,205 - INFO - validation batch 1, loss: 0.484, 32/6976 datapoints
2025-03-06 20:43:55,250 - INFO - validation batch 51, loss: 1.425, 1632/6976 datapoints
2025-03-06 20:43:55,293 - INFO - validation batch 101, loss: 0.542, 3232/6976 datapoints
2025-03-06 20:43:55,338 - INFO - validation batch 151, loss: 0.950, 4832/6976 datapoints
2025-03-06 20:43:55,382 - INFO - validation batch 201, loss: 0.420, 6432/6976 datapoints
2025-03-06 20:43:55,397 - INFO - Epoch 149/800 done.
2025-03-06 20:43:55,397 - INFO - Final validation performance:
Loss: 0.764, top-1 acc: 0.760top-5 acc: 0.760
2025-03-06 20:43:55,398 - INFO - Beginning epoch 150/800
2025-03-06 20:43:55,401 - INFO - training batch 1, loss: 0.878, 32/28000 datapoints
2025-03-06 20:43:55,525 - INFO - training batch 51, loss: 0.723, 1632/28000 datapoints
2025-03-06 20:43:55,656 - INFO - training batch 101, loss: 0.423, 3232/28000 datapoints
2025-03-06 20:43:55,776 - INFO - training batch 151, loss: 1.191, 4832/28000 datapoints
2025-03-06 20:43:55,897 - INFO - training batch 201, loss: 0.566, 6432/28000 datapoints
2025-03-06 20:43:56,018 - INFO - training batch 251, loss: 0.587, 8032/28000 datapoints
2025-03-06 20:43:56,139 - INFO - training batch 301, loss: 0.875, 9632/28000 datapoints
2025-03-06 20:43:56,257 - INFO - training batch 351, loss: 0.658, 11232/28000 datapoints
2025-03-06 20:43:56,376 - INFO - training batch 401, loss: 0.945, 12832/28000 datapoints
2025-03-06 20:43:56,496 - INFO - training batch 451, loss: 0.735, 14432/28000 datapoints
2025-03-06 20:43:56,617 - INFO - training batch 501, loss: 0.577, 16032/28000 datapoints
2025-03-06 20:43:56,740 - INFO - training batch 551, loss: 0.773, 17632/28000 datapoints
2025-03-06 20:43:56,860 - INFO - training batch 601, loss: 0.958, 19232/28000 datapoints
2025-03-06 20:43:56,980 - INFO - training batch 651, loss: 0.411, 20832/28000 datapoints
2025-03-06 20:43:57,099 - INFO - training batch 701, loss: 0.664, 22432/28000 datapoints
2025-03-06 20:43:57,219 - INFO - training batch 751, loss: 0.517, 24032/28000 datapoints
2025-03-06 20:43:57,338 - INFO - training batch 801, loss: 0.566, 25632/28000 datapoints
2025-03-06 20:43:57,484 - INFO - training batch 851, loss: 1.082, 27232/28000 datapoints
2025-03-06 20:43:57,545 - INFO - validation batch 1, loss: 0.477, 32/6976 datapoints
2025-03-06 20:43:57,592 - INFO - validation batch 51, loss: 1.422, 1632/6976 datapoints
2025-03-06 20:43:57,640 - INFO - validation batch 101, loss: 0.532, 3232/6976 datapoints
2025-03-06 20:43:57,685 - INFO - validation batch 151, loss: 0.939, 4832/6976 datapoints
2025-03-06 20:43:57,728 - INFO - validation batch 201, loss: 0.418, 6432/6976 datapoints
2025-03-06 20:43:57,743 - INFO - Epoch 150/800 done.
2025-03-06 20:43:57,744 - INFO - Final validation performance:
Loss: 0.757, top-1 acc: 0.764top-5 acc: 0.764
2025-03-06 20:43:57,744 - INFO - Beginning epoch 151/800
2025-03-06 20:43:57,747 - INFO - training batch 1, loss: 0.873, 32/28000 datapoints
2025-03-06 20:43:57,869 - INFO - training batch 51, loss: 0.710, 1632/28000 datapoints
2025-03-06 20:43:57,988 - INFO - training batch 101, loss: 0.417, 3232/28000 datapoints
2025-03-06 20:43:58,108 - INFO - training batch 151, loss: 1.183, 4832/28000 datapoints
2025-03-06 20:43:58,231 - INFO - training batch 201, loss: 0.558, 6432/28000 datapoints
2025-03-06 20:43:58,351 - INFO - training batch 251, loss: 0.581, 8032/28000 datapoints
2025-03-06 20:43:58,474 - INFO - training batch 301, loss: 0.870, 9632/28000 datapoints
2025-03-06 20:43:58,596 - INFO - training batch 351, loss: 0.655, 11232/28000 datapoints
2025-03-06 20:43:58,721 - INFO - training batch 401, loss: 0.943, 12832/28000 datapoints
2025-03-06 20:43:58,842 - INFO - training batch 451, loss: 0.726, 14432/28000 datapoints
2025-03-06 20:43:58,963 - INFO - training batch 501, loss: 0.569, 16032/28000 datapoints
2025-03-06 20:43:59,083 - INFO - training batch 551, loss: 0.765, 17632/28000 datapoints
2025-03-06 20:43:59,203 - INFO - training batch 601, loss: 0.950, 19232/28000 datapoints
2025-03-06 20:43:59,327 - INFO - training batch 651, loss: 0.404, 20832/28000 datapoints
2025-03-06 20:43:59,446 - INFO - training batch 701, loss: 0.659, 22432/28000 datapoints
2025-03-06 20:43:59,569 - INFO - training batch 751, loss: 0.508, 24032/28000 datapoints
2025-03-06 20:43:59,693 - INFO - training batch 801, loss: 0.560, 25632/28000 datapoints
2025-03-06 20:43:59,813 - INFO - training batch 851, loss: 1.078, 27232/28000 datapoints
2025-03-06 20:43:59,872 - INFO - validation batch 1, loss: 0.470, 32/6976 datapoints
2025-03-06 20:43:59,918 - INFO - validation batch 51, loss: 1.418, 1632/6976 datapoints
2025-03-06 20:43:59,962 - INFO - validation batch 101, loss: 0.521, 3232/6976 datapoints
2025-03-06 20:44:00,006 - INFO - validation batch 151, loss: 0.928, 4832/6976 datapoints
2025-03-06 20:44:00,051 - INFO - validation batch 201, loss: 0.416, 6432/6976 datapoints
2025-03-06 20:44:00,066 - INFO - Epoch 151/800 done.
2025-03-06 20:44:00,066 - INFO - Final validation performance:
Loss: 0.751, top-1 acc: 0.766top-5 acc: 0.766
2025-03-06 20:44:00,067 - INFO - Beginning epoch 152/800
2025-03-06 20:44:00,071 - INFO - training batch 1, loss: 0.868, 32/28000 datapoints
2025-03-06 20:44:00,192 - INFO - training batch 51, loss: 0.698, 1632/28000 datapoints
2025-03-06 20:44:00,311 - INFO - training batch 101, loss: 0.411, 3232/28000 datapoints
2025-03-06 20:44:00,430 - INFO - training batch 151, loss: 1.173, 4832/28000 datapoints
2025-03-06 20:44:00,567 - INFO - training batch 201, loss: 0.550, 6432/28000 datapoints
2025-03-06 20:44:00,691 - INFO - training batch 251, loss: 0.576, 8032/28000 datapoints
2025-03-06 20:44:00,812 - INFO - training batch 301, loss: 0.865, 9632/28000 datapoints
2025-03-06 20:44:00,939 - INFO - training batch 351, loss: 0.652, 11232/28000 datapoints
2025-03-06 20:44:01,062 - INFO - training batch 401, loss: 0.941, 12832/28000 datapoints
2025-03-06 20:44:01,182 - INFO - training batch 451, loss: 0.717, 14432/28000 datapoints
2025-03-06 20:44:01,305 - INFO - training batch 501, loss: 0.560, 16032/28000 datapoints
2025-03-06 20:44:01,424 - INFO - training batch 551, loss: 0.756, 17632/28000 datapoints
2025-03-06 20:44:01,544 - INFO - training batch 601, loss: 0.942, 19232/28000 datapoints
2025-03-06 20:44:01,672 - INFO - training batch 651, loss: 0.396, 20832/28000 datapoints
2025-03-06 20:44:01,792 - INFO - training batch 701, loss: 0.653, 22432/28000 datapoints
2025-03-06 20:44:01,912 - INFO - training batch 751, loss: 0.499, 24032/28000 datapoints
2025-03-06 20:44:02,031 - INFO - training batch 801, loss: 0.553, 25632/28000 datapoints
2025-03-06 20:44:02,150 - INFO - training batch 851, loss: 1.074, 27232/28000 datapoints
2025-03-06 20:44:02,210 - INFO - validation batch 1, loss: 0.463, 32/6976 datapoints
2025-03-06 20:44:02,254 - INFO - validation batch 51, loss: 1.413, 1632/6976 datapoints
2025-03-06 20:44:02,298 - INFO - validation batch 101, loss: 0.511, 3232/6976 datapoints
2025-03-06 20:44:02,341 - INFO - validation batch 151, loss: 0.919, 4832/6976 datapoints
2025-03-06 20:44:02,384 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 20:44:02,399 - INFO - Epoch 152/800 done.
2025-03-06 20:44:02,399 - INFO - Final validation performance:
Loss: 0.744, top-1 acc: 0.769top-5 acc: 0.769
2025-03-06 20:44:02,400 - INFO - Beginning epoch 153/800
2025-03-06 20:44:02,403 - INFO - training batch 1, loss: 0.863, 32/28000 datapoints
2025-03-06 20:44:02,524 - INFO - training batch 51, loss: 0.685, 1632/28000 datapoints
2025-03-06 20:44:02,647 - INFO - training batch 101, loss: 0.405, 3232/28000 datapoints
2025-03-06 20:44:02,772 - INFO - training batch 151, loss: 1.164, 4832/28000 datapoints
2025-03-06 20:44:02,892 - INFO - training batch 201, loss: 0.542, 6432/28000 datapoints
2025-03-06 20:44:03,012 - INFO - training batch 251, loss: 0.571, 8032/28000 datapoints
2025-03-06 20:44:03,132 - INFO - training batch 301, loss: 0.860, 9632/28000 datapoints
2025-03-06 20:44:03,254 - INFO - training batch 351, loss: 0.649, 11232/28000 datapoints
2025-03-06 20:44:03,372 - INFO - training batch 401, loss: 0.939, 12832/28000 datapoints
2025-03-06 20:44:03,492 - INFO - training batch 451, loss: 0.708, 14432/28000 datapoints
2025-03-06 20:44:03,618 - INFO - training batch 501, loss: 0.553, 16032/28000 datapoints
2025-03-06 20:44:03,742 - INFO - training batch 551, loss: 0.746, 17632/28000 datapoints
2025-03-06 20:44:03,862 - INFO - training batch 601, loss: 0.933, 19232/28000 datapoints
2025-03-06 20:44:03,981 - INFO - training batch 651, loss: 0.388, 20832/28000 datapoints
2025-03-06 20:44:04,100 - INFO - training batch 701, loss: 0.648, 22432/28000 datapoints
2025-03-06 20:44:04,221 - INFO - training batch 751, loss: 0.491, 24032/28000 datapoints
2025-03-06 20:44:04,339 - INFO - training batch 801, loss: 0.547, 25632/28000 datapoints
2025-03-06 20:44:04,458 - INFO - training batch 851, loss: 1.071, 27232/28000 datapoints
2025-03-06 20:44:04,517 - INFO - validation batch 1, loss: 0.457, 32/6976 datapoints
2025-03-06 20:44:04,561 - INFO - validation batch 51, loss: 1.408, 1632/6976 datapoints
2025-03-06 20:44:04,605 - INFO - validation batch 101, loss: 0.502, 3232/6976 datapoints
2025-03-06 20:44:04,657 - INFO - validation batch 151, loss: 0.910, 4832/6976 datapoints
2025-03-06 20:44:04,710 - INFO - validation batch 201, loss: 0.412, 6432/6976 datapoints
2025-03-06 20:44:04,730 - INFO - Epoch 153/800 done.
2025-03-06 20:44:04,730 - INFO - Final validation performance:
Loss: 0.738, top-1 acc: 0.772top-5 acc: 0.772
2025-03-06 20:44:04,732 - INFO - Beginning epoch 154/800
2025-03-06 20:44:04,736 - INFO - training batch 1, loss: 0.858, 32/28000 datapoints
2025-03-06 20:44:04,859 - INFO - training batch 51, loss: 0.674, 1632/28000 datapoints
2025-03-06 20:44:04,984 - INFO - training batch 101, loss: 0.400, 3232/28000 datapoints
2025-03-06 20:44:05,107 - INFO - training batch 151, loss: 1.155, 4832/28000 datapoints
2025-03-06 20:44:05,229 - INFO - training batch 201, loss: 0.535, 6432/28000 datapoints
2025-03-06 20:44:05,359 - INFO - training batch 251, loss: 0.566, 8032/28000 datapoints
2025-03-06 20:44:05,481 - INFO - training batch 301, loss: 0.855, 9632/28000 datapoints
2025-03-06 20:44:05,603 - INFO - training batch 351, loss: 0.647, 11232/28000 datapoints
2025-03-06 20:44:05,730 - INFO - training batch 401, loss: 0.936, 12832/28000 datapoints
2025-03-06 20:44:05,848 - INFO - training batch 451, loss: 0.700, 14432/28000 datapoints
2025-03-06 20:44:05,967 - INFO - training batch 501, loss: 0.546, 16032/28000 datapoints
2025-03-06 20:44:06,088 - INFO - training batch 551, loss: 0.738, 17632/28000 datapoints
2025-03-06 20:44:06,211 - INFO - training batch 601, loss: 0.925, 19232/28000 datapoints
2025-03-06 20:44:06,333 - INFO - training batch 651, loss: 0.380, 20832/28000 datapoints
2025-03-06 20:44:06,452 - INFO - training batch 701, loss: 0.643, 22432/28000 datapoints
2025-03-06 20:44:06,578 - INFO - training batch 751, loss: 0.483, 24032/28000 datapoints
2025-03-06 20:44:06,704 - INFO - training batch 801, loss: 0.541, 25632/28000 datapoints
2025-03-06 20:44:06,823 - INFO - training batch 851, loss: 1.067, 27232/28000 datapoints
2025-03-06 20:44:06,882 - INFO - validation batch 1, loss: 0.450, 32/6976 datapoints
2025-03-06 20:44:06,925 - INFO - validation batch 51, loss: 1.402, 1632/6976 datapoints
2025-03-06 20:44:06,969 - INFO - validation batch 101, loss: 0.493, 3232/6976 datapoints
2025-03-06 20:44:07,013 - INFO - validation batch 151, loss: 0.901, 4832/6976 datapoints
2025-03-06 20:44:07,062 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:44:07,077 - INFO - Epoch 154/800 done.
2025-03-06 20:44:07,077 - INFO - Final validation performance:
Loss: 0.731, top-1 acc: 0.774top-5 acc: 0.774
2025-03-06 20:44:07,078 - INFO - Beginning epoch 155/800
2025-03-06 20:44:07,082 - INFO - training batch 1, loss: 0.853, 32/28000 datapoints
2025-03-06 20:44:07,207 - INFO - training batch 51, loss: 0.661, 1632/28000 datapoints
2025-03-06 20:44:07,331 - INFO - training batch 101, loss: 0.395, 3232/28000 datapoints
2025-03-06 20:44:07,458 - INFO - training batch 151, loss: 1.146, 4832/28000 datapoints
2025-03-06 20:44:07,604 - INFO - training batch 201, loss: 0.527, 6432/28000 datapoints
2025-03-06 20:44:07,730 - INFO - training batch 251, loss: 0.562, 8032/28000 datapoints
2025-03-06 20:44:07,858 - INFO - training batch 301, loss: 0.850, 9632/28000 datapoints
2025-03-06 20:44:07,980 - INFO - training batch 351, loss: 0.645, 11232/28000 datapoints
2025-03-06 20:44:08,101 - INFO - training batch 401, loss: 0.934, 12832/28000 datapoints
2025-03-06 20:44:08,219 - INFO - training batch 451, loss: 0.691, 14432/28000 datapoints
2025-03-06 20:44:08,341 - INFO - training batch 501, loss: 0.538, 16032/28000 datapoints
2025-03-06 20:44:08,461 - INFO - training batch 551, loss: 0.729, 17632/28000 datapoints
2025-03-06 20:44:08,581 - INFO - training batch 601, loss: 0.917, 19232/28000 datapoints
2025-03-06 20:44:08,705 - INFO - training batch 651, loss: 0.372, 20832/28000 datapoints
2025-03-06 20:44:08,826 - INFO - training batch 701, loss: 0.638, 22432/28000 datapoints
2025-03-06 20:44:08,948 - INFO - training batch 751, loss: 0.476, 24032/28000 datapoints
2025-03-06 20:44:09,073 - INFO - training batch 801, loss: 0.536, 25632/28000 datapoints
2025-03-06 20:44:09,205 - INFO - training batch 851, loss: 1.065, 27232/28000 datapoints
2025-03-06 20:44:09,269 - INFO - validation batch 1, loss: 0.443, 32/6976 datapoints
2025-03-06 20:44:09,313 - INFO - validation batch 51, loss: 1.397, 1632/6976 datapoints
2025-03-06 20:44:09,356 - INFO - validation batch 101, loss: 0.483, 3232/6976 datapoints
2025-03-06 20:44:09,400 - INFO - validation batch 151, loss: 0.891, 4832/6976 datapoints
2025-03-06 20:44:09,443 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 20:44:09,458 - INFO - Epoch 155/800 done.
2025-03-06 20:44:09,458 - INFO - Final validation performance:
Loss: 0.725, top-1 acc: 0.775top-5 acc: 0.775
2025-03-06 20:44:09,459 - INFO - Beginning epoch 156/800
2025-03-06 20:44:09,462 - INFO - training batch 1, loss: 0.848, 32/28000 datapoints
2025-03-06 20:44:09,582 - INFO - training batch 51, loss: 0.649, 1632/28000 datapoints
2025-03-06 20:44:09,709 - INFO - training batch 101, loss: 0.389, 3232/28000 datapoints
2025-03-06 20:44:09,836 - INFO - training batch 151, loss: 1.136, 4832/28000 datapoints
2025-03-06 20:44:09,966 - INFO - training batch 201, loss: 0.520, 6432/28000 datapoints
2025-03-06 20:44:10,088 - INFO - training batch 251, loss: 0.557, 8032/28000 datapoints
2025-03-06 20:44:10,208 - INFO - training batch 301, loss: 0.846, 9632/28000 datapoints
2025-03-06 20:44:10,328 - INFO - training batch 351, loss: 0.643, 11232/28000 datapoints
2025-03-06 20:44:10,449 - INFO - training batch 401, loss: 0.931, 12832/28000 datapoints
2025-03-06 20:44:10,569 - INFO - training batch 451, loss: 0.682, 14432/28000 datapoints
2025-03-06 20:44:10,691 - INFO - training batch 501, loss: 0.532, 16032/28000 datapoints
2025-03-06 20:44:10,812 - INFO - training batch 551, loss: 0.721, 17632/28000 datapoints
2025-03-06 20:44:10,932 - INFO - training batch 601, loss: 0.909, 19232/28000 datapoints
2025-03-06 20:44:11,053 - INFO - training batch 651, loss: 0.363, 20832/28000 datapoints
2025-03-06 20:44:11,173 - INFO - training batch 701, loss: 0.633, 22432/28000 datapoints
2025-03-06 20:44:11,295 - INFO - training batch 751, loss: 0.469, 24032/28000 datapoints
2025-03-06 20:44:11,414 - INFO - training batch 801, loss: 0.530, 25632/28000 datapoints
2025-03-06 20:44:11,533 - INFO - training batch 851, loss: 1.062, 27232/28000 datapoints
2025-03-06 20:44:11,592 - INFO - validation batch 1, loss: 0.437, 32/6976 datapoints
2025-03-06 20:44:11,643 - INFO - validation batch 51, loss: 1.392, 1632/6976 datapoints
2025-03-06 20:44:11,688 - INFO - validation batch 101, loss: 0.474, 3232/6976 datapoints
2025-03-06 20:44:11,732 - INFO - validation batch 151, loss: 0.882, 4832/6976 datapoints
2025-03-06 20:44:11,778 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 20:44:11,793 - INFO - Epoch 156/800 done.
2025-03-06 20:44:11,793 - INFO - Final validation performance:
Loss: 0.719, top-1 acc: 0.778top-5 acc: 0.778
2025-03-06 20:44:11,794 - INFO - Beginning epoch 157/800
2025-03-06 20:44:11,797 - INFO - training batch 1, loss: 0.842, 32/28000 datapoints
2025-03-06 20:44:11,918 - INFO - training batch 51, loss: 0.637, 1632/28000 datapoints
2025-03-06 20:44:12,037 - INFO - training batch 101, loss: 0.384, 3232/28000 datapoints
2025-03-06 20:44:12,159 - INFO - training batch 151, loss: 1.125, 4832/28000 datapoints
2025-03-06 20:44:12,279 - INFO - training batch 201, loss: 0.514, 6432/28000 datapoints
2025-03-06 20:44:12,401 - INFO - training batch 251, loss: 0.553, 8032/28000 datapoints
2025-03-06 20:44:12,520 - INFO - training batch 301, loss: 0.840, 9632/28000 datapoints
2025-03-06 20:44:12,652 - INFO - training batch 351, loss: 0.643, 11232/28000 datapoints
2025-03-06 20:44:12,778 - INFO - training batch 401, loss: 0.929, 12832/28000 datapoints
2025-03-06 20:44:12,898 - INFO - training batch 451, loss: 0.673, 14432/28000 datapoints
2025-03-06 20:44:13,019 - INFO - training batch 501, loss: 0.526, 16032/28000 datapoints
2025-03-06 20:44:13,138 - INFO - training batch 551, loss: 0.712, 17632/28000 datapoints
2025-03-06 20:44:13,269 - INFO - training batch 601, loss: 0.901, 19232/28000 datapoints
2025-03-06 20:44:13,393 - INFO - training batch 651, loss: 0.355, 20832/28000 datapoints
2025-03-06 20:44:13,512 - INFO - training batch 701, loss: 0.628, 22432/28000 datapoints
2025-03-06 20:44:13,644 - INFO - training batch 751, loss: 0.463, 24032/28000 datapoints
2025-03-06 20:44:13,763 - INFO - training batch 801, loss: 0.525, 25632/28000 datapoints
2025-03-06 20:44:13,884 - INFO - training batch 851, loss: 1.059, 27232/28000 datapoints
2025-03-06 20:44:13,943 - INFO - validation batch 1, loss: 0.431, 32/6976 datapoints
2025-03-06 20:44:13,987 - INFO - validation batch 51, loss: 1.387, 1632/6976 datapoints
2025-03-06 20:44:14,032 - INFO - validation batch 101, loss: 0.466, 3232/6976 datapoints
2025-03-06 20:44:14,078 - INFO - validation batch 151, loss: 0.873, 4832/6976 datapoints
2025-03-06 20:44:14,123 - INFO - validation batch 201, loss: 0.405, 6432/6976 datapoints
2025-03-06 20:44:14,138 - INFO - Epoch 157/800 done.
2025-03-06 20:44:14,138 - INFO - Final validation performance:
Loss: 0.712, top-1 acc: 0.781top-5 acc: 0.781
2025-03-06 20:44:14,138 - INFO - Beginning epoch 158/800
2025-03-06 20:44:14,141 - INFO - training batch 1, loss: 0.837, 32/28000 datapoints
2025-03-06 20:44:14,262 - INFO - training batch 51, loss: 0.626, 1632/28000 datapoints
2025-03-06 20:44:14,385 - INFO - training batch 101, loss: 0.379, 3232/28000 datapoints
2025-03-06 20:44:14,505 - INFO - training batch 151, loss: 1.117, 4832/28000 datapoints
2025-03-06 20:44:14,624 - INFO - training batch 201, loss: 0.506, 6432/28000 datapoints
2025-03-06 20:44:14,747 - INFO - training batch 251, loss: 0.549, 8032/28000 datapoints
2025-03-06 20:44:14,873 - INFO - training batch 301, loss: 0.836, 9632/28000 datapoints
2025-03-06 20:44:14,997 - INFO - training batch 351, loss: 0.641, 11232/28000 datapoints
2025-03-06 20:44:15,118 - INFO - training batch 401, loss: 0.927, 12832/28000 datapoints
2025-03-06 20:44:15,237 - INFO - training batch 451, loss: 0.665, 14432/28000 datapoints
2025-03-06 20:44:15,375 - INFO - training batch 501, loss: 0.519, 16032/28000 datapoints
2025-03-06 20:44:15,517 - INFO - training batch 551, loss: 0.704, 17632/28000 datapoints
2025-03-06 20:44:15,643 - INFO - training batch 601, loss: 0.895, 19232/28000 datapoints
2025-03-06 20:44:15,764 - INFO - training batch 651, loss: 0.346, 20832/28000 datapoints
2025-03-06 20:44:15,891 - INFO - training batch 701, loss: 0.623, 22432/28000 datapoints
2025-03-06 20:44:16,012 - INFO - training batch 751, loss: 0.456, 24032/28000 datapoints
2025-03-06 20:44:16,132 - INFO - training batch 801, loss: 0.520, 25632/28000 datapoints
2025-03-06 20:44:16,251 - INFO - training batch 851, loss: 1.055, 27232/28000 datapoints
2025-03-06 20:44:16,309 - INFO - validation batch 1, loss: 0.424, 32/6976 datapoints
2025-03-06 20:44:16,355 - INFO - validation batch 51, loss: 1.383, 1632/6976 datapoints
2025-03-06 20:44:16,399 - INFO - validation batch 101, loss: 0.458, 3232/6976 datapoints
2025-03-06 20:44:16,442 - INFO - validation batch 151, loss: 0.865, 4832/6976 datapoints
2025-03-06 20:44:16,485 - INFO - validation batch 201, loss: 0.403, 6432/6976 datapoints
2025-03-06 20:44:16,501 - INFO - Epoch 158/800 done.
2025-03-06 20:44:16,501 - INFO - Final validation performance:
Loss: 0.707, top-1 acc: 0.784top-5 acc: 0.784
2025-03-06 20:44:16,502 - INFO - Beginning epoch 159/800
2025-03-06 20:44:16,505 - INFO - training batch 1, loss: 0.832, 32/28000 datapoints
2025-03-06 20:44:16,626 - INFO - training batch 51, loss: 0.614, 1632/28000 datapoints
2025-03-06 20:44:16,749 - INFO - training batch 101, loss: 0.374, 3232/28000 datapoints
2025-03-06 20:44:16,873 - INFO - training batch 151, loss: 1.108, 4832/28000 datapoints
2025-03-06 20:44:16,994 - INFO - training batch 201, loss: 0.500, 6432/28000 datapoints
2025-03-06 20:44:17,113 - INFO - training batch 251, loss: 0.545, 8032/28000 datapoints
2025-03-06 20:44:17,234 - INFO - training batch 301, loss: 0.832, 9632/28000 datapoints
2025-03-06 20:44:17,361 - INFO - training batch 351, loss: 0.640, 11232/28000 datapoints
2025-03-06 20:44:17,481 - INFO - training batch 401, loss: 0.925, 12832/28000 datapoints
2025-03-06 20:44:17,624 - INFO - training batch 451, loss: 0.657, 14432/28000 datapoints
2025-03-06 20:44:17,754 - INFO - training batch 501, loss: 0.513, 16032/28000 datapoints
2025-03-06 20:44:17,875 - INFO - training batch 551, loss: 0.695, 17632/28000 datapoints
2025-03-06 20:44:17,997 - INFO - training batch 601, loss: 0.889, 19232/28000 datapoints
2025-03-06 20:44:18,117 - INFO - training batch 651, loss: 0.338, 20832/28000 datapoints
2025-03-06 20:44:18,239 - INFO - training batch 701, loss: 0.618, 22432/28000 datapoints
2025-03-06 20:44:18,358 - INFO - training batch 751, loss: 0.451, 24032/28000 datapoints
2025-03-06 20:44:18,477 - INFO - training batch 801, loss: 0.515, 25632/28000 datapoints
2025-03-06 20:44:18,597 - INFO - training batch 851, loss: 1.052, 27232/28000 datapoints
2025-03-06 20:44:18,658 - INFO - validation batch 1, loss: 0.418, 32/6976 datapoints
2025-03-06 20:44:18,701 - INFO - validation batch 51, loss: 1.379, 1632/6976 datapoints
2025-03-06 20:44:18,744 - INFO - validation batch 101, loss: 0.450, 3232/6976 datapoints
2025-03-06 20:44:18,788 - INFO - validation batch 151, loss: 0.857, 4832/6976 datapoints
2025-03-06 20:44:18,844 - INFO - validation batch 201, loss: 0.403, 6432/6976 datapoints
2025-03-06 20:44:18,862 - INFO - Epoch 159/800 done.
2025-03-06 20:44:18,862 - INFO - Final validation performance:
Loss: 0.701, top-1 acc: 0.786top-5 acc: 0.786
2025-03-06 20:44:18,863 - INFO - Beginning epoch 160/800
2025-03-06 20:44:18,867 - INFO - training batch 1, loss: 0.827, 32/28000 datapoints
2025-03-06 20:44:18,994 - INFO - training batch 51, loss: 0.604, 1632/28000 datapoints
2025-03-06 20:44:19,114 - INFO - training batch 101, loss: 0.370, 3232/28000 datapoints
2025-03-06 20:44:19,234 - INFO - training batch 151, loss: 1.100, 4832/28000 datapoints
2025-03-06 20:44:19,380 - INFO - training batch 201, loss: 0.493, 6432/28000 datapoints
2025-03-06 20:44:19,498 - INFO - training batch 251, loss: 0.541, 8032/28000 datapoints
2025-03-06 20:44:19,618 - INFO - training batch 301, loss: 0.827, 9632/28000 datapoints
2025-03-06 20:44:19,746 - INFO - training batch 351, loss: 0.641, 11232/28000 datapoints
2025-03-06 20:44:19,868 - INFO - training batch 401, loss: 0.923, 12832/28000 datapoints
2025-03-06 20:44:19,988 - INFO - training batch 451, loss: 0.649, 14432/28000 datapoints
2025-03-06 20:44:20,109 - INFO - training batch 501, loss: 0.507, 16032/28000 datapoints
2025-03-06 20:44:20,228 - INFO - training batch 551, loss: 0.687, 17632/28000 datapoints
2025-03-06 20:44:20,347 - INFO - training batch 601, loss: 0.883, 19232/28000 datapoints
2025-03-06 20:44:20,466 - INFO - training batch 651, loss: 0.329, 20832/28000 datapoints
2025-03-06 20:44:20,586 - INFO - training batch 701, loss: 0.613, 22432/28000 datapoints
2025-03-06 20:44:20,706 - INFO - training batch 751, loss: 0.447, 24032/28000 datapoints
2025-03-06 20:44:20,829 - INFO - training batch 801, loss: 0.509, 25632/28000 datapoints
2025-03-06 20:44:20,950 - INFO - training batch 851, loss: 1.049, 27232/28000 datapoints
2025-03-06 20:44:21,009 - INFO - validation batch 1, loss: 0.412, 32/6976 datapoints
2025-03-06 20:44:21,055 - INFO - validation batch 51, loss: 1.373, 1632/6976 datapoints
2025-03-06 20:44:21,099 - INFO - validation batch 101, loss: 0.442, 3232/6976 datapoints
2025-03-06 20:44:21,143 - INFO - validation batch 151, loss: 0.848, 4832/6976 datapoints
2025-03-06 20:44:21,187 - INFO - validation batch 201, loss: 0.401, 6432/6976 datapoints
2025-03-06 20:44:21,203 - INFO - Epoch 160/800 done.
2025-03-06 20:44:21,203 - INFO - Final validation performance:
Loss: 0.695, top-1 acc: 0.789top-5 acc: 0.789
2025-03-06 20:44:21,204 - INFO - Beginning epoch 161/800
2025-03-06 20:44:21,208 - INFO - training batch 1, loss: 0.822, 32/28000 datapoints
2025-03-06 20:44:21,329 - INFO - training batch 51, loss: 0.593, 1632/28000 datapoints
2025-03-06 20:44:21,451 - INFO - training batch 101, loss: 0.366, 3232/28000 datapoints
2025-03-06 20:44:21,580 - INFO - training batch 151, loss: 1.092, 4832/28000 datapoints
2025-03-06 20:44:21,730 - INFO - training batch 201, loss: 0.487, 6432/28000 datapoints
2025-03-06 20:44:21,892 - INFO - training batch 251, loss: 0.538, 8032/28000 datapoints
2025-03-06 20:44:22,013 - INFO - training batch 301, loss: 0.823, 9632/28000 datapoints
2025-03-06 20:44:22,134 - INFO - training batch 351, loss: 0.641, 11232/28000 datapoints
2025-03-06 20:44:22,262 - INFO - training batch 401, loss: 0.922, 12832/28000 datapoints
2025-03-06 20:44:22,391 - INFO - training batch 451, loss: 0.641, 14432/28000 datapoints
2025-03-06 20:44:22,513 - INFO - training batch 501, loss: 0.501, 16032/28000 datapoints
2025-03-06 20:44:22,636 - INFO - training batch 551, loss: 0.679, 17632/28000 datapoints
2025-03-06 20:44:22,756 - INFO - training batch 601, loss: 0.878, 19232/28000 datapoints
2025-03-06 20:44:22,876 - INFO - training batch 651, loss: 0.321, 20832/28000 datapoints
2025-03-06 20:44:23,000 - INFO - training batch 701, loss: 0.609, 22432/28000 datapoints
2025-03-06 20:44:23,120 - INFO - training batch 751, loss: 0.442, 24032/28000 datapoints
2025-03-06 20:44:23,239 - INFO - training batch 801, loss: 0.504, 25632/28000 datapoints
2025-03-06 20:44:23,359 - INFO - training batch 851, loss: 1.045, 27232/28000 datapoints
2025-03-06 20:44:23,421 - INFO - validation batch 1, loss: 0.406, 32/6976 datapoints
2025-03-06 20:44:23,465 - INFO - validation batch 51, loss: 1.369, 1632/6976 datapoints
2025-03-06 20:44:23,509 - INFO - validation batch 101, loss: 0.434, 3232/6976 datapoints
2025-03-06 20:44:23,552 - INFO - validation batch 151, loss: 0.837, 4832/6976 datapoints
2025-03-06 20:44:23,597 - INFO - validation batch 201, loss: 0.400, 6432/6976 datapoints
2025-03-06 20:44:23,612 - INFO - Epoch 161/800 done.
2025-03-06 20:44:23,613 - INFO - Final validation performance:
Loss: 0.689, top-1 acc: 0.791top-5 acc: 0.791
2025-03-06 20:44:23,613 - INFO - Beginning epoch 162/800
2025-03-06 20:44:23,617 - INFO - training batch 1, loss: 0.816, 32/28000 datapoints
2025-03-06 20:44:23,757 - INFO - training batch 51, loss: 0.582, 1632/28000 datapoints
2025-03-06 20:44:23,883 - INFO - training batch 101, loss: 0.361, 3232/28000 datapoints
2025-03-06 20:44:24,006 - INFO - training batch 151, loss: 1.083, 4832/28000 datapoints
2025-03-06 20:44:24,126 - INFO - training batch 201, loss: 0.481, 6432/28000 datapoints
2025-03-06 20:44:24,246 - INFO - training batch 251, loss: 0.534, 8032/28000 datapoints
2025-03-06 20:44:24,364 - INFO - training batch 301, loss: 0.819, 9632/28000 datapoints
2025-03-06 20:44:24,485 - INFO - training batch 351, loss: 0.640, 11232/28000 datapoints
2025-03-06 20:44:24,603 - INFO - training batch 401, loss: 0.920, 12832/28000 datapoints
2025-03-06 20:44:24,723 - INFO - training batch 451, loss: 0.633, 14432/28000 datapoints
2025-03-06 20:44:24,848 - INFO - training batch 501, loss: 0.495, 16032/28000 datapoints
2025-03-06 20:44:25,000 - INFO - training batch 551, loss: 0.671, 17632/28000 datapoints
2025-03-06 20:44:25,127 - INFO - training batch 601, loss: 0.873, 19232/28000 datapoints
2025-03-06 20:44:25,252 - INFO - training batch 651, loss: 0.313, 20832/28000 datapoints
2025-03-06 20:44:25,383 - INFO - training batch 701, loss: 0.604, 22432/28000 datapoints
2025-03-06 20:44:25,510 - INFO - training batch 751, loss: 0.438, 24032/28000 datapoints
2025-03-06 20:44:25,639 - INFO - training batch 801, loss: 0.499, 25632/28000 datapoints
2025-03-06 20:44:25,768 - INFO - training batch 851, loss: 1.040, 27232/28000 datapoints
2025-03-06 20:44:25,836 - INFO - validation batch 1, loss: 0.399, 32/6976 datapoints
2025-03-06 20:44:25,883 - INFO - validation batch 51, loss: 1.364, 1632/6976 datapoints
2025-03-06 20:44:25,934 - INFO - validation batch 101, loss: 0.426, 3232/6976 datapoints
2025-03-06 20:44:25,984 - INFO - validation batch 151, loss: 0.827, 4832/6976 datapoints
2025-03-06 20:44:26,032 - INFO - validation batch 201, loss: 0.398, 6432/6976 datapoints
2025-03-06 20:44:26,048 - INFO - Epoch 162/800 done.
2025-03-06 20:44:26,049 - INFO - Final validation performance:
Loss: 0.683, top-1 acc: 0.793top-5 acc: 0.793
2025-03-06 20:44:26,049 - INFO - Beginning epoch 163/800
2025-03-06 20:44:26,053 - INFO - training batch 1, loss: 0.811, 32/28000 datapoints
2025-03-06 20:44:26,179 - INFO - training batch 51, loss: 0.572, 1632/28000 datapoints
2025-03-06 20:44:26,311 - INFO - training batch 101, loss: 0.357, 3232/28000 datapoints
2025-03-06 20:44:26,458 - INFO - training batch 151, loss: 1.074, 4832/28000 datapoints
2025-03-06 20:44:26,581 - INFO - training batch 201, loss: 0.474, 6432/28000 datapoints
2025-03-06 20:44:26,706 - INFO - training batch 251, loss: 0.531, 8032/28000 datapoints
2025-03-06 20:44:26,829 - INFO - training batch 301, loss: 0.815, 9632/28000 datapoints
2025-03-06 20:44:27,002 - INFO - training batch 351, loss: 0.640, 11232/28000 datapoints
2025-03-06 20:44:27,127 - INFO - training batch 401, loss: 0.919, 12832/28000 datapoints
2025-03-06 20:44:27,252 - INFO - training batch 451, loss: 0.625, 14432/28000 datapoints
2025-03-06 20:44:27,374 - INFO - training batch 501, loss: 0.489, 16032/28000 datapoints
2025-03-06 20:44:27,497 - INFO - training batch 551, loss: 0.663, 17632/28000 datapoints
2025-03-06 20:44:27,623 - INFO - training batch 601, loss: 0.867, 19232/28000 datapoints
2025-03-06 20:44:27,777 - INFO - training batch 651, loss: 0.305, 20832/28000 datapoints
2025-03-06 20:44:27,904 - INFO - training batch 701, loss: 0.600, 22432/28000 datapoints
2025-03-06 20:44:28,030 - INFO - training batch 751, loss: 0.434, 24032/28000 datapoints
2025-03-06 20:44:28,174 - INFO - training batch 801, loss: 0.493, 25632/28000 datapoints
2025-03-06 20:44:28,298 - INFO - training batch 851, loss: 1.036, 27232/28000 datapoints
2025-03-06 20:44:28,360 - INFO - validation batch 1, loss: 0.393, 32/6976 datapoints
2025-03-06 20:44:28,410 - INFO - validation batch 51, loss: 1.359, 1632/6976 datapoints
2025-03-06 20:44:28,458 - INFO - validation batch 101, loss: 0.419, 3232/6976 datapoints
2025-03-06 20:44:28,507 - INFO - validation batch 151, loss: 0.817, 4832/6976 datapoints
2025-03-06 20:44:28,555 - INFO - validation batch 201, loss: 0.396, 6432/6976 datapoints
2025-03-06 20:44:28,571 - INFO - Epoch 163/800 done.
2025-03-06 20:44:28,571 - INFO - Final validation performance:
Loss: 0.677, top-1 acc: 0.795top-5 acc: 0.795
2025-03-06 20:44:28,572 - INFO - Beginning epoch 164/800
2025-03-06 20:44:28,576 - INFO - training batch 1, loss: 0.805, 32/28000 datapoints
2025-03-06 20:44:28,703 - INFO - training batch 51, loss: 0.561, 1632/28000 datapoints
2025-03-06 20:44:28,825 - INFO - training batch 101, loss: 0.353, 3232/28000 datapoints
2025-03-06 20:44:28,951 - INFO - training batch 151, loss: 1.067, 4832/28000 datapoints
2025-03-06 20:44:29,074 - INFO - training batch 201, loss: 0.468, 6432/28000 datapoints
2025-03-06 20:44:29,195 - INFO - training batch 251, loss: 0.528, 8032/28000 datapoints
2025-03-06 20:44:29,317 - INFO - training batch 301, loss: 0.811, 9632/28000 datapoints
2025-03-06 20:44:29,440 - INFO - training batch 351, loss: 0.640, 11232/28000 datapoints
2025-03-06 20:44:29,560 - INFO - training batch 401, loss: 0.917, 12832/28000 datapoints
2025-03-06 20:44:29,685 - INFO - training batch 451, loss: 0.618, 14432/28000 datapoints
2025-03-06 20:44:29,809 - INFO - training batch 501, loss: 0.484, 16032/28000 datapoints
2025-03-06 20:44:29,929 - INFO - training batch 551, loss: 0.655, 17632/28000 datapoints
2025-03-06 20:44:30,051 - INFO - training batch 601, loss: 0.862, 19232/28000 datapoints
2025-03-06 20:44:30,171 - INFO - training batch 651, loss: 0.297, 20832/28000 datapoints
2025-03-06 20:44:30,294 - INFO - training batch 701, loss: 0.595, 22432/28000 datapoints
2025-03-06 20:44:30,415 - INFO - training batch 751, loss: 0.430, 24032/28000 datapoints
2025-03-06 20:44:30,536 - INFO - training batch 801, loss: 0.488, 25632/28000 datapoints
2025-03-06 20:44:30,657 - INFO - training batch 851, loss: 1.032, 27232/28000 datapoints
2025-03-06 20:44:30,717 - INFO - validation batch 1, loss: 0.387, 32/6976 datapoints
2025-03-06 20:44:30,760 - INFO - validation batch 51, loss: 1.355, 1632/6976 datapoints
2025-03-06 20:44:30,804 - INFO - validation batch 101, loss: 0.412, 3232/6976 datapoints
2025-03-06 20:44:30,848 - INFO - validation batch 151, loss: 0.808, 4832/6976 datapoints
2025-03-06 20:44:30,892 - INFO - validation batch 201, loss: 0.395, 6432/6976 datapoints
2025-03-06 20:44:30,907 - INFO - Epoch 164/800 done.
2025-03-06 20:44:30,907 - INFO - Final validation performance:
Loss: 0.671, top-1 acc: 0.797top-5 acc: 0.797
2025-03-06 20:44:30,907 - INFO - Beginning epoch 165/800
2025-03-06 20:44:30,911 - INFO - training batch 1, loss: 0.799, 32/28000 datapoints
2025-03-06 20:44:31,035 - INFO - training batch 51, loss: 0.551, 1632/28000 datapoints
2025-03-06 20:44:31,172 - INFO - training batch 101, loss: 0.349, 3232/28000 datapoints
2025-03-06 20:44:31,294 - INFO - training batch 151, loss: 1.058, 4832/28000 datapoints
2025-03-06 20:44:31,414 - INFO - training batch 201, loss: 0.462, 6432/28000 datapoints
2025-03-06 20:44:31,542 - INFO - training batch 251, loss: 0.525, 8032/28000 datapoints
2025-03-06 20:44:31,666 - INFO - training batch 301, loss: 0.809, 9632/28000 datapoints
2025-03-06 20:44:31,793 - INFO - training batch 351, loss: 0.640, 11232/28000 datapoints
2025-03-06 20:44:31,914 - INFO - training batch 401, loss: 0.915, 12832/28000 datapoints
2025-03-06 20:44:32,040 - INFO - training batch 451, loss: 0.610, 14432/28000 datapoints
2025-03-06 20:44:32,157 - INFO - training batch 501, loss: 0.478, 16032/28000 datapoints
2025-03-06 20:44:32,276 - INFO - training batch 551, loss: 0.648, 17632/28000 datapoints
2025-03-06 20:44:32,395 - INFO - training batch 601, loss: 0.857, 19232/28000 datapoints
2025-03-06 20:44:32,515 - INFO - training batch 651, loss: 0.289, 20832/28000 datapoints
2025-03-06 20:44:32,637 - INFO - training batch 701, loss: 0.590, 22432/28000 datapoints
2025-03-06 20:44:32,756 - INFO - training batch 751, loss: 0.427, 24032/28000 datapoints
2025-03-06 20:44:32,877 - INFO - training batch 801, loss: 0.483, 25632/28000 datapoints
2025-03-06 20:44:32,997 - INFO - training batch 851, loss: 1.028, 27232/28000 datapoints
2025-03-06 20:44:33,058 - INFO - validation batch 1, loss: 0.381, 32/6976 datapoints
2025-03-06 20:44:33,102 - INFO - validation batch 51, loss: 1.350, 1632/6976 datapoints
2025-03-06 20:44:33,146 - INFO - validation batch 101, loss: 0.405, 3232/6976 datapoints
2025-03-06 20:44:33,189 - INFO - validation batch 151, loss: 0.800, 4832/6976 datapoints
2025-03-06 20:44:33,232 - INFO - validation batch 201, loss: 0.394, 6432/6976 datapoints
2025-03-06 20:44:33,247 - INFO - Epoch 165/800 done.
2025-03-06 20:44:33,248 - INFO - Final validation performance:
Loss: 0.666, top-1 acc: 0.799top-5 acc: 0.799
2025-03-06 20:44:33,248 - INFO - Beginning epoch 166/800
2025-03-06 20:44:33,252 - INFO - training batch 1, loss: 0.793, 32/28000 datapoints
2025-03-06 20:44:33,374 - INFO - training batch 51, loss: 0.540, 1632/28000 datapoints
2025-03-06 20:44:33,495 - INFO - training batch 101, loss: 0.345, 3232/28000 datapoints
2025-03-06 20:44:33,618 - INFO - training batch 151, loss: 1.052, 4832/28000 datapoints
2025-03-06 20:44:33,745 - INFO - training batch 201, loss: 0.456, 6432/28000 datapoints
2025-03-06 20:44:33,866 - INFO - training batch 251, loss: 0.522, 8032/28000 datapoints
2025-03-06 20:44:33,986 - INFO - training batch 301, loss: 0.806, 9632/28000 datapoints
2025-03-06 20:44:34,106 - INFO - training batch 351, loss: 0.640, 11232/28000 datapoints
2025-03-06 20:44:34,226 - INFO - training batch 401, loss: 0.913, 12832/28000 datapoints
2025-03-06 20:44:34,344 - INFO - training batch 451, loss: 0.603, 14432/28000 datapoints
2025-03-06 20:44:34,463 - INFO - training batch 501, loss: 0.473, 16032/28000 datapoints
2025-03-06 20:44:34,584 - INFO - training batch 551, loss: 0.640, 17632/28000 datapoints
2025-03-06 20:44:34,706 - INFO - training batch 601, loss: 0.851, 19232/28000 datapoints
2025-03-06 20:44:34,826 - INFO - training batch 651, loss: 0.281, 20832/28000 datapoints
2025-03-06 20:44:34,951 - INFO - training batch 701, loss: 0.586, 22432/28000 datapoints
2025-03-06 20:44:35,074 - INFO - training batch 751, loss: 0.424, 24032/28000 datapoints
2025-03-06 20:44:35,196 - INFO - training batch 801, loss: 0.478, 25632/28000 datapoints
2025-03-06 20:44:35,315 - INFO - training batch 851, loss: 1.024, 27232/28000 datapoints
2025-03-06 20:44:35,375 - INFO - validation batch 1, loss: 0.375, 32/6976 datapoints
2025-03-06 20:44:35,419 - INFO - validation batch 51, loss: 1.345, 1632/6976 datapoints
2025-03-06 20:44:35,462 - INFO - validation batch 101, loss: 0.398, 3232/6976 datapoints
2025-03-06 20:44:35,505 - INFO - validation batch 151, loss: 0.793, 4832/6976 datapoints
2025-03-06 20:44:35,548 - INFO - validation batch 201, loss: 0.393, 6432/6976 datapoints
2025-03-06 20:44:35,563 - INFO - Epoch 166/800 done.
2025-03-06 20:44:35,564 - INFO - Final validation performance:
Loss: 0.661, top-1 acc: 0.801top-5 acc: 0.801
2025-03-06 20:44:35,564 - INFO - Beginning epoch 167/800
2025-03-06 20:44:35,567 - INFO - training batch 1, loss: 0.788, 32/28000 datapoints
2025-03-06 20:44:35,693 - INFO - training batch 51, loss: 0.530, 1632/28000 datapoints
2025-03-06 20:44:35,818 - INFO - training batch 101, loss: 0.342, 3232/28000 datapoints
2025-03-06 20:44:35,937 - INFO - training batch 151, loss: 1.044, 4832/28000 datapoints
2025-03-06 20:44:36,057 - INFO - training batch 201, loss: 0.450, 6432/28000 datapoints
2025-03-06 20:44:36,179 - INFO - training batch 251, loss: 0.519, 8032/28000 datapoints
2025-03-06 20:44:36,302 - INFO - training batch 301, loss: 0.803, 9632/28000 datapoints
2025-03-06 20:44:36,421 - INFO - training batch 351, loss: 0.639, 11232/28000 datapoints
2025-03-06 20:44:36,539 - INFO - training batch 401, loss: 0.911, 12832/28000 datapoints
2025-03-06 20:44:36,662 - INFO - training batch 451, loss: 0.596, 14432/28000 datapoints
2025-03-06 20:44:36,781 - INFO - training batch 501, loss: 0.467, 16032/28000 datapoints
2025-03-06 20:44:36,901 - INFO - training batch 551, loss: 0.633, 17632/28000 datapoints
2025-03-06 20:44:37,021 - INFO - training batch 601, loss: 0.848, 19232/28000 datapoints
2025-03-06 20:44:37,141 - INFO - training batch 651, loss: 0.274, 20832/28000 datapoints
2025-03-06 20:44:37,274 - INFO - training batch 701, loss: 0.581, 22432/28000 datapoints
2025-03-06 20:44:37,396 - INFO - training batch 751, loss: 0.420, 24032/28000 datapoints
2025-03-06 20:44:37,515 - INFO - training batch 801, loss: 0.473, 25632/28000 datapoints
2025-03-06 20:44:37,654 - INFO - training batch 851, loss: 1.019, 27232/28000 datapoints
2025-03-06 20:44:37,716 - INFO - validation batch 1, loss: 0.369, 32/6976 datapoints
2025-03-06 20:44:37,781 - INFO - validation batch 51, loss: 1.340, 1632/6976 datapoints
2025-03-06 20:44:37,838 - INFO - validation batch 101, loss: 0.391, 3232/6976 datapoints
2025-03-06 20:44:37,886 - INFO - validation batch 151, loss: 0.784, 4832/6976 datapoints
2025-03-06 20:44:37,930 - INFO - validation batch 201, loss: 0.392, 6432/6976 datapoints
2025-03-06 20:44:37,946 - INFO - Epoch 167/800 done.
2025-03-06 20:44:37,946 - INFO - Final validation performance:
Loss: 0.655, top-1 acc: 0.803top-5 acc: 0.803
2025-03-06 20:44:37,946 - INFO - Beginning epoch 168/800
2025-03-06 20:44:37,950 - INFO - training batch 1, loss: 0.783, 32/28000 datapoints
2025-03-06 20:44:38,073 - INFO - training batch 51, loss: 0.520, 1632/28000 datapoints
2025-03-06 20:44:38,196 - INFO - training batch 101, loss: 0.339, 3232/28000 datapoints
2025-03-06 20:44:38,317 - INFO - training batch 151, loss: 1.036, 4832/28000 datapoints
2025-03-06 20:44:38,440 - INFO - training batch 201, loss: 0.444, 6432/28000 datapoints
2025-03-06 20:44:38,559 - INFO - training batch 251, loss: 0.515, 8032/28000 datapoints
2025-03-06 20:44:38,681 - INFO - training batch 301, loss: 0.800, 9632/28000 datapoints
2025-03-06 20:44:38,800 - INFO - training batch 351, loss: 0.641, 11232/28000 datapoints
2025-03-06 20:44:38,924 - INFO - training batch 401, loss: 0.909, 12832/28000 datapoints
2025-03-06 20:44:39,044 - INFO - training batch 451, loss: 0.590, 14432/28000 datapoints
2025-03-06 20:44:39,165 - INFO - training batch 501, loss: 0.461, 16032/28000 datapoints
2025-03-06 20:44:39,287 - INFO - training batch 551, loss: 0.626, 17632/28000 datapoints
2025-03-06 20:44:39,413 - INFO - training batch 601, loss: 0.843, 19232/28000 datapoints
2025-03-06 20:44:39,531 - INFO - training batch 651, loss: 0.266, 20832/28000 datapoints
2025-03-06 20:44:39,651 - INFO - training batch 701, loss: 0.577, 22432/28000 datapoints
2025-03-06 20:44:39,777 - INFO - training batch 751, loss: 0.418, 24032/28000 datapoints
2025-03-06 20:44:39,899 - INFO - training batch 801, loss: 0.468, 25632/28000 datapoints
2025-03-06 20:44:40,024 - INFO - training batch 851, loss: 1.014, 27232/28000 datapoints
2025-03-06 20:44:40,086 - INFO - validation batch 1, loss: 0.363, 32/6976 datapoints
2025-03-06 20:44:40,130 - INFO - validation batch 51, loss: 1.334, 1632/6976 datapoints
2025-03-06 20:44:40,174 - INFO - validation batch 101, loss: 0.385, 3232/6976 datapoints
2025-03-06 20:44:40,219 - INFO - validation batch 151, loss: 0.776, 4832/6976 datapoints
2025-03-06 20:44:40,263 - INFO - validation batch 201, loss: 0.390, 6432/6976 datapoints
2025-03-06 20:44:40,278 - INFO - Epoch 168/800 done.
2025-03-06 20:44:40,278 - INFO - Final validation performance:
Loss: 0.650, top-1 acc: 0.805top-5 acc: 0.805
2025-03-06 20:44:40,279 - INFO - Beginning epoch 169/800
2025-03-06 20:44:40,282 - INFO - training batch 1, loss: 0.777, 32/28000 datapoints
2025-03-06 20:44:40,403 - INFO - training batch 51, loss: 0.511, 1632/28000 datapoints
2025-03-06 20:44:40,522 - INFO - training batch 101, loss: 0.336, 3232/28000 datapoints
2025-03-06 20:44:40,643 - INFO - training batch 151, loss: 1.028, 4832/28000 datapoints
2025-03-06 20:44:40,764 - INFO - training batch 201, loss: 0.439, 6432/28000 datapoints
2025-03-06 20:44:40,884 - INFO - training batch 251, loss: 0.512, 8032/28000 datapoints
2025-03-06 20:44:41,003 - INFO - training batch 301, loss: 0.798, 9632/28000 datapoints
2025-03-06 20:44:41,123 - INFO - training batch 351, loss: 0.640, 11232/28000 datapoints
2025-03-06 20:44:41,245 - INFO - training batch 401, loss: 0.906, 12832/28000 datapoints
2025-03-06 20:44:41,366 - INFO - training batch 451, loss: 0.583, 14432/28000 datapoints
2025-03-06 20:44:41,488 - INFO - training batch 501, loss: 0.456, 16032/28000 datapoints
2025-03-06 20:44:41,605 - INFO - training batch 551, loss: 0.619, 17632/28000 datapoints
2025-03-06 20:44:41,728 - INFO - training batch 601, loss: 0.840, 19232/28000 datapoints
2025-03-06 20:44:41,852 - INFO - training batch 651, loss: 0.259, 20832/28000 datapoints
2025-03-06 20:44:41,975 - INFO - training batch 701, loss: 0.573, 22432/28000 datapoints
2025-03-06 20:44:42,094 - INFO - training batch 751, loss: 0.415, 24032/28000 datapoints
2025-03-06 20:44:42,214 - INFO - training batch 801, loss: 0.463, 25632/28000 datapoints
2025-03-06 20:44:42,333 - INFO - training batch 851, loss: 1.009, 27232/28000 datapoints
2025-03-06 20:44:42,391 - INFO - validation batch 1, loss: 0.357, 32/6976 datapoints
2025-03-06 20:44:42,435 - INFO - validation batch 51, loss: 1.330, 1632/6976 datapoints
2025-03-06 20:44:42,479 - INFO - validation batch 101, loss: 0.379, 3232/6976 datapoints
2025-03-06 20:44:42,522 - INFO - validation batch 151, loss: 0.768, 4832/6976 datapoints
2025-03-06 20:44:42,567 - INFO - validation batch 201, loss: 0.389, 6432/6976 datapoints
2025-03-06 20:44:42,582 - INFO - Epoch 169/800 done.
2025-03-06 20:44:42,582 - INFO - Final validation performance:
Loss: 0.645, top-1 acc: 0.807top-5 acc: 0.807
2025-03-06 20:44:42,583 - INFO - Beginning epoch 170/800
2025-03-06 20:44:42,586 - INFO - training batch 1, loss: 0.770, 32/28000 datapoints
2025-03-06 20:44:42,712 - INFO - training batch 51, loss: 0.501, 1632/28000 datapoints
2025-03-06 20:44:42,831 - INFO - training batch 101, loss: 0.332, 3232/28000 datapoints
2025-03-06 20:44:42,953 - INFO - training batch 151, loss: 1.021, 4832/28000 datapoints
2025-03-06 20:44:43,074 - INFO - training batch 201, loss: 0.434, 6432/28000 datapoints
2025-03-06 20:44:43,193 - INFO - training batch 251, loss: 0.509, 8032/28000 datapoints
2025-03-06 20:44:43,331 - INFO - training batch 301, loss: 0.796, 9632/28000 datapoints
2025-03-06 20:44:43,452 - INFO - training batch 351, loss: 0.641, 11232/28000 datapoints
2025-03-06 20:44:43,570 - INFO - training batch 401, loss: 0.904, 12832/28000 datapoints
2025-03-06 20:44:43,699 - INFO - training batch 451, loss: 0.575, 14432/28000 datapoints
2025-03-06 20:44:43,826 - INFO - training batch 501, loss: 0.450, 16032/28000 datapoints
2025-03-06 20:44:43,950 - INFO - training batch 551, loss: 0.612, 17632/28000 datapoints
2025-03-06 20:44:44,071 - INFO - training batch 601, loss: 0.835, 19232/28000 datapoints
2025-03-06 20:44:44,193 - INFO - training batch 651, loss: 0.252, 20832/28000 datapoints
2025-03-06 20:44:44,314 - INFO - training batch 701, loss: 0.568, 22432/28000 datapoints
2025-03-06 20:44:44,432 - INFO - training batch 751, loss: 0.414, 24032/28000 datapoints
2025-03-06 20:44:44,551 - INFO - training batch 801, loss: 0.458, 25632/28000 datapoints
2025-03-06 20:44:44,670 - INFO - training batch 851, loss: 1.004, 27232/28000 datapoints
2025-03-06 20:44:44,731 - INFO - validation batch 1, loss: 0.351, 32/6976 datapoints
2025-03-06 20:44:44,774 - INFO - validation batch 51, loss: 1.325, 1632/6976 datapoints
2025-03-06 20:44:44,817 - INFO - validation batch 101, loss: 0.372, 3232/6976 datapoints
2025-03-06 20:44:44,862 - INFO - validation batch 151, loss: 0.759, 4832/6976 datapoints
2025-03-06 20:44:44,906 - INFO - validation batch 201, loss: 0.387, 6432/6976 datapoints
2025-03-06 20:44:44,926 - INFO - Epoch 170/800 done.
2025-03-06 20:44:44,926 - INFO - Final validation performance:
Loss: 0.639, top-1 acc: 0.808top-5 acc: 0.808
2025-03-06 20:44:44,926 - INFO - Beginning epoch 171/800
2025-03-06 20:44:44,930 - INFO - training batch 1, loss: 0.764, 32/28000 datapoints
2025-03-06 20:44:45,052 - INFO - training batch 51, loss: 0.492, 1632/28000 datapoints
2025-03-06 20:44:45,179 - INFO - training batch 101, loss: 0.329, 3232/28000 datapoints
2025-03-06 20:44:45,306 - INFO - training batch 151, loss: 1.013, 4832/28000 datapoints
2025-03-06 20:44:45,428 - INFO - training batch 201, loss: 0.428, 6432/28000 datapoints
2025-03-06 20:44:45,555 - INFO - training batch 251, loss: 0.505, 8032/28000 datapoints
2025-03-06 20:44:45,741 - INFO - training batch 301, loss: 0.794, 9632/28000 datapoints
2025-03-06 20:44:45,871 - INFO - training batch 351, loss: 0.641, 11232/28000 datapoints
2025-03-06 20:44:45,995 - INFO - training batch 401, loss: 0.902, 12832/28000 datapoints
2025-03-06 20:44:46,119 - INFO - training batch 451, loss: 0.568, 14432/28000 datapoints
2025-03-06 20:44:46,246 - INFO - training batch 501, loss: 0.445, 16032/28000 datapoints
2025-03-06 20:44:46,375 - INFO - training batch 551, loss: 0.605, 17632/28000 datapoints
2025-03-06 20:44:46,499 - INFO - training batch 601, loss: 0.831, 19232/28000 datapoints
2025-03-06 20:44:46,622 - INFO - training batch 651, loss: 0.245, 20832/28000 datapoints
2025-03-06 20:44:46,747 - INFO - training batch 701, loss: 0.564, 22432/28000 datapoints
2025-03-06 20:44:46,872 - INFO - training batch 751, loss: 0.413, 24032/28000 datapoints
2025-03-06 20:44:46,997 - INFO - training batch 801, loss: 0.453, 25632/28000 datapoints
2025-03-06 20:44:47,120 - INFO - training batch 851, loss: 0.999, 27232/28000 datapoints
2025-03-06 20:44:47,185 - INFO - validation batch 1, loss: 0.345, 32/6976 datapoints
2025-03-06 20:44:47,231 - INFO - validation batch 51, loss: 1.320, 1632/6976 datapoints
2025-03-06 20:44:47,281 - INFO - validation batch 101, loss: 0.367, 3232/6976 datapoints
2025-03-06 20:44:47,342 - INFO - validation batch 151, loss: 0.751, 4832/6976 datapoints
2025-03-06 20:44:47,407 - INFO - validation batch 201, loss: 0.386, 6432/6976 datapoints
2025-03-06 20:44:47,425 - INFO - Epoch 171/800 done.
2025-03-06 20:44:47,425 - INFO - Final validation performance:
Loss: 0.634, top-1 acc: 0.810top-5 acc: 0.810
2025-03-06 20:44:47,426 - INFO - Beginning epoch 172/800
2025-03-06 20:44:47,430 - INFO - training batch 1, loss: 0.757, 32/28000 datapoints
2025-03-06 20:44:47,561 - INFO - training batch 51, loss: 0.483, 1632/28000 datapoints
2025-03-06 20:44:47,683 - INFO - training batch 101, loss: 0.326, 3232/28000 datapoints
2025-03-06 20:44:47,810 - INFO - training batch 151, loss: 1.007, 4832/28000 datapoints
2025-03-06 20:44:47,960 - INFO - training batch 201, loss: 0.423, 6432/28000 datapoints
2025-03-06 20:44:48,081 - INFO - training batch 251, loss: 0.503, 8032/28000 datapoints
2025-03-06 20:44:48,200 - INFO - training batch 301, loss: 0.792, 9632/28000 datapoints
2025-03-06 20:44:48,323 - INFO - training batch 351, loss: 0.641, 11232/28000 datapoints
2025-03-06 20:44:48,444 - INFO - training batch 401, loss: 0.900, 12832/28000 datapoints
2025-03-06 20:44:48,563 - INFO - training batch 451, loss: 0.560, 14432/28000 datapoints
2025-03-06 20:44:48,686 - INFO - training batch 501, loss: 0.440, 16032/28000 datapoints
2025-03-06 20:44:48,814 - INFO - training batch 551, loss: 0.599, 17632/28000 datapoints
2025-03-06 20:44:48,935 - INFO - training batch 601, loss: 0.827, 19232/28000 datapoints
2025-03-06 20:44:49,056 - INFO - training batch 651, loss: 0.238, 20832/28000 datapoints
2025-03-06 20:44:49,176 - INFO - training batch 701, loss: 0.559, 22432/28000 datapoints
2025-03-06 20:44:49,297 - INFO - training batch 751, loss: 0.412, 24032/28000 datapoints
2025-03-06 20:44:49,431 - INFO - training batch 801, loss: 0.449, 25632/28000 datapoints
2025-03-06 20:44:49,554 - INFO - training batch 851, loss: 0.995, 27232/28000 datapoints
2025-03-06 20:44:49,613 - INFO - validation batch 1, loss: 0.340, 32/6976 datapoints
2025-03-06 20:44:49,660 - INFO - validation batch 51, loss: 1.317, 1632/6976 datapoints
2025-03-06 20:44:49,704 - INFO - validation batch 101, loss: 0.361, 3232/6976 datapoints
2025-03-06 20:44:49,747 - INFO - validation batch 151, loss: 0.745, 4832/6976 datapoints
2025-03-06 20:44:49,795 - INFO - validation batch 201, loss: 0.385, 6432/6976 datapoints
2025-03-06 20:44:49,812 - INFO - Epoch 172/800 done.
2025-03-06 20:44:49,812 - INFO - Final validation performance:
Loss: 0.629, top-1 acc: 0.812top-5 acc: 0.812
2025-03-06 20:44:49,813 - INFO - Beginning epoch 173/800
2025-03-06 20:44:49,816 - INFO - training batch 1, loss: 0.751, 32/28000 datapoints
2025-03-06 20:44:49,944 - INFO - training batch 51, loss: 0.475, 1632/28000 datapoints
2025-03-06 20:44:50,064 - INFO - training batch 101, loss: 0.324, 3232/28000 datapoints
2025-03-06 20:44:50,185 - INFO - training batch 151, loss: 1.001, 4832/28000 datapoints
2025-03-06 20:44:50,309 - INFO - training batch 201, loss: 0.417, 6432/28000 datapoints
2025-03-06 20:44:50,428 - INFO - training batch 251, loss: 0.500, 8032/28000 datapoints
2025-03-06 20:44:50,548 - INFO - training batch 301, loss: 0.790, 9632/28000 datapoints
2025-03-06 20:44:50,670 - INFO - training batch 351, loss: 0.639, 11232/28000 datapoints
2025-03-06 20:44:50,789 - INFO - training batch 401, loss: 0.898, 12832/28000 datapoints
2025-03-06 20:44:50,911 - INFO - training batch 451, loss: 0.553, 14432/28000 datapoints
2025-03-06 20:44:51,031 - INFO - training batch 501, loss: 0.435, 16032/28000 datapoints
2025-03-06 20:44:51,152 - INFO - training batch 551, loss: 0.593, 17632/28000 datapoints
2025-03-06 20:44:51,272 - INFO - training batch 601, loss: 0.823, 19232/28000 datapoints
2025-03-06 20:44:51,392 - INFO - training batch 651, loss: 0.232, 20832/28000 datapoints
2025-03-06 20:44:51,512 - INFO - training batch 701, loss: 0.555, 22432/28000 datapoints
2025-03-06 20:44:51,631 - INFO - training batch 751, loss: 0.410, 24032/28000 datapoints
2025-03-06 20:44:51,752 - INFO - training batch 801, loss: 0.445, 25632/28000 datapoints
2025-03-06 20:44:51,878 - INFO - training batch 851, loss: 0.990, 27232/28000 datapoints
2025-03-06 20:44:51,938 - INFO - validation batch 1, loss: 0.334, 32/6976 datapoints
2025-03-06 20:44:51,983 - INFO - validation batch 51, loss: 1.312, 1632/6976 datapoints
2025-03-06 20:44:52,027 - INFO - validation batch 101, loss: 0.355, 3232/6976 datapoints
2025-03-06 20:44:52,070 - INFO - validation batch 151, loss: 0.736, 4832/6976 datapoints
2025-03-06 20:44:52,113 - INFO - validation batch 201, loss: 0.384, 6432/6976 datapoints
2025-03-06 20:44:52,128 - INFO - Epoch 173/800 done.
2025-03-06 20:44:52,129 - INFO - Final validation performance:
Loss: 0.624, top-1 acc: 0.814top-5 acc: 0.814
2025-03-06 20:44:52,129 - INFO - Beginning epoch 174/800
2025-03-06 20:44:52,132 - INFO - training batch 1, loss: 0.744, 32/28000 datapoints
2025-03-06 20:44:52,253 - INFO - training batch 51, loss: 0.467, 1632/28000 datapoints
2025-03-06 20:44:52,376 - INFO - training batch 101, loss: 0.321, 3232/28000 datapoints
2025-03-06 20:44:52,498 - INFO - training batch 151, loss: 0.994, 4832/28000 datapoints
2025-03-06 20:44:52,617 - INFO - training batch 201, loss: 0.412, 6432/28000 datapoints
2025-03-06 20:44:52,740 - INFO - training batch 251, loss: 0.496, 8032/28000 datapoints
2025-03-06 20:44:52,860 - INFO - training batch 301, loss: 0.787, 9632/28000 datapoints
2025-03-06 20:44:52,982 - INFO - training batch 351, loss: 0.638, 11232/28000 datapoints
2025-03-06 20:44:53,101 - INFO - training batch 401, loss: 0.896, 12832/28000 datapoints
2025-03-06 20:44:53,220 - INFO - training batch 451, loss: 0.545, 14432/28000 datapoints
2025-03-06 20:44:53,342 - INFO - training batch 501, loss: 0.430, 16032/28000 datapoints
2025-03-06 20:44:53,463 - INFO - training batch 551, loss: 0.586, 17632/28000 datapoints
2025-03-06 20:44:53,582 - INFO - training batch 601, loss: 0.819, 19232/28000 datapoints
2025-03-06 20:44:53,706 - INFO - training batch 651, loss: 0.226, 20832/28000 datapoints
2025-03-06 20:44:53,848 - INFO - training batch 701, loss: 0.550, 22432/28000 datapoints
2025-03-06 20:44:53,969 - INFO - training batch 751, loss: 0.408, 24032/28000 datapoints
2025-03-06 20:44:54,090 - INFO - training batch 801, loss: 0.441, 25632/28000 datapoints
2025-03-06 20:44:54,209 - INFO - training batch 851, loss: 0.986, 27232/28000 datapoints
2025-03-06 20:44:54,269 - INFO - validation batch 1, loss: 0.329, 32/6976 datapoints
2025-03-06 20:44:54,314 - INFO - validation batch 51, loss: 1.309, 1632/6976 datapoints
2025-03-06 20:44:54,358 - INFO - validation batch 101, loss: 0.349, 3232/6976 datapoints
2025-03-06 20:44:54,402 - INFO - validation batch 151, loss: 0.728, 4832/6976 datapoints
2025-03-06 20:44:54,445 - INFO - validation batch 201, loss: 0.383, 6432/6976 datapoints
2025-03-06 20:44:54,461 - INFO - Epoch 174/800 done.
2025-03-06 20:44:54,461 - INFO - Final validation performance:
Loss: 0.619, top-1 acc: 0.816top-5 acc: 0.816
2025-03-06 20:44:54,461 - INFO - Beginning epoch 175/800
2025-03-06 20:44:54,465 - INFO - training batch 1, loss: 0.738, 32/28000 datapoints
2025-03-06 20:44:54,585 - INFO - training batch 51, loss: 0.459, 1632/28000 datapoints
2025-03-06 20:44:54,706 - INFO - training batch 101, loss: 0.318, 3232/28000 datapoints
2025-03-06 20:44:54,825 - INFO - training batch 151, loss: 0.988, 4832/28000 datapoints
2025-03-06 20:44:54,952 - INFO - training batch 201, loss: 0.406, 6432/28000 datapoints
2025-03-06 20:44:55,073 - INFO - training batch 251, loss: 0.493, 8032/28000 datapoints
2025-03-06 20:44:55,193 - INFO - training batch 301, loss: 0.785, 9632/28000 datapoints
2025-03-06 20:44:55,314 - INFO - training batch 351, loss: 0.636, 11232/28000 datapoints
2025-03-06 20:44:55,435 - INFO - training batch 401, loss: 0.894, 12832/28000 datapoints
2025-03-06 20:44:55,558 - INFO - training batch 451, loss: 0.538, 14432/28000 datapoints
2025-03-06 20:44:55,682 - INFO - training batch 501, loss: 0.425, 16032/28000 datapoints
2025-03-06 20:44:55,801 - INFO - training batch 551, loss: 0.581, 17632/28000 datapoints
2025-03-06 20:44:55,924 - INFO - training batch 601, loss: 0.815, 19232/28000 datapoints
2025-03-06 20:44:56,054 - INFO - training batch 651, loss: 0.221, 20832/28000 datapoints
2025-03-06 20:44:56,175 - INFO - training batch 701, loss: 0.547, 22432/28000 datapoints
2025-03-06 20:44:56,295 - INFO - training batch 751, loss: 0.406, 24032/28000 datapoints
2025-03-06 20:44:56,415 - INFO - training batch 801, loss: 0.437, 25632/28000 datapoints
2025-03-06 20:44:56,535 - INFO - training batch 851, loss: 0.982, 27232/28000 datapoints
2025-03-06 20:44:56,594 - INFO - validation batch 1, loss: 0.323, 32/6976 datapoints
2025-03-06 20:44:56,639 - INFO - validation batch 51, loss: 1.305, 1632/6976 datapoints
2025-03-06 20:44:56,682 - INFO - validation batch 101, loss: 0.344, 3232/6976 datapoints
2025-03-06 20:44:56,727 - INFO - validation batch 151, loss: 0.721, 4832/6976 datapoints
2025-03-06 20:44:56,771 - INFO - validation batch 201, loss: 0.381, 6432/6976 datapoints
2025-03-06 20:44:56,788 - INFO - Epoch 175/800 done.
2025-03-06 20:44:56,788 - INFO - Final validation performance:
Loss: 0.615, top-1 acc: 0.817top-5 acc: 0.817
2025-03-06 20:44:56,789 - INFO - Beginning epoch 176/800
2025-03-06 20:44:56,792 - INFO - training batch 1, loss: 0.732, 32/28000 datapoints
2025-03-06 20:44:56,917 - INFO - training batch 51, loss: 0.451, 1632/28000 datapoints
2025-03-06 20:44:57,044 - INFO - training batch 101, loss: 0.315, 3232/28000 datapoints
2025-03-06 20:44:57,165 - INFO - training batch 151, loss: 0.982, 4832/28000 datapoints
2025-03-06 20:44:57,286 - INFO - training batch 201, loss: 0.401, 6432/28000 datapoints
2025-03-06 20:44:57,409 - INFO - training batch 251, loss: 0.490, 8032/28000 datapoints
2025-03-06 20:44:57,529 - INFO - training batch 301, loss: 0.783, 9632/28000 datapoints
2025-03-06 20:44:57,649 - INFO - training batch 351, loss: 0.635, 11232/28000 datapoints
2025-03-06 20:44:57,769 - INFO - training batch 401, loss: 0.892, 12832/28000 datapoints
2025-03-06 20:44:57,896 - INFO - training batch 451, loss: 0.531, 14432/28000 datapoints
2025-03-06 20:44:58,049 - INFO - training batch 501, loss: 0.420, 16032/28000 datapoints
2025-03-06 20:44:58,171 - INFO - training batch 551, loss: 0.575, 17632/28000 datapoints
2025-03-06 20:44:58,294 - INFO - training batch 601, loss: 0.812, 19232/28000 datapoints
2025-03-06 20:44:58,418 - INFO - training batch 651, loss: 0.215, 20832/28000 datapoints
2025-03-06 20:44:58,542 - INFO - training batch 701, loss: 0.542, 22432/28000 datapoints
2025-03-06 20:44:58,665 - INFO - training batch 751, loss: 0.404, 24032/28000 datapoints
2025-03-06 20:44:58,783 - INFO - training batch 801, loss: 0.434, 25632/28000 datapoints
2025-03-06 20:44:58,905 - INFO - training batch 851, loss: 0.977, 27232/28000 datapoints
2025-03-06 20:44:58,964 - INFO - validation batch 1, loss: 0.318, 32/6976 datapoints
2025-03-06 20:44:59,009 - INFO - validation batch 51, loss: 1.302, 1632/6976 datapoints
2025-03-06 20:44:59,053 - INFO - validation batch 101, loss: 0.338, 3232/6976 datapoints
2025-03-06 20:44:59,097 - INFO - validation batch 151, loss: 0.713, 4832/6976 datapoints
2025-03-06 20:44:59,140 - INFO - validation batch 201, loss: 0.380, 6432/6976 datapoints
2025-03-06 20:44:59,155 - INFO - Epoch 176/800 done.
2025-03-06 20:44:59,155 - INFO - Final validation performance:
Loss: 0.610, top-1 acc: 0.818top-5 acc: 0.818
2025-03-06 20:44:59,156 - INFO - Beginning epoch 177/800
2025-03-06 20:44:59,159 - INFO - training batch 1, loss: 0.725, 32/28000 datapoints
2025-03-06 20:44:59,280 - INFO - training batch 51, loss: 0.444, 1632/28000 datapoints
2025-03-06 20:44:59,407 - INFO - training batch 101, loss: 0.312, 3232/28000 datapoints
2025-03-06 20:44:59,527 - INFO - training batch 151, loss: 0.975, 4832/28000 datapoints
2025-03-06 20:44:59,649 - INFO - training batch 201, loss: 0.395, 6432/28000 datapoints
2025-03-06 20:44:59,768 - INFO - training batch 251, loss: 0.487, 8032/28000 datapoints
2025-03-06 20:44:59,892 - INFO - training batch 301, loss: 0.781, 9632/28000 datapoints
2025-03-06 20:45:00,015 - INFO - training batch 351, loss: 0.633, 11232/28000 datapoints
2025-03-06 20:45:00,135 - INFO - training batch 401, loss: 0.890, 12832/28000 datapoints
2025-03-06 20:45:00,254 - INFO - training batch 451, loss: 0.524, 14432/28000 datapoints
2025-03-06 20:45:00,376 - INFO - training batch 501, loss: 0.415, 16032/28000 datapoints
2025-03-06 20:45:00,497 - INFO - training batch 551, loss: 0.569, 17632/28000 datapoints
2025-03-06 20:45:00,617 - INFO - training batch 601, loss: 0.808, 19232/28000 datapoints
2025-03-06 20:45:00,739 - INFO - training batch 651, loss: 0.210, 20832/28000 datapoints
2025-03-06 20:45:00,858 - INFO - training batch 701, loss: 0.538, 22432/28000 datapoints
2025-03-06 20:45:00,980 - INFO - training batch 751, loss: 0.402, 24032/28000 datapoints
2025-03-06 20:45:01,099 - INFO - training batch 801, loss: 0.430, 25632/28000 datapoints
2025-03-06 20:45:01,220 - INFO - training batch 851, loss: 0.973, 27232/28000 datapoints
2025-03-06 20:45:01,282 - INFO - validation batch 1, loss: 0.312, 32/6976 datapoints
2025-03-06 20:45:01,326 - INFO - validation batch 51, loss: 1.299, 1632/6976 datapoints
2025-03-06 20:45:01,370 - INFO - validation batch 101, loss: 0.333, 3232/6976 datapoints
2025-03-06 20:45:01,413 - INFO - validation batch 151, loss: 0.707, 4832/6976 datapoints
2025-03-06 20:45:01,458 - INFO - validation batch 201, loss: 0.380, 6432/6976 datapoints
2025-03-06 20:45:01,472 - INFO - Epoch 177/800 done.
2025-03-06 20:45:01,473 - INFO - Final validation performance:
Loss: 0.606, top-1 acc: 0.819top-5 acc: 0.819
2025-03-06 20:45:01,473 - INFO - Beginning epoch 178/800
2025-03-06 20:45:01,477 - INFO - training batch 1, loss: 0.719, 32/28000 datapoints
2025-03-06 20:45:01,596 - INFO - training batch 51, loss: 0.437, 1632/28000 datapoints
2025-03-06 20:45:01,736 - INFO - training batch 101, loss: 0.310, 3232/28000 datapoints
2025-03-06 20:45:01,863 - INFO - training batch 151, loss: 0.968, 4832/28000 datapoints
2025-03-06 20:45:01,985 - INFO - training batch 201, loss: 0.390, 6432/28000 datapoints
2025-03-06 20:45:02,106 - INFO - training batch 251, loss: 0.485, 8032/28000 datapoints
2025-03-06 20:45:02,230 - INFO - training batch 301, loss: 0.778, 9632/28000 datapoints
2025-03-06 20:45:02,354 - INFO - training batch 351, loss: 0.631, 11232/28000 datapoints
2025-03-06 20:45:02,476 - INFO - training batch 401, loss: 0.887, 12832/28000 datapoints
2025-03-06 20:45:02,595 - INFO - training batch 451, loss: 0.517, 14432/28000 datapoints
2025-03-06 20:45:02,719 - INFO - training batch 501, loss: 0.410, 16032/28000 datapoints
2025-03-06 20:45:02,839 - INFO - training batch 551, loss: 0.564, 17632/28000 datapoints
2025-03-06 20:45:02,959 - INFO - training batch 601, loss: 0.805, 19232/28000 datapoints
2025-03-06 20:45:03,084 - INFO - training batch 651, loss: 0.205, 20832/28000 datapoints
2025-03-06 20:45:03,203 - INFO - training batch 701, loss: 0.534, 22432/28000 datapoints
2025-03-06 20:45:03,322 - INFO - training batch 751, loss: 0.400, 24032/28000 datapoints
2025-03-06 20:45:03,441 - INFO - training batch 801, loss: 0.427, 25632/28000 datapoints
2025-03-06 20:45:03,561 - INFO - training batch 851, loss: 0.967, 27232/28000 datapoints
2025-03-06 20:45:03,620 - INFO - validation batch 1, loss: 0.308, 32/6976 datapoints
2025-03-06 20:45:03,667 - INFO - validation batch 51, loss: 1.296, 1632/6976 datapoints
2025-03-06 20:45:03,712 - INFO - validation batch 101, loss: 0.328, 3232/6976 datapoints
2025-03-06 20:45:03,755 - INFO - validation batch 151, loss: 0.701, 4832/6976 datapoints
2025-03-06 20:45:03,799 - INFO - validation batch 201, loss: 0.379, 6432/6976 datapoints
2025-03-06 20:45:03,813 - INFO - Epoch 178/800 done.
2025-03-06 20:45:03,813 - INFO - Final validation performance:
Loss: 0.602, top-1 acc: 0.822top-5 acc: 0.822
2025-03-06 20:45:03,813 - INFO - Beginning epoch 179/800
2025-03-06 20:45:03,817 - INFO - training batch 1, loss: 0.712, 32/28000 datapoints
2025-03-06 20:45:03,943 - INFO - training batch 51, loss: 0.430, 1632/28000 datapoints
2025-03-06 20:45:04,066 - INFO - training batch 101, loss: 0.307, 3232/28000 datapoints
2025-03-06 20:45:04,186 - INFO - training batch 151, loss: 0.962, 4832/28000 datapoints
2025-03-06 20:45:04,306 - INFO - training batch 201, loss: 0.385, 6432/28000 datapoints
2025-03-06 20:45:04,425 - INFO - training batch 251, loss: 0.482, 8032/28000 datapoints
2025-03-06 20:45:04,546 - INFO - training batch 301, loss: 0.777, 9632/28000 datapoints
2025-03-06 20:45:04,667 - INFO - training batch 351, loss: 0.631, 11232/28000 datapoints
2025-03-06 20:45:04,786 - INFO - training batch 401, loss: 0.884, 12832/28000 datapoints
2025-03-06 20:45:04,908 - INFO - training batch 451, loss: 0.510, 14432/28000 datapoints
2025-03-06 20:45:05,035 - INFO - training batch 501, loss: 0.406, 16032/28000 datapoints
2025-03-06 20:45:05,164 - INFO - training batch 551, loss: 0.559, 17632/28000 datapoints
2025-03-06 20:45:05,289 - INFO - training batch 601, loss: 0.802, 19232/28000 datapoints
2025-03-06 20:45:05,415 - INFO - training batch 651, loss: 0.199, 20832/28000 datapoints
2025-03-06 20:45:05,541 - INFO - training batch 701, loss: 0.530, 22432/28000 datapoints
2025-03-06 20:45:05,669 - INFO - training batch 751, loss: 0.399, 24032/28000 datapoints
2025-03-06 20:45:05,794 - INFO - training batch 801, loss: 0.423, 25632/28000 datapoints
2025-03-06 20:45:05,921 - INFO - training batch 851, loss: 0.962, 27232/28000 datapoints
2025-03-06 20:45:05,984 - INFO - validation batch 1, loss: 0.303, 32/6976 datapoints
2025-03-06 20:45:06,031 - INFO - validation batch 51, loss: 1.292, 1632/6976 datapoints
2025-03-06 20:45:06,076 - INFO - validation batch 101, loss: 0.323, 3232/6976 datapoints
2025-03-06 20:45:06,120 - INFO - validation batch 151, loss: 0.693, 4832/6976 datapoints
2025-03-06 20:45:06,165 - INFO - validation batch 201, loss: 0.378, 6432/6976 datapoints
2025-03-06 20:45:06,180 - INFO - Epoch 179/800 done.
2025-03-06 20:45:06,180 - INFO - Final validation performance:
Loss: 0.598, top-1 acc: 0.824top-5 acc: 0.824
2025-03-06 20:45:06,181 - INFO - Beginning epoch 180/800
2025-03-06 20:45:06,185 - INFO - training batch 1, loss: 0.705, 32/28000 datapoints
2025-03-06 20:45:06,306 - INFO - training batch 51, loss: 0.424, 1632/28000 datapoints
2025-03-06 20:45:06,428 - INFO - training batch 101, loss: 0.305, 3232/28000 datapoints
2025-03-06 20:45:06,551 - INFO - training batch 151, loss: 0.957, 4832/28000 datapoints
2025-03-06 20:45:06,672 - INFO - training batch 201, loss: 0.380, 6432/28000 datapoints
2025-03-06 20:45:06,793 - INFO - training batch 251, loss: 0.479, 8032/28000 datapoints
2025-03-06 20:45:06,914 - INFO - training batch 301, loss: 0.775, 9632/28000 datapoints
2025-03-06 20:45:07,035 - INFO - training batch 351, loss: 0.630, 11232/28000 datapoints
2025-03-06 20:45:07,154 - INFO - training batch 401, loss: 0.880, 12832/28000 datapoints
2025-03-06 20:45:07,274 - INFO - training batch 451, loss: 0.504, 14432/28000 datapoints
2025-03-06 20:45:07,393 - INFO - training batch 501, loss: 0.401, 16032/28000 datapoints
2025-03-06 20:45:07,514 - INFO - training batch 551, loss: 0.554, 17632/28000 datapoints
2025-03-06 20:45:07,637 - INFO - training batch 601, loss: 0.799, 19232/28000 datapoints
2025-03-06 20:45:07,769 - INFO - training batch 651, loss: 0.194, 20832/28000 datapoints
2025-03-06 20:45:07,896 - INFO - training batch 701, loss: 0.527, 22432/28000 datapoints
2025-03-06 20:45:08,015 - INFO - training batch 751, loss: 0.397, 24032/28000 datapoints
2025-03-06 20:45:08,171 - INFO - training batch 801, loss: 0.419, 25632/28000 datapoints
2025-03-06 20:45:08,294 - INFO - training batch 851, loss: 0.957, 27232/28000 datapoints
2025-03-06 20:45:08,357 - INFO - validation batch 1, loss: 0.298, 32/6976 datapoints
2025-03-06 20:45:08,402 - INFO - validation batch 51, loss: 1.289, 1632/6976 datapoints
2025-03-06 20:45:08,447 - INFO - validation batch 101, loss: 0.318, 3232/6976 datapoints
2025-03-06 20:45:08,491 - INFO - validation batch 151, loss: 0.687, 4832/6976 datapoints
2025-03-06 20:45:08,540 - INFO - validation batch 201, loss: 0.376, 6432/6976 datapoints
2025-03-06 20:45:08,555 - INFO - Epoch 180/800 done.
2025-03-06 20:45:08,556 - INFO - Final validation performance:
Loss: 0.594, top-1 acc: 0.825top-5 acc: 0.825
2025-03-06 20:45:08,556 - INFO - Beginning epoch 181/800
2025-03-06 20:45:08,560 - INFO - training batch 1, loss: 0.699, 32/28000 datapoints
2025-03-06 20:45:08,686 - INFO - training batch 51, loss: 0.417, 1632/28000 datapoints
2025-03-06 20:45:08,815 - INFO - training batch 101, loss: 0.302, 3232/28000 datapoints
2025-03-06 20:45:08,938 - INFO - training batch 151, loss: 0.951, 4832/28000 datapoints
2025-03-06 20:45:09,061 - INFO - training batch 201, loss: 0.375, 6432/28000 datapoints
2025-03-06 20:45:09,181 - INFO - training batch 251, loss: 0.477, 8032/28000 datapoints
2025-03-06 20:45:09,301 - INFO - training batch 301, loss: 0.773, 9632/28000 datapoints
2025-03-06 20:45:09,420 - INFO - training batch 351, loss: 0.630, 11232/28000 datapoints
2025-03-06 20:45:09,544 - INFO - training batch 401, loss: 0.877, 12832/28000 datapoints
2025-03-06 20:45:09,667 - INFO - training batch 451, loss: 0.497, 14432/28000 datapoints
2025-03-06 20:45:09,784 - INFO - training batch 501, loss: 0.396, 16032/28000 datapoints
2025-03-06 20:45:09,907 - INFO - training batch 551, loss: 0.549, 17632/28000 datapoints
2025-03-06 20:45:10,028 - INFO - training batch 601, loss: 0.796, 19232/28000 datapoints
2025-03-06 20:45:10,151 - INFO - training batch 651, loss: 0.190, 20832/28000 datapoints
2025-03-06 20:45:10,273 - INFO - training batch 701, loss: 0.523, 22432/28000 datapoints
2025-03-06 20:45:10,392 - INFO - training batch 751, loss: 0.395, 24032/28000 datapoints
2025-03-06 20:45:10,512 - INFO - training batch 801, loss: 0.415, 25632/28000 datapoints
2025-03-06 20:45:10,634 - INFO - training batch 851, loss: 0.951, 27232/28000 datapoints
2025-03-06 20:45:10,694 - INFO - validation batch 1, loss: 0.293, 32/6976 datapoints
2025-03-06 20:45:10,736 - INFO - validation batch 51, loss: 1.291, 1632/6976 datapoints
2025-03-06 20:45:10,779 - INFO - validation batch 101, loss: 0.314, 3232/6976 datapoints
2025-03-06 20:45:10,822 - INFO - validation batch 151, loss: 0.690, 4832/6976 datapoints
2025-03-06 20:45:10,867 - INFO - validation batch 201, loss: 0.376, 6432/6976 datapoints
2025-03-06 20:45:10,882 - INFO - Epoch 181/800 done.
2025-03-06 20:45:10,882 - INFO - Final validation performance:
Loss: 0.593, top-1 acc: 0.826top-5 acc: 0.826
2025-03-06 20:45:10,883 - INFO - Beginning epoch 182/800
2025-03-06 20:45:10,886 - INFO - training batch 1, loss: 0.693, 32/28000 datapoints
2025-03-06 20:45:11,010 - INFO - training batch 51, loss: 0.410, 1632/28000 datapoints
2025-03-06 20:45:11,133 - INFO - training batch 101, loss: 0.300, 3232/28000 datapoints
2025-03-06 20:45:11,254 - INFO - training batch 151, loss: 0.947, 4832/28000 datapoints
2025-03-06 20:45:11,375 - INFO - training batch 201, loss: 0.370, 6432/28000 datapoints
2025-03-06 20:45:11,495 - INFO - training batch 251, loss: 0.474, 8032/28000 datapoints
2025-03-06 20:45:11,614 - INFO - training batch 301, loss: 0.771, 9632/28000 datapoints
2025-03-06 20:45:11,736 - INFO - training batch 351, loss: 0.628, 11232/28000 datapoints
2025-03-06 20:45:11,855 - INFO - training batch 401, loss: 0.873, 12832/28000 datapoints
2025-03-06 20:45:11,979 - INFO - training batch 451, loss: 0.491, 14432/28000 datapoints
2025-03-06 20:45:12,098 - INFO - training batch 501, loss: 0.392, 16032/28000 datapoints
2025-03-06 20:45:12,217 - INFO - training batch 551, loss: 0.544, 17632/28000 datapoints
2025-03-06 20:45:12,341 - INFO - training batch 601, loss: 0.792, 19232/28000 datapoints
2025-03-06 20:45:12,462 - INFO - training batch 651, loss: 0.186, 20832/28000 datapoints
2025-03-06 20:45:12,584 - INFO - training batch 701, loss: 0.519, 22432/28000 datapoints
2025-03-06 20:45:12,708 - INFO - training batch 751, loss: 0.393, 24032/28000 datapoints
2025-03-06 20:45:12,826 - INFO - training batch 801, loss: 0.412, 25632/28000 datapoints
2025-03-06 20:45:12,945 - INFO - training batch 851, loss: 0.946, 27232/28000 datapoints
2025-03-06 20:45:13,004 - INFO - validation batch 1, loss: 0.288, 32/6976 datapoints
2025-03-06 20:45:13,047 - INFO - validation batch 51, loss: 1.289, 1632/6976 datapoints
2025-03-06 20:45:13,094 - INFO - validation batch 101, loss: 0.310, 3232/6976 datapoints
2025-03-06 20:45:13,137 - INFO - validation batch 151, loss: 0.683, 4832/6976 datapoints
2025-03-06 20:45:13,182 - INFO - validation batch 201, loss: 0.375, 6432/6976 datapoints
2025-03-06 20:45:13,197 - INFO - Epoch 182/800 done.
2025-03-06 20:45:13,197 - INFO - Final validation performance:
Loss: 0.589, top-1 acc: 0.827top-5 acc: 0.827
2025-03-06 20:45:13,198 - INFO - Beginning epoch 183/800
2025-03-06 20:45:13,201 - INFO - training batch 1, loss: 0.686, 32/28000 datapoints
2025-03-06 20:45:13,321 - INFO - training batch 51, loss: 0.404, 1632/28000 datapoints
2025-03-06 20:45:13,442 - INFO - training batch 101, loss: 0.298, 3232/28000 datapoints
2025-03-06 20:45:13,562 - INFO - training batch 151, loss: 0.942, 4832/28000 datapoints
2025-03-06 20:45:13,687 - INFO - training batch 201, loss: 0.365, 6432/28000 datapoints
2025-03-06 20:45:13,820 - INFO - training batch 251, loss: 0.471, 8032/28000 datapoints
2025-03-06 20:45:13,943 - INFO - training batch 301, loss: 0.769, 9632/28000 datapoints
2025-03-06 20:45:14,062 - INFO - training batch 351, loss: 0.628, 11232/28000 datapoints
2025-03-06 20:45:14,183 - INFO - training batch 401, loss: 0.870, 12832/28000 datapoints
2025-03-06 20:45:14,307 - INFO - training batch 451, loss: 0.485, 14432/28000 datapoints
2025-03-06 20:45:14,429 - INFO - training batch 501, loss: 0.388, 16032/28000 datapoints
2025-03-06 20:45:14,552 - INFO - training batch 551, loss: 0.540, 17632/28000 datapoints
2025-03-06 20:45:14,680 - INFO - training batch 601, loss: 0.788, 19232/28000 datapoints
2025-03-06 20:45:14,799 - INFO - training batch 651, loss: 0.181, 20832/28000 datapoints
2025-03-06 20:45:14,925 - INFO - training batch 701, loss: 0.516, 22432/28000 datapoints
2025-03-06 20:45:15,047 - INFO - training batch 751, loss: 0.391, 24032/28000 datapoints
2025-03-06 20:45:15,168 - INFO - training batch 801, loss: 0.408, 25632/28000 datapoints
2025-03-06 20:45:15,288 - INFO - training batch 851, loss: 0.941, 27232/28000 datapoints
2025-03-06 20:45:15,347 - INFO - validation batch 1, loss: 0.284, 32/6976 datapoints
2025-03-06 20:45:15,391 - INFO - validation batch 51, loss: 1.287, 1632/6976 datapoints
2025-03-06 20:45:15,436 - INFO - validation batch 101, loss: 0.305, 3232/6976 datapoints
2025-03-06 20:45:15,479 - INFO - validation batch 151, loss: 0.677, 4832/6976 datapoints
2025-03-06 20:45:15,523 - INFO - validation batch 201, loss: 0.375, 6432/6976 datapoints
2025-03-06 20:45:15,540 - INFO - Epoch 183/800 done.
2025-03-06 20:45:15,540 - INFO - Final validation performance:
Loss: 0.586, top-1 acc: 0.829top-5 acc: 0.829
2025-03-06 20:45:15,541 - INFO - Beginning epoch 184/800
2025-03-06 20:45:15,544 - INFO - training batch 1, loss: 0.679, 32/28000 datapoints
2025-03-06 20:45:15,671 - INFO - training batch 51, loss: 0.398, 1632/28000 datapoints
2025-03-06 20:45:15,790 - INFO - training batch 101, loss: 0.296, 3232/28000 datapoints
2025-03-06 20:45:15,913 - INFO - training batch 151, loss: 0.938, 4832/28000 datapoints
2025-03-06 20:45:16,032 - INFO - training batch 201, loss: 0.361, 6432/28000 datapoints
2025-03-06 20:45:16,155 - INFO - training batch 251, loss: 0.469, 8032/28000 datapoints
2025-03-06 20:45:16,280 - INFO - training batch 301, loss: 0.766, 9632/28000 datapoints
2025-03-06 20:45:16,400 - INFO - training batch 351, loss: 0.626, 11232/28000 datapoints
2025-03-06 20:45:16,521 - INFO - training batch 401, loss: 0.867, 12832/28000 datapoints
2025-03-06 20:45:16,645 - INFO - training batch 451, loss: 0.479, 14432/28000 datapoints
2025-03-06 20:45:16,764 - INFO - training batch 501, loss: 0.384, 16032/28000 datapoints
2025-03-06 20:45:16,885 - INFO - training batch 551, loss: 0.536, 17632/28000 datapoints
2025-03-06 20:45:17,003 - INFO - training batch 601, loss: 0.784, 19232/28000 datapoints
2025-03-06 20:45:17,123 - INFO - training batch 651, loss: 0.177, 20832/28000 datapoints
2025-03-06 20:45:17,246 - INFO - training batch 701, loss: 0.513, 22432/28000 datapoints
2025-03-06 20:45:17,363 - INFO - training batch 751, loss: 0.389, 24032/28000 datapoints
2025-03-06 20:45:17,485 - INFO - training batch 801, loss: 0.404, 25632/28000 datapoints
2025-03-06 20:45:17,605 - INFO - training batch 851, loss: 0.935, 27232/28000 datapoints
2025-03-06 20:45:17,667 - INFO - validation batch 1, loss: 0.280, 32/6976 datapoints
2025-03-06 20:45:17,710 - INFO - validation batch 51, loss: 1.284, 1632/6976 datapoints
2025-03-06 20:45:17,753 - INFO - validation batch 101, loss: 0.301, 3232/6976 datapoints
2025-03-06 20:45:17,796 - INFO - validation batch 151, loss: 0.671, 4832/6976 datapoints
2025-03-06 20:45:17,839 - INFO - validation batch 201, loss: 0.374, 6432/6976 datapoints
2025-03-06 20:45:17,854 - INFO - Epoch 184/800 done.
2025-03-06 20:45:17,854 - INFO - Final validation performance:
Loss: 0.582, top-1 acc: 0.830top-5 acc: 0.830
2025-03-06 20:45:17,855 - INFO - Beginning epoch 185/800
2025-03-06 20:45:17,858 - INFO - training batch 1, loss: 0.673, 32/28000 datapoints
2025-03-06 20:45:17,982 - INFO - training batch 51, loss: 0.393, 1632/28000 datapoints
2025-03-06 20:45:18,103 - INFO - training batch 101, loss: 0.294, 3232/28000 datapoints
2025-03-06 20:45:18,250 - INFO - training batch 151, loss: 0.933, 4832/28000 datapoints
2025-03-06 20:45:18,370 - INFO - training batch 201, loss: 0.356, 6432/28000 datapoints
2025-03-06 20:45:18,491 - INFO - training batch 251, loss: 0.466, 8032/28000 datapoints
2025-03-06 20:45:18,610 - INFO - training batch 301, loss: 0.765, 9632/28000 datapoints
2025-03-06 20:45:18,733 - INFO - training batch 351, loss: 0.623, 11232/28000 datapoints
2025-03-06 20:45:18,853 - INFO - training batch 401, loss: 0.865, 12832/28000 datapoints
2025-03-06 20:45:18,973 - INFO - training batch 451, loss: 0.474, 14432/28000 datapoints
2025-03-06 20:45:19,094 - INFO - training batch 501, loss: 0.379, 16032/28000 datapoints
2025-03-06 20:45:19,214 - INFO - training batch 551, loss: 0.531, 17632/28000 datapoints
2025-03-06 20:45:19,330 - INFO - training batch 601, loss: 0.780, 19232/28000 datapoints
2025-03-06 20:45:19,453 - INFO - training batch 651, loss: 0.173, 20832/28000 datapoints
2025-03-06 20:45:19,572 - INFO - training batch 701, loss: 0.509, 22432/28000 datapoints
2025-03-06 20:45:19,695 - INFO - training batch 751, loss: 0.387, 24032/28000 datapoints
2025-03-06 20:45:19,813 - INFO - training batch 801, loss: 0.400, 25632/28000 datapoints
2025-03-06 20:45:19,951 - INFO - training batch 851, loss: 0.929, 27232/28000 datapoints
2025-03-06 20:45:20,012 - INFO - validation batch 1, loss: 0.275, 32/6976 datapoints
2025-03-06 20:45:20,057 - INFO - validation batch 51, loss: 1.281, 1632/6976 datapoints
2025-03-06 20:45:20,101 - INFO - validation batch 101, loss: 0.297, 3232/6976 datapoints
2025-03-06 20:45:20,145 - INFO - validation batch 151, loss: 0.664, 4832/6976 datapoints
2025-03-06 20:45:20,188 - INFO - validation batch 201, loss: 0.373, 6432/6976 datapoints
2025-03-06 20:45:20,205 - INFO - Epoch 185/800 done.
2025-03-06 20:45:20,206 - INFO - Final validation performance:
Loss: 0.578, top-1 acc: 0.832top-5 acc: 0.832
2025-03-06 20:45:20,206 - INFO - Beginning epoch 186/800
2025-03-06 20:45:20,209 - INFO - training batch 1, loss: 0.667, 32/28000 datapoints
2025-03-06 20:45:20,334 - INFO - training batch 51, loss: 0.387, 1632/28000 datapoints
2025-03-06 20:45:20,454 - INFO - training batch 101, loss: 0.293, 3232/28000 datapoints
2025-03-06 20:45:20,574 - INFO - training batch 151, loss: 0.928, 4832/28000 datapoints
2025-03-06 20:45:20,695 - INFO - training batch 201, loss: 0.352, 6432/28000 datapoints
2025-03-06 20:45:20,816 - INFO - training batch 251, loss: 0.464, 8032/28000 datapoints
2025-03-06 20:45:20,936 - INFO - training batch 301, loss: 0.763, 9632/28000 datapoints
2025-03-06 20:45:21,056 - INFO - training batch 351, loss: 0.619, 11232/28000 datapoints
2025-03-06 20:45:21,177 - INFO - training batch 401, loss: 0.862, 12832/28000 datapoints
2025-03-06 20:45:21,297 - INFO - training batch 451, loss: 0.469, 14432/28000 datapoints
2025-03-06 20:45:21,416 - INFO - training batch 501, loss: 0.375, 16032/28000 datapoints
2025-03-06 20:45:21,536 - INFO - training batch 551, loss: 0.527, 17632/28000 datapoints
2025-03-06 20:45:21,658 - INFO - training batch 601, loss: 0.777, 19232/28000 datapoints
2025-03-06 20:45:21,779 - INFO - training batch 651, loss: 0.169, 20832/28000 datapoints
2025-03-06 20:45:21,899 - INFO - training batch 701, loss: 0.506, 22432/28000 datapoints
2025-03-06 20:45:22,022 - INFO - training batch 751, loss: 0.386, 24032/28000 datapoints
2025-03-06 20:45:22,141 - INFO - training batch 801, loss: 0.397, 25632/28000 datapoints
2025-03-06 20:45:22,262 - INFO - training batch 851, loss: 0.924, 27232/28000 datapoints
2025-03-06 20:45:22,322 - INFO - validation batch 1, loss: 0.271, 32/6976 datapoints
2025-03-06 20:45:22,365 - INFO - validation batch 51, loss: 1.279, 1632/6976 datapoints
2025-03-06 20:45:22,409 - INFO - validation batch 101, loss: 0.293, 3232/6976 datapoints
2025-03-06 20:45:22,454 - INFO - validation batch 151, loss: 0.658, 4832/6976 datapoints
2025-03-06 20:45:22,498 - INFO - validation batch 201, loss: 0.372, 6432/6976 datapoints
2025-03-06 20:45:22,513 - INFO - Epoch 186/800 done.
2025-03-06 20:45:22,513 - INFO - Final validation performance:
Loss: 0.575, top-1 acc: 0.833top-5 acc: 0.833
2025-03-06 20:45:22,514 - INFO - Beginning epoch 187/800
2025-03-06 20:45:22,517 - INFO - training batch 1, loss: 0.660, 32/28000 datapoints
2025-03-06 20:45:22,648 - INFO - training batch 51, loss: 0.383, 1632/28000 datapoints
2025-03-06 20:45:22,775 - INFO - training batch 101, loss: 0.291, 3232/28000 datapoints
2025-03-06 20:45:22,898 - INFO - training batch 151, loss: 0.924, 4832/28000 datapoints
2025-03-06 20:45:23,018 - INFO - training batch 201, loss: 0.348, 6432/28000 datapoints
2025-03-06 20:45:23,139 - INFO - training batch 251, loss: 0.462, 8032/28000 datapoints
2025-03-06 20:45:23,261 - INFO - training batch 301, loss: 0.760, 9632/28000 datapoints
2025-03-06 20:45:23,379 - INFO - training batch 351, loss: 0.616, 11232/28000 datapoints
2025-03-06 20:45:23,498 - INFO - training batch 401, loss: 0.859, 12832/28000 datapoints
2025-03-06 20:45:23,617 - INFO - training batch 451, loss: 0.464, 14432/28000 datapoints
2025-03-06 20:45:23,740 - INFO - training batch 501, loss: 0.371, 16032/28000 datapoints
2025-03-06 20:45:23,861 - INFO - training batch 551, loss: 0.523, 17632/28000 datapoints
2025-03-06 20:45:23,985 - INFO - training batch 601, loss: 0.773, 19232/28000 datapoints
2025-03-06 20:45:24,105 - INFO - training batch 651, loss: 0.165, 20832/28000 datapoints
2025-03-06 20:45:24,227 - INFO - training batch 701, loss: 0.503, 22432/28000 datapoints
2025-03-06 20:45:24,388 - INFO - training batch 751, loss: 0.383, 24032/28000 datapoints
2025-03-06 20:45:24,559 - INFO - training batch 801, loss: 0.393, 25632/28000 datapoints
2025-03-06 20:45:24,697 - INFO - training batch 851, loss: 0.918, 27232/28000 datapoints
2025-03-06 20:45:24,771 - INFO - validation batch 1, loss: 0.268, 32/6976 datapoints
2025-03-06 20:45:24,820 - INFO - validation batch 51, loss: 1.277, 1632/6976 datapoints
2025-03-06 20:45:24,867 - INFO - validation batch 101, loss: 0.289, 3232/6976 datapoints
2025-03-06 20:45:24,920 - INFO - validation batch 151, loss: 0.654, 4832/6976 datapoints
2025-03-06 20:45:24,964 - INFO - validation batch 201, loss: 0.373, 6432/6976 datapoints
2025-03-06 20:45:24,979 - INFO - Epoch 187/800 done.
2025-03-06 20:45:24,979 - INFO - Final validation performance:
Loss: 0.572, top-1 acc: 0.834top-5 acc: 0.834
2025-03-06 20:45:24,980 - INFO - Beginning epoch 188/800
2025-03-06 20:45:24,984 - INFO - training batch 1, loss: 0.654, 32/28000 datapoints
2025-03-06 20:45:25,105 - INFO - training batch 51, loss: 0.378, 1632/28000 datapoints
2025-03-06 20:45:25,233 - INFO - training batch 101, loss: 0.289, 3232/28000 datapoints
2025-03-06 20:45:25,359 - INFO - training batch 151, loss: 0.919, 4832/28000 datapoints
2025-03-06 20:45:25,481 - INFO - training batch 201, loss: 0.343, 6432/28000 datapoints
2025-03-06 20:45:25,606 - INFO - training batch 251, loss: 0.459, 8032/28000 datapoints
2025-03-06 20:45:25,735 - INFO - training batch 301, loss: 0.759, 9632/28000 datapoints
2025-03-06 20:45:25,860 - INFO - training batch 351, loss: 0.612, 11232/28000 datapoints
2025-03-06 20:45:25,996 - INFO - training batch 401, loss: 0.856, 12832/28000 datapoints
2025-03-06 20:45:26,139 - INFO - training batch 451, loss: 0.458, 14432/28000 datapoints
2025-03-06 20:45:26,262 - INFO - training batch 501, loss: 0.367, 16032/28000 datapoints
2025-03-06 20:45:26,392 - INFO - training batch 551, loss: 0.519, 17632/28000 datapoints
2025-03-06 20:45:26,519 - INFO - training batch 601, loss: 0.770, 19232/28000 datapoints
2025-03-06 20:45:26,657 - INFO - training batch 651, loss: 0.162, 20832/28000 datapoints
2025-03-06 20:45:26,786 - INFO - training batch 701, loss: 0.500, 22432/28000 datapoints
2025-03-06 20:45:26,908 - INFO - training batch 751, loss: 0.382, 24032/28000 datapoints
2025-03-06 20:45:27,031 - INFO - training batch 801, loss: 0.390, 25632/28000 datapoints
2025-03-06 20:45:27,163 - INFO - training batch 851, loss: 0.913, 27232/28000 datapoints
2025-03-06 20:45:27,227 - INFO - validation batch 1, loss: 0.264, 32/6976 datapoints
2025-03-06 20:45:27,271 - INFO - validation batch 51, loss: 1.275, 1632/6976 datapoints
2025-03-06 20:45:27,319 - INFO - validation batch 101, loss: 0.286, 3232/6976 datapoints
2025-03-06 20:45:27,363 - INFO - validation batch 151, loss: 0.648, 4832/6976 datapoints
2025-03-06 20:45:27,406 - INFO - validation batch 201, loss: 0.371, 6432/6976 datapoints
2025-03-06 20:45:27,421 - INFO - Epoch 188/800 done.
2025-03-06 20:45:27,421 - INFO - Final validation performance:
Loss: 0.569, top-1 acc: 0.835top-5 acc: 0.835
2025-03-06 20:45:27,422 - INFO - Beginning epoch 189/800
2025-03-06 20:45:27,426 - INFO - training batch 1, loss: 0.648, 32/28000 datapoints
2025-03-06 20:45:27,547 - INFO - training batch 51, loss: 0.372, 1632/28000 datapoints
2025-03-06 20:45:27,676 - INFO - training batch 101, loss: 0.288, 3232/28000 datapoints
2025-03-06 20:45:27,798 - INFO - training batch 151, loss: 0.915, 4832/28000 datapoints
2025-03-06 20:45:27,917 - INFO - training batch 201, loss: 0.339, 6432/28000 datapoints
2025-03-06 20:45:28,042 - INFO - training batch 251, loss: 0.457, 8032/28000 datapoints
2025-03-06 20:45:28,162 - INFO - training batch 301, loss: 0.757, 9632/28000 datapoints
2025-03-06 20:45:28,308 - INFO - training batch 351, loss: 0.609, 11232/28000 datapoints
2025-03-06 20:45:28,433 - INFO - training batch 401, loss: 0.853, 12832/28000 datapoints
2025-03-06 20:45:28,555 - INFO - training batch 451, loss: 0.453, 14432/28000 datapoints
2025-03-06 20:45:28,679 - INFO - training batch 501, loss: 0.363, 16032/28000 datapoints
2025-03-06 20:45:28,800 - INFO - training batch 551, loss: 0.515, 17632/28000 datapoints
2025-03-06 20:45:28,923 - INFO - training batch 601, loss: 0.766, 19232/28000 datapoints
2025-03-06 20:45:29,043 - INFO - training batch 651, loss: 0.158, 20832/28000 datapoints
2025-03-06 20:45:29,161 - INFO - training batch 701, loss: 0.497, 22432/28000 datapoints
2025-03-06 20:45:29,280 - INFO - training batch 751, loss: 0.380, 24032/28000 datapoints
2025-03-06 20:45:29,400 - INFO - training batch 801, loss: 0.386, 25632/28000 datapoints
2025-03-06 20:45:29,526 - INFO - training batch 851, loss: 0.908, 27232/28000 datapoints
2025-03-06 20:45:29,586 - INFO - validation batch 1, loss: 0.260, 32/6976 datapoints
2025-03-06 20:45:29,631 - INFO - validation batch 51, loss: 1.272, 1632/6976 datapoints
2025-03-06 20:45:29,678 - INFO - validation batch 101, loss: 0.283, 3232/6976 datapoints
2025-03-06 20:45:29,721 - INFO - validation batch 151, loss: 0.644, 4832/6976 datapoints
2025-03-06 20:45:29,765 - INFO - validation batch 201, loss: 0.370, 6432/6976 datapoints
2025-03-06 20:45:29,780 - INFO - Epoch 189/800 done.
2025-03-06 20:45:29,780 - INFO - Final validation performance:
Loss: 0.566, top-1 acc: 0.837top-5 acc: 0.837
2025-03-06 20:45:29,781 - INFO - Beginning epoch 190/800
2025-03-06 20:45:29,784 - INFO - training batch 1, loss: 0.642, 32/28000 datapoints
2025-03-06 20:45:29,907 - INFO - training batch 51, loss: 0.368, 1632/28000 datapoints
2025-03-06 20:45:30,035 - INFO - training batch 101, loss: 0.286, 3232/28000 datapoints
2025-03-06 20:45:30,163 - INFO - training batch 151, loss: 0.913, 4832/28000 datapoints
2025-03-06 20:45:30,284 - INFO - training batch 201, loss: 0.335, 6432/28000 datapoints
2025-03-06 20:45:30,406 - INFO - training batch 251, loss: 0.454, 8032/28000 datapoints
2025-03-06 20:45:30,524 - INFO - training batch 301, loss: 0.756, 9632/28000 datapoints
2025-03-06 20:45:30,646 - INFO - training batch 351, loss: 0.606, 11232/28000 datapoints
2025-03-06 20:45:30,766 - INFO - training batch 401, loss: 0.850, 12832/28000 datapoints
2025-03-06 20:45:30,886 - INFO - training batch 451, loss: 0.449, 14432/28000 datapoints
2025-03-06 20:45:31,005 - INFO - training batch 501, loss: 0.359, 16032/28000 datapoints
2025-03-06 20:45:31,126 - INFO - training batch 551, loss: 0.511, 17632/28000 datapoints
2025-03-06 20:45:31,246 - INFO - training batch 601, loss: 0.763, 19232/28000 datapoints
2025-03-06 20:45:31,368 - INFO - training batch 651, loss: 0.156, 20832/28000 datapoints
2025-03-06 20:45:31,488 - INFO - training batch 701, loss: 0.494, 22432/28000 datapoints
2025-03-06 20:45:31,608 - INFO - training batch 751, loss: 0.376, 24032/28000 datapoints
2025-03-06 20:45:31,733 - INFO - training batch 801, loss: 0.382, 25632/28000 datapoints
2025-03-06 20:45:31,853 - INFO - training batch 851, loss: 0.903, 27232/28000 datapoints
2025-03-06 20:45:31,913 - INFO - validation batch 1, loss: 0.256, 32/6976 datapoints
2025-03-06 20:45:31,959 - INFO - validation batch 51, loss: 1.271, 1632/6976 datapoints
2025-03-06 20:45:32,004 - INFO - validation batch 101, loss: 0.279, 3232/6976 datapoints
2025-03-06 20:45:32,048 - INFO - validation batch 151, loss: 0.640, 4832/6976 datapoints
2025-03-06 20:45:32,091 - INFO - validation batch 201, loss: 0.370, 6432/6976 datapoints
2025-03-06 20:45:32,108 - INFO - Epoch 190/800 done.
2025-03-06 20:45:32,108 - INFO - Final validation performance:
Loss: 0.563, top-1 acc: 0.838top-5 acc: 0.838
2025-03-06 20:45:32,108 - INFO - Beginning epoch 191/800
2025-03-06 20:45:32,112 - INFO - training batch 1, loss: 0.636, 32/28000 datapoints
2025-03-06 20:45:32,245 - INFO - training batch 51, loss: 0.363, 1632/28000 datapoints
2025-03-06 20:45:32,365 - INFO - training batch 101, loss: 0.285, 3232/28000 datapoints
2025-03-06 20:45:32,485 - INFO - training batch 151, loss: 0.909, 4832/28000 datapoints
2025-03-06 20:45:32,610 - INFO - training batch 201, loss: 0.331, 6432/28000 datapoints
2025-03-06 20:45:32,734 - INFO - training batch 251, loss: 0.452, 8032/28000 datapoints
2025-03-06 20:45:32,855 - INFO - training batch 301, loss: 0.754, 9632/28000 datapoints
2025-03-06 20:45:32,974 - INFO - training batch 351, loss: 0.602, 11232/28000 datapoints
2025-03-06 20:45:33,093 - INFO - training batch 401, loss: 0.847, 12832/28000 datapoints
2025-03-06 20:45:33,212 - INFO - training batch 451, loss: 0.444, 14432/28000 datapoints
2025-03-06 20:45:33,334 - INFO - training batch 501, loss: 0.355, 16032/28000 datapoints
2025-03-06 20:45:33,454 - INFO - training batch 551, loss: 0.507, 17632/28000 datapoints
2025-03-06 20:45:33,575 - INFO - training batch 601, loss: 0.759, 19232/28000 datapoints
2025-03-06 20:45:33,698 - INFO - training batch 651, loss: 0.153, 20832/28000 datapoints
2025-03-06 20:45:33,817 - INFO - training batch 701, loss: 0.491, 22432/28000 datapoints
2025-03-06 20:45:33,935 - INFO - training batch 751, loss: 0.375, 24032/28000 datapoints
2025-03-06 20:45:34,058 - INFO - training batch 801, loss: 0.378, 25632/28000 datapoints
2025-03-06 20:45:34,177 - INFO - training batch 851, loss: 0.899, 27232/28000 datapoints
2025-03-06 20:45:34,236 - INFO - validation batch 1, loss: 0.252, 32/6976 datapoints
2025-03-06 20:45:34,281 - INFO - validation batch 51, loss: 1.269, 1632/6976 datapoints
2025-03-06 20:45:34,325 - INFO - validation batch 101, loss: 0.276, 3232/6976 datapoints
2025-03-06 20:45:34,368 - INFO - validation batch 151, loss: 0.635, 4832/6976 datapoints
2025-03-06 20:45:34,413 - INFO - validation batch 201, loss: 0.368, 6432/6976 datapoints
2025-03-06 20:45:34,428 - INFO - Epoch 191/800 done.
2025-03-06 20:45:34,428 - INFO - Final validation performance:
Loss: 0.560, top-1 acc: 0.838top-5 acc: 0.838
2025-03-06 20:45:34,428 - INFO - Beginning epoch 192/800
2025-03-06 20:45:34,432 - INFO - training batch 1, loss: 0.630, 32/28000 datapoints
2025-03-06 20:45:34,554 - INFO - training batch 51, loss: 0.358, 1632/28000 datapoints
2025-03-06 20:45:34,676 - INFO - training batch 101, loss: 0.284, 3232/28000 datapoints
2025-03-06 20:45:34,797 - INFO - training batch 151, loss: 0.906, 4832/28000 datapoints
2025-03-06 20:45:34,922 - INFO - training batch 201, loss: 0.327, 6432/28000 datapoints
2025-03-06 20:45:35,042 - INFO - training batch 251, loss: 0.450, 8032/28000 datapoints
2025-03-06 20:45:35,162 - INFO - training batch 301, loss: 0.753, 9632/28000 datapoints
2025-03-06 20:45:35,283 - INFO - training batch 351, loss: 0.598, 11232/28000 datapoints
2025-03-06 20:45:35,404 - INFO - training batch 401, loss: 0.844, 12832/28000 datapoints
2025-03-06 20:45:35,522 - INFO - training batch 451, loss: 0.440, 14432/28000 datapoints
2025-03-06 20:45:35,647 - INFO - training batch 501, loss: 0.351, 16032/28000 datapoints
2025-03-06 20:45:35,769 - INFO - training batch 551, loss: 0.503, 17632/28000 datapoints
2025-03-06 20:45:35,888 - INFO - training batch 601, loss: 0.755, 19232/28000 datapoints
2025-03-06 20:45:36,012 - INFO - training batch 651, loss: 0.150, 20832/28000 datapoints
2025-03-06 20:45:36,132 - INFO - training batch 701, loss: 0.488, 22432/28000 datapoints
2025-03-06 20:45:36,256 - INFO - training batch 751, loss: 0.373, 24032/28000 datapoints
2025-03-06 20:45:36,375 - INFO - training batch 801, loss: 0.375, 25632/28000 datapoints
2025-03-06 20:45:36,496 - INFO - training batch 851, loss: 0.894, 27232/28000 datapoints
2025-03-06 20:45:36,556 - INFO - validation batch 1, loss: 0.249, 32/6976 datapoints
2025-03-06 20:45:36,599 - INFO - validation batch 51, loss: 1.268, 1632/6976 datapoints
2025-03-06 20:45:36,644 - INFO - validation batch 101, loss: 0.274, 3232/6976 datapoints
2025-03-06 20:45:36,688 - INFO - validation batch 151, loss: 0.633, 4832/6976 datapoints
2025-03-06 20:45:36,731 - INFO - validation batch 201, loss: 0.368, 6432/6976 datapoints
2025-03-06 20:45:36,746 - INFO - Epoch 192/800 done.
2025-03-06 20:45:36,746 - INFO - Final validation performance:
Loss: 0.558, top-1 acc: 0.839top-5 acc: 0.839
2025-03-06 20:45:36,747 - INFO - Beginning epoch 193/800
2025-03-06 20:45:36,750 - INFO - training batch 1, loss: 0.624, 32/28000 datapoints
2025-03-06 20:45:36,871 - INFO - training batch 51, loss: 0.354, 1632/28000 datapoints
2025-03-06 20:45:36,993 - INFO - training batch 101, loss: 0.283, 3232/28000 datapoints
2025-03-06 20:45:37,113 - INFO - training batch 151, loss: 0.903, 4832/28000 datapoints
2025-03-06 20:45:37,232 - INFO - training batch 201, loss: 0.324, 6432/28000 datapoints
2025-03-06 20:45:37,352 - INFO - training batch 251, loss: 0.448, 8032/28000 datapoints
2025-03-06 20:45:37,471 - INFO - training batch 301, loss: 0.752, 9632/28000 datapoints
2025-03-06 20:45:37,591 - INFO - training batch 351, loss: 0.593, 11232/28000 datapoints
2025-03-06 20:45:37,730 - INFO - training batch 401, loss: 0.841, 12832/28000 datapoints
2025-03-06 20:45:37,850 - INFO - training batch 451, loss: 0.436, 14432/28000 datapoints
2025-03-06 20:45:37,970 - INFO - training batch 501, loss: 0.347, 16032/28000 datapoints
2025-03-06 20:45:38,094 - INFO - training batch 551, loss: 0.500, 17632/28000 datapoints
2025-03-06 20:45:38,220 - INFO - training batch 601, loss: 0.752, 19232/28000 datapoints
2025-03-06 20:45:38,364 - INFO - training batch 651, loss: 0.148, 20832/28000 datapoints
2025-03-06 20:45:38,504 - INFO - training batch 701, loss: 0.485, 22432/28000 datapoints
2025-03-06 20:45:38,623 - INFO - training batch 751, loss: 0.372, 24032/28000 datapoints
2025-03-06 20:45:38,753 - INFO - training batch 801, loss: 0.372, 25632/28000 datapoints
2025-03-06 20:45:38,877 - INFO - training batch 851, loss: 0.890, 27232/28000 datapoints
2025-03-06 20:45:38,936 - INFO - validation batch 1, loss: 0.246, 32/6976 datapoints
2025-03-06 20:45:38,981 - INFO - validation batch 51, loss: 1.266, 1632/6976 datapoints
2025-03-06 20:45:39,026 - INFO - validation batch 101, loss: 0.271, 3232/6976 datapoints
2025-03-06 20:45:39,083 - INFO - validation batch 151, loss: 0.629, 4832/6976 datapoints
2025-03-06 20:45:39,131 - INFO - validation batch 201, loss: 0.368, 6432/6976 datapoints
2025-03-06 20:45:39,146 - INFO - Epoch 193/800 done.
2025-03-06 20:45:39,147 - INFO - Final validation performance:
Loss: 0.556, top-1 acc: 0.840top-5 acc: 0.840
2025-03-06 20:45:39,147 - INFO - Beginning epoch 194/800
2025-03-06 20:45:39,151 - INFO - training batch 1, loss: 0.618, 32/28000 datapoints
2025-03-06 20:45:39,273 - INFO - training batch 51, loss: 0.349, 1632/28000 datapoints
2025-03-06 20:45:39,395 - INFO - training batch 101, loss: 0.282, 3232/28000 datapoints
2025-03-06 20:45:39,521 - INFO - training batch 151, loss: 0.900, 4832/28000 datapoints
2025-03-06 20:45:39,644 - INFO - training batch 201, loss: 0.320, 6432/28000 datapoints
2025-03-06 20:45:39,763 - INFO - training batch 251, loss: 0.446, 8032/28000 datapoints
2025-03-06 20:45:39,881 - INFO - training batch 301, loss: 0.750, 9632/28000 datapoints
2025-03-06 20:45:40,007 - INFO - training batch 351, loss: 0.589, 11232/28000 datapoints
2025-03-06 20:45:40,163 - INFO - training batch 401, loss: 0.838, 12832/28000 datapoints
2025-03-06 20:45:40,292 - INFO - training batch 451, loss: 0.431, 14432/28000 datapoints
2025-03-06 20:45:40,413 - INFO - training batch 501, loss: 0.342, 16032/28000 datapoints
2025-03-06 20:45:40,535 - INFO - training batch 551, loss: 0.496, 17632/28000 datapoints
2025-03-06 20:45:40,657 - INFO - training batch 601, loss: 0.749, 19232/28000 datapoints
2025-03-06 20:45:40,777 - INFO - training batch 651, loss: 0.145, 20832/28000 datapoints
2025-03-06 20:45:40,901 - INFO - training batch 701, loss: 0.482, 22432/28000 datapoints
2025-03-06 20:45:41,020 - INFO - training batch 751, loss: 0.371, 24032/28000 datapoints
2025-03-06 20:45:41,139 - INFO - training batch 801, loss: 0.368, 25632/28000 datapoints
2025-03-06 20:45:41,260 - INFO - training batch 851, loss: 0.887, 27232/28000 datapoints
2025-03-06 20:45:41,319 - INFO - validation batch 1, loss: 0.243, 32/6976 datapoints
2025-03-06 20:45:41,363 - INFO - validation batch 51, loss: 1.263, 1632/6976 datapoints
2025-03-06 20:45:41,406 - INFO - validation batch 101, loss: 0.268, 3232/6976 datapoints
2025-03-06 20:45:41,449 - INFO - validation batch 151, loss: 0.625, 4832/6976 datapoints
2025-03-06 20:45:41,495 - INFO - validation batch 201, loss: 0.369, 6432/6976 datapoints
2025-03-06 20:45:41,510 - INFO - Epoch 194/800 done.
2025-03-06 20:45:41,510 - INFO - Final validation performance:
Loss: 0.554, top-1 acc: 0.841top-5 acc: 0.841
2025-03-06 20:45:41,511 - INFO - Beginning epoch 195/800
2025-03-06 20:45:41,514 - INFO - training batch 1, loss: 0.611, 32/28000 datapoints
2025-03-06 20:45:41,639 - INFO - training batch 51, loss: 0.345, 1632/28000 datapoints
2025-03-06 20:45:41,759 - INFO - training batch 101, loss: 0.280, 3232/28000 datapoints
2025-03-06 20:45:41,878 - INFO - training batch 151, loss: 0.897, 4832/28000 datapoints
2025-03-06 20:45:41,998 - INFO - training batch 201, loss: 0.317, 6432/28000 datapoints
2025-03-06 20:45:42,124 - INFO - training batch 251, loss: 0.444, 8032/28000 datapoints
2025-03-06 20:45:42,244 - INFO - training batch 301, loss: 0.748, 9632/28000 datapoints
2025-03-06 20:45:42,363 - INFO - training batch 351, loss: 0.585, 11232/28000 datapoints
2025-03-06 20:45:42,482 - INFO - training batch 401, loss: 0.835, 12832/28000 datapoints
2025-03-06 20:45:42,603 - INFO - training batch 451, loss: 0.427, 14432/28000 datapoints
2025-03-06 20:45:42,726 - INFO - training batch 501, loss: 0.338, 16032/28000 datapoints
2025-03-06 20:45:42,849 - INFO - training batch 551, loss: 0.493, 17632/28000 datapoints
2025-03-06 20:45:42,968 - INFO - training batch 601, loss: 0.746, 19232/28000 datapoints
2025-03-06 20:45:43,091 - INFO - training batch 651, loss: 0.143, 20832/28000 datapoints
2025-03-06 20:45:43,211 - INFO - training batch 701, loss: 0.480, 22432/28000 datapoints
2025-03-06 20:45:43,331 - INFO - training batch 751, loss: 0.369, 24032/28000 datapoints
2025-03-06 20:45:43,451 - INFO - training batch 801, loss: 0.365, 25632/28000 datapoints
2025-03-06 20:45:43,574 - INFO - training batch 851, loss: 0.882, 27232/28000 datapoints
2025-03-06 20:45:43,635 - INFO - validation batch 1, loss: 0.240, 32/6976 datapoints
2025-03-06 20:45:43,679 - INFO - validation batch 51, loss: 1.261, 1632/6976 datapoints
2025-03-06 20:45:43,724 - INFO - validation batch 101, loss: 0.266, 3232/6976 datapoints
2025-03-06 20:45:43,768 - INFO - validation batch 151, loss: 0.621, 4832/6976 datapoints
2025-03-06 20:45:43,812 - INFO - validation batch 201, loss: 0.369, 6432/6976 datapoints
2025-03-06 20:45:43,827 - INFO - Epoch 195/800 done.
2025-03-06 20:45:43,827 - INFO - Final validation performance:
Loss: 0.551, top-1 acc: 0.842top-5 acc: 0.842
2025-03-06 20:45:43,828 - INFO - Beginning epoch 196/800
2025-03-06 20:45:43,831 - INFO - training batch 1, loss: 0.606, 32/28000 datapoints
2025-03-06 20:45:43,952 - INFO - training batch 51, loss: 0.341, 1632/28000 datapoints
2025-03-06 20:45:44,078 - INFO - training batch 101, loss: 0.280, 3232/28000 datapoints
2025-03-06 20:45:44,199 - INFO - training batch 151, loss: 0.894, 4832/28000 datapoints
2025-03-06 20:45:44,334 - INFO - training batch 201, loss: 0.313, 6432/28000 datapoints
2025-03-06 20:45:44,454 - INFO - training batch 251, loss: 0.442, 8032/28000 datapoints
2025-03-06 20:45:44,575 - INFO - training batch 301, loss: 0.747, 9632/28000 datapoints
2025-03-06 20:45:44,696 - INFO - training batch 351, loss: 0.580, 11232/28000 datapoints
2025-03-06 20:45:44,823 - INFO - training batch 401, loss: 0.833, 12832/28000 datapoints
2025-03-06 20:45:44,952 - INFO - training batch 451, loss: 0.423, 14432/28000 datapoints
2025-03-06 20:45:45,079 - INFO - training batch 501, loss: 0.334, 16032/28000 datapoints
2025-03-06 20:45:45,211 - INFO - training batch 551, loss: 0.489, 17632/28000 datapoints
2025-03-06 20:45:45,336 - INFO - training batch 601, loss: 0.742, 19232/28000 datapoints
2025-03-06 20:45:45,460 - INFO - training batch 651, loss: 0.140, 20832/28000 datapoints
2025-03-06 20:45:45,587 - INFO - training batch 701, loss: 0.477, 22432/28000 datapoints
2025-03-06 20:45:45,715 - INFO - training batch 751, loss: 0.368, 24032/28000 datapoints
2025-03-06 20:45:45,841 - INFO - training batch 801, loss: 0.362, 25632/28000 datapoints
2025-03-06 20:45:45,964 - INFO - training batch 851, loss: 0.879, 27232/28000 datapoints
2025-03-06 20:45:46,030 - INFO - validation batch 1, loss: 0.236, 32/6976 datapoints
2025-03-06 20:45:46,080 - INFO - validation batch 51, loss: 1.259, 1632/6976 datapoints
2025-03-06 20:45:46,128 - INFO - validation batch 101, loss: 0.264, 3232/6976 datapoints
2025-03-06 20:45:46,177 - INFO - validation batch 151, loss: 0.617, 4832/6976 datapoints
2025-03-06 20:45:46,224 - INFO - validation batch 201, loss: 0.369, 6432/6976 datapoints
2025-03-06 20:45:46,240 - INFO - Epoch 196/800 done.
2025-03-06 20:45:46,240 - INFO - Final validation performance:
Loss: 0.549, top-1 acc: 0.843top-5 acc: 0.843
2025-03-06 20:45:46,240 - INFO - Beginning epoch 197/800
2025-03-06 20:45:46,244 - INFO - training batch 1, loss: 0.599, 32/28000 datapoints
2025-03-06 20:45:46,365 - INFO - training batch 51, loss: 0.337, 1632/28000 datapoints
2025-03-06 20:45:46,485 - INFO - training batch 101, loss: 0.279, 3232/28000 datapoints
2025-03-06 20:45:46,608 - INFO - training batch 151, loss: 0.890, 4832/28000 datapoints
2025-03-06 20:45:46,736 - INFO - training batch 201, loss: 0.310, 6432/28000 datapoints
2025-03-06 20:45:46,863 - INFO - training batch 251, loss: 0.440, 8032/28000 datapoints
2025-03-06 20:45:46,982 - INFO - training batch 301, loss: 0.746, 9632/28000 datapoints
2025-03-06 20:45:47,103 - INFO - training batch 351, loss: 0.577, 11232/28000 datapoints
2025-03-06 20:45:47,222 - INFO - training batch 401, loss: 0.831, 12832/28000 datapoints
2025-03-06 20:45:47,343 - INFO - training batch 451, loss: 0.419, 14432/28000 datapoints
2025-03-06 20:45:47,462 - INFO - training batch 501, loss: 0.331, 16032/28000 datapoints
2025-03-06 20:45:47,583 - INFO - training batch 551, loss: 0.486, 17632/28000 datapoints
2025-03-06 20:45:47,720 - INFO - training batch 601, loss: 0.738, 19232/28000 datapoints
2025-03-06 20:45:47,878 - INFO - training batch 651, loss: 0.138, 20832/28000 datapoints
2025-03-06 20:45:47,999 - INFO - training batch 701, loss: 0.475, 22432/28000 datapoints
2025-03-06 20:45:48,125 - INFO - training batch 751, loss: 0.367, 24032/28000 datapoints
2025-03-06 20:45:48,244 - INFO - training batch 801, loss: 0.359, 25632/28000 datapoints
2025-03-06 20:45:48,364 - INFO - training batch 851, loss: 0.874, 27232/28000 datapoints
2025-03-06 20:45:48,423 - INFO - validation batch 1, loss: 0.234, 32/6976 datapoints
2025-03-06 20:45:48,483 - INFO - validation batch 51, loss: 1.265, 1632/6976 datapoints
2025-03-06 20:45:48,544 - INFO - validation batch 101, loss: 0.262, 3232/6976 datapoints
2025-03-06 20:45:48,590 - INFO - validation batch 151, loss: 0.618, 4832/6976 datapoints
2025-03-06 20:45:48,637 - INFO - validation batch 201, loss: 0.370, 6432/6976 datapoints
2025-03-06 20:45:48,652 - INFO - Epoch 197/800 done.
2025-03-06 20:45:48,652 - INFO - Final validation performance:
Loss: 0.550, top-1 acc: 0.843top-5 acc: 0.843
2025-03-06 20:45:48,653 - INFO - Beginning epoch 198/800
2025-03-06 20:45:48,656 - INFO - training batch 1, loss: 0.593, 32/28000 datapoints
2025-03-06 20:45:48,779 - INFO - training batch 51, loss: 0.333, 1632/28000 datapoints
2025-03-06 20:45:48,899 - INFO - training batch 101, loss: 0.277, 3232/28000 datapoints
2025-03-06 20:45:49,020 - INFO - training batch 151, loss: 0.886, 4832/28000 datapoints
2025-03-06 20:45:49,139 - INFO - training batch 201, loss: 0.307, 6432/28000 datapoints
2025-03-06 20:45:49,260 - INFO - training batch 251, loss: 0.438, 8032/28000 datapoints
2025-03-06 20:45:49,377 - INFO - training batch 301, loss: 0.744, 9632/28000 datapoints
2025-03-06 20:45:49,496 - INFO - training batch 351, loss: 0.573, 11232/28000 datapoints
2025-03-06 20:45:49,620 - INFO - training batch 401, loss: 0.828, 12832/28000 datapoints
2025-03-06 20:45:49,743 - INFO - training batch 451, loss: 0.416, 14432/28000 datapoints
2025-03-06 20:45:49,863 - INFO - training batch 501, loss: 0.326, 16032/28000 datapoints
2025-03-06 20:45:49,982 - INFO - training batch 551, loss: 0.483, 17632/28000 datapoints
2025-03-06 20:45:50,108 - INFO - training batch 601, loss: 0.735, 19232/28000 datapoints
2025-03-06 20:45:50,228 - INFO - training batch 651, loss: 0.136, 20832/28000 datapoints
2025-03-06 20:45:50,362 - INFO - training batch 701, loss: 0.473, 22432/28000 datapoints
2025-03-06 20:45:50,480 - INFO - training batch 751, loss: 0.366, 24032/28000 datapoints
2025-03-06 20:45:50,601 - INFO - training batch 801, loss: 0.356, 25632/28000 datapoints
2025-03-06 20:45:50,731 - INFO - training batch 851, loss: 0.870, 27232/28000 datapoints
2025-03-06 20:45:50,791 - INFO - validation batch 1, loss: 0.231, 32/6976 datapoints
2025-03-06 20:45:50,835 - INFO - validation batch 51, loss: 1.268, 1632/6976 datapoints
2025-03-06 20:45:50,882 - INFO - validation batch 101, loss: 0.260, 3232/6976 datapoints
2025-03-06 20:45:50,925 - INFO - validation batch 151, loss: 0.614, 4832/6976 datapoints
2025-03-06 20:45:50,969 - INFO - validation batch 201, loss: 0.371, 6432/6976 datapoints
2025-03-06 20:45:50,984 - INFO - Epoch 198/800 done.
2025-03-06 20:45:50,984 - INFO - Final validation performance:
Loss: 0.549, top-1 acc: 0.843top-5 acc: 0.843
2025-03-06 20:45:50,985 - INFO - Beginning epoch 199/800
2025-03-06 20:45:50,989 - INFO - training batch 1, loss: 0.587, 32/28000 datapoints
2025-03-06 20:45:51,115 - INFO - training batch 51, loss: 0.330, 1632/28000 datapoints
2025-03-06 20:45:51,237 - INFO - training batch 101, loss: 0.276, 3232/28000 datapoints
2025-03-06 20:45:51,358 - INFO - training batch 151, loss: 0.883, 4832/28000 datapoints
2025-03-06 20:45:51,477 - INFO - training batch 201, loss: 0.304, 6432/28000 datapoints
2025-03-06 20:45:51,595 - INFO - training batch 251, loss: 0.437, 8032/28000 datapoints
2025-03-06 20:45:51,732 - INFO - training batch 301, loss: 0.743, 9632/28000 datapoints
2025-03-06 20:45:51,873 - INFO - training batch 351, loss: 0.568, 11232/28000 datapoints
2025-03-06 20:45:51,993 - INFO - training batch 401, loss: 0.825, 12832/28000 datapoints
2025-03-06 20:45:52,116 - INFO - training batch 451, loss: 0.413, 14432/28000 datapoints
2025-03-06 20:45:52,237 - INFO - training batch 501, loss: 0.323, 16032/28000 datapoints
2025-03-06 20:45:52,357 - INFO - training batch 551, loss: 0.480, 17632/28000 datapoints
2025-03-06 20:45:52,476 - INFO - training batch 601, loss: 0.731, 19232/28000 datapoints
2025-03-06 20:45:52,595 - INFO - training batch 651, loss: 0.134, 20832/28000 datapoints
2025-03-06 20:45:52,721 - INFO - training batch 701, loss: 0.470, 22432/28000 datapoints
2025-03-06 20:45:52,844 - INFO - training batch 751, loss: 0.365, 24032/28000 datapoints
2025-03-06 20:45:52,964 - INFO - training batch 801, loss: 0.353, 25632/28000 datapoints
2025-03-06 20:45:53,085 - INFO - training batch 851, loss: 0.866, 27232/28000 datapoints
2025-03-06 20:45:53,145 - INFO - validation batch 1, loss: 0.228, 32/6976 datapoints
2025-03-06 20:45:53,189 - INFO - validation batch 51, loss: 1.270, 1632/6976 datapoints
2025-03-06 20:45:53,233 - INFO - validation batch 101, loss: 0.258, 3232/6976 datapoints
2025-03-06 20:45:53,279 - INFO - validation batch 151, loss: 0.610, 4832/6976 datapoints
2025-03-06 20:45:53,322 - INFO - validation batch 201, loss: 0.371, 6432/6976 datapoints
2025-03-06 20:45:53,337 - INFO - Epoch 199/800 done.
2025-03-06 20:45:53,337 - INFO - Final validation performance:
Loss: 0.547, top-1 acc: 0.844top-5 acc: 0.844
2025-03-06 20:45:53,338 - INFO - Beginning epoch 200/800
2025-03-06 20:45:53,341 - INFO - training batch 1, loss: 0.581, 32/28000 datapoints
2025-03-06 20:45:53,463 - INFO - training batch 51, loss: 0.327, 1632/28000 datapoints
2025-03-06 20:45:53,584 - INFO - training batch 101, loss: 0.276, 3232/28000 datapoints
2025-03-06 20:45:53,709 - INFO - training batch 151, loss: 0.881, 4832/28000 datapoints
2025-03-06 20:45:53,830 - INFO - training batch 201, loss: 0.301, 6432/28000 datapoints
2025-03-06 20:45:53,948 - INFO - training batch 251, loss: 0.435, 8032/28000 datapoints
2025-03-06 20:45:54,071 - INFO - training batch 301, loss: 0.742, 9632/28000 datapoints
2025-03-06 20:45:54,192 - INFO - training batch 351, loss: 0.564, 11232/28000 datapoints
2025-03-06 20:45:54,312 - INFO - training batch 401, loss: 0.823, 12832/28000 datapoints
2025-03-06 20:45:54,431 - INFO - training batch 451, loss: 0.410, 14432/28000 datapoints
2025-03-06 20:45:54,551 - INFO - training batch 501, loss: 0.320, 16032/28000 datapoints
2025-03-06 20:45:54,674 - INFO - training batch 551, loss: 0.477, 17632/28000 datapoints
2025-03-06 20:45:54,794 - INFO - training batch 601, loss: 0.728, 19232/28000 datapoints
2025-03-06 20:45:54,920 - INFO - training batch 651, loss: 0.132, 20832/28000 datapoints
2025-03-06 20:45:55,040 - INFO - training batch 701, loss: 0.467, 22432/28000 datapoints
2025-03-06 20:45:55,163 - INFO - training batch 751, loss: 0.363, 24032/28000 datapoints
2025-03-06 20:45:55,283 - INFO - training batch 801, loss: 0.350, 25632/28000 datapoints
2025-03-06 20:45:55,401 - INFO - training batch 851, loss: 0.862, 27232/28000 datapoints
2025-03-06 20:45:55,461 - INFO - validation batch 1, loss: 0.225, 32/6976 datapoints
2025-03-06 20:45:55,504 - INFO - validation batch 51, loss: 1.271, 1632/6976 datapoints
2025-03-06 20:45:55,548 - INFO - validation batch 101, loss: 0.256, 3232/6976 datapoints
2025-03-06 20:45:55,591 - INFO - validation batch 151, loss: 0.605, 4832/6976 datapoints
2025-03-06 20:45:55,638 - INFO - validation batch 201, loss: 0.370, 6432/6976 datapoints
2025-03-06 20:45:55,657 - INFO - Epoch 200/800 done.
2025-03-06 20:45:55,660 - INFO - Final validation performance:
Loss: 0.546, top-1 acc: 0.845top-5 acc: 0.845
2025-03-06 20:45:55,661 - INFO - Beginning epoch 201/800
2025-03-06 20:45:55,683 - INFO - training batch 1, loss: 0.575, 32/28000 datapoints
2025-03-06 20:45:55,821 - INFO - training batch 51, loss: 0.323, 1632/28000 datapoints
2025-03-06 20:45:55,941 - INFO - training batch 101, loss: 0.275, 3232/28000 datapoints
2025-03-06 20:45:56,059 - INFO - training batch 151, loss: 0.880, 4832/28000 datapoints
2025-03-06 20:45:56,196 - INFO - training batch 201, loss: 0.298, 6432/28000 datapoints
2025-03-06 20:45:56,328 - INFO - training batch 251, loss: 0.433, 8032/28000 datapoints
2025-03-06 20:45:56,452 - INFO - training batch 301, loss: 0.740, 9632/28000 datapoints
2025-03-06 20:45:56,572 - INFO - training batch 351, loss: 0.560, 11232/28000 datapoints
2025-03-06 20:45:56,696 - INFO - training batch 401, loss: 0.820, 12832/28000 datapoints
2025-03-06 20:45:56,816 - INFO - training batch 451, loss: 0.408, 14432/28000 datapoints
2025-03-06 20:45:56,942 - INFO - training batch 501, loss: 0.317, 16032/28000 datapoints
2025-03-06 20:45:57,064 - INFO - training batch 551, loss: 0.475, 17632/28000 datapoints
2025-03-06 20:45:57,189 - INFO - training batch 601, loss: 0.724, 19232/28000 datapoints
2025-03-06 20:45:57,310 - INFO - training batch 651, loss: 0.131, 20832/28000 datapoints
2025-03-06 20:45:57,432 - INFO - training batch 701, loss: 0.465, 22432/28000 datapoints
2025-03-06 20:45:57,552 - INFO - training batch 751, loss: 0.361, 24032/28000 datapoints
2025-03-06 20:45:57,676 - INFO - training batch 801, loss: 0.347, 25632/28000 datapoints
2025-03-06 20:45:57,796 - INFO - training batch 851, loss: 0.858, 27232/28000 datapoints
2025-03-06 20:45:57,855 - INFO - validation batch 1, loss: 0.223, 32/6976 datapoints
2025-03-06 20:45:57,899 - INFO - validation batch 51, loss: 1.272, 1632/6976 datapoints
2025-03-06 20:45:57,941 - INFO - validation batch 101, loss: 0.255, 3232/6976 datapoints
2025-03-06 20:45:57,984 - INFO - validation batch 151, loss: 0.601, 4832/6976 datapoints
2025-03-06 20:45:58,037 - INFO - validation batch 201, loss: 0.371, 6432/6976 datapoints
2025-03-06 20:45:58,053 - INFO - Epoch 201/800 done.
2025-03-06 20:45:58,053 - INFO - Final validation performance:
Loss: 0.544, top-1 acc: 0.846top-5 acc: 0.846
2025-03-06 20:45:58,053 - INFO - Beginning epoch 202/800
2025-03-06 20:45:58,057 - INFO - training batch 1, loss: 0.569, 32/28000 datapoints
2025-03-06 20:45:58,183 - INFO - training batch 51, loss: 0.320, 1632/28000 datapoints
2025-03-06 20:45:58,301 - INFO - training batch 101, loss: 0.274, 3232/28000 datapoints
2025-03-06 20:45:58,421 - INFO - training batch 151, loss: 0.877, 4832/28000 datapoints
2025-03-06 20:45:58,559 - INFO - training batch 201, loss: 0.295, 6432/28000 datapoints
2025-03-06 20:45:58,718 - INFO - training batch 251, loss: 0.432, 8032/28000 datapoints
2025-03-06 20:45:58,838 - INFO - training batch 301, loss: 0.739, 9632/28000 datapoints
2025-03-06 20:45:58,958 - INFO - training batch 351, loss: 0.555, 11232/28000 datapoints
2025-03-06 20:45:59,083 - INFO - training batch 401, loss: 0.818, 12832/28000 datapoints
2025-03-06 20:45:59,232 - INFO - training batch 451, loss: 0.405, 14432/28000 datapoints
2025-03-06 20:45:59,353 - INFO - training batch 501, loss: 0.314, 16032/28000 datapoints
2025-03-06 20:45:59,474 - INFO - training batch 551, loss: 0.473, 17632/28000 datapoints
2025-03-06 20:45:59,600 - INFO - training batch 601, loss: 0.720, 19232/28000 datapoints
2025-03-06 20:45:59,729 - INFO - training batch 651, loss: 0.129, 20832/28000 datapoints
2025-03-06 20:45:59,846 - INFO - training batch 701, loss: 0.463, 22432/28000 datapoints
2025-03-06 20:45:59,965 - INFO - training batch 751, loss: 0.360, 24032/28000 datapoints
2025-03-06 20:46:00,093 - INFO - training batch 801, loss: 0.344, 25632/28000 datapoints
2025-03-06 20:46:00,216 - INFO - training batch 851, loss: 0.853, 27232/28000 datapoints
2025-03-06 20:46:00,275 - INFO - validation batch 1, loss: 0.220, 32/6976 datapoints
2025-03-06 20:46:00,319 - INFO - validation batch 51, loss: 1.273, 1632/6976 datapoints
2025-03-06 20:46:00,361 - INFO - validation batch 101, loss: 0.253, 3232/6976 datapoints
2025-03-06 20:46:00,404 - INFO - validation batch 151, loss: 0.599, 4832/6976 datapoints
2025-03-06 20:46:00,449 - INFO - validation batch 201, loss: 0.370, 6432/6976 datapoints
2025-03-06 20:46:00,464 - INFO - Epoch 202/800 done.
2025-03-06 20:46:00,464 - INFO - Final validation performance:
Loss: 0.543, top-1 acc: 0.846top-5 acc: 0.846
2025-03-06 20:46:00,465 - INFO - Beginning epoch 203/800
2025-03-06 20:46:00,468 - INFO - training batch 1, loss: 0.564, 32/28000 datapoints
2025-03-06 20:46:00,592 - INFO - training batch 51, loss: 0.317, 1632/28000 datapoints
2025-03-06 20:46:00,721 - INFO - training batch 101, loss: 0.274, 3232/28000 datapoints
2025-03-06 20:46:00,845 - INFO - training batch 151, loss: 0.877, 4832/28000 datapoints
2025-03-06 20:46:00,974 - INFO - training batch 201, loss: 0.292, 6432/28000 datapoints
2025-03-06 20:46:01,094 - INFO - training batch 251, loss: 0.430, 8032/28000 datapoints
2025-03-06 20:46:01,215 - INFO - training batch 301, loss: 0.737, 9632/28000 datapoints
2025-03-06 20:46:01,338 - INFO - training batch 351, loss: 0.550, 11232/28000 datapoints
2025-03-06 20:46:01,457 - INFO - training batch 401, loss: 0.815, 12832/28000 datapoints
2025-03-06 20:46:01,576 - INFO - training batch 451, loss: 0.403, 14432/28000 datapoints
2025-03-06 20:46:01,699 - INFO - training batch 501, loss: 0.311, 16032/28000 datapoints
2025-03-06 20:46:01,821 - INFO - training batch 551, loss: 0.471, 17632/28000 datapoints
2025-03-06 20:46:01,941 - INFO - training batch 601, loss: 0.716, 19232/28000 datapoints
2025-03-06 20:46:02,061 - INFO - training batch 651, loss: 0.127, 20832/28000 datapoints
2025-03-06 20:46:02,188 - INFO - training batch 701, loss: 0.460, 22432/28000 datapoints
2025-03-06 20:46:02,308 - INFO - training batch 751, loss: 0.358, 24032/28000 datapoints
2025-03-06 20:46:02,428 - INFO - training batch 801, loss: 0.341, 25632/28000 datapoints
2025-03-06 20:46:02,564 - INFO - training batch 851, loss: 0.849, 27232/28000 datapoints
2025-03-06 20:46:02,625 - INFO - validation batch 1, loss: 0.217, 32/6976 datapoints
2025-03-06 20:46:02,672 - INFO - validation batch 51, loss: 1.273, 1632/6976 datapoints
2025-03-06 20:46:02,715 - INFO - validation batch 101, loss: 0.252, 3232/6976 datapoints
2025-03-06 20:46:02,760 - INFO - validation batch 151, loss: 0.594, 4832/6976 datapoints
2025-03-06 20:46:02,804 - INFO - validation batch 201, loss: 0.370, 6432/6976 datapoints
2025-03-06 20:46:02,818 - INFO - Epoch 203/800 done.
2025-03-06 20:46:02,819 - INFO - Final validation performance:
Loss: 0.541, top-1 acc: 0.847top-5 acc: 0.847
2025-03-06 20:46:02,819 - INFO - Beginning epoch 204/800
2025-03-06 20:46:02,823 - INFO - training batch 1, loss: 0.558, 32/28000 datapoints
2025-03-06 20:46:02,947 - INFO - training batch 51, loss: 0.314, 1632/28000 datapoints
2025-03-06 20:46:03,069 - INFO - training batch 101, loss: 0.273, 3232/28000 datapoints
2025-03-06 20:46:03,189 - INFO - training batch 151, loss: 0.875, 4832/28000 datapoints
2025-03-06 20:46:03,313 - INFO - training batch 201, loss: 0.290, 6432/28000 datapoints
2025-03-06 20:46:03,433 - INFO - training batch 251, loss: 0.428, 8032/28000 datapoints
2025-03-06 20:46:03,554 - INFO - training batch 301, loss: 0.736, 9632/28000 datapoints
2025-03-06 20:46:03,675 - INFO - training batch 351, loss: 0.545, 11232/28000 datapoints
2025-03-06 20:46:03,797 - INFO - training batch 401, loss: 0.813, 12832/28000 datapoints
2025-03-06 20:46:03,916 - INFO - training batch 451, loss: 0.400, 14432/28000 datapoints
2025-03-06 20:46:04,035 - INFO - training batch 501, loss: 0.308, 16032/28000 datapoints
2025-03-06 20:46:04,158 - INFO - training batch 551, loss: 0.469, 17632/28000 datapoints
2025-03-06 20:46:04,281 - INFO - training batch 601, loss: 0.713, 19232/28000 datapoints
2025-03-06 20:46:04,401 - INFO - training batch 651, loss: 0.125, 20832/28000 datapoints
2025-03-06 20:46:04,521 - INFO - training batch 701, loss: 0.458, 22432/28000 datapoints
2025-03-06 20:46:04,645 - INFO - training batch 751, loss: 0.356, 24032/28000 datapoints
2025-03-06 20:46:04,765 - INFO - training batch 801, loss: 0.338, 25632/28000 datapoints
2025-03-06 20:46:04,890 - INFO - training batch 851, loss: 0.845, 27232/28000 datapoints
2025-03-06 20:46:04,949 - INFO - validation batch 1, loss: 0.215, 32/6976 datapoints
2025-03-06 20:46:04,993 - INFO - validation batch 51, loss: 1.273, 1632/6976 datapoints
2025-03-06 20:46:05,038 - INFO - validation batch 101, loss: 0.250, 3232/6976 datapoints
2025-03-06 20:46:05,082 - INFO - validation batch 151, loss: 0.591, 4832/6976 datapoints
2025-03-06 20:46:05,125 - INFO - validation batch 201, loss: 0.371, 6432/6976 datapoints
2025-03-06 20:46:05,141 - INFO - Epoch 204/800 done.
2025-03-06 20:46:05,141 - INFO - Final validation performance:
Loss: 0.540, top-1 acc: 0.847top-5 acc: 0.847
2025-03-06 20:46:05,141 - INFO - Beginning epoch 205/800
2025-03-06 20:46:05,145 - INFO - training batch 1, loss: 0.553, 32/28000 datapoints
2025-03-06 20:46:05,266 - INFO - training batch 51, loss: 0.310, 1632/28000 datapoints
2025-03-06 20:46:05,390 - INFO - training batch 101, loss: 0.272, 3232/28000 datapoints
2025-03-06 20:46:05,517 - INFO - training batch 151, loss: 0.873, 4832/28000 datapoints
2025-03-06 20:46:05,643 - INFO - training batch 201, loss: 0.287, 6432/28000 datapoints
2025-03-06 20:46:05,767 - INFO - training batch 251, loss: 0.427, 8032/28000 datapoints
2025-03-06 20:46:05,899 - INFO - training batch 301, loss: 0.734, 9632/28000 datapoints
2025-03-06 20:46:06,022 - INFO - training batch 351, loss: 0.541, 11232/28000 datapoints
2025-03-06 20:46:06,149 - INFO - training batch 401, loss: 0.811, 12832/28000 datapoints
2025-03-06 20:46:06,276 - INFO - training batch 451, loss: 0.398, 14432/28000 datapoints
2025-03-06 20:46:06,400 - INFO - training batch 501, loss: 0.305, 16032/28000 datapoints
2025-03-06 20:46:06,525 - INFO - training batch 551, loss: 0.467, 17632/28000 datapoints
2025-03-06 20:46:06,651 - INFO - training batch 601, loss: 0.710, 19232/28000 datapoints
2025-03-06 20:46:06,775 - INFO - training batch 651, loss: 0.124, 20832/28000 datapoints
2025-03-06 20:46:06,899 - INFO - training batch 701, loss: 0.455, 22432/28000 datapoints
2025-03-06 20:46:07,022 - INFO - training batch 751, loss: 0.355, 24032/28000 datapoints
2025-03-06 20:46:07,144 - INFO - training batch 801, loss: 0.335, 25632/28000 datapoints
2025-03-06 20:46:07,266 - INFO - training batch 851, loss: 0.841, 27232/28000 datapoints
2025-03-06 20:46:07,330 - INFO - validation batch 1, loss: 0.212, 32/6976 datapoints
2025-03-06 20:46:07,376 - INFO - validation batch 51, loss: 1.274, 1632/6976 datapoints
2025-03-06 20:46:07,421 - INFO - validation batch 101, loss: 0.249, 3232/6976 datapoints
2025-03-06 20:46:07,466 - INFO - validation batch 151, loss: 0.588, 4832/6976 datapoints
2025-03-06 20:46:07,510 - INFO - validation batch 201, loss: 0.370, 6432/6976 datapoints
2025-03-06 20:46:07,525 - INFO - Epoch 205/800 done.
2025-03-06 20:46:07,525 - INFO - Final validation performance:
Loss: 0.539, top-1 acc: 0.848top-5 acc: 0.848
2025-03-06 20:46:07,526 - INFO - Beginning epoch 206/800
2025-03-06 20:46:07,529 - INFO - training batch 1, loss: 0.547, 32/28000 datapoints
2025-03-06 20:46:07,653 - INFO - training batch 51, loss: 0.307, 1632/28000 datapoints
2025-03-06 20:46:07,775 - INFO - training batch 101, loss: 0.272, 3232/28000 datapoints
2025-03-06 20:46:07,899 - INFO - training batch 151, loss: 0.870, 4832/28000 datapoints
2025-03-06 20:46:08,019 - INFO - training batch 201, loss: 0.284, 6432/28000 datapoints
2025-03-06 20:46:08,141 - INFO - training batch 251, loss: 0.425, 8032/28000 datapoints
2025-03-06 20:46:08,260 - INFO - training batch 301, loss: 0.733, 9632/28000 datapoints
2025-03-06 20:46:08,381 - INFO - training batch 351, loss: 0.536, 11232/28000 datapoints
2025-03-06 20:46:08,512 - INFO - training batch 401, loss: 0.808, 12832/28000 datapoints
2025-03-06 20:46:08,640 - INFO - training batch 451, loss: 0.395, 14432/28000 datapoints
2025-03-06 20:46:08,785 - INFO - training batch 501, loss: 0.302, 16032/28000 datapoints
2025-03-06 20:46:08,905 - INFO - training batch 551, loss: 0.465, 17632/28000 datapoints
2025-03-06 20:46:09,035 - INFO - training batch 601, loss: 0.707, 19232/28000 datapoints
2025-03-06 20:46:09,164 - INFO - training batch 651, loss: 0.122, 20832/28000 datapoints
2025-03-06 20:46:09,285 - INFO - training batch 701, loss: 0.453, 22432/28000 datapoints
2025-03-06 20:46:09,408 - INFO - training batch 751, loss: 0.353, 24032/28000 datapoints
2025-03-06 20:46:09,528 - INFO - training batch 801, loss: 0.333, 25632/28000 datapoints
2025-03-06 20:46:09,654 - INFO - training batch 851, loss: 0.836, 27232/28000 datapoints
2025-03-06 20:46:09,713 - INFO - validation batch 1, loss: 0.210, 32/6976 datapoints
2025-03-06 20:46:09,757 - INFO - validation batch 51, loss: 1.275, 1632/6976 datapoints
2025-03-06 20:46:09,800 - INFO - validation batch 101, loss: 0.248, 3232/6976 datapoints
2025-03-06 20:46:09,845 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 20:46:09,888 - INFO - validation batch 201, loss: 0.371, 6432/6976 datapoints
2025-03-06 20:46:09,903 - INFO - Epoch 206/800 done.
2025-03-06 20:46:09,903 - INFO - Final validation performance:
Loss: 0.538, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 20:46:09,903 - INFO - Beginning epoch 207/800
2025-03-06 20:46:09,907 - INFO - training batch 1, loss: 0.542, 32/28000 datapoints
2025-03-06 20:46:10,029 - INFO - training batch 51, loss: 0.304, 1632/28000 datapoints
2025-03-06 20:46:10,152 - INFO - training batch 101, loss: 0.271, 3232/28000 datapoints
2025-03-06 20:46:10,276 - INFO - training batch 151, loss: 0.868, 4832/28000 datapoints
2025-03-06 20:46:10,397 - INFO - training batch 201, loss: 0.281, 6432/28000 datapoints
2025-03-06 20:46:10,517 - INFO - training batch 251, loss: 0.424, 8032/28000 datapoints
2025-03-06 20:46:10,641 - INFO - training batch 301, loss: 0.732, 9632/28000 datapoints
2025-03-06 20:46:10,761 - INFO - training batch 351, loss: 0.531, 11232/28000 datapoints
2025-03-06 20:46:10,884 - INFO - training batch 401, loss: 0.805, 12832/28000 datapoints
2025-03-06 20:46:11,004 - INFO - training batch 451, loss: 0.394, 14432/28000 datapoints
2025-03-06 20:46:11,124 - INFO - training batch 501, loss: 0.297, 16032/28000 datapoints
2025-03-06 20:46:11,245 - INFO - training batch 551, loss: 0.462, 17632/28000 datapoints
2025-03-06 20:46:11,366 - INFO - training batch 601, loss: 0.704, 19232/28000 datapoints
2025-03-06 20:46:11,487 - INFO - training batch 651, loss: 0.120, 20832/28000 datapoints
2025-03-06 20:46:11,606 - INFO - training batch 701, loss: 0.450, 22432/28000 datapoints
2025-03-06 20:46:11,728 - INFO - training batch 751, loss: 0.352, 24032/28000 datapoints
2025-03-06 20:46:11,847 - INFO - training batch 801, loss: 0.330, 25632/28000 datapoints
2025-03-06 20:46:11,970 - INFO - training batch 851, loss: 0.833, 27232/28000 datapoints
2025-03-06 20:46:12,029 - INFO - validation batch 1, loss: 0.207, 32/6976 datapoints
2025-03-06 20:46:12,071 - INFO - validation batch 51, loss: 1.276, 1632/6976 datapoints
2025-03-06 20:46:12,114 - INFO - validation batch 101, loss: 0.247, 3232/6976 datapoints
2025-03-06 20:46:12,161 - INFO - validation batch 151, loss: 0.582, 4832/6976 datapoints
2025-03-06 20:46:12,205 - INFO - validation batch 201, loss: 0.371, 6432/6976 datapoints
2025-03-06 20:46:12,221 - INFO - Epoch 207/800 done.
2025-03-06 20:46:12,221 - INFO - Final validation performance:
Loss: 0.537, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 20:46:12,221 - INFO - Beginning epoch 208/800
2025-03-06 20:46:12,225 - INFO - training batch 1, loss: 0.537, 32/28000 datapoints
2025-03-06 20:46:12,345 - INFO - training batch 51, loss: 0.300, 1632/28000 datapoints
2025-03-06 20:46:12,466 - INFO - training batch 101, loss: 0.270, 3232/28000 datapoints
2025-03-06 20:46:12,586 - INFO - training batch 151, loss: 0.865, 4832/28000 datapoints
2025-03-06 20:46:12,710 - INFO - training batch 201, loss: 0.278, 6432/28000 datapoints
2025-03-06 20:46:12,828 - INFO - training batch 251, loss: 0.422, 8032/28000 datapoints
2025-03-06 20:46:12,948 - INFO - training batch 301, loss: 0.730, 9632/28000 datapoints
2025-03-06 20:46:13,068 - INFO - training batch 351, loss: 0.527, 11232/28000 datapoints
2025-03-06 20:46:13,189 - INFO - training batch 401, loss: 0.803, 12832/28000 datapoints
2025-03-06 20:46:13,314 - INFO - training batch 451, loss: 0.392, 14432/28000 datapoints
2025-03-06 20:46:13,441 - INFO - training batch 501, loss: 0.294, 16032/28000 datapoints
2025-03-06 20:46:13,570 - INFO - training batch 551, loss: 0.460, 17632/28000 datapoints
2025-03-06 20:46:13,693 - INFO - training batch 601, loss: 0.702, 19232/28000 datapoints
2025-03-06 20:46:13,814 - INFO - training batch 651, loss: 0.119, 20832/28000 datapoints
2025-03-06 20:46:13,937 - INFO - training batch 701, loss: 0.448, 22432/28000 datapoints
2025-03-06 20:46:14,056 - INFO - training batch 751, loss: 0.349, 24032/28000 datapoints
2025-03-06 20:46:14,179 - INFO - training batch 801, loss: 0.327, 25632/28000 datapoints
2025-03-06 20:46:14,300 - INFO - training batch 851, loss: 0.828, 27232/28000 datapoints
2025-03-06 20:46:14,358 - INFO - validation batch 1, loss: 0.206, 32/6976 datapoints
2025-03-06 20:46:14,404 - INFO - validation batch 51, loss: 1.279, 1632/6976 datapoints
2025-03-06 20:46:14,447 - INFO - validation batch 101, loss: 0.246, 3232/6976 datapoints
2025-03-06 20:46:14,491 - INFO - validation batch 151, loss: 0.580, 4832/6976 datapoints
2025-03-06 20:46:14,534 - INFO - validation batch 201, loss: 0.373, 6432/6976 datapoints
2025-03-06 20:46:14,549 - INFO - Epoch 208/800 done.
2025-03-06 20:46:14,549 - INFO - Final validation performance:
Loss: 0.537, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 20:46:14,550 - INFO - Beginning epoch 209/800
2025-03-06 20:46:14,553 - INFO - training batch 1, loss: 0.531, 32/28000 datapoints
2025-03-06 20:46:14,690 - INFO - training batch 51, loss: 0.297, 1632/28000 datapoints
2025-03-06 20:46:14,808 - INFO - training batch 101, loss: 0.269, 3232/28000 datapoints
2025-03-06 20:46:14,938 - INFO - training batch 151, loss: 0.864, 4832/28000 datapoints
2025-03-06 20:46:15,063 - INFO - training batch 201, loss: 0.276, 6432/28000 datapoints
2025-03-06 20:46:15,184 - INFO - training batch 251, loss: 0.421, 8032/28000 datapoints
2025-03-06 20:46:15,308 - INFO - training batch 301, loss: 0.729, 9632/28000 datapoints
2025-03-06 20:46:15,432 - INFO - training batch 351, loss: 0.522, 11232/28000 datapoints
2025-03-06 20:46:15,553 - INFO - training batch 401, loss: 0.801, 12832/28000 datapoints
2025-03-06 20:46:15,676 - INFO - training batch 451, loss: 0.390, 14432/28000 datapoints
2025-03-06 20:46:15,795 - INFO - training batch 501, loss: 0.291, 16032/28000 datapoints
2025-03-06 20:46:15,915 - INFO - training batch 551, loss: 0.458, 17632/28000 datapoints
2025-03-06 20:46:16,035 - INFO - training batch 601, loss: 0.699, 19232/28000 datapoints
2025-03-06 20:46:16,167 - INFO - training batch 651, loss: 0.118, 20832/28000 datapoints
2025-03-06 20:46:16,289 - INFO - training batch 701, loss: 0.445, 22432/28000 datapoints
2025-03-06 20:46:16,408 - INFO - training batch 751, loss: 0.348, 24032/28000 datapoints
2025-03-06 20:46:16,526 - INFO - training batch 801, loss: 0.325, 25632/28000 datapoints
2025-03-06 20:46:16,683 - INFO - training batch 851, loss: 0.825, 27232/28000 datapoints
2025-03-06 20:46:16,759 - INFO - validation batch 1, loss: 0.204, 32/6976 datapoints
2025-03-06 20:46:16,813 - INFO - validation batch 51, loss: 1.281, 1632/6976 datapoints
2025-03-06 20:46:16,866 - INFO - validation batch 101, loss: 0.245, 3232/6976 datapoints
2025-03-06 20:46:16,925 - INFO - validation batch 151, loss: 0.579, 4832/6976 datapoints
2025-03-06 20:46:16,980 - INFO - validation batch 201, loss: 0.373, 6432/6976 datapoints
2025-03-06 20:46:16,996 - INFO - Epoch 209/800 done.
2025-03-06 20:46:16,996 - INFO - Final validation performance:
Loss: 0.536, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 20:46:16,997 - INFO - Beginning epoch 210/800
2025-03-06 20:46:17,000 - INFO - training batch 1, loss: 0.525, 32/28000 datapoints
2025-03-06 20:46:17,128 - INFO - training batch 51, loss: 0.294, 1632/28000 datapoints
2025-03-06 20:46:17,248 - INFO - training batch 101, loss: 0.268, 3232/28000 datapoints
2025-03-06 20:46:17,374 - INFO - training batch 151, loss: 0.861, 4832/28000 datapoints
2025-03-06 20:46:17,542 - INFO - training batch 201, loss: 0.274, 6432/28000 datapoints
2025-03-06 20:46:17,664 - INFO - training batch 251, loss: 0.419, 8032/28000 datapoints
2025-03-06 20:46:17,785 - INFO - training batch 301, loss: 0.728, 9632/28000 datapoints
2025-03-06 20:46:17,904 - INFO - training batch 351, loss: 0.517, 11232/28000 datapoints
2025-03-06 20:46:18,024 - INFO - training batch 401, loss: 0.798, 12832/28000 datapoints
2025-03-06 20:46:18,143 - INFO - training batch 451, loss: 0.388, 14432/28000 datapoints
2025-03-06 20:46:18,267 - INFO - training batch 501, loss: 0.289, 16032/28000 datapoints
2025-03-06 20:46:18,386 - INFO - training batch 551, loss: 0.456, 17632/28000 datapoints
2025-03-06 20:46:18,507 - INFO - training batch 601, loss: 0.696, 19232/28000 datapoints
2025-03-06 20:46:18,628 - INFO - training batch 651, loss: 0.116, 20832/28000 datapoints
2025-03-06 20:46:18,757 - INFO - training batch 701, loss: 0.443, 22432/28000 datapoints
2025-03-06 20:46:18,896 - INFO - training batch 751, loss: 0.345, 24032/28000 datapoints
2025-03-06 20:46:19,015 - INFO - training batch 801, loss: 0.322, 25632/28000 datapoints
2025-03-06 20:46:19,133 - INFO - training batch 851, loss: 0.820, 27232/28000 datapoints
2025-03-06 20:46:19,193 - INFO - validation batch 1, loss: 0.202, 32/6976 datapoints
2025-03-06 20:46:19,236 - INFO - validation batch 51, loss: 1.282, 1632/6976 datapoints
2025-03-06 20:46:19,280 - INFO - validation batch 101, loss: 0.244, 3232/6976 datapoints
2025-03-06 20:46:19,323 - INFO - validation batch 151, loss: 0.576, 4832/6976 datapoints
2025-03-06 20:46:19,366 - INFO - validation batch 201, loss: 0.372, 6432/6976 datapoints
2025-03-06 20:46:19,380 - INFO - Epoch 210/800 done.
2025-03-06 20:46:19,380 - INFO - Final validation performance:
Loss: 0.535, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 20:46:19,381 - INFO - Beginning epoch 211/800
2025-03-06 20:46:19,385 - INFO - training batch 1, loss: 0.520, 32/28000 datapoints
2025-03-06 20:46:19,508 - INFO - training batch 51, loss: 0.291, 1632/28000 datapoints
2025-03-06 20:46:19,627 - INFO - training batch 101, loss: 0.268, 3232/28000 datapoints
2025-03-06 20:46:19,754 - INFO - training batch 151, loss: 0.857, 4832/28000 datapoints
2025-03-06 20:46:19,875 - INFO - training batch 201, loss: 0.271, 6432/28000 datapoints
2025-03-06 20:46:19,996 - INFO - training batch 251, loss: 0.418, 8032/28000 datapoints
2025-03-06 20:46:20,117 - INFO - training batch 301, loss: 0.727, 9632/28000 datapoints
2025-03-06 20:46:20,238 - INFO - training batch 351, loss: 0.512, 11232/28000 datapoints
2025-03-06 20:46:20,358 - INFO - training batch 401, loss: 0.796, 12832/28000 datapoints
2025-03-06 20:46:20,477 - INFO - training batch 451, loss: 0.386, 14432/28000 datapoints
2025-03-06 20:46:20,600 - INFO - training batch 501, loss: 0.286, 16032/28000 datapoints
2025-03-06 20:46:20,739 - INFO - training batch 551, loss: 0.454, 17632/28000 datapoints
2025-03-06 20:46:20,856 - INFO - training batch 601, loss: 0.692, 19232/28000 datapoints
2025-03-06 20:46:20,976 - INFO - training batch 651, loss: 0.115, 20832/28000 datapoints
2025-03-06 20:46:21,103 - INFO - training batch 701, loss: 0.440, 22432/28000 datapoints
2025-03-06 20:46:21,224 - INFO - training batch 751, loss: 0.343, 24032/28000 datapoints
2025-03-06 20:46:21,348 - INFO - training batch 801, loss: 0.320, 25632/28000 datapoints
2025-03-06 20:46:21,470 - INFO - training batch 851, loss: 0.816, 27232/28000 datapoints
2025-03-06 20:46:21,532 - INFO - validation batch 1, loss: 0.200, 32/6976 datapoints
2025-03-06 20:46:21,576 - INFO - validation batch 51, loss: 1.282, 1632/6976 datapoints
2025-03-06 20:46:21,620 - INFO - validation batch 101, loss: 0.243, 3232/6976 datapoints
2025-03-06 20:46:21,669 - INFO - validation batch 151, loss: 0.573, 4832/6976 datapoints
2025-03-06 20:46:21,713 - INFO - validation batch 201, loss: 0.371, 6432/6976 datapoints
2025-03-06 20:46:21,727 - INFO - Epoch 211/800 done.
2025-03-06 20:46:21,728 - INFO - Final validation performance:
Loss: 0.534, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 20:46:21,728 - INFO - Beginning epoch 212/800
2025-03-06 20:46:21,732 - INFO - training batch 1, loss: 0.516, 32/28000 datapoints
2025-03-06 20:46:21,853 - INFO - training batch 51, loss: 0.288, 1632/28000 datapoints
2025-03-06 20:46:21,976 - INFO - training batch 101, loss: 0.267, 3232/28000 datapoints
2025-03-06 20:46:22,098 - INFO - training batch 151, loss: 0.854, 4832/28000 datapoints
2025-03-06 20:46:22,221 - INFO - training batch 201, loss: 0.269, 6432/28000 datapoints
2025-03-06 20:46:22,340 - INFO - training batch 251, loss: 0.416, 8032/28000 datapoints
2025-03-06 20:46:22,459 - INFO - training batch 301, loss: 0.726, 9632/28000 datapoints
2025-03-06 20:46:22,578 - INFO - training batch 351, loss: 0.507, 11232/28000 datapoints
2025-03-06 20:46:22,699 - INFO - training batch 401, loss: 0.794, 12832/28000 datapoints
2025-03-06 20:46:22,818 - INFO - training batch 451, loss: 0.384, 14432/28000 datapoints
2025-03-06 20:46:22,944 - INFO - training batch 501, loss: 0.284, 16032/28000 datapoints
2025-03-06 20:46:23,070 - INFO - training batch 551, loss: 0.453, 17632/28000 datapoints
2025-03-06 20:46:23,194 - INFO - training batch 601, loss: 0.689, 19232/28000 datapoints
2025-03-06 20:46:23,315 - INFO - training batch 651, loss: 0.114, 20832/28000 datapoints
2025-03-06 20:46:23,436 - INFO - training batch 701, loss: 0.437, 22432/28000 datapoints
2025-03-06 20:46:23,555 - INFO - training batch 751, loss: 0.340, 24032/28000 datapoints
2025-03-06 20:46:23,680 - INFO - training batch 801, loss: 0.317, 25632/28000 datapoints
2025-03-06 20:46:23,800 - INFO - training batch 851, loss: 0.813, 27232/28000 datapoints
2025-03-06 20:46:23,859 - INFO - validation batch 1, loss: 0.198, 32/6976 datapoints
2025-03-06 20:46:23,902 - INFO - validation batch 51, loss: 1.284, 1632/6976 datapoints
2025-03-06 20:46:23,947 - INFO - validation batch 101, loss: 0.243, 3232/6976 datapoints
2025-03-06 20:46:23,990 - INFO - validation batch 151, loss: 0.571, 4832/6976 datapoints
2025-03-06 20:46:24,033 - INFO - validation batch 201, loss: 0.371, 6432/6976 datapoints
2025-03-06 20:46:24,050 - INFO - Epoch 212/800 done.
2025-03-06 20:46:24,050 - INFO - Final validation performance:
Loss: 0.533, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 20:46:24,051 - INFO - Beginning epoch 213/800
2025-03-06 20:46:24,054 - INFO - training batch 1, loss: 0.511, 32/28000 datapoints
2025-03-06 20:46:24,174 - INFO - training batch 51, loss: 0.286, 1632/28000 datapoints
2025-03-06 20:46:24,296 - INFO - training batch 101, loss: 0.267, 3232/28000 datapoints
2025-03-06 20:46:24,416 - INFO - training batch 151, loss: 0.852, 4832/28000 datapoints
2025-03-06 20:46:24,534 - INFO - training batch 201, loss: 0.268, 6432/28000 datapoints
2025-03-06 20:46:24,658 - INFO - training batch 251, loss: 0.415, 8032/28000 datapoints
2025-03-06 20:46:24,777 - INFO - training batch 301, loss: 0.725, 9632/28000 datapoints
2025-03-06 20:46:24,900 - INFO - training batch 351, loss: 0.504, 11232/28000 datapoints
2025-03-06 20:46:25,021 - INFO - training batch 401, loss: 0.791, 12832/28000 datapoints
2025-03-06 20:46:25,141 - INFO - training batch 451, loss: 0.382, 14432/28000 datapoints
2025-03-06 20:46:25,262 - INFO - training batch 501, loss: 0.282, 16032/28000 datapoints
2025-03-06 20:46:25,383 - INFO - training batch 551, loss: 0.451, 17632/28000 datapoints
2025-03-06 20:46:25,502 - INFO - training batch 601, loss: 0.687, 19232/28000 datapoints
2025-03-06 20:46:25,629 - INFO - training batch 651, loss: 0.112, 20832/28000 datapoints
2025-03-06 20:46:25,757 - INFO - training batch 701, loss: 0.435, 22432/28000 datapoints
2025-03-06 20:46:25,879 - INFO - training batch 751, loss: 0.339, 24032/28000 datapoints
2025-03-06 20:46:26,004 - INFO - training batch 801, loss: 0.314, 25632/28000 datapoints
2025-03-06 20:46:26,128 - INFO - training batch 851, loss: 0.807, 27232/28000 datapoints
2025-03-06 20:46:26,190 - INFO - validation batch 1, loss: 0.196, 32/6976 datapoints
2025-03-06 20:46:26,242 - INFO - validation batch 51, loss: 1.284, 1632/6976 datapoints
2025-03-06 20:46:26,296 - INFO - validation batch 101, loss: 0.242, 3232/6976 datapoints
2025-03-06 20:46:26,355 - INFO - validation batch 151, loss: 0.568, 4832/6976 datapoints
2025-03-06 20:46:26,403 - INFO - validation batch 201, loss: 0.370, 6432/6976 datapoints
2025-03-06 20:46:26,419 - INFO - Epoch 213/800 done.
2025-03-06 20:46:26,420 - INFO - Final validation performance:
Loss: 0.532, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 20:46:26,420 - INFO - Beginning epoch 214/800
2025-03-06 20:46:26,424 - INFO - training batch 1, loss: 0.506, 32/28000 datapoints
2025-03-06 20:46:26,550 - INFO - training batch 51, loss: 0.283, 1632/28000 datapoints
2025-03-06 20:46:26,679 - INFO - training batch 101, loss: 0.266, 3232/28000 datapoints
2025-03-06 20:46:26,803 - INFO - training batch 151, loss: 0.849, 4832/28000 datapoints
2025-03-06 20:46:26,940 - INFO - training batch 201, loss: 0.265, 6432/28000 datapoints
2025-03-06 20:46:27,063 - INFO - training batch 251, loss: 0.414, 8032/28000 datapoints
2025-03-06 20:46:27,184 - INFO - training batch 301, loss: 0.723, 9632/28000 datapoints
2025-03-06 20:46:27,313 - INFO - training batch 351, loss: 0.499, 11232/28000 datapoints
2025-03-06 20:46:27,441 - INFO - training batch 401, loss: 0.789, 12832/28000 datapoints
2025-03-06 20:46:27,567 - INFO - training batch 451, loss: 0.380, 14432/28000 datapoints
2025-03-06 20:46:27,695 - INFO - training batch 501, loss: 0.280, 16032/28000 datapoints
2025-03-06 20:46:27,821 - INFO - training batch 551, loss: 0.449, 17632/28000 datapoints
2025-03-06 20:46:27,944 - INFO - training batch 601, loss: 0.684, 19232/28000 datapoints
2025-03-06 20:46:28,067 - INFO - training batch 651, loss: 0.111, 20832/28000 datapoints
2025-03-06 20:46:28,189 - INFO - training batch 701, loss: 0.432, 22432/28000 datapoints
2025-03-06 20:46:28,314 - INFO - training batch 751, loss: 0.337, 24032/28000 datapoints
2025-03-06 20:46:28,437 - INFO - training batch 801, loss: 0.312, 25632/28000 datapoints
2025-03-06 20:46:28,559 - INFO - training batch 851, loss: 0.803, 27232/28000 datapoints
2025-03-06 20:46:28,621 - INFO - validation batch 1, loss: 0.195, 32/6976 datapoints
2025-03-06 20:46:28,676 - INFO - validation batch 51, loss: 1.285, 1632/6976 datapoints
2025-03-06 20:46:28,721 - INFO - validation batch 101, loss: 0.242, 3232/6976 datapoints
2025-03-06 20:46:28,767 - INFO - validation batch 151, loss: 0.563, 4832/6976 datapoints
2025-03-06 20:46:28,812 - INFO - validation batch 201, loss: 0.370, 6432/6976 datapoints
2025-03-06 20:46:28,827 - INFO - Epoch 214/800 done.
2025-03-06 20:46:28,827 - INFO - Final validation performance:
Loss: 0.531, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 20:46:28,828 - INFO - Beginning epoch 215/800
2025-03-06 20:46:28,832 - INFO - training batch 1, loss: 0.502, 32/28000 datapoints
2025-03-06 20:46:28,978 - INFO - training batch 51, loss: 0.281, 1632/28000 datapoints
2025-03-06 20:46:29,099 - INFO - training batch 101, loss: 0.266, 3232/28000 datapoints
2025-03-06 20:46:29,221 - INFO - training batch 151, loss: 0.846, 4832/28000 datapoints
2025-03-06 20:46:29,341 - INFO - training batch 201, loss: 0.263, 6432/28000 datapoints
2025-03-06 20:46:29,464 - INFO - training batch 251, loss: 0.413, 8032/28000 datapoints
2025-03-06 20:46:29,583 - INFO - training batch 301, loss: 0.721, 9632/28000 datapoints
2025-03-06 20:46:29,710 - INFO - training batch 351, loss: 0.496, 11232/28000 datapoints
2025-03-06 20:46:29,831 - INFO - training batch 401, loss: 0.787, 12832/28000 datapoints
2025-03-06 20:46:29,951 - INFO - training batch 451, loss: 0.378, 14432/28000 datapoints
2025-03-06 20:46:30,070 - INFO - training batch 501, loss: 0.277, 16032/28000 datapoints
2025-03-06 20:46:30,188 - INFO - training batch 551, loss: 0.447, 17632/28000 datapoints
2025-03-06 20:46:30,311 - INFO - training batch 601, loss: 0.681, 19232/28000 datapoints
2025-03-06 20:46:30,433 - INFO - training batch 651, loss: 0.110, 20832/28000 datapoints
2025-03-06 20:46:30,552 - INFO - training batch 701, loss: 0.430, 22432/28000 datapoints
2025-03-06 20:46:30,676 - INFO - training batch 751, loss: 0.336, 24032/28000 datapoints
2025-03-06 20:46:30,796 - INFO - training batch 801, loss: 0.309, 25632/28000 datapoints
2025-03-06 20:46:30,915 - INFO - training batch 851, loss: 0.799, 27232/28000 datapoints
2025-03-06 20:46:30,976 - INFO - validation batch 1, loss: 0.193, 32/6976 datapoints
2025-03-06 20:46:31,019 - INFO - validation batch 51, loss: 1.284, 1632/6976 datapoints
2025-03-06 20:46:31,062 - INFO - validation batch 101, loss: 0.242, 3232/6976 datapoints
2025-03-06 20:46:31,107 - INFO - validation batch 151, loss: 0.560, 4832/6976 datapoints
2025-03-06 20:46:31,152 - INFO - validation batch 201, loss: 0.370, 6432/6976 datapoints
2025-03-06 20:46:31,167 - INFO - Epoch 215/800 done.
2025-03-06 20:46:31,167 - INFO - Final validation performance:
Loss: 0.530, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 20:46:31,168 - INFO - Beginning epoch 216/800
2025-03-06 20:46:31,171 - INFO - training batch 1, loss: 0.497, 32/28000 datapoints
2025-03-06 20:46:31,292 - INFO - training batch 51, loss: 0.279, 1632/28000 datapoints
2025-03-06 20:46:31,411 - INFO - training batch 101, loss: 0.265, 3232/28000 datapoints
2025-03-06 20:46:31,530 - INFO - training batch 151, loss: 0.843, 4832/28000 datapoints
2025-03-06 20:46:31,654 - INFO - training batch 201, loss: 0.261, 6432/28000 datapoints
2025-03-06 20:46:31,772 - INFO - training batch 251, loss: 0.412, 8032/28000 datapoints
2025-03-06 20:46:31,894 - INFO - training batch 301, loss: 0.720, 9632/28000 datapoints
2025-03-06 20:46:32,015 - INFO - training batch 351, loss: 0.492, 11232/28000 datapoints
2025-03-06 20:46:32,133 - INFO - training batch 401, loss: 0.784, 12832/28000 datapoints
2025-03-06 20:46:32,267 - INFO - training batch 451, loss: 0.377, 14432/28000 datapoints
2025-03-06 20:46:32,389 - INFO - training batch 501, loss: 0.275, 16032/28000 datapoints
2025-03-06 20:46:32,508 - INFO - training batch 551, loss: 0.445, 17632/28000 datapoints
2025-03-06 20:46:32,627 - INFO - training batch 601, loss: 0.679, 19232/28000 datapoints
2025-03-06 20:46:32,750 - INFO - training batch 651, loss: 0.109, 20832/28000 datapoints
2025-03-06 20:46:32,870 - INFO - training batch 701, loss: 0.428, 22432/28000 datapoints
2025-03-06 20:46:33,009 - INFO - training batch 751, loss: 0.334, 24032/28000 datapoints
2025-03-06 20:46:33,128 - INFO - training batch 801, loss: 0.307, 25632/28000 datapoints
2025-03-06 20:46:33,251 - INFO - training batch 851, loss: 0.795, 27232/28000 datapoints
2025-03-06 20:46:33,311 - INFO - validation batch 1, loss: 0.191, 32/6976 datapoints
2025-03-06 20:46:33,358 - INFO - validation batch 51, loss: 1.284, 1632/6976 datapoints
2025-03-06 20:46:33,406 - INFO - validation batch 101, loss: 0.242, 3232/6976 datapoints
2025-03-06 20:46:33,455 - INFO - validation batch 151, loss: 0.557, 4832/6976 datapoints
2025-03-06 20:46:33,498 - INFO - validation batch 201, loss: 0.370, 6432/6976 datapoints
2025-03-06 20:46:33,513 - INFO - Epoch 216/800 done.
2025-03-06 20:46:33,513 - INFO - Final validation performance:
Loss: 0.529, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 20:46:33,514 - INFO - Beginning epoch 217/800
2025-03-06 20:46:33,518 - INFO - training batch 1, loss: 0.492, 32/28000 datapoints
2025-03-06 20:46:33,653 - INFO - training batch 51, loss: 0.277, 1632/28000 datapoints
2025-03-06 20:46:33,777 - INFO - training batch 101, loss: 0.264, 3232/28000 datapoints
2025-03-06 20:46:33,897 - INFO - training batch 151, loss: 0.840, 4832/28000 datapoints
2025-03-06 20:46:34,019 - INFO - training batch 201, loss: 0.259, 6432/28000 datapoints
2025-03-06 20:46:34,138 - INFO - training batch 251, loss: 0.410, 8032/28000 datapoints
2025-03-06 20:46:34,261 - INFO - training batch 301, loss: 0.719, 9632/28000 datapoints
2025-03-06 20:46:34,381 - INFO - training batch 351, loss: 0.488, 11232/28000 datapoints
2025-03-06 20:46:34,500 - INFO - training batch 401, loss: 0.782, 12832/28000 datapoints
2025-03-06 20:46:34,619 - INFO - training batch 451, loss: 0.375, 14432/28000 datapoints
2025-03-06 20:46:34,741 - INFO - training batch 501, loss: 0.272, 16032/28000 datapoints
2025-03-06 20:46:34,861 - INFO - training batch 551, loss: 0.442, 17632/28000 datapoints
2025-03-06 20:46:34,984 - INFO - training batch 601, loss: 0.677, 19232/28000 datapoints
2025-03-06 20:46:35,105 - INFO - training batch 651, loss: 0.108, 20832/28000 datapoints
2025-03-06 20:46:35,225 - INFO - training batch 701, loss: 0.426, 22432/28000 datapoints
2025-03-06 20:46:35,346 - INFO - training batch 751, loss: 0.333, 24032/28000 datapoints
2025-03-06 20:46:35,467 - INFO - training batch 801, loss: 0.304, 25632/28000 datapoints
2025-03-06 20:46:35,586 - INFO - training batch 851, loss: 0.790, 27232/28000 datapoints
2025-03-06 20:46:35,648 - INFO - validation batch 1, loss: 0.190, 32/6976 datapoints
2025-03-06 20:46:35,693 - INFO - validation batch 51, loss: 1.283, 1632/6976 datapoints
2025-03-06 20:46:35,738 - INFO - validation batch 101, loss: 0.241, 3232/6976 datapoints
2025-03-06 20:46:35,780 - INFO - validation batch 151, loss: 0.553, 4832/6976 datapoints
2025-03-06 20:46:35,824 - INFO - validation batch 201, loss: 0.369, 6432/6976 datapoints
2025-03-06 20:46:35,839 - INFO - Epoch 217/800 done.
2025-03-06 20:46:35,839 - INFO - Final validation performance:
Loss: 0.527, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 20:46:35,840 - INFO - Beginning epoch 218/800
2025-03-06 20:46:35,843 - INFO - training batch 1, loss: 0.488, 32/28000 datapoints
2025-03-06 20:46:35,964 - INFO - training batch 51, loss: 0.275, 1632/28000 datapoints
2025-03-06 20:46:36,085 - INFO - training batch 101, loss: 0.263, 3232/28000 datapoints
2025-03-06 20:46:36,218 - INFO - training batch 151, loss: 0.838, 4832/28000 datapoints
2025-03-06 20:46:36,349 - INFO - training batch 201, loss: 0.257, 6432/28000 datapoints
2025-03-06 20:46:36,470 - INFO - training batch 251, loss: 0.410, 8032/28000 datapoints
2025-03-06 20:46:36,588 - INFO - training batch 301, loss: 0.718, 9632/28000 datapoints
2025-03-06 20:46:36,709 - INFO - training batch 351, loss: 0.484, 11232/28000 datapoints
2025-03-06 20:46:36,829 - INFO - training batch 401, loss: 0.779, 12832/28000 datapoints
2025-03-06 20:46:36,950 - INFO - training batch 451, loss: 0.373, 14432/28000 datapoints
2025-03-06 20:46:37,068 - INFO - training batch 501, loss: 0.271, 16032/28000 datapoints
2025-03-06 20:46:37,186 - INFO - training batch 551, loss: 0.440, 17632/28000 datapoints
2025-03-06 20:46:37,307 - INFO - training batch 601, loss: 0.674, 19232/28000 datapoints
2025-03-06 20:46:37,427 - INFO - training batch 651, loss: 0.107, 20832/28000 datapoints
2025-03-06 20:46:37,548 - INFO - training batch 701, loss: 0.423, 22432/28000 datapoints
2025-03-06 20:46:37,685 - INFO - training batch 751, loss: 0.331, 24032/28000 datapoints
2025-03-06 20:46:37,803 - INFO - training batch 801, loss: 0.302, 25632/28000 datapoints
2025-03-06 20:46:37,925 - INFO - training batch 851, loss: 0.786, 27232/28000 datapoints
2025-03-06 20:46:37,984 - INFO - validation batch 1, loss: 0.188, 32/6976 datapoints
2025-03-06 20:46:38,027 - INFO - validation batch 51, loss: 1.284, 1632/6976 datapoints
2025-03-06 20:46:38,071 - INFO - validation batch 101, loss: 0.241, 3232/6976 datapoints
2025-03-06 20:46:38,114 - INFO - validation batch 151, loss: 0.550, 4832/6976 datapoints
2025-03-06 20:46:38,156 - INFO - validation batch 201, loss: 0.369, 6432/6976 datapoints
2025-03-06 20:46:38,171 - INFO - Epoch 218/800 done.
2025-03-06 20:46:38,171 - INFO - Final validation performance:
Loss: 0.527, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 20:46:38,172 - INFO - Beginning epoch 219/800
2025-03-06 20:46:38,175 - INFO - training batch 1, loss: 0.484, 32/28000 datapoints
2025-03-06 20:46:38,302 - INFO - training batch 51, loss: 0.273, 1632/28000 datapoints
2025-03-06 20:46:38,421 - INFO - training batch 101, loss: 0.262, 3232/28000 datapoints
2025-03-06 20:46:38,541 - INFO - training batch 151, loss: 0.835, 4832/28000 datapoints
2025-03-06 20:46:38,662 - INFO - training batch 201, loss: 0.255, 6432/28000 datapoints
2025-03-06 20:46:38,785 - INFO - training batch 251, loss: 0.408, 8032/28000 datapoints
2025-03-06 20:46:38,905 - INFO - training batch 301, loss: 0.717, 9632/28000 datapoints
2025-03-06 20:46:39,074 - INFO - training batch 351, loss: 0.480, 11232/28000 datapoints
2025-03-06 20:46:39,196 - INFO - training batch 401, loss: 0.776, 12832/28000 datapoints
2025-03-06 20:46:39,318 - INFO - training batch 451, loss: 0.372, 14432/28000 datapoints
2025-03-06 20:46:39,436 - INFO - training batch 501, loss: 0.269, 16032/28000 datapoints
2025-03-06 20:46:39,572 - INFO - training batch 551, loss: 0.438, 17632/28000 datapoints
2025-03-06 20:46:39,701 - INFO - training batch 601, loss: 0.672, 19232/28000 datapoints
2025-03-06 20:46:39,831 - INFO - training batch 651, loss: 0.106, 20832/28000 datapoints
2025-03-06 20:46:39,957 - INFO - training batch 701, loss: 0.421, 22432/28000 datapoints
2025-03-06 20:46:40,085 - INFO - training batch 751, loss: 0.331, 24032/28000 datapoints
2025-03-06 20:46:40,203 - INFO - training batch 801, loss: 0.300, 25632/28000 datapoints
2025-03-06 20:46:40,327 - INFO - training batch 851, loss: 0.783, 27232/28000 datapoints
2025-03-06 20:46:40,386 - INFO - validation batch 1, loss: 0.186, 32/6976 datapoints
2025-03-06 20:46:40,430 - INFO - validation batch 51, loss: 1.283, 1632/6976 datapoints
2025-03-06 20:46:40,474 - INFO - validation batch 101, loss: 0.241, 3232/6976 datapoints
2025-03-06 20:46:40,517 - INFO - validation batch 151, loss: 0.546, 4832/6976 datapoints
2025-03-06 20:46:40,560 - INFO - validation batch 201, loss: 0.369, 6432/6976 datapoints
2025-03-06 20:46:40,574 - INFO - Epoch 219/800 done.
2025-03-06 20:46:40,574 - INFO - Final validation performance:
Loss: 0.525, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 20:46:40,575 - INFO - Beginning epoch 220/800
2025-03-06 20:46:40,579 - INFO - training batch 1, loss: 0.478, 32/28000 datapoints
2025-03-06 20:46:40,707 - INFO - training batch 51, loss: 0.271, 1632/28000 datapoints
2025-03-06 20:46:40,829 - INFO - training batch 101, loss: 0.262, 3232/28000 datapoints
2025-03-06 20:46:40,949 - INFO - training batch 151, loss: 0.832, 4832/28000 datapoints
2025-03-06 20:46:41,069 - INFO - training batch 201, loss: 0.253, 6432/28000 datapoints
2025-03-06 20:46:41,187 - INFO - training batch 251, loss: 0.406, 8032/28000 datapoints
2025-03-06 20:46:41,310 - INFO - training batch 301, loss: 0.716, 9632/28000 datapoints
2025-03-06 20:46:41,429 - INFO - training batch 351, loss: 0.477, 11232/28000 datapoints
2025-03-06 20:46:41,548 - INFO - training batch 401, loss: 0.774, 12832/28000 datapoints
2025-03-06 20:46:41,671 - INFO - training batch 451, loss: 0.370, 14432/28000 datapoints
2025-03-06 20:46:41,791 - INFO - training batch 501, loss: 0.267, 16032/28000 datapoints
2025-03-06 20:46:41,914 - INFO - training batch 551, loss: 0.435, 17632/28000 datapoints
2025-03-06 20:46:42,033 - INFO - training batch 601, loss: 0.669, 19232/28000 datapoints
2025-03-06 20:46:42,152 - INFO - training batch 651, loss: 0.105, 20832/28000 datapoints
2025-03-06 20:46:42,278 - INFO - training batch 701, loss: 0.418, 22432/28000 datapoints
2025-03-06 20:46:42,401 - INFO - training batch 751, loss: 0.328, 24032/28000 datapoints
2025-03-06 20:46:42,520 - INFO - training batch 801, loss: 0.297, 25632/28000 datapoints
2025-03-06 20:46:42,641 - INFO - training batch 851, loss: 0.778, 27232/28000 datapoints
2025-03-06 20:46:42,701 - INFO - validation batch 1, loss: 0.185, 32/6976 datapoints
2025-03-06 20:46:42,745 - INFO - validation batch 51, loss: 1.283, 1632/6976 datapoints
2025-03-06 20:46:42,789 - INFO - validation batch 101, loss: 0.241, 3232/6976 datapoints
2025-03-06 20:46:42,832 - INFO - validation batch 151, loss: 0.543, 4832/6976 datapoints
2025-03-06 20:46:42,876 - INFO - validation batch 201, loss: 0.368, 6432/6976 datapoints
2025-03-06 20:46:42,891 - INFO - Epoch 220/800 done.
2025-03-06 20:46:42,891 - INFO - Final validation performance:
Loss: 0.524, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 20:46:42,892 - INFO - Beginning epoch 221/800
2025-03-06 20:46:42,896 - INFO - training batch 1, loss: 0.475, 32/28000 datapoints
2025-03-06 20:46:43,017 - INFO - training batch 51, loss: 0.269, 1632/28000 datapoints
2025-03-06 20:46:43,139 - INFO - training batch 101, loss: 0.261, 3232/28000 datapoints
2025-03-06 20:46:43,258 - INFO - training batch 151, loss: 0.830, 4832/28000 datapoints
2025-03-06 20:46:43,379 - INFO - training batch 201, loss: 0.251, 6432/28000 datapoints
2025-03-06 20:46:43,499 - INFO - training batch 251, loss: 0.405, 8032/28000 datapoints
2025-03-06 20:46:43,618 - INFO - training batch 301, loss: 0.715, 9632/28000 datapoints
2025-03-06 20:46:43,742 - INFO - training batch 351, loss: 0.473, 11232/28000 datapoints
2025-03-06 20:46:43,865 - INFO - training batch 401, loss: 0.772, 12832/28000 datapoints
2025-03-06 20:46:43,986 - INFO - training batch 451, loss: 0.368, 14432/28000 datapoints
2025-03-06 20:46:44,108 - INFO - training batch 501, loss: 0.265, 16032/28000 datapoints
2025-03-06 20:46:44,226 - INFO - training batch 551, loss: 0.433, 17632/28000 datapoints
2025-03-06 20:46:44,352 - INFO - training batch 601, loss: 0.667, 19232/28000 datapoints
2025-03-06 20:46:44,473 - INFO - training batch 651, loss: 0.104, 20832/28000 datapoints
2025-03-06 20:46:44,591 - INFO - training batch 701, loss: 0.416, 22432/28000 datapoints
2025-03-06 20:46:44,714 - INFO - training batch 751, loss: 0.326, 24032/28000 datapoints
2025-03-06 20:46:44,834 - INFO - training batch 801, loss: 0.295, 25632/28000 datapoints
2025-03-06 20:46:44,958 - INFO - training batch 851, loss: 0.774, 27232/28000 datapoints
2025-03-06 20:46:45,018 - INFO - validation batch 1, loss: 0.183, 32/6976 datapoints
2025-03-06 20:46:45,062 - INFO - validation batch 51, loss: 1.282, 1632/6976 datapoints
2025-03-06 20:46:45,118 - INFO - validation batch 101, loss: 0.241, 3232/6976 datapoints
2025-03-06 20:46:45,166 - INFO - validation batch 151, loss: 0.540, 4832/6976 datapoints
2025-03-06 20:46:45,209 - INFO - validation batch 201, loss: 0.369, 6432/6976 datapoints
2025-03-06 20:46:45,224 - INFO - Epoch 221/800 done.
2025-03-06 20:46:45,225 - INFO - Final validation performance:
Loss: 0.523, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 20:46:45,225 - INFO - Beginning epoch 222/800
2025-03-06 20:46:45,229 - INFO - training batch 1, loss: 0.471, 32/28000 datapoints
2025-03-06 20:46:45,356 - INFO - training batch 51, loss: 0.267, 1632/28000 datapoints
2025-03-06 20:46:45,475 - INFO - training batch 101, loss: 0.260, 3232/28000 datapoints
2025-03-06 20:46:45,602 - INFO - training batch 151, loss: 0.828, 4832/28000 datapoints
2025-03-06 20:46:45,729 - INFO - training batch 201, loss: 0.250, 6432/28000 datapoints
2025-03-06 20:46:45,852 - INFO - training batch 251, loss: 0.404, 8032/28000 datapoints
2025-03-06 20:46:45,979 - INFO - training batch 301, loss: 0.714, 9632/28000 datapoints
2025-03-06 20:46:46,105 - INFO - training batch 351, loss: 0.469, 11232/28000 datapoints
2025-03-06 20:46:46,229 - INFO - training batch 401, loss: 0.770, 12832/28000 datapoints
2025-03-06 20:46:46,360 - INFO - training batch 451, loss: 0.367, 14432/28000 datapoints
2025-03-06 20:46:46,484 - INFO - training batch 501, loss: 0.263, 16032/28000 datapoints
2025-03-06 20:46:46,606 - INFO - training batch 551, loss: 0.431, 17632/28000 datapoints
2025-03-06 20:46:46,731 - INFO - training batch 601, loss: 0.665, 19232/28000 datapoints
2025-03-06 20:46:46,856 - INFO - training batch 651, loss: 0.103, 20832/28000 datapoints
2025-03-06 20:46:46,978 - INFO - training batch 701, loss: 0.414, 22432/28000 datapoints
2025-03-06 20:46:47,103 - INFO - training batch 751, loss: 0.326, 24032/28000 datapoints
2025-03-06 20:46:47,234 - INFO - training batch 801, loss: 0.293, 25632/28000 datapoints
2025-03-06 20:46:47,358 - INFO - training batch 851, loss: 0.771, 27232/28000 datapoints
2025-03-06 20:46:47,423 - INFO - validation batch 1, loss: 0.182, 32/6976 datapoints
2025-03-06 20:46:47,472 - INFO - validation batch 51, loss: 1.281, 1632/6976 datapoints
2025-03-06 20:46:47,520 - INFO - validation batch 101, loss: 0.241, 3232/6976 datapoints
2025-03-06 20:46:47,565 - INFO - validation batch 151, loss: 0.536, 4832/6976 datapoints
2025-03-06 20:46:47,613 - INFO - validation batch 201, loss: 0.369, 6432/6976 datapoints
2025-03-06 20:46:47,631 - INFO - Epoch 222/800 done.
2025-03-06 20:46:47,631 - INFO - Final validation performance:
Loss: 0.522, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 20:46:47,633 - INFO - Beginning epoch 223/800
2025-03-06 20:46:47,638 - INFO - training batch 1, loss: 0.466, 32/28000 datapoints
2025-03-06 20:46:47,770 - INFO - training batch 51, loss: 0.264, 1632/28000 datapoints
2025-03-06 20:46:47,896 - INFO - training batch 101, loss: 0.259, 3232/28000 datapoints
2025-03-06 20:46:48,021 - INFO - training batch 151, loss: 0.825, 4832/28000 datapoints
2025-03-06 20:46:48,149 - INFO - training batch 201, loss: 0.248, 6432/28000 datapoints
2025-03-06 20:46:48,311 - INFO - training batch 251, loss: 0.404, 8032/28000 datapoints
2025-03-06 20:46:48,443 - INFO - training batch 301, loss: 0.714, 9632/28000 datapoints
2025-03-06 20:46:48,566 - INFO - training batch 351, loss: 0.465, 11232/28000 datapoints
2025-03-06 20:46:48,693 - INFO - training batch 401, loss: 0.767, 12832/28000 datapoints
2025-03-06 20:46:48,819 - INFO - training batch 451, loss: 0.365, 14432/28000 datapoints
2025-03-06 20:46:48,942 - INFO - training batch 501, loss: 0.261, 16032/28000 datapoints
2025-03-06 20:46:49,072 - INFO - training batch 551, loss: 0.429, 17632/28000 datapoints
2025-03-06 20:46:49,217 - INFO - training batch 601, loss: 0.663, 19232/28000 datapoints
2025-03-06 20:46:49,341 - INFO - training batch 651, loss: 0.102, 20832/28000 datapoints
2025-03-06 20:46:49,464 - INFO - training batch 701, loss: 0.412, 22432/28000 datapoints
2025-03-06 20:46:49,588 - INFO - training batch 751, loss: 0.324, 24032/28000 datapoints
2025-03-06 20:46:49,714 - INFO - training batch 801, loss: 0.290, 25632/28000 datapoints
2025-03-06 20:46:49,840 - INFO - training batch 851, loss: 0.765, 27232/28000 datapoints
2025-03-06 20:46:49,904 - INFO - validation batch 1, loss: 0.181, 32/6976 datapoints
2025-03-06 20:46:49,951 - INFO - validation batch 51, loss: 1.281, 1632/6976 datapoints
2025-03-06 20:46:50,000 - INFO - validation batch 101, loss: 0.242, 3232/6976 datapoints
2025-03-06 20:46:50,047 - INFO - validation batch 151, loss: 0.534, 4832/6976 datapoints
2025-03-06 20:46:50,095 - INFO - validation batch 201, loss: 0.368, 6432/6976 datapoints
2025-03-06 20:46:50,110 - INFO - Epoch 223/800 done.
2025-03-06 20:46:50,110 - INFO - Final validation performance:
Loss: 0.521, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 20:46:50,110 - INFO - Beginning epoch 224/800
2025-03-06 20:46:50,114 - INFO - training batch 1, loss: 0.463, 32/28000 datapoints
2025-03-06 20:46:50,240 - INFO - training batch 51, loss: 0.262, 1632/28000 datapoints
2025-03-06 20:46:50,367 - INFO - training batch 101, loss: 0.258, 3232/28000 datapoints
2025-03-06 20:46:50,495 - INFO - training batch 151, loss: 0.824, 4832/28000 datapoints
2025-03-06 20:46:50,622 - INFO - training batch 201, loss: 0.246, 6432/28000 datapoints
2025-03-06 20:46:50,748 - INFO - training batch 251, loss: 0.402, 8032/28000 datapoints
2025-03-06 20:46:50,873 - INFO - training batch 301, loss: 0.712, 9632/28000 datapoints
2025-03-06 20:46:50,998 - INFO - training batch 351, loss: 0.461, 11232/28000 datapoints
2025-03-06 20:46:51,133 - INFO - training batch 401, loss: 0.765, 12832/28000 datapoints
2025-03-06 20:46:51,261 - INFO - training batch 451, loss: 0.363, 14432/28000 datapoints
2025-03-06 20:46:51,384 - INFO - training batch 501, loss: 0.259, 16032/28000 datapoints
2025-03-06 20:46:51,510 - INFO - training batch 551, loss: 0.428, 17632/28000 datapoints
2025-03-06 20:46:51,645 - INFO - training batch 601, loss: 0.660, 19232/28000 datapoints
2025-03-06 20:46:51,770 - INFO - training batch 651, loss: 0.101, 20832/28000 datapoints
2025-03-06 20:46:51,897 - INFO - training batch 701, loss: 0.410, 22432/28000 datapoints
2025-03-06 20:46:52,026 - INFO - training batch 751, loss: 0.324, 24032/28000 datapoints
2025-03-06 20:46:52,150 - INFO - training batch 801, loss: 0.288, 25632/28000 datapoints
2025-03-06 20:46:52,274 - INFO - training batch 851, loss: 0.762, 27232/28000 datapoints
2025-03-06 20:46:52,341 - INFO - validation batch 1, loss: 0.179, 32/6976 datapoints
2025-03-06 20:46:52,388 - INFO - validation batch 51, loss: 1.280, 1632/6976 datapoints
2025-03-06 20:46:52,436 - INFO - validation batch 101, loss: 0.242, 3232/6976 datapoints
2025-03-06 20:46:52,485 - INFO - validation batch 151, loss: 0.530, 4832/6976 datapoints
2025-03-06 20:46:52,530 - INFO - validation batch 201, loss: 0.368, 6432/6976 datapoints
2025-03-06 20:46:52,546 - INFO - Epoch 224/800 done.
2025-03-06 20:46:52,546 - INFO - Final validation performance:
Loss: 0.520, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 20:46:52,546 - INFO - Beginning epoch 225/800
2025-03-06 20:46:52,550 - INFO - training batch 1, loss: 0.459, 32/28000 datapoints
2025-03-06 20:46:52,675 - INFO - training batch 51, loss: 0.260, 1632/28000 datapoints
2025-03-06 20:46:52,793 - INFO - training batch 101, loss: 0.257, 3232/28000 datapoints
2025-03-06 20:46:52,913 - INFO - training batch 151, loss: 0.822, 4832/28000 datapoints
2025-03-06 20:46:53,035 - INFO - training batch 201, loss: 0.244, 6432/28000 datapoints
2025-03-06 20:46:53,156 - INFO - training batch 251, loss: 0.401, 8032/28000 datapoints
2025-03-06 20:46:53,277 - INFO - training batch 301, loss: 0.712, 9632/28000 datapoints
2025-03-06 20:46:53,398 - INFO - training batch 351, loss: 0.458, 11232/28000 datapoints
2025-03-06 20:46:53,521 - INFO - training batch 401, loss: 0.763, 12832/28000 datapoints
2025-03-06 20:46:53,645 - INFO - training batch 451, loss: 0.362, 14432/28000 datapoints
2025-03-06 20:46:53,765 - INFO - training batch 501, loss: 0.257, 16032/28000 datapoints
2025-03-06 20:46:53,886 - INFO - training batch 551, loss: 0.425, 17632/28000 datapoints
2025-03-06 20:46:54,006 - INFO - training batch 601, loss: 0.659, 19232/28000 datapoints
2025-03-06 20:46:54,127 - INFO - training batch 651, loss: 0.100, 20832/28000 datapoints
2025-03-06 20:46:54,246 - INFO - training batch 701, loss: 0.408, 22432/28000 datapoints
2025-03-06 20:46:54,368 - INFO - training batch 751, loss: 0.322, 24032/28000 datapoints
2025-03-06 20:46:54,490 - INFO - training batch 801, loss: 0.286, 25632/28000 datapoints
2025-03-06 20:46:54,609 - INFO - training batch 851, loss: 0.757, 27232/28000 datapoints
2025-03-06 20:46:54,670 - INFO - validation batch 1, loss: 0.178, 32/6976 datapoints
2025-03-06 20:46:54,714 - INFO - validation batch 51, loss: 1.280, 1632/6976 datapoints
2025-03-06 20:46:54,758 - INFO - validation batch 101, loss: 0.242, 3232/6976 datapoints
2025-03-06 20:46:54,802 - INFO - validation batch 151, loss: 0.527, 4832/6976 datapoints
2025-03-06 20:46:54,846 - INFO - validation batch 201, loss: 0.369, 6432/6976 datapoints
2025-03-06 20:46:54,862 - INFO - Epoch 225/800 done.
2025-03-06 20:46:54,862 - INFO - Final validation performance:
Loss: 0.519, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 20:46:54,863 - INFO - Beginning epoch 226/800
2025-03-06 20:46:54,867 - INFO - training batch 1, loss: 0.456, 32/28000 datapoints
2025-03-06 20:46:54,994 - INFO - training batch 51, loss: 0.258, 1632/28000 datapoints
2025-03-06 20:46:55,116 - INFO - training batch 101, loss: 0.258, 3232/28000 datapoints
2025-03-06 20:46:55,236 - INFO - training batch 151, loss: 0.819, 4832/28000 datapoints
2025-03-06 20:46:55,355 - INFO - training batch 201, loss: 0.242, 6432/28000 datapoints
2025-03-06 20:46:55,477 - INFO - training batch 251, loss: 0.400, 8032/28000 datapoints
2025-03-06 20:46:55,598 - INFO - training batch 301, loss: 0.712, 9632/28000 datapoints
2025-03-06 20:46:55,721 - INFO - training batch 351, loss: 0.452, 11232/28000 datapoints
2025-03-06 20:46:55,841 - INFO - training batch 401, loss: 0.761, 12832/28000 datapoints
2025-03-06 20:46:55,962 - INFO - training batch 451, loss: 0.360, 14432/28000 datapoints
2025-03-06 20:46:56,085 - INFO - training batch 501, loss: 0.255, 16032/28000 datapoints
2025-03-06 20:46:56,204 - INFO - training batch 551, loss: 0.423, 17632/28000 datapoints
2025-03-06 20:46:56,326 - INFO - training batch 601, loss: 0.657, 19232/28000 datapoints
2025-03-06 20:46:56,456 - INFO - training batch 651, loss: 0.099, 20832/28000 datapoints
2025-03-06 20:46:56,578 - INFO - training batch 701, loss: 0.405, 22432/28000 datapoints
2025-03-06 20:46:56,699 - INFO - training batch 751, loss: 0.319, 24032/28000 datapoints
2025-03-06 20:46:56,817 - INFO - training batch 801, loss: 0.284, 25632/28000 datapoints
2025-03-06 20:46:56,936 - INFO - training batch 851, loss: 0.753, 27232/28000 datapoints
2025-03-06 20:46:56,997 - INFO - validation batch 1, loss: 0.177, 32/6976 datapoints
2025-03-06 20:46:57,040 - INFO - validation batch 51, loss: 1.279, 1632/6976 datapoints
2025-03-06 20:46:57,084 - INFO - validation batch 101, loss: 0.242, 3232/6976 datapoints
2025-03-06 20:46:57,129 - INFO - validation batch 151, loss: 0.525, 4832/6976 datapoints
2025-03-06 20:46:57,172 - INFO - validation batch 201, loss: 0.368, 6432/6976 datapoints
2025-03-06 20:46:57,186 - INFO - Epoch 226/800 done.
2025-03-06 20:46:57,187 - INFO - Final validation performance:
Loss: 0.518, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 20:46:57,187 - INFO - Beginning epoch 227/800
2025-03-06 20:46:57,191 - INFO - training batch 1, loss: 0.452, 32/28000 datapoints
2025-03-06 20:46:57,325 - INFO - training batch 51, loss: 0.256, 1632/28000 datapoints
2025-03-06 20:46:57,445 - INFO - training batch 101, loss: 0.258, 3232/28000 datapoints
2025-03-06 20:46:57,568 - INFO - training batch 151, loss: 0.818, 4832/28000 datapoints
2025-03-06 20:46:57,699 - INFO - training batch 201, loss: 0.241, 6432/28000 datapoints
2025-03-06 20:46:57,822 - INFO - training batch 251, loss: 0.399, 8032/28000 datapoints
2025-03-06 20:46:57,942 - INFO - training batch 301, loss: 0.711, 9632/28000 datapoints
2025-03-06 20:46:58,067 - INFO - training batch 351, loss: 0.446, 11232/28000 datapoints
2025-03-06 20:46:58,186 - INFO - training batch 401, loss: 0.760, 12832/28000 datapoints
2025-03-06 20:46:58,305 - INFO - training batch 451, loss: 0.359, 14432/28000 datapoints
2025-03-06 20:46:58,430 - INFO - training batch 501, loss: 0.253, 16032/28000 datapoints
2025-03-06 20:46:58,556 - INFO - training batch 551, loss: 0.421, 17632/28000 datapoints
2025-03-06 20:46:58,679 - INFO - training batch 601, loss: 0.654, 19232/28000 datapoints
2025-03-06 20:46:58,801 - INFO - training batch 651, loss: 0.098, 20832/28000 datapoints
2025-03-06 20:46:58,923 - INFO - training batch 701, loss: 0.403, 22432/28000 datapoints
2025-03-06 20:46:59,045 - INFO - training batch 751, loss: 0.318, 24032/28000 datapoints
2025-03-06 20:46:59,177 - INFO - training batch 801, loss: 0.282, 25632/28000 datapoints
2025-03-06 20:46:59,319 - INFO - training batch 851, loss: 0.748, 27232/28000 datapoints
2025-03-06 20:46:59,380 - INFO - validation batch 1, loss: 0.176, 32/6976 datapoints
2025-03-06 20:46:59,423 - INFO - validation batch 51, loss: 1.276, 1632/6976 datapoints
2025-03-06 20:46:59,466 - INFO - validation batch 101, loss: 0.243, 3232/6976 datapoints
2025-03-06 20:46:59,510 - INFO - validation batch 151, loss: 0.522, 4832/6976 datapoints
2025-03-06 20:46:59,557 - INFO - validation batch 201, loss: 0.368, 6432/6976 datapoints
2025-03-06 20:46:59,572 - INFO - Epoch 227/800 done.
2025-03-06 20:46:59,573 - INFO - Final validation performance:
Loss: 0.517, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 20:46:59,573 - INFO - Beginning epoch 228/800
2025-03-06 20:46:59,576 - INFO - training batch 1, loss: 0.448, 32/28000 datapoints
2025-03-06 20:46:59,702 - INFO - training batch 51, loss: 0.254, 1632/28000 datapoints
2025-03-06 20:46:59,824 - INFO - training batch 101, loss: 0.257, 3232/28000 datapoints
2025-03-06 20:46:59,945 - INFO - training batch 151, loss: 0.816, 4832/28000 datapoints
2025-03-06 20:47:00,068 - INFO - training batch 201, loss: 0.239, 6432/28000 datapoints
2025-03-06 20:47:00,188 - INFO - training batch 251, loss: 0.398, 8032/28000 datapoints
2025-03-06 20:47:00,311 - INFO - training batch 301, loss: 0.710, 9632/28000 datapoints
2025-03-06 20:47:00,439 - INFO - training batch 351, loss: 0.441, 11232/28000 datapoints
2025-03-06 20:47:00,560 - INFO - training batch 401, loss: 0.757, 12832/28000 datapoints
2025-03-06 20:47:00,682 - INFO - training batch 451, loss: 0.357, 14432/28000 datapoints
2025-03-06 20:47:00,801 - INFO - training batch 501, loss: 0.252, 16032/28000 datapoints
2025-03-06 20:47:00,921 - INFO - training batch 551, loss: 0.419, 17632/28000 datapoints
2025-03-06 20:47:01,043 - INFO - training batch 601, loss: 0.651, 19232/28000 datapoints
2025-03-06 20:47:01,163 - INFO - training batch 651, loss: 0.097, 20832/28000 datapoints
2025-03-06 20:47:01,284 - INFO - training batch 701, loss: 0.401, 22432/28000 datapoints
2025-03-06 20:47:01,404 - INFO - training batch 751, loss: 0.317, 24032/28000 datapoints
2025-03-06 20:47:01,524 - INFO - training batch 801, loss: 0.279, 25632/28000 datapoints
2025-03-06 20:47:01,649 - INFO - training batch 851, loss: 0.744, 27232/28000 datapoints
2025-03-06 20:47:01,708 - INFO - validation batch 1, loss: 0.174, 32/6976 datapoints
2025-03-06 20:47:01,752 - INFO - validation batch 51, loss: 1.275, 1632/6976 datapoints
2025-03-06 20:47:01,795 - INFO - validation batch 101, loss: 0.243, 3232/6976 datapoints
2025-03-06 20:47:01,839 - INFO - validation batch 151, loss: 0.519, 4832/6976 datapoints
2025-03-06 20:47:01,886 - INFO - validation batch 201, loss: 0.368, 6432/6976 datapoints
2025-03-06 20:47:01,901 - INFO - Epoch 228/800 done.
2025-03-06 20:47:01,901 - INFO - Final validation performance:
Loss: 0.516, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 20:47:01,901 - INFO - Beginning epoch 229/800
2025-03-06 20:47:01,905 - INFO - training batch 1, loss: 0.445, 32/28000 datapoints
2025-03-06 20:47:02,026 - INFO - training batch 51, loss: 0.252, 1632/28000 datapoints
2025-03-06 20:47:02,150 - INFO - training batch 101, loss: 0.256, 3232/28000 datapoints
2025-03-06 20:47:02,276 - INFO - training batch 151, loss: 0.820, 4832/28000 datapoints
2025-03-06 20:47:02,401 - INFO - training batch 201, loss: 0.238, 6432/28000 datapoints
2025-03-06 20:47:02,518 - INFO - training batch 251, loss: 0.399, 8032/28000 datapoints
2025-03-06 20:47:02,641 - INFO - training batch 301, loss: 0.710, 9632/28000 datapoints
2025-03-06 20:47:02,759 - INFO - training batch 351, loss: 0.438, 11232/28000 datapoints
2025-03-06 20:47:02,878 - INFO - training batch 401, loss: 0.755, 12832/28000 datapoints
2025-03-06 20:47:02,998 - INFO - training batch 451, loss: 0.356, 14432/28000 datapoints
2025-03-06 20:47:03,121 - INFO - training batch 501, loss: 0.250, 16032/28000 datapoints
2025-03-06 20:47:03,244 - INFO - training batch 551, loss: 0.419, 17632/28000 datapoints
2025-03-06 20:47:03,377 - INFO - training batch 601, loss: 0.648, 19232/28000 datapoints
2025-03-06 20:47:03,497 - INFO - training batch 651, loss: 0.097, 20832/28000 datapoints
2025-03-06 20:47:03,618 - INFO - training batch 701, loss: 0.399, 22432/28000 datapoints
2025-03-06 20:47:03,748 - INFO - training batch 751, loss: 0.315, 24032/28000 datapoints
2025-03-06 20:47:03,871 - INFO - training batch 801, loss: 0.276, 25632/28000 datapoints
2025-03-06 20:47:03,992 - INFO - training batch 851, loss: 0.739, 27232/28000 datapoints
2025-03-06 20:47:04,051 - INFO - validation batch 1, loss: 0.173, 32/6976 datapoints
2025-03-06 20:47:04,100 - INFO - validation batch 51, loss: 1.273, 1632/6976 datapoints
2025-03-06 20:47:04,144 - INFO - validation batch 101, loss: 0.244, 3232/6976 datapoints
2025-03-06 20:47:04,188 - INFO - validation batch 151, loss: 0.516, 4832/6976 datapoints
2025-03-06 20:47:04,232 - INFO - validation batch 201, loss: 0.368, 6432/6976 datapoints
2025-03-06 20:47:04,247 - INFO - Epoch 229/800 done.
2025-03-06 20:47:04,247 - INFO - Final validation performance:
Loss: 0.515, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 20:47:04,247 - INFO - Beginning epoch 230/800
2025-03-06 20:47:04,251 - INFO - training batch 1, loss: 0.441, 32/28000 datapoints
2025-03-06 20:47:04,372 - INFO - training batch 51, loss: 0.250, 1632/28000 datapoints
2025-03-06 20:47:04,495 - INFO - training batch 101, loss: 0.255, 3232/28000 datapoints
2025-03-06 20:47:04,619 - INFO - training batch 151, loss: 0.818, 4832/28000 datapoints
2025-03-06 20:47:04,741 - INFO - training batch 201, loss: 0.237, 6432/28000 datapoints
2025-03-06 20:47:04,865 - INFO - training batch 251, loss: 0.398, 8032/28000 datapoints
2025-03-06 20:47:04,991 - INFO - training batch 301, loss: 0.709, 9632/28000 datapoints
2025-03-06 20:47:05,113 - INFO - training batch 351, loss: 0.434, 11232/28000 datapoints
2025-03-06 20:47:05,235 - INFO - training batch 401, loss: 0.753, 12832/28000 datapoints
2025-03-06 20:47:05,355 - INFO - training batch 451, loss: 0.354, 14432/28000 datapoints
2025-03-06 20:47:05,477 - INFO - training batch 501, loss: 0.248, 16032/28000 datapoints
2025-03-06 20:47:05,598 - INFO - training batch 551, loss: 0.417, 17632/28000 datapoints
2025-03-06 20:47:05,731 - INFO - training batch 601, loss: 0.646, 19232/28000 datapoints
2025-03-06 20:47:05,858 - INFO - training batch 651, loss: 0.096, 20832/28000 datapoints
2025-03-06 20:47:05,982 - INFO - training batch 701, loss: 0.397, 22432/28000 datapoints
2025-03-06 20:47:06,106 - INFO - training batch 751, loss: 0.314, 24032/28000 datapoints
2025-03-06 20:47:06,233 - INFO - training batch 801, loss: 0.274, 25632/28000 datapoints
2025-03-06 20:47:06,360 - INFO - training batch 851, loss: 0.735, 27232/28000 datapoints
2025-03-06 20:47:06,428 - INFO - validation batch 1, loss: 0.172, 32/6976 datapoints
2025-03-06 20:47:06,475 - INFO - validation batch 51, loss: 1.272, 1632/6976 datapoints
2025-03-06 20:47:06,520 - INFO - validation batch 101, loss: 0.244, 3232/6976 datapoints
2025-03-06 20:47:06,564 - INFO - validation batch 151, loss: 0.512, 4832/6976 datapoints
2025-03-06 20:47:06,607 - INFO - validation batch 201, loss: 0.368, 6432/6976 datapoints
2025-03-06 20:47:06,624 - INFO - Epoch 230/800 done.
2025-03-06 20:47:06,624 - INFO - Final validation performance:
Loss: 0.514, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 20:47:06,625 - INFO - Beginning epoch 231/800
2025-03-06 20:47:06,629 - INFO - training batch 1, loss: 0.438, 32/28000 datapoints
2025-03-06 20:47:06,752 - INFO - training batch 51, loss: 0.248, 1632/28000 datapoints
2025-03-06 20:47:06,871 - INFO - training batch 101, loss: 0.254, 3232/28000 datapoints
2025-03-06 20:47:06,992 - INFO - training batch 151, loss: 0.815, 4832/28000 datapoints
2025-03-06 20:47:07,111 - INFO - training batch 201, loss: 0.235, 6432/28000 datapoints
2025-03-06 20:47:07,233 - INFO - training batch 251, loss: 0.397, 8032/28000 datapoints
2025-03-06 20:47:07,353 - INFO - training batch 301, loss: 0.709, 9632/28000 datapoints
2025-03-06 20:47:07,474 - INFO - training batch 351, loss: 0.431, 11232/28000 datapoints
2025-03-06 20:47:07,593 - INFO - training batch 401, loss: 0.750, 12832/28000 datapoints
2025-03-06 20:47:07,721 - INFO - training batch 451, loss: 0.353, 14432/28000 datapoints
2025-03-06 20:47:07,840 - INFO - training batch 501, loss: 0.247, 16032/28000 datapoints
2025-03-06 20:47:07,961 - INFO - training batch 551, loss: 0.415, 17632/28000 datapoints
2025-03-06 20:47:08,081 - INFO - training batch 601, loss: 0.643, 19232/28000 datapoints
2025-03-06 20:47:08,202 - INFO - training batch 651, loss: 0.095, 20832/28000 datapoints
2025-03-06 20:47:08,321 - INFO - training batch 701, loss: 0.395, 22432/28000 datapoints
2025-03-06 20:47:08,445 - INFO - training batch 751, loss: 0.313, 24032/28000 datapoints
2025-03-06 20:47:08,564 - INFO - training batch 801, loss: 0.271, 25632/28000 datapoints
2025-03-06 20:47:08,686 - INFO - training batch 851, loss: 0.731, 27232/28000 datapoints
2025-03-06 20:47:08,746 - INFO - validation batch 1, loss: 0.171, 32/6976 datapoints
2025-03-06 20:47:08,788 - INFO - validation batch 51, loss: 1.271, 1632/6976 datapoints
2025-03-06 20:47:08,833 - INFO - validation batch 101, loss: 0.245, 3232/6976 datapoints
2025-03-06 20:47:08,876 - INFO - validation batch 151, loss: 0.509, 4832/6976 datapoints
2025-03-06 20:47:08,921 - INFO - validation batch 201, loss: 0.368, 6432/6976 datapoints
2025-03-06 20:47:08,935 - INFO - Epoch 231/800 done.
2025-03-06 20:47:08,936 - INFO - Final validation performance:
Loss: 0.513, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 20:47:08,936 - INFO - Beginning epoch 232/800
2025-03-06 20:47:08,939 - INFO - training batch 1, loss: 0.435, 32/28000 datapoints
2025-03-06 20:47:09,063 - INFO - training batch 51, loss: 0.246, 1632/28000 datapoints
2025-03-06 20:47:09,203 - INFO - training batch 101, loss: 0.253, 3232/28000 datapoints
2025-03-06 20:47:09,348 - INFO - training batch 151, loss: 0.814, 4832/28000 datapoints
2025-03-06 20:47:09,479 - INFO - training batch 201, loss: 0.234, 6432/28000 datapoints
2025-03-06 20:47:09,610 - INFO - training batch 251, loss: 0.396, 8032/28000 datapoints
2025-03-06 20:47:09,733 - INFO - training batch 301, loss: 0.708, 9632/28000 datapoints
2025-03-06 20:47:09,858 - INFO - training batch 351, loss: 0.428, 11232/28000 datapoints
2025-03-06 20:47:09,977 - INFO - training batch 401, loss: 0.748, 12832/28000 datapoints
2025-03-06 20:47:10,105 - INFO - training batch 451, loss: 0.351, 14432/28000 datapoints
2025-03-06 20:47:10,230 - INFO - training batch 501, loss: 0.246, 16032/28000 datapoints
2025-03-06 20:47:10,351 - INFO - training batch 551, loss: 0.414, 17632/28000 datapoints
2025-03-06 20:47:10,481 - INFO - training batch 601, loss: 0.640, 19232/28000 datapoints
2025-03-06 20:47:10,600 - INFO - training batch 651, loss: 0.094, 20832/28000 datapoints
2025-03-06 20:47:10,724 - INFO - training batch 701, loss: 0.393, 22432/28000 datapoints
2025-03-06 20:47:10,845 - INFO - training batch 751, loss: 0.311, 24032/28000 datapoints
2025-03-06 20:47:10,965 - INFO - training batch 801, loss: 0.269, 25632/28000 datapoints
2025-03-06 20:47:11,085 - INFO - training batch 851, loss: 0.726, 27232/28000 datapoints
2025-03-06 20:47:11,144 - INFO - validation batch 1, loss: 0.170, 32/6976 datapoints
2025-03-06 20:47:11,190 - INFO - validation batch 51, loss: 1.269, 1632/6976 datapoints
2025-03-06 20:47:11,233 - INFO - validation batch 101, loss: 0.245, 3232/6976 datapoints
2025-03-06 20:47:11,278 - INFO - validation batch 151, loss: 0.506, 4832/6976 datapoints
2025-03-06 20:47:11,322 - INFO - validation batch 201, loss: 0.367, 6432/6976 datapoints
2025-03-06 20:47:11,338 - INFO - Epoch 232/800 done.
2025-03-06 20:47:11,338 - INFO - Final validation performance:
Loss: 0.511, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 20:47:11,339 - INFO - Beginning epoch 233/800
2025-03-06 20:47:11,342 - INFO - training batch 1, loss: 0.432, 32/28000 datapoints
2025-03-06 20:47:11,467 - INFO - training batch 51, loss: 0.244, 1632/28000 datapoints
2025-03-06 20:47:11,589 - INFO - training batch 101, loss: 0.252, 3232/28000 datapoints
2025-03-06 20:47:11,717 - INFO - training batch 151, loss: 0.813, 4832/28000 datapoints
2025-03-06 20:47:11,837 - INFO - training batch 201, loss: 0.232, 6432/28000 datapoints
2025-03-06 20:47:11,960 - INFO - training batch 251, loss: 0.395, 8032/28000 datapoints
2025-03-06 20:47:12,082 - INFO - training batch 301, loss: 0.709, 9632/28000 datapoints
2025-03-06 20:47:12,203 - INFO - training batch 351, loss: 0.425, 11232/28000 datapoints
2025-03-06 20:47:12,322 - INFO - training batch 401, loss: 0.745, 12832/28000 datapoints
2025-03-06 20:47:12,446 - INFO - training batch 451, loss: 0.350, 14432/28000 datapoints
2025-03-06 20:47:12,566 - INFO - training batch 501, loss: 0.244, 16032/28000 datapoints
2025-03-06 20:47:12,709 - INFO - training batch 551, loss: 0.412, 17632/28000 datapoints
2025-03-06 20:47:12,855 - INFO - training batch 601, loss: 0.637, 19232/28000 datapoints
2025-03-06 20:47:12,998 - INFO - training batch 651, loss: 0.093, 20832/28000 datapoints
2025-03-06 20:47:13,142 - INFO - training batch 701, loss: 0.391, 22432/28000 datapoints
2025-03-06 20:47:13,265 - INFO - training batch 751, loss: 0.309, 24032/28000 datapoints
2025-03-06 20:47:13,386 - INFO - training batch 801, loss: 0.266, 25632/28000 datapoints
2025-03-06 20:47:13,506 - INFO - training batch 851, loss: 0.722, 27232/28000 datapoints
2025-03-06 20:47:13,566 - INFO - validation batch 1, loss: 0.169, 32/6976 datapoints
2025-03-06 20:47:13,610 - INFO - validation batch 51, loss: 1.268, 1632/6976 datapoints
2025-03-06 20:47:13,658 - INFO - validation batch 101, loss: 0.245, 3232/6976 datapoints
2025-03-06 20:47:13,703 - INFO - validation batch 151, loss: 0.503, 4832/6976 datapoints
2025-03-06 20:47:13,747 - INFO - validation batch 201, loss: 0.367, 6432/6976 datapoints
2025-03-06 20:47:13,762 - INFO - Epoch 233/800 done.
2025-03-06 20:47:13,762 - INFO - Final validation performance:
Loss: 0.510, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 20:47:13,763 - INFO - Beginning epoch 234/800
2025-03-06 20:47:13,766 - INFO - training batch 1, loss: 0.429, 32/28000 datapoints
2025-03-06 20:47:13,888 - INFO - training batch 51, loss: 0.241, 1632/28000 datapoints
2025-03-06 20:47:14,008 - INFO - training batch 101, loss: 0.251, 3232/28000 datapoints
2025-03-06 20:47:14,128 - INFO - training batch 151, loss: 0.812, 4832/28000 datapoints
2025-03-06 20:47:14,250 - INFO - training batch 201, loss: 0.231, 6432/28000 datapoints
2025-03-06 20:47:14,375 - INFO - training batch 251, loss: 0.394, 8032/28000 datapoints
2025-03-06 20:47:14,499 - INFO - training batch 301, loss: 0.708, 9632/28000 datapoints
2025-03-06 20:47:14,620 - INFO - training batch 351, loss: 0.422, 11232/28000 datapoints
2025-03-06 20:47:14,742 - INFO - training batch 401, loss: 0.742, 12832/28000 datapoints
2025-03-06 20:47:14,864 - INFO - training batch 451, loss: 0.348, 14432/28000 datapoints
2025-03-06 20:47:14,990 - INFO - training batch 501, loss: 0.243, 16032/28000 datapoints
2025-03-06 20:47:15,112 - INFO - training batch 551, loss: 0.410, 17632/28000 datapoints
2025-03-06 20:47:15,232 - INFO - training batch 601, loss: 0.634, 19232/28000 datapoints
2025-03-06 20:47:15,352 - INFO - training batch 651, loss: 0.092, 20832/28000 datapoints
2025-03-06 20:47:15,473 - INFO - training batch 701, loss: 0.389, 22432/28000 datapoints
2025-03-06 20:47:15,594 - INFO - training batch 751, loss: 0.309, 24032/28000 datapoints
2025-03-06 20:47:15,730 - INFO - training batch 801, loss: 0.264, 25632/28000 datapoints
2025-03-06 20:47:15,851 - INFO - training batch 851, loss: 0.718, 27232/28000 datapoints
2025-03-06 20:47:15,910 - INFO - validation batch 1, loss: 0.167, 32/6976 datapoints
2025-03-06 20:47:15,955 - INFO - validation batch 51, loss: 1.267, 1632/6976 datapoints
2025-03-06 20:47:15,998 - INFO - validation batch 101, loss: 0.246, 3232/6976 datapoints
2025-03-06 20:47:16,041 - INFO - validation batch 151, loss: 0.500, 4832/6976 datapoints
2025-03-06 20:47:16,089 - INFO - validation batch 201, loss: 0.367, 6432/6976 datapoints
2025-03-06 20:47:16,105 - INFO - Epoch 234/800 done.
2025-03-06 20:47:16,105 - INFO - Final validation performance:
Loss: 0.509, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 20:47:16,105 - INFO - Beginning epoch 235/800
2025-03-06 20:47:16,109 - INFO - training batch 1, loss: 0.426, 32/28000 datapoints
2025-03-06 20:47:16,231 - INFO - training batch 51, loss: 0.239, 1632/28000 datapoints
2025-03-06 20:47:16,361 - INFO - training batch 101, loss: 0.250, 3232/28000 datapoints
2025-03-06 20:47:16,489 - INFO - training batch 151, loss: 0.808, 4832/28000 datapoints
2025-03-06 20:47:16,612 - INFO - training batch 201, loss: 0.229, 6432/28000 datapoints
2025-03-06 20:47:16,736 - INFO - training batch 251, loss: 0.393, 8032/28000 datapoints
2025-03-06 20:47:16,857 - INFO - training batch 301, loss: 0.707, 9632/28000 datapoints
2025-03-06 20:47:16,977 - INFO - training batch 351, loss: 0.419, 11232/28000 datapoints
2025-03-06 20:47:17,097 - INFO - training batch 401, loss: 0.740, 12832/28000 datapoints
2025-03-06 20:47:17,222 - INFO - training batch 451, loss: 0.346, 14432/28000 datapoints
2025-03-06 20:47:17,345 - INFO - training batch 501, loss: 0.242, 16032/28000 datapoints
2025-03-06 20:47:17,465 - INFO - training batch 551, loss: 0.409, 17632/28000 datapoints
2025-03-06 20:47:17,584 - INFO - training batch 601, loss: 0.631, 19232/28000 datapoints
2025-03-06 20:47:17,706 - INFO - training batch 651, loss: 0.092, 20832/28000 datapoints
2025-03-06 20:47:17,825 - INFO - training batch 701, loss: 0.387, 22432/28000 datapoints
2025-03-06 20:47:17,947 - INFO - training batch 751, loss: 0.307, 24032/28000 datapoints
2025-03-06 20:47:18,067 - INFO - training batch 801, loss: 0.261, 25632/28000 datapoints
2025-03-06 20:47:18,186 - INFO - training batch 851, loss: 0.714, 27232/28000 datapoints
2025-03-06 20:47:18,246 - INFO - validation batch 1, loss: 0.166, 32/6976 datapoints
2025-03-06 20:47:18,291 - INFO - validation batch 51, loss: 1.265, 1632/6976 datapoints
2025-03-06 20:47:18,334 - INFO - validation batch 101, loss: 0.246, 3232/6976 datapoints
2025-03-06 20:47:18,377 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 20:47:18,420 - INFO - validation batch 201, loss: 0.367, 6432/6976 datapoints
2025-03-06 20:47:18,434 - INFO - Epoch 235/800 done.
2025-03-06 20:47:18,435 - INFO - Final validation performance:
Loss: 0.508, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 20:47:18,435 - INFO - Beginning epoch 236/800
2025-03-06 20:47:18,439 - INFO - training batch 1, loss: 0.423, 32/28000 datapoints
2025-03-06 20:47:18,564 - INFO - training batch 51, loss: 0.238, 1632/28000 datapoints
2025-03-06 20:47:18,686 - INFO - training batch 101, loss: 0.249, 3232/28000 datapoints
2025-03-06 20:47:18,810 - INFO - training batch 151, loss: 0.802, 4832/28000 datapoints
2025-03-06 20:47:18,931 - INFO - training batch 201, loss: 0.228, 6432/28000 datapoints
2025-03-06 20:47:19,052 - INFO - training batch 251, loss: 0.392, 8032/28000 datapoints
2025-03-06 20:47:19,172 - INFO - training batch 301, loss: 0.707, 9632/28000 datapoints
2025-03-06 20:47:19,292 - INFO - training batch 351, loss: 0.416, 11232/28000 datapoints
2025-03-06 20:47:19,439 - INFO - training batch 401, loss: 0.737, 12832/28000 datapoints
2025-03-06 20:47:19,562 - INFO - training batch 451, loss: 0.344, 14432/28000 datapoints
2025-03-06 20:47:19,686 - INFO - training batch 501, loss: 0.240, 16032/28000 datapoints
2025-03-06 20:47:19,806 - INFO - training batch 551, loss: 0.407, 17632/28000 datapoints
2025-03-06 20:47:19,929 - INFO - training batch 601, loss: 0.629, 19232/28000 datapoints
2025-03-06 20:47:20,050 - INFO - training batch 651, loss: 0.091, 20832/28000 datapoints
2025-03-06 20:47:20,169 - INFO - training batch 701, loss: 0.386, 22432/28000 datapoints
2025-03-06 20:47:20,287 - INFO - training batch 751, loss: 0.307, 24032/28000 datapoints
2025-03-06 20:47:20,406 - INFO - training batch 801, loss: 0.259, 25632/28000 datapoints
2025-03-06 20:47:20,531 - INFO - training batch 851, loss: 0.710, 27232/28000 datapoints
2025-03-06 20:47:20,589 - INFO - validation batch 1, loss: 0.165, 32/6976 datapoints
2025-03-06 20:47:20,636 - INFO - validation batch 51, loss: 1.264, 1632/6976 datapoints
2025-03-06 20:47:20,680 - INFO - validation batch 101, loss: 0.247, 3232/6976 datapoints
2025-03-06 20:47:20,724 - INFO - validation batch 151, loss: 0.493, 4832/6976 datapoints
2025-03-06 20:47:20,771 - INFO - validation batch 201, loss: 0.367, 6432/6976 datapoints
2025-03-06 20:47:20,786 - INFO - Epoch 236/800 done.
2025-03-06 20:47:20,786 - INFO - Final validation performance:
Loss: 0.507, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 20:47:20,787 - INFO - Beginning epoch 237/800
2025-03-06 20:47:20,791 - INFO - training batch 1, loss: 0.420, 32/28000 datapoints
2025-03-06 20:47:20,917 - INFO - training batch 51, loss: 0.236, 1632/28000 datapoints
2025-03-06 20:47:21,038 - INFO - training batch 101, loss: 0.248, 3232/28000 datapoints
2025-03-06 20:47:21,157 - INFO - training batch 151, loss: 0.797, 4832/28000 datapoints
2025-03-06 20:47:21,278 - INFO - training batch 201, loss: 0.226, 6432/28000 datapoints
2025-03-06 20:47:21,399 - INFO - training batch 251, loss: 0.391, 8032/28000 datapoints
2025-03-06 20:47:21,519 - INFO - training batch 301, loss: 0.706, 9632/28000 datapoints
2025-03-06 20:47:21,642 - INFO - training batch 351, loss: 0.413, 11232/28000 datapoints
2025-03-06 20:47:21,775 - INFO - training batch 401, loss: 0.735, 12832/28000 datapoints
2025-03-06 20:47:21,900 - INFO - training batch 451, loss: 0.342, 14432/28000 datapoints
2025-03-06 20:47:22,019 - INFO - training batch 501, loss: 0.239, 16032/28000 datapoints
2025-03-06 20:47:22,137 - INFO - training batch 551, loss: 0.406, 17632/28000 datapoints
2025-03-06 20:47:22,264 - INFO - training batch 601, loss: 0.625, 19232/28000 datapoints
2025-03-06 20:47:22,394 - INFO - training batch 651, loss: 0.090, 20832/28000 datapoints
2025-03-06 20:47:22,522 - INFO - training batch 701, loss: 0.384, 22432/28000 datapoints
2025-03-06 20:47:22,643 - INFO - training batch 751, loss: 0.306, 24032/28000 datapoints
2025-03-06 20:47:22,766 - INFO - training batch 801, loss: 0.257, 25632/28000 datapoints
2025-03-06 20:47:22,886 - INFO - training batch 851, loss: 0.706, 27232/28000 datapoints
2025-03-06 20:47:22,945 - INFO - validation batch 1, loss: 0.164, 32/6976 datapoints
2025-03-06 20:47:22,989 - INFO - validation batch 51, loss: 1.262, 1632/6976 datapoints
2025-03-06 20:47:23,033 - INFO - validation batch 101, loss: 0.247, 3232/6976 datapoints
2025-03-06 20:47:23,077 - INFO - validation batch 151, loss: 0.489, 4832/6976 datapoints
2025-03-06 20:47:23,120 - INFO - validation batch 201, loss: 0.367, 6432/6976 datapoints
2025-03-06 20:47:23,134 - INFO - Epoch 237/800 done.
2025-03-06 20:47:23,135 - INFO - Final validation performance:
Loss: 0.506, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 20:47:23,135 - INFO - Beginning epoch 238/800
2025-03-06 20:47:23,138 - INFO - training batch 1, loss: 0.417, 32/28000 datapoints
2025-03-06 20:47:23,261 - INFO - training batch 51, loss: 0.234, 1632/28000 datapoints
2025-03-06 20:47:23,394 - INFO - training batch 101, loss: 0.248, 3232/28000 datapoints
2025-03-06 20:47:23,520 - INFO - training batch 151, loss: 0.791, 4832/28000 datapoints
2025-03-06 20:47:23,642 - INFO - training batch 201, loss: 0.224, 6432/28000 datapoints
2025-03-06 20:47:23,762 - INFO - training batch 251, loss: 0.390, 8032/28000 datapoints
2025-03-06 20:47:23,882 - INFO - training batch 301, loss: 0.706, 9632/28000 datapoints
2025-03-06 20:47:24,002 - INFO - training batch 351, loss: 0.410, 11232/28000 datapoints
2025-03-06 20:47:24,121 - INFO - training batch 401, loss: 0.732, 12832/28000 datapoints
2025-03-06 20:47:24,240 - INFO - training batch 451, loss: 0.340, 14432/28000 datapoints
2025-03-06 20:47:24,360 - INFO - training batch 501, loss: 0.238, 16032/28000 datapoints
2025-03-06 20:47:24,486 - INFO - training batch 551, loss: 0.405, 17632/28000 datapoints
2025-03-06 20:47:24,606 - INFO - training batch 601, loss: 0.622, 19232/28000 datapoints
2025-03-06 20:47:24,730 - INFO - training batch 651, loss: 0.089, 20832/28000 datapoints
2025-03-06 20:47:24,848 - INFO - training batch 701, loss: 0.382, 22432/28000 datapoints
2025-03-06 20:47:24,973 - INFO - training batch 751, loss: 0.306, 24032/28000 datapoints
2025-03-06 20:47:25,092 - INFO - training batch 801, loss: 0.255, 25632/28000 datapoints
2025-03-06 20:47:25,211 - INFO - training batch 851, loss: 0.703, 27232/28000 datapoints
2025-03-06 20:47:25,271 - INFO - validation batch 1, loss: 0.162, 32/6976 datapoints
2025-03-06 20:47:25,315 - INFO - validation batch 51, loss: 1.261, 1632/6976 datapoints
2025-03-06 20:47:25,358 - INFO - validation batch 101, loss: 0.247, 3232/6976 datapoints
2025-03-06 20:47:25,403 - INFO - validation batch 151, loss: 0.486, 4832/6976 datapoints
2025-03-06 20:47:25,448 - INFO - validation batch 201, loss: 0.367, 6432/6976 datapoints
2025-03-06 20:47:25,463 - INFO - Epoch 238/800 done.
2025-03-06 20:47:25,463 - INFO - Final validation performance:
Loss: 0.505, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 20:47:25,464 - INFO - Beginning epoch 239/800
2025-03-06 20:47:25,467 - INFO - training batch 1, loss: 0.414, 32/28000 datapoints
2025-03-06 20:47:25,588 - INFO - training batch 51, loss: 0.231, 1632/28000 datapoints
2025-03-06 20:47:25,718 - INFO - training batch 101, loss: 0.247, 3232/28000 datapoints
2025-03-06 20:47:25,841 - INFO - training batch 151, loss: 0.786, 4832/28000 datapoints
2025-03-06 20:47:25,968 - INFO - training batch 201, loss: 0.222, 6432/28000 datapoints
2025-03-06 20:47:26,091 - INFO - training batch 251, loss: 0.389, 8032/28000 datapoints
2025-03-06 20:47:26,214 - INFO - training batch 301, loss: 0.705, 9632/28000 datapoints
2025-03-06 20:47:26,342 - INFO - training batch 351, loss: 0.408, 11232/28000 datapoints
2025-03-06 20:47:26,466 - INFO - training batch 401, loss: 0.730, 12832/28000 datapoints
2025-03-06 20:47:26,592 - INFO - training batch 451, loss: 0.339, 14432/28000 datapoints
2025-03-06 20:47:26,728 - INFO - training batch 501, loss: 0.238, 16032/28000 datapoints
2025-03-06 20:47:26,859 - INFO - training batch 551, loss: 0.403, 17632/28000 datapoints
2025-03-06 20:47:26,983 - INFO - training batch 601, loss: 0.620, 19232/28000 datapoints
2025-03-06 20:47:27,107 - INFO - training batch 651, loss: 0.089, 20832/28000 datapoints
2025-03-06 20:47:27,229 - INFO - training batch 701, loss: 0.380, 22432/28000 datapoints
2025-03-06 20:47:27,353 - INFO - training batch 751, loss: 0.305, 24032/28000 datapoints
2025-03-06 20:47:27,479 - INFO - training batch 801, loss: 0.253, 25632/28000 datapoints
2025-03-06 20:47:27,602 - INFO - training batch 851, loss: 0.697, 27232/28000 datapoints
2025-03-06 20:47:27,667 - INFO - validation batch 1, loss: 0.162, 32/6976 datapoints
2025-03-06 20:47:27,715 - INFO - validation batch 51, loss: 1.260, 1632/6976 datapoints
2025-03-06 20:47:27,764 - INFO - validation batch 101, loss: 0.248, 3232/6976 datapoints
2025-03-06 20:47:27,815 - INFO - validation batch 151, loss: 0.483, 4832/6976 datapoints
2025-03-06 20:47:27,870 - INFO - validation batch 201, loss: 0.366, 6432/6976 datapoints
2025-03-06 20:47:27,892 - INFO - Epoch 239/800 done.
2025-03-06 20:47:27,892 - INFO - Final validation performance:
Loss: 0.504, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 20:47:27,893 - INFO - Beginning epoch 240/800
2025-03-06 20:47:27,896 - INFO - training batch 1, loss: 0.412, 32/28000 datapoints
2025-03-06 20:47:28,030 - INFO - training batch 51, loss: 0.229, 1632/28000 datapoints
2025-03-06 20:47:28,153 - INFO - training batch 101, loss: 0.246, 3232/28000 datapoints
2025-03-06 20:47:28,277 - INFO - training batch 151, loss: 0.781, 4832/28000 datapoints
2025-03-06 20:47:28,400 - INFO - training batch 201, loss: 0.221, 6432/28000 datapoints
2025-03-06 20:47:28,527 - INFO - training batch 251, loss: 0.388, 8032/28000 datapoints
2025-03-06 20:47:28,654 - INFO - training batch 301, loss: 0.704, 9632/28000 datapoints
2025-03-06 20:47:28,776 - INFO - training batch 351, loss: 0.406, 11232/28000 datapoints
2025-03-06 20:47:28,901 - INFO - training batch 401, loss: 0.728, 12832/28000 datapoints
2025-03-06 20:47:29,025 - INFO - training batch 451, loss: 0.337, 14432/28000 datapoints
2025-03-06 20:47:29,149 - INFO - training batch 501, loss: 0.237, 16032/28000 datapoints
2025-03-06 20:47:29,272 - INFO - training batch 551, loss: 0.402, 17632/28000 datapoints
2025-03-06 20:47:29,398 - INFO - training batch 601, loss: 0.616, 19232/28000 datapoints
2025-03-06 20:47:29,553 - INFO - training batch 651, loss: 0.088, 20832/28000 datapoints
2025-03-06 20:47:29,683 - INFO - training batch 701, loss: 0.378, 22432/28000 datapoints
2025-03-06 20:47:29,807 - INFO - training batch 751, loss: 0.304, 24032/28000 datapoints
2025-03-06 20:47:29,937 - INFO - training batch 801, loss: 0.251, 25632/28000 datapoints
2025-03-06 20:47:30,061 - INFO - training batch 851, loss: 0.693, 27232/28000 datapoints
2025-03-06 20:47:30,123 - INFO - validation batch 1, loss: 0.161, 32/6976 datapoints
2025-03-06 20:47:30,172 - INFO - validation batch 51, loss: 1.258, 1632/6976 datapoints
2025-03-06 20:47:30,220 - INFO - validation batch 101, loss: 0.249, 3232/6976 datapoints
2025-03-06 20:47:30,267 - INFO - validation batch 151, loss: 0.481, 4832/6976 datapoints
2025-03-06 20:47:30,314 - INFO - validation batch 201, loss: 0.366, 6432/6976 datapoints
2025-03-06 20:47:30,332 - INFO - Epoch 240/800 done.
2025-03-06 20:47:30,332 - INFO - Final validation performance:
Loss: 0.503, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 20:47:30,333 - INFO - Beginning epoch 241/800
2025-03-06 20:47:30,337 - INFO - training batch 1, loss: 0.410, 32/28000 datapoints
2025-03-06 20:47:30,469 - INFO - training batch 51, loss: 0.227, 1632/28000 datapoints
2025-03-06 20:47:30,597 - INFO - training batch 101, loss: 0.245, 3232/28000 datapoints
2025-03-06 20:47:30,723 - INFO - training batch 151, loss: 0.777, 4832/28000 datapoints
2025-03-06 20:47:30,846 - INFO - training batch 201, loss: 0.220, 6432/28000 datapoints
2025-03-06 20:47:30,972 - INFO - training batch 251, loss: 0.387, 8032/28000 datapoints
2025-03-06 20:47:31,093 - INFO - training batch 301, loss: 0.704, 9632/28000 datapoints
2025-03-06 20:47:31,218 - INFO - training batch 351, loss: 0.403, 11232/28000 datapoints
2025-03-06 20:47:31,343 - INFO - training batch 401, loss: 0.726, 12832/28000 datapoints
2025-03-06 20:47:31,467 - INFO - training batch 451, loss: 0.335, 14432/28000 datapoints
2025-03-06 20:47:31,605 - INFO - training batch 501, loss: 0.236, 16032/28000 datapoints
2025-03-06 20:47:31,732 - INFO - training batch 551, loss: 0.401, 17632/28000 datapoints
2025-03-06 20:47:31,857 - INFO - training batch 601, loss: 0.613, 19232/28000 datapoints
2025-03-06 20:47:31,983 - INFO - training batch 651, loss: 0.087, 20832/28000 datapoints
2025-03-06 20:47:32,108 - INFO - training batch 701, loss: 0.376, 22432/28000 datapoints
2025-03-06 20:47:32,229 - INFO - training batch 751, loss: 0.303, 24032/28000 datapoints
2025-03-06 20:47:32,354 - INFO - training batch 801, loss: 0.249, 25632/28000 datapoints
2025-03-06 20:47:32,478 - INFO - training batch 851, loss: 0.689, 27232/28000 datapoints
2025-03-06 20:47:32,543 - INFO - validation batch 1, loss: 0.160, 32/6976 datapoints
2025-03-06 20:47:32,590 - INFO - validation batch 51, loss: 1.256, 1632/6976 datapoints
2025-03-06 20:47:32,642 - INFO - validation batch 101, loss: 0.249, 3232/6976 datapoints
2025-03-06 20:47:32,688 - INFO - validation batch 151, loss: 0.478, 4832/6976 datapoints
2025-03-06 20:47:32,736 - INFO - validation batch 201, loss: 0.367, 6432/6976 datapoints
2025-03-06 20:47:32,751 - INFO - Epoch 241/800 done.
2025-03-06 20:47:32,752 - INFO - Final validation performance:
Loss: 0.502, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 20:47:32,752 - INFO - Beginning epoch 242/800
2025-03-06 20:47:32,755 - INFO - training batch 1, loss: 0.408, 32/28000 datapoints
2025-03-06 20:47:32,880 - INFO - training batch 51, loss: 0.225, 1632/28000 datapoints
2025-03-06 20:47:33,005 - INFO - training batch 101, loss: 0.244, 3232/28000 datapoints
2025-03-06 20:47:33,127 - INFO - training batch 151, loss: 0.770, 4832/28000 datapoints
2025-03-06 20:47:33,252 - INFO - training batch 201, loss: 0.218, 6432/28000 datapoints
2025-03-06 20:47:33,375 - INFO - training batch 251, loss: 0.386, 8032/28000 datapoints
2025-03-06 20:47:33,501 - INFO - training batch 301, loss: 0.703, 9632/28000 datapoints
2025-03-06 20:47:33,624 - INFO - training batch 351, loss: 0.400, 11232/28000 datapoints
2025-03-06 20:47:33,749 - INFO - training batch 401, loss: 0.723, 12832/28000 datapoints
2025-03-06 20:47:33,880 - INFO - training batch 451, loss: 0.334, 14432/28000 datapoints
2025-03-06 20:47:34,017 - INFO - training batch 501, loss: 0.235, 16032/28000 datapoints
2025-03-06 20:47:34,139 - INFO - training batch 551, loss: 0.399, 17632/28000 datapoints
2025-03-06 20:47:34,262 - INFO - training batch 601, loss: 0.611, 19232/28000 datapoints
2025-03-06 20:47:34,395 - INFO - training batch 651, loss: 0.086, 20832/28000 datapoints
2025-03-06 20:47:34,526 - INFO - training batch 701, loss: 0.375, 22432/28000 datapoints
2025-03-06 20:47:34,655 - INFO - training batch 751, loss: 0.303, 24032/28000 datapoints
2025-03-06 20:47:34,783 - INFO - training batch 801, loss: 0.247, 25632/28000 datapoints
2025-03-06 20:47:34,907 - INFO - training batch 851, loss: 0.686, 27232/28000 datapoints
2025-03-06 20:47:34,975 - INFO - validation batch 1, loss: 0.158, 32/6976 datapoints
2025-03-06 20:47:35,024 - INFO - validation batch 51, loss: 1.255, 1632/6976 datapoints
2025-03-06 20:47:35,070 - INFO - validation batch 101, loss: 0.250, 3232/6976 datapoints
2025-03-06 20:47:35,115 - INFO - validation batch 151, loss: 0.475, 4832/6976 datapoints
2025-03-06 20:47:35,158 - INFO - validation batch 201, loss: 0.367, 6432/6976 datapoints
2025-03-06 20:47:35,173 - INFO - Epoch 242/800 done.
2025-03-06 20:47:35,174 - INFO - Final validation performance:
Loss: 0.501, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 20:47:35,174 - INFO - Beginning epoch 243/800
2025-03-06 20:47:35,178 - INFO - training batch 1, loss: 0.406, 32/28000 datapoints
2025-03-06 20:47:35,300 - INFO - training batch 51, loss: 0.224, 1632/28000 datapoints
2025-03-06 20:47:35,419 - INFO - training batch 101, loss: 0.243, 3232/28000 datapoints
2025-03-06 20:47:35,542 - INFO - training batch 151, loss: 0.767, 4832/28000 datapoints
2025-03-06 20:47:35,665 - INFO - training batch 201, loss: 0.217, 6432/28000 datapoints
2025-03-06 20:47:35,785 - INFO - training batch 251, loss: 0.385, 8032/28000 datapoints
2025-03-06 20:47:35,906 - INFO - training batch 301, loss: 0.703, 9632/28000 datapoints
2025-03-06 20:47:36,027 - INFO - training batch 351, loss: 0.397, 11232/28000 datapoints
2025-03-06 20:47:36,145 - INFO - training batch 401, loss: 0.721, 12832/28000 datapoints
2025-03-06 20:47:36,266 - INFO - training batch 451, loss: 0.332, 14432/28000 datapoints
2025-03-06 20:47:36,391 - INFO - training batch 501, loss: 0.234, 16032/28000 datapoints
2025-03-06 20:47:36,514 - INFO - training batch 551, loss: 0.398, 17632/28000 datapoints
2025-03-06 20:47:36,639 - INFO - training batch 601, loss: 0.607, 19232/28000 datapoints
2025-03-06 20:47:36,759 - INFO - training batch 651, loss: 0.085, 20832/28000 datapoints
2025-03-06 20:47:36,880 - INFO - training batch 701, loss: 0.373, 22432/28000 datapoints
2025-03-06 20:47:36,999 - INFO - training batch 751, loss: 0.303, 24032/28000 datapoints
2025-03-06 20:47:37,120 - INFO - training batch 801, loss: 0.245, 25632/28000 datapoints
2025-03-06 20:47:37,239 - INFO - training batch 851, loss: 0.682, 27232/28000 datapoints
2025-03-06 20:47:37,298 - INFO - validation batch 1, loss: 0.157, 32/6976 datapoints
2025-03-06 20:47:37,341 - INFO - validation batch 51, loss: 1.254, 1632/6976 datapoints
2025-03-06 20:47:37,384 - INFO - validation batch 101, loss: 0.251, 3232/6976 datapoints
2025-03-06 20:47:37,427 - INFO - validation batch 151, loss: 0.472, 4832/6976 datapoints
2025-03-06 20:47:37,471 - INFO - validation batch 201, loss: 0.367, 6432/6976 datapoints
2025-03-06 20:47:37,486 - INFO - Epoch 243/800 done.
2025-03-06 20:47:37,486 - INFO - Final validation performance:
Loss: 0.500, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 20:47:37,486 - INFO - Beginning epoch 244/800
2025-03-06 20:47:37,490 - INFO - training batch 1, loss: 0.404, 32/28000 datapoints
2025-03-06 20:47:37,613 - INFO - training batch 51, loss: 0.222, 1632/28000 datapoints
2025-03-06 20:47:37,753 - INFO - training batch 101, loss: 0.242, 3232/28000 datapoints
2025-03-06 20:47:37,875 - INFO - training batch 151, loss: 0.760, 4832/28000 datapoints
2025-03-06 20:47:37,994 - INFO - training batch 201, loss: 0.215, 6432/28000 datapoints
2025-03-06 20:47:38,116 - INFO - training batch 251, loss: 0.384, 8032/28000 datapoints
2025-03-06 20:47:38,236 - INFO - training batch 301, loss: 0.702, 9632/28000 datapoints
2025-03-06 20:47:38,353 - INFO - training batch 351, loss: 0.395, 11232/28000 datapoints
2025-03-06 20:47:38,471 - INFO - training batch 401, loss: 0.719, 12832/28000 datapoints
2025-03-06 20:47:38,596 - INFO - training batch 451, loss: 0.331, 14432/28000 datapoints
2025-03-06 20:47:38,717 - INFO - training batch 501, loss: 0.233, 16032/28000 datapoints
2025-03-06 20:47:38,837 - INFO - training batch 551, loss: 0.397, 17632/28000 datapoints
2025-03-06 20:47:38,958 - INFO - training batch 601, loss: 0.605, 19232/28000 datapoints
2025-03-06 20:47:39,082 - INFO - training batch 651, loss: 0.084, 20832/28000 datapoints
2025-03-06 20:47:39,204 - INFO - training batch 701, loss: 0.371, 22432/28000 datapoints
2025-03-06 20:47:39,321 - INFO - training batch 751, loss: 0.302, 24032/28000 datapoints
2025-03-06 20:47:39,439 - INFO - training batch 801, loss: 0.242, 25632/28000 datapoints
2025-03-06 20:47:39,563 - INFO - training batch 851, loss: 0.679, 27232/28000 datapoints
2025-03-06 20:47:39,645 - INFO - validation batch 1, loss: 0.156, 32/6976 datapoints
2025-03-06 20:47:39,698 - INFO - validation batch 51, loss: 1.253, 1632/6976 datapoints
2025-03-06 20:47:39,742 - INFO - validation batch 101, loss: 0.251, 3232/6976 datapoints
2025-03-06 20:47:39,785 - INFO - validation batch 151, loss: 0.469, 4832/6976 datapoints
2025-03-06 20:47:39,829 - INFO - validation batch 201, loss: 0.367, 6432/6976 datapoints
2025-03-06 20:47:39,844 - INFO - Epoch 244/800 done.
2025-03-06 20:47:39,844 - INFO - Final validation performance:
Loss: 0.499, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 20:47:39,845 - INFO - Beginning epoch 245/800
2025-03-06 20:47:39,848 - INFO - training batch 1, loss: 0.402, 32/28000 datapoints
2025-03-06 20:47:39,978 - INFO - training batch 51, loss: 0.220, 1632/28000 datapoints
2025-03-06 20:47:40,134 - INFO - training batch 101, loss: 0.241, 3232/28000 datapoints
2025-03-06 20:47:40,254 - INFO - training batch 151, loss: 0.755, 4832/28000 datapoints
2025-03-06 20:47:40,373 - INFO - training batch 201, loss: 0.214, 6432/28000 datapoints
2025-03-06 20:47:40,493 - INFO - training batch 251, loss: 0.384, 8032/28000 datapoints
2025-03-06 20:47:40,626 - INFO - training batch 301, loss: 0.702, 9632/28000 datapoints
2025-03-06 20:47:40,750 - INFO - training batch 351, loss: 0.392, 11232/28000 datapoints
2025-03-06 20:47:40,870 - INFO - training batch 401, loss: 0.715, 12832/28000 datapoints
2025-03-06 20:47:40,991 - INFO - training batch 451, loss: 0.329, 14432/28000 datapoints
2025-03-06 20:47:41,119 - INFO - training batch 501, loss: 0.231, 16032/28000 datapoints
2025-03-06 20:47:41,238 - INFO - training batch 551, loss: 0.395, 17632/28000 datapoints
2025-03-06 20:47:41,357 - INFO - training batch 601, loss: 0.602, 19232/28000 datapoints
2025-03-06 20:47:41,485 - INFO - training batch 651, loss: 0.084, 20832/28000 datapoints
2025-03-06 20:47:41,604 - INFO - training batch 701, loss: 0.369, 22432/28000 datapoints
2025-03-06 20:47:41,725 - INFO - training batch 751, loss: 0.302, 24032/28000 datapoints
2025-03-06 20:47:41,844 - INFO - training batch 801, loss: 0.240, 25632/28000 datapoints
2025-03-06 20:47:41,968 - INFO - training batch 851, loss: 0.676, 27232/28000 datapoints
2025-03-06 20:47:42,026 - INFO - validation batch 1, loss: 0.155, 32/6976 datapoints
2025-03-06 20:47:42,071 - INFO - validation batch 51, loss: 1.244, 1632/6976 datapoints
2025-03-06 20:47:42,115 - INFO - validation batch 101, loss: 0.251, 3232/6976 datapoints
2025-03-06 20:47:42,158 - INFO - validation batch 151, loss: 0.459, 4832/6976 datapoints
2025-03-06 20:47:42,202 - INFO - validation batch 201, loss: 0.367, 6432/6976 datapoints
2025-03-06 20:47:42,217 - INFO - Epoch 245/800 done.
2025-03-06 20:47:42,217 - INFO - Final validation performance:
Loss: 0.495, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 20:47:42,218 - INFO - Beginning epoch 246/800
2025-03-06 20:47:42,221 - INFO - training batch 1, loss: 0.400, 32/28000 datapoints
2025-03-06 20:47:42,342 - INFO - training batch 51, loss: 0.218, 1632/28000 datapoints
2025-03-06 20:47:42,463 - INFO - training batch 101, loss: 0.241, 3232/28000 datapoints
2025-03-06 20:47:42,588 - INFO - training batch 151, loss: 0.751, 4832/28000 datapoints
2025-03-06 20:47:42,730 - INFO - training batch 201, loss: 0.212, 6432/28000 datapoints
2025-03-06 20:47:42,851 - INFO - training batch 251, loss: 0.383, 8032/28000 datapoints
2025-03-06 20:47:42,970 - INFO - training batch 301, loss: 0.701, 9632/28000 datapoints
2025-03-06 20:47:43,091 - INFO - training batch 351, loss: 0.390, 11232/28000 datapoints
2025-03-06 20:47:43,211 - INFO - training batch 401, loss: 0.714, 12832/28000 datapoints
2025-03-06 20:47:43,330 - INFO - training batch 451, loss: 0.327, 14432/28000 datapoints
2025-03-06 20:47:43,450 - INFO - training batch 501, loss: 0.230, 16032/28000 datapoints
2025-03-06 20:47:43,570 - INFO - training batch 551, loss: 0.394, 17632/28000 datapoints
2025-03-06 20:47:43,694 - INFO - training batch 601, loss: 0.599, 19232/28000 datapoints
2025-03-06 20:47:43,813 - INFO - training batch 651, loss: 0.083, 20832/28000 datapoints
2025-03-06 20:47:43,934 - INFO - training batch 701, loss: 0.368, 22432/28000 datapoints
2025-03-06 20:47:44,055 - INFO - training batch 751, loss: 0.302, 24032/28000 datapoints
2025-03-06 20:47:44,174 - INFO - training batch 801, loss: 0.238, 25632/28000 datapoints
2025-03-06 20:47:44,293 - INFO - training batch 851, loss: 0.672, 27232/28000 datapoints
2025-03-06 20:47:44,351 - INFO - validation batch 1, loss: 0.154, 32/6976 datapoints
2025-03-06 20:47:44,395 - INFO - validation batch 51, loss: 1.242, 1632/6976 datapoints
2025-03-06 20:47:44,439 - INFO - validation batch 101, loss: 0.252, 3232/6976 datapoints
2025-03-06 20:47:44,483 - INFO - validation batch 151, loss: 0.456, 4832/6976 datapoints
2025-03-06 20:47:44,526 - INFO - validation batch 201, loss: 0.367, 6432/6976 datapoints
2025-03-06 20:47:44,541 - INFO - Epoch 246/800 done.
2025-03-06 20:47:44,541 - INFO - Final validation performance:
Loss: 0.494, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 20:47:44,541 - INFO - Beginning epoch 247/800
2025-03-06 20:47:44,545 - INFO - training batch 1, loss: 0.398, 32/28000 datapoints
2025-03-06 20:47:44,675 - INFO - training batch 51, loss: 0.216, 1632/28000 datapoints
2025-03-06 20:47:44,793 - INFO - training batch 101, loss: 0.240, 3232/28000 datapoints
2025-03-06 20:47:44,917 - INFO - training batch 151, loss: 0.746, 4832/28000 datapoints
2025-03-06 20:47:45,040 - INFO - training batch 201, loss: 0.210, 6432/28000 datapoints
2025-03-06 20:47:45,162 - INFO - training batch 251, loss: 0.383, 8032/28000 datapoints
2025-03-06 20:47:45,283 - INFO - training batch 301, loss: 0.700, 9632/28000 datapoints
2025-03-06 20:47:45,403 - INFO - training batch 351, loss: 0.388, 11232/28000 datapoints
2025-03-06 20:47:45,522 - INFO - training batch 401, loss: 0.710, 12832/28000 datapoints
2025-03-06 20:47:45,646 - INFO - training batch 451, loss: 0.326, 14432/28000 datapoints
2025-03-06 20:47:45,765 - INFO - training batch 501, loss: 0.229, 16032/28000 datapoints
2025-03-06 20:47:45,886 - INFO - training batch 551, loss: 0.392, 17632/28000 datapoints
2025-03-06 20:47:46,012 - INFO - training batch 601, loss: 0.597, 19232/28000 datapoints
2025-03-06 20:47:46,144 - INFO - training batch 651, loss: 0.082, 20832/28000 datapoints
2025-03-06 20:47:46,273 - INFO - training batch 701, loss: 0.366, 22432/28000 datapoints
2025-03-06 20:47:46,401 - INFO - training batch 751, loss: 0.301, 24032/28000 datapoints
2025-03-06 20:47:46,533 - INFO - training batch 801, loss: 0.236, 25632/28000 datapoints
2025-03-06 20:47:46,670 - INFO - training batch 851, loss: 0.669, 27232/28000 datapoints
2025-03-06 20:47:46,737 - INFO - validation batch 1, loss: 0.152, 32/6976 datapoints
2025-03-06 20:47:46,783 - INFO - validation batch 51, loss: 1.241, 1632/6976 datapoints
2025-03-06 20:47:46,831 - INFO - validation batch 101, loss: 0.252, 3232/6976 datapoints
2025-03-06 20:47:46,877 - INFO - validation batch 151, loss: 0.454, 4832/6976 datapoints
2025-03-06 20:47:46,924 - INFO - validation batch 201, loss: 0.368, 6432/6976 datapoints
2025-03-06 20:47:46,941 - INFO - Epoch 247/800 done.
2025-03-06 20:47:46,941 - INFO - Final validation performance:
Loss: 0.494, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 20:47:46,941 - INFO - Beginning epoch 248/800
2025-03-06 20:47:46,945 - INFO - training batch 1, loss: 0.396, 32/28000 datapoints
2025-03-06 20:47:47,064 - INFO - training batch 51, loss: 0.215, 1632/28000 datapoints
2025-03-06 20:47:47,185 - INFO - training batch 101, loss: 0.239, 3232/28000 datapoints
2025-03-06 20:47:47,304 - INFO - training batch 151, loss: 0.741, 4832/28000 datapoints
2025-03-06 20:47:47,425 - INFO - training batch 201, loss: 0.209, 6432/28000 datapoints
2025-03-06 20:47:47,553 - INFO - training batch 251, loss: 0.382, 8032/28000 datapoints
2025-03-06 20:47:47,678 - INFO - training batch 301, loss: 0.699, 9632/28000 datapoints
2025-03-06 20:47:47,797 - INFO - training batch 351, loss: 0.386, 11232/28000 datapoints
2025-03-06 20:47:47,917 - INFO - training batch 401, loss: 0.708, 12832/28000 datapoints
2025-03-06 20:47:48,039 - INFO - training batch 451, loss: 0.325, 14432/28000 datapoints
2025-03-06 20:47:48,160 - INFO - training batch 501, loss: 0.228, 16032/28000 datapoints
2025-03-06 20:47:48,281 - INFO - training batch 551, loss: 0.390, 17632/28000 datapoints
2025-03-06 20:47:48,399 - INFO - training batch 601, loss: 0.595, 19232/28000 datapoints
2025-03-06 20:47:48,519 - INFO - training batch 651, loss: 0.081, 20832/28000 datapoints
2025-03-06 20:47:48,683 - INFO - training batch 701, loss: 0.364, 22432/28000 datapoints
2025-03-06 20:47:48,811 - INFO - training batch 751, loss: 0.300, 24032/28000 datapoints
2025-03-06 20:47:48,932 - INFO - training batch 801, loss: 0.234, 25632/28000 datapoints
2025-03-06 20:47:49,052 - INFO - training batch 851, loss: 0.666, 27232/28000 datapoints
2025-03-06 20:47:49,114 - INFO - validation batch 1, loss: 0.151, 32/6976 datapoints
2025-03-06 20:47:49,160 - INFO - validation batch 51, loss: 1.241, 1632/6976 datapoints
2025-03-06 20:47:49,203 - INFO - validation batch 101, loss: 0.253, 3232/6976 datapoints
2025-03-06 20:47:49,247 - INFO - validation batch 151, loss: 0.453, 4832/6976 datapoints
2025-03-06 20:47:49,291 - INFO - validation batch 201, loss: 0.369, 6432/6976 datapoints
2025-03-06 20:47:49,306 - INFO - Epoch 248/800 done.
2025-03-06 20:47:49,306 - INFO - Final validation performance:
Loss: 0.493, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 20:47:49,307 - INFO - Beginning epoch 249/800
2025-03-06 20:47:49,310 - INFO - training batch 1, loss: 0.394, 32/28000 datapoints
2025-03-06 20:47:49,432 - INFO - training batch 51, loss: 0.213, 1632/28000 datapoints
2025-03-06 20:47:49,552 - INFO - training batch 101, loss: 0.238, 3232/28000 datapoints
2025-03-06 20:47:49,684 - INFO - training batch 151, loss: 0.737, 4832/28000 datapoints
2025-03-06 20:47:49,827 - INFO - training batch 201, loss: 0.208, 6432/28000 datapoints
2025-03-06 20:47:49,947 - INFO - training batch 251, loss: 0.381, 8032/28000 datapoints
2025-03-06 20:47:50,072 - INFO - training batch 301, loss: 0.699, 9632/28000 datapoints
2025-03-06 20:47:50,192 - INFO - training batch 351, loss: 0.384, 11232/28000 datapoints
2025-03-06 20:47:50,311 - INFO - training batch 401, loss: 0.706, 12832/28000 datapoints
2025-03-06 20:47:50,430 - INFO - training batch 451, loss: 0.323, 14432/28000 datapoints
2025-03-06 20:47:50,550 - INFO - training batch 501, loss: 0.227, 16032/28000 datapoints
2025-03-06 20:47:50,679 - INFO - training batch 551, loss: 0.389, 17632/28000 datapoints
2025-03-06 20:47:50,798 - INFO - training batch 601, loss: 0.594, 19232/28000 datapoints
2025-03-06 20:47:50,920 - INFO - training batch 651, loss: 0.081, 20832/28000 datapoints
2025-03-06 20:47:51,041 - INFO - training batch 701, loss: 0.362, 22432/28000 datapoints
2025-03-06 20:47:51,160 - INFO - training batch 751, loss: 0.299, 24032/28000 datapoints
2025-03-06 20:47:51,280 - INFO - training batch 801, loss: 0.232, 25632/28000 datapoints
2025-03-06 20:47:51,400 - INFO - training batch 851, loss: 0.662, 27232/28000 datapoints
2025-03-06 20:47:51,459 - INFO - validation batch 1, loss: 0.151, 32/6976 datapoints
2025-03-06 20:47:51,504 - INFO - validation batch 51, loss: 1.238, 1632/6976 datapoints
2025-03-06 20:47:51,548 - INFO - validation batch 101, loss: 0.254, 3232/6976 datapoints
2025-03-06 20:47:51,594 - INFO - validation batch 151, loss: 0.449, 4832/6976 datapoints
2025-03-06 20:47:51,640 - INFO - validation batch 201, loss: 0.369, 6432/6976 datapoints
2025-03-06 20:47:51,655 - INFO - Epoch 249/800 done.
2025-03-06 20:47:51,656 - INFO - Final validation performance:
Loss: 0.492, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 20:47:51,656 - INFO - Beginning epoch 250/800
2025-03-06 20:47:51,660 - INFO - training batch 1, loss: 0.393, 32/28000 datapoints
2025-03-06 20:47:51,786 - INFO - training batch 51, loss: 0.211, 1632/28000 datapoints
2025-03-06 20:47:51,910 - INFO - training batch 101, loss: 0.237, 3232/28000 datapoints
2025-03-06 20:47:52,029 - INFO - training batch 151, loss: 0.731, 4832/28000 datapoints
2025-03-06 20:47:52,148 - INFO - training batch 201, loss: 0.206, 6432/28000 datapoints
2025-03-06 20:47:52,284 - INFO - training batch 251, loss: 0.380, 8032/28000 datapoints
2025-03-06 20:47:52,404 - INFO - training batch 301, loss: 0.698, 9632/28000 datapoints
2025-03-06 20:47:52,526 - INFO - training batch 351, loss: 0.382, 11232/28000 datapoints
2025-03-06 20:47:52,660 - INFO - training batch 401, loss: 0.703, 12832/28000 datapoints
2025-03-06 20:47:52,786 - INFO - training batch 451, loss: 0.322, 14432/28000 datapoints
2025-03-06 20:47:52,906 - INFO - training batch 501, loss: 0.226, 16032/28000 datapoints
2025-03-06 20:47:53,030 - INFO - training batch 551, loss: 0.387, 17632/28000 datapoints
2025-03-06 20:47:53,149 - INFO - training batch 601, loss: 0.591, 19232/28000 datapoints
2025-03-06 20:47:53,272 - INFO - training batch 651, loss: 0.080, 20832/28000 datapoints
2025-03-06 20:47:53,391 - INFO - training batch 701, loss: 0.361, 22432/28000 datapoints
2025-03-06 20:47:53,510 - INFO - training batch 751, loss: 0.299, 24032/28000 datapoints
2025-03-06 20:47:53,634 - INFO - training batch 801, loss: 0.229, 25632/28000 datapoints
2025-03-06 20:47:53,756 - INFO - training batch 851, loss: 0.659, 27232/28000 datapoints
2025-03-06 20:47:53,814 - INFO - validation batch 1, loss: 0.149, 32/6976 datapoints
2025-03-06 20:47:53,858 - INFO - validation batch 51, loss: 1.236, 1632/6976 datapoints
2025-03-06 20:47:53,903 - INFO - validation batch 101, loss: 0.255, 3232/6976 datapoints
2025-03-06 20:47:53,947 - INFO - validation batch 151, loss: 0.446, 4832/6976 datapoints
2025-03-06 20:47:53,993 - INFO - validation batch 201, loss: 0.369, 6432/6976 datapoints
2025-03-06 20:47:54,008 - INFO - Epoch 250/800 done.
2025-03-06 20:47:54,008 - INFO - Final validation performance:
Loss: 0.491, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 20:47:54,008 - INFO - Beginning epoch 251/800
2025-03-06 20:47:54,012 - INFO - training batch 1, loss: 0.392, 32/28000 datapoints
2025-03-06 20:47:54,135 - INFO - training batch 51, loss: 0.209, 1632/28000 datapoints
2025-03-06 20:47:54,257 - INFO - training batch 101, loss: 0.237, 3232/28000 datapoints
2025-03-06 20:47:54,377 - INFO - training batch 151, loss: 0.728, 4832/28000 datapoints
2025-03-06 20:47:54,498 - INFO - training batch 201, loss: 0.204, 6432/28000 datapoints
2025-03-06 20:47:54,621 - INFO - training batch 251, loss: 0.380, 8032/28000 datapoints
2025-03-06 20:47:54,744 - INFO - training batch 301, loss: 0.698, 9632/28000 datapoints
2025-03-06 20:47:54,863 - INFO - training batch 351, loss: 0.380, 11232/28000 datapoints
2025-03-06 20:47:54,988 - INFO - training batch 401, loss: 0.700, 12832/28000 datapoints
2025-03-06 20:47:55,110 - INFO - training batch 451, loss: 0.321, 14432/28000 datapoints
2025-03-06 20:47:55,231 - INFO - training batch 501, loss: 0.224, 16032/28000 datapoints
2025-03-06 20:47:55,352 - INFO - training batch 551, loss: 0.386, 17632/28000 datapoints
2025-03-06 20:47:55,475 - INFO - training batch 601, loss: 0.588, 19232/28000 datapoints
2025-03-06 20:47:55,595 - INFO - training batch 651, loss: 0.079, 20832/28000 datapoints
2025-03-06 20:47:55,721 - INFO - training batch 701, loss: 0.359, 22432/28000 datapoints
2025-03-06 20:47:55,841 - INFO - training batch 751, loss: 0.299, 24032/28000 datapoints
2025-03-06 20:47:55,961 - INFO - training batch 801, loss: 0.227, 25632/28000 datapoints
2025-03-06 20:47:56,084 - INFO - training batch 851, loss: 0.656, 27232/28000 datapoints
2025-03-06 20:47:56,142 - INFO - validation batch 1, loss: 0.148, 32/6976 datapoints
2025-03-06 20:47:56,186 - INFO - validation batch 51, loss: 1.234, 1632/6976 datapoints
2025-03-06 20:47:56,229 - INFO - validation batch 101, loss: 0.255, 3232/6976 datapoints
2025-03-06 20:47:56,274 - INFO - validation batch 151, loss: 0.442, 4832/6976 datapoints
2025-03-06 20:47:56,319 - INFO - validation batch 201, loss: 0.369, 6432/6976 datapoints
2025-03-06 20:47:56,334 - INFO - Epoch 251/800 done.
2025-03-06 20:47:56,334 - INFO - Final validation performance:
Loss: 0.490, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 20:47:56,335 - INFO - Beginning epoch 252/800
2025-03-06 20:47:56,338 - INFO - training batch 1, loss: 0.390, 32/28000 datapoints
2025-03-06 20:47:56,462 - INFO - training batch 51, loss: 0.207, 1632/28000 datapoints
2025-03-06 20:47:56,582 - INFO - training batch 101, loss: 0.236, 3232/28000 datapoints
2025-03-06 20:47:56,709 - INFO - training batch 151, loss: 0.723, 4832/28000 datapoints
2025-03-06 20:47:56,832 - INFO - training batch 201, loss: 0.203, 6432/28000 datapoints
2025-03-06 20:47:56,951 - INFO - training batch 251, loss: 0.379, 8032/28000 datapoints
2025-03-06 20:47:57,071 - INFO - training batch 301, loss: 0.696, 9632/28000 datapoints
2025-03-06 20:47:57,189 - INFO - training batch 351, loss: 0.378, 11232/28000 datapoints
2025-03-06 20:47:57,310 - INFO - training batch 401, loss: 0.698, 12832/28000 datapoints
2025-03-06 20:47:57,429 - INFO - training batch 451, loss: 0.320, 14432/28000 datapoints
2025-03-06 20:47:57,549 - INFO - training batch 501, loss: 0.223, 16032/28000 datapoints
2025-03-06 20:47:57,674 - INFO - training batch 551, loss: 0.385, 17632/28000 datapoints
2025-03-06 20:47:57,807 - INFO - training batch 601, loss: 0.585, 19232/28000 datapoints
2025-03-06 20:47:57,928 - INFO - training batch 651, loss: 0.078, 20832/28000 datapoints
2025-03-06 20:47:58,047 - INFO - training batch 701, loss: 0.358, 22432/28000 datapoints
2025-03-06 20:47:58,167 - INFO - training batch 751, loss: 0.298, 24032/28000 datapoints
2025-03-06 20:47:58,287 - INFO - training batch 801, loss: 0.225, 25632/28000 datapoints
2025-03-06 20:47:58,426 - INFO - training batch 851, loss: 0.653, 27232/28000 datapoints
2025-03-06 20:47:58,486 - INFO - validation batch 1, loss: 0.148, 32/6976 datapoints
2025-03-06 20:47:58,532 - INFO - validation batch 51, loss: 1.231, 1632/6976 datapoints
2025-03-06 20:47:58,576 - INFO - validation batch 101, loss: 0.256, 3232/6976 datapoints
2025-03-06 20:47:58,624 - INFO - validation batch 151, loss: 0.440, 4832/6976 datapoints
2025-03-06 20:47:58,671 - INFO - validation batch 201, loss: 0.370, 6432/6976 datapoints
2025-03-06 20:47:58,686 - INFO - Epoch 252/800 done.
2025-03-06 20:47:58,686 - INFO - Final validation performance:
Loss: 0.489, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 20:47:58,687 - INFO - Beginning epoch 253/800
2025-03-06 20:47:58,691 - INFO - training batch 1, loss: 0.389, 32/28000 datapoints
2025-03-06 20:47:58,817 - INFO - training batch 51, loss: 0.206, 1632/28000 datapoints
2025-03-06 20:47:58,939 - INFO - training batch 101, loss: 0.235, 3232/28000 datapoints
2025-03-06 20:47:59,061 - INFO - training batch 151, loss: 0.718, 4832/28000 datapoints
2025-03-06 20:47:59,181 - INFO - training batch 201, loss: 0.202, 6432/28000 datapoints
2025-03-06 20:47:59,302 - INFO - training batch 251, loss: 0.378, 8032/28000 datapoints
2025-03-06 20:47:59,426 - INFO - training batch 301, loss: 0.695, 9632/28000 datapoints
2025-03-06 20:47:59,547 - INFO - training batch 351, loss: 0.376, 11232/28000 datapoints
2025-03-06 20:47:59,670 - INFO - training batch 401, loss: 0.697, 12832/28000 datapoints
2025-03-06 20:47:59,798 - INFO - training batch 451, loss: 0.318, 14432/28000 datapoints
2025-03-06 20:47:59,938 - INFO - training batch 501, loss: 0.222, 16032/28000 datapoints
2025-03-06 20:48:00,068 - INFO - training batch 551, loss: 0.384, 17632/28000 datapoints
2025-03-06 20:48:00,191 - INFO - training batch 601, loss: 0.581, 19232/28000 datapoints
2025-03-06 20:48:00,314 - INFO - training batch 651, loss: 0.077, 20832/28000 datapoints
2025-03-06 20:48:00,434 - INFO - training batch 701, loss: 0.356, 22432/28000 datapoints
2025-03-06 20:48:00,554 - INFO - training batch 751, loss: 0.298, 24032/28000 datapoints
2025-03-06 20:48:00,679 - INFO - training batch 801, loss: 0.224, 25632/28000 datapoints
2025-03-06 20:48:00,799 - INFO - training batch 851, loss: 0.650, 27232/28000 datapoints
2025-03-06 20:48:00,859 - INFO - validation batch 1, loss: 0.147, 32/6976 datapoints
2025-03-06 20:48:00,901 - INFO - validation batch 51, loss: 1.229, 1632/6976 datapoints
2025-03-06 20:48:00,944 - INFO - validation batch 101, loss: 0.257, 3232/6976 datapoints
2025-03-06 20:48:00,988 - INFO - validation batch 151, loss: 0.438, 4832/6976 datapoints
2025-03-06 20:48:01,033 - INFO - validation batch 201, loss: 0.371, 6432/6976 datapoints
2025-03-06 20:48:01,048 - INFO - Epoch 253/800 done.
2025-03-06 20:48:01,048 - INFO - Final validation performance:
Loss: 0.488, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 20:48:01,049 - INFO - Beginning epoch 254/800
2025-03-06 20:48:01,052 - INFO - training batch 1, loss: 0.388, 32/28000 datapoints
2025-03-06 20:48:01,172 - INFO - training batch 51, loss: 0.204, 1632/28000 datapoints
2025-03-06 20:48:01,291 - INFO - training batch 101, loss: 0.234, 3232/28000 datapoints
2025-03-06 20:48:01,415 - INFO - training batch 151, loss: 0.713, 4832/28000 datapoints
2025-03-06 20:48:01,535 - INFO - training batch 201, loss: 0.200, 6432/28000 datapoints
2025-03-06 20:48:01,659 - INFO - training batch 251, loss: 0.378, 8032/28000 datapoints
2025-03-06 20:48:01,779 - INFO - training batch 301, loss: 0.695, 9632/28000 datapoints
2025-03-06 20:48:01,903 - INFO - training batch 351, loss: 0.374, 11232/28000 datapoints
2025-03-06 20:48:02,023 - INFO - training batch 401, loss: 0.694, 12832/28000 datapoints
2025-03-06 20:48:02,149 - INFO - training batch 451, loss: 0.317, 14432/28000 datapoints
2025-03-06 20:48:02,272 - INFO - training batch 501, loss: 0.221, 16032/28000 datapoints
2025-03-06 20:48:02,393 - INFO - training batch 551, loss: 0.382, 17632/28000 datapoints
2025-03-06 20:48:02,531 - INFO - training batch 601, loss: 0.578, 19232/28000 datapoints
2025-03-06 20:48:02,665 - INFO - training batch 651, loss: 0.077, 20832/28000 datapoints
2025-03-06 20:48:02,810 - INFO - training batch 701, loss: 0.355, 22432/28000 datapoints
2025-03-06 20:48:02,984 - INFO - training batch 751, loss: 0.297, 24032/28000 datapoints
2025-03-06 20:48:03,139 - INFO - training batch 801, loss: 0.222, 25632/28000 datapoints
2025-03-06 20:48:03,280 - INFO - training batch 851, loss: 0.647, 27232/28000 datapoints
2025-03-06 20:48:03,351 - INFO - validation batch 1, loss: 0.146, 32/6976 datapoints
2025-03-06 20:48:03,395 - INFO - validation batch 51, loss: 1.226, 1632/6976 datapoints
2025-03-06 20:48:03,438 - INFO - validation batch 101, loss: 0.257, 3232/6976 datapoints
2025-03-06 20:48:03,483 - INFO - validation batch 151, loss: 0.436, 4832/6976 datapoints
2025-03-06 20:48:03,528 - INFO - validation batch 201, loss: 0.371, 6432/6976 datapoints
2025-03-06 20:48:03,543 - INFO - Epoch 254/800 done.
2025-03-06 20:48:03,543 - INFO - Final validation performance:
Loss: 0.487, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 20:48:03,544 - INFO - Beginning epoch 255/800
2025-03-06 20:48:03,548 - INFO - training batch 1, loss: 0.386, 32/28000 datapoints
2025-03-06 20:48:03,677 - INFO - training batch 51, loss: 0.203, 1632/28000 datapoints
2025-03-06 20:48:03,797 - INFO - training batch 101, loss: 0.233, 3232/28000 datapoints
2025-03-06 20:48:03,922 - INFO - training batch 151, loss: 0.709, 4832/28000 datapoints
2025-03-06 20:48:04,046 - INFO - training batch 201, loss: 0.199, 6432/28000 datapoints
2025-03-06 20:48:04,165 - INFO - training batch 251, loss: 0.377, 8032/28000 datapoints
2025-03-06 20:48:04,284 - INFO - training batch 301, loss: 0.696, 9632/28000 datapoints
2025-03-06 20:48:04,420 - INFO - training batch 351, loss: 0.372, 11232/28000 datapoints
2025-03-06 20:48:04,540 - INFO - training batch 401, loss: 0.692, 12832/28000 datapoints
2025-03-06 20:48:04,667 - INFO - training batch 451, loss: 0.316, 14432/28000 datapoints
2025-03-06 20:48:04,788 - INFO - training batch 501, loss: 0.221, 16032/28000 datapoints
2025-03-06 20:48:04,925 - INFO - training batch 551, loss: 0.379, 17632/28000 datapoints
2025-03-06 20:48:05,048 - INFO - training batch 601, loss: 0.576, 19232/28000 datapoints
2025-03-06 20:48:05,169 - INFO - training batch 651, loss: 0.076, 20832/28000 datapoints
2025-03-06 20:48:05,292 - INFO - training batch 701, loss: 0.353, 22432/28000 datapoints
2025-03-06 20:48:05,413 - INFO - training batch 751, loss: 0.297, 24032/28000 datapoints
2025-03-06 20:48:05,533 - INFO - training batch 801, loss: 0.220, 25632/28000 datapoints
2025-03-06 20:48:05,655 - INFO - training batch 851, loss: 0.643, 27232/28000 datapoints
2025-03-06 20:48:05,715 - INFO - validation batch 1, loss: 0.145, 32/6976 datapoints
2025-03-06 20:48:05,759 - INFO - validation batch 51, loss: 1.224, 1632/6976 datapoints
2025-03-06 20:48:05,802 - INFO - validation batch 101, loss: 0.258, 3232/6976 datapoints
2025-03-06 20:48:05,846 - INFO - validation batch 151, loss: 0.434, 4832/6976 datapoints
2025-03-06 20:48:05,891 - INFO - validation batch 201, loss: 0.371, 6432/6976 datapoints
2025-03-06 20:48:05,907 - INFO - Epoch 255/800 done.
2025-03-06 20:48:05,907 - INFO - Final validation performance:
Loss: 0.486, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 20:48:05,907 - INFO - Beginning epoch 256/800
2025-03-06 20:48:05,911 - INFO - training batch 1, loss: 0.385, 32/28000 datapoints
2025-03-06 20:48:06,033 - INFO - training batch 51, loss: 0.201, 1632/28000 datapoints
2025-03-06 20:48:06,156 - INFO - training batch 101, loss: 0.232, 3232/28000 datapoints
2025-03-06 20:48:06,280 - INFO - training batch 151, loss: 0.704, 4832/28000 datapoints
2025-03-06 20:48:06,405 - INFO - training batch 201, loss: 0.198, 6432/28000 datapoints
2025-03-06 20:48:06,531 - INFO - training batch 251, loss: 0.376, 8032/28000 datapoints
2025-03-06 20:48:06,664 - INFO - training batch 301, loss: 0.694, 9632/28000 datapoints
2025-03-06 20:48:06,788 - INFO - training batch 351, loss: 0.369, 11232/28000 datapoints
2025-03-06 20:48:06,915 - INFO - training batch 401, loss: 0.690, 12832/28000 datapoints
2025-03-06 20:48:07,038 - INFO - training batch 451, loss: 0.315, 14432/28000 datapoints
2025-03-06 20:48:07,163 - INFO - training batch 501, loss: 0.219, 16032/28000 datapoints
2025-03-06 20:48:07,288 - INFO - training batch 551, loss: 0.378, 17632/28000 datapoints
2025-03-06 20:48:07,413 - INFO - training batch 601, loss: 0.574, 19232/28000 datapoints
2025-03-06 20:48:07,535 - INFO - training batch 651, loss: 0.076, 20832/28000 datapoints
2025-03-06 20:48:07,661 - INFO - training batch 701, loss: 0.351, 22432/28000 datapoints
2025-03-06 20:48:07,785 - INFO - training batch 751, loss: 0.296, 24032/28000 datapoints
2025-03-06 20:48:07,908 - INFO - training batch 801, loss: 0.218, 25632/28000 datapoints
2025-03-06 20:48:08,032 - INFO - training batch 851, loss: 0.641, 27232/28000 datapoints
2025-03-06 20:48:08,094 - INFO - validation batch 1, loss: 0.144, 32/6976 datapoints
2025-03-06 20:48:08,144 - INFO - validation batch 51, loss: 1.222, 1632/6976 datapoints
2025-03-06 20:48:08,193 - INFO - validation batch 101, loss: 0.258, 3232/6976 datapoints
2025-03-06 20:48:08,241 - INFO - validation batch 151, loss: 0.433, 4832/6976 datapoints
2025-03-06 20:48:08,290 - INFO - validation batch 201, loss: 0.374, 6432/6976 datapoints
2025-03-06 20:48:08,305 - INFO - Epoch 256/800 done.
2025-03-06 20:48:08,305 - INFO - Final validation performance:
Loss: 0.486, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 20:48:08,305 - INFO - Beginning epoch 257/800
2025-03-06 20:48:08,309 - INFO - training batch 1, loss: 0.384, 32/28000 datapoints
2025-03-06 20:48:08,435 - INFO - training batch 51, loss: 0.200, 1632/28000 datapoints
2025-03-06 20:48:08,562 - INFO - training batch 101, loss: 0.232, 3232/28000 datapoints
2025-03-06 20:48:08,693 - INFO - training batch 151, loss: 0.700, 4832/28000 datapoints
2025-03-06 20:48:08,817 - INFO - training batch 201, loss: 0.197, 6432/28000 datapoints
2025-03-06 20:48:08,942 - INFO - training batch 251, loss: 0.376, 8032/28000 datapoints
2025-03-06 20:48:09,071 - INFO - training batch 301, loss: 0.694, 9632/28000 datapoints
2025-03-06 20:48:09,197 - INFO - training batch 351, loss: 0.368, 11232/28000 datapoints
2025-03-06 20:48:09,319 - INFO - training batch 401, loss: 0.688, 12832/28000 datapoints
2025-03-06 20:48:09,444 - INFO - training batch 451, loss: 0.314, 14432/28000 datapoints
2025-03-06 20:48:09,568 - INFO - training batch 501, loss: 0.218, 16032/28000 datapoints
2025-03-06 20:48:09,696 - INFO - training batch 551, loss: 0.376, 17632/28000 datapoints
2025-03-06 20:48:09,819 - INFO - training batch 601, loss: 0.571, 19232/28000 datapoints
2025-03-06 20:48:09,966 - INFO - training batch 651, loss: 0.075, 20832/28000 datapoints
2025-03-06 20:48:10,095 - INFO - training batch 701, loss: 0.350, 22432/28000 datapoints
2025-03-06 20:48:10,222 - INFO - training batch 751, loss: 0.293, 24032/28000 datapoints
2025-03-06 20:48:10,346 - INFO - training batch 801, loss: 0.216, 25632/28000 datapoints
2025-03-06 20:48:10,474 - INFO - training batch 851, loss: 0.637, 27232/28000 datapoints
2025-03-06 20:48:10,548 - INFO - validation batch 1, loss: 0.143, 32/6976 datapoints
2025-03-06 20:48:10,595 - INFO - validation batch 51, loss: 1.219, 1632/6976 datapoints
2025-03-06 20:48:10,647 - INFO - validation batch 101, loss: 0.259, 3232/6976 datapoints
2025-03-06 20:48:10,697 - INFO - validation batch 151, loss: 0.430, 4832/6976 datapoints
2025-03-06 20:48:10,745 - INFO - validation batch 201, loss: 0.373, 6432/6976 datapoints
2025-03-06 20:48:10,760 - INFO - Epoch 257/800 done.
2025-03-06 20:48:10,760 - INFO - Final validation performance:
Loss: 0.485, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 20:48:10,760 - INFO - Beginning epoch 258/800
2025-03-06 20:48:10,764 - INFO - training batch 1, loss: 0.382, 32/28000 datapoints
2025-03-06 20:48:10,892 - INFO - training batch 51, loss: 0.199, 1632/28000 datapoints
2025-03-06 20:48:11,019 - INFO - training batch 101, loss: 0.231, 3232/28000 datapoints
2025-03-06 20:48:11,145 - INFO - training batch 151, loss: 0.696, 4832/28000 datapoints
2025-03-06 20:48:11,267 - INFO - training batch 201, loss: 0.195, 6432/28000 datapoints
2025-03-06 20:48:11,391 - INFO - training batch 251, loss: 0.375, 8032/28000 datapoints
2025-03-06 20:48:11,517 - INFO - training batch 301, loss: 0.693, 9632/28000 datapoints
2025-03-06 20:48:11,642 - INFO - training batch 351, loss: 0.366, 11232/28000 datapoints
2025-03-06 20:48:11,765 - INFO - training batch 401, loss: 0.685, 12832/28000 datapoints
2025-03-06 20:48:11,890 - INFO - training batch 451, loss: 0.313, 14432/28000 datapoints
2025-03-06 20:48:12,017 - INFO - training batch 501, loss: 0.217, 16032/28000 datapoints
2025-03-06 20:48:12,138 - INFO - training batch 551, loss: 0.374, 17632/28000 datapoints
2025-03-06 20:48:12,262 - INFO - training batch 601, loss: 0.569, 19232/28000 datapoints
2025-03-06 20:48:12,385 - INFO - training batch 651, loss: 0.075, 20832/28000 datapoints
2025-03-06 20:48:12,508 - INFO - training batch 701, loss: 0.348, 22432/28000 datapoints
2025-03-06 20:48:12,632 - INFO - training batch 751, loss: 0.293, 24032/28000 datapoints
2025-03-06 20:48:12,760 - INFO - training batch 801, loss: 0.214, 25632/28000 datapoints
2025-03-06 20:48:12,884 - INFO - training batch 851, loss: 0.634, 27232/28000 datapoints
2025-03-06 20:48:12,946 - INFO - validation batch 1, loss: 0.143, 32/6976 datapoints
2025-03-06 20:48:12,996 - INFO - validation batch 51, loss: 1.218, 1632/6976 datapoints
2025-03-06 20:48:13,044 - INFO - validation batch 101, loss: 0.260, 3232/6976 datapoints
2025-03-06 20:48:13,092 - INFO - validation batch 151, loss: 0.429, 4832/6976 datapoints
2025-03-06 20:48:13,140 - INFO - validation batch 201, loss: 0.373, 6432/6976 datapoints
2025-03-06 20:48:13,155 - INFO - Epoch 258/800 done.
2025-03-06 20:48:13,155 - INFO - Final validation performance:
Loss: 0.484, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 20:48:13,156 - INFO - Beginning epoch 259/800
2025-03-06 20:48:13,159 - INFO - training batch 1, loss: 0.381, 32/28000 datapoints
2025-03-06 20:48:13,284 - INFO - training batch 51, loss: 0.197, 1632/28000 datapoints
2025-03-06 20:48:13,407 - INFO - training batch 101, loss: 0.230, 3232/28000 datapoints
2025-03-06 20:48:13,534 - INFO - training batch 151, loss: 0.691, 4832/28000 datapoints
2025-03-06 20:48:13,663 - INFO - training batch 201, loss: 0.194, 6432/28000 datapoints
2025-03-06 20:48:13,787 - INFO - training batch 251, loss: 0.375, 8032/28000 datapoints
2025-03-06 20:48:13,912 - INFO - training batch 301, loss: 0.692, 9632/28000 datapoints
2025-03-06 20:48:14,082 - INFO - training batch 351, loss: 0.364, 11232/28000 datapoints
2025-03-06 20:48:14,205 - INFO - training batch 401, loss: 0.683, 12832/28000 datapoints
2025-03-06 20:48:14,330 - INFO - training batch 451, loss: 0.313, 14432/28000 datapoints
2025-03-06 20:48:14,455 - INFO - training batch 501, loss: 0.216, 16032/28000 datapoints
2025-03-06 20:48:14,580 - INFO - training batch 551, loss: 0.372, 17632/28000 datapoints
2025-03-06 20:48:14,715 - INFO - training batch 601, loss: 0.567, 19232/28000 datapoints
2025-03-06 20:48:14,838 - INFO - training batch 651, loss: 0.074, 20832/28000 datapoints
2025-03-06 20:48:14,964 - INFO - training batch 701, loss: 0.347, 22432/28000 datapoints
2025-03-06 20:48:15,090 - INFO - training batch 751, loss: 0.292, 24032/28000 datapoints
2025-03-06 20:48:15,213 - INFO - training batch 801, loss: 0.212, 25632/28000 datapoints
2025-03-06 20:48:15,340 - INFO - training batch 851, loss: 0.632, 27232/28000 datapoints
2025-03-06 20:48:15,403 - INFO - validation batch 1, loss: 0.142, 32/6976 datapoints
2025-03-06 20:48:15,451 - INFO - validation batch 51, loss: 1.215, 1632/6976 datapoints
2025-03-06 20:48:15,498 - INFO - validation batch 101, loss: 0.260, 3232/6976 datapoints
2025-03-06 20:48:15,548 - INFO - validation batch 151, loss: 0.426, 4832/6976 datapoints
2025-03-06 20:48:15,599 - INFO - validation batch 201, loss: 0.374, 6432/6976 datapoints
2025-03-06 20:48:15,614 - INFO - Epoch 259/800 done.
2025-03-06 20:48:15,614 - INFO - Final validation performance:
Loss: 0.484, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 20:48:15,615 - INFO - Beginning epoch 260/800
2025-03-06 20:48:15,619 - INFO - training batch 1, loss: 0.379, 32/28000 datapoints
2025-03-06 20:48:15,749 - INFO - training batch 51, loss: 0.196, 1632/28000 datapoints
2025-03-06 20:48:15,873 - INFO - training batch 101, loss: 0.229, 3232/28000 datapoints
2025-03-06 20:48:15,998 - INFO - training batch 151, loss: 0.687, 4832/28000 datapoints
2025-03-06 20:48:16,127 - INFO - training batch 201, loss: 0.193, 6432/28000 datapoints
2025-03-06 20:48:16,250 - INFO - training batch 251, loss: 0.375, 8032/28000 datapoints
2025-03-06 20:48:16,373 - INFO - training batch 301, loss: 0.692, 9632/28000 datapoints
2025-03-06 20:48:16,504 - INFO - training batch 351, loss: 0.362, 11232/28000 datapoints
2025-03-06 20:48:16,638 - INFO - training batch 401, loss: 0.681, 12832/28000 datapoints
2025-03-06 20:48:16,767 - INFO - training batch 451, loss: 0.311, 14432/28000 datapoints
2025-03-06 20:48:16,893 - INFO - training batch 501, loss: 0.215, 16032/28000 datapoints
2025-03-06 20:48:17,026 - INFO - training batch 551, loss: 0.370, 17632/28000 datapoints
2025-03-06 20:48:17,154 - INFO - training batch 601, loss: 0.566, 19232/28000 datapoints
2025-03-06 20:48:17,279 - INFO - training batch 651, loss: 0.073, 20832/28000 datapoints
2025-03-06 20:48:17,401 - INFO - training batch 701, loss: 0.345, 22432/28000 datapoints
2025-03-06 20:48:17,531 - INFO - training batch 751, loss: 0.290, 24032/28000 datapoints
2025-03-06 20:48:17,662 - INFO - training batch 801, loss: 0.210, 25632/28000 datapoints
2025-03-06 20:48:17,785 - INFO - training batch 851, loss: 0.629, 27232/28000 datapoints
2025-03-06 20:48:17,847 - INFO - validation batch 1, loss: 0.141, 32/6976 datapoints
2025-03-06 20:48:17,893 - INFO - validation batch 51, loss: 1.213, 1632/6976 datapoints
2025-03-06 20:48:17,939 - INFO - validation batch 101, loss: 0.261, 3232/6976 datapoints
2025-03-06 20:48:17,987 - INFO - validation batch 151, loss: 0.425, 4832/6976 datapoints
2025-03-06 20:48:18,035 - INFO - validation batch 201, loss: 0.375, 6432/6976 datapoints
2025-03-06 20:48:18,050 - INFO - Epoch 260/800 done.
2025-03-06 20:48:18,050 - INFO - Final validation performance:
Loss: 0.483, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 20:48:18,051 - INFO - Beginning epoch 261/800
2025-03-06 20:48:18,055 - INFO - training batch 1, loss: 0.379, 32/28000 datapoints
2025-03-06 20:48:18,183 - INFO - training batch 51, loss: 0.194, 1632/28000 datapoints
2025-03-06 20:48:18,308 - INFO - training batch 101, loss: 0.229, 3232/28000 datapoints
2025-03-06 20:48:18,431 - INFO - training batch 151, loss: 0.685, 4832/28000 datapoints
2025-03-06 20:48:18,556 - INFO - training batch 201, loss: 0.191, 6432/28000 datapoints
2025-03-06 20:48:18,685 - INFO - training batch 251, loss: 0.374, 8032/28000 datapoints
2025-03-06 20:48:18,812 - INFO - training batch 301, loss: 0.691, 9632/28000 datapoints
2025-03-06 20:48:18,936 - INFO - training batch 351, loss: 0.360, 11232/28000 datapoints
2025-03-06 20:48:19,060 - INFO - training batch 401, loss: 0.679, 12832/28000 datapoints
2025-03-06 20:48:19,188 - INFO - training batch 451, loss: 0.310, 14432/28000 datapoints
2025-03-06 20:48:19,310 - INFO - training batch 501, loss: 0.214, 16032/28000 datapoints
2025-03-06 20:48:19,432 - INFO - training batch 551, loss: 0.367, 17632/28000 datapoints
2025-03-06 20:48:19,554 - INFO - training batch 601, loss: 0.563, 19232/28000 datapoints
2025-03-06 20:48:19,682 - INFO - training batch 651, loss: 0.073, 20832/28000 datapoints
2025-03-06 20:48:19,805 - INFO - training batch 701, loss: 0.344, 22432/28000 datapoints
2025-03-06 20:48:19,929 - INFO - training batch 751, loss: 0.289, 24032/28000 datapoints
2025-03-06 20:48:20,077 - INFO - training batch 801, loss: 0.209, 25632/28000 datapoints
2025-03-06 20:48:20,206 - INFO - training batch 851, loss: 0.627, 27232/28000 datapoints
2025-03-06 20:48:20,268 - INFO - validation batch 1, loss: 0.140, 32/6976 datapoints
2025-03-06 20:48:20,314 - INFO - validation batch 51, loss: 1.212, 1632/6976 datapoints
2025-03-06 20:48:20,362 - INFO - validation batch 101, loss: 0.262, 3232/6976 datapoints
2025-03-06 20:48:20,409 - INFO - validation batch 151, loss: 0.423, 4832/6976 datapoints
2025-03-06 20:48:20,459 - INFO - validation batch 201, loss: 0.376, 6432/6976 datapoints
2025-03-06 20:48:20,475 - INFO - Epoch 261/800 done.
2025-03-06 20:48:20,476 - INFO - Final validation performance:
Loss: 0.483, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 20:48:20,476 - INFO - Beginning epoch 262/800
2025-03-06 20:48:20,480 - INFO - training batch 1, loss: 0.377, 32/28000 datapoints
2025-03-06 20:48:20,614 - INFO - training batch 51, loss: 0.193, 1632/28000 datapoints
2025-03-06 20:48:20,743 - INFO - training batch 101, loss: 0.227, 3232/28000 datapoints
2025-03-06 20:48:20,868 - INFO - training batch 151, loss: 0.681, 4832/28000 datapoints
2025-03-06 20:48:20,992 - INFO - training batch 201, loss: 0.190, 6432/28000 datapoints
2025-03-06 20:48:21,117 - INFO - training batch 251, loss: 0.374, 8032/28000 datapoints
2025-03-06 20:48:21,239 - INFO - training batch 301, loss: 0.690, 9632/28000 datapoints
2025-03-06 20:48:21,362 - INFO - training batch 351, loss: 0.359, 11232/28000 datapoints
2025-03-06 20:48:21,487 - INFO - training batch 401, loss: 0.677, 12832/28000 datapoints
2025-03-06 20:48:21,613 - INFO - training batch 451, loss: 0.310, 14432/28000 datapoints
2025-03-06 20:48:21,741 - INFO - training batch 501, loss: 0.213, 16032/28000 datapoints
2025-03-06 20:48:21,868 - INFO - training batch 551, loss: 0.366, 17632/28000 datapoints
2025-03-06 20:48:21,993 - INFO - training batch 601, loss: 0.562, 19232/28000 datapoints
2025-03-06 20:48:22,119 - INFO - training batch 651, loss: 0.073, 20832/28000 datapoints
2025-03-06 20:48:22,245 - INFO - training batch 701, loss: 0.342, 22432/28000 datapoints
2025-03-06 20:48:22,368 - INFO - training batch 751, loss: 0.288, 24032/28000 datapoints
2025-03-06 20:48:22,491 - INFO - training batch 801, loss: 0.207, 25632/28000 datapoints
2025-03-06 20:48:22,614 - INFO - training batch 851, loss: 0.624, 27232/28000 datapoints
2025-03-06 20:48:22,687 - INFO - validation batch 1, loss: 0.139, 32/6976 datapoints
2025-03-06 20:48:22,744 - INFO - validation batch 51, loss: 1.208, 1632/6976 datapoints
2025-03-06 20:48:22,793 - INFO - validation batch 101, loss: 0.262, 3232/6976 datapoints
2025-03-06 20:48:22,841 - INFO - validation batch 151, loss: 0.422, 4832/6976 datapoints
2025-03-06 20:48:22,889 - INFO - validation batch 201, loss: 0.376, 6432/6976 datapoints
2025-03-06 20:48:22,905 - INFO - Epoch 262/800 done.
2025-03-06 20:48:22,905 - INFO - Final validation performance:
Loss: 0.482, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 20:48:22,906 - INFO - Beginning epoch 263/800
2025-03-06 20:48:22,910 - INFO - training batch 1, loss: 0.376, 32/28000 datapoints
2025-03-06 20:48:23,038 - INFO - training batch 51, loss: 0.191, 1632/28000 datapoints
2025-03-06 20:48:23,166 - INFO - training batch 101, loss: 0.227, 3232/28000 datapoints
2025-03-06 20:48:23,294 - INFO - training batch 151, loss: 0.677, 4832/28000 datapoints
2025-03-06 20:48:23,417 - INFO - training batch 201, loss: 0.188, 6432/28000 datapoints
2025-03-06 20:48:23,540 - INFO - training batch 251, loss: 0.373, 8032/28000 datapoints
2025-03-06 20:48:23,668 - INFO - training batch 301, loss: 0.689, 9632/28000 datapoints
2025-03-06 20:48:23,800 - INFO - training batch 351, loss: 0.357, 11232/28000 datapoints
2025-03-06 20:48:23,931 - INFO - training batch 401, loss: 0.674, 12832/28000 datapoints
2025-03-06 20:48:24,058 - INFO - training batch 451, loss: 0.308, 14432/28000 datapoints
2025-03-06 20:48:24,183 - INFO - training batch 501, loss: 0.212, 16032/28000 datapoints
2025-03-06 20:48:24,308 - INFO - training batch 551, loss: 0.364, 17632/28000 datapoints
2025-03-06 20:48:24,433 - INFO - training batch 601, loss: 0.559, 19232/28000 datapoints
2025-03-06 20:48:24,555 - INFO - training batch 651, loss: 0.072, 20832/28000 datapoints
2025-03-06 20:48:24,680 - INFO - training batch 701, loss: 0.341, 22432/28000 datapoints
2025-03-06 20:48:24,807 - INFO - training batch 751, loss: 0.288, 24032/28000 datapoints
2025-03-06 20:48:24,936 - INFO - training batch 801, loss: 0.206, 25632/28000 datapoints
2025-03-06 20:48:25,069 - INFO - training batch 851, loss: 0.621, 27232/28000 datapoints
2025-03-06 20:48:25,139 - INFO - validation batch 1, loss: 0.139, 32/6976 datapoints
2025-03-06 20:48:25,198 - INFO - validation batch 51, loss: 1.207, 1632/6976 datapoints
2025-03-06 20:48:25,255 - INFO - validation batch 101, loss: 0.263, 3232/6976 datapoints
2025-03-06 20:48:25,303 - INFO - validation batch 151, loss: 0.421, 4832/6976 datapoints
2025-03-06 20:48:25,350 - INFO - validation batch 201, loss: 0.377, 6432/6976 datapoints
2025-03-06 20:48:25,366 - INFO - Epoch 263/800 done.
2025-03-06 20:48:25,366 - INFO - Final validation performance:
Loss: 0.481, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 20:48:25,367 - INFO - Beginning epoch 264/800
2025-03-06 20:48:25,371 - INFO - training batch 1, loss: 0.375, 32/28000 datapoints
2025-03-06 20:48:25,498 - INFO - training batch 51, loss: 0.190, 1632/28000 datapoints
2025-03-06 20:48:25,623 - INFO - training batch 101, loss: 0.226, 3232/28000 datapoints
2025-03-06 20:48:25,752 - INFO - training batch 151, loss: 0.673, 4832/28000 datapoints
2025-03-06 20:48:25,875 - INFO - training batch 201, loss: 0.187, 6432/28000 datapoints
2025-03-06 20:48:25,999 - INFO - training batch 251, loss: 0.373, 8032/28000 datapoints
2025-03-06 20:48:26,122 - INFO - training batch 301, loss: 0.688, 9632/28000 datapoints
2025-03-06 20:48:26,247 - INFO - training batch 351, loss: 0.356, 11232/28000 datapoints
2025-03-06 20:48:26,369 - INFO - training batch 401, loss: 0.672, 12832/28000 datapoints
2025-03-06 20:48:26,494 - INFO - training batch 451, loss: 0.308, 14432/28000 datapoints
2025-03-06 20:48:26,620 - INFO - training batch 501, loss: 0.211, 16032/28000 datapoints
2025-03-06 20:48:26,755 - INFO - training batch 551, loss: 0.362, 17632/28000 datapoints
2025-03-06 20:48:26,879 - INFO - training batch 601, loss: 0.557, 19232/28000 datapoints
2025-03-06 20:48:27,003 - INFO - training batch 651, loss: 0.071, 20832/28000 datapoints
2025-03-06 20:48:27,126 - INFO - training batch 701, loss: 0.339, 22432/28000 datapoints
2025-03-06 20:48:27,249 - INFO - training batch 751, loss: 0.287, 24032/28000 datapoints
2025-03-06 20:48:27,373 - INFO - training batch 801, loss: 0.204, 25632/28000 datapoints
2025-03-06 20:48:27,498 - INFO - training batch 851, loss: 0.619, 27232/28000 datapoints
2025-03-06 20:48:27,559 - INFO - validation batch 1, loss: 0.138, 32/6976 datapoints
2025-03-06 20:48:27,607 - INFO - validation batch 51, loss: 1.204, 1632/6976 datapoints
2025-03-06 20:48:27,658 - INFO - validation batch 101, loss: 0.263, 3232/6976 datapoints
2025-03-06 20:48:27,707 - INFO - validation batch 151, loss: 0.420, 4832/6976 datapoints
2025-03-06 20:48:27,756 - INFO - validation batch 201, loss: 0.377, 6432/6976 datapoints
2025-03-06 20:48:27,773 - INFO - Epoch 264/800 done.
2025-03-06 20:48:27,773 - INFO - Final validation performance:
Loss: 0.481, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 20:48:27,774 - INFO - Beginning epoch 265/800
2025-03-06 20:48:27,778 - INFO - training batch 1, loss: 0.374, 32/28000 datapoints
2025-03-06 20:48:27,910 - INFO - training batch 51, loss: 0.188, 1632/28000 datapoints
2025-03-06 20:48:28,034 - INFO - training batch 101, loss: 0.224, 3232/28000 datapoints
2025-03-06 20:48:28,157 - INFO - training batch 151, loss: 0.669, 4832/28000 datapoints
2025-03-06 20:48:28,283 - INFO - training batch 201, loss: 0.186, 6432/28000 datapoints
2025-03-06 20:48:28,415 - INFO - training batch 251, loss: 0.373, 8032/28000 datapoints
2025-03-06 20:48:28,548 - INFO - training batch 301, loss: 0.687, 9632/28000 datapoints
2025-03-06 20:48:28,676 - INFO - training batch 351, loss: 0.354, 11232/28000 datapoints
2025-03-06 20:48:28,827 - INFO - training batch 401, loss: 0.670, 12832/28000 datapoints
2025-03-06 20:48:28,951 - INFO - training batch 451, loss: 0.307, 14432/28000 datapoints
2025-03-06 20:48:29,073 - INFO - training batch 501, loss: 0.210, 16032/28000 datapoints
2025-03-06 20:48:29,203 - INFO - training batch 551, loss: 0.360, 17632/28000 datapoints
2025-03-06 20:48:29,329 - INFO - training batch 601, loss: 0.554, 19232/28000 datapoints
2025-03-06 20:48:29,455 - INFO - training batch 651, loss: 0.071, 20832/28000 datapoints
2025-03-06 20:48:29,583 - INFO - training batch 701, loss: 0.338, 22432/28000 datapoints
2025-03-06 20:48:29,711 - INFO - training batch 751, loss: 0.286, 24032/28000 datapoints
2025-03-06 20:48:29,834 - INFO - training batch 801, loss: 0.202, 25632/28000 datapoints
2025-03-06 20:48:29,957 - INFO - training batch 851, loss: 0.616, 27232/28000 datapoints
2025-03-06 20:48:30,020 - INFO - validation batch 1, loss: 0.137, 32/6976 datapoints
2025-03-06 20:48:30,079 - INFO - validation batch 51, loss: 1.202, 1632/6976 datapoints
2025-03-06 20:48:30,143 - INFO - validation batch 101, loss: 0.264, 3232/6976 datapoints
2025-03-06 20:48:30,193 - INFO - validation batch 151, loss: 0.419, 4832/6976 datapoints
2025-03-06 20:48:30,244 - INFO - validation batch 201, loss: 0.379, 6432/6976 datapoints
2025-03-06 20:48:30,259 - INFO - Epoch 265/800 done.
2025-03-06 20:48:30,259 - INFO - Final validation performance:
Loss: 0.480, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 20:48:30,260 - INFO - Beginning epoch 266/800
2025-03-06 20:48:30,264 - INFO - training batch 1, loss: 0.373, 32/28000 datapoints
2025-03-06 20:48:30,390 - INFO - training batch 51, loss: 0.187, 1632/28000 datapoints
2025-03-06 20:48:30,512 - INFO - training batch 101, loss: 0.223, 3232/28000 datapoints
2025-03-06 20:48:30,641 - INFO - training batch 151, loss: 0.665, 4832/28000 datapoints
2025-03-06 20:48:30,771 - INFO - training batch 201, loss: 0.185, 6432/28000 datapoints
2025-03-06 20:48:30,894 - INFO - training batch 251, loss: 0.373, 8032/28000 datapoints
2025-03-06 20:48:31,018 - INFO - training batch 301, loss: 0.686, 9632/28000 datapoints
2025-03-06 20:48:31,142 - INFO - training batch 351, loss: 0.352, 11232/28000 datapoints
2025-03-06 20:48:31,268 - INFO - training batch 401, loss: 0.668, 12832/28000 datapoints
2025-03-06 20:48:31,389 - INFO - training batch 451, loss: 0.307, 14432/28000 datapoints
2025-03-06 20:48:31,513 - INFO - training batch 501, loss: 0.208, 16032/28000 datapoints
2025-03-06 20:48:31,641 - INFO - training batch 551, loss: 0.357, 17632/28000 datapoints
2025-03-06 20:48:31,767 - INFO - training batch 601, loss: 0.553, 19232/28000 datapoints
2025-03-06 20:48:31,895 - INFO - training batch 651, loss: 0.070, 20832/28000 datapoints
2025-03-06 20:48:32,021 - INFO - training batch 701, loss: 0.336, 22432/28000 datapoints
2025-03-06 20:48:32,143 - INFO - training batch 751, loss: 0.286, 24032/28000 datapoints
2025-03-06 20:48:32,270 - INFO - training batch 801, loss: 0.200, 25632/28000 datapoints
2025-03-06 20:48:32,394 - INFO - training batch 851, loss: 0.613, 27232/28000 datapoints
2025-03-06 20:48:32,457 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:48:32,507 - INFO - validation batch 51, loss: 1.199, 1632/6976 datapoints
2025-03-06 20:48:32,561 - INFO - validation batch 101, loss: 0.265, 3232/6976 datapoints
2025-03-06 20:48:32,609 - INFO - validation batch 151, loss: 0.417, 4832/6976 datapoints
2025-03-06 20:48:32,660 - INFO - validation batch 201, loss: 0.378, 6432/6976 datapoints
2025-03-06 20:48:32,679 - INFO - Epoch 266/800 done.
2025-03-06 20:48:32,679 - INFO - Final validation performance:
Loss: 0.479, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 20:48:32,680 - INFO - Beginning epoch 267/800
2025-03-06 20:48:32,684 - INFO - training batch 1, loss: 0.372, 32/28000 datapoints
2025-03-06 20:48:32,815 - INFO - training batch 51, loss: 0.185, 1632/28000 datapoints
2025-03-06 20:48:32,938 - INFO - training batch 101, loss: 0.222, 3232/28000 datapoints
2025-03-06 20:48:33,059 - INFO - training batch 151, loss: 0.661, 4832/28000 datapoints
2025-03-06 20:48:33,177 - INFO - training batch 201, loss: 0.184, 6432/28000 datapoints
2025-03-06 20:48:33,299 - INFO - training batch 251, loss: 0.373, 8032/28000 datapoints
2025-03-06 20:48:33,417 - INFO - training batch 301, loss: 0.685, 9632/28000 datapoints
2025-03-06 20:48:33,537 - INFO - training batch 351, loss: 0.351, 11232/28000 datapoints
2025-03-06 20:48:33,659 - INFO - training batch 401, loss: 0.665, 12832/28000 datapoints
2025-03-06 20:48:33,780 - INFO - training batch 451, loss: 0.306, 14432/28000 datapoints
2025-03-06 20:48:33,898 - INFO - training batch 501, loss: 0.207, 16032/28000 datapoints
2025-03-06 20:48:34,018 - INFO - training batch 551, loss: 0.355, 17632/28000 datapoints
2025-03-06 20:48:34,137 - INFO - training batch 601, loss: 0.551, 19232/28000 datapoints
2025-03-06 20:48:34,257 - INFO - training batch 651, loss: 0.070, 20832/28000 datapoints
2025-03-06 20:48:34,377 - INFO - training batch 701, loss: 0.335, 22432/28000 datapoints
2025-03-06 20:48:34,506 - INFO - training batch 751, loss: 0.285, 24032/28000 datapoints
2025-03-06 20:48:34,627 - INFO - training batch 801, loss: 0.199, 25632/28000 datapoints
2025-03-06 20:48:34,750 - INFO - training batch 851, loss: 0.610, 27232/28000 datapoints
2025-03-06 20:48:34,813 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:48:34,862 - INFO - validation batch 51, loss: 1.197, 1632/6976 datapoints
2025-03-06 20:48:34,917 - INFO - validation batch 101, loss: 0.265, 3232/6976 datapoints
2025-03-06 20:48:34,967 - INFO - validation batch 151, loss: 0.417, 4832/6976 datapoints
2025-03-06 20:48:35,011 - INFO - validation batch 201, loss: 0.380, 6432/6976 datapoints
2025-03-06 20:48:35,026 - INFO - Epoch 267/800 done.
2025-03-06 20:48:35,026 - INFO - Final validation performance:
Loss: 0.479, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 20:48:35,027 - INFO - Beginning epoch 268/800
2025-03-06 20:48:35,031 - INFO - training batch 1, loss: 0.371, 32/28000 datapoints
2025-03-06 20:48:35,152 - INFO - training batch 51, loss: 0.184, 1632/28000 datapoints
2025-03-06 20:48:35,271 - INFO - training batch 101, loss: 0.221, 3232/28000 datapoints
2025-03-06 20:48:35,401 - INFO - training batch 151, loss: 0.657, 4832/28000 datapoints
2025-03-06 20:48:35,520 - INFO - training batch 201, loss: 0.183, 6432/28000 datapoints
2025-03-06 20:48:35,641 - INFO - training batch 251, loss: 0.373, 8032/28000 datapoints
2025-03-06 20:48:35,761 - INFO - training batch 301, loss: 0.684, 9632/28000 datapoints
2025-03-06 20:48:35,881 - INFO - training batch 351, loss: 0.349, 11232/28000 datapoints
2025-03-06 20:48:36,001 - INFO - training batch 401, loss: 0.663, 12832/28000 datapoints
2025-03-06 20:48:36,121 - INFO - training batch 451, loss: 0.306, 14432/28000 datapoints
2025-03-06 20:48:36,243 - INFO - training batch 501, loss: 0.207, 16032/28000 datapoints
2025-03-06 20:48:36,364 - INFO - training batch 551, loss: 0.354, 17632/28000 datapoints
2025-03-06 20:48:36,484 - INFO - training batch 601, loss: 0.550, 19232/28000 datapoints
2025-03-06 20:48:36,603 - INFO - training batch 651, loss: 0.069, 20832/28000 datapoints
2025-03-06 20:48:36,726 - INFO - training batch 701, loss: 0.333, 22432/28000 datapoints
2025-03-06 20:48:36,851 - INFO - training batch 751, loss: 0.285, 24032/28000 datapoints
2025-03-06 20:48:36,971 - INFO - training batch 801, loss: 0.197, 25632/28000 datapoints
2025-03-06 20:48:37,090 - INFO - training batch 851, loss: 0.607, 27232/28000 datapoints
2025-03-06 20:48:37,149 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:48:37,193 - INFO - validation batch 51, loss: 1.194, 1632/6976 datapoints
2025-03-06 20:48:37,236 - INFO - validation batch 101, loss: 0.265, 3232/6976 datapoints
2025-03-06 20:48:37,280 - INFO - validation batch 151, loss: 0.416, 4832/6976 datapoints
2025-03-06 20:48:37,325 - INFO - validation batch 201, loss: 0.378, 6432/6976 datapoints
2025-03-06 20:48:37,341 - INFO - Epoch 268/800 done.
2025-03-06 20:48:37,341 - INFO - Final validation performance:
Loss: 0.478, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 20:48:37,341 - INFO - Beginning epoch 269/800
2025-03-06 20:48:37,345 - INFO - training batch 1, loss: 0.370, 32/28000 datapoints
2025-03-06 20:48:37,466 - INFO - training batch 51, loss: 0.183, 1632/28000 datapoints
2025-03-06 20:48:37,584 - INFO - training batch 101, loss: 0.220, 3232/28000 datapoints
2025-03-06 20:48:37,719 - INFO - training batch 151, loss: 0.653, 4832/28000 datapoints
2025-03-06 20:48:37,842 - INFO - training batch 201, loss: 0.181, 6432/28000 datapoints
2025-03-06 20:48:37,962 - INFO - training batch 251, loss: 0.373, 8032/28000 datapoints
2025-03-06 20:48:38,081 - INFO - training batch 301, loss: 0.683, 9632/28000 datapoints
2025-03-06 20:48:38,201 - INFO - training batch 351, loss: 0.348, 11232/28000 datapoints
2025-03-06 20:48:38,321 - INFO - training batch 401, loss: 0.661, 12832/28000 datapoints
2025-03-06 20:48:38,441 - INFO - training batch 451, loss: 0.305, 14432/28000 datapoints
2025-03-06 20:48:38,559 - INFO - training batch 501, loss: 0.206, 16032/28000 datapoints
2025-03-06 20:48:38,680 - INFO - training batch 551, loss: 0.352, 17632/28000 datapoints
2025-03-06 20:48:38,805 - INFO - training batch 601, loss: 0.547, 19232/28000 datapoints
2025-03-06 20:48:38,927 - INFO - training batch 651, loss: 0.069, 20832/28000 datapoints
2025-03-06 20:48:39,053 - INFO - training batch 701, loss: 0.332, 22432/28000 datapoints
2025-03-06 20:48:39,174 - INFO - training batch 751, loss: 0.284, 24032/28000 datapoints
2025-03-06 20:48:39,294 - INFO - training batch 801, loss: 0.196, 25632/28000 datapoints
2025-03-06 20:48:39,415 - INFO - training batch 851, loss: 0.605, 27232/28000 datapoints
2025-03-06 20:48:39,474 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:48:39,518 - INFO - validation batch 51, loss: 1.191, 1632/6976 datapoints
2025-03-06 20:48:39,562 - INFO - validation batch 101, loss: 0.266, 3232/6976 datapoints
2025-03-06 20:48:39,606 - INFO - validation batch 151, loss: 0.415, 4832/6976 datapoints
2025-03-06 20:48:39,652 - INFO - validation batch 201, loss: 0.378, 6432/6976 datapoints
2025-03-06 20:48:39,667 - INFO - Epoch 269/800 done.
2025-03-06 20:48:39,667 - INFO - Final validation performance:
Loss: 0.477, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 20:48:39,668 - INFO - Beginning epoch 270/800
2025-03-06 20:48:39,671 - INFO - training batch 1, loss: 0.369, 32/28000 datapoints
2025-03-06 20:48:39,793 - INFO - training batch 51, loss: 0.181, 1632/28000 datapoints
2025-03-06 20:48:39,915 - INFO - training batch 101, loss: 0.219, 3232/28000 datapoints
2025-03-06 20:48:40,043 - INFO - training batch 151, loss: 0.649, 4832/28000 datapoints
2025-03-06 20:48:40,176 - INFO - training batch 201, loss: 0.180, 6432/28000 datapoints
2025-03-06 20:48:40,313 - INFO - training batch 251, loss: 0.372, 8032/28000 datapoints
2025-03-06 20:48:40,434 - INFO - training batch 301, loss: 0.682, 9632/28000 datapoints
2025-03-06 20:48:40,553 - INFO - training batch 351, loss: 0.347, 11232/28000 datapoints
2025-03-06 20:48:40,675 - INFO - training batch 401, loss: 0.659, 12832/28000 datapoints
2025-03-06 20:48:40,796 - INFO - training batch 451, loss: 0.304, 14432/28000 datapoints
2025-03-06 20:48:40,922 - INFO - training batch 501, loss: 0.205, 16032/28000 datapoints
2025-03-06 20:48:41,042 - INFO - training batch 551, loss: 0.350, 17632/28000 datapoints
2025-03-06 20:48:41,162 - INFO - training batch 601, loss: 0.545, 19232/28000 datapoints
2025-03-06 20:48:41,284 - INFO - training batch 651, loss: 0.068, 20832/28000 datapoints
2025-03-06 20:48:41,405 - INFO - training batch 701, loss: 0.331, 22432/28000 datapoints
2025-03-06 20:48:41,523 - INFO - training batch 751, loss: 0.283, 24032/28000 datapoints
2025-03-06 20:48:41,646 - INFO - training batch 801, loss: 0.194, 25632/28000 datapoints
2025-03-06 20:48:41,765 - INFO - training batch 851, loss: 0.602, 27232/28000 datapoints
2025-03-06 20:48:41,825 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:48:41,873 - INFO - validation batch 51, loss: 1.188, 1632/6976 datapoints
2025-03-06 20:48:41,917 - INFO - validation batch 101, loss: 0.267, 3232/6976 datapoints
2025-03-06 20:48:41,961 - INFO - validation batch 151, loss: 0.414, 4832/6976 datapoints
2025-03-06 20:48:42,003 - INFO - validation batch 201, loss: 0.380, 6432/6976 datapoints
2025-03-06 20:48:42,019 - INFO - Epoch 270/800 done.
2025-03-06 20:48:42,019 - INFO - Final validation performance:
Loss: 0.477, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 20:48:42,019 - INFO - Beginning epoch 271/800
2025-03-06 20:48:42,023 - INFO - training batch 1, loss: 0.368, 32/28000 datapoints
2025-03-06 20:48:42,144 - INFO - training batch 51, loss: 0.179, 1632/28000 datapoints
2025-03-06 20:48:42,264 - INFO - training batch 101, loss: 0.217, 3232/28000 datapoints
2025-03-06 20:48:42,386 - INFO - training batch 151, loss: 0.645, 4832/28000 datapoints
2025-03-06 20:48:42,511 - INFO - training batch 201, loss: 0.179, 6432/28000 datapoints
2025-03-06 20:48:42,631 - INFO - training batch 251, loss: 0.372, 8032/28000 datapoints
2025-03-06 20:48:42,756 - INFO - training batch 301, loss: 0.682, 9632/28000 datapoints
2025-03-06 20:48:42,880 - INFO - training batch 351, loss: 0.345, 11232/28000 datapoints
2025-03-06 20:48:42,999 - INFO - training batch 401, loss: 0.657, 12832/28000 datapoints
2025-03-06 20:48:43,118 - INFO - training batch 451, loss: 0.304, 14432/28000 datapoints
2025-03-06 20:48:43,239 - INFO - training batch 501, loss: 0.204, 16032/28000 datapoints
2025-03-06 20:48:43,361 - INFO - training batch 551, loss: 0.348, 17632/28000 datapoints
2025-03-06 20:48:43,482 - INFO - training batch 601, loss: 0.543, 19232/28000 datapoints
2025-03-06 20:48:43,603 - INFO - training batch 651, loss: 0.068, 20832/28000 datapoints
2025-03-06 20:48:43,726 - INFO - training batch 701, loss: 0.329, 22432/28000 datapoints
2025-03-06 20:48:43,845 - INFO - training batch 751, loss: 0.283, 24032/28000 datapoints
2025-03-06 20:48:43,967 - INFO - training batch 801, loss: 0.193, 25632/28000 datapoints
2025-03-06 20:48:44,087 - INFO - training batch 851, loss: 0.600, 27232/28000 datapoints
2025-03-06 20:48:44,145 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:48:44,189 - INFO - validation batch 51, loss: 1.186, 1632/6976 datapoints
2025-03-06 20:48:44,233 - INFO - validation batch 101, loss: 0.267, 3232/6976 datapoints
2025-03-06 20:48:44,276 - INFO - validation batch 151, loss: 0.414, 4832/6976 datapoints
2025-03-06 20:48:44,319 - INFO - validation batch 201, loss: 0.381, 6432/6976 datapoints
2025-03-06 20:48:44,334 - INFO - Epoch 271/800 done.
2025-03-06 20:48:44,334 - INFO - Final validation performance:
Loss: 0.476, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 20:48:44,335 - INFO - Beginning epoch 272/800
2025-03-06 20:48:44,338 - INFO - training batch 1, loss: 0.368, 32/28000 datapoints
2025-03-06 20:48:44,461 - INFO - training batch 51, loss: 0.178, 1632/28000 datapoints
2025-03-06 20:48:44,581 - INFO - training batch 101, loss: 0.216, 3232/28000 datapoints
2025-03-06 20:48:44,704 - INFO - training batch 151, loss: 0.641, 4832/28000 datapoints
2025-03-06 20:48:44,827 - INFO - training batch 201, loss: 0.178, 6432/28000 datapoints
2025-03-06 20:48:44,957 - INFO - training batch 251, loss: 0.372, 8032/28000 datapoints
2025-03-06 20:48:45,076 - INFO - training batch 301, loss: 0.681, 9632/28000 datapoints
2025-03-06 20:48:45,197 - INFO - training batch 351, loss: 0.344, 11232/28000 datapoints
2025-03-06 20:48:45,318 - INFO - training batch 401, loss: 0.655, 12832/28000 datapoints
2025-03-06 20:48:45,440 - INFO - training batch 451, loss: 0.303, 14432/28000 datapoints
2025-03-06 20:48:45,560 - INFO - training batch 501, loss: 0.203, 16032/28000 datapoints
2025-03-06 20:48:45,688 - INFO - training batch 551, loss: 0.346, 17632/28000 datapoints
2025-03-06 20:48:45,821 - INFO - training batch 601, loss: 0.541, 19232/28000 datapoints
2025-03-06 20:48:45,943 - INFO - training batch 651, loss: 0.067, 20832/28000 datapoints
2025-03-06 20:48:46,064 - INFO - training batch 701, loss: 0.328, 22432/28000 datapoints
2025-03-06 20:48:46,185 - INFO - training batch 751, loss: 0.282, 24032/28000 datapoints
2025-03-06 20:48:46,307 - INFO - training batch 801, loss: 0.191, 25632/28000 datapoints
2025-03-06 20:48:46,432 - INFO - training batch 851, loss: 0.597, 27232/28000 datapoints
2025-03-06 20:48:46,494 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:48:46,538 - INFO - validation batch 51, loss: 1.183, 1632/6976 datapoints
2025-03-06 20:48:46,583 - INFO - validation batch 101, loss: 0.268, 3232/6976 datapoints
2025-03-06 20:48:46,626 - INFO - validation batch 151, loss: 0.412, 4832/6976 datapoints
2025-03-06 20:48:46,681 - INFO - validation batch 201, loss: 0.381, 6432/6976 datapoints
2025-03-06 20:48:46,696 - INFO - Epoch 272/800 done.
2025-03-06 20:48:46,697 - INFO - Final validation performance:
Loss: 0.475, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 20:48:46,697 - INFO - Beginning epoch 273/800
2025-03-06 20:48:46,701 - INFO - training batch 1, loss: 0.366, 32/28000 datapoints
2025-03-06 20:48:46,823 - INFO - training batch 51, loss: 0.177, 1632/28000 datapoints
2025-03-06 20:48:46,954 - INFO - training batch 101, loss: 0.215, 3232/28000 datapoints
2025-03-06 20:48:47,083 - INFO - training batch 151, loss: 0.636, 4832/28000 datapoints
2025-03-06 20:48:47,211 - INFO - training batch 201, loss: 0.177, 6432/28000 datapoints
2025-03-06 20:48:47,337 - INFO - training batch 251, loss: 0.372, 8032/28000 datapoints
2025-03-06 20:48:47,458 - INFO - training batch 301, loss: 0.680, 9632/28000 datapoints
2025-03-06 20:48:47,576 - INFO - training batch 351, loss: 0.343, 11232/28000 datapoints
2025-03-06 20:48:47,703 - INFO - training batch 401, loss: 0.653, 12832/28000 datapoints
2025-03-06 20:48:47,952 - INFO - training batch 451, loss: 0.302, 14432/28000 datapoints
2025-03-06 20:48:48,077 - INFO - training batch 501, loss: 0.202, 16032/28000 datapoints
2025-03-06 20:48:48,203 - INFO - training batch 551, loss: 0.345, 17632/28000 datapoints
2025-03-06 20:48:48,329 - INFO - training batch 601, loss: 0.539, 19232/28000 datapoints
2025-03-06 20:48:48,457 - INFO - training batch 651, loss: 0.067, 20832/28000 datapoints
2025-03-06 20:48:48,584 - INFO - training batch 701, loss: 0.327, 22432/28000 datapoints
2025-03-06 20:48:48,752 - INFO - training batch 751, loss: 0.282, 24032/28000 datapoints
2025-03-06 20:48:48,915 - INFO - training batch 801, loss: 0.190, 25632/28000 datapoints
2025-03-06 20:48:49,058 - INFO - training batch 851, loss: 0.594, 27232/28000 datapoints
2025-03-06 20:48:49,117 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:48:49,162 - INFO - validation batch 51, loss: 1.180, 1632/6976 datapoints
2025-03-06 20:48:49,206 - INFO - validation batch 101, loss: 0.269, 3232/6976 datapoints
2025-03-06 20:48:49,250 - INFO - validation batch 151, loss: 0.412, 4832/6976 datapoints
2025-03-06 20:48:49,295 - INFO - validation batch 201, loss: 0.382, 6432/6976 datapoints
2025-03-06 20:48:49,310 - INFO - Epoch 273/800 done.
2025-03-06 20:48:49,310 - INFO - Final validation performance:
Loss: 0.475, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:48:49,310 - INFO - Beginning epoch 274/800
2025-03-06 20:48:49,314 - INFO - training batch 1, loss: 0.365, 32/28000 datapoints
2025-03-06 20:48:49,433 - INFO - training batch 51, loss: 0.175, 1632/28000 datapoints
2025-03-06 20:48:49,557 - INFO - training batch 101, loss: 0.214, 3232/28000 datapoints
2025-03-06 20:48:49,681 - INFO - training batch 151, loss: 0.632, 4832/28000 datapoints
2025-03-06 20:48:49,799 - INFO - training batch 201, loss: 0.175, 6432/28000 datapoints
2025-03-06 20:48:49,920 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-06 20:48:50,042 - INFO - training batch 301, loss: 0.679, 9632/28000 datapoints
2025-03-06 20:48:50,161 - INFO - training batch 351, loss: 0.341, 11232/28000 datapoints
2025-03-06 20:48:50,306 - INFO - training batch 401, loss: 0.651, 12832/28000 datapoints
2025-03-06 20:48:50,429 - INFO - training batch 451, loss: 0.302, 14432/28000 datapoints
2025-03-06 20:48:50,550 - INFO - training batch 501, loss: 0.201, 16032/28000 datapoints
2025-03-06 20:48:50,672 - INFO - training batch 551, loss: 0.343, 17632/28000 datapoints
2025-03-06 20:48:50,789 - INFO - training batch 601, loss: 0.538, 19232/28000 datapoints
2025-03-06 20:48:50,914 - INFO - training batch 651, loss: 0.066, 20832/28000 datapoints
2025-03-06 20:48:51,035 - INFO - training batch 701, loss: 0.326, 22432/28000 datapoints
2025-03-06 20:48:51,153 - INFO - training batch 751, loss: 0.282, 24032/28000 datapoints
2025-03-06 20:48:51,274 - INFO - training batch 801, loss: 0.188, 25632/28000 datapoints
2025-03-06 20:48:51,394 - INFO - training batch 851, loss: 0.592, 27232/28000 datapoints
2025-03-06 20:48:51,454 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:48:51,500 - INFO - validation batch 51, loss: 1.179, 1632/6976 datapoints
2025-03-06 20:48:51,544 - INFO - validation batch 101, loss: 0.269, 3232/6976 datapoints
2025-03-06 20:48:51,588 - INFO - validation batch 151, loss: 0.411, 4832/6976 datapoints
2025-03-06 20:48:51,632 - INFO - validation batch 201, loss: 0.383, 6432/6976 datapoints
2025-03-06 20:48:51,651 - INFO - Epoch 274/800 done.
2025-03-06 20:48:51,651 - INFO - Final validation performance:
Loss: 0.475, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:48:51,651 - INFO - Beginning epoch 275/800
2025-03-06 20:48:51,655 - INFO - training batch 1, loss: 0.364, 32/28000 datapoints
2025-03-06 20:48:51,775 - INFO - training batch 51, loss: 0.174, 1632/28000 datapoints
2025-03-06 20:48:51,900 - INFO - training batch 101, loss: 0.213, 3232/28000 datapoints
2025-03-06 20:48:52,025 - INFO - training batch 151, loss: 0.628, 4832/28000 datapoints
2025-03-06 20:48:52,154 - INFO - training batch 201, loss: 0.174, 6432/28000 datapoints
2025-03-06 20:48:52,287 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-06 20:48:52,407 - INFO - training batch 301, loss: 0.678, 9632/28000 datapoints
2025-03-06 20:48:52,530 - INFO - training batch 351, loss: 0.341, 11232/28000 datapoints
2025-03-06 20:48:52,665 - INFO - training batch 401, loss: 0.649, 12832/28000 datapoints
2025-03-06 20:48:52,791 - INFO - training batch 451, loss: 0.301, 14432/28000 datapoints
2025-03-06 20:48:52,917 - INFO - training batch 501, loss: 0.200, 16032/28000 datapoints
2025-03-06 20:48:53,042 - INFO - training batch 551, loss: 0.342, 17632/28000 datapoints
2025-03-06 20:48:53,167 - INFO - training batch 601, loss: 0.534, 19232/28000 datapoints
2025-03-06 20:48:53,286 - INFO - training batch 651, loss: 0.066, 20832/28000 datapoints
2025-03-06 20:48:53,405 - INFO - training batch 701, loss: 0.325, 22432/28000 datapoints
2025-03-06 20:48:53,526 - INFO - training batch 751, loss: 0.282, 24032/28000 datapoints
2025-03-06 20:48:53,648 - INFO - training batch 801, loss: 0.186, 25632/28000 datapoints
2025-03-06 20:48:53,767 - INFO - training batch 851, loss: 0.589, 27232/28000 datapoints
2025-03-06 20:48:53,826 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:48:53,869 - INFO - validation batch 51, loss: 1.177, 1632/6976 datapoints
2025-03-06 20:48:53,914 - INFO - validation batch 101, loss: 0.270, 3232/6976 datapoints
2025-03-06 20:48:53,959 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-06 20:48:54,004 - INFO - validation batch 201, loss: 0.382, 6432/6976 datapoints
2025-03-06 20:48:54,021 - INFO - Epoch 275/800 done.
2025-03-06 20:48:54,021 - INFO - Final validation performance:
Loss: 0.474, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:48:54,022 - INFO - Beginning epoch 276/800
2025-03-06 20:48:54,025 - INFO - training batch 1, loss: 0.364, 32/28000 datapoints
2025-03-06 20:48:54,151 - INFO - training batch 51, loss: 0.173, 1632/28000 datapoints
2025-03-06 20:48:54,271 - INFO - training batch 101, loss: 0.212, 3232/28000 datapoints
2025-03-06 20:48:54,392 - INFO - training batch 151, loss: 0.624, 4832/28000 datapoints
2025-03-06 20:48:54,510 - INFO - training batch 201, loss: 0.173, 6432/28000 datapoints
2025-03-06 20:48:54,631 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-06 20:48:54,753 - INFO - training batch 301, loss: 0.677, 9632/28000 datapoints
2025-03-06 20:48:54,879 - INFO - training batch 351, loss: 0.340, 11232/28000 datapoints
2025-03-06 20:48:55,004 - INFO - training batch 401, loss: 0.648, 12832/28000 datapoints
2025-03-06 20:48:55,126 - INFO - training batch 451, loss: 0.300, 14432/28000 datapoints
2025-03-06 20:48:55,246 - INFO - training batch 501, loss: 0.199, 16032/28000 datapoints
2025-03-06 20:48:55,365 - INFO - training batch 551, loss: 0.340, 17632/28000 datapoints
2025-03-06 20:48:55,485 - INFO - training batch 601, loss: 0.533, 19232/28000 datapoints
2025-03-06 20:48:55,606 - INFO - training batch 651, loss: 0.065, 20832/28000 datapoints
2025-03-06 20:48:55,729 - INFO - training batch 701, loss: 0.323, 22432/28000 datapoints
2025-03-06 20:48:55,849 - INFO - training batch 751, loss: 0.282, 24032/28000 datapoints
2025-03-06 20:48:55,970 - INFO - training batch 801, loss: 0.185, 25632/28000 datapoints
2025-03-06 20:48:56,091 - INFO - training batch 851, loss: 0.587, 27232/28000 datapoints
2025-03-06 20:48:56,149 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:48:56,193 - INFO - validation batch 51, loss: 1.174, 1632/6976 datapoints
2025-03-06 20:48:56,237 - INFO - validation batch 101, loss: 0.271, 3232/6976 datapoints
2025-03-06 20:48:56,281 - INFO - validation batch 151, loss: 0.409, 4832/6976 datapoints
2025-03-06 20:48:56,326 - INFO - validation batch 201, loss: 0.383, 6432/6976 datapoints
2025-03-06 20:48:56,340 - INFO - Epoch 276/800 done.
2025-03-06 20:48:56,340 - INFO - Final validation performance:
Loss: 0.473, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:48:56,341 - INFO - Beginning epoch 277/800
2025-03-06 20:48:56,345 - INFO - training batch 1, loss: 0.362, 32/28000 datapoints
2025-03-06 20:48:56,469 - INFO - training batch 51, loss: 0.171, 1632/28000 datapoints
2025-03-06 20:48:56,595 - INFO - training batch 101, loss: 0.210, 3232/28000 datapoints
2025-03-06 20:48:56,716 - INFO - training batch 151, loss: 0.620, 4832/28000 datapoints
2025-03-06 20:48:56,835 - INFO - training batch 201, loss: 0.172, 6432/28000 datapoints
2025-03-06 20:48:56,958 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-06 20:48:57,081 - INFO - training batch 301, loss: 0.676, 9632/28000 datapoints
2025-03-06 20:48:57,201 - INFO - training batch 351, loss: 0.339, 11232/28000 datapoints
2025-03-06 20:48:57,321 - INFO - training batch 401, loss: 0.646, 12832/28000 datapoints
2025-03-06 20:48:57,441 - INFO - training batch 451, loss: 0.299, 14432/28000 datapoints
2025-03-06 20:48:57,560 - INFO - training batch 501, loss: 0.199, 16032/28000 datapoints
2025-03-06 20:48:57,687 - INFO - training batch 551, loss: 0.338, 17632/28000 datapoints
2025-03-06 20:48:57,806 - INFO - training batch 601, loss: 0.531, 19232/28000 datapoints
2025-03-06 20:48:57,926 - INFO - training batch 651, loss: 0.065, 20832/28000 datapoints
2025-03-06 20:48:58,046 - INFO - training batch 701, loss: 0.322, 22432/28000 datapoints
2025-03-06 20:48:58,167 - INFO - training batch 751, loss: 0.281, 24032/28000 datapoints
2025-03-06 20:48:58,286 - INFO - training batch 801, loss: 0.184, 25632/28000 datapoints
2025-03-06 20:48:58,404 - INFO - training batch 851, loss: 0.584, 27232/28000 datapoints
2025-03-06 20:48:58,462 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 20:48:58,510 - INFO - validation batch 51, loss: 1.172, 1632/6976 datapoints
2025-03-06 20:48:58,554 - INFO - validation batch 101, loss: 0.271, 3232/6976 datapoints
2025-03-06 20:48:58,599 - INFO - validation batch 151, loss: 0.408, 4832/6976 datapoints
2025-03-06 20:48:58,645 - INFO - validation batch 201, loss: 0.383, 6432/6976 datapoints
2025-03-06 20:48:58,659 - INFO - Epoch 277/800 done.
2025-03-06 20:48:58,659 - INFO - Final validation performance:
Loss: 0.473, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:48:58,660 - INFO - Beginning epoch 278/800
2025-03-06 20:48:58,663 - INFO - training batch 1, loss: 0.361, 32/28000 datapoints
2025-03-06 20:48:58,784 - INFO - training batch 51, loss: 0.170, 1632/28000 datapoints
2025-03-06 20:48:58,912 - INFO - training batch 101, loss: 0.209, 3232/28000 datapoints
2025-03-06 20:48:59,035 - INFO - training batch 151, loss: 0.616, 4832/28000 datapoints
2025-03-06 20:48:59,159 - INFO - training batch 201, loss: 0.171, 6432/28000 datapoints
2025-03-06 20:48:59,279 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-06 20:48:59,399 - INFO - training batch 301, loss: 0.675, 9632/28000 datapoints
2025-03-06 20:48:59,519 - INFO - training batch 351, loss: 0.337, 11232/28000 datapoints
2025-03-06 20:48:59,643 - INFO - training batch 401, loss: 0.645, 12832/28000 datapoints
2025-03-06 20:48:59,763 - INFO - training batch 451, loss: 0.298, 14432/28000 datapoints
2025-03-06 20:48:59,882 - INFO - training batch 501, loss: 0.198, 16032/28000 datapoints
2025-03-06 20:49:00,004 - INFO - training batch 551, loss: 0.336, 17632/28000 datapoints
2025-03-06 20:49:00,125 - INFO - training batch 601, loss: 0.528, 19232/28000 datapoints
2025-03-06 20:49:00,248 - INFO - training batch 651, loss: 0.064, 20832/28000 datapoints
2025-03-06 20:49:00,393 - INFO - training batch 701, loss: 0.321, 22432/28000 datapoints
2025-03-06 20:49:00,518 - INFO - training batch 751, loss: 0.281, 24032/28000 datapoints
2025-03-06 20:49:00,642 - INFO - training batch 801, loss: 0.182, 25632/28000 datapoints
2025-03-06 20:49:00,761 - INFO - training batch 851, loss: 0.582, 27232/28000 datapoints
2025-03-06 20:49:00,819 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 20:49:00,865 - INFO - validation batch 51, loss: 1.171, 1632/6976 datapoints
2025-03-06 20:49:00,912 - INFO - validation batch 101, loss: 0.272, 3232/6976 datapoints
2025-03-06 20:49:00,961 - INFO - validation batch 151, loss: 0.408, 4832/6976 datapoints
2025-03-06 20:49:01,005 - INFO - validation batch 201, loss: 0.384, 6432/6976 datapoints
2025-03-06 20:49:01,020 - INFO - Epoch 278/800 done.
2025-03-06 20:49:01,021 - INFO - Final validation performance:
Loss: 0.473, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:49:01,021 - INFO - Beginning epoch 279/800
2025-03-06 20:49:01,024 - INFO - training batch 1, loss: 0.361, 32/28000 datapoints
2025-03-06 20:49:01,145 - INFO - training batch 51, loss: 0.168, 1632/28000 datapoints
2025-03-06 20:49:01,269 - INFO - training batch 101, loss: 0.208, 3232/28000 datapoints
2025-03-06 20:49:01,388 - INFO - training batch 151, loss: 0.612, 4832/28000 datapoints
2025-03-06 20:49:01,509 - INFO - training batch 201, loss: 0.170, 6432/28000 datapoints
2025-03-06 20:49:01,630 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-06 20:49:01,753 - INFO - training batch 301, loss: 0.673, 9632/28000 datapoints
2025-03-06 20:49:01,877 - INFO - training batch 351, loss: 0.336, 11232/28000 datapoints
2025-03-06 20:49:01,997 - INFO - training batch 401, loss: 0.643, 12832/28000 datapoints
2025-03-06 20:49:02,116 - INFO - training batch 451, loss: 0.297, 14432/28000 datapoints
2025-03-06 20:49:02,237 - INFO - training batch 501, loss: 0.197, 16032/28000 datapoints
2025-03-06 20:49:02,357 - INFO - training batch 551, loss: 0.335, 17632/28000 datapoints
2025-03-06 20:49:02,478 - INFO - training batch 601, loss: 0.527, 19232/28000 datapoints
2025-03-06 20:49:02,605 - INFO - training batch 651, loss: 0.064, 20832/28000 datapoints
2025-03-06 20:49:02,729 - INFO - training batch 701, loss: 0.320, 22432/28000 datapoints
2025-03-06 20:49:02,848 - INFO - training batch 751, loss: 0.281, 24032/28000 datapoints
2025-03-06 20:49:02,970 - INFO - training batch 801, loss: 0.181, 25632/28000 datapoints
2025-03-06 20:49:03,090 - INFO - training batch 851, loss: 0.579, 27232/28000 datapoints
2025-03-06 20:49:03,150 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 20:49:03,194 - INFO - validation batch 51, loss: 1.168, 1632/6976 datapoints
2025-03-06 20:49:03,238 - INFO - validation batch 101, loss: 0.272, 3232/6976 datapoints
2025-03-06 20:49:03,281 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 20:49:03,325 - INFO - validation batch 201, loss: 0.385, 6432/6976 datapoints
2025-03-06 20:49:03,339 - INFO - Epoch 279/800 done.
2025-03-06 20:49:03,340 - INFO - Final validation performance:
Loss: 0.473, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 20:49:03,340 - INFO - Beginning epoch 280/800
2025-03-06 20:49:03,344 - INFO - training batch 1, loss: 0.359, 32/28000 datapoints
2025-03-06 20:49:03,466 - INFO - training batch 51, loss: 0.167, 1632/28000 datapoints
2025-03-06 20:49:03,585 - INFO - training batch 101, loss: 0.206, 3232/28000 datapoints
2025-03-06 20:49:03,711 - INFO - training batch 151, loss: 0.608, 4832/28000 datapoints
2025-03-06 20:49:03,830 - INFO - training batch 201, loss: 0.169, 6432/28000 datapoints
2025-03-06 20:49:03,954 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-06 20:49:04,075 - INFO - training batch 301, loss: 0.672, 9632/28000 datapoints
2025-03-06 20:49:04,195 - INFO - training batch 351, loss: 0.335, 11232/28000 datapoints
2025-03-06 20:49:04,316 - INFO - training batch 401, loss: 0.641, 12832/28000 datapoints
2025-03-06 20:49:04,437 - INFO - training batch 451, loss: 0.296, 14432/28000 datapoints
2025-03-06 20:49:04,556 - INFO - training batch 501, loss: 0.196, 16032/28000 datapoints
2025-03-06 20:49:04,679 - INFO - training batch 551, loss: 0.333, 17632/28000 datapoints
2025-03-06 20:49:04,798 - INFO - training batch 601, loss: 0.524, 19232/28000 datapoints
2025-03-06 20:49:04,928 - INFO - training batch 651, loss: 0.063, 20832/28000 datapoints
2025-03-06 20:49:05,049 - INFO - training batch 701, loss: 0.319, 22432/28000 datapoints
2025-03-06 20:49:05,171 - INFO - training batch 751, loss: 0.280, 24032/28000 datapoints
2025-03-06 20:49:05,292 - INFO - training batch 801, loss: 0.180, 25632/28000 datapoints
2025-03-06 20:49:05,411 - INFO - training batch 851, loss: 0.577, 27232/28000 datapoints
2025-03-06 20:49:05,469 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 20:49:05,513 - INFO - validation batch 51, loss: 1.167, 1632/6976 datapoints
2025-03-06 20:49:05,557 - INFO - validation batch 101, loss: 0.273, 3232/6976 datapoints
2025-03-06 20:49:05,600 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 20:49:05,650 - INFO - validation batch 201, loss: 0.386, 6432/6976 datapoints
2025-03-06 20:49:05,670 - INFO - Epoch 280/800 done.
2025-03-06 20:49:05,671 - INFO - Final validation performance:
Loss: 0.472, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 20:49:05,671 - INFO - Beginning epoch 281/800
2025-03-06 20:49:05,674 - INFO - training batch 1, loss: 0.358, 32/28000 datapoints
2025-03-06 20:49:05,799 - INFO - training batch 51, loss: 0.166, 1632/28000 datapoints
2025-03-06 20:49:05,919 - INFO - training batch 101, loss: 0.205, 3232/28000 datapoints
2025-03-06 20:49:06,040 - INFO - training batch 151, loss: 0.603, 4832/28000 datapoints
2025-03-06 20:49:06,160 - INFO - training batch 201, loss: 0.168, 6432/28000 datapoints
2025-03-06 20:49:06,288 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-06 20:49:06,416 - INFO - training batch 301, loss: 0.671, 9632/28000 datapoints
2025-03-06 20:49:06,544 - INFO - training batch 351, loss: 0.334, 11232/28000 datapoints
2025-03-06 20:49:06,670 - INFO - training batch 401, loss: 0.640, 12832/28000 datapoints
2025-03-06 20:49:06,795 - INFO - training batch 451, loss: 0.295, 14432/28000 datapoints
2025-03-06 20:49:06,928 - INFO - training batch 501, loss: 0.196, 16032/28000 datapoints
2025-03-06 20:49:07,060 - INFO - training batch 551, loss: 0.331, 17632/28000 datapoints
2025-03-06 20:49:07,195 - INFO - training batch 601, loss: 0.522, 19232/28000 datapoints
2025-03-06 20:49:07,320 - INFO - training batch 651, loss: 0.062, 20832/28000 datapoints
2025-03-06 20:49:07,446 - INFO - training batch 701, loss: 0.318, 22432/28000 datapoints
2025-03-06 20:49:07,569 - INFO - training batch 751, loss: 0.280, 24032/28000 datapoints
2025-03-06 20:49:07,698 - INFO - training batch 801, loss: 0.178, 25632/28000 datapoints
2025-03-06 20:49:07,823 - INFO - training batch 851, loss: 0.575, 27232/28000 datapoints
2025-03-06 20:49:07,904 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 20:49:07,955 - INFO - validation batch 51, loss: 1.165, 1632/6976 datapoints
2025-03-06 20:49:08,007 - INFO - validation batch 101, loss: 0.274, 3232/6976 datapoints
2025-03-06 20:49:08,055 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 20:49:08,104 - INFO - validation batch 201, loss: 0.386, 6432/6976 datapoints
2025-03-06 20:49:08,121 - INFO - Epoch 281/800 done.
2025-03-06 20:49:08,121 - INFO - Final validation performance:
Loss: 0.472, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:49:08,122 - INFO - Beginning epoch 282/800
2025-03-06 20:49:08,126 - INFO - training batch 1, loss: 0.357, 32/28000 datapoints
2025-03-06 20:49:08,260 - INFO - training batch 51, loss: 0.165, 1632/28000 datapoints
2025-03-06 20:49:08,390 - INFO - training batch 101, loss: 0.204, 3232/28000 datapoints
2025-03-06 20:49:08,519 - INFO - training batch 151, loss: 0.599, 4832/28000 datapoints
2025-03-06 20:49:08,667 - INFO - training batch 201, loss: 0.167, 6432/28000 datapoints
2025-03-06 20:49:08,795 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-06 20:49:08,928 - INFO - training batch 301, loss: 0.670, 9632/28000 datapoints
2025-03-06 20:49:09,052 - INFO - training batch 351, loss: 0.333, 11232/28000 datapoints
2025-03-06 20:49:09,176 - INFO - training batch 401, loss: 0.638, 12832/28000 datapoints
2025-03-06 20:49:09,301 - INFO - training batch 451, loss: 0.294, 14432/28000 datapoints
2025-03-06 20:49:09,427 - INFO - training batch 501, loss: 0.195, 16032/28000 datapoints
2025-03-06 20:49:09,550 - INFO - training batch 551, loss: 0.330, 17632/28000 datapoints
2025-03-06 20:49:09,677 - INFO - training batch 601, loss: 0.521, 19232/28000 datapoints
2025-03-06 20:49:09,803 - INFO - training batch 651, loss: 0.062, 20832/28000 datapoints
2025-03-06 20:49:09,929 - INFO - training batch 701, loss: 0.317, 22432/28000 datapoints
2025-03-06 20:49:10,052 - INFO - training batch 751, loss: 0.280, 24032/28000 datapoints
2025-03-06 20:49:10,177 - INFO - training batch 801, loss: 0.177, 25632/28000 datapoints
2025-03-06 20:49:10,304 - INFO - training batch 851, loss: 0.572, 27232/28000 datapoints
2025-03-06 20:49:10,366 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 20:49:10,422 - INFO - validation batch 51, loss: 1.162, 1632/6976 datapoints
2025-03-06 20:49:10,488 - INFO - validation batch 101, loss: 0.274, 3232/6976 datapoints
2025-03-06 20:49:10,536 - INFO - validation batch 151, loss: 0.404, 4832/6976 datapoints
2025-03-06 20:49:10,582 - INFO - validation batch 201, loss: 0.386, 6432/6976 datapoints
2025-03-06 20:49:10,598 - INFO - Epoch 282/800 done.
2025-03-06 20:49:10,598 - INFO - Final validation performance:
Loss: 0.471, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:49:10,599 - INFO - Beginning epoch 283/800
2025-03-06 20:49:10,602 - INFO - training batch 1, loss: 0.357, 32/28000 datapoints
2025-03-06 20:49:10,730 - INFO - training batch 51, loss: 0.163, 1632/28000 datapoints
2025-03-06 20:49:10,849 - INFO - training batch 101, loss: 0.203, 3232/28000 datapoints
2025-03-06 20:49:10,973 - INFO - training batch 151, loss: 0.598, 4832/28000 datapoints
2025-03-06 20:49:11,094 - INFO - training batch 201, loss: 0.165, 6432/28000 datapoints
2025-03-06 20:49:11,215 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-06 20:49:11,339 - INFO - training batch 301, loss: 0.669, 9632/28000 datapoints
2025-03-06 20:49:11,459 - INFO - training batch 351, loss: 0.332, 11232/28000 datapoints
2025-03-06 20:49:11,579 - INFO - training batch 401, loss: 0.637, 12832/28000 datapoints
2025-03-06 20:49:11,702 - INFO - training batch 451, loss: 0.293, 14432/28000 datapoints
2025-03-06 20:49:11,822 - INFO - training batch 501, loss: 0.194, 16032/28000 datapoints
2025-03-06 20:49:11,947 - INFO - training batch 551, loss: 0.329, 17632/28000 datapoints
2025-03-06 20:49:12,069 - INFO - training batch 601, loss: 0.519, 19232/28000 datapoints
2025-03-06 20:49:12,189 - INFO - training batch 651, loss: 0.062, 20832/28000 datapoints
2025-03-06 20:49:12,311 - INFO - training batch 701, loss: 0.316, 22432/28000 datapoints
2025-03-06 20:49:12,430 - INFO - training batch 751, loss: 0.279, 24032/28000 datapoints
2025-03-06 20:49:12,550 - INFO - training batch 801, loss: 0.175, 25632/28000 datapoints
2025-03-06 20:49:12,675 - INFO - training batch 851, loss: 0.570, 27232/28000 datapoints
2025-03-06 20:49:12,735 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 20:49:12,781 - INFO - validation batch 51, loss: 1.161, 1632/6976 datapoints
2025-03-06 20:49:12,826 - INFO - validation batch 101, loss: 0.275, 3232/6976 datapoints
2025-03-06 20:49:12,870 - INFO - validation batch 151, loss: 0.403, 4832/6976 datapoints
2025-03-06 20:49:12,915 - INFO - validation batch 201, loss: 0.387, 6432/6976 datapoints
2025-03-06 20:49:12,931 - INFO - Epoch 283/800 done.
2025-03-06 20:49:12,931 - INFO - Final validation performance:
Loss: 0.471, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:49:12,931 - INFO - Beginning epoch 284/800
2025-03-06 20:49:12,938 - INFO - training batch 1, loss: 0.357, 32/28000 datapoints
2025-03-06 20:49:13,059 - INFO - training batch 51, loss: 0.162, 1632/28000 datapoints
2025-03-06 20:49:13,179 - INFO - training batch 101, loss: 0.202, 3232/28000 datapoints
2025-03-06 20:49:13,303 - INFO - training batch 151, loss: 0.594, 4832/28000 datapoints
2025-03-06 20:49:13,422 - INFO - training batch 201, loss: 0.164, 6432/28000 datapoints
2025-03-06 20:49:13,542 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-06 20:49:13,664 - INFO - training batch 301, loss: 0.668, 9632/28000 datapoints
2025-03-06 20:49:13,784 - INFO - training batch 351, loss: 0.331, 11232/28000 datapoints
2025-03-06 20:49:13,903 - INFO - training batch 401, loss: 0.635, 12832/28000 datapoints
2025-03-06 20:49:14,023 - INFO - training batch 451, loss: 0.292, 14432/28000 datapoints
2025-03-06 20:49:14,143 - INFO - training batch 501, loss: 0.193, 16032/28000 datapoints
2025-03-06 20:49:14,264 - INFO - training batch 551, loss: 0.327, 17632/28000 datapoints
2025-03-06 20:49:14,382 - INFO - training batch 601, loss: 0.517, 19232/28000 datapoints
2025-03-06 20:49:14,503 - INFO - training batch 651, loss: 0.061, 20832/28000 datapoints
2025-03-06 20:49:14,621 - INFO - training batch 701, loss: 0.314, 22432/28000 datapoints
2025-03-06 20:49:14,742 - INFO - training batch 751, loss: 0.278, 24032/28000 datapoints
2025-03-06 20:49:14,863 - INFO - training batch 801, loss: 0.174, 25632/28000 datapoints
2025-03-06 20:49:14,987 - INFO - training batch 851, loss: 0.567, 27232/28000 datapoints
2025-03-06 20:49:15,047 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 20:49:15,091 - INFO - validation batch 51, loss: 1.159, 1632/6976 datapoints
2025-03-06 20:49:15,135 - INFO - validation batch 101, loss: 0.276, 3232/6976 datapoints
2025-03-06 20:49:15,178 - INFO - validation batch 151, loss: 0.402, 4832/6976 datapoints
2025-03-06 20:49:15,221 - INFO - validation batch 201, loss: 0.387, 6432/6976 datapoints
2025-03-06 20:49:15,237 - INFO - Epoch 284/800 done.
2025-03-06 20:49:15,237 - INFO - Final validation performance:
Loss: 0.470, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:49:15,237 - INFO - Beginning epoch 285/800
2025-03-06 20:49:15,241 - INFO - training batch 1, loss: 0.355, 32/28000 datapoints
2025-03-06 20:49:15,364 - INFO - training batch 51, loss: 0.161, 1632/28000 datapoints
2025-03-06 20:49:15,485 - INFO - training batch 101, loss: 0.202, 3232/28000 datapoints
2025-03-06 20:49:15,608 - INFO - training batch 151, loss: 0.590, 4832/28000 datapoints
2025-03-06 20:49:15,728 - INFO - training batch 201, loss: 0.163, 6432/28000 datapoints
2025-03-06 20:49:15,848 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-06 20:49:15,967 - INFO - training batch 301, loss: 0.667, 9632/28000 datapoints
2025-03-06 20:49:16,088 - INFO - training batch 351, loss: 0.329, 11232/28000 datapoints
2025-03-06 20:49:16,206 - INFO - training batch 401, loss: 0.634, 12832/28000 datapoints
2025-03-06 20:49:16,336 - INFO - training batch 451, loss: 0.291, 14432/28000 datapoints
2025-03-06 20:49:16,478 - INFO - training batch 501, loss: 0.192, 16032/28000 datapoints
2025-03-06 20:49:16,599 - INFO - training batch 551, loss: 0.325, 17632/28000 datapoints
2025-03-06 20:49:16,723 - INFO - training batch 601, loss: 0.515, 19232/28000 datapoints
2025-03-06 20:49:16,843 - INFO - training batch 651, loss: 0.061, 20832/28000 datapoints
2025-03-06 20:49:16,968 - INFO - training batch 701, loss: 0.313, 22432/28000 datapoints
2025-03-06 20:49:17,090 - INFO - training batch 751, loss: 0.278, 24032/28000 datapoints
2025-03-06 20:49:17,209 - INFO - training batch 801, loss: 0.173, 25632/28000 datapoints
2025-03-06 20:49:17,330 - INFO - training batch 851, loss: 0.565, 27232/28000 datapoints
2025-03-06 20:49:17,391 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 20:49:17,437 - INFO - validation batch 51, loss: 1.158, 1632/6976 datapoints
2025-03-06 20:49:17,480 - INFO - validation batch 101, loss: 0.276, 3232/6976 datapoints
2025-03-06 20:49:17,524 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 20:49:17,567 - INFO - validation batch 201, loss: 0.387, 6432/6976 datapoints
2025-03-06 20:49:17,582 - INFO - Epoch 285/800 done.
2025-03-06 20:49:17,583 - INFO - Final validation performance:
Loss: 0.470, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 20:49:17,583 - INFO - Beginning epoch 286/800
2025-03-06 20:49:17,587 - INFO - training batch 1, loss: 0.354, 32/28000 datapoints
2025-03-06 20:49:17,710 - INFO - training batch 51, loss: 0.160, 1632/28000 datapoints
2025-03-06 20:49:17,838 - INFO - training batch 101, loss: 0.200, 3232/28000 datapoints
2025-03-06 20:49:17,958 - INFO - training batch 151, loss: 0.587, 4832/28000 datapoints
2025-03-06 20:49:18,078 - INFO - training batch 201, loss: 0.162, 6432/28000 datapoints
2025-03-06 20:49:18,199 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-06 20:49:18,321 - INFO - training batch 301, loss: 0.666, 9632/28000 datapoints
2025-03-06 20:49:18,442 - INFO - training batch 351, loss: 0.328, 11232/28000 datapoints
2025-03-06 20:49:18,560 - INFO - training batch 401, loss: 0.632, 12832/28000 datapoints
2025-03-06 20:49:18,683 - INFO - training batch 451, loss: 0.291, 14432/28000 datapoints
2025-03-06 20:49:18,802 - INFO - training batch 501, loss: 0.191, 16032/28000 datapoints
2025-03-06 20:49:18,924 - INFO - training batch 551, loss: 0.323, 17632/28000 datapoints
2025-03-06 20:49:19,051 - INFO - training batch 601, loss: 0.513, 19232/28000 datapoints
2025-03-06 20:49:19,173 - INFO - training batch 651, loss: 0.060, 20832/28000 datapoints
2025-03-06 20:49:19,293 - INFO - training batch 701, loss: 0.312, 22432/28000 datapoints
2025-03-06 20:49:19,415 - INFO - training batch 751, loss: 0.278, 24032/28000 datapoints
2025-03-06 20:49:19,535 - INFO - training batch 801, loss: 0.171, 25632/28000 datapoints
2025-03-06 20:49:19,657 - INFO - training batch 851, loss: 0.563, 27232/28000 datapoints
2025-03-06 20:49:19,716 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 20:49:19,760 - INFO - validation batch 51, loss: 1.156, 1632/6976 datapoints
2025-03-06 20:49:19,802 - INFO - validation batch 101, loss: 0.277, 3232/6976 datapoints
2025-03-06 20:49:19,848 - INFO - validation batch 151, loss: 0.400, 4832/6976 datapoints
2025-03-06 20:49:19,893 - INFO - validation batch 201, loss: 0.388, 6432/6976 datapoints
2025-03-06 20:49:19,908 - INFO - Epoch 286/800 done.
2025-03-06 20:49:19,908 - INFO - Final validation performance:
Loss: 0.470, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 20:49:19,909 - INFO - Beginning epoch 287/800
2025-03-06 20:49:19,912 - INFO - training batch 1, loss: 0.354, 32/28000 datapoints
2025-03-06 20:49:20,034 - INFO - training batch 51, loss: 0.158, 1632/28000 datapoints
2025-03-06 20:49:20,154 - INFO - training batch 101, loss: 0.199, 3232/28000 datapoints
2025-03-06 20:49:20,275 - INFO - training batch 151, loss: 0.583, 4832/28000 datapoints
2025-03-06 20:49:20,398 - INFO - training batch 201, loss: 0.161, 6432/28000 datapoints
2025-03-06 20:49:20,523 - INFO - training batch 251, loss: 0.371, 8032/28000 datapoints
2025-03-06 20:49:20,663 - INFO - training batch 301, loss: 0.664, 9632/28000 datapoints
2025-03-06 20:49:20,782 - INFO - training batch 351, loss: 0.326, 11232/28000 datapoints
2025-03-06 20:49:20,903 - INFO - training batch 401, loss: 0.630, 12832/28000 datapoints
2025-03-06 20:49:21,027 - INFO - training batch 451, loss: 0.290, 14432/28000 datapoints
2025-03-06 20:49:21,146 - INFO - training batch 501, loss: 0.190, 16032/28000 datapoints
2025-03-06 20:49:21,264 - INFO - training batch 551, loss: 0.322, 17632/28000 datapoints
2025-03-06 20:49:21,387 - INFO - training batch 601, loss: 0.510, 19232/28000 datapoints
2025-03-06 20:49:21,509 - INFO - training batch 651, loss: 0.060, 20832/28000 datapoints
2025-03-06 20:49:21,628 - INFO - training batch 701, loss: 0.311, 22432/28000 datapoints
2025-03-06 20:49:21,750 - INFO - training batch 751, loss: 0.276, 24032/28000 datapoints
2025-03-06 20:49:21,873 - INFO - training batch 801, loss: 0.170, 25632/28000 datapoints
2025-03-06 20:49:21,993 - INFO - training batch 851, loss: 0.561, 27232/28000 datapoints
2025-03-06 20:49:22,051 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 20:49:22,095 - INFO - validation batch 51, loss: 1.155, 1632/6976 datapoints
2025-03-06 20:49:22,138 - INFO - validation batch 101, loss: 0.278, 3232/6976 datapoints
2025-03-06 20:49:22,182 - INFO - validation batch 151, loss: 0.399, 4832/6976 datapoints
2025-03-06 20:49:22,225 - INFO - validation batch 201, loss: 0.388, 6432/6976 datapoints
2025-03-06 20:49:22,240 - INFO - Epoch 287/800 done.
2025-03-06 20:49:22,241 - INFO - Final validation performance:
Loss: 0.469, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 20:49:22,241 - INFO - Beginning epoch 288/800
2025-03-06 20:49:22,245 - INFO - training batch 1, loss: 0.353, 32/28000 datapoints
2025-03-06 20:49:22,368 - INFO - training batch 51, loss: 0.157, 1632/28000 datapoints
2025-03-06 20:49:22,488 - INFO - training batch 101, loss: 0.198, 3232/28000 datapoints
2025-03-06 20:49:22,612 - INFO - training batch 151, loss: 0.577, 4832/28000 datapoints
2025-03-06 20:49:22,736 - INFO - training batch 201, loss: 0.160, 6432/28000 datapoints
2025-03-06 20:49:22,856 - INFO - training batch 251, loss: 0.370, 8032/28000 datapoints
2025-03-06 20:49:22,976 - INFO - training batch 301, loss: 0.663, 9632/28000 datapoints
2025-03-06 20:49:23,101 - INFO - training batch 351, loss: 0.325, 11232/28000 datapoints
2025-03-06 20:49:23,220 - INFO - training batch 401, loss: 0.629, 12832/28000 datapoints
2025-03-06 20:49:23,340 - INFO - training batch 451, loss: 0.289, 14432/28000 datapoints
2025-03-06 20:49:23,464 - INFO - training batch 501, loss: 0.189, 16032/28000 datapoints
2025-03-06 20:49:23,584 - INFO - training batch 551, loss: 0.321, 17632/28000 datapoints
2025-03-06 20:49:23,707 - INFO - training batch 601, loss: 0.509, 19232/28000 datapoints
2025-03-06 20:49:23,828 - INFO - training batch 651, loss: 0.059, 20832/28000 datapoints
2025-03-06 20:49:23,948 - INFO - training batch 701, loss: 0.310, 22432/28000 datapoints
2025-03-06 20:49:24,071 - INFO - training batch 751, loss: 0.276, 24032/28000 datapoints
2025-03-06 20:49:24,198 - INFO - training batch 801, loss: 0.169, 25632/28000 datapoints
2025-03-06 20:49:24,319 - INFO - training batch 851, loss: 0.559, 27232/28000 datapoints
2025-03-06 20:49:24,379 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 20:49:24,425 - INFO - validation batch 51, loss: 1.153, 1632/6976 datapoints
2025-03-06 20:49:24,471 - INFO - validation batch 101, loss: 0.278, 3232/6976 datapoints
2025-03-06 20:49:24,514 - INFO - validation batch 151, loss: 0.398, 4832/6976 datapoints
2025-03-06 20:49:24,558 - INFO - validation batch 201, loss: 0.388, 6432/6976 datapoints
2025-03-06 20:49:24,573 - INFO - Epoch 288/800 done.
2025-03-06 20:49:24,573 - INFO - Final validation performance:
Loss: 0.469, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 20:49:24,573 - INFO - Beginning epoch 289/800
2025-03-06 20:49:24,577 - INFO - training batch 1, loss: 0.353, 32/28000 datapoints
2025-03-06 20:49:24,701 - INFO - training batch 51, loss: 0.156, 1632/28000 datapoints
2025-03-06 20:49:24,820 - INFO - training batch 101, loss: 0.197, 3232/28000 datapoints
2025-03-06 20:49:24,947 - INFO - training batch 151, loss: 0.576, 4832/28000 datapoints
2025-03-06 20:49:25,075 - INFO - training batch 201, loss: 0.159, 6432/28000 datapoints
2025-03-06 20:49:25,195 - INFO - training batch 251, loss: 0.369, 8032/28000 datapoints
2025-03-06 20:49:25,314 - INFO - training batch 301, loss: 0.662, 9632/28000 datapoints
2025-03-06 20:49:25,434 - INFO - training batch 351, loss: 0.323, 11232/28000 datapoints
2025-03-06 20:49:25,554 - INFO - training batch 401, loss: 0.627, 12832/28000 datapoints
2025-03-06 20:49:25,675 - INFO - training batch 451, loss: 0.289, 14432/28000 datapoints
2025-03-06 20:49:25,794 - INFO - training batch 501, loss: 0.189, 16032/28000 datapoints
2025-03-06 20:49:25,917 - INFO - training batch 551, loss: 0.319, 17632/28000 datapoints
2025-03-06 20:49:26,037 - INFO - training batch 601, loss: 0.507, 19232/28000 datapoints
2025-03-06 20:49:26,157 - INFO - training batch 651, loss: 0.059, 20832/28000 datapoints
2025-03-06 20:49:26,277 - INFO - training batch 701, loss: 0.309, 22432/28000 datapoints
2025-03-06 20:49:26,398 - INFO - training batch 751, loss: 0.275, 24032/28000 datapoints
2025-03-06 20:49:26,521 - INFO - training batch 801, loss: 0.168, 25632/28000 datapoints
2025-03-06 20:49:26,649 - INFO - training batch 851, loss: 0.557, 27232/28000 datapoints
2025-03-06 20:49:26,712 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 20:49:26,760 - INFO - validation batch 51, loss: 1.151, 1632/6976 datapoints
2025-03-06 20:49:26,805 - INFO - validation batch 101, loss: 0.279, 3232/6976 datapoints
2025-03-06 20:49:26,852 - INFO - validation batch 151, loss: 0.397, 4832/6976 datapoints
2025-03-06 20:49:26,899 - INFO - validation batch 201, loss: 0.389, 6432/6976 datapoints
2025-03-06 20:49:26,915 - INFO - Epoch 289/800 done.
2025-03-06 20:49:26,915 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:49:26,916 - INFO - Beginning epoch 290/800
2025-03-06 20:49:26,924 - INFO - training batch 1, loss: 0.352, 32/28000 datapoints
2025-03-06 20:49:27,060 - INFO - training batch 51, loss: 0.155, 1632/28000 datapoints
2025-03-06 20:49:27,194 - INFO - training batch 101, loss: 0.196, 3232/28000 datapoints
2025-03-06 20:49:27,322 - INFO - training batch 151, loss: 0.572, 4832/28000 datapoints
2025-03-06 20:49:27,454 - INFO - training batch 201, loss: 0.157, 6432/28000 datapoints
2025-03-06 20:49:27,582 - INFO - training batch 251, loss: 0.368, 8032/28000 datapoints
2025-03-06 20:49:27,710 - INFO - training batch 301, loss: 0.661, 9632/28000 datapoints
2025-03-06 20:49:27,835 - INFO - training batch 351, loss: 0.322, 11232/28000 datapoints
2025-03-06 20:49:27,959 - INFO - training batch 401, loss: 0.626, 12832/28000 datapoints
2025-03-06 20:49:28,084 - INFO - training batch 451, loss: 0.288, 14432/28000 datapoints
2025-03-06 20:49:28,207 - INFO - training batch 501, loss: 0.188, 16032/28000 datapoints
2025-03-06 20:49:28,332 - INFO - training batch 551, loss: 0.317, 17632/28000 datapoints
2025-03-06 20:49:28,457 - INFO - training batch 601, loss: 0.505, 19232/28000 datapoints
2025-03-06 20:49:28,582 - INFO - training batch 651, loss: 0.058, 20832/28000 datapoints
2025-03-06 20:49:28,707 - INFO - training batch 701, loss: 0.308, 22432/28000 datapoints
2025-03-06 20:49:28,830 - INFO - training batch 751, loss: 0.274, 24032/28000 datapoints
2025-03-06 20:49:28,988 - INFO - training batch 801, loss: 0.167, 25632/28000 datapoints
2025-03-06 20:49:29,117 - INFO - training batch 851, loss: 0.555, 27232/28000 datapoints
2025-03-06 20:49:29,180 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 20:49:29,227 - INFO - validation batch 51, loss: 1.151, 1632/6976 datapoints
2025-03-06 20:49:29,273 - INFO - validation batch 101, loss: 0.280, 3232/6976 datapoints
2025-03-06 20:49:29,315 - INFO - validation batch 151, loss: 0.396, 4832/6976 datapoints
2025-03-06 20:49:29,359 - INFO - validation batch 201, loss: 0.389, 6432/6976 datapoints
2025-03-06 20:49:29,375 - INFO - Epoch 290/800 done.
2025-03-06 20:49:29,375 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:49:29,375 - INFO - Beginning epoch 291/800
2025-03-06 20:49:29,379 - INFO - training batch 1, loss: 0.351, 32/28000 datapoints
2025-03-06 20:49:29,502 - INFO - training batch 51, loss: 0.154, 1632/28000 datapoints
2025-03-06 20:49:29,624 - INFO - training batch 101, loss: 0.196, 3232/28000 datapoints
2025-03-06 20:49:29,747 - INFO - training batch 151, loss: 0.571, 4832/28000 datapoints
2025-03-06 20:49:29,868 - INFO - training batch 201, loss: 0.156, 6432/28000 datapoints
2025-03-06 20:49:29,989 - INFO - training batch 251, loss: 0.369, 8032/28000 datapoints
2025-03-06 20:49:30,109 - INFO - training batch 301, loss: 0.659, 9632/28000 datapoints
2025-03-06 20:49:30,228 - INFO - training batch 351, loss: 0.320, 11232/28000 datapoints
2025-03-06 20:49:30,352 - INFO - training batch 401, loss: 0.625, 12832/28000 datapoints
2025-03-06 20:49:30,472 - INFO - training batch 451, loss: 0.287, 14432/28000 datapoints
2025-03-06 20:49:30,594 - INFO - training batch 501, loss: 0.187, 16032/28000 datapoints
2025-03-06 20:49:30,740 - INFO - training batch 551, loss: 0.315, 17632/28000 datapoints
2025-03-06 20:49:30,861 - INFO - training batch 601, loss: 0.503, 19232/28000 datapoints
2025-03-06 20:49:30,981 - INFO - training batch 651, loss: 0.058, 20832/28000 datapoints
2025-03-06 20:49:31,105 - INFO - training batch 701, loss: 0.307, 22432/28000 datapoints
2025-03-06 20:49:31,225 - INFO - training batch 751, loss: 0.274, 24032/28000 datapoints
2025-03-06 20:49:31,345 - INFO - training batch 801, loss: 0.165, 25632/28000 datapoints
2025-03-06 20:49:31,465 - INFO - training batch 851, loss: 0.553, 27232/28000 datapoints
2025-03-06 20:49:31,527 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 20:49:31,572 - INFO - validation batch 51, loss: 1.150, 1632/6976 datapoints
2025-03-06 20:49:31,620 - INFO - validation batch 101, loss: 0.281, 3232/6976 datapoints
2025-03-06 20:49:31,668 - INFO - validation batch 151, loss: 0.396, 4832/6976 datapoints
2025-03-06 20:49:31,711 - INFO - validation batch 201, loss: 0.390, 6432/6976 datapoints
2025-03-06 20:49:31,725 - INFO - Epoch 291/800 done.
2025-03-06 20:49:31,726 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:49:31,726 - INFO - Beginning epoch 292/800
2025-03-06 20:49:31,730 - INFO - training batch 1, loss: 0.350, 32/28000 datapoints
2025-03-06 20:49:31,852 - INFO - training batch 51, loss: 0.152, 1632/28000 datapoints
2025-03-06 20:49:31,974 - INFO - training batch 101, loss: 0.193, 3232/28000 datapoints
2025-03-06 20:49:32,098 - INFO - training batch 151, loss: 0.565, 4832/28000 datapoints
2025-03-06 20:49:32,216 - INFO - training batch 201, loss: 0.155, 6432/28000 datapoints
2025-03-06 20:49:32,335 - INFO - training batch 251, loss: 0.367, 8032/28000 datapoints
2025-03-06 20:49:32,455 - INFO - training batch 301, loss: 0.658, 9632/28000 datapoints
2025-03-06 20:49:32,574 - INFO - training batch 351, loss: 0.319, 11232/28000 datapoints
2025-03-06 20:49:32,710 - INFO - training batch 401, loss: 0.624, 12832/28000 datapoints
2025-03-06 20:49:32,829 - INFO - training batch 451, loss: 0.287, 14432/28000 datapoints
2025-03-06 20:49:32,948 - INFO - training batch 501, loss: 0.186, 16032/28000 datapoints
2025-03-06 20:49:33,073 - INFO - training batch 551, loss: 0.314, 17632/28000 datapoints
2025-03-06 20:49:33,194 - INFO - training batch 601, loss: 0.501, 19232/28000 datapoints
2025-03-06 20:49:33,314 - INFO - training batch 651, loss: 0.057, 20832/28000 datapoints
2025-03-06 20:49:33,434 - INFO - training batch 701, loss: 0.306, 22432/28000 datapoints
2025-03-06 20:49:33,555 - INFO - training batch 751, loss: 0.273, 24032/28000 datapoints
2025-03-06 20:49:33,675 - INFO - training batch 801, loss: 0.164, 25632/28000 datapoints
2025-03-06 20:49:33,794 - INFO - training batch 851, loss: 0.551, 27232/28000 datapoints
2025-03-06 20:49:33,853 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 20:49:33,900 - INFO - validation batch 51, loss: 1.149, 1632/6976 datapoints
2025-03-06 20:49:33,943 - INFO - validation batch 101, loss: 0.281, 3232/6976 datapoints
2025-03-06 20:49:33,987 - INFO - validation batch 151, loss: 0.396, 4832/6976 datapoints
2025-03-06 20:49:34,034 - INFO - validation batch 201, loss: 0.390, 6432/6976 datapoints
2025-03-06 20:49:34,049 - INFO - Epoch 292/800 done.
2025-03-06 20:49:34,049 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:49:34,050 - INFO - Beginning epoch 293/800
2025-03-06 20:49:34,053 - INFO - training batch 1, loss: 0.350, 32/28000 datapoints
2025-03-06 20:49:34,174 - INFO - training batch 51, loss: 0.151, 1632/28000 datapoints
2025-03-06 20:49:34,294 - INFO - training batch 101, loss: 0.192, 3232/28000 datapoints
2025-03-06 20:49:34,414 - INFO - training batch 151, loss: 0.562, 4832/28000 datapoints
2025-03-06 20:49:34,536 - INFO - training batch 201, loss: 0.154, 6432/28000 datapoints
2025-03-06 20:49:34,657 - INFO - training batch 251, loss: 0.367, 8032/28000 datapoints
2025-03-06 20:49:34,776 - INFO - training batch 301, loss: 0.656, 9632/28000 datapoints
2025-03-06 20:49:34,903 - INFO - training batch 351, loss: 0.318, 11232/28000 datapoints
2025-03-06 20:49:35,023 - INFO - training batch 401, loss: 0.622, 12832/28000 datapoints
2025-03-06 20:49:35,147 - INFO - training batch 451, loss: 0.286, 14432/28000 datapoints
2025-03-06 20:49:35,267 - INFO - training batch 501, loss: 0.185, 16032/28000 datapoints
2025-03-06 20:49:35,389 - INFO - training batch 551, loss: 0.312, 17632/28000 datapoints
2025-03-06 20:49:35,510 - INFO - training batch 601, loss: 0.499, 19232/28000 datapoints
2025-03-06 20:49:35,631 - INFO - training batch 651, loss: 0.057, 20832/28000 datapoints
2025-03-06 20:49:35,754 - INFO - training batch 701, loss: 0.305, 22432/28000 datapoints
2025-03-06 20:49:35,872 - INFO - training batch 751, loss: 0.272, 24032/28000 datapoints
2025-03-06 20:49:35,992 - INFO - training batch 801, loss: 0.163, 25632/28000 datapoints
2025-03-06 20:49:36,112 - INFO - training batch 851, loss: 0.549, 27232/28000 datapoints
2025-03-06 20:49:36,172 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 20:49:36,215 - INFO - validation batch 51, loss: 1.147, 1632/6976 datapoints
2025-03-06 20:49:36,258 - INFO - validation batch 101, loss: 0.282, 3232/6976 datapoints
2025-03-06 20:49:36,302 - INFO - validation batch 151, loss: 0.394, 4832/6976 datapoints
2025-03-06 20:49:36,345 - INFO - validation batch 201, loss: 0.390, 6432/6976 datapoints
2025-03-06 20:49:36,360 - INFO - Epoch 293/800 done.
2025-03-06 20:49:36,360 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:49:36,360 - INFO - Beginning epoch 294/800
2025-03-06 20:49:36,364 - INFO - training batch 1, loss: 0.349, 32/28000 datapoints
2025-03-06 20:49:36,486 - INFO - training batch 51, loss: 0.150, 1632/28000 datapoints
2025-03-06 20:49:36,611 - INFO - training batch 101, loss: 0.192, 3232/28000 datapoints
2025-03-06 20:49:36,732 - INFO - training batch 151, loss: 0.559, 4832/28000 datapoints
2025-03-06 20:49:36,852 - INFO - training batch 201, loss: 0.153, 6432/28000 datapoints
2025-03-06 20:49:36,970 - INFO - training batch 251, loss: 0.366, 8032/28000 datapoints
2025-03-06 20:49:37,096 - INFO - training batch 301, loss: 0.655, 9632/28000 datapoints
2025-03-06 20:49:37,216 - INFO - training batch 351, loss: 0.316, 11232/28000 datapoints
2025-03-06 20:49:37,335 - INFO - training batch 401, loss: 0.622, 12832/28000 datapoints
2025-03-06 20:49:37,455 - INFO - training batch 451, loss: 0.286, 14432/28000 datapoints
2025-03-06 20:49:37,575 - INFO - training batch 501, loss: 0.185, 16032/28000 datapoints
2025-03-06 20:49:37,707 - INFO - training batch 551, loss: 0.311, 17632/28000 datapoints
2025-03-06 20:49:37,826 - INFO - training batch 601, loss: 0.496, 19232/28000 datapoints
2025-03-06 20:49:37,945 - INFO - training batch 651, loss: 0.056, 20832/28000 datapoints
2025-03-06 20:49:38,064 - INFO - training batch 701, loss: 0.304, 22432/28000 datapoints
2025-03-06 20:49:38,184 - INFO - training batch 751, loss: 0.273, 24032/28000 datapoints
2025-03-06 20:49:38,304 - INFO - training batch 801, loss: 0.161, 25632/28000 datapoints
2025-03-06 20:49:38,424 - INFO - training batch 851, loss: 0.547, 27232/28000 datapoints
2025-03-06 20:49:38,482 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 20:49:38,526 - INFO - validation batch 51, loss: 1.146, 1632/6976 datapoints
2025-03-06 20:49:38,573 - INFO - validation batch 101, loss: 0.283, 3232/6976 datapoints
2025-03-06 20:49:38,616 - INFO - validation batch 151, loss: 0.394, 4832/6976 datapoints
2025-03-06 20:49:38,664 - INFO - validation batch 201, loss: 0.391, 6432/6976 datapoints
2025-03-06 20:49:38,679 - INFO - Epoch 294/800 done.
2025-03-06 20:49:38,679 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:49:38,680 - INFO - Beginning epoch 295/800
2025-03-06 20:49:38,683 - INFO - training batch 1, loss: 0.348, 32/28000 datapoints
2025-03-06 20:49:38,803 - INFO - training batch 51, loss: 0.149, 1632/28000 datapoints
2025-03-06 20:49:38,922 - INFO - training batch 101, loss: 0.190, 3232/28000 datapoints
2025-03-06 20:49:39,042 - INFO - training batch 151, loss: 0.555, 4832/28000 datapoints
2025-03-06 20:49:39,170 - INFO - training batch 201, loss: 0.152, 6432/28000 datapoints
2025-03-06 20:49:39,289 - INFO - training batch 251, loss: 0.367, 8032/28000 datapoints
2025-03-06 20:49:39,409 - INFO - training batch 301, loss: 0.654, 9632/28000 datapoints
2025-03-06 20:49:39,530 - INFO - training batch 351, loss: 0.316, 11232/28000 datapoints
2025-03-06 20:49:39,653 - INFO - training batch 401, loss: 0.620, 12832/28000 datapoints
2025-03-06 20:49:39,772 - INFO - training batch 451, loss: 0.285, 14432/28000 datapoints
2025-03-06 20:49:39,892 - INFO - training batch 501, loss: 0.184, 16032/28000 datapoints
2025-03-06 20:49:40,014 - INFO - training batch 551, loss: 0.310, 17632/28000 datapoints
2025-03-06 20:49:40,140 - INFO - training batch 601, loss: 0.493, 19232/28000 datapoints
2025-03-06 20:49:40,260 - INFO - training batch 651, loss: 0.056, 20832/28000 datapoints
2025-03-06 20:49:40,382 - INFO - training batch 701, loss: 0.303, 22432/28000 datapoints
2025-03-06 20:49:40,503 - INFO - training batch 751, loss: 0.272, 24032/28000 datapoints
2025-03-06 20:49:40,626 - INFO - training batch 801, loss: 0.160, 25632/28000 datapoints
2025-03-06 20:49:40,780 - INFO - training batch 851, loss: 0.545, 27232/28000 datapoints
2025-03-06 20:49:40,840 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 20:49:40,883 - INFO - validation batch 51, loss: 1.145, 1632/6976 datapoints
2025-03-06 20:49:40,927 - INFO - validation batch 101, loss: 0.284, 3232/6976 datapoints
2025-03-06 20:49:40,970 - INFO - validation batch 151, loss: 0.394, 4832/6976 datapoints
2025-03-06 20:49:41,014 - INFO - validation batch 201, loss: 0.391, 6432/6976 datapoints
2025-03-06 20:49:41,029 - INFO - Epoch 295/800 done.
2025-03-06 20:49:41,029 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:49:41,029 - INFO - Beginning epoch 296/800
2025-03-06 20:49:41,033 - INFO - training batch 1, loss: 0.348, 32/28000 datapoints
2025-03-06 20:49:41,159 - INFO - training batch 51, loss: 0.147, 1632/28000 datapoints
2025-03-06 20:49:41,279 - INFO - training batch 101, loss: 0.189, 3232/28000 datapoints
2025-03-06 20:49:41,399 - INFO - training batch 151, loss: 0.551, 4832/28000 datapoints
2025-03-06 20:49:41,522 - INFO - training batch 201, loss: 0.151, 6432/28000 datapoints
2025-03-06 20:49:41,645 - INFO - training batch 251, loss: 0.365, 8032/28000 datapoints
2025-03-06 20:49:41,768 - INFO - training batch 301, loss: 0.652, 9632/28000 datapoints
2025-03-06 20:49:41,887 - INFO - training batch 351, loss: 0.314, 11232/28000 datapoints
2025-03-06 20:49:42,009 - INFO - training batch 401, loss: 0.619, 12832/28000 datapoints
2025-03-06 20:49:42,136 - INFO - training batch 451, loss: 0.284, 14432/28000 datapoints
2025-03-06 20:49:42,263 - INFO - training batch 501, loss: 0.183, 16032/28000 datapoints
2025-03-06 20:49:42,384 - INFO - training batch 551, loss: 0.308, 17632/28000 datapoints
2025-03-06 20:49:42,504 - INFO - training batch 601, loss: 0.492, 19232/28000 datapoints
2025-03-06 20:49:42,625 - INFO - training batch 651, loss: 0.056, 20832/28000 datapoints
2025-03-06 20:49:42,761 - INFO - training batch 701, loss: 0.302, 22432/28000 datapoints
2025-03-06 20:49:42,881 - INFO - training batch 751, loss: 0.272, 24032/28000 datapoints
2025-03-06 20:49:42,999 - INFO - training batch 801, loss: 0.159, 25632/28000 datapoints
2025-03-06 20:49:43,122 - INFO - training batch 851, loss: 0.543, 27232/28000 datapoints
2025-03-06 20:49:43,184 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 20:49:43,227 - INFO - validation batch 51, loss: 1.144, 1632/6976 datapoints
2025-03-06 20:49:43,271 - INFO - validation batch 101, loss: 0.285, 3232/6976 datapoints
2025-03-06 20:49:43,315 - INFO - validation batch 151, loss: 0.393, 4832/6976 datapoints
2025-03-06 20:49:43,358 - INFO - validation batch 201, loss: 0.392, 6432/6976 datapoints
2025-03-06 20:49:43,373 - INFO - Epoch 296/800 done.
2025-03-06 20:49:43,373 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:49:43,374 - INFO - Beginning epoch 297/800
2025-03-06 20:49:43,378 - INFO - training batch 1, loss: 0.346, 32/28000 datapoints
2025-03-06 20:49:43,500 - INFO - training batch 51, loss: 0.146, 1632/28000 datapoints
2025-03-06 20:49:43,622 - INFO - training batch 101, loss: 0.188, 3232/28000 datapoints
2025-03-06 20:49:43,748 - INFO - training batch 151, loss: 0.547, 4832/28000 datapoints
2025-03-06 20:49:43,869 - INFO - training batch 201, loss: 0.150, 6432/28000 datapoints
2025-03-06 20:49:43,987 - INFO - training batch 251, loss: 0.364, 8032/28000 datapoints
2025-03-06 20:49:44,107 - INFO - training batch 301, loss: 0.651, 9632/28000 datapoints
2025-03-06 20:49:44,231 - INFO - training batch 351, loss: 0.312, 11232/28000 datapoints
2025-03-06 20:49:44,357 - INFO - training batch 401, loss: 0.617, 12832/28000 datapoints
2025-03-06 20:49:44,484 - INFO - training batch 451, loss: 0.284, 14432/28000 datapoints
2025-03-06 20:49:44,603 - INFO - training batch 501, loss: 0.182, 16032/28000 datapoints
2025-03-06 20:49:44,726 - INFO - training batch 551, loss: 0.306, 17632/28000 datapoints
2025-03-06 20:49:44,845 - INFO - training batch 601, loss: 0.488, 19232/28000 datapoints
2025-03-06 20:49:44,971 - INFO - training batch 651, loss: 0.055, 20832/28000 datapoints
2025-03-06 20:49:45,095 - INFO - training batch 701, loss: 0.301, 22432/28000 datapoints
2025-03-06 20:49:45,215 - INFO - training batch 751, loss: 0.270, 24032/28000 datapoints
2025-03-06 20:49:45,334 - INFO - training batch 801, loss: 0.158, 25632/28000 datapoints
2025-03-06 20:49:45,456 - INFO - training batch 851, loss: 0.540, 27232/28000 datapoints
2025-03-06 20:49:45,515 - INFO - validation batch 1, loss: 0.123, 32/6976 datapoints
2025-03-06 20:49:45,558 - INFO - validation batch 51, loss: 1.144, 1632/6976 datapoints
2025-03-06 20:49:45,602 - INFO - validation batch 101, loss: 0.285, 3232/6976 datapoints
2025-03-06 20:49:45,648 - INFO - validation batch 151, loss: 0.393, 4832/6976 datapoints
2025-03-06 20:49:45,695 - INFO - validation batch 201, loss: 0.392, 6432/6976 datapoints
2025-03-06 20:49:45,710 - INFO - Epoch 297/800 done.
2025-03-06 20:49:45,710 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:49:45,711 - INFO - Beginning epoch 298/800
2025-03-06 20:49:45,714 - INFO - training batch 1, loss: 0.347, 32/28000 datapoints
2025-03-06 20:49:45,836 - INFO - training batch 51, loss: 0.145, 1632/28000 datapoints
2025-03-06 20:49:45,955 - INFO - training batch 101, loss: 0.187, 3232/28000 datapoints
2025-03-06 20:49:46,075 - INFO - training batch 151, loss: 0.544, 4832/28000 datapoints
2025-03-06 20:49:46,195 - INFO - training batch 201, loss: 0.149, 6432/28000 datapoints
2025-03-06 20:49:46,315 - INFO - training batch 251, loss: 0.363, 8032/28000 datapoints
2025-03-06 20:49:46,438 - INFO - training batch 301, loss: 0.650, 9632/28000 datapoints
2025-03-06 20:49:46,559 - INFO - training batch 351, loss: 0.311, 11232/28000 datapoints
2025-03-06 20:49:46,690 - INFO - training batch 401, loss: 0.616, 12832/28000 datapoints
2025-03-06 20:49:46,817 - INFO - training batch 451, loss: 0.283, 14432/28000 datapoints
2025-03-06 20:49:46,941 - INFO - training batch 501, loss: 0.181, 16032/28000 datapoints
2025-03-06 20:49:47,064 - INFO - training batch 551, loss: 0.305, 17632/28000 datapoints
2025-03-06 20:49:47,197 - INFO - training batch 601, loss: 0.487, 19232/28000 datapoints
2025-03-06 20:49:47,324 - INFO - training batch 651, loss: 0.055, 20832/28000 datapoints
2025-03-06 20:49:47,447 - INFO - training batch 701, loss: 0.300, 22432/28000 datapoints
2025-03-06 20:49:47,570 - INFO - training batch 751, loss: 0.269, 24032/28000 datapoints
2025-03-06 20:49:47,695 - INFO - training batch 801, loss: 0.157, 25632/28000 datapoints
2025-03-06 20:49:47,820 - INFO - training batch 851, loss: 0.538, 27232/28000 datapoints
2025-03-06 20:49:47,885 - INFO - validation batch 1, loss: 0.123, 32/6976 datapoints
2025-03-06 20:49:47,933 - INFO - validation batch 51, loss: 1.143, 1632/6976 datapoints
2025-03-06 20:49:47,978 - INFO - validation batch 101, loss: 0.286, 3232/6976 datapoints
2025-03-06 20:49:48,021 - INFO - validation batch 151, loss: 0.392, 4832/6976 datapoints
2025-03-06 20:49:48,064 - INFO - validation batch 201, loss: 0.392, 6432/6976 datapoints
2025-03-06 20:49:48,079 - INFO - Epoch 298/800 done.
2025-03-06 20:49:48,080 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:49:48,080 - INFO - Beginning epoch 299/800
2025-03-06 20:49:48,084 - INFO - training batch 1, loss: 0.346, 32/28000 datapoints
2025-03-06 20:49:48,207 - INFO - training batch 51, loss: 0.144, 1632/28000 datapoints
2025-03-06 20:49:48,334 - INFO - training batch 101, loss: 0.186, 3232/28000 datapoints
2025-03-06 20:49:48,456 - INFO - training batch 151, loss: 0.541, 4832/28000 datapoints
2025-03-06 20:49:48,580 - INFO - training batch 201, loss: 0.148, 6432/28000 datapoints
2025-03-06 20:49:48,708 - INFO - training batch 251, loss: 0.363, 8032/28000 datapoints
2025-03-06 20:49:48,827 - INFO - training batch 301, loss: 0.648, 9632/28000 datapoints
2025-03-06 20:49:48,948 - INFO - training batch 351, loss: 0.309, 11232/28000 datapoints
2025-03-06 20:49:49,069 - INFO - training batch 401, loss: 0.614, 12832/28000 datapoints
2025-03-06 20:49:49,193 - INFO - training batch 451, loss: 0.283, 14432/28000 datapoints
2025-03-06 20:49:49,334 - INFO - training batch 501, loss: 0.181, 16032/28000 datapoints
2025-03-06 20:49:49,472 - INFO - training batch 551, loss: 0.304, 17632/28000 datapoints
2025-03-06 20:49:49,592 - INFO - training batch 601, loss: 0.484, 19232/28000 datapoints
2025-03-06 20:49:49,716 - INFO - training batch 651, loss: 0.054, 20832/28000 datapoints
2025-03-06 20:49:49,836 - INFO - training batch 701, loss: 0.299, 22432/28000 datapoints
2025-03-06 20:49:49,956 - INFO - training batch 751, loss: 0.269, 24032/28000 datapoints
2025-03-06 20:49:50,076 - INFO - training batch 801, loss: 0.156, 25632/28000 datapoints
2025-03-06 20:49:50,195 - INFO - training batch 851, loss: 0.536, 27232/28000 datapoints
2025-03-06 20:49:50,257 - INFO - validation batch 1, loss: 0.123, 32/6976 datapoints
2025-03-06 20:49:50,301 - INFO - validation batch 51, loss: 1.143, 1632/6976 datapoints
2025-03-06 20:49:50,349 - INFO - validation batch 101, loss: 0.287, 3232/6976 datapoints
2025-03-06 20:49:50,394 - INFO - validation batch 151, loss: 0.392, 4832/6976 datapoints
2025-03-06 20:49:50,437 - INFO - validation batch 201, loss: 0.392, 6432/6976 datapoints
2025-03-06 20:49:50,452 - INFO - Epoch 299/800 done.
2025-03-06 20:49:50,452 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:49:50,453 - INFO - Beginning epoch 300/800
2025-03-06 20:49:50,456 - INFO - training batch 1, loss: 0.345, 32/28000 datapoints
2025-03-06 20:49:50,578 - INFO - training batch 51, loss: 0.143, 1632/28000 datapoints
2025-03-06 20:49:50,700 - INFO - training batch 101, loss: 0.185, 3232/28000 datapoints
2025-03-06 20:49:50,843 - INFO - training batch 151, loss: 0.537, 4832/28000 datapoints
2025-03-06 20:49:50,968 - INFO - training batch 201, loss: 0.148, 6432/28000 datapoints
2025-03-06 20:49:51,088 - INFO - training batch 251, loss: 0.363, 8032/28000 datapoints
2025-03-06 20:49:51,213 - INFO - training batch 301, loss: 0.647, 9632/28000 datapoints
2025-03-06 20:49:51,335 - INFO - training batch 351, loss: 0.308, 11232/28000 datapoints
2025-03-06 20:49:51,455 - INFO - training batch 401, loss: 0.612, 12832/28000 datapoints
2025-03-06 20:49:51,575 - INFO - training batch 451, loss: 0.282, 14432/28000 datapoints
2025-03-06 20:49:51,696 - INFO - training batch 501, loss: 0.180, 16032/28000 datapoints
2025-03-06 20:49:51,817 - INFO - training batch 551, loss: 0.302, 17632/28000 datapoints
2025-03-06 20:49:51,939 - INFO - training batch 601, loss: 0.482, 19232/28000 datapoints
2025-03-06 20:49:52,059 - INFO - training batch 651, loss: 0.054, 20832/28000 datapoints
2025-03-06 20:49:52,178 - INFO - training batch 701, loss: 0.298, 22432/28000 datapoints
2025-03-06 20:49:52,298 - INFO - training batch 751, loss: 0.268, 24032/28000 datapoints
2025-03-06 20:49:52,418 - INFO - training batch 801, loss: 0.155, 25632/28000 datapoints
2025-03-06 20:49:52,537 - INFO - training batch 851, loss: 0.534, 27232/28000 datapoints
2025-03-06 20:49:52,596 - INFO - validation batch 1, loss: 0.123, 32/6976 datapoints
2025-03-06 20:49:52,642 - INFO - validation batch 51, loss: 1.142, 1632/6976 datapoints
2025-03-06 20:49:52,686 - INFO - validation batch 101, loss: 0.288, 3232/6976 datapoints
2025-03-06 20:49:52,729 - INFO - validation batch 151, loss: 0.392, 4832/6976 datapoints
2025-03-06 20:49:52,774 - INFO - validation batch 201, loss: 0.393, 6432/6976 datapoints
2025-03-06 20:49:52,789 - INFO - Epoch 300/800 done.
2025-03-06 20:49:52,789 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:49:52,790 - INFO - Beginning epoch 301/800
2025-03-06 20:49:52,793 - INFO - training batch 1, loss: 0.345, 32/28000 datapoints
2025-03-06 20:49:52,914 - INFO - training batch 51, loss: 0.142, 1632/28000 datapoints
2025-03-06 20:49:53,034 - INFO - training batch 101, loss: 0.183, 3232/28000 datapoints
2025-03-06 20:49:53,158 - INFO - training batch 151, loss: 0.533, 4832/28000 datapoints
2025-03-06 20:49:53,281 - INFO - training batch 201, loss: 0.147, 6432/28000 datapoints
2025-03-06 20:49:53,401 - INFO - training batch 251, loss: 0.363, 8032/28000 datapoints
2025-03-06 20:49:53,522 - INFO - training batch 301, loss: 0.647, 9632/28000 datapoints
2025-03-06 20:49:53,643 - INFO - training batch 351, loss: 0.306, 11232/28000 datapoints
2025-03-06 20:49:53,765 - INFO - training batch 401, loss: 0.611, 12832/28000 datapoints
2025-03-06 20:49:53,886 - INFO - training batch 451, loss: 0.282, 14432/28000 datapoints
2025-03-06 20:49:54,007 - INFO - training batch 501, loss: 0.179, 16032/28000 datapoints
2025-03-06 20:49:54,129 - INFO - training batch 551, loss: 0.301, 17632/28000 datapoints
2025-03-06 20:49:54,248 - INFO - training batch 601, loss: 0.480, 19232/28000 datapoints
2025-03-06 20:49:54,372 - INFO - training batch 651, loss: 0.054, 20832/28000 datapoints
2025-03-06 20:49:54,490 - INFO - training batch 701, loss: 0.297, 22432/28000 datapoints
2025-03-06 20:49:54,609 - INFO - training batch 751, loss: 0.267, 24032/28000 datapoints
2025-03-06 20:49:54,730 - INFO - training batch 801, loss: 0.154, 25632/28000 datapoints
2025-03-06 20:49:54,850 - INFO - training batch 851, loss: 0.532, 27232/28000 datapoints
2025-03-06 20:49:54,913 - INFO - validation batch 1, loss: 0.122, 32/6976 datapoints
2025-03-06 20:49:54,957 - INFO - validation batch 51, loss: 1.142, 1632/6976 datapoints
2025-03-06 20:49:55,001 - INFO - validation batch 101, loss: 0.289, 3232/6976 datapoints
2025-03-06 20:49:55,044 - INFO - validation batch 151, loss: 0.392, 4832/6976 datapoints
2025-03-06 20:49:55,088 - INFO - validation batch 201, loss: 0.394, 6432/6976 datapoints
2025-03-06 20:49:55,103 - INFO - Epoch 301/800 done.
2025-03-06 20:49:55,103 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:49:55,104 - INFO - Beginning epoch 302/800
2025-03-06 20:49:55,108 - INFO - training batch 1, loss: 0.344, 32/28000 datapoints
2025-03-06 20:49:55,234 - INFO - training batch 51, loss: 0.141, 1632/28000 datapoints
2025-03-06 20:49:55,358 - INFO - training batch 101, loss: 0.183, 3232/28000 datapoints
2025-03-06 20:49:55,479 - INFO - training batch 151, loss: 0.529, 4832/28000 datapoints
2025-03-06 20:49:55,601 - INFO - training batch 201, loss: 0.146, 6432/28000 datapoints
2025-03-06 20:49:55,725 - INFO - training batch 251, loss: 0.362, 8032/28000 datapoints
2025-03-06 20:49:55,846 - INFO - training batch 301, loss: 0.644, 9632/28000 datapoints
2025-03-06 20:49:55,966 - INFO - training batch 351, loss: 0.305, 11232/28000 datapoints
2025-03-06 20:49:56,085 - INFO - training batch 401, loss: 0.609, 12832/28000 datapoints
2025-03-06 20:49:56,203 - INFO - training batch 451, loss: 0.282, 14432/28000 datapoints
2025-03-06 20:49:56,324 - INFO - training batch 501, loss: 0.179, 16032/28000 datapoints
2025-03-06 20:49:56,444 - INFO - training batch 551, loss: 0.299, 17632/28000 datapoints
2025-03-06 20:49:56,567 - INFO - training batch 601, loss: 0.474, 19232/28000 datapoints
2025-03-06 20:49:56,691 - INFO - training batch 651, loss: 0.053, 20832/28000 datapoints
2025-03-06 20:49:56,812 - INFO - training batch 701, loss: 0.296, 22432/28000 datapoints
2025-03-06 20:49:56,931 - INFO - training batch 751, loss: 0.266, 24032/28000 datapoints
2025-03-06 20:49:57,050 - INFO - training batch 801, loss: 0.153, 25632/28000 datapoints
2025-03-06 20:49:57,173 - INFO - training batch 851, loss: 0.530, 27232/28000 datapoints
2025-03-06 20:49:57,232 - INFO - validation batch 1, loss: 0.122, 32/6976 datapoints
2025-03-06 20:49:57,277 - INFO - validation batch 51, loss: 1.141, 1632/6976 datapoints
2025-03-06 20:49:57,322 - INFO - validation batch 101, loss: 0.289, 3232/6976 datapoints
2025-03-06 20:49:57,365 - INFO - validation batch 151, loss: 0.392, 4832/6976 datapoints
2025-03-06 20:49:57,408 - INFO - validation batch 201, loss: 0.393, 6432/6976 datapoints
2025-03-06 20:49:57,423 - INFO - Epoch 302/800 done.
2025-03-06 20:49:57,423 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:49:57,424 - INFO - Beginning epoch 303/800
2025-03-06 20:49:57,427 - INFO - training batch 1, loss: 0.344, 32/28000 datapoints
2025-03-06 20:49:57,547 - INFO - training batch 51, loss: 0.140, 1632/28000 datapoints
2025-03-06 20:49:57,670 - INFO - training batch 101, loss: 0.182, 3232/28000 datapoints
2025-03-06 20:49:57,793 - INFO - training batch 151, loss: 0.524, 4832/28000 datapoints
2025-03-06 20:49:57,914 - INFO - training batch 201, loss: 0.143, 6432/28000 datapoints
2025-03-06 20:49:58,033 - INFO - training batch 251, loss: 0.359, 8032/28000 datapoints
2025-03-06 20:49:58,153 - INFO - training batch 301, loss: 0.643, 9632/28000 datapoints
2025-03-06 20:49:58,272 - INFO - training batch 351, loss: 0.304, 11232/28000 datapoints
2025-03-06 20:49:58,393 - INFO - training batch 401, loss: 0.608, 12832/28000 datapoints
2025-03-06 20:49:58,514 - INFO - training batch 451, loss: 0.281, 14432/28000 datapoints
2025-03-06 20:49:58,637 - INFO - training batch 501, loss: 0.178, 16032/28000 datapoints
2025-03-06 20:49:58,758 - INFO - training batch 551, loss: 0.298, 17632/28000 datapoints
2025-03-06 20:49:58,879 - INFO - training batch 601, loss: 0.471, 19232/28000 datapoints
2025-03-06 20:49:58,999 - INFO - training batch 651, loss: 0.053, 20832/28000 datapoints
2025-03-06 20:49:59,120 - INFO - training batch 701, loss: 0.295, 22432/28000 datapoints
2025-03-06 20:49:59,243 - INFO - training batch 751, loss: 0.266, 24032/28000 datapoints
2025-03-06 20:49:59,365 - INFO - training batch 801, loss: 0.152, 25632/28000 datapoints
2025-03-06 20:49:59,484 - INFO - training batch 851, loss: 0.528, 27232/28000 datapoints
2025-03-06 20:49:59,543 - INFO - validation batch 1, loss: 0.122, 32/6976 datapoints
2025-03-06 20:49:59,586 - INFO - validation batch 51, loss: 1.141, 1632/6976 datapoints
2025-03-06 20:49:59,629 - INFO - validation batch 101, loss: 0.290, 3232/6976 datapoints
2025-03-06 20:49:59,677 - INFO - validation batch 151, loss: 0.391, 4832/6976 datapoints
2025-03-06 20:49:59,724 - INFO - validation batch 201, loss: 0.393, 6432/6976 datapoints
2025-03-06 20:49:59,739 - INFO - Epoch 303/800 done.
2025-03-06 20:49:59,739 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:49:59,740 - INFO - Beginning epoch 304/800
2025-03-06 20:49:59,743 - INFO - training batch 1, loss: 0.343, 32/28000 datapoints
2025-03-06 20:49:59,865 - INFO - training batch 51, loss: 0.138, 1632/28000 datapoints
2025-03-06 20:49:59,987 - INFO - training batch 101, loss: 0.180, 3232/28000 datapoints
2025-03-06 20:50:00,108 - INFO - training batch 151, loss: 0.521, 4832/28000 datapoints
2025-03-06 20:50:00,227 - INFO - training batch 201, loss: 0.142, 6432/28000 datapoints
2025-03-06 20:50:00,348 - INFO - training batch 251, loss: 0.358, 8032/28000 datapoints
2025-03-06 20:50:00,474 - INFO - training batch 301, loss: 0.642, 9632/28000 datapoints
2025-03-06 20:50:00,594 - INFO - training batch 351, loss: 0.302, 11232/28000 datapoints
2025-03-06 20:50:00,716 - INFO - training batch 401, loss: 0.606, 12832/28000 datapoints
2025-03-06 20:50:00,834 - INFO - training batch 451, loss: 0.281, 14432/28000 datapoints
2025-03-06 20:50:00,980 - INFO - training batch 501, loss: 0.177, 16032/28000 datapoints
2025-03-06 20:50:01,100 - INFO - training batch 551, loss: 0.296, 17632/28000 datapoints
2025-03-06 20:50:01,225 - INFO - training batch 601, loss: 0.467, 19232/28000 datapoints
2025-03-06 20:50:01,346 - INFO - training batch 651, loss: 0.053, 20832/28000 datapoints
2025-03-06 20:50:01,468 - INFO - training batch 701, loss: 0.294, 22432/28000 datapoints
2025-03-06 20:50:01,590 - INFO - training batch 751, loss: 0.266, 24032/28000 datapoints
2025-03-06 20:50:01,713 - INFO - training batch 801, loss: 0.151, 25632/28000 datapoints
2025-03-06 20:50:01,832 - INFO - training batch 851, loss: 0.527, 27232/28000 datapoints
2025-03-06 20:50:01,894 - INFO - validation batch 1, loss: 0.122, 32/6976 datapoints
2025-03-06 20:50:01,938 - INFO - validation batch 51, loss: 1.141, 1632/6976 datapoints
2025-03-06 20:50:01,985 - INFO - validation batch 101, loss: 0.291, 3232/6976 datapoints
2025-03-06 20:50:02,030 - INFO - validation batch 151, loss: 0.391, 4832/6976 datapoints
2025-03-06 20:50:02,075 - INFO - validation batch 201, loss: 0.393, 6432/6976 datapoints
2025-03-06 20:50:02,090 - INFO - Epoch 304/800 done.
2025-03-06 20:50:02,091 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:50:02,091 - INFO - Beginning epoch 305/800
2025-03-06 20:50:02,094 - INFO - training batch 1, loss: 0.342, 32/28000 datapoints
2025-03-06 20:50:02,217 - INFO - training batch 51, loss: 0.137, 1632/28000 datapoints
2025-03-06 20:50:02,339 - INFO - training batch 101, loss: 0.180, 3232/28000 datapoints
2025-03-06 20:50:02,463 - INFO - training batch 151, loss: 0.516, 4832/28000 datapoints
2025-03-06 20:50:02,583 - INFO - training batch 201, loss: 0.141, 6432/28000 datapoints
2025-03-06 20:50:02,706 - INFO - training batch 251, loss: 0.359, 8032/28000 datapoints
2025-03-06 20:50:02,823 - INFO - training batch 301, loss: 0.640, 9632/28000 datapoints
2025-03-06 20:50:02,943 - INFO - training batch 351, loss: 0.300, 11232/28000 datapoints
2025-03-06 20:50:03,063 - INFO - training batch 401, loss: 0.605, 12832/28000 datapoints
2025-03-06 20:50:03,186 - INFO - training batch 451, loss: 0.280, 14432/28000 datapoints
2025-03-06 20:50:03,307 - INFO - training batch 501, loss: 0.176, 16032/28000 datapoints
2025-03-06 20:50:03,428 - INFO - training batch 551, loss: 0.294, 17632/28000 datapoints
2025-03-06 20:50:03,548 - INFO - training batch 601, loss: 0.464, 19232/28000 datapoints
2025-03-06 20:50:03,670 - INFO - training batch 651, loss: 0.052, 20832/28000 datapoints
2025-03-06 20:50:03,789 - INFO - training batch 701, loss: 0.294, 22432/28000 datapoints
2025-03-06 20:50:03,910 - INFO - training batch 751, loss: 0.265, 24032/28000 datapoints
2025-03-06 20:50:04,030 - INFO - training batch 801, loss: 0.150, 25632/28000 datapoints
2025-03-06 20:50:04,149 - INFO - training batch 851, loss: 0.525, 27232/28000 datapoints
2025-03-06 20:50:04,209 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:50:04,253 - INFO - validation batch 51, loss: 1.140, 1632/6976 datapoints
2025-03-06 20:50:04,295 - INFO - validation batch 101, loss: 0.291, 3232/6976 datapoints
2025-03-06 20:50:04,339 - INFO - validation batch 151, loss: 0.391, 4832/6976 datapoints
2025-03-06 20:50:04,384 - INFO - validation batch 201, loss: 0.393, 6432/6976 datapoints
2025-03-06 20:50:04,399 - INFO - Epoch 305/800 done.
2025-03-06 20:50:04,400 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:50:04,400 - INFO - Beginning epoch 306/800
2025-03-06 20:50:04,404 - INFO - training batch 1, loss: 0.341, 32/28000 datapoints
2025-03-06 20:50:04,526 - INFO - training batch 51, loss: 0.136, 1632/28000 datapoints
2025-03-06 20:50:04,647 - INFO - training batch 101, loss: 0.179, 3232/28000 datapoints
2025-03-06 20:50:04,769 - INFO - training batch 151, loss: 0.513, 4832/28000 datapoints
2025-03-06 20:50:04,896 - INFO - training batch 201, loss: 0.140, 6432/28000 datapoints
2025-03-06 20:50:05,016 - INFO - training batch 251, loss: 0.358, 8032/28000 datapoints
2025-03-06 20:50:05,135 - INFO - training batch 301, loss: 0.639, 9632/28000 datapoints
2025-03-06 20:50:05,259 - INFO - training batch 351, loss: 0.299, 11232/28000 datapoints
2025-03-06 20:50:05,379 - INFO - training batch 401, loss: 0.603, 12832/28000 datapoints
2025-03-06 20:50:05,500 - INFO - training batch 451, loss: 0.280, 14432/28000 datapoints
2025-03-06 20:50:05,619 - INFO - training batch 501, loss: 0.175, 16032/28000 datapoints
2025-03-06 20:50:05,744 - INFO - training batch 551, loss: 0.293, 17632/28000 datapoints
2025-03-06 20:50:05,864 - INFO - training batch 601, loss: 0.461, 19232/28000 datapoints
2025-03-06 20:50:05,987 - INFO - training batch 651, loss: 0.052, 20832/28000 datapoints
2025-03-06 20:50:06,109 - INFO - training batch 701, loss: 0.293, 22432/28000 datapoints
2025-03-06 20:50:06,229 - INFO - training batch 751, loss: 0.264, 24032/28000 datapoints
2025-03-06 20:50:06,349 - INFO - training batch 801, loss: 0.149, 25632/28000 datapoints
2025-03-06 20:50:06,470 - INFO - training batch 851, loss: 0.522, 27232/28000 datapoints
2025-03-06 20:50:06,530 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:50:06,576 - INFO - validation batch 51, loss: 1.139, 1632/6976 datapoints
2025-03-06 20:50:06,620 - INFO - validation batch 101, loss: 0.292, 3232/6976 datapoints
2025-03-06 20:50:06,666 - INFO - validation batch 151, loss: 0.391, 4832/6976 datapoints
2025-03-06 20:50:06,717 - INFO - validation batch 201, loss: 0.393, 6432/6976 datapoints
2025-03-06 20:50:06,736 - INFO - Epoch 306/800 done.
2025-03-06 20:50:06,736 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:50:06,737 - INFO - Beginning epoch 307/800
2025-03-06 20:50:06,741 - INFO - training batch 1, loss: 0.340, 32/28000 datapoints
2025-03-06 20:50:06,867 - INFO - training batch 51, loss: 0.135, 1632/28000 datapoints
2025-03-06 20:50:07,041 - INFO - training batch 101, loss: 0.179, 3232/28000 datapoints
2025-03-06 20:50:07,167 - INFO - training batch 151, loss: 0.510, 4832/28000 datapoints
2025-03-06 20:50:07,299 - INFO - training batch 201, loss: 0.140, 6432/28000 datapoints
2025-03-06 20:50:07,424 - INFO - training batch 251, loss: 0.358, 8032/28000 datapoints
2025-03-06 20:50:07,549 - INFO - training batch 301, loss: 0.637, 9632/28000 datapoints
2025-03-06 20:50:07,677 - INFO - training batch 351, loss: 0.297, 11232/28000 datapoints
2025-03-06 20:50:07,800 - INFO - training batch 401, loss: 0.602, 12832/28000 datapoints
2025-03-06 20:50:07,923 - INFO - training batch 451, loss: 0.279, 14432/28000 datapoints
2025-03-06 20:50:08,047 - INFO - training batch 501, loss: 0.175, 16032/28000 datapoints
2025-03-06 20:50:08,173 - INFO - training batch 551, loss: 0.292, 17632/28000 datapoints
2025-03-06 20:50:08,299 - INFO - training batch 601, loss: 0.457, 19232/28000 datapoints
2025-03-06 20:50:08,419 - INFO - training batch 651, loss: 0.051, 20832/28000 datapoints
2025-03-06 20:50:08,544 - INFO - training batch 701, loss: 0.292, 22432/28000 datapoints
2025-03-06 20:50:08,671 - INFO - training batch 751, loss: 0.263, 24032/28000 datapoints
2025-03-06 20:50:08,794 - INFO - training batch 801, loss: 0.148, 25632/28000 datapoints
2025-03-06 20:50:08,919 - INFO - training batch 851, loss: 0.520, 27232/28000 datapoints
2025-03-06 20:50:08,987 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:50:09,043 - INFO - validation batch 51, loss: 1.139, 1632/6976 datapoints
2025-03-06 20:50:09,097 - INFO - validation batch 101, loss: 0.293, 3232/6976 datapoints
2025-03-06 20:50:09,145 - INFO - validation batch 151, loss: 0.390, 4832/6976 datapoints
2025-03-06 20:50:09,196 - INFO - validation batch 201, loss: 0.393, 6432/6976 datapoints
2025-03-06 20:50:09,212 - INFO - Epoch 307/800 done.
2025-03-06 20:50:09,212 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:50:09,213 - INFO - Beginning epoch 308/800
2025-03-06 20:50:09,216 - INFO - training batch 1, loss: 0.339, 32/28000 datapoints
2025-03-06 20:50:09,340 - INFO - training batch 51, loss: 0.133, 1632/28000 datapoints
2025-03-06 20:50:09,466 - INFO - training batch 101, loss: 0.179, 3232/28000 datapoints
2025-03-06 20:50:09,593 - INFO - training batch 151, loss: 0.508, 4832/28000 datapoints
2025-03-06 20:50:09,718 - INFO - training batch 201, loss: 0.139, 6432/28000 datapoints
2025-03-06 20:50:09,840 - INFO - training batch 251, loss: 0.358, 8032/28000 datapoints
2025-03-06 20:50:09,963 - INFO - training batch 301, loss: 0.636, 9632/28000 datapoints
2025-03-06 20:50:10,088 - INFO - training batch 351, loss: 0.296, 11232/28000 datapoints
2025-03-06 20:50:10,210 - INFO - training batch 401, loss: 0.601, 12832/28000 datapoints
2025-03-06 20:50:10,334 - INFO - training batch 451, loss: 0.279, 14432/28000 datapoints
2025-03-06 20:50:10,464 - INFO - training batch 501, loss: 0.174, 16032/28000 datapoints
2025-03-06 20:50:10,588 - INFO - training batch 551, loss: 0.290, 17632/28000 datapoints
2025-03-06 20:50:10,714 - INFO - training batch 601, loss: 0.454, 19232/28000 datapoints
2025-03-06 20:50:10,839 - INFO - training batch 651, loss: 0.051, 20832/28000 datapoints
2025-03-06 20:50:10,971 - INFO - training batch 701, loss: 0.291, 22432/28000 datapoints
2025-03-06 20:50:11,112 - INFO - training batch 751, loss: 0.262, 24032/28000 datapoints
2025-03-06 20:50:11,239 - INFO - training batch 801, loss: 0.147, 25632/28000 datapoints
2025-03-06 20:50:11,365 - INFO - training batch 851, loss: 0.518, 27232/28000 datapoints
2025-03-06 20:50:11,428 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:11,475 - INFO - validation batch 51, loss: 1.138, 1632/6976 datapoints
2025-03-06 20:50:11,523 - INFO - validation batch 101, loss: 0.294, 3232/6976 datapoints
2025-03-06 20:50:11,569 - INFO - validation batch 151, loss: 0.390, 4832/6976 datapoints
2025-03-06 20:50:11,614 - INFO - validation batch 201, loss: 0.393, 6432/6976 datapoints
2025-03-06 20:50:11,629 - INFO - Epoch 308/800 done.
2025-03-06 20:50:11,630 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:50:11,630 - INFO - Beginning epoch 309/800
2025-03-06 20:50:11,636 - INFO - training batch 1, loss: 0.338, 32/28000 datapoints
2025-03-06 20:50:11,758 - INFO - training batch 51, loss: 0.132, 1632/28000 datapoints
2025-03-06 20:50:11,878 - INFO - training batch 101, loss: 0.178, 3232/28000 datapoints
2025-03-06 20:50:12,001 - INFO - training batch 151, loss: 0.504, 4832/28000 datapoints
2025-03-06 20:50:12,121 - INFO - training batch 201, loss: 0.138, 6432/28000 datapoints
2025-03-06 20:50:12,241 - INFO - training batch 251, loss: 0.358, 8032/28000 datapoints
2025-03-06 20:50:12,362 - INFO - training batch 301, loss: 0.634, 9632/28000 datapoints
2025-03-06 20:50:12,483 - INFO - training batch 351, loss: 0.294, 11232/28000 datapoints
2025-03-06 20:50:12,605 - INFO - training batch 401, loss: 0.599, 12832/28000 datapoints
2025-03-06 20:50:12,727 - INFO - training batch 451, loss: 0.279, 14432/28000 datapoints
2025-03-06 20:50:12,847 - INFO - training batch 501, loss: 0.173, 16032/28000 datapoints
2025-03-06 20:50:12,966 - INFO - training batch 551, loss: 0.289, 17632/28000 datapoints
2025-03-06 20:50:13,086 - INFO - training batch 601, loss: 0.450, 19232/28000 datapoints
2025-03-06 20:50:13,206 - INFO - training batch 651, loss: 0.051, 20832/28000 datapoints
2025-03-06 20:50:13,331 - INFO - training batch 701, loss: 0.290, 22432/28000 datapoints
2025-03-06 20:50:13,451 - INFO - training batch 751, loss: 0.261, 24032/28000 datapoints
2025-03-06 20:50:13,571 - INFO - training batch 801, loss: 0.146, 25632/28000 datapoints
2025-03-06 20:50:13,694 - INFO - training batch 851, loss: 0.516, 27232/28000 datapoints
2025-03-06 20:50:13,753 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:13,797 - INFO - validation batch 51, loss: 1.138, 1632/6976 datapoints
2025-03-06 20:50:13,842 - INFO - validation batch 101, loss: 0.294, 3232/6976 datapoints
2025-03-06 20:50:13,884 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-06 20:50:13,928 - INFO - validation batch 201, loss: 0.394, 6432/6976 datapoints
2025-03-06 20:50:13,943 - INFO - Epoch 309/800 done.
2025-03-06 20:50:13,944 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:50:13,944 - INFO - Beginning epoch 310/800
2025-03-06 20:50:13,947 - INFO - training batch 1, loss: 0.338, 32/28000 datapoints
2025-03-06 20:50:14,073 - INFO - training batch 51, loss: 0.131, 1632/28000 datapoints
2025-03-06 20:50:14,193 - INFO - training batch 101, loss: 0.177, 3232/28000 datapoints
2025-03-06 20:50:14,313 - INFO - training batch 151, loss: 0.500, 4832/28000 datapoints
2025-03-06 20:50:14,432 - INFO - training batch 201, loss: 0.137, 6432/28000 datapoints
2025-03-06 20:50:14,555 - INFO - training batch 251, loss: 0.357, 8032/28000 datapoints
2025-03-06 20:50:14,678 - INFO - training batch 301, loss: 0.632, 9632/28000 datapoints
2025-03-06 20:50:14,798 - INFO - training batch 351, loss: 0.292, 11232/28000 datapoints
2025-03-06 20:50:14,925 - INFO - training batch 401, loss: 0.597, 12832/28000 datapoints
2025-03-06 20:50:15,046 - INFO - training batch 451, loss: 0.278, 14432/28000 datapoints
2025-03-06 20:50:15,166 - INFO - training batch 501, loss: 0.173, 16032/28000 datapoints
2025-03-06 20:50:15,291 - INFO - training batch 551, loss: 0.288, 17632/28000 datapoints
2025-03-06 20:50:15,417 - INFO - training batch 601, loss: 0.447, 19232/28000 datapoints
2025-03-06 20:50:15,543 - INFO - training batch 651, loss: 0.050, 20832/28000 datapoints
2025-03-06 20:50:15,667 - INFO - training batch 701, loss: 0.290, 22432/28000 datapoints
2025-03-06 20:50:15,786 - INFO - training batch 751, loss: 0.261, 24032/28000 datapoints
2025-03-06 20:50:15,904 - INFO - training batch 801, loss: 0.145, 25632/28000 datapoints
2025-03-06 20:50:16,023 - INFO - training batch 851, loss: 0.514, 27232/28000 datapoints
2025-03-06 20:50:16,084 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:16,128 - INFO - validation batch 51, loss: 1.137, 1632/6976 datapoints
2025-03-06 20:50:16,171 - INFO - validation batch 101, loss: 0.295, 3232/6976 datapoints
2025-03-06 20:50:16,215 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-06 20:50:16,260 - INFO - validation batch 201, loss: 0.393, 6432/6976 datapoints
2025-03-06 20:50:16,276 - INFO - Epoch 310/800 done.
2025-03-06 20:50:16,276 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:50:16,277 - INFO - Beginning epoch 311/800
2025-03-06 20:50:16,280 - INFO - training batch 1, loss: 0.337, 32/28000 datapoints
2025-03-06 20:50:16,401 - INFO - training batch 51, loss: 0.130, 1632/28000 datapoints
2025-03-06 20:50:16,522 - INFO - training batch 101, loss: 0.176, 3232/28000 datapoints
2025-03-06 20:50:16,651 - INFO - training batch 151, loss: 0.496, 4832/28000 datapoints
2025-03-06 20:50:16,770 - INFO - training batch 201, loss: 0.136, 6432/28000 datapoints
2025-03-06 20:50:16,891 - INFO - training batch 251, loss: 0.356, 8032/28000 datapoints
2025-03-06 20:50:17,010 - INFO - training batch 301, loss: 0.632, 9632/28000 datapoints
2025-03-06 20:50:17,131 - INFO - training batch 351, loss: 0.292, 11232/28000 datapoints
2025-03-06 20:50:17,258 - INFO - training batch 401, loss: 0.596, 12832/28000 datapoints
2025-03-06 20:50:17,378 - INFO - training batch 451, loss: 0.278, 14432/28000 datapoints
2025-03-06 20:50:17,500 - INFO - training batch 501, loss: 0.172, 16032/28000 datapoints
2025-03-06 20:50:17,622 - INFO - training batch 551, loss: 0.287, 17632/28000 datapoints
2025-03-06 20:50:17,746 - INFO - training batch 601, loss: 0.444, 19232/28000 datapoints
2025-03-06 20:50:17,865 - INFO - training batch 651, loss: 0.050, 20832/28000 datapoints
2025-03-06 20:50:17,984 - INFO - training batch 701, loss: 0.289, 22432/28000 datapoints
2025-03-06 20:50:18,110 - INFO - training batch 751, loss: 0.260, 24032/28000 datapoints
2025-03-06 20:50:18,228 - INFO - training batch 801, loss: 0.144, 25632/28000 datapoints
2025-03-06 20:50:18,355 - INFO - training batch 851, loss: 0.512, 27232/28000 datapoints
2025-03-06 20:50:18,414 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:18,459 - INFO - validation batch 51, loss: 1.136, 1632/6976 datapoints
2025-03-06 20:50:18,503 - INFO - validation batch 101, loss: 0.296, 3232/6976 datapoints
2025-03-06 20:50:18,546 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-06 20:50:18,590 - INFO - validation batch 201, loss: 0.394, 6432/6976 datapoints
2025-03-06 20:50:18,607 - INFO - Epoch 311/800 done.
2025-03-06 20:50:18,607 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:50:18,608 - INFO - Beginning epoch 312/800
2025-03-06 20:50:18,611 - INFO - training batch 1, loss: 0.336, 32/28000 datapoints
2025-03-06 20:50:18,737 - INFO - training batch 51, loss: 0.129, 1632/28000 datapoints
2025-03-06 20:50:18,857 - INFO - training batch 101, loss: 0.175, 3232/28000 datapoints
2025-03-06 20:50:18,977 - INFO - training batch 151, loss: 0.491, 4832/28000 datapoints
2025-03-06 20:50:19,101 - INFO - training batch 201, loss: 0.135, 6432/28000 datapoints
2025-03-06 20:50:19,220 - INFO - training batch 251, loss: 0.356, 8032/28000 datapoints
2025-03-06 20:50:19,344 - INFO - training batch 301, loss: 0.630, 9632/28000 datapoints
2025-03-06 20:50:19,464 - INFO - training batch 351, loss: 0.290, 11232/28000 datapoints
2025-03-06 20:50:19,584 - INFO - training batch 401, loss: 0.593, 12832/28000 datapoints
2025-03-06 20:50:19,709 - INFO - training batch 451, loss: 0.277, 14432/28000 datapoints
2025-03-06 20:50:19,832 - INFO - training batch 501, loss: 0.172, 16032/28000 datapoints
2025-03-06 20:50:19,952 - INFO - training batch 551, loss: 0.285, 17632/28000 datapoints
2025-03-06 20:50:20,073 - INFO - training batch 601, loss: 0.441, 19232/28000 datapoints
2025-03-06 20:50:20,194 - INFO - training batch 651, loss: 0.050, 20832/28000 datapoints
2025-03-06 20:50:20,314 - INFO - training batch 701, loss: 0.288, 22432/28000 datapoints
2025-03-06 20:50:20,440 - INFO - training batch 751, loss: 0.259, 24032/28000 datapoints
2025-03-06 20:50:20,561 - INFO - training batch 801, loss: 0.144, 25632/28000 datapoints
2025-03-06 20:50:20,684 - INFO - training batch 851, loss: 0.511, 27232/28000 datapoints
2025-03-06 20:50:20,744 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:20,788 - INFO - validation batch 51, loss: 1.136, 1632/6976 datapoints
2025-03-06 20:50:20,831 - INFO - validation batch 101, loss: 0.297, 3232/6976 datapoints
2025-03-06 20:50:20,876 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-06 20:50:20,919 - INFO - validation batch 201, loss: 0.395, 6432/6976 datapoints
2025-03-06 20:50:20,934 - INFO - Epoch 312/800 done.
2025-03-06 20:50:20,934 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:50:20,935 - INFO - Beginning epoch 313/800
2025-03-06 20:50:20,938 - INFO - training batch 1, loss: 0.335, 32/28000 datapoints
2025-03-06 20:50:21,064 - INFO - training batch 51, loss: 0.128, 1632/28000 datapoints
2025-03-06 20:50:21,206 - INFO - training batch 101, loss: 0.174, 3232/28000 datapoints
2025-03-06 20:50:21,331 - INFO - training batch 151, loss: 0.488, 4832/28000 datapoints
2025-03-06 20:50:21,451 - INFO - training batch 201, loss: 0.135, 6432/28000 datapoints
2025-03-06 20:50:21,575 - INFO - training batch 251, loss: 0.355, 8032/28000 datapoints
2025-03-06 20:50:21,701 - INFO - training batch 301, loss: 0.629, 9632/28000 datapoints
2025-03-06 20:50:21,821 - INFO - training batch 351, loss: 0.289, 11232/28000 datapoints
2025-03-06 20:50:21,943 - INFO - training batch 401, loss: 0.592, 12832/28000 datapoints
2025-03-06 20:50:22,063 - INFO - training batch 451, loss: 0.277, 14432/28000 datapoints
2025-03-06 20:50:22,183 - INFO - training batch 501, loss: 0.171, 16032/28000 datapoints
2025-03-06 20:50:22,304 - INFO - training batch 551, loss: 0.284, 17632/28000 datapoints
2025-03-06 20:50:22,424 - INFO - training batch 601, loss: 0.436, 19232/28000 datapoints
2025-03-06 20:50:22,547 - INFO - training batch 651, loss: 0.049, 20832/28000 datapoints
2025-03-06 20:50:22,671 - INFO - training batch 701, loss: 0.287, 22432/28000 datapoints
2025-03-06 20:50:22,789 - INFO - training batch 751, loss: 0.258, 24032/28000 datapoints
2025-03-06 20:50:22,910 - INFO - training batch 801, loss: 0.143, 25632/28000 datapoints
2025-03-06 20:50:23,028 - INFO - training batch 851, loss: 0.508, 27232/28000 datapoints
2025-03-06 20:50:23,087 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:23,129 - INFO - validation batch 51, loss: 1.135, 1632/6976 datapoints
2025-03-06 20:50:23,175 - INFO - validation batch 101, loss: 0.297, 3232/6976 datapoints
2025-03-06 20:50:23,219 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:50:23,266 - INFO - validation batch 201, loss: 0.395, 6432/6976 datapoints
2025-03-06 20:50:23,281 - INFO - Epoch 313/800 done.
2025-03-06 20:50:23,281 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:50:23,281 - INFO - Beginning epoch 314/800
2025-03-06 20:50:23,285 - INFO - training batch 1, loss: 0.334, 32/28000 datapoints
2025-03-06 20:50:23,406 - INFO - training batch 51, loss: 0.127, 1632/28000 datapoints
2025-03-06 20:50:23,529 - INFO - training batch 101, loss: 0.173, 3232/28000 datapoints
2025-03-06 20:50:23,655 - INFO - training batch 151, loss: 0.484, 4832/28000 datapoints
2025-03-06 20:50:23,775 - INFO - training batch 201, loss: 0.134, 6432/28000 datapoints
2025-03-06 20:50:23,894 - INFO - training batch 251, loss: 0.354, 8032/28000 datapoints
2025-03-06 20:50:24,013 - INFO - training batch 301, loss: 0.627, 9632/28000 datapoints
2025-03-06 20:50:24,136 - INFO - training batch 351, loss: 0.288, 11232/28000 datapoints
2025-03-06 20:50:24,258 - INFO - training batch 401, loss: 0.591, 12832/28000 datapoints
2025-03-06 20:50:24,377 - INFO - training batch 451, loss: 0.276, 14432/28000 datapoints
2025-03-06 20:50:24,500 - INFO - training batch 501, loss: 0.171, 16032/28000 datapoints
2025-03-06 20:50:24,624 - INFO - training batch 551, loss: 0.283, 17632/28000 datapoints
2025-03-06 20:50:24,748 - INFO - training batch 601, loss: 0.434, 19232/28000 datapoints
2025-03-06 20:50:24,868 - INFO - training batch 651, loss: 0.049, 20832/28000 datapoints
2025-03-06 20:50:24,992 - INFO - training batch 701, loss: 0.286, 22432/28000 datapoints
2025-03-06 20:50:25,112 - INFO - training batch 751, loss: 0.258, 24032/28000 datapoints
2025-03-06 20:50:25,233 - INFO - training batch 801, loss: 0.142, 25632/28000 datapoints
2025-03-06 20:50:25,358 - INFO - training batch 851, loss: 0.506, 27232/28000 datapoints
2025-03-06 20:50:25,418 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:25,464 - INFO - validation batch 51, loss: 1.135, 1632/6976 datapoints
2025-03-06 20:50:25,509 - INFO - validation batch 101, loss: 0.298, 3232/6976 datapoints
2025-03-06 20:50:25,553 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:50:25,598 - INFO - validation batch 201, loss: 0.396, 6432/6976 datapoints
2025-03-06 20:50:25,614 - INFO - Epoch 314/800 done.
2025-03-06 20:50:25,614 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:50:25,614 - INFO - Beginning epoch 315/800
2025-03-06 20:50:25,618 - INFO - training batch 1, loss: 0.334, 32/28000 datapoints
2025-03-06 20:50:25,746 - INFO - training batch 51, loss: 0.126, 1632/28000 datapoints
2025-03-06 20:50:25,867 - INFO - training batch 101, loss: 0.172, 3232/28000 datapoints
2025-03-06 20:50:25,988 - INFO - training batch 151, loss: 0.478, 4832/28000 datapoints
2025-03-06 20:50:26,107 - INFO - training batch 201, loss: 0.134, 6432/28000 datapoints
2025-03-06 20:50:26,228 - INFO - training batch 251, loss: 0.353, 8032/28000 datapoints
2025-03-06 20:50:26,348 - INFO - training batch 301, loss: 0.625, 9632/28000 datapoints
2025-03-06 20:50:26,468 - INFO - training batch 351, loss: 0.287, 11232/28000 datapoints
2025-03-06 20:50:26,590 - INFO - training batch 401, loss: 0.589, 12832/28000 datapoints
2025-03-06 20:50:26,714 - INFO - training batch 451, loss: 0.276, 14432/28000 datapoints
2025-03-06 20:50:26,834 - INFO - training batch 501, loss: 0.170, 16032/28000 datapoints
2025-03-06 20:50:26,962 - INFO - training batch 551, loss: 0.282, 17632/28000 datapoints
2025-03-06 20:50:27,087 - INFO - training batch 601, loss: 0.429, 19232/28000 datapoints
2025-03-06 20:50:27,211 - INFO - training batch 651, loss: 0.048, 20832/28000 datapoints
2025-03-06 20:50:27,338 - INFO - training batch 701, loss: 0.286, 22432/28000 datapoints
2025-03-06 20:50:27,467 - INFO - training batch 751, loss: 0.257, 24032/28000 datapoints
2025-03-06 20:50:27,593 - INFO - training batch 801, loss: 0.141, 25632/28000 datapoints
2025-03-06 20:50:27,722 - INFO - training batch 851, loss: 0.503, 27232/28000 datapoints
2025-03-06 20:50:27,786 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:27,833 - INFO - validation batch 51, loss: 1.134, 1632/6976 datapoints
2025-03-06 20:50:27,878 - INFO - validation batch 101, loss: 0.298, 3232/6976 datapoints
2025-03-06 20:50:27,922 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:50:27,966 - INFO - validation batch 201, loss: 0.394, 6432/6976 datapoints
2025-03-06 20:50:27,980 - INFO - Epoch 315/800 done.
2025-03-06 20:50:27,981 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:50:27,981 - INFO - Beginning epoch 316/800
2025-03-06 20:50:27,985 - INFO - training batch 1, loss: 0.334, 32/28000 datapoints
2025-03-06 20:50:28,108 - INFO - training batch 51, loss: 0.126, 1632/28000 datapoints
2025-03-06 20:50:28,231 - INFO - training batch 101, loss: 0.170, 3232/28000 datapoints
2025-03-06 20:50:28,351 - INFO - training batch 151, loss: 0.473, 4832/28000 datapoints
2025-03-06 20:50:28,473 - INFO - training batch 201, loss: 0.133, 6432/28000 datapoints
2025-03-06 20:50:28,593 - INFO - training batch 251, loss: 0.352, 8032/28000 datapoints
2025-03-06 20:50:28,717 - INFO - training batch 301, loss: 0.624, 9632/28000 datapoints
2025-03-06 20:50:28,836 - INFO - training batch 351, loss: 0.286, 11232/28000 datapoints
2025-03-06 20:50:28,956 - INFO - training batch 401, loss: 0.587, 12832/28000 datapoints
2025-03-06 20:50:29,077 - INFO - training batch 451, loss: 0.276, 14432/28000 datapoints
2025-03-06 20:50:29,198 - INFO - training batch 501, loss: 0.170, 16032/28000 datapoints
2025-03-06 20:50:29,322 - INFO - training batch 551, loss: 0.280, 17632/28000 datapoints
2025-03-06 20:50:29,443 - INFO - training batch 601, loss: 0.427, 19232/28000 datapoints
2025-03-06 20:50:29,564 - INFO - training batch 651, loss: 0.048, 20832/28000 datapoints
2025-03-06 20:50:29,684 - INFO - training batch 701, loss: 0.285, 22432/28000 datapoints
2025-03-06 20:50:29,805 - INFO - training batch 751, loss: 0.256, 24032/28000 datapoints
2025-03-06 20:50:29,924 - INFO - training batch 801, loss: 0.140, 25632/28000 datapoints
2025-03-06 20:50:30,044 - INFO - training batch 851, loss: 0.501, 27232/28000 datapoints
2025-03-06 20:50:30,104 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:30,147 - INFO - validation batch 51, loss: 1.133, 1632/6976 datapoints
2025-03-06 20:50:30,191 - INFO - validation batch 101, loss: 0.299, 3232/6976 datapoints
2025-03-06 20:50:30,237 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:50:30,282 - INFO - validation batch 201, loss: 0.396, 6432/6976 datapoints
2025-03-06 20:50:30,298 - INFO - Epoch 316/800 done.
2025-03-06 20:50:30,298 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:50:30,299 - INFO - Beginning epoch 317/800
2025-03-06 20:50:30,302 - INFO - training batch 1, loss: 0.333, 32/28000 datapoints
2025-03-06 20:50:30,425 - INFO - training batch 51, loss: 0.125, 1632/28000 datapoints
2025-03-06 20:50:30,550 - INFO - training batch 101, loss: 0.169, 3232/28000 datapoints
2025-03-06 20:50:30,675 - INFO - training batch 151, loss: 0.469, 4832/28000 datapoints
2025-03-06 20:50:30,806 - INFO - training batch 201, loss: 0.132, 6432/28000 datapoints
2025-03-06 20:50:30,926 - INFO - training batch 251, loss: 0.351, 8032/28000 datapoints
2025-03-06 20:50:31,045 - INFO - training batch 301, loss: 0.622, 9632/28000 datapoints
2025-03-06 20:50:31,176 - INFO - training batch 351, loss: 0.285, 11232/28000 datapoints
2025-03-06 20:50:31,315 - INFO - training batch 401, loss: 0.586, 12832/28000 datapoints
2025-03-06 20:50:31,436 - INFO - training batch 451, loss: 0.275, 14432/28000 datapoints
2025-03-06 20:50:31,559 - INFO - training batch 501, loss: 0.169, 16032/28000 datapoints
2025-03-06 20:50:31,688 - INFO - training batch 551, loss: 0.279, 17632/28000 datapoints
2025-03-06 20:50:31,810 - INFO - training batch 601, loss: 0.424, 19232/28000 datapoints
2025-03-06 20:50:31,933 - INFO - training batch 651, loss: 0.048, 20832/28000 datapoints
2025-03-06 20:50:32,053 - INFO - training batch 701, loss: 0.284, 22432/28000 datapoints
2025-03-06 20:50:32,173 - INFO - training batch 751, loss: 0.256, 24032/28000 datapoints
2025-03-06 20:50:32,294 - INFO - training batch 801, loss: 0.140, 25632/28000 datapoints
2025-03-06 20:50:32,414 - INFO - training batch 851, loss: 0.499, 27232/28000 datapoints
2025-03-06 20:50:32,473 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:32,520 - INFO - validation batch 51, loss: 1.132, 1632/6976 datapoints
2025-03-06 20:50:32,566 - INFO - validation batch 101, loss: 0.300, 3232/6976 datapoints
2025-03-06 20:50:32,610 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:50:32,658 - INFO - validation batch 201, loss: 0.396, 6432/6976 datapoints
2025-03-06 20:50:32,674 - INFO - Epoch 317/800 done.
2025-03-06 20:50:32,674 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:50:32,675 - INFO - Beginning epoch 318/800
2025-03-06 20:50:32,678 - INFO - training batch 1, loss: 0.332, 32/28000 datapoints
2025-03-06 20:50:32,804 - INFO - training batch 51, loss: 0.124, 1632/28000 datapoints
2025-03-06 20:50:32,924 - INFO - training batch 101, loss: 0.167, 3232/28000 datapoints
2025-03-06 20:50:33,044 - INFO - training batch 151, loss: 0.465, 4832/28000 datapoints
2025-03-06 20:50:33,163 - INFO - training batch 201, loss: 0.131, 6432/28000 datapoints
2025-03-06 20:50:33,285 - INFO - training batch 251, loss: 0.351, 8032/28000 datapoints
2025-03-06 20:50:33,409 - INFO - training batch 301, loss: 0.620, 9632/28000 datapoints
2025-03-06 20:50:33,530 - INFO - training batch 351, loss: 0.284, 11232/28000 datapoints
2025-03-06 20:50:33,653 - INFO - training batch 401, loss: 0.584, 12832/28000 datapoints
2025-03-06 20:50:33,774 - INFO - training batch 451, loss: 0.274, 14432/28000 datapoints
2025-03-06 20:50:33,895 - INFO - training batch 501, loss: 0.168, 16032/28000 datapoints
2025-03-06 20:50:34,015 - INFO - training batch 551, loss: 0.277, 17632/28000 datapoints
2025-03-06 20:50:34,136 - INFO - training batch 601, loss: 0.420, 19232/28000 datapoints
2025-03-06 20:50:34,255 - INFO - training batch 651, loss: 0.047, 20832/28000 datapoints
2025-03-06 20:50:34,375 - INFO - training batch 701, loss: 0.283, 22432/28000 datapoints
2025-03-06 20:50:34,495 - INFO - training batch 751, loss: 0.256, 24032/28000 datapoints
2025-03-06 20:50:34,614 - INFO - training batch 801, loss: 0.139, 25632/28000 datapoints
2025-03-06 20:50:34,737 - INFO - training batch 851, loss: 0.497, 27232/28000 datapoints
2025-03-06 20:50:34,797 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:34,841 - INFO - validation batch 51, loss: 1.132, 1632/6976 datapoints
2025-03-06 20:50:34,890 - INFO - validation batch 101, loss: 0.300, 3232/6976 datapoints
2025-03-06 20:50:34,936 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:50:34,980 - INFO - validation batch 201, loss: 0.395, 6432/6976 datapoints
2025-03-06 20:50:34,995 - INFO - Epoch 318/800 done.
2025-03-06 20:50:34,995 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:50:34,996 - INFO - Beginning epoch 319/800
2025-03-06 20:50:34,999 - INFO - training batch 1, loss: 0.332, 32/28000 datapoints
2025-03-06 20:50:35,120 - INFO - training batch 51, loss: 0.123, 1632/28000 datapoints
2025-03-06 20:50:35,239 - INFO - training batch 101, loss: 0.167, 3232/28000 datapoints
2025-03-06 20:50:35,364 - INFO - training batch 151, loss: 0.462, 4832/28000 datapoints
2025-03-06 20:50:35,486 - INFO - training batch 201, loss: 0.131, 6432/28000 datapoints
2025-03-06 20:50:35,606 - INFO - training batch 251, loss: 0.351, 8032/28000 datapoints
2025-03-06 20:50:35,729 - INFO - training batch 301, loss: 0.620, 9632/28000 datapoints
2025-03-06 20:50:35,849 - INFO - training batch 351, loss: 0.284, 11232/28000 datapoints
2025-03-06 20:50:35,968 - INFO - training batch 401, loss: 0.582, 12832/28000 datapoints
2025-03-06 20:50:36,087 - INFO - training batch 451, loss: 0.274, 14432/28000 datapoints
2025-03-06 20:50:36,205 - INFO - training batch 501, loss: 0.168, 16032/28000 datapoints
2025-03-06 20:50:36,339 - INFO - training batch 551, loss: 0.276, 17632/28000 datapoints
2025-03-06 20:50:36,464 - INFO - training batch 601, loss: 0.417, 19232/28000 datapoints
2025-03-06 20:50:36,583 - INFO - training batch 651, loss: 0.047, 20832/28000 datapoints
2025-03-06 20:50:36,715 - INFO - training batch 701, loss: 0.282, 22432/28000 datapoints
2025-03-06 20:50:36,835 - INFO - training batch 751, loss: 0.255, 24032/28000 datapoints
2025-03-06 20:50:36,964 - INFO - training batch 801, loss: 0.138, 25632/28000 datapoints
2025-03-06 20:50:37,091 - INFO - training batch 851, loss: 0.496, 27232/28000 datapoints
2025-03-06 20:50:37,151 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:37,195 - INFO - validation batch 51, loss: 1.132, 1632/6976 datapoints
2025-03-06 20:50:37,238 - INFO - validation batch 101, loss: 0.301, 3232/6976 datapoints
2025-03-06 20:50:37,281 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:50:37,331 - INFO - validation batch 201, loss: 0.396, 6432/6976 datapoints
2025-03-06 20:50:37,347 - INFO - Epoch 319/800 done.
2025-03-06 20:50:37,347 - INFO - Final validation performance:
Loss: 0.467, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:50:37,348 - INFO - Beginning epoch 320/800
2025-03-06 20:50:37,352 - INFO - training batch 1, loss: 0.331, 32/28000 datapoints
2025-03-06 20:50:37,475 - INFO - training batch 51, loss: 0.122, 1632/28000 datapoints
2025-03-06 20:50:37,596 - INFO - training batch 101, loss: 0.166, 3232/28000 datapoints
2025-03-06 20:50:37,728 - INFO - training batch 151, loss: 0.457, 4832/28000 datapoints
2025-03-06 20:50:37,853 - INFO - training batch 201, loss: 0.130, 6432/28000 datapoints
2025-03-06 20:50:37,973 - INFO - training batch 251, loss: 0.350, 8032/28000 datapoints
2025-03-06 20:50:38,094 - INFO - training batch 301, loss: 0.617, 9632/28000 datapoints
2025-03-06 20:50:38,212 - INFO - training batch 351, loss: 0.283, 11232/28000 datapoints
2025-03-06 20:50:38,331 - INFO - training batch 401, loss: 0.580, 12832/28000 datapoints
2025-03-06 20:50:38,452 - INFO - training batch 451, loss: 0.273, 14432/28000 datapoints
2025-03-06 20:50:38,571 - INFO - training batch 501, loss: 0.167, 16032/28000 datapoints
2025-03-06 20:50:38,695 - INFO - training batch 551, loss: 0.275, 17632/28000 datapoints
2025-03-06 20:50:38,816 - INFO - training batch 601, loss: 0.413, 19232/28000 datapoints
2025-03-06 20:50:38,936 - INFO - training batch 651, loss: 0.046, 20832/28000 datapoints
2025-03-06 20:50:39,057 - INFO - training batch 701, loss: 0.281, 22432/28000 datapoints
2025-03-06 20:50:39,179 - INFO - training batch 751, loss: 0.254, 24032/28000 datapoints
2025-03-06 20:50:39,299 - INFO - training batch 801, loss: 0.137, 25632/28000 datapoints
2025-03-06 20:50:39,424 - INFO - training batch 851, loss: 0.494, 27232/28000 datapoints
2025-03-06 20:50:39,484 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:39,529 - INFO - validation batch 51, loss: 1.131, 1632/6976 datapoints
2025-03-06 20:50:39,573 - INFO - validation batch 101, loss: 0.302, 3232/6976 datapoints
2025-03-06 20:50:39,617 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:50:39,664 - INFO - validation batch 201, loss: 0.396, 6432/6976 datapoints
2025-03-06 20:50:39,679 - INFO - Epoch 320/800 done.
2025-03-06 20:50:39,679 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:50:39,680 - INFO - Beginning epoch 321/800
2025-03-06 20:50:39,683 - INFO - training batch 1, loss: 0.330, 32/28000 datapoints
2025-03-06 20:50:39,805 - INFO - training batch 51, loss: 0.121, 1632/28000 datapoints
2025-03-06 20:50:39,928 - INFO - training batch 101, loss: 0.165, 3232/28000 datapoints
2025-03-06 20:50:40,056 - INFO - training batch 151, loss: 0.454, 4832/28000 datapoints
2025-03-06 20:50:40,177 - INFO - training batch 201, loss: 0.129, 6432/28000 datapoints
2025-03-06 20:50:40,296 - INFO - training batch 251, loss: 0.349, 8032/28000 datapoints
2025-03-06 20:50:40,416 - INFO - training batch 301, loss: 0.617, 9632/28000 datapoints
2025-03-06 20:50:40,538 - INFO - training batch 351, loss: 0.282, 11232/28000 datapoints
2025-03-06 20:50:40,661 - INFO - training batch 401, loss: 0.578, 12832/28000 datapoints
2025-03-06 20:50:40,781 - INFO - training batch 451, loss: 0.272, 14432/28000 datapoints
2025-03-06 20:50:40,902 - INFO - training batch 501, loss: 0.167, 16032/28000 datapoints
2025-03-06 20:50:41,024 - INFO - training batch 551, loss: 0.274, 17632/28000 datapoints
2025-03-06 20:50:41,144 - INFO - training batch 601, loss: 0.409, 19232/28000 datapoints
2025-03-06 20:50:41,278 - INFO - training batch 651, loss: 0.046, 20832/28000 datapoints
2025-03-06 20:50:41,412 - INFO - training batch 701, loss: 0.281, 22432/28000 datapoints
2025-03-06 20:50:41,533 - INFO - training batch 751, loss: 0.254, 24032/28000 datapoints
2025-03-06 20:50:41,658 - INFO - training batch 801, loss: 0.136, 25632/28000 datapoints
2025-03-06 20:50:41,779 - INFO - training batch 851, loss: 0.492, 27232/28000 datapoints
2025-03-06 20:50:41,838 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:41,885 - INFO - validation batch 51, loss: 1.131, 1632/6976 datapoints
2025-03-06 20:50:41,929 - INFO - validation batch 101, loss: 0.303, 3232/6976 datapoints
2025-03-06 20:50:41,974 - INFO - validation batch 151, loss: 0.387, 4832/6976 datapoints
2025-03-06 20:50:42,017 - INFO - validation batch 201, loss: 0.396, 6432/6976 datapoints
2025-03-06 20:50:42,032 - INFO - Epoch 321/800 done.
2025-03-06 20:50:42,033 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:50:42,033 - INFO - Beginning epoch 322/800
2025-03-06 20:50:42,036 - INFO - training batch 1, loss: 0.330, 32/28000 datapoints
2025-03-06 20:50:42,158 - INFO - training batch 51, loss: 0.120, 1632/28000 datapoints
2025-03-06 20:50:42,279 - INFO - training batch 101, loss: 0.164, 3232/28000 datapoints
2025-03-06 20:50:42,416 - INFO - training batch 151, loss: 0.450, 4832/28000 datapoints
2025-03-06 20:50:42,537 - INFO - training batch 201, loss: 0.128, 6432/28000 datapoints
2025-03-06 20:50:42,658 - INFO - training batch 251, loss: 0.350, 8032/28000 datapoints
2025-03-06 20:50:42,791 - INFO - training batch 301, loss: 0.614, 9632/28000 datapoints
2025-03-06 20:50:42,914 - INFO - training batch 351, loss: 0.281, 11232/28000 datapoints
2025-03-06 20:50:43,036 - INFO - training batch 401, loss: 0.577, 12832/28000 datapoints
2025-03-06 20:50:43,160 - INFO - training batch 451, loss: 0.272, 14432/28000 datapoints
2025-03-06 20:50:43,279 - INFO - training batch 501, loss: 0.166, 16032/28000 datapoints
2025-03-06 20:50:43,403 - INFO - training batch 551, loss: 0.272, 17632/28000 datapoints
2025-03-06 20:50:43,525 - INFO - training batch 601, loss: 0.405, 19232/28000 datapoints
2025-03-06 20:50:43,649 - INFO - training batch 651, loss: 0.046, 20832/28000 datapoints
2025-03-06 20:50:43,770 - INFO - training batch 701, loss: 0.280, 22432/28000 datapoints
2025-03-06 20:50:43,889 - INFO - training batch 751, loss: 0.253, 24032/28000 datapoints
2025-03-06 20:50:44,011 - INFO - training batch 801, loss: 0.135, 25632/28000 datapoints
2025-03-06 20:50:44,130 - INFO - training batch 851, loss: 0.490, 27232/28000 datapoints
2025-03-06 20:50:44,189 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:44,232 - INFO - validation batch 51, loss: 1.131, 1632/6976 datapoints
2025-03-06 20:50:44,274 - INFO - validation batch 101, loss: 0.304, 3232/6976 datapoints
2025-03-06 20:50:44,317 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:50:44,362 - INFO - validation batch 201, loss: 0.396, 6432/6976 datapoints
2025-03-06 20:50:44,377 - INFO - Epoch 322/800 done.
2025-03-06 20:50:44,377 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:50:44,377 - INFO - Beginning epoch 323/800
2025-03-06 20:50:44,381 - INFO - training batch 1, loss: 0.329, 32/28000 datapoints
2025-03-06 20:50:44,507 - INFO - training batch 51, loss: 0.119, 1632/28000 datapoints
2025-03-06 20:50:44,626 - INFO - training batch 101, loss: 0.163, 3232/28000 datapoints
2025-03-06 20:50:44,747 - INFO - training batch 151, loss: 0.446, 4832/28000 datapoints
2025-03-06 20:50:44,868 - INFO - training batch 201, loss: 0.127, 6432/28000 datapoints
2025-03-06 20:50:44,998 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 20:50:45,118 - INFO - training batch 301, loss: 0.613, 9632/28000 datapoints
2025-03-06 20:50:45,236 - INFO - training batch 351, loss: 0.280, 11232/28000 datapoints
2025-03-06 20:50:45,361 - INFO - training batch 401, loss: 0.575, 12832/28000 datapoints
2025-03-06 20:50:45,482 - INFO - training batch 451, loss: 0.271, 14432/28000 datapoints
2025-03-06 20:50:45,603 - INFO - training batch 501, loss: 0.166, 16032/28000 datapoints
2025-03-06 20:50:45,726 - INFO - training batch 551, loss: 0.271, 17632/28000 datapoints
2025-03-06 20:50:45,848 - INFO - training batch 601, loss: 0.402, 19232/28000 datapoints
2025-03-06 20:50:45,969 - INFO - training batch 651, loss: 0.045, 20832/28000 datapoints
2025-03-06 20:50:46,089 - INFO - training batch 701, loss: 0.279, 22432/28000 datapoints
2025-03-06 20:50:46,207 - INFO - training batch 751, loss: 0.252, 24032/28000 datapoints
2025-03-06 20:50:46,326 - INFO - training batch 801, loss: 0.135, 25632/28000 datapoints
2025-03-06 20:50:46,448 - INFO - training batch 851, loss: 0.488, 27232/28000 datapoints
2025-03-06 20:50:46,507 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:46,550 - INFO - validation batch 51, loss: 1.130, 1632/6976 datapoints
2025-03-06 20:50:46,595 - INFO - validation batch 101, loss: 0.304, 3232/6976 datapoints
2025-03-06 20:50:46,641 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:50:46,686 - INFO - validation batch 201, loss: 0.396, 6432/6976 datapoints
2025-03-06 20:50:46,701 - INFO - Epoch 323/800 done.
2025-03-06 20:50:46,701 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:50:46,701 - INFO - Beginning epoch 324/800
2025-03-06 20:50:46,705 - INFO - training batch 1, loss: 0.328, 32/28000 datapoints
2025-03-06 20:50:46,827 - INFO - training batch 51, loss: 0.118, 1632/28000 datapoints
2025-03-06 20:50:46,952 - INFO - training batch 101, loss: 0.162, 3232/28000 datapoints
2025-03-06 20:50:47,078 - INFO - training batch 151, loss: 0.442, 4832/28000 datapoints
2025-03-06 20:50:47,201 - INFO - training batch 201, loss: 0.127, 6432/28000 datapoints
2025-03-06 20:50:47,324 - INFO - training batch 251, loss: 0.349, 8032/28000 datapoints
2025-03-06 20:50:47,453 - INFO - training batch 301, loss: 0.612, 9632/28000 datapoints
2025-03-06 20:50:47,578 - INFO - training batch 351, loss: 0.279, 11232/28000 datapoints
2025-03-06 20:50:47,706 - INFO - training batch 401, loss: 0.574, 12832/28000 datapoints
2025-03-06 20:50:47,832 - INFO - training batch 451, loss: 0.271, 14432/28000 datapoints
2025-03-06 20:50:47,956 - INFO - training batch 501, loss: 0.165, 16032/28000 datapoints
2025-03-06 20:50:48,082 - INFO - training batch 551, loss: 0.270, 17632/28000 datapoints
2025-03-06 20:50:48,205 - INFO - training batch 601, loss: 0.398, 19232/28000 datapoints
2025-03-06 20:50:48,330 - INFO - training batch 651, loss: 0.045, 20832/28000 datapoints
2025-03-06 20:50:48,462 - INFO - training batch 701, loss: 0.278, 22432/28000 datapoints
2025-03-06 20:50:48,593 - INFO - training batch 751, loss: 0.251, 24032/28000 datapoints
2025-03-06 20:50:48,724 - INFO - training batch 801, loss: 0.134, 25632/28000 datapoints
2025-03-06 20:50:48,849 - INFO - training batch 851, loss: 0.487, 27232/28000 datapoints
2025-03-06 20:50:48,917 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:48,967 - INFO - validation batch 51, loss: 1.131, 1632/6976 datapoints
2025-03-06 20:50:49,016 - INFO - validation batch 101, loss: 0.305, 3232/6976 datapoints
2025-03-06 20:50:49,063 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:50:49,115 - INFO - validation batch 201, loss: 0.396, 6432/6976 datapoints
2025-03-06 20:50:49,134 - INFO - Epoch 324/800 done.
2025-03-06 20:50:49,134 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:50:49,135 - INFO - Beginning epoch 325/800
2025-03-06 20:50:49,139 - INFO - training batch 1, loss: 0.328, 32/28000 datapoints
2025-03-06 20:50:49,268 - INFO - training batch 51, loss: 0.117, 1632/28000 datapoints
2025-03-06 20:50:49,395 - INFO - training batch 101, loss: 0.161, 3232/28000 datapoints
2025-03-06 20:50:49,524 - INFO - training batch 151, loss: 0.438, 4832/28000 datapoints
2025-03-06 20:50:49,648 - INFO - training batch 201, loss: 0.126, 6432/28000 datapoints
2025-03-06 20:50:49,796 - INFO - training batch 251, loss: 0.348, 8032/28000 datapoints
2025-03-06 20:50:49,930 - INFO - training batch 301, loss: 0.611, 9632/28000 datapoints
2025-03-06 20:50:50,057 - INFO - training batch 351, loss: 0.278, 11232/28000 datapoints
2025-03-06 20:50:50,181 - INFO - training batch 401, loss: 0.572, 12832/28000 datapoints
2025-03-06 20:50:50,305 - INFO - training batch 451, loss: 0.270, 14432/28000 datapoints
2025-03-06 20:50:50,429 - INFO - training batch 501, loss: 0.165, 16032/28000 datapoints
2025-03-06 20:50:50,558 - INFO - training batch 551, loss: 0.268, 17632/28000 datapoints
2025-03-06 20:50:50,689 - INFO - training batch 601, loss: 0.395, 19232/28000 datapoints
2025-03-06 20:50:50,813 - INFO - training batch 651, loss: 0.045, 20832/28000 datapoints
2025-03-06 20:50:50,937 - INFO - training batch 701, loss: 0.278, 22432/28000 datapoints
2025-03-06 20:50:51,065 - INFO - training batch 751, loss: 0.251, 24032/28000 datapoints
2025-03-06 20:50:51,187 - INFO - training batch 801, loss: 0.133, 25632/28000 datapoints
2025-03-06 20:50:51,312 - INFO - training batch 851, loss: 0.486, 27232/28000 datapoints
2025-03-06 20:50:51,402 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:51,452 - INFO - validation batch 51, loss: 1.131, 1632/6976 datapoints
2025-03-06 20:50:51,501 - INFO - validation batch 101, loss: 0.305, 3232/6976 datapoints
2025-03-06 20:50:51,551 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:50:51,599 - INFO - validation batch 201, loss: 0.396, 6432/6976 datapoints
2025-03-06 20:50:51,615 - INFO - Epoch 325/800 done.
2025-03-06 20:50:51,615 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:50:51,615 - INFO - Beginning epoch 326/800
2025-03-06 20:50:51,619 - INFO - training batch 1, loss: 0.327, 32/28000 datapoints
2025-03-06 20:50:51,750 - INFO - training batch 51, loss: 0.116, 1632/28000 datapoints
2025-03-06 20:50:51,877 - INFO - training batch 101, loss: 0.160, 3232/28000 datapoints
2025-03-06 20:50:52,003 - INFO - training batch 151, loss: 0.434, 4832/28000 datapoints
2025-03-06 20:50:52,128 - INFO - training batch 201, loss: 0.125, 6432/28000 datapoints
2025-03-06 20:50:52,250 - INFO - training batch 251, loss: 0.347, 8032/28000 datapoints
2025-03-06 20:50:52,376 - INFO - training batch 301, loss: 0.609, 9632/28000 datapoints
2025-03-06 20:50:52,500 - INFO - training batch 351, loss: 0.278, 11232/28000 datapoints
2025-03-06 20:50:52,625 - INFO - training batch 401, loss: 0.571, 12832/28000 datapoints
2025-03-06 20:50:52,750 - INFO - training batch 451, loss: 0.270, 14432/28000 datapoints
2025-03-06 20:50:52,875 - INFO - training batch 501, loss: 0.164, 16032/28000 datapoints
2025-03-06 20:50:53,000 - INFO - training batch 551, loss: 0.267, 17632/28000 datapoints
2025-03-06 20:50:53,124 - INFO - training batch 601, loss: 0.392, 19232/28000 datapoints
2025-03-06 20:50:53,249 - INFO - training batch 651, loss: 0.044, 20832/28000 datapoints
2025-03-06 20:50:53,374 - INFO - training batch 701, loss: 0.277, 22432/28000 datapoints
2025-03-06 20:50:53,500 - INFO - training batch 751, loss: 0.250, 24032/28000 datapoints
2025-03-06 20:50:53,625 - INFO - training batch 801, loss: 0.133, 25632/28000 datapoints
2025-03-06 20:50:53,751 - INFO - training batch 851, loss: 0.484, 27232/28000 datapoints
2025-03-06 20:50:53,815 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:50:53,862 - INFO - validation batch 51, loss: 1.131, 1632/6976 datapoints
2025-03-06 20:50:53,909 - INFO - validation batch 101, loss: 0.306, 3232/6976 datapoints
2025-03-06 20:50:53,955 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-06 20:50:54,004 - INFO - validation batch 201, loss: 0.396, 6432/6976 datapoints
2025-03-06 20:50:54,021 - INFO - Epoch 326/800 done.
2025-03-06 20:50:54,021 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:50:54,022 - INFO - Beginning epoch 327/800
2025-03-06 20:50:54,026 - INFO - training batch 1, loss: 0.327, 32/28000 datapoints
2025-03-06 20:50:54,158 - INFO - training batch 51, loss: 0.116, 1632/28000 datapoints
2025-03-06 20:50:54,282 - INFO - training batch 101, loss: 0.160, 3232/28000 datapoints
2025-03-06 20:50:54,406 - INFO - training batch 151, loss: 0.430, 4832/28000 datapoints
2025-03-06 20:50:54,547 - INFO - training batch 201, loss: 0.124, 6432/28000 datapoints
2025-03-06 20:50:54,675 - INFO - training batch 251, loss: 0.347, 8032/28000 datapoints
2025-03-06 20:50:54,799 - INFO - training batch 301, loss: 0.609, 9632/28000 datapoints
2025-03-06 20:50:54,928 - INFO - training batch 351, loss: 0.277, 11232/28000 datapoints
2025-03-06 20:50:55,063 - INFO - training batch 401, loss: 0.570, 12832/28000 datapoints
2025-03-06 20:50:55,190 - INFO - training batch 451, loss: 0.270, 14432/28000 datapoints
2025-03-06 20:50:55,314 - INFO - training batch 501, loss: 0.164, 16032/28000 datapoints
2025-03-06 20:50:55,447 - INFO - training batch 551, loss: 0.266, 17632/28000 datapoints
2025-03-06 20:50:55,572 - INFO - training batch 601, loss: 0.389, 19232/28000 datapoints
2025-03-06 20:50:55,700 - INFO - training batch 651, loss: 0.044, 20832/28000 datapoints
2025-03-06 20:50:55,825 - INFO - training batch 701, loss: 0.276, 22432/28000 datapoints
2025-03-06 20:50:55,948 - INFO - training batch 751, loss: 0.249, 24032/28000 datapoints
2025-03-06 20:50:56,073 - INFO - training batch 801, loss: 0.132, 25632/28000 datapoints
2025-03-06 20:50:56,197 - INFO - training batch 851, loss: 0.482, 27232/28000 datapoints
2025-03-06 20:50:56,258 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:50:56,306 - INFO - validation batch 51, loss: 1.131, 1632/6976 datapoints
2025-03-06 20:50:56,354 - INFO - validation batch 101, loss: 0.307, 3232/6976 datapoints
2025-03-06 20:50:56,403 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-06 20:50:56,451 - INFO - validation batch 201, loss: 0.396, 6432/6976 datapoints
2025-03-06 20:50:56,467 - INFO - Epoch 327/800 done.
2025-03-06 20:50:56,467 - INFO - Final validation performance:
Loss: 0.469, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:50:56,467 - INFO - Beginning epoch 328/800
2025-03-06 20:50:56,472 - INFO - training batch 1, loss: 0.326, 32/28000 datapoints
2025-03-06 20:50:56,603 - INFO - training batch 51, loss: 0.115, 1632/28000 datapoints
2025-03-06 20:50:56,733 - INFO - training batch 101, loss: 0.159, 3232/28000 datapoints
2025-03-06 20:50:56,859 - INFO - training batch 151, loss: 0.426, 4832/28000 datapoints
2025-03-06 20:50:56,984 - INFO - training batch 201, loss: 0.123, 6432/28000 datapoints
2025-03-06 20:50:57,110 - INFO - training batch 251, loss: 0.346, 8032/28000 datapoints
2025-03-06 20:50:57,234 - INFO - training batch 301, loss: 0.607, 9632/28000 datapoints
2025-03-06 20:50:57,357 - INFO - training batch 351, loss: 0.275, 11232/28000 datapoints
2025-03-06 20:50:57,485 - INFO - training batch 401, loss: 0.568, 12832/28000 datapoints
2025-03-06 20:50:57,610 - INFO - training batch 451, loss: 0.269, 14432/28000 datapoints
2025-03-06 20:50:57,740 - INFO - training batch 501, loss: 0.163, 16032/28000 datapoints
2025-03-06 20:50:57,865 - INFO - training batch 551, loss: 0.265, 17632/28000 datapoints
2025-03-06 20:50:57,990 - INFO - training batch 601, loss: 0.384, 19232/28000 datapoints
2025-03-06 20:50:58,114 - INFO - training batch 651, loss: 0.043, 20832/28000 datapoints
2025-03-06 20:50:58,237 - INFO - training batch 701, loss: 0.275, 22432/28000 datapoints
2025-03-06 20:50:58,361 - INFO - training batch 751, loss: 0.248, 24032/28000 datapoints
2025-03-06 20:50:58,487 - INFO - training batch 801, loss: 0.131, 25632/28000 datapoints
2025-03-06 20:50:58,615 - INFO - training batch 851, loss: 0.480, 27232/28000 datapoints
2025-03-06 20:50:58,685 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:50:58,732 - INFO - validation batch 51, loss: 1.131, 1632/6976 datapoints
2025-03-06 20:50:58,782 - INFO - validation batch 101, loss: 0.307, 3232/6976 datapoints
2025-03-06 20:50:58,829 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:50:58,878 - INFO - validation batch 201, loss: 0.396, 6432/6976 datapoints
2025-03-06 20:50:58,895 - INFO - Epoch 328/800 done.
2025-03-06 20:50:58,895 - INFO - Final validation performance:
Loss: 0.469, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:50:58,895 - INFO - Beginning epoch 329/800
2025-03-06 20:50:58,899 - INFO - training batch 1, loss: 0.326, 32/28000 datapoints
2025-03-06 20:50:59,026 - INFO - training batch 51, loss: 0.114, 1632/28000 datapoints
2025-03-06 20:50:59,149 - INFO - training batch 101, loss: 0.158, 3232/28000 datapoints
2025-03-06 20:50:59,270 - INFO - training batch 151, loss: 0.421, 4832/28000 datapoints
2025-03-06 20:50:59,389 - INFO - training batch 201, loss: 0.123, 6432/28000 datapoints
2025-03-06 20:50:59,512 - INFO - training batch 251, loss: 0.346, 8032/28000 datapoints
2025-03-06 20:50:59,635 - INFO - training batch 301, loss: 0.606, 9632/28000 datapoints
2025-03-06 20:50:59,754 - INFO - training batch 351, loss: 0.275, 11232/28000 datapoints
2025-03-06 20:50:59,874 - INFO - training batch 401, loss: 0.567, 12832/28000 datapoints
2025-03-06 20:50:59,993 - INFO - training batch 451, loss: 0.269, 14432/28000 datapoints
2025-03-06 20:51:00,118 - INFO - training batch 501, loss: 0.163, 16032/28000 datapoints
2025-03-06 20:51:00,238 - INFO - training batch 551, loss: 0.264, 17632/28000 datapoints
2025-03-06 20:51:00,357 - INFO - training batch 601, loss: 0.381, 19232/28000 datapoints
2025-03-06 20:51:00,476 - INFO - training batch 651, loss: 0.043, 20832/28000 datapoints
2025-03-06 20:51:00,609 - INFO - training batch 701, loss: 0.274, 22432/28000 datapoints
2025-03-06 20:51:00,739 - INFO - training batch 751, loss: 0.247, 24032/28000 datapoints
2025-03-06 20:51:00,859 - INFO - training batch 801, loss: 0.130, 25632/28000 datapoints
2025-03-06 20:51:00,981 - INFO - training batch 851, loss: 0.479, 27232/28000 datapoints
2025-03-06 20:51:01,045 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:51:01,091 - INFO - validation batch 51, loss: 1.131, 1632/6976 datapoints
2025-03-06 20:51:01,136 - INFO - validation batch 101, loss: 0.308, 3232/6976 datapoints
2025-03-06 20:51:01,180 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:51:01,227 - INFO - validation batch 201, loss: 0.397, 6432/6976 datapoints
2025-03-06 20:51:01,242 - INFO - Epoch 329/800 done.
2025-03-06 20:51:01,242 - INFO - Final validation performance:
Loss: 0.469, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:51:01,243 - INFO - Beginning epoch 330/800
2025-03-06 20:51:01,246 - INFO - training batch 1, loss: 0.325, 32/28000 datapoints
2025-03-06 20:51:01,372 - INFO - training batch 51, loss: 0.113, 1632/28000 datapoints
2025-03-06 20:51:01,522 - INFO - training batch 101, loss: 0.157, 3232/28000 datapoints
2025-03-06 20:51:01,652 - INFO - training batch 151, loss: 0.416, 4832/28000 datapoints
2025-03-06 20:51:01,773 - INFO - training batch 201, loss: 0.122, 6432/28000 datapoints
2025-03-06 20:51:01,895 - INFO - training batch 251, loss: 0.345, 8032/28000 datapoints
2025-03-06 20:51:02,013 - INFO - training batch 301, loss: 0.603, 9632/28000 datapoints
2025-03-06 20:51:02,133 - INFO - training batch 351, loss: 0.274, 11232/28000 datapoints
2025-03-06 20:51:02,254 - INFO - training batch 401, loss: 0.565, 12832/28000 datapoints
2025-03-06 20:51:02,372 - INFO - training batch 451, loss: 0.268, 14432/28000 datapoints
2025-03-06 20:51:02,491 - INFO - training batch 501, loss: 0.163, 16032/28000 datapoints
2025-03-06 20:51:02,611 - INFO - training batch 551, loss: 0.263, 17632/28000 datapoints
2025-03-06 20:51:02,740 - INFO - training batch 601, loss: 0.378, 19232/28000 datapoints
2025-03-06 20:51:02,860 - INFO - training batch 651, loss: 0.043, 20832/28000 datapoints
2025-03-06 20:51:02,983 - INFO - training batch 701, loss: 0.274, 22432/28000 datapoints
2025-03-06 20:51:03,106 - INFO - training batch 751, loss: 0.247, 24032/28000 datapoints
2025-03-06 20:51:03,226 - INFO - training batch 801, loss: 0.130, 25632/28000 datapoints
2025-03-06 20:51:03,346 - INFO - training batch 851, loss: 0.477, 27232/28000 datapoints
2025-03-06 20:51:03,405 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:51:03,453 - INFO - validation batch 51, loss: 1.131, 1632/6976 datapoints
2025-03-06 20:51:03,498 - INFO - validation batch 101, loss: 0.308, 3232/6976 datapoints
2025-03-06 20:51:03,541 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-06 20:51:03,585 - INFO - validation batch 201, loss: 0.397, 6432/6976 datapoints
2025-03-06 20:51:03,600 - INFO - Epoch 330/800 done.
2025-03-06 20:51:03,601 - INFO - Final validation performance:
Loss: 0.469, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:51:03,601 - INFO - Beginning epoch 331/800
2025-03-06 20:51:03,604 - INFO - training batch 1, loss: 0.325, 32/28000 datapoints
2025-03-06 20:51:03,731 - INFO - training batch 51, loss: 0.113, 1632/28000 datapoints
2025-03-06 20:51:03,853 - INFO - training batch 101, loss: 0.156, 3232/28000 datapoints
2025-03-06 20:51:03,973 - INFO - training batch 151, loss: 0.412, 4832/28000 datapoints
2025-03-06 20:51:04,094 - INFO - training batch 201, loss: 0.122, 6432/28000 datapoints
2025-03-06 20:51:04,236 - INFO - training batch 251, loss: 0.345, 8032/28000 datapoints
2025-03-06 20:51:04,355 - INFO - training batch 301, loss: 0.602, 9632/28000 datapoints
2025-03-06 20:51:04,474 - INFO - training batch 351, loss: 0.273, 11232/28000 datapoints
2025-03-06 20:51:04,594 - INFO - training batch 401, loss: 0.564, 12832/28000 datapoints
2025-03-06 20:51:04,718 - INFO - training batch 451, loss: 0.268, 14432/28000 datapoints
2025-03-06 20:51:04,838 - INFO - training batch 501, loss: 0.163, 16032/28000 datapoints
2025-03-06 20:51:04,965 - INFO - training batch 551, loss: 0.261, 17632/28000 datapoints
2025-03-06 20:51:05,088 - INFO - training batch 601, loss: 0.376, 19232/28000 datapoints
2025-03-06 20:51:05,208 - INFO - training batch 651, loss: 0.042, 20832/28000 datapoints
2025-03-06 20:51:05,327 - INFO - training batch 701, loss: 0.273, 22432/28000 datapoints
2025-03-06 20:51:05,450 - INFO - training batch 751, loss: 0.246, 24032/28000 datapoints
2025-03-06 20:51:05,569 - INFO - training batch 801, loss: 0.129, 25632/28000 datapoints
2025-03-06 20:51:05,692 - INFO - training batch 851, loss: 0.476, 27232/28000 datapoints
2025-03-06 20:51:05,750 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:51:05,794 - INFO - validation batch 51, loss: 1.131, 1632/6976 datapoints
2025-03-06 20:51:05,837 - INFO - validation batch 101, loss: 0.309, 3232/6976 datapoints
2025-03-06 20:51:05,882 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-06 20:51:05,926 - INFO - validation batch 201, loss: 0.397, 6432/6976 datapoints
2025-03-06 20:51:05,941 - INFO - Epoch 331/800 done.
2025-03-06 20:51:05,942 - INFO - Final validation performance:
Loss: 0.469, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:51:05,942 - INFO - Beginning epoch 332/800
2025-03-06 20:51:05,945 - INFO - training batch 1, loss: 0.324, 32/28000 datapoints
2025-03-06 20:51:06,066 - INFO - training batch 51, loss: 0.112, 1632/28000 datapoints
2025-03-06 20:51:06,188 - INFO - training batch 101, loss: 0.155, 3232/28000 datapoints
2025-03-06 20:51:06,309 - INFO - training batch 151, loss: 0.408, 4832/28000 datapoints
2025-03-06 20:51:06,428 - INFO - training batch 201, loss: 0.121, 6432/28000 datapoints
2025-03-06 20:51:06,549 - INFO - training batch 251, loss: 0.344, 8032/28000 datapoints
2025-03-06 20:51:06,690 - INFO - training batch 301, loss: 0.601, 9632/28000 datapoints
2025-03-06 20:51:06,812 - INFO - training batch 351, loss: 0.272, 11232/28000 datapoints
2025-03-06 20:51:06,934 - INFO - training batch 401, loss: 0.562, 12832/28000 datapoints
2025-03-06 20:51:07,065 - INFO - training batch 451, loss: 0.267, 14432/28000 datapoints
2025-03-06 20:51:07,194 - INFO - training batch 501, loss: 0.162, 16032/28000 datapoints
2025-03-06 20:51:07,322 - INFO - training batch 551, loss: 0.261, 17632/28000 datapoints
2025-03-06 20:51:07,450 - INFO - training batch 601, loss: 0.372, 19232/28000 datapoints
2025-03-06 20:51:07,584 - INFO - training batch 651, loss: 0.042, 20832/28000 datapoints
2025-03-06 20:51:07,712 - INFO - training batch 701, loss: 0.273, 22432/28000 datapoints
2025-03-06 20:51:07,837 - INFO - training batch 751, loss: 0.245, 24032/28000 datapoints
2025-03-06 20:51:07,961 - INFO - training batch 801, loss: 0.128, 25632/28000 datapoints
2025-03-06 20:51:08,084 - INFO - training batch 851, loss: 0.474, 27232/28000 datapoints
2025-03-06 20:51:08,147 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:51:08,195 - INFO - validation batch 51, loss: 1.131, 1632/6976 datapoints
2025-03-06 20:51:08,246 - INFO - validation batch 101, loss: 0.309, 3232/6976 datapoints
2025-03-06 20:51:08,295 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:51:08,343 - INFO - validation batch 201, loss: 0.397, 6432/6976 datapoints
2025-03-06 20:51:08,358 - INFO - Epoch 332/800 done.
2025-03-06 20:51:08,358 - INFO - Final validation performance:
Loss: 0.469, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:51:08,358 - INFO - Beginning epoch 333/800
2025-03-06 20:51:08,362 - INFO - training batch 1, loss: 0.323, 32/28000 datapoints
2025-03-06 20:51:08,487 - INFO - training batch 51, loss: 0.111, 1632/28000 datapoints
2025-03-06 20:51:08,610 - INFO - training batch 101, loss: 0.154, 3232/28000 datapoints
2025-03-06 20:51:08,738 - INFO - training batch 151, loss: 0.404, 4832/28000 datapoints
2025-03-06 20:51:08,861 - INFO - training batch 201, loss: 0.121, 6432/28000 datapoints
2025-03-06 20:51:08,984 - INFO - training batch 251, loss: 0.343, 8032/28000 datapoints
2025-03-06 20:51:09,114 - INFO - training batch 301, loss: 0.598, 9632/28000 datapoints
2025-03-06 20:51:09,239 - INFO - training batch 351, loss: 0.271, 11232/28000 datapoints
2025-03-06 20:51:09,364 - INFO - training batch 401, loss: 0.561, 12832/28000 datapoints
2025-03-06 20:51:09,491 - INFO - training batch 451, loss: 0.267, 14432/28000 datapoints
2025-03-06 20:51:09,614 - INFO - training batch 501, loss: 0.162, 16032/28000 datapoints
2025-03-06 20:51:09,742 - INFO - training batch 551, loss: 0.260, 17632/28000 datapoints
2025-03-06 20:51:09,865 - INFO - training batch 601, loss: 0.369, 19232/28000 datapoints
2025-03-06 20:51:09,988 - INFO - training batch 651, loss: 0.042, 20832/28000 datapoints
2025-03-06 20:51:10,113 - INFO - training batch 701, loss: 0.272, 22432/28000 datapoints
2025-03-06 20:51:10,235 - INFO - training batch 751, loss: 0.244, 24032/28000 datapoints
2025-03-06 20:51:10,358 - INFO - training batch 801, loss: 0.128, 25632/28000 datapoints
2025-03-06 20:51:10,483 - INFO - training batch 851, loss: 0.472, 27232/28000 datapoints
2025-03-06 20:51:10,547 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:51:10,597 - INFO - validation batch 51, loss: 1.132, 1632/6976 datapoints
2025-03-06 20:51:10,647 - INFO - validation batch 101, loss: 0.310, 3232/6976 datapoints
2025-03-06 20:51:10,696 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:51:10,745 - INFO - validation batch 201, loss: 0.397, 6432/6976 datapoints
2025-03-06 20:51:10,760 - INFO - Epoch 333/800 done.
2025-03-06 20:51:10,760 - INFO - Final validation performance:
Loss: 0.469, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:51:10,761 - INFO - Beginning epoch 334/800
2025-03-06 20:51:10,765 - INFO - training batch 1, loss: 0.323, 32/28000 datapoints
2025-03-06 20:51:10,890 - INFO - training batch 51, loss: 0.111, 1632/28000 datapoints
2025-03-06 20:51:11,014 - INFO - training batch 101, loss: 0.153, 3232/28000 datapoints
2025-03-06 20:51:11,140 - INFO - training batch 151, loss: 0.399, 4832/28000 datapoints
2025-03-06 20:51:11,265 - INFO - training batch 201, loss: 0.120, 6432/28000 datapoints
2025-03-06 20:51:11,387 - INFO - training batch 251, loss: 0.343, 8032/28000 datapoints
2025-03-06 20:51:11,515 - INFO - training batch 301, loss: 0.598, 9632/28000 datapoints
2025-03-06 20:51:11,666 - INFO - training batch 351, loss: 0.271, 11232/28000 datapoints
2025-03-06 20:51:11,791 - INFO - training batch 401, loss: 0.560, 12832/28000 datapoints
2025-03-06 20:51:11,915 - INFO - training batch 451, loss: 0.266, 14432/28000 datapoints
2025-03-06 20:51:12,038 - INFO - training batch 501, loss: 0.162, 16032/28000 datapoints
2025-03-06 20:51:12,164 - INFO - training batch 551, loss: 0.257, 17632/28000 datapoints
2025-03-06 20:51:12,289 - INFO - training batch 601, loss: 0.365, 19232/28000 datapoints
2025-03-06 20:51:12,410 - INFO - training batch 651, loss: 0.041, 20832/28000 datapoints
2025-03-06 20:51:12,532 - INFO - training batch 701, loss: 0.271, 22432/28000 datapoints
2025-03-06 20:51:12,660 - INFO - training batch 751, loss: 0.243, 24032/28000 datapoints
2025-03-06 20:51:12,798 - INFO - training batch 801, loss: 0.127, 25632/28000 datapoints
2025-03-06 20:51:12,920 - INFO - training batch 851, loss: 0.470, 27232/28000 datapoints
2025-03-06 20:51:12,984 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 20:51:13,030 - INFO - validation batch 51, loss: 1.132, 1632/6976 datapoints
2025-03-06 20:51:13,080 - INFO - validation batch 101, loss: 0.310, 3232/6976 datapoints
2025-03-06 20:51:13,129 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:51:13,174 - INFO - validation batch 201, loss: 0.398, 6432/6976 datapoints
2025-03-06 20:51:13,189 - INFO - Epoch 334/800 done.
2025-03-06 20:51:13,189 - INFO - Final validation performance:
Loss: 0.470, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:51:13,190 - INFO - Beginning epoch 335/800
2025-03-06 20:51:13,193 - INFO - training batch 1, loss: 0.322, 32/28000 datapoints
2025-03-06 20:51:13,321 - INFO - training batch 51, loss: 0.110, 1632/28000 datapoints
2025-03-06 20:51:13,441 - INFO - training batch 101, loss: 0.152, 3232/28000 datapoints
2025-03-06 20:51:13,565 - INFO - training batch 151, loss: 0.394, 4832/28000 datapoints
2025-03-06 20:51:13,687 - INFO - training batch 201, loss: 0.119, 6432/28000 datapoints
2025-03-06 20:51:13,808 - INFO - training batch 251, loss: 0.342, 8032/28000 datapoints
2025-03-06 20:51:13,927 - INFO - training batch 301, loss: 0.596, 9632/28000 datapoints
2025-03-06 20:51:14,046 - INFO - training batch 351, loss: 0.270, 11232/28000 datapoints
2025-03-06 20:51:14,166 - INFO - training batch 401, loss: 0.558, 12832/28000 datapoints
2025-03-06 20:51:14,286 - INFO - training batch 451, loss: 0.266, 14432/28000 datapoints
2025-03-06 20:51:14,406 - INFO - training batch 501, loss: 0.161, 16032/28000 datapoints
2025-03-06 20:51:14,526 - INFO - training batch 551, loss: 0.258, 17632/28000 datapoints
2025-03-06 20:51:14,648 - INFO - training batch 601, loss: 0.364, 19232/28000 datapoints
2025-03-06 20:51:14,767 - INFO - training batch 651, loss: 0.041, 20832/28000 datapoints
2025-03-06 20:51:14,890 - INFO - training batch 701, loss: 0.270, 22432/28000 datapoints
2025-03-06 20:51:15,014 - INFO - training batch 751, loss: 0.243, 24032/28000 datapoints
2025-03-06 20:51:15,137 - INFO - training batch 801, loss: 0.127, 25632/28000 datapoints
2025-03-06 20:51:15,255 - INFO - training batch 851, loss: 0.468, 27232/28000 datapoints
2025-03-06 20:51:15,315 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:51:15,358 - INFO - validation batch 51, loss: 1.131, 1632/6976 datapoints
2025-03-06 20:51:15,401 - INFO - validation batch 101, loss: 0.311, 3232/6976 datapoints
2025-03-06 20:51:15,445 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:51:15,492 - INFO - validation batch 201, loss: 0.398, 6432/6976 datapoints
2025-03-06 20:51:15,507 - INFO - Epoch 335/800 done.
2025-03-06 20:51:15,507 - INFO - Final validation performance:
Loss: 0.470, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:51:15,507 - INFO - Beginning epoch 336/800
2025-03-06 20:51:15,511 - INFO - training batch 1, loss: 0.321, 32/28000 datapoints
2025-03-06 20:51:15,638 - INFO - training batch 51, loss: 0.110, 1632/28000 datapoints
2025-03-06 20:51:15,757 - INFO - training batch 101, loss: 0.151, 3232/28000 datapoints
2025-03-06 20:51:15,880 - INFO - training batch 151, loss: 0.389, 4832/28000 datapoints
2025-03-06 20:51:15,999 - INFO - training batch 201, loss: 0.119, 6432/28000 datapoints
2025-03-06 20:51:16,119 - INFO - training batch 251, loss: 0.341, 8032/28000 datapoints
2025-03-06 20:51:16,237 - INFO - training batch 301, loss: 0.594, 9632/28000 datapoints
2025-03-06 20:51:16,358 - INFO - training batch 351, loss: 0.270, 11232/28000 datapoints
2025-03-06 20:51:16,477 - INFO - training batch 401, loss: 0.556, 12832/28000 datapoints
2025-03-06 20:51:16,597 - INFO - training batch 451, loss: 0.265, 14432/28000 datapoints
2025-03-06 20:51:16,719 - INFO - training batch 501, loss: 0.162, 16032/28000 datapoints
2025-03-06 20:51:16,842 - INFO - training batch 551, loss: 0.256, 17632/28000 datapoints
2025-03-06 20:51:16,963 - INFO - training batch 601, loss: 0.360, 19232/28000 datapoints
2025-03-06 20:51:17,082 - INFO - training batch 651, loss: 0.041, 20832/28000 datapoints
2025-03-06 20:51:17,201 - INFO - training batch 701, loss: 0.270, 22432/28000 datapoints
2025-03-06 20:51:17,318 - INFO - training batch 751, loss: 0.242, 24032/28000 datapoints
2025-03-06 20:51:17,439 - INFO - training batch 801, loss: 0.126, 25632/28000 datapoints
2025-03-06 20:51:17,571 - INFO - training batch 851, loss: 0.467, 27232/28000 datapoints
2025-03-06 20:51:17,630 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:51:17,680 - INFO - validation batch 51, loss: 1.132, 1632/6976 datapoints
2025-03-06 20:51:17,725 - INFO - validation batch 101, loss: 0.311, 3232/6976 datapoints
2025-03-06 20:51:17,787 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:51:17,833 - INFO - validation batch 201, loss: 0.399, 6432/6976 datapoints
2025-03-06 20:51:17,850 - INFO - Epoch 336/800 done.
2025-03-06 20:51:17,850 - INFO - Final validation performance:
Loss: 0.470, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:51:17,851 - INFO - Beginning epoch 337/800
2025-03-06 20:51:17,854 - INFO - training batch 1, loss: 0.319, 32/28000 datapoints
2025-03-06 20:51:17,976 - INFO - training batch 51, loss: 0.109, 1632/28000 datapoints
2025-03-06 20:51:18,096 - INFO - training batch 101, loss: 0.151, 3232/28000 datapoints
2025-03-06 20:51:18,217 - INFO - training batch 151, loss: 0.385, 4832/28000 datapoints
2025-03-06 20:51:18,337 - INFO - training batch 201, loss: 0.118, 6432/28000 datapoints
2025-03-06 20:51:18,458 - INFO - training batch 251, loss: 0.341, 8032/28000 datapoints
2025-03-06 20:51:18,578 - INFO - training batch 301, loss: 0.592, 9632/28000 datapoints
2025-03-06 20:51:18,702 - INFO - training batch 351, loss: 0.268, 11232/28000 datapoints
2025-03-06 20:51:18,840 - INFO - training batch 401, loss: 0.555, 12832/28000 datapoints
2025-03-06 20:51:18,961 - INFO - training batch 451, loss: 0.264, 14432/28000 datapoints
2025-03-06 20:51:19,080 - INFO - training batch 501, loss: 0.161, 16032/28000 datapoints
2025-03-06 20:51:19,201 - INFO - training batch 551, loss: 0.254, 17632/28000 datapoints
2025-03-06 20:51:19,328 - INFO - training batch 601, loss: 0.356, 19232/28000 datapoints
2025-03-06 20:51:19,452 - INFO - training batch 651, loss: 0.040, 20832/28000 datapoints
2025-03-06 20:51:19,575 - INFO - training batch 701, loss: 0.269, 22432/28000 datapoints
2025-03-06 20:51:19,702 - INFO - training batch 751, loss: 0.242, 24032/28000 datapoints
2025-03-06 20:51:19,823 - INFO - training batch 801, loss: 0.125, 25632/28000 datapoints
2025-03-06 20:51:19,945 - INFO - training batch 851, loss: 0.465, 27232/28000 datapoints
2025-03-06 20:51:20,003 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:51:20,047 - INFO - validation batch 51, loss: 1.132, 1632/6976 datapoints
2025-03-06 20:51:20,091 - INFO - validation batch 101, loss: 0.312, 3232/6976 datapoints
2025-03-06 20:51:20,136 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:51:20,180 - INFO - validation batch 201, loss: 0.399, 6432/6976 datapoints
2025-03-06 20:51:20,195 - INFO - Epoch 337/800 done.
2025-03-06 20:51:20,195 - INFO - Final validation performance:
Loss: 0.470, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:51:20,196 - INFO - Beginning epoch 338/800
2025-03-06 20:51:20,200 - INFO - training batch 1, loss: 0.319, 32/28000 datapoints
2025-03-06 20:51:20,321 - INFO - training batch 51, loss: 0.108, 1632/28000 datapoints
2025-03-06 20:51:20,443 - INFO - training batch 101, loss: 0.150, 3232/28000 datapoints
2025-03-06 20:51:20,564 - INFO - training batch 151, loss: 0.381, 4832/28000 datapoints
2025-03-06 20:51:20,692 - INFO - training batch 201, loss: 0.118, 6432/28000 datapoints
2025-03-06 20:51:20,811 - INFO - training batch 251, loss: 0.340, 8032/28000 datapoints
2025-03-06 20:51:20,933 - INFO - training batch 301, loss: 0.591, 9632/28000 datapoints
2025-03-06 20:51:21,053 - INFO - training batch 351, loss: 0.267, 11232/28000 datapoints
2025-03-06 20:51:21,173 - INFO - training batch 401, loss: 0.553, 12832/28000 datapoints
2025-03-06 20:51:21,294 - INFO - training batch 451, loss: 0.264, 14432/28000 datapoints
2025-03-06 20:51:21,414 - INFO - training batch 501, loss: 0.161, 16032/28000 datapoints
2025-03-06 20:51:21,537 - INFO - training batch 551, loss: 0.253, 17632/28000 datapoints
2025-03-06 20:51:21,679 - INFO - training batch 601, loss: 0.353, 19232/28000 datapoints
2025-03-06 20:51:21,805 - INFO - training batch 651, loss: 0.040, 20832/28000 datapoints
2025-03-06 20:51:21,928 - INFO - training batch 701, loss: 0.268, 22432/28000 datapoints
2025-03-06 20:51:22,047 - INFO - training batch 751, loss: 0.241, 24032/28000 datapoints
2025-03-06 20:51:22,167 - INFO - training batch 801, loss: 0.125, 25632/28000 datapoints
2025-03-06 20:51:22,285 - INFO - training batch 851, loss: 0.462, 27232/28000 datapoints
2025-03-06 20:51:22,345 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:51:22,388 - INFO - validation batch 51, loss: 1.132, 1632/6976 datapoints
2025-03-06 20:51:22,433 - INFO - validation batch 101, loss: 0.312, 3232/6976 datapoints
2025-03-06 20:51:22,477 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:51:22,521 - INFO - validation batch 201, loss: 0.399, 6432/6976 datapoints
2025-03-06 20:51:22,536 - INFO - Epoch 338/800 done.
2025-03-06 20:51:22,536 - INFO - Final validation performance:
Loss: 0.471, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:51:22,537 - INFO - Beginning epoch 339/800
2025-03-06 20:51:22,540 - INFO - training batch 1, loss: 0.318, 32/28000 datapoints
2025-03-06 20:51:22,663 - INFO - training batch 51, loss: 0.108, 1632/28000 datapoints
2025-03-06 20:51:22,783 - INFO - training batch 101, loss: 0.149, 3232/28000 datapoints
2025-03-06 20:51:22,904 - INFO - training batch 151, loss: 0.376, 4832/28000 datapoints
2025-03-06 20:51:23,027 - INFO - training batch 201, loss: 0.117, 6432/28000 datapoints
2025-03-06 20:51:23,146 - INFO - training batch 251, loss: 0.340, 8032/28000 datapoints
2025-03-06 20:51:23,268 - INFO - training batch 301, loss: 0.589, 9632/28000 datapoints
2025-03-06 20:51:23,388 - INFO - training batch 351, loss: 0.266, 11232/28000 datapoints
2025-03-06 20:51:23,510 - INFO - training batch 401, loss: 0.552, 12832/28000 datapoints
2025-03-06 20:51:23,634 - INFO - training batch 451, loss: 0.264, 14432/28000 datapoints
2025-03-06 20:51:23,756 - INFO - training batch 501, loss: 0.160, 16032/28000 datapoints
2025-03-06 20:51:23,877 - INFO - training batch 551, loss: 0.252, 17632/28000 datapoints
2025-03-06 20:51:23,997 - INFO - training batch 601, loss: 0.349, 19232/28000 datapoints
2025-03-06 20:51:24,116 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 20:51:24,235 - INFO - training batch 701, loss: 0.268, 22432/28000 datapoints
2025-03-06 20:51:24,353 - INFO - training batch 751, loss: 0.240, 24032/28000 datapoints
2025-03-06 20:51:24,472 - INFO - training batch 801, loss: 0.124, 25632/28000 datapoints
2025-03-06 20:51:24,591 - INFO - training batch 851, loss: 0.460, 27232/28000 datapoints
2025-03-06 20:51:24,652 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:51:24,696 - INFO - validation batch 51, loss: 1.132, 1632/6976 datapoints
2025-03-06 20:51:24,739 - INFO - validation batch 101, loss: 0.313, 3232/6976 datapoints
2025-03-06 20:51:24,783 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:51:24,826 - INFO - validation batch 201, loss: 0.399, 6432/6976 datapoints
2025-03-06 20:51:24,841 - INFO - Epoch 339/800 done.
2025-03-06 20:51:24,842 - INFO - Final validation performance:
Loss: 0.471, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:51:24,842 - INFO - Beginning epoch 340/800
2025-03-06 20:51:24,847 - INFO - training batch 1, loss: 0.317, 32/28000 datapoints
2025-03-06 20:51:24,996 - INFO - training batch 51, loss: 0.107, 1632/28000 datapoints
2025-03-06 20:51:25,116 - INFO - training batch 101, loss: 0.148, 3232/28000 datapoints
2025-03-06 20:51:25,237 - INFO - training batch 151, loss: 0.372, 4832/28000 datapoints
2025-03-06 20:51:25,356 - INFO - training batch 201, loss: 0.116, 6432/28000 datapoints
2025-03-06 20:51:25,486 - INFO - training batch 251, loss: 0.339, 8032/28000 datapoints
2025-03-06 20:51:25,612 - INFO - training batch 301, loss: 0.588, 9632/28000 datapoints
2025-03-06 20:51:25,735 - INFO - training batch 351, loss: 0.266, 11232/28000 datapoints
2025-03-06 20:51:25,859 - INFO - training batch 401, loss: 0.550, 12832/28000 datapoints
2025-03-06 20:51:25,982 - INFO - training batch 451, loss: 0.263, 14432/28000 datapoints
2025-03-06 20:51:26,101 - INFO - training batch 501, loss: 0.160, 16032/28000 datapoints
2025-03-06 20:51:26,221 - INFO - training batch 551, loss: 0.250, 17632/28000 datapoints
2025-03-06 20:51:26,342 - INFO - training batch 601, loss: 0.346, 19232/28000 datapoints
2025-03-06 20:51:26,463 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 20:51:26,582 - INFO - training batch 701, loss: 0.267, 22432/28000 datapoints
2025-03-06 20:51:26,706 - INFO - training batch 751, loss: 0.240, 24032/28000 datapoints
2025-03-06 20:51:26,826 - INFO - training batch 801, loss: 0.123, 25632/28000 datapoints
2025-03-06 20:51:26,948 - INFO - training batch 851, loss: 0.458, 27232/28000 datapoints
2025-03-06 20:51:27,009 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:51:27,053 - INFO - validation batch 51, loss: 1.133, 1632/6976 datapoints
2025-03-06 20:51:27,098 - INFO - validation batch 101, loss: 0.314, 3232/6976 datapoints
2025-03-06 20:51:27,147 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 20:51:27,196 - INFO - validation batch 201, loss: 0.400, 6432/6976 datapoints
2025-03-06 20:51:27,211 - INFO - Epoch 340/800 done.
2025-03-06 20:51:27,211 - INFO - Final validation performance:
Loss: 0.471, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:51:27,211 - INFO - Beginning epoch 341/800
2025-03-06 20:51:27,215 - INFO - training batch 1, loss: 0.316, 32/28000 datapoints
2025-03-06 20:51:27,340 - INFO - training batch 51, loss: 0.107, 1632/28000 datapoints
2025-03-06 20:51:27,466 - INFO - training batch 101, loss: 0.147, 3232/28000 datapoints
2025-03-06 20:51:27,601 - INFO - training batch 151, loss: 0.368, 4832/28000 datapoints
2025-03-06 20:51:27,733 - INFO - training batch 201, loss: 0.115, 6432/28000 datapoints
2025-03-06 20:51:27,859 - INFO - training batch 251, loss: 0.339, 8032/28000 datapoints
2025-03-06 20:51:27,985 - INFO - training batch 301, loss: 0.585, 9632/28000 datapoints
2025-03-06 20:51:28,109 - INFO - training batch 351, loss: 0.265, 11232/28000 datapoints
2025-03-06 20:51:28,231 - INFO - training batch 401, loss: 0.549, 12832/28000 datapoints
2025-03-06 20:51:28,354 - INFO - training batch 451, loss: 0.262, 14432/28000 datapoints
2025-03-06 20:51:28,478 - INFO - training batch 501, loss: 0.160, 16032/28000 datapoints
2025-03-06 20:51:28,604 - INFO - training batch 551, loss: 0.248, 17632/28000 datapoints
2025-03-06 20:51:28,731 - INFO - training batch 601, loss: 0.342, 19232/28000 datapoints
2025-03-06 20:51:28,855 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 20:51:29,005 - INFO - training batch 701, loss: 0.266, 22432/28000 datapoints
2025-03-06 20:51:29,130 - INFO - training batch 751, loss: 0.239, 24032/28000 datapoints
2025-03-06 20:51:29,253 - INFO - training batch 801, loss: 0.123, 25632/28000 datapoints
2025-03-06 20:51:29,377 - INFO - training batch 851, loss: 0.456, 27232/28000 datapoints
2025-03-06 20:51:29,438 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:51:29,486 - INFO - validation batch 51, loss: 1.133, 1632/6976 datapoints
2025-03-06 20:51:29,542 - INFO - validation batch 101, loss: 0.315, 3232/6976 datapoints
2025-03-06 20:51:29,591 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-06 20:51:29,641 - INFO - validation batch 201, loss: 0.400, 6432/6976 datapoints
2025-03-06 20:51:29,656 - INFO - Epoch 341/800 done.
2025-03-06 20:51:29,656 - INFO - Final validation performance:
Loss: 0.471, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:51:29,657 - INFO - Beginning epoch 342/800
2025-03-06 20:51:29,660 - INFO - training batch 1, loss: 0.315, 32/28000 datapoints
2025-03-06 20:51:29,786 - INFO - training batch 51, loss: 0.106, 1632/28000 datapoints
2025-03-06 20:51:29,911 - INFO - training batch 101, loss: 0.146, 3232/28000 datapoints
2025-03-06 20:51:30,037 - INFO - training batch 151, loss: 0.364, 4832/28000 datapoints
2025-03-06 20:51:30,161 - INFO - training batch 201, loss: 0.115, 6432/28000 datapoints
2025-03-06 20:51:30,284 - INFO - training batch 251, loss: 0.338, 8032/28000 datapoints
2025-03-06 20:51:30,411 - INFO - training batch 301, loss: 0.585, 9632/28000 datapoints
2025-03-06 20:51:30,534 - INFO - training batch 351, loss: 0.264, 11232/28000 datapoints
2025-03-06 20:51:30,663 - INFO - training batch 401, loss: 0.547, 12832/28000 datapoints
2025-03-06 20:51:30,786 - INFO - training batch 451, loss: 0.262, 14432/28000 datapoints
2025-03-06 20:51:30,923 - INFO - training batch 501, loss: 0.159, 16032/28000 datapoints
2025-03-06 20:51:31,053 - INFO - training batch 551, loss: 0.247, 17632/28000 datapoints
2025-03-06 20:51:31,177 - INFO - training batch 601, loss: 0.339, 19232/28000 datapoints
2025-03-06 20:51:31,307 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 20:51:31,434 - INFO - training batch 701, loss: 0.265, 22432/28000 datapoints
2025-03-06 20:51:31,564 - INFO - training batch 751, loss: 0.238, 24032/28000 datapoints
2025-03-06 20:51:31,696 - INFO - training batch 801, loss: 0.122, 25632/28000 datapoints
2025-03-06 20:51:31,857 - INFO - training batch 851, loss: 0.455, 27232/28000 datapoints
2025-03-06 20:51:31,921 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:51:31,970 - INFO - validation batch 51, loss: 1.134, 1632/6976 datapoints
2025-03-06 20:51:32,019 - INFO - validation batch 101, loss: 0.316, 3232/6976 datapoints
2025-03-06 20:51:32,069 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-06 20:51:32,115 - INFO - validation batch 201, loss: 0.400, 6432/6976 datapoints
2025-03-06 20:51:32,132 - INFO - Epoch 342/800 done.
2025-03-06 20:51:32,132 - INFO - Final validation performance:
Loss: 0.472, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:51:32,133 - INFO - Beginning epoch 343/800
2025-03-06 20:51:32,137 - INFO - training batch 1, loss: 0.314, 32/28000 datapoints
2025-03-06 20:51:32,260 - INFO - training batch 51, loss: 0.106, 1632/28000 datapoints
2025-03-06 20:51:32,380 - INFO - training batch 101, loss: 0.146, 3232/28000 datapoints
2025-03-06 20:51:32,500 - INFO - training batch 151, loss: 0.360, 4832/28000 datapoints
2025-03-06 20:51:32,620 - INFO - training batch 201, loss: 0.114, 6432/28000 datapoints
2025-03-06 20:51:32,742 - INFO - training batch 251, loss: 0.338, 8032/28000 datapoints
2025-03-06 20:51:32,863 - INFO - training batch 301, loss: 0.583, 9632/28000 datapoints
2025-03-06 20:51:32,983 - INFO - training batch 351, loss: 0.263, 11232/28000 datapoints
2025-03-06 20:51:33,106 - INFO - training batch 401, loss: 0.546, 12832/28000 datapoints
2025-03-06 20:51:33,226 - INFO - training batch 451, loss: 0.261, 14432/28000 datapoints
2025-03-06 20:51:33,352 - INFO - training batch 501, loss: 0.159, 16032/28000 datapoints
2025-03-06 20:51:33,473 - INFO - training batch 551, loss: 0.246, 17632/28000 datapoints
2025-03-06 20:51:33,599 - INFO - training batch 601, loss: 0.336, 19232/28000 datapoints
2025-03-06 20:51:33,722 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 20:51:33,841 - INFO - training batch 701, loss: 0.264, 22432/28000 datapoints
2025-03-06 20:51:33,966 - INFO - training batch 751, loss: 0.237, 24032/28000 datapoints
2025-03-06 20:51:34,089 - INFO - training batch 801, loss: 0.122, 25632/28000 datapoints
2025-03-06 20:51:34,210 - INFO - training batch 851, loss: 0.453, 27232/28000 datapoints
2025-03-06 20:51:34,270 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:51:34,314 - INFO - validation batch 51, loss: 1.134, 1632/6976 datapoints
2025-03-06 20:51:34,357 - INFO - validation batch 101, loss: 0.316, 3232/6976 datapoints
2025-03-06 20:51:34,402 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-06 20:51:34,446 - INFO - validation batch 201, loss: 0.400, 6432/6976 datapoints
2025-03-06 20:51:34,461 - INFO - Epoch 343/800 done.
2025-03-06 20:51:34,461 - INFO - Final validation performance:
Loss: 0.472, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:51:34,461 - INFO - Beginning epoch 344/800
2025-03-06 20:51:34,465 - INFO - training batch 1, loss: 0.312, 32/28000 datapoints
2025-03-06 20:51:34,589 - INFO - training batch 51, loss: 0.105, 1632/28000 datapoints
2025-03-06 20:51:34,711 - INFO - training batch 101, loss: 0.145, 3232/28000 datapoints
2025-03-06 20:51:34,831 - INFO - training batch 151, loss: 0.356, 4832/28000 datapoints
2025-03-06 20:51:34,960 - INFO - training batch 201, loss: 0.114, 6432/28000 datapoints
2025-03-06 20:51:35,083 - INFO - training batch 251, loss: 0.337, 8032/28000 datapoints
2025-03-06 20:51:35,201 - INFO - training batch 301, loss: 0.581, 9632/28000 datapoints
2025-03-06 20:51:35,322 - INFO - training batch 351, loss: 0.261, 11232/28000 datapoints
2025-03-06 20:51:35,440 - INFO - training batch 401, loss: 0.544, 12832/28000 datapoints
2025-03-06 20:51:35,564 - INFO - training batch 451, loss: 0.261, 14432/28000 datapoints
2025-03-06 20:51:35,687 - INFO - training batch 501, loss: 0.159, 16032/28000 datapoints
2025-03-06 20:51:35,807 - INFO - training batch 551, loss: 0.245, 17632/28000 datapoints
2025-03-06 20:51:35,927 - INFO - training batch 601, loss: 0.333, 19232/28000 datapoints
2025-03-06 20:51:36,047 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 20:51:36,169 - INFO - training batch 701, loss: 0.264, 22432/28000 datapoints
2025-03-06 20:51:36,289 - INFO - training batch 751, loss: 0.236, 24032/28000 datapoints
2025-03-06 20:51:36,409 - INFO - training batch 801, loss: 0.121, 25632/28000 datapoints
2025-03-06 20:51:36,528 - INFO - training batch 851, loss: 0.451, 27232/28000 datapoints
2025-03-06 20:51:36,588 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:51:36,631 - INFO - validation batch 51, loss: 1.134, 1632/6976 datapoints
2025-03-06 20:51:36,678 - INFO - validation batch 101, loss: 0.317, 3232/6976 datapoints
2025-03-06 20:51:36,722 - INFO - validation batch 151, loss: 0.390, 4832/6976 datapoints
2025-03-06 20:51:36,766 - INFO - validation batch 201, loss: 0.400, 6432/6976 datapoints
2025-03-06 20:51:36,781 - INFO - Epoch 344/800 done.
2025-03-06 20:51:36,781 - INFO - Final validation performance:
Loss: 0.472, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:51:36,781 - INFO - Beginning epoch 345/800
2025-03-06 20:51:36,785 - INFO - training batch 1, loss: 0.312, 32/28000 datapoints
2025-03-06 20:51:36,908 - INFO - training batch 51, loss: 0.104, 1632/28000 datapoints
2025-03-06 20:51:37,029 - INFO - training batch 101, loss: 0.144, 3232/28000 datapoints
2025-03-06 20:51:37,170 - INFO - training batch 151, loss: 0.352, 4832/28000 datapoints
2025-03-06 20:51:37,290 - INFO - training batch 201, loss: 0.113, 6432/28000 datapoints
2025-03-06 20:51:37,409 - INFO - training batch 251, loss: 0.336, 8032/28000 datapoints
2025-03-06 20:51:37,528 - INFO - training batch 301, loss: 0.578, 9632/28000 datapoints
2025-03-06 20:51:37,683 - INFO - training batch 351, loss: 0.260, 11232/28000 datapoints
2025-03-06 20:51:37,807 - INFO - training batch 401, loss: 0.542, 12832/28000 datapoints
2025-03-06 20:51:37,928 - INFO - training batch 451, loss: 0.260, 14432/28000 datapoints
2025-03-06 20:51:38,053 - INFO - training batch 501, loss: 0.158, 16032/28000 datapoints
2025-03-06 20:51:38,175 - INFO - training batch 551, loss: 0.244, 17632/28000 datapoints
2025-03-06 20:51:38,296 - INFO - training batch 601, loss: 0.329, 19232/28000 datapoints
2025-03-06 20:51:38,417 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 20:51:38,542 - INFO - training batch 701, loss: 0.263, 22432/28000 datapoints
2025-03-06 20:51:38,667 - INFO - training batch 751, loss: 0.236, 24032/28000 datapoints
2025-03-06 20:51:38,785 - INFO - training batch 801, loss: 0.120, 25632/28000 datapoints
2025-03-06 20:51:38,905 - INFO - training batch 851, loss: 0.449, 27232/28000 datapoints
2025-03-06 20:51:38,966 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:51:39,011 - INFO - validation batch 51, loss: 1.134, 1632/6976 datapoints
2025-03-06 20:51:39,059 - INFO - validation batch 101, loss: 0.318, 3232/6976 datapoints
2025-03-06 20:51:39,104 - INFO - validation batch 151, loss: 0.390, 4832/6976 datapoints
2025-03-06 20:51:39,149 - INFO - validation batch 201, loss: 0.400, 6432/6976 datapoints
2025-03-06 20:51:39,165 - INFO - Epoch 345/800 done.
2025-03-06 20:51:39,165 - INFO - Final validation performance:
Loss: 0.473, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:51:39,166 - INFO - Beginning epoch 346/800
2025-03-06 20:51:39,169 - INFO - training batch 1, loss: 0.311, 32/28000 datapoints
2025-03-06 20:51:39,294 - INFO - training batch 51, loss: 0.104, 1632/28000 datapoints
2025-03-06 20:51:39,413 - INFO - training batch 101, loss: 0.144, 3232/28000 datapoints
2025-03-06 20:51:39,533 - INFO - training batch 151, loss: 0.348, 4832/28000 datapoints
2025-03-06 20:51:39,661 - INFO - training batch 201, loss: 0.112, 6432/28000 datapoints
2025-03-06 20:51:39,781 - INFO - training batch 251, loss: 0.336, 8032/28000 datapoints
2025-03-06 20:51:39,901 - INFO - training batch 301, loss: 0.577, 9632/28000 datapoints
2025-03-06 20:51:40,027 - INFO - training batch 351, loss: 0.259, 11232/28000 datapoints
2025-03-06 20:51:40,148 - INFO - training batch 401, loss: 0.541, 12832/28000 datapoints
2025-03-06 20:51:40,268 - INFO - training batch 451, loss: 0.260, 14432/28000 datapoints
2025-03-06 20:51:40,387 - INFO - training batch 501, loss: 0.158, 16032/28000 datapoints
2025-03-06 20:51:40,507 - INFO - training batch 551, loss: 0.243, 17632/28000 datapoints
2025-03-06 20:51:40,630 - INFO - training batch 601, loss: 0.326, 19232/28000 datapoints
2025-03-06 20:51:40,755 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 20:51:40,874 - INFO - training batch 701, loss: 0.262, 22432/28000 datapoints
2025-03-06 20:51:40,994 - INFO - training batch 751, loss: 0.235, 24032/28000 datapoints
2025-03-06 20:51:41,113 - INFO - training batch 801, loss: 0.120, 25632/28000 datapoints
2025-03-06 20:51:41,233 - INFO - training batch 851, loss: 0.447, 27232/28000 datapoints
2025-03-06 20:51:41,294 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:51:41,338 - INFO - validation batch 51, loss: 1.135, 1632/6976 datapoints
2025-03-06 20:51:41,382 - INFO - validation batch 101, loss: 0.319, 3232/6976 datapoints
2025-03-06 20:51:41,426 - INFO - validation batch 151, loss: 0.390, 4832/6976 datapoints
2025-03-06 20:51:41,469 - INFO - validation batch 201, loss: 0.400, 6432/6976 datapoints
2025-03-06 20:51:41,485 - INFO - Epoch 346/800 done.
2025-03-06 20:51:41,485 - INFO - Final validation performance:
Loss: 0.473, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:51:41,485 - INFO - Beginning epoch 347/800
2025-03-06 20:51:41,489 - INFO - training batch 1, loss: 0.310, 32/28000 datapoints
2025-03-06 20:51:41,614 - INFO - training batch 51, loss: 0.103, 1632/28000 datapoints
2025-03-06 20:51:41,741 - INFO - training batch 101, loss: 0.143, 3232/28000 datapoints
2025-03-06 20:51:41,884 - INFO - training batch 151, loss: 0.344, 4832/28000 datapoints
2025-03-06 20:51:42,008 - INFO - training batch 201, loss: 0.112, 6432/28000 datapoints
2025-03-06 20:51:42,127 - INFO - training batch 251, loss: 0.335, 8032/28000 datapoints
2025-03-06 20:51:42,247 - INFO - training batch 301, loss: 0.575, 9632/28000 datapoints
2025-03-06 20:51:42,366 - INFO - training batch 351, loss: 0.258, 11232/28000 datapoints
2025-03-06 20:51:42,483 - INFO - training batch 401, loss: 0.540, 12832/28000 datapoints
2025-03-06 20:51:42,603 - INFO - training batch 451, loss: 0.260, 14432/28000 datapoints
2025-03-06 20:51:42,728 - INFO - training batch 501, loss: 0.158, 16032/28000 datapoints
2025-03-06 20:51:42,849 - INFO - training batch 551, loss: 0.242, 17632/28000 datapoints
2025-03-06 20:51:42,981 - INFO - training batch 601, loss: 0.323, 19232/28000 datapoints
2025-03-06 20:51:43,103 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-06 20:51:43,230 - INFO - training batch 701, loss: 0.261, 22432/28000 datapoints
2025-03-06 20:51:43,356 - INFO - training batch 751, loss: 0.234, 24032/28000 datapoints
2025-03-06 20:51:43,475 - INFO - training batch 801, loss: 0.119, 25632/28000 datapoints
2025-03-06 20:51:43,600 - INFO - training batch 851, loss: 0.446, 27232/28000 datapoints
2025-03-06 20:51:43,670 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:51:43,714 - INFO - validation batch 51, loss: 1.135, 1632/6976 datapoints
2025-03-06 20:51:43,758 - INFO - validation batch 101, loss: 0.320, 3232/6976 datapoints
2025-03-06 20:51:43,804 - INFO - validation batch 151, loss: 0.390, 4832/6976 datapoints
2025-03-06 20:51:43,849 - INFO - validation batch 201, loss: 0.400, 6432/6976 datapoints
2025-03-06 20:51:43,864 - INFO - Epoch 347/800 done.
2025-03-06 20:51:43,864 - INFO - Final validation performance:
Loss: 0.473, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:51:43,864 - INFO - Beginning epoch 348/800
2025-03-06 20:51:43,868 - INFO - training batch 1, loss: 0.309, 32/28000 datapoints
2025-03-06 20:51:43,994 - INFO - training batch 51, loss: 0.103, 1632/28000 datapoints
2025-03-06 20:51:44,113 - INFO - training batch 101, loss: 0.142, 3232/28000 datapoints
2025-03-06 20:51:44,236 - INFO - training batch 151, loss: 0.341, 4832/28000 datapoints
2025-03-06 20:51:44,357 - INFO - training batch 201, loss: 0.111, 6432/28000 datapoints
2025-03-06 20:51:44,476 - INFO - training batch 251, loss: 0.334, 8032/28000 datapoints
2025-03-06 20:51:44,595 - INFO - training batch 301, loss: 0.573, 9632/28000 datapoints
2025-03-06 20:51:44,718 - INFO - training batch 351, loss: 0.257, 11232/28000 datapoints
2025-03-06 20:51:44,837 - INFO - training batch 401, loss: 0.538, 12832/28000 datapoints
2025-03-06 20:51:44,962 - INFO - training batch 451, loss: 0.259, 14432/28000 datapoints
2025-03-06 20:51:45,083 - INFO - training batch 501, loss: 0.157, 16032/28000 datapoints
2025-03-06 20:51:45,204 - INFO - training batch 551, loss: 0.241, 17632/28000 datapoints
2025-03-06 20:51:45,325 - INFO - training batch 601, loss: 0.320, 19232/28000 datapoints
2025-03-06 20:51:45,447 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-06 20:51:45,568 - INFO - training batch 701, loss: 0.261, 22432/28000 datapoints
2025-03-06 20:51:45,705 - INFO - training batch 751, loss: 0.234, 24032/28000 datapoints
2025-03-06 20:51:45,824 - INFO - training batch 801, loss: 0.119, 25632/28000 datapoints
2025-03-06 20:51:45,945 - INFO - training batch 851, loss: 0.442, 27232/28000 datapoints
2025-03-06 20:51:46,005 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:51:46,048 - INFO - validation batch 51, loss: 1.136, 1632/6976 datapoints
2025-03-06 20:51:46,092 - INFO - validation batch 101, loss: 0.321, 3232/6976 datapoints
2025-03-06 20:51:46,135 - INFO - validation batch 151, loss: 0.391, 4832/6976 datapoints
2025-03-06 20:51:46,179 - INFO - validation batch 201, loss: 0.400, 6432/6976 datapoints
2025-03-06 20:51:46,195 - INFO - Epoch 348/800 done.
2025-03-06 20:51:46,197 - INFO - Final validation performance:
Loss: 0.474, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:51:46,197 - INFO - Beginning epoch 349/800
2025-03-06 20:51:46,201 - INFO - training batch 1, loss: 0.309, 32/28000 datapoints
2025-03-06 20:51:46,321 - INFO - training batch 51, loss: 0.102, 1632/28000 datapoints
2025-03-06 20:51:46,441 - INFO - training batch 101, loss: 0.141, 3232/28000 datapoints
2025-03-06 20:51:46,561 - INFO - training batch 151, loss: 0.336, 4832/28000 datapoints
2025-03-06 20:51:46,684 - INFO - training batch 201, loss: 0.111, 6432/28000 datapoints
2025-03-06 20:51:46,807 - INFO - training batch 251, loss: 0.333, 8032/28000 datapoints
2025-03-06 20:51:46,929 - INFO - training batch 301, loss: 0.571, 9632/28000 datapoints
2025-03-06 20:51:47,050 - INFO - training batch 351, loss: 0.256, 11232/28000 datapoints
2025-03-06 20:51:47,169 - INFO - training batch 401, loss: 0.537, 12832/28000 datapoints
2025-03-06 20:51:47,297 - INFO - training batch 451, loss: 0.259, 14432/28000 datapoints
2025-03-06 20:51:47,419 - INFO - training batch 501, loss: 0.157, 16032/28000 datapoints
2025-03-06 20:51:47,543 - INFO - training batch 551, loss: 0.241, 17632/28000 datapoints
2025-03-06 20:51:47,676 - INFO - training batch 601, loss: 0.318, 19232/28000 datapoints
2025-03-06 20:51:47,818 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-06 20:51:47,943 - INFO - training batch 701, loss: 0.260, 22432/28000 datapoints
2025-03-06 20:51:48,068 - INFO - training batch 751, loss: 0.233, 24032/28000 datapoints
2025-03-06 20:51:48,192 - INFO - training batch 801, loss: 0.118, 25632/28000 datapoints
2025-03-06 20:51:48,317 - INFO - training batch 851, loss: 0.441, 27232/28000 datapoints
2025-03-06 20:51:48,380 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 20:51:48,427 - INFO - validation batch 51, loss: 1.136, 1632/6976 datapoints
2025-03-06 20:51:48,472 - INFO - validation batch 101, loss: 0.322, 3232/6976 datapoints
2025-03-06 20:51:48,516 - INFO - validation batch 151, loss: 0.391, 4832/6976 datapoints
2025-03-06 20:51:48,560 - INFO - validation batch 201, loss: 0.400, 6432/6976 datapoints
2025-03-06 20:51:48,577 - INFO - Epoch 349/800 done.
2025-03-06 20:51:48,577 - INFO - Final validation performance:
Loss: 0.474, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:51:48,578 - INFO - Beginning epoch 350/800
2025-03-06 20:51:48,581 - INFO - training batch 1, loss: 0.308, 32/28000 datapoints
2025-03-06 20:51:48,704 - INFO - training batch 51, loss: 0.101, 1632/28000 datapoints
2025-03-06 20:51:48,828 - INFO - training batch 101, loss: 0.140, 3232/28000 datapoints
2025-03-06 20:51:48,950 - INFO - training batch 151, loss: 0.332, 4832/28000 datapoints
2025-03-06 20:51:49,075 - INFO - training batch 201, loss: 0.109, 6432/28000 datapoints
2025-03-06 20:51:49,199 - INFO - training batch 251, loss: 0.333, 8032/28000 datapoints
2025-03-06 20:51:49,322 - INFO - training batch 301, loss: 0.570, 9632/28000 datapoints
2025-03-06 20:51:49,456 - INFO - training batch 351, loss: 0.254, 11232/28000 datapoints
2025-03-06 20:51:49,575 - INFO - training batch 401, loss: 0.536, 12832/28000 datapoints
2025-03-06 20:51:49,702 - INFO - training batch 451, loss: 0.258, 14432/28000 datapoints
2025-03-06 20:51:49,831 - INFO - training batch 501, loss: 0.156, 16032/28000 datapoints
2025-03-06 20:51:49,957 - INFO - training batch 551, loss: 0.240, 17632/28000 datapoints
2025-03-06 20:51:50,079 - INFO - training batch 601, loss: 0.315, 19232/28000 datapoints
2025-03-06 20:51:50,241 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 20:51:50,366 - INFO - training batch 701, loss: 0.260, 22432/28000 datapoints
2025-03-06 20:51:50,487 - INFO - training batch 751, loss: 0.231, 24032/28000 datapoints
2025-03-06 20:51:50,606 - INFO - training batch 801, loss: 0.118, 25632/28000 datapoints
2025-03-06 20:51:50,731 - INFO - training batch 851, loss: 0.439, 27232/28000 datapoints
2025-03-06 20:51:50,791 - INFO - validation batch 1, loss: 0.122, 32/6976 datapoints
2025-03-06 20:51:50,837 - INFO - validation batch 51, loss: 1.137, 1632/6976 datapoints
2025-03-06 20:51:50,880 - INFO - validation batch 101, loss: 0.323, 3232/6976 datapoints
2025-03-06 20:51:50,924 - INFO - validation batch 151, loss: 0.392, 4832/6976 datapoints
2025-03-06 20:51:50,968 - INFO - validation batch 201, loss: 0.401, 6432/6976 datapoints
2025-03-06 20:51:50,983 - INFO - Epoch 350/800 done.
2025-03-06 20:51:50,983 - INFO - Final validation performance:
Loss: 0.475, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:51:50,984 - INFO - Beginning epoch 351/800
2025-03-06 20:51:50,988 - INFO - training batch 1, loss: 0.307, 32/28000 datapoints
2025-03-06 20:51:51,112 - INFO - training batch 51, loss: 0.101, 1632/28000 datapoints
2025-03-06 20:51:51,230 - INFO - training batch 101, loss: 0.140, 3232/28000 datapoints
2025-03-06 20:51:51,353 - INFO - training batch 151, loss: 0.328, 4832/28000 datapoints
2025-03-06 20:51:51,473 - INFO - training batch 201, loss: 0.109, 6432/28000 datapoints
2025-03-06 20:51:51,591 - INFO - training batch 251, loss: 0.332, 8032/28000 datapoints
2025-03-06 20:51:51,720 - INFO - training batch 301, loss: 0.568, 9632/28000 datapoints
2025-03-06 20:51:51,841 - INFO - training batch 351, loss: 0.253, 11232/28000 datapoints
2025-03-06 20:51:51,991 - INFO - training batch 401, loss: 0.534, 12832/28000 datapoints
2025-03-06 20:51:52,113 - INFO - training batch 451, loss: 0.258, 14432/28000 datapoints
2025-03-06 20:51:52,232 - INFO - training batch 501, loss: 0.156, 16032/28000 datapoints
2025-03-06 20:51:52,355 - INFO - training batch 551, loss: 0.239, 17632/28000 datapoints
2025-03-06 20:51:52,475 - INFO - training batch 601, loss: 0.313, 19232/28000 datapoints
2025-03-06 20:51:52,594 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 20:51:52,715 - INFO - training batch 701, loss: 0.259, 22432/28000 datapoints
2025-03-06 20:51:52,835 - INFO - training batch 751, loss: 0.230, 24032/28000 datapoints
2025-03-06 20:51:52,955 - INFO - training batch 801, loss: 0.117, 25632/28000 datapoints
2025-03-06 20:51:53,074 - INFO - training batch 851, loss: 0.436, 27232/28000 datapoints
2025-03-06 20:51:53,134 - INFO - validation batch 1, loss: 0.122, 32/6976 datapoints
2025-03-06 20:51:53,178 - INFO - validation batch 51, loss: 1.138, 1632/6976 datapoints
2025-03-06 20:51:53,221 - INFO - validation batch 101, loss: 0.324, 3232/6976 datapoints
2025-03-06 20:51:53,266 - INFO - validation batch 151, loss: 0.392, 4832/6976 datapoints
2025-03-06 20:51:53,312 - INFO - validation batch 201, loss: 0.401, 6432/6976 datapoints
2025-03-06 20:51:53,327 - INFO - Epoch 351/800 done.
2025-03-06 20:51:53,327 - INFO - Final validation performance:
Loss: 0.475, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:51:53,328 - INFO - Beginning epoch 352/800
2025-03-06 20:51:53,331 - INFO - training batch 1, loss: 0.306, 32/28000 datapoints
2025-03-06 20:51:53,453 - INFO - training batch 51, loss: 0.100, 1632/28000 datapoints
2025-03-06 20:51:53,574 - INFO - training batch 101, loss: 0.139, 3232/28000 datapoints
2025-03-06 20:51:53,699 - INFO - training batch 151, loss: 0.325, 4832/28000 datapoints
2025-03-06 20:51:53,823 - INFO - training batch 201, loss: 0.108, 6432/28000 datapoints
2025-03-06 20:51:53,945 - INFO - training batch 251, loss: 0.332, 8032/28000 datapoints
2025-03-06 20:51:54,067 - INFO - training batch 301, loss: 0.565, 9632/28000 datapoints
2025-03-06 20:51:54,189 - INFO - training batch 351, loss: 0.253, 11232/28000 datapoints
2025-03-06 20:51:54,311 - INFO - training batch 401, loss: 0.533, 12832/28000 datapoints
2025-03-06 20:51:54,430 - INFO - training batch 451, loss: 0.258, 14432/28000 datapoints
2025-03-06 20:51:54,550 - INFO - training batch 501, loss: 0.156, 16032/28000 datapoints
2025-03-06 20:51:54,674 - INFO - training batch 551, loss: 0.238, 17632/28000 datapoints
2025-03-06 20:51:54,794 - INFO - training batch 601, loss: 0.310, 19232/28000 datapoints
2025-03-06 20:51:54,923 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 20:51:55,045 - INFO - training batch 701, loss: 0.259, 22432/28000 datapoints
2025-03-06 20:51:55,166 - INFO - training batch 751, loss: 0.229, 24032/28000 datapoints
2025-03-06 20:51:55,285 - INFO - training batch 801, loss: 0.116, 25632/28000 datapoints
2025-03-06 20:51:55,408 - INFO - training batch 851, loss: 0.434, 27232/28000 datapoints
2025-03-06 20:51:55,469 - INFO - validation batch 1, loss: 0.123, 32/6976 datapoints
2025-03-06 20:51:55,525 - INFO - validation batch 51, loss: 1.139, 1632/6976 datapoints
2025-03-06 20:51:55,575 - INFO - validation batch 101, loss: 0.325, 3232/6976 datapoints
2025-03-06 20:51:55,619 - INFO - validation batch 151, loss: 0.393, 4832/6976 datapoints
2025-03-06 20:51:55,670 - INFO - validation batch 201, loss: 0.401, 6432/6976 datapoints
2025-03-06 20:51:55,685 - INFO - Epoch 352/800 done.
2025-03-06 20:51:55,685 - INFO - Final validation performance:
Loss: 0.476, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:51:55,685 - INFO - Beginning epoch 353/800
2025-03-06 20:51:55,689 - INFO - training batch 1, loss: 0.306, 32/28000 datapoints
2025-03-06 20:51:55,812 - INFO - training batch 51, loss: 0.100, 1632/28000 datapoints
2025-03-06 20:51:55,939 - INFO - training batch 101, loss: 0.139, 3232/28000 datapoints
2025-03-06 20:51:56,062 - INFO - training batch 151, loss: 0.321, 4832/28000 datapoints
2025-03-06 20:51:56,182 - INFO - training batch 201, loss: 0.108, 6432/28000 datapoints
2025-03-06 20:51:56,302 - INFO - training batch 251, loss: 0.331, 8032/28000 datapoints
2025-03-06 20:51:56,422 - INFO - training batch 301, loss: 0.564, 9632/28000 datapoints
2025-03-06 20:51:56,541 - INFO - training batch 351, loss: 0.252, 11232/28000 datapoints
2025-03-06 20:51:56,664 - INFO - training batch 401, loss: 0.531, 12832/28000 datapoints
2025-03-06 20:51:56,784 - INFO - training batch 451, loss: 0.257, 14432/28000 datapoints
2025-03-06 20:51:56,906 - INFO - training batch 501, loss: 0.156, 16032/28000 datapoints
2025-03-06 20:51:57,026 - INFO - training batch 551, loss: 0.238, 17632/28000 datapoints
2025-03-06 20:51:57,148 - INFO - training batch 601, loss: 0.307, 19232/28000 datapoints
2025-03-06 20:51:57,267 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 20:51:57,389 - INFO - training batch 701, loss: 0.258, 22432/28000 datapoints
2025-03-06 20:51:57,509 - INFO - training batch 751, loss: 0.229, 24032/28000 datapoints
2025-03-06 20:51:57,628 - INFO - training batch 801, loss: 0.116, 25632/28000 datapoints
2025-03-06 20:51:57,756 - INFO - training batch 851, loss: 0.433, 27232/28000 datapoints
2025-03-06 20:51:57,815 - INFO - validation batch 1, loss: 0.123, 32/6976 datapoints
2025-03-06 20:51:57,861 - INFO - validation batch 51, loss: 1.139, 1632/6976 datapoints
2025-03-06 20:51:57,905 - INFO - validation batch 101, loss: 0.326, 3232/6976 datapoints
2025-03-06 20:51:57,950 - INFO - validation batch 151, loss: 0.393, 4832/6976 datapoints
2025-03-06 20:51:57,994 - INFO - validation batch 201, loss: 0.401, 6432/6976 datapoints
2025-03-06 20:51:58,009 - INFO - Epoch 353/800 done.
2025-03-06 20:51:58,010 - INFO - Final validation performance:
Loss: 0.476, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:51:58,010 - INFO - Beginning epoch 354/800
2025-03-06 20:51:58,014 - INFO - training batch 1, loss: 0.305, 32/28000 datapoints
2025-03-06 20:51:58,135 - INFO - training batch 51, loss: 0.099, 1632/28000 datapoints
2025-03-06 20:51:58,255 - INFO - training batch 101, loss: 0.138, 3232/28000 datapoints
2025-03-06 20:51:58,378 - INFO - training batch 151, loss: 0.317, 4832/28000 datapoints
2025-03-06 20:51:58,498 - INFO - training batch 201, loss: 0.107, 6432/28000 datapoints
2025-03-06 20:51:58,622 - INFO - training batch 251, loss: 0.330, 8032/28000 datapoints
2025-03-06 20:51:58,743 - INFO - training batch 301, loss: 0.562, 9632/28000 datapoints
2025-03-06 20:51:58,864 - INFO - training batch 351, loss: 0.251, 11232/28000 datapoints
2025-03-06 20:51:58,986 - INFO - training batch 401, loss: 0.530, 12832/28000 datapoints
2025-03-06 20:51:59,107 - INFO - training batch 451, loss: 0.257, 14432/28000 datapoints
2025-03-06 20:51:59,227 - INFO - training batch 501, loss: 0.155, 16032/28000 datapoints
2025-03-06 20:51:59,346 - INFO - training batch 551, loss: 0.237, 17632/28000 datapoints
2025-03-06 20:51:59,469 - INFO - training batch 601, loss: 0.304, 19232/28000 datapoints
2025-03-06 20:51:59,587 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 20:51:59,714 - INFO - training batch 701, loss: 0.258, 22432/28000 datapoints
2025-03-06 20:51:59,833 - INFO - training batch 751, loss: 0.228, 24032/28000 datapoints
2025-03-06 20:51:59,954 - INFO - training batch 801, loss: 0.116, 25632/28000 datapoints
2025-03-06 20:52:00,077 - INFO - training batch 851, loss: 0.430, 27232/28000 datapoints
2025-03-06 20:52:00,137 - INFO - validation batch 1, loss: 0.123, 32/6976 datapoints
2025-03-06 20:52:00,180 - INFO - validation batch 51, loss: 1.140, 1632/6976 datapoints
2025-03-06 20:52:00,223 - INFO - validation batch 101, loss: 0.327, 3232/6976 datapoints
2025-03-06 20:52:00,269 - INFO - validation batch 151, loss: 0.394, 4832/6976 datapoints
2025-03-06 20:52:00,312 - INFO - validation batch 201, loss: 0.403, 6432/6976 datapoints
2025-03-06 20:52:00,328 - INFO - Epoch 354/800 done.
2025-03-06 20:52:00,328 - INFO - Final validation performance:
Loss: 0.478, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:00,329 - INFO - Beginning epoch 355/800
2025-03-06 20:52:00,332 - INFO - training batch 1, loss: 0.305, 32/28000 datapoints
2025-03-06 20:52:00,455 - INFO - training batch 51, loss: 0.098, 1632/28000 datapoints
2025-03-06 20:52:00,577 - INFO - training batch 101, loss: 0.137, 3232/28000 datapoints
2025-03-06 20:52:00,702 - INFO - training batch 151, loss: 0.313, 4832/28000 datapoints
2025-03-06 20:52:00,821 - INFO - training batch 201, loss: 0.107, 6432/28000 datapoints
2025-03-06 20:52:00,942 - INFO - training batch 251, loss: 0.330, 8032/28000 datapoints
2025-03-06 20:52:01,063 - INFO - training batch 301, loss: 0.560, 9632/28000 datapoints
2025-03-06 20:52:01,184 - INFO - training batch 351, loss: 0.250, 11232/28000 datapoints
2025-03-06 20:52:01,304 - INFO - training batch 401, loss: 0.529, 12832/28000 datapoints
2025-03-06 20:52:01,424 - INFO - training batch 451, loss: 0.256, 14432/28000 datapoints
2025-03-06 20:52:01,544 - INFO - training batch 501, loss: 0.155, 16032/28000 datapoints
2025-03-06 20:52:01,669 - INFO - training batch 551, loss: 0.236, 17632/28000 datapoints
2025-03-06 20:52:01,794 - INFO - training batch 601, loss: 0.301, 19232/28000 datapoints
2025-03-06 20:52:01,918 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 20:52:02,062 - INFO - training batch 701, loss: 0.257, 22432/28000 datapoints
2025-03-06 20:52:02,184 - INFO - training batch 751, loss: 0.227, 24032/28000 datapoints
2025-03-06 20:52:02,302 - INFO - training batch 801, loss: 0.115, 25632/28000 datapoints
2025-03-06 20:52:02,423 - INFO - training batch 851, loss: 0.428, 27232/28000 datapoints
2025-03-06 20:52:02,483 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 20:52:02,527 - INFO - validation batch 51, loss: 1.141, 1632/6976 datapoints
2025-03-06 20:52:02,573 - INFO - validation batch 101, loss: 0.329, 3232/6976 datapoints
2025-03-06 20:52:02,618 - INFO - validation batch 151, loss: 0.395, 4832/6976 datapoints
2025-03-06 20:52:02,666 - INFO - validation batch 201, loss: 0.403, 6432/6976 datapoints
2025-03-06 20:52:02,699 - INFO - Epoch 355/800 done.
2025-03-06 20:52:02,705 - INFO - Final validation performance:
Loss: 0.478, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:02,706 - INFO - Beginning epoch 356/800
2025-03-06 20:52:02,709 - INFO - training batch 1, loss: 0.304, 32/28000 datapoints
2025-03-06 20:52:02,847 - INFO - training batch 51, loss: 0.098, 1632/28000 datapoints
2025-03-06 20:52:02,976 - INFO - training batch 101, loss: 0.137, 3232/28000 datapoints
2025-03-06 20:52:03,099 - INFO - training batch 151, loss: 0.310, 4832/28000 datapoints
2025-03-06 20:52:03,219 - INFO - training batch 201, loss: 0.106, 6432/28000 datapoints
2025-03-06 20:52:03,340 - INFO - training batch 251, loss: 0.329, 8032/28000 datapoints
2025-03-06 20:52:03,461 - INFO - training batch 301, loss: 0.557, 9632/28000 datapoints
2025-03-06 20:52:03,579 - INFO - training batch 351, loss: 0.249, 11232/28000 datapoints
2025-03-06 20:52:03,704 - INFO - training batch 401, loss: 0.526, 12832/28000 datapoints
2025-03-06 20:52:03,828 - INFO - training batch 451, loss: 0.256, 14432/28000 datapoints
2025-03-06 20:52:03,950 - INFO - training batch 501, loss: 0.154, 16032/28000 datapoints
2025-03-06 20:52:04,073 - INFO - training batch 551, loss: 0.235, 17632/28000 datapoints
2025-03-06 20:52:04,194 - INFO - training batch 601, loss: 0.298, 19232/28000 datapoints
2025-03-06 20:52:04,314 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 20:52:04,480 - INFO - training batch 701, loss: 0.256, 22432/28000 datapoints
2025-03-06 20:52:04,600 - INFO - training batch 751, loss: 0.226, 24032/28000 datapoints
2025-03-06 20:52:04,722 - INFO - training batch 801, loss: 0.115, 25632/28000 datapoints
2025-03-06 20:52:04,843 - INFO - training batch 851, loss: 0.427, 27232/28000 datapoints
2025-03-06 20:52:04,902 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 20:52:04,954 - INFO - validation batch 51, loss: 1.141, 1632/6976 datapoints
2025-03-06 20:52:04,999 - INFO - validation batch 101, loss: 0.330, 3232/6976 datapoints
2025-03-06 20:52:05,042 - INFO - validation batch 151, loss: 0.395, 4832/6976 datapoints
2025-03-06 20:52:05,087 - INFO - validation batch 201, loss: 0.403, 6432/6976 datapoints
2025-03-06 20:52:05,102 - INFO - Epoch 356/800 done.
2025-03-06 20:52:05,102 - INFO - Final validation performance:
Loss: 0.479, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:05,103 - INFO - Beginning epoch 357/800
2025-03-06 20:52:05,106 - INFO - training batch 1, loss: 0.303, 32/28000 datapoints
2025-03-06 20:52:05,226 - INFO - training batch 51, loss: 0.097, 1632/28000 datapoints
2025-03-06 20:52:05,346 - INFO - training batch 101, loss: 0.136, 3232/28000 datapoints
2025-03-06 20:52:05,468 - INFO - training batch 151, loss: 0.308, 4832/28000 datapoints
2025-03-06 20:52:05,590 - INFO - training batch 201, loss: 0.105, 6432/28000 datapoints
2025-03-06 20:52:05,716 - INFO - training batch 251, loss: 0.328, 8032/28000 datapoints
2025-03-06 20:52:05,836 - INFO - training batch 301, loss: 0.556, 9632/28000 datapoints
2025-03-06 20:52:05,954 - INFO - training batch 351, loss: 0.248, 11232/28000 datapoints
2025-03-06 20:52:06,074 - INFO - training batch 401, loss: 0.525, 12832/28000 datapoints
2025-03-06 20:52:06,194 - INFO - training batch 451, loss: 0.255, 14432/28000 datapoints
2025-03-06 20:52:06,315 - INFO - training batch 501, loss: 0.154, 16032/28000 datapoints
2025-03-06 20:52:06,435 - INFO - training batch 551, loss: 0.234, 17632/28000 datapoints
2025-03-06 20:52:06,557 - INFO - training batch 601, loss: 0.296, 19232/28000 datapoints
2025-03-06 20:52:06,680 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 20:52:06,802 - INFO - training batch 701, loss: 0.256, 22432/28000 datapoints
2025-03-06 20:52:06,922 - INFO - training batch 751, loss: 0.224, 24032/28000 datapoints
2025-03-06 20:52:07,042 - INFO - training batch 801, loss: 0.114, 25632/28000 datapoints
2025-03-06 20:52:07,163 - INFO - training batch 851, loss: 0.424, 27232/28000 datapoints
2025-03-06 20:52:07,222 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 20:52:07,266 - INFO - validation batch 51, loss: 1.143, 1632/6976 datapoints
2025-03-06 20:52:07,309 - INFO - validation batch 101, loss: 0.331, 3232/6976 datapoints
2025-03-06 20:52:07,352 - INFO - validation batch 151, loss: 0.396, 4832/6976 datapoints
2025-03-06 20:52:07,397 - INFO - validation batch 201, loss: 0.403, 6432/6976 datapoints
2025-03-06 20:52:07,413 - INFO - Epoch 357/800 done.
2025-03-06 20:52:07,413 - INFO - Final validation performance:
Loss: 0.479, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:07,413 - INFO - Beginning epoch 358/800
2025-03-06 20:52:07,416 - INFO - training batch 1, loss: 0.303, 32/28000 datapoints
2025-03-06 20:52:07,545 - INFO - training batch 51, loss: 0.097, 1632/28000 datapoints
2025-03-06 20:52:07,677 - INFO - training batch 101, loss: 0.136, 3232/28000 datapoints
2025-03-06 20:52:07,806 - INFO - training batch 151, loss: 0.304, 4832/28000 datapoints
2025-03-06 20:52:07,932 - INFO - training batch 201, loss: 0.105, 6432/28000 datapoints
2025-03-06 20:52:08,059 - INFO - training batch 251, loss: 0.327, 8032/28000 datapoints
2025-03-06 20:52:08,187 - INFO - training batch 301, loss: 0.553, 9632/28000 datapoints
2025-03-06 20:52:08,311 - INFO - training batch 351, loss: 0.247, 11232/28000 datapoints
2025-03-06 20:52:08,435 - INFO - training batch 401, loss: 0.523, 12832/28000 datapoints
2025-03-06 20:52:08,558 - INFO - training batch 451, loss: 0.254, 14432/28000 datapoints
2025-03-06 20:52:08,686 - INFO - training batch 501, loss: 0.154, 16032/28000 datapoints
2025-03-06 20:52:08,811 - INFO - training batch 551, loss: 0.232, 17632/28000 datapoints
2025-03-06 20:52:08,936 - INFO - training batch 601, loss: 0.293, 19232/28000 datapoints
2025-03-06 20:52:09,065 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 20:52:09,189 - INFO - training batch 701, loss: 0.255, 22432/28000 datapoints
2025-03-06 20:52:09,315 - INFO - training batch 751, loss: 0.224, 24032/28000 datapoints
2025-03-06 20:52:09,439 - INFO - training batch 801, loss: 0.114, 25632/28000 datapoints
2025-03-06 20:52:09,563 - INFO - training batch 851, loss: 0.422, 27232/28000 datapoints
2025-03-06 20:52:09,627 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 20:52:09,678 - INFO - validation batch 51, loss: 1.143, 1632/6976 datapoints
2025-03-06 20:52:09,727 - INFO - validation batch 101, loss: 0.332, 3232/6976 datapoints
2025-03-06 20:52:09,770 - INFO - validation batch 151, loss: 0.396, 4832/6976 datapoints
2025-03-06 20:52:09,814 - INFO - validation batch 201, loss: 0.402, 6432/6976 datapoints
2025-03-06 20:52:09,829 - INFO - Epoch 358/800 done.
2025-03-06 20:52:09,829 - INFO - Final validation performance:
Loss: 0.480, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:09,829 - INFO - Beginning epoch 359/800
2025-03-06 20:52:09,833 - INFO - training batch 1, loss: 0.302, 32/28000 datapoints
2025-03-06 20:52:09,956 - INFO - training batch 51, loss: 0.096, 1632/28000 datapoints
2025-03-06 20:52:10,082 - INFO - training batch 101, loss: 0.135, 3232/28000 datapoints
2025-03-06 20:52:10,204 - INFO - training batch 151, loss: 0.301, 4832/28000 datapoints
2025-03-06 20:52:10,323 - INFO - training batch 201, loss: 0.104, 6432/28000 datapoints
2025-03-06 20:52:10,444 - INFO - training batch 251, loss: 0.326, 8032/28000 datapoints
2025-03-06 20:52:10,565 - INFO - training batch 301, loss: 0.552, 9632/28000 datapoints
2025-03-06 20:52:10,687 - INFO - training batch 351, loss: 0.246, 11232/28000 datapoints
2025-03-06 20:52:10,810 - INFO - training batch 401, loss: 0.521, 12832/28000 datapoints
2025-03-06 20:52:10,930 - INFO - training batch 451, loss: 0.254, 14432/28000 datapoints
2025-03-06 20:52:11,051 - INFO - training batch 501, loss: 0.154, 16032/28000 datapoints
2025-03-06 20:52:11,175 - INFO - training batch 551, loss: 0.232, 17632/28000 datapoints
2025-03-06 20:52:11,295 - INFO - training batch 601, loss: 0.290, 19232/28000 datapoints
2025-03-06 20:52:11,416 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 20:52:11,537 - INFO - training batch 701, loss: 0.254, 22432/28000 datapoints
2025-03-06 20:52:11,659 - INFO - training batch 751, loss: 0.224, 24032/28000 datapoints
2025-03-06 20:52:11,784 - INFO - training batch 801, loss: 0.113, 25632/28000 datapoints
2025-03-06 20:52:11,905 - INFO - training batch 851, loss: 0.421, 27232/28000 datapoints
2025-03-06 20:52:11,963 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 20:52:12,007 - INFO - validation batch 51, loss: 1.143, 1632/6976 datapoints
2025-03-06 20:52:12,053 - INFO - validation batch 101, loss: 0.333, 3232/6976 datapoints
2025-03-06 20:52:12,118 - INFO - validation batch 151, loss: 0.397, 4832/6976 datapoints
2025-03-06 20:52:12,170 - INFO - validation batch 201, loss: 0.403, 6432/6976 datapoints
2025-03-06 20:52:12,190 - INFO - Epoch 359/800 done.
2025-03-06 20:52:12,190 - INFO - Final validation performance:
Loss: 0.480, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:12,191 - INFO - Beginning epoch 360/800
2025-03-06 20:52:12,194 - INFO - training batch 1, loss: 0.302, 32/28000 datapoints
2025-03-06 20:52:12,314 - INFO - training batch 51, loss: 0.096, 1632/28000 datapoints
2025-03-06 20:52:12,435 - INFO - training batch 101, loss: 0.134, 3232/28000 datapoints
2025-03-06 20:52:12,556 - INFO - training batch 151, loss: 0.297, 4832/28000 datapoints
2025-03-06 20:52:12,681 - INFO - training batch 201, loss: 0.103, 6432/28000 datapoints
2025-03-06 20:52:12,799 - INFO - training batch 251, loss: 0.326, 8032/28000 datapoints
2025-03-06 20:52:12,919 - INFO - training batch 301, loss: 0.549, 9632/28000 datapoints
2025-03-06 20:52:13,038 - INFO - training batch 351, loss: 0.245, 11232/28000 datapoints
2025-03-06 20:52:13,161 - INFO - training batch 401, loss: 0.520, 12832/28000 datapoints
2025-03-06 20:52:13,282 - INFO - training batch 451, loss: 0.254, 14432/28000 datapoints
2025-03-06 20:52:13,402 - INFO - training batch 501, loss: 0.153, 16032/28000 datapoints
2025-03-06 20:52:13,523 - INFO - training batch 551, loss: 0.232, 17632/28000 datapoints
2025-03-06 20:52:13,649 - INFO - training batch 601, loss: 0.288, 19232/28000 datapoints
2025-03-06 20:52:13,774 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 20:52:13,898 - INFO - training batch 701, loss: 0.254, 22432/28000 datapoints
2025-03-06 20:52:14,018 - INFO - training batch 751, loss: 0.222, 24032/28000 datapoints
2025-03-06 20:52:14,141 - INFO - training batch 801, loss: 0.113, 25632/28000 datapoints
2025-03-06 20:52:14,262 - INFO - training batch 851, loss: 0.417, 27232/28000 datapoints
2025-03-06 20:52:14,322 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 20:52:14,367 - INFO - validation batch 51, loss: 1.145, 1632/6976 datapoints
2025-03-06 20:52:14,411 - INFO - validation batch 101, loss: 0.334, 3232/6976 datapoints
2025-03-06 20:52:14,456 - INFO - validation batch 151, loss: 0.398, 4832/6976 datapoints
2025-03-06 20:52:14,500 - INFO - validation batch 201, loss: 0.403, 6432/6976 datapoints
2025-03-06 20:52:14,515 - INFO - Epoch 360/800 done.
2025-03-06 20:52:14,515 - INFO - Final validation performance:
Loss: 0.481, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:14,515 - INFO - Beginning epoch 361/800
2025-03-06 20:52:14,519 - INFO - training batch 1, loss: 0.301, 32/28000 datapoints
2025-03-06 20:52:14,646 - INFO - training batch 51, loss: 0.095, 1632/28000 datapoints
2025-03-06 20:52:14,766 - INFO - training batch 101, loss: 0.134, 3232/28000 datapoints
2025-03-06 20:52:14,887 - INFO - training batch 151, loss: 0.294, 4832/28000 datapoints
2025-03-06 20:52:15,015 - INFO - training batch 201, loss: 0.103, 6432/28000 datapoints
2025-03-06 20:52:15,138 - INFO - training batch 251, loss: 0.325, 8032/28000 datapoints
2025-03-06 20:52:15,259 - INFO - training batch 301, loss: 0.548, 9632/28000 datapoints
2025-03-06 20:52:15,380 - INFO - training batch 351, loss: 0.244, 11232/28000 datapoints
2025-03-06 20:52:15,502 - INFO - training batch 401, loss: 0.518, 12832/28000 datapoints
2025-03-06 20:52:15,624 - INFO - training batch 451, loss: 0.253, 14432/28000 datapoints
2025-03-06 20:52:15,756 - INFO - training batch 501, loss: 0.153, 16032/28000 datapoints
2025-03-06 20:52:15,877 - INFO - training batch 551, loss: 0.230, 17632/28000 datapoints
2025-03-06 20:52:16,000 - INFO - training batch 601, loss: 0.285, 19232/28000 datapoints
2025-03-06 20:52:16,123 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 20:52:16,243 - INFO - training batch 701, loss: 0.253, 22432/28000 datapoints
2025-03-06 20:52:16,363 - INFO - training batch 751, loss: 0.221, 24032/28000 datapoints
2025-03-06 20:52:16,485 - INFO - training batch 801, loss: 0.113, 25632/28000 datapoints
2025-03-06 20:52:16,604 - INFO - training batch 851, loss: 0.416, 27232/28000 datapoints
2025-03-06 20:52:16,669 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 20:52:16,714 - INFO - validation batch 51, loss: 1.145, 1632/6976 datapoints
2025-03-06 20:52:16,758 - INFO - validation batch 101, loss: 0.335, 3232/6976 datapoints
2025-03-06 20:52:16,802 - INFO - validation batch 151, loss: 0.398, 4832/6976 datapoints
2025-03-06 20:52:16,845 - INFO - validation batch 201, loss: 0.404, 6432/6976 datapoints
2025-03-06 20:52:16,861 - INFO - Epoch 361/800 done.
2025-03-06 20:52:16,861 - INFO - Final validation performance:
Loss: 0.482, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:16,862 - INFO - Beginning epoch 362/800
2025-03-06 20:52:16,865 - INFO - training batch 1, loss: 0.300, 32/28000 datapoints
2025-03-06 20:52:16,987 - INFO - training batch 51, loss: 0.095, 1632/28000 datapoints
2025-03-06 20:52:17,107 - INFO - training batch 101, loss: 0.134, 3232/28000 datapoints
2025-03-06 20:52:17,233 - INFO - training batch 151, loss: 0.292, 4832/28000 datapoints
2025-03-06 20:52:17,352 - INFO - training batch 201, loss: 0.102, 6432/28000 datapoints
2025-03-06 20:52:17,472 - INFO - training batch 251, loss: 0.324, 8032/28000 datapoints
2025-03-06 20:52:17,592 - INFO - training batch 301, loss: 0.546, 9632/28000 datapoints
2025-03-06 20:52:17,718 - INFO - training batch 351, loss: 0.243, 11232/28000 datapoints
2025-03-06 20:52:17,841 - INFO - training batch 401, loss: 0.516, 12832/28000 datapoints
2025-03-06 20:52:17,960 - INFO - training batch 451, loss: 0.253, 14432/28000 datapoints
2025-03-06 20:52:18,081 - INFO - training batch 501, loss: 0.152, 16032/28000 datapoints
2025-03-06 20:52:18,203 - INFO - training batch 551, loss: 0.230, 17632/28000 datapoints
2025-03-06 20:52:18,324 - INFO - training batch 601, loss: 0.283, 19232/28000 datapoints
2025-03-06 20:52:18,444 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 20:52:18,564 - INFO - training batch 701, loss: 0.253, 22432/28000 datapoints
2025-03-06 20:52:18,686 - INFO - training batch 751, loss: 0.220, 24032/28000 datapoints
2025-03-06 20:52:18,805 - INFO - training batch 801, loss: 0.112, 25632/28000 datapoints
2025-03-06 20:52:18,926 - INFO - training batch 851, loss: 0.414, 27232/28000 datapoints
2025-03-06 20:52:18,985 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 20:52:19,029 - INFO - validation batch 51, loss: 1.147, 1632/6976 datapoints
2025-03-06 20:52:19,079 - INFO - validation batch 101, loss: 0.336, 3232/6976 datapoints
2025-03-06 20:52:19,124 - INFO - validation batch 151, loss: 0.399, 4832/6976 datapoints
2025-03-06 20:52:19,174 - INFO - validation batch 201, loss: 0.404, 6432/6976 datapoints
2025-03-06 20:52:19,189 - INFO - Epoch 362/800 done.
2025-03-06 20:52:19,189 - INFO - Final validation performance:
Loss: 0.482, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:52:19,190 - INFO - Beginning epoch 363/800
2025-03-06 20:52:19,193 - INFO - training batch 1, loss: 0.300, 32/28000 datapoints
2025-03-06 20:52:19,313 - INFO - training batch 51, loss: 0.094, 1632/28000 datapoints
2025-03-06 20:52:19,434 - INFO - training batch 101, loss: 0.134, 3232/28000 datapoints
2025-03-06 20:52:19,554 - INFO - training batch 151, loss: 0.288, 4832/28000 datapoints
2025-03-06 20:52:19,678 - INFO - training batch 201, loss: 0.101, 6432/28000 datapoints
2025-03-06 20:52:19,801 - INFO - training batch 251, loss: 0.324, 8032/28000 datapoints
2025-03-06 20:52:19,923 - INFO - training batch 301, loss: 0.544, 9632/28000 datapoints
2025-03-06 20:52:20,045 - INFO - training batch 351, loss: 0.243, 11232/28000 datapoints
2025-03-06 20:52:20,167 - INFO - training batch 401, loss: 0.515, 12832/28000 datapoints
2025-03-06 20:52:20,286 - INFO - training batch 451, loss: 0.252, 14432/28000 datapoints
2025-03-06 20:52:20,407 - INFO - training batch 501, loss: 0.153, 16032/28000 datapoints
2025-03-06 20:52:20,527 - INFO - training batch 551, loss: 0.229, 17632/28000 datapoints
2025-03-06 20:52:20,648 - INFO - training batch 601, loss: 0.280, 19232/28000 datapoints
2025-03-06 20:52:20,772 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 20:52:20,892 - INFO - training batch 701, loss: 0.252, 22432/28000 datapoints
2025-03-06 20:52:21,013 - INFO - training batch 751, loss: 0.220, 24032/28000 datapoints
2025-03-06 20:52:21,133 - INFO - training batch 801, loss: 0.112, 25632/28000 datapoints
2025-03-06 20:52:21,254 - INFO - training batch 851, loss: 0.413, 27232/28000 datapoints
2025-03-06 20:52:21,313 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 20:52:21,357 - INFO - validation batch 51, loss: 1.146, 1632/6976 datapoints
2025-03-06 20:52:21,401 - INFO - validation batch 101, loss: 0.338, 3232/6976 datapoints
2025-03-06 20:52:21,445 - INFO - validation batch 151, loss: 0.399, 4832/6976 datapoints
2025-03-06 20:52:21,489 - INFO - validation batch 201, loss: 0.403, 6432/6976 datapoints
2025-03-06 20:52:21,504 - INFO - Epoch 363/800 done.
2025-03-06 20:52:21,504 - INFO - Final validation performance:
Loss: 0.483, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:21,505 - INFO - Beginning epoch 364/800
2025-03-06 20:52:21,508 - INFO - training batch 1, loss: 0.299, 32/28000 datapoints
2025-03-06 20:52:21,629 - INFO - training batch 51, loss: 0.094, 1632/28000 datapoints
2025-03-06 20:52:21,761 - INFO - training batch 101, loss: 0.133, 3232/28000 datapoints
2025-03-06 20:52:21,883 - INFO - training batch 151, loss: 0.285, 4832/28000 datapoints
2025-03-06 20:52:22,002 - INFO - training batch 201, loss: 0.100, 6432/28000 datapoints
2025-03-06 20:52:22,122 - INFO - training batch 251, loss: 0.323, 8032/28000 datapoints
2025-03-06 20:52:22,270 - INFO - training batch 301, loss: 0.542, 9632/28000 datapoints
2025-03-06 20:52:22,391 - INFO - training batch 351, loss: 0.242, 11232/28000 datapoints
2025-03-06 20:52:22,510 - INFO - training batch 401, loss: 0.515, 12832/28000 datapoints
2025-03-06 20:52:22,629 - INFO - training batch 451, loss: 0.253, 14432/28000 datapoints
2025-03-06 20:52:22,755 - INFO - training batch 501, loss: 0.152, 16032/28000 datapoints
2025-03-06 20:52:22,875 - INFO - training batch 551, loss: 0.229, 17632/28000 datapoints
2025-03-06 20:52:23,003 - INFO - training batch 601, loss: 0.278, 19232/28000 datapoints
2025-03-06 20:52:23,125 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 20:52:23,248 - INFO - training batch 701, loss: 0.251, 22432/28000 datapoints
2025-03-06 20:52:23,368 - INFO - training batch 751, loss: 0.220, 24032/28000 datapoints
2025-03-06 20:52:23,489 - INFO - training batch 801, loss: 0.112, 25632/28000 datapoints
2025-03-06 20:52:23,610 - INFO - training batch 851, loss: 0.410, 27232/28000 datapoints
2025-03-06 20:52:23,672 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 20:52:23,719 - INFO - validation batch 51, loss: 1.148, 1632/6976 datapoints
2025-03-06 20:52:23,766 - INFO - validation batch 101, loss: 0.339, 3232/6976 datapoints
2025-03-06 20:52:23,810 - INFO - validation batch 151, loss: 0.400, 4832/6976 datapoints
2025-03-06 20:52:23,854 - INFO - validation batch 201, loss: 0.404, 6432/6976 datapoints
2025-03-06 20:52:23,868 - INFO - Epoch 364/800 done.
2025-03-06 20:52:23,869 - INFO - Final validation performance:
Loss: 0.483, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:23,869 - INFO - Beginning epoch 365/800
2025-03-06 20:52:23,873 - INFO - training batch 1, loss: 0.299, 32/28000 datapoints
2025-03-06 20:52:23,996 - INFO - training batch 51, loss: 0.093, 1632/28000 datapoints
2025-03-06 20:52:24,116 - INFO - training batch 101, loss: 0.132, 3232/28000 datapoints
2025-03-06 20:52:24,240 - INFO - training batch 151, loss: 0.281, 4832/28000 datapoints
2025-03-06 20:52:24,360 - INFO - training batch 201, loss: 0.100, 6432/28000 datapoints
2025-03-06 20:52:24,481 - INFO - training batch 251, loss: 0.323, 8032/28000 datapoints
2025-03-06 20:52:24,600 - INFO - training batch 301, loss: 0.541, 9632/28000 datapoints
2025-03-06 20:52:24,721 - INFO - training batch 351, loss: 0.241, 11232/28000 datapoints
2025-03-06 20:52:24,842 - INFO - training batch 401, loss: 0.513, 12832/28000 datapoints
2025-03-06 20:52:24,966 - INFO - training batch 451, loss: 0.251, 14432/28000 datapoints
2025-03-06 20:52:25,088 - INFO - training batch 501, loss: 0.152, 16032/28000 datapoints
2025-03-06 20:52:25,215 - INFO - training batch 551, loss: 0.228, 17632/28000 datapoints
2025-03-06 20:52:25,335 - INFO - training batch 601, loss: 0.276, 19232/28000 datapoints
2025-03-06 20:52:25,457 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 20:52:25,576 - INFO - training batch 701, loss: 0.251, 22432/28000 datapoints
2025-03-06 20:52:25,699 - INFO - training batch 751, loss: 0.218, 24032/28000 datapoints
2025-03-06 20:52:25,823 - INFO - training batch 801, loss: 0.111, 25632/28000 datapoints
2025-03-06 20:52:25,943 - INFO - training batch 851, loss: 0.408, 27232/28000 datapoints
2025-03-06 20:52:26,002 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 20:52:26,047 - INFO - validation batch 51, loss: 1.149, 1632/6976 datapoints
2025-03-06 20:52:26,093 - INFO - validation batch 101, loss: 0.340, 3232/6976 datapoints
2025-03-06 20:52:26,137 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 20:52:26,181 - INFO - validation batch 201, loss: 0.405, 6432/6976 datapoints
2025-03-06 20:52:26,197 - INFO - Epoch 365/800 done.
2025-03-06 20:52:26,197 - INFO - Final validation performance:
Loss: 0.484, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:26,197 - INFO - Beginning epoch 366/800
2025-03-06 20:52:26,201 - INFO - training batch 1, loss: 0.298, 32/28000 datapoints
2025-03-06 20:52:26,324 - INFO - training batch 51, loss: 0.093, 1632/28000 datapoints
2025-03-06 20:52:26,444 - INFO - training batch 101, loss: 0.132, 3232/28000 datapoints
2025-03-06 20:52:26,564 - INFO - training batch 151, loss: 0.277, 4832/28000 datapoints
2025-03-06 20:52:26,685 - INFO - training batch 201, loss: 0.099, 6432/28000 datapoints
2025-03-06 20:52:26,808 - INFO - training batch 251, loss: 0.322, 8032/28000 datapoints
2025-03-06 20:52:26,928 - INFO - training batch 301, loss: 0.539, 9632/28000 datapoints
2025-03-06 20:52:27,048 - INFO - training batch 351, loss: 0.240, 11232/28000 datapoints
2025-03-06 20:52:27,167 - INFO - training batch 401, loss: 0.511, 12832/28000 datapoints
2025-03-06 20:52:27,289 - INFO - training batch 451, loss: 0.250, 14432/28000 datapoints
2025-03-06 20:52:27,408 - INFO - training batch 501, loss: 0.152, 16032/28000 datapoints
2025-03-06 20:52:27,533 - INFO - training batch 551, loss: 0.228, 17632/28000 datapoints
2025-03-06 20:52:27,661 - INFO - training batch 601, loss: 0.274, 19232/28000 datapoints
2025-03-06 20:52:27,791 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 20:52:27,914 - INFO - training batch 701, loss: 0.250, 22432/28000 datapoints
2025-03-06 20:52:28,039 - INFO - training batch 751, loss: 0.218, 24032/28000 datapoints
2025-03-06 20:52:28,163 - INFO - training batch 801, loss: 0.111, 25632/28000 datapoints
2025-03-06 20:52:28,290 - INFO - training batch 851, loss: 0.406, 27232/28000 datapoints
2025-03-06 20:52:28,352 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 20:52:28,401 - INFO - validation batch 51, loss: 1.149, 1632/6976 datapoints
2025-03-06 20:52:28,450 - INFO - validation batch 101, loss: 0.341, 3232/6976 datapoints
2025-03-06 20:52:28,498 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 20:52:28,547 - INFO - validation batch 201, loss: 0.405, 6432/6976 datapoints
2025-03-06 20:52:28,562 - INFO - Epoch 366/800 done.
2025-03-06 20:52:28,562 - INFO - Final validation performance:
Loss: 0.485, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:28,563 - INFO - Beginning epoch 367/800
2025-03-06 20:52:28,567 - INFO - training batch 1, loss: 0.298, 32/28000 datapoints
2025-03-06 20:52:28,696 - INFO - training batch 51, loss: 0.092, 1632/28000 datapoints
2025-03-06 20:52:28,821 - INFO - training batch 101, loss: 0.132, 3232/28000 datapoints
2025-03-06 20:52:28,945 - INFO - training batch 151, loss: 0.274, 4832/28000 datapoints
2025-03-06 20:52:29,071 - INFO - training batch 201, loss: 0.098, 6432/28000 datapoints
2025-03-06 20:52:29,196 - INFO - training batch 251, loss: 0.321, 8032/28000 datapoints
2025-03-06 20:52:29,321 - INFO - training batch 301, loss: 0.537, 9632/28000 datapoints
2025-03-06 20:52:29,444 - INFO - training batch 351, loss: 0.239, 11232/28000 datapoints
2025-03-06 20:52:29,568 - INFO - training batch 401, loss: 0.510, 12832/28000 datapoints
2025-03-06 20:52:29,695 - INFO - training batch 451, loss: 0.249, 14432/28000 datapoints
2025-03-06 20:52:29,825 - INFO - training batch 501, loss: 0.152, 16032/28000 datapoints
2025-03-06 20:52:29,950 - INFO - training batch 551, loss: 0.226, 17632/28000 datapoints
2025-03-06 20:52:30,074 - INFO - training batch 601, loss: 0.270, 19232/28000 datapoints
2025-03-06 20:52:30,198 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 20:52:30,323 - INFO - training batch 701, loss: 0.250, 22432/28000 datapoints
2025-03-06 20:52:30,448 - INFO - training batch 751, loss: 0.217, 24032/28000 datapoints
2025-03-06 20:52:30,570 - INFO - training batch 801, loss: 0.111, 25632/28000 datapoints
2025-03-06 20:52:30,695 - INFO - training batch 851, loss: 0.404, 27232/28000 datapoints
2025-03-06 20:52:30,764 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 20:52:30,813 - INFO - validation batch 51, loss: 1.150, 1632/6976 datapoints
2025-03-06 20:52:30,863 - INFO - validation batch 101, loss: 0.342, 3232/6976 datapoints
2025-03-06 20:52:30,911 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 20:52:30,959 - INFO - validation batch 201, loss: 0.405, 6432/6976 datapoints
2025-03-06 20:52:30,977 - INFO - Epoch 367/800 done.
2025-03-06 20:52:30,977 - INFO - Final validation performance:
Loss: 0.485, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:30,978 - INFO - Beginning epoch 368/800
2025-03-06 20:52:30,981 - INFO - training batch 1, loss: 0.298, 32/28000 datapoints
2025-03-06 20:52:31,103 - INFO - training batch 51, loss: 0.092, 1632/28000 datapoints
2025-03-06 20:52:31,225 - INFO - training batch 101, loss: 0.131, 3232/28000 datapoints
2025-03-06 20:52:31,350 - INFO - training batch 151, loss: 0.271, 4832/28000 datapoints
2025-03-06 20:52:31,471 - INFO - training batch 201, loss: 0.097, 6432/28000 datapoints
2025-03-06 20:52:31,592 - INFO - training batch 251, loss: 0.321, 8032/28000 datapoints
2025-03-06 20:52:31,714 - INFO - training batch 301, loss: 0.534, 9632/28000 datapoints
2025-03-06 20:52:31,839 - INFO - training batch 351, loss: 0.239, 11232/28000 datapoints
2025-03-06 20:52:31,961 - INFO - training batch 401, loss: 0.509, 12832/28000 datapoints
2025-03-06 20:52:32,083 - INFO - training batch 451, loss: 0.249, 14432/28000 datapoints
2025-03-06 20:52:32,204 - INFO - training batch 501, loss: 0.151, 16032/28000 datapoints
2025-03-06 20:52:32,357 - INFO - training batch 551, loss: 0.226, 17632/28000 datapoints
2025-03-06 20:52:32,476 - INFO - training batch 601, loss: 0.267, 19232/28000 datapoints
2025-03-06 20:52:32,596 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 20:52:32,717 - INFO - training batch 701, loss: 0.249, 22432/28000 datapoints
2025-03-06 20:52:32,838 - INFO - training batch 751, loss: 0.216, 24032/28000 datapoints
2025-03-06 20:52:32,958 - INFO - training batch 801, loss: 0.110, 25632/28000 datapoints
2025-03-06 20:52:33,088 - INFO - training batch 851, loss: 0.402, 27232/28000 datapoints
2025-03-06 20:52:33,149 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 20:52:33,194 - INFO - validation batch 51, loss: 1.151, 1632/6976 datapoints
2025-03-06 20:52:33,238 - INFO - validation batch 101, loss: 0.343, 3232/6976 datapoints
2025-03-06 20:52:33,283 - INFO - validation batch 151, loss: 0.402, 4832/6976 datapoints
2025-03-06 20:52:33,328 - INFO - validation batch 201, loss: 0.406, 6432/6976 datapoints
2025-03-06 20:52:33,343 - INFO - Epoch 368/800 done.
2025-03-06 20:52:33,343 - INFO - Final validation performance:
Loss: 0.486, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:52:33,344 - INFO - Beginning epoch 369/800
2025-03-06 20:52:33,348 - INFO - training batch 1, loss: 0.297, 32/28000 datapoints
2025-03-06 20:52:33,470 - INFO - training batch 51, loss: 0.091, 1632/28000 datapoints
2025-03-06 20:52:33,588 - INFO - training batch 101, loss: 0.131, 3232/28000 datapoints
2025-03-06 20:52:33,712 - INFO - training batch 151, loss: 0.268, 4832/28000 datapoints
2025-03-06 20:52:33,851 - INFO - training batch 201, loss: 0.097, 6432/28000 datapoints
2025-03-06 20:52:33,972 - INFO - training batch 251, loss: 0.320, 8032/28000 datapoints
2025-03-06 20:52:34,091 - INFO - training batch 301, loss: 0.533, 9632/28000 datapoints
2025-03-06 20:52:34,211 - INFO - training batch 351, loss: 0.238, 11232/28000 datapoints
2025-03-06 20:52:34,333 - INFO - training batch 401, loss: 0.507, 12832/28000 datapoints
2025-03-06 20:52:34,459 - INFO - training batch 451, loss: 0.249, 14432/28000 datapoints
2025-03-06 20:52:34,579 - INFO - training batch 501, loss: 0.152, 16032/28000 datapoints
2025-03-06 20:52:34,703 - INFO - training batch 551, loss: 0.226, 17632/28000 datapoints
2025-03-06 20:52:34,827 - INFO - training batch 601, loss: 0.265, 19232/28000 datapoints
2025-03-06 20:52:34,954 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 20:52:35,074 - INFO - training batch 701, loss: 0.248, 22432/28000 datapoints
2025-03-06 20:52:35,192 - INFO - training batch 751, loss: 0.216, 24032/28000 datapoints
2025-03-06 20:52:35,313 - INFO - training batch 801, loss: 0.110, 25632/28000 datapoints
2025-03-06 20:52:35,434 - INFO - training batch 851, loss: 0.400, 27232/28000 datapoints
2025-03-06 20:52:35,494 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 20:52:35,538 - INFO - validation batch 51, loss: 1.153, 1632/6976 datapoints
2025-03-06 20:52:35,581 - INFO - validation batch 101, loss: 0.345, 3232/6976 datapoints
2025-03-06 20:52:35,624 - INFO - validation batch 151, loss: 0.402, 4832/6976 datapoints
2025-03-06 20:52:35,682 - INFO - validation batch 201, loss: 0.406, 6432/6976 datapoints
2025-03-06 20:52:35,703 - INFO - Epoch 369/800 done.
2025-03-06 20:52:35,703 - INFO - Final validation performance:
Loss: 0.487, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:35,704 - INFO - Beginning epoch 370/800
2025-03-06 20:52:35,708 - INFO - training batch 1, loss: 0.297, 32/28000 datapoints
2025-03-06 20:52:35,866 - INFO - training batch 51, loss: 0.091, 1632/28000 datapoints
2025-03-06 20:52:35,992 - INFO - training batch 101, loss: 0.131, 3232/28000 datapoints
2025-03-06 20:52:36,114 - INFO - training batch 151, loss: 0.265, 4832/28000 datapoints
2025-03-06 20:52:36,234 - INFO - training batch 201, loss: 0.096, 6432/28000 datapoints
2025-03-06 20:52:36,356 - INFO - training batch 251, loss: 0.319, 8032/28000 datapoints
2025-03-06 20:52:36,478 - INFO - training batch 301, loss: 0.531, 9632/28000 datapoints
2025-03-06 20:52:36,597 - INFO - training batch 351, loss: 0.237, 11232/28000 datapoints
2025-03-06 20:52:36,719 - INFO - training batch 401, loss: 0.506, 12832/28000 datapoints
2025-03-06 20:52:36,841 - INFO - training batch 451, loss: 0.248, 14432/28000 datapoints
2025-03-06 20:52:36,960 - INFO - training batch 501, loss: 0.151, 16032/28000 datapoints
2025-03-06 20:52:37,080 - INFO - training batch 551, loss: 0.225, 17632/28000 datapoints
2025-03-06 20:52:37,199 - INFO - training batch 601, loss: 0.262, 19232/28000 datapoints
2025-03-06 20:52:37,322 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 20:52:37,443 - INFO - training batch 701, loss: 0.247, 22432/28000 datapoints
2025-03-06 20:52:37,563 - INFO - training batch 751, loss: 0.215, 24032/28000 datapoints
2025-03-06 20:52:37,703 - INFO - training batch 801, loss: 0.110, 25632/28000 datapoints
2025-03-06 20:52:37,826 - INFO - training batch 851, loss: 0.398, 27232/28000 datapoints
2025-03-06 20:52:37,886 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 20:52:37,930 - INFO - validation batch 51, loss: 1.153, 1632/6976 datapoints
2025-03-06 20:52:37,975 - INFO - validation batch 101, loss: 0.346, 3232/6976 datapoints
2025-03-06 20:52:38,018 - INFO - validation batch 151, loss: 0.403, 4832/6976 datapoints
2025-03-06 20:52:38,061 - INFO - validation batch 201, loss: 0.406, 6432/6976 datapoints
2025-03-06 20:52:38,076 - INFO - Epoch 370/800 done.
2025-03-06 20:52:38,076 - INFO - Final validation performance:
Loss: 0.487, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:38,077 - INFO - Beginning epoch 371/800
2025-03-06 20:52:38,080 - INFO - training batch 1, loss: 0.297, 32/28000 datapoints
2025-03-06 20:52:38,205 - INFO - training batch 51, loss: 0.090, 1632/28000 datapoints
2025-03-06 20:52:38,328 - INFO - training batch 101, loss: 0.130, 3232/28000 datapoints
2025-03-06 20:52:38,451 - INFO - training batch 151, loss: 0.262, 4832/28000 datapoints
2025-03-06 20:52:38,570 - INFO - training batch 201, loss: 0.095, 6432/28000 datapoints
2025-03-06 20:52:38,692 - INFO - training batch 251, loss: 0.319, 8032/28000 datapoints
2025-03-06 20:52:38,811 - INFO - training batch 301, loss: 0.530, 9632/28000 datapoints
2025-03-06 20:52:38,932 - INFO - training batch 351, loss: 0.236, 11232/28000 datapoints
2025-03-06 20:52:39,056 - INFO - training batch 401, loss: 0.504, 12832/28000 datapoints
2025-03-06 20:52:39,178 - INFO - training batch 451, loss: 0.247, 14432/28000 datapoints
2025-03-06 20:52:39,301 - INFO - training batch 501, loss: 0.151, 16032/28000 datapoints
2025-03-06 20:52:39,423 - INFO - training batch 551, loss: 0.223, 17632/28000 datapoints
2025-03-06 20:52:39,545 - INFO - training batch 601, loss: 0.260, 19232/28000 datapoints
2025-03-06 20:52:39,668 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 20:52:39,788 - INFO - training batch 701, loss: 0.247, 22432/28000 datapoints
2025-03-06 20:52:39,912 - INFO - training batch 751, loss: 0.215, 24032/28000 datapoints
2025-03-06 20:52:40,039 - INFO - training batch 801, loss: 0.109, 25632/28000 datapoints
2025-03-06 20:52:40,159 - INFO - training batch 851, loss: 0.396, 27232/28000 datapoints
2025-03-06 20:52:40,221 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 20:52:40,268 - INFO - validation batch 51, loss: 1.155, 1632/6976 datapoints
2025-03-06 20:52:40,314 - INFO - validation batch 101, loss: 0.347, 3232/6976 datapoints
2025-03-06 20:52:40,357 - INFO - validation batch 151, loss: 0.402, 4832/6976 datapoints
2025-03-06 20:52:40,402 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 20:52:40,417 - INFO - Epoch 371/800 done.
2025-03-06 20:52:40,417 - INFO - Final validation performance:
Loss: 0.488, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:52:40,417 - INFO - Beginning epoch 372/800
2025-03-06 20:52:40,421 - INFO - training batch 1, loss: 0.296, 32/28000 datapoints
2025-03-06 20:52:40,543 - INFO - training batch 51, loss: 0.090, 1632/28000 datapoints
2025-03-06 20:52:40,668 - INFO - training batch 101, loss: 0.130, 3232/28000 datapoints
2025-03-06 20:52:40,791 - INFO - training batch 151, loss: 0.259, 4832/28000 datapoints
2025-03-06 20:52:40,912 - INFO - training batch 201, loss: 0.095, 6432/28000 datapoints
2025-03-06 20:52:41,032 - INFO - training batch 251, loss: 0.318, 8032/28000 datapoints
2025-03-06 20:52:41,151 - INFO - training batch 301, loss: 0.527, 9632/28000 datapoints
2025-03-06 20:52:41,274 - INFO - training batch 351, loss: 0.236, 11232/28000 datapoints
2025-03-06 20:52:41,393 - INFO - training batch 401, loss: 0.504, 12832/28000 datapoints
2025-03-06 20:52:41,516 - INFO - training batch 451, loss: 0.249, 14432/28000 datapoints
2025-03-06 20:52:41,638 - INFO - training batch 501, loss: 0.151, 16032/28000 datapoints
2025-03-06 20:52:41,760 - INFO - training batch 551, loss: 0.223, 17632/28000 datapoints
2025-03-06 20:52:41,885 - INFO - training batch 601, loss: 0.257, 19232/28000 datapoints
2025-03-06 20:52:42,007 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 20:52:42,126 - INFO - training batch 701, loss: 0.246, 22432/28000 datapoints
2025-03-06 20:52:42,247 - INFO - training batch 751, loss: 0.214, 24032/28000 datapoints
2025-03-06 20:52:42,391 - INFO - training batch 801, loss: 0.109, 25632/28000 datapoints
2025-03-06 20:52:42,518 - INFO - training batch 851, loss: 0.394, 27232/28000 datapoints
2025-03-06 20:52:42,577 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 20:52:42,621 - INFO - validation batch 51, loss: 1.155, 1632/6976 datapoints
2025-03-06 20:52:42,666 - INFO - validation batch 101, loss: 0.348, 3232/6976 datapoints
2025-03-06 20:52:42,710 - INFO - validation batch 151, loss: 0.404, 4832/6976 datapoints
2025-03-06 20:52:42,754 - INFO - validation batch 201, loss: 0.406, 6432/6976 datapoints
2025-03-06 20:52:42,769 - INFO - Epoch 372/800 done.
2025-03-06 20:52:42,769 - INFO - Final validation performance:
Loss: 0.488, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:42,769 - INFO - Beginning epoch 373/800
2025-03-06 20:52:42,773 - INFO - training batch 1, loss: 0.296, 32/28000 datapoints
2025-03-06 20:52:42,894 - INFO - training batch 51, loss: 0.089, 1632/28000 datapoints
2025-03-06 20:52:43,016 - INFO - training batch 101, loss: 0.129, 3232/28000 datapoints
2025-03-06 20:52:43,136 - INFO - training batch 151, loss: 0.258, 4832/28000 datapoints
2025-03-06 20:52:43,256 - INFO - training batch 201, loss: 0.094, 6432/28000 datapoints
2025-03-06 20:52:43,376 - INFO - training batch 251, loss: 0.317, 8032/28000 datapoints
2025-03-06 20:52:43,497 - INFO - training batch 301, loss: 0.524, 9632/28000 datapoints
2025-03-06 20:52:43,615 - INFO - training batch 351, loss: 0.234, 11232/28000 datapoints
2025-03-06 20:52:43,738 - INFO - training batch 401, loss: 0.502, 12832/28000 datapoints
2025-03-06 20:52:43,861 - INFO - training batch 451, loss: 0.246, 14432/28000 datapoints
2025-03-06 20:52:43,984 - INFO - training batch 501, loss: 0.150, 16032/28000 datapoints
2025-03-06 20:52:44,105 - INFO - training batch 551, loss: 0.223, 17632/28000 datapoints
2025-03-06 20:52:44,226 - INFO - training batch 601, loss: 0.254, 19232/28000 datapoints
2025-03-06 20:52:44,348 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 20:52:44,468 - INFO - training batch 701, loss: 0.245, 22432/28000 datapoints
2025-03-06 20:52:44,586 - INFO - training batch 751, loss: 0.212, 24032/28000 datapoints
2025-03-06 20:52:44,707 - INFO - training batch 801, loss: 0.108, 25632/28000 datapoints
2025-03-06 20:52:44,827 - INFO - training batch 851, loss: 0.393, 27232/28000 datapoints
2025-03-06 20:52:44,891 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 20:52:44,935 - INFO - validation batch 51, loss: 1.156, 1632/6976 datapoints
2025-03-06 20:52:44,980 - INFO - validation batch 101, loss: 0.349, 3232/6976 datapoints
2025-03-06 20:52:45,024 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 20:52:45,068 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 20:52:45,083 - INFO - Epoch 373/800 done.
2025-03-06 20:52:45,083 - INFO - Final validation performance:
Loss: 0.489, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:45,085 - INFO - Beginning epoch 374/800
2025-03-06 20:52:45,088 - INFO - training batch 1, loss: 0.295, 32/28000 datapoints
2025-03-06 20:52:45,210 - INFO - training batch 51, loss: 0.089, 1632/28000 datapoints
2025-03-06 20:52:45,330 - INFO - training batch 101, loss: 0.128, 3232/28000 datapoints
2025-03-06 20:52:45,451 - INFO - training batch 151, loss: 0.255, 4832/28000 datapoints
2025-03-06 20:52:45,573 - INFO - training batch 201, loss: 0.094, 6432/28000 datapoints
2025-03-06 20:52:45,697 - INFO - training batch 251, loss: 0.318, 8032/28000 datapoints
2025-03-06 20:52:45,816 - INFO - training batch 301, loss: 0.524, 9632/28000 datapoints
2025-03-06 20:52:45,939 - INFO - training batch 351, loss: 0.233, 11232/28000 datapoints
2025-03-06 20:52:46,062 - INFO - training batch 401, loss: 0.501, 12832/28000 datapoints
2025-03-06 20:52:46,182 - INFO - training batch 451, loss: 0.246, 14432/28000 datapoints
2025-03-06 20:52:46,303 - INFO - training batch 501, loss: 0.150, 16032/28000 datapoints
2025-03-06 20:52:46,424 - INFO - training batch 551, loss: 0.222, 17632/28000 datapoints
2025-03-06 20:52:46,545 - INFO - training batch 601, loss: 0.253, 19232/28000 datapoints
2025-03-06 20:52:46,666 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 20:52:46,786 - INFO - training batch 701, loss: 0.245, 22432/28000 datapoints
2025-03-06 20:52:46,905 - INFO - training batch 751, loss: 0.212, 24032/28000 datapoints
2025-03-06 20:52:47,026 - INFO - training batch 801, loss: 0.108, 25632/28000 datapoints
2025-03-06 20:52:47,144 - INFO - training batch 851, loss: 0.390, 27232/28000 datapoints
2025-03-06 20:52:47,203 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 20:52:47,248 - INFO - validation batch 51, loss: 1.158, 1632/6976 datapoints
2025-03-06 20:52:47,302 - INFO - validation batch 101, loss: 0.350, 3232/6976 datapoints
2025-03-06 20:52:47,355 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 20:52:47,397 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-06 20:52:47,413 - INFO - Epoch 374/800 done.
2025-03-06 20:52:47,413 - INFO - Final validation performance:
Loss: 0.490, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:52:47,413 - INFO - Beginning epoch 375/800
2025-03-06 20:52:47,417 - INFO - training batch 1, loss: 0.295, 32/28000 datapoints
2025-03-06 20:52:47,542 - INFO - training batch 51, loss: 0.088, 1632/28000 datapoints
2025-03-06 20:52:47,673 - INFO - training batch 101, loss: 0.128, 3232/28000 datapoints
2025-03-06 20:52:47,795 - INFO - training batch 151, loss: 0.252, 4832/28000 datapoints
2025-03-06 20:52:47,921 - INFO - training batch 201, loss: 0.093, 6432/28000 datapoints
2025-03-06 20:52:48,049 - INFO - training batch 251, loss: 0.316, 8032/28000 datapoints
2025-03-06 20:52:48,173 - INFO - training batch 301, loss: 0.522, 9632/28000 datapoints
2025-03-06 20:52:48,299 - INFO - training batch 351, loss: 0.232, 11232/28000 datapoints
2025-03-06 20:52:48,423 - INFO - training batch 401, loss: 0.499, 12832/28000 datapoints
2025-03-06 20:52:48,549 - INFO - training batch 451, loss: 0.245, 14432/28000 datapoints
2025-03-06 20:52:48,683 - INFO - training batch 501, loss: 0.150, 16032/28000 datapoints
2025-03-06 20:52:48,833 - INFO - training batch 551, loss: 0.221, 17632/28000 datapoints
2025-03-06 20:52:48,958 - INFO - training batch 601, loss: 0.249, 19232/28000 datapoints
2025-03-06 20:52:49,085 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 20:52:49,208 - INFO - training batch 701, loss: 0.244, 22432/28000 datapoints
2025-03-06 20:52:49,334 - INFO - training batch 751, loss: 0.212, 24032/28000 datapoints
2025-03-06 20:52:49,458 - INFO - training batch 801, loss: 0.108, 25632/28000 datapoints
2025-03-06 20:52:49,589 - INFO - training batch 851, loss: 0.388, 27232/28000 datapoints
2025-03-06 20:52:49,653 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 20:52:49,703 - INFO - validation batch 51, loss: 1.159, 1632/6976 datapoints
2025-03-06 20:52:49,754 - INFO - validation batch 101, loss: 0.352, 3232/6976 datapoints
2025-03-06 20:52:49,801 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 20:52:49,849 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 20:52:49,865 - INFO - Epoch 375/800 done.
2025-03-06 20:52:49,865 - INFO - Final validation performance:
Loss: 0.490, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 20:52:49,865 - INFO - Beginning epoch 376/800
2025-03-06 20:52:49,873 - INFO - training batch 1, loss: 0.294, 32/28000 datapoints
2025-03-06 20:52:49,997 - INFO - training batch 51, loss: 0.088, 1632/28000 datapoints
2025-03-06 20:52:50,123 - INFO - training batch 101, loss: 0.127, 3232/28000 datapoints
2025-03-06 20:52:50,245 - INFO - training batch 151, loss: 0.249, 4832/28000 datapoints
2025-03-06 20:52:50,365 - INFO - training batch 201, loss: 0.093, 6432/28000 datapoints
2025-03-06 20:52:50,484 - INFO - training batch 251, loss: 0.315, 8032/28000 datapoints
2025-03-06 20:52:50,642 - INFO - training batch 301, loss: 0.519, 9632/28000 datapoints
2025-03-06 20:52:50,773 - INFO - training batch 351, loss: 0.231, 11232/28000 datapoints
2025-03-06 20:52:50,896 - INFO - training batch 401, loss: 0.498, 12832/28000 datapoints
2025-03-06 20:52:51,016 - INFO - training batch 451, loss: 0.245, 14432/28000 datapoints
2025-03-06 20:52:51,136 - INFO - training batch 501, loss: 0.149, 16032/28000 datapoints
2025-03-06 20:52:51,255 - INFO - training batch 551, loss: 0.220, 17632/28000 datapoints
2025-03-06 20:52:51,375 - INFO - training batch 601, loss: 0.246, 19232/28000 datapoints
2025-03-06 20:52:51,493 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 20:52:51,614 - INFO - training batch 701, loss: 0.244, 22432/28000 datapoints
2025-03-06 20:52:51,754 - INFO - training batch 751, loss: 0.210, 24032/28000 datapoints
2025-03-06 20:52:51,908 - INFO - training batch 801, loss: 0.108, 25632/28000 datapoints
2025-03-06 20:52:52,030 - INFO - training batch 851, loss: 0.386, 27232/28000 datapoints
2025-03-06 20:52:52,089 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 20:52:52,133 - INFO - validation batch 51, loss: 1.160, 1632/6976 datapoints
2025-03-06 20:52:52,177 - INFO - validation batch 101, loss: 0.353, 3232/6976 datapoints
2025-03-06 20:52:52,221 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 20:52:52,266 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 20:52:52,281 - INFO - Epoch 376/800 done.
2025-03-06 20:52:52,282 - INFO - Final validation performance:
Loss: 0.491, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 20:52:52,282 - INFO - Beginning epoch 377/800
2025-03-06 20:52:52,286 - INFO - training batch 1, loss: 0.293, 32/28000 datapoints
2025-03-06 20:52:52,412 - INFO - training batch 51, loss: 0.087, 1632/28000 datapoints
2025-03-06 20:52:52,564 - INFO - training batch 101, loss: 0.126, 3232/28000 datapoints
2025-03-06 20:52:52,688 - INFO - training batch 151, loss: 0.244, 4832/28000 datapoints
2025-03-06 20:52:52,807 - INFO - training batch 201, loss: 0.092, 6432/28000 datapoints
2025-03-06 20:52:52,928 - INFO - training batch 251, loss: 0.315, 8032/28000 datapoints
2025-03-06 20:52:53,048 - INFO - training batch 301, loss: 0.517, 9632/28000 datapoints
2025-03-06 20:52:53,166 - INFO - training batch 351, loss: 0.231, 11232/28000 datapoints
2025-03-06 20:52:53,285 - INFO - training batch 401, loss: 0.496, 12832/28000 datapoints
2025-03-06 20:52:53,404 - INFO - training batch 451, loss: 0.244, 14432/28000 datapoints
2025-03-06 20:52:53,525 - INFO - training batch 501, loss: 0.149, 16032/28000 datapoints
2025-03-06 20:52:53,649 - INFO - training batch 551, loss: 0.219, 17632/28000 datapoints
2025-03-06 20:52:53,768 - INFO - training batch 601, loss: 0.243, 19232/28000 datapoints
2025-03-06 20:52:53,891 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 20:52:54,011 - INFO - training batch 701, loss: 0.243, 22432/28000 datapoints
2025-03-06 20:52:54,133 - INFO - training batch 751, loss: 0.208, 24032/28000 datapoints
2025-03-06 20:52:54,252 - INFO - training batch 801, loss: 0.108, 25632/28000 datapoints
2025-03-06 20:52:54,372 - INFO - training batch 851, loss: 0.383, 27232/28000 datapoints
2025-03-06 20:52:54,431 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 20:52:54,476 - INFO - validation batch 51, loss: 1.161, 1632/6976 datapoints
2025-03-06 20:52:54,520 - INFO - validation batch 101, loss: 0.354, 3232/6976 datapoints
2025-03-06 20:52:54,566 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 20:52:54,609 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-06 20:52:54,624 - INFO - Epoch 377/800 done.
2025-03-06 20:52:54,624 - INFO - Final validation performance:
Loss: 0.492, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 20:52:54,625 - INFO - Beginning epoch 378/800
2025-03-06 20:52:54,628 - INFO - training batch 1, loss: 0.293, 32/28000 datapoints
2025-03-06 20:52:54,749 - INFO - training batch 51, loss: 0.087, 1632/28000 datapoints
2025-03-06 20:52:54,870 - INFO - training batch 101, loss: 0.125, 3232/28000 datapoints
2025-03-06 20:52:54,992 - INFO - training batch 151, loss: 0.241, 4832/28000 datapoints
2025-03-06 20:52:55,118 - INFO - training batch 201, loss: 0.091, 6432/28000 datapoints
2025-03-06 20:52:55,235 - INFO - training batch 251, loss: 0.314, 8032/28000 datapoints
2025-03-06 20:52:55,356 - INFO - training batch 301, loss: 0.516, 9632/28000 datapoints
2025-03-06 20:52:55,476 - INFO - training batch 351, loss: 0.230, 11232/28000 datapoints
2025-03-06 20:52:55,596 - INFO - training batch 401, loss: 0.495, 12832/28000 datapoints
2025-03-06 20:52:55,719 - INFO - training batch 451, loss: 0.246, 14432/28000 datapoints
2025-03-06 20:52:55,836 - INFO - training batch 501, loss: 0.149, 16032/28000 datapoints
2025-03-06 20:52:55,961 - INFO - training batch 551, loss: 0.218, 17632/28000 datapoints
2025-03-06 20:52:56,083 - INFO - training batch 601, loss: 0.241, 19232/28000 datapoints
2025-03-06 20:52:56,202 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 20:52:56,325 - INFO - training batch 701, loss: 0.243, 22432/28000 datapoints
2025-03-06 20:52:56,445 - INFO - training batch 751, loss: 0.209, 24032/28000 datapoints
2025-03-06 20:52:56,567 - INFO - training batch 801, loss: 0.107, 25632/28000 datapoints
2025-03-06 20:52:56,688 - INFO - training batch 851, loss: 0.382, 27232/28000 datapoints
2025-03-06 20:52:56,748 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 20:52:56,793 - INFO - validation batch 51, loss: 1.161, 1632/6976 datapoints
2025-03-06 20:52:56,836 - INFO - validation batch 101, loss: 0.355, 3232/6976 datapoints
2025-03-06 20:52:56,882 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 20:52:56,926 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 20:52:56,941 - INFO - Epoch 378/800 done.
2025-03-06 20:52:56,941 - INFO - Final validation performance:
Loss: 0.492, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 20:52:56,942 - INFO - Beginning epoch 379/800
2025-03-06 20:52:56,945 - INFO - training batch 1, loss: 0.293, 32/28000 datapoints
2025-03-06 20:52:57,071 - INFO - training batch 51, loss: 0.086, 1632/28000 datapoints
2025-03-06 20:52:57,191 - INFO - training batch 101, loss: 0.125, 3232/28000 datapoints
2025-03-06 20:52:57,313 - INFO - training batch 151, loss: 0.238, 4832/28000 datapoints
2025-03-06 20:52:57,433 - INFO - training batch 201, loss: 0.091, 6432/28000 datapoints
2025-03-06 20:52:57,552 - INFO - training batch 251, loss: 0.314, 8032/28000 datapoints
2025-03-06 20:52:57,678 - INFO - training batch 301, loss: 0.514, 9632/28000 datapoints
2025-03-06 20:52:57,797 - INFO - training batch 351, loss: 0.229, 11232/28000 datapoints
2025-03-06 20:52:57,920 - INFO - training batch 401, loss: 0.493, 12832/28000 datapoints
2025-03-06 20:52:58,039 - INFO - training batch 451, loss: 0.243, 14432/28000 datapoints
2025-03-06 20:52:58,161 - INFO - training batch 501, loss: 0.149, 16032/28000 datapoints
2025-03-06 20:52:58,281 - INFO - training batch 551, loss: 0.218, 17632/28000 datapoints
2025-03-06 20:52:58,400 - INFO - training batch 601, loss: 0.239, 19232/28000 datapoints
2025-03-06 20:52:58,521 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 20:52:58,643 - INFO - training batch 701, loss: 0.242, 22432/28000 datapoints
2025-03-06 20:52:58,763 - INFO - training batch 751, loss: 0.208, 24032/28000 datapoints
2025-03-06 20:52:58,882 - INFO - training batch 801, loss: 0.107, 25632/28000 datapoints
2025-03-06 20:52:59,003 - INFO - training batch 851, loss: 0.379, 27232/28000 datapoints
2025-03-06 20:52:59,063 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 20:52:59,107 - INFO - validation batch 51, loss: 1.164, 1632/6976 datapoints
2025-03-06 20:52:59,150 - INFO - validation batch 101, loss: 0.357, 3232/6976 datapoints
2025-03-06 20:52:59,194 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 20:52:59,237 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 20:52:59,253 - INFO - Epoch 379/800 done.
2025-03-06 20:52:59,253 - INFO - Final validation performance:
Loss: 0.493, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 20:52:59,254 - INFO - Beginning epoch 380/800
2025-03-06 20:52:59,257 - INFO - training batch 1, loss: 0.293, 32/28000 datapoints
2025-03-06 20:52:59,379 - INFO - training batch 51, loss: 0.086, 1632/28000 datapoints
2025-03-06 20:52:59,498 - INFO - training batch 101, loss: 0.126, 3232/28000 datapoints
2025-03-06 20:52:59,621 - INFO - training batch 151, loss: 0.235, 4832/28000 datapoints
2025-03-06 20:52:59,744 - INFO - training batch 201, loss: 0.090, 6432/28000 datapoints
2025-03-06 20:52:59,863 - INFO - training batch 251, loss: 0.315, 8032/28000 datapoints
2025-03-06 20:52:59,988 - INFO - training batch 301, loss: 0.511, 9632/28000 datapoints
2025-03-06 20:53:00,111 - INFO - training batch 351, loss: 0.229, 11232/28000 datapoints
2025-03-06 20:53:00,229 - INFO - training batch 401, loss: 0.492, 12832/28000 datapoints
2025-03-06 20:53:00,348 - INFO - training batch 451, loss: 0.243, 14432/28000 datapoints
2025-03-06 20:53:00,468 - INFO - training batch 501, loss: 0.149, 16032/28000 datapoints
2025-03-06 20:53:00,590 - INFO - training batch 551, loss: 0.217, 17632/28000 datapoints
2025-03-06 20:53:00,711 - INFO - training batch 601, loss: 0.236, 19232/28000 datapoints
2025-03-06 20:53:00,831 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 20:53:00,953 - INFO - training batch 701, loss: 0.242, 22432/28000 datapoints
2025-03-06 20:53:01,074 - INFO - training batch 751, loss: 0.208, 24032/28000 datapoints
2025-03-06 20:53:01,194 - INFO - training batch 801, loss: 0.107, 25632/28000 datapoints
2025-03-06 20:53:01,314 - INFO - training batch 851, loss: 0.378, 27232/28000 datapoints
2025-03-06 20:53:01,374 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:53:01,417 - INFO - validation batch 51, loss: 1.165, 1632/6976 datapoints
2025-03-06 20:53:01,461 - INFO - validation batch 101, loss: 0.358, 3232/6976 datapoints
2025-03-06 20:53:01,504 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 20:53:01,548 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-06 20:53:01,563 - INFO - Epoch 380/800 done.
2025-03-06 20:53:01,563 - INFO - Final validation performance:
Loss: 0.494, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 20:53:01,564 - INFO - Beginning epoch 381/800
2025-03-06 20:53:01,567 - INFO - training batch 1, loss: 0.292, 32/28000 datapoints
2025-03-06 20:53:01,693 - INFO - training batch 51, loss: 0.085, 1632/28000 datapoints
2025-03-06 20:53:01,813 - INFO - training batch 101, loss: 0.125, 3232/28000 datapoints
2025-03-06 20:53:01,938 - INFO - training batch 151, loss: 0.232, 4832/28000 datapoints
2025-03-06 20:53:02,057 - INFO - training batch 201, loss: 0.090, 6432/28000 datapoints
2025-03-06 20:53:02,177 - INFO - training batch 251, loss: 0.314, 8032/28000 datapoints
2025-03-06 20:53:02,294 - INFO - training batch 301, loss: 0.509, 9632/28000 datapoints
2025-03-06 20:53:02,416 - INFO - training batch 351, loss: 0.228, 11232/28000 datapoints
2025-03-06 20:53:02,546 - INFO - training batch 401, loss: 0.490, 12832/28000 datapoints
2025-03-06 20:53:02,689 - INFO - training batch 451, loss: 0.242, 14432/28000 datapoints
2025-03-06 20:53:02,808 - INFO - training batch 501, loss: 0.148, 16032/28000 datapoints
2025-03-06 20:53:02,928 - INFO - training batch 551, loss: 0.216, 17632/28000 datapoints
2025-03-06 20:53:03,047 - INFO - training batch 601, loss: 0.234, 19232/28000 datapoints
2025-03-06 20:53:03,168 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 20:53:03,286 - INFO - training batch 701, loss: 0.241, 22432/28000 datapoints
2025-03-06 20:53:03,406 - INFO - training batch 751, loss: 0.206, 24032/28000 datapoints
2025-03-06 20:53:03,525 - INFO - training batch 801, loss: 0.107, 25632/28000 datapoints
2025-03-06 20:53:03,648 - INFO - training batch 851, loss: 0.375, 27232/28000 datapoints
2025-03-06 20:53:03,707 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:53:03,750 - INFO - validation batch 51, loss: 1.165, 1632/6976 datapoints
2025-03-06 20:53:03,794 - INFO - validation batch 101, loss: 0.359, 3232/6976 datapoints
2025-03-06 20:53:03,837 - INFO - validation batch 151, loss: 0.408, 4832/6976 datapoints
2025-03-06 20:53:03,881 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-06 20:53:03,896 - INFO - Epoch 381/800 done.
2025-03-06 20:53:03,896 - INFO - Final validation performance:
Loss: 0.494, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 20:53:03,896 - INFO - Beginning epoch 382/800
2025-03-06 20:53:03,900 - INFO - training batch 1, loss: 0.292, 32/28000 datapoints
2025-03-06 20:53:04,025 - INFO - training batch 51, loss: 0.085, 1632/28000 datapoints
2025-03-06 20:53:04,146 - INFO - training batch 101, loss: 0.124, 3232/28000 datapoints
2025-03-06 20:53:04,265 - INFO - training batch 151, loss: 0.229, 4832/28000 datapoints
2025-03-06 20:53:04,409 - INFO - training batch 201, loss: 0.089, 6432/28000 datapoints
2025-03-06 20:53:04,528 - INFO - training batch 251, loss: 0.312, 8032/28000 datapoints
2025-03-06 20:53:04,652 - INFO - training batch 301, loss: 0.508, 9632/28000 datapoints
2025-03-06 20:53:04,771 - INFO - training batch 351, loss: 0.227, 11232/28000 datapoints
2025-03-06 20:53:04,891 - INFO - training batch 401, loss: 0.488, 12832/28000 datapoints
2025-03-06 20:53:05,024 - INFO - training batch 451, loss: 0.242, 14432/28000 datapoints
2025-03-06 20:53:05,148 - INFO - training batch 501, loss: 0.149, 16032/28000 datapoints
2025-03-06 20:53:05,291 - INFO - training batch 551, loss: 0.215, 17632/28000 datapoints
2025-03-06 20:53:05,436 - INFO - training batch 601, loss: 0.231, 19232/28000 datapoints
2025-03-06 20:53:05,557 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 20:53:05,681 - INFO - training batch 701, loss: 0.241, 22432/28000 datapoints
2025-03-06 20:53:05,799 - INFO - training batch 751, loss: 0.206, 24032/28000 datapoints
2025-03-06 20:53:05,918 - INFO - training batch 801, loss: 0.107, 25632/28000 datapoints
2025-03-06 20:53:06,057 - INFO - training batch 851, loss: 0.373, 27232/28000 datapoints
2025-03-06 20:53:06,129 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:53:06,185 - INFO - validation batch 51, loss: 1.167, 1632/6976 datapoints
2025-03-06 20:53:06,244 - INFO - validation batch 101, loss: 0.360, 3232/6976 datapoints
2025-03-06 20:53:06,303 - INFO - validation batch 151, loss: 0.409, 4832/6976 datapoints
2025-03-06 20:53:06,352 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 20:53:06,370 - INFO - Epoch 382/800 done.
2025-03-06 20:53:06,370 - INFO - Final validation performance:
Loss: 0.495, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 20:53:06,370 - INFO - Beginning epoch 383/800
2025-03-06 20:53:06,374 - INFO - training batch 1, loss: 0.292, 32/28000 datapoints
2025-03-06 20:53:06,512 - INFO - training batch 51, loss: 0.085, 1632/28000 datapoints
2025-03-06 20:53:06,661 - INFO - training batch 101, loss: 0.124, 3232/28000 datapoints
2025-03-06 20:53:06,786 - INFO - training batch 151, loss: 0.226, 4832/28000 datapoints
2025-03-06 20:53:06,908 - INFO - training batch 201, loss: 0.088, 6432/28000 datapoints
2025-03-06 20:53:07,028 - INFO - training batch 251, loss: 0.311, 8032/28000 datapoints
2025-03-06 20:53:07,148 - INFO - training batch 301, loss: 0.506, 9632/28000 datapoints
2025-03-06 20:53:07,269 - INFO - training batch 351, loss: 0.226, 11232/28000 datapoints
2025-03-06 20:53:07,391 - INFO - training batch 401, loss: 0.487, 12832/28000 datapoints
2025-03-06 20:53:07,510 - INFO - training batch 451, loss: 0.241, 14432/28000 datapoints
2025-03-06 20:53:07,637 - INFO - training batch 501, loss: 0.148, 16032/28000 datapoints
2025-03-06 20:53:07,767 - INFO - training batch 551, loss: 0.215, 17632/28000 datapoints
2025-03-06 20:53:07,897 - INFO - training batch 601, loss: 0.229, 19232/28000 datapoints
2025-03-06 20:53:08,024 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 20:53:08,149 - INFO - training batch 701, loss: 0.240, 22432/28000 datapoints
2025-03-06 20:53:08,275 - INFO - training batch 751, loss: 0.206, 24032/28000 datapoints
2025-03-06 20:53:08,400 - INFO - training batch 801, loss: 0.106, 25632/28000 datapoints
2025-03-06 20:53:08,528 - INFO - training batch 851, loss: 0.371, 27232/28000 datapoints
2025-03-06 20:53:08,591 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:53:08,642 - INFO - validation batch 51, loss: 1.168, 1632/6976 datapoints
2025-03-06 20:53:08,690 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 20:53:08,741 - INFO - validation batch 151, loss: 0.409, 4832/6976 datapoints
2025-03-06 20:53:08,788 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 20:53:08,804 - INFO - Epoch 383/800 done.
2025-03-06 20:53:08,804 - INFO - Final validation performance:
Loss: 0.496, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 20:53:08,804 - INFO - Beginning epoch 384/800
2025-03-06 20:53:08,808 - INFO - training batch 1, loss: 0.291, 32/28000 datapoints
2025-03-06 20:53:08,933 - INFO - training batch 51, loss: 0.084, 1632/28000 datapoints
2025-03-06 20:53:09,062 - INFO - training batch 101, loss: 0.123, 3232/28000 datapoints
2025-03-06 20:53:09,196 - INFO - training batch 151, loss: 0.223, 4832/28000 datapoints
2025-03-06 20:53:09,323 - INFO - training batch 201, loss: 0.088, 6432/28000 datapoints
2025-03-06 20:53:09,446 - INFO - training batch 251, loss: 0.311, 8032/28000 datapoints
2025-03-06 20:53:09,569 - INFO - training batch 301, loss: 0.503, 9632/28000 datapoints
2025-03-06 20:53:09,695 - INFO - training batch 351, loss: 0.226, 11232/28000 datapoints
2025-03-06 20:53:09,819 - INFO - training batch 401, loss: 0.485, 12832/28000 datapoints
2025-03-06 20:53:09,941 - INFO - training batch 451, loss: 0.242, 14432/28000 datapoints
2025-03-06 20:53:10,067 - INFO - training batch 501, loss: 0.148, 16032/28000 datapoints
2025-03-06 20:53:10,193 - INFO - training batch 551, loss: 0.214, 17632/28000 datapoints
2025-03-06 20:53:10,318 - INFO - training batch 601, loss: 0.227, 19232/28000 datapoints
2025-03-06 20:53:10,444 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 20:53:10,567 - INFO - training batch 701, loss: 0.239, 22432/28000 datapoints
2025-03-06 20:53:10,694 - INFO - training batch 751, loss: 0.204, 24032/28000 datapoints
2025-03-06 20:53:10,819 - INFO - training batch 801, loss: 0.106, 25632/28000 datapoints
2025-03-06 20:53:10,946 - INFO - training batch 851, loss: 0.369, 27232/28000 datapoints
2025-03-06 20:53:11,008 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:53:11,058 - INFO - validation batch 51, loss: 1.170, 1632/6976 datapoints
2025-03-06 20:53:11,109 - INFO - validation batch 101, loss: 0.363, 3232/6976 datapoints
2025-03-06 20:53:11,160 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-06 20:53:11,211 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 20:53:11,231 - INFO - Epoch 384/800 done.
2025-03-06 20:53:11,232 - INFO - Final validation performance:
Loss: 0.497, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 20:53:11,232 - INFO - Beginning epoch 385/800
2025-03-06 20:53:11,236 - INFO - training batch 1, loss: 0.291, 32/28000 datapoints
2025-03-06 20:53:11,361 - INFO - training batch 51, loss: 0.083, 1632/28000 datapoints
2025-03-06 20:53:11,484 - INFO - training batch 101, loss: 0.123, 3232/28000 datapoints
2025-03-06 20:53:11,606 - INFO - training batch 151, loss: 0.220, 4832/28000 datapoints
2025-03-06 20:53:11,729 - INFO - training batch 201, loss: 0.087, 6432/28000 datapoints
2025-03-06 20:53:11,850 - INFO - training batch 251, loss: 0.310, 8032/28000 datapoints
2025-03-06 20:53:11,975 - INFO - training batch 301, loss: 0.503, 9632/28000 datapoints
2025-03-06 20:53:12,095 - INFO - training batch 351, loss: 0.225, 11232/28000 datapoints
2025-03-06 20:53:12,214 - INFO - training batch 401, loss: 0.483, 12832/28000 datapoints
2025-03-06 20:53:12,336 - INFO - training batch 451, loss: 0.240, 14432/28000 datapoints
2025-03-06 20:53:12,460 - INFO - training batch 501, loss: 0.148, 16032/28000 datapoints
2025-03-06 20:53:12,580 - INFO - training batch 551, loss: 0.213, 17632/28000 datapoints
2025-03-06 20:53:12,732 - INFO - training batch 601, loss: 0.225, 19232/28000 datapoints
2025-03-06 20:53:12,853 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 20:53:12,973 - INFO - training batch 701, loss: 0.239, 22432/28000 datapoints
2025-03-06 20:53:13,092 - INFO - training batch 751, loss: 0.205, 24032/28000 datapoints
2025-03-06 20:53:13,211 - INFO - training batch 801, loss: 0.106, 25632/28000 datapoints
2025-03-06 20:53:13,338 - INFO - training batch 851, loss: 0.367, 27232/28000 datapoints
2025-03-06 20:53:13,398 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:53:13,442 - INFO - validation batch 51, loss: 1.171, 1632/6976 datapoints
2025-03-06 20:53:13,486 - INFO - validation batch 101, loss: 0.364, 3232/6976 datapoints
2025-03-06 20:53:13,531 - INFO - validation batch 151, loss: 0.409, 4832/6976 datapoints
2025-03-06 20:53:13,575 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:53:13,590 - INFO - Epoch 385/800 done.
2025-03-06 20:53:13,591 - INFO - Final validation performance:
Loss: 0.497, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 20:53:13,591 - INFO - Beginning epoch 386/800
2025-03-06 20:53:13,595 - INFO - training batch 1, loss: 0.290, 32/28000 datapoints
2025-03-06 20:53:13,719 - INFO - training batch 51, loss: 0.083, 1632/28000 datapoints
2025-03-06 20:53:13,843 - INFO - training batch 101, loss: 0.123, 3232/28000 datapoints
2025-03-06 20:53:13,963 - INFO - training batch 151, loss: 0.217, 4832/28000 datapoints
2025-03-06 20:53:14,087 - INFO - training batch 201, loss: 0.086, 6432/28000 datapoints
2025-03-06 20:53:14,207 - INFO - training batch 251, loss: 0.309, 8032/28000 datapoints
2025-03-06 20:53:14,326 - INFO - training batch 301, loss: 0.501, 9632/28000 datapoints
2025-03-06 20:53:14,446 - INFO - training batch 351, loss: 0.224, 11232/28000 datapoints
2025-03-06 20:53:14,587 - INFO - training batch 401, loss: 0.482, 12832/28000 datapoints
2025-03-06 20:53:14,725 - INFO - training batch 451, loss: 0.239, 14432/28000 datapoints
2025-03-06 20:53:14,847 - INFO - training batch 501, loss: 0.147, 16032/28000 datapoints
2025-03-06 20:53:14,974 - INFO - training batch 551, loss: 0.213, 17632/28000 datapoints
2025-03-06 20:53:15,096 - INFO - training batch 601, loss: 0.222, 19232/28000 datapoints
2025-03-06 20:53:15,216 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 20:53:15,337 - INFO - training batch 701, loss: 0.238, 22432/28000 datapoints
2025-03-06 20:53:15,459 - INFO - training batch 751, loss: 0.204, 24032/28000 datapoints
2025-03-06 20:53:15,580 - INFO - training batch 801, loss: 0.107, 25632/28000 datapoints
2025-03-06 20:53:15,707 - INFO - training batch 851, loss: 0.366, 27232/28000 datapoints
2025-03-06 20:53:15,767 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:53:15,812 - INFO - validation batch 51, loss: 1.172, 1632/6976 datapoints
2025-03-06 20:53:15,855 - INFO - validation batch 101, loss: 0.365, 3232/6976 datapoints
2025-03-06 20:53:15,899 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-06 20:53:15,942 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 20:53:15,958 - INFO - Epoch 386/800 done.
2025-03-06 20:53:15,958 - INFO - Final validation performance:
Loss: 0.498, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:15,958 - INFO - Beginning epoch 387/800
2025-03-06 20:53:15,962 - INFO - training batch 1, loss: 0.290, 32/28000 datapoints
2025-03-06 20:53:16,086 - INFO - training batch 51, loss: 0.083, 1632/28000 datapoints
2025-03-06 20:53:16,208 - INFO - training batch 101, loss: 0.122, 3232/28000 datapoints
2025-03-06 20:53:16,331 - INFO - training batch 151, loss: 0.215, 4832/28000 datapoints
2025-03-06 20:53:16,451 - INFO - training batch 201, loss: 0.086, 6432/28000 datapoints
2025-03-06 20:53:16,570 - INFO - training batch 251, loss: 0.309, 8032/28000 datapoints
2025-03-06 20:53:16,692 - INFO - training batch 301, loss: 0.498, 9632/28000 datapoints
2025-03-06 20:53:16,813 - INFO - training batch 351, loss: 0.223, 11232/28000 datapoints
2025-03-06 20:53:16,933 - INFO - training batch 401, loss: 0.480, 12832/28000 datapoints
2025-03-06 20:53:17,053 - INFO - training batch 451, loss: 0.239, 14432/28000 datapoints
2025-03-06 20:53:17,174 - INFO - training batch 501, loss: 0.147, 16032/28000 datapoints
2025-03-06 20:53:17,293 - INFO - training batch 551, loss: 0.212, 17632/28000 datapoints
2025-03-06 20:53:17,416 - INFO - training batch 601, loss: 0.219, 19232/28000 datapoints
2025-03-06 20:53:17,536 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 20:53:17,658 - INFO - training batch 701, loss: 0.238, 22432/28000 datapoints
2025-03-06 20:53:17,779 - INFO - training batch 751, loss: 0.202, 24032/28000 datapoints
2025-03-06 20:53:17,899 - INFO - training batch 801, loss: 0.106, 25632/28000 datapoints
2025-03-06 20:53:18,022 - INFO - training batch 851, loss: 0.363, 27232/28000 datapoints
2025-03-06 20:53:18,081 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:53:18,124 - INFO - validation batch 51, loss: 1.173, 1632/6976 datapoints
2025-03-06 20:53:18,168 - INFO - validation batch 101, loss: 0.367, 3232/6976 datapoints
2025-03-06 20:53:18,213 - INFO - validation batch 151, loss: 0.411, 4832/6976 datapoints
2025-03-06 20:53:18,257 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 20:53:18,272 - INFO - Epoch 387/800 done.
2025-03-06 20:53:18,273 - INFO - Final validation performance:
Loss: 0.498, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 20:53:18,273 - INFO - Beginning epoch 388/800
2025-03-06 20:53:18,276 - INFO - training batch 1, loss: 0.290, 32/28000 datapoints
2025-03-06 20:53:18,400 - INFO - training batch 51, loss: 0.082, 1632/28000 datapoints
2025-03-06 20:53:18,521 - INFO - training batch 101, loss: 0.121, 3232/28000 datapoints
2025-03-06 20:53:18,643 - INFO - training batch 151, loss: 0.212, 4832/28000 datapoints
2025-03-06 20:53:18,762 - INFO - training batch 201, loss: 0.085, 6432/28000 datapoints
2025-03-06 20:53:18,886 - INFO - training batch 251, loss: 0.308, 8032/28000 datapoints
2025-03-06 20:53:19,007 - INFO - training batch 301, loss: 0.498, 9632/28000 datapoints
2025-03-06 20:53:19,128 - INFO - training batch 351, loss: 0.223, 11232/28000 datapoints
2025-03-06 20:53:19,247 - INFO - training batch 401, loss: 0.479, 12832/28000 datapoints
2025-03-06 20:53:19,370 - INFO - training batch 451, loss: 0.238, 14432/28000 datapoints
2025-03-06 20:53:19,490 - INFO - training batch 501, loss: 0.147, 16032/28000 datapoints
2025-03-06 20:53:19,614 - INFO - training batch 551, loss: 0.211, 17632/28000 datapoints
2025-03-06 20:53:19,737 - INFO - training batch 601, loss: 0.218, 19232/28000 datapoints
2025-03-06 20:53:19,857 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 20:53:19,976 - INFO - training batch 701, loss: 0.237, 22432/28000 datapoints
2025-03-06 20:53:20,101 - INFO - training batch 751, loss: 0.202, 24032/28000 datapoints
2025-03-06 20:53:20,225 - INFO - training batch 801, loss: 0.106, 25632/28000 datapoints
2025-03-06 20:53:20,347 - INFO - training batch 851, loss: 0.361, 27232/28000 datapoints
2025-03-06 20:53:20,406 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:53:20,452 - INFO - validation batch 51, loss: 1.174, 1632/6976 datapoints
2025-03-06 20:53:20,497 - INFO - validation batch 101, loss: 0.368, 3232/6976 datapoints
2025-03-06 20:53:20,540 - INFO - validation batch 151, loss: 0.411, 4832/6976 datapoints
2025-03-06 20:53:20,584 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:53:20,599 - INFO - Epoch 388/800 done.
2025-03-06 20:53:20,599 - INFO - Final validation performance:
Loss: 0.499, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 20:53:20,600 - INFO - Beginning epoch 389/800
2025-03-06 20:53:20,603 - INFO - training batch 1, loss: 0.290, 32/28000 datapoints
2025-03-06 20:53:20,729 - INFO - training batch 51, loss: 0.082, 1632/28000 datapoints
2025-03-06 20:53:20,848 - INFO - training batch 101, loss: 0.122, 3232/28000 datapoints
2025-03-06 20:53:20,976 - INFO - training batch 151, loss: 0.209, 4832/28000 datapoints
2025-03-06 20:53:21,096 - INFO - training batch 201, loss: 0.085, 6432/28000 datapoints
2025-03-06 20:53:21,217 - INFO - training batch 251, loss: 0.307, 8032/28000 datapoints
2025-03-06 20:53:21,338 - INFO - training batch 301, loss: 0.495, 9632/28000 datapoints
2025-03-06 20:53:21,458 - INFO - training batch 351, loss: 0.222, 11232/28000 datapoints
2025-03-06 20:53:21,578 - INFO - training batch 401, loss: 0.477, 12832/28000 datapoints
2025-03-06 20:53:21,700 - INFO - training batch 451, loss: 0.238, 14432/28000 datapoints
2025-03-06 20:53:21,821 - INFO - training batch 501, loss: 0.146, 16032/28000 datapoints
2025-03-06 20:53:21,945 - INFO - training batch 551, loss: 0.211, 17632/28000 datapoints
2025-03-06 20:53:22,071 - INFO - training batch 601, loss: 0.215, 19232/28000 datapoints
2025-03-06 20:53:22,191 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 20:53:22,310 - INFO - training batch 701, loss: 0.237, 22432/28000 datapoints
2025-03-06 20:53:22,433 - INFO - training batch 751, loss: 0.202, 24032/28000 datapoints
2025-03-06 20:53:22,554 - INFO - training batch 801, loss: 0.106, 25632/28000 datapoints
2025-03-06 20:53:22,677 - INFO - training batch 851, loss: 0.358, 27232/28000 datapoints
2025-03-06 20:53:22,741 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:53:22,803 - INFO - validation batch 51, loss: 1.176, 1632/6976 datapoints
2025-03-06 20:53:22,851 - INFO - validation batch 101, loss: 0.369, 3232/6976 datapoints
2025-03-06 20:53:22,897 - INFO - validation batch 151, loss: 0.411, 4832/6976 datapoints
2025-03-06 20:53:22,940 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 20:53:22,955 - INFO - Epoch 389/800 done.
2025-03-06 20:53:22,955 - INFO - Final validation performance:
Loss: 0.499, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:22,956 - INFO - Beginning epoch 390/800
2025-03-06 20:53:22,959 - INFO - training batch 1, loss: 0.288, 32/28000 datapoints
2025-03-06 20:53:23,081 - INFO - training batch 51, loss: 0.081, 1632/28000 datapoints
2025-03-06 20:53:23,201 - INFO - training batch 101, loss: 0.120, 3232/28000 datapoints
2025-03-06 20:53:23,321 - INFO - training batch 151, loss: 0.206, 4832/28000 datapoints
2025-03-06 20:53:23,442 - INFO - training batch 201, loss: 0.084, 6432/28000 datapoints
2025-03-06 20:53:23,566 - INFO - training batch 251, loss: 0.307, 8032/28000 datapoints
2025-03-06 20:53:23,689 - INFO - training batch 301, loss: 0.493, 9632/28000 datapoints
2025-03-06 20:53:23,808 - INFO - training batch 351, loss: 0.221, 11232/28000 datapoints
2025-03-06 20:53:23,929 - INFO - training batch 401, loss: 0.476, 12832/28000 datapoints
2025-03-06 20:53:24,055 - INFO - training batch 451, loss: 0.239, 14432/28000 datapoints
2025-03-06 20:53:24,175 - INFO - training batch 501, loss: 0.146, 16032/28000 datapoints
2025-03-06 20:53:24,297 - INFO - training batch 551, loss: 0.209, 17632/28000 datapoints
2025-03-06 20:53:24,420 - INFO - training batch 601, loss: 0.212, 19232/28000 datapoints
2025-03-06 20:53:24,539 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 20:53:24,661 - INFO - training batch 701, loss: 0.236, 22432/28000 datapoints
2025-03-06 20:53:24,781 - INFO - training batch 751, loss: 0.201, 24032/28000 datapoints
2025-03-06 20:53:24,906 - INFO - training batch 801, loss: 0.106, 25632/28000 datapoints
2025-03-06 20:53:25,028 - INFO - training batch 851, loss: 0.356, 27232/28000 datapoints
2025-03-06 20:53:25,087 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:53:25,131 - INFO - validation batch 51, loss: 1.177, 1632/6976 datapoints
2025-03-06 20:53:25,175 - INFO - validation batch 101, loss: 0.370, 3232/6976 datapoints
2025-03-06 20:53:25,219 - INFO - validation batch 151, loss: 0.411, 4832/6976 datapoints
2025-03-06 20:53:25,263 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:53:25,278 - INFO - Epoch 390/800 done.
2025-03-06 20:53:25,278 - INFO - Final validation performance:
Loss: 0.500, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:25,279 - INFO - Beginning epoch 391/800
2025-03-06 20:53:25,282 - INFO - training batch 1, loss: 0.288, 32/28000 datapoints
2025-03-06 20:53:25,405 - INFO - training batch 51, loss: 0.081, 1632/28000 datapoints
2025-03-06 20:53:25,532 - INFO - training batch 101, loss: 0.120, 3232/28000 datapoints
2025-03-06 20:53:25,659 - INFO - training batch 151, loss: 0.203, 4832/28000 datapoints
2025-03-06 20:53:25,781 - INFO - training batch 201, loss: 0.084, 6432/28000 datapoints
2025-03-06 20:53:25,900 - INFO - training batch 251, loss: 0.305, 8032/28000 datapoints
2025-03-06 20:53:26,025 - INFO - training batch 301, loss: 0.492, 9632/28000 datapoints
2025-03-06 20:53:26,144 - INFO - training batch 351, loss: 0.220, 11232/28000 datapoints
2025-03-06 20:53:26,265 - INFO - training batch 401, loss: 0.474, 12832/28000 datapoints
2025-03-06 20:53:26,384 - INFO - training batch 451, loss: 0.236, 14432/28000 datapoints
2025-03-06 20:53:26,506 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-06 20:53:26,626 - INFO - training batch 551, loss: 0.208, 17632/28000 datapoints
2025-03-06 20:53:26,766 - INFO - training batch 601, loss: 0.209, 19232/28000 datapoints
2025-03-06 20:53:26,903 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 20:53:27,025 - INFO - training batch 701, loss: 0.235, 22432/28000 datapoints
2025-03-06 20:53:27,144 - INFO - training batch 751, loss: 0.199, 24032/28000 datapoints
2025-03-06 20:53:27,264 - INFO - training batch 801, loss: 0.105, 25632/28000 datapoints
2025-03-06 20:53:27,383 - INFO - training batch 851, loss: 0.354, 27232/28000 datapoints
2025-03-06 20:53:27,446 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:53:27,490 - INFO - validation batch 51, loss: 1.178, 1632/6976 datapoints
2025-03-06 20:53:27,534 - INFO - validation batch 101, loss: 0.372, 3232/6976 datapoints
2025-03-06 20:53:27,578 - INFO - validation batch 151, loss: 0.412, 4832/6976 datapoints
2025-03-06 20:53:27,621 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:53:27,640 - INFO - Epoch 391/800 done.
2025-03-06 20:53:27,640 - INFO - Final validation performance:
Loss: 0.501, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:27,641 - INFO - Beginning epoch 392/800
2025-03-06 20:53:27,644 - INFO - training batch 1, loss: 0.288, 32/28000 datapoints
2025-03-06 20:53:27,776 - INFO - training batch 51, loss: 0.081, 1632/28000 datapoints
2025-03-06 20:53:27,899 - INFO - training batch 101, loss: 0.120, 3232/28000 datapoints
2025-03-06 20:53:28,029 - INFO - training batch 151, loss: 0.201, 4832/28000 datapoints
2025-03-06 20:53:28,156 - INFO - training batch 201, loss: 0.083, 6432/28000 datapoints
2025-03-06 20:53:28,281 - INFO - training batch 251, loss: 0.304, 8032/28000 datapoints
2025-03-06 20:53:28,405 - INFO - training batch 301, loss: 0.491, 9632/28000 datapoints
2025-03-06 20:53:28,530 - INFO - training batch 351, loss: 0.220, 11232/28000 datapoints
2025-03-06 20:53:28,657 - INFO - training batch 401, loss: 0.473, 12832/28000 datapoints
2025-03-06 20:53:28,781 - INFO - training batch 451, loss: 0.236, 14432/28000 datapoints
2025-03-06 20:53:28,906 - INFO - training batch 501, loss: 0.146, 16032/28000 datapoints
2025-03-06 20:53:29,033 - INFO - training batch 551, loss: 0.207, 17632/28000 datapoints
2025-03-06 20:53:29,165 - INFO - training batch 601, loss: 0.207, 19232/28000 datapoints
2025-03-06 20:53:29,291 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 20:53:29,414 - INFO - training batch 701, loss: 0.235, 22432/28000 datapoints
2025-03-06 20:53:29,542 - INFO - training batch 751, loss: 0.200, 24032/28000 datapoints
2025-03-06 20:53:29,668 - INFO - training batch 801, loss: 0.105, 25632/28000 datapoints
2025-03-06 20:53:29,791 - INFO - training batch 851, loss: 0.352, 27232/28000 datapoints
2025-03-06 20:53:29,855 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:53:29,904 - INFO - validation batch 51, loss: 1.179, 1632/6976 datapoints
2025-03-06 20:53:29,952 - INFO - validation batch 101, loss: 0.373, 3232/6976 datapoints
2025-03-06 20:53:30,002 - INFO - validation batch 151, loss: 0.412, 4832/6976 datapoints
2025-03-06 20:53:30,053 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:53:30,069 - INFO - Epoch 392/800 done.
2025-03-06 20:53:30,069 - INFO - Final validation performance:
Loss: 0.501, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:30,070 - INFO - Beginning epoch 393/800
2025-03-06 20:53:30,074 - INFO - training batch 1, loss: 0.287, 32/28000 datapoints
2025-03-06 20:53:30,198 - INFO - training batch 51, loss: 0.080, 1632/28000 datapoints
2025-03-06 20:53:30,318 - INFO - training batch 101, loss: 0.120, 3232/28000 datapoints
2025-03-06 20:53:30,438 - INFO - training batch 151, loss: 0.198, 4832/28000 datapoints
2025-03-06 20:53:30,561 - INFO - training batch 201, loss: 0.083, 6432/28000 datapoints
2025-03-06 20:53:30,683 - INFO - training batch 251, loss: 0.304, 8032/28000 datapoints
2025-03-06 20:53:30,804 - INFO - training batch 301, loss: 0.489, 9632/28000 datapoints
2025-03-06 20:53:30,924 - INFO - training batch 351, loss: 0.219, 11232/28000 datapoints
2025-03-06 20:53:31,047 - INFO - training batch 401, loss: 0.471, 12832/28000 datapoints
2025-03-06 20:53:31,166 - INFO - training batch 451, loss: 0.235, 14432/28000 datapoints
2025-03-06 20:53:31,288 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-06 20:53:31,409 - INFO - training batch 551, loss: 0.207, 17632/28000 datapoints
2025-03-06 20:53:31,529 - INFO - training batch 601, loss: 0.204, 19232/28000 datapoints
2025-03-06 20:53:31,655 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 20:53:31,774 - INFO - training batch 701, loss: 0.234, 22432/28000 datapoints
2025-03-06 20:53:31,896 - INFO - training batch 751, loss: 0.199, 24032/28000 datapoints
2025-03-06 20:53:32,015 - INFO - training batch 801, loss: 0.105, 25632/28000 datapoints
2025-03-06 20:53:32,138 - INFO - training batch 851, loss: 0.350, 27232/28000 datapoints
2025-03-06 20:53:32,197 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:53:32,242 - INFO - validation batch 51, loss: 1.180, 1632/6976 datapoints
2025-03-06 20:53:32,285 - INFO - validation batch 101, loss: 0.374, 3232/6976 datapoints
2025-03-06 20:53:32,329 - INFO - validation batch 151, loss: 0.412, 4832/6976 datapoints
2025-03-06 20:53:32,372 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:53:32,387 - INFO - Epoch 393/800 done.
2025-03-06 20:53:32,387 - INFO - Final validation performance:
Loss: 0.502, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:32,388 - INFO - Beginning epoch 394/800
2025-03-06 20:53:32,392 - INFO - training batch 1, loss: 0.287, 32/28000 datapoints
2025-03-06 20:53:32,516 - INFO - training batch 51, loss: 0.080, 1632/28000 datapoints
2025-03-06 20:53:32,634 - INFO - training batch 101, loss: 0.118, 3232/28000 datapoints
2025-03-06 20:53:32,756 - INFO - training batch 151, loss: 0.195, 4832/28000 datapoints
2025-03-06 20:53:32,901 - INFO - training batch 201, loss: 0.082, 6432/28000 datapoints
2025-03-06 20:53:33,027 - INFO - training batch 251, loss: 0.303, 8032/28000 datapoints
2025-03-06 20:53:33,147 - INFO - training batch 301, loss: 0.486, 9632/28000 datapoints
2025-03-06 20:53:33,266 - INFO - training batch 351, loss: 0.219, 11232/28000 datapoints
2025-03-06 20:53:33,385 - INFO - training batch 401, loss: 0.470, 12832/28000 datapoints
2025-03-06 20:53:33,505 - INFO - training batch 451, loss: 0.234, 14432/28000 datapoints
2025-03-06 20:53:33,627 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-06 20:53:33,750 - INFO - training batch 551, loss: 0.206, 17632/28000 datapoints
2025-03-06 20:53:33,869 - INFO - training batch 601, loss: 0.202, 19232/28000 datapoints
2025-03-06 20:53:33,990 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 20:53:34,114 - INFO - training batch 701, loss: 0.234, 22432/28000 datapoints
2025-03-06 20:53:34,234 - INFO - training batch 751, loss: 0.198, 24032/28000 datapoints
2025-03-06 20:53:34,354 - INFO - training batch 801, loss: 0.105, 25632/28000 datapoints
2025-03-06 20:53:34,480 - INFO - training batch 851, loss: 0.348, 27232/28000 datapoints
2025-03-06 20:53:34,539 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:53:34,585 - INFO - validation batch 51, loss: 1.180, 1632/6976 datapoints
2025-03-06 20:53:34,628 - INFO - validation batch 101, loss: 0.376, 3232/6976 datapoints
2025-03-06 20:53:34,674 - INFO - validation batch 151, loss: 0.413, 4832/6976 datapoints
2025-03-06 20:53:34,719 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:53:34,734 - INFO - Epoch 394/800 done.
2025-03-06 20:53:34,735 - INFO - Final validation performance:
Loss: 0.502, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:34,735 - INFO - Beginning epoch 395/800
2025-03-06 20:53:34,738 - INFO - training batch 1, loss: 0.288, 32/28000 datapoints
2025-03-06 20:53:34,864 - INFO - training batch 51, loss: 0.079, 1632/28000 datapoints
2025-03-06 20:53:34,990 - INFO - training batch 101, loss: 0.118, 3232/28000 datapoints
2025-03-06 20:53:35,115 - INFO - training batch 151, loss: 0.193, 4832/28000 datapoints
2025-03-06 20:53:35,233 - INFO - training batch 201, loss: 0.082, 6432/28000 datapoints
2025-03-06 20:53:35,351 - INFO - training batch 251, loss: 0.302, 8032/28000 datapoints
2025-03-06 20:53:35,474 - INFO - training batch 301, loss: 0.485, 9632/28000 datapoints
2025-03-06 20:53:35,595 - INFO - training batch 351, loss: 0.218, 11232/28000 datapoints
2025-03-06 20:53:35,723 - INFO - training batch 401, loss: 0.468, 12832/28000 datapoints
2025-03-06 20:53:35,841 - INFO - training batch 451, loss: 0.233, 14432/28000 datapoints
2025-03-06 20:53:35,962 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-06 20:53:36,086 - INFO - training batch 551, loss: 0.205, 17632/28000 datapoints
2025-03-06 20:53:36,204 - INFO - training batch 601, loss: 0.199, 19232/28000 datapoints
2025-03-06 20:53:36,324 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 20:53:36,443 - INFO - training batch 701, loss: 0.233, 22432/28000 datapoints
2025-03-06 20:53:36,562 - INFO - training batch 751, loss: 0.198, 24032/28000 datapoints
2025-03-06 20:53:36,684 - INFO - training batch 801, loss: 0.104, 25632/28000 datapoints
2025-03-06 20:53:36,805 - INFO - training batch 851, loss: 0.345, 27232/28000 datapoints
2025-03-06 20:53:36,864 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:53:36,909 - INFO - validation batch 51, loss: 1.182, 1632/6976 datapoints
2025-03-06 20:53:36,952 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-06 20:53:36,995 - INFO - validation batch 151, loss: 0.413, 4832/6976 datapoints
2025-03-06 20:53:37,039 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:53:37,055 - INFO - Epoch 395/800 done.
2025-03-06 20:53:37,055 - INFO - Final validation performance:
Loss: 0.503, top-1 acc: 0.873top-5 acc: 0.873
2025-03-06 20:53:37,055 - INFO - Beginning epoch 396/800
2025-03-06 20:53:37,059 - INFO - training batch 1, loss: 0.287, 32/28000 datapoints
2025-03-06 20:53:37,180 - INFO - training batch 51, loss: 0.079, 1632/28000 datapoints
2025-03-06 20:53:37,300 - INFO - training batch 101, loss: 0.118, 3232/28000 datapoints
2025-03-06 20:53:37,420 - INFO - training batch 151, loss: 0.191, 4832/28000 datapoints
2025-03-06 20:53:37,540 - INFO - training batch 201, loss: 0.081, 6432/28000 datapoints
2025-03-06 20:53:37,689 - INFO - training batch 251, loss: 0.302, 8032/28000 datapoints
2025-03-06 20:53:37,826 - INFO - training batch 301, loss: 0.483, 9632/28000 datapoints
2025-03-06 20:53:37,984 - INFO - training batch 351, loss: 0.218, 11232/28000 datapoints
2025-03-06 20:53:38,111 - INFO - training batch 401, loss: 0.467, 12832/28000 datapoints
2025-03-06 20:53:38,232 - INFO - training batch 451, loss: 0.234, 14432/28000 datapoints
2025-03-06 20:53:38,351 - INFO - training batch 501, loss: 0.144, 16032/28000 datapoints
2025-03-06 20:53:38,471 - INFO - training batch 551, loss: 0.204, 17632/28000 datapoints
2025-03-06 20:53:38,592 - INFO - training batch 601, loss: 0.198, 19232/28000 datapoints
2025-03-06 20:53:38,718 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 20:53:38,837 - INFO - training batch 701, loss: 0.233, 22432/28000 datapoints
2025-03-06 20:53:38,956 - INFO - training batch 751, loss: 0.197, 24032/28000 datapoints
2025-03-06 20:53:39,085 - INFO - training batch 801, loss: 0.104, 25632/28000 datapoints
2025-03-06 20:53:39,204 - INFO - training batch 851, loss: 0.344, 27232/28000 datapoints
2025-03-06 20:53:39,264 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:53:39,308 - INFO - validation batch 51, loss: 1.183, 1632/6976 datapoints
2025-03-06 20:53:39,352 - INFO - validation batch 101, loss: 0.378, 3232/6976 datapoints
2025-03-06 20:53:39,396 - INFO - validation batch 151, loss: 0.414, 4832/6976 datapoints
2025-03-06 20:53:39,440 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:53:39,455 - INFO - Epoch 396/800 done.
2025-03-06 20:53:39,456 - INFO - Final validation performance:
Loss: 0.503, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:39,456 - INFO - Beginning epoch 397/800
2025-03-06 20:53:39,460 - INFO - training batch 1, loss: 0.286, 32/28000 datapoints
2025-03-06 20:53:39,581 - INFO - training batch 51, loss: 0.079, 1632/28000 datapoints
2025-03-06 20:53:39,710 - INFO - training batch 101, loss: 0.118, 3232/28000 datapoints
2025-03-06 20:53:39,829 - INFO - training batch 151, loss: 0.188, 4832/28000 datapoints
2025-03-06 20:53:39,948 - INFO - training batch 201, loss: 0.081, 6432/28000 datapoints
2025-03-06 20:53:40,077 - INFO - training batch 251, loss: 0.301, 8032/28000 datapoints
2025-03-06 20:53:40,197 - INFO - training batch 301, loss: 0.480, 9632/28000 datapoints
2025-03-06 20:53:40,315 - INFO - training batch 351, loss: 0.217, 11232/28000 datapoints
2025-03-06 20:53:40,435 - INFO - training batch 401, loss: 0.466, 12832/28000 datapoints
2025-03-06 20:53:40,556 - INFO - training batch 451, loss: 0.232, 14432/28000 datapoints
2025-03-06 20:53:40,680 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-06 20:53:40,803 - INFO - training batch 551, loss: 0.203, 17632/28000 datapoints
2025-03-06 20:53:40,922 - INFO - training batch 601, loss: 0.193, 19232/28000 datapoints
2025-03-06 20:53:41,047 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 20:53:41,166 - INFO - training batch 701, loss: 0.232, 22432/28000 datapoints
2025-03-06 20:53:41,285 - INFO - training batch 751, loss: 0.195, 24032/28000 datapoints
2025-03-06 20:53:41,404 - INFO - training batch 801, loss: 0.104, 25632/28000 datapoints
2025-03-06 20:53:41,523 - INFO - training batch 851, loss: 0.342, 27232/28000 datapoints
2025-03-06 20:53:41,582 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:53:41,626 - INFO - validation batch 51, loss: 1.184, 1632/6976 datapoints
2025-03-06 20:53:41,674 - INFO - validation batch 101, loss: 0.379, 3232/6976 datapoints
2025-03-06 20:53:41,718 - INFO - validation batch 151, loss: 0.415, 4832/6976 datapoints
2025-03-06 20:53:41,764 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:53:41,779 - INFO - Epoch 397/800 done.
2025-03-06 20:53:41,779 - INFO - Final validation performance:
Loss: 0.504, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:41,780 - INFO - Beginning epoch 398/800
2025-03-06 20:53:41,783 - INFO - training batch 1, loss: 0.286, 32/28000 datapoints
2025-03-06 20:53:41,906 - INFO - training batch 51, loss: 0.078, 1632/28000 datapoints
2025-03-06 20:53:42,029 - INFO - training batch 101, loss: 0.117, 3232/28000 datapoints
2025-03-06 20:53:42,160 - INFO - training batch 151, loss: 0.185, 4832/28000 datapoints
2025-03-06 20:53:42,280 - INFO - training batch 201, loss: 0.080, 6432/28000 datapoints
2025-03-06 20:53:42,401 - INFO - training batch 251, loss: 0.300, 8032/28000 datapoints
2025-03-06 20:53:42,522 - INFO - training batch 301, loss: 0.480, 9632/28000 datapoints
2025-03-06 20:53:42,647 - INFO - training batch 351, loss: 0.216, 11232/28000 datapoints
2025-03-06 20:53:42,767 - INFO - training batch 401, loss: 0.465, 12832/28000 datapoints
2025-03-06 20:53:42,886 - INFO - training batch 451, loss: 0.231, 14432/28000 datapoints
2025-03-06 20:53:43,033 - INFO - training batch 501, loss: 0.144, 16032/28000 datapoints
2025-03-06 20:53:43,157 - INFO - training batch 551, loss: 0.202, 17632/28000 datapoints
2025-03-06 20:53:43,276 - INFO - training batch 601, loss: 0.194, 19232/28000 datapoints
2025-03-06 20:53:43,395 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 20:53:43,515 - INFO - training batch 701, loss: 0.232, 22432/28000 datapoints
2025-03-06 20:53:43,638 - INFO - training batch 751, loss: 0.196, 24032/28000 datapoints
2025-03-06 20:53:43,762 - INFO - training batch 801, loss: 0.104, 25632/28000 datapoints
2025-03-06 20:53:43,880 - INFO - training batch 851, loss: 0.339, 27232/28000 datapoints
2025-03-06 20:53:43,939 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:53:43,982 - INFO - validation batch 51, loss: 1.185, 1632/6976 datapoints
2025-03-06 20:53:44,026 - INFO - validation batch 101, loss: 0.380, 3232/6976 datapoints
2025-03-06 20:53:44,071 - INFO - validation batch 151, loss: 0.415, 4832/6976 datapoints
2025-03-06 20:53:44,118 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:53:44,133 - INFO - Epoch 398/800 done.
2025-03-06 20:53:44,133 - INFO - Final validation performance:
Loss: 0.505, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:44,134 - INFO - Beginning epoch 399/800
2025-03-06 20:53:44,137 - INFO - training batch 1, loss: 0.286, 32/28000 datapoints
2025-03-06 20:53:44,262 - INFO - training batch 51, loss: 0.078, 1632/28000 datapoints
2025-03-06 20:53:44,383 - INFO - training batch 101, loss: 0.117, 3232/28000 datapoints
2025-03-06 20:53:44,503 - INFO - training batch 151, loss: 0.183, 4832/28000 datapoints
2025-03-06 20:53:44,620 - INFO - training batch 201, loss: 0.080, 6432/28000 datapoints
2025-03-06 20:53:44,744 - INFO - training batch 251, loss: 0.300, 8032/28000 datapoints
2025-03-06 20:53:44,864 - INFO - training batch 301, loss: 0.478, 9632/28000 datapoints
2025-03-06 20:53:44,987 - INFO - training batch 351, loss: 0.216, 11232/28000 datapoints
2025-03-06 20:53:45,109 - INFO - training batch 401, loss: 0.463, 12832/28000 datapoints
2025-03-06 20:53:45,231 - INFO - training batch 451, loss: 0.230, 14432/28000 datapoints
2025-03-06 20:53:45,351 - INFO - training batch 501, loss: 0.144, 16032/28000 datapoints
2025-03-06 20:53:45,472 - INFO - training batch 551, loss: 0.202, 17632/28000 datapoints
2025-03-06 20:53:45,592 - INFO - training batch 601, loss: 0.190, 19232/28000 datapoints
2025-03-06 20:53:45,719 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 20:53:45,840 - INFO - training batch 701, loss: 0.231, 22432/28000 datapoints
2025-03-06 20:53:45,959 - INFO - training batch 751, loss: 0.194, 24032/28000 datapoints
2025-03-06 20:53:46,078 - INFO - training batch 801, loss: 0.103, 25632/28000 datapoints
2025-03-06 20:53:46,201 - INFO - training batch 851, loss: 0.337, 27232/28000 datapoints
2025-03-06 20:53:46,263 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:53:46,307 - INFO - validation batch 51, loss: 1.186, 1632/6976 datapoints
2025-03-06 20:53:46,351 - INFO - validation batch 101, loss: 0.382, 3232/6976 datapoints
2025-03-06 20:53:46,394 - INFO - validation batch 151, loss: 0.416, 4832/6976 datapoints
2025-03-06 20:53:46,439 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:53:46,454 - INFO - Epoch 399/800 done.
2025-03-06 20:53:46,454 - INFO - Final validation performance:
Loss: 0.505, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:46,454 - INFO - Beginning epoch 400/800
2025-03-06 20:53:46,458 - INFO - training batch 1, loss: 0.286, 32/28000 datapoints
2025-03-06 20:53:46,578 - INFO - training batch 51, loss: 0.077, 1632/28000 datapoints
2025-03-06 20:53:46,700 - INFO - training batch 101, loss: 0.116, 3232/28000 datapoints
2025-03-06 20:53:46,823 - INFO - training batch 151, loss: 0.181, 4832/28000 datapoints
2025-03-06 20:53:46,944 - INFO - training batch 201, loss: 0.079, 6432/28000 datapoints
2025-03-06 20:53:47,064 - INFO - training batch 251, loss: 0.299, 8032/28000 datapoints
2025-03-06 20:53:47,183 - INFO - training batch 301, loss: 0.475, 9632/28000 datapoints
2025-03-06 20:53:47,304 - INFO - training batch 351, loss: 0.215, 11232/28000 datapoints
2025-03-06 20:53:47,428 - INFO - training batch 401, loss: 0.462, 12832/28000 datapoints
2025-03-06 20:53:47,557 - INFO - training batch 451, loss: 0.231, 14432/28000 datapoints
2025-03-06 20:53:47,689 - INFO - training batch 501, loss: 0.143, 16032/28000 datapoints
2025-03-06 20:53:47,810 - INFO - training batch 551, loss: 0.201, 17632/28000 datapoints
2025-03-06 20:53:47,936 - INFO - training batch 601, loss: 0.190, 19232/28000 datapoints
2025-03-06 20:53:48,060 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 20:53:48,187 - INFO - training batch 701, loss: 0.230, 22432/28000 datapoints
2025-03-06 20:53:48,312 - INFO - training batch 751, loss: 0.194, 24032/28000 datapoints
2025-03-06 20:53:48,438 - INFO - training batch 801, loss: 0.103, 25632/28000 datapoints
2025-03-06 20:53:48,561 - INFO - training batch 851, loss: 0.336, 27232/28000 datapoints
2025-03-06 20:53:48,624 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:53:48,679 - INFO - validation batch 51, loss: 1.187, 1632/6976 datapoints
2025-03-06 20:53:48,740 - INFO - validation batch 101, loss: 0.383, 3232/6976 datapoints
2025-03-06 20:53:48,863 - INFO - validation batch 151, loss: 0.416, 4832/6976 datapoints
2025-03-06 20:53:48,932 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:53:48,949 - INFO - Epoch 400/800 done.
2025-03-06 20:53:48,949 - INFO - Final validation performance:
Loss: 0.506, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:48,949 - INFO - Beginning epoch 401/800
2025-03-06 20:53:48,953 - INFO - training batch 1, loss: 0.286, 32/28000 datapoints
2025-03-06 20:53:49,083 - INFO - training batch 51, loss: 0.077, 1632/28000 datapoints
2025-03-06 20:53:49,206 - INFO - training batch 101, loss: 0.116, 3232/28000 datapoints
2025-03-06 20:53:49,335 - INFO - training batch 151, loss: 0.179, 4832/28000 datapoints
2025-03-06 20:53:49,459 - INFO - training batch 201, loss: 0.079, 6432/28000 datapoints
2025-03-06 20:53:49,583 - INFO - training batch 251, loss: 0.298, 8032/28000 datapoints
2025-03-06 20:53:49,713 - INFO - training batch 301, loss: 0.474, 9632/28000 datapoints
2025-03-06 20:53:49,851 - INFO - training batch 351, loss: 0.215, 11232/28000 datapoints
2025-03-06 20:53:49,980 - INFO - training batch 401, loss: 0.460, 12832/28000 datapoints
2025-03-06 20:53:50,103 - INFO - training batch 451, loss: 0.229, 14432/28000 datapoints
2025-03-06 20:53:50,232 - INFO - training batch 501, loss: 0.144, 16032/28000 datapoints
2025-03-06 20:53:50,357 - INFO - training batch 551, loss: 0.200, 17632/28000 datapoints
2025-03-06 20:53:50,482 - INFO - training batch 601, loss: 0.187, 19232/28000 datapoints
2025-03-06 20:53:50,606 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 20:53:50,734 - INFO - training batch 701, loss: 0.230, 22432/28000 datapoints
2025-03-06 20:53:50,861 - INFO - training batch 751, loss: 0.194, 24032/28000 datapoints
2025-03-06 20:53:51,027 - INFO - training batch 801, loss: 0.103, 25632/28000 datapoints
2025-03-06 20:53:51,151 - INFO - training batch 851, loss: 0.333, 27232/28000 datapoints
2025-03-06 20:53:51,214 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:53:51,263 - INFO - validation batch 51, loss: 1.188, 1632/6976 datapoints
2025-03-06 20:53:51,313 - INFO - validation batch 101, loss: 0.384, 3232/6976 datapoints
2025-03-06 20:53:51,362 - INFO - validation batch 151, loss: 0.415, 4832/6976 datapoints
2025-03-06 20:53:51,409 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:53:51,427 - INFO - Epoch 401/800 done.
2025-03-06 20:53:51,427 - INFO - Final validation performance:
Loss: 0.506, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:51,427 - INFO - Beginning epoch 402/800
2025-03-06 20:53:51,432 - INFO - training batch 1, loss: 0.284, 32/28000 datapoints
2025-03-06 20:53:51,555 - INFO - training batch 51, loss: 0.077, 1632/28000 datapoints
2025-03-06 20:53:51,678 - INFO - training batch 101, loss: 0.115, 3232/28000 datapoints
2025-03-06 20:53:51,800 - INFO - training batch 151, loss: 0.176, 4832/28000 datapoints
2025-03-06 20:53:51,921 - INFO - training batch 201, loss: 0.078, 6432/28000 datapoints
2025-03-06 20:53:52,041 - INFO - training batch 251, loss: 0.298, 8032/28000 datapoints
2025-03-06 20:53:52,164 - INFO - training batch 301, loss: 0.472, 9632/28000 datapoints
2025-03-06 20:53:52,284 - INFO - training batch 351, loss: 0.214, 11232/28000 datapoints
2025-03-06 20:53:52,401 - INFO - training batch 401, loss: 0.458, 12832/28000 datapoints
2025-03-06 20:53:52,522 - INFO - training batch 451, loss: 0.228, 14432/28000 datapoints
2025-03-06 20:53:52,646 - INFO - training batch 501, loss: 0.143, 16032/28000 datapoints
2025-03-06 20:53:52,766 - INFO - training batch 551, loss: 0.200, 17632/28000 datapoints
2025-03-06 20:53:52,888 - INFO - training batch 601, loss: 0.186, 19232/28000 datapoints
2025-03-06 20:53:53,011 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 20:53:53,153 - INFO - training batch 701, loss: 0.229, 22432/28000 datapoints
2025-03-06 20:53:53,273 - INFO - training batch 751, loss: 0.192, 24032/28000 datapoints
2025-03-06 20:53:53,393 - INFO - training batch 801, loss: 0.103, 25632/28000 datapoints
2025-03-06 20:53:53,513 - INFO - training batch 851, loss: 0.331, 27232/28000 datapoints
2025-03-06 20:53:53,573 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:53:53,618 - INFO - validation batch 51, loss: 1.189, 1632/6976 datapoints
2025-03-06 20:53:53,665 - INFO - validation batch 101, loss: 0.385, 3232/6976 datapoints
2025-03-06 20:53:53,710 - INFO - validation batch 151, loss: 0.416, 4832/6976 datapoints
2025-03-06 20:53:53,754 - INFO - validation batch 201, loss: 0.411, 6432/6976 datapoints
2025-03-06 20:53:53,769 - INFO - Epoch 402/800 done.
2025-03-06 20:53:53,769 - INFO - Final validation performance:
Loss: 0.507, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:53,770 - INFO - Beginning epoch 403/800
2025-03-06 20:53:53,773 - INFO - training batch 1, loss: 0.284, 32/28000 datapoints
2025-03-06 20:53:53,898 - INFO - training batch 51, loss: 0.076, 1632/28000 datapoints
2025-03-06 20:53:54,019 - INFO - training batch 101, loss: 0.115, 3232/28000 datapoints
2025-03-06 20:53:54,143 - INFO - training batch 151, loss: 0.173, 4832/28000 datapoints
2025-03-06 20:53:54,263 - INFO - training batch 201, loss: 0.077, 6432/28000 datapoints
2025-03-06 20:53:54,384 - INFO - training batch 251, loss: 0.297, 8032/28000 datapoints
2025-03-06 20:53:54,502 - INFO - training batch 301, loss: 0.469, 9632/28000 datapoints
2025-03-06 20:53:54,622 - INFO - training batch 351, loss: 0.214, 11232/28000 datapoints
2025-03-06 20:53:54,745 - INFO - training batch 401, loss: 0.457, 12832/28000 datapoints
2025-03-06 20:53:54,867 - INFO - training batch 451, loss: 0.227, 14432/28000 datapoints
2025-03-06 20:53:54,993 - INFO - training batch 501, loss: 0.143, 16032/28000 datapoints
2025-03-06 20:53:55,114 - INFO - training batch 551, loss: 0.199, 17632/28000 datapoints
2025-03-06 20:53:55,235 - INFO - training batch 601, loss: 0.183, 19232/28000 datapoints
2025-03-06 20:53:55,356 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 20:53:55,476 - INFO - training batch 701, loss: 0.229, 22432/28000 datapoints
2025-03-06 20:53:55,594 - INFO - training batch 751, loss: 0.193, 24032/28000 datapoints
2025-03-06 20:53:55,715 - INFO - training batch 801, loss: 0.103, 25632/28000 datapoints
2025-03-06 20:53:55,838 - INFO - training batch 851, loss: 0.329, 27232/28000 datapoints
2025-03-06 20:53:55,897 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:53:55,942 - INFO - validation batch 51, loss: 1.190, 1632/6976 datapoints
2025-03-06 20:53:55,986 - INFO - validation batch 101, loss: 0.387, 3232/6976 datapoints
2025-03-06 20:53:56,031 - INFO - validation batch 151, loss: 0.417, 4832/6976 datapoints
2025-03-06 20:53:56,075 - INFO - validation batch 201, loss: 0.411, 6432/6976 datapoints
2025-03-06 20:53:56,089 - INFO - Epoch 403/800 done.
2025-03-06 20:53:56,090 - INFO - Final validation performance:
Loss: 0.508, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:56,090 - INFO - Beginning epoch 404/800
2025-03-06 20:53:56,094 - INFO - training batch 1, loss: 0.285, 32/28000 datapoints
2025-03-06 20:53:56,216 - INFO - training batch 51, loss: 0.076, 1632/28000 datapoints
2025-03-06 20:53:56,340 - INFO - training batch 101, loss: 0.114, 3232/28000 datapoints
2025-03-06 20:53:56,462 - INFO - training batch 151, loss: 0.171, 4832/28000 datapoints
2025-03-06 20:53:56,582 - INFO - training batch 201, loss: 0.077, 6432/28000 datapoints
2025-03-06 20:53:56,704 - INFO - training batch 251, loss: 0.296, 8032/28000 datapoints
2025-03-06 20:53:56,823 - INFO - training batch 301, loss: 0.469, 9632/28000 datapoints
2025-03-06 20:53:56,946 - INFO - training batch 351, loss: 0.213, 11232/28000 datapoints
2025-03-06 20:53:57,066 - INFO - training batch 401, loss: 0.456, 12832/28000 datapoints
2025-03-06 20:53:57,186 - INFO - training batch 451, loss: 0.226, 14432/28000 datapoints
2025-03-06 20:53:57,310 - INFO - training batch 501, loss: 0.142, 16032/28000 datapoints
2025-03-06 20:53:57,447 - INFO - training batch 551, loss: 0.198, 17632/28000 datapoints
2025-03-06 20:53:57,568 - INFO - training batch 601, loss: 0.180, 19232/28000 datapoints
2025-03-06 20:53:57,694 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 20:53:57,812 - INFO - training batch 701, loss: 0.228, 22432/28000 datapoints
2025-03-06 20:53:57,943 - INFO - training batch 751, loss: 0.192, 24032/28000 datapoints
2025-03-06 20:53:58,068 - INFO - training batch 801, loss: 0.102, 25632/28000 datapoints
2025-03-06 20:53:58,195 - INFO - training batch 851, loss: 0.328, 27232/28000 datapoints
2025-03-06 20:53:58,254 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:53:58,301 - INFO - validation batch 51, loss: 1.192, 1632/6976 datapoints
2025-03-06 20:53:58,345 - INFO - validation batch 101, loss: 0.388, 3232/6976 datapoints
2025-03-06 20:53:58,390 - INFO - validation batch 151, loss: 0.417, 4832/6976 datapoints
2025-03-06 20:53:58,434 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:53:58,450 - INFO - Epoch 404/800 done.
2025-03-06 20:53:58,450 - INFO - Final validation performance:
Loss: 0.508, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:53:58,451 - INFO - Beginning epoch 405/800
2025-03-06 20:53:58,454 - INFO - training batch 1, loss: 0.284, 32/28000 datapoints
2025-03-06 20:53:58,578 - INFO - training batch 51, loss: 0.076, 1632/28000 datapoints
2025-03-06 20:53:58,699 - INFO - training batch 101, loss: 0.114, 3232/28000 datapoints
2025-03-06 20:53:58,821 - INFO - training batch 151, loss: 0.169, 4832/28000 datapoints
2025-03-06 20:53:58,944 - INFO - training batch 201, loss: 0.077, 6432/28000 datapoints
2025-03-06 20:53:59,067 - INFO - training batch 251, loss: 0.296, 8032/28000 datapoints
2025-03-06 20:53:59,187 - INFO - training batch 301, loss: 0.466, 9632/28000 datapoints
2025-03-06 20:53:59,307 - INFO - training batch 351, loss: 0.213, 11232/28000 datapoints
2025-03-06 20:53:59,429 - INFO - training batch 401, loss: 0.454, 12832/28000 datapoints
2025-03-06 20:53:59,548 - INFO - training batch 451, loss: 0.225, 14432/28000 datapoints
2025-03-06 20:53:59,672 - INFO - training batch 501, loss: 0.143, 16032/28000 datapoints
2025-03-06 20:53:59,793 - INFO - training batch 551, loss: 0.197, 17632/28000 datapoints
2025-03-06 20:53:59,914 - INFO - training batch 601, loss: 0.179, 19232/28000 datapoints
2025-03-06 20:54:00,035 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 20:54:00,160 - INFO - training batch 701, loss: 0.227, 22432/28000 datapoints
2025-03-06 20:54:00,280 - INFO - training batch 751, loss: 0.191, 24032/28000 datapoints
2025-03-06 20:54:00,399 - INFO - training batch 801, loss: 0.102, 25632/28000 datapoints
2025-03-06 20:54:00,519 - INFO - training batch 851, loss: 0.325, 27232/28000 datapoints
2025-03-06 20:54:00,579 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:54:00,623 - INFO - validation batch 51, loss: 1.193, 1632/6976 datapoints
2025-03-06 20:54:00,669 - INFO - validation batch 101, loss: 0.389, 3232/6976 datapoints
2025-03-06 20:54:00,713 - INFO - validation batch 151, loss: 0.418, 4832/6976 datapoints
2025-03-06 20:54:00,758 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:54:00,774 - INFO - Epoch 405/800 done.
2025-03-06 20:54:00,774 - INFO - Final validation performance:
Loss: 0.509, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:00,774 - INFO - Beginning epoch 406/800
2025-03-06 20:54:00,778 - INFO - training batch 1, loss: 0.283, 32/28000 datapoints
2025-03-06 20:54:00,902 - INFO - training batch 51, loss: 0.075, 1632/28000 datapoints
2025-03-06 20:54:01,076 - INFO - training batch 101, loss: 0.114, 3232/28000 datapoints
2025-03-06 20:54:01,196 - INFO - training batch 151, loss: 0.167, 4832/28000 datapoints
2025-03-06 20:54:01,317 - INFO - training batch 201, loss: 0.076, 6432/28000 datapoints
2025-03-06 20:54:01,437 - INFO - training batch 251, loss: 0.295, 8032/28000 datapoints
2025-03-06 20:54:01,558 - INFO - training batch 301, loss: 0.465, 9632/28000 datapoints
2025-03-06 20:54:01,679 - INFO - training batch 351, loss: 0.212, 11232/28000 datapoints
2025-03-06 20:54:01,799 - INFO - training batch 401, loss: 0.453, 12832/28000 datapoints
2025-03-06 20:54:01,921 - INFO - training batch 451, loss: 0.225, 14432/28000 datapoints
2025-03-06 20:54:02,041 - INFO - training batch 501, loss: 0.142, 16032/28000 datapoints
2025-03-06 20:54:02,165 - INFO - training batch 551, loss: 0.197, 17632/28000 datapoints
2025-03-06 20:54:02,287 - INFO - training batch 601, loss: 0.177, 19232/28000 datapoints
2025-03-06 20:54:02,407 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 20:54:02,528 - INFO - training batch 701, loss: 0.227, 22432/28000 datapoints
2025-03-06 20:54:02,651 - INFO - training batch 751, loss: 0.191, 24032/28000 datapoints
2025-03-06 20:54:02,771 - INFO - training batch 801, loss: 0.102, 25632/28000 datapoints
2025-03-06 20:54:02,892 - INFO - training batch 851, loss: 0.323, 27232/28000 datapoints
2025-03-06 20:54:02,951 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:02,998 - INFO - validation batch 51, loss: 1.194, 1632/6976 datapoints
2025-03-06 20:54:03,042 - INFO - validation batch 101, loss: 0.391, 3232/6976 datapoints
2025-03-06 20:54:03,091 - INFO - validation batch 151, loss: 0.419, 4832/6976 datapoints
2025-03-06 20:54:03,152 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:54:03,172 - INFO - Epoch 406/800 done.
2025-03-06 20:54:03,172 - INFO - Final validation performance:
Loss: 0.510, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:03,173 - INFO - Beginning epoch 407/800
2025-03-06 20:54:03,177 - INFO - training batch 1, loss: 0.284, 32/28000 datapoints
2025-03-06 20:54:03,299 - INFO - training batch 51, loss: 0.075, 1632/28000 datapoints
2025-03-06 20:54:03,419 - INFO - training batch 101, loss: 0.113, 3232/28000 datapoints
2025-03-06 20:54:03,557 - INFO - training batch 151, loss: 0.164, 4832/28000 datapoints
2025-03-06 20:54:03,680 - INFO - training batch 201, loss: 0.076, 6432/28000 datapoints
2025-03-06 20:54:03,800 - INFO - training batch 251, loss: 0.295, 8032/28000 datapoints
2025-03-06 20:54:03,925 - INFO - training batch 301, loss: 0.464, 9632/28000 datapoints
2025-03-06 20:54:04,049 - INFO - training batch 351, loss: 0.212, 11232/28000 datapoints
2025-03-06 20:54:04,176 - INFO - training batch 401, loss: 0.451, 12832/28000 datapoints
2025-03-06 20:54:04,297 - INFO - training batch 451, loss: 0.224, 14432/28000 datapoints
2025-03-06 20:54:04,421 - INFO - training batch 501, loss: 0.142, 16032/28000 datapoints
2025-03-06 20:54:04,542 - INFO - training batch 551, loss: 0.196, 17632/28000 datapoints
2025-03-06 20:54:04,665 - INFO - training batch 601, loss: 0.175, 19232/28000 datapoints
2025-03-06 20:54:04,788 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 20:54:04,913 - INFO - training batch 701, loss: 0.226, 22432/28000 datapoints
2025-03-06 20:54:05,036 - INFO - training batch 751, loss: 0.190, 24032/28000 datapoints
2025-03-06 20:54:05,157 - INFO - training batch 801, loss: 0.102, 25632/28000 datapoints
2025-03-06 20:54:05,278 - INFO - training batch 851, loss: 0.321, 27232/28000 datapoints
2025-03-06 20:54:05,338 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:05,383 - INFO - validation batch 51, loss: 1.196, 1632/6976 datapoints
2025-03-06 20:54:05,428 - INFO - validation batch 101, loss: 0.392, 3232/6976 datapoints
2025-03-06 20:54:05,472 - INFO - validation batch 151, loss: 0.418, 4832/6976 datapoints
2025-03-06 20:54:05,518 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:54:05,534 - INFO - Epoch 407/800 done.
2025-03-06 20:54:05,534 - INFO - Final validation performance:
Loss: 0.510, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:05,534 - INFO - Beginning epoch 408/800
2025-03-06 20:54:05,538 - INFO - training batch 1, loss: 0.282, 32/28000 datapoints
2025-03-06 20:54:05,666 - INFO - training batch 51, loss: 0.075, 1632/28000 datapoints
2025-03-06 20:54:05,786 - INFO - training batch 101, loss: 0.113, 3232/28000 datapoints
2025-03-06 20:54:05,912 - INFO - training batch 151, loss: 0.162, 4832/28000 datapoints
2025-03-06 20:54:06,039 - INFO - training batch 201, loss: 0.075, 6432/28000 datapoints
2025-03-06 20:54:06,162 - INFO - training batch 251, loss: 0.294, 8032/28000 datapoints
2025-03-06 20:54:06,286 - INFO - training batch 301, loss: 0.461, 9632/28000 datapoints
2025-03-06 20:54:06,407 - INFO - training batch 351, loss: 0.211, 11232/28000 datapoints
2025-03-06 20:54:06,529 - INFO - training batch 401, loss: 0.450, 12832/28000 datapoints
2025-03-06 20:54:06,656 - INFO - training batch 451, loss: 0.224, 14432/28000 datapoints
2025-03-06 20:54:06,807 - INFO - training batch 501, loss: 0.141, 16032/28000 datapoints
2025-03-06 20:54:06,951 - INFO - training batch 551, loss: 0.195, 17632/28000 datapoints
2025-03-06 20:54:07,092 - INFO - training batch 601, loss: 0.173, 19232/28000 datapoints
2025-03-06 20:54:07,213 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 20:54:07,336 - INFO - training batch 701, loss: 0.226, 22432/28000 datapoints
2025-03-06 20:54:07,468 - INFO - training batch 751, loss: 0.190, 24032/28000 datapoints
2025-03-06 20:54:07,590 - INFO - training batch 801, loss: 0.102, 25632/28000 datapoints
2025-03-06 20:54:07,722 - INFO - training batch 851, loss: 0.319, 27232/28000 datapoints
2025-03-06 20:54:07,782 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:07,826 - INFO - validation batch 51, loss: 1.196, 1632/6976 datapoints
2025-03-06 20:54:07,871 - INFO - validation batch 101, loss: 0.393, 3232/6976 datapoints
2025-03-06 20:54:07,915 - INFO - validation batch 151, loss: 0.419, 4832/6976 datapoints
2025-03-06 20:54:07,960 - INFO - validation batch 201, loss: 0.411, 6432/6976 datapoints
2025-03-06 20:54:07,976 - INFO - Epoch 408/800 done.
2025-03-06 20:54:07,976 - INFO - Final validation performance:
Loss: 0.511, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:07,977 - INFO - Beginning epoch 409/800
2025-03-06 20:54:07,980 - INFO - training batch 1, loss: 0.283, 32/28000 datapoints
2025-03-06 20:54:08,104 - INFO - training batch 51, loss: 0.074, 1632/28000 datapoints
2025-03-06 20:54:08,236 - INFO - training batch 101, loss: 0.113, 3232/28000 datapoints
2025-03-06 20:54:08,359 - INFO - training batch 151, loss: 0.161, 4832/28000 datapoints
2025-03-06 20:54:08,483 - INFO - training batch 201, loss: 0.075, 6432/28000 datapoints
2025-03-06 20:54:08,613 - INFO - training batch 251, loss: 0.293, 8032/28000 datapoints
2025-03-06 20:54:08,742 - INFO - training batch 301, loss: 0.460, 9632/28000 datapoints
2025-03-06 20:54:08,868 - INFO - training batch 351, loss: 0.210, 11232/28000 datapoints
2025-03-06 20:54:08,993 - INFO - training batch 401, loss: 0.448, 12832/28000 datapoints
2025-03-06 20:54:09,121 - INFO - training batch 451, loss: 0.222, 14432/28000 datapoints
2025-03-06 20:54:09,245 - INFO - training batch 501, loss: 0.142, 16032/28000 datapoints
2025-03-06 20:54:09,370 - INFO - training batch 551, loss: 0.195, 17632/28000 datapoints
2025-03-06 20:54:09,493 - INFO - training batch 601, loss: 0.171, 19232/28000 datapoints
2025-03-06 20:54:09,630 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 20:54:09,759 - INFO - training batch 701, loss: 0.225, 22432/28000 datapoints
2025-03-06 20:54:09,883 - INFO - training batch 751, loss: 0.188, 24032/28000 datapoints
2025-03-06 20:54:10,008 - INFO - training batch 801, loss: 0.102, 25632/28000 datapoints
2025-03-06 20:54:10,145 - INFO - training batch 851, loss: 0.317, 27232/28000 datapoints
2025-03-06 20:54:10,211 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:10,261 - INFO - validation batch 51, loss: 1.198, 1632/6976 datapoints
2025-03-06 20:54:10,310 - INFO - validation batch 101, loss: 0.394, 3232/6976 datapoints
2025-03-06 20:54:10,360 - INFO - validation batch 151, loss: 0.419, 4832/6976 datapoints
2025-03-06 20:54:10,409 - INFO - validation batch 201, loss: 0.411, 6432/6976 datapoints
2025-03-06 20:54:10,426 - INFO - Epoch 409/800 done.
2025-03-06 20:54:10,426 - INFO - Final validation performance:
Loss: 0.512, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:10,427 - INFO - Beginning epoch 410/800
2025-03-06 20:54:10,431 - INFO - training batch 1, loss: 0.281, 32/28000 datapoints
2025-03-06 20:54:10,558 - INFO - training batch 51, loss: 0.074, 1632/28000 datapoints
2025-03-06 20:54:10,684 - INFO - training batch 101, loss: 0.113, 3232/28000 datapoints
2025-03-06 20:54:10,804 - INFO - training batch 151, loss: 0.158, 4832/28000 datapoints
2025-03-06 20:54:10,927 - INFO - training batch 201, loss: 0.074, 6432/28000 datapoints
2025-03-06 20:54:11,051 - INFO - training batch 251, loss: 0.293, 8032/28000 datapoints
2025-03-06 20:54:11,172 - INFO - training batch 301, loss: 0.459, 9632/28000 datapoints
2025-03-06 20:54:11,293 - INFO - training batch 351, loss: 0.210, 11232/28000 datapoints
2025-03-06 20:54:11,413 - INFO - training batch 401, loss: 0.447, 12832/28000 datapoints
2025-03-06 20:54:11,530 - INFO - training batch 451, loss: 0.221, 14432/28000 datapoints
2025-03-06 20:54:11,654 - INFO - training batch 501, loss: 0.141, 16032/28000 datapoints
2025-03-06 20:54:11,780 - INFO - training batch 551, loss: 0.194, 17632/28000 datapoints
2025-03-06 20:54:11,903 - INFO - training batch 601, loss: 0.169, 19232/28000 datapoints
2025-03-06 20:54:12,024 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 20:54:12,148 - INFO - training batch 701, loss: 0.225, 22432/28000 datapoints
2025-03-06 20:54:12,272 - INFO - training batch 751, loss: 0.189, 24032/28000 datapoints
2025-03-06 20:54:12,392 - INFO - training batch 801, loss: 0.101, 25632/28000 datapoints
2025-03-06 20:54:12,511 - INFO - training batch 851, loss: 0.315, 27232/28000 datapoints
2025-03-06 20:54:12,569 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:12,615 - INFO - validation batch 51, loss: 1.199, 1632/6976 datapoints
2025-03-06 20:54:12,662 - INFO - validation batch 101, loss: 0.396, 3232/6976 datapoints
2025-03-06 20:54:12,706 - INFO - validation batch 151, loss: 0.419, 4832/6976 datapoints
2025-03-06 20:54:12,751 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:54:12,766 - INFO - Epoch 410/800 done.
2025-03-06 20:54:12,766 - INFO - Final validation performance:
Loss: 0.512, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:12,767 - INFO - Beginning epoch 411/800
2025-03-06 20:54:12,770 - INFO - training batch 1, loss: 0.281, 32/28000 datapoints
2025-03-06 20:54:12,895 - INFO - training batch 51, loss: 0.074, 1632/28000 datapoints
2025-03-06 20:54:13,014 - INFO - training batch 101, loss: 0.111, 3232/28000 datapoints
2025-03-06 20:54:13,137 - INFO - training batch 151, loss: 0.157, 4832/28000 datapoints
2025-03-06 20:54:13,284 - INFO - training batch 201, loss: 0.074, 6432/28000 datapoints
2025-03-06 20:54:13,406 - INFO - training batch 251, loss: 0.292, 8032/28000 datapoints
2025-03-06 20:54:13,527 - INFO - training batch 301, loss: 0.456, 9632/28000 datapoints
2025-03-06 20:54:13,652 - INFO - training batch 351, loss: 0.209, 11232/28000 datapoints
2025-03-06 20:54:13,772 - INFO - training batch 401, loss: 0.445, 12832/28000 datapoints
2025-03-06 20:54:13,893 - INFO - training batch 451, loss: 0.221, 14432/28000 datapoints
2025-03-06 20:54:14,014 - INFO - training batch 501, loss: 0.141, 16032/28000 datapoints
2025-03-06 20:54:14,137 - INFO - training batch 551, loss: 0.194, 17632/28000 datapoints
2025-03-06 20:54:14,262 - INFO - training batch 601, loss: 0.168, 19232/28000 datapoints
2025-03-06 20:54:14,383 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 20:54:14,501 - INFO - training batch 701, loss: 0.224, 22432/28000 datapoints
2025-03-06 20:54:14,622 - INFO - training batch 751, loss: 0.188, 24032/28000 datapoints
2025-03-06 20:54:14,744 - INFO - training batch 801, loss: 0.101, 25632/28000 datapoints
2025-03-06 20:54:14,865 - INFO - training batch 851, loss: 0.313, 27232/28000 datapoints
2025-03-06 20:54:14,929 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:54:14,973 - INFO - validation batch 51, loss: 1.200, 1632/6976 datapoints
2025-03-06 20:54:15,018 - INFO - validation batch 101, loss: 0.397, 3232/6976 datapoints
2025-03-06 20:54:15,062 - INFO - validation batch 151, loss: 0.420, 4832/6976 datapoints
2025-03-06 20:54:15,107 - INFO - validation batch 201, loss: 0.411, 6432/6976 datapoints
2025-03-06 20:54:15,124 - INFO - Epoch 411/800 done.
2025-03-06 20:54:15,124 - INFO - Final validation performance:
Loss: 0.513, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:15,125 - INFO - Beginning epoch 412/800
2025-03-06 20:54:15,129 - INFO - training batch 1, loss: 0.282, 32/28000 datapoints
2025-03-06 20:54:15,250 - INFO - training batch 51, loss: 0.073, 1632/28000 datapoints
2025-03-06 20:54:15,369 - INFO - training batch 101, loss: 0.112, 3232/28000 datapoints
2025-03-06 20:54:15,490 - INFO - training batch 151, loss: 0.155, 4832/28000 datapoints
2025-03-06 20:54:15,622 - INFO - training batch 201, loss: 0.073, 6432/28000 datapoints
2025-03-06 20:54:15,753 - INFO - training batch 251, loss: 0.291, 8032/28000 datapoints
2025-03-06 20:54:15,874 - INFO - training batch 301, loss: 0.455, 9632/28000 datapoints
2025-03-06 20:54:15,993 - INFO - training batch 351, loss: 0.208, 11232/28000 datapoints
2025-03-06 20:54:16,117 - INFO - training batch 401, loss: 0.443, 12832/28000 datapoints
2025-03-06 20:54:16,247 - INFO - training batch 451, loss: 0.220, 14432/28000 datapoints
2025-03-06 20:54:16,371 - INFO - training batch 501, loss: 0.141, 16032/28000 datapoints
2025-03-06 20:54:16,496 - INFO - training batch 551, loss: 0.192, 17632/28000 datapoints
2025-03-06 20:54:16,616 - INFO - training batch 601, loss: 0.165, 19232/28000 datapoints
2025-03-06 20:54:16,739 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 20:54:16,858 - INFO - training batch 701, loss: 0.224, 22432/28000 datapoints
2025-03-06 20:54:16,979 - INFO - training batch 751, loss: 0.187, 24032/28000 datapoints
2025-03-06 20:54:17,098 - INFO - training batch 801, loss: 0.101, 25632/28000 datapoints
2025-03-06 20:54:17,218 - INFO - training batch 851, loss: 0.311, 27232/28000 datapoints
2025-03-06 20:54:17,277 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:17,327 - INFO - validation batch 51, loss: 1.202, 1632/6976 datapoints
2025-03-06 20:54:17,382 - INFO - validation batch 101, loss: 0.398, 3232/6976 datapoints
2025-03-06 20:54:17,435 - INFO - validation batch 151, loss: 0.420, 4832/6976 datapoints
2025-03-06 20:54:17,488 - INFO - validation batch 201, loss: 0.411, 6432/6976 datapoints
2025-03-06 20:54:17,504 - INFO - Epoch 412/800 done.
2025-03-06 20:54:17,504 - INFO - Final validation performance:
Loss: 0.513, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:17,504 - INFO - Beginning epoch 413/800
2025-03-06 20:54:17,508 - INFO - training batch 1, loss: 0.280, 32/28000 datapoints
2025-03-06 20:54:17,629 - INFO - training batch 51, loss: 0.073, 1632/28000 datapoints
2025-03-06 20:54:17,757 - INFO - training batch 101, loss: 0.111, 3232/28000 datapoints
2025-03-06 20:54:17,879 - INFO - training batch 151, loss: 0.153, 4832/28000 datapoints
2025-03-06 20:54:18,000 - INFO - training batch 201, loss: 0.073, 6432/28000 datapoints
2025-03-06 20:54:18,120 - INFO - training batch 251, loss: 0.291, 8032/28000 datapoints
2025-03-06 20:54:18,244 - INFO - training batch 301, loss: 0.452, 9632/28000 datapoints
2025-03-06 20:54:18,364 - INFO - training batch 351, loss: 0.208, 11232/28000 datapoints
2025-03-06 20:54:18,484 - INFO - training batch 401, loss: 0.443, 12832/28000 datapoints
2025-03-06 20:54:18,604 - INFO - training batch 451, loss: 0.219, 14432/28000 datapoints
2025-03-06 20:54:18,726 - INFO - training batch 501, loss: 0.140, 16032/28000 datapoints
2025-03-06 20:54:18,846 - INFO - training batch 551, loss: 0.192, 17632/28000 datapoints
2025-03-06 20:54:18,967 - INFO - training batch 601, loss: 0.163, 19232/28000 datapoints
2025-03-06 20:54:19,089 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 20:54:19,211 - INFO - training batch 701, loss: 0.223, 22432/28000 datapoints
2025-03-06 20:54:19,330 - INFO - training batch 751, loss: 0.186, 24032/28000 datapoints
2025-03-06 20:54:19,450 - INFO - training batch 801, loss: 0.101, 25632/28000 datapoints
2025-03-06 20:54:19,571 - INFO - training batch 851, loss: 0.309, 27232/28000 datapoints
2025-03-06 20:54:19,630 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:54:19,682 - INFO - validation batch 51, loss: 1.204, 1632/6976 datapoints
2025-03-06 20:54:19,725 - INFO - validation batch 101, loss: 0.400, 3232/6976 datapoints
2025-03-06 20:54:19,769 - INFO - validation batch 151, loss: 0.420, 4832/6976 datapoints
2025-03-06 20:54:19,813 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 20:54:19,828 - INFO - Epoch 413/800 done.
2025-03-06 20:54:19,828 - INFO - Final validation performance:
Loss: 0.514, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:19,828 - INFO - Beginning epoch 414/800
2025-03-06 20:54:19,832 - INFO - training batch 1, loss: 0.280, 32/28000 datapoints
2025-03-06 20:54:19,960 - INFO - training batch 51, loss: 0.073, 1632/28000 datapoints
2025-03-06 20:54:20,082 - INFO - training batch 101, loss: 0.110, 3232/28000 datapoints
2025-03-06 20:54:20,206 - INFO - training batch 151, loss: 0.151, 4832/28000 datapoints
2025-03-06 20:54:20,330 - INFO - training batch 201, loss: 0.072, 6432/28000 datapoints
2025-03-06 20:54:20,450 - INFO - training batch 251, loss: 0.290, 8032/28000 datapoints
2025-03-06 20:54:20,569 - INFO - training batch 301, loss: 0.452, 9632/28000 datapoints
2025-03-06 20:54:20,694 - INFO - training batch 351, loss: 0.207, 11232/28000 datapoints
2025-03-06 20:54:20,814 - INFO - training batch 401, loss: 0.440, 12832/28000 datapoints
2025-03-06 20:54:20,935 - INFO - training batch 451, loss: 0.218, 14432/28000 datapoints
2025-03-06 20:54:21,057 - INFO - training batch 501, loss: 0.140, 16032/28000 datapoints
2025-03-06 20:54:21,184 - INFO - training batch 551, loss: 0.191, 17632/28000 datapoints
2025-03-06 20:54:21,303 - INFO - training batch 601, loss: 0.162, 19232/28000 datapoints
2025-03-06 20:54:21,425 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 20:54:21,545 - INFO - training batch 701, loss: 0.223, 22432/28000 datapoints
2025-03-06 20:54:21,669 - INFO - training batch 751, loss: 0.184, 24032/28000 datapoints
2025-03-06 20:54:21,802 - INFO - training batch 801, loss: 0.101, 25632/28000 datapoints
2025-03-06 20:54:21,929 - INFO - training batch 851, loss: 0.307, 27232/28000 datapoints
2025-03-06 20:54:21,989 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:22,033 - INFO - validation batch 51, loss: 1.207, 1632/6976 datapoints
2025-03-06 20:54:22,079 - INFO - validation batch 101, loss: 0.401, 3232/6976 datapoints
2025-03-06 20:54:22,124 - INFO - validation batch 151, loss: 0.422, 4832/6976 datapoints
2025-03-06 20:54:22,167 - INFO - validation batch 201, loss: 0.411, 6432/6976 datapoints
2025-03-06 20:54:22,182 - INFO - Epoch 414/800 done.
2025-03-06 20:54:22,183 - INFO - Final validation performance:
Loss: 0.515, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:22,183 - INFO - Beginning epoch 415/800
2025-03-06 20:54:22,187 - INFO - training batch 1, loss: 0.280, 32/28000 datapoints
2025-03-06 20:54:22,318 - INFO - training batch 51, loss: 0.073, 1632/28000 datapoints
2025-03-06 20:54:22,438 - INFO - training batch 101, loss: 0.110, 3232/28000 datapoints
2025-03-06 20:54:22,557 - INFO - training batch 151, loss: 0.149, 4832/28000 datapoints
2025-03-06 20:54:22,684 - INFO - training batch 201, loss: 0.072, 6432/28000 datapoints
2025-03-06 20:54:22,804 - INFO - training batch 251, loss: 0.289, 8032/28000 datapoints
2025-03-06 20:54:22,925 - INFO - training batch 301, loss: 0.448, 9632/28000 datapoints
2025-03-06 20:54:23,045 - INFO - training batch 351, loss: 0.207, 11232/28000 datapoints
2025-03-06 20:54:23,164 - INFO - training batch 401, loss: 0.439, 12832/28000 datapoints
2025-03-06 20:54:23,305 - INFO - training batch 451, loss: 0.217, 14432/28000 datapoints
2025-03-06 20:54:23,439 - INFO - training batch 501, loss: 0.140, 16032/28000 datapoints
2025-03-06 20:54:23,559 - INFO - training batch 551, loss: 0.190, 17632/28000 datapoints
2025-03-06 20:54:23,683 - INFO - training batch 601, loss: 0.160, 19232/28000 datapoints
2025-03-06 20:54:23,803 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 20:54:23,923 - INFO - training batch 701, loss: 0.222, 22432/28000 datapoints
2025-03-06 20:54:24,042 - INFO - training batch 751, loss: 0.185, 24032/28000 datapoints
2025-03-06 20:54:24,162 - INFO - training batch 801, loss: 0.101, 25632/28000 datapoints
2025-03-06 20:54:24,284 - INFO - training batch 851, loss: 0.305, 27232/28000 datapoints
2025-03-06 20:54:24,343 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:24,388 - INFO - validation batch 51, loss: 1.208, 1632/6976 datapoints
2025-03-06 20:54:24,432 - INFO - validation batch 101, loss: 0.402, 3232/6976 datapoints
2025-03-06 20:54:24,476 - INFO - validation batch 151, loss: 0.422, 4832/6976 datapoints
2025-03-06 20:54:24,520 - INFO - validation batch 201, loss: 0.412, 6432/6976 datapoints
2025-03-06 20:54:24,534 - INFO - Epoch 415/800 done.
2025-03-06 20:54:24,534 - INFO - Final validation performance:
Loss: 0.516, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:24,535 - INFO - Beginning epoch 416/800
2025-03-06 20:54:24,538 - INFO - training batch 1, loss: 0.281, 32/28000 datapoints
2025-03-06 20:54:24,662 - INFO - training batch 51, loss: 0.072, 1632/28000 datapoints
2025-03-06 20:54:24,785 - INFO - training batch 101, loss: 0.110, 3232/28000 datapoints
2025-03-06 20:54:24,910 - INFO - training batch 151, loss: 0.147, 4832/28000 datapoints
2025-03-06 20:54:25,035 - INFO - training batch 201, loss: 0.071, 6432/28000 datapoints
2025-03-06 20:54:25,154 - INFO - training batch 251, loss: 0.289, 8032/28000 datapoints
2025-03-06 20:54:25,274 - INFO - training batch 301, loss: 0.447, 9632/28000 datapoints
2025-03-06 20:54:25,393 - INFO - training batch 351, loss: 0.206, 11232/28000 datapoints
2025-03-06 20:54:25,514 - INFO - training batch 401, loss: 0.438, 12832/28000 datapoints
2025-03-06 20:54:25,633 - INFO - training batch 451, loss: 0.216, 14432/28000 datapoints
2025-03-06 20:54:25,756 - INFO - training batch 501, loss: 0.140, 16032/28000 datapoints
2025-03-06 20:54:25,877 - INFO - training batch 551, loss: 0.189, 17632/28000 datapoints
2025-03-06 20:54:26,003 - INFO - training batch 601, loss: 0.158, 19232/28000 datapoints
2025-03-06 20:54:26,122 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 20:54:26,241 - INFO - training batch 701, loss: 0.221, 22432/28000 datapoints
2025-03-06 20:54:26,366 - INFO - training batch 751, loss: 0.184, 24032/28000 datapoints
2025-03-06 20:54:26,494 - INFO - training batch 801, loss: 0.101, 25632/28000 datapoints
2025-03-06 20:54:26,626 - INFO - training batch 851, loss: 0.303, 27232/28000 datapoints
2025-03-06 20:54:26,688 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:26,732 - INFO - validation batch 51, loss: 1.210, 1632/6976 datapoints
2025-03-06 20:54:26,777 - INFO - validation batch 101, loss: 0.403, 3232/6976 datapoints
2025-03-06 20:54:26,820 - INFO - validation batch 151, loss: 0.423, 4832/6976 datapoints
2025-03-06 20:54:26,865 - INFO - validation batch 201, loss: 0.411, 6432/6976 datapoints
2025-03-06 20:54:26,880 - INFO - Epoch 416/800 done.
2025-03-06 20:54:26,881 - INFO - Final validation performance:
Loss: 0.516, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:26,881 - INFO - Beginning epoch 417/800
2025-03-06 20:54:26,885 - INFO - training batch 1, loss: 0.280, 32/28000 datapoints
2025-03-06 20:54:27,007 - INFO - training batch 51, loss: 0.072, 1632/28000 datapoints
2025-03-06 20:54:27,129 - INFO - training batch 101, loss: 0.110, 3232/28000 datapoints
2025-03-06 20:54:27,249 - INFO - training batch 151, loss: 0.146, 4832/28000 datapoints
2025-03-06 20:54:27,371 - INFO - training batch 201, loss: 0.071, 6432/28000 datapoints
2025-03-06 20:54:27,492 - INFO - training batch 251, loss: 0.288, 8032/28000 datapoints
2025-03-06 20:54:27,611 - INFO - training batch 301, loss: 0.446, 9632/28000 datapoints
2025-03-06 20:54:27,737 - INFO - training batch 351, loss: 0.206, 11232/28000 datapoints
2025-03-06 20:54:27,859 - INFO - training batch 401, loss: 0.436, 12832/28000 datapoints
2025-03-06 20:54:27,981 - INFO - training batch 451, loss: 0.215, 14432/28000 datapoints
2025-03-06 20:54:28,101 - INFO - training batch 501, loss: 0.140, 16032/28000 datapoints
2025-03-06 20:54:28,229 - INFO - training batch 551, loss: 0.189, 17632/28000 datapoints
2025-03-06 20:54:28,360 - INFO - training batch 601, loss: 0.157, 19232/28000 datapoints
2025-03-06 20:54:28,485 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 20:54:28,609 - INFO - training batch 701, loss: 0.221, 22432/28000 datapoints
2025-03-06 20:54:28,735 - INFO - training batch 751, loss: 0.184, 24032/28000 datapoints
2025-03-06 20:54:28,861 - INFO - training batch 801, loss: 0.100, 25632/28000 datapoints
2025-03-06 20:54:28,986 - INFO - training batch 851, loss: 0.300, 27232/28000 datapoints
2025-03-06 20:54:29,048 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:29,097 - INFO - validation batch 51, loss: 1.212, 1632/6976 datapoints
2025-03-06 20:54:29,145 - INFO - validation batch 101, loss: 0.404, 3232/6976 datapoints
2025-03-06 20:54:29,193 - INFO - validation batch 151, loss: 0.423, 4832/6976 datapoints
2025-03-06 20:54:29,241 - INFO - validation batch 201, loss: 0.411, 6432/6976 datapoints
2025-03-06 20:54:29,256 - INFO - Epoch 417/800 done.
2025-03-06 20:54:29,257 - INFO - Final validation performance:
Loss: 0.517, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:29,257 - INFO - Beginning epoch 418/800
2025-03-06 20:54:29,261 - INFO - training batch 1, loss: 0.279, 32/28000 datapoints
2025-03-06 20:54:29,390 - INFO - training batch 51, loss: 0.072, 1632/28000 datapoints
2025-03-06 20:54:29,516 - INFO - training batch 101, loss: 0.109, 3232/28000 datapoints
2025-03-06 20:54:29,644 - INFO - training batch 151, loss: 0.144, 4832/28000 datapoints
2025-03-06 20:54:29,767 - INFO - training batch 201, loss: 0.071, 6432/28000 datapoints
2025-03-06 20:54:29,893 - INFO - training batch 251, loss: 0.287, 8032/28000 datapoints
2025-03-06 20:54:30,016 - INFO - training batch 301, loss: 0.443, 9632/28000 datapoints
2025-03-06 20:54:30,141 - INFO - training batch 351, loss: 0.205, 11232/28000 datapoints
2025-03-06 20:54:30,266 - INFO - training batch 401, loss: 0.435, 12832/28000 datapoints
2025-03-06 20:54:30,394 - INFO - training batch 451, loss: 0.215, 14432/28000 datapoints
2025-03-06 20:54:30,519 - INFO - training batch 501, loss: 0.139, 16032/28000 datapoints
2025-03-06 20:54:30,645 - INFO - training batch 551, loss: 0.188, 17632/28000 datapoints
2025-03-06 20:54:30,772 - INFO - training batch 601, loss: 0.155, 19232/28000 datapoints
2025-03-06 20:54:30,899 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 20:54:31,027 - INFO - training batch 701, loss: 0.220, 22432/28000 datapoints
2025-03-06 20:54:31,155 - INFO - training batch 751, loss: 0.183, 24032/28000 datapoints
2025-03-06 20:54:31,281 - INFO - training batch 801, loss: 0.100, 25632/28000 datapoints
2025-03-06 20:54:31,406 - INFO - training batch 851, loss: 0.298, 27232/28000 datapoints
2025-03-06 20:54:31,468 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:54:31,516 - INFO - validation batch 51, loss: 1.213, 1632/6976 datapoints
2025-03-06 20:54:31,563 - INFO - validation batch 101, loss: 0.406, 3232/6976 datapoints
2025-03-06 20:54:31,611 - INFO - validation batch 151, loss: 0.424, 4832/6976 datapoints
2025-03-06 20:54:31,663 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 20:54:31,681 - INFO - Epoch 418/800 done.
2025-03-06 20:54:31,681 - INFO - Final validation performance:
Loss: 0.518, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:31,681 - INFO - Beginning epoch 419/800
2025-03-06 20:54:31,686 - INFO - training batch 1, loss: 0.280, 32/28000 datapoints
2025-03-06 20:54:31,809 - INFO - training batch 51, loss: 0.071, 1632/28000 datapoints
2025-03-06 20:54:31,933 - INFO - training batch 101, loss: 0.109, 3232/28000 datapoints
2025-03-06 20:54:32,054 - INFO - training batch 151, loss: 0.143, 4832/28000 datapoints
2025-03-06 20:54:32,173 - INFO - training batch 201, loss: 0.070, 6432/28000 datapoints
2025-03-06 20:54:32,296 - INFO - training batch 251, loss: 0.287, 8032/28000 datapoints
2025-03-06 20:54:32,417 - INFO - training batch 301, loss: 0.443, 9632/28000 datapoints
2025-03-06 20:54:32,536 - INFO - training batch 351, loss: 0.205, 11232/28000 datapoints
2025-03-06 20:54:32,658 - INFO - training batch 401, loss: 0.434, 12832/28000 datapoints
2025-03-06 20:54:32,778 - INFO - training batch 451, loss: 0.214, 14432/28000 datapoints
2025-03-06 20:54:32,900 - INFO - training batch 501, loss: 0.139, 16032/28000 datapoints
2025-03-06 20:54:33,023 - INFO - training batch 551, loss: 0.187, 17632/28000 datapoints
2025-03-06 20:54:33,142 - INFO - training batch 601, loss: 0.154, 19232/28000 datapoints
2025-03-06 20:54:33,262 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 20:54:33,403 - INFO - training batch 701, loss: 0.220, 22432/28000 datapoints
2025-03-06 20:54:33,530 - INFO - training batch 751, loss: 0.181, 24032/28000 datapoints
2025-03-06 20:54:33,652 - INFO - training batch 801, loss: 0.100, 25632/28000 datapoints
2025-03-06 20:54:33,772 - INFO - training batch 851, loss: 0.296, 27232/28000 datapoints
2025-03-06 20:54:33,831 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:33,876 - INFO - validation batch 51, loss: 1.214, 1632/6976 datapoints
2025-03-06 20:54:33,919 - INFO - validation batch 101, loss: 0.407, 3232/6976 datapoints
2025-03-06 20:54:33,964 - INFO - validation batch 151, loss: 0.424, 4832/6976 datapoints
2025-03-06 20:54:34,011 - INFO - validation batch 201, loss: 0.412, 6432/6976 datapoints
2025-03-06 20:54:34,028 - INFO - Epoch 419/800 done.
2025-03-06 20:54:34,028 - INFO - Final validation performance:
Loss: 0.518, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:34,029 - INFO - Beginning epoch 420/800
2025-03-06 20:54:34,032 - INFO - training batch 1, loss: 0.279, 32/28000 datapoints
2025-03-06 20:54:34,156 - INFO - training batch 51, loss: 0.071, 1632/28000 datapoints
2025-03-06 20:54:34,276 - INFO - training batch 101, loss: 0.109, 3232/28000 datapoints
2025-03-06 20:54:34,402 - INFO - training batch 151, loss: 0.141, 4832/28000 datapoints
2025-03-06 20:54:34,523 - INFO - training batch 201, loss: 0.070, 6432/28000 datapoints
2025-03-06 20:54:34,644 - INFO - training batch 251, loss: 0.287, 8032/28000 datapoints
2025-03-06 20:54:34,764 - INFO - training batch 301, loss: 0.439, 9632/28000 datapoints
2025-03-06 20:54:34,892 - INFO - training batch 351, loss: 0.204, 11232/28000 datapoints
2025-03-06 20:54:35,012 - INFO - training batch 401, loss: 0.433, 12832/28000 datapoints
2025-03-06 20:54:35,133 - INFO - training batch 451, loss: 0.213, 14432/28000 datapoints
2025-03-06 20:54:35,253 - INFO - training batch 501, loss: 0.139, 16032/28000 datapoints
2025-03-06 20:54:35,374 - INFO - training batch 551, loss: 0.187, 17632/28000 datapoints
2025-03-06 20:54:35,494 - INFO - training batch 601, loss: 0.152, 19232/28000 datapoints
2025-03-06 20:54:35,614 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 20:54:35,738 - INFO - training batch 701, loss: 0.220, 22432/28000 datapoints
2025-03-06 20:54:35,857 - INFO - training batch 751, loss: 0.182, 24032/28000 datapoints
2025-03-06 20:54:35,979 - INFO - training batch 801, loss: 0.100, 25632/28000 datapoints
2025-03-06 20:54:36,098 - INFO - training batch 851, loss: 0.294, 27232/28000 datapoints
2025-03-06 20:54:36,157 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:54:36,200 - INFO - validation batch 51, loss: 1.215, 1632/6976 datapoints
2025-03-06 20:54:36,244 - INFO - validation batch 101, loss: 0.408, 3232/6976 datapoints
2025-03-06 20:54:36,289 - INFO - validation batch 151, loss: 0.424, 4832/6976 datapoints
2025-03-06 20:54:36,337 - INFO - validation batch 201, loss: 0.412, 6432/6976 datapoints
2025-03-06 20:54:36,356 - INFO - Epoch 420/800 done.
2025-03-06 20:54:36,356 - INFO - Final validation performance:
Loss: 0.519, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:36,357 - INFO - Beginning epoch 421/800
2025-03-06 20:54:36,360 - INFO - training batch 1, loss: 0.279, 32/28000 datapoints
2025-03-06 20:54:36,486 - INFO - training batch 51, loss: 0.071, 1632/28000 datapoints
2025-03-06 20:54:36,606 - INFO - training batch 101, loss: 0.107, 3232/28000 datapoints
2025-03-06 20:54:36,730 - INFO - training batch 151, loss: 0.139, 4832/28000 datapoints
2025-03-06 20:54:36,851 - INFO - training batch 201, loss: 0.070, 6432/28000 datapoints
2025-03-06 20:54:36,974 - INFO - training batch 251, loss: 0.286, 8032/28000 datapoints
2025-03-06 20:54:37,095 - INFO - training batch 301, loss: 0.439, 9632/28000 datapoints
2025-03-06 20:54:37,215 - INFO - training batch 351, loss: 0.204, 11232/28000 datapoints
2025-03-06 20:54:37,335 - INFO - training batch 401, loss: 0.430, 12832/28000 datapoints
2025-03-06 20:54:37,456 - INFO - training batch 451, loss: 0.213, 14432/28000 datapoints
2025-03-06 20:54:37,576 - INFO - training batch 501, loss: 0.138, 16032/28000 datapoints
2025-03-06 20:54:37,716 - INFO - training batch 551, loss: 0.186, 17632/28000 datapoints
2025-03-06 20:54:37,837 - INFO - training batch 601, loss: 0.152, 19232/28000 datapoints
2025-03-06 20:54:37,958 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 20:54:38,079 - INFO - training batch 701, loss: 0.219, 22432/28000 datapoints
2025-03-06 20:54:38,199 - INFO - training batch 751, loss: 0.181, 24032/28000 datapoints
2025-03-06 20:54:38,322 - INFO - training batch 801, loss: 0.100, 25632/28000 datapoints
2025-03-06 20:54:38,443 - INFO - training batch 851, loss: 0.292, 27232/28000 datapoints
2025-03-06 20:54:38,502 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:54:38,546 - INFO - validation batch 51, loss: 1.215, 1632/6976 datapoints
2025-03-06 20:54:38,590 - INFO - validation batch 101, loss: 0.409, 3232/6976 datapoints
2025-03-06 20:54:38,633 - INFO - validation batch 151, loss: 0.424, 4832/6976 datapoints
2025-03-06 20:54:38,679 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 20:54:38,695 - INFO - Epoch 421/800 done.
2025-03-06 20:54:38,695 - INFO - Final validation performance:
Loss: 0.520, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:38,695 - INFO - Beginning epoch 422/800
2025-03-06 20:54:38,698 - INFO - training batch 1, loss: 0.276, 32/28000 datapoints
2025-03-06 20:54:38,819 - INFO - training batch 51, loss: 0.071, 1632/28000 datapoints
2025-03-06 20:54:38,943 - INFO - training batch 101, loss: 0.107, 3232/28000 datapoints
2025-03-06 20:54:39,073 - INFO - training batch 151, loss: 0.139, 4832/28000 datapoints
2025-03-06 20:54:39,193 - INFO - training batch 201, loss: 0.069, 6432/28000 datapoints
2025-03-06 20:54:39,314 - INFO - training batch 251, loss: 0.286, 8032/28000 datapoints
2025-03-06 20:54:39,436 - INFO - training batch 301, loss: 0.437, 9632/28000 datapoints
2025-03-06 20:54:39,557 - INFO - training batch 351, loss: 0.203, 11232/28000 datapoints
2025-03-06 20:54:39,681 - INFO - training batch 401, loss: 0.430, 12832/28000 datapoints
2025-03-06 20:54:39,801 - INFO - training batch 451, loss: 0.212, 14432/28000 datapoints
2025-03-06 20:54:39,923 - INFO - training batch 501, loss: 0.138, 16032/28000 datapoints
2025-03-06 20:54:40,055 - INFO - training batch 551, loss: 0.185, 17632/28000 datapoints
2025-03-06 20:54:40,176 - INFO - training batch 601, loss: 0.150, 19232/28000 datapoints
2025-03-06 20:54:40,296 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 20:54:40,421 - INFO - training batch 701, loss: 0.218, 22432/28000 datapoints
2025-03-06 20:54:40,541 - INFO - training batch 751, loss: 0.180, 24032/28000 datapoints
2025-03-06 20:54:40,662 - INFO - training batch 801, loss: 0.100, 25632/28000 datapoints
2025-03-06 20:54:40,783 - INFO - training batch 851, loss: 0.289, 27232/28000 datapoints
2025-03-06 20:54:40,842 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:40,886 - INFO - validation batch 51, loss: 1.220, 1632/6976 datapoints
2025-03-06 20:54:40,932 - INFO - validation batch 101, loss: 0.410, 3232/6976 datapoints
2025-03-06 20:54:40,976 - INFO - validation batch 151, loss: 0.425, 4832/6976 datapoints
2025-03-06 20:54:41,022 - INFO - validation batch 201, loss: 0.412, 6432/6976 datapoints
2025-03-06 20:54:41,037 - INFO - Epoch 422/800 done.
2025-03-06 20:54:41,037 - INFO - Final validation performance:
Loss: 0.521, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:41,038 - INFO - Beginning epoch 423/800
2025-03-06 20:54:41,041 - INFO - training batch 1, loss: 0.277, 32/28000 datapoints
2025-03-06 20:54:41,164 - INFO - training batch 51, loss: 0.071, 1632/28000 datapoints
2025-03-06 20:54:41,284 - INFO - training batch 101, loss: 0.108, 3232/28000 datapoints
2025-03-06 20:54:41,403 - INFO - training batch 151, loss: 0.137, 4832/28000 datapoints
2025-03-06 20:54:41,528 - INFO - training batch 201, loss: 0.069, 6432/28000 datapoints
2025-03-06 20:54:41,653 - INFO - training batch 251, loss: 0.285, 8032/28000 datapoints
2025-03-06 20:54:41,773 - INFO - training batch 301, loss: 0.433, 9632/28000 datapoints
2025-03-06 20:54:41,894 - INFO - training batch 351, loss: 0.203, 11232/28000 datapoints
2025-03-06 20:54:42,020 - INFO - training batch 401, loss: 0.428, 12832/28000 datapoints
2025-03-06 20:54:42,142 - INFO - training batch 451, loss: 0.212, 14432/28000 datapoints
2025-03-06 20:54:42,262 - INFO - training batch 501, loss: 0.138, 16032/28000 datapoints
2025-03-06 20:54:42,386 - INFO - training batch 551, loss: 0.184, 17632/28000 datapoints
2025-03-06 20:54:42,507 - INFO - training batch 601, loss: 0.144, 19232/28000 datapoints
2025-03-06 20:54:42,627 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 20:54:42,752 - INFO - training batch 701, loss: 0.218, 22432/28000 datapoints
2025-03-06 20:54:42,871 - INFO - training batch 751, loss: 0.179, 24032/28000 datapoints
2025-03-06 20:54:42,992 - INFO - training batch 801, loss: 0.099, 25632/28000 datapoints
2025-03-06 20:54:43,114 - INFO - training batch 851, loss: 0.288, 27232/28000 datapoints
2025-03-06 20:54:43,173 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:54:43,217 - INFO - validation batch 51, loss: 1.221, 1632/6976 datapoints
2025-03-06 20:54:43,262 - INFO - validation batch 101, loss: 0.412, 3232/6976 datapoints
2025-03-06 20:54:43,306 - INFO - validation batch 151, loss: 0.426, 4832/6976 datapoints
2025-03-06 20:54:43,351 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 20:54:43,374 - INFO - Epoch 423/800 done.
2025-03-06 20:54:43,374 - INFO - Final validation performance:
Loss: 0.522, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:43,374 - INFO - Beginning epoch 424/800
2025-03-06 20:54:43,378 - INFO - training batch 1, loss: 0.277, 32/28000 datapoints
2025-03-06 20:54:43,527 - INFO - training batch 51, loss: 0.070, 1632/28000 datapoints
2025-03-06 20:54:43,651 - INFO - training batch 101, loss: 0.106, 3232/28000 datapoints
2025-03-06 20:54:43,773 - INFO - training batch 151, loss: 0.135, 4832/28000 datapoints
2025-03-06 20:54:43,893 - INFO - training batch 201, loss: 0.068, 6432/28000 datapoints
2025-03-06 20:54:44,015 - INFO - training batch 251, loss: 0.284, 8032/28000 datapoints
2025-03-06 20:54:44,134 - INFO - training batch 301, loss: 0.433, 9632/28000 datapoints
2025-03-06 20:54:44,255 - INFO - training batch 351, loss: 0.202, 11232/28000 datapoints
2025-03-06 20:54:44,378 - INFO - training batch 401, loss: 0.426, 12832/28000 datapoints
2025-03-06 20:54:44,499 - INFO - training batch 451, loss: 0.210, 14432/28000 datapoints
2025-03-06 20:54:44,619 - INFO - training batch 501, loss: 0.137, 16032/28000 datapoints
2025-03-06 20:54:44,740 - INFO - training batch 551, loss: 0.183, 17632/28000 datapoints
2025-03-06 20:54:44,863 - INFO - training batch 601, loss: 0.147, 19232/28000 datapoints
2025-03-06 20:54:44,986 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 20:54:45,110 - INFO - training batch 701, loss: 0.218, 22432/28000 datapoints
2025-03-06 20:54:45,230 - INFO - training batch 751, loss: 0.177, 24032/28000 datapoints
2025-03-06 20:54:45,349 - INFO - training batch 801, loss: 0.099, 25632/28000 datapoints
2025-03-06 20:54:45,470 - INFO - training batch 851, loss: 0.285, 27232/28000 datapoints
2025-03-06 20:54:45,530 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:54:45,574 - INFO - validation batch 51, loss: 1.224, 1632/6976 datapoints
2025-03-06 20:54:45,618 - INFO - validation batch 101, loss: 0.413, 3232/6976 datapoints
2025-03-06 20:54:45,667 - INFO - validation batch 151, loss: 0.426, 4832/6976 datapoints
2025-03-06 20:54:45,712 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 20:54:45,727 - INFO - Epoch 424/800 done.
2025-03-06 20:54:45,728 - INFO - Final validation performance:
Loss: 0.522, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:45,728 - INFO - Beginning epoch 425/800
2025-03-06 20:54:45,732 - INFO - training batch 1, loss: 0.276, 32/28000 datapoints
2025-03-06 20:54:45,855 - INFO - training batch 51, loss: 0.070, 1632/28000 datapoints
2025-03-06 20:54:45,974 - INFO - training batch 101, loss: 0.106, 3232/28000 datapoints
2025-03-06 20:54:46,101 - INFO - training batch 151, loss: 0.134, 4832/28000 datapoints
2025-03-06 20:54:46,220 - INFO - training batch 201, loss: 0.068, 6432/28000 datapoints
2025-03-06 20:54:46,340 - INFO - training batch 251, loss: 0.283, 8032/28000 datapoints
2025-03-06 20:54:46,465 - INFO - training batch 301, loss: 0.429, 9632/28000 datapoints
2025-03-06 20:54:46,587 - INFO - training batch 351, loss: 0.202, 11232/28000 datapoints
2025-03-06 20:54:46,711 - INFO - training batch 401, loss: 0.426, 12832/28000 datapoints
2025-03-06 20:54:46,831 - INFO - training batch 451, loss: 0.209, 14432/28000 datapoints
2025-03-06 20:54:46,951 - INFO - training batch 501, loss: 0.137, 16032/28000 datapoints
2025-03-06 20:54:47,075 - INFO - training batch 551, loss: 0.183, 17632/28000 datapoints
2025-03-06 20:54:47,195 - INFO - training batch 601, loss: 0.141, 19232/28000 datapoints
2025-03-06 20:54:47,315 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 20:54:47,434 - INFO - training batch 701, loss: 0.217, 22432/28000 datapoints
2025-03-06 20:54:47,556 - INFO - training batch 751, loss: 0.177, 24032/28000 datapoints
2025-03-06 20:54:47,680 - INFO - training batch 801, loss: 0.099, 25632/28000 datapoints
2025-03-06 20:54:47,801 - INFO - training batch 851, loss: 0.283, 27232/28000 datapoints
2025-03-06 20:54:47,859 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:47,904 - INFO - validation batch 51, loss: 1.225, 1632/6976 datapoints
2025-03-06 20:54:47,947 - INFO - validation batch 101, loss: 0.414, 3232/6976 datapoints
2025-03-06 20:54:47,991 - INFO - validation batch 151, loss: 0.426, 4832/6976 datapoints
2025-03-06 20:54:48,037 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 20:54:48,053 - INFO - Epoch 425/800 done.
2025-03-06 20:54:48,053 - INFO - Final validation performance:
Loss: 0.523, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:48,054 - INFO - Beginning epoch 426/800
2025-03-06 20:54:48,057 - INFO - training batch 1, loss: 0.276, 32/28000 datapoints
2025-03-06 20:54:48,176 - INFO - training batch 51, loss: 0.070, 1632/28000 datapoints
2025-03-06 20:54:48,297 - INFO - training batch 101, loss: 0.105, 3232/28000 datapoints
2025-03-06 20:54:48,422 - INFO - training batch 151, loss: 0.133, 4832/28000 datapoints
2025-03-06 20:54:48,550 - INFO - training batch 201, loss: 0.068, 6432/28000 datapoints
2025-03-06 20:54:48,684 - INFO - training batch 251, loss: 0.283, 8032/28000 datapoints
2025-03-06 20:54:48,810 - INFO - training batch 301, loss: 0.430, 9632/28000 datapoints
2025-03-06 20:54:48,934 - INFO - training batch 351, loss: 0.200, 11232/28000 datapoints
2025-03-06 20:54:49,061 - INFO - training batch 401, loss: 0.423, 12832/28000 datapoints
2025-03-06 20:54:49,188 - INFO - training batch 451, loss: 0.209, 14432/28000 datapoints
2025-03-06 20:54:49,313 - INFO - training batch 501, loss: 0.137, 16032/28000 datapoints
2025-03-06 20:54:49,440 - INFO - training batch 551, loss: 0.183, 17632/28000 datapoints
2025-03-06 20:54:49,566 - INFO - training batch 601, loss: 0.141, 19232/28000 datapoints
2025-03-06 20:54:49,694 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 20:54:49,818 - INFO - training batch 701, loss: 0.216, 22432/28000 datapoints
2025-03-06 20:54:49,943 - INFO - training batch 751, loss: 0.177, 24032/28000 datapoints
2025-03-06 20:54:50,071 - INFO - training batch 801, loss: 0.099, 25632/28000 datapoints
2025-03-06 20:54:50,196 - INFO - training batch 851, loss: 0.281, 27232/28000 datapoints
2025-03-06 20:54:50,264 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:54:50,316 - INFO - validation batch 51, loss: 1.226, 1632/6976 datapoints
2025-03-06 20:54:50,365 - INFO - validation batch 101, loss: 0.416, 3232/6976 datapoints
2025-03-06 20:54:50,417 - INFO - validation batch 151, loss: 0.427, 4832/6976 datapoints
2025-03-06 20:54:50,468 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 20:54:50,488 - INFO - Epoch 426/800 done.
2025-03-06 20:54:50,489 - INFO - Final validation performance:
Loss: 0.524, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:50,489 - INFO - Beginning epoch 427/800
2025-03-06 20:54:50,493 - INFO - training batch 1, loss: 0.276, 32/28000 datapoints
2025-03-06 20:54:50,622 - INFO - training batch 51, loss: 0.070, 1632/28000 datapoints
2025-03-06 20:54:50,748 - INFO - training batch 101, loss: 0.105, 3232/28000 datapoints
2025-03-06 20:54:50,873 - INFO - training batch 151, loss: 0.132, 4832/28000 datapoints
2025-03-06 20:54:50,997 - INFO - training batch 201, loss: 0.067, 6432/28000 datapoints
2025-03-06 20:54:51,125 - INFO - training batch 251, loss: 0.282, 8032/28000 datapoints
2025-03-06 20:54:51,249 - INFO - training batch 301, loss: 0.426, 9632/28000 datapoints
2025-03-06 20:54:51,403 - INFO - training batch 351, loss: 0.200, 11232/28000 datapoints
2025-03-06 20:54:51,533 - INFO - training batch 401, loss: 0.423, 12832/28000 datapoints
2025-03-06 20:54:51,661 - INFO - training batch 451, loss: 0.208, 14432/28000 datapoints
2025-03-06 20:54:51,789 - INFO - training batch 501, loss: 0.137, 16032/28000 datapoints
2025-03-06 20:54:51,915 - INFO - training batch 551, loss: 0.182, 17632/28000 datapoints
2025-03-06 20:54:52,039 - INFO - training batch 601, loss: 0.139, 19232/28000 datapoints
2025-03-06 20:54:52,164 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 20:54:52,289 - INFO - training batch 701, loss: 0.216, 22432/28000 datapoints
2025-03-06 20:54:52,418 - INFO - training batch 751, loss: 0.176, 24032/28000 datapoints
2025-03-06 20:54:52,541 - INFO - training batch 801, loss: 0.098, 25632/28000 datapoints
2025-03-06 20:54:52,668 - INFO - training batch 851, loss: 0.279, 27232/28000 datapoints
2025-03-06 20:54:52,732 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:52,779 - INFO - validation batch 51, loss: 1.228, 1632/6976 datapoints
2025-03-06 20:54:52,825 - INFO - validation batch 101, loss: 0.417, 3232/6976 datapoints
2025-03-06 20:54:52,870 - INFO - validation batch 151, loss: 0.427, 4832/6976 datapoints
2025-03-06 20:54:52,916 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 20:54:52,931 - INFO - Epoch 427/800 done.
2025-03-06 20:54:52,931 - INFO - Final validation performance:
Loss: 0.524, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:52,932 - INFO - Beginning epoch 428/800
2025-03-06 20:54:52,935 - INFO - training batch 1, loss: 0.275, 32/28000 datapoints
2025-03-06 20:54:53,061 - INFO - training batch 51, loss: 0.069, 1632/28000 datapoints
2025-03-06 20:54:53,185 - INFO - training batch 101, loss: 0.104, 3232/28000 datapoints
2025-03-06 20:54:53,305 - INFO - training batch 151, loss: 0.130, 4832/28000 datapoints
2025-03-06 20:54:53,424 - INFO - training batch 201, loss: 0.067, 6432/28000 datapoints
2025-03-06 20:54:53,555 - INFO - training batch 251, loss: 0.282, 8032/28000 datapoints
2025-03-06 20:54:53,697 - INFO - training batch 301, loss: 0.426, 9632/28000 datapoints
2025-03-06 20:54:53,817 - INFO - training batch 351, loss: 0.199, 11232/28000 datapoints
2025-03-06 20:54:53,936 - INFO - training batch 401, loss: 0.420, 12832/28000 datapoints
2025-03-06 20:54:54,056 - INFO - training batch 451, loss: 0.207, 14432/28000 datapoints
2025-03-06 20:54:54,178 - INFO - training batch 501, loss: 0.136, 16032/28000 datapoints
2025-03-06 20:54:54,299 - INFO - training batch 551, loss: 0.181, 17632/28000 datapoints
2025-03-06 20:54:54,422 - INFO - training batch 601, loss: 0.137, 19232/28000 datapoints
2025-03-06 20:54:54,542 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 20:54:54,665 - INFO - training batch 701, loss: 0.215, 22432/28000 datapoints
2025-03-06 20:54:54,784 - INFO - training batch 751, loss: 0.173, 24032/28000 datapoints
2025-03-06 20:54:54,910 - INFO - training batch 801, loss: 0.098, 25632/28000 datapoints
2025-03-06 20:54:55,030 - INFO - training batch 851, loss: 0.276, 27232/28000 datapoints
2025-03-06 20:54:55,090 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:55,136 - INFO - validation batch 51, loss: 1.229, 1632/6976 datapoints
2025-03-06 20:54:55,179 - INFO - validation batch 101, loss: 0.418, 3232/6976 datapoints
2025-03-06 20:54:55,223 - INFO - validation batch 151, loss: 0.427, 4832/6976 datapoints
2025-03-06 20:54:55,267 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 20:54:55,282 - INFO - Epoch 428/800 done.
2025-03-06 20:54:55,282 - INFO - Final validation performance:
Loss: 0.525, top-1 acc: 0.872top-5 acc: 0.872
2025-03-06 20:54:55,283 - INFO - Beginning epoch 429/800
2025-03-06 20:54:55,286 - INFO - training batch 1, loss: 0.274, 32/28000 datapoints
2025-03-06 20:54:55,408 - INFO - training batch 51, loss: 0.069, 1632/28000 datapoints
2025-03-06 20:54:55,528 - INFO - training batch 101, loss: 0.104, 3232/28000 datapoints
2025-03-06 20:54:55,654 - INFO - training batch 151, loss: 0.129, 4832/28000 datapoints
2025-03-06 20:54:55,775 - INFO - training batch 201, loss: 0.066, 6432/28000 datapoints
2025-03-06 20:54:55,896 - INFO - training batch 251, loss: 0.281, 8032/28000 datapoints
2025-03-06 20:54:56,016 - INFO - training batch 301, loss: 0.423, 9632/28000 datapoints
2025-03-06 20:54:56,141 - INFO - training batch 351, loss: 0.199, 11232/28000 datapoints
2025-03-06 20:54:56,260 - INFO - training batch 401, loss: 0.419, 12832/28000 datapoints
2025-03-06 20:54:56,383 - INFO - training batch 451, loss: 0.208, 14432/28000 datapoints
2025-03-06 20:54:56,507 - INFO - training batch 501, loss: 0.136, 16032/28000 datapoints
2025-03-06 20:54:56,629 - INFO - training batch 551, loss: 0.181, 17632/28000 datapoints
2025-03-06 20:54:56,753 - INFO - training batch 601, loss: 0.136, 19232/28000 datapoints
2025-03-06 20:54:56,874 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 20:54:56,996 - INFO - training batch 701, loss: 0.215, 22432/28000 datapoints
2025-03-06 20:54:57,115 - INFO - training batch 751, loss: 0.174, 24032/28000 datapoints
2025-03-06 20:54:57,237 - INFO - training batch 801, loss: 0.098, 25632/28000 datapoints
2025-03-06 20:54:57,357 - INFO - training batch 851, loss: 0.274, 27232/28000 datapoints
2025-03-06 20:54:57,417 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:54:57,462 - INFO - validation batch 51, loss: 1.230, 1632/6976 datapoints
2025-03-06 20:54:57,506 - INFO - validation batch 101, loss: 0.420, 3232/6976 datapoints
2025-03-06 20:54:57,550 - INFO - validation batch 151, loss: 0.426, 4832/6976 datapoints
2025-03-06 20:54:57,593 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 20:54:57,609 - INFO - Epoch 429/800 done.
2025-03-06 20:54:57,609 - INFO - Final validation performance:
Loss: 0.525, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:54:57,609 - INFO - Beginning epoch 430/800
2025-03-06 20:54:57,613 - INFO - training batch 1, loss: 0.274, 32/28000 datapoints
2025-03-06 20:54:57,741 - INFO - training batch 51, loss: 0.069, 1632/28000 datapoints
2025-03-06 20:54:57,863 - INFO - training batch 101, loss: 0.104, 3232/28000 datapoints
2025-03-06 20:54:57,984 - INFO - training batch 151, loss: 0.128, 4832/28000 datapoints
2025-03-06 20:54:58,105 - INFO - training batch 201, loss: 0.066, 6432/28000 datapoints
2025-03-06 20:54:58,229 - INFO - training batch 251, loss: 0.280, 8032/28000 datapoints
2025-03-06 20:54:58,349 - INFO - training batch 301, loss: 0.422, 9632/28000 datapoints
2025-03-06 20:54:58,476 - INFO - training batch 351, loss: 0.199, 11232/28000 datapoints
2025-03-06 20:54:58,597 - INFO - training batch 401, loss: 0.417, 12832/28000 datapoints
2025-03-06 20:54:58,721 - INFO - training batch 451, loss: 0.202, 14432/28000 datapoints
2025-03-06 20:54:58,843 - INFO - training batch 501, loss: 0.135, 16032/28000 datapoints
2025-03-06 20:54:58,965 - INFO - training batch 551, loss: 0.180, 17632/28000 datapoints
2025-03-06 20:54:59,087 - INFO - training batch 601, loss: 0.134, 19232/28000 datapoints
2025-03-06 20:54:59,209 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 20:54:59,331 - INFO - training batch 701, loss: 0.215, 22432/28000 datapoints
2025-03-06 20:54:59,451 - INFO - training batch 751, loss: 0.173, 24032/28000 datapoints
2025-03-06 20:54:59,571 - INFO - training batch 801, loss: 0.098, 25632/28000 datapoints
2025-03-06 20:54:59,694 - INFO - training batch 851, loss: 0.272, 27232/28000 datapoints
2025-03-06 20:54:59,754 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:54:59,798 - INFO - validation batch 51, loss: 1.230, 1632/6976 datapoints
2025-03-06 20:54:59,842 - INFO - validation batch 101, loss: 0.421, 3232/6976 datapoints
2025-03-06 20:54:59,887 - INFO - validation batch 151, loss: 0.427, 4832/6976 datapoints
2025-03-06 20:54:59,931 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 20:54:59,945 - INFO - Epoch 430/800 done.
2025-03-06 20:54:59,946 - INFO - Final validation performance:
Loss: 0.525, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:54:59,946 - INFO - Beginning epoch 431/800
2025-03-06 20:54:59,950 - INFO - training batch 1, loss: 0.272, 32/28000 datapoints
2025-03-06 20:55:00,072 - INFO - training batch 51, loss: 0.069, 1632/28000 datapoints
2025-03-06 20:55:00,197 - INFO - training batch 101, loss: 0.103, 3232/28000 datapoints
2025-03-06 20:55:00,318 - INFO - training batch 151, loss: 0.127, 4832/28000 datapoints
2025-03-06 20:55:00,443 - INFO - training batch 201, loss: 0.065, 6432/28000 datapoints
2025-03-06 20:55:00,565 - INFO - training batch 251, loss: 0.280, 8032/28000 datapoints
2025-03-06 20:55:00,689 - INFO - training batch 301, loss: 0.420, 9632/28000 datapoints
2025-03-06 20:55:00,810 - INFO - training batch 351, loss: 0.198, 11232/28000 datapoints
2025-03-06 20:55:00,930 - INFO - training batch 401, loss: 0.417, 12832/28000 datapoints
2025-03-06 20:55:01,050 - INFO - training batch 451, loss: 0.205, 14432/28000 datapoints
2025-03-06 20:55:01,175 - INFO - training batch 501, loss: 0.135, 16032/28000 datapoints
2025-03-06 20:55:01,298 - INFO - training batch 551, loss: 0.180, 17632/28000 datapoints
2025-03-06 20:55:01,419 - INFO - training batch 601, loss: 0.133, 19232/28000 datapoints
2025-03-06 20:55:01,539 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 20:55:01,662 - INFO - training batch 701, loss: 0.214, 22432/28000 datapoints
2025-03-06 20:55:01,784 - INFO - training batch 751, loss: 0.172, 24032/28000 datapoints
2025-03-06 20:55:01,906 - INFO - training batch 801, loss: 0.098, 25632/28000 datapoints
2025-03-06 20:55:02,028 - INFO - training batch 851, loss: 0.271, 27232/28000 datapoints
2025-03-06 20:55:02,088 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:55:02,133 - INFO - validation batch 51, loss: 1.232, 1632/6976 datapoints
2025-03-06 20:55:02,177 - INFO - validation batch 101, loss: 0.422, 3232/6976 datapoints
2025-03-06 20:55:02,222 - INFO - validation batch 151, loss: 0.427, 4832/6976 datapoints
2025-03-06 20:55:02,265 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 20:55:02,280 - INFO - Epoch 431/800 done.
2025-03-06 20:55:02,280 - INFO - Final validation performance:
Loss: 0.526, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:02,281 - INFO - Beginning epoch 432/800
2025-03-06 20:55:02,284 - INFO - training batch 1, loss: 0.272, 32/28000 datapoints
2025-03-06 20:55:02,407 - INFO - training batch 51, loss: 0.069, 1632/28000 datapoints
2025-03-06 20:55:02,530 - INFO - training batch 101, loss: 0.103, 3232/28000 datapoints
2025-03-06 20:55:02,653 - INFO - training batch 151, loss: 0.125, 4832/28000 datapoints
2025-03-06 20:55:02,778 - INFO - training batch 201, loss: 0.065, 6432/28000 datapoints
2025-03-06 20:55:02,899 - INFO - training batch 251, loss: 0.280, 8032/28000 datapoints
2025-03-06 20:55:03,019 - INFO - training batch 301, loss: 0.419, 9632/28000 datapoints
2025-03-06 20:55:03,139 - INFO - training batch 351, loss: 0.197, 11232/28000 datapoints
2025-03-06 20:55:03,260 - INFO - training batch 401, loss: 0.416, 12832/28000 datapoints
2025-03-06 20:55:03,378 - INFO - training batch 451, loss: 0.204, 14432/28000 datapoints
2025-03-06 20:55:03,512 - INFO - training batch 501, loss: 0.135, 16032/28000 datapoints
2025-03-06 20:55:03,643 - INFO - training batch 551, loss: 0.180, 17632/28000 datapoints
2025-03-06 20:55:03,782 - INFO - training batch 601, loss: 0.131, 19232/28000 datapoints
2025-03-06 20:55:03,903 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 20:55:04,024 - INFO - training batch 701, loss: 0.214, 22432/28000 datapoints
2025-03-06 20:55:04,145 - INFO - training batch 751, loss: 0.170, 24032/28000 datapoints
2025-03-06 20:55:04,268 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 20:55:04,391 - INFO - training batch 851, loss: 0.268, 27232/28000 datapoints
2025-03-06 20:55:04,456 - INFO - validation batch 1, loss: 0.138, 32/6976 datapoints
2025-03-06 20:55:04,501 - INFO - validation batch 51, loss: 1.232, 1632/6976 datapoints
2025-03-06 20:55:04,545 - INFO - validation batch 101, loss: 0.423, 3232/6976 datapoints
2025-03-06 20:55:04,590 - INFO - validation batch 151, loss: 0.428, 4832/6976 datapoints
2025-03-06 20:55:04,635 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 20:55:04,652 - INFO - Epoch 432/800 done.
2025-03-06 20:55:04,652 - INFO - Final validation performance:
Loss: 0.527, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:04,653 - INFO - Beginning epoch 433/800
2025-03-06 20:55:04,656 - INFO - training batch 1, loss: 0.271, 32/28000 datapoints
2025-03-06 20:55:04,781 - INFO - training batch 51, loss: 0.069, 1632/28000 datapoints
2025-03-06 20:55:04,909 - INFO - training batch 101, loss: 0.102, 3232/28000 datapoints
2025-03-06 20:55:05,034 - INFO - training batch 151, loss: 0.124, 4832/28000 datapoints
2025-03-06 20:55:05,156 - INFO - training batch 201, loss: 0.064, 6432/28000 datapoints
2025-03-06 20:55:05,278 - INFO - training batch 251, loss: 0.279, 8032/28000 datapoints
2025-03-06 20:55:05,398 - INFO - training batch 301, loss: 0.418, 9632/28000 datapoints
2025-03-06 20:55:05,519 - INFO - training batch 351, loss: 0.197, 11232/28000 datapoints
2025-03-06 20:55:05,642 - INFO - training batch 401, loss: 0.415, 12832/28000 datapoints
2025-03-06 20:55:05,764 - INFO - training batch 451, loss: 0.204, 14432/28000 datapoints
2025-03-06 20:55:05,886 - INFO - training batch 501, loss: 0.134, 16032/28000 datapoints
2025-03-06 20:55:06,008 - INFO - training batch 551, loss: 0.179, 17632/28000 datapoints
2025-03-06 20:55:06,129 - INFO - training batch 601, loss: 0.131, 19232/28000 datapoints
2025-03-06 20:55:06,249 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 20:55:06,370 - INFO - training batch 701, loss: 0.213, 22432/28000 datapoints
2025-03-06 20:55:06,495 - INFO - training batch 751, loss: 0.170, 24032/28000 datapoints
2025-03-06 20:55:06,614 - INFO - training batch 801, loss: 0.098, 25632/28000 datapoints
2025-03-06 20:55:06,737 - INFO - training batch 851, loss: 0.267, 27232/28000 datapoints
2025-03-06 20:55:06,798 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:55:06,842 - INFO - validation batch 51, loss: 1.237, 1632/6976 datapoints
2025-03-06 20:55:06,889 - INFO - validation batch 101, loss: 0.424, 3232/6976 datapoints
2025-03-06 20:55:06,933 - INFO - validation batch 151, loss: 0.428, 4832/6976 datapoints
2025-03-06 20:55:06,982 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 20:55:06,998 - INFO - Epoch 433/800 done.
2025-03-06 20:55:06,999 - INFO - Final validation performance:
Loss: 0.528, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:06,999 - INFO - Beginning epoch 434/800
2025-03-06 20:55:07,003 - INFO - training batch 1, loss: 0.272, 32/28000 datapoints
2025-03-06 20:55:07,123 - INFO - training batch 51, loss: 0.068, 1632/28000 datapoints
2025-03-06 20:55:07,247 - INFO - training batch 101, loss: 0.102, 3232/28000 datapoints
2025-03-06 20:55:07,371 - INFO - training batch 151, loss: 0.123, 4832/28000 datapoints
2025-03-06 20:55:07,492 - INFO - training batch 201, loss: 0.064, 6432/28000 datapoints
2025-03-06 20:55:07,610 - INFO - training batch 251, loss: 0.279, 8032/28000 datapoints
2025-03-06 20:55:07,738 - INFO - training batch 301, loss: 0.414, 9632/28000 datapoints
2025-03-06 20:55:07,860 - INFO - training batch 351, loss: 0.197, 11232/28000 datapoints
2025-03-06 20:55:07,981 - INFO - training batch 401, loss: 0.413, 12832/28000 datapoints
2025-03-06 20:55:08,101 - INFO - training batch 451, loss: 0.203, 14432/28000 datapoints
2025-03-06 20:55:08,222 - INFO - training batch 501, loss: 0.134, 16032/28000 datapoints
2025-03-06 20:55:08,346 - INFO - training batch 551, loss: 0.178, 17632/28000 datapoints
2025-03-06 20:55:08,473 - INFO - training batch 601, loss: 0.128, 19232/28000 datapoints
2025-03-06 20:55:08,600 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 20:55:08,725 - INFO - training batch 701, loss: 0.213, 22432/28000 datapoints
2025-03-06 20:55:08,849 - INFO - training batch 751, loss: 0.169, 24032/28000 datapoints
2025-03-06 20:55:08,974 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 20:55:09,103 - INFO - training batch 851, loss: 0.264, 27232/28000 datapoints
2025-03-06 20:55:09,163 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:55:09,214 - INFO - validation batch 51, loss: 1.239, 1632/6976 datapoints
2025-03-06 20:55:09,262 - INFO - validation batch 101, loss: 0.425, 3232/6976 datapoints
2025-03-06 20:55:09,312 - INFO - validation batch 151, loss: 0.429, 4832/6976 datapoints
2025-03-06 20:55:09,360 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 20:55:09,378 - INFO - Epoch 434/800 done.
2025-03-06 20:55:09,379 - INFO - Final validation performance:
Loss: 0.528, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:09,379 - INFO - Beginning epoch 435/800
2025-03-06 20:55:09,383 - INFO - training batch 1, loss: 0.272, 32/28000 datapoints
2025-03-06 20:55:09,517 - INFO - training batch 51, loss: 0.068, 1632/28000 datapoints
2025-03-06 20:55:09,642 - INFO - training batch 101, loss: 0.101, 3232/28000 datapoints
2025-03-06 20:55:09,765 - INFO - training batch 151, loss: 0.122, 4832/28000 datapoints
2025-03-06 20:55:09,888 - INFO - training batch 201, loss: 0.064, 6432/28000 datapoints
2025-03-06 20:55:10,010 - INFO - training batch 251, loss: 0.278, 8032/28000 datapoints
2025-03-06 20:55:10,133 - INFO - training batch 301, loss: 0.414, 9632/28000 datapoints
2025-03-06 20:55:10,253 - INFO - training batch 351, loss: 0.196, 11232/28000 datapoints
2025-03-06 20:55:10,376 - INFO - training batch 401, loss: 0.411, 12832/28000 datapoints
2025-03-06 20:55:10,501 - INFO - training batch 451, loss: 0.200, 14432/28000 datapoints
2025-03-06 20:55:10,623 - INFO - training batch 501, loss: 0.134, 16032/28000 datapoints
2025-03-06 20:55:10,747 - INFO - training batch 551, loss: 0.178, 17632/28000 datapoints
2025-03-06 20:55:10,871 - INFO - training batch 601, loss: 0.127, 19232/28000 datapoints
2025-03-06 20:55:10,993 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 20:55:11,114 - INFO - training batch 701, loss: 0.212, 22432/28000 datapoints
2025-03-06 20:55:11,242 - INFO - training batch 751, loss: 0.169, 24032/28000 datapoints
2025-03-06 20:55:11,365 - INFO - training batch 801, loss: 0.098, 25632/28000 datapoints
2025-03-06 20:55:11,485 - INFO - training batch 851, loss: 0.263, 27232/28000 datapoints
2025-03-06 20:55:11,545 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:55:11,590 - INFO - validation batch 51, loss: 1.239, 1632/6976 datapoints
2025-03-06 20:55:11,637 - INFO - validation batch 101, loss: 0.426, 3232/6976 datapoints
2025-03-06 20:55:11,681 - INFO - validation batch 151, loss: 0.427, 4832/6976 datapoints
2025-03-06 20:55:11,726 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 20:55:11,741 - INFO - Epoch 435/800 done.
2025-03-06 20:55:11,741 - INFO - Final validation performance:
Loss: 0.529, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:11,742 - INFO - Beginning epoch 436/800
2025-03-06 20:55:11,745 - INFO - training batch 1, loss: 0.270, 32/28000 datapoints
2025-03-06 20:55:11,871 - INFO - training batch 51, loss: 0.068, 1632/28000 datapoints
2025-03-06 20:55:11,993 - INFO - training batch 101, loss: 0.101, 3232/28000 datapoints
2025-03-06 20:55:12,114 - INFO - training batch 151, loss: 0.121, 4832/28000 datapoints
2025-03-06 20:55:12,236 - INFO - training batch 201, loss: 0.063, 6432/28000 datapoints
2025-03-06 20:55:12,357 - INFO - training batch 251, loss: 0.278, 8032/28000 datapoints
2025-03-06 20:55:12,482 - INFO - training batch 301, loss: 0.411, 9632/28000 datapoints
2025-03-06 20:55:12,602 - INFO - training batch 351, loss: 0.196, 11232/28000 datapoints
2025-03-06 20:55:12,723 - INFO - training batch 401, loss: 0.411, 12832/28000 datapoints
2025-03-06 20:55:12,843 - INFO - training batch 451, loss: 0.201, 14432/28000 datapoints
2025-03-06 20:55:12,966 - INFO - training batch 501, loss: 0.133, 16032/28000 datapoints
2025-03-06 20:55:13,088 - INFO - training batch 551, loss: 0.177, 17632/28000 datapoints
2025-03-06 20:55:13,208 - INFO - training batch 601, loss: 0.126, 19232/28000 datapoints
2025-03-06 20:55:13,328 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 20:55:13,449 - INFO - training batch 701, loss: 0.211, 22432/28000 datapoints
2025-03-06 20:55:13,568 - INFO - training batch 751, loss: 0.167, 24032/28000 datapoints
2025-03-06 20:55:13,693 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 20:55:13,839 - INFO - training batch 851, loss: 0.261, 27232/28000 datapoints
2025-03-06 20:55:13,900 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:55:13,945 - INFO - validation batch 51, loss: 1.242, 1632/6976 datapoints
2025-03-06 20:55:13,989 - INFO - validation batch 101, loss: 0.428, 3232/6976 datapoints
2025-03-06 20:55:14,032 - INFO - validation batch 151, loss: 0.428, 4832/6976 datapoints
2025-03-06 20:55:14,077 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 20:55:14,093 - INFO - Epoch 436/800 done.
2025-03-06 20:55:14,093 - INFO - Final validation performance:
Loss: 0.529, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:14,094 - INFO - Beginning epoch 437/800
2025-03-06 20:55:14,097 - INFO - training batch 1, loss: 0.270, 32/28000 datapoints
2025-03-06 20:55:14,219 - INFO - training batch 51, loss: 0.068, 1632/28000 datapoints
2025-03-06 20:55:14,338 - INFO - training batch 101, loss: 0.100, 3232/28000 datapoints
2025-03-06 20:55:14,464 - INFO - training batch 151, loss: 0.120, 4832/28000 datapoints
2025-03-06 20:55:14,589 - INFO - training batch 201, loss: 0.063, 6432/28000 datapoints
2025-03-06 20:55:14,711 - INFO - training batch 251, loss: 0.277, 8032/28000 datapoints
2025-03-06 20:55:14,833 - INFO - training batch 301, loss: 0.409, 9632/28000 datapoints
2025-03-06 20:55:14,961 - INFO - training batch 351, loss: 0.195, 11232/28000 datapoints
2025-03-06 20:55:15,082 - INFO - training batch 401, loss: 0.408, 12832/28000 datapoints
2025-03-06 20:55:15,202 - INFO - training batch 451, loss: 0.201, 14432/28000 datapoints
2025-03-06 20:55:15,321 - INFO - training batch 501, loss: 0.134, 16032/28000 datapoints
2025-03-06 20:55:15,444 - INFO - training batch 551, loss: 0.177, 17632/28000 datapoints
2025-03-06 20:55:15,565 - INFO - training batch 601, loss: 0.124, 19232/28000 datapoints
2025-03-06 20:55:15,690 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 20:55:15,809 - INFO - training batch 701, loss: 0.211, 22432/28000 datapoints
2025-03-06 20:55:15,930 - INFO - training batch 751, loss: 0.167, 24032/28000 datapoints
2025-03-06 20:55:16,049 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 20:55:16,170 - INFO - training batch 851, loss: 0.259, 27232/28000 datapoints
2025-03-06 20:55:16,232 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:55:16,277 - INFO - validation batch 51, loss: 1.242, 1632/6976 datapoints
2025-03-06 20:55:16,320 - INFO - validation batch 101, loss: 0.429, 3232/6976 datapoints
2025-03-06 20:55:16,363 - INFO - validation batch 151, loss: 0.428, 4832/6976 datapoints
2025-03-06 20:55:16,409 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 20:55:16,424 - INFO - Epoch 437/800 done.
2025-03-06 20:55:16,424 - INFO - Final validation performance:
Loss: 0.530, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:16,425 - INFO - Beginning epoch 438/800
2025-03-06 20:55:16,429 - INFO - training batch 1, loss: 0.270, 32/28000 datapoints
2025-03-06 20:55:16,553 - INFO - training batch 51, loss: 0.068, 1632/28000 datapoints
2025-03-06 20:55:16,678 - INFO - training batch 101, loss: 0.100, 3232/28000 datapoints
2025-03-06 20:55:16,799 - INFO - training batch 151, loss: 0.118, 4832/28000 datapoints
2025-03-06 20:55:16,922 - INFO - training batch 201, loss: 0.063, 6432/28000 datapoints
2025-03-06 20:55:17,044 - INFO - training batch 251, loss: 0.277, 8032/28000 datapoints
2025-03-06 20:55:17,164 - INFO - training batch 301, loss: 0.408, 9632/28000 datapoints
2025-03-06 20:55:17,285 - INFO - training batch 351, loss: 0.195, 11232/28000 datapoints
2025-03-06 20:55:17,404 - INFO - training batch 401, loss: 0.408, 12832/28000 datapoints
2025-03-06 20:55:17,525 - INFO - training batch 451, loss: 0.200, 14432/28000 datapoints
2025-03-06 20:55:17,648 - INFO - training batch 501, loss: 0.133, 16032/28000 datapoints
2025-03-06 20:55:17,771 - INFO - training batch 551, loss: 0.175, 17632/28000 datapoints
2025-03-06 20:55:17,893 - INFO - training batch 601, loss: 0.122, 19232/28000 datapoints
2025-03-06 20:55:18,014 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 20:55:18,133 - INFO - training batch 701, loss: 0.210, 22432/28000 datapoints
2025-03-06 20:55:18,253 - INFO - training batch 751, loss: 0.167, 24032/28000 datapoints
2025-03-06 20:55:18,371 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 20:55:18,492 - INFO - training batch 851, loss: 0.257, 27232/28000 datapoints
2025-03-06 20:55:18,555 - INFO - validation batch 1, loss: 0.137, 32/6976 datapoints
2025-03-06 20:55:18,598 - INFO - validation batch 51, loss: 1.244, 1632/6976 datapoints
2025-03-06 20:55:18,644 - INFO - validation batch 101, loss: 0.430, 3232/6976 datapoints
2025-03-06 20:55:18,688 - INFO - validation batch 151, loss: 0.429, 4832/6976 datapoints
2025-03-06 20:55:18,732 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 20:55:18,747 - INFO - Epoch 438/800 done.
2025-03-06 20:55:18,747 - INFO - Final validation performance:
Loss: 0.531, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:18,748 - INFO - Beginning epoch 439/800
2025-03-06 20:55:18,751 - INFO - training batch 1, loss: 0.270, 32/28000 datapoints
2025-03-06 20:55:18,873 - INFO - training batch 51, loss: 0.067, 1632/28000 datapoints
2025-03-06 20:55:18,996 - INFO - training batch 101, loss: 0.100, 3232/28000 datapoints
2025-03-06 20:55:19,118 - INFO - training batch 151, loss: 0.117, 4832/28000 datapoints
2025-03-06 20:55:19,238 - INFO - training batch 201, loss: 0.062, 6432/28000 datapoints
2025-03-06 20:55:19,358 - INFO - training batch 251, loss: 0.276, 8032/28000 datapoints
2025-03-06 20:55:19,480 - INFO - training batch 301, loss: 0.405, 9632/28000 datapoints
2025-03-06 20:55:19,598 - INFO - training batch 351, loss: 0.195, 11232/28000 datapoints
2025-03-06 20:55:19,722 - INFO - training batch 401, loss: 0.406, 12832/28000 datapoints
2025-03-06 20:55:19,841 - INFO - training batch 451, loss: 0.199, 14432/28000 datapoints
2025-03-06 20:55:19,964 - INFO - training batch 501, loss: 0.133, 16032/28000 datapoints
2025-03-06 20:55:20,085 - INFO - training batch 551, loss: 0.175, 17632/28000 datapoints
2025-03-06 20:55:20,206 - INFO - training batch 601, loss: 0.122, 19232/28000 datapoints
2025-03-06 20:55:20,331 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 20:55:20,452 - INFO - training batch 701, loss: 0.210, 22432/28000 datapoints
2025-03-06 20:55:20,577 - INFO - training batch 751, loss: 0.165, 24032/28000 datapoints
2025-03-06 20:55:20,700 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 20:55:20,819 - INFO - training batch 851, loss: 0.255, 27232/28000 datapoints
2025-03-06 20:55:20,877 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:55:20,921 - INFO - validation batch 51, loss: 1.246, 1632/6976 datapoints
2025-03-06 20:55:20,966 - INFO - validation batch 101, loss: 0.431, 3232/6976 datapoints
2025-03-06 20:55:21,009 - INFO - validation batch 151, loss: 0.429, 4832/6976 datapoints
2025-03-06 20:55:21,053 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 20:55:21,068 - INFO - Epoch 439/800 done.
2025-03-06 20:55:21,068 - INFO - Final validation performance:
Loss: 0.531, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:21,069 - INFO - Beginning epoch 440/800
2025-03-06 20:55:21,072 - INFO - training batch 1, loss: 0.269, 32/28000 datapoints
2025-03-06 20:55:21,196 - INFO - training batch 51, loss: 0.067, 1632/28000 datapoints
2025-03-06 20:55:21,319 - INFO - training batch 101, loss: 0.100, 3232/28000 datapoints
2025-03-06 20:55:21,437 - INFO - training batch 151, loss: 0.117, 4832/28000 datapoints
2025-03-06 20:55:21,560 - INFO - training batch 201, loss: 0.062, 6432/28000 datapoints
2025-03-06 20:55:21,683 - INFO - training batch 251, loss: 0.276, 8032/28000 datapoints
2025-03-06 20:55:21,804 - INFO - training batch 301, loss: 0.403, 9632/28000 datapoints
2025-03-06 20:55:21,925 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 20:55:22,046 - INFO - training batch 401, loss: 0.405, 12832/28000 datapoints
2025-03-06 20:55:22,166 - INFO - training batch 451, loss: 0.195, 14432/28000 datapoints
2025-03-06 20:55:22,291 - INFO - training batch 501, loss: 0.132, 16032/28000 datapoints
2025-03-06 20:55:22,410 - INFO - training batch 551, loss: 0.174, 17632/28000 datapoints
2025-03-06 20:55:22,536 - INFO - training batch 601, loss: 0.119, 19232/28000 datapoints
2025-03-06 20:55:22,664 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 20:55:22,785 - INFO - training batch 701, loss: 0.209, 22432/28000 datapoints
2025-03-06 20:55:22,907 - INFO - training batch 751, loss: 0.164, 24032/28000 datapoints
2025-03-06 20:55:23,028 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 20:55:23,145 - INFO - training batch 851, loss: 0.254, 27232/28000 datapoints
2025-03-06 20:55:23,205 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:55:23,250 - INFO - validation batch 51, loss: 1.248, 1632/6976 datapoints
2025-03-06 20:55:23,293 - INFO - validation batch 101, loss: 0.433, 3232/6976 datapoints
2025-03-06 20:55:23,336 - INFO - validation batch 151, loss: 0.429, 4832/6976 datapoints
2025-03-06 20:55:23,381 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 20:55:23,396 - INFO - Epoch 440/800 done.
2025-03-06 20:55:23,396 - INFO - Final validation performance:
Loss: 0.532, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:23,397 - INFO - Beginning epoch 441/800
2025-03-06 20:55:23,400 - INFO - training batch 1, loss: 0.269, 32/28000 datapoints
2025-03-06 20:55:23,529 - INFO - training batch 51, loss: 0.067, 1632/28000 datapoints
2025-03-06 20:55:23,653 - INFO - training batch 101, loss: 0.099, 3232/28000 datapoints
2025-03-06 20:55:23,774 - INFO - training batch 151, loss: 0.115, 4832/28000 datapoints
2025-03-06 20:55:23,922 - INFO - training batch 201, loss: 0.062, 6432/28000 datapoints
2025-03-06 20:55:24,044 - INFO - training batch 251, loss: 0.275, 8032/28000 datapoints
2025-03-06 20:55:24,164 - INFO - training batch 301, loss: 0.401, 9632/28000 datapoints
2025-03-06 20:55:24,284 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 20:55:24,403 - INFO - training batch 401, loss: 0.403, 12832/28000 datapoints
2025-03-06 20:55:24,530 - INFO - training batch 451, loss: 0.197, 14432/28000 datapoints
2025-03-06 20:55:24,652 - INFO - training batch 501, loss: 0.132, 16032/28000 datapoints
2025-03-06 20:55:24,773 - INFO - training batch 551, loss: 0.174, 17632/28000 datapoints
2025-03-06 20:55:24,893 - INFO - training batch 601, loss: 0.119, 19232/28000 datapoints
2025-03-06 20:55:25,018 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 20:55:25,137 - INFO - training batch 701, loss: 0.209, 22432/28000 datapoints
2025-03-06 20:55:25,255 - INFO - training batch 751, loss: 0.164, 24032/28000 datapoints
2025-03-06 20:55:25,373 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 20:55:25,493 - INFO - training batch 851, loss: 0.252, 27232/28000 datapoints
2025-03-06 20:55:25,554 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:55:25,598 - INFO - validation batch 51, loss: 1.249, 1632/6976 datapoints
2025-03-06 20:55:25,645 - INFO - validation batch 101, loss: 0.434, 3232/6976 datapoints
2025-03-06 20:55:25,688 - INFO - validation batch 151, loss: 0.429, 4832/6976 datapoints
2025-03-06 20:55:25,732 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 20:55:25,747 - INFO - Epoch 441/800 done.
2025-03-06 20:55:25,747 - INFO - Final validation performance:
Loss: 0.532, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:25,747 - INFO - Beginning epoch 442/800
2025-03-06 20:55:25,751 - INFO - training batch 1, loss: 0.269, 32/28000 datapoints
2025-03-06 20:55:25,872 - INFO - training batch 51, loss: 0.067, 1632/28000 datapoints
2025-03-06 20:55:25,993 - INFO - training batch 101, loss: 0.100, 3232/28000 datapoints
2025-03-06 20:55:26,115 - INFO - training batch 151, loss: 0.115, 4832/28000 datapoints
2025-03-06 20:55:26,236 - INFO - training batch 201, loss: 0.061, 6432/28000 datapoints
2025-03-06 20:55:26,362 - INFO - training batch 251, loss: 0.275, 8032/28000 datapoints
2025-03-06 20:55:26,483 - INFO - training batch 301, loss: 0.399, 9632/28000 datapoints
2025-03-06 20:55:26,607 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 20:55:26,730 - INFO - training batch 401, loss: 0.402, 12832/28000 datapoints
2025-03-06 20:55:26,849 - INFO - training batch 451, loss: 0.197, 14432/28000 datapoints
2025-03-06 20:55:26,968 - INFO - training batch 501, loss: 0.133, 16032/28000 datapoints
2025-03-06 20:55:27,090 - INFO - training batch 551, loss: 0.174, 17632/28000 datapoints
2025-03-06 20:55:27,210 - INFO - training batch 601, loss: 0.117, 19232/28000 datapoints
2025-03-06 20:55:27,330 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 20:55:27,449 - INFO - training batch 701, loss: 0.208, 22432/28000 datapoints
2025-03-06 20:55:27,572 - INFO - training batch 751, loss: 0.163, 24032/28000 datapoints
2025-03-06 20:55:27,696 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 20:55:27,817 - INFO - training batch 851, loss: 0.250, 27232/28000 datapoints
2025-03-06 20:55:27,877 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:55:27,921 - INFO - validation batch 51, loss: 1.251, 1632/6976 datapoints
2025-03-06 20:55:27,966 - INFO - validation batch 101, loss: 0.435, 3232/6976 datapoints
2025-03-06 20:55:28,009 - INFO - validation batch 151, loss: 0.429, 4832/6976 datapoints
2025-03-06 20:55:28,054 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 20:55:28,069 - INFO - Epoch 442/800 done.
2025-03-06 20:55:28,069 - INFO - Final validation performance:
Loss: 0.533, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:28,070 - INFO - Beginning epoch 443/800
2025-03-06 20:55:28,073 - INFO - training batch 1, loss: 0.268, 32/28000 datapoints
2025-03-06 20:55:28,193 - INFO - training batch 51, loss: 0.067, 1632/28000 datapoints
2025-03-06 20:55:28,314 - INFO - training batch 101, loss: 0.098, 3232/28000 datapoints
2025-03-06 20:55:28,433 - INFO - training batch 151, loss: 0.113, 4832/28000 datapoints
2025-03-06 20:55:28,565 - INFO - training batch 201, loss: 0.061, 6432/28000 datapoints
2025-03-06 20:55:28,690 - INFO - training batch 251, loss: 0.273, 8032/28000 datapoints
2025-03-06 20:55:28,813 - INFO - training batch 301, loss: 0.397, 9632/28000 datapoints
2025-03-06 20:55:28,937 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 20:55:29,067 - INFO - training batch 401, loss: 0.400, 12832/28000 datapoints
2025-03-06 20:55:29,190 - INFO - training batch 451, loss: 0.196, 14432/28000 datapoints
2025-03-06 20:55:29,317 - INFO - training batch 501, loss: 0.131, 16032/28000 datapoints
2025-03-06 20:55:29,440 - INFO - training batch 551, loss: 0.172, 17632/28000 datapoints
2025-03-06 20:55:29,566 - INFO - training batch 601, loss: 0.116, 19232/28000 datapoints
2025-03-06 20:55:29,693 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 20:55:29,816 - INFO - training batch 701, loss: 0.208, 22432/28000 datapoints
2025-03-06 20:55:29,941 - INFO - training batch 751, loss: 0.162, 24032/28000 datapoints
2025-03-06 20:55:30,065 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 20:55:30,192 - INFO - training batch 851, loss: 0.248, 27232/28000 datapoints
2025-03-06 20:55:30,254 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:55:30,303 - INFO - validation batch 51, loss: 1.251, 1632/6976 datapoints
2025-03-06 20:55:30,352 - INFO - validation batch 101, loss: 0.437, 3232/6976 datapoints
2025-03-06 20:55:30,399 - INFO - validation batch 151, loss: 0.431, 4832/6976 datapoints
2025-03-06 20:55:30,446 - INFO - validation batch 201, loss: 0.415, 6432/6976 datapoints
2025-03-06 20:55:30,461 - INFO - Epoch 443/800 done.
2025-03-06 20:55:30,461 - INFO - Final validation performance:
Loss: 0.534, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:30,461 - INFO - Beginning epoch 444/800
2025-03-06 20:55:30,465 - INFO - training batch 1, loss: 0.268, 32/28000 datapoints
2025-03-06 20:55:30,597 - INFO - training batch 51, loss: 0.067, 1632/28000 datapoints
2025-03-06 20:55:30,723 - INFO - training batch 101, loss: 0.098, 3232/28000 datapoints
2025-03-06 20:55:30,846 - INFO - training batch 151, loss: 0.112, 4832/28000 datapoints
2025-03-06 20:55:30,969 - INFO - training batch 201, loss: 0.061, 6432/28000 datapoints
2025-03-06 20:55:31,092 - INFO - training batch 251, loss: 0.273, 8032/28000 datapoints
2025-03-06 20:55:31,221 - INFO - training batch 301, loss: 0.396, 9632/28000 datapoints
2025-03-06 20:55:31,346 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 20:55:31,469 - INFO - training batch 401, loss: 0.399, 12832/28000 datapoints
2025-03-06 20:55:31,593 - INFO - training batch 451, loss: 0.195, 14432/28000 datapoints
2025-03-06 20:55:31,720 - INFO - training batch 501, loss: 0.131, 16032/28000 datapoints
2025-03-06 20:55:31,843 - INFO - training batch 551, loss: 0.172, 17632/28000 datapoints
2025-03-06 20:55:31,969 - INFO - training batch 601, loss: 0.115, 19232/28000 datapoints
2025-03-06 20:55:32,093 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 20:55:32,218 - INFO - training batch 701, loss: 0.207, 22432/28000 datapoints
2025-03-06 20:55:32,339 - INFO - training batch 751, loss: 0.162, 24032/28000 datapoints
2025-03-06 20:55:32,462 - INFO - training batch 801, loss: 0.096, 25632/28000 datapoints
2025-03-06 20:55:32,592 - INFO - training batch 851, loss: 0.247, 27232/28000 datapoints
2025-03-06 20:55:32,656 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:55:32,706 - INFO - validation batch 51, loss: 1.254, 1632/6976 datapoints
2025-03-06 20:55:32,754 - INFO - validation batch 101, loss: 0.438, 3232/6976 datapoints
2025-03-06 20:55:32,802 - INFO - validation batch 151, loss: 0.431, 4832/6976 datapoints
2025-03-06 20:55:32,849 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 20:55:32,864 - INFO - Epoch 444/800 done.
2025-03-06 20:55:32,864 - INFO - Final validation performance:
Loss: 0.535, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:55:32,865 - INFO - Beginning epoch 445/800
2025-03-06 20:55:32,868 - INFO - training batch 1, loss: 0.267, 32/28000 datapoints
2025-03-06 20:55:32,995 - INFO - training batch 51, loss: 0.067, 1632/28000 datapoints
2025-03-06 20:55:33,121 - INFO - training batch 101, loss: 0.097, 3232/28000 datapoints
2025-03-06 20:55:33,246 - INFO - training batch 151, loss: 0.112, 4832/28000 datapoints
2025-03-06 20:55:33,370 - INFO - training batch 201, loss: 0.060, 6432/28000 datapoints
2025-03-06 20:55:33,504 - INFO - training batch 251, loss: 0.273, 8032/28000 datapoints
2025-03-06 20:55:33,631 - INFO - training batch 301, loss: 0.395, 9632/28000 datapoints
2025-03-06 20:55:33,758 - INFO - training batch 351, loss: 0.192, 11232/28000 datapoints
2025-03-06 20:55:33,883 - INFO - training batch 401, loss: 0.398, 12832/28000 datapoints
2025-03-06 20:55:34,028 - INFO - training batch 451, loss: 0.191, 14432/28000 datapoints
2025-03-06 20:55:34,152 - INFO - training batch 501, loss: 0.130, 16032/28000 datapoints
2025-03-06 20:55:34,277 - INFO - training batch 551, loss: 0.172, 17632/28000 datapoints
2025-03-06 20:55:34,401 - INFO - training batch 601, loss: 0.114, 19232/28000 datapoints
2025-03-06 20:55:34,525 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 20:55:34,656 - INFO - training batch 701, loss: 0.207, 22432/28000 datapoints
2025-03-06 20:55:34,780 - INFO - training batch 751, loss: 0.160, 24032/28000 datapoints
2025-03-06 20:55:34,911 - INFO - training batch 801, loss: 0.096, 25632/28000 datapoints
2025-03-06 20:55:35,034 - INFO - training batch 851, loss: 0.245, 27232/28000 datapoints
2025-03-06 20:55:35,097 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:55:35,146 - INFO - validation batch 51, loss: 1.256, 1632/6976 datapoints
2025-03-06 20:55:35,193 - INFO - validation batch 101, loss: 0.439, 3232/6976 datapoints
2025-03-06 20:55:35,240 - INFO - validation batch 151, loss: 0.432, 4832/6976 datapoints
2025-03-06 20:55:35,289 - INFO - validation batch 201, loss: 0.415, 6432/6976 datapoints
2025-03-06 20:55:35,304 - INFO - Epoch 445/800 done.
2025-03-06 20:55:35,304 - INFO - Final validation performance:
Loss: 0.535, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:55:35,305 - INFO - Beginning epoch 446/800
2025-03-06 20:55:35,308 - INFO - training batch 1, loss: 0.267, 32/28000 datapoints
2025-03-06 20:55:35,436 - INFO - training batch 51, loss: 0.067, 1632/28000 datapoints
2025-03-06 20:55:35,560 - INFO - training batch 101, loss: 0.098, 3232/28000 datapoints
2025-03-06 20:55:35,690 - INFO - training batch 151, loss: 0.111, 4832/28000 datapoints
2025-03-06 20:55:35,815 - INFO - training batch 201, loss: 0.060, 6432/28000 datapoints
2025-03-06 20:55:35,940 - INFO - training batch 251, loss: 0.272, 8032/28000 datapoints
2025-03-06 20:55:36,063 - INFO - training batch 301, loss: 0.392, 9632/28000 datapoints
2025-03-06 20:55:36,188 - INFO - training batch 351, loss: 0.192, 11232/28000 datapoints
2025-03-06 20:55:36,314 - INFO - training batch 401, loss: 0.396, 12832/28000 datapoints
2025-03-06 20:55:36,439 - INFO - training batch 451, loss: 0.193, 14432/28000 datapoints
2025-03-06 20:55:36,563 - INFO - training batch 501, loss: 0.131, 16032/28000 datapoints
2025-03-06 20:55:36,694 - INFO - training batch 551, loss: 0.171, 17632/28000 datapoints
2025-03-06 20:55:36,817 - INFO - training batch 601, loss: 0.112, 19232/28000 datapoints
2025-03-06 20:55:36,942 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 20:55:37,070 - INFO - training batch 701, loss: 0.206, 22432/28000 datapoints
2025-03-06 20:55:37,195 - INFO - training batch 751, loss: 0.161, 24032/28000 datapoints
2025-03-06 20:55:37,319 - INFO - training batch 801, loss: 0.096, 25632/28000 datapoints
2025-03-06 20:55:37,442 - INFO - training batch 851, loss: 0.244, 27232/28000 datapoints
2025-03-06 20:55:37,504 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:55:37,554 - INFO - validation batch 51, loss: 1.257, 1632/6976 datapoints
2025-03-06 20:55:37,604 - INFO - validation batch 101, loss: 0.440, 3232/6976 datapoints
2025-03-06 20:55:37,667 - INFO - validation batch 151, loss: 0.432, 4832/6976 datapoints
2025-03-06 20:55:37,718 - INFO - validation batch 201, loss: 0.415, 6432/6976 datapoints
2025-03-06 20:55:37,736 - INFO - Epoch 446/800 done.
2025-03-06 20:55:37,737 - INFO - Final validation performance:
Loss: 0.536, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:55:37,737 - INFO - Beginning epoch 447/800
2025-03-06 20:55:37,741 - INFO - training batch 1, loss: 0.267, 32/28000 datapoints
2025-03-06 20:55:37,865 - INFO - training batch 51, loss: 0.067, 1632/28000 datapoints
2025-03-06 20:55:37,992 - INFO - training batch 101, loss: 0.097, 3232/28000 datapoints
2025-03-06 20:55:38,116 - INFO - training batch 151, loss: 0.110, 4832/28000 datapoints
2025-03-06 20:55:38,242 - INFO - training batch 201, loss: 0.060, 6432/28000 datapoints
2025-03-06 20:55:38,365 - INFO - training batch 251, loss: 0.271, 8032/28000 datapoints
2025-03-06 20:55:38,493 - INFO - training batch 301, loss: 0.390, 9632/28000 datapoints
2025-03-06 20:55:38,622 - INFO - training batch 351, loss: 0.192, 11232/28000 datapoints
2025-03-06 20:55:38,748 - INFO - training batch 401, loss: 0.394, 12832/28000 datapoints
2025-03-06 20:55:38,872 - INFO - training batch 451, loss: 0.193, 14432/28000 datapoints
2025-03-06 20:55:38,996 - INFO - training batch 501, loss: 0.130, 16032/28000 datapoints
2025-03-06 20:55:39,124 - INFO - training batch 551, loss: 0.170, 17632/28000 datapoints
2025-03-06 20:55:39,250 - INFO - training batch 601, loss: 0.112, 19232/28000 datapoints
2025-03-06 20:55:39,373 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 20:55:39,497 - INFO - training batch 701, loss: 0.206, 22432/28000 datapoints
2025-03-06 20:55:39,619 - INFO - training batch 751, loss: 0.159, 24032/28000 datapoints
2025-03-06 20:55:39,745 - INFO - training batch 801, loss: 0.096, 25632/28000 datapoints
2025-03-06 20:55:39,870 - INFO - training batch 851, loss: 0.242, 27232/28000 datapoints
2025-03-06 20:55:39,932 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:55:39,978 - INFO - validation batch 51, loss: 1.259, 1632/6976 datapoints
2025-03-06 20:55:40,035 - INFO - validation batch 101, loss: 0.442, 3232/6976 datapoints
2025-03-06 20:55:40,080 - INFO - validation batch 151, loss: 0.433, 4832/6976 datapoints
2025-03-06 20:55:40,124 - INFO - validation batch 201, loss: 0.415, 6432/6976 datapoints
2025-03-06 20:55:40,139 - INFO - Epoch 447/800 done.
2025-03-06 20:55:40,140 - INFO - Final validation performance:
Loss: 0.537, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:55:40,140 - INFO - Beginning epoch 448/800
2025-03-06 20:55:40,144 - INFO - training batch 1, loss: 0.266, 32/28000 datapoints
2025-03-06 20:55:40,269 - INFO - training batch 51, loss: 0.067, 1632/28000 datapoints
2025-03-06 20:55:40,388 - INFO - training batch 101, loss: 0.097, 3232/28000 datapoints
2025-03-06 20:55:40,507 - INFO - training batch 151, loss: 0.109, 4832/28000 datapoints
2025-03-06 20:55:40,631 - INFO - training batch 201, loss: 0.059, 6432/28000 datapoints
2025-03-06 20:55:40,754 - INFO - training batch 251, loss: 0.270, 8032/28000 datapoints
2025-03-06 20:55:40,877 - INFO - training batch 301, loss: 0.388, 9632/28000 datapoints
2025-03-06 20:55:40,997 - INFO - training batch 351, loss: 0.192, 11232/28000 datapoints
2025-03-06 20:55:41,117 - INFO - training batch 401, loss: 0.394, 12832/28000 datapoints
2025-03-06 20:55:41,240 - INFO - training batch 451, loss: 0.192, 14432/28000 datapoints
2025-03-06 20:55:41,363 - INFO - training batch 501, loss: 0.130, 16032/28000 datapoints
2025-03-06 20:55:41,484 - INFO - training batch 551, loss: 0.170, 17632/28000 datapoints
2025-03-06 20:55:41,604 - INFO - training batch 601, loss: 0.110, 19232/28000 datapoints
2025-03-06 20:55:41,727 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 20:55:41,848 - INFO - training batch 701, loss: 0.206, 22432/28000 datapoints
2025-03-06 20:55:41,970 - INFO - training batch 751, loss: 0.159, 24032/28000 datapoints
2025-03-06 20:55:42,091 - INFO - training batch 801, loss: 0.096, 25632/28000 datapoints
2025-03-06 20:55:42,211 - INFO - training batch 851, loss: 0.240, 27232/28000 datapoints
2025-03-06 20:55:42,274 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:55:42,317 - INFO - validation batch 51, loss: 1.261, 1632/6976 datapoints
2025-03-06 20:55:42,361 - INFO - validation batch 101, loss: 0.443, 3232/6976 datapoints
2025-03-06 20:55:42,405 - INFO - validation batch 151, loss: 0.434, 4832/6976 datapoints
2025-03-06 20:55:42,449 - INFO - validation batch 201, loss: 0.415, 6432/6976 datapoints
2025-03-06 20:55:42,464 - INFO - Epoch 448/800 done.
2025-03-06 20:55:42,465 - INFO - Final validation performance:
Loss: 0.538, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:42,465 - INFO - Beginning epoch 449/800
2025-03-06 20:55:42,468 - INFO - training batch 1, loss: 0.267, 32/28000 datapoints
2025-03-06 20:55:42,589 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-06 20:55:42,714 - INFO - training batch 101, loss: 0.096, 3232/28000 datapoints
2025-03-06 20:55:42,838 - INFO - training batch 151, loss: 0.108, 4832/28000 datapoints
2025-03-06 20:55:42,962 - INFO - training batch 201, loss: 0.059, 6432/28000 datapoints
2025-03-06 20:55:43,083 - INFO - training batch 251, loss: 0.269, 8032/28000 datapoints
2025-03-06 20:55:43,204 - INFO - training batch 301, loss: 0.387, 9632/28000 datapoints
2025-03-06 20:55:43,325 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 20:55:43,445 - INFO - training batch 401, loss: 0.391, 12832/28000 datapoints
2025-03-06 20:55:43,565 - INFO - training batch 451, loss: 0.188, 14432/28000 datapoints
2025-03-06 20:55:43,689 - INFO - training batch 501, loss: 0.129, 16032/28000 datapoints
2025-03-06 20:55:43,811 - INFO - training batch 551, loss: 0.169, 17632/28000 datapoints
2025-03-06 20:55:43,932 - INFO - training batch 601, loss: 0.110, 19232/28000 datapoints
2025-03-06 20:55:44,074 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 20:55:44,196 - INFO - training batch 701, loss: 0.205, 22432/28000 datapoints
2025-03-06 20:55:44,317 - INFO - training batch 751, loss: 0.157, 24032/28000 datapoints
2025-03-06 20:55:44,438 - INFO - training batch 801, loss: 0.096, 25632/28000 datapoints
2025-03-06 20:55:44,559 - INFO - training batch 851, loss: 0.238, 27232/28000 datapoints
2025-03-06 20:55:44,622 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:55:44,667 - INFO - validation batch 51, loss: 1.263, 1632/6976 datapoints
2025-03-06 20:55:44,710 - INFO - validation batch 101, loss: 0.444, 3232/6976 datapoints
2025-03-06 20:55:44,755 - INFO - validation batch 151, loss: 0.433, 4832/6976 datapoints
2025-03-06 20:55:44,801 - INFO - validation batch 201, loss: 0.415, 6432/6976 datapoints
2025-03-06 20:55:44,816 - INFO - Epoch 449/800 done.
2025-03-06 20:55:44,816 - INFO - Final validation performance:
Loss: 0.538, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:55:44,817 - INFO - Beginning epoch 450/800
2025-03-06 20:55:44,820 - INFO - training batch 1, loss: 0.265, 32/28000 datapoints
2025-03-06 20:55:44,948 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-06 20:55:45,067 - INFO - training batch 101, loss: 0.096, 3232/28000 datapoints
2025-03-06 20:55:45,188 - INFO - training batch 151, loss: 0.107, 4832/28000 datapoints
2025-03-06 20:55:45,311 - INFO - training batch 201, loss: 0.058, 6432/28000 datapoints
2025-03-06 20:55:45,432 - INFO - training batch 251, loss: 0.269, 8032/28000 datapoints
2025-03-06 20:55:45,552 - INFO - training batch 301, loss: 0.385, 9632/28000 datapoints
2025-03-06 20:55:45,682 - INFO - training batch 351, loss: 0.190, 11232/28000 datapoints
2025-03-06 20:55:45,803 - INFO - training batch 401, loss: 0.390, 12832/28000 datapoints
2025-03-06 20:55:45,921 - INFO - training batch 451, loss: 0.191, 14432/28000 datapoints
2025-03-06 20:55:46,041 - INFO - training batch 501, loss: 0.130, 16032/28000 datapoints
2025-03-06 20:55:46,161 - INFO - training batch 551, loss: 0.170, 17632/28000 datapoints
2025-03-06 20:55:46,283 - INFO - training batch 601, loss: 0.108, 19232/28000 datapoints
2025-03-06 20:55:46,405 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 20:55:46,524 - INFO - training batch 701, loss: 0.205, 22432/28000 datapoints
2025-03-06 20:55:46,651 - INFO - training batch 751, loss: 0.158, 24032/28000 datapoints
2025-03-06 20:55:46,770 - INFO - training batch 801, loss: 0.096, 25632/28000 datapoints
2025-03-06 20:55:46,891 - INFO - training batch 851, loss: 0.236, 27232/28000 datapoints
2025-03-06 20:55:46,951 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:55:46,995 - INFO - validation batch 51, loss: 1.264, 1632/6976 datapoints
2025-03-06 20:55:47,042 - INFO - validation batch 101, loss: 0.447, 3232/6976 datapoints
2025-03-06 20:55:47,087 - INFO - validation batch 151, loss: 0.433, 4832/6976 datapoints
2025-03-06 20:55:47,132 - INFO - validation batch 201, loss: 0.415, 6432/6976 datapoints
2025-03-06 20:55:47,147 - INFO - Epoch 450/800 done.
2025-03-06 20:55:47,147 - INFO - Final validation performance:
Loss: 0.539, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:47,148 - INFO - Beginning epoch 451/800
2025-03-06 20:55:47,152 - INFO - training batch 1, loss: 0.265, 32/28000 datapoints
2025-03-06 20:55:47,273 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-06 20:55:47,395 - INFO - training batch 101, loss: 0.095, 3232/28000 datapoints
2025-03-06 20:55:47,516 - INFO - training batch 151, loss: 0.107, 4832/28000 datapoints
2025-03-06 20:55:47,638 - INFO - training batch 201, loss: 0.058, 6432/28000 datapoints
2025-03-06 20:55:47,762 - INFO - training batch 251, loss: 0.268, 8032/28000 datapoints
2025-03-06 20:55:47,882 - INFO - training batch 301, loss: 0.383, 9632/28000 datapoints
2025-03-06 20:55:48,004 - INFO - training batch 351, loss: 0.190, 11232/28000 datapoints
2025-03-06 20:55:48,124 - INFO - training batch 401, loss: 0.389, 12832/28000 datapoints
2025-03-06 20:55:48,244 - INFO - training batch 451, loss: 0.189, 14432/28000 datapoints
2025-03-06 20:55:48,367 - INFO - training batch 501, loss: 0.128, 16032/28000 datapoints
2025-03-06 20:55:48,489 - INFO - training batch 551, loss: 0.168, 17632/28000 datapoints
2025-03-06 20:55:48,615 - INFO - training batch 601, loss: 0.108, 19232/28000 datapoints
2025-03-06 20:55:48,744 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 20:55:48,868 - INFO - training batch 701, loss: 0.204, 22432/28000 datapoints
2025-03-06 20:55:48,991 - INFO - training batch 751, loss: 0.156, 24032/28000 datapoints
2025-03-06 20:55:49,116 - INFO - training batch 801, loss: 0.096, 25632/28000 datapoints
2025-03-06 20:55:49,240 - INFO - training batch 851, loss: 0.234, 27232/28000 datapoints
2025-03-06 20:55:49,303 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:55:49,351 - INFO - validation batch 51, loss: 1.268, 1632/6976 datapoints
2025-03-06 20:55:49,398 - INFO - validation batch 101, loss: 0.447, 3232/6976 datapoints
2025-03-06 20:55:49,446 - INFO - validation batch 151, loss: 0.435, 4832/6976 datapoints
2025-03-06 20:55:49,495 - INFO - validation batch 201, loss: 0.415, 6432/6976 datapoints
2025-03-06 20:55:49,512 - INFO - Epoch 451/800 done.
2025-03-06 20:55:49,512 - INFO - Final validation performance:
Loss: 0.540, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:55:49,512 - INFO - Beginning epoch 452/800
2025-03-06 20:55:49,516 - INFO - training batch 1, loss: 0.265, 32/28000 datapoints
2025-03-06 20:55:49,645 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-06 20:55:49,768 - INFO - training batch 101, loss: 0.095, 3232/28000 datapoints
2025-03-06 20:55:49,895 - INFO - training batch 151, loss: 0.106, 4832/28000 datapoints
2025-03-06 20:55:50,019 - INFO - training batch 201, loss: 0.058, 6432/28000 datapoints
2025-03-06 20:55:50,144 - INFO - training batch 251, loss: 0.267, 8032/28000 datapoints
2025-03-06 20:55:50,267 - INFO - training batch 301, loss: 0.382, 9632/28000 datapoints
2025-03-06 20:55:50,390 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 20:55:50,512 - INFO - training batch 401, loss: 0.388, 12832/28000 datapoints
2025-03-06 20:55:50,641 - INFO - training batch 451, loss: 0.189, 14432/28000 datapoints
2025-03-06 20:55:50,775 - INFO - training batch 501, loss: 0.129, 16032/28000 datapoints
2025-03-06 20:55:50,901 - INFO - training batch 551, loss: 0.168, 17632/28000 datapoints
2025-03-06 20:55:51,023 - INFO - training batch 601, loss: 0.106, 19232/28000 datapoints
2025-03-06 20:55:51,147 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 20:55:51,272 - INFO - training batch 701, loss: 0.204, 22432/28000 datapoints
2025-03-06 20:55:51,401 - INFO - training batch 751, loss: 0.156, 24032/28000 datapoints
2025-03-06 20:55:51,526 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-06 20:55:51,652 - INFO - training batch 851, loss: 0.232, 27232/28000 datapoints
2025-03-06 20:55:51,727 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:55:51,803 - INFO - validation batch 51, loss: 1.269, 1632/6976 datapoints
2025-03-06 20:55:51,865 - INFO - validation batch 101, loss: 0.449, 3232/6976 datapoints
2025-03-06 20:55:51,915 - INFO - validation batch 151, loss: 0.435, 4832/6976 datapoints
2025-03-06 20:55:51,965 - INFO - validation batch 201, loss: 0.416, 6432/6976 datapoints
2025-03-06 20:55:51,985 - INFO - Epoch 452/800 done.
2025-03-06 20:55:51,985 - INFO - Final validation performance:
Loss: 0.541, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:51,986 - INFO - Beginning epoch 453/800
2025-03-06 20:55:51,990 - INFO - training batch 1, loss: 0.264, 32/28000 datapoints
2025-03-06 20:55:52,117 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-06 20:55:52,243 - INFO - training batch 101, loss: 0.094, 3232/28000 datapoints
2025-03-06 20:55:52,370 - INFO - training batch 151, loss: 0.105, 4832/28000 datapoints
2025-03-06 20:55:52,493 - INFO - training batch 201, loss: 0.058, 6432/28000 datapoints
2025-03-06 20:55:52,616 - INFO - training batch 251, loss: 0.266, 8032/28000 datapoints
2025-03-06 20:55:52,747 - INFO - training batch 301, loss: 0.379, 9632/28000 datapoints
2025-03-06 20:55:52,872 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 20:55:52,999 - INFO - training batch 401, loss: 0.385, 12832/28000 datapoints
2025-03-06 20:55:53,128 - INFO - training batch 451, loss: 0.189, 14432/28000 datapoints
2025-03-06 20:55:53,252 - INFO - training batch 501, loss: 0.127, 16032/28000 datapoints
2025-03-06 20:55:53,378 - INFO - training batch 551, loss: 0.167, 17632/28000 datapoints
2025-03-06 20:55:53,502 - INFO - training batch 601, loss: 0.106, 19232/28000 datapoints
2025-03-06 20:55:53,626 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 20:55:53,751 - INFO - training batch 701, loss: 0.203, 22432/28000 datapoints
2025-03-06 20:55:53,873 - INFO - training batch 751, loss: 0.154, 24032/28000 datapoints
2025-03-06 20:55:53,998 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-06 20:55:54,150 - INFO - training batch 851, loss: 0.230, 27232/28000 datapoints
2025-03-06 20:55:54,214 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:55:54,264 - INFO - validation batch 51, loss: 1.271, 1632/6976 datapoints
2025-03-06 20:55:54,311 - INFO - validation batch 101, loss: 0.451, 3232/6976 datapoints
2025-03-06 20:55:54,360 - INFO - validation batch 151, loss: 0.435, 4832/6976 datapoints
2025-03-06 20:55:54,409 - INFO - validation batch 201, loss: 0.416, 6432/6976 datapoints
2025-03-06 20:55:54,426 - INFO - Epoch 453/800 done.
2025-03-06 20:55:54,426 - INFO - Final validation performance:
Loss: 0.541, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:54,427 - INFO - Beginning epoch 454/800
2025-03-06 20:55:54,431 - INFO - training batch 1, loss: 0.264, 32/28000 datapoints
2025-03-06 20:55:54,556 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-06 20:55:54,683 - INFO - training batch 101, loss: 0.095, 3232/28000 datapoints
2025-03-06 20:55:54,802 - INFO - training batch 151, loss: 0.104, 4832/28000 datapoints
2025-03-06 20:55:54,930 - INFO - training batch 201, loss: 0.057, 6432/28000 datapoints
2025-03-06 20:55:55,051 - INFO - training batch 251, loss: 0.266, 8032/28000 datapoints
2025-03-06 20:55:55,171 - INFO - training batch 301, loss: 0.378, 9632/28000 datapoints
2025-03-06 20:55:55,290 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 20:55:55,410 - INFO - training batch 401, loss: 0.385, 12832/28000 datapoints
2025-03-06 20:55:55,531 - INFO - training batch 451, loss: 0.185, 14432/28000 datapoints
2025-03-06 20:55:55,654 - INFO - training batch 501, loss: 0.127, 16032/28000 datapoints
2025-03-06 20:55:55,776 - INFO - training batch 551, loss: 0.166, 17632/28000 datapoints
2025-03-06 20:55:55,895 - INFO - training batch 601, loss: 0.105, 19232/28000 datapoints
2025-03-06 20:55:56,016 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 20:55:56,137 - INFO - training batch 701, loss: 0.203, 22432/28000 datapoints
2025-03-06 20:55:56,256 - INFO - training batch 751, loss: 0.155, 24032/28000 datapoints
2025-03-06 20:55:56,378 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-06 20:55:56,501 - INFO - training batch 851, loss: 0.228, 27232/28000 datapoints
2025-03-06 20:55:56,560 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:55:56,603 - INFO - validation batch 51, loss: 1.272, 1632/6976 datapoints
2025-03-06 20:55:56,648 - INFO - validation batch 101, loss: 0.453, 3232/6976 datapoints
2025-03-06 20:55:56,695 - INFO - validation batch 151, loss: 0.435, 4832/6976 datapoints
2025-03-06 20:55:56,738 - INFO - validation batch 201, loss: 0.416, 6432/6976 datapoints
2025-03-06 20:55:56,753 - INFO - Epoch 454/800 done.
2025-03-06 20:55:56,753 - INFO - Final validation performance:
Loss: 0.542, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:55:56,754 - INFO - Beginning epoch 455/800
2025-03-06 20:55:56,757 - INFO - training batch 1, loss: 0.263, 32/28000 datapoints
2025-03-06 20:55:56,879 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-06 20:55:57,002 - INFO - training batch 101, loss: 0.093, 3232/28000 datapoints
2025-03-06 20:55:57,124 - INFO - training batch 151, loss: 0.103, 4832/28000 datapoints
2025-03-06 20:55:57,244 - INFO - training batch 201, loss: 0.057, 6432/28000 datapoints
2025-03-06 20:55:57,364 - INFO - training batch 251, loss: 0.265, 8032/28000 datapoints
2025-03-06 20:55:57,484 - INFO - training batch 301, loss: 0.376, 9632/28000 datapoints
2025-03-06 20:55:57,612 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 20:55:57,738 - INFO - training batch 401, loss: 0.385, 12832/28000 datapoints
2025-03-06 20:55:57,858 - INFO - training batch 451, loss: 0.187, 14432/28000 datapoints
2025-03-06 20:55:57,980 - INFO - training batch 501, loss: 0.128, 16032/28000 datapoints
2025-03-06 20:55:58,102 - INFO - training batch 551, loss: 0.166, 17632/28000 datapoints
2025-03-06 20:55:58,221 - INFO - training batch 601, loss: 0.103, 19232/28000 datapoints
2025-03-06 20:55:58,340 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 20:55:58,460 - INFO - training batch 701, loss: 0.202, 22432/28000 datapoints
2025-03-06 20:55:58,581 - INFO - training batch 751, loss: 0.153, 24032/28000 datapoints
2025-03-06 20:55:58,706 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-06 20:55:58,827 - INFO - training batch 851, loss: 0.226, 27232/28000 datapoints
2025-03-06 20:55:58,887 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:55:58,930 - INFO - validation batch 51, loss: 1.275, 1632/6976 datapoints
2025-03-06 20:55:58,975 - INFO - validation batch 101, loss: 0.453, 3232/6976 datapoints
2025-03-06 20:55:59,019 - INFO - validation batch 151, loss: 0.436, 4832/6976 datapoints
2025-03-06 20:55:59,064 - INFO - validation batch 201, loss: 0.416, 6432/6976 datapoints
2025-03-06 20:55:59,079 - INFO - Epoch 455/800 done.
2025-03-06 20:55:59,080 - INFO - Final validation performance:
Loss: 0.543, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:55:59,080 - INFO - Beginning epoch 456/800
2025-03-06 20:55:59,083 - INFO - training batch 1, loss: 0.263, 32/28000 datapoints
2025-03-06 20:55:59,205 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-06 20:55:59,327 - INFO - training batch 101, loss: 0.094, 3232/28000 datapoints
2025-03-06 20:55:59,496 - INFO - training batch 151, loss: 0.103, 4832/28000 datapoints
2025-03-06 20:55:59,617 - INFO - training batch 201, loss: 0.057, 6432/28000 datapoints
2025-03-06 20:55:59,740 - INFO - training batch 251, loss: 0.265, 8032/28000 datapoints
2025-03-06 20:55:59,861 - INFO - training batch 301, loss: 0.375, 9632/28000 datapoints
2025-03-06 20:55:59,980 - INFO - training batch 351, loss: 0.188, 11232/28000 datapoints
2025-03-06 20:56:00,105 - INFO - training batch 401, loss: 0.383, 12832/28000 datapoints
2025-03-06 20:56:00,223 - INFO - training batch 451, loss: 0.186, 14432/28000 datapoints
2025-03-06 20:56:00,344 - INFO - training batch 501, loss: 0.126, 16032/28000 datapoints
2025-03-06 20:56:00,463 - INFO - training batch 551, loss: 0.164, 17632/28000 datapoints
2025-03-06 20:56:00,584 - INFO - training batch 601, loss: 0.102, 19232/28000 datapoints
2025-03-06 20:56:00,710 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 20:56:00,829 - INFO - training batch 701, loss: 0.202, 22432/28000 datapoints
2025-03-06 20:56:00,949 - INFO - training batch 751, loss: 0.153, 24032/28000 datapoints
2025-03-06 20:56:01,071 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-06 20:56:01,190 - INFO - training batch 851, loss: 0.225, 27232/28000 datapoints
2025-03-06 20:56:01,249 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:56:01,293 - INFO - validation batch 51, loss: 1.277, 1632/6976 datapoints
2025-03-06 20:56:01,343 - INFO - validation batch 101, loss: 0.455, 3232/6976 datapoints
2025-03-06 20:56:01,386 - INFO - validation batch 151, loss: 0.437, 4832/6976 datapoints
2025-03-06 20:56:01,430 - INFO - validation batch 201, loss: 0.416, 6432/6976 datapoints
2025-03-06 20:56:01,445 - INFO - Epoch 456/800 done.
2025-03-06 20:56:01,445 - INFO - Final validation performance:
Loss: 0.544, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:56:01,445 - INFO - Beginning epoch 457/800
2025-03-06 20:56:01,449 - INFO - training batch 1, loss: 0.263, 32/28000 datapoints
2025-03-06 20:56:01,572 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 20:56:01,696 - INFO - training batch 101, loss: 0.093, 3232/28000 datapoints
2025-03-06 20:56:01,815 - INFO - training batch 151, loss: 0.102, 4832/28000 datapoints
2025-03-06 20:56:01,936 - INFO - training batch 201, loss: 0.057, 6432/28000 datapoints
2025-03-06 20:56:02,058 - INFO - training batch 251, loss: 0.264, 8032/28000 datapoints
2025-03-06 20:56:02,178 - INFO - training batch 301, loss: 0.373, 9632/28000 datapoints
2025-03-06 20:56:02,297 - INFO - training batch 351, loss: 0.188, 11232/28000 datapoints
2025-03-06 20:56:02,416 - INFO - training batch 401, loss: 0.382, 12832/28000 datapoints
2025-03-06 20:56:02,538 - INFO - training batch 451, loss: 0.183, 14432/28000 datapoints
2025-03-06 20:56:02,661 - INFO - training batch 501, loss: 0.126, 16032/28000 datapoints
2025-03-06 20:56:02,784 - INFO - training batch 551, loss: 0.164, 17632/28000 datapoints
2025-03-06 20:56:02,904 - INFO - training batch 601, loss: 0.101, 19232/28000 datapoints
2025-03-06 20:56:03,025 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 20:56:03,147 - INFO - training batch 701, loss: 0.201, 22432/28000 datapoints
2025-03-06 20:56:03,265 - INFO - training batch 751, loss: 0.151, 24032/28000 datapoints
2025-03-06 20:56:03,385 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-06 20:56:03,505 - INFO - training batch 851, loss: 0.223, 27232/28000 datapoints
2025-03-06 20:56:03,565 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:56:03,609 - INFO - validation batch 51, loss: 1.278, 1632/6976 datapoints
2025-03-06 20:56:03,654 - INFO - validation batch 101, loss: 0.457, 3232/6976 datapoints
2025-03-06 20:56:03,700 - INFO - validation batch 151, loss: 0.436, 4832/6976 datapoints
2025-03-06 20:56:03,743 - INFO - validation batch 201, loss: 0.417, 6432/6976 datapoints
2025-03-06 20:56:03,759 - INFO - Epoch 457/800 done.
2025-03-06 20:56:03,760 - INFO - Final validation performance:
Loss: 0.544, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:56:03,760 - INFO - Beginning epoch 458/800
2025-03-06 20:56:03,763 - INFO - training batch 1, loss: 0.262, 32/28000 datapoints
2025-03-06 20:56:03,885 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 20:56:04,005 - INFO - training batch 101, loss: 0.094, 3232/28000 datapoints
2025-03-06 20:56:04,128 - INFO - training batch 151, loss: 0.102, 4832/28000 datapoints
2025-03-06 20:56:04,276 - INFO - training batch 201, loss: 0.056, 6432/28000 datapoints
2025-03-06 20:56:04,397 - INFO - training batch 251, loss: 0.263, 8032/28000 datapoints
2025-03-06 20:56:04,517 - INFO - training batch 301, loss: 0.372, 9632/28000 datapoints
2025-03-06 20:56:04,642 - INFO - training batch 351, loss: 0.187, 11232/28000 datapoints
2025-03-06 20:56:04,767 - INFO - training batch 401, loss: 0.381, 12832/28000 datapoints
2025-03-06 20:56:04,890 - INFO - training batch 451, loss: 0.185, 14432/28000 datapoints
2025-03-06 20:56:05,011 - INFO - training batch 501, loss: 0.127, 16032/28000 datapoints
2025-03-06 20:56:05,134 - INFO - training batch 551, loss: 0.164, 17632/28000 datapoints
2025-03-06 20:56:05,253 - INFO - training batch 601, loss: 0.100, 19232/28000 datapoints
2025-03-06 20:56:05,374 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 20:56:05,494 - INFO - training batch 701, loss: 0.201, 22432/28000 datapoints
2025-03-06 20:56:05,615 - INFO - training batch 751, loss: 0.151, 24032/28000 datapoints
2025-03-06 20:56:05,736 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-06 20:56:05,856 - INFO - training batch 851, loss: 0.221, 27232/28000 datapoints
2025-03-06 20:56:05,916 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:56:05,960 - INFO - validation batch 51, loss: 1.282, 1632/6976 datapoints
2025-03-06 20:56:06,003 - INFO - validation batch 101, loss: 0.458, 3232/6976 datapoints
2025-03-06 20:56:06,046 - INFO - validation batch 151, loss: 0.437, 4832/6976 datapoints
2025-03-06 20:56:06,092 - INFO - validation batch 201, loss: 0.417, 6432/6976 datapoints
2025-03-06 20:56:06,107 - INFO - Epoch 458/800 done.
2025-03-06 20:56:06,107 - INFO - Final validation performance:
Loss: 0.546, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:56:06,108 - INFO - Beginning epoch 459/800
2025-03-06 20:56:06,111 - INFO - training batch 1, loss: 0.263, 32/28000 datapoints
2025-03-06 20:56:06,234 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 20:56:06,358 - INFO - training batch 101, loss: 0.092, 3232/28000 datapoints
2025-03-06 20:56:06,478 - INFO - training batch 151, loss: 0.100, 4832/28000 datapoints
2025-03-06 20:56:06,602 - INFO - training batch 201, loss: 0.056, 6432/28000 datapoints
2025-03-06 20:56:06,728 - INFO - training batch 251, loss: 0.262, 8032/28000 datapoints
2025-03-06 20:56:06,847 - INFO - training batch 301, loss: 0.370, 9632/28000 datapoints
2025-03-06 20:56:06,967 - INFO - training batch 351, loss: 0.188, 11232/28000 datapoints
2025-03-06 20:56:07,088 - INFO - training batch 401, loss: 0.381, 12832/28000 datapoints
2025-03-06 20:56:07,225 - INFO - training batch 451, loss: 0.185, 14432/28000 datapoints
2025-03-06 20:56:07,345 - INFO - training batch 501, loss: 0.126, 16032/28000 datapoints
2025-03-06 20:56:07,465 - INFO - training batch 551, loss: 0.163, 17632/28000 datapoints
2025-03-06 20:56:07,586 - INFO - training batch 601, loss: 0.099, 19232/28000 datapoints
2025-03-06 20:56:07,716 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 20:56:07,836 - INFO - training batch 701, loss: 0.201, 22432/28000 datapoints
2025-03-06 20:56:07,954 - INFO - training batch 751, loss: 0.150, 24032/28000 datapoints
2025-03-06 20:56:08,074 - INFO - training batch 801, loss: 0.094, 25632/28000 datapoints
2025-03-06 20:56:08,200 - INFO - training batch 851, loss: 0.219, 27232/28000 datapoints
2025-03-06 20:56:08,259 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:56:08,302 - INFO - validation batch 51, loss: 1.279, 1632/6976 datapoints
2025-03-06 20:56:08,347 - INFO - validation batch 101, loss: 0.460, 3232/6976 datapoints
2025-03-06 20:56:08,391 - INFO - validation batch 151, loss: 0.437, 4832/6976 datapoints
2025-03-06 20:56:08,435 - INFO - validation batch 201, loss: 0.418, 6432/6976 datapoints
2025-03-06 20:56:08,450 - INFO - Epoch 459/800 done.
2025-03-06 20:56:08,450 - INFO - Final validation performance:
Loss: 0.546, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:56:08,451 - INFO - Beginning epoch 460/800
2025-03-06 20:56:08,454 - INFO - training batch 1, loss: 0.260, 32/28000 datapoints
2025-03-06 20:56:08,583 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 20:56:08,715 - INFO - training batch 101, loss: 0.092, 3232/28000 datapoints
2025-03-06 20:56:08,835 - INFO - training batch 151, loss: 0.099, 4832/28000 datapoints
2025-03-06 20:56:08,956 - INFO - training batch 201, loss: 0.055, 6432/28000 datapoints
2025-03-06 20:56:09,078 - INFO - training batch 251, loss: 0.262, 8032/28000 datapoints
2025-03-06 20:56:09,199 - INFO - training batch 301, loss: 0.369, 9632/28000 datapoints
2025-03-06 20:56:09,320 - INFO - training batch 351, loss: 0.187, 11232/28000 datapoints
2025-03-06 20:56:09,440 - INFO - training batch 401, loss: 0.378, 12832/28000 datapoints
2025-03-06 20:56:09,560 - INFO - training batch 451, loss: 0.181, 14432/28000 datapoints
2025-03-06 20:56:09,688 - INFO - training batch 501, loss: 0.125, 16032/28000 datapoints
2025-03-06 20:56:09,807 - INFO - training batch 551, loss: 0.162, 17632/28000 datapoints
2025-03-06 20:56:09,942 - INFO - training batch 601, loss: 0.098, 19232/28000 datapoints
2025-03-06 20:56:10,071 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 20:56:10,193 - INFO - training batch 701, loss: 0.200, 22432/28000 datapoints
2025-03-06 20:56:10,313 - INFO - training batch 751, loss: 0.150, 24032/28000 datapoints
2025-03-06 20:56:10,433 - INFO - training batch 801, loss: 0.094, 25632/28000 datapoints
2025-03-06 20:56:10,553 - INFO - training batch 851, loss: 0.218, 27232/28000 datapoints
2025-03-06 20:56:10,612 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:56:10,660 - INFO - validation batch 51, loss: 1.281, 1632/6976 datapoints
2025-03-06 20:56:10,704 - INFO - validation batch 101, loss: 0.462, 3232/6976 datapoints
2025-03-06 20:56:10,751 - INFO - validation batch 151, loss: 0.437, 4832/6976 datapoints
2025-03-06 20:56:10,795 - INFO - validation batch 201, loss: 0.418, 6432/6976 datapoints
2025-03-06 20:56:10,811 - INFO - Epoch 460/800 done.
2025-03-06 20:56:10,811 - INFO - Final validation performance:
Loss: 0.547, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:56:10,811 - INFO - Beginning epoch 461/800
2025-03-06 20:56:10,815 - INFO - training batch 1, loss: 0.259, 32/28000 datapoints
2025-03-06 20:56:10,936 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 20:56:11,056 - INFO - training batch 101, loss: 0.091, 3232/28000 datapoints
2025-03-06 20:56:11,181 - INFO - training batch 151, loss: 0.099, 4832/28000 datapoints
2025-03-06 20:56:11,303 - INFO - training batch 201, loss: 0.055, 6432/28000 datapoints
2025-03-06 20:56:11,430 - INFO - training batch 251, loss: 0.261, 8032/28000 datapoints
2025-03-06 20:56:11,550 - INFO - training batch 301, loss: 0.367, 9632/28000 datapoints
2025-03-06 20:56:11,674 - INFO - training batch 351, loss: 0.187, 11232/28000 datapoints
2025-03-06 20:56:11,794 - INFO - training batch 401, loss: 0.377, 12832/28000 datapoints
2025-03-06 20:56:11,914 - INFO - training batch 451, loss: 0.183, 14432/28000 datapoints
2025-03-06 20:56:12,037 - INFO - training batch 501, loss: 0.126, 16032/28000 datapoints
2025-03-06 20:56:12,160 - INFO - training batch 551, loss: 0.162, 17632/28000 datapoints
2025-03-06 20:56:12,280 - INFO - training batch 601, loss: 0.098, 19232/28000 datapoints
2025-03-06 20:56:12,400 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 20:56:12,520 - INFO - training batch 701, loss: 0.199, 22432/28000 datapoints
2025-03-06 20:56:12,642 - INFO - training batch 751, loss: 0.149, 24032/28000 datapoints
2025-03-06 20:56:12,767 - INFO - training batch 801, loss: 0.094, 25632/28000 datapoints
2025-03-06 20:56:12,888 - INFO - training batch 851, loss: 0.216, 27232/28000 datapoints
2025-03-06 20:56:12,947 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:56:12,991 - INFO - validation batch 51, loss: 1.284, 1632/6976 datapoints
2025-03-06 20:56:13,035 - INFO - validation batch 101, loss: 0.463, 3232/6976 datapoints
2025-03-06 20:56:13,078 - INFO - validation batch 151, loss: 0.438, 4832/6976 datapoints
2025-03-06 20:56:13,124 - INFO - validation batch 201, loss: 0.418, 6432/6976 datapoints
2025-03-06 20:56:13,139 - INFO - Epoch 461/800 done.
2025-03-06 20:56:13,139 - INFO - Final validation performance:
Loss: 0.548, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:56:13,140 - INFO - Beginning epoch 462/800
2025-03-06 20:56:13,143 - INFO - training batch 1, loss: 0.260, 32/28000 datapoints
2025-03-06 20:56:13,268 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 20:56:13,395 - INFO - training batch 101, loss: 0.091, 3232/28000 datapoints
2025-03-06 20:56:13,541 - INFO - training batch 151, loss: 0.098, 4832/28000 datapoints
2025-03-06 20:56:13,673 - INFO - training batch 201, loss: 0.055, 6432/28000 datapoints
2025-03-06 20:56:13,793 - INFO - training batch 251, loss: 0.260, 8032/28000 datapoints
2025-03-06 20:56:13,917 - INFO - training batch 301, loss: 0.365, 9632/28000 datapoints
2025-03-06 20:56:14,037 - INFO - training batch 351, loss: 0.187, 11232/28000 datapoints
2025-03-06 20:56:14,167 - INFO - training batch 401, loss: 0.376, 12832/28000 datapoints
2025-03-06 20:56:14,301 - INFO - training batch 451, loss: 0.183, 14432/28000 datapoints
2025-03-06 20:56:14,439 - INFO - training batch 501, loss: 0.124, 16032/28000 datapoints
2025-03-06 20:56:14,561 - INFO - training batch 551, loss: 0.162, 17632/28000 datapoints
2025-03-06 20:56:14,685 - INFO - training batch 601, loss: 0.097, 19232/28000 datapoints
2025-03-06 20:56:14,811 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 20:56:14,937 - INFO - training batch 701, loss: 0.199, 22432/28000 datapoints
2025-03-06 20:56:15,057 - INFO - training batch 751, loss: 0.149, 24032/28000 datapoints
2025-03-06 20:56:15,178 - INFO - training batch 801, loss: 0.094, 25632/28000 datapoints
2025-03-06 20:56:15,299 - INFO - training batch 851, loss: 0.214, 27232/28000 datapoints
2025-03-06 20:56:15,359 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:56:15,403 - INFO - validation batch 51, loss: 1.286, 1632/6976 datapoints
2025-03-06 20:56:15,448 - INFO - validation batch 101, loss: 0.465, 3232/6976 datapoints
2025-03-06 20:56:15,492 - INFO - validation batch 151, loss: 0.438, 4832/6976 datapoints
2025-03-06 20:56:15,535 - INFO - validation batch 201, loss: 0.417, 6432/6976 datapoints
2025-03-06 20:56:15,550 - INFO - Epoch 462/800 done.
2025-03-06 20:56:15,550 - INFO - Final validation performance:
Loss: 0.548, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:56:15,551 - INFO - Beginning epoch 463/800
2025-03-06 20:56:15,555 - INFO - training batch 1, loss: 0.259, 32/28000 datapoints
2025-03-06 20:56:15,680 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 20:56:15,804 - INFO - training batch 101, loss: 0.091, 3232/28000 datapoints
2025-03-06 20:56:15,924 - INFO - training batch 151, loss: 0.098, 4832/28000 datapoints
2025-03-06 20:56:16,047 - INFO - training batch 201, loss: 0.055, 6432/28000 datapoints
2025-03-06 20:56:16,168 - INFO - training batch 251, loss: 0.260, 8032/28000 datapoints
2025-03-06 20:56:16,290 - INFO - training batch 301, loss: 0.363, 9632/28000 datapoints
2025-03-06 20:56:16,411 - INFO - training batch 351, loss: 0.186, 11232/28000 datapoints
2025-03-06 20:56:16,535 - INFO - training batch 401, loss: 0.374, 12832/28000 datapoints
2025-03-06 20:56:16,661 - INFO - training batch 451, loss: 0.179, 14432/28000 datapoints
2025-03-06 20:56:16,787 - INFO - training batch 501, loss: 0.124, 16032/28000 datapoints
2025-03-06 20:56:16,907 - INFO - training batch 551, loss: 0.160, 17632/28000 datapoints
2025-03-06 20:56:17,027 - INFO - training batch 601, loss: 0.096, 19232/28000 datapoints
2025-03-06 20:56:17,151 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 20:56:17,272 - INFO - training batch 701, loss: 0.199, 22432/28000 datapoints
2025-03-06 20:56:17,392 - INFO - training batch 751, loss: 0.147, 24032/28000 datapoints
2025-03-06 20:56:17,522 - INFO - training batch 801, loss: 0.094, 25632/28000 datapoints
2025-03-06 20:56:17,644 - INFO - training batch 851, loss: 0.213, 27232/28000 datapoints
2025-03-06 20:56:17,705 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:56:17,750 - INFO - validation batch 51, loss: 1.289, 1632/6976 datapoints
2025-03-06 20:56:17,793 - INFO - validation batch 101, loss: 0.467, 3232/6976 datapoints
2025-03-06 20:56:17,837 - INFO - validation batch 151, loss: 0.438, 4832/6976 datapoints
2025-03-06 20:56:17,882 - INFO - validation batch 201, loss: 0.418, 6432/6976 datapoints
2025-03-06 20:56:17,897 - INFO - Epoch 463/800 done.
2025-03-06 20:56:17,898 - INFO - Final validation performance:
Loss: 0.549, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:56:17,898 - INFO - Beginning epoch 464/800
2025-03-06 20:56:17,902 - INFO - training batch 1, loss: 0.258, 32/28000 datapoints
2025-03-06 20:56:18,023 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 20:56:18,146 - INFO - training batch 101, loss: 0.092, 3232/28000 datapoints
2025-03-06 20:56:18,269 - INFO - training batch 151, loss: 0.098, 4832/28000 datapoints
2025-03-06 20:56:18,389 - INFO - training batch 201, loss: 0.054, 6432/28000 datapoints
2025-03-06 20:56:18,513 - INFO - training batch 251, loss: 0.259, 8032/28000 datapoints
2025-03-06 20:56:18,633 - INFO - training batch 301, loss: 0.361, 9632/28000 datapoints
2025-03-06 20:56:18,760 - INFO - training batch 351, loss: 0.186, 11232/28000 datapoints
2025-03-06 20:56:18,879 - INFO - training batch 401, loss: 0.373, 12832/28000 datapoints
2025-03-06 20:56:18,999 - INFO - training batch 451, loss: 0.182, 14432/28000 datapoints
2025-03-06 20:56:19,120 - INFO - training batch 501, loss: 0.125, 16032/28000 datapoints
2025-03-06 20:56:19,239 - INFO - training batch 551, loss: 0.161, 17632/28000 datapoints
2025-03-06 20:56:19,363 - INFO - training batch 601, loss: 0.095, 19232/28000 datapoints
2025-03-06 20:56:19,483 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 20:56:19,604 - INFO - training batch 701, loss: 0.198, 22432/28000 datapoints
2025-03-06 20:56:19,727 - INFO - training batch 751, loss: 0.147, 24032/28000 datapoints
2025-03-06 20:56:19,849 - INFO - training batch 801, loss: 0.093, 25632/28000 datapoints
2025-03-06 20:56:19,971 - INFO - training batch 851, loss: 0.211, 27232/28000 datapoints
2025-03-06 20:56:20,030 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:56:20,074 - INFO - validation batch 51, loss: 1.291, 1632/6976 datapoints
2025-03-06 20:56:20,118 - INFO - validation batch 101, loss: 0.468, 3232/6976 datapoints
2025-03-06 20:56:20,162 - INFO - validation batch 151, loss: 0.440, 4832/6976 datapoints
2025-03-06 20:56:20,207 - INFO - validation batch 201, loss: 0.418, 6432/6976 datapoints
2025-03-06 20:56:20,222 - INFO - Epoch 464/800 done.
2025-03-06 20:56:20,222 - INFO - Final validation performance:
Loss: 0.550, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:56:20,223 - INFO - Beginning epoch 465/800
2025-03-06 20:56:20,226 - INFO - training batch 1, loss: 0.258, 32/28000 datapoints
2025-03-06 20:56:20,350 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 20:56:20,471 - INFO - training batch 101, loss: 0.090, 3232/28000 datapoints
2025-03-06 20:56:20,591 - INFO - training batch 151, loss: 0.096, 4832/28000 datapoints
2025-03-06 20:56:20,718 - INFO - training batch 201, loss: 0.054, 6432/28000 datapoints
2025-03-06 20:56:20,845 - INFO - training batch 251, loss: 0.258, 8032/28000 datapoints
2025-03-06 20:56:20,966 - INFO - training batch 301, loss: 0.360, 9632/28000 datapoints
2025-03-06 20:56:21,086 - INFO - training batch 351, loss: 0.186, 11232/28000 datapoints
2025-03-06 20:56:21,206 - INFO - training batch 401, loss: 0.372, 12832/28000 datapoints
2025-03-06 20:56:21,327 - INFO - training batch 451, loss: 0.182, 14432/28000 datapoints
2025-03-06 20:56:21,452 - INFO - training batch 501, loss: 0.124, 16032/28000 datapoints
2025-03-06 20:56:21,572 - INFO - training batch 551, loss: 0.160, 17632/28000 datapoints
2025-03-06 20:56:21,697 - INFO - training batch 601, loss: 0.095, 19232/28000 datapoints
2025-03-06 20:56:21,818 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 20:56:21,939 - INFO - training batch 701, loss: 0.198, 22432/28000 datapoints
2025-03-06 20:56:22,062 - INFO - training batch 751, loss: 0.146, 24032/28000 datapoints
2025-03-06 20:56:22,184 - INFO - training batch 801, loss: 0.094, 25632/28000 datapoints
2025-03-06 20:56:22,306 - INFO - training batch 851, loss: 0.210, 27232/28000 datapoints
2025-03-06 20:56:22,366 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:56:22,409 - INFO - validation batch 51, loss: 1.294, 1632/6976 datapoints
2025-03-06 20:56:22,453 - INFO - validation batch 101, loss: 0.470, 3232/6976 datapoints
2025-03-06 20:56:22,497 - INFO - validation batch 151, loss: 0.439, 4832/6976 datapoints
2025-03-06 20:56:22,540 - INFO - validation batch 201, loss: 0.419, 6432/6976 datapoints
2025-03-06 20:56:22,555 - INFO - Epoch 465/800 done.
2025-03-06 20:56:22,555 - INFO - Final validation performance:
Loss: 0.551, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:56:22,556 - INFO - Beginning epoch 466/800
2025-03-06 20:56:22,560 - INFO - training batch 1, loss: 0.257, 32/28000 datapoints
2025-03-06 20:56:22,685 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 20:56:22,811 - INFO - training batch 101, loss: 0.091, 3232/28000 datapoints
2025-03-06 20:56:22,932 - INFO - training batch 151, loss: 0.096, 4832/28000 datapoints
2025-03-06 20:56:23,052 - INFO - training batch 201, loss: 0.054, 6432/28000 datapoints
2025-03-06 20:56:23,175 - INFO - training batch 251, loss: 0.257, 8032/28000 datapoints
2025-03-06 20:56:23,296 - INFO - training batch 301, loss: 0.359, 9632/28000 datapoints
2025-03-06 20:56:23,424 - INFO - training batch 351, loss: 0.185, 11232/28000 datapoints
2025-03-06 20:56:23,560 - INFO - training batch 401, loss: 0.371, 12832/28000 datapoints
2025-03-06 20:56:23,693 - INFO - training batch 451, loss: 0.178, 14432/28000 datapoints
2025-03-06 20:56:23,816 - INFO - training batch 501, loss: 0.122, 16032/28000 datapoints
2025-03-06 20:56:23,938 - INFO - training batch 551, loss: 0.159, 17632/28000 datapoints
2025-03-06 20:56:24,058 - INFO - training batch 601, loss: 0.094, 19232/28000 datapoints
2025-03-06 20:56:24,189 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 20:56:24,315 - INFO - training batch 701, loss: 0.197, 22432/28000 datapoints
2025-03-06 20:56:24,461 - INFO - training batch 751, loss: 0.146, 24032/28000 datapoints
2025-03-06 20:56:24,586 - INFO - training batch 801, loss: 0.093, 25632/28000 datapoints
2025-03-06 20:56:24,708 - INFO - training batch 851, loss: 0.208, 27232/28000 datapoints
2025-03-06 20:56:24,767 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:56:24,815 - INFO - validation batch 51, loss: 1.297, 1632/6976 datapoints
2025-03-06 20:56:24,862 - INFO - validation batch 101, loss: 0.471, 3232/6976 datapoints
2025-03-06 20:56:24,908 - INFO - validation batch 151, loss: 0.441, 4832/6976 datapoints
2025-03-06 20:56:24,954 - INFO - validation batch 201, loss: 0.418, 6432/6976 datapoints
2025-03-06 20:56:24,969 - INFO - Epoch 466/800 done.
2025-03-06 20:56:24,969 - INFO - Final validation performance:
Loss: 0.552, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:56:24,970 - INFO - Beginning epoch 467/800
2025-03-06 20:56:24,973 - INFO - training batch 1, loss: 0.258, 32/28000 datapoints
2025-03-06 20:56:25,098 - INFO - training batch 51, loss: 0.064, 1632/28000 datapoints
2025-03-06 20:56:25,220 - INFO - training batch 101, loss: 0.089, 3232/28000 datapoints
2025-03-06 20:56:25,340 - INFO - training batch 151, loss: 0.095, 4832/28000 datapoints
2025-03-06 20:56:25,463 - INFO - training batch 201, loss: 0.053, 6432/28000 datapoints
2025-03-06 20:56:25,584 - INFO - training batch 251, loss: 0.256, 8032/28000 datapoints
2025-03-06 20:56:25,709 - INFO - training batch 301, loss: 0.356, 9632/28000 datapoints
2025-03-06 20:56:25,829 - INFO - training batch 351, loss: 0.185, 11232/28000 datapoints
2025-03-06 20:56:25,952 - INFO - training batch 401, loss: 0.369, 12832/28000 datapoints
2025-03-06 20:56:26,073 - INFO - training batch 451, loss: 0.180, 14432/28000 datapoints
2025-03-06 20:56:26,194 - INFO - training batch 501, loss: 0.122, 16032/28000 datapoints
2025-03-06 20:56:26,315 - INFO - training batch 551, loss: 0.158, 17632/28000 datapoints
2025-03-06 20:56:26,436 - INFO - training batch 601, loss: 0.094, 19232/28000 datapoints
2025-03-06 20:56:26,556 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 20:56:26,684 - INFO - training batch 701, loss: 0.197, 22432/28000 datapoints
2025-03-06 20:56:26,807 - INFO - training batch 751, loss: 0.145, 24032/28000 datapoints
2025-03-06 20:56:26,928 - INFO - training batch 801, loss: 0.093, 25632/28000 datapoints
2025-03-06 20:56:27,048 - INFO - training batch 851, loss: 0.206, 27232/28000 datapoints
2025-03-06 20:56:27,107 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:56:27,152 - INFO - validation batch 51, loss: 1.300, 1632/6976 datapoints
2025-03-06 20:56:27,197 - INFO - validation batch 101, loss: 0.473, 3232/6976 datapoints
2025-03-06 20:56:27,240 - INFO - validation batch 151, loss: 0.442, 4832/6976 datapoints
2025-03-06 20:56:27,285 - INFO - validation batch 201, loss: 0.419, 6432/6976 datapoints
2025-03-06 20:56:27,301 - INFO - Epoch 467/800 done.
2025-03-06 20:56:27,301 - INFO - Final validation performance:
Loss: 0.553, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:56:27,301 - INFO - Beginning epoch 468/800
2025-03-06 20:56:27,305 - INFO - training batch 1, loss: 0.258, 32/28000 datapoints
2025-03-06 20:56:27,429 - INFO - training batch 51, loss: 0.064, 1632/28000 datapoints
2025-03-06 20:56:27,547 - INFO - training batch 101, loss: 0.089, 3232/28000 datapoints
2025-03-06 20:56:27,671 - INFO - training batch 151, loss: 0.095, 4832/28000 datapoints
2025-03-06 20:56:27,793 - INFO - training batch 201, loss: 0.053, 6432/28000 datapoints
2025-03-06 20:56:27,914 - INFO - training batch 251, loss: 0.256, 8032/28000 datapoints
2025-03-06 20:56:28,033 - INFO - training batch 301, loss: 0.355, 9632/28000 datapoints
2025-03-06 20:56:28,153 - INFO - training batch 351, loss: 0.184, 11232/28000 datapoints
2025-03-06 20:56:28,273 - INFO - training batch 401, loss: 0.368, 12832/28000 datapoints
2025-03-06 20:56:28,391 - INFO - training batch 451, loss: 0.180, 14432/28000 datapoints
2025-03-06 20:56:28,511 - INFO - training batch 501, loss: 0.123, 16032/28000 datapoints
2025-03-06 20:56:28,639 - INFO - training batch 551, loss: 0.158, 17632/28000 datapoints
2025-03-06 20:56:28,763 - INFO - training batch 601, loss: 0.092, 19232/28000 datapoints
2025-03-06 20:56:28,888 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 20:56:29,013 - INFO - training batch 701, loss: 0.196, 22432/28000 datapoints
2025-03-06 20:56:29,137 - INFO - training batch 751, loss: 0.144, 24032/28000 datapoints
2025-03-06 20:56:29,273 - INFO - training batch 801, loss: 0.093, 25632/28000 datapoints
2025-03-06 20:56:29,400 - INFO - training batch 851, loss: 0.204, 27232/28000 datapoints
2025-03-06 20:56:29,463 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:56:29,514 - INFO - validation batch 51, loss: 1.300, 1632/6976 datapoints
2025-03-06 20:56:29,570 - INFO - validation batch 101, loss: 0.475, 3232/6976 datapoints
2025-03-06 20:56:29,617 - INFO - validation batch 151, loss: 0.442, 4832/6976 datapoints
2025-03-06 20:56:29,667 - INFO - validation batch 201, loss: 0.419, 6432/6976 datapoints
2025-03-06 20:56:29,689 - INFO - Epoch 468/800 done.
2025-03-06 20:56:29,689 - INFO - Final validation performance:
Loss: 0.554, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:56:29,690 - INFO - Beginning epoch 469/800
2025-03-06 20:56:29,694 - INFO - training batch 1, loss: 0.256, 32/28000 datapoints
2025-03-06 20:56:29,822 - INFO - training batch 51, loss: 0.064, 1632/28000 datapoints
2025-03-06 20:56:29,949 - INFO - training batch 101, loss: 0.089, 3232/28000 datapoints
2025-03-06 20:56:30,074 - INFO - training batch 151, loss: 0.094, 4832/28000 datapoints
2025-03-06 20:56:30,200 - INFO - training batch 201, loss: 0.053, 6432/28000 datapoints
2025-03-06 20:56:30,324 - INFO - training batch 251, loss: 0.255, 8032/28000 datapoints
2025-03-06 20:56:30,449 - INFO - training batch 301, loss: 0.354, 9632/28000 datapoints
2025-03-06 20:56:30,574 - INFO - training batch 351, loss: 0.184, 11232/28000 datapoints
2025-03-06 20:56:30,713 - INFO - training batch 401, loss: 0.368, 12832/28000 datapoints
2025-03-06 20:56:30,871 - INFO - training batch 451, loss: 0.180, 14432/28000 datapoints
2025-03-06 20:56:30,996 - INFO - training batch 501, loss: 0.121, 16032/28000 datapoints
2025-03-06 20:56:31,120 - INFO - training batch 551, loss: 0.157, 17632/28000 datapoints
2025-03-06 20:56:31,245 - INFO - training batch 601, loss: 0.092, 19232/28000 datapoints
2025-03-06 20:56:31,371 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 20:56:31,509 - INFO - training batch 701, loss: 0.196, 22432/28000 datapoints
2025-03-06 20:56:31,633 - INFO - training batch 751, loss: 0.143, 24032/28000 datapoints
2025-03-06 20:56:31,761 - INFO - training batch 801, loss: 0.093, 25632/28000 datapoints
2025-03-06 20:56:31,886 - INFO - training batch 851, loss: 0.204, 27232/28000 datapoints
2025-03-06 20:56:31,950 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:56:31,999 - INFO - validation batch 51, loss: 1.304, 1632/6976 datapoints
2025-03-06 20:56:32,046 - INFO - validation batch 101, loss: 0.477, 3232/6976 datapoints
2025-03-06 20:56:32,095 - INFO - validation batch 151, loss: 0.442, 4832/6976 datapoints
2025-03-06 20:56:32,143 - INFO - validation batch 201, loss: 0.419, 6432/6976 datapoints
2025-03-06 20:56:32,158 - INFO - Epoch 469/800 done.
2025-03-06 20:56:32,158 - INFO - Final validation performance:
Loss: 0.555, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:56:32,158 - INFO - Beginning epoch 470/800
2025-03-06 20:56:32,162 - INFO - training batch 1, loss: 0.257, 32/28000 datapoints
2025-03-06 20:56:32,290 - INFO - training batch 51, loss: 0.064, 1632/28000 datapoints
2025-03-06 20:56:32,413 - INFO - training batch 101, loss: 0.090, 3232/28000 datapoints
2025-03-06 20:56:32,538 - INFO - training batch 151, loss: 0.093, 4832/28000 datapoints
2025-03-06 20:56:32,664 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-06 20:56:32,787 - INFO - training batch 251, loss: 0.254, 8032/28000 datapoints
2025-03-06 20:56:32,917 - INFO - training batch 301, loss: 0.353, 9632/28000 datapoints
2025-03-06 20:56:33,048 - INFO - training batch 351, loss: 0.184, 11232/28000 datapoints
2025-03-06 20:56:33,174 - INFO - training batch 401, loss: 0.365, 12832/28000 datapoints
2025-03-06 20:56:33,303 - INFO - training batch 451, loss: 0.176, 14432/28000 datapoints
2025-03-06 20:56:33,425 - INFO - training batch 501, loss: 0.121, 16032/28000 datapoints
2025-03-06 20:56:33,553 - INFO - training batch 551, loss: 0.156, 17632/28000 datapoints
2025-03-06 20:56:33,681 - INFO - training batch 601, loss: 0.091, 19232/28000 datapoints
2025-03-06 20:56:33,804 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 20:56:33,927 - INFO - training batch 701, loss: 0.195, 22432/28000 datapoints
2025-03-06 20:56:34,090 - INFO - training batch 751, loss: 0.143, 24032/28000 datapoints
2025-03-06 20:56:34,225 - INFO - training batch 801, loss: 0.093, 25632/28000 datapoints
2025-03-06 20:56:34,350 - INFO - training batch 851, loss: 0.202, 27232/28000 datapoints
2025-03-06 20:56:34,413 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:56:34,470 - INFO - validation batch 51, loss: 1.307, 1632/6976 datapoints
2025-03-06 20:56:34,538 - INFO - validation batch 101, loss: 0.478, 3232/6976 datapoints
2025-03-06 20:56:34,590 - INFO - validation batch 151, loss: 0.443, 4832/6976 datapoints
2025-03-06 20:56:34,642 - INFO - validation batch 201, loss: 0.418, 6432/6976 datapoints
2025-03-06 20:56:34,657 - INFO - Epoch 470/800 done.
2025-03-06 20:56:34,657 - INFO - Final validation performance:
Loss: 0.556, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:56:34,658 - INFO - Beginning epoch 471/800
2025-03-06 20:56:34,661 - INFO - training batch 1, loss: 0.256, 32/28000 datapoints
2025-03-06 20:56:34,785 - INFO - training batch 51, loss: 0.064, 1632/28000 datapoints
2025-03-06 20:56:34,917 - INFO - training batch 101, loss: 0.088, 3232/28000 datapoints
2025-03-06 20:56:35,043 - INFO - training batch 151, loss: 0.093, 4832/28000 datapoints
2025-03-06 20:56:35,167 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-06 20:56:35,292 - INFO - training batch 251, loss: 0.254, 8032/28000 datapoints
2025-03-06 20:56:35,417 - INFO - training batch 301, loss: 0.350, 9632/28000 datapoints
2025-03-06 20:56:35,543 - INFO - training batch 351, loss: 0.184, 11232/28000 datapoints
2025-03-06 20:56:35,669 - INFO - training batch 401, loss: 0.365, 12832/28000 datapoints
2025-03-06 20:56:35,798 - INFO - training batch 451, loss: 0.178, 14432/28000 datapoints
2025-03-06 20:56:35,921 - INFO - training batch 501, loss: 0.122, 16032/28000 datapoints
2025-03-06 20:56:36,046 - INFO - training batch 551, loss: 0.156, 17632/28000 datapoints
2025-03-06 20:56:36,169 - INFO - training batch 601, loss: 0.090, 19232/28000 datapoints
2025-03-06 20:56:36,295 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-06 20:56:36,417 - INFO - training batch 701, loss: 0.195, 22432/28000 datapoints
2025-03-06 20:56:36,543 - INFO - training batch 751, loss: 0.142, 24032/28000 datapoints
2025-03-06 20:56:36,669 - INFO - training batch 801, loss: 0.092, 25632/28000 datapoints
2025-03-06 20:56:36,792 - INFO - training batch 851, loss: 0.200, 27232/28000 datapoints
2025-03-06 20:56:36,855 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:56:36,903 - INFO - validation batch 51, loss: 1.308, 1632/6976 datapoints
2025-03-06 20:56:36,953 - INFO - validation batch 101, loss: 0.481, 3232/6976 datapoints
2025-03-06 20:56:37,003 - INFO - validation batch 151, loss: 0.442, 4832/6976 datapoints
2025-03-06 20:56:37,051 - INFO - validation batch 201, loss: 0.419, 6432/6976 datapoints
2025-03-06 20:56:37,066 - INFO - Epoch 471/800 done.
2025-03-06 20:56:37,067 - INFO - Final validation performance:
Loss: 0.557, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:56:37,067 - INFO - Beginning epoch 472/800
2025-03-06 20:56:37,072 - INFO - training batch 1, loss: 0.255, 32/28000 datapoints
2025-03-06 20:56:37,198 - INFO - training batch 51, loss: 0.064, 1632/28000 datapoints
2025-03-06 20:56:37,322 - INFO - training batch 101, loss: 0.089, 3232/28000 datapoints
2025-03-06 20:56:37,446 - INFO - training batch 151, loss: 0.093, 4832/28000 datapoints
2025-03-06 20:56:37,571 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-06 20:56:37,715 - INFO - training batch 251, loss: 0.253, 8032/28000 datapoints
2025-03-06 20:56:37,866 - INFO - training batch 301, loss: 0.350, 9632/28000 datapoints
2025-03-06 20:56:37,997 - INFO - training batch 351, loss: 0.183, 11232/28000 datapoints
2025-03-06 20:56:38,120 - INFO - training batch 401, loss: 0.363, 12832/28000 datapoints
2025-03-06 20:56:38,244 - INFO - training batch 451, loss: 0.178, 14432/28000 datapoints
2025-03-06 20:56:38,368 - INFO - training batch 501, loss: 0.120, 16032/28000 datapoints
2025-03-06 20:56:38,491 - INFO - training batch 551, loss: 0.155, 17632/28000 datapoints
2025-03-06 20:56:38,616 - INFO - training batch 601, loss: 0.090, 19232/28000 datapoints
2025-03-06 20:56:38,742 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 20:56:38,869 - INFO - training batch 701, loss: 0.194, 22432/28000 datapoints
2025-03-06 20:56:38,995 - INFO - training batch 751, loss: 0.141, 24032/28000 datapoints
2025-03-06 20:56:39,126 - INFO - training batch 801, loss: 0.092, 25632/28000 datapoints
2025-03-06 20:56:39,250 - INFO - training batch 851, loss: 0.199, 27232/28000 datapoints
2025-03-06 20:56:39,313 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:56:39,361 - INFO - validation batch 51, loss: 1.314, 1632/6976 datapoints
2025-03-06 20:56:39,410 - INFO - validation batch 101, loss: 0.481, 3232/6976 datapoints
2025-03-06 20:56:39,458 - INFO - validation batch 151, loss: 0.445, 4832/6976 datapoints
2025-03-06 20:56:39,504 - INFO - validation batch 201, loss: 0.419, 6432/6976 datapoints
2025-03-06 20:56:39,519 - INFO - Epoch 472/800 done.
2025-03-06 20:56:39,523 - INFO - Final validation performance:
Loss: 0.558, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:56:39,523 - INFO - Beginning epoch 473/800
2025-03-06 20:56:39,527 - INFO - training batch 1, loss: 0.255, 32/28000 datapoints
2025-03-06 20:56:39,653 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-06 20:56:39,777 - INFO - training batch 101, loss: 0.087, 3232/28000 datapoints
2025-03-06 20:56:39,896 - INFO - training batch 151, loss: 0.091, 4832/28000 datapoints
2025-03-06 20:56:40,020 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-06 20:56:40,177 - INFO - training batch 251, loss: 0.252, 8032/28000 datapoints
2025-03-06 20:56:40,308 - INFO - training batch 301, loss: 0.348, 9632/28000 datapoints
2025-03-06 20:56:40,432 - INFO - training batch 351, loss: 0.183, 11232/28000 datapoints
2025-03-06 20:56:40,552 - INFO - training batch 401, loss: 0.362, 12832/28000 datapoints
2025-03-06 20:56:40,676 - INFO - training batch 451, loss: 0.174, 14432/28000 datapoints
2025-03-06 20:56:40,796 - INFO - training batch 501, loss: 0.120, 16032/28000 datapoints
2025-03-06 20:56:40,920 - INFO - training batch 551, loss: 0.154, 17632/28000 datapoints
2025-03-06 20:56:41,042 - INFO - training batch 601, loss: 0.088, 19232/28000 datapoints
2025-03-06 20:56:41,163 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 20:56:41,284 - INFO - training batch 701, loss: 0.194, 22432/28000 datapoints
2025-03-06 20:56:41,404 - INFO - training batch 751, loss: 0.140, 24032/28000 datapoints
2025-03-06 20:56:41,531 - INFO - training batch 801, loss: 0.092, 25632/28000 datapoints
2025-03-06 20:56:41,656 - INFO - training batch 851, loss: 0.197, 27232/28000 datapoints
2025-03-06 20:56:41,713 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:56:41,758 - INFO - validation batch 51, loss: 1.314, 1632/6976 datapoints
2025-03-06 20:56:41,802 - INFO - validation batch 101, loss: 0.484, 3232/6976 datapoints
2025-03-06 20:56:41,846 - INFO - validation batch 151, loss: 0.444, 4832/6976 datapoints
2025-03-06 20:56:41,893 - INFO - validation batch 201, loss: 0.420, 6432/6976 datapoints
2025-03-06 20:56:41,908 - INFO - Epoch 473/800 done.
2025-03-06 20:56:41,908 - INFO - Final validation performance:
Loss: 0.559, top-1 acc: 0.871top-5 acc: 0.871
2025-03-06 20:56:41,908 - INFO - Beginning epoch 474/800
2025-03-06 20:56:41,912 - INFO - training batch 1, loss: 0.254, 32/28000 datapoints
2025-03-06 20:56:42,035 - INFO - training batch 51, loss: 0.064, 1632/28000 datapoints
2025-03-06 20:56:42,160 - INFO - training batch 101, loss: 0.087, 3232/28000 datapoints
2025-03-06 20:56:42,281 - INFO - training batch 151, loss: 0.091, 4832/28000 datapoints
2025-03-06 20:56:42,401 - INFO - training batch 201, loss: 0.051, 6432/28000 datapoints
2025-03-06 20:56:42,523 - INFO - training batch 251, loss: 0.251, 8032/28000 datapoints
2025-03-06 20:56:42,646 - INFO - training batch 301, loss: 0.346, 9632/28000 datapoints
2025-03-06 20:56:42,770 - INFO - training batch 351, loss: 0.183, 11232/28000 datapoints
2025-03-06 20:56:42,894 - INFO - training batch 401, loss: 0.361, 12832/28000 datapoints
2025-03-06 20:56:43,013 - INFO - training batch 451, loss: 0.176, 14432/28000 datapoints
2025-03-06 20:56:43,134 - INFO - training batch 501, loss: 0.120, 16032/28000 datapoints
2025-03-06 20:56:43,254 - INFO - training batch 551, loss: 0.154, 17632/28000 datapoints
2025-03-06 20:56:43,373 - INFO - training batch 601, loss: 0.087, 19232/28000 datapoints
2025-03-06 20:56:43,495 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 20:56:43,625 - INFO - training batch 701, loss: 0.193, 22432/28000 datapoints
2025-03-06 20:56:43,750 - INFO - training batch 751, loss: 0.139, 24032/28000 datapoints
2025-03-06 20:56:43,871 - INFO - training batch 801, loss: 0.092, 25632/28000 datapoints
2025-03-06 20:56:43,992 - INFO - training batch 851, loss: 0.196, 27232/28000 datapoints
2025-03-06 20:56:44,053 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:56:44,098 - INFO - validation batch 51, loss: 1.319, 1632/6976 datapoints
2025-03-06 20:56:44,142 - INFO - validation batch 101, loss: 0.484, 3232/6976 datapoints
2025-03-06 20:56:44,186 - INFO - validation batch 151, loss: 0.445, 4832/6976 datapoints
2025-03-06 20:56:44,230 - INFO - validation batch 201, loss: 0.419, 6432/6976 datapoints
2025-03-06 20:56:44,245 - INFO - Epoch 474/800 done.
2025-03-06 20:56:44,245 - INFO - Final validation performance:
Loss: 0.560, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:56:44,246 - INFO - Beginning epoch 475/800
2025-03-06 20:56:44,250 - INFO - training batch 1, loss: 0.255, 32/28000 datapoints
2025-03-06 20:56:44,374 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-06 20:56:44,495 - INFO - training batch 101, loss: 0.088, 3232/28000 datapoints
2025-03-06 20:56:44,652 - INFO - training batch 151, loss: 0.091, 4832/28000 datapoints
2025-03-06 20:56:44,774 - INFO - training batch 201, loss: 0.051, 6432/28000 datapoints
2025-03-06 20:56:44,907 - INFO - training batch 251, loss: 0.251, 8032/28000 datapoints
2025-03-06 20:56:45,027 - INFO - training batch 301, loss: 0.343, 9632/28000 datapoints
2025-03-06 20:56:45,149 - INFO - training batch 351, loss: 0.182, 11232/28000 datapoints
2025-03-06 20:56:45,270 - INFO - training batch 401, loss: 0.360, 12832/28000 datapoints
2025-03-06 20:56:45,388 - INFO - training batch 451, loss: 0.176, 14432/28000 datapoints
2025-03-06 20:56:45,507 - INFO - training batch 501, loss: 0.120, 16032/28000 datapoints
2025-03-06 20:56:45,629 - INFO - training batch 551, loss: 0.154, 17632/28000 datapoints
2025-03-06 20:56:45,755 - INFO - training batch 601, loss: 0.087, 19232/28000 datapoints
2025-03-06 20:56:45,876 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 20:56:45,995 - INFO - training batch 701, loss: 0.193, 22432/28000 datapoints
2025-03-06 20:56:46,116 - INFO - training batch 751, loss: 0.139, 24032/28000 datapoints
2025-03-06 20:56:46,235 - INFO - training batch 801, loss: 0.091, 25632/28000 datapoints
2025-03-06 20:56:46,358 - INFO - training batch 851, loss: 0.195, 27232/28000 datapoints
2025-03-06 20:56:46,417 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:56:46,461 - INFO - validation batch 51, loss: 1.320, 1632/6976 datapoints
2025-03-06 20:56:46,506 - INFO - validation batch 101, loss: 0.487, 3232/6976 datapoints
2025-03-06 20:56:46,549 - INFO - validation batch 151, loss: 0.444, 4832/6976 datapoints
2025-03-06 20:56:46,591 - INFO - validation batch 201, loss: 0.419, 6432/6976 datapoints
2025-03-06 20:56:46,608 - INFO - Epoch 475/800 done.
2025-03-06 20:56:46,608 - INFO - Final validation performance:
Loss: 0.561, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:56:46,609 - INFO - Beginning epoch 476/800
2025-03-06 20:56:46,613 - INFO - training batch 1, loss: 0.254, 32/28000 datapoints
2025-03-06 20:56:46,736 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-06 20:56:46,858 - INFO - training batch 101, loss: 0.087, 3232/28000 datapoints
2025-03-06 20:56:46,982 - INFO - training batch 151, loss: 0.090, 4832/28000 datapoints
2025-03-06 20:56:47,102 - INFO - training batch 201, loss: 0.051, 6432/28000 datapoints
2025-03-06 20:56:47,224 - INFO - training batch 251, loss: 0.250, 8032/28000 datapoints
2025-03-06 20:56:47,345 - INFO - training batch 301, loss: 0.343, 9632/28000 datapoints
2025-03-06 20:56:47,469 - INFO - training batch 351, loss: 0.183, 11232/28000 datapoints
2025-03-06 20:56:47,593 - INFO - training batch 401, loss: 0.358, 12832/28000 datapoints
2025-03-06 20:56:47,719 - INFO - training batch 451, loss: 0.172, 14432/28000 datapoints
2025-03-06 20:56:47,842 - INFO - training batch 501, loss: 0.118, 16032/28000 datapoints
2025-03-06 20:56:47,965 - INFO - training batch 551, loss: 0.152, 17632/28000 datapoints
2025-03-06 20:56:48,089 - INFO - training batch 601, loss: 0.086, 19232/28000 datapoints
2025-03-06 20:56:48,210 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 20:56:48,331 - INFO - training batch 701, loss: 0.192, 22432/28000 datapoints
2025-03-06 20:56:48,451 - INFO - training batch 751, loss: 0.139, 24032/28000 datapoints
2025-03-06 20:56:48,571 - INFO - training batch 801, loss: 0.091, 25632/28000 datapoints
2025-03-06 20:56:48,701 - INFO - training batch 851, loss: 0.193, 27232/28000 datapoints
2025-03-06 20:56:48,765 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:56:48,814 - INFO - validation batch 51, loss: 1.324, 1632/6976 datapoints
2025-03-06 20:56:48,862 - INFO - validation batch 101, loss: 0.488, 3232/6976 datapoints
2025-03-06 20:56:48,914 - INFO - validation batch 151, loss: 0.446, 4832/6976 datapoints
2025-03-06 20:56:48,962 - INFO - validation batch 201, loss: 0.420, 6432/6976 datapoints
2025-03-06 20:56:48,980 - INFO - Epoch 476/800 done.
2025-03-06 20:56:48,981 - INFO - Final validation performance:
Loss: 0.562, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:56:48,981 - INFO - Beginning epoch 477/800
2025-03-06 20:56:48,986 - INFO - training batch 1, loss: 0.254, 32/28000 datapoints
2025-03-06 20:56:49,110 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-06 20:56:49,232 - INFO - training batch 101, loss: 0.087, 3232/28000 datapoints
2025-03-06 20:56:49,356 - INFO - training batch 151, loss: 0.090, 4832/28000 datapoints
2025-03-06 20:56:49,474 - INFO - training batch 201, loss: 0.051, 6432/28000 datapoints
2025-03-06 20:56:49,597 - INFO - training batch 251, loss: 0.250, 8032/28000 datapoints
2025-03-06 20:56:49,721 - INFO - training batch 301, loss: 0.341, 9632/28000 datapoints
2025-03-06 20:56:49,844 - INFO - training batch 351, loss: 0.182, 11232/28000 datapoints
2025-03-06 20:56:49,965 - INFO - training batch 401, loss: 0.357, 12832/28000 datapoints
2025-03-06 20:56:50,087 - INFO - training batch 451, loss: 0.175, 14432/28000 datapoints
2025-03-06 20:56:50,209 - INFO - training batch 501, loss: 0.119, 16032/28000 datapoints
2025-03-06 20:56:50,331 - INFO - training batch 551, loss: 0.152, 17632/28000 datapoints
2025-03-06 20:56:50,451 - INFO - training batch 601, loss: 0.085, 19232/28000 datapoints
2025-03-06 20:56:50,572 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 20:56:50,695 - INFO - training batch 701, loss: 0.192, 22432/28000 datapoints
2025-03-06 20:56:50,814 - INFO - training batch 751, loss: 0.138, 24032/28000 datapoints
2025-03-06 20:56:50,939 - INFO - training batch 801, loss: 0.091, 25632/28000 datapoints
2025-03-06 20:56:51,073 - INFO - training batch 851, loss: 0.192, 27232/28000 datapoints
2025-03-06 20:56:51,133 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:56:51,178 - INFO - validation batch 51, loss: 1.326, 1632/6976 datapoints
2025-03-06 20:56:51,221 - INFO - validation batch 101, loss: 0.490, 3232/6976 datapoints
2025-03-06 20:56:51,265 - INFO - validation batch 151, loss: 0.447, 4832/6976 datapoints
2025-03-06 20:56:51,309 - INFO - validation batch 201, loss: 0.419, 6432/6976 datapoints
2025-03-06 20:56:51,324 - INFO - Epoch 477/800 done.
2025-03-06 20:56:51,324 - INFO - Final validation performance:
Loss: 0.563, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:56:51,325 - INFO - Beginning epoch 478/800
2025-03-06 20:56:51,329 - INFO - training batch 1, loss: 0.253, 32/28000 datapoints
2025-03-06 20:56:51,451 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-06 20:56:51,578 - INFO - training batch 101, loss: 0.085, 3232/28000 datapoints
2025-03-06 20:56:51,705 - INFO - training batch 151, loss: 0.088, 4832/28000 datapoints
2025-03-06 20:56:51,825 - INFO - training batch 201, loss: 0.050, 6432/28000 datapoints
2025-03-06 20:56:51,947 - INFO - training batch 251, loss: 0.249, 8032/28000 datapoints
2025-03-06 20:56:52,068 - INFO - training batch 301, loss: 0.339, 9632/28000 datapoints
2025-03-06 20:56:52,192 - INFO - training batch 351, loss: 0.182, 11232/28000 datapoints
2025-03-06 20:56:52,313 - INFO - training batch 401, loss: 0.355, 12832/28000 datapoints
2025-03-06 20:56:52,434 - INFO - training batch 451, loss: 0.175, 14432/28000 datapoints
2025-03-06 20:56:52,555 - INFO - training batch 501, loss: 0.117, 16032/28000 datapoints
2025-03-06 20:56:52,679 - INFO - training batch 551, loss: 0.151, 17632/28000 datapoints
2025-03-06 20:56:52,799 - INFO - training batch 601, loss: 0.085, 19232/28000 datapoints
2025-03-06 20:56:52,923 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 20:56:53,044 - INFO - training batch 701, loss: 0.191, 22432/28000 datapoints
2025-03-06 20:56:53,162 - INFO - training batch 751, loss: 0.137, 24032/28000 datapoints
2025-03-06 20:56:53,283 - INFO - training batch 801, loss: 0.091, 25632/28000 datapoints
2025-03-06 20:56:53,403 - INFO - training batch 851, loss: 0.190, 27232/28000 datapoints
2025-03-06 20:56:53,462 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:56:53,506 - INFO - validation batch 51, loss: 1.326, 1632/6976 datapoints
2025-03-06 20:56:53,550 - INFO - validation batch 101, loss: 0.492, 3232/6976 datapoints
2025-03-06 20:56:53,594 - INFO - validation batch 151, loss: 0.447, 4832/6976 datapoints
2025-03-06 20:56:53,641 - INFO - validation batch 201, loss: 0.421, 6432/6976 datapoints
2025-03-06 20:56:53,656 - INFO - Epoch 478/800 done.
2025-03-06 20:56:53,656 - INFO - Final validation performance:
Loss: 0.563, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:56:53,656 - INFO - Beginning epoch 479/800
2025-03-06 20:56:53,660 - INFO - training batch 1, loss: 0.252, 32/28000 datapoints
2025-03-06 20:56:53,784 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-06 20:56:53,910 - INFO - training batch 101, loss: 0.086, 3232/28000 datapoints
2025-03-06 20:56:54,031 - INFO - training batch 151, loss: 0.088, 4832/28000 datapoints
2025-03-06 20:56:54,157 - INFO - training batch 201, loss: 0.050, 6432/28000 datapoints
2025-03-06 20:56:54,278 - INFO - training batch 251, loss: 0.249, 8032/28000 datapoints
2025-03-06 20:56:54,400 - INFO - training batch 301, loss: 0.338, 9632/28000 datapoints
2025-03-06 20:56:54,520 - INFO - training batch 351, loss: 0.181, 11232/28000 datapoints
2025-03-06 20:56:54,645 - INFO - training batch 401, loss: 0.354, 12832/28000 datapoints
2025-03-06 20:56:54,798 - INFO - training batch 451, loss: 0.171, 14432/28000 datapoints
2025-03-06 20:56:54,927 - INFO - training batch 501, loss: 0.117, 16032/28000 datapoints
2025-03-06 20:56:55,050 - INFO - training batch 551, loss: 0.150, 17632/28000 datapoints
2025-03-06 20:56:55,171 - INFO - training batch 601, loss: 0.085, 19232/28000 datapoints
2025-03-06 20:56:55,293 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 20:56:55,413 - INFO - training batch 701, loss: 0.190, 22432/28000 datapoints
2025-03-06 20:56:55,533 - INFO - training batch 751, loss: 0.137, 24032/28000 datapoints
2025-03-06 20:56:55,656 - INFO - training batch 801, loss: 0.090, 25632/28000 datapoints
2025-03-06 20:56:55,776 - INFO - training batch 851, loss: 0.189, 27232/28000 datapoints
2025-03-06 20:56:55,836 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:56:55,878 - INFO - validation batch 51, loss: 1.331, 1632/6976 datapoints
2025-03-06 20:56:55,923 - INFO - validation batch 101, loss: 0.493, 3232/6976 datapoints
2025-03-06 20:56:55,966 - INFO - validation batch 151, loss: 0.448, 4832/6976 datapoints
2025-03-06 20:56:56,010 - INFO - validation batch 201, loss: 0.421, 6432/6976 datapoints
2025-03-06 20:56:56,026 - INFO - Epoch 479/800 done.
2025-03-06 20:56:56,026 - INFO - Final validation performance:
Loss: 0.565, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:56:56,027 - INFO - Beginning epoch 480/800
2025-03-06 20:56:56,030 - INFO - training batch 1, loss: 0.253, 32/28000 datapoints
2025-03-06 20:56:56,154 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-06 20:56:56,278 - INFO - training batch 101, loss: 0.084, 3232/28000 datapoints
2025-03-06 20:56:56,399 - INFO - training batch 151, loss: 0.087, 4832/28000 datapoints
2025-03-06 20:56:56,518 - INFO - training batch 201, loss: 0.050, 6432/28000 datapoints
2025-03-06 20:56:56,642 - INFO - training batch 251, loss: 0.248, 8032/28000 datapoints
2025-03-06 20:56:56,763 - INFO - training batch 301, loss: 0.337, 9632/28000 datapoints
2025-03-06 20:56:56,886 - INFO - training batch 351, loss: 0.181, 11232/28000 datapoints
2025-03-06 20:56:57,008 - INFO - training batch 401, loss: 0.352, 12832/28000 datapoints
2025-03-06 20:56:57,129 - INFO - training batch 451, loss: 0.173, 14432/28000 datapoints
2025-03-06 20:56:57,249 - INFO - training batch 501, loss: 0.118, 16032/28000 datapoints
2025-03-06 20:56:57,370 - INFO - training batch 551, loss: 0.150, 17632/28000 datapoints
2025-03-06 20:56:57,488 - INFO - training batch 601, loss: 0.083, 19232/28000 datapoints
2025-03-06 20:56:57,609 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 20:56:57,745 - INFO - training batch 701, loss: 0.190, 22432/28000 datapoints
2025-03-06 20:56:57,872 - INFO - training batch 751, loss: 0.136, 24032/28000 datapoints
2025-03-06 20:56:57,992 - INFO - training batch 801, loss: 0.091, 25632/28000 datapoints
2025-03-06 20:56:58,113 - INFO - training batch 851, loss: 0.188, 27232/28000 datapoints
2025-03-06 20:56:58,173 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:56:58,216 - INFO - validation batch 51, loss: 1.332, 1632/6976 datapoints
2025-03-06 20:56:58,262 - INFO - validation batch 101, loss: 0.496, 3232/6976 datapoints
2025-03-06 20:56:58,306 - INFO - validation batch 151, loss: 0.448, 4832/6976 datapoints
2025-03-06 20:56:58,350 - INFO - validation batch 201, loss: 0.421, 6432/6976 datapoints
2025-03-06 20:56:58,365 - INFO - Epoch 480/800 done.
2025-03-06 20:56:58,365 - INFO - Final validation performance:
Loss: 0.566, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:56:58,366 - INFO - Beginning epoch 481/800
2025-03-06 20:56:58,369 - INFO - training batch 1, loss: 0.252, 32/28000 datapoints
2025-03-06 20:56:58,493 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-06 20:56:58,614 - INFO - training batch 101, loss: 0.086, 3232/28000 datapoints
2025-03-06 20:56:58,737 - INFO - training batch 151, loss: 0.087, 4832/28000 datapoints
2025-03-06 20:56:58,860 - INFO - training batch 201, loss: 0.050, 6432/28000 datapoints
2025-03-06 20:56:58,984 - INFO - training batch 251, loss: 0.247, 8032/28000 datapoints
2025-03-06 20:56:59,108 - INFO - training batch 301, loss: 0.334, 9632/28000 datapoints
2025-03-06 20:56:59,230 - INFO - training batch 351, loss: 0.181, 11232/28000 datapoints
2025-03-06 20:56:59,351 - INFO - training batch 401, loss: 0.352, 12832/28000 datapoints
2025-03-06 20:56:59,474 - INFO - training batch 451, loss: 0.173, 14432/28000 datapoints
2025-03-06 20:56:59,594 - INFO - training batch 501, loss: 0.116, 16032/28000 datapoints
2025-03-06 20:56:59,718 - INFO - training batch 551, loss: 0.149, 17632/28000 datapoints
2025-03-06 20:56:59,843 - INFO - training batch 601, loss: 0.083, 19232/28000 datapoints
2025-03-06 20:56:59,963 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 20:57:00,085 - INFO - training batch 701, loss: 0.190, 22432/28000 datapoints
2025-03-06 20:57:00,207 - INFO - training batch 751, loss: 0.135, 24032/28000 datapoints
2025-03-06 20:57:00,332 - INFO - training batch 801, loss: 0.090, 25632/28000 datapoints
2025-03-06 20:57:00,453 - INFO - training batch 851, loss: 0.187, 27232/28000 datapoints
2025-03-06 20:57:00,512 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:57:00,556 - INFO - validation batch 51, loss: 1.335, 1632/6976 datapoints
2025-03-06 20:57:00,600 - INFO - validation batch 101, loss: 0.497, 3232/6976 datapoints
2025-03-06 20:57:00,646 - INFO - validation batch 151, loss: 0.450, 4832/6976 datapoints
2025-03-06 20:57:00,690 - INFO - validation batch 201, loss: 0.421, 6432/6976 datapoints
2025-03-06 20:57:00,705 - INFO - Epoch 481/800 done.
2025-03-06 20:57:00,706 - INFO - Final validation performance:
Loss: 0.567, top-1 acc: 0.870top-5 acc: 0.870
2025-03-06 20:57:00,706 - INFO - Beginning epoch 482/800
2025-03-06 20:57:00,710 - INFO - training batch 1, loss: 0.252, 32/28000 datapoints
2025-03-06 20:57:00,834 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 20:57:00,958 - INFO - training batch 101, loss: 0.084, 3232/28000 datapoints
2025-03-06 20:57:01,079 - INFO - training batch 151, loss: 0.086, 4832/28000 datapoints
2025-03-06 20:57:01,199 - INFO - training batch 201, loss: 0.049, 6432/28000 datapoints
2025-03-06 20:57:01,321 - INFO - training batch 251, loss: 0.247, 8032/28000 datapoints
2025-03-06 20:57:01,441 - INFO - training batch 301, loss: 0.333, 9632/28000 datapoints
2025-03-06 20:57:01,563 - INFO - training batch 351, loss: 0.181, 11232/28000 datapoints
2025-03-06 20:57:01,690 - INFO - training batch 401, loss: 0.350, 12832/28000 datapoints
2025-03-06 20:57:01,812 - INFO - training batch 451, loss: 0.168, 14432/28000 datapoints
2025-03-06 20:57:01,934 - INFO - training batch 501, loss: 0.116, 16032/28000 datapoints
2025-03-06 20:57:02,055 - INFO - training batch 551, loss: 0.148, 17632/28000 datapoints
2025-03-06 20:57:02,178 - INFO - training batch 601, loss: 0.083, 19232/28000 datapoints
2025-03-06 20:57:02,299 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 20:57:02,421 - INFO - training batch 701, loss: 0.189, 22432/28000 datapoints
2025-03-06 20:57:02,540 - INFO - training batch 751, loss: 0.134, 24032/28000 datapoints
2025-03-06 20:57:02,661 - INFO - training batch 801, loss: 0.090, 25632/28000 datapoints
2025-03-06 20:57:02,779 - INFO - training batch 851, loss: 0.185, 27232/28000 datapoints
2025-03-06 20:57:02,840 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:57:02,883 - INFO - validation batch 51, loss: 1.337, 1632/6976 datapoints
2025-03-06 20:57:02,927 - INFO - validation batch 101, loss: 0.499, 3232/6976 datapoints
2025-03-06 20:57:02,973 - INFO - validation batch 151, loss: 0.449, 4832/6976 datapoints
2025-03-06 20:57:03,017 - INFO - validation batch 201, loss: 0.422, 6432/6976 datapoints
2025-03-06 20:57:03,032 - INFO - Epoch 482/800 done.
2025-03-06 20:57:03,032 - INFO - Final validation performance:
Loss: 0.568, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:03,033 - INFO - Beginning epoch 483/800
2025-03-06 20:57:03,036 - INFO - training batch 1, loss: 0.250, 32/28000 datapoints
2025-03-06 20:57:03,157 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-06 20:57:03,277 - INFO - training batch 101, loss: 0.085, 3232/28000 datapoints
2025-03-06 20:57:03,401 - INFO - training batch 151, loss: 0.086, 4832/28000 datapoints
2025-03-06 20:57:03,521 - INFO - training batch 201, loss: 0.049, 6432/28000 datapoints
2025-03-06 20:57:03,645 - INFO - training batch 251, loss: 0.247, 8032/28000 datapoints
2025-03-06 20:57:03,765 - INFO - training batch 301, loss: 0.331, 9632/28000 datapoints
2025-03-06 20:57:03,888 - INFO - training batch 351, loss: 0.180, 11232/28000 datapoints
2025-03-06 20:57:04,006 - INFO - training batch 401, loss: 0.348, 12832/28000 datapoints
2025-03-06 20:57:04,127 - INFO - training batch 451, loss: 0.173, 14432/28000 datapoints
2025-03-06 20:57:04,247 - INFO - training batch 501, loss: 0.116, 16032/28000 datapoints
2025-03-06 20:57:04,368 - INFO - training batch 551, loss: 0.148, 17632/28000 datapoints
2025-03-06 20:57:04,488 - INFO - training batch 601, loss: 0.081, 19232/28000 datapoints
2025-03-06 20:57:04,609 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 20:57:04,732 - INFO - training batch 701, loss: 0.188, 22432/28000 datapoints
2025-03-06 20:57:04,881 - INFO - training batch 751, loss: 0.134, 24032/28000 datapoints
2025-03-06 20:57:05,011 - INFO - training batch 801, loss: 0.090, 25632/28000 datapoints
2025-03-06 20:57:05,134 - INFO - training batch 851, loss: 0.184, 27232/28000 datapoints
2025-03-06 20:57:05,194 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:57:05,237 - INFO - validation batch 51, loss: 1.343, 1632/6976 datapoints
2025-03-06 20:57:05,283 - INFO - validation batch 101, loss: 0.500, 3232/6976 datapoints
2025-03-06 20:57:05,326 - INFO - validation batch 151, loss: 0.452, 4832/6976 datapoints
2025-03-06 20:57:05,370 - INFO - validation batch 201, loss: 0.422, 6432/6976 datapoints
2025-03-06 20:57:05,388 - INFO - Epoch 483/800 done.
2025-03-06 20:57:05,388 - INFO - Final validation performance:
Loss: 0.570, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:05,388 - INFO - Beginning epoch 484/800
2025-03-06 20:57:05,392 - INFO - training batch 1, loss: 0.251, 32/28000 datapoints
2025-03-06 20:57:05,513 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 20:57:05,632 - INFO - training batch 101, loss: 0.084, 3232/28000 datapoints
2025-03-06 20:57:05,755 - INFO - training batch 151, loss: 0.085, 4832/28000 datapoints
2025-03-06 20:57:05,877 - INFO - training batch 201, loss: 0.049, 6432/28000 datapoints
2025-03-06 20:57:05,997 - INFO - training batch 251, loss: 0.246, 8032/28000 datapoints
2025-03-06 20:57:06,118 - INFO - training batch 301, loss: 0.329, 9632/28000 datapoints
2025-03-06 20:57:06,238 - INFO - training batch 351, loss: 0.180, 11232/28000 datapoints
2025-03-06 20:57:06,359 - INFO - training batch 401, loss: 0.348, 12832/28000 datapoints
2025-03-06 20:57:06,481 - INFO - training batch 451, loss: 0.168, 14432/28000 datapoints
2025-03-06 20:57:06,602 - INFO - training batch 501, loss: 0.115, 16032/28000 datapoints
2025-03-06 20:57:06,725 - INFO - training batch 551, loss: 0.147, 17632/28000 datapoints
2025-03-06 20:57:06,845 - INFO - training batch 601, loss: 0.081, 19232/28000 datapoints
2025-03-06 20:57:06,970 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 20:57:07,089 - INFO - training batch 701, loss: 0.188, 22432/28000 datapoints
2025-03-06 20:57:07,211 - INFO - training batch 751, loss: 0.133, 24032/28000 datapoints
2025-03-06 20:57:07,331 - INFO - training batch 801, loss: 0.089, 25632/28000 datapoints
2025-03-06 20:57:07,453 - INFO - training batch 851, loss: 0.183, 27232/28000 datapoints
2025-03-06 20:57:07,511 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:57:07,555 - INFO - validation batch 51, loss: 1.345, 1632/6976 datapoints
2025-03-06 20:57:07,598 - INFO - validation batch 101, loss: 0.502, 3232/6976 datapoints
2025-03-06 20:57:07,646 - INFO - validation batch 151, loss: 0.452, 4832/6976 datapoints
2025-03-06 20:57:07,693 - INFO - validation batch 201, loss: 0.422, 6432/6976 datapoints
2025-03-06 20:57:07,708 - INFO - Epoch 484/800 done.
2025-03-06 20:57:07,708 - INFO - Final validation performance:
Loss: 0.571, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:07,708 - INFO - Beginning epoch 485/800
2025-03-06 20:57:07,712 - INFO - training batch 1, loss: 0.251, 32/28000 datapoints
2025-03-06 20:57:07,844 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 20:57:07,971 - INFO - training batch 101, loss: 0.084, 3232/28000 datapoints
2025-03-06 20:57:08,092 - INFO - training batch 151, loss: 0.085, 4832/28000 datapoints
2025-03-06 20:57:08,214 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-06 20:57:08,335 - INFO - training batch 251, loss: 0.245, 8032/28000 datapoints
2025-03-06 20:57:08,456 - INFO - training batch 301, loss: 0.328, 9632/28000 datapoints
2025-03-06 20:57:08,575 - INFO - training batch 351, loss: 0.180, 11232/28000 datapoints
2025-03-06 20:57:08,697 - INFO - training batch 401, loss: 0.346, 12832/28000 datapoints
2025-03-06 20:57:08,817 - INFO - training batch 451, loss: 0.171, 14432/28000 datapoints
2025-03-06 20:57:08,946 - INFO - training batch 501, loss: 0.115, 16032/28000 datapoints
2025-03-06 20:57:09,080 - INFO - training batch 551, loss: 0.146, 17632/28000 datapoints
2025-03-06 20:57:09,210 - INFO - training batch 601, loss: 0.080, 19232/28000 datapoints
2025-03-06 20:57:09,336 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-06 20:57:09,466 - INFO - training batch 701, loss: 0.187, 22432/28000 datapoints
2025-03-06 20:57:09,590 - INFO - training batch 751, loss: 0.133, 24032/28000 datapoints
2025-03-06 20:57:09,718 - INFO - training batch 801, loss: 0.089, 25632/28000 datapoints
2025-03-06 20:57:09,839 - INFO - training batch 851, loss: 0.181, 27232/28000 datapoints
2025-03-06 20:57:09,904 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:57:09,954 - INFO - validation batch 51, loss: 1.348, 1632/6976 datapoints
2025-03-06 20:57:10,002 - INFO - validation batch 101, loss: 0.505, 3232/6976 datapoints
2025-03-06 20:57:10,050 - INFO - validation batch 151, loss: 0.452, 4832/6976 datapoints
2025-03-06 20:57:10,100 - INFO - validation batch 201, loss: 0.422, 6432/6976 datapoints
2025-03-06 20:57:10,115 - INFO - Epoch 485/800 done.
2025-03-06 20:57:10,116 - INFO - Final validation performance:
Loss: 0.572, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:10,116 - INFO - Beginning epoch 486/800
2025-03-06 20:57:10,120 - INFO - training batch 1, loss: 0.249, 32/28000 datapoints
2025-03-06 20:57:10,260 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 20:57:10,389 - INFO - training batch 101, loss: 0.084, 3232/28000 datapoints
2025-03-06 20:57:10,518 - INFO - training batch 151, loss: 0.084, 4832/28000 datapoints
2025-03-06 20:57:10,646 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-06 20:57:10,771 - INFO - training batch 251, loss: 0.244, 8032/28000 datapoints
2025-03-06 20:57:10,894 - INFO - training batch 301, loss: 0.325, 9632/28000 datapoints
2025-03-06 20:57:11,022 - INFO - training batch 351, loss: 0.180, 11232/28000 datapoints
2025-03-06 20:57:11,147 - INFO - training batch 401, loss: 0.345, 12832/28000 datapoints
2025-03-06 20:57:11,271 - INFO - training batch 451, loss: 0.167, 14432/28000 datapoints
2025-03-06 20:57:11,395 - INFO - training batch 501, loss: 0.114, 16032/28000 datapoints
2025-03-06 20:57:11,522 - INFO - training batch 551, loss: 0.145, 17632/28000 datapoints
2025-03-06 20:57:11,655 - INFO - training batch 601, loss: 0.080, 19232/28000 datapoints
2025-03-06 20:57:11,779 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:11,905 - INFO - training batch 701, loss: 0.187, 22432/28000 datapoints
2025-03-06 20:57:12,029 - INFO - training batch 751, loss: 0.132, 24032/28000 datapoints
2025-03-06 20:57:12,152 - INFO - training batch 801, loss: 0.089, 25632/28000 datapoints
2025-03-06 20:57:12,279 - INFO - training batch 851, loss: 0.180, 27232/28000 datapoints
2025-03-06 20:57:12,342 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:57:12,389 - INFO - validation batch 51, loss: 1.351, 1632/6976 datapoints
2025-03-06 20:57:12,438 - INFO - validation batch 101, loss: 0.506, 3232/6976 datapoints
2025-03-06 20:57:12,488 - INFO - validation batch 151, loss: 0.454, 4832/6976 datapoints
2025-03-06 20:57:12,537 - INFO - validation batch 201, loss: 0.422, 6432/6976 datapoints
2025-03-06 20:57:12,552 - INFO - Epoch 486/800 done.
2025-03-06 20:57:12,552 - INFO - Final validation performance:
Loss: 0.573, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:12,553 - INFO - Beginning epoch 487/800
2025-03-06 20:57:12,557 - INFO - training batch 1, loss: 0.250, 32/28000 datapoints
2025-03-06 20:57:12,685 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 20:57:12,810 - INFO - training batch 101, loss: 0.082, 3232/28000 datapoints
2025-03-06 20:57:12,935 - INFO - training batch 151, loss: 0.083, 4832/28000 datapoints
2025-03-06 20:57:13,065 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-06 20:57:13,188 - INFO - training batch 251, loss: 0.244, 8032/28000 datapoints
2025-03-06 20:57:13,313 - INFO - training batch 301, loss: 0.325, 9632/28000 datapoints
2025-03-06 20:57:13,438 - INFO - training batch 351, loss: 0.180, 11232/28000 datapoints
2025-03-06 20:57:13,564 - INFO - training batch 401, loss: 0.343, 12832/28000 datapoints
2025-03-06 20:57:13,692 - INFO - training batch 451, loss: 0.171, 14432/28000 datapoints
2025-03-06 20:57:13,815 - INFO - training batch 501, loss: 0.115, 16032/28000 datapoints
2025-03-06 20:57:13,942 - INFO - training batch 551, loss: 0.146, 17632/28000 datapoints
2025-03-06 20:57:14,066 - INFO - training batch 601, loss: 0.078, 19232/28000 datapoints
2025-03-06 20:57:14,189 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:14,312 - INFO - training batch 701, loss: 0.186, 22432/28000 datapoints
2025-03-06 20:57:14,437 - INFO - training batch 751, loss: 0.131, 24032/28000 datapoints
2025-03-06 20:57:14,562 - INFO - training batch 801, loss: 0.088, 25632/28000 datapoints
2025-03-06 20:57:14,689 - INFO - training batch 851, loss: 0.179, 27232/28000 datapoints
2025-03-06 20:57:14,751 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:57:14,799 - INFO - validation batch 51, loss: 1.353, 1632/6976 datapoints
2025-03-06 20:57:14,849 - INFO - validation batch 101, loss: 0.509, 3232/6976 datapoints
2025-03-06 20:57:14,916 - INFO - validation batch 151, loss: 0.453, 4832/6976 datapoints
2025-03-06 20:57:14,981 - INFO - validation batch 201, loss: 0.423, 6432/6976 datapoints
2025-03-06 20:57:15,002 - INFO - Epoch 487/800 done.
2025-03-06 20:57:15,002 - INFO - Final validation performance:
Loss: 0.574, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:15,002 - INFO - Beginning epoch 488/800
2025-03-06 20:57:15,006 - INFO - training batch 1, loss: 0.249, 32/28000 datapoints
2025-03-06 20:57:15,137 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 20:57:15,263 - INFO - training batch 101, loss: 0.084, 3232/28000 datapoints
2025-03-06 20:57:15,388 - INFO - training batch 151, loss: 0.083, 4832/28000 datapoints
2025-03-06 20:57:15,513 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-06 20:57:15,639 - INFO - training batch 251, loss: 0.243, 8032/28000 datapoints
2025-03-06 20:57:15,764 - INFO - training batch 301, loss: 0.322, 9632/28000 datapoints
2025-03-06 20:57:15,886 - INFO - training batch 351, loss: 0.179, 11232/28000 datapoints
2025-03-06 20:57:16,009 - INFO - training batch 401, loss: 0.343, 12832/28000 datapoints
2025-03-06 20:57:16,133 - INFO - training batch 451, loss: 0.169, 14432/28000 datapoints
2025-03-06 20:57:16,259 - INFO - training batch 501, loss: 0.114, 16032/28000 datapoints
2025-03-06 20:57:16,384 - INFO - training batch 551, loss: 0.144, 17632/28000 datapoints
2025-03-06 20:57:16,510 - INFO - training batch 601, loss: 0.078, 19232/28000 datapoints
2025-03-06 20:57:16,633 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:16,760 - INFO - training batch 701, loss: 0.185, 22432/28000 datapoints
2025-03-06 20:57:16,882 - INFO - training batch 751, loss: 0.131, 24032/28000 datapoints
2025-03-06 20:57:17,010 - INFO - training batch 801, loss: 0.088, 25632/28000 datapoints
2025-03-06 20:57:17,134 - INFO - training batch 851, loss: 0.178, 27232/28000 datapoints
2025-03-06 20:57:17,199 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:57:17,247 - INFO - validation batch 51, loss: 1.357, 1632/6976 datapoints
2025-03-06 20:57:17,296 - INFO - validation batch 101, loss: 0.510, 3232/6976 datapoints
2025-03-06 20:57:17,344 - INFO - validation batch 151, loss: 0.456, 4832/6976 datapoints
2025-03-06 20:57:17,393 - INFO - validation batch 201, loss: 0.423, 6432/6976 datapoints
2025-03-06 20:57:17,408 - INFO - Epoch 488/800 done.
2025-03-06 20:57:17,408 - INFO - Final validation performance:
Loss: 0.576, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:17,409 - INFO - Beginning epoch 489/800
2025-03-06 20:57:17,412 - INFO - training batch 1, loss: 0.249, 32/28000 datapoints
2025-03-06 20:57:17,539 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 20:57:17,667 - INFO - training batch 101, loss: 0.083, 3232/28000 datapoints
2025-03-06 20:57:17,791 - INFO - training batch 151, loss: 0.083, 4832/28000 datapoints
2025-03-06 20:57:17,914 - INFO - training batch 201, loss: 0.047, 6432/28000 datapoints
2025-03-06 20:57:18,042 - INFO - training batch 251, loss: 0.242, 8032/28000 datapoints
2025-03-06 20:57:18,165 - INFO - training batch 301, loss: 0.322, 9632/28000 datapoints
2025-03-06 20:57:18,288 - INFO - training batch 351, loss: 0.179, 11232/28000 datapoints
2025-03-06 20:57:18,415 - INFO - training batch 401, loss: 0.341, 12832/28000 datapoints
2025-03-06 20:57:18,543 - INFO - training batch 451, loss: 0.165, 14432/28000 datapoints
2025-03-06 20:57:18,669 - INFO - training batch 501, loss: 0.113, 16032/28000 datapoints
2025-03-06 20:57:18,792 - INFO - training batch 551, loss: 0.143, 17632/28000 datapoints
2025-03-06 20:57:18,915 - INFO - training batch 601, loss: 0.078, 19232/28000 datapoints
2025-03-06 20:57:19,044 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:19,165 - INFO - training batch 701, loss: 0.185, 22432/28000 datapoints
2025-03-06 20:57:19,291 - INFO - training batch 751, loss: 0.130, 24032/28000 datapoints
2025-03-06 20:57:19,420 - INFO - training batch 801, loss: 0.088, 25632/28000 datapoints
2025-03-06 20:57:19,544 - INFO - training batch 851, loss: 0.177, 27232/28000 datapoints
2025-03-06 20:57:19,606 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:57:19,657 - INFO - validation batch 51, loss: 1.359, 1632/6976 datapoints
2025-03-06 20:57:19,708 - INFO - validation batch 101, loss: 0.513, 3232/6976 datapoints
2025-03-06 20:57:19,754 - INFO - validation batch 151, loss: 0.456, 4832/6976 datapoints
2025-03-06 20:57:19,804 - INFO - validation batch 201, loss: 0.424, 6432/6976 datapoints
2025-03-06 20:57:19,820 - INFO - Epoch 489/800 done.
2025-03-06 20:57:19,820 - INFO - Final validation performance:
Loss: 0.577, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:19,821 - INFO - Beginning epoch 490/800
2025-03-06 20:57:19,825 - INFO - training batch 1, loss: 0.248, 32/28000 datapoints
2025-03-06 20:57:19,953 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 20:57:20,076 - INFO - training batch 101, loss: 0.083, 3232/28000 datapoints
2025-03-06 20:57:20,197 - INFO - training batch 151, loss: 0.082, 4832/28000 datapoints
2025-03-06 20:57:20,317 - INFO - training batch 201, loss: 0.047, 6432/28000 datapoints
2025-03-06 20:57:20,438 - INFO - training batch 251, loss: 0.242, 8032/28000 datapoints
2025-03-06 20:57:20,559 - INFO - training batch 301, loss: 0.320, 9632/28000 datapoints
2025-03-06 20:57:20,682 - INFO - training batch 351, loss: 0.179, 11232/28000 datapoints
2025-03-06 20:57:20,800 - INFO - training batch 401, loss: 0.340, 12832/28000 datapoints
2025-03-06 20:57:20,919 - INFO - training batch 451, loss: 0.169, 14432/28000 datapoints
2025-03-06 20:57:21,045 - INFO - training batch 501, loss: 0.113, 16032/28000 datapoints
2025-03-06 20:57:21,170 - INFO - training batch 551, loss: 0.143, 17632/28000 datapoints
2025-03-06 20:57:21,294 - INFO - training batch 601, loss: 0.077, 19232/28000 datapoints
2025-03-06 20:57:21,413 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:21,534 - INFO - training batch 701, loss: 0.184, 22432/28000 datapoints
2025-03-06 20:57:21,662 - INFO - training batch 751, loss: 0.130, 24032/28000 datapoints
2025-03-06 20:57:21,782 - INFO - training batch 801, loss: 0.088, 25632/28000 datapoints
2025-03-06 20:57:21,902 - INFO - training batch 851, loss: 0.176, 27232/28000 datapoints
2025-03-06 20:57:21,962 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:57:22,006 - INFO - validation batch 51, loss: 1.363, 1632/6976 datapoints
2025-03-06 20:57:22,051 - INFO - validation batch 101, loss: 0.514, 3232/6976 datapoints
2025-03-06 20:57:22,095 - INFO - validation batch 151, loss: 0.458, 4832/6976 datapoints
2025-03-06 20:57:22,140 - INFO - validation batch 201, loss: 0.423, 6432/6976 datapoints
2025-03-06 20:57:22,155 - INFO - Epoch 490/800 done.
2025-03-06 20:57:22,155 - INFO - Final validation performance:
Loss: 0.578, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:22,155 - INFO - Beginning epoch 491/800
2025-03-06 20:57:22,159 - INFO - training batch 1, loss: 0.248, 32/28000 datapoints
2025-03-06 20:57:22,284 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 20:57:22,404 - INFO - training batch 101, loss: 0.082, 3232/28000 datapoints
2025-03-06 20:57:22,525 - INFO - training batch 151, loss: 0.081, 4832/28000 datapoints
2025-03-06 20:57:22,650 - INFO - training batch 201, loss: 0.047, 6432/28000 datapoints
2025-03-06 20:57:22,771 - INFO - training batch 251, loss: 0.241, 8032/28000 datapoints
2025-03-06 20:57:22,891 - INFO - training batch 301, loss: 0.318, 9632/28000 datapoints
2025-03-06 20:57:23,012 - INFO - training batch 351, loss: 0.179, 11232/28000 datapoints
2025-03-06 20:57:23,136 - INFO - training batch 401, loss: 0.339, 12832/28000 datapoints
2025-03-06 20:57:23,257 - INFO - training batch 451, loss: 0.164, 14432/28000 datapoints
2025-03-06 20:57:23,378 - INFO - training batch 501, loss: 0.112, 16032/28000 datapoints
2025-03-06 20:57:23,499 - INFO - training batch 551, loss: 0.142, 17632/28000 datapoints
2025-03-06 20:57:23,620 - INFO - training batch 601, loss: 0.076, 19232/28000 datapoints
2025-03-06 20:57:23,744 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:23,864 - INFO - training batch 701, loss: 0.183, 22432/28000 datapoints
2025-03-06 20:57:23,985 - INFO - training batch 751, loss: 0.128, 24032/28000 datapoints
2025-03-06 20:57:24,106 - INFO - training batch 801, loss: 0.088, 25632/28000 datapoints
2025-03-06 20:57:24,226 - INFO - training batch 851, loss: 0.174, 27232/28000 datapoints
2025-03-06 20:57:24,288 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:57:24,332 - INFO - validation batch 51, loss: 1.366, 1632/6976 datapoints
2025-03-06 20:57:24,380 - INFO - validation batch 101, loss: 0.516, 3232/6976 datapoints
2025-03-06 20:57:24,426 - INFO - validation batch 151, loss: 0.458, 4832/6976 datapoints
2025-03-06 20:57:24,470 - INFO - validation batch 201, loss: 0.424, 6432/6976 datapoints
2025-03-06 20:57:24,485 - INFO - Epoch 491/800 done.
2025-03-06 20:57:24,485 - INFO - Final validation performance:
Loss: 0.579, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:24,486 - INFO - Beginning epoch 492/800
2025-03-06 20:57:24,489 - INFO - training batch 1, loss: 0.247, 32/28000 datapoints
2025-03-06 20:57:24,613 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 20:57:24,739 - INFO - training batch 101, loss: 0.081, 3232/28000 datapoints
2025-03-06 20:57:24,860 - INFO - training batch 151, loss: 0.081, 4832/28000 datapoints
2025-03-06 20:57:24,988 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-06 20:57:25,134 - INFO - training batch 251, loss: 0.241, 8032/28000 datapoints
2025-03-06 20:57:25,262 - INFO - training batch 301, loss: 0.316, 9632/28000 datapoints
2025-03-06 20:57:25,383 - INFO - training batch 351, loss: 0.178, 11232/28000 datapoints
2025-03-06 20:57:25,503 - INFO - training batch 401, loss: 0.338, 12832/28000 datapoints
2025-03-06 20:57:25,632 - INFO - training batch 451, loss: 0.167, 14432/28000 datapoints
2025-03-06 20:57:25,781 - INFO - training batch 501, loss: 0.112, 16032/28000 datapoints
2025-03-06 20:57:25,929 - INFO - training batch 551, loss: 0.142, 17632/28000 datapoints
2025-03-06 20:57:26,053 - INFO - training batch 601, loss: 0.075, 19232/28000 datapoints
2025-03-06 20:57:26,197 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:26,367 - INFO - training batch 701, loss: 0.183, 22432/28000 datapoints
2025-03-06 20:57:26,528 - INFO - training batch 751, loss: 0.128, 24032/28000 datapoints
2025-03-06 20:57:26,704 - INFO - training batch 801, loss: 0.088, 25632/28000 datapoints
2025-03-06 20:57:26,851 - INFO - training batch 851, loss: 0.174, 27232/28000 datapoints
2025-03-06 20:57:26,921 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:57:26,984 - INFO - validation batch 51, loss: 1.366, 1632/6976 datapoints
2025-03-06 20:57:27,048 - INFO - validation batch 101, loss: 0.519, 3232/6976 datapoints
2025-03-06 20:57:27,097 - INFO - validation batch 151, loss: 0.458, 4832/6976 datapoints
2025-03-06 20:57:27,161 - INFO - validation batch 201, loss: 0.424, 6432/6976 datapoints
2025-03-06 20:57:27,183 - INFO - Epoch 492/800 done.
2025-03-06 20:57:27,184 - INFO - Final validation performance:
Loss: 0.580, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:27,184 - INFO - Beginning epoch 493/800
2025-03-06 20:57:27,191 - INFO - training batch 1, loss: 0.247, 32/28000 datapoints
2025-03-06 20:57:27,446 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 20:57:27,617 - INFO - training batch 101, loss: 0.082, 3232/28000 datapoints
2025-03-06 20:57:27,760 - INFO - training batch 151, loss: 0.080, 4832/28000 datapoints
2025-03-06 20:57:27,885 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-06 20:57:28,007 - INFO - training batch 251, loss: 0.240, 8032/28000 datapoints
2025-03-06 20:57:28,132 - INFO - training batch 301, loss: 0.315, 9632/28000 datapoints
2025-03-06 20:57:28,256 - INFO - training batch 351, loss: 0.178, 11232/28000 datapoints
2025-03-06 20:57:28,377 - INFO - training batch 401, loss: 0.337, 12832/28000 datapoints
2025-03-06 20:57:28,498 - INFO - training batch 451, loss: 0.163, 14432/28000 datapoints
2025-03-06 20:57:28,618 - INFO - training batch 501, loss: 0.111, 16032/28000 datapoints
2025-03-06 20:57:28,742 - INFO - training batch 551, loss: 0.141, 17632/28000 datapoints
2025-03-06 20:57:28,865 - INFO - training batch 601, loss: 0.075, 19232/28000 datapoints
2025-03-06 20:57:28,990 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:29,113 - INFO - training batch 701, loss: 0.182, 22432/28000 datapoints
2025-03-06 20:57:29,241 - INFO - training batch 751, loss: 0.128, 24032/28000 datapoints
2025-03-06 20:57:29,365 - INFO - training batch 801, loss: 0.087, 25632/28000 datapoints
2025-03-06 20:57:29,489 - INFO - training batch 851, loss: 0.172, 27232/28000 datapoints
2025-03-06 20:57:29,552 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:57:29,601 - INFO - validation batch 51, loss: 1.371, 1632/6976 datapoints
2025-03-06 20:57:29,653 - INFO - validation batch 101, loss: 0.520, 3232/6976 datapoints
2025-03-06 20:57:29,700 - INFO - validation batch 151, loss: 0.460, 4832/6976 datapoints
2025-03-06 20:57:29,752 - INFO - validation batch 201, loss: 0.424, 6432/6976 datapoints
2025-03-06 20:57:29,769 - INFO - Epoch 493/800 done.
2025-03-06 20:57:29,769 - INFO - Final validation performance:
Loss: 0.581, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:29,769 - INFO - Beginning epoch 494/800
2025-03-06 20:57:29,775 - INFO - training batch 1, loss: 0.247, 32/28000 datapoints
2025-03-06 20:57:29,903 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 20:57:30,025 - INFO - training batch 101, loss: 0.081, 3232/28000 datapoints
2025-03-06 20:57:30,148 - INFO - training batch 151, loss: 0.079, 4832/28000 datapoints
2025-03-06 20:57:30,271 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-06 20:57:30,393 - INFO - training batch 251, loss: 0.240, 8032/28000 datapoints
2025-03-06 20:57:30,513 - INFO - training batch 301, loss: 0.313, 9632/28000 datapoints
2025-03-06 20:57:30,642 - INFO - training batch 351, loss: 0.177, 11232/28000 datapoints
2025-03-06 20:57:30,764 - INFO - training batch 401, loss: 0.335, 12832/28000 datapoints
2025-03-06 20:57:30,887 - INFO - training batch 451, loss: 0.166, 14432/28000 datapoints
2025-03-06 20:57:31,009 - INFO - training batch 501, loss: 0.112, 16032/28000 datapoints
2025-03-06 20:57:31,133 - INFO - training batch 551, loss: 0.140, 17632/28000 datapoints
2025-03-06 20:57:31,254 - INFO - training batch 601, loss: 0.075, 19232/28000 datapoints
2025-03-06 20:57:31,377 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:31,498 - INFO - training batch 701, loss: 0.182, 22432/28000 datapoints
2025-03-06 20:57:31,617 - INFO - training batch 751, loss: 0.127, 24032/28000 datapoints
2025-03-06 20:57:31,745 - INFO - training batch 801, loss: 0.087, 25632/28000 datapoints
2025-03-06 20:57:31,867 - INFO - training batch 851, loss: 0.171, 27232/28000 datapoints
2025-03-06 20:57:31,927 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:57:31,970 - INFO - validation batch 51, loss: 1.372, 1632/6976 datapoints
2025-03-06 20:57:32,014 - INFO - validation batch 101, loss: 0.523, 3232/6976 datapoints
2025-03-06 20:57:32,058 - INFO - validation batch 151, loss: 0.459, 4832/6976 datapoints
2025-03-06 20:57:32,102 - INFO - validation batch 201, loss: 0.425, 6432/6976 datapoints
2025-03-06 20:57:32,117 - INFO - Epoch 494/800 done.
2025-03-06 20:57:32,117 - INFO - Final validation performance:
Loss: 0.582, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:32,118 - INFO - Beginning epoch 495/800
2025-03-06 20:57:32,121 - INFO - training batch 1, loss: 0.245, 32/28000 datapoints
2025-03-06 20:57:32,250 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 20:57:32,372 - INFO - training batch 101, loss: 0.081, 3232/28000 datapoints
2025-03-06 20:57:32,493 - INFO - training batch 151, loss: 0.079, 4832/28000 datapoints
2025-03-06 20:57:32,613 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-06 20:57:32,738 - INFO - training batch 251, loss: 0.239, 8032/28000 datapoints
2025-03-06 20:57:32,858 - INFO - training batch 301, loss: 0.310, 9632/28000 datapoints
2025-03-06 20:57:32,978 - INFO - training batch 351, loss: 0.177, 11232/28000 datapoints
2025-03-06 20:57:33,103 - INFO - training batch 401, loss: 0.334, 12832/28000 datapoints
2025-03-06 20:57:33,225 - INFO - training batch 451, loss: 0.165, 14432/28000 datapoints
2025-03-06 20:57:33,346 - INFO - training batch 501, loss: 0.110, 16032/28000 datapoints
2025-03-06 20:57:33,467 - INFO - training batch 551, loss: 0.139, 17632/28000 datapoints
2025-03-06 20:57:33,588 - INFO - training batch 601, loss: 0.074, 19232/28000 datapoints
2025-03-06 20:57:33,712 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:33,832 - INFO - training batch 701, loss: 0.181, 22432/28000 datapoints
2025-03-06 20:57:33,952 - INFO - training batch 751, loss: 0.125, 24032/28000 datapoints
2025-03-06 20:57:34,072 - INFO - training batch 801, loss: 0.087, 25632/28000 datapoints
2025-03-06 20:57:34,192 - INFO - training batch 851, loss: 0.170, 27232/28000 datapoints
2025-03-06 20:57:34,252 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:57:34,296 - INFO - validation batch 51, loss: 1.377, 1632/6976 datapoints
2025-03-06 20:57:34,340 - INFO - validation batch 101, loss: 0.524, 3232/6976 datapoints
2025-03-06 20:57:34,384 - INFO - validation batch 151, loss: 0.461, 4832/6976 datapoints
2025-03-06 20:57:34,428 - INFO - validation batch 201, loss: 0.425, 6432/6976 datapoints
2025-03-06 20:57:34,443 - INFO - Epoch 495/800 done.
2025-03-06 20:57:34,443 - INFO - Final validation performance:
Loss: 0.584, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:34,444 - INFO - Beginning epoch 496/800
2025-03-06 20:57:34,447 - INFO - training batch 1, loss: 0.246, 32/28000 datapoints
2025-03-06 20:57:34,570 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 20:57:34,695 - INFO - training batch 101, loss: 0.080, 3232/28000 datapoints
2025-03-06 20:57:34,818 - INFO - training batch 151, loss: 0.078, 4832/28000 datapoints
2025-03-06 20:57:34,944 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-06 20:57:35,067 - INFO - training batch 251, loss: 0.239, 8032/28000 datapoints
2025-03-06 20:57:35,215 - INFO - training batch 301, loss: 0.309, 9632/28000 datapoints
2025-03-06 20:57:35,336 - INFO - training batch 351, loss: 0.177, 11232/28000 datapoints
2025-03-06 20:57:35,454 - INFO - training batch 401, loss: 0.333, 12832/28000 datapoints
2025-03-06 20:57:35,576 - INFO - training batch 451, loss: 0.161, 14432/28000 datapoints
2025-03-06 20:57:35,699 - INFO - training batch 501, loss: 0.110, 16032/28000 datapoints
2025-03-06 20:57:35,821 - INFO - training batch 551, loss: 0.137, 17632/28000 datapoints
2025-03-06 20:57:35,941 - INFO - training batch 601, loss: 0.074, 19232/28000 datapoints
2025-03-06 20:57:36,062 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:36,183 - INFO - training batch 701, loss: 0.180, 22432/28000 datapoints
2025-03-06 20:57:36,305 - INFO - training batch 751, loss: 0.125, 24032/28000 datapoints
2025-03-06 20:57:36,423 - INFO - training batch 801, loss: 0.087, 25632/28000 datapoints
2025-03-06 20:57:36,544 - INFO - training batch 851, loss: 0.169, 27232/28000 datapoints
2025-03-06 20:57:36,604 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:57:36,650 - INFO - validation batch 51, loss: 1.378, 1632/6976 datapoints
2025-03-06 20:57:36,694 - INFO - validation batch 101, loss: 0.527, 3232/6976 datapoints
2025-03-06 20:57:36,739 - INFO - validation batch 151, loss: 0.461, 4832/6976 datapoints
2025-03-06 20:57:36,784 - INFO - validation batch 201, loss: 0.426, 6432/6976 datapoints
2025-03-06 20:57:36,799 - INFO - Epoch 496/800 done.
2025-03-06 20:57:36,799 - INFO - Final validation performance:
Loss: 0.585, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:36,800 - INFO - Beginning epoch 497/800
2025-03-06 20:57:36,803 - INFO - training batch 1, loss: 0.244, 32/28000 datapoints
2025-03-06 20:57:36,927 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 20:57:37,047 - INFO - training batch 101, loss: 0.080, 3232/28000 datapoints
2025-03-06 20:57:37,171 - INFO - training batch 151, loss: 0.078, 4832/28000 datapoints
2025-03-06 20:57:37,293 - INFO - training batch 201, loss: 0.045, 6432/28000 datapoints
2025-03-06 20:57:37,415 - INFO - training batch 251, loss: 0.237, 8032/28000 datapoints
2025-03-06 20:57:37,537 - INFO - training batch 301, loss: 0.307, 9632/28000 datapoints
2025-03-06 20:57:37,682 - INFO - training batch 351, loss: 0.176, 11232/28000 datapoints
2025-03-06 20:57:37,804 - INFO - training batch 401, loss: 0.332, 12832/28000 datapoints
2025-03-06 20:57:37,924 - INFO - training batch 451, loss: 0.164, 14432/28000 datapoints
2025-03-06 20:57:38,044 - INFO - training batch 501, loss: 0.110, 16032/28000 datapoints
2025-03-06 20:57:38,165 - INFO - training batch 551, loss: 0.138, 17632/28000 datapoints
2025-03-06 20:57:38,287 - INFO - training batch 601, loss: 0.073, 19232/28000 datapoints
2025-03-06 20:57:38,408 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:38,529 - INFO - training batch 701, loss: 0.179, 22432/28000 datapoints
2025-03-06 20:57:38,651 - INFO - training batch 751, loss: 0.125, 24032/28000 datapoints
2025-03-06 20:57:38,793 - INFO - training batch 801, loss: 0.087, 25632/28000 datapoints
2025-03-06 20:57:38,913 - INFO - training batch 851, loss: 0.168, 27232/28000 datapoints
2025-03-06 20:57:38,974 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:57:39,018 - INFO - validation batch 51, loss: 1.382, 1632/6976 datapoints
2025-03-06 20:57:39,065 - INFO - validation batch 101, loss: 0.527, 3232/6976 datapoints
2025-03-06 20:57:39,117 - INFO - validation batch 151, loss: 0.462, 4832/6976 datapoints
2025-03-06 20:57:39,160 - INFO - validation batch 201, loss: 0.425, 6432/6976 datapoints
2025-03-06 20:57:39,175 - INFO - Epoch 497/800 done.
2025-03-06 20:57:39,175 - INFO - Final validation performance:
Loss: 0.586, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:39,176 - INFO - Beginning epoch 498/800
2025-03-06 20:57:39,180 - INFO - training batch 1, loss: 0.244, 32/28000 datapoints
2025-03-06 20:57:39,306 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 20:57:39,428 - INFO - training batch 101, loss: 0.080, 3232/28000 datapoints
2025-03-06 20:57:39,547 - INFO - training batch 151, loss: 0.077, 4832/28000 datapoints
2025-03-06 20:57:39,676 - INFO - training batch 201, loss: 0.045, 6432/28000 datapoints
2025-03-06 20:57:39,797 - INFO - training batch 251, loss: 0.237, 8032/28000 datapoints
2025-03-06 20:57:39,919 - INFO - training batch 301, loss: 0.305, 9632/28000 datapoints
2025-03-06 20:57:40,048 - INFO - training batch 351, loss: 0.176, 11232/28000 datapoints
2025-03-06 20:57:40,174 - INFO - training batch 401, loss: 0.331, 12832/28000 datapoints
2025-03-06 20:57:40,295 - INFO - training batch 451, loss: 0.159, 14432/28000 datapoints
2025-03-06 20:57:40,417 - INFO - training batch 501, loss: 0.109, 16032/28000 datapoints
2025-03-06 20:57:40,537 - INFO - training batch 551, loss: 0.136, 17632/28000 datapoints
2025-03-06 20:57:40,661 - INFO - training batch 601, loss: 0.072, 19232/28000 datapoints
2025-03-06 20:57:40,782 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:40,928 - INFO - training batch 701, loss: 0.179, 22432/28000 datapoints
2025-03-06 20:57:41,051 - INFO - training batch 751, loss: 0.124, 24032/28000 datapoints
2025-03-06 20:57:41,175 - INFO - training batch 801, loss: 0.087, 25632/28000 datapoints
2025-03-06 20:57:41,296 - INFO - training batch 851, loss: 0.167, 27232/28000 datapoints
2025-03-06 20:57:41,356 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:57:41,403 - INFO - validation batch 51, loss: 1.384, 1632/6976 datapoints
2025-03-06 20:57:41,447 - INFO - validation batch 101, loss: 0.531, 3232/6976 datapoints
2025-03-06 20:57:41,490 - INFO - validation batch 151, loss: 0.463, 4832/6976 datapoints
2025-03-06 20:57:41,535 - INFO - validation batch 201, loss: 0.426, 6432/6976 datapoints
2025-03-06 20:57:41,551 - INFO - Epoch 498/800 done.
2025-03-06 20:57:41,551 - INFO - Final validation performance:
Loss: 0.587, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:57:41,552 - INFO - Beginning epoch 499/800
2025-03-06 20:57:41,555 - INFO - training batch 1, loss: 0.243, 32/28000 datapoints
2025-03-06 20:57:41,680 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 20:57:41,809 - INFO - training batch 101, loss: 0.078, 3232/28000 datapoints
2025-03-06 20:57:41,932 - INFO - training batch 151, loss: 0.076, 4832/28000 datapoints
2025-03-06 20:57:42,052 - INFO - training batch 201, loss: 0.045, 6432/28000 datapoints
2025-03-06 20:57:42,174 - INFO - training batch 251, loss: 0.236, 8032/28000 datapoints
2025-03-06 20:57:42,295 - INFO - training batch 301, loss: 0.304, 9632/28000 datapoints
2025-03-06 20:57:42,416 - INFO - training batch 351, loss: 0.175, 11232/28000 datapoints
2025-03-06 20:57:42,535 - INFO - training batch 401, loss: 0.330, 12832/28000 datapoints
2025-03-06 20:57:42,660 - INFO - training batch 451, loss: 0.163, 14432/28000 datapoints
2025-03-06 20:57:42,780 - INFO - training batch 501, loss: 0.109, 16032/28000 datapoints
2025-03-06 20:57:42,906 - INFO - training batch 551, loss: 0.136, 17632/28000 datapoints
2025-03-06 20:57:43,028 - INFO - training batch 601, loss: 0.072, 19232/28000 datapoints
2025-03-06 20:57:43,159 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:43,279 - INFO - training batch 701, loss: 0.178, 22432/28000 datapoints
2025-03-06 20:57:43,401 - INFO - training batch 751, loss: 0.123, 24032/28000 datapoints
2025-03-06 20:57:43,521 - INFO - training batch 801, loss: 0.086, 25632/28000 datapoints
2025-03-06 20:57:43,645 - INFO - training batch 851, loss: 0.166, 27232/28000 datapoints
2025-03-06 20:57:43,704 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 20:57:43,748 - INFO - validation batch 51, loss: 1.388, 1632/6976 datapoints
2025-03-06 20:57:43,800 - INFO - validation batch 101, loss: 0.532, 3232/6976 datapoints
2025-03-06 20:57:43,850 - INFO - validation batch 151, loss: 0.463, 4832/6976 datapoints
2025-03-06 20:57:43,900 - INFO - validation batch 201, loss: 0.426, 6432/6976 datapoints
2025-03-06 20:57:43,914 - INFO - Epoch 499/800 done.
2025-03-06 20:57:43,915 - INFO - Final validation performance:
Loss: 0.588, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:43,915 - INFO - Beginning epoch 500/800
2025-03-06 20:57:43,919 - INFO - training batch 1, loss: 0.243, 32/28000 datapoints
2025-03-06 20:57:44,041 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 20:57:44,161 - INFO - training batch 101, loss: 0.080, 3232/28000 datapoints
2025-03-06 20:57:44,283 - INFO - training batch 151, loss: 0.076, 4832/28000 datapoints
2025-03-06 20:57:44,405 - INFO - training batch 201, loss: 0.045, 6432/28000 datapoints
2025-03-06 20:57:44,525 - INFO - training batch 251, loss: 0.236, 8032/28000 datapoints
2025-03-06 20:57:44,647 - INFO - training batch 301, loss: 0.301, 9632/28000 datapoints
2025-03-06 20:57:44,767 - INFO - training batch 351, loss: 0.175, 11232/28000 datapoints
2025-03-06 20:57:44,892 - INFO - training batch 401, loss: 0.328, 12832/28000 datapoints
2025-03-06 20:57:45,015 - INFO - training batch 451, loss: 0.162, 14432/28000 datapoints
2025-03-06 20:57:45,139 - INFO - training batch 501, loss: 0.108, 16032/28000 datapoints
2025-03-06 20:57:45,288 - INFO - training batch 551, loss: 0.136, 17632/28000 datapoints
2025-03-06 20:57:45,410 - INFO - training batch 601, loss: 0.072, 19232/28000 datapoints
2025-03-06 20:57:45,529 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:45,650 - INFO - training batch 701, loss: 0.177, 22432/28000 datapoints
2025-03-06 20:57:45,770 - INFO - training batch 751, loss: 0.123, 24032/28000 datapoints
2025-03-06 20:57:45,891 - INFO - training batch 801, loss: 0.086, 25632/28000 datapoints
2025-03-06 20:57:46,010 - INFO - training batch 851, loss: 0.165, 27232/28000 datapoints
2025-03-06 20:57:46,069 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:57:46,115 - INFO - validation batch 51, loss: 1.389, 1632/6976 datapoints
2025-03-06 20:57:46,159 - INFO - validation batch 101, loss: 0.535, 3232/6976 datapoints
2025-03-06 20:57:46,205 - INFO - validation batch 151, loss: 0.464, 4832/6976 datapoints
2025-03-06 20:57:46,249 - INFO - validation batch 201, loss: 0.427, 6432/6976 datapoints
2025-03-06 20:57:46,264 - INFO - Epoch 500/800 done.
2025-03-06 20:57:46,265 - INFO - Final validation performance:
Loss: 0.589, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:57:46,265 - INFO - Beginning epoch 501/800
2025-03-06 20:57:46,268 - INFO - training batch 1, loss: 0.243, 32/28000 datapoints
2025-03-06 20:57:46,395 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 20:57:46,513 - INFO - training batch 101, loss: 0.080, 3232/28000 datapoints
2025-03-06 20:57:46,633 - INFO - training batch 151, loss: 0.075, 4832/28000 datapoints
2025-03-06 20:57:46,763 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-06 20:57:46,885 - INFO - training batch 251, loss: 0.236, 8032/28000 datapoints
2025-03-06 20:57:47,006 - INFO - training batch 301, loss: 0.300, 9632/28000 datapoints
2025-03-06 20:57:47,126 - INFO - training batch 351, loss: 0.175, 11232/28000 datapoints
2025-03-06 20:57:47,251 - INFO - training batch 401, loss: 0.327, 12832/28000 datapoints
2025-03-06 20:57:47,376 - INFO - training batch 451, loss: 0.158, 14432/28000 datapoints
2025-03-06 20:57:47,518 - INFO - training batch 501, loss: 0.106, 16032/28000 datapoints
2025-03-06 20:57:47,642 - INFO - training batch 551, loss: 0.134, 17632/28000 datapoints
2025-03-06 20:57:47,766 - INFO - training batch 601, loss: 0.071, 19232/28000 datapoints
2025-03-06 20:57:47,888 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:48,006 - INFO - training batch 701, loss: 0.177, 22432/28000 datapoints
2025-03-06 20:57:48,125 - INFO - training batch 751, loss: 0.122, 24032/28000 datapoints
2025-03-06 20:57:48,246 - INFO - training batch 801, loss: 0.086, 25632/28000 datapoints
2025-03-06 20:57:48,366 - INFO - training batch 851, loss: 0.163, 27232/28000 datapoints
2025-03-06 20:57:48,425 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:57:48,470 - INFO - validation batch 51, loss: 1.394, 1632/6976 datapoints
2025-03-06 20:57:48,514 - INFO - validation batch 101, loss: 0.536, 3232/6976 datapoints
2025-03-06 20:57:48,557 - INFO - validation batch 151, loss: 0.464, 4832/6976 datapoints
2025-03-06 20:57:48,601 - INFO - validation batch 201, loss: 0.426, 6432/6976 datapoints
2025-03-06 20:57:48,616 - INFO - Epoch 501/800 done.
2025-03-06 20:57:48,616 - INFO - Final validation performance:
Loss: 0.590, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:48,617 - INFO - Beginning epoch 502/800
2025-03-06 20:57:48,621 - INFO - training batch 1, loss: 0.242, 32/28000 datapoints
2025-03-06 20:57:48,745 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 20:57:48,867 - INFO - training batch 101, loss: 0.079, 3232/28000 datapoints
2025-03-06 20:57:48,991 - INFO - training batch 151, loss: 0.075, 4832/28000 datapoints
2025-03-06 20:57:49,110 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-06 20:57:49,242 - INFO - training batch 251, loss: 0.235, 8032/28000 datapoints
2025-03-06 20:57:49,371 - INFO - training batch 301, loss: 0.298, 9632/28000 datapoints
2025-03-06 20:57:49,496 - INFO - training batch 351, loss: 0.174, 11232/28000 datapoints
2025-03-06 20:57:49,620 - INFO - training batch 401, loss: 0.325, 12832/28000 datapoints
2025-03-06 20:57:49,750 - INFO - training batch 451, loss: 0.161, 14432/28000 datapoints
2025-03-06 20:57:49,876 - INFO - training batch 501, loss: 0.106, 16032/28000 datapoints
2025-03-06 20:57:50,002 - INFO - training batch 551, loss: 0.133, 17632/28000 datapoints
2025-03-06 20:57:50,126 - INFO - training batch 601, loss: 0.070, 19232/28000 datapoints
2025-03-06 20:57:50,249 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:50,371 - INFO - training batch 701, loss: 0.176, 22432/28000 datapoints
2025-03-06 20:57:50,497 - INFO - training batch 751, loss: 0.121, 24032/28000 datapoints
2025-03-06 20:57:50,620 - INFO - training batch 801, loss: 0.086, 25632/28000 datapoints
2025-03-06 20:57:50,746 - INFO - training batch 851, loss: 0.162, 27232/28000 datapoints
2025-03-06 20:57:50,809 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:57:50,858 - INFO - validation batch 51, loss: 1.396, 1632/6976 datapoints
2025-03-06 20:57:50,907 - INFO - validation batch 101, loss: 0.539, 3232/6976 datapoints
2025-03-06 20:57:50,954 - INFO - validation batch 151, loss: 0.465, 4832/6976 datapoints
2025-03-06 20:57:51,002 - INFO - validation batch 201, loss: 0.427, 6432/6976 datapoints
2025-03-06 20:57:51,017 - INFO - Epoch 502/800 done.
2025-03-06 20:57:51,017 - INFO - Final validation performance:
Loss: 0.592, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:57:51,018 - INFO - Beginning epoch 503/800
2025-03-06 20:57:51,022 - INFO - training batch 1, loss: 0.241, 32/28000 datapoints
2025-03-06 20:57:51,149 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 20:57:51,276 - INFO - training batch 101, loss: 0.079, 3232/28000 datapoints
2025-03-06 20:57:51,406 - INFO - training batch 151, loss: 0.075, 4832/28000 datapoints
2025-03-06 20:57:51,540 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-06 20:57:51,667 - INFO - training batch 251, loss: 0.234, 8032/28000 datapoints
2025-03-06 20:57:51,795 - INFO - training batch 301, loss: 0.295, 9632/28000 datapoints
2025-03-06 20:57:51,923 - INFO - training batch 351, loss: 0.174, 11232/28000 datapoints
2025-03-06 20:57:52,050 - INFO - training batch 401, loss: 0.324, 12832/28000 datapoints
2025-03-06 20:57:52,178 - INFO - training batch 451, loss: 0.157, 14432/28000 datapoints
2025-03-06 20:57:52,307 - INFO - training batch 501, loss: 0.105, 16032/28000 datapoints
2025-03-06 20:57:52,435 - INFO - training batch 551, loss: 0.133, 17632/28000 datapoints
2025-03-06 20:57:52,597 - INFO - training batch 601, loss: 0.070, 19232/28000 datapoints
2025-03-06 20:57:52,732 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:52,856 - INFO - training batch 701, loss: 0.175, 22432/28000 datapoints
2025-03-06 20:57:52,982 - INFO - training batch 751, loss: 0.121, 24032/28000 datapoints
2025-03-06 20:57:53,108 - INFO - training batch 801, loss: 0.086, 25632/28000 datapoints
2025-03-06 20:57:53,235 - INFO - training batch 851, loss: 0.161, 27232/28000 datapoints
2025-03-06 20:57:53,304 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:57:53,357 - INFO - validation batch 51, loss: 1.400, 1632/6976 datapoints
2025-03-06 20:57:53,407 - INFO - validation batch 101, loss: 0.539, 3232/6976 datapoints
2025-03-06 20:57:53,458 - INFO - validation batch 151, loss: 0.466, 4832/6976 datapoints
2025-03-06 20:57:53,508 - INFO - validation batch 201, loss: 0.427, 6432/6976 datapoints
2025-03-06 20:57:53,526 - INFO - Epoch 503/800 done.
2025-03-06 20:57:53,526 - INFO - Final validation performance:
Loss: 0.593, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:53,527 - INFO - Beginning epoch 504/800
2025-03-06 20:57:53,531 - INFO - training batch 1, loss: 0.241, 32/28000 datapoints
2025-03-06 20:57:53,657 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 20:57:53,778 - INFO - training batch 101, loss: 0.079, 3232/28000 datapoints
2025-03-06 20:57:53,900 - INFO - training batch 151, loss: 0.073, 4832/28000 datapoints
2025-03-06 20:57:54,076 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-06 20:57:54,196 - INFO - training batch 251, loss: 0.234, 8032/28000 datapoints
2025-03-06 20:57:54,316 - INFO - training batch 301, loss: 0.294, 9632/28000 datapoints
2025-03-06 20:57:54,437 - INFO - training batch 351, loss: 0.174, 11232/28000 datapoints
2025-03-06 20:57:54,557 - INFO - training batch 401, loss: 0.323, 12832/28000 datapoints
2025-03-06 20:57:54,679 - INFO - training batch 451, loss: 0.160, 14432/28000 datapoints
2025-03-06 20:57:54,799 - INFO - training batch 501, loss: 0.106, 16032/28000 datapoints
2025-03-06 20:57:54,927 - INFO - training batch 551, loss: 0.132, 17632/28000 datapoints
2025-03-06 20:57:55,050 - INFO - training batch 601, loss: 0.069, 19232/28000 datapoints
2025-03-06 20:57:55,177 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:55,317 - INFO - training batch 701, loss: 0.176, 22432/28000 datapoints
2025-03-06 20:57:55,447 - INFO - training batch 751, loss: 0.120, 24032/28000 datapoints
2025-03-06 20:57:55,569 - INFO - training batch 801, loss: 0.085, 25632/28000 datapoints
2025-03-06 20:57:55,692 - INFO - training batch 851, loss: 0.161, 27232/28000 datapoints
2025-03-06 20:57:55,751 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:57:55,795 - INFO - validation batch 51, loss: 1.401, 1632/6976 datapoints
2025-03-06 20:57:55,838 - INFO - validation batch 101, loss: 0.543, 3232/6976 datapoints
2025-03-06 20:57:55,887 - INFO - validation batch 151, loss: 0.467, 4832/6976 datapoints
2025-03-06 20:57:55,932 - INFO - validation batch 201, loss: 0.427, 6432/6976 datapoints
2025-03-06 20:57:55,947 - INFO - Epoch 504/800 done.
2025-03-06 20:57:55,948 - INFO - Final validation performance:
Loss: 0.594, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:55,948 - INFO - Beginning epoch 505/800
2025-03-06 20:57:55,952 - INFO - training batch 1, loss: 0.239, 32/28000 datapoints
2025-03-06 20:57:56,077 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 20:57:56,204 - INFO - training batch 101, loss: 0.078, 3232/28000 datapoints
2025-03-06 20:57:56,325 - INFO - training batch 151, loss: 0.073, 4832/28000 datapoints
2025-03-06 20:57:56,447 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-06 20:57:56,570 - INFO - training batch 251, loss: 0.233, 8032/28000 datapoints
2025-03-06 20:57:56,693 - INFO - training batch 301, loss: 0.292, 9632/28000 datapoints
2025-03-06 20:57:56,816 - INFO - training batch 351, loss: 0.174, 11232/28000 datapoints
2025-03-06 20:57:56,937 - INFO - training batch 401, loss: 0.321, 12832/28000 datapoints
2025-03-06 20:57:57,059 - INFO - training batch 451, loss: 0.157, 14432/28000 datapoints
2025-03-06 20:57:57,189 - INFO - training batch 501, loss: 0.104, 16032/28000 datapoints
2025-03-06 20:57:57,310 - INFO - training batch 551, loss: 0.131, 17632/28000 datapoints
2025-03-06 20:57:57,430 - INFO - training batch 601, loss: 0.069, 19232/28000 datapoints
2025-03-06 20:57:57,551 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:57:57,675 - INFO - training batch 701, loss: 0.175, 22432/28000 datapoints
2025-03-06 20:57:57,795 - INFO - training batch 751, loss: 0.119, 24032/28000 datapoints
2025-03-06 20:57:57,915 - INFO - training batch 801, loss: 0.085, 25632/28000 datapoints
2025-03-06 20:57:58,034 - INFO - training batch 851, loss: 0.159, 27232/28000 datapoints
2025-03-06 20:57:58,096 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:57:58,139 - INFO - validation batch 51, loss: 1.405, 1632/6976 datapoints
2025-03-06 20:57:58,183 - INFO - validation batch 101, loss: 0.544, 3232/6976 datapoints
2025-03-06 20:57:58,226 - INFO - validation batch 151, loss: 0.468, 4832/6976 datapoints
2025-03-06 20:57:58,271 - INFO - validation batch 201, loss: 0.426, 6432/6976 datapoints
2025-03-06 20:57:58,286 - INFO - Epoch 505/800 done.
2025-03-06 20:57:58,286 - INFO - Final validation performance:
Loss: 0.595, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:57:58,287 - INFO - Beginning epoch 506/800
2025-03-06 20:57:58,290 - INFO - training batch 1, loss: 0.239, 32/28000 datapoints
2025-03-06 20:57:58,411 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:57:58,534 - INFO - training batch 101, loss: 0.077, 3232/28000 datapoints
2025-03-06 20:57:58,661 - INFO - training batch 151, loss: 0.072, 4832/28000 datapoints
2025-03-06 20:57:58,781 - INFO - training batch 201, loss: 0.043, 6432/28000 datapoints
2025-03-06 20:57:58,902 - INFO - training batch 251, loss: 0.232, 8032/28000 datapoints
2025-03-06 20:57:59,022 - INFO - training batch 301, loss: 0.290, 9632/28000 datapoints
2025-03-06 20:57:59,145 - INFO - training batch 351, loss: 0.174, 11232/28000 datapoints
2025-03-06 20:57:59,270 - INFO - training batch 401, loss: 0.320, 12832/28000 datapoints
2025-03-06 20:57:59,390 - INFO - training batch 451, loss: 0.159, 14432/28000 datapoints
2025-03-06 20:57:59,513 - INFO - training batch 501, loss: 0.105, 16032/28000 datapoints
2025-03-06 20:57:59,634 - INFO - training batch 551, loss: 0.131, 17632/28000 datapoints
2025-03-06 20:57:59,757 - INFO - training batch 601, loss: 0.069, 19232/28000 datapoints
2025-03-06 20:57:59,879 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:57:59,999 - INFO - training batch 701, loss: 0.174, 22432/28000 datapoints
2025-03-06 20:58:00,124 - INFO - training batch 751, loss: 0.119, 24032/28000 datapoints
2025-03-06 20:58:00,243 - INFO - training batch 801, loss: 0.085, 25632/28000 datapoints
2025-03-06 20:58:00,365 - INFO - training batch 851, loss: 0.158, 27232/28000 datapoints
2025-03-06 20:58:00,425 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 20:58:00,469 - INFO - validation batch 51, loss: 1.406, 1632/6976 datapoints
2025-03-06 20:58:00,513 - INFO - validation batch 101, loss: 0.547, 3232/6976 datapoints
2025-03-06 20:58:00,557 - INFO - validation batch 151, loss: 0.469, 4832/6976 datapoints
2025-03-06 20:58:00,602 - INFO - validation batch 201, loss: 0.427, 6432/6976 datapoints
2025-03-06 20:58:00,617 - INFO - Epoch 506/800 done.
2025-03-06 20:58:00,617 - INFO - Final validation performance:
Loss: 0.596, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:58:00,618 - INFO - Beginning epoch 507/800
2025-03-06 20:58:00,621 - INFO - training batch 1, loss: 0.237, 32/28000 datapoints
2025-03-06 20:58:00,744 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:00,863 - INFO - training batch 101, loss: 0.076, 3232/28000 datapoints
2025-03-06 20:58:00,986 - INFO - training batch 151, loss: 0.071, 4832/28000 datapoints
2025-03-06 20:58:01,110 - INFO - training batch 201, loss: 0.043, 6432/28000 datapoints
2025-03-06 20:58:01,236 - INFO - training batch 251, loss: 0.231, 8032/28000 datapoints
2025-03-06 20:58:01,358 - INFO - training batch 301, loss: 0.288, 9632/28000 datapoints
2025-03-06 20:58:01,478 - INFO - training batch 351, loss: 0.173, 11232/28000 datapoints
2025-03-06 20:58:01,599 - INFO - training batch 401, loss: 0.318, 12832/28000 datapoints
2025-03-06 20:58:01,721 - INFO - training batch 451, loss: 0.159, 14432/28000 datapoints
2025-03-06 20:58:01,847 - INFO - training batch 501, loss: 0.104, 16032/28000 datapoints
2025-03-06 20:58:01,971 - INFO - training batch 551, loss: 0.130, 17632/28000 datapoints
2025-03-06 20:58:02,091 - INFO - training batch 601, loss: 0.068, 19232/28000 datapoints
2025-03-06 20:58:02,212 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-06 20:58:02,332 - INFO - training batch 701, loss: 0.174, 22432/28000 datapoints
2025-03-06 20:58:02,454 - INFO - training batch 751, loss: 0.119, 24032/28000 datapoints
2025-03-06 20:58:02,573 - INFO - training batch 801, loss: 0.085, 25632/28000 datapoints
2025-03-06 20:58:02,695 - INFO - training batch 851, loss: 0.158, 27232/28000 datapoints
2025-03-06 20:58:02,755 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:58:02,798 - INFO - validation batch 51, loss: 1.408, 1632/6976 datapoints
2025-03-06 20:58:02,842 - INFO - validation batch 101, loss: 0.549, 3232/6976 datapoints
2025-03-06 20:58:02,885 - INFO - validation batch 151, loss: 0.471, 4832/6976 datapoints
2025-03-06 20:58:02,929 - INFO - validation batch 201, loss: 0.426, 6432/6976 datapoints
2025-03-06 20:58:02,944 - INFO - Epoch 507/800 done.
2025-03-06 20:58:02,944 - INFO - Final validation performance:
Loss: 0.598, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:58:02,945 - INFO - Beginning epoch 508/800
2025-03-06 20:58:02,948 - INFO - training batch 1, loss: 0.238, 32/28000 datapoints
2025-03-06 20:58:03,072 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:03,196 - INFO - training batch 101, loss: 0.077, 3232/28000 datapoints
2025-03-06 20:58:03,320 - INFO - training batch 151, loss: 0.072, 4832/28000 datapoints
2025-03-06 20:58:03,441 - INFO - training batch 201, loss: 0.043, 6432/28000 datapoints
2025-03-06 20:58:03,562 - INFO - training batch 251, loss: 0.231, 8032/28000 datapoints
2025-03-06 20:58:03,686 - INFO - training batch 301, loss: 0.286, 9632/28000 datapoints
2025-03-06 20:58:03,806 - INFO - training batch 351, loss: 0.173, 11232/28000 datapoints
2025-03-06 20:58:03,924 - INFO - training batch 401, loss: 0.318, 12832/28000 datapoints
2025-03-06 20:58:04,045 - INFO - training batch 451, loss: 0.155, 14432/28000 datapoints
2025-03-06 20:58:04,170 - INFO - training batch 501, loss: 0.102, 16032/28000 datapoints
2025-03-06 20:58:04,291 - INFO - training batch 551, loss: 0.129, 17632/28000 datapoints
2025-03-06 20:58:04,410 - INFO - training batch 601, loss: 0.069, 19232/28000 datapoints
2025-03-06 20:58:04,532 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:04,658 - INFO - training batch 701, loss: 0.173, 22432/28000 datapoints
2025-03-06 20:58:04,778 - INFO - training batch 751, loss: 0.117, 24032/28000 datapoints
2025-03-06 20:58:04,905 - INFO - training batch 801, loss: 0.084, 25632/28000 datapoints
2025-03-06 20:58:05,028 - INFO - training batch 851, loss: 0.157, 27232/28000 datapoints
2025-03-06 20:58:05,089 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 20:58:05,136 - INFO - validation batch 51, loss: 1.411, 1632/6976 datapoints
2025-03-06 20:58:05,181 - INFO - validation batch 101, loss: 0.552, 3232/6976 datapoints
2025-03-06 20:58:05,229 - INFO - validation batch 151, loss: 0.471, 4832/6976 datapoints
2025-03-06 20:58:05,274 - INFO - validation batch 201, loss: 0.428, 6432/6976 datapoints
2025-03-06 20:58:05,289 - INFO - Epoch 508/800 done.
2025-03-06 20:58:05,289 - INFO - Final validation performance:
Loss: 0.599, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:58:05,290 - INFO - Beginning epoch 509/800
2025-03-06 20:58:05,293 - INFO - training batch 1, loss: 0.236, 32/28000 datapoints
2025-03-06 20:58:05,444 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:05,566 - INFO - training batch 101, loss: 0.077, 3232/28000 datapoints
2025-03-06 20:58:05,693 - INFO - training batch 151, loss: 0.071, 4832/28000 datapoints
2025-03-06 20:58:05,812 - INFO - training batch 201, loss: 0.043, 6432/28000 datapoints
2025-03-06 20:58:05,934 - INFO - training batch 251, loss: 0.230, 8032/28000 datapoints
2025-03-06 20:58:06,054 - INFO - training batch 301, loss: 0.284, 9632/28000 datapoints
2025-03-06 20:58:06,174 - INFO - training batch 351, loss: 0.173, 11232/28000 datapoints
2025-03-06 20:58:06,295 - INFO - training batch 401, loss: 0.316, 12832/28000 datapoints
2025-03-06 20:58:06,415 - INFO - training batch 451, loss: 0.158, 14432/28000 datapoints
2025-03-06 20:58:06,535 - INFO - training batch 501, loss: 0.103, 16032/28000 datapoints
2025-03-06 20:58:06,657 - INFO - training batch 551, loss: 0.129, 17632/28000 datapoints
2025-03-06 20:58:06,779 - INFO - training batch 601, loss: 0.067, 19232/28000 datapoints
2025-03-06 20:58:06,900 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:07,022 - INFO - training batch 701, loss: 0.172, 22432/28000 datapoints
2025-03-06 20:58:07,141 - INFO - training batch 751, loss: 0.117, 24032/28000 datapoints
2025-03-06 20:58:07,270 - INFO - training batch 801, loss: 0.084, 25632/28000 datapoints
2025-03-06 20:58:07,391 - INFO - training batch 851, loss: 0.156, 27232/28000 datapoints
2025-03-06 20:58:07,450 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:58:07,495 - INFO - validation batch 51, loss: 1.413, 1632/6976 datapoints
2025-03-06 20:58:07,539 - INFO - validation batch 101, loss: 0.554, 3232/6976 datapoints
2025-03-06 20:58:07,582 - INFO - validation batch 151, loss: 0.472, 4832/6976 datapoints
2025-03-06 20:58:07,626 - INFO - validation batch 201, loss: 0.428, 6432/6976 datapoints
2025-03-06 20:58:07,645 - INFO - Epoch 509/800 done.
2025-03-06 20:58:07,645 - INFO - Final validation performance:
Loss: 0.600, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:07,645 - INFO - Beginning epoch 510/800
2025-03-06 20:58:07,649 - INFO - training batch 1, loss: 0.236, 32/28000 datapoints
2025-03-06 20:58:07,776 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:07,921 - INFO - training batch 101, loss: 0.076, 3232/28000 datapoints
2025-03-06 20:58:08,077 - INFO - training batch 151, loss: 0.071, 4832/28000 datapoints
2025-03-06 20:58:08,230 - INFO - training batch 201, loss: 0.042, 6432/28000 datapoints
2025-03-06 20:58:08,365 - INFO - training batch 251, loss: 0.229, 8032/28000 datapoints
2025-03-06 20:58:08,505 - INFO - training batch 301, loss: 0.282, 9632/28000 datapoints
2025-03-06 20:58:08,632 - INFO - training batch 351, loss: 0.172, 11232/28000 datapoints
2025-03-06 20:58:08,758 - INFO - training batch 401, loss: 0.316, 12832/28000 datapoints
2025-03-06 20:58:08,880 - INFO - training batch 451, loss: 0.154, 14432/28000 datapoints
2025-03-06 20:58:09,001 - INFO - training batch 501, loss: 0.102, 16032/28000 datapoints
2025-03-06 20:58:09,127 - INFO - training batch 551, loss: 0.127, 17632/28000 datapoints
2025-03-06 20:58:09,252 - INFO - training batch 601, loss: 0.067, 19232/28000 datapoints
2025-03-06 20:58:09,373 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:09,501 - INFO - training batch 701, loss: 0.172, 22432/28000 datapoints
2025-03-06 20:58:09,626 - INFO - training batch 751, loss: 0.116, 24032/28000 datapoints
2025-03-06 20:58:09,762 - INFO - training batch 801, loss: 0.084, 25632/28000 datapoints
2025-03-06 20:58:09,897 - INFO - training batch 851, loss: 0.155, 27232/28000 datapoints
2025-03-06 20:58:09,959 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:58:10,007 - INFO - validation batch 51, loss: 1.419, 1632/6976 datapoints
2025-03-06 20:58:10,053 - INFO - validation batch 101, loss: 0.555, 3232/6976 datapoints
2025-03-06 20:58:10,101 - INFO - validation batch 151, loss: 0.474, 4832/6976 datapoints
2025-03-06 20:58:10,153 - INFO - validation batch 201, loss: 0.428, 6432/6976 datapoints
2025-03-06 20:58:10,169 - INFO - Epoch 510/800 done.
2025-03-06 20:58:10,169 - INFO - Final validation performance:
Loss: 0.602, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:10,170 - INFO - Beginning epoch 511/800
2025-03-06 20:58:10,174 - INFO - training batch 1, loss: 0.237, 32/28000 datapoints
2025-03-06 20:58:10,304 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:10,432 - INFO - training batch 101, loss: 0.076, 3232/28000 datapoints
2025-03-06 20:58:10,558 - INFO - training batch 151, loss: 0.070, 4832/28000 datapoints
2025-03-06 20:58:10,689 - INFO - training batch 201, loss: 0.042, 6432/28000 datapoints
2025-03-06 20:58:10,815 - INFO - training batch 251, loss: 0.229, 8032/28000 datapoints
2025-03-06 20:58:10,939 - INFO - training batch 301, loss: 0.280, 9632/28000 datapoints
2025-03-06 20:58:11,063 - INFO - training batch 351, loss: 0.174, 11232/28000 datapoints
2025-03-06 20:58:11,188 - INFO - training batch 401, loss: 0.313, 12832/28000 datapoints
2025-03-06 20:58:11,318 - INFO - training batch 451, loss: 0.157, 14432/28000 datapoints
2025-03-06 20:58:11,441 - INFO - training batch 501, loss: 0.102, 16032/28000 datapoints
2025-03-06 20:58:11,565 - INFO - training batch 551, loss: 0.127, 17632/28000 datapoints
2025-03-06 20:58:11,690 - INFO - training batch 601, loss: 0.066, 19232/28000 datapoints
2025-03-06 20:58:11,819 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:11,945 - INFO - training batch 701, loss: 0.171, 22432/28000 datapoints
2025-03-06 20:58:12,068 - INFO - training batch 751, loss: 0.115, 24032/28000 datapoints
2025-03-06 20:58:12,192 - INFO - training batch 801, loss: 0.084, 25632/28000 datapoints
2025-03-06 20:58:12,317 - INFO - training batch 851, loss: 0.155, 27232/28000 datapoints
2025-03-06 20:58:12,381 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:58:12,429 - INFO - validation batch 51, loss: 1.422, 1632/6976 datapoints
2025-03-06 20:58:12,474 - INFO - validation batch 101, loss: 0.559, 3232/6976 datapoints
2025-03-06 20:58:12,519 - INFO - validation batch 151, loss: 0.473, 4832/6976 datapoints
2025-03-06 20:58:12,563 - INFO - validation batch 201, loss: 0.429, 6432/6976 datapoints
2025-03-06 20:58:12,578 - INFO - Epoch 511/800 done.
2025-03-06 20:58:12,579 - INFO - Final validation performance:
Loss: 0.603, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:12,579 - INFO - Beginning epoch 512/800
2025-03-06 20:58:12,583 - INFO - training batch 1, loss: 0.234, 32/28000 datapoints
2025-03-06 20:58:12,711 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:12,836 - INFO - training batch 101, loss: 0.075, 3232/28000 datapoints
2025-03-06 20:58:12,957 - INFO - training batch 151, loss: 0.069, 4832/28000 datapoints
2025-03-06 20:58:13,078 - INFO - training batch 201, loss: 0.042, 6432/28000 datapoints
2025-03-06 20:58:13,198 - INFO - training batch 251, loss: 0.228, 8032/28000 datapoints
2025-03-06 20:58:13,327 - INFO - training batch 301, loss: 0.278, 9632/28000 datapoints
2025-03-06 20:58:13,447 - INFO - training batch 351, loss: 0.172, 11232/28000 datapoints
2025-03-06 20:58:13,567 - INFO - training batch 401, loss: 0.312, 12832/28000 datapoints
2025-03-06 20:58:13,690 - INFO - training batch 451, loss: 0.156, 14432/28000 datapoints
2025-03-06 20:58:13,813 - INFO - training batch 501, loss: 0.100, 16032/28000 datapoints
2025-03-06 20:58:13,933 - INFO - training batch 551, loss: 0.127, 17632/28000 datapoints
2025-03-06 20:58:14,053 - INFO - training batch 601, loss: 0.066, 19232/28000 datapoints
2025-03-06 20:58:14,174 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:14,298 - INFO - training batch 701, loss: 0.170, 22432/28000 datapoints
2025-03-06 20:58:14,417 - INFO - training batch 751, loss: 0.115, 24032/28000 datapoints
2025-03-06 20:58:14,536 - INFO - training batch 801, loss: 0.083, 25632/28000 datapoints
2025-03-06 20:58:14,659 - INFO - training batch 851, loss: 0.154, 27232/28000 datapoints
2025-03-06 20:58:14,720 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:58:14,766 - INFO - validation batch 51, loss: 1.423, 1632/6976 datapoints
2025-03-06 20:58:14,810 - INFO - validation batch 101, loss: 0.561, 3232/6976 datapoints
2025-03-06 20:58:14,855 - INFO - validation batch 151, loss: 0.476, 4832/6976 datapoints
2025-03-06 20:58:14,903 - INFO - validation batch 201, loss: 0.429, 6432/6976 datapoints
2025-03-06 20:58:14,918 - INFO - Epoch 512/800 done.
2025-03-06 20:58:14,918 - INFO - Final validation performance:
Loss: 0.605, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:58:14,919 - INFO - Beginning epoch 513/800
2025-03-06 20:58:14,922 - INFO - training batch 1, loss: 0.235, 32/28000 datapoints
2025-03-06 20:58:15,044 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:15,166 - INFO - training batch 101, loss: 0.076, 3232/28000 datapoints
2025-03-06 20:58:15,290 - INFO - training batch 151, loss: 0.068, 4832/28000 datapoints
2025-03-06 20:58:15,413 - INFO - training batch 201, loss: 0.042, 6432/28000 datapoints
2025-03-06 20:58:15,563 - INFO - training batch 251, loss: 0.227, 8032/28000 datapoints
2025-03-06 20:58:15,689 - INFO - training batch 301, loss: 0.277, 9632/28000 datapoints
2025-03-06 20:58:15,811 - INFO - training batch 351, loss: 0.171, 11232/28000 datapoints
2025-03-06 20:58:15,932 - INFO - training batch 401, loss: 0.310, 12832/28000 datapoints
2025-03-06 20:58:16,053 - INFO - training batch 451, loss: 0.153, 14432/28000 datapoints
2025-03-06 20:58:16,172 - INFO - training batch 501, loss: 0.100, 16032/28000 datapoints
2025-03-06 20:58:16,294 - INFO - training batch 551, loss: 0.126, 17632/28000 datapoints
2025-03-06 20:58:16,414 - INFO - training batch 601, loss: 0.066, 19232/28000 datapoints
2025-03-06 20:58:16,535 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:16,658 - INFO - training batch 701, loss: 0.170, 22432/28000 datapoints
2025-03-06 20:58:16,779 - INFO - training batch 751, loss: 0.115, 24032/28000 datapoints
2025-03-06 20:58:16,901 - INFO - training batch 801, loss: 0.083, 25632/28000 datapoints
2025-03-06 20:58:17,022 - INFO - training batch 851, loss: 0.153, 27232/28000 datapoints
2025-03-06 20:58:17,081 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:58:17,126 - INFO - validation batch 51, loss: 1.427, 1632/6976 datapoints
2025-03-06 20:58:17,170 - INFO - validation batch 101, loss: 0.562, 3232/6976 datapoints
2025-03-06 20:58:17,215 - INFO - validation batch 151, loss: 0.477, 4832/6976 datapoints
2025-03-06 20:58:17,263 - INFO - validation batch 201, loss: 0.429, 6432/6976 datapoints
2025-03-06 20:58:17,278 - INFO - Epoch 513/800 done.
2025-03-06 20:58:17,278 - INFO - Final validation performance:
Loss: 0.606, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:17,279 - INFO - Beginning epoch 514/800
2025-03-06 20:58:17,282 - INFO - training batch 1, loss: 0.235, 32/28000 datapoints
2025-03-06 20:58:17,406 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:17,528 - INFO - training batch 101, loss: 0.075, 3232/28000 datapoints
2025-03-06 20:58:17,651 - INFO - training batch 151, loss: 0.068, 4832/28000 datapoints
2025-03-06 20:58:17,773 - INFO - training batch 201, loss: 0.042, 6432/28000 datapoints
2025-03-06 20:58:17,893 - INFO - training batch 251, loss: 0.227, 8032/28000 datapoints
2025-03-06 20:58:18,013 - INFO - training batch 301, loss: 0.275, 9632/28000 datapoints
2025-03-06 20:58:18,133 - INFO - training batch 351, loss: 0.173, 11232/28000 datapoints
2025-03-06 20:58:18,252 - INFO - training batch 401, loss: 0.309, 12832/28000 datapoints
2025-03-06 20:58:18,373 - INFO - training batch 451, loss: 0.156, 14432/28000 datapoints
2025-03-06 20:58:18,494 - INFO - training batch 501, loss: 0.101, 16032/28000 datapoints
2025-03-06 20:58:18,614 - INFO - training batch 551, loss: 0.125, 17632/28000 datapoints
2025-03-06 20:58:18,736 - INFO - training batch 601, loss: 0.065, 19232/28000 datapoints
2025-03-06 20:58:18,858 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:18,978 - INFO - training batch 701, loss: 0.169, 22432/28000 datapoints
2025-03-06 20:58:19,097 - INFO - training batch 751, loss: 0.114, 24032/28000 datapoints
2025-03-06 20:58:19,218 - INFO - training batch 801, loss: 0.083, 25632/28000 datapoints
2025-03-06 20:58:19,343 - INFO - training batch 851, loss: 0.153, 27232/28000 datapoints
2025-03-06 20:58:19,405 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:58:19,449 - INFO - validation batch 51, loss: 1.431, 1632/6976 datapoints
2025-03-06 20:58:19,494 - INFO - validation batch 101, loss: 0.565, 3232/6976 datapoints
2025-03-06 20:58:19,538 - INFO - validation batch 151, loss: 0.476, 4832/6976 datapoints
2025-03-06 20:58:19,582 - INFO - validation batch 201, loss: 0.429, 6432/6976 datapoints
2025-03-06 20:58:19,597 - INFO - Epoch 514/800 done.
2025-03-06 20:58:19,597 - INFO - Final validation performance:
Loss: 0.607, top-1 acc: 0.869top-5 acc: 0.869
2025-03-06 20:58:19,598 - INFO - Beginning epoch 515/800
2025-03-06 20:58:19,601 - INFO - training batch 1, loss: 0.233, 32/28000 datapoints
2025-03-06 20:58:19,726 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:19,849 - INFO - training batch 101, loss: 0.076, 3232/28000 datapoints
2025-03-06 20:58:19,971 - INFO - training batch 151, loss: 0.067, 4832/28000 datapoints
2025-03-06 20:58:20,093 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-06 20:58:20,217 - INFO - training batch 251, loss: 0.227, 8032/28000 datapoints
2025-03-06 20:58:20,338 - INFO - training batch 301, loss: 0.273, 9632/28000 datapoints
2025-03-06 20:58:20,459 - INFO - training batch 351, loss: 0.173, 11232/28000 datapoints
2025-03-06 20:58:20,579 - INFO - training batch 401, loss: 0.308, 12832/28000 datapoints
2025-03-06 20:58:20,720 - INFO - training batch 451, loss: 0.152, 14432/28000 datapoints
2025-03-06 20:58:20,843 - INFO - training batch 501, loss: 0.099, 16032/28000 datapoints
2025-03-06 20:58:20,963 - INFO - training batch 551, loss: 0.124, 17632/28000 datapoints
2025-03-06 20:58:21,083 - INFO - training batch 601, loss: 0.065, 19232/28000 datapoints
2025-03-06 20:58:21,202 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:21,328 - INFO - training batch 701, loss: 0.169, 22432/28000 datapoints
2025-03-06 20:58:21,450 - INFO - training batch 751, loss: 0.113, 24032/28000 datapoints
2025-03-06 20:58:21,575 - INFO - training batch 801, loss: 0.083, 25632/28000 datapoints
2025-03-06 20:58:21,699 - INFO - training batch 851, loss: 0.152, 27232/28000 datapoints
2025-03-06 20:58:21,758 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 20:58:21,807 - INFO - validation batch 51, loss: 1.435, 1632/6976 datapoints
2025-03-06 20:58:21,855 - INFO - validation batch 101, loss: 0.567, 3232/6976 datapoints
2025-03-06 20:58:21,899 - INFO - validation batch 151, loss: 0.478, 4832/6976 datapoints
2025-03-06 20:58:21,944 - INFO - validation batch 201, loss: 0.429, 6432/6976 datapoints
2025-03-06 20:58:21,959 - INFO - Epoch 515/800 done.
2025-03-06 20:58:21,959 - INFO - Final validation performance:
Loss: 0.609, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:21,959 - INFO - Beginning epoch 516/800
2025-03-06 20:58:21,963 - INFO - training batch 1, loss: 0.233, 32/28000 datapoints
2025-03-06 20:58:22,085 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:22,207 - INFO - training batch 101, loss: 0.076, 3232/28000 datapoints
2025-03-06 20:58:22,331 - INFO - training batch 151, loss: 0.067, 4832/28000 datapoints
2025-03-06 20:58:22,453 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-06 20:58:22,575 - INFO - training batch 251, loss: 0.226, 8032/28000 datapoints
2025-03-06 20:58:22,699 - INFO - training batch 301, loss: 0.272, 9632/28000 datapoints
2025-03-06 20:58:22,820 - INFO - training batch 351, loss: 0.172, 11232/28000 datapoints
2025-03-06 20:58:22,943 - INFO - training batch 401, loss: 0.307, 12832/28000 datapoints
2025-03-06 20:58:23,064 - INFO - training batch 451, loss: 0.154, 14432/28000 datapoints
2025-03-06 20:58:23,184 - INFO - training batch 501, loss: 0.099, 16032/28000 datapoints
2025-03-06 20:58:23,309 - INFO - training batch 551, loss: 0.124, 17632/28000 datapoints
2025-03-06 20:58:23,432 - INFO - training batch 601, loss: 0.065, 19232/28000 datapoints
2025-03-06 20:58:23,553 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:23,677 - INFO - training batch 701, loss: 0.168, 22432/28000 datapoints
2025-03-06 20:58:23,798 - INFO - training batch 751, loss: 0.113, 24032/28000 datapoints
2025-03-06 20:58:23,920 - INFO - training batch 801, loss: 0.082, 25632/28000 datapoints
2025-03-06 20:58:24,041 - INFO - training batch 851, loss: 0.151, 27232/28000 datapoints
2025-03-06 20:58:24,100 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:58:24,145 - INFO - validation batch 51, loss: 1.439, 1632/6976 datapoints
2025-03-06 20:58:24,189 - INFO - validation batch 101, loss: 0.568, 3232/6976 datapoints
2025-03-06 20:58:24,233 - INFO - validation batch 151, loss: 0.479, 4832/6976 datapoints
2025-03-06 20:58:24,276 - INFO - validation batch 201, loss: 0.430, 6432/6976 datapoints
2025-03-06 20:58:24,291 - INFO - Epoch 516/800 done.
2025-03-06 20:58:24,291 - INFO - Final validation performance:
Loss: 0.610, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:24,291 - INFO - Beginning epoch 517/800
2025-03-06 20:58:24,295 - INFO - training batch 1, loss: 0.233, 32/28000 datapoints
2025-03-06 20:58:24,420 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:24,541 - INFO - training batch 101, loss: 0.075, 3232/28000 datapoints
2025-03-06 20:58:24,664 - INFO - training batch 151, loss: 0.066, 4832/28000 datapoints
2025-03-06 20:58:24,784 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-06 20:58:24,912 - INFO - training batch 251, loss: 0.226, 8032/28000 datapoints
2025-03-06 20:58:25,034 - INFO - training batch 301, loss: 0.269, 9632/28000 datapoints
2025-03-06 20:58:25,156 - INFO - training batch 351, loss: 0.172, 11232/28000 datapoints
2025-03-06 20:58:25,275 - INFO - training batch 401, loss: 0.305, 12832/28000 datapoints
2025-03-06 20:58:25,407 - INFO - training batch 451, loss: 0.150, 14432/28000 datapoints
2025-03-06 20:58:25,530 - INFO - training batch 501, loss: 0.098, 16032/28000 datapoints
2025-03-06 20:58:25,680 - INFO - training batch 551, loss: 0.123, 17632/28000 datapoints
2025-03-06 20:58:25,800 - INFO - training batch 601, loss: 0.064, 19232/28000 datapoints
2025-03-06 20:58:25,922 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:26,044 - INFO - training batch 701, loss: 0.167, 22432/28000 datapoints
2025-03-06 20:58:26,164 - INFO - training batch 751, loss: 0.112, 24032/28000 datapoints
2025-03-06 20:58:26,284 - INFO - training batch 801, loss: 0.082, 25632/28000 datapoints
2025-03-06 20:58:26,406 - INFO - training batch 851, loss: 0.150, 27232/28000 datapoints
2025-03-06 20:58:26,466 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 20:58:26,510 - INFO - validation batch 51, loss: 1.441, 1632/6976 datapoints
2025-03-06 20:58:26,555 - INFO - validation batch 101, loss: 0.571, 3232/6976 datapoints
2025-03-06 20:58:26,599 - INFO - validation batch 151, loss: 0.480, 4832/6976 datapoints
2025-03-06 20:58:26,646 - INFO - validation batch 201, loss: 0.430, 6432/6976 datapoints
2025-03-06 20:58:26,661 - INFO - Epoch 517/800 done.
2025-03-06 20:58:26,662 - INFO - Final validation performance:
Loss: 0.611, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:26,662 - INFO - Beginning epoch 518/800
2025-03-06 20:58:26,666 - INFO - training batch 1, loss: 0.232, 32/28000 datapoints
2025-03-06 20:58:26,787 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:26,910 - INFO - training batch 101, loss: 0.075, 3232/28000 datapoints
2025-03-06 20:58:27,034 - INFO - training batch 151, loss: 0.066, 4832/28000 datapoints
2025-03-06 20:58:27,154 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-06 20:58:27,275 - INFO - training batch 251, loss: 0.225, 8032/28000 datapoints
2025-03-06 20:58:27,406 - INFO - training batch 301, loss: 0.267, 9632/28000 datapoints
2025-03-06 20:58:27,530 - INFO - training batch 351, loss: 0.171, 11232/28000 datapoints
2025-03-06 20:58:27,653 - INFO - training batch 401, loss: 0.303, 12832/28000 datapoints
2025-03-06 20:58:27,775 - INFO - training batch 451, loss: 0.153, 14432/28000 datapoints
2025-03-06 20:58:27,897 - INFO - training batch 501, loss: 0.099, 16032/28000 datapoints
2025-03-06 20:58:28,029 - INFO - training batch 551, loss: 0.122, 17632/28000 datapoints
2025-03-06 20:58:28,164 - INFO - training batch 601, loss: 0.064, 19232/28000 datapoints
2025-03-06 20:58:28,297 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:28,419 - INFO - training batch 701, loss: 0.166, 22432/28000 datapoints
2025-03-06 20:58:28,540 - INFO - training batch 751, loss: 0.111, 24032/28000 datapoints
2025-03-06 20:58:28,662 - INFO - training batch 801, loss: 0.082, 25632/28000 datapoints
2025-03-06 20:58:28,782 - INFO - training batch 851, loss: 0.149, 27232/28000 datapoints
2025-03-06 20:58:28,843 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:58:28,886 - INFO - validation batch 51, loss: 1.446, 1632/6976 datapoints
2025-03-06 20:58:28,930 - INFO - validation batch 101, loss: 0.572, 3232/6976 datapoints
2025-03-06 20:58:28,975 - INFO - validation batch 151, loss: 0.481, 4832/6976 datapoints
2025-03-06 20:58:29,019 - INFO - validation batch 201, loss: 0.430, 6432/6976 datapoints
2025-03-06 20:58:29,034 - INFO - Epoch 518/800 done.
2025-03-06 20:58:29,034 - INFO - Final validation performance:
Loss: 0.613, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:29,035 - INFO - Beginning epoch 519/800
2025-03-06 20:58:29,038 - INFO - training batch 1, loss: 0.232, 32/28000 datapoints
2025-03-06 20:58:29,161 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:29,283 - INFO - training batch 101, loss: 0.075, 3232/28000 datapoints
2025-03-06 20:58:29,407 - INFO - training batch 151, loss: 0.065, 4832/28000 datapoints
2025-03-06 20:58:29,536 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-06 20:58:29,664 - INFO - training batch 251, loss: 0.225, 8032/28000 datapoints
2025-03-06 20:58:29,790 - INFO - training batch 301, loss: 0.264, 9632/28000 datapoints
2025-03-06 20:58:29,915 - INFO - training batch 351, loss: 0.171, 11232/28000 datapoints
2025-03-06 20:58:30,041 - INFO - training batch 401, loss: 0.303, 12832/28000 datapoints
2025-03-06 20:58:30,167 - INFO - training batch 451, loss: 0.149, 14432/28000 datapoints
2025-03-06 20:58:30,293 - INFO - training batch 501, loss: 0.097, 16032/28000 datapoints
2025-03-06 20:58:30,419 - INFO - training batch 551, loss: 0.122, 17632/28000 datapoints
2025-03-06 20:58:30,545 - INFO - training batch 601, loss: 0.064, 19232/28000 datapoints
2025-03-06 20:58:30,675 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:30,800 - INFO - training batch 701, loss: 0.166, 22432/28000 datapoints
2025-03-06 20:58:30,925 - INFO - training batch 751, loss: 0.111, 24032/28000 datapoints
2025-03-06 20:58:31,051 - INFO - training batch 801, loss: 0.081, 25632/28000 datapoints
2025-03-06 20:58:31,173 - INFO - training batch 851, loss: 0.148, 27232/28000 datapoints
2025-03-06 20:58:31,236 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 20:58:31,286 - INFO - validation batch 51, loss: 1.447, 1632/6976 datapoints
2025-03-06 20:58:31,337 - INFO - validation batch 101, loss: 0.576, 3232/6976 datapoints
2025-03-06 20:58:31,385 - INFO - validation batch 151, loss: 0.482, 4832/6976 datapoints
2025-03-06 20:58:31,431 - INFO - validation batch 201, loss: 0.430, 6432/6976 datapoints
2025-03-06 20:58:31,446 - INFO - Epoch 519/800 done.
2025-03-06 20:58:31,446 - INFO - Final validation performance:
Loss: 0.614, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:31,447 - INFO - Beginning epoch 520/800
2025-03-06 20:58:31,450 - INFO - training batch 1, loss: 0.231, 32/28000 datapoints
2025-03-06 20:58:31,595 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:31,719 - INFO - training batch 101, loss: 0.075, 3232/28000 datapoints
2025-03-06 20:58:31,844 - INFO - training batch 151, loss: 0.065, 4832/28000 datapoints
2025-03-06 20:58:31,967 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-06 20:58:32,090 - INFO - training batch 251, loss: 0.224, 8032/28000 datapoints
2025-03-06 20:58:32,220 - INFO - training batch 301, loss: 0.263, 9632/28000 datapoints
2025-03-06 20:58:32,351 - INFO - training batch 351, loss: 0.171, 11232/28000 datapoints
2025-03-06 20:58:32,474 - INFO - training batch 401, loss: 0.302, 12832/28000 datapoints
2025-03-06 20:58:32,598 - INFO - training batch 451, loss: 0.153, 14432/28000 datapoints
2025-03-06 20:58:32,722 - INFO - training batch 501, loss: 0.098, 16032/28000 datapoints
2025-03-06 20:58:32,843 - INFO - training batch 551, loss: 0.121, 17632/28000 datapoints
2025-03-06 20:58:32,963 - INFO - training batch 601, loss: 0.063, 19232/28000 datapoints
2025-03-06 20:58:33,086 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:33,205 - INFO - training batch 701, loss: 0.165, 22432/28000 datapoints
2025-03-06 20:58:33,332 - INFO - training batch 751, loss: 0.111, 24032/28000 datapoints
2025-03-06 20:58:33,455 - INFO - training batch 801, loss: 0.081, 25632/28000 datapoints
2025-03-06 20:58:33,577 - INFO - training batch 851, loss: 0.148, 27232/28000 datapoints
2025-03-06 20:58:33,639 - INFO - validation batch 1, loss: 0.137, 32/6976 datapoints
2025-03-06 20:58:33,686 - INFO - validation batch 51, loss: 1.450, 1632/6976 datapoints
2025-03-06 20:58:33,729 - INFO - validation batch 101, loss: 0.578, 3232/6976 datapoints
2025-03-06 20:58:33,773 - INFO - validation batch 151, loss: 0.482, 4832/6976 datapoints
2025-03-06 20:58:33,817 - INFO - validation batch 201, loss: 0.431, 6432/6976 datapoints
2025-03-06 20:58:33,838 - INFO - Epoch 520/800 done.
2025-03-06 20:58:33,838 - INFO - Final validation performance:
Loss: 0.615, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:33,839 - INFO - Beginning epoch 521/800
2025-03-06 20:58:33,842 - INFO - training batch 1, loss: 0.231, 32/28000 datapoints
2025-03-06 20:58:33,966 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:34,090 - INFO - training batch 101, loss: 0.074, 3232/28000 datapoints
2025-03-06 20:58:34,212 - INFO - training batch 151, loss: 0.065, 4832/28000 datapoints
2025-03-06 20:58:34,336 - INFO - training batch 201, loss: 0.040, 6432/28000 datapoints
2025-03-06 20:58:34,456 - INFO - training batch 251, loss: 0.224, 8032/28000 datapoints
2025-03-06 20:58:34,577 - INFO - training batch 301, loss: 0.261, 9632/28000 datapoints
2025-03-06 20:58:34,700 - INFO - training batch 351, loss: 0.169, 11232/28000 datapoints
2025-03-06 20:58:34,820 - INFO - training batch 401, loss: 0.300, 12832/28000 datapoints
2025-03-06 20:58:34,949 - INFO - training batch 451, loss: 0.151, 14432/28000 datapoints
2025-03-06 20:58:35,071 - INFO - training batch 501, loss: 0.096, 16032/28000 datapoints
2025-03-06 20:58:35,192 - INFO - training batch 551, loss: 0.120, 17632/28000 datapoints
2025-03-06 20:58:35,313 - INFO - training batch 601, loss: 0.063, 19232/28000 datapoints
2025-03-06 20:58:35,436 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:35,558 - INFO - training batch 701, loss: 0.165, 22432/28000 datapoints
2025-03-06 20:58:35,701 - INFO - training batch 751, loss: 0.109, 24032/28000 datapoints
2025-03-06 20:58:35,829 - INFO - training batch 801, loss: 0.081, 25632/28000 datapoints
2025-03-06 20:58:35,954 - INFO - training batch 851, loss: 0.147, 27232/28000 datapoints
2025-03-06 20:58:36,015 - INFO - validation batch 1, loss: 0.137, 32/6976 datapoints
2025-03-06 20:58:36,061 - INFO - validation batch 51, loss: 1.456, 1632/6976 datapoints
2025-03-06 20:58:36,105 - INFO - validation batch 101, loss: 0.579, 3232/6976 datapoints
2025-03-06 20:58:36,149 - INFO - validation batch 151, loss: 0.485, 4832/6976 datapoints
2025-03-06 20:58:36,193 - INFO - validation batch 201, loss: 0.431, 6432/6976 datapoints
2025-03-06 20:58:36,208 - INFO - Epoch 521/800 done.
2025-03-06 20:58:36,208 - INFO - Final validation performance:
Loss: 0.618, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:36,209 - INFO - Beginning epoch 522/800
2025-03-06 20:58:36,212 - INFO - training batch 1, loss: 0.231, 32/28000 datapoints
2025-03-06 20:58:36,335 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-06 20:58:36,457 - INFO - training batch 101, loss: 0.074, 3232/28000 datapoints
2025-03-06 20:58:36,581 - INFO - training batch 151, loss: 0.064, 4832/28000 datapoints
2025-03-06 20:58:36,704 - INFO - training batch 201, loss: 0.040, 6432/28000 datapoints
2025-03-06 20:58:36,824 - INFO - training batch 251, loss: 0.223, 8032/28000 datapoints
2025-03-06 20:58:36,945 - INFO - training batch 301, loss: 0.259, 9632/28000 datapoints
2025-03-06 20:58:37,067 - INFO - training batch 351, loss: 0.171, 11232/28000 datapoints
2025-03-06 20:58:37,186 - INFO - training batch 401, loss: 0.299, 12832/28000 datapoints
2025-03-06 20:58:37,307 - INFO - training batch 451, loss: 0.148, 14432/28000 datapoints
2025-03-06 20:58:37,431 - INFO - training batch 501, loss: 0.096, 16032/28000 datapoints
2025-03-06 20:58:37,553 - INFO - training batch 551, loss: 0.120, 17632/28000 datapoints
2025-03-06 20:58:37,710 - INFO - training batch 601, loss: 0.063, 19232/28000 datapoints
2025-03-06 20:58:37,832 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:37,953 - INFO - training batch 701, loss: 0.164, 22432/28000 datapoints
2025-03-06 20:58:38,084 - INFO - training batch 751, loss: 0.109, 24032/28000 datapoints
2025-03-06 20:58:38,208 - INFO - training batch 801, loss: 0.081, 25632/28000 datapoints
2025-03-06 20:58:38,329 - INFO - training batch 851, loss: 0.146, 27232/28000 datapoints
2025-03-06 20:58:38,394 - INFO - validation batch 1, loss: 0.137, 32/6976 datapoints
2025-03-06 20:58:38,437 - INFO - validation batch 51, loss: 1.458, 1632/6976 datapoints
2025-03-06 20:58:38,481 - INFO - validation batch 101, loss: 0.582, 3232/6976 datapoints
2025-03-06 20:58:38,525 - INFO - validation batch 151, loss: 0.485, 4832/6976 datapoints
2025-03-06 20:58:38,570 - INFO - validation batch 201, loss: 0.432, 6432/6976 datapoints
2025-03-06 20:58:38,586 - INFO - Epoch 522/800 done.
2025-03-06 20:58:38,586 - INFO - Final validation performance:
Loss: 0.619, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:38,586 - INFO - Beginning epoch 523/800
2025-03-06 20:58:38,590 - INFO - training batch 1, loss: 0.230, 32/28000 datapoints
2025-03-06 20:58:38,714 - INFO - training batch 51, loss: 0.060, 1632/28000 datapoints
2025-03-06 20:58:38,835 - INFO - training batch 101, loss: 0.074, 3232/28000 datapoints
2025-03-06 20:58:38,958 - INFO - training batch 151, loss: 0.064, 4832/28000 datapoints
2025-03-06 20:58:39,090 - INFO - training batch 201, loss: 0.040, 6432/28000 datapoints
2025-03-06 20:58:39,211 - INFO - training batch 251, loss: 0.223, 8032/28000 datapoints
2025-03-06 20:58:39,331 - INFO - training batch 301, loss: 0.258, 9632/28000 datapoints
2025-03-06 20:58:39,456 - INFO - training batch 351, loss: 0.170, 11232/28000 datapoints
2025-03-06 20:58:39,579 - INFO - training batch 401, loss: 0.298, 12832/28000 datapoints
2025-03-06 20:58:39,703 - INFO - training batch 451, loss: 0.151, 14432/28000 datapoints
2025-03-06 20:58:39,824 - INFO - training batch 501, loss: 0.095, 16032/28000 datapoints
2025-03-06 20:58:39,945 - INFO - training batch 551, loss: 0.118, 17632/28000 datapoints
2025-03-06 20:58:40,077 - INFO - training batch 601, loss: 0.062, 19232/28000 datapoints
2025-03-06 20:58:40,199 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:40,321 - INFO - training batch 701, loss: 0.163, 22432/28000 datapoints
2025-03-06 20:58:40,443 - INFO - training batch 751, loss: 0.109, 24032/28000 datapoints
2025-03-06 20:58:40,567 - INFO - training batch 801, loss: 0.080, 25632/28000 datapoints
2025-03-06 20:58:40,695 - INFO - training batch 851, loss: 0.146, 27232/28000 datapoints
2025-03-06 20:58:40,755 - INFO - validation batch 1, loss: 0.138, 32/6976 datapoints
2025-03-06 20:58:40,799 - INFO - validation batch 51, loss: 1.462, 1632/6976 datapoints
2025-03-06 20:58:40,842 - INFO - validation batch 101, loss: 0.585, 3232/6976 datapoints
2025-03-06 20:58:40,888 - INFO - validation batch 151, loss: 0.486, 4832/6976 datapoints
2025-03-06 20:58:40,932 - INFO - validation batch 201, loss: 0.432, 6432/6976 datapoints
2025-03-06 20:58:40,947 - INFO - Epoch 523/800 done.
2025-03-06 20:58:40,947 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:40,948 - INFO - Beginning epoch 524/800
2025-03-06 20:58:40,951 - INFO - training batch 1, loss: 0.229, 32/28000 datapoints
2025-03-06 20:58:41,075 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-06 20:58:41,195 - INFO - training batch 101, loss: 0.074, 3232/28000 datapoints
2025-03-06 20:58:41,315 - INFO - training batch 151, loss: 0.063, 4832/28000 datapoints
2025-03-06 20:58:41,442 - INFO - training batch 201, loss: 0.040, 6432/28000 datapoints
2025-03-06 20:58:41,561 - INFO - training batch 251, loss: 0.222, 8032/28000 datapoints
2025-03-06 20:58:41,687 - INFO - training batch 301, loss: 0.255, 9632/28000 datapoints
2025-03-06 20:58:41,807 - INFO - training batch 351, loss: 0.168, 11232/28000 datapoints
2025-03-06 20:58:41,935 - INFO - training batch 401, loss: 0.297, 12832/28000 datapoints
2025-03-06 20:58:42,057 - INFO - training batch 451, loss: 0.146, 14432/28000 datapoints
2025-03-06 20:58:42,179 - INFO - training batch 501, loss: 0.094, 16032/28000 datapoints
2025-03-06 20:58:42,301 - INFO - training batch 551, loss: 0.118, 17632/28000 datapoints
2025-03-06 20:58:42,422 - INFO - training batch 601, loss: 0.062, 19232/28000 datapoints
2025-03-06 20:58:42,544 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:42,667 - INFO - training batch 701, loss: 0.163, 22432/28000 datapoints
2025-03-06 20:58:42,789 - INFO - training batch 751, loss: 0.107, 24032/28000 datapoints
2025-03-06 20:58:42,910 - INFO - training batch 801, loss: 0.080, 25632/28000 datapoints
2025-03-06 20:58:43,030 - INFO - training batch 851, loss: 0.144, 27232/28000 datapoints
2025-03-06 20:58:43,092 - INFO - validation batch 1, loss: 0.139, 32/6976 datapoints
2025-03-06 20:58:43,135 - INFO - validation batch 51, loss: 1.468, 1632/6976 datapoints
2025-03-06 20:58:43,179 - INFO - validation batch 101, loss: 0.586, 3232/6976 datapoints
2025-03-06 20:58:43,223 - INFO - validation batch 151, loss: 0.488, 4832/6976 datapoints
2025-03-06 20:58:43,267 - INFO - validation batch 201, loss: 0.435, 6432/6976 datapoints
2025-03-06 20:58:43,282 - INFO - Epoch 524/800 done.
2025-03-06 20:58:43,282 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:43,283 - INFO - Beginning epoch 525/800
2025-03-06 20:58:43,286 - INFO - training batch 1, loss: 0.230, 32/28000 datapoints
2025-03-06 20:58:43,412 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-06 20:58:43,534 - INFO - training batch 101, loss: 0.073, 3232/28000 datapoints
2025-03-06 20:58:43,677 - INFO - training batch 151, loss: 0.063, 4832/28000 datapoints
2025-03-06 20:58:43,796 - INFO - training batch 201, loss: 0.040, 6432/28000 datapoints
2025-03-06 20:58:43,917 - INFO - training batch 251, loss: 0.221, 8032/28000 datapoints
2025-03-06 20:58:44,038 - INFO - training batch 301, loss: 0.254, 9632/28000 datapoints
2025-03-06 20:58:44,167 - INFO - training batch 351, loss: 0.169, 11232/28000 datapoints
2025-03-06 20:58:44,292 - INFO - training batch 401, loss: 0.295, 12832/28000 datapoints
2025-03-06 20:58:44,411 - INFO - training batch 451, loss: 0.150, 14432/28000 datapoints
2025-03-06 20:58:44,538 - INFO - training batch 501, loss: 0.095, 16032/28000 datapoints
2025-03-06 20:58:44,661 - INFO - training batch 551, loss: 0.118, 17632/28000 datapoints
2025-03-06 20:58:44,783 - INFO - training batch 601, loss: 0.061, 19232/28000 datapoints
2025-03-06 20:58:44,905 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:45,030 - INFO - training batch 701, loss: 0.162, 22432/28000 datapoints
2025-03-06 20:58:45,151 - INFO - training batch 751, loss: 0.108, 24032/28000 datapoints
2025-03-06 20:58:45,271 - INFO - training batch 801, loss: 0.080, 25632/28000 datapoints
2025-03-06 20:58:45,395 - INFO - training batch 851, loss: 0.144, 27232/28000 datapoints
2025-03-06 20:58:45,455 - INFO - validation batch 1, loss: 0.138, 32/6976 datapoints
2025-03-06 20:58:45,499 - INFO - validation batch 51, loss: 1.470, 1632/6976 datapoints
2025-03-06 20:58:45,544 - INFO - validation batch 101, loss: 0.589, 3232/6976 datapoints
2025-03-06 20:58:45,588 - INFO - validation batch 151, loss: 0.488, 4832/6976 datapoints
2025-03-06 20:58:45,634 - INFO - validation batch 201, loss: 0.432, 6432/6976 datapoints
2025-03-06 20:58:45,652 - INFO - Epoch 525/800 done.
2025-03-06 20:58:45,652 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:45,653 - INFO - Beginning epoch 526/800
2025-03-06 20:58:45,656 - INFO - training batch 1, loss: 0.228, 32/28000 datapoints
2025-03-06 20:58:45,805 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-06 20:58:45,933 - INFO - training batch 101, loss: 0.072, 3232/28000 datapoints
2025-03-06 20:58:46,056 - INFO - training batch 151, loss: 0.063, 4832/28000 datapoints
2025-03-06 20:58:46,179 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-06 20:58:46,299 - INFO - training batch 251, loss: 0.220, 8032/28000 datapoints
2025-03-06 20:58:46,420 - INFO - training batch 301, loss: 0.252, 9632/28000 datapoints
2025-03-06 20:58:46,540 - INFO - training batch 351, loss: 0.170, 11232/28000 datapoints
2025-03-06 20:58:46,664 - INFO - training batch 401, loss: 0.294, 12832/28000 datapoints
2025-03-06 20:58:46,784 - INFO - training batch 451, loss: 0.149, 14432/28000 datapoints
2025-03-06 20:58:46,905 - INFO - training batch 501, loss: 0.094, 16032/28000 datapoints
2025-03-06 20:58:47,026 - INFO - training batch 551, loss: 0.117, 17632/28000 datapoints
2025-03-06 20:58:47,152 - INFO - training batch 601, loss: 0.062, 19232/28000 datapoints
2025-03-06 20:58:47,273 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:47,396 - INFO - training batch 701, loss: 0.162, 22432/28000 datapoints
2025-03-06 20:58:47,517 - INFO - training batch 751, loss: 0.106, 24032/28000 datapoints
2025-03-06 20:58:47,640 - INFO - training batch 801, loss: 0.079, 25632/28000 datapoints
2025-03-06 20:58:47,765 - INFO - training batch 851, loss: 0.143, 27232/28000 datapoints
2025-03-06 20:58:47,825 - INFO - validation batch 1, loss: 0.140, 32/6976 datapoints
2025-03-06 20:58:47,869 - INFO - validation batch 51, loss: 1.475, 1632/6976 datapoints
2025-03-06 20:58:47,913 - INFO - validation batch 101, loss: 0.591, 3232/6976 datapoints
2025-03-06 20:58:47,956 - INFO - validation batch 151, loss: 0.490, 4832/6976 datapoints
2025-03-06 20:58:48,001 - INFO - validation batch 201, loss: 0.433, 6432/6976 datapoints
2025-03-06 20:58:48,017 - INFO - Epoch 526/800 done.
2025-03-06 20:58:48,017 - INFO - Final validation performance:
Loss: 0.626, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:48,018 - INFO - Beginning epoch 527/800
2025-03-06 20:58:48,021 - INFO - training batch 1, loss: 0.229, 32/28000 datapoints
2025-03-06 20:58:48,143 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-06 20:58:48,267 - INFO - training batch 101, loss: 0.073, 3232/28000 datapoints
2025-03-06 20:58:48,386 - INFO - training batch 151, loss: 0.062, 4832/28000 datapoints
2025-03-06 20:58:48,508 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-06 20:58:48,629 - INFO - training batch 251, loss: 0.220, 8032/28000 datapoints
2025-03-06 20:58:48,752 - INFO - training batch 301, loss: 0.250, 9632/28000 datapoints
2025-03-06 20:58:48,872 - INFO - training batch 351, loss: 0.169, 11232/28000 datapoints
2025-03-06 20:58:48,993 - INFO - training batch 401, loss: 0.293, 12832/28000 datapoints
2025-03-06 20:58:49,114 - INFO - training batch 451, loss: 0.145, 14432/28000 datapoints
2025-03-06 20:58:49,238 - INFO - training batch 501, loss: 0.093, 16032/28000 datapoints
2025-03-06 20:58:49,357 - INFO - training batch 551, loss: 0.115, 17632/28000 datapoints
2025-03-06 20:58:49,482 - INFO - training batch 601, loss: 0.061, 19232/28000 datapoints
2025-03-06 20:58:49,610 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:49,780 - INFO - training batch 701, loss: 0.161, 22432/28000 datapoints
2025-03-06 20:58:49,973 - INFO - training batch 751, loss: 0.106, 24032/28000 datapoints
2025-03-06 20:58:50,099 - INFO - training batch 801, loss: 0.080, 25632/28000 datapoints
2025-03-06 20:58:50,232 - INFO - training batch 851, loss: 0.142, 27232/28000 datapoints
2025-03-06 20:58:50,300 - INFO - validation batch 1, loss: 0.139, 32/6976 datapoints
2025-03-06 20:58:50,350 - INFO - validation batch 51, loss: 1.478, 1632/6976 datapoints
2025-03-06 20:58:50,402 - INFO - validation batch 101, loss: 0.594, 3232/6976 datapoints
2025-03-06 20:58:50,451 - INFO - validation batch 151, loss: 0.490, 4832/6976 datapoints
2025-03-06 20:58:50,503 - INFO - validation batch 201, loss: 0.437, 6432/6976 datapoints
2025-03-06 20:58:50,518 - INFO - Epoch 527/800 done.
2025-03-06 20:58:50,518 - INFO - Final validation performance:
Loss: 0.628, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 20:58:50,519 - INFO - Beginning epoch 528/800
2025-03-06 20:58:50,522 - INFO - training batch 1, loss: 0.227, 32/28000 datapoints
2025-03-06 20:58:50,652 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-06 20:58:50,780 - INFO - training batch 101, loss: 0.073, 3232/28000 datapoints
2025-03-06 20:58:50,905 - INFO - training batch 151, loss: 0.062, 4832/28000 datapoints
2025-03-06 20:58:51,031 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-06 20:58:51,155 - INFO - training batch 251, loss: 0.219, 8032/28000 datapoints
2025-03-06 20:58:51,281 - INFO - training batch 301, loss: 0.248, 9632/28000 datapoints
2025-03-06 20:58:51,410 - INFO - training batch 351, loss: 0.167, 11232/28000 datapoints
2025-03-06 20:58:51,534 - INFO - training batch 401, loss: 0.292, 12832/28000 datapoints
2025-03-06 20:58:51,661 - INFO - training batch 451, loss: 0.147, 14432/28000 datapoints
2025-03-06 20:58:51,786 - INFO - training batch 501, loss: 0.091, 16032/28000 datapoints
2025-03-06 20:58:51,931 - INFO - training batch 551, loss: 0.115, 17632/28000 datapoints
2025-03-06 20:58:52,060 - INFO - training batch 601, loss: 0.061, 19232/28000 datapoints
2025-03-06 20:58:52,185 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:52,312 - INFO - training batch 701, loss: 0.160, 22432/28000 datapoints
2025-03-06 20:58:52,437 - INFO - training batch 751, loss: 0.105, 24032/28000 datapoints
2025-03-06 20:58:52,563 - INFO - training batch 801, loss: 0.079, 25632/28000 datapoints
2025-03-06 20:58:52,691 - INFO - training batch 851, loss: 0.142, 27232/28000 datapoints
2025-03-06 20:58:52,754 - INFO - validation batch 1, loss: 0.140, 32/6976 datapoints
2025-03-06 20:58:52,802 - INFO - validation batch 51, loss: 1.482, 1632/6976 datapoints
2025-03-06 20:58:52,857 - INFO - validation batch 101, loss: 0.596, 3232/6976 datapoints
2025-03-06 20:58:52,926 - INFO - validation batch 151, loss: 0.493, 4832/6976 datapoints
2025-03-06 20:58:52,995 - INFO - validation batch 201, loss: 0.437, 6432/6976 datapoints
2025-03-06 20:58:53,014 - INFO - Epoch 528/800 done.
2025-03-06 20:58:53,015 - INFO - Final validation performance:
Loss: 0.629, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:53,015 - INFO - Beginning epoch 529/800
2025-03-06 20:58:53,019 - INFO - training batch 1, loss: 0.225, 32/28000 datapoints
2025-03-06 20:58:53,153 - INFO - training batch 51, loss: 0.058, 1632/28000 datapoints
2025-03-06 20:58:53,282 - INFO - training batch 101, loss: 0.073, 3232/28000 datapoints
2025-03-06 20:58:53,408 - INFO - training batch 151, loss: 0.061, 4832/28000 datapoints
2025-03-06 20:58:53,538 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-06 20:58:53,664 - INFO - training batch 251, loss: 0.218, 8032/28000 datapoints
2025-03-06 20:58:53,789 - INFO - training batch 301, loss: 0.246, 9632/28000 datapoints
2025-03-06 20:58:53,913 - INFO - training batch 351, loss: 0.169, 11232/28000 datapoints
2025-03-06 20:58:54,038 - INFO - training batch 401, loss: 0.291, 12832/28000 datapoints
2025-03-06 20:58:54,161 - INFO - training batch 451, loss: 0.144, 14432/28000 datapoints
2025-03-06 20:58:54,287 - INFO - training batch 501, loss: 0.091, 16032/28000 datapoints
2025-03-06 20:58:54,411 - INFO - training batch 551, loss: 0.113, 17632/28000 datapoints
2025-03-06 20:58:54,538 - INFO - training batch 601, loss: 0.061, 19232/28000 datapoints
2025-03-06 20:58:54,665 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-06 20:58:54,792 - INFO - training batch 701, loss: 0.159, 22432/28000 datapoints
2025-03-06 20:58:54,920 - INFO - training batch 751, loss: 0.105, 24032/28000 datapoints
2025-03-06 20:58:55,047 - INFO - training batch 801, loss: 0.078, 25632/28000 datapoints
2025-03-06 20:58:55,172 - INFO - training batch 851, loss: 0.141, 27232/28000 datapoints
2025-03-06 20:58:55,236 - INFO - validation batch 1, loss: 0.141, 32/6976 datapoints
2025-03-06 20:58:55,283 - INFO - validation batch 51, loss: 1.485, 1632/6976 datapoints
2025-03-06 20:58:55,329 - INFO - validation batch 101, loss: 0.597, 3232/6976 datapoints
2025-03-06 20:58:55,373 - INFO - validation batch 151, loss: 0.495, 4832/6976 datapoints
2025-03-06 20:58:55,416 - INFO - validation batch 201, loss: 0.433, 6432/6976 datapoints
2025-03-06 20:58:55,434 - INFO - Epoch 529/800 done.
2025-03-06 20:58:55,435 - INFO - Final validation performance:
Loss: 0.630, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:55,435 - INFO - Beginning epoch 530/800
2025-03-06 20:58:55,439 - INFO - training batch 1, loss: 0.227, 32/28000 datapoints
2025-03-06 20:58:55,561 - INFO - training batch 51, loss: 0.058, 1632/28000 datapoints
2025-03-06 20:58:55,685 - INFO - training batch 101, loss: 0.072, 3232/28000 datapoints
2025-03-06 20:58:55,821 - INFO - training batch 151, loss: 0.061, 4832/28000 datapoints
2025-03-06 20:58:55,977 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-06 20:58:56,097 - INFO - training batch 251, loss: 0.218, 8032/28000 datapoints
2025-03-06 20:58:56,227 - INFO - training batch 301, loss: 0.244, 9632/28000 datapoints
2025-03-06 20:58:56,352 - INFO - training batch 351, loss: 0.168, 11232/28000 datapoints
2025-03-06 20:58:56,470 - INFO - training batch 401, loss: 0.289, 12832/28000 datapoints
2025-03-06 20:58:56,594 - INFO - training batch 451, loss: 0.147, 14432/28000 datapoints
2025-03-06 20:58:56,716 - INFO - training batch 501, loss: 0.092, 16032/28000 datapoints
2025-03-06 20:58:56,839 - INFO - training batch 551, loss: 0.114, 17632/28000 datapoints
2025-03-06 20:58:56,961 - INFO - training batch 601, loss: 0.060, 19232/28000 datapoints
2025-03-06 20:58:57,081 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:58:57,201 - INFO - training batch 701, loss: 0.159, 22432/28000 datapoints
2025-03-06 20:58:57,323 - INFO - training batch 751, loss: 0.104, 24032/28000 datapoints
2025-03-06 20:58:57,448 - INFO - training batch 801, loss: 0.078, 25632/28000 datapoints
2025-03-06 20:58:57,571 - INFO - training batch 851, loss: 0.141, 27232/28000 datapoints
2025-03-06 20:58:57,631 - INFO - validation batch 1, loss: 0.140, 32/6976 datapoints
2025-03-06 20:58:57,682 - INFO - validation batch 51, loss: 1.488, 1632/6976 datapoints
2025-03-06 20:58:57,726 - INFO - validation batch 101, loss: 0.600, 3232/6976 datapoints
2025-03-06 20:58:57,770 - INFO - validation batch 151, loss: 0.495, 4832/6976 datapoints
2025-03-06 20:58:57,815 - INFO - validation batch 201, loss: 0.434, 6432/6976 datapoints
2025-03-06 20:58:57,830 - INFO - Epoch 530/800 done.
2025-03-06 20:58:57,830 - INFO - Final validation performance:
Loss: 0.631, top-1 acc: 0.868top-5 acc: 0.868
2025-03-06 20:58:57,831 - INFO - Beginning epoch 531/800
2025-03-06 20:58:57,834 - INFO - training batch 1, loss: 0.225, 32/28000 datapoints
2025-03-06 20:58:57,956 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-06 20:58:58,078 - INFO - training batch 101, loss: 0.072, 3232/28000 datapoints
2025-03-06 20:58:58,198 - INFO - training batch 151, loss: 0.060, 4832/28000 datapoints
2025-03-06 20:58:58,321 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-06 20:58:58,440 - INFO - training batch 251, loss: 0.217, 8032/28000 datapoints
2025-03-06 20:58:58,564 - INFO - training batch 301, loss: 0.243, 9632/28000 datapoints
2025-03-06 20:58:58,687 - INFO - training batch 351, loss: 0.166, 11232/28000 datapoints
2025-03-06 20:58:58,809 - INFO - training batch 401, loss: 0.288, 12832/28000 datapoints
2025-03-06 20:58:58,931 - INFO - training batch 451, loss: 0.143, 14432/28000 datapoints
2025-03-06 20:58:59,052 - INFO - training batch 501, loss: 0.090, 16032/28000 datapoints
2025-03-06 20:58:59,172 - INFO - training batch 551, loss: 0.111, 17632/28000 datapoints
2025-03-06 20:58:59,294 - INFO - training batch 601, loss: 0.060, 19232/28000 datapoints
2025-03-06 20:58:59,413 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:58:59,538 - INFO - training batch 701, loss: 0.158, 22432/28000 datapoints
2025-03-06 20:58:59,659 - INFO - training batch 751, loss: 0.103, 24032/28000 datapoints
2025-03-06 20:58:59,781 - INFO - training batch 801, loss: 0.078, 25632/28000 datapoints
2025-03-06 20:58:59,903 - INFO - training batch 851, loss: 0.140, 27232/28000 datapoints
2025-03-06 20:58:59,964 - INFO - validation batch 1, loss: 0.141, 32/6976 datapoints
2025-03-06 20:59:00,009 - INFO - validation batch 51, loss: 1.495, 1632/6976 datapoints
2025-03-06 20:59:00,053 - INFO - validation batch 101, loss: 0.601, 3232/6976 datapoints
2025-03-06 20:59:00,098 - INFO - validation batch 151, loss: 0.495, 4832/6976 datapoints
2025-03-06 20:59:00,141 - INFO - validation batch 201, loss: 0.439, 6432/6976 datapoints
2025-03-06 20:59:00,156 - INFO - Epoch 531/800 done.
2025-03-06 20:59:00,157 - INFO - Final validation performance:
Loss: 0.634, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 20:59:00,157 - INFO - Beginning epoch 532/800
2025-03-06 20:59:00,161 - INFO - training batch 1, loss: 0.224, 32/28000 datapoints
2025-03-06 20:59:00,283 - INFO - training batch 51, loss: 0.058, 1632/28000 datapoints
2025-03-06 20:59:00,403 - INFO - training batch 101, loss: 0.073, 3232/28000 datapoints
2025-03-06 20:59:00,523 - INFO - training batch 151, loss: 0.060, 4832/28000 datapoints
2025-03-06 20:59:00,645 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-06 20:59:00,765 - INFO - training batch 251, loss: 0.217, 8032/28000 datapoints
2025-03-06 20:59:00,886 - INFO - training batch 301, loss: 0.240, 9632/28000 datapoints
2025-03-06 20:59:01,008 - INFO - training batch 351, loss: 0.168, 11232/28000 datapoints
2025-03-06 20:59:01,128 - INFO - training batch 401, loss: 0.287, 12832/28000 datapoints
2025-03-06 20:59:01,248 - INFO - training batch 451, loss: 0.145, 14432/28000 datapoints
2025-03-06 20:59:01,370 - INFO - training batch 501, loss: 0.091, 16032/28000 datapoints
2025-03-06 20:59:01,494 - INFO - training batch 551, loss: 0.111, 17632/28000 datapoints
2025-03-06 20:59:01,613 - INFO - training batch 601, loss: 0.059, 19232/28000 datapoints
2025-03-06 20:59:01,737 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:01,858 - INFO - training batch 701, loss: 0.157, 22432/28000 datapoints
2025-03-06 20:59:01,982 - INFO - training batch 751, loss: 0.103, 24032/28000 datapoints
2025-03-06 20:59:02,102 - INFO - training batch 801, loss: 0.078, 25632/28000 datapoints
2025-03-06 20:59:02,223 - INFO - training batch 851, loss: 0.139, 27232/28000 datapoints
2025-03-06 20:59:02,284 - INFO - validation batch 1, loss: 0.142, 32/6976 datapoints
2025-03-06 20:59:02,329 - INFO - validation batch 51, loss: 1.498, 1632/6976 datapoints
2025-03-06 20:59:02,372 - INFO - validation batch 101, loss: 0.605, 3232/6976 datapoints
2025-03-06 20:59:02,417 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 20:59:02,460 - INFO - validation batch 201, loss: 0.441, 6432/6976 datapoints
2025-03-06 20:59:02,475 - INFO - Epoch 532/800 done.
2025-03-06 20:59:02,476 - INFO - Final validation performance:
Loss: 0.636, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 20:59:02,476 - INFO - Beginning epoch 533/800
2025-03-06 20:59:02,480 - INFO - training batch 1, loss: 0.223, 32/28000 datapoints
2025-03-06 20:59:02,600 - INFO - training batch 51, loss: 0.058, 1632/28000 datapoints
2025-03-06 20:59:02,722 - INFO - training batch 101, loss: 0.073, 3232/28000 datapoints
2025-03-06 20:59:02,845 - INFO - training batch 151, loss: 0.060, 4832/28000 datapoints
2025-03-06 20:59:02,964 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-06 20:59:03,084 - INFO - training batch 251, loss: 0.216, 8032/28000 datapoints
2025-03-06 20:59:03,206 - INFO - training batch 301, loss: 0.239, 9632/28000 datapoints
2025-03-06 20:59:03,327 - INFO - training batch 351, loss: 0.168, 11232/28000 datapoints
2025-03-06 20:59:03,447 - INFO - training batch 401, loss: 0.286, 12832/28000 datapoints
2025-03-06 20:59:03,571 - INFO - training batch 451, loss: 0.145, 14432/28000 datapoints
2025-03-06 20:59:03,693 - INFO - training batch 501, loss: 0.090, 16032/28000 datapoints
2025-03-06 20:59:03,814 - INFO - training batch 551, loss: 0.110, 17632/28000 datapoints
2025-03-06 20:59:03,938 - INFO - training batch 601, loss: 0.059, 19232/28000 datapoints
2025-03-06 20:59:04,056 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:04,176 - INFO - training batch 701, loss: 0.157, 22432/28000 datapoints
2025-03-06 20:59:04,296 - INFO - training batch 751, loss: 0.102, 24032/28000 datapoints
2025-03-06 20:59:04,418 - INFO - training batch 801, loss: 0.078, 25632/28000 datapoints
2025-03-06 20:59:04,540 - INFO - training batch 851, loss: 0.139, 27232/28000 datapoints
2025-03-06 20:59:04,612 - INFO - validation batch 1, loss: 0.142, 32/6976 datapoints
2025-03-06 20:59:04,667 - INFO - validation batch 51, loss: 1.503, 1632/6976 datapoints
2025-03-06 20:59:04,711 - INFO - validation batch 101, loss: 0.607, 3232/6976 datapoints
2025-03-06 20:59:04,754 - INFO - validation batch 151, loss: 0.497, 4832/6976 datapoints
2025-03-06 20:59:04,799 - INFO - validation batch 201, loss: 0.441, 6432/6976 datapoints
2025-03-06 20:59:04,814 - INFO - Epoch 533/800 done.
2025-03-06 20:59:04,814 - INFO - Final validation performance:
Loss: 0.638, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 20:59:04,814 - INFO - Beginning epoch 534/800
2025-03-06 20:59:04,818 - INFO - training batch 1, loss: 0.222, 32/28000 datapoints
2025-03-06 20:59:04,949 - INFO - training batch 51, loss: 0.058, 1632/28000 datapoints
2025-03-06 20:59:05,075 - INFO - training batch 101, loss: 0.072, 3232/28000 datapoints
2025-03-06 20:59:05,196 - INFO - training batch 151, loss: 0.060, 4832/28000 datapoints
2025-03-06 20:59:05,317 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-06 20:59:05,437 - INFO - training batch 251, loss: 0.215, 8032/28000 datapoints
2025-03-06 20:59:05,561 - INFO - training batch 301, loss: 0.237, 9632/28000 datapoints
2025-03-06 20:59:05,683 - INFO - training batch 351, loss: 0.168, 11232/28000 datapoints
2025-03-06 20:59:05,804 - INFO - training batch 401, loss: 0.285, 12832/28000 datapoints
2025-03-06 20:59:05,929 - INFO - training batch 451, loss: 0.141, 14432/28000 datapoints
2025-03-06 20:59:06,074 - INFO - training batch 501, loss: 0.089, 16032/28000 datapoints
2025-03-06 20:59:06,196 - INFO - training batch 551, loss: 0.110, 17632/28000 datapoints
2025-03-06 20:59:06,316 - INFO - training batch 601, loss: 0.059, 19232/28000 datapoints
2025-03-06 20:59:06,438 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:06,559 - INFO - training batch 701, loss: 0.156, 22432/28000 datapoints
2025-03-06 20:59:06,681 - INFO - training batch 751, loss: 0.101, 24032/28000 datapoints
2025-03-06 20:59:06,801 - INFO - training batch 801, loss: 0.077, 25632/28000 datapoints
2025-03-06 20:59:06,923 - INFO - training batch 851, loss: 0.138, 27232/28000 datapoints
2025-03-06 20:59:06,983 - INFO - validation batch 1, loss: 0.143, 32/6976 datapoints
2025-03-06 20:59:07,027 - INFO - validation batch 51, loss: 1.506, 1632/6976 datapoints
2025-03-06 20:59:07,071 - INFO - validation batch 101, loss: 0.609, 3232/6976 datapoints
2025-03-06 20:59:07,115 - INFO - validation batch 151, loss: 0.498, 4832/6976 datapoints
2025-03-06 20:59:07,160 - INFO - validation batch 201, loss: 0.440, 6432/6976 datapoints
2025-03-06 20:59:07,175 - INFO - Epoch 534/800 done.
2025-03-06 20:59:07,175 - INFO - Final validation performance:
Loss: 0.639, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 20:59:07,176 - INFO - Beginning epoch 535/800
2025-03-06 20:59:07,179 - INFO - training batch 1, loss: 0.222, 32/28000 datapoints
2025-03-06 20:59:07,300 - INFO - training batch 51, loss: 0.058, 1632/28000 datapoints
2025-03-06 20:59:07,425 - INFO - training batch 101, loss: 0.071, 3232/28000 datapoints
2025-03-06 20:59:07,549 - INFO - training batch 151, loss: 0.059, 4832/28000 datapoints
2025-03-06 20:59:07,680 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-06 20:59:07,806 - INFO - training batch 251, loss: 0.215, 8032/28000 datapoints
2025-03-06 20:59:07,929 - INFO - training batch 301, loss: 0.235, 9632/28000 datapoints
2025-03-06 20:59:08,050 - INFO - training batch 351, loss: 0.167, 11232/28000 datapoints
2025-03-06 20:59:08,170 - INFO - training batch 401, loss: 0.283, 12832/28000 datapoints
2025-03-06 20:59:08,293 - INFO - training batch 451, loss: 0.144, 14432/28000 datapoints
2025-03-06 20:59:08,423 - INFO - training batch 501, loss: 0.089, 16032/28000 datapoints
2025-03-06 20:59:08,550 - INFO - training batch 551, loss: 0.110, 17632/28000 datapoints
2025-03-06 20:59:08,671 - INFO - training batch 601, loss: 0.058, 19232/28000 datapoints
2025-03-06 20:59:08,791 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:08,914 - INFO - training batch 701, loss: 0.156, 22432/28000 datapoints
2025-03-06 20:59:09,035 - INFO - training batch 751, loss: 0.101, 24032/28000 datapoints
2025-03-06 20:59:09,158 - INFO - training batch 801, loss: 0.077, 25632/28000 datapoints
2025-03-06 20:59:09,278 - INFO - training batch 851, loss: 0.138, 27232/28000 datapoints
2025-03-06 20:59:09,338 - INFO - validation batch 1, loss: 0.144, 32/6976 datapoints
2025-03-06 20:59:09,381 - INFO - validation batch 51, loss: 1.508, 1632/6976 datapoints
2025-03-06 20:59:09,427 - INFO - validation batch 101, loss: 0.612, 3232/6976 datapoints
2025-03-06 20:59:09,471 - INFO - validation batch 151, loss: 0.499, 4832/6976 datapoints
2025-03-06 20:59:09,518 - INFO - validation batch 201, loss: 0.440, 6432/6976 datapoints
2025-03-06 20:59:09,533 - INFO - Epoch 535/800 done.
2025-03-06 20:59:09,533 - INFO - Final validation performance:
Loss: 0.641, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 20:59:09,534 - INFO - Beginning epoch 536/800
2025-03-06 20:59:09,537 - INFO - training batch 1, loss: 0.221, 32/28000 datapoints
2025-03-06 20:59:09,666 - INFO - training batch 51, loss: 0.058, 1632/28000 datapoints
2025-03-06 20:59:09,794 - INFO - training batch 101, loss: 0.071, 3232/28000 datapoints
2025-03-06 20:59:09,920 - INFO - training batch 151, loss: 0.059, 4832/28000 datapoints
2025-03-06 20:59:10,046 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-06 20:59:10,172 - INFO - training batch 251, loss: 0.214, 8032/28000 datapoints
2025-03-06 20:59:10,296 - INFO - training batch 301, loss: 0.233, 9632/28000 datapoints
2025-03-06 20:59:10,420 - INFO - training batch 351, loss: 0.167, 11232/28000 datapoints
2025-03-06 20:59:10,544 - INFO - training batch 401, loss: 0.282, 12832/28000 datapoints
2025-03-06 20:59:10,675 - INFO - training batch 451, loss: 0.140, 14432/28000 datapoints
2025-03-06 20:59:10,823 - INFO - training batch 501, loss: 0.087, 16032/28000 datapoints
2025-03-06 20:59:10,952 - INFO - training batch 551, loss: 0.108, 17632/28000 datapoints
2025-03-06 20:59:11,080 - INFO - training batch 601, loss: 0.058, 19232/28000 datapoints
2025-03-06 20:59:11,204 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:11,338 - INFO - training batch 701, loss: 0.155, 22432/28000 datapoints
2025-03-06 20:59:11,465 - INFO - training batch 751, loss: 0.100, 24032/28000 datapoints
2025-03-06 20:59:11,591 - INFO - training batch 801, loss: 0.077, 25632/28000 datapoints
2025-03-06 20:59:11,721 - INFO - training batch 851, loss: 0.137, 27232/28000 datapoints
2025-03-06 20:59:11,785 - INFO - validation batch 1, loss: 0.143, 32/6976 datapoints
2025-03-06 20:59:11,831 - INFO - validation batch 51, loss: 1.513, 1632/6976 datapoints
2025-03-06 20:59:11,880 - INFO - validation batch 101, loss: 0.614, 3232/6976 datapoints
2025-03-06 20:59:11,926 - INFO - validation batch 151, loss: 0.501, 4832/6976 datapoints
2025-03-06 20:59:11,971 - INFO - validation batch 201, loss: 0.441, 6432/6976 datapoints
2025-03-06 20:59:11,987 - INFO - Epoch 536/800 done.
2025-03-06 20:59:11,987 - INFO - Final validation performance:
Loss: 0.643, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:11,987 - INFO - Beginning epoch 537/800
2025-03-06 20:59:11,991 - INFO - training batch 1, loss: 0.220, 32/28000 datapoints
2025-03-06 20:59:12,121 - INFO - training batch 51, loss: 0.058, 1632/28000 datapoints
2025-03-06 20:59:12,245 - INFO - training batch 101, loss: 0.071, 3232/28000 datapoints
2025-03-06 20:59:12,367 - INFO - training batch 151, loss: 0.059, 4832/28000 datapoints
2025-03-06 20:59:12,490 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-06 20:59:12,610 - INFO - training batch 251, loss: 0.213, 8032/28000 datapoints
2025-03-06 20:59:12,733 - INFO - training batch 301, loss: 0.231, 9632/28000 datapoints
2025-03-06 20:59:12,854 - INFO - training batch 351, loss: 0.167, 11232/28000 datapoints
2025-03-06 20:59:12,976 - INFO - training batch 401, loss: 0.281, 12832/28000 datapoints
2025-03-06 20:59:13,098 - INFO - training batch 451, loss: 0.143, 14432/28000 datapoints
2025-03-06 20:59:13,218 - INFO - training batch 501, loss: 0.088, 16032/28000 datapoints
2025-03-06 20:59:13,339 - INFO - training batch 551, loss: 0.108, 17632/28000 datapoints
2025-03-06 20:59:13,461 - INFO - training batch 601, loss: 0.058, 19232/28000 datapoints
2025-03-06 20:59:13,585 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:13,709 - INFO - training batch 701, loss: 0.154, 22432/28000 datapoints
2025-03-06 20:59:13,829 - INFO - training batch 751, loss: 0.099, 24032/28000 datapoints
2025-03-06 20:59:13,951 - INFO - training batch 801, loss: 0.077, 25632/28000 datapoints
2025-03-06 20:59:14,071 - INFO - training batch 851, loss: 0.137, 27232/28000 datapoints
2025-03-06 20:59:14,132 - INFO - validation batch 1, loss: 0.145, 32/6976 datapoints
2025-03-06 20:59:14,176 - INFO - validation batch 51, loss: 1.519, 1632/6976 datapoints
2025-03-06 20:59:14,220 - INFO - validation batch 101, loss: 0.615, 3232/6976 datapoints
2025-03-06 20:59:14,264 - INFO - validation batch 151, loss: 0.501, 4832/6976 datapoints
2025-03-06 20:59:14,307 - INFO - validation batch 201, loss: 0.441, 6432/6976 datapoints
2025-03-06 20:59:14,323 - INFO - Epoch 537/800 done.
2025-03-06 20:59:14,323 - INFO - Final validation performance:
Loss: 0.644, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 20:59:14,324 - INFO - Beginning epoch 538/800
2025-03-06 20:59:14,327 - INFO - training batch 1, loss: 0.220, 32/28000 datapoints
2025-03-06 20:59:14,453 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-06 20:59:14,574 - INFO - training batch 101, loss: 0.071, 3232/28000 datapoints
2025-03-06 20:59:14,696 - INFO - training batch 151, loss: 0.058, 4832/28000 datapoints
2025-03-06 20:59:14,817 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-06 20:59:14,944 - INFO - training batch 251, loss: 0.213, 8032/28000 datapoints
2025-03-06 20:59:15,067 - INFO - training batch 301, loss: 0.229, 9632/28000 datapoints
2025-03-06 20:59:15,186 - INFO - training batch 351, loss: 0.167, 11232/28000 datapoints
2025-03-06 20:59:15,307 - INFO - training batch 401, loss: 0.280, 12832/28000 datapoints
2025-03-06 20:59:15,426 - INFO - training batch 451, loss: 0.142, 14432/28000 datapoints
2025-03-06 20:59:15,552 - INFO - training batch 501, loss: 0.087, 16032/28000 datapoints
2025-03-06 20:59:15,676 - INFO - training batch 551, loss: 0.107, 17632/28000 datapoints
2025-03-06 20:59:15,800 - INFO - training batch 601, loss: 0.058, 19232/28000 datapoints
2025-03-06 20:59:15,925 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:16,083 - INFO - training batch 701, loss: 0.154, 22432/28000 datapoints
2025-03-06 20:59:16,212 - INFO - training batch 751, loss: 0.099, 24032/28000 datapoints
2025-03-06 20:59:16,330 - INFO - training batch 801, loss: 0.076, 25632/28000 datapoints
2025-03-06 20:59:16,450 - INFO - training batch 851, loss: 0.136, 27232/28000 datapoints
2025-03-06 20:59:16,511 - INFO - validation batch 1, loss: 0.145, 32/6976 datapoints
2025-03-06 20:59:16,555 - INFO - validation batch 51, loss: 1.522, 1632/6976 datapoints
2025-03-06 20:59:16,597 - INFO - validation batch 101, loss: 0.619, 3232/6976 datapoints
2025-03-06 20:59:16,644 - INFO - validation batch 151, loss: 0.502, 4832/6976 datapoints
2025-03-06 20:59:16,687 - INFO - validation batch 201, loss: 0.442, 6432/6976 datapoints
2025-03-06 20:59:16,702 - INFO - Epoch 538/800 done.
2025-03-06 20:59:16,702 - INFO - Final validation performance:
Loss: 0.646, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:16,702 - INFO - Beginning epoch 539/800
2025-03-06 20:59:16,706 - INFO - training batch 1, loss: 0.219, 32/28000 datapoints
2025-03-06 20:59:16,843 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-06 20:59:16,964 - INFO - training batch 101, loss: 0.071, 3232/28000 datapoints
2025-03-06 20:59:17,088 - INFO - training batch 151, loss: 0.058, 4832/28000 datapoints
2025-03-06 20:59:17,217 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-06 20:59:17,345 - INFO - training batch 251, loss: 0.212, 8032/28000 datapoints
2025-03-06 20:59:17,466 - INFO - training batch 301, loss: 0.228, 9632/28000 datapoints
2025-03-06 20:59:17,596 - INFO - training batch 351, loss: 0.164, 11232/28000 datapoints
2025-03-06 20:59:17,722 - INFO - training batch 401, loss: 0.279, 12832/28000 datapoints
2025-03-06 20:59:17,842 - INFO - training batch 451, loss: 0.138, 14432/28000 datapoints
2025-03-06 20:59:17,962 - INFO - training batch 501, loss: 0.086, 16032/28000 datapoints
2025-03-06 20:59:18,083 - INFO - training batch 551, loss: 0.108, 17632/28000 datapoints
2025-03-06 20:59:18,202 - INFO - training batch 601, loss: 0.058, 19232/28000 datapoints
2025-03-06 20:59:18,325 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:18,464 - INFO - training batch 701, loss: 0.153, 22432/28000 datapoints
2025-03-06 20:59:18,590 - INFO - training batch 751, loss: 0.098, 24032/28000 datapoints
2025-03-06 20:59:18,713 - INFO - training batch 801, loss: 0.076, 25632/28000 datapoints
2025-03-06 20:59:18,833 - INFO - training batch 851, loss: 0.136, 27232/28000 datapoints
2025-03-06 20:59:18,895 - INFO - validation batch 1, loss: 0.145, 32/6976 datapoints
2025-03-06 20:59:18,938 - INFO - validation batch 51, loss: 1.525, 1632/6976 datapoints
2025-03-06 20:59:18,982 - INFO - validation batch 101, loss: 0.622, 3232/6976 datapoints
2025-03-06 20:59:19,029 - INFO - validation batch 151, loss: 0.501, 4832/6976 datapoints
2025-03-06 20:59:19,073 - INFO - validation batch 201, loss: 0.443, 6432/6976 datapoints
2025-03-06 20:59:19,089 - INFO - Epoch 539/800 done.
2025-03-06 20:59:19,089 - INFO - Final validation performance:
Loss: 0.647, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:19,090 - INFO - Beginning epoch 540/800
2025-03-06 20:59:19,093 - INFO - training batch 1, loss: 0.218, 32/28000 datapoints
2025-03-06 20:59:19,215 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-06 20:59:19,338 - INFO - training batch 101, loss: 0.070, 3232/28000 datapoints
2025-03-06 20:59:19,459 - INFO - training batch 151, loss: 0.057, 4832/28000 datapoints
2025-03-06 20:59:19,586 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-06 20:59:19,712 - INFO - training batch 251, loss: 0.212, 8032/28000 datapoints
2025-03-06 20:59:19,833 - INFO - training batch 301, loss: 0.226, 9632/28000 datapoints
2025-03-06 20:59:19,954 - INFO - training batch 351, loss: 0.166, 11232/28000 datapoints
2025-03-06 20:59:20,080 - INFO - training batch 401, loss: 0.277, 12832/28000 datapoints
2025-03-06 20:59:20,207 - INFO - training batch 451, loss: 0.142, 14432/28000 datapoints
2025-03-06 20:59:20,328 - INFO - training batch 501, loss: 0.085, 16032/28000 datapoints
2025-03-06 20:59:20,448 - INFO - training batch 551, loss: 0.106, 17632/28000 datapoints
2025-03-06 20:59:20,568 - INFO - training batch 601, loss: 0.058, 19232/28000 datapoints
2025-03-06 20:59:20,691 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:20,811 - INFO - training batch 701, loss: 0.152, 22432/28000 datapoints
2025-03-06 20:59:20,931 - INFO - training batch 751, loss: 0.097, 24032/28000 datapoints
2025-03-06 20:59:21,053 - INFO - training batch 801, loss: 0.076, 25632/28000 datapoints
2025-03-06 20:59:21,174 - INFO - training batch 851, loss: 0.135, 27232/28000 datapoints
2025-03-06 20:59:21,233 - INFO - validation batch 1, loss: 0.147, 32/6976 datapoints
2025-03-06 20:59:21,275 - INFO - validation batch 51, loss: 1.532, 1632/6976 datapoints
2025-03-06 20:59:21,319 - INFO - validation batch 101, loss: 0.623, 3232/6976 datapoints
2025-03-06 20:59:21,363 - INFO - validation batch 151, loss: 0.505, 4832/6976 datapoints
2025-03-06 20:59:21,407 - INFO - validation batch 201, loss: 0.444, 6432/6976 datapoints
2025-03-06 20:59:21,424 - INFO - Epoch 540/800 done.
2025-03-06 20:59:21,424 - INFO - Final validation performance:
Loss: 0.650, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:21,425 - INFO - Beginning epoch 541/800
2025-03-06 20:59:21,428 - INFO - training batch 1, loss: 0.218, 32/28000 datapoints
2025-03-06 20:59:21,554 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-06 20:59:21,678 - INFO - training batch 101, loss: 0.070, 3232/28000 datapoints
2025-03-06 20:59:21,799 - INFO - training batch 151, loss: 0.057, 4832/28000 datapoints
2025-03-06 20:59:21,929 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-06 20:59:22,063 - INFO - training batch 251, loss: 0.211, 8032/28000 datapoints
2025-03-06 20:59:22,184 - INFO - training batch 301, loss: 0.224, 9632/28000 datapoints
2025-03-06 20:59:22,308 - INFO - training batch 351, loss: 0.166, 11232/28000 datapoints
2025-03-06 20:59:22,428 - INFO - training batch 401, loss: 0.276, 12832/28000 datapoints
2025-03-06 20:59:22,549 - INFO - training batch 451, loss: 0.137, 14432/28000 datapoints
2025-03-06 20:59:22,671 - INFO - training batch 501, loss: 0.085, 16032/28000 datapoints
2025-03-06 20:59:22,799 - INFO - training batch 551, loss: 0.105, 17632/28000 datapoints
2025-03-06 20:59:22,929 - INFO - training batch 601, loss: 0.057, 19232/28000 datapoints
2025-03-06 20:59:23,049 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:23,169 - INFO - training batch 701, loss: 0.152, 22432/28000 datapoints
2025-03-06 20:59:23,301 - INFO - training batch 751, loss: 0.097, 24032/28000 datapoints
2025-03-06 20:59:23,424 - INFO - training batch 801, loss: 0.075, 25632/28000 datapoints
2025-03-06 20:59:23,554 - INFO - training batch 851, loss: 0.135, 27232/28000 datapoints
2025-03-06 20:59:23,617 - INFO - validation batch 1, loss: 0.146, 32/6976 datapoints
2025-03-06 20:59:23,666 - INFO - validation batch 51, loss: 1.535, 1632/6976 datapoints
2025-03-06 20:59:23,710 - INFO - validation batch 101, loss: 0.626, 3232/6976 datapoints
2025-03-06 20:59:23,754 - INFO - validation batch 151, loss: 0.507, 4832/6976 datapoints
2025-03-06 20:59:23,798 - INFO - validation batch 201, loss: 0.444, 6432/6976 datapoints
2025-03-06 20:59:23,813 - INFO - Epoch 541/800 done.
2025-03-06 20:59:23,813 - INFO - Final validation performance:
Loss: 0.652, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:23,814 - INFO - Beginning epoch 542/800
2025-03-06 20:59:23,817 - INFO - training batch 1, loss: 0.217, 32/28000 datapoints
2025-03-06 20:59:23,942 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-06 20:59:24,064 - INFO - training batch 101, loss: 0.070, 3232/28000 datapoints
2025-03-06 20:59:24,187 - INFO - training batch 151, loss: 0.057, 4832/28000 datapoints
2025-03-06 20:59:24,306 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-06 20:59:24,428 - INFO - training batch 251, loss: 0.210, 8032/28000 datapoints
2025-03-06 20:59:24,548 - INFO - training batch 301, loss: 0.222, 9632/28000 datapoints
2025-03-06 20:59:24,672 - INFO - training batch 351, loss: 0.165, 11232/28000 datapoints
2025-03-06 20:59:24,793 - INFO - training batch 401, loss: 0.274, 12832/28000 datapoints
2025-03-06 20:59:24,921 - INFO - training batch 451, loss: 0.140, 14432/28000 datapoints
2025-03-06 20:59:25,043 - INFO - training batch 501, loss: 0.085, 16032/28000 datapoints
2025-03-06 20:59:25,166 - INFO - training batch 551, loss: 0.106, 17632/28000 datapoints
2025-03-06 20:59:25,288 - INFO - training batch 601, loss: 0.057, 19232/28000 datapoints
2025-03-06 20:59:25,408 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:25,528 - INFO - training batch 701, loss: 0.151, 22432/28000 datapoints
2025-03-06 20:59:25,656 - INFO - training batch 751, loss: 0.096, 24032/28000 datapoints
2025-03-06 20:59:25,775 - INFO - training batch 801, loss: 0.075, 25632/28000 datapoints
2025-03-06 20:59:25,895 - INFO - training batch 851, loss: 0.134, 27232/28000 datapoints
2025-03-06 20:59:25,954 - INFO - validation batch 1, loss: 0.147, 32/6976 datapoints
2025-03-06 20:59:25,998 - INFO - validation batch 51, loss: 1.540, 1632/6976 datapoints
2025-03-06 20:59:26,042 - INFO - validation batch 101, loss: 0.628, 3232/6976 datapoints
2025-03-06 20:59:26,085 - INFO - validation batch 151, loss: 0.507, 4832/6976 datapoints
2025-03-06 20:59:26,138 - INFO - validation batch 201, loss: 0.444, 6432/6976 datapoints
2025-03-06 20:59:26,160 - INFO - Epoch 542/800 done.
2025-03-06 20:59:26,161 - INFO - Final validation performance:
Loss: 0.653, top-1 acc: 0.867top-5 acc: 0.867
2025-03-06 20:59:26,161 - INFO - Beginning epoch 543/800
2025-03-06 20:59:26,165 - INFO - training batch 1, loss: 0.216, 32/28000 datapoints
2025-03-06 20:59:26,298 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-06 20:59:26,420 - INFO - training batch 101, loss: 0.070, 3232/28000 datapoints
2025-03-06 20:59:26,541 - INFO - training batch 151, loss: 0.056, 4832/28000 datapoints
2025-03-06 20:59:26,667 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-06 20:59:26,787 - INFO - training batch 251, loss: 0.210, 8032/28000 datapoints
2025-03-06 20:59:26,909 - INFO - training batch 301, loss: 0.220, 9632/28000 datapoints
2025-03-06 20:59:27,029 - INFO - training batch 351, loss: 0.165, 11232/28000 datapoints
2025-03-06 20:59:27,152 - INFO - training batch 401, loss: 0.273, 12832/28000 datapoints
2025-03-06 20:59:27,274 - INFO - training batch 451, loss: 0.136, 14432/28000 datapoints
2025-03-06 20:59:27,401 - INFO - training batch 501, loss: 0.084, 16032/28000 datapoints
2025-03-06 20:59:27,524 - INFO - training batch 551, loss: 0.104, 17632/28000 datapoints
2025-03-06 20:59:27,656 - INFO - training batch 601, loss: 0.057, 19232/28000 datapoints
2025-03-06 20:59:27,786 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:27,918 - INFO - training batch 701, loss: 0.150, 22432/28000 datapoints
2025-03-06 20:59:28,040 - INFO - training batch 751, loss: 0.096, 24032/28000 datapoints
2025-03-06 20:59:28,162 - INFO - training batch 801, loss: 0.075, 25632/28000 datapoints
2025-03-06 20:59:28,282 - INFO - training batch 851, loss: 0.134, 27232/28000 datapoints
2025-03-06 20:59:28,343 - INFO - validation batch 1, loss: 0.147, 32/6976 datapoints
2025-03-06 20:59:28,387 - INFO - validation batch 51, loss: 1.547, 1632/6976 datapoints
2025-03-06 20:59:28,431 - INFO - validation batch 101, loss: 0.629, 3232/6976 datapoints
2025-03-06 20:59:28,476 - INFO - validation batch 151, loss: 0.509, 4832/6976 datapoints
2025-03-06 20:59:28,521 - INFO - validation batch 201, loss: 0.445, 6432/6976 datapoints
2025-03-06 20:59:28,536 - INFO - Epoch 543/800 done.
2025-03-06 20:59:28,536 - INFO - Final validation performance:
Loss: 0.655, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:28,536 - INFO - Beginning epoch 544/800
2025-03-06 20:59:28,540 - INFO - training batch 1, loss: 0.216, 32/28000 datapoints
2025-03-06 20:59:28,667 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-06 20:59:28,791 - INFO - training batch 101, loss: 0.070, 3232/28000 datapoints
2025-03-06 20:59:28,924 - INFO - training batch 151, loss: 0.056, 4832/28000 datapoints
2025-03-06 20:59:29,046 - INFO - training batch 201, loss: 0.036, 6432/28000 datapoints
2025-03-06 20:59:29,169 - INFO - training batch 251, loss: 0.209, 8032/28000 datapoints
2025-03-06 20:59:29,297 - INFO - training batch 301, loss: 0.218, 9632/28000 datapoints
2025-03-06 20:59:29,422 - INFO - training batch 351, loss: 0.165, 11232/28000 datapoints
2025-03-06 20:59:29,546 - INFO - training batch 401, loss: 0.272, 12832/28000 datapoints
2025-03-06 20:59:29,679 - INFO - training batch 451, loss: 0.139, 14432/28000 datapoints
2025-03-06 20:59:29,809 - INFO - training batch 501, loss: 0.084, 16032/28000 datapoints
2025-03-06 20:59:29,934 - INFO - training batch 551, loss: 0.103, 17632/28000 datapoints
2025-03-06 20:59:30,057 - INFO - training batch 601, loss: 0.056, 19232/28000 datapoints
2025-03-06 20:59:30,189 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:30,318 - INFO - training batch 701, loss: 0.149, 22432/28000 datapoints
2025-03-06 20:59:30,441 - INFO - training batch 751, loss: 0.095, 24032/28000 datapoints
2025-03-06 20:59:30,565 - INFO - training batch 801, loss: 0.075, 25632/28000 datapoints
2025-03-06 20:59:30,692 - INFO - training batch 851, loss: 0.134, 27232/28000 datapoints
2025-03-06 20:59:30,757 - INFO - validation batch 1, loss: 0.148, 32/6976 datapoints
2025-03-06 20:59:30,806 - INFO - validation batch 51, loss: 1.548, 1632/6976 datapoints
2025-03-06 20:59:30,856 - INFO - validation batch 101, loss: 0.633, 3232/6976 datapoints
2025-03-06 20:59:30,903 - INFO - validation batch 151, loss: 0.509, 4832/6976 datapoints
2025-03-06 20:59:30,951 - INFO - validation batch 201, loss: 0.445, 6432/6976 datapoints
2025-03-06 20:59:30,966 - INFO - Epoch 544/800 done.
2025-03-06 20:59:30,966 - INFO - Final validation performance:
Loss: 0.656, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:30,966 - INFO - Beginning epoch 545/800
2025-03-06 20:59:30,970 - INFO - training batch 1, loss: 0.214, 32/28000 datapoints
2025-03-06 20:59:31,098 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-06 20:59:31,227 - INFO - training batch 101, loss: 0.070, 3232/28000 datapoints
2025-03-06 20:59:31,355 - INFO - training batch 151, loss: 0.056, 4832/28000 datapoints
2025-03-06 20:59:31,480 - INFO - training batch 201, loss: 0.036, 6432/28000 datapoints
2025-03-06 20:59:31,608 - INFO - training batch 251, loss: 0.208, 8032/28000 datapoints
2025-03-06 20:59:31,736 - INFO - training batch 301, loss: 0.217, 9632/28000 datapoints
2025-03-06 20:59:31,862 - INFO - training batch 351, loss: 0.165, 11232/28000 datapoints
2025-03-06 20:59:31,990 - INFO - training batch 401, loss: 0.271, 12832/28000 datapoints
2025-03-06 20:59:32,120 - INFO - training batch 451, loss: 0.136, 14432/28000 datapoints
2025-03-06 20:59:32,247 - INFO - training batch 501, loss: 0.083, 16032/28000 datapoints
2025-03-06 20:59:32,371 - INFO - training batch 551, loss: 0.103, 17632/28000 datapoints
2025-03-06 20:59:32,498 - INFO - training batch 601, loss: 0.056, 19232/28000 datapoints
2025-03-06 20:59:32,622 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:32,750 - INFO - training batch 701, loss: 0.149, 22432/28000 datapoints
2025-03-06 20:59:32,874 - INFO - training batch 751, loss: 0.095, 24032/28000 datapoints
2025-03-06 20:59:32,998 - INFO - training batch 801, loss: 0.074, 25632/28000 datapoints
2025-03-06 20:59:33,125 - INFO - training batch 851, loss: 0.133, 27232/28000 datapoints
2025-03-06 20:59:33,189 - INFO - validation batch 1, loss: 0.148, 32/6976 datapoints
2025-03-06 20:59:33,239 - INFO - validation batch 51, loss: 1.554, 1632/6976 datapoints
2025-03-06 20:59:33,288 - INFO - validation batch 101, loss: 0.635, 3232/6976 datapoints
2025-03-06 20:59:33,336 - INFO - validation batch 151, loss: 0.509, 4832/6976 datapoints
2025-03-06 20:59:33,383 - INFO - validation batch 201, loss: 0.446, 6432/6976 datapoints
2025-03-06 20:59:33,399 - INFO - Epoch 545/800 done.
2025-03-06 20:59:33,399 - INFO - Final validation performance:
Loss: 0.658, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:33,400 - INFO - Beginning epoch 546/800
2025-03-06 20:59:33,404 - INFO - training batch 1, loss: 0.214, 32/28000 datapoints
2025-03-06 20:59:33,543 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-06 20:59:33,686 - INFO - training batch 101, loss: 0.069, 3232/28000 datapoints
2025-03-06 20:59:33,827 - INFO - training batch 151, loss: 0.055, 4832/28000 datapoints
2025-03-06 20:59:33,949 - INFO - training batch 201, loss: 0.036, 6432/28000 datapoints
2025-03-06 20:59:34,071 - INFO - training batch 251, loss: 0.207, 8032/28000 datapoints
2025-03-06 20:59:34,192 - INFO - training batch 301, loss: 0.214, 9632/28000 datapoints
2025-03-06 20:59:34,313 - INFO - training batch 351, loss: 0.164, 11232/28000 datapoints
2025-03-06 20:59:34,434 - INFO - training batch 401, loss: 0.271, 12832/28000 datapoints
2025-03-06 20:59:34,554 - INFO - training batch 451, loss: 0.137, 14432/28000 datapoints
2025-03-06 20:59:34,679 - INFO - training batch 501, loss: 0.082, 16032/28000 datapoints
2025-03-06 20:59:34,801 - INFO - training batch 551, loss: 0.102, 17632/28000 datapoints
2025-03-06 20:59:34,934 - INFO - training batch 601, loss: 0.056, 19232/28000 datapoints
2025-03-06 20:59:35,067 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:35,189 - INFO - training batch 701, loss: 0.148, 22432/28000 datapoints
2025-03-06 20:59:35,310 - INFO - training batch 751, loss: 0.094, 24032/28000 datapoints
2025-03-06 20:59:35,430 - INFO - training batch 801, loss: 0.074, 25632/28000 datapoints
2025-03-06 20:59:35,558 - INFO - training batch 851, loss: 0.132, 27232/28000 datapoints
2025-03-06 20:59:35,622 - INFO - validation batch 1, loss: 0.149, 32/6976 datapoints
2025-03-06 20:59:35,669 - INFO - validation batch 51, loss: 1.557, 1632/6976 datapoints
2025-03-06 20:59:35,715 - INFO - validation batch 101, loss: 0.638, 3232/6976 datapoints
2025-03-06 20:59:35,761 - INFO - validation batch 151, loss: 0.514, 4832/6976 datapoints
2025-03-06 20:59:35,805 - INFO - validation batch 201, loss: 0.446, 6432/6976 datapoints
2025-03-06 20:59:35,820 - INFO - Epoch 546/800 done.
2025-03-06 20:59:35,820 - INFO - Final validation performance:
Loss: 0.661, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:35,821 - INFO - Beginning epoch 547/800
2025-03-06 20:59:35,824 - INFO - training batch 1, loss: 0.214, 32/28000 datapoints
2025-03-06 20:59:35,949 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 20:59:36,071 - INFO - training batch 101, loss: 0.069, 3232/28000 datapoints
2025-03-06 20:59:36,192 - INFO - training batch 151, loss: 0.054, 4832/28000 datapoints
2025-03-06 20:59:36,349 - INFO - training batch 201, loss: 0.036, 6432/28000 datapoints
2025-03-06 20:59:36,470 - INFO - training batch 251, loss: 0.206, 8032/28000 datapoints
2025-03-06 20:59:36,591 - INFO - training batch 301, loss: 0.213, 9632/28000 datapoints
2025-03-06 20:59:36,712 - INFO - training batch 351, loss: 0.164, 11232/28000 datapoints
2025-03-06 20:59:36,833 - INFO - training batch 401, loss: 0.269, 12832/28000 datapoints
2025-03-06 20:59:36,953 - INFO - training batch 451, loss: 0.134, 14432/28000 datapoints
2025-03-06 20:59:37,074 - INFO - training batch 501, loss: 0.081, 16032/28000 datapoints
2025-03-06 20:59:37,195 - INFO - training batch 551, loss: 0.102, 17632/28000 datapoints
2025-03-06 20:59:37,318 - INFO - training batch 601, loss: 0.056, 19232/28000 datapoints
2025-03-06 20:59:37,439 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:37,558 - INFO - training batch 701, loss: 0.147, 22432/28000 datapoints
2025-03-06 20:59:37,702 - INFO - training batch 751, loss: 0.094, 24032/28000 datapoints
2025-03-06 20:59:37,823 - INFO - training batch 801, loss: 0.074, 25632/28000 datapoints
2025-03-06 20:59:37,944 - INFO - training batch 851, loss: 0.132, 27232/28000 datapoints
2025-03-06 20:59:38,005 - INFO - validation batch 1, loss: 0.150, 32/6976 datapoints
2025-03-06 20:59:38,049 - INFO - validation batch 51, loss: 1.562, 1632/6976 datapoints
2025-03-06 20:59:38,092 - INFO - validation batch 101, loss: 0.639, 3232/6976 datapoints
2025-03-06 20:59:38,137 - INFO - validation batch 151, loss: 0.514, 4832/6976 datapoints
2025-03-06 20:59:38,180 - INFO - validation batch 201, loss: 0.447, 6432/6976 datapoints
2025-03-06 20:59:38,195 - INFO - Epoch 547/800 done.
2025-03-06 20:59:38,195 - INFO - Final validation performance:
Loss: 0.662, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:38,195 - INFO - Beginning epoch 548/800
2025-03-06 20:59:38,199 - INFO - training batch 1, loss: 0.214, 32/28000 datapoints
2025-03-06 20:59:38,326 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 20:59:38,445 - INFO - training batch 101, loss: 0.069, 3232/28000 datapoints
2025-03-06 20:59:38,566 - INFO - training batch 151, loss: 0.054, 4832/28000 datapoints
2025-03-06 20:59:38,688 - INFO - training batch 201, loss: 0.036, 6432/28000 datapoints
2025-03-06 20:59:38,810 - INFO - training batch 251, loss: 0.206, 8032/28000 datapoints
2025-03-06 20:59:38,930 - INFO - training batch 301, loss: 0.211, 9632/28000 datapoints
2025-03-06 20:59:39,051 - INFO - training batch 351, loss: 0.161, 11232/28000 datapoints
2025-03-06 20:59:39,177 - INFO - training batch 401, loss: 0.268, 12832/28000 datapoints
2025-03-06 20:59:39,299 - INFO - training batch 451, loss: 0.137, 14432/28000 datapoints
2025-03-06 20:59:39,422 - INFO - training batch 501, loss: 0.082, 16032/28000 datapoints
2025-03-06 20:59:39,543 - INFO - training batch 551, loss: 0.101, 17632/28000 datapoints
2025-03-06 20:59:39,671 - INFO - training batch 601, loss: 0.056, 19232/28000 datapoints
2025-03-06 20:59:39,793 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:39,915 - INFO - training batch 701, loss: 0.147, 22432/28000 datapoints
2025-03-06 20:59:40,042 - INFO - training batch 751, loss: 0.093, 24032/28000 datapoints
2025-03-06 20:59:40,164 - INFO - training batch 801, loss: 0.073, 25632/28000 datapoints
2025-03-06 20:59:40,287 - INFO - training batch 851, loss: 0.131, 27232/28000 datapoints
2025-03-06 20:59:40,349 - INFO - validation batch 1, loss: 0.152, 32/6976 datapoints
2025-03-06 20:59:40,393 - INFO - validation batch 51, loss: 1.566, 1632/6976 datapoints
2025-03-06 20:59:40,437 - INFO - validation batch 101, loss: 0.643, 3232/6976 datapoints
2025-03-06 20:59:40,480 - INFO - validation batch 151, loss: 0.516, 4832/6976 datapoints
2025-03-06 20:59:40,525 - INFO - validation batch 201, loss: 0.448, 6432/6976 datapoints
2025-03-06 20:59:40,540 - INFO - Epoch 548/800 done.
2025-03-06 20:59:40,540 - INFO - Final validation performance:
Loss: 0.665, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:40,541 - INFO - Beginning epoch 549/800
2025-03-06 20:59:40,544 - INFO - training batch 1, loss: 0.212, 32/28000 datapoints
2025-03-06 20:59:40,668 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 20:59:40,789 - INFO - training batch 101, loss: 0.069, 3232/28000 datapoints
2025-03-06 20:59:40,923 - INFO - training batch 151, loss: 0.053, 4832/28000 datapoints
2025-03-06 20:59:41,056 - INFO - training batch 201, loss: 0.036, 6432/28000 datapoints
2025-03-06 20:59:41,176 - INFO - training batch 251, loss: 0.205, 8032/28000 datapoints
2025-03-06 20:59:41,295 - INFO - training batch 301, loss: 0.209, 9632/28000 datapoints
2025-03-06 20:59:41,422 - INFO - training batch 351, loss: 0.163, 11232/28000 datapoints
2025-03-06 20:59:41,546 - INFO - training batch 401, loss: 0.267, 12832/28000 datapoints
2025-03-06 20:59:41,675 - INFO - training batch 451, loss: 0.133, 14432/28000 datapoints
2025-03-06 20:59:41,808 - INFO - training batch 501, loss: 0.080, 16032/28000 datapoints
2025-03-06 20:59:41,932 - INFO - training batch 551, loss: 0.100, 17632/28000 datapoints
2025-03-06 20:59:42,052 - INFO - training batch 601, loss: 0.056, 19232/28000 datapoints
2025-03-06 20:59:42,178 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:42,299 - INFO - training batch 701, loss: 0.146, 22432/28000 datapoints
2025-03-06 20:59:42,421 - INFO - training batch 751, loss: 0.092, 24032/28000 datapoints
2025-03-06 20:59:42,540 - INFO - training batch 801, loss: 0.073, 25632/28000 datapoints
2025-03-06 20:59:42,662 - INFO - training batch 851, loss: 0.131, 27232/28000 datapoints
2025-03-06 20:59:42,722 - INFO - validation batch 1, loss: 0.151, 32/6976 datapoints
2025-03-06 20:59:42,766 - INFO - validation batch 51, loss: 1.571, 1632/6976 datapoints
2025-03-06 20:59:42,810 - INFO - validation batch 101, loss: 0.644, 3232/6976 datapoints
2025-03-06 20:59:42,856 - INFO - validation batch 151, loss: 0.517, 4832/6976 datapoints
2025-03-06 20:59:42,900 - INFO - validation batch 201, loss: 0.449, 6432/6976 datapoints
2025-03-06 20:59:42,915 - INFO - Epoch 549/800 done.
2025-03-06 20:59:42,915 - INFO - Final validation performance:
Loss: 0.666, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:42,916 - INFO - Beginning epoch 550/800
2025-03-06 20:59:42,919 - INFO - training batch 1, loss: 0.212, 32/28000 datapoints
2025-03-06 20:59:43,040 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 20:59:43,160 - INFO - training batch 101, loss: 0.069, 3232/28000 datapoints
2025-03-06 20:59:43,282 - INFO - training batch 151, loss: 0.054, 4832/28000 datapoints
2025-03-06 20:59:43,406 - INFO - training batch 201, loss: 0.036, 6432/28000 datapoints
2025-03-06 20:59:43,531 - INFO - training batch 251, loss: 0.205, 8032/28000 datapoints
2025-03-06 20:59:43,658 - INFO - training batch 301, loss: 0.207, 9632/28000 datapoints
2025-03-06 20:59:43,778 - INFO - training batch 351, loss: 0.163, 11232/28000 datapoints
2025-03-06 20:59:43,900 - INFO - training batch 401, loss: 0.266, 12832/28000 datapoints
2025-03-06 20:59:44,018 - INFO - training batch 451, loss: 0.136, 14432/28000 datapoints
2025-03-06 20:59:44,137 - INFO - training batch 501, loss: 0.081, 16032/28000 datapoints
2025-03-06 20:59:44,258 - INFO - training batch 551, loss: 0.099, 17632/28000 datapoints
2025-03-06 20:59:44,380 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-06 20:59:44,501 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-06 20:59:44,621 - INFO - training batch 701, loss: 0.145, 22432/28000 datapoints
2025-03-06 20:59:44,743 - INFO - training batch 751, loss: 0.092, 24032/28000 datapoints
2025-03-06 20:59:44,865 - INFO - training batch 801, loss: 0.073, 25632/28000 datapoints
2025-03-06 20:59:44,992 - INFO - training batch 851, loss: 0.131, 27232/28000 datapoints
2025-03-06 20:59:45,052 - INFO - validation batch 1, loss: 0.153, 32/6976 datapoints
2025-03-06 20:59:45,097 - INFO - validation batch 51, loss: 1.577, 1632/6976 datapoints
2025-03-06 20:59:45,141 - INFO - validation batch 101, loss: 0.646, 3232/6976 datapoints
2025-03-06 20:59:45,185 - INFO - validation batch 151, loss: 0.518, 4832/6976 datapoints
2025-03-06 20:59:45,228 - INFO - validation batch 201, loss: 0.449, 6432/6976 datapoints
2025-03-06 20:59:45,244 - INFO - Epoch 550/800 done.
2025-03-06 20:59:45,244 - INFO - Final validation performance:
Loss: 0.668, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:45,244 - INFO - Beginning epoch 551/800
2025-03-06 20:59:45,248 - INFO - training batch 1, loss: 0.211, 32/28000 datapoints
2025-03-06 20:59:45,372 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 20:59:45,493 - INFO - training batch 101, loss: 0.068, 3232/28000 datapoints
2025-03-06 20:59:45,613 - INFO - training batch 151, loss: 0.054, 4832/28000 datapoints
2025-03-06 20:59:45,741 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 20:59:45,862 - INFO - training batch 251, loss: 0.204, 8032/28000 datapoints
2025-03-06 20:59:45,982 - INFO - training batch 301, loss: 0.205, 9632/28000 datapoints
2025-03-06 20:59:46,101 - INFO - training batch 351, loss: 0.163, 11232/28000 datapoints
2025-03-06 20:59:46,221 - INFO - training batch 401, loss: 0.264, 12832/28000 datapoints
2025-03-06 20:59:46,352 - INFO - training batch 451, loss: 0.132, 14432/28000 datapoints
2025-03-06 20:59:46,493 - INFO - training batch 501, loss: 0.080, 16032/28000 datapoints
2025-03-06 20:59:46,612 - INFO - training batch 551, loss: 0.099, 17632/28000 datapoints
2025-03-06 20:59:46,734 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-06 20:59:46,854 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 20:59:46,977 - INFO - training batch 701, loss: 0.144, 22432/28000 datapoints
2025-03-06 20:59:47,107 - INFO - training batch 751, loss: 0.091, 24032/28000 datapoints
2025-03-06 20:59:47,231 - INFO - training batch 801, loss: 0.072, 25632/28000 datapoints
2025-03-06 20:59:47,352 - INFO - training batch 851, loss: 0.130, 27232/28000 datapoints
2025-03-06 20:59:47,413 - INFO - validation batch 1, loss: 0.154, 32/6976 datapoints
2025-03-06 20:59:47,457 - INFO - validation batch 51, loss: 1.578, 1632/6976 datapoints
2025-03-06 20:59:47,501 - INFO - validation batch 101, loss: 0.649, 3232/6976 datapoints
2025-03-06 20:59:47,544 - INFO - validation batch 151, loss: 0.517, 4832/6976 datapoints
2025-03-06 20:59:47,596 - INFO - validation batch 201, loss: 0.450, 6432/6976 datapoints
2025-03-06 20:59:47,611 - INFO - Epoch 551/800 done.
2025-03-06 20:59:47,611 - INFO - Final validation performance:
Loss: 0.670, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 20:59:47,611 - INFO - Beginning epoch 552/800
2025-03-06 20:59:47,615 - INFO - training batch 1, loss: 0.210, 32/28000 datapoints
2025-03-06 20:59:47,748 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 20:59:47,870 - INFO - training batch 101, loss: 0.068, 3232/28000 datapoints
2025-03-06 20:59:47,998 - INFO - training batch 151, loss: 0.053, 4832/28000 datapoints
2025-03-06 20:59:48,119 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 20:59:48,240 - INFO - training batch 251, loss: 0.203, 8032/28000 datapoints
2025-03-06 20:59:48,360 - INFO - training batch 301, loss: 0.203, 9632/28000 datapoints
2025-03-06 20:59:48,481 - INFO - training batch 351, loss: 0.162, 11232/28000 datapoints
2025-03-06 20:59:48,601 - INFO - training batch 401, loss: 0.263, 12832/28000 datapoints
2025-03-06 20:59:48,722 - INFO - training batch 451, loss: 0.134, 14432/28000 datapoints
2025-03-06 20:59:48,843 - INFO - training batch 501, loss: 0.080, 16032/28000 datapoints
2025-03-06 20:59:48,965 - INFO - training batch 551, loss: 0.098, 17632/28000 datapoints
2025-03-06 20:59:49,085 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-06 20:59:49,206 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 20:59:49,327 - INFO - training batch 701, loss: 0.144, 22432/28000 datapoints
2025-03-06 20:59:49,450 - INFO - training batch 751, loss: 0.091, 24032/28000 datapoints
2025-03-06 20:59:49,568 - INFO - training batch 801, loss: 0.072, 25632/28000 datapoints
2025-03-06 20:59:49,696 - INFO - training batch 851, loss: 0.130, 27232/28000 datapoints
2025-03-06 20:59:49,756 - INFO - validation batch 1, loss: 0.154, 32/6976 datapoints
2025-03-06 20:59:49,801 - INFO - validation batch 51, loss: 1.584, 1632/6976 datapoints
2025-03-06 20:59:49,845 - INFO - validation batch 101, loss: 0.652, 3232/6976 datapoints
2025-03-06 20:59:49,889 - INFO - validation batch 151, loss: 0.520, 4832/6976 datapoints
2025-03-06 20:59:49,936 - INFO - validation batch 201, loss: 0.451, 6432/6976 datapoints
2025-03-06 20:59:49,951 - INFO - Epoch 552/800 done.
2025-03-06 20:59:49,951 - INFO - Final validation performance:
Loss: 0.672, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:49,952 - INFO - Beginning epoch 553/800
2025-03-06 20:59:49,955 - INFO - training batch 1, loss: 0.210, 32/28000 datapoints
2025-03-06 20:59:50,086 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 20:59:50,220 - INFO - training batch 101, loss: 0.068, 3232/28000 datapoints
2025-03-06 20:59:50,347 - INFO - training batch 151, loss: 0.052, 4832/28000 datapoints
2025-03-06 20:59:50,474 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 20:59:50,600 - INFO - training batch 251, loss: 0.202, 8032/28000 datapoints
2025-03-06 20:59:50,727 - INFO - training batch 301, loss: 0.201, 9632/28000 datapoints
2025-03-06 20:59:50,851 - INFO - training batch 351, loss: 0.163, 11232/28000 datapoints
2025-03-06 20:59:50,978 - INFO - training batch 401, loss: 0.261, 12832/28000 datapoints
2025-03-06 20:59:51,102 - INFO - training batch 451, loss: 0.132, 14432/28000 datapoints
2025-03-06 20:59:51,225 - INFO - training batch 501, loss: 0.078, 16032/28000 datapoints
2025-03-06 20:59:51,351 - INFO - training batch 551, loss: 0.097, 17632/28000 datapoints
2025-03-06 20:59:51,478 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-06 20:59:51,602 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 20:59:51,732 - INFO - training batch 701, loss: 0.143, 22432/28000 datapoints
2025-03-06 20:59:51,856 - INFO - training batch 751, loss: 0.090, 24032/28000 datapoints
2025-03-06 20:59:51,984 - INFO - training batch 801, loss: 0.072, 25632/28000 datapoints
2025-03-06 20:59:52,108 - INFO - training batch 851, loss: 0.129, 27232/28000 datapoints
2025-03-06 20:59:52,176 - INFO - validation batch 1, loss: 0.155, 32/6976 datapoints
2025-03-06 20:59:52,225 - INFO - validation batch 51, loss: 1.589, 1632/6976 datapoints
2025-03-06 20:59:52,277 - INFO - validation batch 101, loss: 0.653, 3232/6976 datapoints
2025-03-06 20:59:52,325 - INFO - validation batch 151, loss: 0.521, 4832/6976 datapoints
2025-03-06 20:59:52,373 - INFO - validation batch 201, loss: 0.450, 6432/6976 datapoints
2025-03-06 20:59:52,388 - INFO - Epoch 553/800 done.
2025-03-06 20:59:52,388 - INFO - Final validation performance:
Loss: 0.674, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:52,389 - INFO - Beginning epoch 554/800
2025-03-06 20:59:52,392 - INFO - training batch 1, loss: 0.209, 32/28000 datapoints
2025-03-06 20:59:52,569 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 20:59:52,695 - INFO - training batch 101, loss: 0.068, 3232/28000 datapoints
2025-03-06 20:59:52,817 - INFO - training batch 151, loss: 0.052, 4832/28000 datapoints
2025-03-06 20:59:52,943 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 20:59:53,067 - INFO - training batch 251, loss: 0.201, 8032/28000 datapoints
2025-03-06 20:59:53,200 - INFO - training batch 301, loss: 0.200, 9632/28000 datapoints
2025-03-06 20:59:53,343 - INFO - training batch 351, loss: 0.161, 11232/28000 datapoints
2025-03-06 20:59:53,488 - INFO - training batch 401, loss: 0.261, 12832/28000 datapoints
2025-03-06 20:59:53,615 - INFO - training batch 451, loss: 0.133, 14432/28000 datapoints
2025-03-06 20:59:53,746 - INFO - training batch 501, loss: 0.079, 16032/28000 datapoints
2025-03-06 20:59:53,869 - INFO - training batch 551, loss: 0.097, 17632/28000 datapoints
2025-03-06 20:59:53,993 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-06 20:59:54,115 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 20:59:54,238 - INFO - training batch 701, loss: 0.142, 22432/28000 datapoints
2025-03-06 20:59:54,359 - INFO - training batch 751, loss: 0.089, 24032/28000 datapoints
2025-03-06 20:59:54,481 - INFO - training batch 801, loss: 0.071, 25632/28000 datapoints
2025-03-06 20:59:54,601 - INFO - training batch 851, loss: 0.129, 27232/28000 datapoints
2025-03-06 20:59:54,663 - INFO - validation batch 1, loss: 0.157, 32/6976 datapoints
2025-03-06 20:59:54,707 - INFO - validation batch 51, loss: 1.596, 1632/6976 datapoints
2025-03-06 20:59:54,750 - INFO - validation batch 101, loss: 0.655, 3232/6976 datapoints
2025-03-06 20:59:54,793 - INFO - validation batch 151, loss: 0.523, 4832/6976 datapoints
2025-03-06 20:59:54,837 - INFO - validation batch 201, loss: 0.452, 6432/6976 datapoints
2025-03-06 20:59:54,853 - INFO - Epoch 554/800 done.
2025-03-06 20:59:54,853 - INFO - Final validation performance:
Loss: 0.676, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:54,854 - INFO - Beginning epoch 555/800
2025-03-06 20:59:54,857 - INFO - training batch 1, loss: 0.209, 32/28000 datapoints
2025-03-06 20:59:54,986 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-06 20:59:55,109 - INFO - training batch 101, loss: 0.068, 3232/28000 datapoints
2025-03-06 20:59:55,232 - INFO - training batch 151, loss: 0.052, 4832/28000 datapoints
2025-03-06 20:59:55,355 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 20:59:55,475 - INFO - training batch 251, loss: 0.201, 8032/28000 datapoints
2025-03-06 20:59:55,596 - INFO - training batch 301, loss: 0.196, 9632/28000 datapoints
2025-03-06 20:59:55,725 - INFO - training batch 351, loss: 0.162, 11232/28000 datapoints
2025-03-06 20:59:55,844 - INFO - training batch 401, loss: 0.260, 12832/28000 datapoints
2025-03-06 20:59:55,964 - INFO - training batch 451, loss: 0.131, 14432/28000 datapoints
2025-03-06 20:59:56,087 - INFO - training batch 501, loss: 0.078, 16032/28000 datapoints
2025-03-06 20:59:56,209 - INFO - training batch 551, loss: 0.096, 17632/28000 datapoints
2025-03-06 20:59:56,330 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-06 20:59:56,467 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 20:59:56,596 - INFO - training batch 701, loss: 0.142, 22432/28000 datapoints
2025-03-06 20:59:56,720 - INFO - training batch 751, loss: 0.089, 24032/28000 datapoints
2025-03-06 20:59:56,840 - INFO - training batch 801, loss: 0.071, 25632/28000 datapoints
2025-03-06 20:59:56,961 - INFO - training batch 851, loss: 0.128, 27232/28000 datapoints
2025-03-06 20:59:57,021 - INFO - validation batch 1, loss: 0.157, 32/6976 datapoints
2025-03-06 20:59:57,066 - INFO - validation batch 51, loss: 1.599, 1632/6976 datapoints
2025-03-06 20:59:57,110 - INFO - validation batch 101, loss: 0.658, 3232/6976 datapoints
2025-03-06 20:59:57,154 - INFO - validation batch 151, loss: 0.523, 4832/6976 datapoints
2025-03-06 20:59:57,197 - INFO - validation batch 201, loss: 0.453, 6432/6976 datapoints
2025-03-06 20:59:57,213 - INFO - Epoch 555/800 done.
2025-03-06 20:59:57,213 - INFO - Final validation performance:
Loss: 0.678, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:57,214 - INFO - Beginning epoch 556/800
2025-03-06 20:59:57,218 - INFO - training batch 1, loss: 0.208, 32/28000 datapoints
2025-03-06 20:59:57,343 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-06 20:59:57,466 - INFO - training batch 101, loss: 0.067, 3232/28000 datapoints
2025-03-06 20:59:57,586 - INFO - training batch 151, loss: 0.051, 4832/28000 datapoints
2025-03-06 20:59:57,716 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 20:59:57,835 - INFO - training batch 251, loss: 0.199, 8032/28000 datapoints
2025-03-06 20:59:57,961 - INFO - training batch 301, loss: 0.195, 9632/28000 datapoints
2025-03-06 20:59:58,083 - INFO - training batch 351, loss: 0.161, 11232/28000 datapoints
2025-03-06 20:59:58,209 - INFO - training batch 401, loss: 0.258, 12832/28000 datapoints
2025-03-06 20:59:58,328 - INFO - training batch 451, loss: 0.132, 14432/28000 datapoints
2025-03-06 20:59:58,449 - INFO - training batch 501, loss: 0.078, 16032/28000 datapoints
2025-03-06 20:59:58,571 - INFO - training batch 551, loss: 0.096, 17632/28000 datapoints
2025-03-06 20:59:58,696 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-06 20:59:58,817 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 20:59:58,938 - INFO - training batch 701, loss: 0.141, 22432/28000 datapoints
2025-03-06 20:59:59,059 - INFO - training batch 751, loss: 0.088, 24032/28000 datapoints
2025-03-06 20:59:59,179 - INFO - training batch 801, loss: 0.071, 25632/28000 datapoints
2025-03-06 20:59:59,318 - INFO - training batch 851, loss: 0.128, 27232/28000 datapoints
2025-03-06 20:59:59,378 - INFO - validation batch 1, loss: 0.158, 32/6976 datapoints
2025-03-06 20:59:59,422 - INFO - validation batch 51, loss: 1.602, 1632/6976 datapoints
2025-03-06 20:59:59,466 - INFO - validation batch 101, loss: 0.661, 3232/6976 datapoints
2025-03-06 20:59:59,512 - INFO - validation batch 151, loss: 0.525, 4832/6976 datapoints
2025-03-06 20:59:59,556 - INFO - validation batch 201, loss: 0.454, 6432/6976 datapoints
2025-03-06 20:59:59,571 - INFO - Epoch 556/800 done.
2025-03-06 20:59:59,571 - INFO - Final validation performance:
Loss: 0.680, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 20:59:59,572 - INFO - Beginning epoch 557/800
2025-03-06 20:59:59,575 - INFO - training batch 1, loss: 0.207, 32/28000 datapoints
2025-03-06 20:59:59,711 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-06 20:59:59,833 - INFO - training batch 101, loss: 0.067, 3232/28000 datapoints
2025-03-06 20:59:59,954 - INFO - training batch 151, loss: 0.051, 4832/28000 datapoints
2025-03-06 21:00:00,078 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 21:00:00,199 - INFO - training batch 251, loss: 0.199, 8032/28000 datapoints
2025-03-06 21:00:00,322 - INFO - training batch 301, loss: 0.193, 9632/28000 datapoints
2025-03-06 21:00:00,442 - INFO - training batch 351, loss: 0.162, 11232/28000 datapoints
2025-03-06 21:00:00,563 - INFO - training batch 401, loss: 0.258, 12832/28000 datapoints
2025-03-06 21:00:00,687 - INFO - training batch 451, loss: 0.132, 14432/28000 datapoints
2025-03-06 21:00:00,807 - INFO - training batch 501, loss: 0.076, 16032/28000 datapoints
2025-03-06 21:00:00,928 - INFO - training batch 551, loss: 0.095, 17632/28000 datapoints
2025-03-06 21:00:01,048 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-06 21:00:01,168 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:01,289 - INFO - training batch 701, loss: 0.141, 22432/28000 datapoints
2025-03-06 21:00:01,412 - INFO - training batch 751, loss: 0.088, 24032/28000 datapoints
2025-03-06 21:00:01,533 - INFO - training batch 801, loss: 0.071, 25632/28000 datapoints
2025-03-06 21:00:01,660 - INFO - training batch 851, loss: 0.128, 27232/28000 datapoints
2025-03-06 21:00:01,724 - INFO - validation batch 1, loss: 0.159, 32/6976 datapoints
2025-03-06 21:00:01,768 - INFO - validation batch 51, loss: 1.607, 1632/6976 datapoints
2025-03-06 21:00:01,812 - INFO - validation batch 101, loss: 0.663, 3232/6976 datapoints
2025-03-06 21:00:01,859 - INFO - validation batch 151, loss: 0.528, 4832/6976 datapoints
2025-03-06 21:00:01,904 - INFO - validation batch 201, loss: 0.454, 6432/6976 datapoints
2025-03-06 21:00:01,919 - INFO - Epoch 557/800 done.
2025-03-06 21:00:01,919 - INFO - Final validation performance:
Loss: 0.682, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:00:01,920 - INFO - Beginning epoch 558/800
2025-03-06 21:00:01,924 - INFO - training batch 1, loss: 0.207, 32/28000 datapoints
2025-03-06 21:00:02,045 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-06 21:00:02,172 - INFO - training batch 101, loss: 0.067, 3232/28000 datapoints
2025-03-06 21:00:02,304 - INFO - training batch 151, loss: 0.050, 4832/28000 datapoints
2025-03-06 21:00:02,428 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 21:00:02,550 - INFO - training batch 251, loss: 0.198, 8032/28000 datapoints
2025-03-06 21:00:02,679 - INFO - training batch 301, loss: 0.191, 9632/28000 datapoints
2025-03-06 21:00:02,799 - INFO - training batch 351, loss: 0.161, 11232/28000 datapoints
2025-03-06 21:00:02,928 - INFO - training batch 401, loss: 0.256, 12832/28000 datapoints
2025-03-06 21:00:03,049 - INFO - training batch 451, loss: 0.129, 14432/28000 datapoints
2025-03-06 21:00:03,171 - INFO - training batch 501, loss: 0.076, 16032/28000 datapoints
2025-03-06 21:00:03,295 - INFO - training batch 551, loss: 0.094, 17632/28000 datapoints
2025-03-06 21:00:03,416 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-06 21:00:03,535 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:03,659 - INFO - training batch 701, loss: 0.140, 22432/28000 datapoints
2025-03-06 21:00:03,783 - INFO - training batch 751, loss: 0.087, 24032/28000 datapoints
2025-03-06 21:00:03,902 - INFO - training batch 801, loss: 0.070, 25632/28000 datapoints
2025-03-06 21:00:04,024 - INFO - training batch 851, loss: 0.127, 27232/28000 datapoints
2025-03-06 21:00:04,083 - INFO - validation batch 1, loss: 0.161, 32/6976 datapoints
2025-03-06 21:00:04,127 - INFO - validation batch 51, loss: 1.612, 1632/6976 datapoints
2025-03-06 21:00:04,173 - INFO - validation batch 101, loss: 0.666, 3232/6976 datapoints
2025-03-06 21:00:04,216 - INFO - validation batch 151, loss: 0.527, 4832/6976 datapoints
2025-03-06 21:00:04,261 - INFO - validation batch 201, loss: 0.455, 6432/6976 datapoints
2025-03-06 21:00:04,276 - INFO - Epoch 558/800 done.
2025-03-06 21:00:04,277 - INFO - Final validation performance:
Loss: 0.684, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:00:04,277 - INFO - Beginning epoch 559/800
2025-03-06 21:00:04,281 - INFO - training batch 1, loss: 0.205, 32/28000 datapoints
2025-03-06 21:00:04,405 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-06 21:00:04,527 - INFO - training batch 101, loss: 0.067, 3232/28000 datapoints
2025-03-06 21:00:04,656 - INFO - training batch 151, loss: 0.050, 4832/28000 datapoints
2025-03-06 21:00:04,779 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-06 21:00:04,902 - INFO - training batch 251, loss: 0.197, 8032/28000 datapoints
2025-03-06 21:00:05,029 - INFO - training batch 301, loss: 0.190, 9632/28000 datapoints
2025-03-06 21:00:05,149 - INFO - training batch 351, loss: 0.161, 11232/28000 datapoints
2025-03-06 21:00:05,282 - INFO - training batch 401, loss: 0.255, 12832/28000 datapoints
2025-03-06 21:00:05,408 - INFO - training batch 451, loss: 0.131, 14432/28000 datapoints
2025-03-06 21:00:05,529 - INFO - training batch 501, loss: 0.076, 16032/28000 datapoints
2025-03-06 21:00:05,660 - INFO - training batch 551, loss: 0.094, 17632/28000 datapoints
2025-03-06 21:00:05,801 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-06 21:00:05,927 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:06,048 - INFO - training batch 701, loss: 0.139, 22432/28000 datapoints
2025-03-06 21:00:06,168 - INFO - training batch 751, loss: 0.087, 24032/28000 datapoints
2025-03-06 21:00:06,291 - INFO - training batch 801, loss: 0.070, 25632/28000 datapoints
2025-03-06 21:00:06,411 - INFO - training batch 851, loss: 0.127, 27232/28000 datapoints
2025-03-06 21:00:06,472 - INFO - validation batch 1, loss: 0.162, 32/6976 datapoints
2025-03-06 21:00:06,525 - INFO - validation batch 51, loss: 1.616, 1632/6976 datapoints
2025-03-06 21:00:06,588 - INFO - validation batch 101, loss: 0.668, 3232/6976 datapoints
2025-03-06 21:00:06,643 - INFO - validation batch 151, loss: 0.530, 4832/6976 datapoints
2025-03-06 21:00:06,691 - INFO - validation batch 201, loss: 0.456, 6432/6976 datapoints
2025-03-06 21:00:06,708 - INFO - Epoch 559/800 done.
2025-03-06 21:00:06,708 - INFO - Final validation performance:
Loss: 0.686, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:00:06,708 - INFO - Beginning epoch 560/800
2025-03-06 21:00:06,712 - INFO - training batch 1, loss: 0.206, 32/28000 datapoints
2025-03-06 21:00:06,835 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-06 21:00:06,956 - INFO - training batch 101, loss: 0.067, 3232/28000 datapoints
2025-03-06 21:00:07,079 - INFO - training batch 151, loss: 0.049, 4832/28000 datapoints
2025-03-06 21:00:07,200 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 21:00:07,322 - INFO - training batch 251, loss: 0.197, 8032/28000 datapoints
2025-03-06 21:00:07,443 - INFO - training batch 301, loss: 0.188, 9632/28000 datapoints
2025-03-06 21:00:07,565 - INFO - training batch 351, loss: 0.160, 11232/28000 datapoints
2025-03-06 21:00:07,694 - INFO - training batch 401, loss: 0.254, 12832/28000 datapoints
2025-03-06 21:00:07,818 - INFO - training batch 451, loss: 0.127, 14432/28000 datapoints
2025-03-06 21:00:07,940 - INFO - training batch 501, loss: 0.075, 16032/28000 datapoints
2025-03-06 21:00:08,061 - INFO - training batch 551, loss: 0.093, 17632/28000 datapoints
2025-03-06 21:00:08,181 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-06 21:00:08,304 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:08,424 - INFO - training batch 701, loss: 0.138, 22432/28000 datapoints
2025-03-06 21:00:08,545 - INFO - training batch 751, loss: 0.086, 24032/28000 datapoints
2025-03-06 21:00:08,668 - INFO - training batch 801, loss: 0.070, 25632/28000 datapoints
2025-03-06 21:00:08,790 - INFO - training batch 851, loss: 0.126, 27232/28000 datapoints
2025-03-06 21:00:08,850 - INFO - validation batch 1, loss: 0.164, 32/6976 datapoints
2025-03-06 21:00:08,895 - INFO - validation batch 51, loss: 1.623, 1632/6976 datapoints
2025-03-06 21:00:08,939 - INFO - validation batch 101, loss: 0.669, 3232/6976 datapoints
2025-03-06 21:00:08,983 - INFO - validation batch 151, loss: 0.532, 4832/6976 datapoints
2025-03-06 21:00:09,028 - INFO - validation batch 201, loss: 0.455, 6432/6976 datapoints
2025-03-06 21:00:09,043 - INFO - Epoch 560/800 done.
2025-03-06 21:00:09,044 - INFO - Final validation performance:
Loss: 0.689, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:00:09,044 - INFO - Beginning epoch 561/800
2025-03-06 21:00:09,048 - INFO - training batch 1, loss: 0.205, 32/28000 datapoints
2025-03-06 21:00:09,171 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-06 21:00:09,295 - INFO - training batch 101, loss: 0.067, 3232/28000 datapoints
2025-03-06 21:00:09,415 - INFO - training batch 151, loss: 0.049, 4832/28000 datapoints
2025-03-06 21:00:09,537 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-06 21:00:09,670 - INFO - training batch 251, loss: 0.196, 8032/28000 datapoints
2025-03-06 21:00:09,796 - INFO - training batch 301, loss: 0.186, 9632/28000 datapoints
2025-03-06 21:00:09,918 - INFO - training batch 351, loss: 0.160, 11232/28000 datapoints
2025-03-06 21:00:10,039 - INFO - training batch 401, loss: 0.253, 12832/28000 datapoints
2025-03-06 21:00:10,163 - INFO - training batch 451, loss: 0.130, 14432/28000 datapoints
2025-03-06 21:00:10,291 - INFO - training batch 501, loss: 0.075, 16032/28000 datapoints
2025-03-06 21:00:10,417 - INFO - training batch 551, loss: 0.092, 17632/28000 datapoints
2025-03-06 21:00:10,543 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-06 21:00:10,673 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:10,800 - INFO - training batch 701, loss: 0.138, 22432/28000 datapoints
2025-03-06 21:00:10,926 - INFO - training batch 751, loss: 0.086, 24032/28000 datapoints
2025-03-06 21:00:11,049 - INFO - training batch 801, loss: 0.069, 25632/28000 datapoints
2025-03-06 21:00:11,176 - INFO - training batch 851, loss: 0.126, 27232/28000 datapoints
2025-03-06 21:00:11,242 - INFO - validation batch 1, loss: 0.165, 32/6976 datapoints
2025-03-06 21:00:11,290 - INFO - validation batch 51, loss: 1.625, 1632/6976 datapoints
2025-03-06 21:00:11,341 - INFO - validation batch 101, loss: 0.672, 3232/6976 datapoints
2025-03-06 21:00:11,390 - INFO - validation batch 151, loss: 0.533, 4832/6976 datapoints
2025-03-06 21:00:11,437 - INFO - validation batch 201, loss: 0.457, 6432/6976 datapoints
2025-03-06 21:00:11,452 - INFO - Epoch 561/800 done.
2025-03-06 21:00:11,453 - INFO - Final validation performance:
Loss: 0.690, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:00:11,453 - INFO - Beginning epoch 562/800
2025-03-06 21:00:11,457 - INFO - training batch 1, loss: 0.203, 32/28000 datapoints
2025-03-06 21:00:11,583 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-06 21:00:11,711 - INFO - training batch 101, loss: 0.066, 3232/28000 datapoints
2025-03-06 21:00:11,841 - INFO - training batch 151, loss: 0.049, 4832/28000 datapoints
2025-03-06 21:00:11,968 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-06 21:00:12,094 - INFO - training batch 251, loss: 0.195, 8032/28000 datapoints
2025-03-06 21:00:12,217 - INFO - training batch 301, loss: 0.184, 9632/28000 datapoints
2025-03-06 21:00:12,350 - INFO - training batch 351, loss: 0.159, 11232/28000 datapoints
2025-03-06 21:00:12,484 - INFO - training batch 401, loss: 0.251, 12832/28000 datapoints
2025-03-06 21:00:12,609 - INFO - training batch 451, loss: 0.126, 14432/28000 datapoints
2025-03-06 21:00:12,737 - INFO - training batch 501, loss: 0.074, 16032/28000 datapoints
2025-03-06 21:00:12,864 - INFO - training batch 551, loss: 0.092, 17632/28000 datapoints
2025-03-06 21:00:12,990 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-06 21:00:13,116 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:13,238 - INFO - training batch 701, loss: 0.137, 22432/28000 datapoints
2025-03-06 21:00:13,364 - INFO - training batch 751, loss: 0.085, 24032/28000 datapoints
2025-03-06 21:00:13,488 - INFO - training batch 801, loss: 0.069, 25632/28000 datapoints
2025-03-06 21:00:13,613 - INFO - training batch 851, loss: 0.126, 27232/28000 datapoints
2025-03-06 21:00:13,679 - INFO - validation batch 1, loss: 0.166, 32/6976 datapoints
2025-03-06 21:00:13,725 - INFO - validation batch 51, loss: 1.631, 1632/6976 datapoints
2025-03-06 21:00:13,775 - INFO - validation batch 101, loss: 0.674, 3232/6976 datapoints
2025-03-06 21:00:13,819 - INFO - validation batch 151, loss: 0.532, 4832/6976 datapoints
2025-03-06 21:00:13,863 - INFO - validation batch 201, loss: 0.457, 6432/6976 datapoints
2025-03-06 21:00:13,878 - INFO - Epoch 562/800 done.
2025-03-06 21:00:13,878 - INFO - Final validation performance:
Loss: 0.692, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:13,879 - INFO - Beginning epoch 563/800
2025-03-06 21:00:13,883 - INFO - training batch 1, loss: 0.203, 32/28000 datapoints
2025-03-06 21:00:14,016 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-06 21:00:14,139 - INFO - training batch 101, loss: 0.066, 3232/28000 datapoints
2025-03-06 21:00:14,260 - INFO - training batch 151, loss: 0.049, 4832/28000 datapoints
2025-03-06 21:00:14,383 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-06 21:00:14,505 - INFO - training batch 251, loss: 0.194, 8032/28000 datapoints
2025-03-06 21:00:14,627 - INFO - training batch 301, loss: 0.182, 9632/28000 datapoints
2025-03-06 21:00:14,749 - INFO - training batch 351, loss: 0.159, 11232/28000 datapoints
2025-03-06 21:00:14,870 - INFO - training batch 401, loss: 0.250, 12832/28000 datapoints
2025-03-06 21:00:14,997 - INFO - training batch 451, loss: 0.129, 14432/28000 datapoints
2025-03-06 21:00:15,119 - INFO - training batch 501, loss: 0.073, 16032/28000 datapoints
2025-03-06 21:00:15,240 - INFO - training batch 551, loss: 0.091, 17632/28000 datapoints
2025-03-06 21:00:15,361 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-06 21:00:15,480 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:15,602 - INFO - training batch 701, loss: 0.136, 22432/28000 datapoints
2025-03-06 21:00:15,727 - INFO - training batch 751, loss: 0.084, 24032/28000 datapoints
2025-03-06 21:00:15,851 - INFO - training batch 801, loss: 0.068, 25632/28000 datapoints
2025-03-06 21:00:15,971 - INFO - training batch 851, loss: 0.125, 27232/28000 datapoints
2025-03-06 21:00:16,032 - INFO - validation batch 1, loss: 0.169, 32/6976 datapoints
2025-03-06 21:00:16,077 - INFO - validation batch 51, loss: 1.637, 1632/6976 datapoints
2025-03-06 21:00:16,122 - INFO - validation batch 101, loss: 0.675, 3232/6976 datapoints
2025-03-06 21:00:16,171 - INFO - validation batch 151, loss: 0.537, 4832/6976 datapoints
2025-03-06 21:00:16,219 - INFO - validation batch 201, loss: 0.457, 6432/6976 datapoints
2025-03-06 21:00:16,234 - INFO - Epoch 563/800 done.
2025-03-06 21:00:16,234 - INFO - Final validation performance:
Loss: 0.695, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:16,235 - INFO - Beginning epoch 564/800
2025-03-06 21:00:16,238 - INFO - training batch 1, loss: 0.203, 32/28000 datapoints
2025-03-06 21:00:16,366 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-06 21:00:16,487 - INFO - training batch 101, loss: 0.066, 3232/28000 datapoints
2025-03-06 21:00:16,613 - INFO - training batch 151, loss: 0.048, 4832/28000 datapoints
2025-03-06 21:00:16,765 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-06 21:00:16,889 - INFO - training batch 251, loss: 0.194, 8032/28000 datapoints
2025-03-06 21:00:17,010 - INFO - training batch 301, loss: 0.179, 9632/28000 datapoints
2025-03-06 21:00:17,132 - INFO - training batch 351, loss: 0.158, 11232/28000 datapoints
2025-03-06 21:00:17,252 - INFO - training batch 401, loss: 0.249, 12832/28000 datapoints
2025-03-06 21:00:17,375 - INFO - training batch 451, loss: 0.124, 14432/28000 datapoints
2025-03-06 21:00:17,500 - INFO - training batch 501, loss: 0.072, 16032/28000 datapoints
2025-03-06 21:00:17,620 - INFO - training batch 551, loss: 0.090, 17632/28000 datapoints
2025-03-06 21:00:17,747 - INFO - training batch 601, loss: 0.053, 19232/28000 datapoints
2025-03-06 21:00:17,871 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:17,991 - INFO - training batch 701, loss: 0.136, 22432/28000 datapoints
2025-03-06 21:00:18,113 - INFO - training batch 751, loss: 0.084, 24032/28000 datapoints
2025-03-06 21:00:18,233 - INFO - training batch 801, loss: 0.068, 25632/28000 datapoints
2025-03-06 21:00:18,357 - INFO - training batch 851, loss: 0.125, 27232/28000 datapoints
2025-03-06 21:00:18,417 - INFO - validation batch 1, loss: 0.169, 32/6976 datapoints
2025-03-06 21:00:18,461 - INFO - validation batch 51, loss: 1.639, 1632/6976 datapoints
2025-03-06 21:00:18,505 - INFO - validation batch 101, loss: 0.680, 3232/6976 datapoints
2025-03-06 21:00:18,549 - INFO - validation batch 151, loss: 0.538, 4832/6976 datapoints
2025-03-06 21:00:18,593 - INFO - validation batch 201, loss: 0.459, 6432/6976 datapoints
2025-03-06 21:00:18,608 - INFO - Epoch 564/800 done.
2025-03-06 21:00:18,608 - INFO - Final validation performance:
Loss: 0.697, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:00:18,609 - INFO - Beginning epoch 565/800
2025-03-06 21:00:18,612 - INFO - training batch 1, loss: 0.202, 32/28000 datapoints
2025-03-06 21:00:18,737 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-06 21:00:18,860 - INFO - training batch 101, loss: 0.065, 3232/28000 datapoints
2025-03-06 21:00:18,981 - INFO - training batch 151, loss: 0.048, 4832/28000 datapoints
2025-03-06 21:00:19,101 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-06 21:00:19,222 - INFO - training batch 251, loss: 0.193, 8032/28000 datapoints
2025-03-06 21:00:19,343 - INFO - training batch 301, loss: 0.178, 9632/28000 datapoints
2025-03-06 21:00:19,465 - INFO - training batch 351, loss: 0.158, 11232/28000 datapoints
2025-03-06 21:00:19,586 - INFO - training batch 401, loss: 0.248, 12832/28000 datapoints
2025-03-06 21:00:19,709 - INFO - training batch 451, loss: 0.128, 14432/28000 datapoints
2025-03-06 21:00:19,833 - INFO - training batch 501, loss: 0.073, 16032/28000 datapoints
2025-03-06 21:00:19,956 - INFO - training batch 551, loss: 0.090, 17632/28000 datapoints
2025-03-06 21:00:20,078 - INFO - training batch 601, loss: 0.053, 19232/28000 datapoints
2025-03-06 21:00:20,197 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:20,316 - INFO - training batch 701, loss: 0.135, 22432/28000 datapoints
2025-03-06 21:00:20,437 - INFO - training batch 751, loss: 0.083, 24032/28000 datapoints
2025-03-06 21:00:20,558 - INFO - training batch 801, loss: 0.068, 25632/28000 datapoints
2025-03-06 21:00:20,686 - INFO - training batch 851, loss: 0.126, 27232/28000 datapoints
2025-03-06 21:00:20,745 - INFO - validation batch 1, loss: 0.171, 32/6976 datapoints
2025-03-06 21:00:20,789 - INFO - validation batch 51, loss: 1.645, 1632/6976 datapoints
2025-03-06 21:00:20,833 - INFO - validation batch 101, loss: 0.681, 3232/6976 datapoints
2025-03-06 21:00:20,878 - INFO - validation batch 151, loss: 0.539, 4832/6976 datapoints
2025-03-06 21:00:20,922 - INFO - validation batch 201, loss: 0.460, 6432/6976 datapoints
2025-03-06 21:00:20,937 - INFO - Epoch 565/800 done.
2025-03-06 21:00:20,937 - INFO - Final validation performance:
Loss: 0.699, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:00:20,937 - INFO - Beginning epoch 566/800
2025-03-06 21:00:20,941 - INFO - training batch 1, loss: 0.201, 32/28000 datapoints
2025-03-06 21:00:21,063 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-06 21:00:21,184 - INFO - training batch 101, loss: 0.065, 3232/28000 datapoints
2025-03-06 21:00:21,304 - INFO - training batch 151, loss: 0.048, 4832/28000 datapoints
2025-03-06 21:00:21,428 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:00:21,550 - INFO - training batch 251, loss: 0.192, 8032/28000 datapoints
2025-03-06 21:00:21,673 - INFO - training batch 301, loss: 0.177, 9632/28000 datapoints
2025-03-06 21:00:21,798 - INFO - training batch 351, loss: 0.158, 11232/28000 datapoints
2025-03-06 21:00:21,922 - INFO - training batch 401, loss: 0.247, 12832/28000 datapoints
2025-03-06 21:00:22,042 - INFO - training batch 451, loss: 0.124, 14432/28000 datapoints
2025-03-06 21:00:22,163 - INFO - training batch 501, loss: 0.072, 16032/28000 datapoints
2025-03-06 21:00:22,291 - INFO - training batch 551, loss: 0.090, 17632/28000 datapoints
2025-03-06 21:00:22,416 - INFO - training batch 601, loss: 0.053, 19232/28000 datapoints
2025-03-06 21:00:22,538 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:22,662 - INFO - training batch 701, loss: 0.135, 22432/28000 datapoints
2025-03-06 21:00:22,782 - INFO - training batch 751, loss: 0.082, 24032/28000 datapoints
2025-03-06 21:00:22,905 - INFO - training batch 801, loss: 0.067, 25632/28000 datapoints
2025-03-06 21:00:23,024 - INFO - training batch 851, loss: 0.124, 27232/28000 datapoints
2025-03-06 21:00:23,085 - INFO - validation batch 1, loss: 0.172, 32/6976 datapoints
2025-03-06 21:00:23,130 - INFO - validation batch 51, loss: 1.651, 1632/6976 datapoints
2025-03-06 21:00:23,174 - INFO - validation batch 101, loss: 0.683, 3232/6976 datapoints
2025-03-06 21:00:23,218 - INFO - validation batch 151, loss: 0.539, 4832/6976 datapoints
2025-03-06 21:00:23,262 - INFO - validation batch 201, loss: 0.460, 6432/6976 datapoints
2025-03-06 21:00:23,277 - INFO - Epoch 566/800 done.
2025-03-06 21:00:23,277 - INFO - Final validation performance:
Loss: 0.701, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:00:23,278 - INFO - Beginning epoch 567/800
2025-03-06 21:00:23,281 - INFO - training batch 1, loss: 0.200, 32/28000 datapoints
2025-03-06 21:00:23,407 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-06 21:00:23,527 - INFO - training batch 101, loss: 0.065, 3232/28000 datapoints
2025-03-06 21:00:23,650 - INFO - training batch 151, loss: 0.048, 4832/28000 datapoints
2025-03-06 21:00:23,774 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:00:23,900 - INFO - training batch 251, loss: 0.191, 8032/28000 datapoints
2025-03-06 21:00:24,023 - INFO - training batch 301, loss: 0.174, 9632/28000 datapoints
2025-03-06 21:00:24,145 - INFO - training batch 351, loss: 0.158, 11232/28000 datapoints
2025-03-06 21:00:24,264 - INFO - training batch 401, loss: 0.246, 12832/28000 datapoints
2025-03-06 21:00:24,383 - INFO - training batch 451, loss: 0.126, 14432/28000 datapoints
2025-03-06 21:00:24,508 - INFO - training batch 501, loss: 0.072, 16032/28000 datapoints
2025-03-06 21:00:24,629 - INFO - training batch 551, loss: 0.089, 17632/28000 datapoints
2025-03-06 21:00:24,754 - INFO - training batch 601, loss: 0.053, 19232/28000 datapoints
2025-03-06 21:00:24,876 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:25,002 - INFO - training batch 701, loss: 0.133, 22432/28000 datapoints
2025-03-06 21:00:25,123 - INFO - training batch 751, loss: 0.082, 24032/28000 datapoints
2025-03-06 21:00:25,242 - INFO - training batch 801, loss: 0.068, 25632/28000 datapoints
2025-03-06 21:00:25,363 - INFO - training batch 851, loss: 0.125, 27232/28000 datapoints
2025-03-06 21:00:25,423 - INFO - validation batch 1, loss: 0.174, 32/6976 datapoints
2025-03-06 21:00:25,468 - INFO - validation batch 51, loss: 1.654, 1632/6976 datapoints
2025-03-06 21:00:25,513 - INFO - validation batch 101, loss: 0.685, 3232/6976 datapoints
2025-03-06 21:00:25,557 - INFO - validation batch 151, loss: 0.543, 4832/6976 datapoints
2025-03-06 21:00:25,601 - INFO - validation batch 201, loss: 0.462, 6432/6976 datapoints
2025-03-06 21:00:25,616 - INFO - Epoch 567/800 done.
2025-03-06 21:00:25,616 - INFO - Final validation performance:
Loss: 0.704, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:00:25,616 - INFO - Beginning epoch 568/800
2025-03-06 21:00:25,620 - INFO - training batch 1, loss: 0.200, 32/28000 datapoints
2025-03-06 21:00:25,745 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-06 21:00:25,869 - INFO - training batch 101, loss: 0.065, 3232/28000 datapoints
2025-03-06 21:00:25,992 - INFO - training batch 151, loss: 0.048, 4832/28000 datapoints
2025-03-06 21:00:26,113 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:00:26,233 - INFO - training batch 251, loss: 0.190, 8032/28000 datapoints
2025-03-06 21:00:26,354 - INFO - training batch 301, loss: 0.174, 9632/28000 datapoints
2025-03-06 21:00:26,475 - INFO - training batch 351, loss: 0.158, 11232/28000 datapoints
2025-03-06 21:00:26,594 - INFO - training batch 401, loss: 0.245, 12832/28000 datapoints
2025-03-06 21:00:26,723 - INFO - training batch 451, loss: 0.122, 14432/28000 datapoints
2025-03-06 21:00:26,862 - INFO - training batch 501, loss: 0.071, 16032/28000 datapoints
2025-03-06 21:00:26,985 - INFO - training batch 551, loss: 0.088, 17632/28000 datapoints
2025-03-06 21:00:27,105 - INFO - training batch 601, loss: 0.053, 19232/28000 datapoints
2025-03-06 21:00:27,226 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:27,346 - INFO - training batch 701, loss: 0.133, 22432/28000 datapoints
2025-03-06 21:00:27,468 - INFO - training batch 751, loss: 0.082, 24032/28000 datapoints
2025-03-06 21:00:27,589 - INFO - training batch 801, loss: 0.067, 25632/28000 datapoints
2025-03-06 21:00:27,715 - INFO - training batch 851, loss: 0.124, 27232/28000 datapoints
2025-03-06 21:00:27,775 - INFO - validation batch 1, loss: 0.177, 32/6976 datapoints
2025-03-06 21:00:27,823 - INFO - validation batch 51, loss: 1.659, 1632/6976 datapoints
2025-03-06 21:00:27,866 - INFO - validation batch 101, loss: 0.688, 3232/6976 datapoints
2025-03-06 21:00:27,910 - INFO - validation batch 151, loss: 0.543, 4832/6976 datapoints
2025-03-06 21:00:27,955 - INFO - validation batch 201, loss: 0.462, 6432/6976 datapoints
2025-03-06 21:00:27,972 - INFO - Epoch 568/800 done.
2025-03-06 21:00:27,972 - INFO - Final validation performance:
Loss: 0.706, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:27,972 - INFO - Beginning epoch 569/800
2025-03-06 21:00:27,976 - INFO - training batch 1, loss: 0.199, 32/28000 datapoints
2025-03-06 21:00:28,107 - INFO - training batch 51, loss: 0.053, 1632/28000 datapoints
2025-03-06 21:00:28,228 - INFO - training batch 101, loss: 0.065, 3232/28000 datapoints
2025-03-06 21:00:28,350 - INFO - training batch 151, loss: 0.048, 4832/28000 datapoints
2025-03-06 21:00:28,472 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:00:28,592 - INFO - training batch 251, loss: 0.189, 8032/28000 datapoints
2025-03-06 21:00:28,715 - INFO - training batch 301, loss: 0.171, 9632/28000 datapoints
2025-03-06 21:00:28,833 - INFO - training batch 351, loss: 0.157, 11232/28000 datapoints
2025-03-06 21:00:28,954 - INFO - training batch 401, loss: 0.244, 12832/28000 datapoints
2025-03-06 21:00:29,077 - INFO - training batch 451, loss: 0.125, 14432/28000 datapoints
2025-03-06 21:00:29,198 - INFO - training batch 501, loss: 0.070, 16032/28000 datapoints
2025-03-06 21:00:29,317 - INFO - training batch 551, loss: 0.088, 17632/28000 datapoints
2025-03-06 21:00:29,436 - INFO - training batch 601, loss: 0.053, 19232/28000 datapoints
2025-03-06 21:00:29,556 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:29,682 - INFO - training batch 701, loss: 0.132, 22432/28000 datapoints
2025-03-06 21:00:29,801 - INFO - training batch 751, loss: 0.082, 24032/28000 datapoints
2025-03-06 21:00:29,928 - INFO - training batch 801, loss: 0.067, 25632/28000 datapoints
2025-03-06 21:00:30,048 - INFO - training batch 851, loss: 0.124, 27232/28000 datapoints
2025-03-06 21:00:30,108 - INFO - validation batch 1, loss: 0.179, 32/6976 datapoints
2025-03-06 21:00:30,152 - INFO - validation batch 51, loss: 1.664, 1632/6976 datapoints
2025-03-06 21:00:30,208 - INFO - validation batch 101, loss: 0.689, 3232/6976 datapoints
2025-03-06 21:00:30,254 - INFO - validation batch 151, loss: 0.545, 4832/6976 datapoints
2025-03-06 21:00:30,304 - INFO - validation batch 201, loss: 0.462, 6432/6976 datapoints
2025-03-06 21:00:30,319 - INFO - Epoch 569/800 done.
2025-03-06 21:00:30,319 - INFO - Final validation performance:
Loss: 0.708, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:30,320 - INFO - Beginning epoch 570/800
2025-03-06 21:00:30,324 - INFO - training batch 1, loss: 0.198, 32/28000 datapoints
2025-03-06 21:00:30,453 - INFO - training batch 51, loss: 0.053, 1632/28000 datapoints
2025-03-06 21:00:30,584 - INFO - training batch 101, loss: 0.065, 3232/28000 datapoints
2025-03-06 21:00:30,709 - INFO - training batch 151, loss: 0.047, 4832/28000 datapoints
2025-03-06 21:00:30,833 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:00:30,960 - INFO - training batch 251, loss: 0.189, 8032/28000 datapoints
2025-03-06 21:00:31,085 - INFO - training batch 301, loss: 0.169, 9632/28000 datapoints
2025-03-06 21:00:31,210 - INFO - training batch 351, loss: 0.157, 11232/28000 datapoints
2025-03-06 21:00:31,335 - INFO - training batch 401, loss: 0.242, 12832/28000 datapoints
2025-03-06 21:00:31,461 - INFO - training batch 451, loss: 0.121, 14432/28000 datapoints
2025-03-06 21:00:31,587 - INFO - training batch 501, loss: 0.069, 16032/28000 datapoints
2025-03-06 21:00:31,714 - INFO - training batch 551, loss: 0.087, 17632/28000 datapoints
2025-03-06 21:00:31,844 - INFO - training batch 601, loss: 0.053, 19232/28000 datapoints
2025-03-06 21:00:31,969 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:32,094 - INFO - training batch 701, loss: 0.131, 22432/28000 datapoints
2025-03-06 21:00:32,218 - INFO - training batch 751, loss: 0.081, 24032/28000 datapoints
2025-03-06 21:00:32,346 - INFO - training batch 801, loss: 0.066, 25632/28000 datapoints
2025-03-06 21:00:32,474 - INFO - training batch 851, loss: 0.123, 27232/28000 datapoints
2025-03-06 21:00:32,540 - INFO - validation batch 1, loss: 0.180, 32/6976 datapoints
2025-03-06 21:00:32,586 - INFO - validation batch 51, loss: 1.669, 1632/6976 datapoints
2025-03-06 21:00:32,631 - INFO - validation batch 101, loss: 0.693, 3232/6976 datapoints
2025-03-06 21:00:32,680 - INFO - validation batch 151, loss: 0.546, 4832/6976 datapoints
2025-03-06 21:00:32,726 - INFO - validation batch 201, loss: 0.463, 6432/6976 datapoints
2025-03-06 21:00:32,741 - INFO - Epoch 570/800 done.
2025-03-06 21:00:32,741 - INFO - Final validation performance:
Loss: 0.710, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:32,741 - INFO - Beginning epoch 571/800
2025-03-06 21:00:32,745 - INFO - training batch 1, loss: 0.197, 32/28000 datapoints
2025-03-06 21:00:32,867 - INFO - training batch 51, loss: 0.053, 1632/28000 datapoints
2025-03-06 21:00:32,989 - INFO - training batch 101, loss: 0.065, 3232/28000 datapoints
2025-03-06 21:00:33,114 - INFO - training batch 151, loss: 0.046, 4832/28000 datapoints
2025-03-06 21:00:33,234 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:00:33,354 - INFO - training batch 251, loss: 0.187, 8032/28000 datapoints
2025-03-06 21:00:33,475 - INFO - training batch 301, loss: 0.168, 9632/28000 datapoints
2025-03-06 21:00:33,596 - INFO - training batch 351, loss: 0.156, 11232/28000 datapoints
2025-03-06 21:00:33,719 - INFO - training batch 401, loss: 0.241, 12832/28000 datapoints
2025-03-06 21:00:33,843 - INFO - training batch 451, loss: 0.122, 14432/28000 datapoints
2025-03-06 21:00:33,964 - INFO - training batch 501, loss: 0.070, 16032/28000 datapoints
2025-03-06 21:00:34,085 - INFO - training batch 551, loss: 0.088, 17632/28000 datapoints
2025-03-06 21:00:34,205 - INFO - training batch 601, loss: 0.052, 19232/28000 datapoints
2025-03-06 21:00:34,324 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:34,444 - INFO - training batch 701, loss: 0.130, 22432/28000 datapoints
2025-03-06 21:00:34,564 - INFO - training batch 751, loss: 0.081, 24032/28000 datapoints
2025-03-06 21:00:34,688 - INFO - training batch 801, loss: 0.066, 25632/28000 datapoints
2025-03-06 21:00:34,807 - INFO - training batch 851, loss: 0.123, 27232/28000 datapoints
2025-03-06 21:00:34,869 - INFO - validation batch 1, loss: 0.182, 32/6976 datapoints
2025-03-06 21:00:34,917 - INFO - validation batch 51, loss: 1.672, 1632/6976 datapoints
2025-03-06 21:00:34,962 - INFO - validation batch 101, loss: 0.695, 3232/6976 datapoints
2025-03-06 21:00:35,005 - INFO - validation batch 151, loss: 0.546, 4832/6976 datapoints
2025-03-06 21:00:35,050 - INFO - validation batch 201, loss: 0.464, 6432/6976 datapoints
2025-03-06 21:00:35,066 - INFO - Epoch 571/800 done.
2025-03-06 21:00:35,067 - INFO - Final validation performance:
Loss: 0.712, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:35,067 - INFO - Beginning epoch 572/800
2025-03-06 21:00:35,071 - INFO - training batch 1, loss: 0.196, 32/28000 datapoints
2025-03-06 21:00:35,194 - INFO - training batch 51, loss: 0.053, 1632/28000 datapoints
2025-03-06 21:00:35,314 - INFO - training batch 101, loss: 0.064, 3232/28000 datapoints
2025-03-06 21:00:35,435 - INFO - training batch 151, loss: 0.046, 4832/28000 datapoints
2025-03-06 21:00:35,557 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:00:35,684 - INFO - training batch 251, loss: 0.186, 8032/28000 datapoints
2025-03-06 21:00:35,806 - INFO - training batch 301, loss: 0.166, 9632/28000 datapoints
2025-03-06 21:00:35,933 - INFO - training batch 351, loss: 0.156, 11232/28000 datapoints
2025-03-06 21:00:36,053 - INFO - training batch 401, loss: 0.240, 12832/28000 datapoints
2025-03-06 21:00:36,176 - INFO - training batch 451, loss: 0.123, 14432/28000 datapoints
2025-03-06 21:00:36,298 - INFO - training batch 501, loss: 0.069, 16032/28000 datapoints
2025-03-06 21:00:36,420 - INFO - training batch 551, loss: 0.086, 17632/28000 datapoints
2025-03-06 21:00:36,541 - INFO - training batch 601, loss: 0.052, 19232/28000 datapoints
2025-03-06 21:00:36,664 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:36,783 - INFO - training batch 701, loss: 0.130, 22432/28000 datapoints
2025-03-06 21:00:36,928 - INFO - training batch 751, loss: 0.080, 24032/28000 datapoints
2025-03-06 21:00:37,048 - INFO - training batch 801, loss: 0.066, 25632/28000 datapoints
2025-03-06 21:00:37,170 - INFO - training batch 851, loss: 0.123, 27232/28000 datapoints
2025-03-06 21:00:37,229 - INFO - validation batch 1, loss: 0.184, 32/6976 datapoints
2025-03-06 21:00:37,274 - INFO - validation batch 51, loss: 1.679, 1632/6976 datapoints
2025-03-06 21:00:37,317 - INFO - validation batch 101, loss: 0.697, 3232/6976 datapoints
2025-03-06 21:00:37,361 - INFO - validation batch 151, loss: 0.548, 4832/6976 datapoints
2025-03-06 21:00:37,406 - INFO - validation batch 201, loss: 0.464, 6432/6976 datapoints
2025-03-06 21:00:37,421 - INFO - Epoch 572/800 done.
2025-03-06 21:00:37,421 - INFO - Final validation performance:
Loss: 0.714, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:37,422 - INFO - Beginning epoch 573/800
2025-03-06 21:00:37,426 - INFO - training batch 1, loss: 0.196, 32/28000 datapoints
2025-03-06 21:00:37,549 - INFO - training batch 51, loss: 0.053, 1632/28000 datapoints
2025-03-06 21:00:37,703 - INFO - training batch 101, loss: 0.064, 3232/28000 datapoints
2025-03-06 21:00:37,850 - INFO - training batch 151, loss: 0.047, 4832/28000 datapoints
2025-03-06 21:00:37,973 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:00:38,093 - INFO - training batch 251, loss: 0.186, 8032/28000 datapoints
2025-03-06 21:00:38,218 - INFO - training batch 301, loss: 0.164, 9632/28000 datapoints
2025-03-06 21:00:38,338 - INFO - training batch 351, loss: 0.156, 11232/28000 datapoints
2025-03-06 21:00:38,458 - INFO - training batch 401, loss: 0.239, 12832/28000 datapoints
2025-03-06 21:00:38,578 - INFO - training batch 451, loss: 0.120, 14432/28000 datapoints
2025-03-06 21:00:38,702 - INFO - training batch 501, loss: 0.068, 16032/28000 datapoints
2025-03-06 21:00:38,822 - INFO - training batch 551, loss: 0.086, 17632/28000 datapoints
2025-03-06 21:00:38,943 - INFO - training batch 601, loss: 0.052, 19232/28000 datapoints
2025-03-06 21:00:39,068 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:39,191 - INFO - training batch 701, loss: 0.129, 22432/28000 datapoints
2025-03-06 21:00:39,311 - INFO - training batch 751, loss: 0.080, 24032/28000 datapoints
2025-03-06 21:00:39,432 - INFO - training batch 801, loss: 0.065, 25632/28000 datapoints
2025-03-06 21:00:39,553 - INFO - training batch 851, loss: 0.122, 27232/28000 datapoints
2025-03-06 21:00:39,613 - INFO - validation batch 1, loss: 0.186, 32/6976 datapoints
2025-03-06 21:00:39,663 - INFO - validation batch 51, loss: 1.682, 1632/6976 datapoints
2025-03-06 21:00:39,709 - INFO - validation batch 101, loss: 0.699, 3232/6976 datapoints
2025-03-06 21:00:39,753 - INFO - validation batch 151, loss: 0.548, 4832/6976 datapoints
2025-03-06 21:00:39,797 - INFO - validation batch 201, loss: 0.466, 6432/6976 datapoints
2025-03-06 21:00:39,812 - INFO - Epoch 573/800 done.
2025-03-06 21:00:39,812 - INFO - Final validation performance:
Loss: 0.716, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:39,813 - INFO - Beginning epoch 574/800
2025-03-06 21:00:39,817 - INFO - training batch 1, loss: 0.194, 32/28000 datapoints
2025-03-06 21:00:39,943 - INFO - training batch 51, loss: 0.053, 1632/28000 datapoints
2025-03-06 21:00:40,072 - INFO - training batch 101, loss: 0.064, 3232/28000 datapoints
2025-03-06 21:00:40,196 - INFO - training batch 151, loss: 0.045, 4832/28000 datapoints
2025-03-06 21:00:40,317 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:00:40,439 - INFO - training batch 251, loss: 0.185, 8032/28000 datapoints
2025-03-06 21:00:40,561 - INFO - training batch 301, loss: 0.162, 9632/28000 datapoints
2025-03-06 21:00:40,685 - INFO - training batch 351, loss: 0.155, 11232/28000 datapoints
2025-03-06 21:00:40,805 - INFO - training batch 401, loss: 0.238, 12832/28000 datapoints
2025-03-06 21:00:40,925 - INFO - training batch 451, loss: 0.122, 14432/28000 datapoints
2025-03-06 21:00:41,047 - INFO - training batch 501, loss: 0.067, 16032/28000 datapoints
2025-03-06 21:00:41,170 - INFO - training batch 551, loss: 0.085, 17632/28000 datapoints
2025-03-06 21:00:41,293 - INFO - training batch 601, loss: 0.052, 19232/28000 datapoints
2025-03-06 21:00:41,413 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:41,534 - INFO - training batch 701, loss: 0.129, 22432/28000 datapoints
2025-03-06 21:00:41,658 - INFO - training batch 751, loss: 0.079, 24032/28000 datapoints
2025-03-06 21:00:41,777 - INFO - training batch 801, loss: 0.065, 25632/28000 datapoints
2025-03-06 21:00:41,906 - INFO - training batch 851, loss: 0.122, 27232/28000 datapoints
2025-03-06 21:00:41,966 - INFO - validation batch 1, loss: 0.189, 32/6976 datapoints
2025-03-06 21:00:42,010 - INFO - validation batch 51, loss: 1.690, 1632/6976 datapoints
2025-03-06 21:00:42,054 - INFO - validation batch 101, loss: 0.702, 3232/6976 datapoints
2025-03-06 21:00:42,099 - INFO - validation batch 151, loss: 0.551, 4832/6976 datapoints
2025-03-06 21:00:42,144 - INFO - validation batch 201, loss: 0.466, 6432/6976 datapoints
2025-03-06 21:00:42,159 - INFO - Epoch 574/800 done.
2025-03-06 21:00:42,160 - INFO - Final validation performance:
Loss: 0.720, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:42,160 - INFO - Beginning epoch 575/800
2025-03-06 21:00:42,164 - INFO - training batch 1, loss: 0.193, 32/28000 datapoints
2025-03-06 21:00:42,289 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-06 21:00:42,417 - INFO - training batch 101, loss: 0.064, 3232/28000 datapoints
2025-03-06 21:00:42,548 - INFO - training batch 151, loss: 0.045, 4832/28000 datapoints
2025-03-06 21:00:42,672 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:00:42,793 - INFO - training batch 251, loss: 0.184, 8032/28000 datapoints
2025-03-06 21:00:42,912 - INFO - training batch 301, loss: 0.161, 9632/28000 datapoints
2025-03-06 21:00:43,032 - INFO - training batch 351, loss: 0.155, 11232/28000 datapoints
2025-03-06 21:00:43,153 - INFO - training batch 401, loss: 0.237, 12832/28000 datapoints
2025-03-06 21:00:43,274 - INFO - training batch 451, loss: 0.119, 14432/28000 datapoints
2025-03-06 21:00:43,395 - INFO - training batch 501, loss: 0.068, 16032/28000 datapoints
2025-03-06 21:00:43,517 - INFO - training batch 551, loss: 0.084, 17632/28000 datapoints
2025-03-06 21:00:43,643 - INFO - training batch 601, loss: 0.052, 19232/28000 datapoints
2025-03-06 21:00:43,765 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:43,889 - INFO - training batch 701, loss: 0.128, 22432/28000 datapoints
2025-03-06 21:00:44,010 - INFO - training batch 751, loss: 0.078, 24032/28000 datapoints
2025-03-06 21:00:44,131 - INFO - training batch 801, loss: 0.065, 25632/28000 datapoints
2025-03-06 21:00:44,253 - INFO - training batch 851, loss: 0.121, 27232/28000 datapoints
2025-03-06 21:00:44,313 - INFO - validation batch 1, loss: 0.190, 32/6976 datapoints
2025-03-06 21:00:44,357 - INFO - validation batch 51, loss: 1.693, 1632/6976 datapoints
2025-03-06 21:00:44,401 - INFO - validation batch 101, loss: 0.705, 3232/6976 datapoints
2025-03-06 21:00:44,446 - INFO - validation batch 151, loss: 0.552, 4832/6976 datapoints
2025-03-06 21:00:44,490 - INFO - validation batch 201, loss: 0.467, 6432/6976 datapoints
2025-03-06 21:00:44,505 - INFO - Epoch 575/800 done.
2025-03-06 21:00:44,505 - INFO - Final validation performance:
Loss: 0.721, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:44,505 - INFO - Beginning epoch 576/800
2025-03-06 21:00:44,509 - INFO - training batch 1, loss: 0.193, 32/28000 datapoints
2025-03-06 21:00:44,634 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-06 21:00:44,761 - INFO - training batch 101, loss: 0.063, 3232/28000 datapoints
2025-03-06 21:00:44,888 - INFO - training batch 151, loss: 0.046, 4832/28000 datapoints
2025-03-06 21:00:45,008 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:00:45,130 - INFO - training batch 251, loss: 0.183, 8032/28000 datapoints
2025-03-06 21:00:45,252 - INFO - training batch 301, loss: 0.160, 9632/28000 datapoints
2025-03-06 21:00:45,372 - INFO - training batch 351, loss: 0.155, 11232/28000 datapoints
2025-03-06 21:00:45,493 - INFO - training batch 401, loss: 0.237, 12832/28000 datapoints
2025-03-06 21:00:45,613 - INFO - training batch 451, loss: 0.121, 14432/28000 datapoints
2025-03-06 21:00:45,740 - INFO - training batch 501, loss: 0.067, 16032/28000 datapoints
2025-03-06 21:00:45,861 - INFO - training batch 551, loss: 0.084, 17632/28000 datapoints
2025-03-06 21:00:45,984 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 21:00:46,106 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-06 21:00:46,226 - INFO - training batch 701, loss: 0.127, 22432/28000 datapoints
2025-03-06 21:00:46,348 - INFO - training batch 751, loss: 0.078, 24032/28000 datapoints
2025-03-06 21:00:46,469 - INFO - training batch 801, loss: 0.064, 25632/28000 datapoints
2025-03-06 21:00:46,589 - INFO - training batch 851, loss: 0.121, 27232/28000 datapoints
2025-03-06 21:00:46,653 - INFO - validation batch 1, loss: 0.192, 32/6976 datapoints
2025-03-06 21:00:46,700 - INFO - validation batch 51, loss: 1.699, 1632/6976 datapoints
2025-03-06 21:00:46,745 - INFO - validation batch 101, loss: 0.707, 3232/6976 datapoints
2025-03-06 21:00:46,789 - INFO - validation batch 151, loss: 0.551, 4832/6976 datapoints
2025-03-06 21:00:46,832 - INFO - validation batch 201, loss: 0.468, 6432/6976 datapoints
2025-03-06 21:00:46,847 - INFO - Epoch 576/800 done.
2025-03-06 21:00:46,847 - INFO - Final validation performance:
Loss: 0.723, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:46,848 - INFO - Beginning epoch 577/800
2025-03-06 21:00:46,851 - INFO - training batch 1, loss: 0.191, 32/28000 datapoints
2025-03-06 21:00:47,000 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-06 21:00:47,122 - INFO - training batch 101, loss: 0.063, 3232/28000 datapoints
2025-03-06 21:00:47,245 - INFO - training batch 151, loss: 0.045, 4832/28000 datapoints
2025-03-06 21:00:47,364 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-06 21:00:47,486 - INFO - training batch 251, loss: 0.182, 8032/28000 datapoints
2025-03-06 21:00:47,608 - INFO - training batch 301, loss: 0.158, 9632/28000 datapoints
2025-03-06 21:00:47,734 - INFO - training batch 351, loss: 0.155, 11232/28000 datapoints
2025-03-06 21:00:47,856 - INFO - training batch 401, loss: 0.234, 12832/28000 datapoints
2025-03-06 21:00:47,981 - INFO - training batch 451, loss: 0.117, 14432/28000 datapoints
2025-03-06 21:00:48,102 - INFO - training batch 501, loss: 0.066, 16032/28000 datapoints
2025-03-06 21:00:48,224 - INFO - training batch 551, loss: 0.083, 17632/28000 datapoints
2025-03-06 21:00:48,346 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 21:00:48,467 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:00:48,587 - INFO - training batch 701, loss: 0.127, 22432/28000 datapoints
2025-03-06 21:00:48,709 - INFO - training batch 751, loss: 0.077, 24032/28000 datapoints
2025-03-06 21:00:48,830 - INFO - training batch 801, loss: 0.064, 25632/28000 datapoints
2025-03-06 21:00:48,951 - INFO - training batch 851, loss: 0.121, 27232/28000 datapoints
2025-03-06 21:00:49,011 - INFO - validation batch 1, loss: 0.194, 32/6976 datapoints
2025-03-06 21:00:49,056 - INFO - validation batch 51, loss: 1.701, 1632/6976 datapoints
2025-03-06 21:00:49,100 - INFO - validation batch 101, loss: 0.709, 3232/6976 datapoints
2025-03-06 21:00:49,144 - INFO - validation batch 151, loss: 0.554, 4832/6976 datapoints
2025-03-06 21:00:49,188 - INFO - validation batch 201, loss: 0.470, 6432/6976 datapoints
2025-03-06 21:00:49,203 - INFO - Epoch 577/800 done.
2025-03-06 21:00:49,203 - INFO - Final validation performance:
Loss: 0.726, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:49,204 - INFO - Beginning epoch 578/800
2025-03-06 21:00:49,207 - INFO - training batch 1, loss: 0.191, 32/28000 datapoints
2025-03-06 21:00:49,332 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-06 21:00:49,452 - INFO - training batch 101, loss: 0.063, 3232/28000 datapoints
2025-03-06 21:00:49,571 - INFO - training batch 151, loss: 0.044, 4832/28000 datapoints
2025-03-06 21:00:49,696 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-06 21:00:49,816 - INFO - training batch 251, loss: 0.182, 8032/28000 datapoints
2025-03-06 21:00:49,941 - INFO - training batch 301, loss: 0.155, 9632/28000 datapoints
2025-03-06 21:00:50,063 - INFO - training batch 351, loss: 0.155, 11232/28000 datapoints
2025-03-06 21:00:50,186 - INFO - training batch 401, loss: 0.233, 12832/28000 datapoints
2025-03-06 21:00:50,313 - INFO - training batch 451, loss: 0.120, 14432/28000 datapoints
2025-03-06 21:00:50,439 - INFO - training batch 501, loss: 0.065, 16032/28000 datapoints
2025-03-06 21:00:50,565 - INFO - training batch 551, loss: 0.082, 17632/28000 datapoints
2025-03-06 21:00:50,690 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 21:00:50,814 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:00:50,940 - INFO - training batch 701, loss: 0.126, 22432/28000 datapoints
2025-03-06 21:00:51,067 - INFO - training batch 751, loss: 0.077, 24032/28000 datapoints
2025-03-06 21:00:51,193 - INFO - training batch 801, loss: 0.064, 25632/28000 datapoints
2025-03-06 21:00:51,318 - INFO - training batch 851, loss: 0.120, 27232/28000 datapoints
2025-03-06 21:00:51,384 - INFO - validation batch 1, loss: 0.198, 32/6976 datapoints
2025-03-06 21:00:51,430 - INFO - validation batch 51, loss: 1.710, 1632/6976 datapoints
2025-03-06 21:00:51,476 - INFO - validation batch 101, loss: 0.710, 3232/6976 datapoints
2025-03-06 21:00:51,521 - INFO - validation batch 151, loss: 0.558, 4832/6976 datapoints
2025-03-06 21:00:51,564 - INFO - validation batch 201, loss: 0.469, 6432/6976 datapoints
2025-03-06 21:00:51,579 - INFO - Epoch 578/800 done.
2025-03-06 21:00:51,580 - INFO - Final validation performance:
Loss: 0.729, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:51,580 - INFO - Beginning epoch 579/800
2025-03-06 21:00:51,584 - INFO - training batch 1, loss: 0.190, 32/28000 datapoints
2025-03-06 21:00:51,708 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-06 21:00:51,830 - INFO - training batch 101, loss: 0.064, 3232/28000 datapoints
2025-03-06 21:00:51,957 - INFO - training batch 151, loss: 0.044, 4832/28000 datapoints
2025-03-06 21:00:52,077 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-06 21:00:52,201 - INFO - training batch 251, loss: 0.181, 8032/28000 datapoints
2025-03-06 21:00:52,323 - INFO - training batch 301, loss: 0.155, 9632/28000 datapoints
2025-03-06 21:00:52,451 - INFO - training batch 351, loss: 0.154, 11232/28000 datapoints
2025-03-06 21:00:52,572 - INFO - training batch 401, loss: 0.232, 12832/28000 datapoints
2025-03-06 21:00:52,707 - INFO - training batch 451, loss: 0.116, 14432/28000 datapoints
2025-03-06 21:00:52,829 - INFO - training batch 501, loss: 0.065, 16032/28000 datapoints
2025-03-06 21:00:52,949 - INFO - training batch 551, loss: 0.082, 17632/28000 datapoints
2025-03-06 21:00:53,068 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 21:00:53,190 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:00:53,320 - INFO - training batch 701, loss: 0.125, 22432/28000 datapoints
2025-03-06 21:00:53,441 - INFO - training batch 751, loss: 0.076, 24032/28000 datapoints
2025-03-06 21:00:53,561 - INFO - training batch 801, loss: 0.063, 25632/28000 datapoints
2025-03-06 21:00:53,696 - INFO - training batch 851, loss: 0.120, 27232/28000 datapoints
2025-03-06 21:00:53,782 - INFO - validation batch 1, loss: 0.199, 32/6976 datapoints
2025-03-06 21:00:53,840 - INFO - validation batch 51, loss: 1.712, 1632/6976 datapoints
2025-03-06 21:00:53,893 - INFO - validation batch 101, loss: 0.713, 3232/6976 datapoints
2025-03-06 21:00:53,940 - INFO - validation batch 151, loss: 0.557, 4832/6976 datapoints
2025-03-06 21:00:53,984 - INFO - validation batch 201, loss: 0.470, 6432/6976 datapoints
2025-03-06 21:00:54,000 - INFO - Epoch 579/800 done.
2025-03-06 21:00:54,001 - INFO - Final validation performance:
Loss: 0.730, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:54,001 - INFO - Beginning epoch 580/800
2025-03-06 21:00:54,004 - INFO - training batch 1, loss: 0.189, 32/28000 datapoints
2025-03-06 21:00:54,127 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-06 21:00:54,248 - INFO - training batch 101, loss: 0.063, 3232/28000 datapoints
2025-03-06 21:00:54,371 - INFO - training batch 151, loss: 0.043, 4832/28000 datapoints
2025-03-06 21:00:54,491 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-06 21:00:54,613 - INFO - training batch 251, loss: 0.180, 8032/28000 datapoints
2025-03-06 21:00:54,741 - INFO - training batch 301, loss: 0.153, 9632/28000 datapoints
2025-03-06 21:00:54,861 - INFO - training batch 351, loss: 0.154, 11232/28000 datapoints
2025-03-06 21:00:54,986 - INFO - training batch 401, loss: 0.230, 12832/28000 datapoints
2025-03-06 21:00:55,108 - INFO - training batch 451, loss: 0.115, 14432/28000 datapoints
2025-03-06 21:00:55,227 - INFO - training batch 501, loss: 0.065, 16032/28000 datapoints
2025-03-06 21:00:55,347 - INFO - training batch 551, loss: 0.081, 17632/28000 datapoints
2025-03-06 21:00:55,469 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 21:00:55,588 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:00:55,710 - INFO - training batch 701, loss: 0.124, 22432/28000 datapoints
2025-03-06 21:00:55,828 - INFO - training batch 751, loss: 0.076, 24032/28000 datapoints
2025-03-06 21:00:55,954 - INFO - training batch 801, loss: 0.063, 25632/28000 datapoints
2025-03-06 21:00:56,075 - INFO - training batch 851, loss: 0.120, 27232/28000 datapoints
2025-03-06 21:00:56,134 - INFO - validation batch 1, loss: 0.201, 32/6976 datapoints
2025-03-06 21:00:56,178 - INFO - validation batch 51, loss: 1.714, 1632/6976 datapoints
2025-03-06 21:00:56,222 - INFO - validation batch 101, loss: 0.717, 3232/6976 datapoints
2025-03-06 21:00:56,267 - INFO - validation batch 151, loss: 0.559, 4832/6976 datapoints
2025-03-06 21:00:56,312 - INFO - validation batch 201, loss: 0.471, 6432/6976 datapoints
2025-03-06 21:00:56,328 - INFO - Epoch 580/800 done.
2025-03-06 21:00:56,328 - INFO - Final validation performance:
Loss: 0.732, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:56,328 - INFO - Beginning epoch 581/800
2025-03-06 21:00:56,332 - INFO - training batch 1, loss: 0.189, 32/28000 datapoints
2025-03-06 21:00:56,457 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-06 21:00:56,578 - INFO - training batch 101, loss: 0.063, 3232/28000 datapoints
2025-03-06 21:00:56,702 - INFO - training batch 151, loss: 0.045, 4832/28000 datapoints
2025-03-06 21:00:56,821 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-06 21:00:56,942 - INFO - training batch 251, loss: 0.180, 8032/28000 datapoints
2025-03-06 21:00:57,088 - INFO - training batch 301, loss: 0.151, 9632/28000 datapoints
2025-03-06 21:00:57,207 - INFO - training batch 351, loss: 0.153, 11232/28000 datapoints
2025-03-06 21:00:57,327 - INFO - training batch 401, loss: 0.231, 12832/28000 datapoints
2025-03-06 21:00:57,450 - INFO - training batch 451, loss: 0.119, 14432/28000 datapoints
2025-03-06 21:00:57,572 - INFO - training batch 501, loss: 0.065, 16032/28000 datapoints
2025-03-06 21:00:57,701 - INFO - training batch 551, loss: 0.081, 17632/28000 datapoints
2025-03-06 21:00:57,821 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 21:00:57,946 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:00:58,065 - INFO - training batch 701, loss: 0.124, 22432/28000 datapoints
2025-03-06 21:00:58,187 - INFO - training batch 751, loss: 0.075, 24032/28000 datapoints
2025-03-06 21:00:58,309 - INFO - training batch 801, loss: 0.063, 25632/28000 datapoints
2025-03-06 21:00:58,430 - INFO - training batch 851, loss: 0.119, 27232/28000 datapoints
2025-03-06 21:00:58,493 - INFO - validation batch 1, loss: 0.206, 32/6976 datapoints
2025-03-06 21:00:58,539 - INFO - validation batch 51, loss: 1.721, 1632/6976 datapoints
2025-03-06 21:00:58,584 - INFO - validation batch 101, loss: 0.717, 3232/6976 datapoints
2025-03-06 21:00:58,631 - INFO - validation batch 151, loss: 0.559, 4832/6976 datapoints
2025-03-06 21:00:58,685 - INFO - validation batch 201, loss: 0.471, 6432/6976 datapoints
2025-03-06 21:00:58,701 - INFO - Epoch 581/800 done.
2025-03-06 21:00:58,701 - INFO - Final validation performance:
Loss: 0.735, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:00:58,701 - INFO - Beginning epoch 582/800
2025-03-06 21:00:58,705 - INFO - training batch 1, loss: 0.188, 32/28000 datapoints
2025-03-06 21:00:58,831 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 21:00:58,960 - INFO - training batch 101, loss: 0.063, 3232/28000 datapoints
2025-03-06 21:00:59,085 - INFO - training batch 151, loss: 0.043, 4832/28000 datapoints
2025-03-06 21:00:59,206 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-06 21:00:59,327 - INFO - training batch 251, loss: 0.179, 8032/28000 datapoints
2025-03-06 21:00:59,449 - INFO - training batch 301, loss: 0.149, 9632/28000 datapoints
2025-03-06 21:00:59,570 - INFO - training batch 351, loss: 0.153, 11232/28000 datapoints
2025-03-06 21:00:59,692 - INFO - training batch 401, loss: 0.228, 12832/28000 datapoints
2025-03-06 21:00:59,812 - INFO - training batch 451, loss: 0.114, 14432/28000 datapoints
2025-03-06 21:00:59,934 - INFO - training batch 501, loss: 0.064, 16032/28000 datapoints
2025-03-06 21:01:00,061 - INFO - training batch 551, loss: 0.080, 17632/28000 datapoints
2025-03-06 21:01:00,183 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 21:01:00,306 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:00,427 - INFO - training batch 701, loss: 0.123, 22432/28000 datapoints
2025-03-06 21:01:00,547 - INFO - training batch 751, loss: 0.075, 24032/28000 datapoints
2025-03-06 21:01:00,669 - INFO - training batch 801, loss: 0.063, 25632/28000 datapoints
2025-03-06 21:01:00,789 - INFO - training batch 851, loss: 0.118, 27232/28000 datapoints
2025-03-06 21:01:00,848 - INFO - validation batch 1, loss: 0.206, 32/6976 datapoints
2025-03-06 21:01:00,890 - INFO - validation batch 51, loss: 1.727, 1632/6976 datapoints
2025-03-06 21:01:00,935 - INFO - validation batch 101, loss: 0.720, 3232/6976 datapoints
2025-03-06 21:01:00,979 - INFO - validation batch 151, loss: 0.560, 4832/6976 datapoints
2025-03-06 21:01:01,022 - INFO - validation batch 201, loss: 0.472, 6432/6976 datapoints
2025-03-06 21:01:01,038 - INFO - Epoch 582/800 done.
2025-03-06 21:01:01,038 - INFO - Final validation performance:
Loss: 0.737, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:01:01,038 - INFO - Beginning epoch 583/800
2025-03-06 21:01:01,042 - INFO - training batch 1, loss: 0.187, 32/28000 datapoints
2025-03-06 21:01:01,164 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 21:01:01,286 - INFO - training batch 101, loss: 0.062, 3232/28000 datapoints
2025-03-06 21:01:01,405 - INFO - training batch 151, loss: 0.044, 4832/28000 datapoints
2025-03-06 21:01:01,527 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-06 21:01:01,650 - INFO - training batch 251, loss: 0.178, 8032/28000 datapoints
2025-03-06 21:01:01,770 - INFO - training batch 301, loss: 0.148, 9632/28000 datapoints
2025-03-06 21:01:01,890 - INFO - training batch 351, loss: 0.153, 11232/28000 datapoints
2025-03-06 21:01:02,013 - INFO - training batch 401, loss: 0.228, 12832/28000 datapoints
2025-03-06 21:01:02,135 - INFO - training batch 451, loss: 0.116, 14432/28000 datapoints
2025-03-06 21:01:02,255 - INFO - training batch 501, loss: 0.064, 16032/28000 datapoints
2025-03-06 21:01:02,377 - INFO - training batch 551, loss: 0.080, 17632/28000 datapoints
2025-03-06 21:01:02,503 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 21:01:02,624 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:02,748 - INFO - training batch 701, loss: 0.122, 22432/28000 datapoints
2025-03-06 21:01:02,873 - INFO - training batch 751, loss: 0.074, 24032/28000 datapoints
2025-03-06 21:01:02,994 - INFO - training batch 801, loss: 0.062, 25632/28000 datapoints
2025-03-06 21:01:03,117 - INFO - training batch 851, loss: 0.118, 27232/28000 datapoints
2025-03-06 21:01:03,176 - INFO - validation batch 1, loss: 0.211, 32/6976 datapoints
2025-03-06 21:01:03,220 - INFO - validation batch 51, loss: 1.731, 1632/6976 datapoints
2025-03-06 21:01:03,264 - INFO - validation batch 101, loss: 0.723, 3232/6976 datapoints
2025-03-06 21:01:03,308 - INFO - validation batch 151, loss: 0.562, 4832/6976 datapoints
2025-03-06 21:01:03,351 - INFO - validation batch 201, loss: 0.474, 6432/6976 datapoints
2025-03-06 21:01:03,367 - INFO - Epoch 583/800 done.
2025-03-06 21:01:03,367 - INFO - Final validation performance:
Loss: 0.740, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:01:03,367 - INFO - Beginning epoch 584/800
2025-03-06 21:01:03,371 - INFO - training batch 1, loss: 0.186, 32/28000 datapoints
2025-03-06 21:01:03,496 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 21:01:03,616 - INFO - training batch 101, loss: 0.062, 3232/28000 datapoints
2025-03-06 21:01:03,742 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-06 21:01:03,862 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-06 21:01:03,988 - INFO - training batch 251, loss: 0.177, 8032/28000 datapoints
2025-03-06 21:01:04,110 - INFO - training batch 301, loss: 0.146, 9632/28000 datapoints
2025-03-06 21:01:04,229 - INFO - training batch 351, loss: 0.153, 11232/28000 datapoints
2025-03-06 21:01:04,350 - INFO - training batch 401, loss: 0.226, 12832/28000 datapoints
2025-03-06 21:01:04,471 - INFO - training batch 451, loss: 0.114, 14432/28000 datapoints
2025-03-06 21:01:04,594 - INFO - training batch 501, loss: 0.062, 16032/28000 datapoints
2025-03-06 21:01:04,717 - INFO - training batch 551, loss: 0.079, 17632/28000 datapoints
2025-03-06 21:01:04,838 - INFO - training batch 601, loss: 0.050, 19232/28000 datapoints
2025-03-06 21:01:04,967 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:05,089 - INFO - training batch 701, loss: 0.121, 22432/28000 datapoints
2025-03-06 21:01:05,210 - INFO - training batch 751, loss: 0.073, 24032/28000 datapoints
2025-03-06 21:01:05,331 - INFO - training batch 801, loss: 0.062, 25632/28000 datapoints
2025-03-06 21:01:05,453 - INFO - training batch 851, loss: 0.118, 27232/28000 datapoints
2025-03-06 21:01:05,516 - INFO - validation batch 1, loss: 0.213, 32/6976 datapoints
2025-03-06 21:01:05,559 - INFO - validation batch 51, loss: 1.737, 1632/6976 datapoints
2025-03-06 21:01:05,603 - INFO - validation batch 101, loss: 0.724, 3232/6976 datapoints
2025-03-06 21:01:05,649 - INFO - validation batch 151, loss: 0.563, 4832/6976 datapoints
2025-03-06 21:01:05,692 - INFO - validation batch 201, loss: 0.474, 6432/6976 datapoints
2025-03-06 21:01:05,707 - INFO - Epoch 584/800 done.
2025-03-06 21:01:05,708 - INFO - Final validation performance:
Loss: 0.742, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:01:05,708 - INFO - Beginning epoch 585/800
2025-03-06 21:01:05,711 - INFO - training batch 1, loss: 0.185, 32/28000 datapoints
2025-03-06 21:01:05,833 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 21:01:05,953 - INFO - training batch 101, loss: 0.062, 3232/28000 datapoints
2025-03-06 21:01:06,080 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-06 21:01:06,199 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 21:01:06,321 - INFO - training batch 251, loss: 0.176, 8032/28000 datapoints
2025-03-06 21:01:06,447 - INFO - training batch 301, loss: 0.145, 9632/28000 datapoints
2025-03-06 21:01:06,567 - INFO - training batch 351, loss: 0.153, 11232/28000 datapoints
2025-03-06 21:01:06,688 - INFO - training batch 401, loss: 0.225, 12832/28000 datapoints
2025-03-06 21:01:06,810 - INFO - training batch 451, loss: 0.115, 14432/28000 datapoints
2025-03-06 21:01:06,932 - INFO - training batch 501, loss: 0.063, 16032/28000 datapoints
2025-03-06 21:01:07,054 - INFO - training batch 551, loss: 0.079, 17632/28000 datapoints
2025-03-06 21:01:07,205 - INFO - training batch 601, loss: 0.050, 19232/28000 datapoints
2025-03-06 21:01:07,326 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:07,447 - INFO - training batch 701, loss: 0.121, 22432/28000 datapoints
2025-03-06 21:01:07,569 - INFO - training batch 751, loss: 0.073, 24032/28000 datapoints
2025-03-06 21:01:07,698 - INFO - training batch 801, loss: 0.061, 25632/28000 datapoints
2025-03-06 21:01:07,820 - INFO - training batch 851, loss: 0.117, 27232/28000 datapoints
2025-03-06 21:01:07,880 - INFO - validation batch 1, loss: 0.218, 32/6976 datapoints
2025-03-06 21:01:07,924 - INFO - validation batch 51, loss: 1.742, 1632/6976 datapoints
2025-03-06 21:01:07,967 - INFO - validation batch 101, loss: 0.726, 3232/6976 datapoints
2025-03-06 21:01:08,017 - INFO - validation batch 151, loss: 0.565, 4832/6976 datapoints
2025-03-06 21:01:08,062 - INFO - validation batch 201, loss: 0.475, 6432/6976 datapoints
2025-03-06 21:01:08,077 - INFO - Epoch 585/800 done.
2025-03-06 21:01:08,077 - INFO - Final validation performance:
Loss: 0.745, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:01:08,078 - INFO - Beginning epoch 586/800
2025-03-06 21:01:08,081 - INFO - training batch 1, loss: 0.185, 32/28000 datapoints
2025-03-06 21:01:08,203 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 21:01:08,323 - INFO - training batch 101, loss: 0.062, 3232/28000 datapoints
2025-03-06 21:01:08,450 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-06 21:01:08,573 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 21:01:08,695 - INFO - training batch 251, loss: 0.175, 8032/28000 datapoints
2025-03-06 21:01:08,814 - INFO - training batch 301, loss: 0.143, 9632/28000 datapoints
2025-03-06 21:01:08,934 - INFO - training batch 351, loss: 0.152, 11232/28000 datapoints
2025-03-06 21:01:09,060 - INFO - training batch 401, loss: 0.224, 12832/28000 datapoints
2025-03-06 21:01:09,181 - INFO - training batch 451, loss: 0.112, 14432/28000 datapoints
2025-03-06 21:01:09,302 - INFO - training batch 501, loss: 0.062, 16032/28000 datapoints
2025-03-06 21:01:09,421 - INFO - training batch 551, loss: 0.078, 17632/28000 datapoints
2025-03-06 21:01:09,543 - INFO - training batch 601, loss: 0.050, 19232/28000 datapoints
2025-03-06 21:01:09,667 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:09,789 - INFO - training batch 701, loss: 0.120, 22432/28000 datapoints
2025-03-06 21:01:09,909 - INFO - training batch 751, loss: 0.073, 24032/28000 datapoints
2025-03-06 21:01:10,055 - INFO - training batch 801, loss: 0.061, 25632/28000 datapoints
2025-03-06 21:01:10,176 - INFO - training batch 851, loss: 0.116, 27232/28000 datapoints
2025-03-06 21:01:10,236 - INFO - validation batch 1, loss: 0.219, 32/6976 datapoints
2025-03-06 21:01:10,281 - INFO - validation batch 51, loss: 1.744, 1632/6976 datapoints
2025-03-06 21:01:10,332 - INFO - validation batch 101, loss: 0.729, 3232/6976 datapoints
2025-03-06 21:01:10,376 - INFO - validation batch 151, loss: 0.565, 4832/6976 datapoints
2025-03-06 21:01:10,421 - INFO - validation batch 201, loss: 0.476, 6432/6976 datapoints
2025-03-06 21:01:10,436 - INFO - Epoch 586/800 done.
2025-03-06 21:01:10,436 - INFO - Final validation performance:
Loss: 0.747, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:01:10,437 - INFO - Beginning epoch 587/800
2025-03-06 21:01:10,440 - INFO - training batch 1, loss: 0.183, 32/28000 datapoints
2025-03-06 21:01:10,572 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 21:01:10,699 - INFO - training batch 101, loss: 0.061, 3232/28000 datapoints
2025-03-06 21:01:10,824 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-06 21:01:10,949 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 21:01:11,076 - INFO - training batch 251, loss: 0.174, 8032/28000 datapoints
2025-03-06 21:01:11,200 - INFO - training batch 301, loss: 0.141, 9632/28000 datapoints
2025-03-06 21:01:11,326 - INFO - training batch 351, loss: 0.152, 11232/28000 datapoints
2025-03-06 21:01:11,452 - INFO - training batch 401, loss: 0.223, 12832/28000 datapoints
2025-03-06 21:01:11,577 - INFO - training batch 451, loss: 0.114, 14432/28000 datapoints
2025-03-06 21:01:11,704 - INFO - training batch 501, loss: 0.062, 16032/28000 datapoints
2025-03-06 21:01:11,830 - INFO - training batch 551, loss: 0.078, 17632/28000 datapoints
2025-03-06 21:01:11,957 - INFO - training batch 601, loss: 0.050, 19232/28000 datapoints
2025-03-06 21:01:12,085 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:12,208 - INFO - training batch 701, loss: 0.120, 22432/28000 datapoints
2025-03-06 21:01:12,337 - INFO - training batch 751, loss: 0.072, 24032/28000 datapoints
2025-03-06 21:01:12,470 - INFO - training batch 801, loss: 0.061, 25632/28000 datapoints
2025-03-06 21:01:12,596 - INFO - training batch 851, loss: 0.116, 27232/28000 datapoints
2025-03-06 21:01:12,661 - INFO - validation batch 1, loss: 0.223, 32/6976 datapoints
2025-03-06 21:01:12,713 - INFO - validation batch 51, loss: 1.749, 1632/6976 datapoints
2025-03-06 21:01:12,781 - INFO - validation batch 101, loss: 0.731, 3232/6976 datapoints
2025-03-06 21:01:12,832 - INFO - validation batch 151, loss: 0.567, 4832/6976 datapoints
2025-03-06 21:01:12,879 - INFO - validation batch 201, loss: 0.477, 6432/6976 datapoints
2025-03-06 21:01:12,908 - INFO - Epoch 587/800 done.
2025-03-06 21:01:12,909 - INFO - Final validation performance:
Loss: 0.749, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:01:12,909 - INFO - Beginning epoch 588/800
2025-03-06 21:01:12,913 - INFO - training batch 1, loss: 0.183, 32/28000 datapoints
2025-03-06 21:01:13,037 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 21:01:13,166 - INFO - training batch 101, loss: 0.061, 3232/28000 datapoints
2025-03-06 21:01:13,291 - INFO - training batch 151, loss: 0.041, 4832/28000 datapoints
2025-03-06 21:01:13,415 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 21:01:13,541 - INFO - training batch 251, loss: 0.173, 8032/28000 datapoints
2025-03-06 21:01:13,669 - INFO - training batch 301, loss: 0.140, 9632/28000 datapoints
2025-03-06 21:01:13,794 - INFO - training batch 351, loss: 0.151, 11232/28000 datapoints
2025-03-06 21:01:13,918 - INFO - training batch 401, loss: 0.222, 12832/28000 datapoints
2025-03-06 21:01:14,047 - INFO - training batch 451, loss: 0.110, 14432/28000 datapoints
2025-03-06 21:01:14,182 - INFO - training batch 501, loss: 0.061, 16032/28000 datapoints
2025-03-06 21:01:14,308 - INFO - training batch 551, loss: 0.078, 17632/28000 datapoints
2025-03-06 21:01:14,434 - INFO - training batch 601, loss: 0.050, 19232/28000 datapoints
2025-03-06 21:01:14,559 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:14,688 - INFO - training batch 701, loss: 0.119, 22432/28000 datapoints
2025-03-06 21:01:14,818 - INFO - training batch 751, loss: 0.071, 24032/28000 datapoints
2025-03-06 21:01:14,955 - INFO - training batch 801, loss: 0.061, 25632/28000 datapoints
2025-03-06 21:01:15,079 - INFO - training batch 851, loss: 0.116, 27232/28000 datapoints
2025-03-06 21:01:15,143 - INFO - validation batch 1, loss: 0.226, 32/6976 datapoints
2025-03-06 21:01:15,190 - INFO - validation batch 51, loss: 1.752, 1632/6976 datapoints
2025-03-06 21:01:15,237 - INFO - validation batch 101, loss: 0.733, 3232/6976 datapoints
2025-03-06 21:01:15,287 - INFO - validation batch 151, loss: 0.566, 4832/6976 datapoints
2025-03-06 21:01:15,333 - INFO - validation batch 201, loss: 0.478, 6432/6976 datapoints
2025-03-06 21:01:15,349 - INFO - Epoch 588/800 done.
2025-03-06 21:01:15,349 - INFO - Final validation performance:
Loss: 0.751, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:01:15,349 - INFO - Beginning epoch 589/800
2025-03-06 21:01:15,353 - INFO - training batch 1, loss: 0.181, 32/28000 datapoints
2025-03-06 21:01:15,477 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 21:01:15,597 - INFO - training batch 101, loss: 0.061, 3232/28000 datapoints
2025-03-06 21:01:15,724 - INFO - training batch 151, loss: 0.041, 4832/28000 datapoints
2025-03-06 21:01:15,845 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 21:01:15,965 - INFO - training batch 251, loss: 0.172, 8032/28000 datapoints
2025-03-06 21:01:16,089 - INFO - training batch 301, loss: 0.138, 9632/28000 datapoints
2025-03-06 21:01:16,209 - INFO - training batch 351, loss: 0.151, 11232/28000 datapoints
2025-03-06 21:01:16,330 - INFO - training batch 401, loss: 0.220, 12832/28000 datapoints
2025-03-06 21:01:16,452 - INFO - training batch 451, loss: 0.113, 14432/28000 datapoints
2025-03-06 21:01:16,571 - INFO - training batch 501, loss: 0.060, 16032/28000 datapoints
2025-03-06 21:01:16,697 - INFO - training batch 551, loss: 0.076, 17632/28000 datapoints
2025-03-06 21:01:16,819 - INFO - training batch 601, loss: 0.050, 19232/28000 datapoints
2025-03-06 21:01:16,938 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:17,056 - INFO - training batch 701, loss: 0.119, 22432/28000 datapoints
2025-03-06 21:01:17,176 - INFO - training batch 751, loss: 0.071, 24032/28000 datapoints
2025-03-06 21:01:17,325 - INFO - training batch 801, loss: 0.060, 25632/28000 datapoints
2025-03-06 21:01:17,448 - INFO - training batch 851, loss: 0.115, 27232/28000 datapoints
2025-03-06 21:01:17,516 - INFO - validation batch 1, loss: 0.231, 32/6976 datapoints
2025-03-06 21:01:17,561 - INFO - validation batch 51, loss: 1.763, 1632/6976 datapoints
2025-03-06 21:01:17,607 - INFO - validation batch 101, loss: 0.734, 3232/6976 datapoints
2025-03-06 21:01:17,657 - INFO - validation batch 151, loss: 0.567, 4832/6976 datapoints
2025-03-06 21:01:17,705 - INFO - validation batch 201, loss: 0.478, 6432/6976 datapoints
2025-03-06 21:01:17,720 - INFO - Epoch 589/800 done.
2025-03-06 21:01:17,720 - INFO - Final validation performance:
Loss: 0.755, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:01:17,721 - INFO - Beginning epoch 590/800
2025-03-06 21:01:17,724 - INFO - training batch 1, loss: 0.180, 32/28000 datapoints
2025-03-06 21:01:17,847 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-06 21:01:17,969 - INFO - training batch 101, loss: 0.061, 3232/28000 datapoints
2025-03-06 21:01:18,094 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-06 21:01:18,243 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 21:01:18,368 - INFO - training batch 251, loss: 0.171, 8032/28000 datapoints
2025-03-06 21:01:18,490 - INFO - training batch 301, loss: 0.137, 9632/28000 datapoints
2025-03-06 21:01:18,612 - INFO - training batch 351, loss: 0.149, 11232/28000 datapoints
2025-03-06 21:01:18,736 - INFO - training batch 401, loss: 0.221, 12832/28000 datapoints
2025-03-06 21:01:18,857 - INFO - training batch 451, loss: 0.109, 14432/28000 datapoints
2025-03-06 21:01:18,978 - INFO - training batch 501, loss: 0.060, 16032/28000 datapoints
2025-03-06 21:01:19,100 - INFO - training batch 551, loss: 0.076, 17632/28000 datapoints
2025-03-06 21:01:19,221 - INFO - training batch 601, loss: 0.050, 19232/28000 datapoints
2025-03-06 21:01:19,342 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:19,464 - INFO - training batch 701, loss: 0.118, 22432/28000 datapoints
2025-03-06 21:01:19,585 - INFO - training batch 751, loss: 0.070, 24032/28000 datapoints
2025-03-06 21:01:19,709 - INFO - training batch 801, loss: 0.060, 25632/28000 datapoints
2025-03-06 21:01:19,830 - INFO - training batch 851, loss: 0.115, 27232/28000 datapoints
2025-03-06 21:01:19,890 - INFO - validation batch 1, loss: 0.233, 32/6976 datapoints
2025-03-06 21:01:19,936 - INFO - validation batch 51, loss: 1.766, 1632/6976 datapoints
2025-03-06 21:01:19,981 - INFO - validation batch 101, loss: 0.737, 3232/6976 datapoints
2025-03-06 21:01:20,027 - INFO - validation batch 151, loss: 0.570, 4832/6976 datapoints
2025-03-06 21:01:20,071 - INFO - validation batch 201, loss: 0.480, 6432/6976 datapoints
2025-03-06 21:01:20,086 - INFO - Epoch 590/800 done.
2025-03-06 21:01:20,086 - INFO - Final validation performance:
Loss: 0.757, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:01:20,087 - INFO - Beginning epoch 591/800
2025-03-06 21:01:20,090 - INFO - training batch 1, loss: 0.180, 32/28000 datapoints
2025-03-06 21:01:20,214 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-06 21:01:20,336 - INFO - training batch 101, loss: 0.060, 3232/28000 datapoints
2025-03-06 21:01:20,460 - INFO - training batch 151, loss: 0.041, 4832/28000 datapoints
2025-03-06 21:01:20,582 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 21:01:20,704 - INFO - training batch 251, loss: 0.170, 8032/28000 datapoints
2025-03-06 21:01:20,824 - INFO - training batch 301, loss: 0.136, 9632/28000 datapoints
2025-03-06 21:01:20,943 - INFO - training batch 351, loss: 0.149, 11232/28000 datapoints
2025-03-06 21:01:21,064 - INFO - training batch 401, loss: 0.218, 12832/28000 datapoints
2025-03-06 21:01:21,185 - INFO - training batch 451, loss: 0.110, 14432/28000 datapoints
2025-03-06 21:01:21,309 - INFO - training batch 501, loss: 0.060, 16032/28000 datapoints
2025-03-06 21:01:21,430 - INFO - training batch 551, loss: 0.076, 17632/28000 datapoints
2025-03-06 21:01:21,552 - INFO - training batch 601, loss: 0.050, 19232/28000 datapoints
2025-03-06 21:01:21,675 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:21,802 - INFO - training batch 701, loss: 0.117, 22432/28000 datapoints
2025-03-06 21:01:21,921 - INFO - training batch 751, loss: 0.070, 24032/28000 datapoints
2025-03-06 21:01:22,046 - INFO - training batch 801, loss: 0.060, 25632/28000 datapoints
2025-03-06 21:01:22,169 - INFO - training batch 851, loss: 0.114, 27232/28000 datapoints
2025-03-06 21:01:22,229 - INFO - validation batch 1, loss: 0.237, 32/6976 datapoints
2025-03-06 21:01:22,274 - INFO - validation batch 51, loss: 1.771, 1632/6976 datapoints
2025-03-06 21:01:22,319 - INFO - validation batch 101, loss: 0.738, 3232/6976 datapoints
2025-03-06 21:01:22,365 - INFO - validation batch 151, loss: 0.571, 4832/6976 datapoints
2025-03-06 21:01:22,409 - INFO - validation batch 201, loss: 0.480, 6432/6976 datapoints
2025-03-06 21:01:22,425 - INFO - Epoch 591/800 done.
2025-03-06 21:01:22,426 - INFO - Final validation performance:
Loss: 0.759, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:01:22,426 - INFO - Beginning epoch 592/800
2025-03-06 21:01:22,430 - INFO - training batch 1, loss: 0.180, 32/28000 datapoints
2025-03-06 21:01:22,556 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-06 21:01:22,681 - INFO - training batch 101, loss: 0.060, 3232/28000 datapoints
2025-03-06 21:01:22,808 - INFO - training batch 151, loss: 0.041, 4832/28000 datapoints
2025-03-06 21:01:22,931 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 21:01:23,052 - INFO - training batch 251, loss: 0.169, 8032/28000 datapoints
2025-03-06 21:01:23,173 - INFO - training batch 301, loss: 0.134, 9632/28000 datapoints
2025-03-06 21:01:23,295 - INFO - training batch 351, loss: 0.148, 11232/28000 datapoints
2025-03-06 21:01:23,415 - INFO - training batch 401, loss: 0.218, 12832/28000 datapoints
2025-03-06 21:01:23,539 - INFO - training batch 451, loss: 0.111, 14432/28000 datapoints
2025-03-06 21:01:23,664 - INFO - training batch 501, loss: 0.060, 16032/28000 datapoints
2025-03-06 21:01:23,789 - INFO - training batch 551, loss: 0.075, 17632/28000 datapoints
2025-03-06 21:01:23,910 - INFO - training batch 601, loss: 0.050, 19232/28000 datapoints
2025-03-06 21:01:24,031 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:24,155 - INFO - training batch 701, loss: 0.116, 22432/28000 datapoints
2025-03-06 21:01:24,276 - INFO - training batch 751, loss: 0.069, 24032/28000 datapoints
2025-03-06 21:01:24,398 - INFO - training batch 801, loss: 0.059, 25632/28000 datapoints
2025-03-06 21:01:24,520 - INFO - training batch 851, loss: 0.114, 27232/28000 datapoints
2025-03-06 21:01:24,579 - INFO - validation batch 1, loss: 0.240, 32/6976 datapoints
2025-03-06 21:01:24,624 - INFO - validation batch 51, loss: 1.774, 1632/6976 datapoints
2025-03-06 21:01:24,672 - INFO - validation batch 101, loss: 0.741, 3232/6976 datapoints
2025-03-06 21:01:24,715 - INFO - validation batch 151, loss: 0.570, 4832/6976 datapoints
2025-03-06 21:01:24,762 - INFO - validation batch 201, loss: 0.482, 6432/6976 datapoints
2025-03-06 21:01:24,777 - INFO - Epoch 592/800 done.
2025-03-06 21:01:24,777 - INFO - Final validation performance:
Loss: 0.761, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:01:24,778 - INFO - Beginning epoch 593/800
2025-03-06 21:01:24,782 - INFO - training batch 1, loss: 0.178, 32/28000 datapoints
2025-03-06 21:01:24,908 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-06 21:01:25,032 - INFO - training batch 101, loss: 0.059, 3232/28000 datapoints
2025-03-06 21:01:25,153 - INFO - training batch 151, loss: 0.040, 4832/28000 datapoints
2025-03-06 21:01:25,275 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 21:01:25,396 - INFO - training batch 251, loss: 0.168, 8032/28000 datapoints
2025-03-06 21:01:25,518 - INFO - training batch 301, loss: 0.133, 9632/28000 datapoints
2025-03-06 21:01:25,645 - INFO - training batch 351, loss: 0.149, 11232/28000 datapoints
2025-03-06 21:01:25,767 - INFO - training batch 401, loss: 0.216, 12832/28000 datapoints
2025-03-06 21:01:25,888 - INFO - training batch 451, loss: 0.108, 14432/28000 datapoints
2025-03-06 21:01:26,009 - INFO - training batch 501, loss: 0.059, 16032/28000 datapoints
2025-03-06 21:01:26,135 - INFO - training batch 551, loss: 0.074, 17632/28000 datapoints
2025-03-06 21:01:26,256 - INFO - training batch 601, loss: 0.050, 19232/28000 datapoints
2025-03-06 21:01:26,376 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:26,496 - INFO - training batch 701, loss: 0.116, 22432/28000 datapoints
2025-03-06 21:01:26,616 - INFO - training batch 751, loss: 0.069, 24032/28000 datapoints
2025-03-06 21:01:26,739 - INFO - training batch 801, loss: 0.059, 25632/28000 datapoints
2025-03-06 21:01:26,862 - INFO - training batch 851, loss: 0.114, 27232/28000 datapoints
2025-03-06 21:01:26,922 - INFO - validation batch 1, loss: 0.244, 32/6976 datapoints
2025-03-06 21:01:26,966 - INFO - validation batch 51, loss: 1.777, 1632/6976 datapoints
2025-03-06 21:01:27,010 - INFO - validation batch 101, loss: 0.743, 3232/6976 datapoints
2025-03-06 21:01:27,054 - INFO - validation batch 151, loss: 0.570, 4832/6976 datapoints
2025-03-06 21:01:27,099 - INFO - validation batch 201, loss: 0.484, 6432/6976 datapoints
2025-03-06 21:01:27,114 - INFO - Epoch 593/800 done.
2025-03-06 21:01:27,114 - INFO - Final validation performance:
Loss: 0.764, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:01:27,115 - INFO - Beginning epoch 594/800
2025-03-06 21:01:27,118 - INFO - training batch 1, loss: 0.177, 32/28000 datapoints
2025-03-06 21:01:27,238 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-06 21:01:27,387 - INFO - training batch 101, loss: 0.059, 3232/28000 datapoints
2025-03-06 21:01:27,511 - INFO - training batch 151, loss: 0.040, 4832/28000 datapoints
2025-03-06 21:01:27,633 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 21:01:27,760 - INFO - training batch 251, loss: 0.168, 8032/28000 datapoints
2025-03-06 21:01:27,882 - INFO - training batch 301, loss: 0.131, 9632/28000 datapoints
2025-03-06 21:01:28,001 - INFO - training batch 351, loss: 0.148, 11232/28000 datapoints
2025-03-06 21:01:28,127 - INFO - training batch 401, loss: 0.215, 12832/28000 datapoints
2025-03-06 21:01:28,249 - INFO - training batch 451, loss: 0.111, 14432/28000 datapoints
2025-03-06 21:01:28,371 - INFO - training batch 501, loss: 0.058, 16032/28000 datapoints
2025-03-06 21:01:28,502 - INFO - training batch 551, loss: 0.074, 17632/28000 datapoints
2025-03-06 21:01:28,624 - INFO - training batch 601, loss: 0.050, 19232/28000 datapoints
2025-03-06 21:01:28,747 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:28,870 - INFO - training batch 701, loss: 0.115, 22432/28000 datapoints
2025-03-06 21:01:28,989 - INFO - training batch 751, loss: 0.067, 24032/28000 datapoints
2025-03-06 21:01:29,109 - INFO - training batch 801, loss: 0.058, 25632/28000 datapoints
2025-03-06 21:01:29,229 - INFO - training batch 851, loss: 0.113, 27232/28000 datapoints
2025-03-06 21:01:29,289 - INFO - validation batch 1, loss: 0.249, 32/6976 datapoints
2025-03-06 21:01:29,334 - INFO - validation batch 51, loss: 1.787, 1632/6976 datapoints
2025-03-06 21:01:29,378 - INFO - validation batch 101, loss: 0.744, 3232/6976 datapoints
2025-03-06 21:01:29,424 - INFO - validation batch 151, loss: 0.572, 4832/6976 datapoints
2025-03-06 21:01:29,468 - INFO - validation batch 201, loss: 0.483, 6432/6976 datapoints
2025-03-06 21:01:29,484 - INFO - Epoch 594/800 done.
2025-03-06 21:01:29,484 - INFO - Final validation performance:
Loss: 0.767, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:01:29,485 - INFO - Beginning epoch 595/800
2025-03-06 21:01:29,488 - INFO - training batch 1, loss: 0.176, 32/28000 datapoints
2025-03-06 21:01:29,611 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-06 21:01:29,735 - INFO - training batch 101, loss: 0.059, 3232/28000 datapoints
2025-03-06 21:01:29,860 - INFO - training batch 151, loss: 0.040, 4832/28000 datapoints
2025-03-06 21:01:29,982 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 21:01:30,109 - INFO - training batch 251, loss: 0.166, 8032/28000 datapoints
2025-03-06 21:01:30,230 - INFO - training batch 301, loss: 0.130, 9632/28000 datapoints
2025-03-06 21:01:30,353 - INFO - training batch 351, loss: 0.148, 11232/28000 datapoints
2025-03-06 21:01:30,476 - INFO - training batch 401, loss: 0.214, 12832/28000 datapoints
2025-03-06 21:01:30,603 - INFO - training batch 451, loss: 0.107, 14432/28000 datapoints
2025-03-06 21:01:30,730 - INFO - training batch 501, loss: 0.059, 16032/28000 datapoints
2025-03-06 21:01:30,856 - INFO - training batch 551, loss: 0.074, 17632/28000 datapoints
2025-03-06 21:01:30,983 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 21:01:31,108 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:31,233 - INFO - training batch 701, loss: 0.113, 22432/28000 datapoints
2025-03-06 21:01:31,358 - INFO - training batch 751, loss: 0.067, 24032/28000 datapoints
2025-03-06 21:01:31,484 - INFO - training batch 801, loss: 0.058, 25632/28000 datapoints
2025-03-06 21:01:31,608 - INFO - training batch 851, loss: 0.113, 27232/28000 datapoints
2025-03-06 21:01:31,674 - INFO - validation batch 1, loss: 0.250, 32/6976 datapoints
2025-03-06 21:01:31,722 - INFO - validation batch 51, loss: 1.787, 1632/6976 datapoints
2025-03-06 21:01:31,770 - INFO - validation batch 101, loss: 0.747, 3232/6976 datapoints
2025-03-06 21:01:31,817 - INFO - validation batch 151, loss: 0.573, 4832/6976 datapoints
2025-03-06 21:01:31,868 - INFO - validation batch 201, loss: 0.486, 6432/6976 datapoints
2025-03-06 21:01:31,890 - INFO - Epoch 595/800 done.
2025-03-06 21:01:31,890 - INFO - Final validation performance:
Loss: 0.769, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:01:31,890 - INFO - Beginning epoch 596/800
2025-03-06 21:01:31,894 - INFO - training batch 1, loss: 0.175, 32/28000 datapoints
2025-03-06 21:01:32,024 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-06 21:01:32,154 - INFO - training batch 101, loss: 0.059, 3232/28000 datapoints
2025-03-06 21:01:32,279 - INFO - training batch 151, loss: 0.040, 4832/28000 datapoints
2025-03-06 21:01:32,405 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:01:32,533 - INFO - training batch 251, loss: 0.165, 8032/28000 datapoints
2025-03-06 21:01:32,661 - INFO - training batch 301, loss: 0.128, 9632/28000 datapoints
2025-03-06 21:01:32,786 - INFO - training batch 351, loss: 0.147, 11232/28000 datapoints
2025-03-06 21:01:32,913 - INFO - training batch 401, loss: 0.213, 12832/28000 datapoints
2025-03-06 21:01:33,038 - INFO - training batch 451, loss: 0.109, 14432/28000 datapoints
2025-03-06 21:01:33,162 - INFO - training batch 501, loss: 0.058, 16032/28000 datapoints
2025-03-06 21:01:33,286 - INFO - training batch 551, loss: 0.073, 17632/28000 datapoints
2025-03-06 21:01:33,409 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 21:01:33,535 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:33,664 - INFO - training batch 701, loss: 0.112, 22432/28000 datapoints
2025-03-06 21:01:33,788 - INFO - training batch 751, loss: 0.067, 24032/28000 datapoints
2025-03-06 21:01:33,917 - INFO - training batch 801, loss: 0.058, 25632/28000 datapoints
2025-03-06 21:01:34,042 - INFO - training batch 851, loss: 0.112, 27232/28000 datapoints
2025-03-06 21:01:34,111 - INFO - validation batch 1, loss: 0.254, 32/6976 datapoints
2025-03-06 21:01:34,158 - INFO - validation batch 51, loss: 1.798, 1632/6976 datapoints
2025-03-06 21:01:34,207 - INFO - validation batch 101, loss: 0.750, 3232/6976 datapoints
2025-03-06 21:01:34,259 - INFO - validation batch 151, loss: 0.574, 4832/6976 datapoints
2025-03-06 21:01:34,310 - INFO - validation batch 201, loss: 0.487, 6432/6976 datapoints
2025-03-06 21:01:34,328 - INFO - Epoch 596/800 done.
2025-03-06 21:01:34,328 - INFO - Final validation performance:
Loss: 0.772, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:01:34,329 - INFO - Beginning epoch 597/800
2025-03-06 21:01:34,333 - INFO - training batch 1, loss: 0.174, 32/28000 datapoints
2025-03-06 21:01:34,463 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 21:01:34,588 - INFO - training batch 101, loss: 0.058, 3232/28000 datapoints
2025-03-06 21:01:34,711 - INFO - training batch 151, loss: 0.040, 4832/28000 datapoints
2025-03-06 21:01:34,832 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:01:34,961 - INFO - training batch 251, loss: 0.164, 8032/28000 datapoints
2025-03-06 21:01:35,083 - INFO - training batch 301, loss: 0.127, 9632/28000 datapoints
2025-03-06 21:01:35,203 - INFO - training batch 351, loss: 0.147, 11232/28000 datapoints
2025-03-06 21:01:35,322 - INFO - training batch 401, loss: 0.212, 12832/28000 datapoints
2025-03-06 21:01:35,445 - INFO - training batch 451, loss: 0.106, 14432/28000 datapoints
2025-03-06 21:01:35,567 - INFO - training batch 501, loss: 0.057, 16032/28000 datapoints
2025-03-06 21:01:35,689 - INFO - training batch 551, loss: 0.073, 17632/28000 datapoints
2025-03-06 21:01:35,809 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 21:01:35,929 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:36,047 - INFO - training batch 701, loss: 0.112, 22432/28000 datapoints
2025-03-06 21:01:36,171 - INFO - training batch 751, loss: 0.067, 24032/28000 datapoints
2025-03-06 21:01:36,290 - INFO - training batch 801, loss: 0.057, 25632/28000 datapoints
2025-03-06 21:01:36,420 - INFO - training batch 851, loss: 0.111, 27232/28000 datapoints
2025-03-06 21:01:36,481 - INFO - validation batch 1, loss: 0.258, 32/6976 datapoints
2025-03-06 21:01:36,525 - INFO - validation batch 51, loss: 1.799, 1632/6976 datapoints
2025-03-06 21:01:36,569 - INFO - validation batch 101, loss: 0.751, 3232/6976 datapoints
2025-03-06 21:01:36,614 - INFO - validation batch 151, loss: 0.574, 4832/6976 datapoints
2025-03-06 21:01:36,661 - INFO - validation batch 201, loss: 0.489, 6432/6976 datapoints
2025-03-06 21:01:36,677 - INFO - Epoch 597/800 done.
2025-03-06 21:01:36,677 - INFO - Final validation performance:
Loss: 0.774, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:01:36,678 - INFO - Beginning epoch 598/800
2025-03-06 21:01:36,681 - INFO - training batch 1, loss: 0.173, 32/28000 datapoints
2025-03-06 21:01:36,802 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 21:01:36,928 - INFO - training batch 101, loss: 0.058, 3232/28000 datapoints
2025-03-06 21:01:37,048 - INFO - training batch 151, loss: 0.039, 4832/28000 datapoints
2025-03-06 21:01:37,170 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:01:37,291 - INFO - training batch 251, loss: 0.163, 8032/28000 datapoints
2025-03-06 21:01:37,427 - INFO - training batch 301, loss: 0.126, 9632/28000 datapoints
2025-03-06 21:01:37,565 - INFO - training batch 351, loss: 0.147, 11232/28000 datapoints
2025-03-06 21:01:37,701 - INFO - training batch 401, loss: 0.210, 12832/28000 datapoints
2025-03-06 21:01:37,821 - INFO - training batch 451, loss: 0.107, 14432/28000 datapoints
2025-03-06 21:01:37,946 - INFO - training batch 501, loss: 0.057, 16032/28000 datapoints
2025-03-06 21:01:38,068 - INFO - training batch 551, loss: 0.072, 17632/28000 datapoints
2025-03-06 21:01:38,194 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 21:01:38,313 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-06 21:01:38,435 - INFO - training batch 701, loss: 0.111, 22432/28000 datapoints
2025-03-06 21:01:38,557 - INFO - training batch 751, loss: 0.066, 24032/28000 datapoints
2025-03-06 21:01:38,680 - INFO - training batch 801, loss: 0.057, 25632/28000 datapoints
2025-03-06 21:01:38,799 - INFO - training batch 851, loss: 0.111, 27232/28000 datapoints
2025-03-06 21:01:38,861 - INFO - validation batch 1, loss: 0.260, 32/6976 datapoints
2025-03-06 21:01:38,905 - INFO - validation batch 51, loss: 1.804, 1632/6976 datapoints
2025-03-06 21:01:38,952 - INFO - validation batch 101, loss: 0.753, 3232/6976 datapoints
2025-03-06 21:01:38,998 - INFO - validation batch 151, loss: 0.575, 4832/6976 datapoints
2025-03-06 21:01:39,043 - INFO - validation batch 201, loss: 0.490, 6432/6976 datapoints
2025-03-06 21:01:39,058 - INFO - Epoch 598/800 done.
2025-03-06 21:01:39,058 - INFO - Final validation performance:
Loss: 0.776, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:01:39,059 - INFO - Beginning epoch 599/800
2025-03-06 21:01:39,063 - INFO - training batch 1, loss: 0.173, 32/28000 datapoints
2025-03-06 21:01:39,189 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 21:01:39,309 - INFO - training batch 101, loss: 0.058, 3232/28000 datapoints
2025-03-06 21:01:39,429 - INFO - training batch 151, loss: 0.039, 4832/28000 datapoints
2025-03-06 21:01:39,553 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:01:39,678 - INFO - training batch 251, loss: 0.163, 8032/28000 datapoints
2025-03-06 21:01:39,801 - INFO - training batch 301, loss: 0.125, 9632/28000 datapoints
2025-03-06 21:01:39,921 - INFO - training batch 351, loss: 0.146, 11232/28000 datapoints
2025-03-06 21:01:40,050 - INFO - training batch 401, loss: 0.209, 12832/28000 datapoints
2025-03-06 21:01:40,176 - INFO - training batch 451, loss: 0.105, 14432/28000 datapoints
2025-03-06 21:01:40,297 - INFO - training batch 501, loss: 0.056, 16032/28000 datapoints
2025-03-06 21:01:40,420 - INFO - training batch 551, loss: 0.071, 17632/28000 datapoints
2025-03-06 21:01:40,542 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 21:01:40,666 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:01:40,786 - INFO - training batch 701, loss: 0.111, 22432/28000 datapoints
2025-03-06 21:01:40,906 - INFO - training batch 751, loss: 0.065, 24032/28000 datapoints
2025-03-06 21:01:41,027 - INFO - training batch 801, loss: 0.057, 25632/28000 datapoints
2025-03-06 21:01:41,147 - INFO - training batch 851, loss: 0.110, 27232/28000 datapoints
2025-03-06 21:01:41,207 - INFO - validation batch 1, loss: 0.265, 32/6976 datapoints
2025-03-06 21:01:41,251 - INFO - validation batch 51, loss: 1.814, 1632/6976 datapoints
2025-03-06 21:01:41,296 - INFO - validation batch 101, loss: 0.755, 3232/6976 datapoints
2025-03-06 21:01:41,339 - INFO - validation batch 151, loss: 0.574, 4832/6976 datapoints
2025-03-06 21:01:41,383 - INFO - validation batch 201, loss: 0.491, 6432/6976 datapoints
2025-03-06 21:01:41,399 - INFO - Epoch 599/800 done.
2025-03-06 21:01:41,399 - INFO - Final validation performance:
Loss: 0.780, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:01:41,400 - INFO - Beginning epoch 600/800
2025-03-06 21:01:41,403 - INFO - training batch 1, loss: 0.172, 32/28000 datapoints
2025-03-06 21:01:41,530 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 21:01:41,652 - INFO - training batch 101, loss: 0.058, 3232/28000 datapoints
2025-03-06 21:01:41,774 - INFO - training batch 151, loss: 0.040, 4832/28000 datapoints
2025-03-06 21:01:41,894 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:01:42,016 - INFO - training batch 251, loss: 0.161, 8032/28000 datapoints
2025-03-06 21:01:42,143 - INFO - training batch 301, loss: 0.123, 9632/28000 datapoints
2025-03-06 21:01:42,263 - INFO - training batch 351, loss: 0.146, 11232/28000 datapoints
2025-03-06 21:01:42,383 - INFO - training batch 401, loss: 0.209, 12832/28000 datapoints
2025-03-06 21:01:42,511 - INFO - training batch 451, loss: 0.106, 14432/28000 datapoints
2025-03-06 21:01:42,632 - INFO - training batch 501, loss: 0.055, 16032/28000 datapoints
2025-03-06 21:01:42,758 - INFO - training batch 551, loss: 0.071, 17632/28000 datapoints
2025-03-06 21:01:42,879 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 21:01:43,003 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:01:43,121 - INFO - training batch 701, loss: 0.111, 22432/28000 datapoints
2025-03-06 21:01:43,240 - INFO - training batch 751, loss: 0.064, 24032/28000 datapoints
2025-03-06 21:01:43,359 - INFO - training batch 801, loss: 0.056, 25632/28000 datapoints
2025-03-06 21:01:43,480 - INFO - training batch 851, loss: 0.110, 27232/28000 datapoints
2025-03-06 21:01:43,542 - INFO - validation batch 1, loss: 0.271, 32/6976 datapoints
2025-03-06 21:01:43,585 - INFO - validation batch 51, loss: 1.818, 1632/6976 datapoints
2025-03-06 21:01:43,629 - INFO - validation batch 101, loss: 0.758, 3232/6976 datapoints
2025-03-06 21:01:43,676 - INFO - validation batch 151, loss: 0.576, 4832/6976 datapoints
2025-03-06 21:01:43,727 - INFO - validation batch 201, loss: 0.491, 6432/6976 datapoints
2025-03-06 21:01:43,760 - INFO - Epoch 600/800 done.
2025-03-06 21:01:43,760 - INFO - Final validation performance:
Loss: 0.783, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:01:43,761 - INFO - Beginning epoch 601/800
2025-03-06 21:01:43,764 - INFO - training batch 1, loss: 0.171, 32/28000 datapoints
2025-03-06 21:01:43,887 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 21:01:44,011 - INFO - training batch 101, loss: 0.057, 3232/28000 datapoints
2025-03-06 21:01:44,137 - INFO - training batch 151, loss: 0.039, 4832/28000 datapoints
2025-03-06 21:01:44,258 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:01:44,377 - INFO - training batch 251, loss: 0.161, 8032/28000 datapoints
2025-03-06 21:01:44,498 - INFO - training batch 301, loss: 0.122, 9632/28000 datapoints
2025-03-06 21:01:44,623 - INFO - training batch 351, loss: 0.145, 11232/28000 datapoints
2025-03-06 21:01:44,745 - INFO - training batch 401, loss: 0.208, 12832/28000 datapoints
2025-03-06 21:01:44,868 - INFO - training batch 451, loss: 0.104, 14432/28000 datapoints
2025-03-06 21:01:44,994 - INFO - training batch 501, loss: 0.055, 16032/28000 datapoints
2025-03-06 21:01:45,117 - INFO - training batch 551, loss: 0.071, 17632/28000 datapoints
2025-03-06 21:01:45,235 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 21:01:45,355 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:01:45,479 - INFO - training batch 701, loss: 0.109, 22432/28000 datapoints
2025-03-06 21:01:45,603 - INFO - training batch 751, loss: 0.064, 24032/28000 datapoints
2025-03-06 21:01:45,730 - INFO - training batch 801, loss: 0.056, 25632/28000 datapoints
2025-03-06 21:01:45,852 - INFO - training batch 851, loss: 0.109, 27232/28000 datapoints
2025-03-06 21:01:45,912 - INFO - validation batch 1, loss: 0.273, 32/6976 datapoints
2025-03-06 21:01:45,956 - INFO - validation batch 51, loss: 1.822, 1632/6976 datapoints
2025-03-06 21:01:46,001 - INFO - validation batch 101, loss: 0.760, 3232/6976 datapoints
2025-03-06 21:01:46,047 - INFO - validation batch 151, loss: 0.578, 4832/6976 datapoints
2025-03-06 21:01:46,092 - INFO - validation batch 201, loss: 0.494, 6432/6976 datapoints
2025-03-06 21:01:46,106 - INFO - Epoch 601/800 done.
2025-03-06 21:01:46,107 - INFO - Final validation performance:
Loss: 0.785, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:01:46,107 - INFO - Beginning epoch 602/800
2025-03-06 21:01:46,111 - INFO - training batch 1, loss: 0.170, 32/28000 datapoints
2025-03-06 21:01:46,236 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 21:01:46,360 - INFO - training batch 101, loss: 0.057, 3232/28000 datapoints
2025-03-06 21:01:46,486 - INFO - training batch 151, loss: 0.039, 4832/28000 datapoints
2025-03-06 21:01:46,612 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:01:46,735 - INFO - training batch 251, loss: 0.160, 8032/28000 datapoints
2025-03-06 21:01:46,856 - INFO - training batch 301, loss: 0.121, 9632/28000 datapoints
2025-03-06 21:01:46,976 - INFO - training batch 351, loss: 0.145, 11232/28000 datapoints
2025-03-06 21:01:47,095 - INFO - training batch 401, loss: 0.206, 12832/28000 datapoints
2025-03-06 21:01:47,214 - INFO - training batch 451, loss: 0.103, 14432/28000 datapoints
2025-03-06 21:01:47,335 - INFO - training batch 501, loss: 0.055, 16032/28000 datapoints
2025-03-06 21:01:47,457 - INFO - training batch 551, loss: 0.070, 17632/28000 datapoints
2025-03-06 21:01:47,607 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 21:01:47,736 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:01:47,855 - INFO - training batch 701, loss: 0.109, 22432/28000 datapoints
2025-03-06 21:01:47,975 - INFO - training batch 751, loss: 0.064, 24032/28000 datapoints
2025-03-06 21:01:48,097 - INFO - training batch 801, loss: 0.056, 25632/28000 datapoints
2025-03-06 21:01:48,222 - INFO - training batch 851, loss: 0.109, 27232/28000 datapoints
2025-03-06 21:01:48,283 - INFO - validation batch 1, loss: 0.279, 32/6976 datapoints
2025-03-06 21:01:48,326 - INFO - validation batch 51, loss: 1.829, 1632/6976 datapoints
2025-03-06 21:01:48,369 - INFO - validation batch 101, loss: 0.762, 3232/6976 datapoints
2025-03-06 21:01:48,413 - INFO - validation batch 151, loss: 0.576, 4832/6976 datapoints
2025-03-06 21:01:48,458 - INFO - validation batch 201, loss: 0.495, 6432/6976 datapoints
2025-03-06 21:01:48,473 - INFO - Epoch 602/800 done.
2025-03-06 21:01:48,473 - INFO - Final validation performance:
Loss: 0.788, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:01:48,473 - INFO - Beginning epoch 603/800
2025-03-06 21:01:48,477 - INFO - training batch 1, loss: 0.169, 32/28000 datapoints
2025-03-06 21:01:48,603 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 21:01:48,727 - INFO - training batch 101, loss: 0.057, 3232/28000 datapoints
2025-03-06 21:01:48,848 - INFO - training batch 151, loss: 0.038, 4832/28000 datapoints
2025-03-06 21:01:48,967 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:01:49,089 - INFO - training batch 251, loss: 0.158, 8032/28000 datapoints
2025-03-06 21:01:49,210 - INFO - training batch 301, loss: 0.120, 9632/28000 datapoints
2025-03-06 21:01:49,330 - INFO - training batch 351, loss: 0.144, 11232/28000 datapoints
2025-03-06 21:01:49,450 - INFO - training batch 401, loss: 0.205, 12832/28000 datapoints
2025-03-06 21:01:49,571 - INFO - training batch 451, loss: 0.105, 14432/28000 datapoints
2025-03-06 21:01:49,745 - INFO - training batch 501, loss: 0.055, 16032/28000 datapoints
2025-03-06 21:01:49,866 - INFO - training batch 551, loss: 0.070, 17632/28000 datapoints
2025-03-06 21:01:49,990 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-06 21:01:50,110 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:01:50,235 - INFO - training batch 701, loss: 0.108, 22432/28000 datapoints
2025-03-06 21:01:50,354 - INFO - training batch 751, loss: 0.063, 24032/28000 datapoints
2025-03-06 21:01:50,475 - INFO - training batch 801, loss: 0.055, 25632/28000 datapoints
2025-03-06 21:01:50,595 - INFO - training batch 851, loss: 0.109, 27232/28000 datapoints
2025-03-06 21:01:50,663 - INFO - validation batch 1, loss: 0.281, 32/6976 datapoints
2025-03-06 21:01:50,711 - INFO - validation batch 51, loss: 1.832, 1632/6976 datapoints
2025-03-06 21:01:50,758 - INFO - validation batch 101, loss: 0.764, 3232/6976 datapoints
2025-03-06 21:01:50,805 - INFO - validation batch 151, loss: 0.578, 4832/6976 datapoints
2025-03-06 21:01:50,851 - INFO - validation batch 201, loss: 0.497, 6432/6976 datapoints
2025-03-06 21:01:50,866 - INFO - Epoch 603/800 done.
2025-03-06 21:01:50,866 - INFO - Final validation performance:
Loss: 0.790, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:01:50,867 - INFO - Beginning epoch 604/800
2025-03-06 21:01:50,870 - INFO - training batch 1, loss: 0.168, 32/28000 datapoints
2025-03-06 21:01:50,998 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 21:01:51,123 - INFO - training batch 101, loss: 0.057, 3232/28000 datapoints
2025-03-06 21:01:51,252 - INFO - training batch 151, loss: 0.038, 4832/28000 datapoints
2025-03-06 21:01:51,379 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:01:51,506 - INFO - training batch 251, loss: 0.157, 8032/28000 datapoints
2025-03-06 21:01:51,637 - INFO - training batch 301, loss: 0.118, 9632/28000 datapoints
2025-03-06 21:01:51,786 - INFO - training batch 351, loss: 0.145, 11232/28000 datapoints
2025-03-06 21:01:51,941 - INFO - training batch 401, loss: 0.203, 12832/28000 datapoints
2025-03-06 21:01:52,079 - INFO - training batch 451, loss: 0.102, 14432/28000 datapoints
2025-03-06 21:01:52,226 - INFO - training batch 501, loss: 0.054, 16032/28000 datapoints
2025-03-06 21:01:52,372 - INFO - training batch 551, loss: 0.069, 17632/28000 datapoints
2025-03-06 21:01:52,518 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-06 21:01:52,673 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:01:52,810 - INFO - training batch 701, loss: 0.107, 22432/28000 datapoints
2025-03-06 21:01:52,932 - INFO - training batch 751, loss: 0.062, 24032/28000 datapoints
2025-03-06 21:01:53,066 - INFO - training batch 801, loss: 0.055, 25632/28000 datapoints
2025-03-06 21:01:53,189 - INFO - training batch 851, loss: 0.108, 27232/28000 datapoints
2025-03-06 21:01:53,255 - INFO - validation batch 1, loss: 0.286, 32/6976 datapoints
2025-03-06 21:01:53,304 - INFO - validation batch 51, loss: 1.841, 1632/6976 datapoints
2025-03-06 21:01:53,352 - INFO - validation batch 101, loss: 0.765, 3232/6976 datapoints
2025-03-06 21:01:53,400 - INFO - validation batch 151, loss: 0.578, 4832/6976 datapoints
2025-03-06 21:01:53,447 - INFO - validation batch 201, loss: 0.498, 6432/6976 datapoints
2025-03-06 21:01:53,463 - INFO - Epoch 604/800 done.
2025-03-06 21:01:53,464 - INFO - Final validation performance:
Loss: 0.794, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:01:53,464 - INFO - Beginning epoch 605/800
2025-03-06 21:01:53,468 - INFO - training batch 1, loss: 0.167, 32/28000 datapoints
2025-03-06 21:01:53,596 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 21:01:53,724 - INFO - training batch 101, loss: 0.057, 3232/28000 datapoints
2025-03-06 21:01:53,848 - INFO - training batch 151, loss: 0.038, 4832/28000 datapoints
2025-03-06 21:01:53,971 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:01:54,123 - INFO - training batch 251, loss: 0.157, 8032/28000 datapoints
2025-03-06 21:01:54,264 - INFO - training batch 301, loss: 0.118, 9632/28000 datapoints
2025-03-06 21:01:54,391 - INFO - training batch 351, loss: 0.144, 11232/28000 datapoints
2025-03-06 21:01:54,515 - INFO - training batch 401, loss: 0.203, 12832/28000 datapoints
2025-03-06 21:01:54,642 - INFO - training batch 451, loss: 0.103, 14432/28000 datapoints
2025-03-06 21:01:54,769 - INFO - training batch 501, loss: 0.054, 16032/28000 datapoints
2025-03-06 21:01:54,895 - INFO - training batch 551, loss: 0.068, 17632/28000 datapoints
2025-03-06 21:01:55,027 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-06 21:01:55,151 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:01:55,275 - INFO - training batch 701, loss: 0.106, 22432/28000 datapoints
2025-03-06 21:01:55,401 - INFO - training batch 751, loss: 0.062, 24032/28000 datapoints
2025-03-06 21:01:55,537 - INFO - training batch 801, loss: 0.055, 25632/28000 datapoints
2025-03-06 21:01:55,666 - INFO - training batch 851, loss: 0.108, 27232/28000 datapoints
2025-03-06 21:01:55,730 - INFO - validation batch 1, loss: 0.289, 32/6976 datapoints
2025-03-06 21:01:55,777 - INFO - validation batch 51, loss: 1.841, 1632/6976 datapoints
2025-03-06 21:01:55,826 - INFO - validation batch 101, loss: 0.768, 3232/6976 datapoints
2025-03-06 21:01:55,872 - INFO - validation batch 151, loss: 0.578, 4832/6976 datapoints
2025-03-06 21:01:55,915 - INFO - validation batch 201, loss: 0.499, 6432/6976 datapoints
2025-03-06 21:01:55,931 - INFO - Epoch 605/800 done.
2025-03-06 21:01:55,931 - INFO - Final validation performance:
Loss: 0.795, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:01:55,932 - INFO - Beginning epoch 606/800
2025-03-06 21:01:55,935 - INFO - training batch 1, loss: 0.166, 32/28000 datapoints
2025-03-06 21:01:56,056 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 21:01:56,178 - INFO - training batch 101, loss: 0.056, 3232/28000 datapoints
2025-03-06 21:01:56,302 - INFO - training batch 151, loss: 0.037, 4832/28000 datapoints
2025-03-06 21:01:56,427 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 21:01:56,563 - INFO - training batch 251, loss: 0.155, 8032/28000 datapoints
2025-03-06 21:01:56,685 - INFO - training batch 301, loss: 0.117, 9632/28000 datapoints
2025-03-06 21:01:56,807 - INFO - training batch 351, loss: 0.143, 11232/28000 datapoints
2025-03-06 21:01:56,927 - INFO - training batch 401, loss: 0.201, 12832/28000 datapoints
2025-03-06 21:01:57,048 - INFO - training batch 451, loss: 0.101, 14432/28000 datapoints
2025-03-06 21:01:57,168 - INFO - training batch 501, loss: 0.053, 16032/28000 datapoints
2025-03-06 21:01:57,290 - INFO - training batch 551, loss: 0.068, 17632/28000 datapoints
2025-03-06 21:01:57,409 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-06 21:01:57,530 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:01:57,681 - INFO - training batch 701, loss: 0.106, 22432/28000 datapoints
2025-03-06 21:01:57,803 - INFO - training batch 751, loss: 0.061, 24032/28000 datapoints
2025-03-06 21:01:57,922 - INFO - training batch 801, loss: 0.054, 25632/28000 datapoints
2025-03-06 21:01:58,045 - INFO - training batch 851, loss: 0.107, 27232/28000 datapoints
2025-03-06 21:01:58,104 - INFO - validation batch 1, loss: 0.292, 32/6976 datapoints
2025-03-06 21:01:58,147 - INFO - validation batch 51, loss: 1.850, 1632/6976 datapoints
2025-03-06 21:01:58,194 - INFO - validation batch 101, loss: 0.769, 3232/6976 datapoints
2025-03-06 21:01:58,237 - INFO - validation batch 151, loss: 0.577, 4832/6976 datapoints
2025-03-06 21:01:58,282 - INFO - validation batch 201, loss: 0.501, 6432/6976 datapoints
2025-03-06 21:01:58,297 - INFO - Epoch 606/800 done.
2025-03-06 21:01:58,297 - INFO - Final validation performance:
Loss: 0.798, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:01:58,298 - INFO - Beginning epoch 607/800
2025-03-06 21:01:58,301 - INFO - training batch 1, loss: 0.165, 32/28000 datapoints
2025-03-06 21:01:58,421 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 21:01:58,544 - INFO - training batch 101, loss: 0.056, 3232/28000 datapoints
2025-03-06 21:01:58,670 - INFO - training batch 151, loss: 0.037, 4832/28000 datapoints
2025-03-06 21:01:58,792 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:01:58,913 - INFO - training batch 251, loss: 0.155, 8032/28000 datapoints
2025-03-06 21:01:59,032 - INFO - training batch 301, loss: 0.115, 9632/28000 datapoints
2025-03-06 21:01:59,151 - INFO - training batch 351, loss: 0.143, 11232/28000 datapoints
2025-03-06 21:01:59,270 - INFO - training batch 401, loss: 0.200, 12832/28000 datapoints
2025-03-06 21:01:59,389 - INFO - training batch 451, loss: 0.102, 14432/28000 datapoints
2025-03-06 21:01:59,509 - INFO - training batch 501, loss: 0.053, 16032/28000 datapoints
2025-03-06 21:01:59,629 - INFO - training batch 551, loss: 0.067, 17632/28000 datapoints
2025-03-06 21:01:59,751 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-06 21:01:59,873 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:01:59,994 - INFO - training batch 701, loss: 0.105, 22432/28000 datapoints
2025-03-06 21:02:00,115 - INFO - training batch 751, loss: 0.061, 24032/28000 datapoints
2025-03-06 21:02:00,239 - INFO - training batch 801, loss: 0.054, 25632/28000 datapoints
2025-03-06 21:02:00,360 - INFO - training batch 851, loss: 0.107, 27232/28000 datapoints
2025-03-06 21:02:00,419 - INFO - validation batch 1, loss: 0.298, 32/6976 datapoints
2025-03-06 21:02:00,463 - INFO - validation batch 51, loss: 1.855, 1632/6976 datapoints
2025-03-06 21:02:00,508 - INFO - validation batch 101, loss: 0.772, 3232/6976 datapoints
2025-03-06 21:02:00,551 - INFO - validation batch 151, loss: 0.578, 4832/6976 datapoints
2025-03-06 21:02:00,595 - INFO - validation batch 201, loss: 0.501, 6432/6976 datapoints
2025-03-06 21:02:00,610 - INFO - Epoch 607/800 done.
2025-03-06 21:02:00,610 - INFO - Final validation performance:
Loss: 0.801, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:02:00,611 - INFO - Beginning epoch 608/800
2025-03-06 21:02:00,614 - INFO - training batch 1, loss: 0.165, 32/28000 datapoints
2025-03-06 21:02:00,739 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 21:02:00,876 - INFO - training batch 101, loss: 0.056, 3232/28000 datapoints
2025-03-06 21:02:01,005 - INFO - training batch 151, loss: 0.038, 4832/28000 datapoints
2025-03-06 21:02:01,126 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:02:01,246 - INFO - training batch 251, loss: 0.153, 8032/28000 datapoints
2025-03-06 21:02:01,369 - INFO - training batch 301, loss: 0.114, 9632/28000 datapoints
2025-03-06 21:02:01,500 - INFO - training batch 351, loss: 0.143, 11232/28000 datapoints
2025-03-06 21:02:01,624 - INFO - training batch 401, loss: 0.200, 12832/28000 datapoints
2025-03-06 21:02:01,750 - INFO - training batch 451, loss: 0.100, 14432/28000 datapoints
2025-03-06 21:02:01,876 - INFO - training batch 501, loss: 0.053, 16032/28000 datapoints
2025-03-06 21:02:01,998 - INFO - training batch 551, loss: 0.067, 17632/28000 datapoints
2025-03-06 21:02:02,119 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-06 21:02:02,242 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:02,363 - INFO - training batch 701, loss: 0.104, 22432/28000 datapoints
2025-03-06 21:02:02,484 - INFO - training batch 751, loss: 0.061, 24032/28000 datapoints
2025-03-06 21:02:02,607 - INFO - training batch 801, loss: 0.054, 25632/28000 datapoints
2025-03-06 21:02:02,731 - INFO - training batch 851, loss: 0.106, 27232/28000 datapoints
2025-03-06 21:02:02,790 - INFO - validation batch 1, loss: 0.301, 32/6976 datapoints
2025-03-06 21:02:02,836 - INFO - validation batch 51, loss: 1.861, 1632/6976 datapoints
2025-03-06 21:02:02,879 - INFO - validation batch 101, loss: 0.774, 3232/6976 datapoints
2025-03-06 21:02:02,923 - INFO - validation batch 151, loss: 0.578, 4832/6976 datapoints
2025-03-06 21:02:02,967 - INFO - validation batch 201, loss: 0.503, 6432/6976 datapoints
2025-03-06 21:02:02,982 - INFO - Epoch 608/800 done.
2025-03-06 21:02:02,982 - INFO - Final validation performance:
Loss: 0.803, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:02,983 - INFO - Beginning epoch 609/800
2025-03-06 21:02:02,986 - INFO - training batch 1, loss: 0.164, 32/28000 datapoints
2025-03-06 21:02:03,113 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 21:02:03,233 - INFO - training batch 101, loss: 0.055, 3232/28000 datapoints
2025-03-06 21:02:03,356 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-06 21:02:03,477 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 21:02:03,598 - INFO - training batch 251, loss: 0.152, 8032/28000 datapoints
2025-03-06 21:02:03,722 - INFO - training batch 301, loss: 0.113, 9632/28000 datapoints
2025-03-06 21:02:03,844 - INFO - training batch 351, loss: 0.142, 11232/28000 datapoints
2025-03-06 21:02:03,964 - INFO - training batch 401, loss: 0.197, 12832/28000 datapoints
2025-03-06 21:02:04,084 - INFO - training batch 451, loss: 0.100, 14432/28000 datapoints
2025-03-06 21:02:04,204 - INFO - training batch 501, loss: 0.052, 16032/28000 datapoints
2025-03-06 21:02:04,330 - INFO - training batch 551, loss: 0.066, 17632/28000 datapoints
2025-03-06 21:02:04,449 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-06 21:02:04,570 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:04,694 - INFO - training batch 701, loss: 0.104, 22432/28000 datapoints
2025-03-06 21:02:04,814 - INFO - training batch 751, loss: 0.060, 24032/28000 datapoints
2025-03-06 21:02:04,943 - INFO - training batch 801, loss: 0.053, 25632/28000 datapoints
2025-03-06 21:02:05,064 - INFO - training batch 851, loss: 0.106, 27232/28000 datapoints
2025-03-06 21:02:05,124 - INFO - validation batch 1, loss: 0.305, 32/6976 datapoints
2025-03-06 21:02:05,168 - INFO - validation batch 51, loss: 1.867, 1632/6976 datapoints
2025-03-06 21:02:05,212 - INFO - validation batch 101, loss: 0.775, 3232/6976 datapoints
2025-03-06 21:02:05,255 - INFO - validation batch 151, loss: 0.580, 4832/6976 datapoints
2025-03-06 21:02:05,299 - INFO - validation batch 201, loss: 0.505, 6432/6976 datapoints
2025-03-06 21:02:05,314 - INFO - Epoch 609/800 done.
2025-03-06 21:02:05,315 - INFO - Final validation performance:
Loss: 0.806, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:02:05,315 - INFO - Beginning epoch 610/800
2025-03-06 21:02:05,318 - INFO - training batch 1, loss: 0.163, 32/28000 datapoints
2025-03-06 21:02:05,441 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 21:02:05,562 - INFO - training batch 101, loss: 0.055, 3232/28000 datapoints
2025-03-06 21:02:05,684 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-06 21:02:05,804 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 21:02:05,925 - INFO - training batch 251, loss: 0.152, 8032/28000 datapoints
2025-03-06 21:02:06,046 - INFO - training batch 301, loss: 0.112, 9632/28000 datapoints
2025-03-06 21:02:06,164 - INFO - training batch 351, loss: 0.142, 11232/28000 datapoints
2025-03-06 21:02:06,288 - INFO - training batch 401, loss: 0.196, 12832/28000 datapoints
2025-03-06 21:02:06,410 - INFO - training batch 451, loss: 0.097, 14432/28000 datapoints
2025-03-06 21:02:06,531 - INFO - training batch 501, loss: 0.051, 16032/28000 datapoints
2025-03-06 21:02:06,655 - INFO - training batch 551, loss: 0.066, 17632/28000 datapoints
2025-03-06 21:02:06,774 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-06 21:02:06,908 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:07,035 - INFO - training batch 701, loss: 0.103, 22432/28000 datapoints
2025-03-06 21:02:07,153 - INFO - training batch 751, loss: 0.060, 24032/28000 datapoints
2025-03-06 21:02:07,273 - INFO - training batch 801, loss: 0.053, 25632/28000 datapoints
2025-03-06 21:02:07,402 - INFO - training batch 851, loss: 0.106, 27232/28000 datapoints
2025-03-06 21:02:07,461 - INFO - validation batch 1, loss: 0.310, 32/6976 datapoints
2025-03-06 21:02:07,506 - INFO - validation batch 51, loss: 1.869, 1632/6976 datapoints
2025-03-06 21:02:07,554 - INFO - validation batch 101, loss: 0.778, 3232/6976 datapoints
2025-03-06 21:02:07,597 - INFO - validation batch 151, loss: 0.581, 4832/6976 datapoints
2025-03-06 21:02:07,646 - INFO - validation batch 201, loss: 0.507, 6432/6976 datapoints
2025-03-06 21:02:07,666 - INFO - Epoch 610/800 done.
2025-03-06 21:02:07,666 - INFO - Final validation performance:
Loss: 0.809, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:02:07,667 - INFO - Beginning epoch 611/800
2025-03-06 21:02:07,671 - INFO - training batch 1, loss: 0.162, 32/28000 datapoints
2025-03-06 21:02:07,819 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 21:02:07,944 - INFO - training batch 101, loss: 0.055, 3232/28000 datapoints
2025-03-06 21:02:08,066 - INFO - training batch 151, loss: 0.037, 4832/28000 datapoints
2025-03-06 21:02:08,186 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 21:02:08,309 - INFO - training batch 251, loss: 0.150, 8032/28000 datapoints
2025-03-06 21:02:08,432 - INFO - training batch 301, loss: 0.111, 9632/28000 datapoints
2025-03-06 21:02:08,552 - INFO - training batch 351, loss: 0.141, 11232/28000 datapoints
2025-03-06 21:02:08,674 - INFO - training batch 401, loss: 0.196, 12832/28000 datapoints
2025-03-06 21:02:08,793 - INFO - training batch 451, loss: 0.100, 14432/28000 datapoints
2025-03-06 21:02:08,913 - INFO - training batch 501, loss: 0.052, 16032/28000 datapoints
2025-03-06 21:02:09,036 - INFO - training batch 551, loss: 0.066, 17632/28000 datapoints
2025-03-06 21:02:09,159 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-06 21:02:09,278 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:09,399 - INFO - training batch 701, loss: 0.102, 22432/28000 datapoints
2025-03-06 21:02:09,520 - INFO - training batch 751, loss: 0.059, 24032/28000 datapoints
2025-03-06 21:02:09,643 - INFO - training batch 801, loss: 0.053, 25632/28000 datapoints
2025-03-06 21:02:09,763 - INFO - training batch 851, loss: 0.105, 27232/28000 datapoints
2025-03-06 21:02:09,822 - INFO - validation batch 1, loss: 0.311, 32/6976 datapoints
2025-03-06 21:02:09,867 - INFO - validation batch 51, loss: 1.877, 1632/6976 datapoints
2025-03-06 21:02:09,913 - INFO - validation batch 101, loss: 0.779, 3232/6976 datapoints
2025-03-06 21:02:09,956 - INFO - validation batch 151, loss: 0.580, 4832/6976 datapoints
2025-03-06 21:02:10,002 - INFO - validation batch 201, loss: 0.509, 6432/6976 datapoints
2025-03-06 21:02:10,017 - INFO - Epoch 611/800 done.
2025-03-06 21:02:10,017 - INFO - Final validation performance:
Loss: 0.811, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:02:10,017 - INFO - Beginning epoch 612/800
2025-03-06 21:02:10,021 - INFO - training batch 1, loss: 0.161, 32/28000 datapoints
2025-03-06 21:02:10,144 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 21:02:10,267 - INFO - training batch 101, loss: 0.055, 3232/28000 datapoints
2025-03-06 21:02:10,387 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-06 21:02:10,514 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 21:02:10,637 - INFO - training batch 251, loss: 0.149, 8032/28000 datapoints
2025-03-06 21:02:10,765 - INFO - training batch 301, loss: 0.110, 9632/28000 datapoints
2025-03-06 21:02:10,889 - INFO - training batch 351, loss: 0.141, 11232/28000 datapoints
2025-03-06 21:02:11,014 - INFO - training batch 401, loss: 0.194, 12832/28000 datapoints
2025-03-06 21:02:11,139 - INFO - training batch 451, loss: 0.096, 14432/28000 datapoints
2025-03-06 21:02:11,263 - INFO - training batch 501, loss: 0.051, 16032/28000 datapoints
2025-03-06 21:02:11,386 - INFO - training batch 551, loss: 0.065, 17632/28000 datapoints
2025-03-06 21:02:11,511 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-06 21:02:11,634 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:11,763 - INFO - training batch 701, loss: 0.102, 22432/28000 datapoints
2025-03-06 21:02:11,888 - INFO - training batch 751, loss: 0.059, 24032/28000 datapoints
2025-03-06 21:02:12,012 - INFO - training batch 801, loss: 0.052, 25632/28000 datapoints
2025-03-06 21:02:12,138 - INFO - training batch 851, loss: 0.104, 27232/28000 datapoints
2025-03-06 21:02:12,203 - INFO - validation batch 1, loss: 0.318, 32/6976 datapoints
2025-03-06 21:02:12,255 - INFO - validation batch 51, loss: 1.880, 1632/6976 datapoints
2025-03-06 21:02:12,304 - INFO - validation batch 101, loss: 0.782, 3232/6976 datapoints
2025-03-06 21:02:12,352 - INFO - validation batch 151, loss: 0.581, 4832/6976 datapoints
2025-03-06 21:02:12,398 - INFO - validation batch 201, loss: 0.509, 6432/6976 datapoints
2025-03-06 21:02:12,413 - INFO - Epoch 612/800 done.
2025-03-06 21:02:12,414 - INFO - Final validation performance:
Loss: 0.814, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:12,414 - INFO - Beginning epoch 613/800
2025-03-06 21:02:12,418 - INFO - training batch 1, loss: 0.161, 32/28000 datapoints
2025-03-06 21:02:12,547 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 21:02:12,677 - INFO - training batch 101, loss: 0.055, 3232/28000 datapoints
2025-03-06 21:02:12,801 - INFO - training batch 151, loss: 0.037, 4832/28000 datapoints
2025-03-06 21:02:12,938 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 21:02:13,069 - INFO - training batch 251, loss: 0.148, 8032/28000 datapoints
2025-03-06 21:02:13,192 - INFO - training batch 301, loss: 0.109, 9632/28000 datapoints
2025-03-06 21:02:13,323 - INFO - training batch 351, loss: 0.140, 11232/28000 datapoints
2025-03-06 21:02:13,451 - INFO - training batch 401, loss: 0.194, 12832/28000 datapoints
2025-03-06 21:02:13,579 - INFO - training batch 451, loss: 0.099, 14432/28000 datapoints
2025-03-06 21:02:13,710 - INFO - training batch 501, loss: 0.051, 16032/28000 datapoints
2025-03-06 21:02:13,832 - INFO - training batch 551, loss: 0.065, 17632/28000 datapoints
2025-03-06 21:02:13,960 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-06 21:02:14,083 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:14,207 - INFO - training batch 701, loss: 0.100, 22432/28000 datapoints
2025-03-06 21:02:14,335 - INFO - training batch 751, loss: 0.058, 24032/28000 datapoints
2025-03-06 21:02:14,461 - INFO - training batch 801, loss: 0.052, 25632/28000 datapoints
2025-03-06 21:02:14,584 - INFO - training batch 851, loss: 0.104, 27232/28000 datapoints
2025-03-06 21:02:14,651 - INFO - validation batch 1, loss: 0.322, 32/6976 datapoints
2025-03-06 21:02:14,716 - INFO - validation batch 51, loss: 1.888, 1632/6976 datapoints
2025-03-06 21:02:14,774 - INFO - validation batch 101, loss: 0.782, 3232/6976 datapoints
2025-03-06 21:02:14,818 - INFO - validation batch 151, loss: 0.581, 4832/6976 datapoints
2025-03-06 21:02:14,862 - INFO - validation batch 201, loss: 0.511, 6432/6976 datapoints
2025-03-06 21:02:14,879 - INFO - Epoch 613/800 done.
2025-03-06 21:02:14,879 - INFO - Final validation performance:
Loss: 0.817, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:14,880 - INFO - Beginning epoch 614/800
2025-03-06 21:02:14,884 - INFO - training batch 1, loss: 0.158, 32/28000 datapoints
2025-03-06 21:02:15,011 - INFO - training batch 51, loss: 0.047, 1632/28000 datapoints
2025-03-06 21:02:15,133 - INFO - training batch 101, loss: 0.054, 3232/28000 datapoints
2025-03-06 21:02:15,257 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-06 21:02:15,376 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 21:02:15,496 - INFO - training batch 251, loss: 0.147, 8032/28000 datapoints
2025-03-06 21:02:15,618 - INFO - training batch 301, loss: 0.108, 9632/28000 datapoints
2025-03-06 21:02:15,740 - INFO - training batch 351, loss: 0.140, 11232/28000 datapoints
2025-03-06 21:02:15,862 - INFO - training batch 401, loss: 0.191, 12832/28000 datapoints
2025-03-06 21:02:15,984 - INFO - training batch 451, loss: 0.095, 14432/28000 datapoints
2025-03-06 21:02:16,105 - INFO - training batch 501, loss: 0.050, 16032/28000 datapoints
2025-03-06 21:02:16,226 - INFO - training batch 551, loss: 0.064, 17632/28000 datapoints
2025-03-06 21:02:16,350 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-06 21:02:16,472 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:16,594 - INFO - training batch 701, loss: 0.100, 22432/28000 datapoints
2025-03-06 21:02:16,719 - INFO - training batch 751, loss: 0.058, 24032/28000 datapoints
2025-03-06 21:02:16,839 - INFO - training batch 801, loss: 0.052, 25632/28000 datapoints
2025-03-06 21:02:16,960 - INFO - training batch 851, loss: 0.103, 27232/28000 datapoints
2025-03-06 21:02:17,022 - INFO - validation batch 1, loss: 0.324, 32/6976 datapoints
2025-03-06 21:02:17,066 - INFO - validation batch 51, loss: 1.894, 1632/6976 datapoints
2025-03-06 21:02:17,109 - INFO - validation batch 101, loss: 0.784, 3232/6976 datapoints
2025-03-06 21:02:17,153 - INFO - validation batch 151, loss: 0.583, 4832/6976 datapoints
2025-03-06 21:02:17,197 - INFO - validation batch 201, loss: 0.512, 6432/6976 datapoints
2025-03-06 21:02:17,212 - INFO - Epoch 614/800 done.
2025-03-06 21:02:17,212 - INFO - Final validation performance:
Loss: 0.820, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:02:17,212 - INFO - Beginning epoch 615/800
2025-03-06 21:02:17,216 - INFO - training batch 1, loss: 0.158, 32/28000 datapoints
2025-03-06 21:02:17,338 - INFO - training batch 51, loss: 0.047, 1632/28000 datapoints
2025-03-06 21:02:17,458 - INFO - training batch 101, loss: 0.054, 3232/28000 datapoints
2025-03-06 21:02:17,582 - INFO - training batch 151, loss: 0.035, 4832/28000 datapoints
2025-03-06 21:02:17,709 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 21:02:17,857 - INFO - training batch 251, loss: 0.146, 8032/28000 datapoints
2025-03-06 21:02:17,981 - INFO - training batch 301, loss: 0.107, 9632/28000 datapoints
2025-03-06 21:02:18,103 - INFO - training batch 351, loss: 0.139, 11232/28000 datapoints
2025-03-06 21:02:18,223 - INFO - training batch 401, loss: 0.190, 12832/28000 datapoints
2025-03-06 21:02:18,348 - INFO - training batch 451, loss: 0.096, 14432/28000 datapoints
2025-03-06 21:02:18,469 - INFO - training batch 501, loss: 0.050, 16032/28000 datapoints
2025-03-06 21:02:18,591 - INFO - training batch 551, loss: 0.063, 17632/28000 datapoints
2025-03-06 21:02:18,714 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-06 21:02:18,834 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:18,954 - INFO - training batch 701, loss: 0.100, 22432/28000 datapoints
2025-03-06 21:02:19,088 - INFO - training batch 751, loss: 0.058, 24032/28000 datapoints
2025-03-06 21:02:19,211 - INFO - training batch 801, loss: 0.052, 25632/28000 datapoints
2025-03-06 21:02:19,333 - INFO - training batch 851, loss: 0.102, 27232/28000 datapoints
2025-03-06 21:02:19,392 - INFO - validation batch 1, loss: 0.326, 32/6976 datapoints
2025-03-06 21:02:19,435 - INFO - validation batch 51, loss: 1.900, 1632/6976 datapoints
2025-03-06 21:02:19,479 - INFO - validation batch 101, loss: 0.786, 3232/6976 datapoints
2025-03-06 21:02:19,524 - INFO - validation batch 151, loss: 0.582, 4832/6976 datapoints
2025-03-06 21:02:19,568 - INFO - validation batch 201, loss: 0.513, 6432/6976 datapoints
2025-03-06 21:02:19,583 - INFO - Epoch 615/800 done.
2025-03-06 21:02:19,583 - INFO - Final validation performance:
Loss: 0.821, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:19,584 - INFO - Beginning epoch 616/800
2025-03-06 21:02:19,587 - INFO - training batch 1, loss: 0.157, 32/28000 datapoints
2025-03-06 21:02:19,717 - INFO - training batch 51, loss: 0.047, 1632/28000 datapoints
2025-03-06 21:02:19,837 - INFO - training batch 101, loss: 0.054, 3232/28000 datapoints
2025-03-06 21:02:19,960 - INFO - training batch 151, loss: 0.035, 4832/28000 datapoints
2025-03-06 21:02:20,085 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 21:02:20,207 - INFO - training batch 251, loss: 0.145, 8032/28000 datapoints
2025-03-06 21:02:20,331 - INFO - training batch 301, loss: 0.106, 9632/28000 datapoints
2025-03-06 21:02:20,450 - INFO - training batch 351, loss: 0.138, 11232/28000 datapoints
2025-03-06 21:02:20,573 - INFO - training batch 401, loss: 0.189, 12832/28000 datapoints
2025-03-06 21:02:20,697 - INFO - training batch 451, loss: 0.096, 14432/28000 datapoints
2025-03-06 21:02:20,817 - INFO - training batch 501, loss: 0.050, 16032/28000 datapoints
2025-03-06 21:02:20,939 - INFO - training batch 551, loss: 0.063, 17632/28000 datapoints
2025-03-06 21:02:21,062 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-06 21:02:21,183 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:21,306 - INFO - training batch 701, loss: 0.099, 22432/28000 datapoints
2025-03-06 21:02:21,424 - INFO - training batch 751, loss: 0.057, 24032/28000 datapoints
2025-03-06 21:02:21,545 - INFO - training batch 801, loss: 0.051, 25632/28000 datapoints
2025-03-06 21:02:21,668 - INFO - training batch 851, loss: 0.102, 27232/28000 datapoints
2025-03-06 21:02:21,728 - INFO - validation batch 1, loss: 0.332, 32/6976 datapoints
2025-03-06 21:02:21,772 - INFO - validation batch 51, loss: 1.903, 1632/6976 datapoints
2025-03-06 21:02:21,815 - INFO - validation batch 101, loss: 0.788, 3232/6976 datapoints
2025-03-06 21:02:21,860 - INFO - validation batch 151, loss: 0.584, 4832/6976 datapoints
2025-03-06 21:02:21,905 - INFO - validation batch 201, loss: 0.517, 6432/6976 datapoints
2025-03-06 21:02:21,919 - INFO - Epoch 616/800 done.
2025-03-06 21:02:21,920 - INFO - Final validation performance:
Loss: 0.825, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:21,920 - INFO - Beginning epoch 617/800
2025-03-06 21:02:21,924 - INFO - training batch 1, loss: 0.156, 32/28000 datapoints
2025-03-06 21:02:22,049 - INFO - training batch 51, loss: 0.047, 1632/28000 datapoints
2025-03-06 21:02:22,170 - INFO - training batch 101, loss: 0.053, 3232/28000 datapoints
2025-03-06 21:02:22,295 - INFO - training batch 151, loss: 0.035, 4832/28000 datapoints
2025-03-06 21:02:22,415 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:02:22,536 - INFO - training batch 251, loss: 0.143, 8032/28000 datapoints
2025-03-06 21:02:22,663 - INFO - training batch 301, loss: 0.105, 9632/28000 datapoints
2025-03-06 21:02:22,784 - INFO - training batch 351, loss: 0.138, 11232/28000 datapoints
2025-03-06 21:02:22,908 - INFO - training batch 401, loss: 0.187, 12832/28000 datapoints
2025-03-06 21:02:23,032 - INFO - training batch 451, loss: 0.094, 14432/28000 datapoints
2025-03-06 21:02:23,159 - INFO - training batch 501, loss: 0.049, 16032/28000 datapoints
2025-03-06 21:02:23,281 - INFO - training batch 551, loss: 0.062, 17632/28000 datapoints
2025-03-06 21:02:23,401 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-06 21:02:23,522 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:23,648 - INFO - training batch 701, loss: 0.099, 22432/28000 datapoints
2025-03-06 21:02:23,768 - INFO - training batch 751, loss: 0.056, 24032/28000 datapoints
2025-03-06 21:02:23,890 - INFO - training batch 801, loss: 0.051, 25632/28000 datapoints
2025-03-06 21:02:24,012 - INFO - training batch 851, loss: 0.101, 27232/28000 datapoints
2025-03-06 21:02:24,072 - INFO - validation batch 1, loss: 0.337, 32/6976 datapoints
2025-03-06 21:02:24,116 - INFO - validation batch 51, loss: 1.914, 1632/6976 datapoints
2025-03-06 21:02:24,160 - INFO - validation batch 101, loss: 0.789, 3232/6976 datapoints
2025-03-06 21:02:24,205 - INFO - validation batch 151, loss: 0.584, 4832/6976 datapoints
2025-03-06 21:02:24,249 - INFO - validation batch 201, loss: 0.517, 6432/6976 datapoints
2025-03-06 21:02:24,264 - INFO - Epoch 617/800 done.
2025-03-06 21:02:24,264 - INFO - Final validation performance:
Loss: 0.828, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:24,264 - INFO - Beginning epoch 618/800
2025-03-06 21:02:24,268 - INFO - training batch 1, loss: 0.155, 32/28000 datapoints
2025-03-06 21:02:24,391 - INFO - training batch 51, loss: 0.047, 1632/28000 datapoints
2025-03-06 21:02:24,512 - INFO - training batch 101, loss: 0.053, 3232/28000 datapoints
2025-03-06 21:02:24,637 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-06 21:02:24,759 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 21:02:24,880 - INFO - training batch 251, loss: 0.142, 8032/28000 datapoints
2025-03-06 21:02:25,010 - INFO - training batch 301, loss: 0.104, 9632/28000 datapoints
2025-03-06 21:02:25,149 - INFO - training batch 351, loss: 0.137, 11232/28000 datapoints
2025-03-06 21:02:25,271 - INFO - training batch 401, loss: 0.187, 12832/28000 datapoints
2025-03-06 21:02:25,393 - INFO - training batch 451, loss: 0.095, 14432/28000 datapoints
2025-03-06 21:02:25,524 - INFO - training batch 501, loss: 0.049, 16032/28000 datapoints
2025-03-06 21:02:25,660 - INFO - training batch 551, loss: 0.062, 17632/28000 datapoints
2025-03-06 21:02:25,803 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-06 21:02:25,955 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:26,108 - INFO - training batch 701, loss: 0.098, 22432/28000 datapoints
2025-03-06 21:02:26,228 - INFO - training batch 751, loss: 0.056, 24032/28000 datapoints
2025-03-06 21:02:26,353 - INFO - training batch 801, loss: 0.050, 25632/28000 datapoints
2025-03-06 21:02:26,474 - INFO - training batch 851, loss: 0.102, 27232/28000 datapoints
2025-03-06 21:02:26,535 - INFO - validation batch 1, loss: 0.340, 32/6976 datapoints
2025-03-06 21:02:26,580 - INFO - validation batch 51, loss: 1.916, 1632/6976 datapoints
2025-03-06 21:02:26,626 - INFO - validation batch 101, loss: 0.792, 3232/6976 datapoints
2025-03-06 21:02:26,671 - INFO - validation batch 151, loss: 0.586, 4832/6976 datapoints
2025-03-06 21:02:26,715 - INFO - validation batch 201, loss: 0.519, 6432/6976 datapoints
2025-03-06 21:02:26,730 - INFO - Epoch 618/800 done.
2025-03-06 21:02:26,730 - INFO - Final validation performance:
Loss: 0.830, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:02:26,731 - INFO - Beginning epoch 619/800
2025-03-06 21:02:26,734 - INFO - training batch 1, loss: 0.155, 32/28000 datapoints
2025-03-06 21:02:26,860 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 21:02:26,983 - INFO - training batch 101, loss: 0.053, 3232/28000 datapoints
2025-03-06 21:02:27,108 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-06 21:02:27,230 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:02:27,358 - INFO - training batch 251, loss: 0.141, 8032/28000 datapoints
2025-03-06 21:02:27,481 - INFO - training batch 301, loss: 0.103, 9632/28000 datapoints
2025-03-06 21:02:27,601 - INFO - training batch 351, loss: 0.137, 11232/28000 datapoints
2025-03-06 21:02:27,729 - INFO - training batch 401, loss: 0.185, 12832/28000 datapoints
2025-03-06 21:02:27,853 - INFO - training batch 451, loss: 0.092, 14432/28000 datapoints
2025-03-06 21:02:28,000 - INFO - training batch 501, loss: 0.049, 16032/28000 datapoints
2025-03-06 21:02:28,125 - INFO - training batch 551, loss: 0.062, 17632/28000 datapoints
2025-03-06 21:02:28,246 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-06 21:02:28,371 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:28,493 - INFO - training batch 701, loss: 0.098, 22432/28000 datapoints
2025-03-06 21:02:28,612 - INFO - training batch 751, loss: 0.056, 24032/28000 datapoints
2025-03-06 21:02:28,734 - INFO - training batch 801, loss: 0.050, 25632/28000 datapoints
2025-03-06 21:02:28,865 - INFO - training batch 851, loss: 0.100, 27232/28000 datapoints
2025-03-06 21:02:28,927 - INFO - validation batch 1, loss: 0.344, 32/6976 datapoints
2025-03-06 21:02:28,971 - INFO - validation batch 51, loss: 1.923, 1632/6976 datapoints
2025-03-06 21:02:29,016 - INFO - validation batch 101, loss: 0.793, 3232/6976 datapoints
2025-03-06 21:02:29,060 - INFO - validation batch 151, loss: 0.583, 4832/6976 datapoints
2025-03-06 21:02:29,104 - INFO - validation batch 201, loss: 0.521, 6432/6976 datapoints
2025-03-06 21:02:29,119 - INFO - Epoch 619/800 done.
2025-03-06 21:02:29,120 - INFO - Final validation performance:
Loss: 0.833, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:29,120 - INFO - Beginning epoch 620/800
2025-03-06 21:02:29,124 - INFO - training batch 1, loss: 0.154, 32/28000 datapoints
2025-03-06 21:02:29,249 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 21:02:29,369 - INFO - training batch 101, loss: 0.052, 3232/28000 datapoints
2025-03-06 21:02:29,491 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-06 21:02:29,612 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 21:02:29,736 - INFO - training batch 251, loss: 0.140, 8032/28000 datapoints
2025-03-06 21:02:29,857 - INFO - training batch 301, loss: 0.102, 9632/28000 datapoints
2025-03-06 21:02:29,978 - INFO - training batch 351, loss: 0.137, 11232/28000 datapoints
2025-03-06 21:02:30,116 - INFO - training batch 401, loss: 0.184, 12832/28000 datapoints
2025-03-06 21:02:30,241 - INFO - training batch 451, loss: 0.095, 14432/28000 datapoints
2025-03-06 21:02:30,366 - INFO - training batch 501, loss: 0.049, 16032/28000 datapoints
2025-03-06 21:02:30,488 - INFO - training batch 551, loss: 0.061, 17632/28000 datapoints
2025-03-06 21:02:30,621 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:02:30,743 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:30,865 - INFO - training batch 701, loss: 0.097, 22432/28000 datapoints
2025-03-06 21:02:30,992 - INFO - training batch 751, loss: 0.055, 24032/28000 datapoints
2025-03-06 21:02:31,116 - INFO - training batch 801, loss: 0.050, 25632/28000 datapoints
2025-03-06 21:02:31,251 - INFO - training batch 851, loss: 0.100, 27232/28000 datapoints
2025-03-06 21:02:31,319 - INFO - validation batch 1, loss: 0.349, 32/6976 datapoints
2025-03-06 21:02:31,366 - INFO - validation batch 51, loss: 1.930, 1632/6976 datapoints
2025-03-06 21:02:31,413 - INFO - validation batch 101, loss: 0.795, 3232/6976 datapoints
2025-03-06 21:02:31,461 - INFO - validation batch 151, loss: 0.583, 4832/6976 datapoints
2025-03-06 21:02:31,511 - INFO - validation batch 201, loss: 0.522, 6432/6976 datapoints
2025-03-06 21:02:31,528 - INFO - Epoch 620/800 done.
2025-03-06 21:02:31,528 - INFO - Final validation performance:
Loss: 0.836, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:31,529 - INFO - Beginning epoch 621/800
2025-03-06 21:02:31,532 - INFO - training batch 1, loss: 0.152, 32/28000 datapoints
2025-03-06 21:02:31,665 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 21:02:31,802 - INFO - training batch 101, loss: 0.053, 3232/28000 datapoints
2025-03-06 21:02:31,927 - INFO - training batch 151, loss: 0.035, 4832/28000 datapoints
2025-03-06 21:02:32,053 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:02:32,179 - INFO - training batch 251, loss: 0.139, 8032/28000 datapoints
2025-03-06 21:02:32,305 - INFO - training batch 301, loss: 0.102, 9632/28000 datapoints
2025-03-06 21:02:32,434 - INFO - training batch 351, loss: 0.136, 11232/28000 datapoints
2025-03-06 21:02:32,561 - INFO - training batch 401, loss: 0.183, 12832/28000 datapoints
2025-03-06 21:02:32,693 - INFO - training batch 451, loss: 0.091, 14432/28000 datapoints
2025-03-06 21:02:32,819 - INFO - training batch 501, loss: 0.047, 16032/28000 datapoints
2025-03-06 21:02:32,945 - INFO - training batch 551, loss: 0.060, 17632/28000 datapoints
2025-03-06 21:02:33,069 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-06 21:02:33,195 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:33,318 - INFO - training batch 701, loss: 0.096, 22432/28000 datapoints
2025-03-06 21:02:33,443 - INFO - training batch 751, loss: 0.054, 24032/28000 datapoints
2025-03-06 21:02:33,569 - INFO - training batch 801, loss: 0.049, 25632/28000 datapoints
2025-03-06 21:02:33,696 - INFO - training batch 851, loss: 0.100, 27232/28000 datapoints
2025-03-06 21:02:33,759 - INFO - validation batch 1, loss: 0.353, 32/6976 datapoints
2025-03-06 21:02:33,810 - INFO - validation batch 51, loss: 1.934, 1632/6976 datapoints
2025-03-06 21:02:33,859 - INFO - validation batch 101, loss: 0.797, 3232/6976 datapoints
2025-03-06 21:02:33,907 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-06 21:02:33,956 - INFO - validation batch 201, loss: 0.523, 6432/6976 datapoints
2025-03-06 21:02:33,972 - INFO - Epoch 621/800 done.
2025-03-06 21:02:33,972 - INFO - Final validation performance:
Loss: 0.839, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:33,972 - INFO - Beginning epoch 622/800
2025-03-06 21:02:33,977 - INFO - training batch 1, loss: 0.152, 32/28000 datapoints
2025-03-06 21:02:34,106 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 21:02:34,234 - INFO - training batch 101, loss: 0.052, 3232/28000 datapoints
2025-03-06 21:02:34,361 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-06 21:02:34,487 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:02:34,610 - INFO - training batch 251, loss: 0.138, 8032/28000 datapoints
2025-03-06 21:02:34,738 - INFO - training batch 301, loss: 0.101, 9632/28000 datapoints
2025-03-06 21:02:34,864 - INFO - training batch 351, loss: 0.136, 11232/28000 datapoints
2025-03-06 21:02:34,993 - INFO - training batch 401, loss: 0.181, 12832/28000 datapoints
2025-03-06 21:02:35,119 - INFO - training batch 451, loss: 0.093, 14432/28000 datapoints
2025-03-06 21:02:35,244 - INFO - training batch 501, loss: 0.048, 16032/28000 datapoints
2025-03-06 21:02:35,369 - INFO - training batch 551, loss: 0.060, 17632/28000 datapoints
2025-03-06 21:02:35,494 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:02:35,620 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:35,748 - INFO - training batch 701, loss: 0.095, 22432/28000 datapoints
2025-03-06 21:02:35,872 - INFO - training batch 751, loss: 0.054, 24032/28000 datapoints
2025-03-06 21:02:35,997 - INFO - training batch 801, loss: 0.049, 25632/28000 datapoints
2025-03-06 21:02:36,123 - INFO - training batch 851, loss: 0.099, 27232/28000 datapoints
2025-03-06 21:02:36,187 - INFO - validation batch 1, loss: 0.356, 32/6976 datapoints
2025-03-06 21:02:36,234 - INFO - validation batch 51, loss: 1.940, 1632/6976 datapoints
2025-03-06 21:02:36,282 - INFO - validation batch 101, loss: 0.799, 3232/6976 datapoints
2025-03-06 21:02:36,331 - INFO - validation batch 151, loss: 0.584, 4832/6976 datapoints
2025-03-06 21:02:36,383 - INFO - validation batch 201, loss: 0.525, 6432/6976 datapoints
2025-03-06 21:02:36,400 - INFO - Epoch 622/800 done.
2025-03-06 21:02:36,400 - INFO - Final validation performance:
Loss: 0.841, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:36,401 - INFO - Beginning epoch 623/800
2025-03-06 21:02:36,404 - INFO - training batch 1, loss: 0.150, 32/28000 datapoints
2025-03-06 21:02:36,537 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 21:02:36,662 - INFO - training batch 101, loss: 0.052, 3232/28000 datapoints
2025-03-06 21:02:36,792 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-06 21:02:36,917 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:02:37,042 - INFO - training batch 251, loss: 0.136, 8032/28000 datapoints
2025-03-06 21:02:37,166 - INFO - training batch 301, loss: 0.100, 9632/28000 datapoints
2025-03-06 21:02:37,294 - INFO - training batch 351, loss: 0.135, 11232/28000 datapoints
2025-03-06 21:02:37,418 - INFO - training batch 401, loss: 0.180, 12832/28000 datapoints
2025-03-06 21:02:37,544 - INFO - training batch 451, loss: 0.090, 14432/28000 datapoints
2025-03-06 21:02:37,695 - INFO - training batch 501, loss: 0.047, 16032/28000 datapoints
2025-03-06 21:02:37,821 - INFO - training batch 551, loss: 0.060, 17632/28000 datapoints
2025-03-06 21:02:37,946 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:02:38,099 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:38,224 - INFO - training batch 701, loss: 0.095, 22432/28000 datapoints
2025-03-06 21:02:38,350 - INFO - training batch 751, loss: 0.054, 24032/28000 datapoints
2025-03-06 21:02:38,478 - INFO - training batch 801, loss: 0.049, 25632/28000 datapoints
2025-03-06 21:02:38,604 - INFO - training batch 851, loss: 0.098, 27232/28000 datapoints
2025-03-06 21:02:38,670 - INFO - validation batch 1, loss: 0.361, 32/6976 datapoints
2025-03-06 21:02:38,718 - INFO - validation batch 51, loss: 1.945, 1632/6976 datapoints
2025-03-06 21:02:38,766 - INFO - validation batch 101, loss: 0.800, 3232/6976 datapoints
2025-03-06 21:02:38,815 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 21:02:38,864 - INFO - validation batch 201, loss: 0.527, 6432/6976 datapoints
2025-03-06 21:02:38,882 - INFO - Epoch 623/800 done.
2025-03-06 21:02:38,882 - INFO - Final validation performance:
Loss: 0.843, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:38,882 - INFO - Beginning epoch 624/800
2025-03-06 21:02:38,887 - INFO - training batch 1, loss: 0.150, 32/28000 datapoints
2025-03-06 21:02:39,009 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 21:02:39,137 - INFO - training batch 101, loss: 0.052, 3232/28000 datapoints
2025-03-06 21:02:39,257 - INFO - training batch 151, loss: 0.035, 4832/28000 datapoints
2025-03-06 21:02:39,380 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:02:39,504 - INFO - training batch 251, loss: 0.136, 8032/28000 datapoints
2025-03-06 21:02:39,624 - INFO - training batch 301, loss: 0.099, 9632/28000 datapoints
2025-03-06 21:02:39,747 - INFO - training batch 351, loss: 0.134, 11232/28000 datapoints
2025-03-06 21:02:39,870 - INFO - training batch 401, loss: 0.180, 12832/28000 datapoints
2025-03-06 21:02:39,990 - INFO - training batch 451, loss: 0.091, 14432/28000 datapoints
2025-03-06 21:02:40,123 - INFO - training batch 501, loss: 0.047, 16032/28000 datapoints
2025-03-06 21:02:40,244 - INFO - training batch 551, loss: 0.059, 17632/28000 datapoints
2025-03-06 21:02:40,366 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:02:40,492 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:40,612 - INFO - training batch 701, loss: 0.095, 22432/28000 datapoints
2025-03-06 21:02:40,737 - INFO - training batch 751, loss: 0.053, 24032/28000 datapoints
2025-03-06 21:02:40,859 - INFO - training batch 801, loss: 0.048, 25632/28000 datapoints
2025-03-06 21:02:40,980 - INFO - training batch 851, loss: 0.098, 27232/28000 datapoints
2025-03-06 21:02:41,041 - INFO - validation batch 1, loss: 0.367, 32/6976 datapoints
2025-03-06 21:02:41,086 - INFO - validation batch 51, loss: 1.952, 1632/6976 datapoints
2025-03-06 21:02:41,130 - INFO - validation batch 101, loss: 0.804, 3232/6976 datapoints
2025-03-06 21:02:41,174 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 21:02:41,217 - INFO - validation batch 201, loss: 0.528, 6432/6976 datapoints
2025-03-06 21:02:41,232 - INFO - Epoch 624/800 done.
2025-03-06 21:02:41,232 - INFO - Final validation performance:
Loss: 0.847, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:41,233 - INFO - Beginning epoch 625/800
2025-03-06 21:02:41,236 - INFO - training batch 1, loss: 0.149, 32/28000 datapoints
2025-03-06 21:02:41,361 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 21:02:41,482 - INFO - training batch 101, loss: 0.051, 3232/28000 datapoints
2025-03-06 21:02:41,604 - INFO - training batch 151, loss: 0.033, 4832/28000 datapoints
2025-03-06 21:02:41,730 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:02:41,855 - INFO - training batch 251, loss: 0.134, 8032/28000 datapoints
2025-03-06 21:02:41,977 - INFO - training batch 301, loss: 0.099, 9632/28000 datapoints
2025-03-06 21:02:42,098 - INFO - training batch 351, loss: 0.134, 11232/28000 datapoints
2025-03-06 21:02:42,219 - INFO - training batch 401, loss: 0.178, 12832/28000 datapoints
2025-03-06 21:02:42,340 - INFO - training batch 451, loss: 0.090, 14432/28000 datapoints
2025-03-06 21:02:42,465 - INFO - training batch 501, loss: 0.047, 16032/28000 datapoints
2025-03-06 21:02:42,586 - INFO - training batch 551, loss: 0.059, 17632/28000 datapoints
2025-03-06 21:02:42,717 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:02:42,841 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:42,961 - INFO - training batch 701, loss: 0.094, 22432/28000 datapoints
2025-03-06 21:02:43,080 - INFO - training batch 751, loss: 0.053, 24032/28000 datapoints
2025-03-06 21:02:43,199 - INFO - training batch 801, loss: 0.048, 25632/28000 datapoints
2025-03-06 21:02:43,320 - INFO - training batch 851, loss: 0.097, 27232/28000 datapoints
2025-03-06 21:02:43,382 - INFO - validation batch 1, loss: 0.370, 32/6976 datapoints
2025-03-06 21:02:43,426 - INFO - validation batch 51, loss: 1.959, 1632/6976 datapoints
2025-03-06 21:02:43,471 - INFO - validation batch 101, loss: 0.804, 3232/6976 datapoints
2025-03-06 21:02:43,515 - INFO - validation batch 151, loss: 0.584, 4832/6976 datapoints
2025-03-06 21:02:43,558 - INFO - validation batch 201, loss: 0.530, 6432/6976 datapoints
2025-03-06 21:02:43,573 - INFO - Epoch 625/800 done.
2025-03-06 21:02:43,573 - INFO - Final validation performance:
Loss: 0.849, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:43,573 - INFO - Beginning epoch 626/800
2025-03-06 21:02:43,577 - INFO - training batch 1, loss: 0.148, 32/28000 datapoints
2025-03-06 21:02:43,703 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 21:02:43,821 - INFO - training batch 101, loss: 0.051, 3232/28000 datapoints
2025-03-06 21:02:43,946 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-06 21:02:44,069 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:02:44,192 - INFO - training batch 251, loss: 0.133, 8032/28000 datapoints
2025-03-06 21:02:44,313 - INFO - training batch 301, loss: 0.097, 9632/28000 datapoints
2025-03-06 21:02:44,439 - INFO - training batch 351, loss: 0.133, 11232/28000 datapoints
2025-03-06 21:02:44,558 - INFO - training batch 401, loss: 0.177, 12832/28000 datapoints
2025-03-06 21:02:44,681 - INFO - training batch 451, loss: 0.090, 14432/28000 datapoints
2025-03-06 21:02:44,802 - INFO - training batch 501, loss: 0.046, 16032/28000 datapoints
2025-03-06 21:02:44,931 - INFO - training batch 551, loss: 0.058, 17632/28000 datapoints
2025-03-06 21:02:45,054 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:02:45,177 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:45,297 - INFO - training batch 701, loss: 0.093, 22432/28000 datapoints
2025-03-06 21:02:45,418 - INFO - training batch 751, loss: 0.052, 24032/28000 datapoints
2025-03-06 21:02:45,538 - INFO - training batch 801, loss: 0.048, 25632/28000 datapoints
2025-03-06 21:02:45,663 - INFO - training batch 851, loss: 0.097, 27232/28000 datapoints
2025-03-06 21:02:45,724 - INFO - validation batch 1, loss: 0.373, 32/6976 datapoints
2025-03-06 21:02:45,769 - INFO - validation batch 51, loss: 1.963, 1632/6976 datapoints
2025-03-06 21:02:45,813 - INFO - validation batch 101, loss: 0.806, 3232/6976 datapoints
2025-03-06 21:02:45,857 - INFO - validation batch 151, loss: 0.584, 4832/6976 datapoints
2025-03-06 21:02:45,903 - INFO - validation batch 201, loss: 0.532, 6432/6976 datapoints
2025-03-06 21:02:45,918 - INFO - Epoch 626/800 done.
2025-03-06 21:02:45,919 - INFO - Final validation performance:
Loss: 0.852, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:45,919 - INFO - Beginning epoch 627/800
2025-03-06 21:02:45,923 - INFO - training batch 1, loss: 0.147, 32/28000 datapoints
2025-03-06 21:02:46,045 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 21:02:46,166 - INFO - training batch 101, loss: 0.051, 3232/28000 datapoints
2025-03-06 21:02:46,289 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-06 21:02:46,417 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:02:46,538 - INFO - training batch 251, loss: 0.132, 8032/28000 datapoints
2025-03-06 21:02:46,661 - INFO - training batch 301, loss: 0.097, 9632/28000 datapoints
2025-03-06 21:02:46,780 - INFO - training batch 351, loss: 0.133, 11232/28000 datapoints
2025-03-06 21:02:46,900 - INFO - training batch 401, loss: 0.175, 12832/28000 datapoints
2025-03-06 21:02:47,023 - INFO - training batch 451, loss: 0.088, 14432/28000 datapoints
2025-03-06 21:02:47,143 - INFO - training batch 501, loss: 0.045, 16032/28000 datapoints
2025-03-06 21:02:47,265 - INFO - training batch 551, loss: 0.058, 17632/28000 datapoints
2025-03-06 21:02:47,385 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:02:47,507 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:47,627 - INFO - training batch 701, loss: 0.093, 22432/28000 datapoints
2025-03-06 21:02:47,755 - INFO - training batch 751, loss: 0.052, 24032/28000 datapoints
2025-03-06 21:02:47,877 - INFO - training batch 801, loss: 0.048, 25632/28000 datapoints
2025-03-06 21:02:47,998 - INFO - training batch 851, loss: 0.096, 27232/28000 datapoints
2025-03-06 21:02:48,061 - INFO - validation batch 1, loss: 0.380, 32/6976 datapoints
2025-03-06 21:02:48,120 - INFO - validation batch 51, loss: 1.972, 1632/6976 datapoints
2025-03-06 21:02:48,171 - INFO - validation batch 101, loss: 0.808, 3232/6976 datapoints
2025-03-06 21:02:48,217 - INFO - validation batch 151, loss: 0.584, 4832/6976 datapoints
2025-03-06 21:02:48,261 - INFO - validation batch 201, loss: 0.534, 6432/6976 datapoints
2025-03-06 21:02:48,276 - INFO - Epoch 627/800 done.
2025-03-06 21:02:48,276 - INFO - Final validation performance:
Loss: 0.856, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:48,276 - INFO - Beginning epoch 628/800
2025-03-06 21:02:48,280 - INFO - training batch 1, loss: 0.146, 32/28000 datapoints
2025-03-06 21:02:48,401 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 21:02:48,528 - INFO - training batch 101, loss: 0.051, 3232/28000 datapoints
2025-03-06 21:02:48,651 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-06 21:02:48,771 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:02:48,893 - INFO - training batch 251, loss: 0.131, 8032/28000 datapoints
2025-03-06 21:02:49,015 - INFO - training batch 301, loss: 0.096, 9632/28000 datapoints
2025-03-06 21:02:49,134 - INFO - training batch 351, loss: 0.132, 11232/28000 datapoints
2025-03-06 21:02:49,254 - INFO - training batch 401, loss: 0.175, 12832/28000 datapoints
2025-03-06 21:02:49,374 - INFO - training batch 451, loss: 0.087, 14432/28000 datapoints
2025-03-06 21:02:49,499 - INFO - training batch 501, loss: 0.045, 16032/28000 datapoints
2025-03-06 21:02:49,620 - INFO - training batch 551, loss: 0.057, 17632/28000 datapoints
2025-03-06 21:02:49,744 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:02:49,865 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:49,986 - INFO - training batch 701, loss: 0.092, 22432/28000 datapoints
2025-03-06 21:02:50,108 - INFO - training batch 751, loss: 0.051, 24032/28000 datapoints
2025-03-06 21:02:50,229 - INFO - training batch 801, loss: 0.047, 25632/28000 datapoints
2025-03-06 21:02:50,349 - INFO - training batch 851, loss: 0.096, 27232/28000 datapoints
2025-03-06 21:02:50,410 - INFO - validation batch 1, loss: 0.384, 32/6976 datapoints
2025-03-06 21:02:50,459 - INFO - validation batch 51, loss: 1.975, 1632/6976 datapoints
2025-03-06 21:02:50,502 - INFO - validation batch 101, loss: 0.810, 3232/6976 datapoints
2025-03-06 21:02:50,545 - INFO - validation batch 151, loss: 0.586, 4832/6976 datapoints
2025-03-06 21:02:50,589 - INFO - validation batch 201, loss: 0.536, 6432/6976 datapoints
2025-03-06 21:02:50,604 - INFO - Epoch 628/800 done.
2025-03-06 21:02:50,604 - INFO - Final validation performance:
Loss: 0.858, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:50,604 - INFO - Beginning epoch 629/800
2025-03-06 21:02:50,608 - INFO - training batch 1, loss: 0.146, 32/28000 datapoints
2025-03-06 21:02:50,733 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 21:02:50,856 - INFO - training batch 101, loss: 0.051, 3232/28000 datapoints
2025-03-06 21:02:50,978 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-06 21:02:51,100 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:02:51,229 - INFO - training batch 251, loss: 0.129, 8032/28000 datapoints
2025-03-06 21:02:51,350 - INFO - training batch 301, loss: 0.095, 9632/28000 datapoints
2025-03-06 21:02:51,474 - INFO - training batch 351, loss: 0.131, 11232/28000 datapoints
2025-03-06 21:02:51,598 - INFO - training batch 401, loss: 0.172, 12832/28000 datapoints
2025-03-06 21:02:51,725 - INFO - training batch 451, loss: 0.089, 14432/28000 datapoints
2025-03-06 21:02:51,852 - INFO - training batch 501, loss: 0.045, 16032/28000 datapoints
2025-03-06 21:02:51,981 - INFO - training batch 551, loss: 0.057, 17632/28000 datapoints
2025-03-06 21:02:52,107 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:02:52,231 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:52,354 - INFO - training batch 701, loss: 0.091, 22432/28000 datapoints
2025-03-06 21:02:52,485 - INFO - training batch 751, loss: 0.051, 24032/28000 datapoints
2025-03-06 21:02:52,611 - INFO - training batch 801, loss: 0.047, 25632/28000 datapoints
2025-03-06 21:02:52,744 - INFO - training batch 851, loss: 0.095, 27232/28000 datapoints
2025-03-06 21:02:52,807 - INFO - validation batch 1, loss: 0.387, 32/6976 datapoints
2025-03-06 21:02:52,855 - INFO - validation batch 51, loss: 1.983, 1632/6976 datapoints
2025-03-06 21:02:52,904 - INFO - validation batch 101, loss: 0.812, 3232/6976 datapoints
2025-03-06 21:02:52,951 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 21:02:53,000 - INFO - validation batch 201, loss: 0.537, 6432/6976 datapoints
2025-03-06 21:02:53,015 - INFO - Epoch 629/800 done.
2025-03-06 21:02:53,016 - INFO - Final validation performance:
Loss: 0.861, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:53,016 - INFO - Beginning epoch 630/800
2025-03-06 21:02:53,020 - INFO - training batch 1, loss: 0.145, 32/28000 datapoints
2025-03-06 21:02:53,147 - INFO - training batch 51, loss: 0.044, 1632/28000 datapoints
2025-03-06 21:02:53,274 - INFO - training batch 101, loss: 0.050, 3232/28000 datapoints
2025-03-06 21:02:53,404 - INFO - training batch 151, loss: 0.033, 4832/28000 datapoints
2025-03-06 21:02:53,539 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:02:53,667 - INFO - training batch 251, loss: 0.128, 8032/28000 datapoints
2025-03-06 21:02:53,793 - INFO - training batch 301, loss: 0.094, 9632/28000 datapoints
2025-03-06 21:02:53,918 - INFO - training batch 351, loss: 0.130, 11232/28000 datapoints
2025-03-06 21:02:54,042 - INFO - training batch 401, loss: 0.172, 12832/28000 datapoints
2025-03-06 21:02:54,168 - INFO - training batch 451, loss: 0.085, 14432/28000 datapoints
2025-03-06 21:02:54,291 - INFO - training batch 501, loss: 0.045, 16032/28000 datapoints
2025-03-06 21:02:54,416 - INFO - training batch 551, loss: 0.057, 17632/28000 datapoints
2025-03-06 21:02:54,562 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:02:54,714 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:54,838 - INFO - training batch 701, loss: 0.091, 22432/28000 datapoints
2025-03-06 21:02:54,970 - INFO - training batch 751, loss: 0.051, 24032/28000 datapoints
2025-03-06 21:02:55,101 - INFO - training batch 801, loss: 0.047, 25632/28000 datapoints
2025-03-06 21:02:55,227 - INFO - training batch 851, loss: 0.094, 27232/28000 datapoints
2025-03-06 21:02:55,291 - INFO - validation batch 1, loss: 0.395, 32/6976 datapoints
2025-03-06 21:02:55,339 - INFO - validation batch 51, loss: 1.988, 1632/6976 datapoints
2025-03-06 21:02:55,384 - INFO - validation batch 101, loss: 0.815, 3232/6976 datapoints
2025-03-06 21:02:55,430 - INFO - validation batch 151, loss: 0.584, 4832/6976 datapoints
2025-03-06 21:02:55,474 - INFO - validation batch 201, loss: 0.538, 6432/6976 datapoints
2025-03-06 21:02:55,490 - INFO - Epoch 630/800 done.
2025-03-06 21:02:55,490 - INFO - Final validation performance:
Loss: 0.864, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:55,491 - INFO - Beginning epoch 631/800
2025-03-06 21:02:55,495 - INFO - training batch 1, loss: 0.144, 32/28000 datapoints
2025-03-06 21:02:55,622 - INFO - training batch 51, loss: 0.044, 1632/28000 datapoints
2025-03-06 21:02:55,747 - INFO - training batch 101, loss: 0.050, 3232/28000 datapoints
2025-03-06 21:02:55,869 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-06 21:02:55,992 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:02:56,114 - INFO - training batch 251, loss: 0.127, 8032/28000 datapoints
2025-03-06 21:02:56,235 - INFO - training batch 301, loss: 0.094, 9632/28000 datapoints
2025-03-06 21:02:56,355 - INFO - training batch 351, loss: 0.130, 11232/28000 datapoints
2025-03-06 21:02:56,480 - INFO - training batch 401, loss: 0.170, 12832/28000 datapoints
2025-03-06 21:02:56,610 - INFO - training batch 451, loss: 0.087, 14432/28000 datapoints
2025-03-06 21:02:56,760 - INFO - training batch 501, loss: 0.045, 16032/28000 datapoints
2025-03-06 21:02:56,882 - INFO - training batch 551, loss: 0.056, 17632/28000 datapoints
2025-03-06 21:02:57,003 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:02:57,124 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:02:57,244 - INFO - training batch 701, loss: 0.090, 22432/28000 datapoints
2025-03-06 21:02:57,363 - INFO - training batch 751, loss: 0.050, 24032/28000 datapoints
2025-03-06 21:02:57,483 - INFO - training batch 801, loss: 0.046, 25632/28000 datapoints
2025-03-06 21:02:57,606 - INFO - training batch 851, loss: 0.094, 27232/28000 datapoints
2025-03-06 21:02:57,672 - INFO - validation batch 1, loss: 0.397, 32/6976 datapoints
2025-03-06 21:02:57,715 - INFO - validation batch 51, loss: 1.992, 1632/6976 datapoints
2025-03-06 21:02:57,759 - INFO - validation batch 101, loss: 0.817, 3232/6976 datapoints
2025-03-06 21:02:57,803 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 21:02:57,847 - INFO - validation batch 201, loss: 0.541, 6432/6976 datapoints
2025-03-06 21:02:57,864 - INFO - Epoch 631/800 done.
2025-03-06 21:02:57,864 - INFO - Final validation performance:
Loss: 0.867, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:02:57,864 - INFO - Beginning epoch 632/800
2025-03-06 21:02:57,868 - INFO - training batch 1, loss: 0.143, 32/28000 datapoints
2025-03-06 21:02:57,988 - INFO - training batch 51, loss: 0.044, 1632/28000 datapoints
2025-03-06 21:02:58,110 - INFO - training batch 101, loss: 0.050, 3232/28000 datapoints
2025-03-06 21:02:58,261 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-06 21:02:58,385 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:02:58,515 - INFO - training batch 251, loss: 0.126, 8032/28000 datapoints
2025-03-06 21:02:58,639 - INFO - training batch 301, loss: 0.093, 9632/28000 datapoints
2025-03-06 21:02:58,760 - INFO - training batch 351, loss: 0.130, 11232/28000 datapoints
2025-03-06 21:02:58,881 - INFO - training batch 401, loss: 0.168, 12832/28000 datapoints
2025-03-06 21:02:59,005 - INFO - training batch 451, loss: 0.085, 14432/28000 datapoints
2025-03-06 21:02:59,128 - INFO - training batch 501, loss: 0.044, 16032/28000 datapoints
2025-03-06 21:02:59,248 - INFO - training batch 551, loss: 0.055, 17632/28000 datapoints
2025-03-06 21:02:59,367 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:02:59,486 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:02:59,607 - INFO - training batch 701, loss: 0.090, 22432/28000 datapoints
2025-03-06 21:02:59,731 - INFO - training batch 751, loss: 0.050, 24032/28000 datapoints
2025-03-06 21:02:59,852 - INFO - training batch 801, loss: 0.046, 25632/28000 datapoints
2025-03-06 21:02:59,974 - INFO - training batch 851, loss: 0.093, 27232/28000 datapoints
2025-03-06 21:03:00,036 - INFO - validation batch 1, loss: 0.401, 32/6976 datapoints
2025-03-06 21:03:00,083 - INFO - validation batch 51, loss: 2.000, 1632/6976 datapoints
2025-03-06 21:03:00,128 - INFO - validation batch 101, loss: 0.817, 3232/6976 datapoints
2025-03-06 21:03:00,173 - INFO - validation batch 151, loss: 0.584, 4832/6976 datapoints
2025-03-06 21:03:00,219 - INFO - validation batch 201, loss: 0.542, 6432/6976 datapoints
2025-03-06 21:03:00,234 - INFO - Epoch 632/800 done.
2025-03-06 21:03:00,234 - INFO - Final validation performance:
Loss: 0.869, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:03:00,235 - INFO - Beginning epoch 633/800
2025-03-06 21:03:00,238 - INFO - training batch 1, loss: 0.142, 32/28000 datapoints
2025-03-06 21:03:00,360 - INFO - training batch 51, loss: 0.044, 1632/28000 datapoints
2025-03-06 21:03:00,483 - INFO - training batch 101, loss: 0.049, 3232/28000 datapoints
2025-03-06 21:03:00,605 - INFO - training batch 151, loss: 0.033, 4832/28000 datapoints
2025-03-06 21:03:00,730 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:03:00,851 - INFO - training batch 251, loss: 0.125, 8032/28000 datapoints
2025-03-06 21:03:00,971 - INFO - training batch 301, loss: 0.092, 9632/28000 datapoints
2025-03-06 21:03:01,091 - INFO - training batch 351, loss: 0.129, 11232/28000 datapoints
2025-03-06 21:03:01,211 - INFO - training batch 401, loss: 0.168, 12832/28000 datapoints
2025-03-06 21:03:01,332 - INFO - training batch 451, loss: 0.085, 14432/28000 datapoints
2025-03-06 21:03:01,453 - INFO - training batch 501, loss: 0.044, 16032/28000 datapoints
2025-03-06 21:03:01,577 - INFO - training batch 551, loss: 0.055, 17632/28000 datapoints
2025-03-06 21:03:01,704 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:03:01,822 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:03:01,945 - INFO - training batch 701, loss: 0.089, 22432/28000 datapoints
2025-03-06 21:03:02,065 - INFO - training batch 751, loss: 0.049, 24032/28000 datapoints
2025-03-06 21:03:02,187 - INFO - training batch 801, loss: 0.046, 25632/28000 datapoints
2025-03-06 21:03:02,308 - INFO - training batch 851, loss: 0.093, 27232/28000 datapoints
2025-03-06 21:03:02,367 - INFO - validation batch 1, loss: 0.408, 32/6976 datapoints
2025-03-06 21:03:02,411 - INFO - validation batch 51, loss: 2.004, 1632/6976 datapoints
2025-03-06 21:03:02,455 - INFO - validation batch 101, loss: 0.820, 3232/6976 datapoints
2025-03-06 21:03:02,502 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 21:03:02,547 - INFO - validation batch 201, loss: 0.546, 6432/6976 datapoints
2025-03-06 21:03:02,563 - INFO - Epoch 633/800 done.
2025-03-06 21:03:02,563 - INFO - Final validation performance:
Loss: 0.872, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:03:02,564 - INFO - Beginning epoch 634/800
2025-03-06 21:03:02,567 - INFO - training batch 1, loss: 0.141, 32/28000 datapoints
2025-03-06 21:03:02,695 - INFO - training batch 51, loss: 0.044, 1632/28000 datapoints
2025-03-06 21:03:02,820 - INFO - training batch 101, loss: 0.049, 3232/28000 datapoints
2025-03-06 21:03:02,942 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-06 21:03:03,063 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:03:03,185 - INFO - training batch 251, loss: 0.124, 8032/28000 datapoints
2025-03-06 21:03:03,307 - INFO - training batch 301, loss: 0.092, 9632/28000 datapoints
2025-03-06 21:03:03,427 - INFO - training batch 351, loss: 0.129, 11232/28000 datapoints
2025-03-06 21:03:03,549 - INFO - training batch 401, loss: 0.166, 12832/28000 datapoints
2025-03-06 21:03:03,674 - INFO - training batch 451, loss: 0.084, 14432/28000 datapoints
2025-03-06 21:03:03,794 - INFO - training batch 501, loss: 0.043, 16032/28000 datapoints
2025-03-06 21:03:03,915 - INFO - training batch 551, loss: 0.054, 17632/28000 datapoints
2025-03-06 21:03:04,036 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:03:04,158 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:04,279 - INFO - training batch 701, loss: 0.089, 22432/28000 datapoints
2025-03-06 21:03:04,398 - INFO - training batch 751, loss: 0.049, 24032/28000 datapoints
2025-03-06 21:03:04,523 - INFO - training batch 801, loss: 0.046, 25632/28000 datapoints
2025-03-06 21:03:04,647 - INFO - training batch 851, loss: 0.092, 27232/28000 datapoints
2025-03-06 21:03:04,709 - INFO - validation batch 1, loss: 0.410, 32/6976 datapoints
2025-03-06 21:03:04,752 - INFO - validation batch 51, loss: 2.012, 1632/6976 datapoints
2025-03-06 21:03:04,795 - INFO - validation batch 101, loss: 0.822, 3232/6976 datapoints
2025-03-06 21:03:04,838 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 21:03:04,889 - INFO - validation batch 201, loss: 0.547, 6432/6976 datapoints
2025-03-06 21:03:04,904 - INFO - Epoch 634/800 done.
2025-03-06 21:03:04,905 - INFO - Final validation performance:
Loss: 0.875, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:03:04,905 - INFO - Beginning epoch 635/800
2025-03-06 21:03:04,908 - INFO - training batch 1, loss: 0.141, 32/28000 datapoints
2025-03-06 21:03:05,031 - INFO - training batch 51, loss: 0.044, 1632/28000 datapoints
2025-03-06 21:03:05,156 - INFO - training batch 101, loss: 0.049, 3232/28000 datapoints
2025-03-06 21:03:05,276 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-06 21:03:05,397 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:03:05,518 - INFO - training batch 251, loss: 0.122, 8032/28000 datapoints
2025-03-06 21:03:05,641 - INFO - training batch 301, loss: 0.091, 9632/28000 datapoints
2025-03-06 21:03:05,762 - INFO - training batch 351, loss: 0.128, 11232/28000 datapoints
2025-03-06 21:03:05,882 - INFO - training batch 401, loss: 0.164, 12832/28000 datapoints
2025-03-06 21:03:06,003 - INFO - training batch 451, loss: 0.083, 14432/28000 datapoints
2025-03-06 21:03:06,124 - INFO - training batch 501, loss: 0.043, 16032/28000 datapoints
2025-03-06 21:03:06,247 - INFO - training batch 551, loss: 0.054, 17632/28000 datapoints
2025-03-06 21:03:06,366 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:03:06,486 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:03:06,611 - INFO - training batch 701, loss: 0.089, 22432/28000 datapoints
2025-03-06 21:03:06,735 - INFO - training batch 751, loss: 0.049, 24032/28000 datapoints
2025-03-06 21:03:06,854 - INFO - training batch 801, loss: 0.046, 25632/28000 datapoints
2025-03-06 21:03:06,975 - INFO - training batch 851, loss: 0.092, 27232/28000 datapoints
2025-03-06 21:03:07,037 - INFO - validation batch 1, loss: 0.416, 32/6976 datapoints
2025-03-06 21:03:07,081 - INFO - validation batch 51, loss: 2.015, 1632/6976 datapoints
2025-03-06 21:03:07,124 - INFO - validation batch 101, loss: 0.825, 3232/6976 datapoints
2025-03-06 21:03:07,169 - INFO - validation batch 151, loss: 0.583, 4832/6976 datapoints
2025-03-06 21:03:07,212 - INFO - validation batch 201, loss: 0.548, 6432/6976 datapoints
2025-03-06 21:03:07,227 - INFO - Epoch 635/800 done.
2025-03-06 21:03:07,227 - INFO - Final validation performance:
Loss: 0.877, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:07,228 - INFO - Beginning epoch 636/800
2025-03-06 21:03:07,232 - INFO - training batch 1, loss: 0.140, 32/28000 datapoints
2025-03-06 21:03:07,353 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 21:03:07,474 - INFO - training batch 101, loss: 0.049, 3232/28000 datapoints
2025-03-06 21:03:07,596 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-06 21:03:07,725 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:07,849 - INFO - training batch 251, loss: 0.122, 8032/28000 datapoints
2025-03-06 21:03:07,970 - INFO - training batch 301, loss: 0.091, 9632/28000 datapoints
2025-03-06 21:03:08,091 - INFO - training batch 351, loss: 0.127, 11232/28000 datapoints
2025-03-06 21:03:08,216 - INFO - training batch 401, loss: 0.164, 12832/28000 datapoints
2025-03-06 21:03:08,365 - INFO - training batch 451, loss: 0.084, 14432/28000 datapoints
2025-03-06 21:03:08,488 - INFO - training batch 501, loss: 0.043, 16032/28000 datapoints
2025-03-06 21:03:08,619 - INFO - training batch 551, loss: 0.054, 17632/28000 datapoints
2025-03-06 21:03:08,744 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:03:08,865 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-06 21:03:08,984 - INFO - training batch 701, loss: 0.087, 22432/28000 datapoints
2025-03-06 21:03:09,109 - INFO - training batch 751, loss: 0.048, 24032/28000 datapoints
2025-03-06 21:03:09,239 - INFO - training batch 801, loss: 0.045, 25632/28000 datapoints
2025-03-06 21:03:09,377 - INFO - training batch 851, loss: 0.091, 27232/28000 datapoints
2025-03-06 21:03:09,450 - INFO - validation batch 1, loss: 0.422, 32/6976 datapoints
2025-03-06 21:03:09,509 - INFO - validation batch 51, loss: 2.025, 1632/6976 datapoints
2025-03-06 21:03:09,561 - INFO - validation batch 101, loss: 0.826, 3232/6976 datapoints
2025-03-06 21:03:09,616 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 21:03:09,673 - INFO - validation batch 201, loss: 0.550, 6432/6976 datapoints
2025-03-06 21:03:09,695 - INFO - Epoch 636/800 done.
2025-03-06 21:03:09,695 - INFO - Final validation performance:
Loss: 0.881, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:09,696 - INFO - Beginning epoch 637/800
2025-03-06 21:03:09,699 - INFO - training batch 1, loss: 0.139, 32/28000 datapoints
2025-03-06 21:03:09,833 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 21:03:09,973 - INFO - training batch 101, loss: 0.049, 3232/28000 datapoints
2025-03-06 21:03:10,097 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-06 21:03:10,220 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:03:10,341 - INFO - training batch 251, loss: 0.120, 8032/28000 datapoints
2025-03-06 21:03:10,463 - INFO - training batch 301, loss: 0.090, 9632/28000 datapoints
2025-03-06 21:03:10,587 - INFO - training batch 351, loss: 0.127, 11232/28000 datapoints
2025-03-06 21:03:10,714 - INFO - training batch 401, loss: 0.162, 12832/28000 datapoints
2025-03-06 21:03:10,835 - INFO - training batch 451, loss: 0.083, 14432/28000 datapoints
2025-03-06 21:03:10,957 - INFO - training batch 501, loss: 0.043, 16032/28000 datapoints
2025-03-06 21:03:11,086 - INFO - training batch 551, loss: 0.053, 17632/28000 datapoints
2025-03-06 21:03:11,216 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:03:11,343 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:11,466 - INFO - training batch 701, loss: 0.087, 22432/28000 datapoints
2025-03-06 21:03:11,590 - INFO - training batch 751, loss: 0.048, 24032/28000 datapoints
2025-03-06 21:03:11,718 - INFO - training batch 801, loss: 0.045, 25632/28000 datapoints
2025-03-06 21:03:11,846 - INFO - training batch 851, loss: 0.091, 27232/28000 datapoints
2025-03-06 21:03:11,910 - INFO - validation batch 1, loss: 0.426, 32/6976 datapoints
2025-03-06 21:03:11,959 - INFO - validation batch 51, loss: 2.031, 1632/6976 datapoints
2025-03-06 21:03:12,009 - INFO - validation batch 101, loss: 0.827, 3232/6976 datapoints
2025-03-06 21:03:12,059 - INFO - validation batch 151, loss: 0.584, 4832/6976 datapoints
2025-03-06 21:03:12,108 - INFO - validation batch 201, loss: 0.552, 6432/6976 datapoints
2025-03-06 21:03:12,124 - INFO - Epoch 637/800 done.
2025-03-06 21:03:12,124 - INFO - Final validation performance:
Loss: 0.884, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:12,125 - INFO - Beginning epoch 638/800
2025-03-06 21:03:12,129 - INFO - training batch 1, loss: 0.137, 32/28000 datapoints
2025-03-06 21:03:12,258 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 21:03:12,377 - INFO - training batch 101, loss: 0.049, 3232/28000 datapoints
2025-03-06 21:03:12,498 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-06 21:03:12,626 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:12,750 - INFO - training batch 251, loss: 0.119, 8032/28000 datapoints
2025-03-06 21:03:12,878 - INFO - training batch 301, loss: 0.089, 9632/28000 datapoints
2025-03-06 21:03:12,999 - INFO - training batch 351, loss: 0.126, 11232/28000 datapoints
2025-03-06 21:03:13,119 - INFO - training batch 401, loss: 0.162, 12832/28000 datapoints
2025-03-06 21:03:13,239 - INFO - training batch 451, loss: 0.083, 14432/28000 datapoints
2025-03-06 21:03:13,362 - INFO - training batch 501, loss: 0.042, 16032/28000 datapoints
2025-03-06 21:03:13,482 - INFO - training batch 551, loss: 0.053, 17632/28000 datapoints
2025-03-06 21:03:13,601 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:03:13,726 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:13,848 - INFO - training batch 701, loss: 0.087, 22432/28000 datapoints
2025-03-06 21:03:13,972 - INFO - training batch 751, loss: 0.047, 24032/28000 datapoints
2025-03-06 21:03:14,096 - INFO - training batch 801, loss: 0.045, 25632/28000 datapoints
2025-03-06 21:03:14,217 - INFO - training batch 851, loss: 0.090, 27232/28000 datapoints
2025-03-06 21:03:14,279 - INFO - validation batch 1, loss: 0.429, 32/6976 datapoints
2025-03-06 21:03:14,322 - INFO - validation batch 51, loss: 2.035, 1632/6976 datapoints
2025-03-06 21:03:14,366 - INFO - validation batch 101, loss: 0.830, 3232/6976 datapoints
2025-03-06 21:03:14,410 - INFO - validation batch 151, loss: 0.586, 4832/6976 datapoints
2025-03-06 21:03:14,454 - INFO - validation batch 201, loss: 0.554, 6432/6976 datapoints
2025-03-06 21:03:14,469 - INFO - Epoch 638/800 done.
2025-03-06 21:03:14,469 - INFO - Final validation performance:
Loss: 0.887, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:14,469 - INFO - Beginning epoch 639/800
2025-03-06 21:03:14,473 - INFO - training batch 1, loss: 0.137, 32/28000 datapoints
2025-03-06 21:03:14,597 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 21:03:14,720 - INFO - training batch 101, loss: 0.049, 3232/28000 datapoints
2025-03-06 21:03:14,845 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-06 21:03:14,972 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:15,095 - INFO - training batch 251, loss: 0.118, 8032/28000 datapoints
2025-03-06 21:03:15,219 - INFO - training batch 301, loss: 0.088, 9632/28000 datapoints
2025-03-06 21:03:15,341 - INFO - training batch 351, loss: 0.125, 11232/28000 datapoints
2025-03-06 21:03:15,461 - INFO - training batch 401, loss: 0.161, 12832/28000 datapoints
2025-03-06 21:03:15,581 - INFO - training batch 451, loss: 0.082, 14432/28000 datapoints
2025-03-06 21:03:15,704 - INFO - training batch 501, loss: 0.042, 16032/28000 datapoints
2025-03-06 21:03:15,827 - INFO - training batch 551, loss: 0.053, 17632/28000 datapoints
2025-03-06 21:03:15,948 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:03:16,069 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:16,189 - INFO - training batch 701, loss: 0.086, 22432/28000 datapoints
2025-03-06 21:03:16,311 - INFO - training batch 751, loss: 0.047, 24032/28000 datapoints
2025-03-06 21:03:16,432 - INFO - training batch 801, loss: 0.044, 25632/28000 datapoints
2025-03-06 21:03:16,557 - INFO - training batch 851, loss: 0.090, 27232/28000 datapoints
2025-03-06 21:03:16,617 - INFO - validation batch 1, loss: 0.433, 32/6976 datapoints
2025-03-06 21:03:16,670 - INFO - validation batch 51, loss: 2.043, 1632/6976 datapoints
2025-03-06 21:03:16,724 - INFO - validation batch 101, loss: 0.832, 3232/6976 datapoints
2025-03-06 21:03:16,781 - INFO - validation batch 151, loss: 0.583, 4832/6976 datapoints
2025-03-06 21:03:16,832 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 21:03:16,852 - INFO - Epoch 639/800 done.
2025-03-06 21:03:16,852 - INFO - Final validation performance:
Loss: 0.890, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:16,853 - INFO - Beginning epoch 640/800
2025-03-06 21:03:16,857 - INFO - training batch 1, loss: 0.135, 32/28000 datapoints
2025-03-06 21:03:17,006 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 21:03:17,128 - INFO - training batch 101, loss: 0.048, 3232/28000 datapoints
2025-03-06 21:03:17,250 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-06 21:03:17,374 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:17,497 - INFO - training batch 251, loss: 0.116, 8032/28000 datapoints
2025-03-06 21:03:17,618 - INFO - training batch 301, loss: 0.088, 9632/28000 datapoints
2025-03-06 21:03:17,746 - INFO - training batch 351, loss: 0.125, 11232/28000 datapoints
2025-03-06 21:03:17,870 - INFO - training batch 401, loss: 0.158, 12832/28000 datapoints
2025-03-06 21:03:17,991 - INFO - training batch 451, loss: 0.082, 14432/28000 datapoints
2025-03-06 21:03:18,111 - INFO - training batch 501, loss: 0.042, 16032/28000 datapoints
2025-03-06 21:03:18,232 - INFO - training batch 551, loss: 0.052, 17632/28000 datapoints
2025-03-06 21:03:18,356 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:03:18,508 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:18,634 - INFO - training batch 701, loss: 0.086, 22432/28000 datapoints
2025-03-06 21:03:18,758 - INFO - training batch 751, loss: 0.047, 24032/28000 datapoints
2025-03-06 21:03:18,880 - INFO - training batch 801, loss: 0.044, 25632/28000 datapoints
2025-03-06 21:03:19,000 - INFO - training batch 851, loss: 0.090, 27232/28000 datapoints
2025-03-06 21:03:19,061 - INFO - validation batch 1, loss: 0.439, 32/6976 datapoints
2025-03-06 21:03:19,105 - INFO - validation batch 51, loss: 2.044, 1632/6976 datapoints
2025-03-06 21:03:19,149 - INFO - validation batch 101, loss: 0.836, 3232/6976 datapoints
2025-03-06 21:03:19,193 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 21:03:19,236 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 21:03:19,251 - INFO - Epoch 640/800 done.
2025-03-06 21:03:19,252 - INFO - Final validation performance:
Loss: 0.893, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:19,252 - INFO - Beginning epoch 641/800
2025-03-06 21:03:19,256 - INFO - training batch 1, loss: 0.135, 32/28000 datapoints
2025-03-06 21:03:19,380 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 21:03:19,500 - INFO - training batch 101, loss: 0.048, 3232/28000 datapoints
2025-03-06 21:03:19,622 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-06 21:03:19,748 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:19,870 - INFO - training batch 251, loss: 0.115, 8032/28000 datapoints
2025-03-06 21:03:19,993 - INFO - training batch 301, loss: 0.087, 9632/28000 datapoints
2025-03-06 21:03:20,114 - INFO - training batch 351, loss: 0.124, 11232/28000 datapoints
2025-03-06 21:03:20,235 - INFO - training batch 401, loss: 0.157, 12832/28000 datapoints
2025-03-06 21:03:20,358 - INFO - training batch 451, loss: 0.079, 14432/28000 datapoints
2025-03-06 21:03:20,479 - INFO - training batch 501, loss: 0.041, 16032/28000 datapoints
2025-03-06 21:03:20,603 - INFO - training batch 551, loss: 0.052, 17632/28000 datapoints
2025-03-06 21:03:20,725 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:03:20,849 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:20,968 - INFO - training batch 701, loss: 0.085, 22432/28000 datapoints
2025-03-06 21:03:21,087 - INFO - training batch 751, loss: 0.046, 24032/28000 datapoints
2025-03-06 21:03:21,206 - INFO - training batch 801, loss: 0.044, 25632/28000 datapoints
2025-03-06 21:03:21,328 - INFO - training batch 851, loss: 0.089, 27232/28000 datapoints
2025-03-06 21:03:21,391 - INFO - validation batch 1, loss: 0.444, 32/6976 datapoints
2025-03-06 21:03:21,434 - INFO - validation batch 51, loss: 2.052, 1632/6976 datapoints
2025-03-06 21:03:21,478 - INFO - validation batch 101, loss: 0.838, 3232/6976 datapoints
2025-03-06 21:03:21,521 - INFO - validation batch 151, loss: 0.586, 4832/6976 datapoints
2025-03-06 21:03:21,564 - INFO - validation batch 201, loss: 0.561, 6432/6976 datapoints
2025-03-06 21:03:21,579 - INFO - Epoch 641/800 done.
2025-03-06 21:03:21,579 - INFO - Final validation performance:
Loss: 0.896, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:21,580 - INFO - Beginning epoch 642/800
2025-03-06 21:03:21,583 - INFO - training batch 1, loss: 0.134, 32/28000 datapoints
2025-03-06 21:03:21,709 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 21:03:21,829 - INFO - training batch 101, loss: 0.047, 3232/28000 datapoints
2025-03-06 21:03:21,954 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-06 21:03:22,076 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:22,196 - INFO - training batch 251, loss: 0.114, 8032/28000 datapoints
2025-03-06 21:03:22,317 - INFO - training batch 301, loss: 0.086, 9632/28000 datapoints
2025-03-06 21:03:22,438 - INFO - training batch 351, loss: 0.123, 11232/28000 datapoints
2025-03-06 21:03:22,562 - INFO - training batch 401, loss: 0.156, 12832/28000 datapoints
2025-03-06 21:03:22,688 - INFO - training batch 451, loss: 0.080, 14432/28000 datapoints
2025-03-06 21:03:22,814 - INFO - training batch 501, loss: 0.041, 16032/28000 datapoints
2025-03-06 21:03:22,937 - INFO - training batch 551, loss: 0.051, 17632/28000 datapoints
2025-03-06 21:03:23,059 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:03:23,181 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:23,304 - INFO - training batch 701, loss: 0.084, 22432/28000 datapoints
2025-03-06 21:03:23,426 - INFO - training batch 751, loss: 0.045, 24032/28000 datapoints
2025-03-06 21:03:23,551 - INFO - training batch 801, loss: 0.044, 25632/28000 datapoints
2025-03-06 21:03:23,674 - INFO - training batch 851, loss: 0.088, 27232/28000 datapoints
2025-03-06 21:03:23,740 - INFO - validation batch 1, loss: 0.448, 32/6976 datapoints
2025-03-06 21:03:23,783 - INFO - validation batch 51, loss: 2.062, 1632/6976 datapoints
2025-03-06 21:03:23,827 - INFO - validation batch 101, loss: 0.838, 3232/6976 datapoints
2025-03-06 21:03:23,873 - INFO - validation batch 151, loss: 0.583, 4832/6976 datapoints
2025-03-06 21:03:23,917 - INFO - validation batch 201, loss: 0.563, 6432/6976 datapoints
2025-03-06 21:03:23,932 - INFO - Epoch 642/800 done.
2025-03-06 21:03:23,933 - INFO - Final validation performance:
Loss: 0.899, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:23,933 - INFO - Beginning epoch 643/800
2025-03-06 21:03:23,937 - INFO - training batch 1, loss: 0.133, 32/28000 datapoints
2025-03-06 21:03:24,060 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 21:03:24,180 - INFO - training batch 101, loss: 0.048, 3232/28000 datapoints
2025-03-06 21:03:24,303 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-06 21:03:24,425 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:24,546 - INFO - training batch 251, loss: 0.113, 8032/28000 datapoints
2025-03-06 21:03:24,673 - INFO - training batch 301, loss: 0.085, 9632/28000 datapoints
2025-03-06 21:03:24,793 - INFO - training batch 351, loss: 0.122, 11232/28000 datapoints
2025-03-06 21:03:24,922 - INFO - training batch 401, loss: 0.156, 12832/28000 datapoints
2025-03-06 21:03:25,043 - INFO - training batch 451, loss: 0.080, 14432/28000 datapoints
2025-03-06 21:03:25,166 - INFO - training batch 501, loss: 0.041, 16032/28000 datapoints
2025-03-06 21:03:25,286 - INFO - training batch 551, loss: 0.051, 17632/28000 datapoints
2025-03-06 21:03:25,408 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:03:25,528 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:25,652 - INFO - training batch 701, loss: 0.084, 22432/28000 datapoints
2025-03-06 21:03:25,773 - INFO - training batch 751, loss: 0.045, 24032/28000 datapoints
2025-03-06 21:03:25,896 - INFO - training batch 801, loss: 0.043, 25632/28000 datapoints
2025-03-06 21:03:26,024 - INFO - training batch 851, loss: 0.088, 27232/28000 datapoints
2025-03-06 21:03:26,085 - INFO - validation batch 1, loss: 0.452, 32/6976 datapoints
2025-03-06 21:03:26,130 - INFO - validation batch 51, loss: 2.064, 1632/6976 datapoints
2025-03-06 21:03:26,174 - INFO - validation batch 101, loss: 0.842, 3232/6976 datapoints
2025-03-06 21:03:26,217 - INFO - validation batch 151, loss: 0.586, 4832/6976 datapoints
2025-03-06 21:03:26,262 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:03:26,278 - INFO - Epoch 643/800 done.
2025-03-06 21:03:26,278 - INFO - Final validation performance:
Loss: 0.902, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:26,278 - INFO - Beginning epoch 644/800
2025-03-06 21:03:26,282 - INFO - training batch 1, loss: 0.132, 32/28000 datapoints
2025-03-06 21:03:26,404 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 21:03:26,528 - INFO - training batch 101, loss: 0.047, 3232/28000 datapoints
2025-03-06 21:03:26,654 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 21:03:26,774 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:26,896 - INFO - training batch 251, loss: 0.111, 8032/28000 datapoints
2025-03-06 21:03:27,018 - INFO - training batch 301, loss: 0.085, 9632/28000 datapoints
2025-03-06 21:03:27,139 - INFO - training batch 351, loss: 0.122, 11232/28000 datapoints
2025-03-06 21:03:27,258 - INFO - training batch 401, loss: 0.154, 12832/28000 datapoints
2025-03-06 21:03:27,381 - INFO - training batch 451, loss: 0.079, 14432/28000 datapoints
2025-03-06 21:03:27,503 - INFO - training batch 501, loss: 0.040, 16032/28000 datapoints
2025-03-06 21:03:27,625 - INFO - training batch 551, loss: 0.050, 17632/28000 datapoints
2025-03-06 21:03:27,753 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:03:27,875 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:27,997 - INFO - training batch 701, loss: 0.084, 22432/28000 datapoints
2025-03-06 21:03:28,116 - INFO - training batch 751, loss: 0.045, 24032/28000 datapoints
2025-03-06 21:03:28,236 - INFO - training batch 801, loss: 0.043, 25632/28000 datapoints
2025-03-06 21:03:28,358 - INFO - training batch 851, loss: 0.087, 27232/28000 datapoints
2025-03-06 21:03:28,419 - INFO - validation batch 1, loss: 0.457, 32/6976 datapoints
2025-03-06 21:03:28,468 - INFO - validation batch 51, loss: 2.072, 1632/6976 datapoints
2025-03-06 21:03:28,532 - INFO - validation batch 101, loss: 0.843, 3232/6976 datapoints
2025-03-06 21:03:28,582 - INFO - validation batch 151, loss: 0.586, 4832/6976 datapoints
2025-03-06 21:03:28,628 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:03:28,646 - INFO - Epoch 644/800 done.
2025-03-06 21:03:28,646 - INFO - Final validation performance:
Loss: 0.905, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:28,647 - INFO - Beginning epoch 645/800
2025-03-06 21:03:28,651 - INFO - training batch 1, loss: 0.131, 32/28000 datapoints
2025-03-06 21:03:28,773 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 21:03:28,896 - INFO - training batch 101, loss: 0.047, 3232/28000 datapoints
2025-03-06 21:03:29,021 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 21:03:29,152 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:29,281 - INFO - training batch 251, loss: 0.110, 8032/28000 datapoints
2025-03-06 21:03:29,402 - INFO - training batch 301, loss: 0.085, 9632/28000 datapoints
2025-03-06 21:03:29,524 - INFO - training batch 351, loss: 0.121, 11232/28000 datapoints
2025-03-06 21:03:29,660 - INFO - training batch 401, loss: 0.152, 12832/28000 datapoints
2025-03-06 21:03:29,802 - INFO - training batch 451, loss: 0.077, 14432/28000 datapoints
2025-03-06 21:03:29,927 - INFO - training batch 501, loss: 0.040, 16032/28000 datapoints
2025-03-06 21:03:30,051 - INFO - training batch 551, loss: 0.050, 17632/28000 datapoints
2025-03-06 21:03:30,172 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:03:30,294 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:30,418 - INFO - training batch 701, loss: 0.084, 22432/28000 datapoints
2025-03-06 21:03:30,540 - INFO - training batch 751, loss: 0.044, 24032/28000 datapoints
2025-03-06 21:03:30,668 - INFO - training batch 801, loss: 0.043, 25632/28000 datapoints
2025-03-06 21:03:30,792 - INFO - training batch 851, loss: 0.086, 27232/28000 datapoints
2025-03-06 21:03:30,853 - INFO - validation batch 1, loss: 0.463, 32/6976 datapoints
2025-03-06 21:03:30,897 - INFO - validation batch 51, loss: 2.075, 1632/6976 datapoints
2025-03-06 21:03:30,940 - INFO - validation batch 101, loss: 0.846, 3232/6976 datapoints
2025-03-06 21:03:30,988 - INFO - validation batch 151, loss: 0.586, 4832/6976 datapoints
2025-03-06 21:03:31,033 - INFO - validation batch 201, loss: 0.570, 6432/6976 datapoints
2025-03-06 21:03:31,048 - INFO - Epoch 645/800 done.
2025-03-06 21:03:31,048 - INFO - Final validation performance:
Loss: 0.908, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:31,049 - INFO - Beginning epoch 646/800
2025-03-06 21:03:31,052 - INFO - training batch 1, loss: 0.131, 32/28000 datapoints
2025-03-06 21:03:31,177 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 21:03:31,298 - INFO - training batch 101, loss: 0.047, 3232/28000 datapoints
2025-03-06 21:03:31,421 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-06 21:03:31,548 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:31,676 - INFO - training batch 251, loss: 0.109, 8032/28000 datapoints
2025-03-06 21:03:31,799 - INFO - training batch 301, loss: 0.084, 9632/28000 datapoints
2025-03-06 21:03:31,927 - INFO - training batch 351, loss: 0.120, 11232/28000 datapoints
2025-03-06 21:03:32,057 - INFO - training batch 401, loss: 0.153, 12832/28000 datapoints
2025-03-06 21:03:32,187 - INFO - training batch 451, loss: 0.077, 14432/28000 datapoints
2025-03-06 21:03:32,311 - INFO - training batch 501, loss: 0.040, 16032/28000 datapoints
2025-03-06 21:03:32,435 - INFO - training batch 551, loss: 0.049, 17632/28000 datapoints
2025-03-06 21:03:32,561 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:03:32,692 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:32,820 - INFO - training batch 701, loss: 0.082, 22432/28000 datapoints
2025-03-06 21:03:32,949 - INFO - training batch 751, loss: 0.044, 24032/28000 datapoints
2025-03-06 21:03:33,078 - INFO - training batch 801, loss: 0.042, 25632/28000 datapoints
2025-03-06 21:03:33,204 - INFO - training batch 851, loss: 0.086, 27232/28000 datapoints
2025-03-06 21:03:33,267 - INFO - validation batch 1, loss: 0.467, 32/6976 datapoints
2025-03-06 21:03:33,317 - INFO - validation batch 51, loss: 2.080, 1632/6976 datapoints
2025-03-06 21:03:33,367 - INFO - validation batch 101, loss: 0.848, 3232/6976 datapoints
2025-03-06 21:03:33,415 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 21:03:33,463 - INFO - validation batch 201, loss: 0.574, 6432/6976 datapoints
2025-03-06 21:03:33,481 - INFO - Epoch 646/800 done.
2025-03-06 21:03:33,481 - INFO - Final validation performance:
Loss: 0.911, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:33,482 - INFO - Beginning epoch 647/800
2025-03-06 21:03:33,489 - INFO - training batch 1, loss: 0.130, 32/28000 datapoints
2025-03-06 21:03:33,617 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 21:03:33,743 - INFO - training batch 101, loss: 0.047, 3232/28000 datapoints
2025-03-06 21:03:33,872 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 21:03:34,000 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:34,127 - INFO - training batch 251, loss: 0.108, 8032/28000 datapoints
2025-03-06 21:03:34,255 - INFO - training batch 301, loss: 0.083, 9632/28000 datapoints
2025-03-06 21:03:34,379 - INFO - training batch 351, loss: 0.119, 11232/28000 datapoints
2025-03-06 21:03:34,505 - INFO - training batch 401, loss: 0.150, 12832/28000 datapoints
2025-03-06 21:03:34,633 - INFO - training batch 451, loss: 0.079, 14432/28000 datapoints
2025-03-06 21:03:34,763 - INFO - training batch 501, loss: 0.040, 16032/28000 datapoints
2025-03-06 21:03:34,892 - INFO - training batch 551, loss: 0.049, 17632/28000 datapoints
2025-03-06 21:03:35,021 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:03:35,148 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:35,273 - INFO - training batch 701, loss: 0.082, 22432/28000 datapoints
2025-03-06 21:03:35,400 - INFO - training batch 751, loss: 0.044, 24032/28000 datapoints
2025-03-06 21:03:35,527 - INFO - training batch 801, loss: 0.042, 25632/28000 datapoints
2025-03-06 21:03:35,654 - INFO - training batch 851, loss: 0.085, 27232/28000 datapoints
2025-03-06 21:03:35,717 - INFO - validation batch 1, loss: 0.470, 32/6976 datapoints
2025-03-06 21:03:35,766 - INFO - validation batch 51, loss: 2.088, 1632/6976 datapoints
2025-03-06 21:03:35,815 - INFO - validation batch 101, loss: 0.849, 3232/6976 datapoints
2025-03-06 21:03:35,864 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 21:03:35,913 - INFO - validation batch 201, loss: 0.574, 6432/6976 datapoints
2025-03-06 21:03:35,930 - INFO - Epoch 647/800 done.
2025-03-06 21:03:35,930 - INFO - Final validation performance:
Loss: 0.913, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:35,930 - INFO - Beginning epoch 648/800
2025-03-06 21:03:35,935 - INFO - training batch 1, loss: 0.129, 32/28000 datapoints
2025-03-06 21:03:36,062 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 21:03:36,182 - INFO - training batch 101, loss: 0.046, 3232/28000 datapoints
2025-03-06 21:03:36,304 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 21:03:36,425 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:36,547 - INFO - training batch 251, loss: 0.107, 8032/28000 datapoints
2025-03-06 21:03:36,673 - INFO - training batch 301, loss: 0.083, 9632/28000 datapoints
2025-03-06 21:03:36,806 - INFO - training batch 351, loss: 0.119, 11232/28000 datapoints
2025-03-06 21:03:36,928 - INFO - training batch 401, loss: 0.149, 12832/28000 datapoints
2025-03-06 21:03:37,050 - INFO - training batch 451, loss: 0.076, 14432/28000 datapoints
2025-03-06 21:03:37,171 - INFO - training batch 501, loss: 0.040, 16032/28000 datapoints
2025-03-06 21:03:37,292 - INFO - training batch 551, loss: 0.049, 17632/28000 datapoints
2025-03-06 21:03:37,413 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:03:37,535 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:37,669 - INFO - training batch 701, loss: 0.082, 22432/28000 datapoints
2025-03-06 21:03:37,793 - INFO - training batch 751, loss: 0.043, 24032/28000 datapoints
2025-03-06 21:03:37,916 - INFO - training batch 801, loss: 0.042, 25632/28000 datapoints
2025-03-06 21:03:38,037 - INFO - training batch 851, loss: 0.085, 27232/28000 datapoints
2025-03-06 21:03:38,100 - INFO - validation batch 1, loss: 0.475, 32/6976 datapoints
2025-03-06 21:03:38,143 - INFO - validation batch 51, loss: 2.091, 1632/6976 datapoints
2025-03-06 21:03:38,187 - INFO - validation batch 101, loss: 0.852, 3232/6976 datapoints
2025-03-06 21:03:38,235 - INFO - validation batch 151, loss: 0.586, 4832/6976 datapoints
2025-03-06 21:03:38,279 - INFO - validation batch 201, loss: 0.578, 6432/6976 datapoints
2025-03-06 21:03:38,294 - INFO - Epoch 648/800 done.
2025-03-06 21:03:38,294 - INFO - Final validation performance:
Loss: 0.916, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:38,295 - INFO - Beginning epoch 649/800
2025-03-06 21:03:38,298 - INFO - training batch 1, loss: 0.128, 32/28000 datapoints
2025-03-06 21:03:38,422 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 21:03:38,547 - INFO - training batch 101, loss: 0.046, 3232/28000 datapoints
2025-03-06 21:03:38,699 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 21:03:38,822 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:38,944 - INFO - training batch 251, loss: 0.106, 8032/28000 datapoints
2025-03-06 21:03:39,073 - INFO - training batch 301, loss: 0.082, 9632/28000 datapoints
2025-03-06 21:03:39,195 - INFO - training batch 351, loss: 0.117, 11232/28000 datapoints
2025-03-06 21:03:39,316 - INFO - training batch 401, loss: 0.148, 12832/28000 datapoints
2025-03-06 21:03:39,438 - INFO - training batch 451, loss: 0.077, 14432/28000 datapoints
2025-03-06 21:03:39,560 - INFO - training batch 501, loss: 0.039, 16032/28000 datapoints
2025-03-06 21:03:39,684 - INFO - training batch 551, loss: 0.048, 17632/28000 datapoints
2025-03-06 21:03:39,805 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:03:39,927 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:40,056 - INFO - training batch 701, loss: 0.081, 22432/28000 datapoints
2025-03-06 21:03:40,180 - INFO - training batch 751, loss: 0.043, 24032/28000 datapoints
2025-03-06 21:03:40,302 - INFO - training batch 801, loss: 0.042, 25632/28000 datapoints
2025-03-06 21:03:40,423 - INFO - training batch 851, loss: 0.084, 27232/28000 datapoints
2025-03-06 21:03:40,483 - INFO - validation batch 1, loss: 0.478, 32/6976 datapoints
2025-03-06 21:03:40,527 - INFO - validation batch 51, loss: 2.099, 1632/6976 datapoints
2025-03-06 21:03:40,572 - INFO - validation batch 101, loss: 0.854, 3232/6976 datapoints
2025-03-06 21:03:40,616 - INFO - validation batch 151, loss: 0.586, 4832/6976 datapoints
2025-03-06 21:03:40,666 - INFO - validation batch 201, loss: 0.578, 6432/6976 datapoints
2025-03-06 21:03:40,681 - INFO - Epoch 649/800 done.
2025-03-06 21:03:40,681 - INFO - Final validation performance:
Loss: 0.919, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:40,681 - INFO - Beginning epoch 650/800
2025-03-06 21:03:40,685 - INFO - training batch 1, loss: 0.127, 32/28000 datapoints
2025-03-06 21:03:40,808 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 21:03:40,936 - INFO - training batch 101, loss: 0.046, 3232/28000 datapoints
2025-03-06 21:03:41,061 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-06 21:03:41,187 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:41,311 - INFO - training batch 251, loss: 0.105, 8032/28000 datapoints
2025-03-06 21:03:41,432 - INFO - training batch 301, loss: 0.081, 9632/28000 datapoints
2025-03-06 21:03:41,552 - INFO - training batch 351, loss: 0.117, 11232/28000 datapoints
2025-03-06 21:03:41,677 - INFO - training batch 401, loss: 0.148, 12832/28000 datapoints
2025-03-06 21:03:41,799 - INFO - training batch 451, loss: 0.075, 14432/28000 datapoints
2025-03-06 21:03:41,921 - INFO - training batch 501, loss: 0.039, 16032/28000 datapoints
2025-03-06 21:03:42,042 - INFO - training batch 551, loss: 0.048, 17632/28000 datapoints
2025-03-06 21:03:42,163 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:03:42,287 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:42,408 - INFO - training batch 701, loss: 0.082, 22432/28000 datapoints
2025-03-06 21:03:42,530 - INFO - training batch 751, loss: 0.043, 24032/28000 datapoints
2025-03-06 21:03:42,659 - INFO - training batch 801, loss: 0.042, 25632/28000 datapoints
2025-03-06 21:03:42,778 - INFO - training batch 851, loss: 0.083, 27232/28000 datapoints
2025-03-06 21:03:42,840 - INFO - validation batch 1, loss: 0.486, 32/6976 datapoints
2025-03-06 21:03:42,887 - INFO - validation batch 51, loss: 2.103, 1632/6976 datapoints
2025-03-06 21:03:42,931 - INFO - validation batch 101, loss: 0.857, 3232/6976 datapoints
2025-03-06 21:03:42,975 - INFO - validation batch 151, loss: 0.584, 4832/6976 datapoints
2025-03-06 21:03:43,019 - INFO - validation batch 201, loss: 0.580, 6432/6976 datapoints
2025-03-06 21:03:43,034 - INFO - Epoch 650/800 done.
2025-03-06 21:03:43,034 - INFO - Final validation performance:
Loss: 0.922, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:43,035 - INFO - Beginning epoch 651/800
2025-03-06 21:03:43,039 - INFO - training batch 1, loss: 0.126, 32/28000 datapoints
2025-03-06 21:03:43,164 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 21:03:43,286 - INFO - training batch 101, loss: 0.046, 3232/28000 datapoints
2025-03-06 21:03:43,409 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-06 21:03:43,531 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:43,654 - INFO - training batch 251, loss: 0.104, 8032/28000 datapoints
2025-03-06 21:03:43,779 - INFO - training batch 301, loss: 0.081, 9632/28000 datapoints
2025-03-06 21:03:43,902 - INFO - training batch 351, loss: 0.116, 11232/28000 datapoints
2025-03-06 21:03:44,027 - INFO - training batch 401, loss: 0.147, 12832/28000 datapoints
2025-03-06 21:03:44,152 - INFO - training batch 451, loss: 0.076, 14432/28000 datapoints
2025-03-06 21:03:44,277 - INFO - training batch 501, loss: 0.039, 16032/28000 datapoints
2025-03-06 21:03:44,403 - INFO - training batch 551, loss: 0.048, 17632/28000 datapoints
2025-03-06 21:03:44,523 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:03:44,652 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:44,775 - INFO - training batch 701, loss: 0.080, 22432/28000 datapoints
2025-03-06 21:03:44,902 - INFO - training batch 751, loss: 0.042, 24032/28000 datapoints
2025-03-06 21:03:45,026 - INFO - training batch 801, loss: 0.041, 25632/28000 datapoints
2025-03-06 21:03:45,157 - INFO - training batch 851, loss: 0.083, 27232/28000 datapoints
2025-03-06 21:03:45,216 - INFO - validation batch 1, loss: 0.490, 32/6976 datapoints
2025-03-06 21:03:45,259 - INFO - validation batch 51, loss: 2.109, 1632/6976 datapoints
2025-03-06 21:03:45,303 - INFO - validation batch 101, loss: 0.859, 3232/6976 datapoints
2025-03-06 21:03:45,347 - INFO - validation batch 151, loss: 0.586, 4832/6976 datapoints
2025-03-06 21:03:45,392 - INFO - validation batch 201, loss: 0.584, 6432/6976 datapoints
2025-03-06 21:03:45,407 - INFO - Epoch 651/800 done.
2025-03-06 21:03:45,407 - INFO - Final validation performance:
Loss: 0.926, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:45,408 - INFO - Beginning epoch 652/800
2025-03-06 21:03:45,411 - INFO - training batch 1, loss: 0.125, 32/28000 datapoints
2025-03-06 21:03:45,533 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 21:03:45,660 - INFO - training batch 101, loss: 0.045, 3232/28000 datapoints
2025-03-06 21:03:45,805 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 21:03:45,938 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:46,059 - INFO - training batch 251, loss: 0.102, 8032/28000 datapoints
2025-03-06 21:03:46,182 - INFO - training batch 301, loss: 0.080, 9632/28000 datapoints
2025-03-06 21:03:46,302 - INFO - training batch 351, loss: 0.116, 11232/28000 datapoints
2025-03-06 21:03:46,423 - INFO - training batch 401, loss: 0.144, 12832/28000 datapoints
2025-03-06 21:03:46,562 - INFO - training batch 451, loss: 0.074, 14432/28000 datapoints
2025-03-06 21:03:46,695 - INFO - training batch 501, loss: 0.038, 16032/28000 datapoints
2025-03-06 21:03:46,818 - INFO - training batch 551, loss: 0.047, 17632/28000 datapoints
2025-03-06 21:03:46,941 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:03:47,059 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:47,180 - INFO - training batch 701, loss: 0.080, 22432/28000 datapoints
2025-03-06 21:03:47,300 - INFO - training batch 751, loss: 0.042, 24032/28000 datapoints
2025-03-06 21:03:47,423 - INFO - training batch 801, loss: 0.041, 25632/28000 datapoints
2025-03-06 21:03:47,543 - INFO - training batch 851, loss: 0.083, 27232/28000 datapoints
2025-03-06 21:03:47,603 - INFO - validation batch 1, loss: 0.494, 32/6976 datapoints
2025-03-06 21:03:47,653 - INFO - validation batch 51, loss: 2.115, 1632/6976 datapoints
2025-03-06 21:03:47,698 - INFO - validation batch 101, loss: 0.861, 3232/6976 datapoints
2025-03-06 21:03:47,742 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-06 21:03:47,785 - INFO - validation batch 201, loss: 0.586, 6432/6976 datapoints
2025-03-06 21:03:47,800 - INFO - Epoch 652/800 done.
2025-03-06 21:03:47,800 - INFO - Final validation performance:
Loss: 0.929, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:47,801 - INFO - Beginning epoch 653/800
2025-03-06 21:03:47,805 - INFO - training batch 1, loss: 0.124, 32/28000 datapoints
2025-03-06 21:03:47,929 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 21:03:48,050 - INFO - training batch 101, loss: 0.046, 3232/28000 datapoints
2025-03-06 21:03:48,173 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 21:03:48,294 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:48,418 - INFO - training batch 251, loss: 0.102, 8032/28000 datapoints
2025-03-06 21:03:48,539 - INFO - training batch 301, loss: 0.080, 9632/28000 datapoints
2025-03-06 21:03:48,668 - INFO - training batch 351, loss: 0.114, 11232/28000 datapoints
2025-03-06 21:03:48,819 - INFO - training batch 401, loss: 0.145, 12832/28000 datapoints
2025-03-06 21:03:48,941 - INFO - training batch 451, loss: 0.074, 14432/28000 datapoints
2025-03-06 21:03:49,062 - INFO - training batch 501, loss: 0.038, 16032/28000 datapoints
2025-03-06 21:03:49,184 - INFO - training batch 551, loss: 0.047, 17632/28000 datapoints
2025-03-06 21:03:49,305 - INFO - training batch 601, loss: 0.044, 19232/28000 datapoints
2025-03-06 21:03:49,426 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:49,546 - INFO - training batch 701, loss: 0.079, 22432/28000 datapoints
2025-03-06 21:03:49,671 - INFO - training batch 751, loss: 0.042, 24032/28000 datapoints
2025-03-06 21:03:49,791 - INFO - training batch 801, loss: 0.041, 25632/28000 datapoints
2025-03-06 21:03:49,912 - INFO - training batch 851, loss: 0.082, 27232/28000 datapoints
2025-03-06 21:03:49,973 - INFO - validation batch 1, loss: 0.500, 32/6976 datapoints
2025-03-06 21:03:50,018 - INFO - validation batch 51, loss: 2.122, 1632/6976 datapoints
2025-03-06 21:03:50,061 - INFO - validation batch 101, loss: 0.864, 3232/6976 datapoints
2025-03-06 21:03:50,106 - INFO - validation batch 151, loss: 0.584, 4832/6976 datapoints
2025-03-06 21:03:50,152 - INFO - validation batch 201, loss: 0.589, 6432/6976 datapoints
2025-03-06 21:03:50,167 - INFO - Epoch 653/800 done.
2025-03-06 21:03:50,167 - INFO - Final validation performance:
Loss: 0.931, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:50,168 - INFO - Beginning epoch 654/800
2025-03-06 21:03:50,172 - INFO - training batch 1, loss: 0.123, 32/28000 datapoints
2025-03-06 21:03:50,295 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 21:03:50,419 - INFO - training batch 101, loss: 0.045, 3232/28000 datapoints
2025-03-06 21:03:50,542 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 21:03:50,667 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:50,814 - INFO - training batch 251, loss: 0.100, 8032/28000 datapoints
2025-03-06 21:03:51,004 - INFO - training batch 301, loss: 0.079, 9632/28000 datapoints
2025-03-06 21:03:51,123 - INFO - training batch 351, loss: 0.113, 11232/28000 datapoints
2025-03-06 21:03:51,244 - INFO - training batch 401, loss: 0.143, 12832/28000 datapoints
2025-03-06 21:03:51,368 - INFO - training batch 451, loss: 0.073, 14432/28000 datapoints
2025-03-06 21:03:51,489 - INFO - training batch 501, loss: 0.038, 16032/28000 datapoints
2025-03-06 21:03:51,616 - INFO - training batch 551, loss: 0.046, 17632/28000 datapoints
2025-03-06 21:03:51,803 - INFO - training batch 601, loss: 0.044, 19232/28000 datapoints
2025-03-06 21:03:51,935 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:52,066 - INFO - training batch 701, loss: 0.078, 22432/28000 datapoints
2025-03-06 21:03:52,197 - INFO - training batch 751, loss: 0.041, 24032/28000 datapoints
2025-03-06 21:03:52,333 - INFO - training batch 801, loss: 0.041, 25632/28000 datapoints
2025-03-06 21:03:52,458 - INFO - training batch 851, loss: 0.081, 27232/28000 datapoints
2025-03-06 21:03:52,521 - INFO - validation batch 1, loss: 0.505, 32/6976 datapoints
2025-03-06 21:03:52,569 - INFO - validation batch 51, loss: 2.128, 1632/6976 datapoints
2025-03-06 21:03:52,620 - INFO - validation batch 101, loss: 0.867, 3232/6976 datapoints
2025-03-06 21:03:52,673 - INFO - validation batch 151, loss: 0.586, 4832/6976 datapoints
2025-03-06 21:03:52,726 - INFO - validation batch 201, loss: 0.589, 6432/6976 datapoints
2025-03-06 21:03:52,744 - INFO - Epoch 654/800 done.
2025-03-06 21:03:52,744 - INFO - Final validation performance:
Loss: 0.935, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:03:52,745 - INFO - Beginning epoch 655/800
2025-03-06 21:03:52,748 - INFO - training batch 1, loss: 0.123, 32/28000 datapoints
2025-03-06 21:03:52,877 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 21:03:53,009 - INFO - training batch 101, loss: 0.045, 3232/28000 datapoints
2025-03-06 21:03:53,134 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 21:03:53,258 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:53,384 - INFO - training batch 251, loss: 0.099, 8032/28000 datapoints
2025-03-06 21:03:53,511 - INFO - training batch 301, loss: 0.079, 9632/28000 datapoints
2025-03-06 21:03:53,635 - INFO - training batch 351, loss: 0.113, 11232/28000 datapoints
2025-03-06 21:03:53,761 - INFO - training batch 401, loss: 0.142, 12832/28000 datapoints
2025-03-06 21:03:53,899 - INFO - training batch 451, loss: 0.073, 14432/28000 datapoints
2025-03-06 21:03:54,025 - INFO - training batch 501, loss: 0.038, 16032/28000 datapoints
2025-03-06 21:03:54,148 - INFO - training batch 551, loss: 0.046, 17632/28000 datapoints
2025-03-06 21:03:54,274 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:03:54,403 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:54,528 - INFO - training batch 701, loss: 0.078, 22432/28000 datapoints
2025-03-06 21:03:54,654 - INFO - training batch 751, loss: 0.041, 24032/28000 datapoints
2025-03-06 21:03:54,783 - INFO - training batch 801, loss: 0.041, 25632/28000 datapoints
2025-03-06 21:03:54,921 - INFO - training batch 851, loss: 0.081, 27232/28000 datapoints
2025-03-06 21:03:55,011 - INFO - validation batch 1, loss: 0.508, 32/6976 datapoints
2025-03-06 21:03:55,066 - INFO - validation batch 51, loss: 2.133, 1632/6976 datapoints
2025-03-06 21:03:55,121 - INFO - validation batch 101, loss: 0.870, 3232/6976 datapoints
2025-03-06 21:03:55,171 - INFO - validation batch 151, loss: 0.584, 4832/6976 datapoints
2025-03-06 21:03:55,219 - INFO - validation batch 201, loss: 0.594, 6432/6976 datapoints
2025-03-06 21:03:55,238 - INFO - Epoch 655/800 done.
2025-03-06 21:03:55,238 - INFO - Final validation performance:
Loss: 0.938, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:03:55,239 - INFO - Beginning epoch 656/800
2025-03-06 21:03:55,243 - INFO - training batch 1, loss: 0.121, 32/28000 datapoints
2025-03-06 21:03:55,373 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 21:03:55,500 - INFO - training batch 101, loss: 0.044, 3232/28000 datapoints
2025-03-06 21:03:55,625 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 21:03:55,751 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:55,875 - INFO - training batch 251, loss: 0.098, 8032/28000 datapoints
2025-03-06 21:03:56,000 - INFO - training batch 301, loss: 0.078, 9632/28000 datapoints
2025-03-06 21:03:56,123 - INFO - training batch 351, loss: 0.112, 11232/28000 datapoints
2025-03-06 21:03:56,248 - INFO - training batch 401, loss: 0.140, 12832/28000 datapoints
2025-03-06 21:03:56,376 - INFO - training batch 451, loss: 0.072, 14432/28000 datapoints
2025-03-06 21:03:56,504 - INFO - training batch 501, loss: 0.037, 16032/28000 datapoints
2025-03-06 21:03:56,629 - INFO - training batch 551, loss: 0.045, 17632/28000 datapoints
2025-03-06 21:03:56,760 - INFO - training batch 601, loss: 0.044, 19232/28000 datapoints
2025-03-06 21:03:56,892 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:03:57,018 - INFO - training batch 701, loss: 0.078, 22432/28000 datapoints
2025-03-06 21:03:57,141 - INFO - training batch 751, loss: 0.041, 24032/28000 datapoints
2025-03-06 21:03:57,264 - INFO - training batch 801, loss: 0.040, 25632/28000 datapoints
2025-03-06 21:03:57,390 - INFO - training batch 851, loss: 0.080, 27232/28000 datapoints
2025-03-06 21:03:57,455 - INFO - validation batch 1, loss: 0.515, 32/6976 datapoints
2025-03-06 21:03:57,502 - INFO - validation batch 51, loss: 2.138, 1632/6976 datapoints
2025-03-06 21:03:57,550 - INFO - validation batch 101, loss: 0.873, 3232/6976 datapoints
2025-03-06 21:03:57,597 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 21:03:57,648 - INFO - validation batch 201, loss: 0.595, 6432/6976 datapoints
2025-03-06 21:03:57,664 - INFO - Epoch 656/800 done.
2025-03-06 21:03:57,664 - INFO - Final validation performance:
Loss: 0.941, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:03:57,665 - INFO - Beginning epoch 657/800
2025-03-06 21:03:57,669 - INFO - training batch 1, loss: 0.120, 32/28000 datapoints
2025-03-06 21:03:57,795 - INFO - training batch 51, loss: 0.039, 1632/28000 datapoints
2025-03-06 21:03:57,921 - INFO - training batch 101, loss: 0.044, 3232/28000 datapoints
2025-03-06 21:03:58,045 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 21:03:58,169 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:03:58,296 - INFO - training batch 251, loss: 0.097, 8032/28000 datapoints
2025-03-06 21:03:58,422 - INFO - training batch 301, loss: 0.077, 9632/28000 datapoints
2025-03-06 21:03:58,548 - INFO - training batch 351, loss: 0.112, 11232/28000 datapoints
2025-03-06 21:03:58,676 - INFO - training batch 401, loss: 0.140, 12832/28000 datapoints
2025-03-06 21:03:58,825 - INFO - training batch 451, loss: 0.072, 14432/28000 datapoints
2025-03-06 21:03:58,963 - INFO - training batch 501, loss: 0.037, 16032/28000 datapoints
2025-03-06 21:03:59,091 - INFO - training batch 551, loss: 0.045, 17632/28000 datapoints
2025-03-06 21:03:59,214 - INFO - training batch 601, loss: 0.044, 19232/28000 datapoints
2025-03-06 21:03:59,343 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:03:59,488 - INFO - training batch 701, loss: 0.078, 22432/28000 datapoints
2025-03-06 21:03:59,619 - INFO - training batch 751, loss: 0.040, 24032/28000 datapoints
2025-03-06 21:03:59,746 - INFO - training batch 801, loss: 0.040, 25632/28000 datapoints
2025-03-06 21:03:59,872 - INFO - training batch 851, loss: 0.080, 27232/28000 datapoints
2025-03-06 21:03:59,935 - INFO - validation batch 1, loss: 0.519, 32/6976 datapoints
2025-03-06 21:03:59,983 - INFO - validation batch 51, loss: 2.143, 1632/6976 datapoints
2025-03-06 21:04:00,033 - INFO - validation batch 101, loss: 0.875, 3232/6976 datapoints
2025-03-06 21:04:00,078 - INFO - validation batch 151, loss: 0.588, 4832/6976 datapoints
2025-03-06 21:04:00,122 - INFO - validation batch 201, loss: 0.600, 6432/6976 datapoints
2025-03-06 21:04:00,138 - INFO - Epoch 657/800 done.
2025-03-06 21:04:00,138 - INFO - Final validation performance:
Loss: 0.945, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:04:00,139 - INFO - Beginning epoch 658/800
2025-03-06 21:04:00,142 - INFO - training batch 1, loss: 0.119, 32/28000 datapoints
2025-03-06 21:04:00,266 - INFO - training batch 51, loss: 0.039, 1632/28000 datapoints
2025-03-06 21:04:00,389 - INFO - training batch 101, loss: 0.044, 3232/28000 datapoints
2025-03-06 21:04:00,511 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 21:04:00,631 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:04:00,757 - INFO - training batch 251, loss: 0.097, 8032/28000 datapoints
2025-03-06 21:04:00,878 - INFO - training batch 301, loss: 0.077, 9632/28000 datapoints
2025-03-06 21:04:00,999 - INFO - training batch 351, loss: 0.111, 11232/28000 datapoints
2025-03-06 21:04:01,120 - INFO - training batch 401, loss: 0.139, 12832/28000 datapoints
2025-03-06 21:04:01,240 - INFO - training batch 451, loss: 0.071, 14432/28000 datapoints
2025-03-06 21:04:01,360 - INFO - training batch 501, loss: 0.037, 16032/28000 datapoints
2025-03-06 21:04:01,482 - INFO - training batch 551, loss: 0.045, 17632/28000 datapoints
2025-03-06 21:04:01,601 - INFO - training batch 601, loss: 0.044, 19232/28000 datapoints
2025-03-06 21:04:01,725 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:04:01,843 - INFO - training batch 701, loss: 0.077, 22432/28000 datapoints
2025-03-06 21:04:01,966 - INFO - training batch 751, loss: 0.040, 24032/28000 datapoints
2025-03-06 21:04:02,085 - INFO - training batch 801, loss: 0.040, 25632/28000 datapoints
2025-03-06 21:04:02,205 - INFO - training batch 851, loss: 0.079, 27232/28000 datapoints
2025-03-06 21:04:02,265 - INFO - validation batch 1, loss: 0.524, 32/6976 datapoints
2025-03-06 21:04:02,308 - INFO - validation batch 51, loss: 2.151, 1632/6976 datapoints
2025-03-06 21:04:02,352 - INFO - validation batch 101, loss: 0.877, 3232/6976 datapoints
2025-03-06 21:04:02,398 - INFO - validation batch 151, loss: 0.586, 4832/6976 datapoints
2025-03-06 21:04:02,443 - INFO - validation batch 201, loss: 0.601, 6432/6976 datapoints
2025-03-06 21:04:02,458 - INFO - Epoch 658/800 done.
2025-03-06 21:04:02,458 - INFO - Final validation performance:
Loss: 0.948, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:04:02,459 - INFO - Beginning epoch 659/800
2025-03-06 21:04:02,462 - INFO - training batch 1, loss: 0.118, 32/28000 datapoints
2025-03-06 21:04:02,584 - INFO - training batch 51, loss: 0.039, 1632/28000 datapoints
2025-03-06 21:04:02,709 - INFO - training batch 101, loss: 0.044, 3232/28000 datapoints
2025-03-06 21:04:02,832 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 21:04:02,965 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:04:03,088 - INFO - training batch 251, loss: 0.096, 8032/28000 datapoints
2025-03-06 21:04:03,209 - INFO - training batch 301, loss: 0.077, 9632/28000 datapoints
2025-03-06 21:04:03,330 - INFO - training batch 351, loss: 0.109, 11232/28000 datapoints
2025-03-06 21:04:03,453 - INFO - training batch 401, loss: 0.137, 12832/28000 datapoints
2025-03-06 21:04:03,575 - INFO - training batch 451, loss: 0.070, 14432/28000 datapoints
2025-03-06 21:04:03,698 - INFO - training batch 501, loss: 0.037, 16032/28000 datapoints
2025-03-06 21:04:03,818 - INFO - training batch 551, loss: 0.044, 17632/28000 datapoints
2025-03-06 21:04:03,939 - INFO - training batch 601, loss: 0.044, 19232/28000 datapoints
2025-03-06 21:04:04,059 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-06 21:04:04,179 - INFO - training batch 701, loss: 0.077, 22432/28000 datapoints
2025-03-06 21:04:04,298 - INFO - training batch 751, loss: 0.040, 24032/28000 datapoints
2025-03-06 21:04:04,419 - INFO - training batch 801, loss: 0.040, 25632/28000 datapoints
2025-03-06 21:04:04,543 - INFO - training batch 851, loss: 0.078, 27232/28000 datapoints
2025-03-06 21:04:04,603 - INFO - validation batch 1, loss: 0.529, 32/6976 datapoints
2025-03-06 21:04:04,649 - INFO - validation batch 51, loss: 2.154, 1632/6976 datapoints
2025-03-06 21:04:04,694 - INFO - validation batch 101, loss: 0.881, 3232/6976 datapoints
2025-03-06 21:04:04,738 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-06 21:04:04,786 - INFO - validation batch 201, loss: 0.603, 6432/6976 datapoints
2025-03-06 21:04:04,801 - INFO - Epoch 659/800 done.
2025-03-06 21:04:04,801 - INFO - Final validation performance:
Loss: 0.951, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:04:04,801 - INFO - Beginning epoch 660/800
2025-03-06 21:04:04,805 - INFO - training batch 1, loss: 0.117, 32/28000 datapoints
2025-03-06 21:04:04,933 - INFO - training batch 51, loss: 0.039, 1632/28000 datapoints
2025-03-06 21:04:05,057 - INFO - training batch 101, loss: 0.044, 3232/28000 datapoints
2025-03-06 21:04:05,178 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 21:04:05,300 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:04:05,422 - INFO - training batch 251, loss: 0.094, 8032/28000 datapoints
2025-03-06 21:04:05,543 - INFO - training batch 301, loss: 0.076, 9632/28000 datapoints
2025-03-06 21:04:05,664 - INFO - training batch 351, loss: 0.109, 11232/28000 datapoints
2025-03-06 21:04:05,785 - INFO - training batch 401, loss: 0.137, 12832/28000 datapoints
2025-03-06 21:04:05,907 - INFO - training batch 451, loss: 0.069, 14432/28000 datapoints
2025-03-06 21:04:06,031 - INFO - training batch 501, loss: 0.036, 16032/28000 datapoints
2025-03-06 21:04:06,152 - INFO - training batch 551, loss: 0.044, 17632/28000 datapoints
2025-03-06 21:04:06,272 - INFO - training batch 601, loss: 0.043, 19232/28000 datapoints
2025-03-06 21:04:06,393 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:06,516 - INFO - training batch 701, loss: 0.076, 22432/28000 datapoints
2025-03-06 21:04:06,635 - INFO - training batch 751, loss: 0.039, 24032/28000 datapoints
2025-03-06 21:04:06,762 - INFO - training batch 801, loss: 0.040, 25632/28000 datapoints
2025-03-06 21:04:06,881 - INFO - training batch 851, loss: 0.078, 27232/28000 datapoints
2025-03-06 21:04:06,943 - INFO - validation batch 1, loss: 0.531, 32/6976 datapoints
2025-03-06 21:04:06,987 - INFO - validation batch 51, loss: 2.160, 1632/6976 datapoints
2025-03-06 21:04:07,031 - INFO - validation batch 101, loss: 0.883, 3232/6976 datapoints
2025-03-06 21:04:07,074 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-06 21:04:07,117 - INFO - validation batch 201, loss: 0.606, 6432/6976 datapoints
2025-03-06 21:04:07,132 - INFO - Epoch 660/800 done.
2025-03-06 21:04:07,132 - INFO - Final validation performance:
Loss: 0.954, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:04:07,133 - INFO - Beginning epoch 661/800
2025-03-06 21:04:07,136 - INFO - training batch 1, loss: 0.117, 32/28000 datapoints
2025-03-06 21:04:07,258 - INFO - training batch 51, loss: 0.038, 1632/28000 datapoints
2025-03-06 21:04:07,379 - INFO - training batch 101, loss: 0.043, 3232/28000 datapoints
2025-03-06 21:04:07,502 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-06 21:04:07,622 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:04:07,750 - INFO - training batch 251, loss: 0.094, 8032/28000 datapoints
2025-03-06 21:04:07,876 - INFO - training batch 301, loss: 0.075, 9632/28000 datapoints
2025-03-06 21:04:08,000 - INFO - training batch 351, loss: 0.107, 11232/28000 datapoints
2025-03-06 21:04:08,121 - INFO - training batch 401, loss: 0.135, 12832/28000 datapoints
2025-03-06 21:04:08,241 - INFO - training batch 451, loss: 0.069, 14432/28000 datapoints
2025-03-06 21:04:08,361 - INFO - training batch 501, loss: 0.035, 16032/28000 datapoints
2025-03-06 21:04:08,485 - INFO - training batch 551, loss: 0.043, 17632/28000 datapoints
2025-03-06 21:04:08,614 - INFO - training batch 601, loss: 0.044, 19232/28000 datapoints
2025-03-06 21:04:08,738 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:08,867 - INFO - training batch 701, loss: 0.075, 22432/28000 datapoints
2025-03-06 21:04:09,021 - INFO - training batch 751, loss: 0.039, 24032/28000 datapoints
2025-03-06 21:04:09,145 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-06 21:04:09,271 - INFO - training batch 851, loss: 0.077, 27232/28000 datapoints
2025-03-06 21:04:09,331 - INFO - validation batch 1, loss: 0.537, 32/6976 datapoints
2025-03-06 21:04:09,375 - INFO - validation batch 51, loss: 2.166, 1632/6976 datapoints
2025-03-06 21:04:09,418 - INFO - validation batch 101, loss: 0.885, 3232/6976 datapoints
2025-03-06 21:04:09,463 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-06 21:04:09,512 - INFO - validation batch 201, loss: 0.609, 6432/6976 datapoints
2025-03-06 21:04:09,528 - INFO - Epoch 661/800 done.
2025-03-06 21:04:09,528 - INFO - Final validation performance:
Loss: 0.957, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:04:09,528 - INFO - Beginning epoch 662/800
2025-03-06 21:04:09,532 - INFO - training batch 1, loss: 0.115, 32/28000 datapoints
2025-03-06 21:04:09,657 - INFO - training batch 51, loss: 0.038, 1632/28000 datapoints
2025-03-06 21:04:09,777 - INFO - training batch 101, loss: 0.043, 3232/28000 datapoints
2025-03-06 21:04:09,913 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-06 21:04:10,041 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:04:10,162 - INFO - training batch 251, loss: 0.092, 8032/28000 datapoints
2025-03-06 21:04:10,282 - INFO - training batch 301, loss: 0.075, 9632/28000 datapoints
2025-03-06 21:04:10,405 - INFO - training batch 351, loss: 0.107, 11232/28000 datapoints
2025-03-06 21:04:10,528 - INFO - training batch 401, loss: 0.134, 12832/28000 datapoints
2025-03-06 21:04:10,652 - INFO - training batch 451, loss: 0.069, 14432/28000 datapoints
2025-03-06 21:04:10,776 - INFO - training batch 501, loss: 0.036, 16032/28000 datapoints
2025-03-06 21:04:10,896 - INFO - training batch 551, loss: 0.043, 17632/28000 datapoints
2025-03-06 21:04:11,019 - INFO - training batch 601, loss: 0.043, 19232/28000 datapoints
2025-03-06 21:04:11,140 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:11,261 - INFO - training batch 701, loss: 0.075, 22432/28000 datapoints
2025-03-06 21:04:11,382 - INFO - training batch 751, loss: 0.039, 24032/28000 datapoints
2025-03-06 21:04:11,505 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-06 21:04:11,631 - INFO - training batch 851, loss: 0.077, 27232/28000 datapoints
2025-03-06 21:04:11,696 - INFO - validation batch 1, loss: 0.543, 32/6976 datapoints
2025-03-06 21:04:11,743 - INFO - validation batch 51, loss: 2.172, 1632/6976 datapoints
2025-03-06 21:04:11,791 - INFO - validation batch 101, loss: 0.888, 3232/6976 datapoints
2025-03-06 21:04:11,838 - INFO - validation batch 151, loss: 0.588, 4832/6976 datapoints
2025-03-06 21:04:11,886 - INFO - validation batch 201, loss: 0.611, 6432/6976 datapoints
2025-03-06 21:04:11,902 - INFO - Epoch 662/800 done.
2025-03-06 21:04:11,902 - INFO - Final validation performance:
Loss: 0.960, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:04:11,902 - INFO - Beginning epoch 663/800
2025-03-06 21:04:11,906 - INFO - training batch 1, loss: 0.115, 32/28000 datapoints
2025-03-06 21:04:12,044 - INFO - training batch 51, loss: 0.038, 1632/28000 datapoints
2025-03-06 21:04:12,169 - INFO - training batch 101, loss: 0.043, 3232/28000 datapoints
2025-03-06 21:04:12,293 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-06 21:04:12,417 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:04:12,550 - INFO - training batch 251, loss: 0.092, 8032/28000 datapoints
2025-03-06 21:04:12,676 - INFO - training batch 301, loss: 0.075, 9632/28000 datapoints
2025-03-06 21:04:12,803 - INFO - training batch 351, loss: 0.106, 11232/28000 datapoints
2025-03-06 21:04:12,927 - INFO - training batch 401, loss: 0.134, 12832/28000 datapoints
2025-03-06 21:04:13,060 - INFO - training batch 451, loss: 0.067, 14432/28000 datapoints
2025-03-06 21:04:13,184 - INFO - training batch 501, loss: 0.035, 16032/28000 datapoints
2025-03-06 21:04:13,310 - INFO - training batch 551, loss: 0.043, 17632/28000 datapoints
2025-03-06 21:04:13,435 - INFO - training batch 601, loss: 0.043, 19232/28000 datapoints
2025-03-06 21:04:13,565 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:13,695 - INFO - training batch 701, loss: 0.074, 22432/28000 datapoints
2025-03-06 21:04:13,819 - INFO - training batch 751, loss: 0.038, 24032/28000 datapoints
2025-03-06 21:04:13,945 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-06 21:04:14,071 - INFO - training batch 851, loss: 0.076, 27232/28000 datapoints
2025-03-06 21:04:14,134 - INFO - validation batch 1, loss: 0.547, 32/6976 datapoints
2025-03-06 21:04:14,180 - INFO - validation batch 51, loss: 2.181, 1632/6976 datapoints
2025-03-06 21:04:14,226 - INFO - validation batch 101, loss: 0.889, 3232/6976 datapoints
2025-03-06 21:04:14,270 - INFO - validation batch 151, loss: 0.585, 4832/6976 datapoints
2025-03-06 21:04:14,314 - INFO - validation batch 201, loss: 0.612, 6432/6976 datapoints
2025-03-06 21:04:14,330 - INFO - Epoch 663/800 done.
2025-03-06 21:04:14,330 - INFO - Final validation performance:
Loss: 0.963, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:04:14,330 - INFO - Beginning epoch 664/800
2025-03-06 21:04:14,334 - INFO - training batch 1, loss: 0.113, 32/28000 datapoints
2025-03-06 21:04:14,458 - INFO - training batch 51, loss: 0.038, 1632/28000 datapoints
2025-03-06 21:04:14,583 - INFO - training batch 101, loss: 0.043, 3232/28000 datapoints
2025-03-06 21:04:14,708 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 21:04:14,834 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:04:14,960 - INFO - training batch 251, loss: 0.091, 8032/28000 datapoints
2025-03-06 21:04:15,083 - INFO - training batch 301, loss: 0.074, 9632/28000 datapoints
2025-03-06 21:04:15,204 - INFO - training batch 351, loss: 0.105, 11232/28000 datapoints
2025-03-06 21:04:15,324 - INFO - training batch 401, loss: 0.133, 12832/28000 datapoints
2025-03-06 21:04:15,445 - INFO - training batch 451, loss: 0.066, 14432/28000 datapoints
2025-03-06 21:04:15,567 - INFO - training batch 501, loss: 0.034, 16032/28000 datapoints
2025-03-06 21:04:15,691 - INFO - training batch 551, loss: 0.042, 17632/28000 datapoints
2025-03-06 21:04:15,813 - INFO - training batch 601, loss: 0.043, 19232/28000 datapoints
2025-03-06 21:04:15,933 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:16,057 - INFO - training batch 701, loss: 0.074, 22432/28000 datapoints
2025-03-06 21:04:16,177 - INFO - training batch 751, loss: 0.038, 24032/28000 datapoints
2025-03-06 21:04:16,300 - INFO - training batch 801, loss: 0.038, 25632/28000 datapoints
2025-03-06 21:04:16,421 - INFO - training batch 851, loss: 0.076, 27232/28000 datapoints
2025-03-06 21:04:16,482 - INFO - validation batch 1, loss: 0.551, 32/6976 datapoints
2025-03-06 21:04:16,528 - INFO - validation batch 51, loss: 2.181, 1632/6976 datapoints
2025-03-06 21:04:16,573 - INFO - validation batch 101, loss: 0.893, 3232/6976 datapoints
2025-03-06 21:04:16,616 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-06 21:04:16,664 - INFO - validation batch 201, loss: 0.616, 6432/6976 datapoints
2025-03-06 21:04:16,681 - INFO - Epoch 664/800 done.
2025-03-06 21:04:16,686 - INFO - Final validation performance:
Loss: 0.966, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:04:16,686 - INFO - Beginning epoch 665/800
2025-03-06 21:04:16,709 - INFO - training batch 1, loss: 0.113, 32/28000 datapoints
2025-03-06 21:04:16,859 - INFO - training batch 51, loss: 0.038, 1632/28000 datapoints
2025-03-06 21:04:16,982 - INFO - training batch 101, loss: 0.043, 3232/28000 datapoints
2025-03-06 21:04:17,109 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-06 21:04:17,229 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:04:17,349 - INFO - training batch 251, loss: 0.090, 8032/28000 datapoints
2025-03-06 21:04:17,468 - INFO - training batch 301, loss: 0.073, 9632/28000 datapoints
2025-03-06 21:04:17,591 - INFO - training batch 351, loss: 0.104, 11232/28000 datapoints
2025-03-06 21:04:17,715 - INFO - training batch 401, loss: 0.131, 12832/28000 datapoints
2025-03-06 21:04:17,836 - INFO - training batch 451, loss: 0.067, 14432/28000 datapoints
2025-03-06 21:04:17,958 - INFO - training batch 501, loss: 0.035, 16032/28000 datapoints
2025-03-06 21:04:18,082 - INFO - training batch 551, loss: 0.042, 17632/28000 datapoints
2025-03-06 21:04:18,202 - INFO - training batch 601, loss: 0.043, 19232/28000 datapoints
2025-03-06 21:04:18,323 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:18,444 - INFO - training batch 701, loss: 0.074, 22432/28000 datapoints
2025-03-06 21:04:18,566 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-06 21:04:18,690 - INFO - training batch 801, loss: 0.038, 25632/28000 datapoints
2025-03-06 21:04:18,814 - INFO - training batch 851, loss: 0.075, 27232/28000 datapoints
2025-03-06 21:04:18,874 - INFO - validation batch 1, loss: 0.557, 32/6976 datapoints
2025-03-06 21:04:18,917 - INFO - validation batch 51, loss: 2.192, 1632/6976 datapoints
2025-03-06 21:04:18,962 - INFO - validation batch 101, loss: 0.895, 3232/6976 datapoints
2025-03-06 21:04:19,024 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-06 21:04:19,081 - INFO - validation batch 201, loss: 0.617, 6432/6976 datapoints
2025-03-06 21:04:19,096 - INFO - Epoch 665/800 done.
2025-03-06 21:04:19,096 - INFO - Final validation performance:
Loss: 0.970, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:04:19,097 - INFO - Beginning epoch 666/800
2025-03-06 21:04:19,101 - INFO - training batch 1, loss: 0.112, 32/28000 datapoints
2025-03-06 21:04:19,237 - INFO - training batch 51, loss: 0.038, 1632/28000 datapoints
2025-03-06 21:04:19,368 - INFO - training batch 101, loss: 0.042, 3232/28000 datapoints
2025-03-06 21:04:19,491 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-06 21:04:19,618 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:04:19,743 - INFO - training batch 251, loss: 0.088, 8032/28000 datapoints
2025-03-06 21:04:19,864 - INFO - training batch 301, loss: 0.073, 9632/28000 datapoints
2025-03-06 21:04:19,984 - INFO - training batch 351, loss: 0.103, 11232/28000 datapoints
2025-03-06 21:04:20,108 - INFO - training batch 401, loss: 0.130, 12832/28000 datapoints
2025-03-06 21:04:20,230 - INFO - training batch 451, loss: 0.065, 14432/28000 datapoints
2025-03-06 21:04:20,352 - INFO - training batch 501, loss: 0.035, 16032/28000 datapoints
2025-03-06 21:04:20,473 - INFO - training batch 551, loss: 0.041, 17632/28000 datapoints
2025-03-06 21:04:20,594 - INFO - training batch 601, loss: 0.043, 19232/28000 datapoints
2025-03-06 21:04:20,718 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:20,845 - INFO - training batch 701, loss: 0.073, 22432/28000 datapoints
2025-03-06 21:04:20,966 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-06 21:04:21,089 - INFO - training batch 801, loss: 0.038, 25632/28000 datapoints
2025-03-06 21:04:21,212 - INFO - training batch 851, loss: 0.075, 27232/28000 datapoints
2025-03-06 21:04:21,271 - INFO - validation batch 1, loss: 0.561, 32/6976 datapoints
2025-03-06 21:04:21,315 - INFO - validation batch 51, loss: 2.194, 1632/6976 datapoints
2025-03-06 21:04:21,358 - INFO - validation batch 101, loss: 0.899, 3232/6976 datapoints
2025-03-06 21:04:21,402 - INFO - validation batch 151, loss: 0.588, 4832/6976 datapoints
2025-03-06 21:04:21,446 - INFO - validation batch 201, loss: 0.620, 6432/6976 datapoints
2025-03-06 21:04:21,461 - INFO - Epoch 666/800 done.
2025-03-06 21:04:21,462 - INFO - Final validation performance:
Loss: 0.972, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:04:21,462 - INFO - Beginning epoch 667/800
2025-03-06 21:04:21,465 - INFO - training batch 1, loss: 0.111, 32/28000 datapoints
2025-03-06 21:04:21,587 - INFO - training batch 51, loss: 0.037, 1632/28000 datapoints
2025-03-06 21:04:21,712 - INFO - training batch 101, loss: 0.042, 3232/28000 datapoints
2025-03-06 21:04:21,832 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-06 21:04:21,955 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:04:22,077 - INFO - training batch 251, loss: 0.088, 8032/28000 datapoints
2025-03-06 21:04:22,201 - INFO - training batch 301, loss: 0.072, 9632/28000 datapoints
2025-03-06 21:04:22,321 - INFO - training batch 351, loss: 0.102, 11232/28000 datapoints
2025-03-06 21:04:22,441 - INFO - training batch 401, loss: 0.130, 12832/28000 datapoints
2025-03-06 21:04:22,564 - INFO - training batch 451, loss: 0.067, 14432/28000 datapoints
2025-03-06 21:04:22,690 - INFO - training batch 501, loss: 0.035, 16032/28000 datapoints
2025-03-06 21:04:22,810 - INFO - training batch 551, loss: 0.042, 17632/28000 datapoints
2025-03-06 21:04:22,943 - INFO - training batch 601, loss: 0.043, 19232/28000 datapoints
2025-03-06 21:04:23,070 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:23,191 - INFO - training batch 701, loss: 0.072, 22432/28000 datapoints
2025-03-06 21:04:23,311 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-06 21:04:23,432 - INFO - training batch 801, loss: 0.038, 25632/28000 datapoints
2025-03-06 21:04:23,554 - INFO - training batch 851, loss: 0.074, 27232/28000 datapoints
2025-03-06 21:04:23,614 - INFO - validation batch 1, loss: 0.564, 32/6976 datapoints
2025-03-06 21:04:23,663 - INFO - validation batch 51, loss: 2.200, 1632/6976 datapoints
2025-03-06 21:04:23,707 - INFO - validation batch 101, loss: 0.901, 3232/6976 datapoints
2025-03-06 21:04:23,751 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-06 21:04:23,794 - INFO - validation batch 201, loss: 0.624, 6432/6976 datapoints
2025-03-06 21:04:23,810 - INFO - Epoch 667/800 done.
2025-03-06 21:04:23,811 - INFO - Final validation performance:
Loss: 0.975, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:04:23,811 - INFO - Beginning epoch 668/800
2025-03-06 21:04:23,814 - INFO - training batch 1, loss: 0.110, 32/28000 datapoints
2025-03-06 21:04:23,941 - INFO - training batch 51, loss: 0.037, 1632/28000 datapoints
2025-03-06 21:04:24,064 - INFO - training batch 101, loss: 0.042, 3232/28000 datapoints
2025-03-06 21:04:24,189 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 21:04:24,311 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:04:24,431 - INFO - training batch 251, loss: 0.087, 8032/28000 datapoints
2025-03-06 21:04:24,552 - INFO - training batch 301, loss: 0.072, 9632/28000 datapoints
2025-03-06 21:04:24,677 - INFO - training batch 351, loss: 0.101, 11232/28000 datapoints
2025-03-06 21:04:24,798 - INFO - training batch 401, loss: 0.128, 12832/28000 datapoints
2025-03-06 21:04:24,933 - INFO - training batch 451, loss: 0.064, 14432/28000 datapoints
2025-03-06 21:04:25,057 - INFO - training batch 501, loss: 0.033, 16032/28000 datapoints
2025-03-06 21:04:25,181 - INFO - training batch 551, loss: 0.041, 17632/28000 datapoints
2025-03-06 21:04:25,303 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-06 21:04:25,424 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:25,546 - INFO - training batch 701, loss: 0.073, 22432/28000 datapoints
2025-03-06 21:04:25,672 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-06 21:04:25,793 - INFO - training batch 801, loss: 0.038, 25632/28000 datapoints
2025-03-06 21:04:25,915 - INFO - training batch 851, loss: 0.073, 27232/28000 datapoints
2025-03-06 21:04:25,974 - INFO - validation batch 1, loss: 0.573, 32/6976 datapoints
2025-03-06 21:04:26,024 - INFO - validation batch 51, loss: 2.206, 1632/6976 datapoints
2025-03-06 21:04:26,069 - INFO - validation batch 101, loss: 0.904, 3232/6976 datapoints
2025-03-06 21:04:26,112 - INFO - validation batch 151, loss: 0.591, 4832/6976 datapoints
2025-03-06 21:04:26,157 - INFO - validation batch 201, loss: 0.626, 6432/6976 datapoints
2025-03-06 21:04:26,174 - INFO - Epoch 668/800 done.
2025-03-06 21:04:26,174 - INFO - Final validation performance:
Loss: 0.980, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:04:26,175 - INFO - Beginning epoch 669/800
2025-03-06 21:04:26,178 - INFO - training batch 1, loss: 0.109, 32/28000 datapoints
2025-03-06 21:04:26,300 - INFO - training batch 51, loss: 0.037, 1632/28000 datapoints
2025-03-06 21:04:26,423 - INFO - training batch 101, loss: 0.042, 3232/28000 datapoints
2025-03-06 21:04:26,545 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-06 21:04:26,671 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:04:26,794 - INFO - training batch 251, loss: 0.086, 8032/28000 datapoints
2025-03-06 21:04:26,919 - INFO - training batch 301, loss: 0.072, 9632/28000 datapoints
2025-03-06 21:04:27,039 - INFO - training batch 351, loss: 0.100, 11232/28000 datapoints
2025-03-06 21:04:27,160 - INFO - training batch 401, loss: 0.128, 12832/28000 datapoints
2025-03-06 21:04:27,282 - INFO - training batch 451, loss: 0.064, 14432/28000 datapoints
2025-03-06 21:04:27,401 - INFO - training batch 501, loss: 0.034, 16032/28000 datapoints
2025-03-06 21:04:27,524 - INFO - training batch 551, loss: 0.040, 17632/28000 datapoints
2025-03-06 21:04:27,649 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-06 21:04:27,775 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:27,896 - INFO - training batch 701, loss: 0.071, 22432/28000 datapoints
2025-03-06 21:04:28,017 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-06 21:04:28,138 - INFO - training batch 801, loss: 0.038, 25632/28000 datapoints
2025-03-06 21:04:28,261 - INFO - training batch 851, loss: 0.073, 27232/28000 datapoints
2025-03-06 21:04:28,320 - INFO - validation batch 1, loss: 0.577, 32/6976 datapoints
2025-03-06 21:04:28,364 - INFO - validation batch 51, loss: 2.211, 1632/6976 datapoints
2025-03-06 21:04:28,407 - INFO - validation batch 101, loss: 0.907, 3232/6976 datapoints
2025-03-06 21:04:28,451 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-06 21:04:28,495 - INFO - validation batch 201, loss: 0.630, 6432/6976 datapoints
2025-03-06 21:04:28,510 - INFO - Epoch 669/800 done.
2025-03-06 21:04:28,510 - INFO - Final validation performance:
Loss: 0.982, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:04:28,510 - INFO - Beginning epoch 670/800
2025-03-06 21:04:28,514 - INFO - training batch 1, loss: 0.108, 32/28000 datapoints
2025-03-06 21:04:28,641 - INFO - training batch 51, loss: 0.037, 1632/28000 datapoints
2025-03-06 21:04:28,766 - INFO - training batch 101, loss: 0.041, 3232/28000 datapoints
2025-03-06 21:04:28,891 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 21:04:29,011 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:04:29,159 - INFO - training batch 251, loss: 0.085, 8032/28000 datapoints
2025-03-06 21:04:29,284 - INFO - training batch 301, loss: 0.071, 9632/28000 datapoints
2025-03-06 21:04:29,403 - INFO - training batch 351, loss: 0.100, 11232/28000 datapoints
2025-03-06 21:04:29,534 - INFO - training batch 401, loss: 0.126, 12832/28000 datapoints
2025-03-06 21:04:29,664 - INFO - training batch 451, loss: 0.065, 14432/28000 datapoints
2025-03-06 21:04:29,785 - INFO - training batch 501, loss: 0.034, 16032/28000 datapoints
2025-03-06 21:04:29,908 - INFO - training batch 551, loss: 0.040, 17632/28000 datapoints
2025-03-06 21:04:30,030 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-06 21:04:30,154 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:30,298 - INFO - training batch 701, loss: 0.071, 22432/28000 datapoints
2025-03-06 21:04:30,418 - INFO - training batch 751, loss: 0.036, 24032/28000 datapoints
2025-03-06 21:04:30,540 - INFO - training batch 801, loss: 0.038, 25632/28000 datapoints
2025-03-06 21:04:30,665 - INFO - training batch 851, loss: 0.072, 27232/28000 datapoints
2025-03-06 21:04:30,727 - INFO - validation batch 1, loss: 0.580, 32/6976 datapoints
2025-03-06 21:04:30,771 - INFO - validation batch 51, loss: 2.220, 1632/6976 datapoints
2025-03-06 21:04:30,815 - INFO - validation batch 101, loss: 0.910, 3232/6976 datapoints
2025-03-06 21:04:30,862 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-06 21:04:30,906 - INFO - validation batch 201, loss: 0.629, 6432/6976 datapoints
2025-03-06 21:04:30,921 - INFO - Epoch 670/800 done.
2025-03-06 21:04:30,922 - INFO - Final validation performance:
Loss: 0.985, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:04:30,922 - INFO - Beginning epoch 671/800
2025-03-06 21:04:30,925 - INFO - training batch 1, loss: 0.107, 32/28000 datapoints
2025-03-06 21:04:31,049 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-06 21:04:31,170 - INFO - training batch 101, loss: 0.041, 3232/28000 datapoints
2025-03-06 21:04:31,295 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 21:04:31,414 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:04:31,536 - INFO - training batch 251, loss: 0.084, 8032/28000 datapoints
2025-03-06 21:04:31,664 - INFO - training batch 301, loss: 0.070, 9632/28000 datapoints
2025-03-06 21:04:31,789 - INFO - training batch 351, loss: 0.098, 11232/28000 datapoints
2025-03-06 21:04:31,913 - INFO - training batch 401, loss: 0.125, 12832/28000 datapoints
2025-03-06 21:04:32,037 - INFO - training batch 451, loss: 0.062, 14432/28000 datapoints
2025-03-06 21:04:32,167 - INFO - training batch 501, loss: 0.033, 16032/28000 datapoints
2025-03-06 21:04:32,295 - INFO - training batch 551, loss: 0.040, 17632/28000 datapoints
2025-03-06 21:04:32,421 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-06 21:04:32,547 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:32,674 - INFO - training batch 701, loss: 0.070, 22432/28000 datapoints
2025-03-06 21:04:32,800 - INFO - training batch 751, loss: 0.036, 24032/28000 datapoints
2025-03-06 21:04:32,943 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-06 21:04:33,078 - INFO - training batch 851, loss: 0.072, 27232/28000 datapoints
2025-03-06 21:04:33,147 - INFO - validation batch 1, loss: 0.586, 32/6976 datapoints
2025-03-06 21:04:33,195 - INFO - validation batch 51, loss: 2.227, 1632/6976 datapoints
2025-03-06 21:04:33,245 - INFO - validation batch 101, loss: 0.912, 3232/6976 datapoints
2025-03-06 21:04:33,296 - INFO - validation batch 151, loss: 0.589, 4832/6976 datapoints
2025-03-06 21:04:33,345 - INFO - validation batch 201, loss: 0.633, 6432/6976 datapoints
2025-03-06 21:04:33,360 - INFO - Epoch 671/800 done.
2025-03-06 21:04:33,361 - INFO - Final validation performance:
Loss: 0.989, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:04:33,361 - INFO - Beginning epoch 672/800
2025-03-06 21:04:33,365 - INFO - training batch 1, loss: 0.106, 32/28000 datapoints
2025-03-06 21:04:33,496 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-06 21:04:33,624 - INFO - training batch 101, loss: 0.041, 3232/28000 datapoints
2025-03-06 21:04:33,752 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 21:04:33,878 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:04:34,003 - INFO - training batch 251, loss: 0.083, 8032/28000 datapoints
2025-03-06 21:04:34,130 - INFO - training batch 301, loss: 0.070, 9632/28000 datapoints
2025-03-06 21:04:34,254 - INFO - training batch 351, loss: 0.098, 11232/28000 datapoints
2025-03-06 21:04:34,382 - INFO - training batch 401, loss: 0.124, 12832/28000 datapoints
2025-03-06 21:04:34,507 - INFO - training batch 451, loss: 0.062, 14432/28000 datapoints
2025-03-06 21:04:34,634 - INFO - training batch 501, loss: 0.033, 16032/28000 datapoints
2025-03-06 21:04:34,772 - INFO - training batch 551, loss: 0.039, 17632/28000 datapoints
2025-03-06 21:04:34,905 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-06 21:04:35,038 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:35,167 - INFO - training batch 701, loss: 0.070, 22432/28000 datapoints
2025-03-06 21:04:35,295 - INFO - training batch 751, loss: 0.036, 24032/28000 datapoints
2025-03-06 21:04:35,421 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-06 21:04:35,547 - INFO - training batch 851, loss: 0.071, 27232/28000 datapoints
2025-03-06 21:04:35,610 - INFO - validation batch 1, loss: 0.589, 32/6976 datapoints
2025-03-06 21:04:35,662 - INFO - validation batch 51, loss: 2.232, 1632/6976 datapoints
2025-03-06 21:04:35,709 - INFO - validation batch 101, loss: 0.915, 3232/6976 datapoints
2025-03-06 21:04:35,757 - INFO - validation batch 151, loss: 0.586, 4832/6976 datapoints
2025-03-06 21:04:35,807 - INFO - validation batch 201, loss: 0.634, 6432/6976 datapoints
2025-03-06 21:04:35,823 - INFO - Epoch 672/800 done.
2025-03-06 21:04:35,823 - INFO - Final validation performance:
Loss: 0.991, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:04:35,824 - INFO - Beginning epoch 673/800
2025-03-06 21:04:35,828 - INFO - training batch 1, loss: 0.105, 32/28000 datapoints
2025-03-06 21:04:35,954 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-06 21:04:36,077 - INFO - training batch 101, loss: 0.041, 3232/28000 datapoints
2025-03-06 21:04:36,201 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 21:04:36,327 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:04:36,447 - INFO - training batch 251, loss: 0.082, 8032/28000 datapoints
2025-03-06 21:04:36,567 - INFO - training batch 301, loss: 0.069, 9632/28000 datapoints
2025-03-06 21:04:36,688 - INFO - training batch 351, loss: 0.097, 11232/28000 datapoints
2025-03-06 21:04:36,813 - INFO - training batch 401, loss: 0.123, 12832/28000 datapoints
2025-03-06 21:04:36,938 - INFO - training batch 451, loss: 0.063, 14432/28000 datapoints
2025-03-06 21:04:37,059 - INFO - training batch 501, loss: 0.033, 16032/28000 datapoints
2025-03-06 21:04:37,180 - INFO - training batch 551, loss: 0.039, 17632/28000 datapoints
2025-03-06 21:04:37,300 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-06 21:04:37,422 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:37,541 - INFO - training batch 701, loss: 0.069, 22432/28000 datapoints
2025-03-06 21:04:37,680 - INFO - training batch 751, loss: 0.035, 24032/28000 datapoints
2025-03-06 21:04:37,801 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-06 21:04:37,924 - INFO - training batch 851, loss: 0.070, 27232/28000 datapoints
2025-03-06 21:04:37,984 - INFO - validation batch 1, loss: 0.595, 32/6976 datapoints
2025-03-06 21:04:38,028 - INFO - validation batch 51, loss: 2.235, 1632/6976 datapoints
2025-03-06 21:04:38,072 - INFO - validation batch 101, loss: 0.919, 3232/6976 datapoints
2025-03-06 21:04:38,116 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-06 21:04:38,160 - INFO - validation batch 201, loss: 0.641, 6432/6976 datapoints
2025-03-06 21:04:38,175 - INFO - Epoch 673/800 done.
2025-03-06 21:04:38,175 - INFO - Final validation performance:
Loss: 0.995, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:04:38,176 - INFO - Beginning epoch 674/800
2025-03-06 21:04:38,179 - INFO - training batch 1, loss: 0.104, 32/28000 datapoints
2025-03-06 21:04:38,299 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-06 21:04:38,422 - INFO - training batch 101, loss: 0.040, 3232/28000 datapoints
2025-03-06 21:04:38,544 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 21:04:38,668 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:04:38,789 - INFO - training batch 251, loss: 0.081, 8032/28000 datapoints
2025-03-06 21:04:38,925 - INFO - training batch 301, loss: 0.069, 9632/28000 datapoints
2025-03-06 21:04:39,052 - INFO - training batch 351, loss: 0.096, 11232/28000 datapoints
2025-03-06 21:04:39,186 - INFO - training batch 401, loss: 0.122, 12832/28000 datapoints
2025-03-06 21:04:39,343 - INFO - training batch 451, loss: 0.061, 14432/28000 datapoints
2025-03-06 21:04:39,467 - INFO - training batch 501, loss: 0.033, 16032/28000 datapoints
2025-03-06 21:04:39,597 - INFO - training batch 551, loss: 0.039, 17632/28000 datapoints
2025-03-06 21:04:39,722 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-06 21:04:39,849 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:39,973 - INFO - training batch 701, loss: 0.069, 22432/28000 datapoints
2025-03-06 21:04:40,106 - INFO - training batch 751, loss: 0.035, 24032/28000 datapoints
2025-03-06 21:04:40,232 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-06 21:04:40,357 - INFO - training batch 851, loss: 0.070, 27232/28000 datapoints
2025-03-06 21:04:40,416 - INFO - validation batch 1, loss: 0.600, 32/6976 datapoints
2025-03-06 21:04:40,461 - INFO - validation batch 51, loss: 2.240, 1632/6976 datapoints
2025-03-06 21:04:40,505 - INFO - validation batch 101, loss: 0.921, 3232/6976 datapoints
2025-03-06 21:04:40,551 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-06 21:04:40,595 - INFO - validation batch 201, loss: 0.643, 6432/6976 datapoints
2025-03-06 21:04:40,611 - INFO - Epoch 674/800 done.
2025-03-06 21:04:40,612 - INFO - Final validation performance:
Loss: 0.998, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:04:40,612 - INFO - Beginning epoch 675/800
2025-03-06 21:04:40,615 - INFO - training batch 1, loss: 0.103, 32/28000 datapoints
2025-03-06 21:04:40,742 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-06 21:04:40,866 - INFO - training batch 101, loss: 0.040, 3232/28000 datapoints
2025-03-06 21:04:40,990 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 21:04:41,113 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:04:41,234 - INFO - training batch 251, loss: 0.080, 8032/28000 datapoints
2025-03-06 21:04:41,358 - INFO - training batch 301, loss: 0.068, 9632/28000 datapoints
2025-03-06 21:04:41,480 - INFO - training batch 351, loss: 0.095, 11232/28000 datapoints
2025-03-06 21:04:41,601 - INFO - training batch 401, loss: 0.122, 12832/28000 datapoints
2025-03-06 21:04:41,727 - INFO - training batch 451, loss: 0.062, 14432/28000 datapoints
2025-03-06 21:04:41,848 - INFO - training batch 501, loss: 0.033, 16032/28000 datapoints
2025-03-06 21:04:41,971 - INFO - training batch 551, loss: 0.038, 17632/28000 datapoints
2025-03-06 21:04:42,092 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-06 21:04:42,214 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:42,335 - INFO - training batch 701, loss: 0.069, 22432/28000 datapoints
2025-03-06 21:04:42,458 - INFO - training batch 751, loss: 0.035, 24032/28000 datapoints
2025-03-06 21:04:42,579 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-06 21:04:42,718 - INFO - training batch 851, loss: 0.069, 27232/28000 datapoints
2025-03-06 21:04:42,777 - INFO - validation batch 1, loss: 0.607, 32/6976 datapoints
2025-03-06 21:04:42,822 - INFO - validation batch 51, loss: 2.248, 1632/6976 datapoints
2025-03-06 21:04:42,868 - INFO - validation batch 101, loss: 0.925, 3232/6976 datapoints
2025-03-06 21:04:42,918 - INFO - validation batch 151, loss: 0.587, 4832/6976 datapoints
2025-03-06 21:04:42,962 - INFO - validation batch 201, loss: 0.643, 6432/6976 datapoints
2025-03-06 21:04:42,978 - INFO - Epoch 675/800 done.
2025-03-06 21:04:42,978 - INFO - Final validation performance:
Loss: 1.002, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:04:42,978 - INFO - Beginning epoch 676/800
2025-03-06 21:04:42,982 - INFO - training batch 1, loss: 0.102, 32/28000 datapoints
2025-03-06 21:04:43,104 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-06 21:04:43,231 - INFO - training batch 101, loss: 0.040, 3232/28000 datapoints
2025-03-06 21:04:43,353 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-06 21:04:43,474 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:04:43,595 - INFO - training batch 251, loss: 0.079, 8032/28000 datapoints
2025-03-06 21:04:43,721 - INFO - training batch 301, loss: 0.068, 9632/28000 datapoints
2025-03-06 21:04:43,842 - INFO - training batch 351, loss: 0.095, 11232/28000 datapoints
2025-03-06 21:04:43,963 - INFO - training batch 401, loss: 0.120, 12832/28000 datapoints
2025-03-06 21:04:44,086 - INFO - training batch 451, loss: 0.061, 14432/28000 datapoints
2025-03-06 21:04:44,210 - INFO - training batch 501, loss: 0.032, 16032/28000 datapoints
2025-03-06 21:04:44,332 - INFO - training batch 551, loss: 0.038, 17632/28000 datapoints
2025-03-06 21:04:44,453 - INFO - training batch 601, loss: 0.040, 19232/28000 datapoints
2025-03-06 21:04:44,575 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-06 21:04:44,700 - INFO - training batch 701, loss: 0.068, 22432/28000 datapoints
2025-03-06 21:04:44,822 - INFO - training batch 751, loss: 0.034, 24032/28000 datapoints
2025-03-06 21:04:44,953 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-06 21:04:45,087 - INFO - training batch 851, loss: 0.068, 27232/28000 datapoints
2025-03-06 21:04:45,152 - INFO - validation batch 1, loss: 0.611, 32/6976 datapoints
2025-03-06 21:04:45,197 - INFO - validation batch 51, loss: 2.253, 1632/6976 datapoints
2025-03-06 21:04:45,241 - INFO - validation batch 101, loss: 0.927, 3232/6976 datapoints
2025-03-06 21:04:45,285 - INFO - validation batch 151, loss: 0.589, 4832/6976 datapoints
2025-03-06 21:04:45,329 - INFO - validation batch 201, loss: 0.647, 6432/6976 datapoints
2025-03-06 21:04:45,344 - INFO - Epoch 676/800 done.
2025-03-06 21:04:45,344 - INFO - Final validation performance:
Loss: 1.005, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:04:45,345 - INFO - Beginning epoch 677/800
2025-03-06 21:04:45,348 - INFO - training batch 1, loss: 0.101, 32/28000 datapoints
2025-03-06 21:04:45,478 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-06 21:04:45,598 - INFO - training batch 101, loss: 0.040, 3232/28000 datapoints
2025-03-06 21:04:45,724 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 21:04:45,848 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:04:45,972 - INFO - training batch 251, loss: 0.078, 8032/28000 datapoints
2025-03-06 21:04:46,094 - INFO - training batch 301, loss: 0.067, 9632/28000 datapoints
2025-03-06 21:04:46,215 - INFO - training batch 351, loss: 0.093, 11232/28000 datapoints
2025-03-06 21:04:46,336 - INFO - training batch 401, loss: 0.120, 12832/28000 datapoints
2025-03-06 21:04:46,459 - INFO - training batch 451, loss: 0.060, 14432/28000 datapoints
2025-03-06 21:04:46,580 - INFO - training batch 501, loss: 0.031, 16032/28000 datapoints
2025-03-06 21:04:46,704 - INFO - training batch 551, loss: 0.037, 17632/28000 datapoints
2025-03-06 21:04:46,824 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-06 21:04:46,951 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:04:47,073 - INFO - training batch 701, loss: 0.068, 22432/28000 datapoints
2025-03-06 21:04:47,194 - INFO - training batch 751, loss: 0.034, 24032/28000 datapoints
2025-03-06 21:04:47,318 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-06 21:04:47,440 - INFO - training batch 851, loss: 0.068, 27232/28000 datapoints
2025-03-06 21:04:47,500 - INFO - validation batch 1, loss: 0.617, 32/6976 datapoints
2025-03-06 21:04:47,544 - INFO - validation batch 51, loss: 2.260, 1632/6976 datapoints
2025-03-06 21:04:47,588 - INFO - validation batch 101, loss: 0.931, 3232/6976 datapoints
2025-03-06 21:04:47,632 - INFO - validation batch 151, loss: 0.590, 4832/6976 datapoints
2025-03-06 21:04:47,684 - INFO - validation batch 201, loss: 0.649, 6432/6976 datapoints
2025-03-06 21:04:47,703 - INFO - Epoch 677/800 done.
2025-03-06 21:04:47,707 - INFO - Final validation performance:
Loss: 1.009, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:04:47,708 - INFO - Beginning epoch 678/800
2025-03-06 21:04:47,712 - INFO - training batch 1, loss: 0.101, 32/28000 datapoints
2025-03-06 21:04:47,850 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-06 21:04:47,976 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-06 21:04:48,099 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-06 21:04:48,220 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:04:48,342 - INFO - training batch 251, loss: 0.078, 8032/28000 datapoints
2025-03-06 21:04:48,465 - INFO - training batch 301, loss: 0.067, 9632/28000 datapoints
2025-03-06 21:04:48,584 - INFO - training batch 351, loss: 0.093, 11232/28000 datapoints
2025-03-06 21:04:48,711 - INFO - training batch 401, loss: 0.119, 12832/28000 datapoints
2025-03-06 21:04:48,833 - INFO - training batch 451, loss: 0.059, 14432/28000 datapoints
2025-03-06 21:04:48,959 - INFO - training batch 501, loss: 0.031, 16032/28000 datapoints
2025-03-06 21:04:49,082 - INFO - training batch 551, loss: 0.037, 17632/28000 datapoints
2025-03-06 21:04:49,203 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-06 21:04:49,348 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:04:49,477 - INFO - training batch 701, loss: 0.067, 22432/28000 datapoints
2025-03-06 21:04:49,598 - INFO - training batch 751, loss: 0.034, 24032/28000 datapoints
2025-03-06 21:04:49,723 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-06 21:04:49,844 - INFO - training batch 851, loss: 0.067, 27232/28000 datapoints
2025-03-06 21:04:49,903 - INFO - validation batch 1, loss: 0.620, 32/6976 datapoints
2025-03-06 21:04:49,948 - INFO - validation batch 51, loss: 2.265, 1632/6976 datapoints
2025-03-06 21:04:49,994 - INFO - validation batch 101, loss: 0.934, 3232/6976 datapoints
2025-03-06 21:04:50,040 - INFO - validation batch 151, loss: 0.588, 4832/6976 datapoints
2025-03-06 21:04:50,085 - INFO - validation batch 201, loss: 0.651, 6432/6976 datapoints
2025-03-06 21:04:50,100 - INFO - Epoch 678/800 done.
2025-03-06 21:04:50,100 - INFO - Final validation performance:
Loss: 1.012, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:04:50,101 - INFO - Beginning epoch 679/800
2025-03-06 21:04:50,104 - INFO - training batch 1, loss: 0.099, 32/28000 datapoints
2025-03-06 21:04:50,227 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-06 21:04:50,351 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-06 21:04:50,475 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-06 21:04:50,597 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:04:50,720 - INFO - training batch 251, loss: 0.077, 8032/28000 datapoints
2025-03-06 21:04:50,841 - INFO - training batch 301, loss: 0.066, 9632/28000 datapoints
2025-03-06 21:04:50,965 - INFO - training batch 351, loss: 0.092, 11232/28000 datapoints
2025-03-06 21:04:51,085 - INFO - training batch 401, loss: 0.117, 12832/28000 datapoints
2025-03-06 21:04:51,224 - INFO - training batch 451, loss: 0.059, 14432/28000 datapoints
2025-03-06 21:04:51,346 - INFO - training batch 501, loss: 0.031, 16032/28000 datapoints
2025-03-06 21:04:51,468 - INFO - training batch 551, loss: 0.037, 17632/28000 datapoints
2025-03-06 21:04:51,596 - INFO - training batch 601, loss: 0.040, 19232/28000 datapoints
2025-03-06 21:04:51,732 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:04:51,859 - INFO - training batch 701, loss: 0.066, 22432/28000 datapoints
2025-03-06 21:04:51,983 - INFO - training batch 751, loss: 0.033, 24032/28000 datapoints
2025-03-06 21:04:52,116 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-06 21:04:52,242 - INFO - training batch 851, loss: 0.066, 27232/28000 datapoints
2025-03-06 21:04:52,305 - INFO - validation batch 1, loss: 0.625, 32/6976 datapoints
2025-03-06 21:04:52,353 - INFO - validation batch 51, loss: 2.271, 1632/6976 datapoints
2025-03-06 21:04:52,402 - INFO - validation batch 101, loss: 0.936, 3232/6976 datapoints
2025-03-06 21:04:52,449 - INFO - validation batch 151, loss: 0.590, 4832/6976 datapoints
2025-03-06 21:04:52,499 - INFO - validation batch 201, loss: 0.653, 6432/6976 datapoints
2025-03-06 21:04:52,515 - INFO - Epoch 679/800 done.
2025-03-06 21:04:52,515 - INFO - Final validation performance:
Loss: 1.015, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:04:52,515 - INFO - Beginning epoch 680/800
2025-03-06 21:04:52,519 - INFO - training batch 1, loss: 0.099, 32/28000 datapoints
2025-03-06 21:04:52,651 - INFO - training batch 51, loss: 0.034, 1632/28000 datapoints
2025-03-06 21:04:52,778 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-06 21:04:52,904 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-06 21:04:53,036 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:04:53,164 - INFO - training batch 251, loss: 0.076, 8032/28000 datapoints
2025-03-06 21:04:53,297 - INFO - training batch 301, loss: 0.065, 9632/28000 datapoints
2025-03-06 21:04:53,422 - INFO - training batch 351, loss: 0.091, 11232/28000 datapoints
2025-03-06 21:04:53,550 - INFO - training batch 401, loss: 0.116, 12832/28000 datapoints
2025-03-06 21:04:53,680 - INFO - training batch 451, loss: 0.059, 14432/28000 datapoints
2025-03-06 21:04:53,805 - INFO - training batch 501, loss: 0.031, 16032/28000 datapoints
2025-03-06 21:04:53,929 - INFO - training batch 551, loss: 0.037, 17632/28000 datapoints
2025-03-06 21:04:54,057 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-06 21:04:54,181 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:04:54,314 - INFO - training batch 701, loss: 0.066, 22432/28000 datapoints
2025-03-06 21:04:54,439 - INFO - training batch 751, loss: 0.033, 24032/28000 datapoints
2025-03-06 21:04:54,567 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-06 21:04:54,696 - INFO - training batch 851, loss: 0.066, 27232/28000 datapoints
2025-03-06 21:04:54,760 - INFO - validation batch 1, loss: 0.629, 32/6976 datapoints
2025-03-06 21:04:54,808 - INFO - validation batch 51, loss: 2.276, 1632/6976 datapoints
2025-03-06 21:04:54,859 - INFO - validation batch 101, loss: 0.941, 3232/6976 datapoints
2025-03-06 21:04:54,914 - INFO - validation batch 151, loss: 0.591, 4832/6976 datapoints
2025-03-06 21:04:54,966 - INFO - validation batch 201, loss: 0.655, 6432/6976 datapoints
2025-03-06 21:04:54,984 - INFO - Epoch 680/800 done.
2025-03-06 21:04:54,984 - INFO - Final validation performance:
Loss: 1.019, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:04:54,985 - INFO - Beginning epoch 681/800
2025-03-06 21:04:54,989 - INFO - training batch 1, loss: 0.097, 32/28000 datapoints
2025-03-06 21:04:55,117 - INFO - training batch 51, loss: 0.034, 1632/28000 datapoints
2025-03-06 21:04:55,240 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-06 21:04:55,398 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-06 21:04:55,539 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:04:55,664 - INFO - training batch 251, loss: 0.075, 8032/28000 datapoints
2025-03-06 21:04:55,788 - INFO - training batch 301, loss: 0.064, 9632/28000 datapoints
2025-03-06 21:04:55,907 - INFO - training batch 351, loss: 0.090, 11232/28000 datapoints
2025-03-06 21:04:56,028 - INFO - training batch 401, loss: 0.115, 12832/28000 datapoints
2025-03-06 21:04:56,152 - INFO - training batch 451, loss: 0.058, 14432/28000 datapoints
2025-03-06 21:04:56,274 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-06 21:04:56,415 - INFO - training batch 551, loss: 0.036, 17632/28000 datapoints
2025-03-06 21:04:56,537 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-06 21:04:56,663 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:04:56,786 - INFO - training batch 701, loss: 0.065, 22432/28000 datapoints
2025-03-06 21:04:56,907 - INFO - training batch 751, loss: 0.032, 24032/28000 datapoints
2025-03-06 21:04:57,044 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-06 21:04:57,166 - INFO - training batch 851, loss: 0.065, 27232/28000 datapoints
2025-03-06 21:04:57,227 - INFO - validation batch 1, loss: 0.635, 32/6976 datapoints
2025-03-06 21:04:57,279 - INFO - validation batch 51, loss: 2.286, 1632/6976 datapoints
2025-03-06 21:04:57,330 - INFO - validation batch 101, loss: 0.942, 3232/6976 datapoints
2025-03-06 21:04:57,376 - INFO - validation batch 151, loss: 0.590, 4832/6976 datapoints
2025-03-06 21:04:57,421 - INFO - validation batch 201, loss: 0.658, 6432/6976 datapoints
2025-03-06 21:04:57,436 - INFO - Epoch 681/800 done.
2025-03-06 21:04:57,436 - INFO - Final validation performance:
Loss: 1.022, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:04:57,436 - INFO - Beginning epoch 682/800
2025-03-06 21:04:57,440 - INFO - training batch 1, loss: 0.097, 32/28000 datapoints
2025-03-06 21:04:57,573 - INFO - training batch 51, loss: 0.034, 1632/28000 datapoints
2025-03-06 21:04:57,701 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-06 21:04:57,824 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-06 21:04:57,945 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:04:58,069 - INFO - training batch 251, loss: 0.074, 8032/28000 datapoints
2025-03-06 21:04:58,191 - INFO - training batch 301, loss: 0.064, 9632/28000 datapoints
2025-03-06 21:04:58,313 - INFO - training batch 351, loss: 0.089, 11232/28000 datapoints
2025-03-06 21:04:58,435 - INFO - training batch 401, loss: 0.114, 12832/28000 datapoints
2025-03-06 21:04:58,562 - INFO - training batch 451, loss: 0.058, 14432/28000 datapoints
2025-03-06 21:04:58,688 - INFO - training batch 501, loss: 0.031, 16032/28000 datapoints
2025-03-06 21:04:58,811 - INFO - training batch 551, loss: 0.036, 17632/28000 datapoints
2025-03-06 21:04:58,931 - INFO - training batch 601, loss: 0.040, 19232/28000 datapoints
2025-03-06 21:04:59,058 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:04:59,181 - INFO - training batch 701, loss: 0.065, 22432/28000 datapoints
2025-03-06 21:04:59,304 - INFO - training batch 751, loss: 0.032, 24032/28000 datapoints
2025-03-06 21:04:59,450 - INFO - training batch 801, loss: 0.035, 25632/28000 datapoints
2025-03-06 21:04:59,575 - INFO - training batch 851, loss: 0.064, 27232/28000 datapoints
2025-03-06 21:04:59,637 - INFO - validation batch 1, loss: 0.640, 32/6976 datapoints
2025-03-06 21:04:59,683 - INFO - validation batch 51, loss: 2.292, 1632/6976 datapoints
2025-03-06 21:04:59,730 - INFO - validation batch 101, loss: 0.946, 3232/6976 datapoints
2025-03-06 21:04:59,774 - INFO - validation batch 151, loss: 0.592, 4832/6976 datapoints
2025-03-06 21:04:59,818 - INFO - validation batch 201, loss: 0.658, 6432/6976 datapoints
2025-03-06 21:04:59,833 - INFO - Epoch 682/800 done.
2025-03-06 21:04:59,833 - INFO - Final validation performance:
Loss: 1.026, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:04:59,833 - INFO - Beginning epoch 683/800
2025-03-06 21:04:59,837 - INFO - training batch 1, loss: 0.096, 32/28000 datapoints
2025-03-06 21:04:59,959 - INFO - training batch 51, loss: 0.033, 1632/28000 datapoints
2025-03-06 21:05:00,084 - INFO - training batch 101, loss: 0.038, 3232/28000 datapoints
2025-03-06 21:05:00,207 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-06 21:05:00,330 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:05:00,450 - INFO - training batch 251, loss: 0.073, 8032/28000 datapoints
2025-03-06 21:05:00,573 - INFO - training batch 301, loss: 0.064, 9632/28000 datapoints
2025-03-06 21:05:00,698 - INFO - training batch 351, loss: 0.088, 11232/28000 datapoints
2025-03-06 21:05:00,819 - INFO - training batch 401, loss: 0.114, 12832/28000 datapoints
2025-03-06 21:05:00,941 - INFO - training batch 451, loss: 0.057, 14432/28000 datapoints
2025-03-06 21:05:01,066 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-06 21:05:01,188 - INFO - training batch 551, loss: 0.036, 17632/28000 datapoints
2025-03-06 21:05:01,311 - INFO - training batch 601, loss: 0.040, 19232/28000 datapoints
2025-03-06 21:05:01,432 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:05:01,555 - INFO - training batch 701, loss: 0.064, 22432/28000 datapoints
2025-03-06 21:05:01,680 - INFO - training batch 751, loss: 0.032, 24032/28000 datapoints
2025-03-06 21:05:01,803 - INFO - training batch 801, loss: 0.035, 25632/28000 datapoints
2025-03-06 21:05:01,931 - INFO - training batch 851, loss: 0.064, 27232/28000 datapoints
2025-03-06 21:05:01,991 - INFO - validation batch 1, loss: 0.644, 32/6976 datapoints
2025-03-06 21:05:02,036 - INFO - validation batch 51, loss: 2.294, 1632/6976 datapoints
2025-03-06 21:05:02,080 - INFO - validation batch 101, loss: 0.950, 3232/6976 datapoints
2025-03-06 21:05:02,126 - INFO - validation batch 151, loss: 0.592, 4832/6976 datapoints
2025-03-06 21:05:02,168 - INFO - validation batch 201, loss: 0.662, 6432/6976 datapoints
2025-03-06 21:05:02,183 - INFO - Epoch 683/800 done.
2025-03-06 21:05:02,183 - INFO - Final validation performance:
Loss: 1.028, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:05:02,184 - INFO - Beginning epoch 684/800
2025-03-06 21:05:02,187 - INFO - training batch 1, loss: 0.095, 32/28000 datapoints
2025-03-06 21:05:02,310 - INFO - training batch 51, loss: 0.033, 1632/28000 datapoints
2025-03-06 21:05:02,432 - INFO - training batch 101, loss: 0.038, 3232/28000 datapoints
2025-03-06 21:05:02,554 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-06 21:05:02,679 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:05:02,801 - INFO - training batch 251, loss: 0.073, 8032/28000 datapoints
2025-03-06 21:05:02,921 - INFO - training batch 301, loss: 0.063, 9632/28000 datapoints
2025-03-06 21:05:03,049 - INFO - training batch 351, loss: 0.087, 11232/28000 datapoints
2025-03-06 21:05:03,172 - INFO - training batch 401, loss: 0.112, 12832/28000 datapoints
2025-03-06 21:05:03,308 - INFO - training batch 451, loss: 0.056, 14432/28000 datapoints
2025-03-06 21:05:03,436 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-06 21:05:03,558 - INFO - training batch 551, loss: 0.035, 17632/28000 datapoints
2025-03-06 21:05:03,683 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-06 21:05:03,807 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:05:03,936 - INFO - training batch 701, loss: 0.064, 22432/28000 datapoints
2025-03-06 21:05:04,060 - INFO - training batch 751, loss: 0.032, 24032/28000 datapoints
2025-03-06 21:05:04,184 - INFO - training batch 801, loss: 0.035, 25632/28000 datapoints
2025-03-06 21:05:04,311 - INFO - training batch 851, loss: 0.063, 27232/28000 datapoints
2025-03-06 21:05:04,371 - INFO - validation batch 1, loss: 0.648, 32/6976 datapoints
2025-03-06 21:05:04,414 - INFO - validation batch 51, loss: 2.304, 1632/6976 datapoints
2025-03-06 21:05:04,458 - INFO - validation batch 101, loss: 0.952, 3232/6976 datapoints
2025-03-06 21:05:04,502 - INFO - validation batch 151, loss: 0.594, 4832/6976 datapoints
2025-03-06 21:05:04,545 - INFO - validation batch 201, loss: 0.665, 6432/6976 datapoints
2025-03-06 21:05:04,561 - INFO - Epoch 684/800 done.
2025-03-06 21:05:04,561 - INFO - Final validation performance:
Loss: 1.032, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:05:04,561 - INFO - Beginning epoch 685/800
2025-03-06 21:05:04,565 - INFO - training batch 1, loss: 0.094, 32/28000 datapoints
2025-03-06 21:05:04,695 - INFO - training batch 51, loss: 0.033, 1632/28000 datapoints
2025-03-06 21:05:04,819 - INFO - training batch 101, loss: 0.038, 3232/28000 datapoints
2025-03-06 21:05:04,944 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-06 21:05:05,068 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:05:05,192 - INFO - training batch 251, loss: 0.072, 8032/28000 datapoints
2025-03-06 21:05:05,315 - INFO - training batch 301, loss: 0.063, 9632/28000 datapoints
2025-03-06 21:05:05,436 - INFO - training batch 351, loss: 0.086, 11232/28000 datapoints
2025-03-06 21:05:05,557 - INFO - training batch 401, loss: 0.112, 12832/28000 datapoints
2025-03-06 21:05:05,684 - INFO - training batch 451, loss: 0.056, 14432/28000 datapoints
2025-03-06 21:05:05,805 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-06 21:05:05,926 - INFO - training batch 551, loss: 0.035, 17632/28000 datapoints
2025-03-06 21:05:06,045 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-06 21:05:06,171 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:05:06,293 - INFO - training batch 701, loss: 0.063, 22432/28000 datapoints
2025-03-06 21:05:06,414 - INFO - training batch 751, loss: 0.031, 24032/28000 datapoints
2025-03-06 21:05:06,536 - INFO - training batch 801, loss: 0.035, 25632/28000 datapoints
2025-03-06 21:05:06,659 - INFO - training batch 851, loss: 0.062, 27232/28000 datapoints
2025-03-06 21:05:06,721 - INFO - validation batch 1, loss: 0.654, 32/6976 datapoints
2025-03-06 21:05:06,766 - INFO - validation batch 51, loss: 2.310, 1632/6976 datapoints
2025-03-06 21:05:06,809 - INFO - validation batch 101, loss: 0.955, 3232/6976 datapoints
2025-03-06 21:05:06,854 - INFO - validation batch 151, loss: 0.593, 4832/6976 datapoints
2025-03-06 21:05:06,901 - INFO - validation batch 201, loss: 0.667, 6432/6976 datapoints
2025-03-06 21:05:06,916 - INFO - Epoch 685/800 done.
2025-03-06 21:05:06,916 - INFO - Final validation performance:
Loss: 1.036, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:06,916 - INFO - Beginning epoch 686/800
2025-03-06 21:05:06,920 - INFO - training batch 1, loss: 0.093, 32/28000 datapoints
2025-03-06 21:05:07,046 - INFO - training batch 51, loss: 0.033, 1632/28000 datapoints
2025-03-06 21:05:07,168 - INFO - training batch 101, loss: 0.038, 3232/28000 datapoints
2025-03-06 21:05:07,292 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-06 21:05:07,413 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:05:07,534 - INFO - training batch 251, loss: 0.071, 8032/28000 datapoints
2025-03-06 21:05:07,659 - INFO - training batch 301, loss: 0.062, 9632/28000 datapoints
2025-03-06 21:05:07,787 - INFO - training batch 351, loss: 0.085, 11232/28000 datapoints
2025-03-06 21:05:07,908 - INFO - training batch 401, loss: 0.110, 12832/28000 datapoints
2025-03-06 21:05:08,031 - INFO - training batch 451, loss: 0.056, 14432/28000 datapoints
2025-03-06 21:05:08,152 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-06 21:05:08,274 - INFO - training batch 551, loss: 0.035, 17632/28000 datapoints
2025-03-06 21:05:08,396 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-06 21:05:08,519 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:05:08,643 - INFO - training batch 701, loss: 0.063, 22432/28000 datapoints
2025-03-06 21:05:08,767 - INFO - training batch 751, loss: 0.031, 24032/28000 datapoints
2025-03-06 21:05:08,887 - INFO - training batch 801, loss: 0.034, 25632/28000 datapoints
2025-03-06 21:05:09,014 - INFO - training batch 851, loss: 0.062, 27232/28000 datapoints
2025-03-06 21:05:09,081 - INFO - validation batch 1, loss: 0.658, 32/6976 datapoints
2025-03-06 21:05:09,125 - INFO - validation batch 51, loss: 2.315, 1632/6976 datapoints
2025-03-06 21:05:09,168 - INFO - validation batch 101, loss: 0.959, 3232/6976 datapoints
2025-03-06 21:05:09,214 - INFO - validation batch 151, loss: 0.596, 4832/6976 datapoints
2025-03-06 21:05:09,258 - INFO - validation batch 201, loss: 0.669, 6432/6976 datapoints
2025-03-06 21:05:09,273 - INFO - Epoch 686/800 done.
2025-03-06 21:05:09,273 - INFO - Final validation performance:
Loss: 1.040, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:09,274 - INFO - Beginning epoch 687/800
2025-03-06 21:05:09,277 - INFO - training batch 1, loss: 0.092, 32/28000 datapoints
2025-03-06 21:05:09,397 - INFO - training batch 51, loss: 0.033, 1632/28000 datapoints
2025-03-06 21:05:09,555 - INFO - training batch 101, loss: 0.037, 3232/28000 datapoints
2025-03-06 21:05:09,684 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-06 21:05:09,810 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:05:09,938 - INFO - training batch 251, loss: 0.070, 8032/28000 datapoints
2025-03-06 21:05:10,062 - INFO - training batch 301, loss: 0.062, 9632/28000 datapoints
2025-03-06 21:05:10,194 - INFO - training batch 351, loss: 0.085, 11232/28000 datapoints
2025-03-06 21:05:10,318 - INFO - training batch 401, loss: 0.110, 12832/28000 datapoints
2025-03-06 21:05:10,445 - INFO - training batch 451, loss: 0.055, 14432/28000 datapoints
2025-03-06 21:05:10,567 - INFO - training batch 501, loss: 0.029, 16032/28000 datapoints
2025-03-06 21:05:10,694 - INFO - training batch 551, loss: 0.034, 17632/28000 datapoints
2025-03-06 21:05:10,818 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-06 21:05:10,942 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:05:11,066 - INFO - training batch 701, loss: 0.062, 22432/28000 datapoints
2025-03-06 21:05:11,192 - INFO - training batch 751, loss: 0.031, 24032/28000 datapoints
2025-03-06 21:05:11,317 - INFO - training batch 801, loss: 0.034, 25632/28000 datapoints
2025-03-06 21:05:11,438 - INFO - training batch 851, loss: 0.061, 27232/28000 datapoints
2025-03-06 21:05:11,498 - INFO - validation batch 1, loss: 0.660, 32/6976 datapoints
2025-03-06 21:05:11,543 - INFO - validation batch 51, loss: 2.320, 1632/6976 datapoints
2025-03-06 21:05:11,586 - INFO - validation batch 101, loss: 0.963, 3232/6976 datapoints
2025-03-06 21:05:11,630 - INFO - validation batch 151, loss: 0.597, 4832/6976 datapoints
2025-03-06 21:05:11,678 - INFO - validation batch 201, loss: 0.670, 6432/6976 datapoints
2025-03-06 21:05:11,693 - INFO - Epoch 687/800 done.
2025-03-06 21:05:11,693 - INFO - Final validation performance:
Loss: 1.042, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:11,694 - INFO - Beginning epoch 688/800
2025-03-06 21:05:11,697 - INFO - training batch 1, loss: 0.091, 32/28000 datapoints
2025-03-06 21:05:11,824 - INFO - training batch 51, loss: 0.032, 1632/28000 datapoints
2025-03-06 21:05:11,952 - INFO - training batch 101, loss: 0.037, 3232/28000 datapoints
2025-03-06 21:05:12,078 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-06 21:05:12,201 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:05:12,327 - INFO - training batch 251, loss: 0.069, 8032/28000 datapoints
2025-03-06 21:05:12,453 - INFO - training batch 301, loss: 0.061, 9632/28000 datapoints
2025-03-06 21:05:12,579 - INFO - training batch 351, loss: 0.084, 11232/28000 datapoints
2025-03-06 21:05:12,704 - INFO - training batch 401, loss: 0.109, 12832/28000 datapoints
2025-03-06 21:05:12,835 - INFO - training batch 451, loss: 0.055, 14432/28000 datapoints
2025-03-06 21:05:12,961 - INFO - training batch 501, loss: 0.029, 16032/28000 datapoints
2025-03-06 21:05:13,090 - INFO - training batch 551, loss: 0.034, 17632/28000 datapoints
2025-03-06 21:05:13,213 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-06 21:05:13,343 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:05:13,469 - INFO - training batch 701, loss: 0.062, 22432/28000 datapoints
2025-03-06 21:05:13,593 - INFO - training batch 751, loss: 0.030, 24032/28000 datapoints
2025-03-06 21:05:13,721 - INFO - training batch 801, loss: 0.034, 25632/28000 datapoints
2025-03-06 21:05:13,850 - INFO - training batch 851, loss: 0.060, 27232/28000 datapoints
2025-03-06 21:05:13,912 - INFO - validation batch 1, loss: 0.666, 32/6976 datapoints
2025-03-06 21:05:13,959 - INFO - validation batch 51, loss: 2.328, 1632/6976 datapoints
2025-03-06 21:05:14,009 - INFO - validation batch 101, loss: 0.967, 3232/6976 datapoints
2025-03-06 21:05:14,057 - INFO - validation batch 151, loss: 0.594, 4832/6976 datapoints
2025-03-06 21:05:14,105 - INFO - validation batch 201, loss: 0.675, 6432/6976 datapoints
2025-03-06 21:05:14,119 - INFO - Epoch 688/800 done.
2025-03-06 21:05:14,119 - INFO - Final validation performance:
Loss: 1.046, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:14,120 - INFO - Beginning epoch 689/800
2025-03-06 21:05:14,124 - INFO - training batch 1, loss: 0.090, 32/28000 datapoints
2025-03-06 21:05:14,251 - INFO - training batch 51, loss: 0.032, 1632/28000 datapoints
2025-03-06 21:05:14,381 - INFO - training batch 101, loss: 0.037, 3232/28000 datapoints
2025-03-06 21:05:14,507 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-06 21:05:14,630 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:05:14,757 - INFO - training batch 251, loss: 0.068, 8032/28000 datapoints
2025-03-06 21:05:14,883 - INFO - training batch 301, loss: 0.060, 9632/28000 datapoints
2025-03-06 21:05:15,011 - INFO - training batch 351, loss: 0.083, 11232/28000 datapoints
2025-03-06 21:05:15,140 - INFO - training batch 401, loss: 0.107, 12832/28000 datapoints
2025-03-06 21:05:15,267 - INFO - training batch 451, loss: 0.054, 14432/28000 datapoints
2025-03-06 21:05:15,393 - INFO - training batch 501, loss: 0.029, 16032/28000 datapoints
2025-03-06 21:05:15,530 - INFO - training batch 551, loss: 0.034, 17632/28000 datapoints
2025-03-06 21:05:15,660 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-06 21:05:15,788 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:05:15,920 - INFO - training batch 701, loss: 0.061, 22432/28000 datapoints
2025-03-06 21:05:16,048 - INFO - training batch 751, loss: 0.030, 24032/28000 datapoints
2025-03-06 21:05:16,176 - INFO - training batch 801, loss: 0.034, 25632/28000 datapoints
2025-03-06 21:05:16,307 - INFO - training batch 851, loss: 0.060, 27232/28000 datapoints
2025-03-06 21:05:16,373 - INFO - validation batch 1, loss: 0.671, 32/6976 datapoints
2025-03-06 21:05:16,422 - INFO - validation batch 51, loss: 2.329, 1632/6976 datapoints
2025-03-06 21:05:16,472 - INFO - validation batch 101, loss: 0.972, 3232/6976 datapoints
2025-03-06 21:05:16,521 - INFO - validation batch 151, loss: 0.596, 4832/6976 datapoints
2025-03-06 21:05:16,568 - INFO - validation batch 201, loss: 0.679, 6432/6976 datapoints
2025-03-06 21:05:16,587 - INFO - Epoch 689/800 done.
2025-03-06 21:05:16,587 - INFO - Final validation performance:
Loss: 1.049, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:16,587 - INFO - Beginning epoch 690/800
2025-03-06 21:05:16,592 - INFO - training batch 1, loss: 0.090, 32/28000 datapoints
2025-03-06 21:05:16,717 - INFO - training batch 51, loss: 0.032, 1632/28000 datapoints
2025-03-06 21:05:16,842 - INFO - training batch 101, loss: 0.036, 3232/28000 datapoints
2025-03-06 21:05:16,967 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-06 21:05:17,093 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:05:17,214 - INFO - training batch 251, loss: 0.067, 8032/28000 datapoints
2025-03-06 21:05:17,338 - INFO - training batch 301, loss: 0.061, 9632/28000 datapoints
2025-03-06 21:05:17,459 - INFO - training batch 351, loss: 0.083, 11232/28000 datapoints
2025-03-06 21:05:17,580 - INFO - training batch 401, loss: 0.107, 12832/28000 datapoints
2025-03-06 21:05:17,707 - INFO - training batch 451, loss: 0.054, 14432/28000 datapoints
2025-03-06 21:05:17,834 - INFO - training batch 501, loss: 0.028, 16032/28000 datapoints
2025-03-06 21:05:17,958 - INFO - training batch 551, loss: 0.033, 17632/28000 datapoints
2025-03-06 21:05:18,079 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-06 21:05:18,200 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:05:18,324 - INFO - training batch 701, loss: 0.061, 22432/28000 datapoints
2025-03-06 21:05:18,445 - INFO - training batch 751, loss: 0.030, 24032/28000 datapoints
2025-03-06 21:05:18,567 - INFO - training batch 801, loss: 0.034, 25632/28000 datapoints
2025-03-06 21:05:18,690 - INFO - training batch 851, loss: 0.059, 27232/28000 datapoints
2025-03-06 21:05:18,750 - INFO - validation batch 1, loss: 0.675, 32/6976 datapoints
2025-03-06 21:05:18,795 - INFO - validation batch 51, loss: 2.340, 1632/6976 datapoints
2025-03-06 21:05:18,841 - INFO - validation batch 101, loss: 0.974, 3232/6976 datapoints
2025-03-06 21:05:18,884 - INFO - validation batch 151, loss: 0.595, 4832/6976 datapoints
2025-03-06 21:05:18,928 - INFO - validation batch 201, loss: 0.680, 6432/6976 datapoints
2025-03-06 21:05:18,943 - INFO - Epoch 690/800 done.
2025-03-06 21:05:18,943 - INFO - Final validation performance:
Loss: 1.053, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:18,943 - INFO - Beginning epoch 691/800
2025-03-06 21:05:18,947 - INFO - training batch 1, loss: 0.088, 32/28000 datapoints
2025-03-06 21:05:19,072 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-06 21:05:19,192 - INFO - training batch 101, loss: 0.036, 3232/28000 datapoints
2025-03-06 21:05:19,316 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-06 21:05:19,436 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:05:19,557 - INFO - training batch 251, loss: 0.067, 8032/28000 datapoints
2025-03-06 21:05:19,712 - INFO - training batch 301, loss: 0.059, 9632/28000 datapoints
2025-03-06 21:05:19,834 - INFO - training batch 351, loss: 0.082, 11232/28000 datapoints
2025-03-06 21:05:19,955 - INFO - training batch 401, loss: 0.106, 12832/28000 datapoints
2025-03-06 21:05:20,078 - INFO - training batch 451, loss: 0.053, 14432/28000 datapoints
2025-03-06 21:05:20,200 - INFO - training batch 501, loss: 0.028, 16032/28000 datapoints
2025-03-06 21:05:20,325 - INFO - training batch 551, loss: 0.033, 17632/28000 datapoints
2025-03-06 21:05:20,447 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-06 21:05:20,569 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:05:20,693 - INFO - training batch 701, loss: 0.060, 22432/28000 datapoints
2025-03-06 21:05:20,816 - INFO - training batch 751, loss: 0.030, 24032/28000 datapoints
2025-03-06 21:05:20,939 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-06 21:05:21,059 - INFO - training batch 851, loss: 0.059, 27232/28000 datapoints
2025-03-06 21:05:21,122 - INFO - validation batch 1, loss: 0.681, 32/6976 datapoints
2025-03-06 21:05:21,168 - INFO - validation batch 51, loss: 2.344, 1632/6976 datapoints
2025-03-06 21:05:21,212 - INFO - validation batch 101, loss: 0.977, 3232/6976 datapoints
2025-03-06 21:05:21,258 - INFO - validation batch 151, loss: 0.599, 4832/6976 datapoints
2025-03-06 21:05:21,304 - INFO - validation batch 201, loss: 0.685, 6432/6976 datapoints
2025-03-06 21:05:21,319 - INFO - Epoch 691/800 done.
2025-03-06 21:05:21,319 - INFO - Final validation performance:
Loss: 1.057, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:21,320 - INFO - Beginning epoch 692/800
2025-03-06 21:05:21,323 - INFO - training batch 1, loss: 0.088, 32/28000 datapoints
2025-03-06 21:05:21,448 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-06 21:05:21,569 - INFO - training batch 101, loss: 0.036, 3232/28000 datapoints
2025-03-06 21:05:21,695 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-06 21:05:21,830 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:05:21,953 - INFO - training batch 251, loss: 0.066, 8032/28000 datapoints
2025-03-06 21:05:22,074 - INFO - training batch 301, loss: 0.059, 9632/28000 datapoints
2025-03-06 21:05:22,196 - INFO - training batch 351, loss: 0.081, 11232/28000 datapoints
2025-03-06 21:05:22,323 - INFO - training batch 401, loss: 0.105, 12832/28000 datapoints
2025-03-06 21:05:22,449 - INFO - training batch 451, loss: 0.053, 14432/28000 datapoints
2025-03-06 21:05:22,570 - INFO - training batch 501, loss: 0.028, 16032/28000 datapoints
2025-03-06 21:05:22,700 - INFO - training batch 551, loss: 0.033, 17632/28000 datapoints
2025-03-06 21:05:22,820 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-06 21:05:22,944 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-06 21:05:23,070 - INFO - training batch 701, loss: 0.059, 22432/28000 datapoints
2025-03-06 21:05:23,198 - INFO - training batch 751, loss: 0.029, 24032/28000 datapoints
2025-03-06 21:05:23,326 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-06 21:05:23,448 - INFO - training batch 851, loss: 0.058, 27232/28000 datapoints
2025-03-06 21:05:23,508 - INFO - validation batch 1, loss: 0.685, 32/6976 datapoints
2025-03-06 21:05:23,552 - INFO - validation batch 51, loss: 2.353, 1632/6976 datapoints
2025-03-06 21:05:23,595 - INFO - validation batch 101, loss: 0.981, 3232/6976 datapoints
2025-03-06 21:05:23,642 - INFO - validation batch 151, loss: 0.595, 4832/6976 datapoints
2025-03-06 21:05:23,685 - INFO - validation batch 201, loss: 0.686, 6432/6976 datapoints
2025-03-06 21:05:23,700 - INFO - Epoch 692/800 done.
2025-03-06 21:05:23,701 - INFO - Final validation performance:
Loss: 1.060, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:23,701 - INFO - Beginning epoch 693/800
2025-03-06 21:05:23,705 - INFO - training batch 1, loss: 0.087, 32/28000 datapoints
2025-03-06 21:05:23,829 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-06 21:05:23,954 - INFO - training batch 101, loss: 0.036, 3232/28000 datapoints
2025-03-06 21:05:24,076 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-06 21:05:24,198 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:05:24,320 - INFO - training batch 251, loss: 0.065, 8032/28000 datapoints
2025-03-06 21:05:24,448 - INFO - training batch 301, loss: 0.059, 9632/28000 datapoints
2025-03-06 21:05:24,567 - INFO - training batch 351, loss: 0.080, 11232/28000 datapoints
2025-03-06 21:05:24,690 - INFO - training batch 401, loss: 0.103, 12832/28000 datapoints
2025-03-06 21:05:24,812 - INFO - training batch 451, loss: 0.051, 14432/28000 datapoints
2025-03-06 21:05:24,940 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-06 21:05:25,062 - INFO - training batch 551, loss: 0.033, 17632/28000 datapoints
2025-03-06 21:05:25,187 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-06 21:05:25,309 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:05:25,433 - INFO - training batch 701, loss: 0.059, 22432/28000 datapoints
2025-03-06 21:05:25,555 - INFO - training batch 751, loss: 0.029, 24032/28000 datapoints
2025-03-06 21:05:25,679 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-06 21:05:25,806 - INFO - training batch 851, loss: 0.058, 27232/28000 datapoints
2025-03-06 21:05:25,866 - INFO - validation batch 1, loss: 0.691, 32/6976 datapoints
2025-03-06 21:05:25,911 - INFO - validation batch 51, loss: 2.361, 1632/6976 datapoints
2025-03-06 21:05:25,955 - INFO - validation batch 101, loss: 0.985, 3232/6976 datapoints
2025-03-06 21:05:26,000 - INFO - validation batch 151, loss: 0.600, 4832/6976 datapoints
2025-03-06 21:05:26,044 - INFO - validation batch 201, loss: 0.687, 6432/6976 datapoints
2025-03-06 21:05:26,059 - INFO - Epoch 693/800 done.
2025-03-06 21:05:26,059 - INFO - Final validation performance:
Loss: 1.065, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:26,060 - INFO - Beginning epoch 694/800
2025-03-06 21:05:26,063 - INFO - training batch 1, loss: 0.086, 32/28000 datapoints
2025-03-06 21:05:26,184 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-06 21:05:26,306 - INFO - training batch 101, loss: 0.036, 3232/28000 datapoints
2025-03-06 21:05:26,430 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 21:05:26,553 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:05:26,675 - INFO - training batch 251, loss: 0.065, 8032/28000 datapoints
2025-03-06 21:05:26,796 - INFO - training batch 301, loss: 0.058, 9632/28000 datapoints
2025-03-06 21:05:26,920 - INFO - training batch 351, loss: 0.079, 11232/28000 datapoints
2025-03-06 21:05:27,041 - INFO - training batch 401, loss: 0.102, 12832/28000 datapoints
2025-03-06 21:05:27,166 - INFO - training batch 451, loss: 0.051, 14432/28000 datapoints
2025-03-06 21:05:27,289 - INFO - training batch 501, loss: 0.028, 16032/28000 datapoints
2025-03-06 21:05:27,410 - INFO - training batch 551, loss: 0.032, 17632/28000 datapoints
2025-03-06 21:05:27,532 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-06 21:05:27,658 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:05:27,783 - INFO - training batch 701, loss: 0.059, 22432/28000 datapoints
2025-03-06 21:05:27,919 - INFO - training batch 751, loss: 0.029, 24032/28000 datapoints
2025-03-06 21:05:28,042 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-06 21:05:28,163 - INFO - training batch 851, loss: 0.057, 27232/28000 datapoints
2025-03-06 21:05:28,222 - INFO - validation batch 1, loss: 0.690, 32/6976 datapoints
2025-03-06 21:05:28,272 - INFO - validation batch 51, loss: 2.361, 1632/6976 datapoints
2025-03-06 21:05:28,318 - INFO - validation batch 101, loss: 0.990, 3232/6976 datapoints
2025-03-06 21:05:28,363 - INFO - validation batch 151, loss: 0.601, 4832/6976 datapoints
2025-03-06 21:05:28,407 - INFO - validation batch 201, loss: 0.692, 6432/6976 datapoints
2025-03-06 21:05:28,422 - INFO - Epoch 694/800 done.
2025-03-06 21:05:28,422 - INFO - Final validation performance:
Loss: 1.067, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:28,422 - INFO - Beginning epoch 695/800
2025-03-06 21:05:28,428 - INFO - training batch 1, loss: 0.086, 32/28000 datapoints
2025-03-06 21:05:28,556 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-06 21:05:28,681 - INFO - training batch 101, loss: 0.035, 3232/28000 datapoints
2025-03-06 21:05:28,802 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-06 21:05:28,926 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:05:29,048 - INFO - training batch 251, loss: 0.065, 8032/28000 datapoints
2025-03-06 21:05:29,171 - INFO - training batch 301, loss: 0.058, 9632/28000 datapoints
2025-03-06 21:05:29,292 - INFO - training batch 351, loss: 0.078, 11232/28000 datapoints
2025-03-06 21:05:29,411 - INFO - training batch 401, loss: 0.102, 12832/28000 datapoints
2025-03-06 21:05:29,534 - INFO - training batch 451, loss: 0.051, 14432/28000 datapoints
2025-03-06 21:05:29,660 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-06 21:05:29,807 - INFO - training batch 551, loss: 0.032, 17632/28000 datapoints
2025-03-06 21:05:29,941 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-06 21:05:30,068 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:05:30,189 - INFO - training batch 701, loss: 0.058, 22432/28000 datapoints
2025-03-06 21:05:30,311 - INFO - training batch 751, loss: 0.029, 24032/28000 datapoints
2025-03-06 21:05:30,432 - INFO - training batch 801, loss: 0.032, 25632/28000 datapoints
2025-03-06 21:05:30,555 - INFO - training batch 851, loss: 0.056, 27232/28000 datapoints
2025-03-06 21:05:30,614 - INFO - validation batch 1, loss: 0.696, 32/6976 datapoints
2025-03-06 21:05:30,660 - INFO - validation batch 51, loss: 2.373, 1632/6976 datapoints
2025-03-06 21:05:30,705 - INFO - validation batch 101, loss: 0.991, 3232/6976 datapoints
2025-03-06 21:05:30,749 - INFO - validation batch 151, loss: 0.598, 4832/6976 datapoints
2025-03-06 21:05:30,792 - INFO - validation batch 201, loss: 0.692, 6432/6976 datapoints
2025-03-06 21:05:30,807 - INFO - Epoch 695/800 done.
2025-03-06 21:05:30,807 - INFO - Final validation performance:
Loss: 1.070, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:30,808 - INFO - Beginning epoch 696/800
2025-03-06 21:05:30,811 - INFO - training batch 1, loss: 0.084, 32/28000 datapoints
2025-03-06 21:05:30,936 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-06 21:05:31,061 - INFO - training batch 101, loss: 0.035, 3232/28000 datapoints
2025-03-06 21:05:31,186 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 21:05:31,305 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:05:31,427 - INFO - training batch 251, loss: 0.063, 8032/28000 datapoints
2025-03-06 21:05:31,550 - INFO - training batch 301, loss: 0.057, 9632/28000 datapoints
2025-03-06 21:05:31,675 - INFO - training batch 351, loss: 0.078, 11232/28000 datapoints
2025-03-06 21:05:31,796 - INFO - training batch 401, loss: 0.100, 12832/28000 datapoints
2025-03-06 21:05:31,922 - INFO - training batch 451, loss: 0.050, 14432/28000 datapoints
2025-03-06 21:05:32,044 - INFO - training batch 501, loss: 0.026, 16032/28000 datapoints
2025-03-06 21:05:32,169 - INFO - training batch 551, loss: 0.032, 17632/28000 datapoints
2025-03-06 21:05:32,294 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-06 21:05:32,419 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:05:32,545 - INFO - training batch 701, loss: 0.058, 22432/28000 datapoints
2025-03-06 21:05:32,671 - INFO - training batch 751, loss: 0.028, 24032/28000 datapoints
2025-03-06 21:05:32,802 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-06 21:05:32,929 - INFO - training batch 851, loss: 0.056, 27232/28000 datapoints
2025-03-06 21:05:32,995 - INFO - validation batch 1, loss: 0.701, 32/6976 datapoints
2025-03-06 21:05:33,042 - INFO - validation batch 51, loss: 2.378, 1632/6976 datapoints
2025-03-06 21:05:33,089 - INFO - validation batch 101, loss: 0.996, 3232/6976 datapoints
2025-03-06 21:05:33,139 - INFO - validation batch 151, loss: 0.602, 4832/6976 datapoints
2025-03-06 21:05:33,187 - INFO - validation batch 201, loss: 0.696, 6432/6976 datapoints
2025-03-06 21:05:33,203 - INFO - Epoch 696/800 done.
2025-03-06 21:05:33,203 - INFO - Final validation performance:
Loss: 1.075, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:33,204 - INFO - Beginning epoch 697/800
2025-03-06 21:05:33,207 - INFO - training batch 1, loss: 0.083, 32/28000 datapoints
2025-03-06 21:05:33,337 - INFO - training batch 51, loss: 0.030, 1632/28000 datapoints
2025-03-06 21:05:33,462 - INFO - training batch 101, loss: 0.035, 3232/28000 datapoints
2025-03-06 21:05:33,589 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-06 21:05:33,714 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:05:33,849 - INFO - training batch 251, loss: 0.063, 8032/28000 datapoints
2025-03-06 21:05:33,981 - INFO - training batch 301, loss: 0.057, 9632/28000 datapoints
2025-03-06 21:05:34,111 - INFO - training batch 351, loss: 0.077, 11232/28000 datapoints
2025-03-06 21:05:34,236 - INFO - training batch 401, loss: 0.100, 12832/28000 datapoints
2025-03-06 21:05:34,360 - INFO - training batch 451, loss: 0.050, 14432/28000 datapoints
2025-03-06 21:05:34,488 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-06 21:05:34,621 - INFO - training batch 551, loss: 0.032, 17632/28000 datapoints
2025-03-06 21:05:34,751 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-06 21:05:34,880 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:05:35,014 - INFO - training batch 701, loss: 0.057, 22432/28000 datapoints
2025-03-06 21:05:35,145 - INFO - training batch 751, loss: 0.028, 24032/28000 datapoints
2025-03-06 21:05:35,270 - INFO - training batch 801, loss: 0.032, 25632/28000 datapoints
2025-03-06 21:05:35,396 - INFO - training batch 851, loss: 0.055, 27232/28000 datapoints
2025-03-06 21:05:35,458 - INFO - validation batch 1, loss: 0.705, 32/6976 datapoints
2025-03-06 21:05:35,508 - INFO - validation batch 51, loss: 2.388, 1632/6976 datapoints
2025-03-06 21:05:35,556 - INFO - validation batch 101, loss: 0.997, 3232/6976 datapoints
2025-03-06 21:05:35,605 - INFO - validation batch 151, loss: 0.599, 4832/6976 datapoints
2025-03-06 21:05:35,655 - INFO - validation batch 201, loss: 0.698, 6432/6976 datapoints
2025-03-06 21:05:35,670 - INFO - Epoch 697/800 done.
2025-03-06 21:05:35,670 - INFO - Final validation performance:
Loss: 1.077, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:35,671 - INFO - Beginning epoch 698/800
2025-03-06 21:05:35,675 - INFO - training batch 1, loss: 0.082, 32/28000 datapoints
2025-03-06 21:05:35,802 - INFO - training batch 51, loss: 0.030, 1632/28000 datapoints
2025-03-06 21:05:35,930 - INFO - training batch 101, loss: 0.035, 3232/28000 datapoints
2025-03-06 21:05:36,060 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 21:05:36,185 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:05:36,310 - INFO - training batch 251, loss: 0.062, 8032/28000 datapoints
2025-03-06 21:05:36,437 - INFO - training batch 301, loss: 0.056, 9632/28000 datapoints
2025-03-06 21:05:36,565 - INFO - training batch 351, loss: 0.075, 11232/28000 datapoints
2025-03-06 21:05:36,692 - INFO - training batch 401, loss: 0.099, 12832/28000 datapoints
2025-03-06 21:05:36,817 - INFO - training batch 451, loss: 0.049, 14432/28000 datapoints
2025-03-06 21:05:36,944 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-06 21:05:37,079 - INFO - training batch 551, loss: 0.031, 17632/28000 datapoints
2025-03-06 21:05:37,209 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-06 21:05:37,334 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:05:37,460 - INFO - training batch 701, loss: 0.057, 22432/28000 datapoints
2025-03-06 21:05:37,586 - INFO - training batch 751, loss: 0.028, 24032/28000 datapoints
2025-03-06 21:05:37,733 - INFO - training batch 801, loss: 0.032, 25632/28000 datapoints
2025-03-06 21:05:37,860 - INFO - training batch 851, loss: 0.054, 27232/28000 datapoints
2025-03-06 21:05:37,924 - INFO - validation batch 1, loss: 0.710, 32/6976 datapoints
2025-03-06 21:05:37,974 - INFO - validation batch 51, loss: 2.390, 1632/6976 datapoints
2025-03-06 21:05:38,022 - INFO - validation batch 101, loss: 1.004, 3232/6976 datapoints
2025-03-06 21:05:38,074 - INFO - validation batch 151, loss: 0.599, 4832/6976 datapoints
2025-03-06 21:05:38,124 - INFO - validation batch 201, loss: 0.698, 6432/6976 datapoints
2025-03-06 21:05:38,143 - INFO - Epoch 698/800 done.
2025-03-06 21:05:38,143 - INFO - Final validation performance:
Loss: 1.080, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:38,144 - INFO - Beginning epoch 699/800
2025-03-06 21:05:38,148 - INFO - training batch 1, loss: 0.082, 32/28000 datapoints
2025-03-06 21:05:38,274 - INFO - training batch 51, loss: 0.030, 1632/28000 datapoints
2025-03-06 21:05:38,398 - INFO - training batch 101, loss: 0.035, 3232/28000 datapoints
2025-03-06 21:05:38,524 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 21:05:38,653 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:05:38,777 - INFO - training batch 251, loss: 0.062, 8032/28000 datapoints
2025-03-06 21:05:38,903 - INFO - training batch 301, loss: 0.056, 9632/28000 datapoints
2025-03-06 21:05:39,032 - INFO - training batch 351, loss: 0.075, 11232/28000 datapoints
2025-03-06 21:05:39,163 - INFO - training batch 401, loss: 0.098, 12832/28000 datapoints
2025-03-06 21:05:39,289 - INFO - training batch 451, loss: 0.049, 14432/28000 datapoints
2025-03-06 21:05:39,415 - INFO - training batch 501, loss: 0.026, 16032/28000 datapoints
2025-03-06 21:05:39,542 - INFO - training batch 551, loss: 0.031, 17632/28000 datapoints
2025-03-06 21:05:39,670 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-06 21:05:39,810 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:05:39,960 - INFO - training batch 701, loss: 0.056, 22432/28000 datapoints
2025-03-06 21:05:40,099 - INFO - training batch 751, loss: 0.028, 24032/28000 datapoints
2025-03-06 21:05:40,224 - INFO - training batch 801, loss: 0.032, 25632/28000 datapoints
2025-03-06 21:05:40,350 - INFO - training batch 851, loss: 0.055, 27232/28000 datapoints
2025-03-06 21:05:40,414 - INFO - validation batch 1, loss: 0.711, 32/6976 datapoints
2025-03-06 21:05:40,468 - INFO - validation batch 51, loss: 2.397, 1632/6976 datapoints
2025-03-06 21:05:40,519 - INFO - validation batch 101, loss: 1.006, 3232/6976 datapoints
2025-03-06 21:05:40,570 - INFO - validation batch 151, loss: 0.604, 4832/6976 datapoints
2025-03-06 21:05:40,620 - INFO - validation batch 201, loss: 0.708, 6432/6976 datapoints
2025-03-06 21:05:40,644 - INFO - Epoch 699/800 done.
2025-03-06 21:05:40,644 - INFO - Final validation performance:
Loss: 1.085, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:40,644 - INFO - Beginning epoch 700/800
2025-03-06 21:05:40,648 - INFO - training batch 1, loss: 0.080, 32/28000 datapoints
2025-03-06 21:05:40,776 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-06 21:05:40,901 - INFO - training batch 101, loss: 0.034, 3232/28000 datapoints
2025-03-06 21:05:41,031 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 21:05:41,162 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:05:41,288 - INFO - training batch 251, loss: 0.061, 8032/28000 datapoints
2025-03-06 21:05:41,413 - INFO - training batch 301, loss: 0.055, 9632/28000 datapoints
2025-03-06 21:05:41,537 - INFO - training batch 351, loss: 0.074, 11232/28000 datapoints
2025-03-06 21:05:41,666 - INFO - training batch 401, loss: 0.098, 12832/28000 datapoints
2025-03-06 21:05:41,795 - INFO - training batch 451, loss: 0.048, 14432/28000 datapoints
2025-03-06 21:05:41,920 - INFO - training batch 501, loss: 0.025, 16032/28000 datapoints
2025-03-06 21:05:42,047 - INFO - training batch 551, loss: 0.030, 17632/28000 datapoints
2025-03-06 21:05:42,173 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-06 21:05:42,301 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:05:42,425 - INFO - training batch 701, loss: 0.056, 22432/28000 datapoints
2025-03-06 21:05:42,550 - INFO - training batch 751, loss: 0.027, 24032/28000 datapoints
2025-03-06 21:05:42,679 - INFO - training batch 801, loss: 0.032, 25632/28000 datapoints
2025-03-06 21:05:42,804 - INFO - training batch 851, loss: 0.053, 27232/28000 datapoints
2025-03-06 21:05:42,867 - INFO - validation batch 1, loss: 0.719, 32/6976 datapoints
2025-03-06 21:05:42,917 - INFO - validation batch 51, loss: 2.404, 1632/6976 datapoints
2025-03-06 21:05:42,967 - INFO - validation batch 101, loss: 1.009, 3232/6976 datapoints
2025-03-06 21:05:43,017 - INFO - validation batch 151, loss: 0.604, 4832/6976 datapoints
2025-03-06 21:05:43,065 - INFO - validation batch 201, loss: 0.705, 6432/6976 datapoints
2025-03-06 21:05:43,082 - INFO - Epoch 700/800 done.
2025-03-06 21:05:43,082 - INFO - Final validation performance:
Loss: 1.088, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:43,083 - INFO - Beginning epoch 701/800
2025-03-06 21:05:43,087 - INFO - training batch 1, loss: 0.080, 32/28000 datapoints
2025-03-06 21:05:43,216 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-06 21:05:43,344 - INFO - training batch 101, loss: 0.034, 3232/28000 datapoints
2025-03-06 21:05:43,465 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 21:05:43,587 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:05:43,713 - INFO - training batch 251, loss: 0.061, 8032/28000 datapoints
2025-03-06 21:05:43,835 - INFO - training batch 301, loss: 0.055, 9632/28000 datapoints
2025-03-06 21:05:43,956 - INFO - training batch 351, loss: 0.072, 11232/28000 datapoints
2025-03-06 21:05:44,077 - INFO - training batch 401, loss: 0.097, 12832/28000 datapoints
2025-03-06 21:05:44,201 - INFO - training batch 451, loss: 0.048, 14432/28000 datapoints
2025-03-06 21:05:44,321 - INFO - training batch 501, loss: 0.026, 16032/28000 datapoints
2025-03-06 21:05:44,443 - INFO - training batch 551, loss: 0.030, 17632/28000 datapoints
2025-03-06 21:05:44,563 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-06 21:05:44,688 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:05:44,809 - INFO - training batch 701, loss: 0.055, 22432/28000 datapoints
2025-03-06 21:05:44,940 - INFO - training batch 751, loss: 0.027, 24032/28000 datapoints
2025-03-06 21:05:45,063 - INFO - training batch 801, loss: 0.031, 25632/28000 datapoints
2025-03-06 21:05:45,191 - INFO - training batch 851, loss: 0.052, 27232/28000 datapoints
2025-03-06 21:05:45,250 - INFO - validation batch 1, loss: 0.723, 32/6976 datapoints
2025-03-06 21:05:45,295 - INFO - validation batch 51, loss: 2.412, 1632/6976 datapoints
2025-03-06 21:05:45,339 - INFO - validation batch 101, loss: 1.013, 3232/6976 datapoints
2025-03-06 21:05:45,383 - INFO - validation batch 151, loss: 0.603, 4832/6976 datapoints
2025-03-06 21:05:45,427 - INFO - validation batch 201, loss: 0.706, 6432/6976 datapoints
2025-03-06 21:05:45,442 - INFO - Epoch 701/800 done.
2025-03-06 21:05:45,442 - INFO - Final validation performance:
Loss: 1.092, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:45,443 - INFO - Beginning epoch 702/800
2025-03-06 21:05:45,446 - INFO - training batch 1, loss: 0.079, 32/28000 datapoints
2025-03-06 21:05:45,569 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-06 21:05:45,697 - INFO - training batch 101, loss: 0.033, 3232/28000 datapoints
2025-03-06 21:05:45,819 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 21:05:45,947 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:05:46,079 - INFO - training batch 251, loss: 0.060, 8032/28000 datapoints
2025-03-06 21:05:46,201 - INFO - training batch 301, loss: 0.054, 9632/28000 datapoints
2025-03-06 21:05:46,324 - INFO - training batch 351, loss: 0.072, 11232/28000 datapoints
2025-03-06 21:05:46,455 - INFO - training batch 401, loss: 0.096, 12832/28000 datapoints
2025-03-06 21:05:46,580 - INFO - training batch 451, loss: 0.047, 14432/28000 datapoints
2025-03-06 21:05:46,723 - INFO - training batch 501, loss: 0.025, 16032/28000 datapoints
2025-03-06 21:05:46,879 - INFO - training batch 551, loss: 0.030, 17632/28000 datapoints
2025-03-06 21:05:47,023 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-06 21:05:47,167 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:05:47,292 - INFO - training batch 701, loss: 0.055, 22432/28000 datapoints
2025-03-06 21:05:47,412 - INFO - training batch 751, loss: 0.027, 24032/28000 datapoints
2025-03-06 21:05:47,533 - INFO - training batch 801, loss: 0.031, 25632/28000 datapoints
2025-03-06 21:05:47,658 - INFO - training batch 851, loss: 0.053, 27232/28000 datapoints
2025-03-06 21:05:47,720 - INFO - validation batch 1, loss: 0.726, 32/6976 datapoints
2025-03-06 21:05:47,764 - INFO - validation batch 51, loss: 2.423, 1632/6976 datapoints
2025-03-06 21:05:47,810 - INFO - validation batch 101, loss: 1.016, 3232/6976 datapoints
2025-03-06 21:05:47,854 - INFO - validation batch 151, loss: 0.605, 4832/6976 datapoints
2025-03-06 21:05:47,909 - INFO - validation batch 201, loss: 0.715, 6432/6976 datapoints
2025-03-06 21:05:47,924 - INFO - Epoch 702/800 done.
2025-03-06 21:05:47,925 - INFO - Final validation performance:
Loss: 1.097, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:47,925 - INFO - Beginning epoch 703/800
2025-03-06 21:05:47,928 - INFO - training batch 1, loss: 0.077, 32/28000 datapoints
2025-03-06 21:05:48,052 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-06 21:05:48,178 - INFO - training batch 101, loss: 0.034, 3232/28000 datapoints
2025-03-06 21:05:48,299 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 21:05:48,422 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:05:48,544 - INFO - training batch 251, loss: 0.059, 8032/28000 datapoints
2025-03-06 21:05:48,670 - INFO - training batch 301, loss: 0.054, 9632/28000 datapoints
2025-03-06 21:05:48,790 - INFO - training batch 351, loss: 0.071, 11232/28000 datapoints
2025-03-06 21:05:48,915 - INFO - training batch 401, loss: 0.095, 12832/28000 datapoints
2025-03-06 21:05:49,039 - INFO - training batch 451, loss: 0.047, 14432/28000 datapoints
2025-03-06 21:05:49,165 - INFO - training batch 501, loss: 0.025, 16032/28000 datapoints
2025-03-06 21:05:49,290 - INFO - training batch 551, loss: 0.030, 17632/28000 datapoints
2025-03-06 21:05:49,411 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-06 21:05:49,532 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:05:49,658 - INFO - training batch 701, loss: 0.054, 22432/28000 datapoints
2025-03-06 21:05:49,779 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-06 21:05:49,908 - INFO - training batch 801, loss: 0.031, 25632/28000 datapoints
2025-03-06 21:05:50,054 - INFO - training batch 851, loss: 0.052, 27232/28000 datapoints
2025-03-06 21:05:50,115 - INFO - validation batch 1, loss: 0.731, 32/6976 datapoints
2025-03-06 21:05:50,160 - INFO - validation batch 51, loss: 2.423, 1632/6976 datapoints
2025-03-06 21:05:50,206 - INFO - validation batch 101, loss: 1.021, 3232/6976 datapoints
2025-03-06 21:05:50,250 - INFO - validation batch 151, loss: 0.605, 4832/6976 datapoints
2025-03-06 21:05:50,295 - INFO - validation batch 201, loss: 0.711, 6432/6976 datapoints
2025-03-06 21:05:50,311 - INFO - Epoch 703/800 done.
2025-03-06 21:05:50,311 - INFO - Final validation performance:
Loss: 1.098, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:50,312 - INFO - Beginning epoch 704/800
2025-03-06 21:05:50,315 - INFO - training batch 1, loss: 0.078, 32/28000 datapoints
2025-03-06 21:05:50,438 - INFO - training batch 51, loss: 0.028, 1632/28000 datapoints
2025-03-06 21:05:50,559 - INFO - training batch 101, loss: 0.033, 3232/28000 datapoints
2025-03-06 21:05:50,685 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 21:05:50,805 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:05:50,927 - INFO - training batch 251, loss: 0.059, 8032/28000 datapoints
2025-03-06 21:05:51,049 - INFO - training batch 301, loss: 0.053, 9632/28000 datapoints
2025-03-06 21:05:51,170 - INFO - training batch 351, loss: 0.070, 11232/28000 datapoints
2025-03-06 21:05:51,297 - INFO - training batch 401, loss: 0.094, 12832/28000 datapoints
2025-03-06 21:05:51,419 - INFO - training batch 451, loss: 0.046, 14432/28000 datapoints
2025-03-06 21:05:51,541 - INFO - training batch 501, loss: 0.025, 16032/28000 datapoints
2025-03-06 21:05:51,664 - INFO - training batch 551, loss: 0.029, 17632/28000 datapoints
2025-03-06 21:05:51,785 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-06 21:05:51,907 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:05:52,028 - INFO - training batch 701, loss: 0.053, 22432/28000 datapoints
2025-03-06 21:05:52,168 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-06 21:05:52,300 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-06 21:05:52,425 - INFO - training batch 851, loss: 0.052, 27232/28000 datapoints
2025-03-06 21:05:52,489 - INFO - validation batch 1, loss: 0.733, 32/6976 datapoints
2025-03-06 21:05:52,534 - INFO - validation batch 51, loss: 2.434, 1632/6976 datapoints
2025-03-06 21:05:52,581 - INFO - validation batch 101, loss: 1.024, 3232/6976 datapoints
2025-03-06 21:05:52,632 - INFO - validation batch 151, loss: 0.609, 4832/6976 datapoints
2025-03-06 21:05:52,693 - INFO - validation batch 201, loss: 0.720, 6432/6976 datapoints
2025-03-06 21:05:52,714 - INFO - Epoch 704/800 done.
2025-03-06 21:05:52,714 - INFO - Final validation performance:
Loss: 1.104, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:52,814 - INFO - Beginning epoch 705/800
2025-03-06 21:05:52,818 - INFO - training batch 1, loss: 0.076, 32/28000 datapoints
2025-03-06 21:05:52,976 - INFO - training batch 51, loss: 0.028, 1632/28000 datapoints
2025-03-06 21:05:53,121 - INFO - training batch 101, loss: 0.033, 3232/28000 datapoints
2025-03-06 21:05:53,289 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 21:05:53,420 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:05:53,543 - INFO - training batch 251, loss: 0.057, 8032/28000 datapoints
2025-03-06 21:05:53,667 - INFO - training batch 301, loss: 0.053, 9632/28000 datapoints
2025-03-06 21:05:53,790 - INFO - training batch 351, loss: 0.069, 11232/28000 datapoints
2025-03-06 21:05:53,912 - INFO - training batch 401, loss: 0.093, 12832/28000 datapoints
2025-03-06 21:05:54,035 - INFO - training batch 451, loss: 0.046, 14432/28000 datapoints
2025-03-06 21:05:54,158 - INFO - training batch 501, loss: 0.025, 16032/28000 datapoints
2025-03-06 21:05:54,282 - INFO - training batch 551, loss: 0.029, 17632/28000 datapoints
2025-03-06 21:05:54,402 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-06 21:05:54,525 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:05:54,647 - INFO - training batch 701, loss: 0.053, 22432/28000 datapoints
2025-03-06 21:05:54,781 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-06 21:05:54,904 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-06 21:05:55,032 - INFO - training batch 851, loss: 0.051, 27232/28000 datapoints
2025-03-06 21:05:55,093 - INFO - validation batch 1, loss: 0.739, 32/6976 datapoints
2025-03-06 21:05:55,137 - INFO - validation batch 51, loss: 2.439, 1632/6976 datapoints
2025-03-06 21:05:55,180 - INFO - validation batch 101, loss: 1.029, 3232/6976 datapoints
2025-03-06 21:05:55,226 - INFO - validation batch 151, loss: 0.607, 4832/6976 datapoints
2025-03-06 21:05:55,272 - INFO - validation batch 201, loss: 0.722, 6432/6976 datapoints
2025-03-06 21:05:55,288 - INFO - Epoch 705/800 done.
2025-03-06 21:05:55,288 - INFO - Final validation performance:
Loss: 1.107, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:55,289 - INFO - Beginning epoch 706/800
2025-03-06 21:05:55,292 - INFO - training batch 1, loss: 0.075, 32/28000 datapoints
2025-03-06 21:05:55,416 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-06 21:05:55,539 - INFO - training batch 101, loss: 0.033, 3232/28000 datapoints
2025-03-06 21:05:55,665 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 21:05:55,824 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:05:55,959 - INFO - training batch 251, loss: 0.058, 8032/28000 datapoints
2025-03-06 21:05:56,084 - INFO - training batch 301, loss: 0.052, 9632/28000 datapoints
2025-03-06 21:05:56,204 - INFO - training batch 351, loss: 0.069, 11232/28000 datapoints
2025-03-06 21:05:56,330 - INFO - training batch 401, loss: 0.092, 12832/28000 datapoints
2025-03-06 21:05:56,454 - INFO - training batch 451, loss: 0.045, 14432/28000 datapoints
2025-03-06 21:05:56,576 - INFO - training batch 501, loss: 0.025, 16032/28000 datapoints
2025-03-06 21:05:56,704 - INFO - training batch 551, loss: 0.029, 17632/28000 datapoints
2025-03-06 21:05:56,827 - INFO - training batch 601, loss: 0.035, 19232/28000 datapoints
2025-03-06 21:05:56,950 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:05:57,072 - INFO - training batch 701, loss: 0.052, 22432/28000 datapoints
2025-03-06 21:05:57,206 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-06 21:05:57,332 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-06 21:05:57,456 - INFO - training batch 851, loss: 0.050, 27232/28000 datapoints
2025-03-06 21:05:57,515 - INFO - validation batch 1, loss: 0.741, 32/6976 datapoints
2025-03-06 21:05:57,559 - INFO - validation batch 51, loss: 2.448, 1632/6976 datapoints
2025-03-06 21:05:57,603 - INFO - validation batch 101, loss: 1.031, 3232/6976 datapoints
2025-03-06 21:05:57,650 - INFO - validation batch 151, loss: 0.607, 4832/6976 datapoints
2025-03-06 21:05:57,697 - INFO - validation batch 201, loss: 0.728, 6432/6976 datapoints
2025-03-06 21:05:57,711 - INFO - Epoch 706/800 done.
2025-03-06 21:05:57,712 - INFO - Final validation performance:
Loss: 1.111, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:05:57,712 - INFO - Beginning epoch 707/800
2025-03-06 21:05:57,716 - INFO - training batch 1, loss: 0.075, 32/28000 datapoints
2025-03-06 21:05:57,843 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-06 21:05:57,964 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 21:05:58,096 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 21:05:58,226 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:05:58,350 - INFO - training batch 251, loss: 0.057, 8032/28000 datapoints
2025-03-06 21:05:58,474 - INFO - training batch 301, loss: 0.051, 9632/28000 datapoints
2025-03-06 21:05:58,604 - INFO - training batch 351, loss: 0.068, 11232/28000 datapoints
2025-03-06 21:05:58,732 - INFO - training batch 401, loss: 0.091, 12832/28000 datapoints
2025-03-06 21:05:58,857 - INFO - training batch 451, loss: 0.045, 14432/28000 datapoints
2025-03-06 21:05:58,984 - INFO - training batch 501, loss: 0.025, 16032/28000 datapoints
2025-03-06 21:05:59,107 - INFO - training batch 551, loss: 0.029, 17632/28000 datapoints
2025-03-06 21:05:59,228 - INFO - training batch 601, loss: 0.034, 19232/28000 datapoints
2025-03-06 21:05:59,355 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:05:59,477 - INFO - training batch 701, loss: 0.052, 22432/28000 datapoints
2025-03-06 21:05:59,599 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-06 21:05:59,724 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-06 21:05:59,846 - INFO - training batch 851, loss: 0.050, 27232/28000 datapoints
2025-03-06 21:05:59,907 - INFO - validation batch 1, loss: 0.745, 32/6976 datapoints
2025-03-06 21:05:59,951 - INFO - validation batch 51, loss: 2.450, 1632/6976 datapoints
2025-03-06 21:06:00,001 - INFO - validation batch 101, loss: 1.038, 3232/6976 datapoints
2025-03-06 21:06:00,068 - INFO - validation batch 151, loss: 0.609, 4832/6976 datapoints
2025-03-06 21:06:00,122 - INFO - validation batch 201, loss: 0.727, 6432/6976 datapoints
2025-03-06 21:06:00,137 - INFO - Epoch 707/800 done.
2025-03-06 21:06:00,137 - INFO - Final validation performance:
Loss: 1.114, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:06:00,138 - INFO - Beginning epoch 708/800
2025-03-06 21:06:00,141 - INFO - training batch 1, loss: 0.074, 32/28000 datapoints
2025-03-06 21:06:00,267 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-06 21:06:00,391 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 21:06:00,513 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 21:06:00,634 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:06:00,760 - INFO - training batch 251, loss: 0.056, 8032/28000 datapoints
2025-03-06 21:06:00,882 - INFO - training batch 301, loss: 0.051, 9632/28000 datapoints
2025-03-06 21:06:01,004 - INFO - training batch 351, loss: 0.067, 11232/28000 datapoints
2025-03-06 21:06:01,124 - INFO - training batch 401, loss: 0.089, 12832/28000 datapoints
2025-03-06 21:06:01,249 - INFO - training batch 451, loss: 0.044, 14432/28000 datapoints
2025-03-06 21:06:01,374 - INFO - training batch 501, loss: 0.024, 16032/28000 datapoints
2025-03-06 21:06:01,496 - INFO - training batch 551, loss: 0.028, 17632/28000 datapoints
2025-03-06 21:06:01,617 - INFO - training batch 601, loss: 0.034, 19232/28000 datapoints
2025-03-06 21:06:01,743 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:06:01,866 - INFO - training batch 701, loss: 0.052, 22432/28000 datapoints
2025-03-06 21:06:01,989 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-06 21:06:02,111 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-06 21:06:02,233 - INFO - training batch 851, loss: 0.049, 27232/28000 datapoints
2025-03-06 21:06:02,293 - INFO - validation batch 1, loss: 0.747, 32/6976 datapoints
2025-03-06 21:06:02,337 - INFO - validation batch 51, loss: 2.460, 1632/6976 datapoints
2025-03-06 21:06:02,391 - INFO - validation batch 101, loss: 1.041, 3232/6976 datapoints
2025-03-06 21:06:02,435 - INFO - validation batch 151, loss: 0.611, 4832/6976 datapoints
2025-03-06 21:06:02,479 - INFO - validation batch 201, loss: 0.732, 6432/6976 datapoints
2025-03-06 21:06:02,494 - INFO - Epoch 708/800 done.
2025-03-06 21:06:02,494 - INFO - Final validation performance:
Loss: 1.118, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:06:02,494 - INFO - Beginning epoch 709/800
2025-03-06 21:06:02,498 - INFO - training batch 1, loss: 0.073, 32/28000 datapoints
2025-03-06 21:06:02,624 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-06 21:06:02,750 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 21:06:02,876 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 21:06:03,000 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:06:03,123 - INFO - training batch 251, loss: 0.055, 8032/28000 datapoints
2025-03-06 21:06:03,245 - INFO - training batch 301, loss: 0.051, 9632/28000 datapoints
2025-03-06 21:06:03,370 - INFO - training batch 351, loss: 0.066, 11232/28000 datapoints
2025-03-06 21:06:03,494 - INFO - training batch 401, loss: 0.090, 12832/28000 datapoints
2025-03-06 21:06:03,618 - INFO - training batch 451, loss: 0.044, 14432/28000 datapoints
2025-03-06 21:06:03,748 - INFO - training batch 501, loss: 0.024, 16032/28000 datapoints
2025-03-06 21:06:03,871 - INFO - training batch 551, loss: 0.028, 17632/28000 datapoints
2025-03-06 21:06:03,994 - INFO - training batch 601, loss: 0.035, 19232/28000 datapoints
2025-03-06 21:06:04,116 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:06:04,256 - INFO - training batch 701, loss: 0.051, 22432/28000 datapoints
2025-03-06 21:06:04,378 - INFO - training batch 751, loss: 0.025, 24032/28000 datapoints
2025-03-06 21:06:04,499 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-06 21:06:04,626 - INFO - training batch 851, loss: 0.049, 27232/28000 datapoints
2025-03-06 21:06:04,691 - INFO - validation batch 1, loss: 0.751, 32/6976 datapoints
2025-03-06 21:06:04,735 - INFO - validation batch 51, loss: 2.470, 1632/6976 datapoints
2025-03-06 21:06:04,779 - INFO - validation batch 101, loss: 1.045, 3232/6976 datapoints
2025-03-06 21:06:04,827 - INFO - validation batch 151, loss: 0.608, 4832/6976 datapoints
2025-03-06 21:06:04,871 - INFO - validation batch 201, loss: 0.736, 6432/6976 datapoints
2025-03-06 21:06:04,889 - INFO - Epoch 709/800 done.
2025-03-06 21:06:04,890 - INFO - Final validation performance:
Loss: 1.122, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:06:04,890 - INFO - Beginning epoch 710/800
2025-03-06 21:06:04,894 - INFO - training batch 1, loss: 0.072, 32/28000 datapoints
2025-03-06 21:06:05,031 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-06 21:06:05,156 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 21:06:05,283 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 21:06:05,406 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:06:05,529 - INFO - training batch 251, loss: 0.055, 8032/28000 datapoints
2025-03-06 21:06:05,654 - INFO - training batch 301, loss: 0.050, 9632/28000 datapoints
2025-03-06 21:06:05,775 - INFO - training batch 351, loss: 0.065, 11232/28000 datapoints
2025-03-06 21:06:05,898 - INFO - training batch 401, loss: 0.089, 12832/28000 datapoints
2025-03-06 21:06:06,022 - INFO - training batch 451, loss: 0.044, 14432/28000 datapoints
2025-03-06 21:06:06,145 - INFO - training batch 501, loss: 0.024, 16032/28000 datapoints
2025-03-06 21:06:06,268 - INFO - training batch 551, loss: 0.028, 17632/28000 datapoints
2025-03-06 21:06:06,389 - INFO - training batch 601, loss: 0.035, 19232/28000 datapoints
2025-03-06 21:06:06,514 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-06 21:06:06,636 - INFO - training batch 701, loss: 0.050, 22432/28000 datapoints
2025-03-06 21:06:06,763 - INFO - training batch 751, loss: 0.025, 24032/28000 datapoints
2025-03-06 21:06:06,885 - INFO - training batch 801, loss: 0.029, 25632/28000 datapoints
2025-03-06 21:06:07,006 - INFO - training batch 851, loss: 0.048, 27232/28000 datapoints
2025-03-06 21:06:07,066 - INFO - validation batch 1, loss: 0.758, 32/6976 datapoints
2025-03-06 21:06:07,110 - INFO - validation batch 51, loss: 2.476, 1632/6976 datapoints
2025-03-06 21:06:07,153 - INFO - validation batch 101, loss: 1.049, 3232/6976 datapoints
2025-03-06 21:06:07,197 - INFO - validation batch 151, loss: 0.611, 4832/6976 datapoints
2025-03-06 21:06:07,242 - INFO - validation batch 201, loss: 0.737, 6432/6976 datapoints
2025-03-06 21:06:07,257 - INFO - Epoch 710/800 done.
2025-03-06 21:06:07,257 - INFO - Final validation performance:
Loss: 1.126, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:06:07,257 - INFO - Beginning epoch 711/800
2025-03-06 21:06:07,261 - INFO - training batch 1, loss: 0.072, 32/28000 datapoints
2025-03-06 21:06:07,387 - INFO - training batch 51, loss: 0.026, 1632/28000 datapoints
2025-03-06 21:06:07,513 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 21:06:07,634 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 21:06:07,765 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:06:07,888 - INFO - training batch 251, loss: 0.054, 8032/28000 datapoints
2025-03-06 21:06:08,011 - INFO - training batch 301, loss: 0.050, 9632/28000 datapoints
2025-03-06 21:06:08,134 - INFO - training batch 351, loss: 0.065, 11232/28000 datapoints
2025-03-06 21:06:08,253 - INFO - training batch 401, loss: 0.088, 12832/28000 datapoints
2025-03-06 21:06:08,374 - INFO - training batch 451, loss: 0.043, 14432/28000 datapoints
2025-03-06 21:06:08,499 - INFO - training batch 501, loss: 0.024, 16032/28000 datapoints
2025-03-06 21:06:08,621 - INFO - training batch 551, loss: 0.028, 17632/28000 datapoints
2025-03-06 21:06:08,745 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-06 21:06:08,868 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 21:06:08,991 - INFO - training batch 701, loss: 0.050, 22432/28000 datapoints
2025-03-06 21:06:09,117 - INFO - training batch 751, loss: 0.025, 24032/28000 datapoints
2025-03-06 21:06:09,238 - INFO - training batch 801, loss: 0.029, 25632/28000 datapoints
2025-03-06 21:06:09,363 - INFO - training batch 851, loss: 0.048, 27232/28000 datapoints
2025-03-06 21:06:09,422 - INFO - validation batch 1, loss: 0.758, 32/6976 datapoints
2025-03-06 21:06:09,467 - INFO - validation batch 51, loss: 2.486, 1632/6976 datapoints
2025-03-06 21:06:09,511 - INFO - validation batch 101, loss: 1.054, 3232/6976 datapoints
2025-03-06 21:06:09,553 - INFO - validation batch 151, loss: 0.613, 4832/6976 datapoints
2025-03-06 21:06:09,597 - INFO - validation batch 201, loss: 0.738, 6432/6976 datapoints
2025-03-06 21:06:09,612 - INFO - Epoch 711/800 done.
2025-03-06 21:06:09,612 - INFO - Final validation performance:
Loss: 1.130, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:06:09,613 - INFO - Beginning epoch 712/800
2025-03-06 21:06:09,616 - INFO - training batch 1, loss: 0.071, 32/28000 datapoints
2025-03-06 21:06:09,741 - INFO - training batch 51, loss: 0.026, 1632/28000 datapoints
2025-03-06 21:06:09,864 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 21:06:09,989 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 21:06:10,120 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:06:10,278 - INFO - training batch 251, loss: 0.054, 8032/28000 datapoints
2025-03-06 21:06:10,401 - INFO - training batch 301, loss: 0.049, 9632/28000 datapoints
2025-03-06 21:06:10,522 - INFO - training batch 351, loss: 0.064, 11232/28000 datapoints
2025-03-06 21:06:10,655 - INFO - training batch 401, loss: 0.087, 12832/28000 datapoints
2025-03-06 21:06:10,779 - INFO - training batch 451, loss: 0.042, 14432/28000 datapoints
2025-03-06 21:06:10,905 - INFO - training batch 501, loss: 0.023, 16032/28000 datapoints
2025-03-06 21:06:11,034 - INFO - training batch 551, loss: 0.028, 17632/28000 datapoints
2025-03-06 21:06:11,163 - INFO - training batch 601, loss: 0.034, 19232/28000 datapoints
2025-03-06 21:06:11,286 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 21:06:11,414 - INFO - training batch 701, loss: 0.050, 22432/28000 datapoints
2025-03-06 21:06:11,541 - INFO - training batch 751, loss: 0.024, 24032/28000 datapoints
2025-03-06 21:06:11,664 - INFO - training batch 801, loss: 0.029, 25632/28000 datapoints
2025-03-06 21:06:11,787 - INFO - training batch 851, loss: 0.047, 27232/28000 datapoints
2025-03-06 21:06:11,847 - INFO - validation batch 1, loss: 0.765, 32/6976 datapoints
2025-03-06 21:06:11,892 - INFO - validation batch 51, loss: 2.490, 1632/6976 datapoints
2025-03-06 21:06:11,936 - INFO - validation batch 101, loss: 1.058, 3232/6976 datapoints
2025-03-06 21:06:11,980 - INFO - validation batch 151, loss: 0.613, 4832/6976 datapoints
2025-03-06 21:06:12,027 - INFO - validation batch 201, loss: 0.742, 6432/6976 datapoints
2025-03-06 21:06:12,042 - INFO - Epoch 712/800 done.
2025-03-06 21:06:12,042 - INFO - Final validation performance:
Loss: 1.134, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:06:12,043 - INFO - Beginning epoch 713/800
2025-03-06 21:06:12,046 - INFO - training batch 1, loss: 0.070, 32/28000 datapoints
2025-03-06 21:06:12,172 - INFO - training batch 51, loss: 0.026, 1632/28000 datapoints
2025-03-06 21:06:12,295 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-06 21:06:12,418 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-06 21:06:12,548 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:06:12,677 - INFO - training batch 251, loss: 0.053, 8032/28000 datapoints
2025-03-06 21:06:12,801 - INFO - training batch 301, loss: 0.049, 9632/28000 datapoints
2025-03-06 21:06:12,928 - INFO - training batch 351, loss: 0.063, 11232/28000 datapoints
2025-03-06 21:06:13,058 - INFO - training batch 401, loss: 0.086, 12832/28000 datapoints
2025-03-06 21:06:13,189 - INFO - training batch 451, loss: 0.042, 14432/28000 datapoints
2025-03-06 21:06:13,321 - INFO - training batch 501, loss: 0.023, 16032/28000 datapoints
2025-03-06 21:06:13,447 - INFO - training batch 551, loss: 0.028, 17632/28000 datapoints
2025-03-06 21:06:13,577 - INFO - training batch 601, loss: 0.034, 19232/28000 datapoints
2025-03-06 21:06:13,706 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 21:06:13,832 - INFO - training batch 701, loss: 0.049, 22432/28000 datapoints
2025-03-06 21:06:13,958 - INFO - training batch 751, loss: 0.024, 24032/28000 datapoints
2025-03-06 21:06:14,085 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-06 21:06:14,212 - INFO - training batch 851, loss: 0.046, 27232/28000 datapoints
2025-03-06 21:06:14,276 - INFO - validation batch 1, loss: 0.768, 32/6976 datapoints
2025-03-06 21:06:14,323 - INFO - validation batch 51, loss: 2.499, 1632/6976 datapoints
2025-03-06 21:06:14,370 - INFO - validation batch 101, loss: 1.062, 3232/6976 datapoints
2025-03-06 21:06:14,419 - INFO - validation batch 151, loss: 0.614, 4832/6976 datapoints
2025-03-06 21:06:14,467 - INFO - validation batch 201, loss: 0.743, 6432/6976 datapoints
2025-03-06 21:06:14,485 - INFO - Epoch 713/800 done.
2025-03-06 21:06:14,485 - INFO - Final validation performance:
Loss: 1.137, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:06:14,486 - INFO - Beginning epoch 714/800
2025-03-06 21:06:14,490 - INFO - training batch 1, loss: 0.069, 32/28000 datapoints
2025-03-06 21:06:14,615 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-06 21:06:14,740 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-06 21:06:14,862 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-06 21:06:14,990 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:06:15,115 - INFO - training batch 251, loss: 0.052, 8032/28000 datapoints
2025-03-06 21:06:15,237 - INFO - training batch 301, loss: 0.048, 9632/28000 datapoints
2025-03-06 21:06:15,363 - INFO - training batch 351, loss: 0.062, 11232/28000 datapoints
2025-03-06 21:06:15,485 - INFO - training batch 401, loss: 0.085, 12832/28000 datapoints
2025-03-06 21:06:15,608 - INFO - training batch 451, loss: 0.042, 14432/28000 datapoints
2025-03-06 21:06:15,732 - INFO - training batch 501, loss: 0.022, 16032/28000 datapoints
2025-03-06 21:06:15,855 - INFO - training batch 551, loss: 0.027, 17632/28000 datapoints
2025-03-06 21:06:15,976 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-06 21:06:16,098 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 21:06:16,222 - INFO - training batch 701, loss: 0.048, 22432/28000 datapoints
2025-03-06 21:06:16,357 - INFO - training batch 751, loss: 0.024, 24032/28000 datapoints
2025-03-06 21:06:16,478 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-06 21:06:16,601 - INFO - training batch 851, loss: 0.046, 27232/28000 datapoints
2025-03-06 21:06:16,665 - INFO - validation batch 1, loss: 0.771, 32/6976 datapoints
2025-03-06 21:06:16,710 - INFO - validation batch 51, loss: 2.507, 1632/6976 datapoints
2025-03-06 21:06:16,754 - INFO - validation batch 101, loss: 1.068, 3232/6976 datapoints
2025-03-06 21:06:16,804 - INFO - validation batch 151, loss: 0.615, 4832/6976 datapoints
2025-03-06 21:06:16,850 - INFO - validation batch 201, loss: 0.748, 6432/6976 datapoints
2025-03-06 21:06:16,865 - INFO - Epoch 714/800 done.
2025-03-06 21:06:16,866 - INFO - Final validation performance:
Loss: 1.142, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:16,866 - INFO - Beginning epoch 715/800
2025-03-06 21:06:16,870 - INFO - training batch 1, loss: 0.068, 32/28000 datapoints
2025-03-06 21:06:16,997 - INFO - training batch 51, loss: 0.026, 1632/28000 datapoints
2025-03-06 21:06:17,123 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-06 21:06:17,245 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-06 21:06:17,370 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:06:17,492 - INFO - training batch 251, loss: 0.052, 8032/28000 datapoints
2025-03-06 21:06:17,616 - INFO - training batch 301, loss: 0.048, 9632/28000 datapoints
2025-03-06 21:06:17,742 - INFO - training batch 351, loss: 0.061, 11232/28000 datapoints
2025-03-06 21:06:17,865 - INFO - training batch 401, loss: 0.084, 12832/28000 datapoints
2025-03-06 21:06:17,986 - INFO - training batch 451, loss: 0.041, 14432/28000 datapoints
2025-03-06 21:06:18,110 - INFO - training batch 501, loss: 0.023, 16032/28000 datapoints
2025-03-06 21:06:18,233 - INFO - training batch 551, loss: 0.027, 17632/28000 datapoints
2025-03-06 21:06:18,354 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-06 21:06:18,475 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 21:06:18,599 - INFO - training batch 701, loss: 0.048, 22432/28000 datapoints
2025-03-06 21:06:18,726 - INFO - training batch 751, loss: 0.024, 24032/28000 datapoints
2025-03-06 21:06:18,850 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-06 21:06:18,972 - INFO - training batch 851, loss: 0.045, 27232/28000 datapoints
2025-03-06 21:06:19,034 - INFO - validation batch 1, loss: 0.776, 32/6976 datapoints
2025-03-06 21:06:19,080 - INFO - validation batch 51, loss: 2.514, 1632/6976 datapoints
2025-03-06 21:06:19,124 - INFO - validation batch 101, loss: 1.071, 3232/6976 datapoints
2025-03-06 21:06:19,168 - INFO - validation batch 151, loss: 0.615, 4832/6976 datapoints
2025-03-06 21:06:19,212 - INFO - validation batch 201, loss: 0.747, 6432/6976 datapoints
2025-03-06 21:06:19,227 - INFO - Epoch 715/800 done.
2025-03-06 21:06:19,227 - INFO - Final validation performance:
Loss: 1.145, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:19,227 - INFO - Beginning epoch 716/800
2025-03-06 21:06:19,231 - INFO - training batch 1, loss: 0.067, 32/28000 datapoints
2025-03-06 21:06:19,357 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-06 21:06:19,477 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-06 21:06:19,602 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-06 21:06:19,727 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:06:19,849 - INFO - training batch 251, loss: 0.051, 8032/28000 datapoints
2025-03-06 21:06:19,971 - INFO - training batch 301, loss: 0.047, 9632/28000 datapoints
2025-03-06 21:06:20,094 - INFO - training batch 351, loss: 0.061, 11232/28000 datapoints
2025-03-06 21:06:20,227 - INFO - training batch 401, loss: 0.083, 12832/28000 datapoints
2025-03-06 21:06:20,369 - INFO - training batch 451, loss: 0.041, 14432/28000 datapoints
2025-03-06 21:06:20,494 - INFO - training batch 501, loss: 0.022, 16032/28000 datapoints
2025-03-06 21:06:20,617 - INFO - training batch 551, loss: 0.027, 17632/28000 datapoints
2025-03-06 21:06:20,741 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-06 21:06:20,863 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 21:06:20,984 - INFO - training batch 701, loss: 0.047, 22432/28000 datapoints
2025-03-06 21:06:21,107 - INFO - training batch 751, loss: 0.024, 24032/28000 datapoints
2025-03-06 21:06:21,229 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-06 21:06:21,356 - INFO - training batch 851, loss: 0.045, 27232/28000 datapoints
2025-03-06 21:06:21,416 - INFO - validation batch 1, loss: 0.779, 32/6976 datapoints
2025-03-06 21:06:21,462 - INFO - validation batch 51, loss: 2.521, 1632/6976 datapoints
2025-03-06 21:06:21,505 - INFO - validation batch 101, loss: 1.077, 3232/6976 datapoints
2025-03-06 21:06:21,549 - INFO - validation batch 151, loss: 0.620, 4832/6976 datapoints
2025-03-06 21:06:21,594 - INFO - validation batch 201, loss: 0.753, 6432/6976 datapoints
2025-03-06 21:06:21,609 - INFO - Epoch 716/800 done.
2025-03-06 21:06:21,610 - INFO - Final validation performance:
Loss: 1.150, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:21,610 - INFO - Beginning epoch 717/800
2025-03-06 21:06:21,613 - INFO - training batch 1, loss: 0.067, 32/28000 datapoints
2025-03-06 21:06:21,740 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-06 21:06:21,860 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-06 21:06:21,983 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-06 21:06:22,108 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:06:22,229 - INFO - training batch 251, loss: 0.051, 8032/28000 datapoints
2025-03-06 21:06:22,362 - INFO - training batch 301, loss: 0.047, 9632/28000 datapoints
2025-03-06 21:06:22,486 - INFO - training batch 351, loss: 0.060, 11232/28000 datapoints
2025-03-06 21:06:22,608 - INFO - training batch 401, loss: 0.083, 12832/28000 datapoints
2025-03-06 21:06:22,734 - INFO - training batch 451, loss: 0.040, 14432/28000 datapoints
2025-03-06 21:06:22,863 - INFO - training batch 501, loss: 0.022, 16032/28000 datapoints
2025-03-06 21:06:22,987 - INFO - training batch 551, loss: 0.027, 17632/28000 datapoints
2025-03-06 21:06:23,112 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-06 21:06:23,239 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 21:06:23,367 - INFO - training batch 701, loss: 0.047, 22432/28000 datapoints
2025-03-06 21:06:23,492 - INFO - training batch 751, loss: 0.023, 24032/28000 datapoints
2025-03-06 21:06:23,616 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-06 21:06:23,744 - INFO - training batch 851, loss: 0.044, 27232/28000 datapoints
2025-03-06 21:06:23,803 - INFO - validation batch 1, loss: 0.785, 32/6976 datapoints
2025-03-06 21:06:23,848 - INFO - validation batch 51, loss: 2.530, 1632/6976 datapoints
2025-03-06 21:06:23,893 - INFO - validation batch 101, loss: 1.079, 3232/6976 datapoints
2025-03-06 21:06:23,937 - INFO - validation batch 151, loss: 0.616, 4832/6976 datapoints
2025-03-06 21:06:23,981 - INFO - validation batch 201, loss: 0.753, 6432/6976 datapoints
2025-03-06 21:06:23,996 - INFO - Epoch 717/800 done.
2025-03-06 21:06:23,996 - INFO - Final validation performance:
Loss: 1.153, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:23,997 - INFO - Beginning epoch 718/800
2025-03-06 21:06:24,000 - INFO - training batch 1, loss: 0.066, 32/28000 datapoints
2025-03-06 21:06:24,128 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-06 21:06:24,251 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-06 21:06:24,373 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-06 21:06:24,493 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:06:24,615 - INFO - training batch 251, loss: 0.050, 8032/28000 datapoints
2025-03-06 21:06:24,745 - INFO - training batch 301, loss: 0.047, 9632/28000 datapoints
2025-03-06 21:06:24,869 - INFO - training batch 351, loss: 0.059, 11232/28000 datapoints
2025-03-06 21:06:24,997 - INFO - training batch 401, loss: 0.082, 12832/28000 datapoints
2025-03-06 21:06:25,120 - INFO - training batch 451, loss: 0.041, 14432/28000 datapoints
2025-03-06 21:06:25,245 - INFO - training batch 501, loss: 0.022, 16032/28000 datapoints
2025-03-06 21:06:25,372 - INFO - training batch 551, loss: 0.027, 17632/28000 datapoints
2025-03-06 21:06:25,494 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-06 21:06:25,615 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 21:06:25,743 - INFO - training batch 701, loss: 0.047, 22432/28000 datapoints
2025-03-06 21:06:25,863 - INFO - training batch 751, loss: 0.023, 24032/28000 datapoints
2025-03-06 21:06:25,986 - INFO - training batch 801, loss: 0.027, 25632/28000 datapoints
2025-03-06 21:06:26,108 - INFO - training batch 851, loss: 0.044, 27232/28000 datapoints
2025-03-06 21:06:26,169 - INFO - validation batch 1, loss: 0.787, 32/6976 datapoints
2025-03-06 21:06:26,213 - INFO - validation batch 51, loss: 2.537, 1632/6976 datapoints
2025-03-06 21:06:26,256 - INFO - validation batch 101, loss: 1.085, 3232/6976 datapoints
2025-03-06 21:06:26,300 - INFO - validation batch 151, loss: 0.616, 4832/6976 datapoints
2025-03-06 21:06:26,344 - INFO - validation batch 201, loss: 0.755, 6432/6976 datapoints
2025-03-06 21:06:26,360 - INFO - Epoch 718/800 done.
2025-03-06 21:06:26,360 - INFO - Final validation performance:
Loss: 1.156, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:26,360 - INFO - Beginning epoch 719/800
2025-03-06 21:06:26,364 - INFO - training batch 1, loss: 0.065, 32/28000 datapoints
2025-03-06 21:06:26,488 - INFO - training batch 51, loss: 0.024, 1632/28000 datapoints
2025-03-06 21:06:26,609 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-06 21:06:26,742 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-06 21:06:26,864 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:06:26,987 - INFO - training batch 251, loss: 0.050, 8032/28000 datapoints
2025-03-06 21:06:27,110 - INFO - training batch 301, loss: 0.046, 9632/28000 datapoints
2025-03-06 21:06:27,232 - INFO - training batch 351, loss: 0.059, 11232/28000 datapoints
2025-03-06 21:06:27,357 - INFO - training batch 401, loss: 0.081, 12832/28000 datapoints
2025-03-06 21:06:27,479 - INFO - training batch 451, loss: 0.039, 14432/28000 datapoints
2025-03-06 21:06:27,602 - INFO - training batch 501, loss: 0.021, 16032/28000 datapoints
2025-03-06 21:06:27,731 - INFO - training batch 551, loss: 0.026, 17632/28000 datapoints
2025-03-06 21:06:27,852 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-06 21:06:27,974 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 21:06:28,100 - INFO - training batch 701, loss: 0.047, 22432/28000 datapoints
2025-03-06 21:06:28,224 - INFO - training batch 751, loss: 0.023, 24032/28000 datapoints
2025-03-06 21:06:28,345 - INFO - training batch 801, loss: 0.027, 25632/28000 datapoints
2025-03-06 21:06:28,470 - INFO - training batch 851, loss: 0.043, 27232/28000 datapoints
2025-03-06 21:06:28,539 - INFO - validation batch 1, loss: 0.793, 32/6976 datapoints
2025-03-06 21:06:28,585 - INFO - validation batch 51, loss: 2.542, 1632/6976 datapoints
2025-03-06 21:06:28,628 - INFO - validation batch 101, loss: 1.090, 3232/6976 datapoints
2025-03-06 21:06:28,678 - INFO - validation batch 151, loss: 0.620, 4832/6976 datapoints
2025-03-06 21:06:28,721 - INFO - validation batch 201, loss: 0.760, 6432/6976 datapoints
2025-03-06 21:06:28,736 - INFO - Epoch 719/800 done.
2025-03-06 21:06:28,736 - INFO - Final validation performance:
Loss: 1.161, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:28,737 - INFO - Beginning epoch 720/800
2025-03-06 21:06:28,741 - INFO - training batch 1, loss: 0.064, 32/28000 datapoints
2025-03-06 21:06:28,868 - INFO - training batch 51, loss: 0.024, 1632/28000 datapoints
2025-03-06 21:06:28,989 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-06 21:06:29,114 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 21:06:29,238 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:06:29,359 - INFO - training batch 251, loss: 0.049, 8032/28000 datapoints
2025-03-06 21:06:29,486 - INFO - training batch 301, loss: 0.046, 9632/28000 datapoints
2025-03-06 21:06:29,607 - INFO - training batch 351, loss: 0.058, 11232/28000 datapoints
2025-03-06 21:06:29,754 - INFO - training batch 401, loss: 0.080, 12832/28000 datapoints
2025-03-06 21:06:29,894 - INFO - training batch 451, loss: 0.039, 14432/28000 datapoints
2025-03-06 21:06:30,044 - INFO - training batch 501, loss: 0.021, 16032/28000 datapoints
2025-03-06 21:06:30,200 - INFO - training batch 551, loss: 0.026, 17632/28000 datapoints
2025-03-06 21:06:30,389 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-06 21:06:30,520 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 21:06:30,645 - INFO - training batch 701, loss: 0.046, 22432/28000 datapoints
2025-03-06 21:06:30,777 - INFO - training batch 751, loss: 0.023, 24032/28000 datapoints
2025-03-06 21:06:30,899 - INFO - training batch 801, loss: 0.026, 25632/28000 datapoints
2025-03-06 21:06:31,019 - INFO - training batch 851, loss: 0.043, 27232/28000 datapoints
2025-03-06 21:06:31,080 - INFO - validation batch 1, loss: 0.796, 32/6976 datapoints
2025-03-06 21:06:31,124 - INFO - validation batch 51, loss: 2.549, 1632/6976 datapoints
2025-03-06 21:06:31,169 - INFO - validation batch 101, loss: 1.096, 3232/6976 datapoints
2025-03-06 21:06:31,223 - INFO - validation batch 151, loss: 0.621, 4832/6976 datapoints
2025-03-06 21:06:31,268 - INFO - validation batch 201, loss: 0.761, 6432/6976 datapoints
2025-03-06 21:06:31,285 - INFO - Epoch 720/800 done.
2025-03-06 21:06:31,285 - INFO - Final validation performance:
Loss: 1.165, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:31,285 - INFO - Beginning epoch 721/800
2025-03-06 21:06:31,289 - INFO - training batch 1, loss: 0.064, 32/28000 datapoints
2025-03-06 21:06:31,415 - INFO - training batch 51, loss: 0.024, 1632/28000 datapoints
2025-03-06 21:06:31,536 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-06 21:06:31,662 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 21:06:31,784 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:06:31,906 - INFO - training batch 251, loss: 0.049, 8032/28000 datapoints
2025-03-06 21:06:32,030 - INFO - training batch 301, loss: 0.045, 9632/28000 datapoints
2025-03-06 21:06:32,152 - INFO - training batch 351, loss: 0.057, 11232/28000 datapoints
2025-03-06 21:06:32,273 - INFO - training batch 401, loss: 0.079, 12832/28000 datapoints
2025-03-06 21:06:32,394 - INFO - training batch 451, loss: 0.039, 14432/28000 datapoints
2025-03-06 21:06:32,523 - INFO - training batch 501, loss: 0.021, 16032/28000 datapoints
2025-03-06 21:06:32,651 - INFO - training batch 551, loss: 0.026, 17632/28000 datapoints
2025-03-06 21:06:32,777 - INFO - training batch 601, loss: 0.031, 19232/28000 datapoints
2025-03-06 21:06:32,904 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 21:06:33,031 - INFO - training batch 701, loss: 0.045, 22432/28000 datapoints
2025-03-06 21:06:33,159 - INFO - training batch 751, loss: 0.022, 24032/28000 datapoints
2025-03-06 21:06:33,287 - INFO - training batch 801, loss: 0.027, 25632/28000 datapoints
2025-03-06 21:06:33,415 - INFO - training batch 851, loss: 0.042, 27232/28000 datapoints
2025-03-06 21:06:33,479 - INFO - validation batch 1, loss: 0.801, 32/6976 datapoints
2025-03-06 21:06:33,531 - INFO - validation batch 51, loss: 2.560, 1632/6976 datapoints
2025-03-06 21:06:33,577 - INFO - validation batch 101, loss: 1.100, 3232/6976 datapoints
2025-03-06 21:06:33,621 - INFO - validation batch 151, loss: 0.618, 4832/6976 datapoints
2025-03-06 21:06:33,669 - INFO - validation batch 201, loss: 0.764, 6432/6976 datapoints
2025-03-06 21:06:33,685 - INFO - Epoch 721/800 done.
2025-03-06 21:06:33,686 - INFO - Final validation performance:
Loss: 1.169, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:33,686 - INFO - Beginning epoch 722/800
2025-03-06 21:06:33,690 - INFO - training batch 1, loss: 0.063, 32/28000 datapoints
2025-03-06 21:06:33,815 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-06 21:06:33,935 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-06 21:06:34,062 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 21:06:34,184 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:06:34,306 - INFO - training batch 251, loss: 0.048, 8032/28000 datapoints
2025-03-06 21:06:34,427 - INFO - training batch 301, loss: 0.045, 9632/28000 datapoints
2025-03-06 21:06:34,559 - INFO - training batch 351, loss: 0.057, 11232/28000 datapoints
2025-03-06 21:06:34,687 - INFO - training batch 401, loss: 0.078, 12832/28000 datapoints
2025-03-06 21:06:34,810 - INFO - training batch 451, loss: 0.038, 14432/28000 datapoints
2025-03-06 21:06:34,939 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-06 21:06:35,062 - INFO - training batch 551, loss: 0.026, 17632/28000 datapoints
2025-03-06 21:06:35,197 - INFO - training batch 601, loss: 0.031, 19232/28000 datapoints
2025-03-06 21:06:35,324 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 21:06:35,451 - INFO - training batch 701, loss: 0.045, 22432/28000 datapoints
2025-03-06 21:06:35,576 - INFO - training batch 751, loss: 0.022, 24032/28000 datapoints
2025-03-06 21:06:35,700 - INFO - training batch 801, loss: 0.026, 25632/28000 datapoints
2025-03-06 21:06:35,822 - INFO - training batch 851, loss: 0.042, 27232/28000 datapoints
2025-03-06 21:06:35,882 - INFO - validation batch 1, loss: 0.806, 32/6976 datapoints
2025-03-06 21:06:35,925 - INFO - validation batch 51, loss: 2.568, 1632/6976 datapoints
2025-03-06 21:06:35,970 - INFO - validation batch 101, loss: 1.106, 3232/6976 datapoints
2025-03-06 21:06:36,013 - INFO - validation batch 151, loss: 0.624, 4832/6976 datapoints
2025-03-06 21:06:36,057 - INFO - validation batch 201, loss: 0.765, 6432/6976 datapoints
2025-03-06 21:06:36,073 - INFO - Epoch 722/800 done.
2025-03-06 21:06:36,073 - INFO - Final validation performance:
Loss: 1.174, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:36,073 - INFO - Beginning epoch 723/800
2025-03-06 21:06:36,077 - INFO - training batch 1, loss: 0.062, 32/28000 datapoints
2025-03-06 21:06:36,201 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-06 21:06:36,326 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 21:06:36,449 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 21:06:36,574 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:06:36,698 - INFO - training batch 251, loss: 0.048, 8032/28000 datapoints
2025-03-06 21:06:36,821 - INFO - training batch 301, loss: 0.044, 9632/28000 datapoints
2025-03-06 21:06:36,942 - INFO - training batch 351, loss: 0.056, 11232/28000 datapoints
2025-03-06 21:06:37,064 - INFO - training batch 401, loss: 0.077, 12832/28000 datapoints
2025-03-06 21:06:37,187 - INFO - training batch 451, loss: 0.038, 14432/28000 datapoints
2025-03-06 21:06:37,312 - INFO - training batch 501, loss: 0.021, 16032/28000 datapoints
2025-03-06 21:06:37,437 - INFO - training batch 551, loss: 0.026, 17632/28000 datapoints
2025-03-06 21:06:37,559 - INFO - training batch 601, loss: 0.031, 19232/28000 datapoints
2025-03-06 21:06:37,716 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-06 21:06:37,842 - INFO - training batch 701, loss: 0.044, 22432/28000 datapoints
2025-03-06 21:06:37,970 - INFO - training batch 751, loss: 0.022, 24032/28000 datapoints
2025-03-06 21:06:38,091 - INFO - training batch 801, loss: 0.026, 25632/28000 datapoints
2025-03-06 21:06:38,214 - INFO - training batch 851, loss: 0.041, 27232/28000 datapoints
2025-03-06 21:06:38,274 - INFO - validation batch 1, loss: 0.808, 32/6976 datapoints
2025-03-06 21:06:38,326 - INFO - validation batch 51, loss: 2.576, 1632/6976 datapoints
2025-03-06 21:06:38,370 - INFO - validation batch 101, loss: 1.108, 3232/6976 datapoints
2025-03-06 21:06:38,413 - INFO - validation batch 151, loss: 0.623, 4832/6976 datapoints
2025-03-06 21:06:38,457 - INFO - validation batch 201, loss: 0.771, 6432/6976 datapoints
2025-03-06 21:06:38,472 - INFO - Epoch 723/800 done.
2025-03-06 21:06:38,473 - INFO - Final validation performance:
Loss: 1.177, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:38,473 - INFO - Beginning epoch 724/800
2025-03-06 21:06:38,477 - INFO - training batch 1, loss: 0.061, 32/28000 datapoints
2025-03-06 21:06:38,605 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-06 21:06:38,728 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-06 21:06:38,853 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 21:06:38,975 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:06:39,101 - INFO - training batch 251, loss: 0.047, 8032/28000 datapoints
2025-03-06 21:06:39,226 - INFO - training batch 301, loss: 0.044, 9632/28000 datapoints
2025-03-06 21:06:39,348 - INFO - training batch 351, loss: 0.055, 11232/28000 datapoints
2025-03-06 21:06:39,473 - INFO - training batch 401, loss: 0.076, 12832/28000 datapoints
2025-03-06 21:06:39,595 - INFO - training batch 451, loss: 0.037, 14432/28000 datapoints
2025-03-06 21:06:39,722 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-06 21:06:39,844 - INFO - training batch 551, loss: 0.025, 17632/28000 datapoints
2025-03-06 21:06:39,965 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-06 21:06:40,098 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:06:40,221 - INFO - training batch 701, loss: 0.045, 22432/28000 datapoints
2025-03-06 21:06:40,345 - INFO - training batch 751, loss: 0.022, 24032/28000 datapoints
2025-03-06 21:06:40,494 - INFO - training batch 801, loss: 0.026, 25632/28000 datapoints
2025-03-06 21:06:40,620 - INFO - training batch 851, loss: 0.041, 27232/28000 datapoints
2025-03-06 21:06:40,691 - INFO - validation batch 1, loss: 0.813, 32/6976 datapoints
2025-03-06 21:06:40,745 - INFO - validation batch 51, loss: 2.582, 1632/6976 datapoints
2025-03-06 21:06:40,789 - INFO - validation batch 101, loss: 1.115, 3232/6976 datapoints
2025-03-06 21:06:40,835 - INFO - validation batch 151, loss: 0.623, 4832/6976 datapoints
2025-03-06 21:06:40,880 - INFO - validation batch 201, loss: 0.769, 6432/6976 datapoints
2025-03-06 21:06:40,895 - INFO - Epoch 724/800 done.
2025-03-06 21:06:40,895 - INFO - Final validation performance:
Loss: 1.180, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:40,896 - INFO - Beginning epoch 725/800
2025-03-06 21:06:40,899 - INFO - training batch 1, loss: 0.061, 32/28000 datapoints
2025-03-06 21:06:41,021 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-06 21:06:41,143 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 21:06:41,272 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 21:06:41,396 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:06:41,521 - INFO - training batch 251, loss: 0.047, 8032/28000 datapoints
2025-03-06 21:06:41,647 - INFO - training batch 301, loss: 0.043, 9632/28000 datapoints
2025-03-06 21:06:41,767 - INFO - training batch 351, loss: 0.054, 11232/28000 datapoints
2025-03-06 21:06:41,890 - INFO - training batch 401, loss: 0.075, 12832/28000 datapoints
2025-03-06 21:06:42,016 - INFO - training batch 451, loss: 0.037, 14432/28000 datapoints
2025-03-06 21:06:42,143 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-06 21:06:42,266 - INFO - training batch 551, loss: 0.026, 17632/28000 datapoints
2025-03-06 21:06:42,389 - INFO - training batch 601, loss: 0.031, 19232/28000 datapoints
2025-03-06 21:06:42,512 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:06:42,635 - INFO - training batch 701, loss: 0.044, 22432/28000 datapoints
2025-03-06 21:06:42,759 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-06 21:06:42,883 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-06 21:06:43,004 - INFO - training batch 851, loss: 0.040, 27232/28000 datapoints
2025-03-06 21:06:43,065 - INFO - validation batch 1, loss: 0.821, 32/6976 datapoints
2025-03-06 21:06:43,110 - INFO - validation batch 51, loss: 2.594, 1632/6976 datapoints
2025-03-06 21:06:43,154 - INFO - validation batch 101, loss: 1.118, 3232/6976 datapoints
2025-03-06 21:06:43,199 - INFO - validation batch 151, loss: 0.626, 4832/6976 datapoints
2025-03-06 21:06:43,243 - INFO - validation batch 201, loss: 0.775, 6432/6976 datapoints
2025-03-06 21:06:43,259 - INFO - Epoch 725/800 done.
2025-03-06 21:06:43,259 - INFO - Final validation performance:
Loss: 1.187, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:43,260 - INFO - Beginning epoch 726/800
2025-03-06 21:06:43,263 - INFO - training batch 1, loss: 0.060, 32/28000 datapoints
2025-03-06 21:06:43,391 - INFO - training batch 51, loss: 0.022, 1632/28000 datapoints
2025-03-06 21:06:43,515 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 21:06:43,645 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 21:06:43,766 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:06:43,888 - INFO - training batch 251, loss: 0.046, 8032/28000 datapoints
2025-03-06 21:06:44,012 - INFO - training batch 301, loss: 0.043, 9632/28000 datapoints
2025-03-06 21:06:44,137 - INFO - training batch 351, loss: 0.054, 11232/28000 datapoints
2025-03-06 21:06:44,259 - INFO - training batch 401, loss: 0.075, 12832/28000 datapoints
2025-03-06 21:06:44,384 - INFO - training batch 451, loss: 0.038, 14432/28000 datapoints
2025-03-06 21:06:44,508 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-06 21:06:44,629 - INFO - training batch 551, loss: 0.025, 17632/28000 datapoints
2025-03-06 21:06:44,752 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-06 21:06:44,879 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:06:45,005 - INFO - training batch 701, loss: 0.044, 22432/28000 datapoints
2025-03-06 21:06:45,129 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-06 21:06:45,254 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-06 21:06:45,378 - INFO - training batch 851, loss: 0.040, 27232/28000 datapoints
2025-03-06 21:06:45,442 - INFO - validation batch 1, loss: 0.822, 32/6976 datapoints
2025-03-06 21:06:45,486 - INFO - validation batch 51, loss: 2.599, 1632/6976 datapoints
2025-03-06 21:06:45,529 - INFO - validation batch 101, loss: 1.125, 3232/6976 datapoints
2025-03-06 21:06:45,574 - INFO - validation batch 151, loss: 0.625, 4832/6976 datapoints
2025-03-06 21:06:45,617 - INFO - validation batch 201, loss: 0.777, 6432/6976 datapoints
2025-03-06 21:06:45,632 - INFO - Epoch 726/800 done.
2025-03-06 21:06:45,632 - INFO - Final validation performance:
Loss: 1.190, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:45,633 - INFO - Beginning epoch 727/800
2025-03-06 21:06:45,638 - INFO - training batch 1, loss: 0.060, 32/28000 datapoints
2025-03-06 21:06:45,761 - INFO - training batch 51, loss: 0.022, 1632/28000 datapoints
2025-03-06 21:06:45,885 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 21:06:46,010 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 21:06:46,129 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:06:46,250 - INFO - training batch 251, loss: 0.046, 8032/28000 datapoints
2025-03-06 21:06:46,373 - INFO - training batch 301, loss: 0.043, 9632/28000 datapoints
2025-03-06 21:06:46,496 - INFO - training batch 351, loss: 0.054, 11232/28000 datapoints
2025-03-06 21:06:46,617 - INFO - training batch 401, loss: 0.075, 12832/28000 datapoints
2025-03-06 21:06:46,745 - INFO - training batch 451, loss: 0.037, 14432/28000 datapoints
2025-03-06 21:06:46,868 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-06 21:06:46,993 - INFO - training batch 551, loss: 0.025, 17632/28000 datapoints
2025-03-06 21:06:47,114 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-06 21:06:47,237 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:06:47,361 - INFO - training batch 701, loss: 0.043, 22432/28000 datapoints
2025-03-06 21:06:47,487 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-06 21:06:47,608 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-06 21:06:47,738 - INFO - training batch 851, loss: 0.039, 27232/28000 datapoints
2025-03-06 21:06:47,810 - INFO - validation batch 1, loss: 0.829, 32/6976 datapoints
2025-03-06 21:06:47,856 - INFO - validation batch 51, loss: 2.612, 1632/6976 datapoints
2025-03-06 21:06:47,899 - INFO - validation batch 101, loss: 1.128, 3232/6976 datapoints
2025-03-06 21:06:47,945 - INFO - validation batch 151, loss: 0.625, 4832/6976 datapoints
2025-03-06 21:06:47,989 - INFO - validation batch 201, loss: 0.778, 6432/6976 datapoints
2025-03-06 21:06:48,004 - INFO - Epoch 727/800 done.
2025-03-06 21:06:48,004 - INFO - Final validation performance:
Loss: 1.194, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:48,005 - INFO - Beginning epoch 728/800
2025-03-06 21:06:48,009 - INFO - training batch 1, loss: 0.059, 32/28000 datapoints
2025-03-06 21:06:48,133 - INFO - training batch 51, loss: 0.022, 1632/28000 datapoints
2025-03-06 21:06:48,255 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 21:06:48,381 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 21:06:48,506 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:06:48,631 - INFO - training batch 251, loss: 0.046, 8032/28000 datapoints
2025-03-06 21:06:48,755 - INFO - training batch 301, loss: 0.043, 9632/28000 datapoints
2025-03-06 21:06:48,876 - INFO - training batch 351, loss: 0.052, 11232/28000 datapoints
2025-03-06 21:06:48,997 - INFO - training batch 401, loss: 0.073, 12832/28000 datapoints
2025-03-06 21:06:49,122 - INFO - training batch 451, loss: 0.037, 14432/28000 datapoints
2025-03-06 21:06:49,254 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-06 21:06:49,394 - INFO - training batch 551, loss: 0.025, 17632/28000 datapoints
2025-03-06 21:06:49,521 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-06 21:06:49,648 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:06:49,789 - INFO - training batch 701, loss: 0.043, 22432/28000 datapoints
2025-03-06 21:06:49,910 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-06 21:06:50,038 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-06 21:06:50,162 - INFO - training batch 851, loss: 0.039, 27232/28000 datapoints
2025-03-06 21:06:50,223 - INFO - validation batch 1, loss: 0.832, 32/6976 datapoints
2025-03-06 21:06:50,267 - INFO - validation batch 51, loss: 2.618, 1632/6976 datapoints
2025-03-06 21:06:50,311 - INFO - validation batch 101, loss: 1.135, 3232/6976 datapoints
2025-03-06 21:06:50,356 - INFO - validation batch 151, loss: 0.628, 4832/6976 datapoints
2025-03-06 21:06:50,400 - INFO - validation batch 201, loss: 0.783, 6432/6976 datapoints
2025-03-06 21:06:50,414 - INFO - Epoch 728/800 done.
2025-03-06 21:06:50,415 - INFO - Final validation performance:
Loss: 1.199, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:50,415 - INFO - Beginning epoch 729/800
2025-03-06 21:06:50,419 - INFO - training batch 1, loss: 0.058, 32/28000 datapoints
2025-03-06 21:06:50,560 - INFO - training batch 51, loss: 0.021, 1632/28000 datapoints
2025-03-06 21:06:50,700 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 21:06:50,825 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 21:06:50,951 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:06:51,075 - INFO - training batch 251, loss: 0.045, 8032/28000 datapoints
2025-03-06 21:06:51,199 - INFO - training batch 301, loss: 0.042, 9632/28000 datapoints
2025-03-06 21:06:51,337 - INFO - training batch 351, loss: 0.052, 11232/28000 datapoints
2025-03-06 21:06:51,465 - INFO - training batch 401, loss: 0.073, 12832/28000 datapoints
2025-03-06 21:06:51,590 - INFO - training batch 451, loss: 0.036, 14432/28000 datapoints
2025-03-06 21:06:51,715 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-06 21:06:51,840 - INFO - training batch 551, loss: 0.024, 17632/28000 datapoints
2025-03-06 21:06:51,967 - INFO - training batch 601, loss: 0.031, 19232/28000 datapoints
2025-03-06 21:06:52,090 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:06:52,217 - INFO - training batch 701, loss: 0.042, 22432/28000 datapoints
2025-03-06 21:06:52,340 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-06 21:06:52,462 - INFO - training batch 801, loss: 0.024, 25632/28000 datapoints
2025-03-06 21:06:52,595 - INFO - training batch 851, loss: 0.038, 27232/28000 datapoints
2025-03-06 21:06:52,661 - INFO - validation batch 1, loss: 0.837, 32/6976 datapoints
2025-03-06 21:06:52,709 - INFO - validation batch 51, loss: 2.628, 1632/6976 datapoints
2025-03-06 21:06:52,754 - INFO - validation batch 101, loss: 1.139, 3232/6976 datapoints
2025-03-06 21:06:52,802 - INFO - validation batch 151, loss: 0.627, 4832/6976 datapoints
2025-03-06 21:06:52,847 - INFO - validation batch 201, loss: 0.784, 6432/6976 datapoints
2025-03-06 21:06:52,863 - INFO - Epoch 729/800 done.
2025-03-06 21:06:52,863 - INFO - Final validation performance:
Loss: 1.203, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:06:52,864 - INFO - Beginning epoch 730/800
2025-03-06 21:06:52,867 - INFO - training batch 1, loss: 0.058, 32/28000 datapoints
2025-03-06 21:06:53,005 - INFO - training batch 51, loss: 0.021, 1632/28000 datapoints
2025-03-06 21:06:53,132 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 21:06:53,259 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 21:06:53,386 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:06:53,518 - INFO - training batch 251, loss: 0.044, 8032/28000 datapoints
2025-03-06 21:06:53,651 - INFO - training batch 301, loss: 0.041, 9632/28000 datapoints
2025-03-06 21:06:53,779 - INFO - training batch 351, loss: 0.051, 11232/28000 datapoints
2025-03-06 21:06:53,907 - INFO - training batch 401, loss: 0.071, 12832/28000 datapoints
2025-03-06 21:06:54,036 - INFO - training batch 451, loss: 0.036, 14432/28000 datapoints
2025-03-06 21:06:54,162 - INFO - training batch 501, loss: 0.019, 16032/28000 datapoints
2025-03-06 21:06:54,290 - INFO - training batch 551, loss: 0.024, 17632/28000 datapoints
2025-03-06 21:06:54,416 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 21:06:54,544 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:06:54,672 - INFO - training batch 701, loss: 0.042, 22432/28000 datapoints
2025-03-06 21:06:54,799 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-06 21:06:54,929 - INFO - training batch 801, loss: 0.024, 25632/28000 datapoints
2025-03-06 21:06:55,056 - INFO - training batch 851, loss: 0.038, 27232/28000 datapoints
2025-03-06 21:06:55,132 - INFO - validation batch 1, loss: 0.841, 32/6976 datapoints
2025-03-06 21:06:55,183 - INFO - validation batch 51, loss: 2.635, 1632/6976 datapoints
2025-03-06 21:06:55,231 - INFO - validation batch 101, loss: 1.146, 3232/6976 datapoints
2025-03-06 21:06:55,280 - INFO - validation batch 151, loss: 0.628, 4832/6976 datapoints
2025-03-06 21:06:55,326 - INFO - validation batch 201, loss: 0.792, 6432/6976 datapoints
2025-03-06 21:06:55,341 - INFO - Epoch 730/800 done.
2025-03-06 21:06:55,341 - INFO - Final validation performance:
Loss: 1.208, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:06:55,341 - INFO - Beginning epoch 731/800
2025-03-06 21:06:55,345 - INFO - training batch 1, loss: 0.057, 32/28000 datapoints
2025-03-06 21:06:55,472 - INFO - training batch 51, loss: 0.021, 1632/28000 datapoints
2025-03-06 21:06:55,600 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 21:06:55,727 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 21:06:55,851 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:06:55,972 - INFO - training batch 251, loss: 0.044, 8032/28000 datapoints
2025-03-06 21:06:56,097 - INFO - training batch 301, loss: 0.041, 9632/28000 datapoints
2025-03-06 21:06:56,256 - INFO - training batch 351, loss: 0.051, 11232/28000 datapoints
2025-03-06 21:06:56,393 - INFO - training batch 401, loss: 0.071, 12832/28000 datapoints
2025-03-06 21:06:56,517 - INFO - training batch 451, loss: 0.035, 14432/28000 datapoints
2025-03-06 21:06:56,645 - INFO - training batch 501, loss: 0.019, 16032/28000 datapoints
2025-03-06 21:06:56,767 - INFO - training batch 551, loss: 0.024, 17632/28000 datapoints
2025-03-06 21:06:56,889 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-06 21:06:57,014 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:06:57,139 - INFO - training batch 701, loss: 0.041, 22432/28000 datapoints
2025-03-06 21:06:57,269 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-06 21:06:57,391 - INFO - training batch 801, loss: 0.024, 25632/28000 datapoints
2025-03-06 21:06:57,522 - INFO - training batch 851, loss: 0.037, 27232/28000 datapoints
2025-03-06 21:06:57,586 - INFO - validation batch 1, loss: 0.847, 32/6976 datapoints
2025-03-06 21:06:57,631 - INFO - validation batch 51, loss: 2.647, 1632/6976 datapoints
2025-03-06 21:06:57,680 - INFO - validation batch 101, loss: 1.149, 3232/6976 datapoints
2025-03-06 21:06:57,724 - INFO - validation batch 151, loss: 0.629, 4832/6976 datapoints
2025-03-06 21:06:57,768 - INFO - validation batch 201, loss: 0.792, 6432/6976 datapoints
2025-03-06 21:06:57,784 - INFO - Epoch 731/800 done.
2025-03-06 21:06:57,784 - INFO - Final validation performance:
Loss: 1.213, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:06:57,784 - INFO - Beginning epoch 732/800
2025-03-06 21:06:57,788 - INFO - training batch 1, loss: 0.056, 32/28000 datapoints
2025-03-06 21:06:57,913 - INFO - training batch 51, loss: 0.021, 1632/28000 datapoints
2025-03-06 21:06:58,038 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 21:06:58,166 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 21:06:58,292 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:06:58,417 - INFO - training batch 251, loss: 0.043, 8032/28000 datapoints
2025-03-06 21:06:58,545 - INFO - training batch 301, loss: 0.041, 9632/28000 datapoints
2025-03-06 21:06:58,674 - INFO - training batch 351, loss: 0.050, 11232/28000 datapoints
2025-03-06 21:06:58,797 - INFO - training batch 401, loss: 0.070, 12832/28000 datapoints
2025-03-06 21:06:58,920 - INFO - training batch 451, loss: 0.035, 14432/28000 datapoints
2025-03-06 21:06:59,046 - INFO - training batch 501, loss: 0.019, 16032/28000 datapoints
2025-03-06 21:06:59,170 - INFO - training batch 551, loss: 0.024, 17632/28000 datapoints
2025-03-06 21:06:59,296 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 21:06:59,421 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:06:59,551 - INFO - training batch 701, loss: 0.041, 22432/28000 datapoints
2025-03-06 21:06:59,677 - INFO - training batch 751, loss: 0.020, 24032/28000 datapoints
2025-03-06 21:06:59,800 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-06 21:06:59,923 - INFO - training batch 851, loss: 0.036, 27232/28000 datapoints
2025-03-06 21:06:59,984 - INFO - validation batch 1, loss: 0.851, 32/6976 datapoints
2025-03-06 21:07:00,030 - INFO - validation batch 51, loss: 2.654, 1632/6976 datapoints
2025-03-06 21:07:00,075 - INFO - validation batch 101, loss: 1.154, 3232/6976 datapoints
2025-03-06 21:07:00,120 - INFO - validation batch 151, loss: 0.628, 4832/6976 datapoints
2025-03-06 21:07:00,164 - INFO - validation batch 201, loss: 0.796, 6432/6976 datapoints
2025-03-06 21:07:00,179 - INFO - Epoch 732/800 done.
2025-03-06 21:07:00,179 - INFO - Final validation performance:
Loss: 1.217, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:00,180 - INFO - Beginning epoch 733/800
2025-03-06 21:07:00,184 - INFO - training batch 1, loss: 0.056, 32/28000 datapoints
2025-03-06 21:07:00,309 - INFO - training batch 51, loss: 0.021, 1632/28000 datapoints
2025-03-06 21:07:00,432 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 21:07:00,559 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 21:07:00,714 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:07:00,840 - INFO - training batch 251, loss: 0.043, 8032/28000 datapoints
2025-03-06 21:07:00,965 - INFO - training batch 301, loss: 0.040, 9632/28000 datapoints
2025-03-06 21:07:01,088 - INFO - training batch 351, loss: 0.050, 11232/28000 datapoints
2025-03-06 21:07:01,208 - INFO - training batch 401, loss: 0.070, 12832/28000 datapoints
2025-03-06 21:07:01,333 - INFO - training batch 451, loss: 0.035, 14432/28000 datapoints
2025-03-06 21:07:01,457 - INFO - training batch 501, loss: 0.019, 16032/28000 datapoints
2025-03-06 21:07:01,585 - INFO - training batch 551, loss: 0.024, 17632/28000 datapoints
2025-03-06 21:07:01,713 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-06 21:07:01,835 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:07:01,958 - INFO - training batch 701, loss: 0.040, 22432/28000 datapoints
2025-03-06 21:07:02,080 - INFO - training batch 751, loss: 0.020, 24032/28000 datapoints
2025-03-06 21:07:02,204 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-06 21:07:02,327 - INFO - training batch 851, loss: 0.037, 27232/28000 datapoints
2025-03-06 21:07:02,388 - INFO - validation batch 1, loss: 0.856, 32/6976 datapoints
2025-03-06 21:07:02,433 - INFO - validation batch 51, loss: 2.661, 1632/6976 datapoints
2025-03-06 21:07:02,478 - INFO - validation batch 101, loss: 1.162, 3232/6976 datapoints
2025-03-06 21:07:02,522 - INFO - validation batch 151, loss: 0.631, 4832/6976 datapoints
2025-03-06 21:07:02,565 - INFO - validation batch 201, loss: 0.797, 6432/6976 datapoints
2025-03-06 21:07:02,580 - INFO - Epoch 733/800 done.
2025-03-06 21:07:02,581 - INFO - Final validation performance:
Loss: 1.222, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:02,581 - INFO - Beginning epoch 734/800
2025-03-06 21:07:02,585 - INFO - training batch 1, loss: 0.054, 32/28000 datapoints
2025-03-06 21:07:02,713 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-06 21:07:02,835 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 21:07:02,959 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 21:07:03,082 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:07:03,212 - INFO - training batch 251, loss: 0.043, 8032/28000 datapoints
2025-03-06 21:07:03,336 - INFO - training batch 301, loss: 0.040, 9632/28000 datapoints
2025-03-06 21:07:03,459 - INFO - training batch 351, loss: 0.049, 11232/28000 datapoints
2025-03-06 21:07:03,585 - INFO - training batch 401, loss: 0.068, 12832/28000 datapoints
2025-03-06 21:07:03,714 - INFO - training batch 451, loss: 0.034, 14432/28000 datapoints
2025-03-06 21:07:03,838 - INFO - training batch 501, loss: 0.018, 16032/28000 datapoints
2025-03-06 21:07:03,961 - INFO - training batch 551, loss: 0.024, 17632/28000 datapoints
2025-03-06 21:07:04,085 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 21:07:04,211 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:07:04,335 - INFO - training batch 701, loss: 0.040, 22432/28000 datapoints
2025-03-06 21:07:04,459 - INFO - training batch 751, loss: 0.020, 24032/28000 datapoints
2025-03-06 21:07:04,582 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-06 21:07:04,709 - INFO - training batch 851, loss: 0.036, 27232/28000 datapoints
2025-03-06 21:07:04,771 - INFO - validation batch 1, loss: 0.858, 32/6976 datapoints
2025-03-06 21:07:04,816 - INFO - validation batch 51, loss: 2.668, 1632/6976 datapoints
2025-03-06 21:07:04,861 - INFO - validation batch 101, loss: 1.167, 3232/6976 datapoints
2025-03-06 21:07:04,912 - INFO - validation batch 151, loss: 0.635, 4832/6976 datapoints
2025-03-06 21:07:04,957 - INFO - validation batch 201, loss: 0.804, 6432/6976 datapoints
2025-03-06 21:07:04,972 - INFO - Epoch 734/800 done.
2025-03-06 21:07:04,972 - INFO - Final validation performance:
Loss: 1.226, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:04,973 - INFO - Beginning epoch 735/800
2025-03-06 21:07:04,976 - INFO - training batch 1, loss: 0.054, 32/28000 datapoints
2025-03-06 21:07:05,104 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-06 21:07:05,231 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 21:07:05,351 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 21:07:05,481 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:07:05,610 - INFO - training batch 251, loss: 0.042, 8032/28000 datapoints
2025-03-06 21:07:05,737 - INFO - training batch 301, loss: 0.040, 9632/28000 datapoints
2025-03-06 21:07:05,858 - INFO - training batch 351, loss: 0.049, 11232/28000 datapoints
2025-03-06 21:07:05,980 - INFO - training batch 401, loss: 0.068, 12832/28000 datapoints
2025-03-06 21:07:06,102 - INFO - training batch 451, loss: 0.034, 14432/28000 datapoints
2025-03-06 21:07:06,226 - INFO - training batch 501, loss: 0.019, 16032/28000 datapoints
2025-03-06 21:07:06,349 - INFO - training batch 551, loss: 0.024, 17632/28000 datapoints
2025-03-06 21:07:06,472 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 21:07:06,596 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:07:06,723 - INFO - training batch 701, loss: 0.039, 22432/28000 datapoints
2025-03-06 21:07:06,845 - INFO - training batch 751, loss: 0.020, 24032/28000 datapoints
2025-03-06 21:07:06,965 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-06 21:07:07,087 - INFO - training batch 851, loss: 0.036, 27232/28000 datapoints
2025-03-06 21:07:07,149 - INFO - validation batch 1, loss: 0.863, 32/6976 datapoints
2025-03-06 21:07:07,192 - INFO - validation batch 51, loss: 2.680, 1632/6976 datapoints
2025-03-06 21:07:07,236 - INFO - validation batch 101, loss: 1.172, 3232/6976 datapoints
2025-03-06 21:07:07,279 - INFO - validation batch 151, loss: 0.629, 4832/6976 datapoints
2025-03-06 21:07:07,323 - INFO - validation batch 201, loss: 0.805, 6432/6976 datapoints
2025-03-06 21:07:07,338 - INFO - Epoch 735/800 done.
2025-03-06 21:07:07,338 - INFO - Final validation performance:
Loss: 1.230, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:07,339 - INFO - Beginning epoch 736/800
2025-03-06 21:07:07,343 - INFO - training batch 1, loss: 0.054, 32/28000 datapoints
2025-03-06 21:07:07,469 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-06 21:07:07,594 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 21:07:07,728 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 21:07:07,851 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:07:07,976 - INFO - training batch 251, loss: 0.042, 8032/28000 datapoints
2025-03-06 21:07:08,102 - INFO - training batch 301, loss: 0.039, 9632/28000 datapoints
2025-03-06 21:07:08,226 - INFO - training batch 351, loss: 0.048, 11232/28000 datapoints
2025-03-06 21:07:08,347 - INFO - training batch 401, loss: 0.067, 12832/28000 datapoints
2025-03-06 21:07:08,471 - INFO - training batch 451, loss: 0.034, 14432/28000 datapoints
2025-03-06 21:07:08,604 - INFO - training batch 501, loss: 0.018, 16032/28000 datapoints
2025-03-06 21:07:08,733 - INFO - training batch 551, loss: 0.023, 17632/28000 datapoints
2025-03-06 21:07:08,874 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 21:07:09,016 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:07:09,155 - INFO - training batch 701, loss: 0.040, 22432/28000 datapoints
2025-03-06 21:07:09,297 - INFO - training batch 751, loss: 0.020, 24032/28000 datapoints
2025-03-06 21:07:09,420 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-06 21:07:09,551 - INFO - training batch 851, loss: 0.035, 27232/28000 datapoints
2025-03-06 21:07:09,613 - INFO - validation batch 1, loss: 0.871, 32/6976 datapoints
2025-03-06 21:07:09,662 - INFO - validation batch 51, loss: 2.691, 1632/6976 datapoints
2025-03-06 21:07:09,706 - INFO - validation batch 101, loss: 1.179, 3232/6976 datapoints
2025-03-06 21:07:09,751 - INFO - validation batch 151, loss: 0.631, 4832/6976 datapoints
2025-03-06 21:07:09,794 - INFO - validation batch 201, loss: 0.806, 6432/6976 datapoints
2025-03-06 21:07:09,809 - INFO - Epoch 736/800 done.
2025-03-06 21:07:09,810 - INFO - Final validation performance:
Loss: 1.235, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:09,810 - INFO - Beginning epoch 737/800
2025-03-06 21:07:09,814 - INFO - training batch 1, loss: 0.053, 32/28000 datapoints
2025-03-06 21:07:09,950 - INFO - training batch 51, loss: 0.019, 1632/28000 datapoints
2025-03-06 21:07:10,074 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 21:07:10,202 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 21:07:10,325 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:07:10,448 - INFO - training batch 251, loss: 0.041, 8032/28000 datapoints
2025-03-06 21:07:10,573 - INFO - training batch 301, loss: 0.039, 9632/28000 datapoints
2025-03-06 21:07:10,701 - INFO - training batch 351, loss: 0.047, 11232/28000 datapoints
2025-03-06 21:07:10,852 - INFO - training batch 401, loss: 0.067, 12832/28000 datapoints
2025-03-06 21:07:10,977 - INFO - training batch 451, loss: 0.033, 14432/28000 datapoints
2025-03-06 21:07:11,102 - INFO - training batch 501, loss: 0.018, 16032/28000 datapoints
2025-03-06 21:07:11,230 - INFO - training batch 551, loss: 0.023, 17632/28000 datapoints
2025-03-06 21:07:11,354 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 21:07:11,477 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:07:11,604 - INFO - training batch 701, loss: 0.039, 22432/28000 datapoints
2025-03-06 21:07:11,730 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-06 21:07:11,851 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-06 21:07:11,974 - INFO - training batch 851, loss: 0.035, 27232/28000 datapoints
2025-03-06 21:07:12,034 - INFO - validation batch 1, loss: 0.875, 32/6976 datapoints
2025-03-06 21:07:12,078 - INFO - validation batch 51, loss: 2.698, 1632/6976 datapoints
2025-03-06 21:07:12,122 - INFO - validation batch 101, loss: 1.183, 3232/6976 datapoints
2025-03-06 21:07:12,165 - INFO - validation batch 151, loss: 0.632, 4832/6976 datapoints
2025-03-06 21:07:12,211 - INFO - validation batch 201, loss: 0.808, 6432/6976 datapoints
2025-03-06 21:07:12,226 - INFO - Epoch 737/800 done.
2025-03-06 21:07:12,226 - INFO - Final validation performance:
Loss: 1.239, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:07:12,227 - INFO - Beginning epoch 738/800
2025-03-06 21:07:12,230 - INFO - training batch 1, loss: 0.052, 32/28000 datapoints
2025-03-06 21:07:12,354 - INFO - training batch 51, loss: 0.019, 1632/28000 datapoints
2025-03-06 21:07:12,480 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 21:07:12,610 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 21:07:12,740 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:07:12,866 - INFO - training batch 251, loss: 0.041, 8032/28000 datapoints
2025-03-06 21:07:12,994 - INFO - training batch 301, loss: 0.038, 9632/28000 datapoints
2025-03-06 21:07:13,121 - INFO - training batch 351, loss: 0.047, 11232/28000 datapoints
2025-03-06 21:07:13,250 - INFO - training batch 401, loss: 0.065, 12832/28000 datapoints
2025-03-06 21:07:13,375 - INFO - training batch 451, loss: 0.033, 14432/28000 datapoints
2025-03-06 21:07:13,503 - INFO - training batch 501, loss: 0.018, 16032/28000 datapoints
2025-03-06 21:07:13,638 - INFO - training batch 551, loss: 0.023, 17632/28000 datapoints
2025-03-06 21:07:13,771 - INFO - training batch 601, loss: 0.028, 19232/28000 datapoints
2025-03-06 21:07:13,899 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:07:14,028 - INFO - training batch 701, loss: 0.038, 22432/28000 datapoints
2025-03-06 21:07:14,155 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-06 21:07:14,284 - INFO - training batch 801, loss: 0.021, 25632/28000 datapoints
2025-03-06 21:07:14,411 - INFO - training batch 851, loss: 0.035, 27232/28000 datapoints
2025-03-06 21:07:14,475 - INFO - validation batch 1, loss: 0.880, 32/6976 datapoints
2025-03-06 21:07:14,525 - INFO - validation batch 51, loss: 2.706, 1632/6976 datapoints
2025-03-06 21:07:14,574 - INFO - validation batch 101, loss: 1.190, 3232/6976 datapoints
2025-03-06 21:07:14,621 - INFO - validation batch 151, loss: 0.636, 4832/6976 datapoints
2025-03-06 21:07:14,671 - INFO - validation batch 201, loss: 0.812, 6432/6976 datapoints
2025-03-06 21:07:14,689 - INFO - Epoch 738/800 done.
2025-03-06 21:07:14,689 - INFO - Final validation performance:
Loss: 1.245, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:14,689 - INFO - Beginning epoch 739/800
2025-03-06 21:07:14,693 - INFO - training batch 1, loss: 0.052, 32/28000 datapoints
2025-03-06 21:07:14,825 - INFO - training batch 51, loss: 0.019, 1632/28000 datapoints
2025-03-06 21:07:14,956 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 21:07:15,084 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 21:07:15,210 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:07:15,337 - INFO - training batch 251, loss: 0.041, 8032/28000 datapoints
2025-03-06 21:07:15,466 - INFO - training batch 301, loss: 0.038, 9632/28000 datapoints
2025-03-06 21:07:15,594 - INFO - training batch 351, loss: 0.046, 11232/28000 datapoints
2025-03-06 21:07:15,723 - INFO - training batch 401, loss: 0.064, 12832/28000 datapoints
2025-03-06 21:07:15,853 - INFO - training batch 451, loss: 0.033, 14432/28000 datapoints
2025-03-06 21:07:15,979 - INFO - training batch 501, loss: 0.018, 16032/28000 datapoints
2025-03-06 21:07:16,106 - INFO - training batch 551, loss: 0.023, 17632/28000 datapoints
2025-03-06 21:07:16,231 - INFO - training batch 601, loss: 0.028, 19232/28000 datapoints
2025-03-06 21:07:16,359 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:07:16,487 - INFO - training batch 701, loss: 0.038, 22432/28000 datapoints
2025-03-06 21:07:16,614 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-06 21:07:16,743 - INFO - training batch 801, loss: 0.021, 25632/28000 datapoints
2025-03-06 21:07:16,871 - INFO - training batch 851, loss: 0.034, 27232/28000 datapoints
2025-03-06 21:07:16,936 - INFO - validation batch 1, loss: 0.882, 32/6976 datapoints
2025-03-06 21:07:16,983 - INFO - validation batch 51, loss: 2.714, 1632/6976 datapoints
2025-03-06 21:07:17,029 - INFO - validation batch 101, loss: 1.194, 3232/6976 datapoints
2025-03-06 21:07:17,073 - INFO - validation batch 151, loss: 0.634, 4832/6976 datapoints
2025-03-06 21:07:17,116 - INFO - validation batch 201, loss: 0.816, 6432/6976 datapoints
2025-03-06 21:07:17,131 - INFO - Epoch 739/800 done.
2025-03-06 21:07:17,132 - INFO - Final validation performance:
Loss: 1.248, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:17,132 - INFO - Beginning epoch 740/800
2025-03-06 21:07:17,136 - INFO - training batch 1, loss: 0.051, 32/28000 datapoints
2025-03-06 21:07:17,262 - INFO - training batch 51, loss: 0.019, 1632/28000 datapoints
2025-03-06 21:07:17,390 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 21:07:17,516 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 21:07:17,645 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:07:17,771 - INFO - training batch 251, loss: 0.040, 8032/28000 datapoints
2025-03-06 21:07:17,897 - INFO - training batch 301, loss: 0.038, 9632/28000 datapoints
2025-03-06 21:07:18,019 - INFO - training batch 351, loss: 0.045, 11232/28000 datapoints
2025-03-06 21:07:18,141 - INFO - training batch 401, loss: 0.064, 12832/28000 datapoints
2025-03-06 21:07:18,265 - INFO - training batch 451, loss: 0.032, 14432/28000 datapoints
2025-03-06 21:07:18,389 - INFO - training batch 501, loss: 0.018, 16032/28000 datapoints
2025-03-06 21:07:18,512 - INFO - training batch 551, loss: 0.023, 17632/28000 datapoints
2025-03-06 21:07:18,634 - INFO - training batch 601, loss: 0.028, 19232/28000 datapoints
2025-03-06 21:07:18,758 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-06 21:07:18,884 - INFO - training batch 701, loss: 0.037, 22432/28000 datapoints
2025-03-06 21:07:19,006 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-06 21:07:19,129 - INFO - training batch 801, loss: 0.020, 25632/28000 datapoints
2025-03-06 21:07:19,252 - INFO - training batch 851, loss: 0.034, 27232/28000 datapoints
2025-03-06 21:07:19,316 - INFO - validation batch 1, loss: 0.888, 32/6976 datapoints
2025-03-06 21:07:19,359 - INFO - validation batch 51, loss: 2.725, 1632/6976 datapoints
2025-03-06 21:07:19,402 - INFO - validation batch 101, loss: 1.200, 3232/6976 datapoints
2025-03-06 21:07:19,445 - INFO - validation batch 151, loss: 0.637, 4832/6976 datapoints
2025-03-06 21:07:19,490 - INFO - validation batch 201, loss: 0.817, 6432/6976 datapoints
2025-03-06 21:07:19,505 - INFO - Epoch 740/800 done.
2025-03-06 21:07:19,505 - INFO - Final validation performance:
Loss: 1.253, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:07:19,506 - INFO - Beginning epoch 741/800
2025-03-06 21:07:19,509 - INFO - training batch 1, loss: 0.051, 32/28000 datapoints
2025-03-06 21:07:19,639 - INFO - training batch 51, loss: 0.019, 1632/28000 datapoints
2025-03-06 21:07:19,764 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 21:07:19,907 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 21:07:20,032 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:07:20,154 - INFO - training batch 251, loss: 0.040, 8032/28000 datapoints
2025-03-06 21:07:20,278 - INFO - training batch 301, loss: 0.037, 9632/28000 datapoints
2025-03-06 21:07:20,404 - INFO - training batch 351, loss: 0.045, 11232/28000 datapoints
2025-03-06 21:07:20,527 - INFO - training batch 401, loss: 0.063, 12832/28000 datapoints
2025-03-06 21:07:20,653 - INFO - training batch 451, loss: 0.032, 14432/28000 datapoints
2025-03-06 21:07:20,775 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-06 21:07:20,922 - INFO - training batch 551, loss: 0.022, 17632/28000 datapoints
2025-03-06 21:07:21,047 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 21:07:21,170 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:21,294 - INFO - training batch 701, loss: 0.037, 22432/28000 datapoints
2025-03-06 21:07:21,417 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-06 21:07:21,540 - INFO - training batch 801, loss: 0.019, 25632/28000 datapoints
2025-03-06 21:07:21,672 - INFO - training batch 851, loss: 0.033, 27232/28000 datapoints
2025-03-06 21:07:21,733 - INFO - validation batch 1, loss: 0.893, 32/6976 datapoints
2025-03-06 21:07:21,776 - INFO - validation batch 51, loss: 2.736, 1632/6976 datapoints
2025-03-06 21:07:21,820 - INFO - validation batch 101, loss: 1.209, 3232/6976 datapoints
2025-03-06 21:07:21,865 - INFO - validation batch 151, loss: 0.639, 4832/6976 datapoints
2025-03-06 21:07:21,909 - INFO - validation batch 201, loss: 0.821, 6432/6976 datapoints
2025-03-06 21:07:21,924 - INFO - Epoch 741/800 done.
2025-03-06 21:07:21,924 - INFO - Final validation performance:
Loss: 1.259, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:21,925 - INFO - Beginning epoch 742/800
2025-03-06 21:07:21,928 - INFO - training batch 1, loss: 0.050, 32/28000 datapoints
2025-03-06 21:07:22,052 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-06 21:07:22,174 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 21:07:22,297 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 21:07:22,422 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:07:22,545 - INFO - training batch 251, loss: 0.039, 8032/28000 datapoints
2025-03-06 21:07:22,672 - INFO - training batch 301, loss: 0.037, 9632/28000 datapoints
2025-03-06 21:07:22,794 - INFO - training batch 351, loss: 0.043, 11232/28000 datapoints
2025-03-06 21:07:22,918 - INFO - training batch 401, loss: 0.063, 12832/28000 datapoints
2025-03-06 21:07:23,042 - INFO - training batch 451, loss: 0.032, 14432/28000 datapoints
2025-03-06 21:07:23,166 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-06 21:07:23,289 - INFO - training batch 551, loss: 0.022, 17632/28000 datapoints
2025-03-06 21:07:23,417 - INFO - training batch 601, loss: 0.028, 19232/28000 datapoints
2025-03-06 21:07:23,541 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:23,673 - INFO - training batch 701, loss: 0.036, 22432/28000 datapoints
2025-03-06 21:07:23,797 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-06 21:07:23,920 - INFO - training batch 801, loss: 0.019, 25632/28000 datapoints
2025-03-06 21:07:24,043 - INFO - training batch 851, loss: 0.033, 27232/28000 datapoints
2025-03-06 21:07:24,104 - INFO - validation batch 1, loss: 0.900, 32/6976 datapoints
2025-03-06 21:07:24,147 - INFO - validation batch 51, loss: 2.746, 1632/6976 datapoints
2025-03-06 21:07:24,191 - INFO - validation batch 101, loss: 1.210, 3232/6976 datapoints
2025-03-06 21:07:24,235 - INFO - validation batch 151, loss: 0.636, 4832/6976 datapoints
2025-03-06 21:07:24,279 - INFO - validation batch 201, loss: 0.821, 6432/6976 datapoints
2025-03-06 21:07:24,295 - INFO - Epoch 742/800 done.
2025-03-06 21:07:24,295 - INFO - Final validation performance:
Loss: 1.263, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:24,295 - INFO - Beginning epoch 743/800
2025-03-06 21:07:24,299 - INFO - training batch 1, loss: 0.049, 32/28000 datapoints
2025-03-06 21:07:24,428 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-06 21:07:24,550 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 21:07:24,676 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 21:07:24,797 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:07:24,926 - INFO - training batch 251, loss: 0.039, 8032/28000 datapoints
2025-03-06 21:07:25,050 - INFO - training batch 301, loss: 0.036, 9632/28000 datapoints
2025-03-06 21:07:25,177 - INFO - training batch 351, loss: 0.043, 11232/28000 datapoints
2025-03-06 21:07:25,300 - INFO - training batch 401, loss: 0.062, 12832/28000 datapoints
2025-03-06 21:07:25,426 - INFO - training batch 451, loss: 0.031, 14432/28000 datapoints
2025-03-06 21:07:25,550 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-06 21:07:25,681 - INFO - training batch 551, loss: 0.022, 17632/28000 datapoints
2025-03-06 21:07:25,805 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 21:07:25,929 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:26,053 - INFO - training batch 701, loss: 0.037, 22432/28000 datapoints
2025-03-06 21:07:26,176 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-06 21:07:26,298 - INFO - training batch 801, loss: 0.018, 25632/28000 datapoints
2025-03-06 21:07:26,424 - INFO - training batch 851, loss: 0.033, 27232/28000 datapoints
2025-03-06 21:07:26,484 - INFO - validation batch 1, loss: 0.904, 32/6976 datapoints
2025-03-06 21:07:26,528 - INFO - validation batch 51, loss: 2.754, 1632/6976 datapoints
2025-03-06 21:07:26,573 - INFO - validation batch 101, loss: 1.219, 3232/6976 datapoints
2025-03-06 21:07:26,616 - INFO - validation batch 151, loss: 0.641, 4832/6976 datapoints
2025-03-06 21:07:26,662 - INFO - validation batch 201, loss: 0.822, 6432/6976 datapoints
2025-03-06 21:07:26,678 - INFO - Epoch 743/800 done.
2025-03-06 21:07:26,678 - INFO - Final validation performance:
Loss: 1.268, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:26,678 - INFO - Beginning epoch 744/800
2025-03-06 21:07:26,682 - INFO - training batch 1, loss: 0.049, 32/28000 datapoints
2025-03-06 21:07:26,806 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-06 21:07:26,932 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-06 21:07:27,058 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 21:07:27,181 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:07:27,303 - INFO - training batch 251, loss: 0.039, 8032/28000 datapoints
2025-03-06 21:07:27,427 - INFO - training batch 301, loss: 0.036, 9632/28000 datapoints
2025-03-06 21:07:27,550 - INFO - training batch 351, loss: 0.043, 11232/28000 datapoints
2025-03-06 21:07:27,685 - INFO - training batch 401, loss: 0.061, 12832/28000 datapoints
2025-03-06 21:07:27,809 - INFO - training batch 451, loss: 0.031, 14432/28000 datapoints
2025-03-06 21:07:27,935 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-06 21:07:28,059 - INFO - training batch 551, loss: 0.022, 17632/28000 datapoints
2025-03-06 21:07:28,183 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 21:07:28,305 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:28,431 - INFO - training batch 701, loss: 0.035, 22432/28000 datapoints
2025-03-06 21:07:28,555 - INFO - training batch 751, loss: 0.018, 24032/28000 datapoints
2025-03-06 21:07:28,683 - INFO - training batch 801, loss: 0.018, 25632/28000 datapoints
2025-03-06 21:07:28,805 - INFO - training batch 851, loss: 0.032, 27232/28000 datapoints
2025-03-06 21:07:28,867 - INFO - validation batch 1, loss: 0.907, 32/6976 datapoints
2025-03-06 21:07:28,911 - INFO - validation batch 51, loss: 2.766, 1632/6976 datapoints
2025-03-06 21:07:28,957 - INFO - validation batch 101, loss: 1.222, 3232/6976 datapoints
2025-03-06 21:07:29,002 - INFO - validation batch 151, loss: 0.641, 4832/6976 datapoints
2025-03-06 21:07:29,046 - INFO - validation batch 201, loss: 0.827, 6432/6976 datapoints
2025-03-06 21:07:29,061 - INFO - Epoch 744/800 done.
2025-03-06 21:07:29,061 - INFO - Final validation performance:
Loss: 1.273, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:29,062 - INFO - Beginning epoch 745/800
2025-03-06 21:07:29,065 - INFO - training batch 1, loss: 0.048, 32/28000 datapoints
2025-03-06 21:07:29,190 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-06 21:07:29,314 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-06 21:07:29,441 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 21:07:29,565 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:07:29,696 - INFO - training batch 251, loss: 0.038, 8032/28000 datapoints
2025-03-06 21:07:29,822 - INFO - training batch 301, loss: 0.036, 9632/28000 datapoints
2025-03-06 21:07:29,945 - INFO - training batch 351, loss: 0.042, 11232/28000 datapoints
2025-03-06 21:07:30,067 - INFO - training batch 401, loss: 0.060, 12832/28000 datapoints
2025-03-06 21:07:30,191 - INFO - training batch 451, loss: 0.031, 14432/28000 datapoints
2025-03-06 21:07:30,314 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-06 21:07:30,438 - INFO - training batch 551, loss: 0.022, 17632/28000 datapoints
2025-03-06 21:07:30,563 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 21:07:30,695 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:30,828 - INFO - training batch 701, loss: 0.035, 22432/28000 datapoints
2025-03-06 21:07:30,974 - INFO - training batch 751, loss: 0.018, 24032/28000 datapoints
2025-03-06 21:07:31,103 - INFO - training batch 801, loss: 0.018, 25632/28000 datapoints
2025-03-06 21:07:31,227 - INFO - training batch 851, loss: 0.032, 27232/28000 datapoints
2025-03-06 21:07:31,286 - INFO - validation batch 1, loss: 0.915, 32/6976 datapoints
2025-03-06 21:07:31,333 - INFO - validation batch 51, loss: 2.775, 1632/6976 datapoints
2025-03-06 21:07:31,379 - INFO - validation batch 101, loss: 1.229, 3232/6976 datapoints
2025-03-06 21:07:31,425 - INFO - validation batch 151, loss: 0.641, 4832/6976 datapoints
2025-03-06 21:07:31,472 - INFO - validation batch 201, loss: 0.829, 6432/6976 datapoints
2025-03-06 21:07:31,488 - INFO - Epoch 745/800 done.
2025-03-06 21:07:31,488 - INFO - Final validation performance:
Loss: 1.278, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:31,488 - INFO - Beginning epoch 746/800
2025-03-06 21:07:31,492 - INFO - training batch 1, loss: 0.048, 32/28000 datapoints
2025-03-06 21:07:31,623 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-06 21:07:31,756 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-06 21:07:31,879 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 21:07:32,005 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:07:32,127 - INFO - training batch 251, loss: 0.038, 8032/28000 datapoints
2025-03-06 21:07:32,251 - INFO - training batch 301, loss: 0.035, 9632/28000 datapoints
2025-03-06 21:07:32,372 - INFO - training batch 351, loss: 0.041, 11232/28000 datapoints
2025-03-06 21:07:32,496 - INFO - training batch 401, loss: 0.059, 12832/28000 datapoints
2025-03-06 21:07:32,621 - INFO - training batch 451, loss: 0.030, 14432/28000 datapoints
2025-03-06 21:07:32,753 - INFO - training batch 501, loss: 0.016, 16032/28000 datapoints
2025-03-06 21:07:32,879 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-06 21:07:33,009 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 21:07:33,136 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:33,266 - INFO - training batch 701, loss: 0.035, 22432/28000 datapoints
2025-03-06 21:07:33,393 - INFO - training batch 751, loss: 0.018, 24032/28000 datapoints
2025-03-06 21:07:33,521 - INFO - training batch 801, loss: 0.017, 25632/28000 datapoints
2025-03-06 21:07:33,652 - INFO - training batch 851, loss: 0.031, 27232/28000 datapoints
2025-03-06 21:07:33,724 - INFO - validation batch 1, loss: 0.919, 32/6976 datapoints
2025-03-06 21:07:33,774 - INFO - validation batch 51, loss: 2.787, 1632/6976 datapoints
2025-03-06 21:07:33,822 - INFO - validation batch 101, loss: 1.236, 3232/6976 datapoints
2025-03-06 21:07:33,871 - INFO - validation batch 151, loss: 0.643, 4832/6976 datapoints
2025-03-06 21:07:33,918 - INFO - validation batch 201, loss: 0.834, 6432/6976 datapoints
2025-03-06 21:07:33,935 - INFO - Epoch 746/800 done.
2025-03-06 21:07:33,935 - INFO - Final validation performance:
Loss: 1.284, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:33,935 - INFO - Beginning epoch 747/800
2025-03-06 21:07:33,940 - INFO - training batch 1, loss: 0.047, 32/28000 datapoints
2025-03-06 21:07:34,071 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-06 21:07:34,195 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-06 21:07:34,319 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 21:07:34,442 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:07:34,566 - INFO - training batch 251, loss: 0.037, 8032/28000 datapoints
2025-03-06 21:07:34,692 - INFO - training batch 301, loss: 0.035, 9632/28000 datapoints
2025-03-06 21:07:34,813 - INFO - training batch 351, loss: 0.042, 11232/28000 datapoints
2025-03-06 21:07:34,942 - INFO - training batch 401, loss: 0.059, 12832/28000 datapoints
2025-03-06 21:07:35,072 - INFO - training batch 451, loss: 0.030, 14432/28000 datapoints
2025-03-06 21:07:35,202 - INFO - training batch 501, loss: 0.016, 16032/28000 datapoints
2025-03-06 21:07:35,326 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-06 21:07:35,450 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:07:35,574 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:35,704 - INFO - training batch 701, loss: 0.034, 22432/28000 datapoints
2025-03-06 21:07:35,828 - INFO - training batch 751, loss: 0.018, 24032/28000 datapoints
2025-03-06 21:07:35,952 - INFO - training batch 801, loss: 0.017, 25632/28000 datapoints
2025-03-06 21:07:36,078 - INFO - training batch 851, loss: 0.031, 27232/28000 datapoints
2025-03-06 21:07:36,140 - INFO - validation batch 1, loss: 0.924, 32/6976 datapoints
2025-03-06 21:07:36,185 - INFO - validation batch 51, loss: 2.797, 1632/6976 datapoints
2025-03-06 21:07:36,229 - INFO - validation batch 101, loss: 1.240, 3232/6976 datapoints
2025-03-06 21:07:36,274 - INFO - validation batch 151, loss: 0.640, 4832/6976 datapoints
2025-03-06 21:07:36,320 - INFO - validation batch 201, loss: 0.836, 6432/6976 datapoints
2025-03-06 21:07:36,335 - INFO - Epoch 747/800 done.
2025-03-06 21:07:36,335 - INFO - Final validation performance:
Loss: 1.288, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:36,336 - INFO - Beginning epoch 748/800
2025-03-06 21:07:36,340 - INFO - training batch 1, loss: 0.046, 32/28000 datapoints
2025-03-06 21:07:36,468 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-06 21:07:36,595 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-06 21:07:36,720 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 21:07:36,843 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:07:36,965 - INFO - training batch 251, loss: 0.037, 8032/28000 datapoints
2025-03-06 21:07:37,089 - INFO - training batch 301, loss: 0.034, 9632/28000 datapoints
2025-03-06 21:07:37,211 - INFO - training batch 351, loss: 0.040, 11232/28000 datapoints
2025-03-06 21:07:37,332 - INFO - training batch 401, loss: 0.058, 12832/28000 datapoints
2025-03-06 21:07:37,456 - INFO - training batch 451, loss: 0.030, 14432/28000 datapoints
2025-03-06 21:07:37,581 - INFO - training batch 501, loss: 0.016, 16032/28000 datapoints
2025-03-06 21:07:37,726 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-06 21:07:37,849 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 21:07:37,973 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:38,100 - INFO - training batch 701, loss: 0.034, 22432/28000 datapoints
2025-03-06 21:07:38,225 - INFO - training batch 751, loss: 0.018, 24032/28000 datapoints
2025-03-06 21:07:38,350 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-06 21:07:38,477 - INFO - training batch 851, loss: 0.030, 27232/28000 datapoints
2025-03-06 21:07:38,539 - INFO - validation batch 1, loss: 0.928, 32/6976 datapoints
2025-03-06 21:07:38,584 - INFO - validation batch 51, loss: 2.806, 1632/6976 datapoints
2025-03-06 21:07:38,628 - INFO - validation batch 101, loss: 1.248, 3232/6976 datapoints
2025-03-06 21:07:38,675 - INFO - validation batch 151, loss: 0.643, 4832/6976 datapoints
2025-03-06 21:07:38,719 - INFO - validation batch 201, loss: 0.837, 6432/6976 datapoints
2025-03-06 21:07:38,734 - INFO - Epoch 748/800 done.
2025-03-06 21:07:38,734 - INFO - Final validation performance:
Loss: 1.292, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:38,735 - INFO - Beginning epoch 749/800
2025-03-06 21:07:38,738 - INFO - training batch 1, loss: 0.047, 32/28000 datapoints
2025-03-06 21:07:38,864 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-06 21:07:38,987 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-06 21:07:39,120 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 21:07:39,245 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:07:39,368 - INFO - training batch 251, loss: 0.037, 8032/28000 datapoints
2025-03-06 21:07:39,495 - INFO - training batch 301, loss: 0.035, 9632/28000 datapoints
2025-03-06 21:07:39,621 - INFO - training batch 351, loss: 0.040, 11232/28000 datapoints
2025-03-06 21:07:39,752 - INFO - training batch 401, loss: 0.058, 12832/28000 datapoints
2025-03-06 21:07:39,876 - INFO - training batch 451, loss: 0.030, 14432/28000 datapoints
2025-03-06 21:07:40,000 - INFO - training batch 501, loss: 0.016, 16032/28000 datapoints
2025-03-06 21:07:40,139 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-06 21:07:40,263 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:07:40,387 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:40,515 - INFO - training batch 701, loss: 0.034, 22432/28000 datapoints
2025-03-06 21:07:40,642 - INFO - training batch 751, loss: 0.018, 24032/28000 datapoints
2025-03-06 21:07:40,765 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-06 21:07:40,889 - INFO - training batch 851, loss: 0.030, 27232/28000 datapoints
2025-03-06 21:07:40,949 - INFO - validation batch 1, loss: 0.936, 32/6976 datapoints
2025-03-06 21:07:40,994 - INFO - validation batch 51, loss: 2.815, 1632/6976 datapoints
2025-03-06 21:07:41,058 - INFO - validation batch 101, loss: 1.254, 3232/6976 datapoints
2025-03-06 21:07:41,115 - INFO - validation batch 151, loss: 0.645, 4832/6976 datapoints
2025-03-06 21:07:41,161 - INFO - validation batch 201, loss: 0.840, 6432/6976 datapoints
2025-03-06 21:07:41,177 - INFO - Epoch 749/800 done.
2025-03-06 21:07:41,177 - INFO - Final validation performance:
Loss: 1.298, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:41,177 - INFO - Beginning epoch 750/800
2025-03-06 21:07:41,181 - INFO - training batch 1, loss: 0.045, 32/28000 datapoints
2025-03-06 21:07:41,310 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-06 21:07:41,438 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 21:07:41,565 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 21:07:41,695 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:07:41,824 - INFO - training batch 251, loss: 0.036, 8032/28000 datapoints
2025-03-06 21:07:41,950 - INFO - training batch 301, loss: 0.034, 9632/28000 datapoints
2025-03-06 21:07:42,073 - INFO - training batch 351, loss: 0.040, 11232/28000 datapoints
2025-03-06 21:07:42,198 - INFO - training batch 401, loss: 0.057, 12832/28000 datapoints
2025-03-06 21:07:42,319 - INFO - training batch 451, loss: 0.029, 14432/28000 datapoints
2025-03-06 21:07:42,440 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 21:07:42,563 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-06 21:07:42,691 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:07:42,815 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:42,945 - INFO - training batch 701, loss: 0.033, 22432/28000 datapoints
2025-03-06 21:07:43,069 - INFO - training batch 751, loss: 0.017, 24032/28000 datapoints
2025-03-06 21:07:43,195 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-06 21:07:43,322 - INFO - training batch 851, loss: 0.029, 27232/28000 datapoints
2025-03-06 21:07:43,383 - INFO - validation batch 1, loss: 0.941, 32/6976 datapoints
2025-03-06 21:07:43,429 - INFO - validation batch 51, loss: 2.829, 1632/6976 datapoints
2025-03-06 21:07:43,474 - INFO - validation batch 101, loss: 1.257, 3232/6976 datapoints
2025-03-06 21:07:43,519 - INFO - validation batch 151, loss: 0.645, 4832/6976 datapoints
2025-03-06 21:07:43,563 - INFO - validation batch 201, loss: 0.844, 6432/6976 datapoints
2025-03-06 21:07:43,578 - INFO - Epoch 750/800 done.
2025-03-06 21:07:43,578 - INFO - Final validation performance:
Loss: 1.303, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:43,579 - INFO - Beginning epoch 751/800
2025-03-06 21:07:43,582 - INFO - training batch 1, loss: 0.045, 32/28000 datapoints
2025-03-06 21:07:43,719 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-06 21:07:43,848 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-06 21:07:43,972 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 21:07:44,096 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:07:44,219 - INFO - training batch 251, loss: 0.036, 8032/28000 datapoints
2025-03-06 21:07:44,342 - INFO - training batch 301, loss: 0.034, 9632/28000 datapoints
2025-03-06 21:07:44,465 - INFO - training batch 351, loss: 0.039, 11232/28000 datapoints
2025-03-06 21:07:44,588 - INFO - training batch 401, loss: 0.055, 12832/28000 datapoints
2025-03-06 21:07:44,716 - INFO - training batch 451, loss: 0.029, 14432/28000 datapoints
2025-03-06 21:07:44,839 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 21:07:44,967 - INFO - training batch 551, loss: 0.020, 17632/28000 datapoints
2025-03-06 21:07:45,093 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:07:45,229 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:45,354 - INFO - training batch 701, loss: 0.033, 22432/28000 datapoints
2025-03-06 21:07:45,478 - INFO - training batch 751, loss: 0.017, 24032/28000 datapoints
2025-03-06 21:07:45,605 - INFO - training batch 801, loss: 0.015, 25632/28000 datapoints
2025-03-06 21:07:45,737 - INFO - training batch 851, loss: 0.029, 27232/28000 datapoints
2025-03-06 21:07:45,800 - INFO - validation batch 1, loss: 0.946, 32/6976 datapoints
2025-03-06 21:07:45,845 - INFO - validation batch 51, loss: 2.837, 1632/6976 datapoints
2025-03-06 21:07:45,890 - INFO - validation batch 101, loss: 1.267, 3232/6976 datapoints
2025-03-06 21:07:45,933 - INFO - validation batch 151, loss: 0.647, 4832/6976 datapoints
2025-03-06 21:07:45,977 - INFO - validation batch 201, loss: 0.847, 6432/6976 datapoints
2025-03-06 21:07:45,992 - INFO - Epoch 751/800 done.
2025-03-06 21:07:45,992 - INFO - Final validation performance:
Loss: 1.309, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:45,993 - INFO - Beginning epoch 752/800
2025-03-06 21:07:45,996 - INFO - training batch 1, loss: 0.044, 32/28000 datapoints
2025-03-06 21:07:46,122 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-06 21:07:46,247 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 21:07:46,370 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 21:07:46,495 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:07:46,617 - INFO - training batch 251, loss: 0.036, 8032/28000 datapoints
2025-03-06 21:07:46,743 - INFO - training batch 301, loss: 0.034, 9632/28000 datapoints
2025-03-06 21:07:46,866 - INFO - training batch 351, loss: 0.038, 11232/28000 datapoints
2025-03-06 21:07:46,987 - INFO - training batch 401, loss: 0.055, 12832/28000 datapoints
2025-03-06 21:07:47,110 - INFO - training batch 451, loss: 0.029, 14432/28000 datapoints
2025-03-06 21:07:47,238 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 21:07:47,360 - INFO - training batch 551, loss: 0.020, 17632/28000 datapoints
2025-03-06 21:07:47,485 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:07:47,607 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:47,743 - INFO - training batch 701, loss: 0.032, 22432/28000 datapoints
2025-03-06 21:07:47,865 - INFO - training batch 751, loss: 0.017, 24032/28000 datapoints
2025-03-06 21:07:47,989 - INFO - training batch 801, loss: 0.015, 25632/28000 datapoints
2025-03-06 21:07:48,114 - INFO - training batch 851, loss: 0.029, 27232/28000 datapoints
2025-03-06 21:07:48,177 - INFO - validation batch 1, loss: 0.952, 32/6976 datapoints
2025-03-06 21:07:48,221 - INFO - validation batch 51, loss: 2.850, 1632/6976 datapoints
2025-03-06 21:07:48,266 - INFO - validation batch 101, loss: 1.271, 3232/6976 datapoints
2025-03-06 21:07:48,308 - INFO - validation batch 151, loss: 0.649, 4832/6976 datapoints
2025-03-06 21:07:48,352 - INFO - validation batch 201, loss: 0.852, 6432/6976 datapoints
2025-03-06 21:07:48,368 - INFO - Epoch 752/800 done.
2025-03-06 21:07:48,368 - INFO - Final validation performance:
Loss: 1.315, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:48,369 - INFO - Beginning epoch 753/800
2025-03-06 21:07:48,372 - INFO - training batch 1, loss: 0.044, 32/28000 datapoints
2025-03-06 21:07:48,499 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 21:07:48,622 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 21:07:48,751 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 21:07:48,873 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:07:48,995 - INFO - training batch 251, loss: 0.035, 8032/28000 datapoints
2025-03-06 21:07:49,118 - INFO - training batch 301, loss: 0.033, 9632/28000 datapoints
2025-03-06 21:07:49,241 - INFO - training batch 351, loss: 0.038, 11232/28000 datapoints
2025-03-06 21:07:49,362 - INFO - training batch 401, loss: 0.055, 12832/28000 datapoints
2025-03-06 21:07:49,485 - INFO - training batch 451, loss: 0.029, 14432/28000 datapoints
2025-03-06 21:07:49,610 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 21:07:49,741 - INFO - training batch 551, loss: 0.020, 17632/28000 datapoints
2025-03-06 21:07:49,864 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:07:49,988 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:50,114 - INFO - training batch 701, loss: 0.033, 22432/28000 datapoints
2025-03-06 21:07:50,237 - INFO - training batch 751, loss: 0.017, 24032/28000 datapoints
2025-03-06 21:07:50,361 - INFO - training batch 801, loss: 0.015, 25632/28000 datapoints
2025-03-06 21:07:50,496 - INFO - training batch 851, loss: 0.029, 27232/28000 datapoints
2025-03-06 21:07:50,570 - INFO - validation batch 1, loss: 0.956, 32/6976 datapoints
2025-03-06 21:07:50,615 - INFO - validation batch 51, loss: 2.859, 1632/6976 datapoints
2025-03-06 21:07:50,668 - INFO - validation batch 101, loss: 1.280, 3232/6976 datapoints
2025-03-06 21:07:50,724 - INFO - validation batch 151, loss: 0.652, 4832/6976 datapoints
2025-03-06 21:07:50,779 - INFO - validation batch 201, loss: 0.854, 6432/6976 datapoints
2025-03-06 21:07:50,796 - INFO - Epoch 753/800 done.
2025-03-06 21:07:50,796 - INFO - Final validation performance:
Loss: 1.320, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:50,797 - INFO - Beginning epoch 754/800
2025-03-06 21:07:50,801 - INFO - training batch 1, loss: 0.043, 32/28000 datapoints
2025-03-06 21:07:50,955 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 21:07:51,083 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 21:07:51,237 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 21:07:51,359 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:07:51,481 - INFO - training batch 251, loss: 0.035, 8032/28000 datapoints
2025-03-06 21:07:51,605 - INFO - training batch 301, loss: 0.033, 9632/28000 datapoints
2025-03-06 21:07:51,730 - INFO - training batch 351, loss: 0.038, 11232/28000 datapoints
2025-03-06 21:07:51,859 - INFO - training batch 401, loss: 0.054, 12832/28000 datapoints
2025-03-06 21:07:51,982 - INFO - training batch 451, loss: 0.028, 14432/28000 datapoints
2025-03-06 21:07:52,107 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 21:07:52,231 - INFO - training batch 551, loss: 0.020, 17632/28000 datapoints
2025-03-06 21:07:52,353 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 21:07:52,476 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:52,599 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-06 21:07:52,732 - INFO - training batch 751, loss: 0.017, 24032/28000 datapoints
2025-03-06 21:07:52,862 - INFO - training batch 801, loss: 0.015, 25632/28000 datapoints
2025-03-06 21:07:52,991 - INFO - training batch 851, loss: 0.028, 27232/28000 datapoints
2025-03-06 21:07:53,052 - INFO - validation batch 1, loss: 0.962, 32/6976 datapoints
2025-03-06 21:07:53,100 - INFO - validation batch 51, loss: 2.874, 1632/6976 datapoints
2025-03-06 21:07:53,146 - INFO - validation batch 101, loss: 1.284, 3232/6976 datapoints
2025-03-06 21:07:53,194 - INFO - validation batch 151, loss: 0.650, 4832/6976 datapoints
2025-03-06 21:07:53,240 - INFO - validation batch 201, loss: 0.858, 6432/6976 datapoints
2025-03-06 21:07:53,257 - INFO - Epoch 754/800 done.
2025-03-06 21:07:53,257 - INFO - Final validation performance:
Loss: 1.325, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:53,258 - INFO - Beginning epoch 755/800
2025-03-06 21:07:53,262 - INFO - training batch 1, loss: 0.043, 32/28000 datapoints
2025-03-06 21:07:53,393 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 21:07:53,519 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 21:07:53,647 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 21:07:53,785 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:07:53,911 - INFO - training batch 251, loss: 0.034, 8032/28000 datapoints
2025-03-06 21:07:54,039 - INFO - training batch 301, loss: 0.032, 9632/28000 datapoints
2025-03-06 21:07:54,165 - INFO - training batch 351, loss: 0.038, 11232/28000 datapoints
2025-03-06 21:07:54,293 - INFO - training batch 401, loss: 0.053, 12832/28000 datapoints
2025-03-06 21:07:54,420 - INFO - training batch 451, loss: 0.028, 14432/28000 datapoints
2025-03-06 21:07:54,550 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 21:07:54,679 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-06 21:07:54,808 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 21:07:54,939 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:55,068 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-06 21:07:55,196 - INFO - training batch 751, loss: 0.017, 24032/28000 datapoints
2025-03-06 21:07:55,326 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-06 21:07:55,453 - INFO - training batch 851, loss: 0.028, 27232/28000 datapoints
2025-03-06 21:07:55,517 - INFO - validation batch 1, loss: 0.967, 32/6976 datapoints
2025-03-06 21:07:55,574 - INFO - validation batch 51, loss: 2.886, 1632/6976 datapoints
2025-03-06 21:07:55,622 - INFO - validation batch 101, loss: 1.290, 3232/6976 datapoints
2025-03-06 21:07:55,674 - INFO - validation batch 151, loss: 0.644, 4832/6976 datapoints
2025-03-06 21:07:55,722 - INFO - validation batch 201, loss: 0.861, 6432/6976 datapoints
2025-03-06 21:07:55,742 - INFO - Epoch 755/800 done.
2025-03-06 21:07:55,742 - INFO - Final validation performance:
Loss: 1.329, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:07:55,742 - INFO - Beginning epoch 756/800
2025-03-06 21:07:55,746 - INFO - training batch 1, loss: 0.041, 32/28000 datapoints
2025-03-06 21:07:55,881 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 21:07:56,008 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 21:07:56,135 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 21:07:56,263 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:07:56,391 - INFO - training batch 251, loss: 0.034, 8032/28000 datapoints
2025-03-06 21:07:56,520 - INFO - training batch 301, loss: 0.032, 9632/28000 datapoints
2025-03-06 21:07:56,677 - INFO - training batch 351, loss: 0.036, 11232/28000 datapoints
2025-03-06 21:07:56,829 - INFO - training batch 401, loss: 0.052, 12832/28000 datapoints
2025-03-06 21:07:56,957 - INFO - training batch 451, loss: 0.028, 14432/28000 datapoints
2025-03-06 21:07:57,083 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-06 21:07:57,213 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-06 21:07:57,341 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 21:07:57,467 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:07:57,594 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-06 21:07:57,726 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 21:07:57,860 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-06 21:07:57,989 - INFO - training batch 851, loss: 0.027, 27232/28000 datapoints
2025-03-06 21:07:58,053 - INFO - validation batch 1, loss: 0.970, 32/6976 datapoints
2025-03-06 21:07:58,107 - INFO - validation batch 51, loss: 2.894, 1632/6976 datapoints
2025-03-06 21:07:58,154 - INFO - validation batch 101, loss: 1.299, 3232/6976 datapoints
2025-03-06 21:07:58,202 - INFO - validation batch 151, loss: 0.650, 4832/6976 datapoints
2025-03-06 21:07:58,251 - INFO - validation batch 201, loss: 0.863, 6432/6976 datapoints
2025-03-06 21:07:58,267 - INFO - Epoch 756/800 done.
2025-03-06 21:07:58,267 - INFO - Final validation performance:
Loss: 1.335, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:07:58,268 - INFO - Beginning epoch 757/800
2025-03-06 21:07:58,271 - INFO - training batch 1, loss: 0.042, 32/28000 datapoints
2025-03-06 21:07:58,403 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 21:07:58,534 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-06 21:07:58,668 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 21:07:58,797 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:07:58,925 - INFO - training batch 251, loss: 0.034, 8032/28000 datapoints
2025-03-06 21:07:59,051 - INFO - training batch 301, loss: 0.032, 9632/28000 datapoints
2025-03-06 21:07:59,178 - INFO - training batch 351, loss: 0.036, 11232/28000 datapoints
2025-03-06 21:07:59,303 - INFO - training batch 401, loss: 0.052, 12832/28000 datapoints
2025-03-06 21:07:59,492 - INFO - training batch 451, loss: 0.027, 14432/28000 datapoints
2025-03-06 21:07:59,618 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 21:07:59,748 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-06 21:07:59,880 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:08:00,011 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:08:00,141 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-06 21:08:00,268 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 21:08:00,394 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-06 21:08:00,523 - INFO - training batch 851, loss: 0.027, 27232/28000 datapoints
2025-03-06 21:08:00,589 - INFO - validation batch 1, loss: 0.975, 32/6976 datapoints
2025-03-06 21:08:00,635 - INFO - validation batch 51, loss: 2.900, 1632/6976 datapoints
2025-03-06 21:08:00,685 - INFO - validation batch 101, loss: 1.304, 3232/6976 datapoints
2025-03-06 21:08:00,733 - INFO - validation batch 151, loss: 0.652, 4832/6976 datapoints
2025-03-06 21:08:00,780 - INFO - validation batch 201, loss: 0.866, 6432/6976 datapoints
2025-03-06 21:08:00,797 - INFO - Epoch 757/800 done.
2025-03-06 21:08:00,797 - INFO - Final validation performance:
Loss: 1.340, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:00,797 - INFO - Beginning epoch 758/800
2025-03-06 21:08:00,801 - INFO - training batch 1, loss: 0.040, 32/28000 datapoints
2025-03-06 21:08:00,930 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 21:08:01,056 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-06 21:08:01,179 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 21:08:01,334 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:08:01,458 - INFO - training batch 251, loss: 0.033, 8032/28000 datapoints
2025-03-06 21:08:01,581 - INFO - training batch 301, loss: 0.032, 9632/28000 datapoints
2025-03-06 21:08:01,709 - INFO - training batch 351, loss: 0.036, 11232/28000 datapoints
2025-03-06 21:08:01,834 - INFO - training batch 401, loss: 0.051, 12832/28000 datapoints
2025-03-06 21:08:01,961 - INFO - training batch 451, loss: 0.027, 14432/28000 datapoints
2025-03-06 21:08:02,082 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 21:08:02,203 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-06 21:08:02,327 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:08:02,451 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:08:02,575 - INFO - training batch 701, loss: 0.030, 22432/28000 datapoints
2025-03-06 21:08:02,702 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 21:08:02,824 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-06 21:08:02,950 - INFO - training batch 851, loss: 0.027, 27232/28000 datapoints
2025-03-06 21:08:03,012 - INFO - validation batch 1, loss: 0.984, 32/6976 datapoints
2025-03-06 21:08:03,056 - INFO - validation batch 51, loss: 2.920, 1632/6976 datapoints
2025-03-06 21:08:03,099 - INFO - validation batch 101, loss: 1.310, 3232/6976 datapoints
2025-03-06 21:08:03,144 - INFO - validation batch 151, loss: 0.649, 4832/6976 datapoints
2025-03-06 21:08:03,188 - INFO - validation batch 201, loss: 0.871, 6432/6976 datapoints
2025-03-06 21:08:03,204 - INFO - Epoch 758/800 done.
2025-03-06 21:08:03,204 - INFO - Final validation performance:
Loss: 1.347, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:08:03,205 - INFO - Beginning epoch 759/800
2025-03-06 21:08:03,208 - INFO - training batch 1, loss: 0.040, 32/28000 datapoints
2025-03-06 21:08:03,332 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 21:08:03,457 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-06 21:08:03,582 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 21:08:03,708 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:08:03,839 - INFO - training batch 251, loss: 0.033, 8032/28000 datapoints
2025-03-06 21:08:03,964 - INFO - training batch 301, loss: 0.031, 9632/28000 datapoints
2025-03-06 21:08:04,088 - INFO - training batch 351, loss: 0.035, 11232/28000 datapoints
2025-03-06 21:08:04,210 - INFO - training batch 401, loss: 0.050, 12832/28000 datapoints
2025-03-06 21:08:04,333 - INFO - training batch 451, loss: 0.027, 14432/28000 datapoints
2025-03-06 21:08:04,457 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 21:08:04,580 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-06 21:08:04,710 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:08:04,832 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-06 21:08:04,963 - INFO - training batch 701, loss: 0.030, 22432/28000 datapoints
2025-03-06 21:08:05,088 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 21:08:05,213 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-06 21:08:05,337 - INFO - training batch 851, loss: 0.026, 27232/28000 datapoints
2025-03-06 21:08:05,397 - INFO - validation batch 1, loss: 0.989, 32/6976 datapoints
2025-03-06 21:08:05,440 - INFO - validation batch 51, loss: 2.929, 1632/6976 datapoints
2025-03-06 21:08:05,487 - INFO - validation batch 101, loss: 1.319, 3232/6976 datapoints
2025-03-06 21:08:05,530 - INFO - validation batch 151, loss: 0.655, 4832/6976 datapoints
2025-03-06 21:08:05,573 - INFO - validation batch 201, loss: 0.872, 6432/6976 datapoints
2025-03-06 21:08:05,587 - INFO - Epoch 759/800 done.
2025-03-06 21:08:05,588 - INFO - Final validation performance:
Loss: 1.353, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:08:05,588 - INFO - Beginning epoch 760/800
2025-03-06 21:08:05,591 - INFO - training batch 1, loss: 0.040, 32/28000 datapoints
2025-03-06 21:08:05,720 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 21:08:05,849 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-06 21:08:05,974 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 21:08:06,100 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:08:06,223 - INFO - training batch 251, loss: 0.033, 8032/28000 datapoints
2025-03-06 21:08:06,348 - INFO - training batch 301, loss: 0.031, 9632/28000 datapoints
2025-03-06 21:08:06,471 - INFO - training batch 351, loss: 0.035, 11232/28000 datapoints
2025-03-06 21:08:06,596 - INFO - training batch 401, loss: 0.050, 12832/28000 datapoints
2025-03-06 21:08:06,721 - INFO - training batch 451, loss: 0.026, 14432/28000 datapoints
2025-03-06 21:08:06,843 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 21:08:06,967 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 21:08:07,092 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:08:07,216 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:07,344 - INFO - training batch 701, loss: 0.030, 22432/28000 datapoints
2025-03-06 21:08:07,467 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 21:08:07,592 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-06 21:08:07,723 - INFO - training batch 851, loss: 0.026, 27232/28000 datapoints
2025-03-06 21:08:07,783 - INFO - validation batch 1, loss: 0.992, 32/6976 datapoints
2025-03-06 21:08:07,831 - INFO - validation batch 51, loss: 2.940, 1632/6976 datapoints
2025-03-06 21:08:07,875 - INFO - validation batch 101, loss: 1.324, 3232/6976 datapoints
2025-03-06 21:08:07,919 - INFO - validation batch 151, loss: 0.653, 4832/6976 datapoints
2025-03-06 21:08:07,964 - INFO - validation batch 201, loss: 0.877, 6432/6976 datapoints
2025-03-06 21:08:07,980 - INFO - Epoch 760/800 done.
2025-03-06 21:08:07,980 - INFO - Final validation performance:
Loss: 1.357, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:08:07,981 - INFO - Beginning epoch 761/800
2025-03-06 21:08:07,985 - INFO - training batch 1, loss: 0.039, 32/28000 datapoints
2025-03-06 21:08:08,113 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 21:08:08,236 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-06 21:08:08,361 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 21:08:08,483 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:08:08,607 - INFO - training batch 251, loss: 0.032, 8032/28000 datapoints
2025-03-06 21:08:08,734 - INFO - training batch 301, loss: 0.031, 9632/28000 datapoints
2025-03-06 21:08:08,857 - INFO - training batch 351, loss: 0.034, 11232/28000 datapoints
2025-03-06 21:08:08,980 - INFO - training batch 401, loss: 0.049, 12832/28000 datapoints
2025-03-06 21:08:09,108 - INFO - training batch 451, loss: 0.026, 14432/28000 datapoints
2025-03-06 21:08:09,230 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 21:08:09,352 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 21:08:09,475 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-06 21:08:09,600 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:09,729 - INFO - training batch 701, loss: 0.029, 22432/28000 datapoints
2025-03-06 21:08:09,857 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 21:08:09,984 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-06 21:08:10,112 - INFO - training batch 851, loss: 0.026, 27232/28000 datapoints
2025-03-06 21:08:10,173 - INFO - validation batch 1, loss: 1.001, 32/6976 datapoints
2025-03-06 21:08:10,217 - INFO - validation batch 51, loss: 2.954, 1632/6976 datapoints
2025-03-06 21:08:10,260 - INFO - validation batch 101, loss: 1.330, 3232/6976 datapoints
2025-03-06 21:08:10,305 - INFO - validation batch 151, loss: 0.651, 4832/6976 datapoints
2025-03-06 21:08:10,349 - INFO - validation batch 201, loss: 0.878, 6432/6976 datapoints
2025-03-06 21:08:10,364 - INFO - Epoch 761/800 done.
2025-03-06 21:08:10,365 - INFO - Final validation performance:
Loss: 1.363, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:08:10,365 - INFO - Beginning epoch 762/800
2025-03-06 21:08:10,369 - INFO - training batch 1, loss: 0.039, 32/28000 datapoints
2025-03-06 21:08:10,496 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 21:08:10,624 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 21:08:10,749 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 21:08:10,872 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:08:11,011 - INFO - training batch 251, loss: 0.032, 8032/28000 datapoints
2025-03-06 21:08:11,159 - INFO - training batch 301, loss: 0.030, 9632/28000 datapoints
2025-03-06 21:08:11,327 - INFO - training batch 351, loss: 0.034, 11232/28000 datapoints
2025-03-06 21:08:11,501 - INFO - training batch 401, loss: 0.048, 12832/28000 datapoints
2025-03-06 21:08:11,646 - INFO - training batch 451, loss: 0.026, 14432/28000 datapoints
2025-03-06 21:08:11,793 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 21:08:11,926 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 21:08:12,055 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:08:12,179 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:12,303 - INFO - training batch 701, loss: 0.028, 22432/28000 datapoints
2025-03-06 21:08:12,426 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 21:08:12,551 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 21:08:12,687 - INFO - training batch 851, loss: 0.025, 27232/28000 datapoints
2025-03-06 21:08:12,749 - INFO - validation batch 1, loss: 1.004, 32/6976 datapoints
2025-03-06 21:08:12,792 - INFO - validation batch 51, loss: 2.964, 1632/6976 datapoints
2025-03-06 21:08:12,835 - INFO - validation batch 101, loss: 1.337, 3232/6976 datapoints
2025-03-06 21:08:12,881 - INFO - validation batch 151, loss: 0.658, 4832/6976 datapoints
2025-03-06 21:08:12,929 - INFO - validation batch 201, loss: 0.882, 6432/6976 datapoints
2025-03-06 21:08:12,948 - INFO - Epoch 762/800 done.
2025-03-06 21:08:12,949 - INFO - Final validation performance:
Loss: 1.369, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:08:12,949 - INFO - Beginning epoch 763/800
2025-03-06 21:08:12,953 - INFO - training batch 1, loss: 0.038, 32/28000 datapoints
2025-03-06 21:08:13,090 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 21:08:13,220 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-06 21:08:13,352 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 21:08:13,486 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:08:13,615 - INFO - training batch 251, loss: 0.031, 8032/28000 datapoints
2025-03-06 21:08:13,749 - INFO - training batch 301, loss: 0.030, 9632/28000 datapoints
2025-03-06 21:08:13,883 - INFO - training batch 351, loss: 0.034, 11232/28000 datapoints
2025-03-06 21:08:14,013 - INFO - training batch 401, loss: 0.048, 12832/28000 datapoints
2025-03-06 21:08:14,144 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-06 21:08:14,268 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-06 21:08:14,395 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 21:08:14,522 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:08:14,653 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:14,780 - INFO - training batch 701, loss: 0.028, 22432/28000 datapoints
2025-03-06 21:08:14,910 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-06 21:08:15,043 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 21:08:15,172 - INFO - training batch 851, loss: 0.025, 27232/28000 datapoints
2025-03-06 21:08:15,238 - INFO - validation batch 1, loss: 1.010, 32/6976 datapoints
2025-03-06 21:08:15,284 - INFO - validation batch 51, loss: 2.975, 1632/6976 datapoints
2025-03-06 21:08:15,331 - INFO - validation batch 101, loss: 1.346, 3232/6976 datapoints
2025-03-06 21:08:15,375 - INFO - validation batch 151, loss: 0.657, 4832/6976 datapoints
2025-03-06 21:08:15,419 - INFO - validation batch 201, loss: 0.885, 6432/6976 datapoints
2025-03-06 21:08:15,434 - INFO - Epoch 763/800 done.
2025-03-06 21:08:15,434 - INFO - Final validation performance:
Loss: 1.374, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:15,435 - INFO - Beginning epoch 764/800
2025-03-06 21:08:15,439 - INFO - training batch 1, loss: 0.038, 32/28000 datapoints
2025-03-06 21:08:15,565 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 21:08:15,693 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 21:08:15,817 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 21:08:15,948 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:08:16,072 - INFO - training batch 251, loss: 0.031, 8032/28000 datapoints
2025-03-06 21:08:16,197 - INFO - training batch 301, loss: 0.030, 9632/28000 datapoints
2025-03-06 21:08:16,319 - INFO - training batch 351, loss: 0.033, 11232/28000 datapoints
2025-03-06 21:08:16,444 - INFO - training batch 401, loss: 0.047, 12832/28000 datapoints
2025-03-06 21:08:16,568 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-06 21:08:16,695 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 21:08:16,818 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 21:08:16,943 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-06 21:08:17,066 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:17,192 - INFO - training batch 701, loss: 0.028, 22432/28000 datapoints
2025-03-06 21:08:17,317 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-06 21:08:17,442 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 21:08:17,569 - INFO - training batch 851, loss: 0.024, 27232/28000 datapoints
2025-03-06 21:08:17,630 - INFO - validation batch 1, loss: 1.019, 32/6976 datapoints
2025-03-06 21:08:17,683 - INFO - validation batch 51, loss: 2.990, 1632/6976 datapoints
2025-03-06 21:08:17,727 - INFO - validation batch 101, loss: 1.351, 3232/6976 datapoints
2025-03-06 21:08:17,771 - INFO - validation batch 151, loss: 0.651, 4832/6976 datapoints
2025-03-06 21:08:17,814 - INFO - validation batch 201, loss: 0.890, 6432/6976 datapoints
2025-03-06 21:08:17,830 - INFO - Epoch 764/800 done.
2025-03-06 21:08:17,830 - INFO - Final validation performance:
Loss: 1.380, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:17,830 - INFO - Beginning epoch 765/800
2025-03-06 21:08:17,834 - INFO - training batch 1, loss: 0.037, 32/28000 datapoints
2025-03-06 21:08:17,962 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 21:08:18,091 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 21:08:18,216 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 21:08:18,342 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 21:08:18,465 - INFO - training batch 251, loss: 0.031, 8032/28000 datapoints
2025-03-06 21:08:18,589 - INFO - training batch 301, loss: 0.029, 9632/28000 datapoints
2025-03-06 21:08:18,720 - INFO - training batch 351, loss: 0.033, 11232/28000 datapoints
2025-03-06 21:08:18,844 - INFO - training batch 401, loss: 0.047, 12832/28000 datapoints
2025-03-06 21:08:18,967 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-06 21:08:19,091 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 21:08:19,216 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-06 21:08:19,339 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:08:19,461 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:19,587 - INFO - training batch 701, loss: 0.028, 22432/28000 datapoints
2025-03-06 21:08:19,716 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-06 21:08:19,842 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 21:08:19,971 - INFO - training batch 851, loss: 0.024, 27232/28000 datapoints
2025-03-06 21:08:20,034 - INFO - validation batch 1, loss: 1.022, 32/6976 datapoints
2025-03-06 21:08:20,080 - INFO - validation batch 51, loss: 2.998, 1632/6976 datapoints
2025-03-06 21:08:20,124 - INFO - validation batch 101, loss: 1.360, 3232/6976 datapoints
2025-03-06 21:08:20,170 - INFO - validation batch 151, loss: 0.658, 4832/6976 datapoints
2025-03-06 21:08:20,213 - INFO - validation batch 201, loss: 0.893, 6432/6976 datapoints
2025-03-06 21:08:20,228 - INFO - Epoch 765/800 done.
2025-03-06 21:08:20,228 - INFO - Final validation performance:
Loss: 1.386, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:20,229 - INFO - Beginning epoch 766/800
2025-03-06 21:08:20,232 - INFO - training batch 1, loss: 0.038, 32/28000 datapoints
2025-03-06 21:08:20,358 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 21:08:20,484 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 21:08:20,610 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 21:08:20,738 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:08:20,927 - INFO - training batch 251, loss: 0.031, 8032/28000 datapoints
2025-03-06 21:08:21,054 - INFO - training batch 301, loss: 0.029, 9632/28000 datapoints
2025-03-06 21:08:21,180 - INFO - training batch 351, loss: 0.032, 11232/28000 datapoints
2025-03-06 21:08:21,303 - INFO - training batch 401, loss: 0.046, 12832/28000 datapoints
2025-03-06 21:08:21,432 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-06 21:08:21,578 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 21:08:21,707 - INFO - training batch 551, loss: 0.017, 17632/28000 datapoints
2025-03-06 21:08:21,831 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-06 21:08:22,005 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:22,177 - INFO - training batch 701, loss: 0.027, 22432/28000 datapoints
2025-03-06 21:08:22,352 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-06 21:08:22,494 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 21:08:22,618 - INFO - training batch 851, loss: 0.024, 27232/28000 datapoints
2025-03-06 21:08:22,683 - INFO - validation batch 1, loss: 1.028, 32/6976 datapoints
2025-03-06 21:08:22,730 - INFO - validation batch 51, loss: 3.013, 1632/6976 datapoints
2025-03-06 21:08:22,774 - INFO - validation batch 101, loss: 1.366, 3232/6976 datapoints
2025-03-06 21:08:22,820 - INFO - validation batch 151, loss: 0.656, 4832/6976 datapoints
2025-03-06 21:08:22,865 - INFO - validation batch 201, loss: 0.896, 6432/6976 datapoints
2025-03-06 21:08:22,881 - INFO - Epoch 766/800 done.
2025-03-06 21:08:22,881 - INFO - Final validation performance:
Loss: 1.392, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:22,882 - INFO - Beginning epoch 767/800
2025-03-06 21:08:22,885 - INFO - training batch 1, loss: 0.036, 32/28000 datapoints
2025-03-06 21:08:23,013 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 21:08:23,136 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 21:08:23,264 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 21:08:23,387 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 21:08:23,513 - INFO - training batch 251, loss: 0.030, 8032/28000 datapoints
2025-03-06 21:08:23,637 - INFO - training batch 301, loss: 0.029, 9632/28000 datapoints
2025-03-06 21:08:23,766 - INFO - training batch 351, loss: 0.032, 11232/28000 datapoints
2025-03-06 21:08:23,899 - INFO - training batch 401, loss: 0.045, 12832/28000 datapoints
2025-03-06 21:08:24,023 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-06 21:08:24,150 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 21:08:24,275 - INFO - training batch 551, loss: 0.017, 17632/28000 datapoints
2025-03-06 21:08:24,398 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-06 21:08:24,521 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:24,650 - INFO - training batch 701, loss: 0.027, 22432/28000 datapoints
2025-03-06 21:08:24,778 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-06 21:08:24,909 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-06 21:08:25,051 - INFO - training batch 851, loss: 0.024, 27232/28000 datapoints
2025-03-06 21:08:25,115 - INFO - validation batch 1, loss: 1.038, 32/6976 datapoints
2025-03-06 21:08:25,159 - INFO - validation batch 51, loss: 3.022, 1632/6976 datapoints
2025-03-06 21:08:25,203 - INFO - validation batch 101, loss: 1.374, 3232/6976 datapoints
2025-03-06 21:08:25,254 - INFO - validation batch 151, loss: 0.657, 4832/6976 datapoints
2025-03-06 21:08:25,299 - INFO - validation batch 201, loss: 0.901, 6432/6976 datapoints
2025-03-06 21:08:25,315 - INFO - Epoch 767/800 done.
2025-03-06 21:08:25,316 - INFO - Final validation performance:
Loss: 1.398, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:25,316 - INFO - Beginning epoch 768/800
2025-03-06 21:08:25,320 - INFO - training batch 1, loss: 0.036, 32/28000 datapoints
2025-03-06 21:08:25,449 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 21:08:25,577 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 21:08:25,712 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-06 21:08:25,838 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 21:08:25,968 - INFO - training batch 251, loss: 0.030, 8032/28000 datapoints
2025-03-06 21:08:26,094 - INFO - training batch 301, loss: 0.029, 9632/28000 datapoints
2025-03-06 21:08:26,215 - INFO - training batch 351, loss: 0.031, 11232/28000 datapoints
2025-03-06 21:08:26,339 - INFO - training batch 401, loss: 0.045, 12832/28000 datapoints
2025-03-06 21:08:26,464 - INFO - training batch 451, loss: 0.024, 14432/28000 datapoints
2025-03-06 21:08:26,586 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 21:08:26,713 - INFO - training batch 551, loss: 0.017, 17632/28000 datapoints
2025-03-06 21:08:26,842 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-06 21:08:26,971 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:27,096 - INFO - training batch 701, loss: 0.027, 22432/28000 datapoints
2025-03-06 21:08:27,219 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-06 21:08:27,348 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 21:08:27,472 - INFO - training batch 851, loss: 0.023, 27232/28000 datapoints
2025-03-06 21:08:27,536 - INFO - validation batch 1, loss: 1.038, 32/6976 datapoints
2025-03-06 21:08:27,580 - INFO - validation batch 51, loss: 3.034, 1632/6976 datapoints
2025-03-06 21:08:27,624 - INFO - validation batch 101, loss: 1.380, 3232/6976 datapoints
2025-03-06 21:08:27,670 - INFO - validation batch 151, loss: 0.660, 4832/6976 datapoints
2025-03-06 21:08:27,717 - INFO - validation batch 201, loss: 0.903, 6432/6976 datapoints
2025-03-06 21:08:27,732 - INFO - Epoch 768/800 done.
2025-03-06 21:08:27,732 - INFO - Final validation performance:
Loss: 1.403, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:27,733 - INFO - Beginning epoch 769/800
2025-03-06 21:08:27,736 - INFO - training batch 1, loss: 0.036, 32/28000 datapoints
2025-03-06 21:08:27,866 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 21:08:27,996 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 21:08:28,121 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-06 21:08:28,243 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 21:08:28,368 - INFO - training batch 251, loss: 0.029, 8032/28000 datapoints
2025-03-06 21:08:28,491 - INFO - training batch 301, loss: 0.028, 9632/28000 datapoints
2025-03-06 21:08:28,613 - INFO - training batch 351, loss: 0.031, 11232/28000 datapoints
2025-03-06 21:08:28,744 - INFO - training batch 401, loss: 0.044, 12832/28000 datapoints
2025-03-06 21:08:28,874 - INFO - training batch 451, loss: 0.024, 14432/28000 datapoints
2025-03-06 21:08:29,000 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-06 21:08:29,128 - INFO - training batch 551, loss: 0.017, 17632/28000 datapoints
2025-03-06 21:08:29,254 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-06 21:08:29,381 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:29,508 - INFO - training batch 701, loss: 0.027, 22432/28000 datapoints
2025-03-06 21:08:29,631 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-06 21:08:29,759 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 21:08:29,887 - INFO - training batch 851, loss: 0.023, 27232/28000 datapoints
2025-03-06 21:08:29,953 - INFO - validation batch 1, loss: 1.048, 32/6976 datapoints
2025-03-06 21:08:29,998 - INFO - validation batch 51, loss: 3.046, 1632/6976 datapoints
2025-03-06 21:08:30,043 - INFO - validation batch 101, loss: 1.389, 3232/6976 datapoints
2025-03-06 21:08:30,088 - INFO - validation batch 151, loss: 0.656, 4832/6976 datapoints
2025-03-06 21:08:30,130 - INFO - validation batch 201, loss: 0.911, 6432/6976 datapoints
2025-03-06 21:08:30,146 - INFO - Epoch 769/800 done.
2025-03-06 21:08:30,146 - INFO - Final validation performance:
Loss: 1.410, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:30,146 - INFO - Beginning epoch 770/800
2025-03-06 21:08:30,150 - INFO - training batch 1, loss: 0.035, 32/28000 datapoints
2025-03-06 21:08:30,284 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 21:08:30,411 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 21:08:30,535 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-06 21:08:30,663 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 21:08:30,788 - INFO - training batch 251, loss: 0.029, 8032/28000 datapoints
2025-03-06 21:08:30,916 - INFO - training batch 301, loss: 0.028, 9632/28000 datapoints
2025-03-06 21:08:31,043 - INFO - training batch 351, loss: 0.030, 11232/28000 datapoints
2025-03-06 21:08:31,178 - INFO - training batch 401, loss: 0.044, 12832/28000 datapoints
2025-03-06 21:08:31,307 - INFO - training batch 451, loss: 0.023, 14432/28000 datapoints
2025-03-06 21:08:31,429 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 21:08:31,572 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 21:08:31,713 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-06 21:08:31,838 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:31,970 - INFO - training batch 701, loss: 0.026, 22432/28000 datapoints
2025-03-06 21:08:32,094 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 21:08:32,218 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 21:08:32,344 - INFO - training batch 851, loss: 0.023, 27232/28000 datapoints
2025-03-06 21:08:32,405 - INFO - validation batch 1, loss: 1.053, 32/6976 datapoints
2025-03-06 21:08:32,450 - INFO - validation batch 51, loss: 3.062, 1632/6976 datapoints
2025-03-06 21:08:32,493 - INFO - validation batch 101, loss: 1.391, 3232/6976 datapoints
2025-03-06 21:08:32,536 - INFO - validation batch 151, loss: 0.656, 4832/6976 datapoints
2025-03-06 21:08:32,580 - INFO - validation batch 201, loss: 0.910, 6432/6976 datapoints
2025-03-06 21:08:32,595 - INFO - Epoch 770/800 done.
2025-03-06 21:08:32,595 - INFO - Final validation performance:
Loss: 1.414, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:32,596 - INFO - Beginning epoch 771/800
2025-03-06 21:08:32,599 - INFO - training batch 1, loss: 0.035, 32/28000 datapoints
2025-03-06 21:08:32,731 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 21:08:32,859 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 21:08:32,991 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-06 21:08:33,120 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 21:08:33,247 - INFO - training batch 251, loss: 0.029, 8032/28000 datapoints
2025-03-06 21:08:33,379 - INFO - training batch 301, loss: 0.028, 9632/28000 datapoints
2025-03-06 21:08:33,508 - INFO - training batch 351, loss: 0.030, 11232/28000 datapoints
2025-03-06 21:08:33,648 - INFO - training batch 401, loss: 0.043, 12832/28000 datapoints
2025-03-06 21:08:33,776 - INFO - training batch 451, loss: 0.023, 14432/28000 datapoints
2025-03-06 21:08:33,916 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 21:08:34,050 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 21:08:34,181 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-06 21:08:34,308 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:34,440 - INFO - training batch 701, loss: 0.026, 22432/28000 datapoints
2025-03-06 21:08:34,569 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 21:08:34,704 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 21:08:34,832 - INFO - training batch 851, loss: 0.022, 27232/28000 datapoints
2025-03-06 21:08:34,904 - INFO - validation batch 1, loss: 1.061, 32/6976 datapoints
2025-03-06 21:08:34,954 - INFO - validation batch 51, loss: 3.068, 1632/6976 datapoints
2025-03-06 21:08:35,006 - INFO - validation batch 101, loss: 1.402, 3232/6976 datapoints
2025-03-06 21:08:35,055 - INFO - validation batch 151, loss: 0.655, 4832/6976 datapoints
2025-03-06 21:08:35,105 - INFO - validation batch 201, loss: 0.915, 6432/6976 datapoints
2025-03-06 21:08:35,121 - INFO - Epoch 771/800 done.
2025-03-06 21:08:35,121 - INFO - Final validation performance:
Loss: 1.420, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:35,122 - INFO - Beginning epoch 772/800
2025-03-06 21:08:35,126 - INFO - training batch 1, loss: 0.034, 32/28000 datapoints
2025-03-06 21:08:35,255 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 21:08:35,386 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 21:08:35,515 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-06 21:08:35,645 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 21:08:35,774 - INFO - training batch 251, loss: 0.029, 8032/28000 datapoints
2025-03-06 21:08:35,905 - INFO - training batch 301, loss: 0.027, 9632/28000 datapoints
2025-03-06 21:08:36,036 - INFO - training batch 351, loss: 0.029, 11232/28000 datapoints
2025-03-06 21:08:36,162 - INFO - training batch 401, loss: 0.043, 12832/28000 datapoints
2025-03-06 21:08:36,294 - INFO - training batch 451, loss: 0.023, 14432/28000 datapoints
2025-03-06 21:08:36,422 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 21:08:36,550 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 21:08:36,680 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-06 21:08:36,807 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:36,938 - INFO - training batch 701, loss: 0.026, 22432/28000 datapoints
2025-03-06 21:08:37,069 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 21:08:37,199 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-06 21:08:37,332 - INFO - training batch 851, loss: 0.022, 27232/28000 datapoints
2025-03-06 21:08:37,399 - INFO - validation batch 1, loss: 1.061, 32/6976 datapoints
2025-03-06 21:08:37,448 - INFO - validation batch 51, loss: 3.084, 1632/6976 datapoints
2025-03-06 21:08:37,495 - INFO - validation batch 101, loss: 1.408, 3232/6976 datapoints
2025-03-06 21:08:37,542 - INFO - validation batch 151, loss: 0.661, 4832/6976 datapoints
2025-03-06 21:08:37,590 - INFO - validation batch 201, loss: 0.919, 6432/6976 datapoints
2025-03-06 21:08:37,607 - INFO - Epoch 772/800 done.
2025-03-06 21:08:37,607 - INFO - Final validation performance:
Loss: 1.427, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:37,608 - INFO - Beginning epoch 773/800
2025-03-06 21:08:37,611 - INFO - training batch 1, loss: 0.034, 32/28000 datapoints
2025-03-06 21:08:37,773 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 21:08:37,903 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 21:08:38,037 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-06 21:08:38,166 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 21:08:38,295 - INFO - training batch 251, loss: 0.028, 8032/28000 datapoints
2025-03-06 21:08:38,425 - INFO - training batch 301, loss: 0.027, 9632/28000 datapoints
2025-03-06 21:08:38,551 - INFO - training batch 351, loss: 0.029, 11232/28000 datapoints
2025-03-06 21:08:38,682 - INFO - training batch 401, loss: 0.042, 12832/28000 datapoints
2025-03-06 21:08:38,808 - INFO - training batch 451, loss: 0.023, 14432/28000 datapoints
2025-03-06 21:08:38,936 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 21:08:39,069 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 21:08:39,197 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-06 21:08:39,324 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:39,454 - INFO - training batch 701, loss: 0.025, 22432/28000 datapoints
2025-03-06 21:08:39,584 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 21:08:39,714 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 21:08:39,845 - INFO - training batch 851, loss: 0.022, 27232/28000 datapoints
2025-03-06 21:08:39,910 - INFO - validation batch 1, loss: 1.068, 32/6976 datapoints
2025-03-06 21:08:39,964 - INFO - validation batch 51, loss: 3.095, 1632/6976 datapoints
2025-03-06 21:08:40,018 - INFO - validation batch 101, loss: 1.415, 3232/6976 datapoints
2025-03-06 21:08:40,073 - INFO - validation batch 151, loss: 0.657, 4832/6976 datapoints
2025-03-06 21:08:40,121 - INFO - validation batch 201, loss: 0.919, 6432/6976 datapoints
2025-03-06 21:08:40,141 - INFO - Epoch 773/800 done.
2025-03-06 21:08:40,141 - INFO - Final validation performance:
Loss: 1.431, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:40,142 - INFO - Beginning epoch 774/800
2025-03-06 21:08:40,146 - INFO - training batch 1, loss: 0.033, 32/28000 datapoints
2025-03-06 21:08:40,276 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 21:08:40,410 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-06 21:08:40,540 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-06 21:08:40,674 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 21:08:40,801 - INFO - training batch 251, loss: 0.028, 8032/28000 datapoints
2025-03-06 21:08:40,932 - INFO - training batch 301, loss: 0.027, 9632/28000 datapoints
2025-03-06 21:08:41,061 - INFO - training batch 351, loss: 0.029, 11232/28000 datapoints
2025-03-06 21:08:41,189 - INFO - training batch 401, loss: 0.041, 12832/28000 datapoints
2025-03-06 21:08:41,317 - INFO - training batch 451, loss: 0.023, 14432/28000 datapoints
2025-03-06 21:08:41,445 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 21:08:41,573 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 21:08:41,730 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-06 21:08:41,861 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:41,998 - INFO - training batch 701, loss: 0.025, 22432/28000 datapoints
2025-03-06 21:08:42,126 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 21:08:42,253 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 21:08:42,406 - INFO - training batch 851, loss: 0.021, 27232/28000 datapoints
2025-03-06 21:08:42,479 - INFO - validation batch 1, loss: 1.077, 32/6976 datapoints
2025-03-06 21:08:42,523 - INFO - validation batch 51, loss: 3.110, 1632/6976 datapoints
2025-03-06 21:08:42,567 - INFO - validation batch 101, loss: 1.420, 3232/6976 datapoints
2025-03-06 21:08:42,611 - INFO - validation batch 151, loss: 0.655, 4832/6976 datapoints
2025-03-06 21:08:42,658 - INFO - validation batch 201, loss: 0.929, 6432/6976 datapoints
2025-03-06 21:08:42,673 - INFO - Epoch 774/800 done.
2025-03-06 21:08:42,674 - INFO - Final validation performance:
Loss: 1.438, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:42,674 - INFO - Beginning epoch 775/800
2025-03-06 21:08:42,678 - INFO - training batch 1, loss: 0.032, 32/28000 datapoints
2025-03-06 21:08:42,809 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 21:08:42,936 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-06 21:08:43,062 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-06 21:08:43,186 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 21:08:43,311 - INFO - training batch 251, loss: 0.028, 8032/28000 datapoints
2025-03-06 21:08:43,437 - INFO - training batch 301, loss: 0.026, 9632/28000 datapoints
2025-03-06 21:08:43,562 - INFO - training batch 351, loss: 0.028, 11232/28000 datapoints
2025-03-06 21:08:43,688 - INFO - training batch 401, loss: 0.040, 12832/28000 datapoints
2025-03-06 21:08:43,814 - INFO - training batch 451, loss: 0.022, 14432/28000 datapoints
2025-03-06 21:08:43,938 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 21:08:44,078 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-06 21:08:44,206 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-06 21:08:44,329 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:44,457 - INFO - training batch 701, loss: 0.025, 22432/28000 datapoints
2025-03-06 21:08:44,579 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 21:08:44,706 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 21:08:44,832 - INFO - training batch 851, loss: 0.021, 27232/28000 datapoints
2025-03-06 21:08:44,900 - INFO - validation batch 1, loss: 1.083, 32/6976 datapoints
2025-03-06 21:08:44,948 - INFO - validation batch 51, loss: 3.116, 1632/6976 datapoints
2025-03-06 21:08:44,992 - INFO - validation batch 101, loss: 1.432, 3232/6976 datapoints
2025-03-06 21:08:45,037 - INFO - validation batch 151, loss: 0.660, 4832/6976 datapoints
2025-03-06 21:08:45,082 - INFO - validation batch 201, loss: 0.929, 6432/6976 datapoints
2025-03-06 21:08:45,098 - INFO - Epoch 775/800 done.
2025-03-06 21:08:45,098 - INFO - Final validation performance:
Loss: 1.444, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:45,099 - INFO - Beginning epoch 776/800
2025-03-06 21:08:45,102 - INFO - training batch 1, loss: 0.033, 32/28000 datapoints
2025-03-06 21:08:45,228 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 21:08:45,353 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-06 21:08:45,479 - INFO - training batch 151, loss: 0.013, 4832/28000 datapoints
2025-03-06 21:08:45,604 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 21:08:45,732 - INFO - training batch 251, loss: 0.027, 8032/28000 datapoints
2025-03-06 21:08:45,867 - INFO - training batch 301, loss: 0.026, 9632/28000 datapoints
2025-03-06 21:08:46,015 - INFO - training batch 351, loss: 0.028, 11232/28000 datapoints
2025-03-06 21:08:46,138 - INFO - training batch 401, loss: 0.040, 12832/28000 datapoints
2025-03-06 21:08:46,263 - INFO - training batch 451, loss: 0.022, 14432/28000 datapoints
2025-03-06 21:08:46,388 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-06 21:08:46,517 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-06 21:08:46,644 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 21:08:46,768 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:46,892 - INFO - training batch 701, loss: 0.025, 22432/28000 datapoints
2025-03-06 21:08:47,020 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 21:08:47,146 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 21:08:47,273 - INFO - training batch 851, loss: 0.021, 27232/28000 datapoints
2025-03-06 21:08:47,333 - INFO - validation batch 1, loss: 1.089, 32/6976 datapoints
2025-03-06 21:08:47,379 - INFO - validation batch 51, loss: 3.135, 1632/6976 datapoints
2025-03-06 21:08:47,423 - INFO - validation batch 101, loss: 1.440, 3232/6976 datapoints
2025-03-06 21:08:47,468 - INFO - validation batch 151, loss: 0.658, 4832/6976 datapoints
2025-03-06 21:08:47,514 - INFO - validation batch 201, loss: 0.934, 6432/6976 datapoints
2025-03-06 21:08:47,529 - INFO - Epoch 776/800 done.
2025-03-06 21:08:47,529 - INFO - Final validation performance:
Loss: 1.451, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:47,529 - INFO - Beginning epoch 777/800
2025-03-06 21:08:47,533 - INFO - training batch 1, loss: 0.032, 32/28000 datapoints
2025-03-06 21:08:47,661 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 21:08:47,790 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-06 21:08:47,915 - INFO - training batch 151, loss: 0.013, 4832/28000 datapoints
2025-03-06 21:08:48,045 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 21:08:48,170 - INFO - training batch 251, loss: 0.027, 8032/28000 datapoints
2025-03-06 21:08:48,304 - INFO - training batch 301, loss: 0.026, 9632/28000 datapoints
2025-03-06 21:08:48,439 - INFO - training batch 351, loss: 0.028, 11232/28000 datapoints
2025-03-06 21:08:48,565 - INFO - training batch 401, loss: 0.040, 12832/28000 datapoints
2025-03-06 21:08:48,694 - INFO - training batch 451, loss: 0.022, 14432/28000 datapoints
2025-03-06 21:08:48,826 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 21:08:48,956 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-06 21:08:49,083 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 21:08:49,212 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-06 21:08:49,338 - INFO - training batch 701, loss: 0.024, 22432/28000 datapoints
2025-03-06 21:08:49,462 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-06 21:08:49,589 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 21:08:49,718 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-06 21:08:49,779 - INFO - validation batch 1, loss: 1.092, 32/6976 datapoints
2025-03-06 21:08:49,823 - INFO - validation batch 51, loss: 3.144, 1632/6976 datapoints
2025-03-06 21:08:49,868 - INFO - validation batch 101, loss: 1.449, 3232/6976 datapoints
2025-03-06 21:08:49,913 - INFO - validation batch 151, loss: 0.662, 4832/6976 datapoints
2025-03-06 21:08:49,959 - INFO - validation batch 201, loss: 0.940, 6432/6976 datapoints
2025-03-06 21:08:49,977 - INFO - Epoch 777/800 done.
2025-03-06 21:08:49,978 - INFO - Final validation performance:
Loss: 1.457, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:49,978 - INFO - Beginning epoch 778/800
2025-03-06 21:08:49,982 - INFO - training batch 1, loss: 0.031, 32/28000 datapoints
2025-03-06 21:08:50,115 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 21:08:50,240 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-06 21:08:50,366 - INFO - training batch 151, loss: 0.013, 4832/28000 datapoints
2025-03-06 21:08:50,491 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 21:08:50,618 - INFO - training batch 251, loss: 0.027, 8032/28000 datapoints
2025-03-06 21:08:50,748 - INFO - training batch 301, loss: 0.026, 9632/28000 datapoints
2025-03-06 21:08:50,872 - INFO - training batch 351, loss: 0.028, 11232/28000 datapoints
2025-03-06 21:08:50,996 - INFO - training batch 401, loss: 0.040, 12832/28000 datapoints
2025-03-06 21:08:51,123 - INFO - training batch 451, loss: 0.022, 14432/28000 datapoints
2025-03-06 21:08:51,245 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 21:08:51,368 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-06 21:08:51,493 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 21:08:51,617 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:08:51,767 - INFO - training batch 701, loss: 0.024, 22432/28000 datapoints
2025-03-06 21:08:52,048 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-06 21:08:52,173 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-06 21:08:52,302 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-06 21:08:52,363 - INFO - validation batch 1, loss: 1.103, 32/6976 datapoints
2025-03-06 21:08:52,407 - INFO - validation batch 51, loss: 3.159, 1632/6976 datapoints
2025-03-06 21:08:52,452 - INFO - validation batch 101, loss: 1.452, 3232/6976 datapoints
2025-03-06 21:08:52,498 - INFO - validation batch 151, loss: 0.658, 4832/6976 datapoints
2025-03-06 21:08:52,544 - INFO - validation batch 201, loss: 0.940, 6432/6976 datapoints
2025-03-06 21:08:52,559 - INFO - Epoch 778/800 done.
2025-03-06 21:08:52,559 - INFO - Final validation performance:
Loss: 1.462, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:52,560 - INFO - Beginning epoch 779/800
2025-03-06 21:08:52,563 - INFO - training batch 1, loss: 0.031, 32/28000 datapoints
2025-03-06 21:08:52,692 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 21:08:52,816 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-06 21:08:52,940 - INFO - training batch 151, loss: 0.013, 4832/28000 datapoints
2025-03-06 21:08:53,069 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 21:08:53,203 - INFO - training batch 251, loss: 0.026, 8032/28000 datapoints
2025-03-06 21:08:53,337 - INFO - training batch 301, loss: 0.025, 9632/28000 datapoints
2025-03-06 21:08:53,462 - INFO - training batch 351, loss: 0.027, 11232/28000 datapoints
2025-03-06 21:08:53,593 - INFO - training batch 401, loss: 0.038, 12832/28000 datapoints
2025-03-06 21:08:53,727 - INFO - training batch 451, loss: 0.021, 14432/28000 datapoints
2025-03-06 21:08:53,857 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 21:08:53,994 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-06 21:08:54,125 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 21:08:54,254 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:08:54,388 - INFO - training batch 701, loss: 0.024, 22432/28000 datapoints
2025-03-06 21:08:54,526 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-06 21:08:54,659 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 21:08:54,790 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-06 21:08:54,854 - INFO - validation batch 1, loss: 1.107, 32/6976 datapoints
2025-03-06 21:08:54,909 - INFO - validation batch 51, loss: 3.172, 1632/6976 datapoints
2025-03-06 21:08:54,968 - INFO - validation batch 101, loss: 1.465, 3232/6976 datapoints
2025-03-06 21:08:55,016 - INFO - validation batch 151, loss: 0.661, 4832/6976 datapoints
2025-03-06 21:08:55,067 - INFO - validation batch 201, loss: 0.950, 6432/6976 datapoints
2025-03-06 21:08:55,089 - INFO - Epoch 779/800 done.
2025-03-06 21:08:55,089 - INFO - Final validation performance:
Loss: 1.471, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:55,090 - INFO - Beginning epoch 780/800
2025-03-06 21:08:55,094 - INFO - training batch 1, loss: 0.031, 32/28000 datapoints
2025-03-06 21:08:55,226 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 21:08:55,355 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 21:08:55,484 - INFO - training batch 151, loss: 0.013, 4832/28000 datapoints
2025-03-06 21:08:55,616 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 21:08:55,749 - INFO - training batch 251, loss: 0.026, 8032/28000 datapoints
2025-03-06 21:08:55,878 - INFO - training batch 301, loss: 0.025, 9632/28000 datapoints
2025-03-06 21:08:56,017 - INFO - training batch 351, loss: 0.027, 11232/28000 datapoints
2025-03-06 21:08:56,150 - INFO - training batch 401, loss: 0.038, 12832/28000 datapoints
2025-03-06 21:08:56,278 - INFO - training batch 451, loss: 0.021, 14432/28000 datapoints
2025-03-06 21:08:56,407 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 21:08:56,535 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 21:08:56,671 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 21:08:56,798 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:08:56,928 - INFO - training batch 701, loss: 0.023, 22432/28000 datapoints
2025-03-06 21:08:57,082 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-06 21:08:57,231 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 21:08:57,364 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-06 21:08:57,430 - INFO - validation batch 1, loss: 1.114, 32/6976 datapoints
2025-03-06 21:08:57,477 - INFO - validation batch 51, loss: 3.184, 1632/6976 datapoints
2025-03-06 21:08:57,521 - INFO - validation batch 101, loss: 1.470, 3232/6976 datapoints
2025-03-06 21:08:57,569 - INFO - validation batch 151, loss: 0.663, 4832/6976 datapoints
2025-03-06 21:08:57,625 - INFO - validation batch 201, loss: 0.950, 6432/6976 datapoints
2025-03-06 21:08:57,645 - INFO - Epoch 780/800 done.
2025-03-06 21:08:57,645 - INFO - Final validation performance:
Loss: 1.476, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:08:57,646 - INFO - Beginning epoch 781/800
2025-03-06 21:08:57,649 - INFO - training batch 1, loss: 0.030, 32/28000 datapoints
2025-03-06 21:08:57,778 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 21:08:57,902 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 21:08:58,032 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 21:08:58,160 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 21:08:58,287 - INFO - training batch 251, loss: 0.026, 8032/28000 datapoints
2025-03-06 21:08:58,415 - INFO - training batch 301, loss: 0.025, 9632/28000 datapoints
2025-03-06 21:08:58,543 - INFO - training batch 351, loss: 0.026, 11232/28000 datapoints
2025-03-06 21:08:58,672 - INFO - training batch 401, loss: 0.037, 12832/28000 datapoints
2025-03-06 21:08:58,798 - INFO - training batch 451, loss: 0.021, 14432/28000 datapoints
2025-03-06 21:08:58,923 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 21:08:59,047 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-06 21:08:59,175 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 21:08:59,305 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:08:59,430 - INFO - training batch 701, loss: 0.023, 22432/28000 datapoints
2025-03-06 21:08:59,558 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-06 21:08:59,686 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 21:08:59,812 - INFO - training batch 851, loss: 0.019, 27232/28000 datapoints
2025-03-06 21:08:59,873 - INFO - validation batch 1, loss: 1.118, 32/6976 datapoints
2025-03-06 21:08:59,917 - INFO - validation batch 51, loss: 3.201, 1632/6976 datapoints
2025-03-06 21:08:59,962 - INFO - validation batch 101, loss: 1.477, 3232/6976 datapoints
2025-03-06 21:09:00,013 - INFO - validation batch 151, loss: 0.662, 4832/6976 datapoints
2025-03-06 21:09:00,059 - INFO - validation batch 201, loss: 0.954, 6432/6976 datapoints
2025-03-06 21:09:00,075 - INFO - Epoch 781/800 done.
2025-03-06 21:09:00,075 - INFO - Final validation performance:
Loss: 1.482, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:00,076 - INFO - Beginning epoch 782/800
2025-03-06 21:09:00,079 - INFO - training batch 1, loss: 0.030, 32/28000 datapoints
2025-03-06 21:09:00,208 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 21:09:00,333 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 21:09:00,458 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 21:09:00,582 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 21:09:00,727 - INFO - training batch 251, loss: 0.025, 8032/28000 datapoints
2025-03-06 21:09:00,853 - INFO - training batch 301, loss: 0.024, 9632/28000 datapoints
2025-03-06 21:09:00,977 - INFO - training batch 351, loss: 0.026, 11232/28000 datapoints
2025-03-06 21:09:01,102 - INFO - training batch 401, loss: 0.037, 12832/28000 datapoints
2025-03-06 21:09:01,241 - INFO - training batch 451, loss: 0.021, 14432/28000 datapoints
2025-03-06 21:09:01,371 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 21:09:01,496 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 21:09:01,624 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 21:09:01,752 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:01,889 - INFO - training batch 701, loss: 0.022, 22432/28000 datapoints
2025-03-06 21:09:02,036 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-06 21:09:02,163 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 21:09:02,292 - INFO - training batch 851, loss: 0.019, 27232/28000 datapoints
2025-03-06 21:09:02,352 - INFO - validation batch 1, loss: 1.131, 32/6976 datapoints
2025-03-06 21:09:02,396 - INFO - validation batch 51, loss: 3.213, 1632/6976 datapoints
2025-03-06 21:09:02,440 - INFO - validation batch 101, loss: 1.485, 3232/6976 datapoints
2025-03-06 21:09:02,484 - INFO - validation batch 151, loss: 0.658, 4832/6976 datapoints
2025-03-06 21:09:02,528 - INFO - validation batch 201, loss: 0.955, 6432/6976 datapoints
2025-03-06 21:09:02,543 - INFO - Epoch 782/800 done.
2025-03-06 21:09:02,543 - INFO - Final validation performance:
Loss: 1.488, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:02,543 - INFO - Beginning epoch 783/800
2025-03-06 21:09:02,547 - INFO - training batch 1, loss: 0.029, 32/28000 datapoints
2025-03-06 21:09:02,678 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 21:09:02,803 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 21:09:02,927 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 21:09:03,054 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 21:09:03,184 - INFO - training batch 251, loss: 0.025, 8032/28000 datapoints
2025-03-06 21:09:03,312 - INFO - training batch 301, loss: 0.024, 9632/28000 datapoints
2025-03-06 21:09:03,435 - INFO - training batch 351, loss: 0.025, 11232/28000 datapoints
2025-03-06 21:09:03,563 - INFO - training batch 401, loss: 0.036, 12832/28000 datapoints
2025-03-06 21:09:03,694 - INFO - training batch 451, loss: 0.020, 14432/28000 datapoints
2025-03-06 21:09:03,817 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 21:09:03,941 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 21:09:04,074 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 21:09:04,199 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:04,326 - INFO - training batch 701, loss: 0.022, 22432/28000 datapoints
2025-03-06 21:09:04,452 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-06 21:09:04,577 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 21:09:04,711 - INFO - training batch 851, loss: 0.019, 27232/28000 datapoints
2025-03-06 21:09:04,772 - INFO - validation batch 1, loss: 1.132, 32/6976 datapoints
2025-03-06 21:09:04,818 - INFO - validation batch 51, loss: 3.223, 1632/6976 datapoints
2025-03-06 21:09:04,862 - INFO - validation batch 101, loss: 1.496, 3232/6976 datapoints
2025-03-06 21:09:04,909 - INFO - validation batch 151, loss: 0.668, 4832/6976 datapoints
2025-03-06 21:09:04,958 - INFO - validation batch 201, loss: 0.964, 6432/6976 datapoints
2025-03-06 21:09:04,973 - INFO - Epoch 783/800 done.
2025-03-06 21:09:04,974 - INFO - Final validation performance:
Loss: 1.496, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:04,974 - INFO - Beginning epoch 784/800
2025-03-06 21:09:04,978 - INFO - training batch 1, loss: 0.029, 32/28000 datapoints
2025-03-06 21:09:05,106 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:09:05,236 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 21:09:05,361 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 21:09:05,486 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 21:09:05,614 - INFO - training batch 251, loss: 0.025, 8032/28000 datapoints
2025-03-06 21:09:05,742 - INFO - training batch 301, loss: 0.024, 9632/28000 datapoints
2025-03-06 21:09:05,867 - INFO - training batch 351, loss: 0.025, 11232/28000 datapoints
2025-03-06 21:09:05,989 - INFO - training batch 401, loss: 0.036, 12832/28000 datapoints
2025-03-06 21:09:06,119 - INFO - training batch 451, loss: 0.020, 14432/28000 datapoints
2025-03-06 21:09:06,245 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 21:09:06,370 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 21:09:06,494 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 21:09:06,618 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:06,759 - INFO - training batch 701, loss: 0.023, 22432/28000 datapoints
2025-03-06 21:09:06,889 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 21:09:07,015 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-06 21:09:07,149 - INFO - training batch 851, loss: 0.019, 27232/28000 datapoints
2025-03-06 21:09:07,215 - INFO - validation batch 1, loss: 1.138, 32/6976 datapoints
2025-03-06 21:09:07,259 - INFO - validation batch 51, loss: 3.239, 1632/6976 datapoints
2025-03-06 21:09:07,306 - INFO - validation batch 101, loss: 1.499, 3232/6976 datapoints
2025-03-06 21:09:07,351 - INFO - validation batch 151, loss: 0.660, 4832/6976 datapoints
2025-03-06 21:09:07,396 - INFO - validation batch 201, loss: 0.970, 6432/6976 datapoints
2025-03-06 21:09:07,411 - INFO - Epoch 784/800 done.
2025-03-06 21:09:07,412 - INFO - Final validation performance:
Loss: 1.501, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:07,412 - INFO - Beginning epoch 785/800
2025-03-06 21:09:07,416 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-06 21:09:07,546 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:09:07,675 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 21:09:07,808 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 21:09:07,931 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 21:09:08,061 - INFO - training batch 251, loss: 0.024, 8032/28000 datapoints
2025-03-06 21:09:08,187 - INFO - training batch 301, loss: 0.024, 9632/28000 datapoints
2025-03-06 21:09:08,312 - INFO - training batch 351, loss: 0.024, 11232/28000 datapoints
2025-03-06 21:09:08,437 - INFO - training batch 401, loss: 0.035, 12832/28000 datapoints
2025-03-06 21:09:08,563 - INFO - training batch 451, loss: 0.020, 14432/28000 datapoints
2025-03-06 21:09:08,690 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 21:09:08,813 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 21:09:08,941 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 21:09:09,077 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:09,209 - INFO - training batch 701, loss: 0.022, 22432/28000 datapoints
2025-03-06 21:09:09,338 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 21:09:09,464 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 21:09:09,601 - INFO - training batch 851, loss: 0.018, 27232/28000 datapoints
2025-03-06 21:09:09,666 - INFO - validation batch 1, loss: 1.150, 32/6976 datapoints
2025-03-06 21:09:09,713 - INFO - validation batch 51, loss: 3.255, 1632/6976 datapoints
2025-03-06 21:09:09,758 - INFO - validation batch 101, loss: 1.512, 3232/6976 datapoints
2025-03-06 21:09:09,803 - INFO - validation batch 151, loss: 0.662, 4832/6976 datapoints
2025-03-06 21:09:09,846 - INFO - validation batch 201, loss: 0.973, 6432/6976 datapoints
2025-03-06 21:09:09,861 - INFO - Epoch 785/800 done.
2025-03-06 21:09:09,862 - INFO - Final validation performance:
Loss: 1.510, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:09,862 - INFO - Beginning epoch 786/800
2025-03-06 21:09:09,866 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-06 21:09:09,992 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 21:09:10,124 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 21:09:10,266 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 21:09:10,393 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 21:09:10,521 - INFO - training batch 251, loss: 0.024, 8032/28000 datapoints
2025-03-06 21:09:10,652 - INFO - training batch 301, loss: 0.024, 9632/28000 datapoints
2025-03-06 21:09:10,777 - INFO - training batch 351, loss: 0.024, 11232/28000 datapoints
2025-03-06 21:09:10,902 - INFO - training batch 401, loss: 0.035, 12832/28000 datapoints
2025-03-06 21:09:11,027 - INFO - training batch 451, loss: 0.020, 14432/28000 datapoints
2025-03-06 21:09:11,151 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-06 21:09:11,280 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 21:09:11,406 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 21:09:11,530 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:11,659 - INFO - training batch 701, loss: 0.022, 22432/28000 datapoints
2025-03-06 21:09:11,786 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 21:09:11,911 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 21:09:12,068 - INFO - training batch 851, loss: 0.018, 27232/28000 datapoints
2025-03-06 21:09:12,132 - INFO - validation batch 1, loss: 1.152, 32/6976 datapoints
2025-03-06 21:09:12,176 - INFO - validation batch 51, loss: 3.263, 1632/6976 datapoints
2025-03-06 21:09:12,221 - INFO - validation batch 101, loss: 1.518, 3232/6976 datapoints
2025-03-06 21:09:12,265 - INFO - validation batch 151, loss: 0.662, 4832/6976 datapoints
2025-03-06 21:09:12,312 - INFO - validation batch 201, loss: 0.976, 6432/6976 datapoints
2025-03-06 21:09:12,327 - INFO - Epoch 786/800 done.
2025-03-06 21:09:12,327 - INFO - Final validation performance:
Loss: 1.514, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:09:12,328 - INFO - Beginning epoch 787/800
2025-03-06 21:09:12,331 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-06 21:09:12,455 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:09:12,581 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-06 21:09:12,717 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 21:09:12,852 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 21:09:12,977 - INFO - training batch 251, loss: 0.024, 8032/28000 datapoints
2025-03-06 21:09:13,104 - INFO - training batch 301, loss: 0.023, 9632/28000 datapoints
2025-03-06 21:09:13,244 - INFO - training batch 351, loss: 0.024, 11232/28000 datapoints
2025-03-06 21:09:13,378 - INFO - training batch 401, loss: 0.034, 12832/28000 datapoints
2025-03-06 21:09:13,509 - INFO - training batch 451, loss: 0.019, 14432/28000 datapoints
2025-03-06 21:09:13,645 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 21:09:13,776 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-06 21:09:13,907 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 21:09:14,037 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:14,176 - INFO - training batch 701, loss: 0.021, 22432/28000 datapoints
2025-03-06 21:09:14,310 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 21:09:14,438 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 21:09:14,575 - INFO - training batch 851, loss: 0.018, 27232/28000 datapoints
2025-03-06 21:09:14,642 - INFO - validation batch 1, loss: 1.160, 32/6976 datapoints
2025-03-06 21:09:14,689 - INFO - validation batch 51, loss: 3.278, 1632/6976 datapoints
2025-03-06 21:09:14,738 - INFO - validation batch 101, loss: 1.530, 3232/6976 datapoints
2025-03-06 21:09:14,785 - INFO - validation batch 151, loss: 0.671, 4832/6976 datapoints
2025-03-06 21:09:14,831 - INFO - validation batch 201, loss: 0.982, 6432/6976 datapoints
2025-03-06 21:09:14,846 - INFO - Epoch 787/800 done.
2025-03-06 21:09:14,846 - INFO - Final validation performance:
Loss: 1.524, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:14,847 - INFO - Beginning epoch 788/800
2025-03-06 21:09:14,850 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-06 21:09:14,983 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:09:15,113 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 21:09:15,237 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 21:09:15,363 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 21:09:15,490 - INFO - training batch 251, loss: 0.023, 8032/28000 datapoints
2025-03-06 21:09:15,618 - INFO - training batch 301, loss: 0.023, 9632/28000 datapoints
2025-03-06 21:09:15,746 - INFO - training batch 351, loss: 0.024, 11232/28000 datapoints
2025-03-06 21:09:15,871 - INFO - training batch 401, loss: 0.034, 12832/28000 datapoints
2025-03-06 21:09:15,995 - INFO - training batch 451, loss: 0.019, 14432/28000 datapoints
2025-03-06 21:09:16,122 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 21:09:16,247 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 21:09:16,374 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 21:09:16,499 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:16,622 - INFO - training batch 701, loss: 0.022, 22432/28000 datapoints
2025-03-06 21:09:16,752 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 21:09:16,874 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 21:09:17,002 - INFO - training batch 851, loss: 0.018, 27232/28000 datapoints
2025-03-06 21:09:17,066 - INFO - validation batch 1, loss: 1.165, 32/6976 datapoints
2025-03-06 21:09:17,110 - INFO - validation batch 51, loss: 3.292, 1632/6976 datapoints
2025-03-06 21:09:17,154 - INFO - validation batch 101, loss: 1.538, 3232/6976 datapoints
2025-03-06 21:09:17,199 - INFO - validation batch 151, loss: 0.661, 4832/6976 datapoints
2025-03-06 21:09:17,243 - INFO - validation batch 201, loss: 0.985, 6432/6976 datapoints
2025-03-06 21:09:17,258 - INFO - Epoch 788/800 done.
2025-03-06 21:09:17,258 - INFO - Final validation performance:
Loss: 1.528, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:09:17,259 - INFO - Beginning epoch 789/800
2025-03-06 21:09:17,263 - INFO - training batch 1, loss: 0.027, 32/28000 datapoints
2025-03-06 21:09:17,401 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:09:17,530 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 21:09:17,660 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 21:09:17,786 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 21:09:17,913 - INFO - training batch 251, loss: 0.024, 8032/28000 datapoints
2025-03-06 21:09:18,039 - INFO - training batch 301, loss: 0.023, 9632/28000 datapoints
2025-03-06 21:09:18,168 - INFO - training batch 351, loss: 0.023, 11232/28000 datapoints
2025-03-06 21:09:18,292 - INFO - training batch 401, loss: 0.033, 12832/28000 datapoints
2025-03-06 21:09:18,420 - INFO - training batch 451, loss: 0.019, 14432/28000 datapoints
2025-03-06 21:09:18,544 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 21:09:18,670 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 21:09:18,800 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 21:09:18,936 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:19,063 - INFO - training batch 701, loss: 0.020, 22432/28000 datapoints
2025-03-06 21:09:19,190 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 21:09:19,324 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 21:09:19,457 - INFO - training batch 851, loss: 0.017, 27232/28000 datapoints
2025-03-06 21:09:19,519 - INFO - validation batch 1, loss: 1.170, 32/6976 datapoints
2025-03-06 21:09:19,562 - INFO - validation batch 51, loss: 3.308, 1632/6976 datapoints
2025-03-06 21:09:19,607 - INFO - validation batch 101, loss: 1.543, 3232/6976 datapoints
2025-03-06 21:09:19,658 - INFO - validation batch 151, loss: 0.661, 4832/6976 datapoints
2025-03-06 21:09:19,702 - INFO - validation batch 201, loss: 0.994, 6432/6976 datapoints
2025-03-06 21:09:19,717 - INFO - Epoch 789/800 done.
2025-03-06 21:09:19,717 - INFO - Final validation performance:
Loss: 1.535, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:19,718 - INFO - Beginning epoch 790/800
2025-03-06 21:09:19,721 - INFO - training batch 1, loss: 0.026, 32/28000 datapoints
2025-03-06 21:09:19,846 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:09:19,974 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 21:09:20,106 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-06 21:09:20,244 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 21:09:20,380 - INFO - training batch 251, loss: 0.023, 8032/28000 datapoints
2025-03-06 21:09:20,508 - INFO - training batch 301, loss: 0.022, 9632/28000 datapoints
2025-03-06 21:09:20,633 - INFO - training batch 351, loss: 0.023, 11232/28000 datapoints
2025-03-06 21:09:20,760 - INFO - training batch 401, loss: 0.033, 12832/28000 datapoints
2025-03-06 21:09:20,887 - INFO - training batch 451, loss: 0.019, 14432/28000 datapoints
2025-03-06 21:09:21,012 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 21:09:21,139 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 21:09:21,264 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 21:09:21,388 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:21,517 - INFO - training batch 701, loss: 0.021, 22432/28000 datapoints
2025-03-06 21:09:21,645 - INFO - training batch 751, loss: 0.012, 24032/28000 datapoints
2025-03-06 21:09:21,772 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 21:09:21,899 - INFO - training batch 851, loss: 0.017, 27232/28000 datapoints
2025-03-06 21:09:21,964 - INFO - validation batch 1, loss: 1.179, 32/6976 datapoints
2025-03-06 21:09:22,009 - INFO - validation batch 51, loss: 3.318, 1632/6976 datapoints
2025-03-06 21:09:22,062 - INFO - validation batch 101, loss: 1.553, 3232/6976 datapoints
2025-03-06 21:09:22,130 - INFO - validation batch 151, loss: 0.667, 4832/6976 datapoints
2025-03-06 21:09:22,176 - INFO - validation batch 201, loss: 0.990, 6432/6976 datapoints
2025-03-06 21:09:22,191 - INFO - Epoch 790/800 done.
2025-03-06 21:09:22,191 - INFO - Final validation performance:
Loss: 1.541, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:22,192 - INFO - Beginning epoch 791/800
2025-03-06 21:09:22,195 - INFO - training batch 1, loss: 0.027, 32/28000 datapoints
2025-03-06 21:09:22,322 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:09:22,451 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-06 21:09:22,573 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 21:09:22,701 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 21:09:22,826 - INFO - training batch 251, loss: 0.023, 8032/28000 datapoints
2025-03-06 21:09:22,955 - INFO - training batch 301, loss: 0.022, 9632/28000 datapoints
2025-03-06 21:09:23,081 - INFO - training batch 351, loss: 0.023, 11232/28000 datapoints
2025-03-06 21:09:23,203 - INFO - training batch 401, loss: 0.032, 12832/28000 datapoints
2025-03-06 21:09:23,329 - INFO - training batch 451, loss: 0.019, 14432/28000 datapoints
2025-03-06 21:09:23,455 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 21:09:23,579 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 21:09:23,707 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 21:09:23,830 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:23,958 - INFO - training batch 701, loss: 0.021, 22432/28000 datapoints
2025-03-06 21:09:24,088 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-06 21:09:24,217 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-06 21:09:24,347 - INFO - training batch 851, loss: 0.017, 27232/28000 datapoints
2025-03-06 21:09:24,409 - INFO - validation batch 1, loss: 1.179, 32/6976 datapoints
2025-03-06 21:09:24,454 - INFO - validation batch 51, loss: 3.333, 1632/6976 datapoints
2025-03-06 21:09:24,498 - INFO - validation batch 101, loss: 1.560, 3232/6976 datapoints
2025-03-06 21:09:24,542 - INFO - validation batch 151, loss: 0.667, 4832/6976 datapoints
2025-03-06 21:09:24,586 - INFO - validation batch 201, loss: 0.998, 6432/6976 datapoints
2025-03-06 21:09:24,601 - INFO - Epoch 791/800 done.
2025-03-06 21:09:24,601 - INFO - Final validation performance:
Loss: 1.547, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:24,602 - INFO - Beginning epoch 792/800
2025-03-06 21:09:24,605 - INFO - training batch 1, loss: 0.026, 32/28000 datapoints
2025-03-06 21:09:24,734 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:09:24,873 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-06 21:09:25,008 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 21:09:25,134 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 21:09:25,261 - INFO - training batch 251, loss: 0.022, 8032/28000 datapoints
2025-03-06 21:09:25,400 - INFO - training batch 301, loss: 0.022, 9632/28000 datapoints
2025-03-06 21:09:25,531 - INFO - training batch 351, loss: 0.022, 11232/28000 datapoints
2025-03-06 21:09:25,657 - INFO - training batch 401, loss: 0.032, 12832/28000 datapoints
2025-03-06 21:09:25,785 - INFO - training batch 451, loss: 0.019, 14432/28000 datapoints
2025-03-06 21:09:25,909 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-06 21:09:26,035 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 21:09:26,168 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 21:09:26,294 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:26,420 - INFO - training batch 701, loss: 0.020, 22432/28000 datapoints
2025-03-06 21:09:26,547 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-06 21:09:26,673 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 21:09:26,799 - INFO - training batch 851, loss: 0.017, 27232/28000 datapoints
2025-03-06 21:09:26,861 - INFO - validation batch 1, loss: 1.190, 32/6976 datapoints
2025-03-06 21:09:26,905 - INFO - validation batch 51, loss: 3.348, 1632/6976 datapoints
2025-03-06 21:09:26,950 - INFO - validation batch 101, loss: 1.571, 3232/6976 datapoints
2025-03-06 21:09:26,995 - INFO - validation batch 151, loss: 0.662, 4832/6976 datapoints
2025-03-06 21:09:27,040 - INFO - validation batch 201, loss: 1.002, 6432/6976 datapoints
2025-03-06 21:09:27,055 - INFO - Epoch 792/800 done.
2025-03-06 21:09:27,056 - INFO - Final validation performance:
Loss: 1.554, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:27,056 - INFO - Beginning epoch 793/800
2025-03-06 21:09:27,060 - INFO - training batch 1, loss: 0.026, 32/28000 datapoints
2025-03-06 21:09:27,186 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:09:27,315 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-06 21:09:27,442 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 21:09:27,569 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 21:09:27,697 - INFO - training batch 251, loss: 0.022, 8032/28000 datapoints
2025-03-06 21:09:27,824 - INFO - training batch 301, loss: 0.022, 9632/28000 datapoints
2025-03-06 21:09:27,948 - INFO - training batch 351, loss: 0.022, 11232/28000 datapoints
2025-03-06 21:09:28,075 - INFO - training batch 401, loss: 0.031, 12832/28000 datapoints
2025-03-06 21:09:28,203 - INFO - training batch 451, loss: 0.018, 14432/28000 datapoints
2025-03-06 21:09:28,333 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 21:09:28,459 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 21:09:28,585 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 21:09:28,720 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:28,849 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-06 21:09:28,974 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-06 21:09:29,098 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 21:09:29,225 - INFO - training batch 851, loss: 0.016, 27232/28000 datapoints
2025-03-06 21:09:29,288 - INFO - validation batch 1, loss: 1.196, 32/6976 datapoints
2025-03-06 21:09:29,331 - INFO - validation batch 51, loss: 3.368, 1632/6976 datapoints
2025-03-06 21:09:29,376 - INFO - validation batch 101, loss: 1.576, 3232/6976 datapoints
2025-03-06 21:09:29,421 - INFO - validation batch 151, loss: 0.665, 4832/6976 datapoints
2025-03-06 21:09:29,466 - INFO - validation batch 201, loss: 1.012, 6432/6976 datapoints
2025-03-06 21:09:29,481 - INFO - Epoch 793/800 done.
2025-03-06 21:09:29,482 - INFO - Final validation performance:
Loss: 1.564, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:29,482 - INFO - Beginning epoch 794/800
2025-03-06 21:09:29,485 - INFO - training batch 1, loss: 0.025, 32/28000 datapoints
2025-03-06 21:09:29,613 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:09:29,747 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-06 21:09:29,873 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 21:09:29,998 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 21:09:30,128 - INFO - training batch 251, loss: 0.021, 8032/28000 datapoints
2025-03-06 21:09:30,259 - INFO - training batch 301, loss: 0.021, 9632/28000 datapoints
2025-03-06 21:09:30,395 - INFO - training batch 351, loss: 0.021, 11232/28000 datapoints
2025-03-06 21:09:30,539 - INFO - training batch 401, loss: 0.031, 12832/28000 datapoints
2025-03-06 21:09:30,667 - INFO - training batch 451, loss: 0.018, 14432/28000 datapoints
2025-03-06 21:09:30,791 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 21:09:30,933 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 21:09:31,060 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-06 21:09:31,184 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:31,311 - INFO - training batch 701, loss: 0.020, 22432/28000 datapoints
2025-03-06 21:09:31,453 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-06 21:09:31,591 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 21:09:31,720 - INFO - training batch 851, loss: 0.016, 27232/28000 datapoints
2025-03-06 21:09:31,786 - INFO - validation batch 1, loss: 1.207, 32/6976 datapoints
2025-03-06 21:09:31,830 - INFO - validation batch 51, loss: 3.376, 1632/6976 datapoints
2025-03-06 21:09:31,873 - INFO - validation batch 101, loss: 1.588, 3232/6976 datapoints
2025-03-06 21:09:31,917 - INFO - validation batch 151, loss: 0.664, 4832/6976 datapoints
2025-03-06 21:09:31,961 - INFO - validation batch 201, loss: 1.009, 6432/6976 datapoints
2025-03-06 21:09:31,976 - INFO - Epoch 794/800 done.
2025-03-06 21:09:31,976 - INFO - Final validation performance:
Loss: 1.569, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:31,977 - INFO - Beginning epoch 795/800
2025-03-06 21:09:31,980 - INFO - training batch 1, loss: 0.025, 32/28000 datapoints
2025-03-06 21:09:32,107 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:09:32,265 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 21:09:32,393 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-06 21:09:32,520 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 21:09:32,650 - INFO - training batch 251, loss: 0.022, 8032/28000 datapoints
2025-03-06 21:09:32,776 - INFO - training batch 301, loss: 0.021, 9632/28000 datapoints
2025-03-06 21:09:32,901 - INFO - training batch 351, loss: 0.021, 11232/28000 datapoints
2025-03-06 21:09:33,024 - INFO - training batch 401, loss: 0.030, 12832/28000 datapoints
2025-03-06 21:09:33,154 - INFO - training batch 451, loss: 0.018, 14432/28000 datapoints
2025-03-06 21:09:33,280 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 21:09:33,410 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-06 21:09:33,541 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-06 21:09:33,673 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:33,801 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-06 21:09:33,930 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-06 21:09:34,061 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 21:09:34,205 - INFO - training batch 851, loss: 0.016, 27232/28000 datapoints
2025-03-06 21:09:34,270 - INFO - validation batch 1, loss: 1.202, 32/6976 datapoints
2025-03-06 21:09:34,324 - INFO - validation batch 51, loss: 3.392, 1632/6976 datapoints
2025-03-06 21:09:34,372 - INFO - validation batch 101, loss: 1.597, 3232/6976 datapoints
2025-03-06 21:09:34,419 - INFO - validation batch 151, loss: 0.670, 4832/6976 datapoints
2025-03-06 21:09:34,467 - INFO - validation batch 201, loss: 1.021, 6432/6976 datapoints
2025-03-06 21:09:34,485 - INFO - Epoch 795/800 done.
2025-03-06 21:09:34,485 - INFO - Final validation performance:
Loss: 1.576, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:34,486 - INFO - Beginning epoch 796/800
2025-03-06 21:09:34,490 - INFO - training batch 1, loss: 0.025, 32/28000 datapoints
2025-03-06 21:09:34,625 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:09:34,759 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 21:09:34,897 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 21:09:35,026 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 21:09:35,158 - INFO - training batch 251, loss: 0.021, 8032/28000 datapoints
2025-03-06 21:09:35,290 - INFO - training batch 301, loss: 0.021, 9632/28000 datapoints
2025-03-06 21:09:35,421 - INFO - training batch 351, loss: 0.021, 11232/28000 datapoints
2025-03-06 21:09:35,548 - INFO - training batch 401, loss: 0.030, 12832/28000 datapoints
2025-03-06 21:09:35,682 - INFO - training batch 451, loss: 0.018, 14432/28000 datapoints
2025-03-06 21:09:35,809 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 21:09:35,936 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 21:09:36,066 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-06 21:09:36,199 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:36,331 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-06 21:09:36,461 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-06 21:09:36,589 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 21:09:36,724 - INFO - training batch 851, loss: 0.016, 27232/28000 datapoints
2025-03-06 21:09:36,790 - INFO - validation batch 1, loss: 1.215, 32/6976 datapoints
2025-03-06 21:09:36,836 - INFO - validation batch 51, loss: 3.405, 1632/6976 datapoints
2025-03-06 21:09:36,885 - INFO - validation batch 101, loss: 1.604, 3232/6976 datapoints
2025-03-06 21:09:36,933 - INFO - validation batch 151, loss: 0.665, 4832/6976 datapoints
2025-03-06 21:09:36,984 - INFO - validation batch 201, loss: 1.018, 6432/6976 datapoints
2025-03-06 21:09:37,002 - INFO - Epoch 796/800 done.
2025-03-06 21:09:37,002 - INFO - Final validation performance:
Loss: 1.581, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:37,003 - INFO - Beginning epoch 797/800
2025-03-06 21:09:37,007 - INFO - training batch 1, loss: 0.024, 32/28000 datapoints
2025-03-06 21:09:37,143 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 21:09:37,269 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 21:09:37,395 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 21:09:37,526 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 21:09:37,679 - INFO - training batch 251, loss: 0.021, 8032/28000 datapoints
2025-03-06 21:09:37,811 - INFO - training batch 301, loss: 0.020, 9632/28000 datapoints
2025-03-06 21:09:37,937 - INFO - training batch 351, loss: 0.020, 11232/28000 datapoints
2025-03-06 21:09:38,062 - INFO - training batch 401, loss: 0.029, 12832/28000 datapoints
2025-03-06 21:09:38,193 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-06 21:09:38,322 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 21:09:38,449 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 21:09:38,574 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 21:09:38,703 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:38,830 - INFO - training batch 701, loss: 0.018, 22432/28000 datapoints
2025-03-06 21:09:38,954 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-06 21:09:39,084 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 21:09:39,219 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-06 21:09:39,283 - INFO - validation batch 1, loss: 1.218, 32/6976 datapoints
2025-03-06 21:09:39,326 - INFO - validation batch 51, loss: 3.427, 1632/6976 datapoints
2025-03-06 21:09:39,370 - INFO - validation batch 101, loss: 1.615, 3232/6976 datapoints
2025-03-06 21:09:39,414 - INFO - validation batch 151, loss: 0.668, 4832/6976 datapoints
2025-03-06 21:09:39,459 - INFO - validation batch 201, loss: 1.027, 6432/6976 datapoints
2025-03-06 21:09:39,474 - INFO - Epoch 797/800 done.
2025-03-06 21:09:39,474 - INFO - Final validation performance:
Loss: 1.591, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:39,475 - INFO - Beginning epoch 798/800
2025-03-06 21:09:39,479 - INFO - training batch 1, loss: 0.024, 32/28000 datapoints
2025-03-06 21:09:39,605 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:09:39,735 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 21:09:39,861 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 21:09:39,988 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 21:09:40,128 - INFO - training batch 251, loss: 0.020, 8032/28000 datapoints
2025-03-06 21:09:40,261 - INFO - training batch 301, loss: 0.020, 9632/28000 datapoints
2025-03-06 21:09:40,388 - INFO - training batch 351, loss: 0.020, 11232/28000 datapoints
2025-03-06 21:09:40,512 - INFO - training batch 401, loss: 0.029, 12832/28000 datapoints
2025-03-06 21:09:40,642 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-06 21:09:40,767 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 21:09:40,892 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 21:09:41,017 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 21:09:41,143 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:41,272 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-06 21:09:41,398 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-06 21:09:41,524 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-06 21:09:41,652 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-06 21:09:41,716 - INFO - validation batch 1, loss: 1.223, 32/6976 datapoints
2025-03-06 21:09:41,759 - INFO - validation batch 51, loss: 3.434, 1632/6976 datapoints
2025-03-06 21:09:41,803 - INFO - validation batch 101, loss: 1.623, 3232/6976 datapoints
2025-03-06 21:09:41,846 - INFO - validation batch 151, loss: 0.664, 4832/6976 datapoints
2025-03-06 21:09:41,891 - INFO - validation batch 201, loss: 1.031, 6432/6976 datapoints
2025-03-06 21:09:41,906 - INFO - Epoch 798/800 done.
2025-03-06 21:09:41,907 - INFO - Final validation performance:
Loss: 1.595, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:41,907 - INFO - Beginning epoch 799/800
2025-03-06 21:09:41,911 - INFO - training batch 1, loss: 0.024, 32/28000 datapoints
2025-03-06 21:09:42,036 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 21:09:42,162 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 21:09:42,317 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 21:09:42,451 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 21:09:42,580 - INFO - training batch 251, loss: 0.020, 8032/28000 datapoints
2025-03-06 21:09:42,710 - INFO - training batch 301, loss: 0.020, 9632/28000 datapoints
2025-03-06 21:09:42,835 - INFO - training batch 351, loss: 0.020, 11232/28000 datapoints
2025-03-06 21:09:42,959 - INFO - training batch 401, loss: 0.028, 12832/28000 datapoints
2025-03-06 21:09:43,090 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-06 21:09:43,214 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 21:09:43,340 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-06 21:09:43,467 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-06 21:09:43,592 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-06 21:09:43,733 - INFO - training batch 701, loss: 0.019, 22432/28000 datapoints
2025-03-06 21:09:43,860 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 21:09:43,987 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 21:09:44,117 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-06 21:09:44,185 - INFO - validation batch 1, loss: 1.230, 32/6976 datapoints
2025-03-06 21:09:44,233 - INFO - validation batch 51, loss: 3.448, 1632/6976 datapoints
2025-03-06 21:09:44,277 - INFO - validation batch 101, loss: 1.634, 3232/6976 datapoints
2025-03-06 21:09:44,322 - INFO - validation batch 151, loss: 0.670, 4832/6976 datapoints
2025-03-06 21:09:44,367 - INFO - validation batch 201, loss: 1.038, 6432/6976 datapoints
2025-03-06 21:09:44,382 - INFO - Epoch 799/800 done.
2025-03-06 21:09:44,383 - INFO - Final validation performance:
Loss: 1.604, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:44,383 - INFO - Beginning epoch 800/800
2025-03-06 21:09:44,387 - INFO - training batch 1, loss: 0.023, 32/28000 datapoints
2025-03-06 21:09:44,515 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 21:09:44,644 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 21:09:44,773 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-06 21:09:44,898 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 21:09:45,036 - INFO - training batch 251, loss: 0.020, 8032/28000 datapoints
2025-03-06 21:09:45,166 - INFO - training batch 301, loss: 0.020, 9632/28000 datapoints
2025-03-06 21:09:45,294 - INFO - training batch 351, loss: 0.020, 11232/28000 datapoints
2025-03-06 21:09:45,417 - INFO - training batch 401, loss: 0.028, 12832/28000 datapoints
2025-03-06 21:09:45,545 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-06 21:09:45,672 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-06 21:09:45,798 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-06 21:09:45,924 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-06 21:09:46,048 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-06 21:09:46,178 - INFO - training batch 701, loss: 0.018, 22432/28000 datapoints
2025-03-06 21:09:46,310 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-06 21:09:46,435 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-06 21:09:46,563 - INFO - training batch 851, loss: 0.014, 27232/28000 datapoints
2025-03-06 21:09:46,625 - INFO - validation batch 1, loss: 1.234, 32/6976 datapoints
2025-03-06 21:09:46,672 - INFO - validation batch 51, loss: 3.469, 1632/6976 datapoints
2025-03-06 21:09:46,716 - INFO - validation batch 101, loss: 1.641, 3232/6976 datapoints
2025-03-06 21:09:46,761 - INFO - validation batch 151, loss: 0.669, 4832/6976 datapoints
2025-03-06 21:09:46,806 - INFO - validation batch 201, loss: 1.042, 6432/6976 datapoints
2025-03-06 21:09:46,821 - INFO - Epoch 800/800 done.
2025-03-06 21:09:46,821 - INFO - Final validation performance:
Loss: 1.611, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:09:46,821 - INFO - Finished training in 1903.75 seconds.
2025-03-06 21:09:46,822 - INFO - Model trained in {train_time:.2f} s
2025-03-06 21:09:46,822 - INFO - Evaluating model...
2025-03-06 21:09:46,823 - INFO - validation batch 1, loss: 1.234, 32/6976 datapoints
2025-03-06 21:09:46,868 - INFO - validation batch 51, loss: 3.469, 1632/6976 datapoints
2025-03-06 21:09:46,913 - INFO - validation batch 101, loss: 1.641, 3232/6976 datapoints
2025-03-06 21:09:46,957 - INFO - validation batch 151, loss: 0.669, 4832/6976 datapoints
2025-03-06 21:09:47,001 - INFO - validation batch 201, loss: 1.042, 6432/6976 datapoints
2025-03-06 21:09:47,016 - INFO - Done evaluating.
2025-03-06 21:09:47,017 - INFO - Average final validation loss: 1.611
2025-03-06 21:09:47,017 - INFO - Saving...
2025-03-06 21:09:49,350 - INFO - Done saving.
2025-03-06 21:09:49,351 - INFO - Successfully completed hyperparameter combination 1 of 4