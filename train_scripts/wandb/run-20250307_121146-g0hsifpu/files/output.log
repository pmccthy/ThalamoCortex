2025-03-07 12:11:51,419 - INFO - Running hyperparameter combination 1 of 1
2025-03-07 12:11:51,419 - INFO - 0_CTCNet_TC_add_reciprocal_readout
2025-03-07 12:11:51,419 - INFO - Loading data...
2025-03-07 12:11:52,516 - INFO - Done loading.
2025-03-07 12:11:52,517 - INFO - Building model and optimiser...
2025-03-07 12:11:52,550 - INFO - =================================================================
Layer (type:depth-idx)                   Param #
=================================================================
├─Sequential: 1-1                        --
|    └─Linear: 2-1                       32,832
|    └─ReLU: 2-2                         --
├─Linear: 1-2                            101,920
├─Linear: 1-3                            16,640
├─Linear: 1-4                            16,640
├─Sequential: 1-5                        --
|    └─Linear: 2-3                       401,664
|    └─ReLU: 2-4                         --
├─Sequential: 1-6                        --
|    └─Linear: 2-5                       65,792
|    └─ReLU: 2-6                         --
├─Sequential: 1-7                        --
|    └─Linear: 2-7                       2,570
=================================================================
Total params: 638,058
Trainable params: 638,058
Non-trainable params: 0
=================================================================
2025-03-07 12:11:52,551 - INFO - Done.
2025-03-07 12:11:52,551 - INFO - Training...
2025-03-07 12:11:52,551 - INFO - Beginning epoch 1/800
2025-03-07 12:11:52,649 - INFO - training batch 1, loss: 2.318, 32/28000 datapoints
2025-03-07 12:11:52,999 - INFO - training batch 51, loss: 2.310, 1632/28000 datapoints
2025-03-07 12:11:53,321 - INFO - training batch 101, loss: 2.312, 3232/28000 datapoints
2025-03-07 12:11:53,625 - INFO - training batch 151, loss: 2.296, 4832/28000 datapoints
2025-03-07 12:11:53,949 - INFO - training batch 201, loss: 2.287, 6432/28000 datapoints
2025-03-07 12:11:54,313 - INFO - training batch 251, loss: 2.281, 8032/28000 datapoints
2025-03-07 12:11:54,675 - INFO - training batch 301, loss: 2.279, 9632/28000 datapoints
2025-03-07 12:11:55,028 - INFO - training batch 351, loss: 2.273, 11232/28000 datapoints
2025-03-07 12:11:55,351 - INFO - training batch 401, loss: 2.264, 12832/28000 datapoints
2025-03-07 12:11:55,697 - INFO - training batch 451, loss: 2.258, 14432/28000 datapoints
2025-03-07 12:11:56,045 - INFO - training batch 501, loss: 2.230, 16032/28000 datapoints
2025-03-07 12:11:56,384 - INFO - training batch 551, loss: 2.231, 17632/28000 datapoints
2025-03-07 12:11:56,761 - INFO - training batch 601, loss: 2.230, 19232/28000 datapoints
2025-03-07 12:11:57,136 - INFO - training batch 651, loss: 2.226, 20832/28000 datapoints
2025-03-07 12:11:57,605 - INFO - training batch 701, loss: 2.169, 22432/28000 datapoints
2025-03-07 12:11:58,061 - INFO - training batch 751, loss: 2.223, 24032/28000 datapoints
2025-03-07 12:11:58,492 - INFO - training batch 801, loss: 2.189, 25632/28000 datapoints
2025-03-07 12:11:58,861 - INFO - training batch 851, loss: 2.158, 27232/28000 datapoints
2025-03-07 12:11:59,020 - INFO - validation batch 1, loss: 2.153, 32/6976 datapoints
2025-03-07 12:11:59,144 - INFO - validation batch 51, loss: 2.176, 1632/6976 datapoints
2025-03-07 12:11:59,268 - INFO - validation batch 101, loss: 2.175, 3232/6976 datapoints
2025-03-07 12:11:59,391 - INFO - validation batch 151, loss: 2.219, 4832/6976 datapoints
2025-03-07 12:11:59,506 - INFO - validation batch 201, loss: 2.151, 6432/6976 datapoints
2025-03-07 12:11:59,541 - INFO - Epoch 1/800 done.
2025-03-07 12:11:59,541 - INFO - Final validation performance:
Loss: 2.175, top-1 acc: 0.351top-5 acc: 0.351
2025-03-07 12:11:59,543 - INFO - Beginning epoch 2/800
2025-03-07 12:11:59,551 - INFO - training batch 1, loss: 2.209, 32/28000 datapoints
2025-03-07 12:11:59,929 - INFO - training batch 51, loss: 2.184, 1632/28000 datapoints
2025-03-07 12:12:00,310 - INFO - training batch 101, loss: 2.108, 3232/28000 datapoints
2025-03-07 12:12:00,670 - INFO - training batch 151, loss: 2.166, 4832/28000 datapoints
2025-03-07 12:12:01,047 - INFO - training batch 201, loss: 2.105, 6432/28000 datapoints
2025-03-07 12:12:01,388 - INFO - training batch 251, loss: 2.114, 8032/28000 datapoints
2025-03-07 12:12:01,727 - INFO - training batch 301, loss: 2.117, 9632/28000 datapoints
2025-03-07 12:12:02,081 - INFO - training batch 351, loss: 2.049, 11232/28000 datapoints
2025-03-07 12:12:02,470 - INFO - training batch 401, loss: 2.041, 12832/28000 datapoints
2025-03-07 12:12:02,789 - INFO - training batch 451, loss: 2.000, 14432/28000 datapoints
2025-03-07 12:12:03,094 - INFO - training batch 501, loss: 1.874, 16032/28000 datapoints
2025-03-07 12:12:03,416 - INFO - training batch 551, loss: 1.891, 17632/28000 datapoints
2025-03-07 12:12:03,750 - INFO - training batch 601, loss: 1.939, 19232/28000 datapoints
2025-03-07 12:12:04,045 - INFO - training batch 651, loss: 1.866, 20832/28000 datapoints
2025-03-07 12:12:04,336 - INFO - training batch 701, loss: 1.720, 22432/28000 datapoints
2025-03-07 12:12:04,614 - INFO - training batch 751, loss: 1.931, 24032/28000 datapoints
2025-03-07 12:12:04,892 - INFO - training batch 801, loss: 1.877, 25632/28000 datapoints
2025-03-07 12:12:05,165 - INFO - training batch 851, loss: 1.786, 27232/28000 datapoints
2025-03-07 12:12:05,299 - INFO - validation batch 1, loss: 1.734, 32/6976 datapoints
2025-03-07 12:12:05,374 - INFO - validation batch 51, loss: 1.836, 1632/6976 datapoints
2025-03-07 12:12:05,458 - INFO - validation batch 101, loss: 1.816, 3232/6976 datapoints
2025-03-07 12:12:05,538 - INFO - validation batch 151, loss: 2.019, 4832/6976 datapoints
2025-03-07 12:12:05,615 - INFO - validation batch 201, loss: 1.700, 6432/6976 datapoints
2025-03-07 12:12:05,643 - INFO - Epoch 2/800 done.
2025-03-07 12:12:05,643 - INFO - Final validation performance:
Loss: 1.821, top-1 acc: 0.402top-5 acc: 0.402
2025-03-07 12:12:05,644 - INFO - Beginning epoch 3/800
2025-03-07 12:12:05,652 - INFO - training batch 1, loss: 1.978, 32/28000 datapoints
2025-03-07 12:12:05,920 - INFO - training batch 51, loss: 1.945, 1632/28000 datapoints
2025-03-07 12:12:06,189 - INFO - training batch 101, loss: 1.721, 3232/28000 datapoints
2025-03-07 12:12:06,495 - INFO - training batch 151, loss: 1.885, 4832/28000 datapoints
2025-03-07 12:12:06,840 - INFO - training batch 201, loss: 1.846, 6432/28000 datapoints
2025-03-07 12:12:07,222 - INFO - training batch 251, loss: 1.862, 8032/28000 datapoints
2025-03-07 12:12:07,596 - INFO - training batch 301, loss: 1.905, 9632/28000 datapoints
2025-03-07 12:12:07,996 - INFO - training batch 351, loss: 1.839, 11232/28000 datapoints
2025-03-07 12:12:08,337 - INFO - training batch 401, loss: 1.803, 12832/28000 datapoints
2025-03-07 12:12:08,747 - INFO - training batch 451, loss: 1.747, 14432/28000 datapoints
2025-03-07 12:12:09,107 - INFO - training batch 501, loss: 1.501, 16032/28000 datapoints
2025-03-07 12:12:09,424 - INFO - training batch 551, loss: 1.618, 17632/28000 datapoints
2025-03-07 12:12:09,860 - INFO - training batch 601, loss: 1.681, 19232/28000 datapoints
2025-03-07 12:12:10,201 - INFO - training batch 651, loss: 1.594, 20832/28000 datapoints
2025-03-07 12:12:10,574 - INFO - training batch 701, loss: 1.500, 22432/28000 datapoints
2025-03-07 12:12:10,866 - INFO - training batch 751, loss: 1.743, 24032/28000 datapoints
2025-03-07 12:12:11,254 - INFO - training batch 801, loss: 1.660, 25632/28000 datapoints
2025-03-07 12:12:11,624 - INFO - training batch 851, loss: 1.606, 27232/28000 datapoints
2025-03-07 12:12:11,775 - INFO - validation batch 1, loss: 1.478, 32/6976 datapoints
2025-03-07 12:12:11,893 - INFO - validation batch 51, loss: 1.701, 1632/6976 datapoints
2025-03-07 12:12:11,998 - INFO - validation batch 101, loss: 1.648, 3232/6976 datapoints
2025-03-07 12:12:12,082 - INFO - validation batch 151, loss: 1.966, 4832/6976 datapoints
2025-03-07 12:12:12,176 - INFO - validation batch 201, loss: 1.406, 6432/6976 datapoints
2025-03-07 12:12:12,208 - INFO - Epoch 3/800 done.
2025-03-07 12:12:12,208 - INFO - Final validation performance:
Loss: 1.640, top-1 acc: 0.433top-5 acc: 0.433
2025-03-07 12:12:12,209 - INFO - Beginning epoch 4/800
2025-03-07 12:12:12,218 - INFO - training batch 1, loss: 1.870, 32/28000 datapoints
2025-03-07 12:12:12,607 - INFO - training batch 51, loss: 1.819, 1632/28000 datapoints
2025-03-07 12:12:12,896 - INFO - training batch 101, loss: 1.530, 3232/28000 datapoints
2025-03-07 12:12:13,247 - INFO - training batch 151, loss: 1.778, 4832/28000 datapoints
2025-03-07 12:12:13,612 - INFO - training batch 201, loss: 1.741, 6432/28000 datapoints
2025-03-07 12:12:14,015 - INFO - training batch 251, loss: 1.742, 8032/28000 datapoints
2025-03-07 12:12:14,539 - INFO - training batch 301, loss: 1.805, 9632/28000 datapoints
2025-03-07 12:12:15,007 - INFO - training batch 351, loss: 1.744, 11232/28000 datapoints
2025-03-07 12:12:15,381 - INFO - training batch 401, loss: 1.679, 12832/28000 datapoints
2025-03-07 12:12:15,726 - INFO - training batch 451, loss: 1.632, 14432/28000 datapoints
2025-03-07 12:12:16,125 - INFO - training batch 501, loss: 1.327, 16032/28000 datapoints
2025-03-07 12:12:16,565 - INFO - training batch 551, loss: 1.551, 17632/28000 datapoints
2025-03-07 12:12:17,141 - INFO - training batch 601, loss: 1.595, 19232/28000 datapoints
2025-03-07 12:12:17,699 - INFO - training batch 651, loss: 1.427, 20832/28000 datapoints
2025-03-07 12:12:18,170 - INFO - training batch 701, loss: 1.407, 22432/28000 datapoints
2025-03-07 12:12:18,627 - INFO - training batch 751, loss: 1.665, 24032/28000 datapoints
2025-03-07 12:12:19,029 - INFO - training batch 801, loss: 1.538, 25632/28000 datapoints
2025-03-07 12:12:19,440 - INFO - training batch 851, loss: 1.505, 27232/28000 datapoints
2025-03-07 12:12:19,594 - INFO - validation batch 1, loss: 1.355, 32/6976 datapoints
2025-03-07 12:12:19,688 - INFO - validation batch 51, loss: 1.669, 1632/6976 datapoints
2025-03-07 12:12:19,810 - INFO - validation batch 101, loss: 1.578, 3232/6976 datapoints
2025-03-07 12:12:19,924 - INFO - validation batch 151, loss: 1.936, 4832/6976 datapoints
2025-03-07 12:12:20,020 - INFO - validation batch 201, loss: 1.269, 6432/6976 datapoints
2025-03-07 12:12:20,052 - INFO - Epoch 4/800 done.
2025-03-07 12:12:20,052 - INFO - Final validation performance:
Loss: 1.561, top-1 acc: 0.450top-5 acc: 0.450
2025-03-07 12:12:20,053 - INFO - Beginning epoch 5/800
2025-03-07 12:12:20,061 - INFO - training batch 1, loss: 1.815, 32/28000 datapoints
2025-03-07 12:12:20,379 - INFO - training batch 51, loss: 1.761, 1632/28000 datapoints
2025-03-07 12:12:20,692 - INFO - training batch 101, loss: 1.416, 3232/28000 datapoints
2025-03-07 12:12:20,975 - INFO - training batch 151, loss: 1.728, 4832/28000 datapoints
2025-03-07 12:12:21,284 - INFO - training batch 201, loss: 1.680, 6432/28000 datapoints
2025-03-07 12:12:21,682 - INFO - training batch 251, loss: 1.666, 8032/28000 datapoints
2025-03-07 12:12:21,978 - INFO - training batch 301, loss: 1.741, 9632/28000 datapoints
2025-03-07 12:12:22,259 - INFO - training batch 351, loss: 1.662, 11232/28000 datapoints
2025-03-07 12:12:22,561 - INFO - training batch 401, loss: 1.616, 12832/28000 datapoints
2025-03-07 12:12:22,902 - INFO - training batch 451, loss: 1.569, 14432/28000 datapoints
2025-03-07 12:12:23,256 - INFO - training batch 501, loss: 1.247, 16032/28000 datapoints
2025-03-07 12:12:23,593 - INFO - training batch 551, loss: 1.529, 17632/28000 datapoints
2025-03-07 12:12:23,872 - INFO - training batch 601, loss: 1.551, 19232/28000 datapoints
2025-03-07 12:12:24,151 - INFO - training batch 651, loss: 1.315, 20832/28000 datapoints
2025-03-07 12:12:24,422 - INFO - training batch 701, loss: 1.348, 22432/28000 datapoints
2025-03-07 12:12:24,699 - INFO - training batch 751, loss: 1.624, 24032/28000 datapoints
2025-03-07 12:12:25,001 - INFO - training batch 801, loss: 1.461, 25632/28000 datapoints
2025-03-07 12:12:25,340 - INFO - training batch 851, loss: 1.438, 27232/28000 datapoints
2025-03-07 12:12:25,497 - INFO - validation batch 1, loss: 1.277, 32/6976 datapoints
2025-03-07 12:12:25,580 - INFO - validation batch 51, loss: 1.658, 1632/6976 datapoints
2025-03-07 12:12:25,659 - INFO - validation batch 101, loss: 1.529, 3232/6976 datapoints
2025-03-07 12:12:25,737 - INFO - validation batch 151, loss: 1.908, 4832/6976 datapoints
2025-03-07 12:12:25,816 - INFO - validation batch 201, loss: 1.189, 6432/6976 datapoints
2025-03-07 12:12:25,846 - INFO - Epoch 5/800 done.
2025-03-07 12:12:25,846 - INFO - Final validation performance:
Loss: 1.512, top-1 acc: 0.465top-5 acc: 0.465
2025-03-07 12:12:25,847 - INFO - Beginning epoch 6/800
2025-03-07 12:12:25,855 - INFO - training batch 1, loss: 1.759, 32/28000 datapoints
2025-03-07 12:12:26,139 - INFO - training batch 51, loss: 1.731, 1632/28000 datapoints
2025-03-07 12:12:26,448 - INFO - training batch 101, loss: 1.335, 3232/28000 datapoints
2025-03-07 12:12:26,753 - INFO - training batch 151, loss: 1.685, 4832/28000 datapoints
2025-03-07 12:12:27,185 - INFO - training batch 201, loss: 1.641, 6432/28000 datapoints
2025-03-07 12:12:27,638 - INFO - training batch 251, loss: 1.599, 8032/28000 datapoints
2025-03-07 12:12:28,145 - INFO - training batch 301, loss: 1.690, 9632/28000 datapoints
2025-03-07 12:12:28,576 - INFO - training batch 351, loss: 1.590, 11232/28000 datapoints
2025-03-07 12:12:28,965 - INFO - training batch 401, loss: 1.577, 12832/28000 datapoints
2025-03-07 12:12:29,370 - INFO - training batch 451, loss: 1.531, 14432/28000 datapoints
2025-03-07 12:12:30,065 - INFO - training batch 501, loss: 1.204, 16032/28000 datapoints
2025-03-07 12:12:30,540 - INFO - training batch 551, loss: 1.516, 17632/28000 datapoints
2025-03-07 12:12:30,894 - INFO - training batch 601, loss: 1.516, 19232/28000 datapoints
2025-03-07 12:12:31,185 - INFO - training batch 651, loss: 1.235, 20832/28000 datapoints
2025-03-07 12:12:31,473 - INFO - training batch 701, loss: 1.306, 22432/28000 datapoints
2025-03-07 12:12:31,784 - INFO - training batch 751, loss: 1.595, 24032/28000 datapoints
2025-03-07 12:12:32,111 - INFO - training batch 801, loss: 1.405, 25632/28000 datapoints
2025-03-07 12:12:32,386 - INFO - training batch 851, loss: 1.390, 27232/28000 datapoints
2025-03-07 12:12:32,535 - INFO - validation batch 1, loss: 1.216, 32/6976 datapoints
2025-03-07 12:12:32,643 - INFO - validation batch 51, loss: 1.653, 1632/6976 datapoints
2025-03-07 12:12:32,726 - INFO - validation batch 101, loss: 1.492, 3232/6976 datapoints
2025-03-07 12:12:32,806 - INFO - validation batch 151, loss: 1.875, 4832/6976 datapoints
2025-03-07 12:12:32,882 - INFO - validation batch 201, loss: 1.130, 6432/6976 datapoints
2025-03-07 12:12:32,916 - INFO - Epoch 6/800 done.
2025-03-07 12:12:32,916 - INFO - Final validation performance:
Loss: 1.473, top-1 acc: 0.475top-5 acc: 0.475
2025-03-07 12:12:32,917 - INFO - Beginning epoch 7/800
2025-03-07 12:12:32,925 - INFO - training batch 1, loss: 1.703, 32/28000 datapoints
2025-03-07 12:12:33,216 - INFO - training batch 51, loss: 1.707, 1632/28000 datapoints
2025-03-07 12:12:33,486 - INFO - training batch 101, loss: 1.275, 3232/28000 datapoints
2025-03-07 12:12:33,771 - INFO - training batch 151, loss: 1.644, 4832/28000 datapoints
2025-03-07 12:12:34,075 - INFO - training batch 201, loss: 1.610, 6432/28000 datapoints
2025-03-07 12:12:34,342 - INFO - training batch 251, loss: 1.537, 8032/28000 datapoints
2025-03-07 12:12:34,609 - INFO - training batch 301, loss: 1.647, 9632/28000 datapoints
2025-03-07 12:12:34,894 - INFO - training batch 351, loss: 1.533, 11232/28000 datapoints
2025-03-07 12:12:35,202 - INFO - training batch 401, loss: 1.548, 12832/28000 datapoints
2025-03-07 12:12:35,477 - INFO - training batch 451, loss: 1.503, 14432/28000 datapoints
2025-03-07 12:12:35,756 - INFO - training batch 501, loss: 1.175, 16032/28000 datapoints
2025-03-07 12:12:36,047 - INFO - training batch 551, loss: 1.509, 17632/28000 datapoints
2025-03-07 12:12:36,316 - INFO - training batch 601, loss: 1.489, 19232/28000 datapoints
2025-03-07 12:12:36,587 - INFO - training batch 651, loss: 1.173, 20832/28000 datapoints
2025-03-07 12:12:36,867 - INFO - training batch 701, loss: 1.276, 22432/28000 datapoints
2025-03-07 12:12:37,136 - INFO - training batch 751, loss: 1.572, 24032/28000 datapoints
2025-03-07 12:12:37,506 - INFO - training batch 801, loss: 1.357, 25632/28000 datapoints
2025-03-07 12:12:37,800 - INFO - training batch 851, loss: 1.353, 27232/28000 datapoints
2025-03-07 12:12:37,935 - INFO - validation batch 1, loss: 1.166, 32/6976 datapoints
2025-03-07 12:12:38,012 - INFO - validation batch 51, loss: 1.650, 1632/6976 datapoints
2025-03-07 12:12:38,116 - INFO - validation batch 101, loss: 1.464, 3232/6976 datapoints
2025-03-07 12:12:38,220 - INFO - validation batch 151, loss: 1.839, 4832/6976 datapoints
2025-03-07 12:12:38,314 - INFO - validation batch 201, loss: 1.086, 6432/6976 datapoints
2025-03-07 12:12:38,352 - INFO - Epoch 7/800 done.
2025-03-07 12:12:38,352 - INFO - Final validation performance:
Loss: 1.441, top-1 acc: 0.486top-5 acc: 0.486
2025-03-07 12:12:38,353 - INFO - Beginning epoch 8/800
2025-03-07 12:12:38,362 - INFO - training batch 1, loss: 1.653, 32/28000 datapoints
2025-03-07 12:12:38,697 - INFO - training batch 51, loss: 1.682, 1632/28000 datapoints
2025-03-07 12:12:39,033 - INFO - training batch 101, loss: 1.232, 3232/28000 datapoints
2025-03-07 12:12:39,375 - INFO - training batch 151, loss: 1.607, 4832/28000 datapoints
2025-03-07 12:12:39,710 - INFO - training batch 201, loss: 1.580, 6432/28000 datapoints
2025-03-07 12:12:40,057 - INFO - training batch 251, loss: 1.478, 8032/28000 datapoints
2025-03-07 12:12:40,372 - INFO - training batch 301, loss: 1.611, 9632/28000 datapoints
2025-03-07 12:12:40,670 - INFO - training batch 351, loss: 1.485, 11232/28000 datapoints
2025-03-07 12:12:40,957 - INFO - training batch 401, loss: 1.518, 12832/28000 datapoints
2025-03-07 12:12:41,242 - INFO - training batch 451, loss: 1.478, 14432/28000 datapoints
2025-03-07 12:12:41,525 - INFO - training batch 501, loss: 1.148, 16032/28000 datapoints
2025-03-07 12:12:41,839 - INFO - training batch 551, loss: 1.503, 17632/28000 datapoints
2025-03-07 12:12:42,127 - INFO - training batch 601, loss: 1.465, 19232/28000 datapoints
2025-03-07 12:12:42,397 - INFO - training batch 651, loss: 1.123, 20832/28000 datapoints
2025-03-07 12:12:42,685 - INFO - training batch 701, loss: 1.250, 22432/28000 datapoints
2025-03-07 12:12:42,971 - INFO - training batch 751, loss: 1.549, 24032/28000 datapoints
2025-03-07 12:12:43,248 - INFO - training batch 801, loss: 1.313, 25632/28000 datapoints
2025-03-07 12:12:43,518 - INFO - training batch 851, loss: 1.321, 27232/28000 datapoints
2025-03-07 12:12:43,651 - INFO - validation batch 1, loss: 1.122, 32/6976 datapoints
2025-03-07 12:12:43,728 - INFO - validation batch 51, loss: 1.645, 1632/6976 datapoints
2025-03-07 12:12:43,805 - INFO - validation batch 101, loss: 1.440, 3232/6976 datapoints
2025-03-07 12:12:43,883 - INFO - validation batch 151, loss: 1.804, 4832/6976 datapoints
2025-03-07 12:12:43,958 - INFO - validation batch 201, loss: 1.051, 6432/6976 datapoints
2025-03-07 12:12:43,982 - INFO - Epoch 8/800 done.
2025-03-07 12:12:43,983 - INFO - Final validation performance:
Loss: 1.412, top-1 acc: 0.494top-5 acc: 0.494
2025-03-07 12:12:43,983 - INFO - Beginning epoch 9/800
2025-03-07 12:12:43,992 - INFO - training batch 1, loss: 1.609, 32/28000 datapoints
2025-03-07 12:12:44,286 - INFO - training batch 51, loss: 1.656, 1632/28000 datapoints
2025-03-07 12:12:44,549 - INFO - training batch 101, loss: 1.196, 3232/28000 datapoints
2025-03-07 12:12:44,832 - INFO - training batch 151, loss: 1.571, 4832/28000 datapoints
2025-03-07 12:12:45,094 - INFO - training batch 201, loss: 1.550, 6432/28000 datapoints
2025-03-07 12:12:45,360 - INFO - training batch 251, loss: 1.420, 8032/28000 datapoints
2025-03-07 12:12:45,635 - INFO - training batch 301, loss: 1.576, 9632/28000 datapoints
2025-03-07 12:12:45,911 - INFO - training batch 351, loss: 1.444, 11232/28000 datapoints
2025-03-07 12:12:46,181 - INFO - training batch 401, loss: 1.487, 12832/28000 datapoints
2025-03-07 12:12:46,463 - INFO - training batch 451, loss: 1.453, 14432/28000 datapoints
2025-03-07 12:12:46,731 - INFO - training batch 501, loss: 1.122, 16032/28000 datapoints
2025-03-07 12:12:47,013 - INFO - training batch 551, loss: 1.495, 17632/28000 datapoints
2025-03-07 12:12:47,289 - INFO - training batch 601, loss: 1.442, 19232/28000 datapoints
2025-03-07 12:12:47,609 - INFO - training batch 651, loss: 1.079, 20832/28000 datapoints
2025-03-07 12:12:47,962 - INFO - training batch 701, loss: 1.226, 22432/28000 datapoints
2025-03-07 12:12:48,328 - INFO - training batch 751, loss: 1.524, 24032/28000 datapoints
2025-03-07 12:12:48,680 - INFO - training batch 801, loss: 1.270, 25632/28000 datapoints
2025-03-07 12:12:49,030 - INFO - training batch 851, loss: 1.292, 27232/28000 datapoints
2025-03-07 12:12:49,207 - INFO - validation batch 1, loss: 1.082, 32/6976 datapoints
2025-03-07 12:12:49,306 - INFO - validation batch 51, loss: 1.635, 1632/6976 datapoints
2025-03-07 12:12:49,402 - INFO - validation batch 101, loss: 1.417, 3232/6976 datapoints
2025-03-07 12:12:49,504 - INFO - validation batch 151, loss: 1.765, 4832/6976 datapoints
2025-03-07 12:12:49,607 - INFO - validation batch 201, loss: 1.021, 6432/6976 datapoints
2025-03-07 12:12:49,638 - INFO - Epoch 9/800 done.
2025-03-07 12:12:49,638 - INFO - Final validation performance:
Loss: 1.384, top-1 acc: 0.505top-5 acc: 0.505
2025-03-07 12:12:49,639 - INFO - Beginning epoch 10/800
2025-03-07 12:12:49,648 - INFO - training batch 1, loss: 1.565, 32/28000 datapoints
2025-03-07 12:12:49,980 - INFO - training batch 51, loss: 1.627, 1632/28000 datapoints
2025-03-07 12:12:50,299 - INFO - training batch 101, loss: 1.161, 3232/28000 datapoints
2025-03-07 12:12:50,606 - INFO - training batch 151, loss: 1.534, 4832/28000 datapoints
2025-03-07 12:12:50,888 - INFO - training batch 201, loss: 1.518, 6432/28000 datapoints
2025-03-07 12:12:51,171 - INFO - training batch 251, loss: 1.363, 8032/28000 datapoints
2025-03-07 12:12:51,447 - INFO - training batch 301, loss: 1.543, 9632/28000 datapoints
2025-03-07 12:12:51,731 - INFO - training batch 351, loss: 1.405, 11232/28000 datapoints
2025-03-07 12:12:52,013 - INFO - training batch 401, loss: 1.455, 12832/28000 datapoints
2025-03-07 12:12:52,300 - INFO - training batch 451, loss: 1.427, 14432/28000 datapoints
2025-03-07 12:12:52,595 - INFO - training batch 501, loss: 1.095, 16032/28000 datapoints
2025-03-07 12:12:52,937 - INFO - training batch 551, loss: 1.481, 17632/28000 datapoints
2025-03-07 12:12:53,209 - INFO - training batch 601, loss: 1.422, 19232/28000 datapoints
2025-03-07 12:12:53,511 - INFO - training batch 651, loss: 1.039, 20832/28000 datapoints
2025-03-07 12:12:53,781 - INFO - training batch 701, loss: 1.201, 22432/28000 datapoints
2025-03-07 12:12:54,049 - INFO - training batch 751, loss: 1.495, 24032/28000 datapoints
2025-03-07 12:12:54,313 - INFO - training batch 801, loss: 1.223, 25632/28000 datapoints
2025-03-07 12:12:54,581 - INFO - training batch 851, loss: 1.264, 27232/28000 datapoints
2025-03-07 12:12:54,713 - INFO - validation batch 1, loss: 1.044, 32/6976 datapoints
2025-03-07 12:12:54,796 - INFO - validation batch 51, loss: 1.624, 1632/6976 datapoints
2025-03-07 12:12:54,888 - INFO - validation batch 101, loss: 1.393, 3232/6976 datapoints
2025-03-07 12:12:54,971 - INFO - validation batch 151, loss: 1.724, 4832/6976 datapoints
2025-03-07 12:12:55,051 - INFO - validation batch 201, loss: 0.994, 6432/6976 datapoints
2025-03-07 12:12:55,080 - INFO - Epoch 10/800 done.
2025-03-07 12:12:55,081 - INFO - Final validation performance:
Loss: 1.356, top-1 acc: 0.516top-5 acc: 0.516
2025-03-07 12:12:55,081 - INFO - Beginning epoch 11/800
2025-03-07 12:12:55,090 - INFO - training batch 1, loss: 1.523, 32/28000 datapoints
2025-03-07 12:12:55,391 - INFO - training batch 51, loss: 1.596, 1632/28000 datapoints
2025-03-07 12:12:55,678 - INFO - training batch 101, loss: 1.126, 3232/28000 datapoints
2025-03-07 12:12:55,945 - INFO - training batch 151, loss: 1.496, 4832/28000 datapoints
2025-03-07 12:12:56,215 - INFO - training batch 201, loss: 1.487, 6432/28000 datapoints
2025-03-07 12:12:56,489 - INFO - training batch 251, loss: 1.305, 8032/28000 datapoints
2025-03-07 12:12:56,754 - INFO - training batch 301, loss: 1.505, 9632/28000 datapoints
2025-03-07 12:12:57,024 - INFO - training batch 351, loss: 1.369, 11232/28000 datapoints
2025-03-07 12:12:57,288 - INFO - training batch 401, loss: 1.420, 12832/28000 datapoints
2025-03-07 12:12:57,560 - INFO - training batch 451, loss: 1.398, 14432/28000 datapoints
2025-03-07 12:12:57,919 - INFO - training batch 501, loss: 1.067, 16032/28000 datapoints
2025-03-07 12:12:58,312 - INFO - training batch 551, loss: 1.463, 17632/28000 datapoints
2025-03-07 12:12:58,674 - INFO - training batch 601, loss: 1.399, 19232/28000 datapoints
2025-03-07 12:12:59,025 - INFO - training batch 651, loss: 0.999, 20832/28000 datapoints
2025-03-07 12:12:59,357 - INFO - training batch 701, loss: 1.172, 22432/28000 datapoints
2025-03-07 12:12:59,685 - INFO - training batch 751, loss: 1.459, 24032/28000 datapoints
2025-03-07 12:13:00,033 - INFO - training batch 801, loss: 1.173, 25632/28000 datapoints
2025-03-07 12:13:00,353 - INFO - training batch 851, loss: 1.233, 27232/28000 datapoints
2025-03-07 12:13:00,517 - INFO - validation batch 1, loss: 1.005, 32/6976 datapoints
2025-03-07 12:13:00,602 - INFO - validation batch 51, loss: 1.610, 1632/6976 datapoints
2025-03-07 12:13:00,686 - INFO - validation batch 101, loss: 1.368, 3232/6976 datapoints
2025-03-07 12:13:00,771 - INFO - validation batch 151, loss: 1.679, 4832/6976 datapoints
2025-03-07 12:13:00,867 - INFO - validation batch 201, loss: 0.966, 6432/6976 datapoints
2025-03-07 12:13:00,906 - INFO - Epoch 11/800 done.
2025-03-07 12:13:00,907 - INFO - Final validation performance:
Loss: 1.325, top-1 acc: 0.530top-5 acc: 0.530
2025-03-07 12:13:00,907 - INFO - Beginning epoch 12/800
2025-03-07 12:13:00,917 - INFO - training batch 1, loss: 1.479, 32/28000 datapoints
2025-03-07 12:13:01,280 - INFO - training batch 51, loss: 1.560, 1632/28000 datapoints
2025-03-07 12:13:01,608 - INFO - training batch 101, loss: 1.087, 3232/28000 datapoints
2025-03-07 12:13:01,972 - INFO - training batch 151, loss: 1.455, 4832/28000 datapoints
2025-03-07 12:13:02,280 - INFO - training batch 201, loss: 1.451, 6432/28000 datapoints
2025-03-07 12:13:02,553 - INFO - training batch 251, loss: 1.244, 8032/28000 datapoints
2025-03-07 12:13:02,824 - INFO - training batch 301, loss: 1.463, 9632/28000 datapoints
2025-03-07 12:13:03,179 - INFO - training batch 351, loss: 1.332, 11232/28000 datapoints
2025-03-07 12:13:03,508 - INFO - training batch 401, loss: 1.381, 12832/28000 datapoints
2025-03-07 12:13:03,800 - INFO - training batch 451, loss: 1.365, 14432/28000 datapoints
2025-03-07 12:13:04,066 - INFO - training batch 501, loss: 1.037, 16032/28000 datapoints
2025-03-07 12:13:04,330 - INFO - training batch 551, loss: 1.434, 17632/28000 datapoints
2025-03-07 12:13:04,602 - INFO - training batch 601, loss: 1.375, 19232/28000 datapoints
2025-03-07 12:13:04,862 - INFO - training batch 651, loss: 0.958, 20832/28000 datapoints
2025-03-07 12:13:05,119 - INFO - training batch 701, loss: 1.140, 22432/28000 datapoints
2025-03-07 12:13:05,375 - INFO - training batch 751, loss: 1.419, 24032/28000 datapoints
2025-03-07 12:13:05,633 - INFO - training batch 801, loss: 1.118, 25632/28000 datapoints
2025-03-07 12:13:05,892 - INFO - training batch 851, loss: 1.204, 27232/28000 datapoints
2025-03-07 12:13:06,015 - INFO - validation batch 1, loss: 0.964, 32/6976 datapoints
2025-03-07 12:13:06,084 - INFO - validation batch 51, loss: 1.591, 1632/6976 datapoints
2025-03-07 12:13:06,153 - INFO - validation batch 101, loss: 1.338, 3232/6976 datapoints
2025-03-07 12:13:06,221 - INFO - validation batch 151, loss: 1.631, 4832/6976 datapoints
2025-03-07 12:13:06,293 - INFO - validation batch 201, loss: 0.938, 6432/6976 datapoints
2025-03-07 12:13:06,316 - INFO - Epoch 12/800 done.
2025-03-07 12:13:06,316 - INFO - Final validation performance:
Loss: 1.292, top-1 acc: 0.541top-5 acc: 0.541
2025-03-07 12:13:06,317 - INFO - Beginning epoch 13/800
2025-03-07 12:13:06,324 - INFO - training batch 1, loss: 1.430, 32/28000 datapoints
2025-03-07 12:13:06,587 - INFO - training batch 51, loss: 1.521, 1632/28000 datapoints
2025-03-07 12:13:06,841 - INFO - training batch 101, loss: 1.045, 3232/28000 datapoints
2025-03-07 12:13:07,098 - INFO - training batch 151, loss: 1.408, 4832/28000 datapoints
2025-03-07 12:13:07,361 - INFO - training batch 201, loss: 1.413, 6432/28000 datapoints
2025-03-07 12:13:07,633 - INFO - training batch 251, loss: 1.183, 8032/28000 datapoints
2025-03-07 12:13:07,960 - INFO - training batch 301, loss: 1.419, 9632/28000 datapoints
2025-03-07 12:13:08,329 - INFO - training batch 351, loss: 1.294, 11232/28000 datapoints
2025-03-07 12:13:08,659 - INFO - training batch 401, loss: 1.335, 12832/28000 datapoints
2025-03-07 12:13:08,996 - INFO - training batch 451, loss: 1.328, 14432/28000 datapoints
2025-03-07 12:13:09,315 - INFO - training batch 501, loss: 1.004, 16032/28000 datapoints
2025-03-07 12:13:09,633 - INFO - training batch 551, loss: 1.397, 17632/28000 datapoints
2025-03-07 12:13:09,947 - INFO - training batch 601, loss: 1.349, 19232/28000 datapoints
2025-03-07 12:13:10,346 - INFO - training batch 651, loss: 0.916, 20832/28000 datapoints
2025-03-07 12:13:10,646 - INFO - training batch 701, loss: 1.102, 22432/28000 datapoints
2025-03-07 12:13:10,928 - INFO - training batch 751, loss: 1.375, 24032/28000 datapoints
2025-03-07 12:13:11,210 - INFO - training batch 801, loss: 1.056, 25632/28000 datapoints
2025-03-07 12:13:11,490 - INFO - training batch 851, loss: 1.172, 27232/28000 datapoints
2025-03-07 12:13:11,631 - INFO - validation batch 1, loss: 0.920, 32/6976 datapoints
2025-03-07 12:13:11,712 - INFO - validation batch 51, loss: 1.566, 1632/6976 datapoints
2025-03-07 12:13:11,791 - INFO - validation batch 101, loss: 1.302, 3232/6976 datapoints
2025-03-07 12:13:11,867 - INFO - validation batch 151, loss: 1.580, 4832/6976 datapoints
2025-03-07 12:13:11,944 - INFO - validation batch 201, loss: 0.907, 6432/6976 datapoints
2025-03-07 12:13:11,972 - INFO - Epoch 13/800 done.
2025-03-07 12:13:11,972 - INFO - Final validation performance:
Loss: 1.255, top-1 acc: 0.564top-5 acc: 0.564
2025-03-07 12:13:11,973 - INFO - Beginning epoch 14/800
2025-03-07 12:13:11,980 - INFO - training batch 1, loss: 1.378, 32/28000 datapoints
2025-03-07 12:13:12,256 - INFO - training batch 51, loss: 1.480, 1632/28000 datapoints
2025-03-07 12:13:12,554 - INFO - training batch 101, loss: 1.000, 3232/28000 datapoints
2025-03-07 12:13:12,824 - INFO - training batch 151, loss: 1.353, 4832/28000 datapoints
2025-03-07 12:13:13,131 - INFO - training batch 201, loss: 1.370, 6432/28000 datapoints
2025-03-07 12:13:13,414 - INFO - training batch 251, loss: 1.121, 8032/28000 datapoints
2025-03-07 12:13:13,702 - INFO - training batch 301, loss: 1.369, 9632/28000 datapoints
2025-03-07 12:13:13,995 - INFO - training batch 351, loss: 1.251, 11232/28000 datapoints
2025-03-07 12:13:14,281 - INFO - training batch 401, loss: 1.283, 12832/28000 datapoints
2025-03-07 12:13:14,551 - INFO - training batch 451, loss: 1.285, 14432/28000 datapoints
2025-03-07 12:13:14,813 - INFO - training batch 501, loss: 0.967, 16032/28000 datapoints
2025-03-07 12:13:15,080 - INFO - training batch 551, loss: 1.354, 17632/28000 datapoints
2025-03-07 12:13:15,346 - INFO - training batch 601, loss: 1.319, 19232/28000 datapoints
2025-03-07 12:13:15,614 - INFO - training batch 651, loss: 0.871, 20832/28000 datapoints
2025-03-07 12:13:15,880 - INFO - training batch 701, loss: 1.059, 22432/28000 datapoints
2025-03-07 12:13:16,143 - INFO - training batch 751, loss: 1.323, 24032/28000 datapoints
2025-03-07 12:13:16,484 - INFO - training batch 801, loss: 0.989, 25632/28000 datapoints
2025-03-07 12:13:16,790 - INFO - training batch 851, loss: 1.137, 27232/28000 datapoints
2025-03-07 12:13:16,926 - INFO - validation batch 1, loss: 0.874, 32/6976 datapoints
2025-03-07 12:13:17,005 - INFO - validation batch 51, loss: 1.538, 1632/6976 datapoints
2025-03-07 12:13:17,081 - INFO - validation batch 101, loss: 1.261, 3232/6976 datapoints
2025-03-07 12:13:17,158 - INFO - validation batch 151, loss: 1.521, 4832/6976 datapoints
2025-03-07 12:13:17,236 - INFO - validation batch 201, loss: 0.873, 6432/6976 datapoints
2025-03-07 12:13:17,265 - INFO - Epoch 14/800 done.
2025-03-07 12:13:17,265 - INFO - Final validation performance:
Loss: 1.213, top-1 acc: 0.585top-5 acc: 0.585
2025-03-07 12:13:17,266 - INFO - Beginning epoch 15/800
2025-03-07 12:13:17,273 - INFO - training batch 1, loss: 1.322, 32/28000 datapoints
2025-03-07 12:13:17,546 - INFO - training batch 51, loss: 1.434, 1632/28000 datapoints
2025-03-07 12:13:17,835 - INFO - training batch 101, loss: 0.948, 3232/28000 datapoints
2025-03-07 12:13:18,184 - INFO - training batch 151, loss: 1.292, 4832/28000 datapoints
2025-03-07 12:13:18,556 - INFO - training batch 201, loss: 1.322, 6432/28000 datapoints
2025-03-07 12:13:18,939 - INFO - training batch 251, loss: 1.060, 8032/28000 datapoints
2025-03-07 12:13:19,275 - INFO - training batch 301, loss: 1.314, 9632/28000 datapoints
2025-03-07 12:13:19,615 - INFO - training batch 351, loss: 1.203, 11232/28000 datapoints
2025-03-07 12:13:19,948 - INFO - training batch 401, loss: 1.227, 12832/28000 datapoints
2025-03-07 12:13:20,273 - INFO - training batch 451, loss: 1.235, 14432/28000 datapoints
2025-03-07 12:13:20,587 - INFO - training batch 501, loss: 0.925, 16032/28000 datapoints
2025-03-07 12:13:20,898 - INFO - training batch 551, loss: 1.305, 17632/28000 datapoints
2025-03-07 12:13:21,209 - INFO - training batch 601, loss: 1.286, 19232/28000 datapoints
2025-03-07 12:13:21,498 - INFO - training batch 651, loss: 0.824, 20832/28000 datapoints
2025-03-07 12:13:21,780 - INFO - training batch 701, loss: 1.011, 22432/28000 datapoints
2025-03-07 12:13:22,062 - INFO - training batch 751, loss: 1.267, 24032/28000 datapoints
2025-03-07 12:13:22,401 - INFO - training batch 801, loss: 0.918, 25632/28000 datapoints
2025-03-07 12:13:22,765 - INFO - training batch 851, loss: 1.097, 27232/28000 datapoints
2025-03-07 12:13:22,919 - INFO - validation batch 1, loss: 0.827, 32/6976 datapoints
2025-03-07 12:13:23,002 - INFO - validation batch 51, loss: 1.505, 1632/6976 datapoints
2025-03-07 12:13:23,085 - INFO - validation batch 101, loss: 1.213, 3232/6976 datapoints
2025-03-07 12:13:23,192 - INFO - validation batch 151, loss: 1.452, 4832/6976 datapoints
2025-03-07 12:13:23,277 - INFO - validation batch 201, loss: 0.836, 6432/6976 datapoints
2025-03-07 12:13:23,306 - INFO - Epoch 15/800 done.
2025-03-07 12:13:23,306 - INFO - Final validation performance:
Loss: 1.167, top-1 acc: 0.612top-5 acc: 0.612
2025-03-07 12:13:23,307 - INFO - Beginning epoch 16/800
2025-03-07 12:13:23,315 - INFO - training batch 1, loss: 1.261, 32/28000 datapoints
2025-03-07 12:13:23,603 - INFO - training batch 51, loss: 1.386, 1632/28000 datapoints
2025-03-07 12:13:23,870 - INFO - training batch 101, loss: 0.892, 3232/28000 datapoints
2025-03-07 12:13:24,153 - INFO - training batch 151, loss: 1.225, 4832/28000 datapoints
2025-03-07 12:13:24,469 - INFO - training batch 201, loss: 1.267, 6432/28000 datapoints
2025-03-07 12:13:24,848 - INFO - training batch 251, loss: 0.999, 8032/28000 datapoints
2025-03-07 12:13:25,342 - INFO - training batch 301, loss: 1.251, 9632/28000 datapoints
2025-03-07 12:13:25,868 - INFO - training batch 351, loss: 1.151, 11232/28000 datapoints
2025-03-07 12:13:26,218 - INFO - training batch 401, loss: 1.167, 12832/28000 datapoints
2025-03-07 12:13:26,633 - INFO - training batch 451, loss: 1.182, 14432/28000 datapoints
2025-03-07 12:13:27,025 - INFO - training batch 501, loss: 0.876, 16032/28000 datapoints
2025-03-07 12:13:27,526 - INFO - training batch 551, loss: 1.253, 17632/28000 datapoints
2025-03-07 12:13:28,048 - INFO - training batch 601, loss: 1.249, 19232/28000 datapoints
2025-03-07 12:13:28,674 - INFO - training batch 651, loss: 0.774, 20832/28000 datapoints
2025-03-07 12:13:29,414 - INFO - training batch 701, loss: 0.961, 22432/28000 datapoints
2025-03-07 12:13:30,066 - INFO - training batch 751, loss: 1.207, 24032/28000 datapoints
2025-03-07 12:13:30,679 - INFO - training batch 801, loss: 0.845, 25632/28000 datapoints
2025-03-07 12:13:31,692 - INFO - training batch 851, loss: 1.058, 27232/28000 datapoints
2025-03-07 12:13:32,199 - INFO - validation batch 1, loss: 0.779, 32/6976 datapoints
2025-03-07 12:13:32,375 - INFO - validation batch 51, loss: 1.467, 1632/6976 datapoints
2025-03-07 12:13:32,609 - INFO - validation batch 101, loss: 1.160, 3232/6976 datapoints
2025-03-07 12:13:32,811 - INFO - validation batch 151, loss: 1.379, 4832/6976 datapoints
2025-03-07 12:13:32,968 - INFO - validation batch 201, loss: 0.800, 6432/6976 datapoints
2025-03-07 12:13:33,032 - INFO - Epoch 16/800 done.
2025-03-07 12:13:33,033 - INFO - Final validation performance:
Loss: 1.117, top-1 acc: 0.636top-5 acc: 0.636
2025-03-07 12:13:33,035 - INFO - Beginning epoch 17/800
2025-03-07 12:13:33,048 - INFO - training batch 1, loss: 1.199, 32/28000 datapoints
2025-03-07 12:13:33,835 - INFO - training batch 51, loss: 1.331, 1632/28000 datapoints
2025-03-07 12:13:34,467 - INFO - training batch 101, loss: 0.832, 3232/28000 datapoints
2025-03-07 12:13:34,940 - INFO - training batch 151, loss: 1.155, 4832/28000 datapoints
2025-03-07 12:13:35,544 - INFO - training batch 201, loss: 1.206, 6432/28000 datapoints
2025-03-07 12:13:36,174 - INFO - training batch 251, loss: 0.941, 8032/28000 datapoints
2025-03-07 12:13:36,716 - INFO - training batch 301, loss: 1.183, 9632/28000 datapoints
2025-03-07 12:13:37,292 - INFO - training batch 351, loss: 1.094, 11232/28000 datapoints
2025-03-07 12:13:37,998 - INFO - training batch 401, loss: 1.106, 12832/28000 datapoints
2025-03-07 12:13:38,527 - INFO - training batch 451, loss: 1.126, 14432/28000 datapoints
2025-03-07 12:13:39,023 - INFO - training batch 501, loss: 0.826, 16032/28000 datapoints
2025-03-07 12:13:39,648 - INFO - training batch 551, loss: 1.200, 17632/28000 datapoints
2025-03-07 12:13:40,196 - INFO - training batch 601, loss: 1.210, 19232/28000 datapoints
2025-03-07 12:13:40,647 - INFO - training batch 651, loss: 0.726, 20832/28000 datapoints
2025-03-07 12:13:41,125 - INFO - training batch 701, loss: 0.911, 22432/28000 datapoints
2025-03-07 12:13:41,694 - INFO - training batch 751, loss: 1.144, 24032/28000 datapoints
2025-03-07 12:13:42,132 - INFO - training batch 801, loss: 0.773, 25632/28000 datapoints
2025-03-07 12:13:42,590 - INFO - training batch 851, loss: 1.020, 27232/28000 datapoints
2025-03-07 12:13:42,807 - INFO - validation batch 1, loss: 0.733, 32/6976 datapoints
2025-03-07 12:13:42,949 - INFO - validation batch 51, loss: 1.426, 1632/6976 datapoints
2025-03-07 12:13:43,195 - INFO - validation batch 101, loss: 1.100, 3232/6976 datapoints
2025-03-07 12:13:43,338 - INFO - validation batch 151, loss: 1.298, 4832/6976 datapoints
2025-03-07 12:13:43,503 - INFO - validation batch 201, loss: 0.765, 6432/6976 datapoints
2025-03-07 12:13:43,567 - INFO - Epoch 17/800 done.
2025-03-07 12:13:43,567 - INFO - Final validation performance:
Loss: 1.064, top-1 acc: 0.664top-5 acc: 0.664
2025-03-07 12:13:43,568 - INFO - Beginning epoch 18/800
2025-03-07 12:13:43,581 - INFO - training batch 1, loss: 1.134, 32/28000 datapoints
2025-03-07 12:13:44,386 - INFO - training batch 51, loss: 1.271, 1632/28000 datapoints
2025-03-07 12:13:44,786 - INFO - training batch 101, loss: 0.771, 3232/28000 datapoints
2025-03-07 12:13:45,234 - INFO - training batch 151, loss: 1.084, 4832/28000 datapoints
2025-03-07 12:13:45,564 - INFO - training batch 201, loss: 1.142, 6432/28000 datapoints
2025-03-07 12:13:45,967 - INFO - training batch 251, loss: 0.883, 8032/28000 datapoints
2025-03-07 12:13:46,368 - INFO - training batch 301, loss: 1.111, 9632/28000 datapoints
2025-03-07 12:13:46,768 - INFO - training batch 351, loss: 1.032, 11232/28000 datapoints
2025-03-07 12:13:47,133 - INFO - training batch 401, loss: 1.047, 12832/28000 datapoints
2025-03-07 12:13:47,507 - INFO - training batch 451, loss: 1.071, 14432/28000 datapoints
2025-03-07 12:13:47,877 - INFO - training batch 501, loss: 0.774, 16032/28000 datapoints
2025-03-07 12:13:48,232 - INFO - training batch 551, loss: 1.151, 17632/28000 datapoints
2025-03-07 12:13:48,517 - INFO - training batch 601, loss: 1.168, 19232/28000 datapoints
2025-03-07 12:13:48,876 - INFO - training batch 651, loss: 0.679, 20832/28000 datapoints
2025-03-07 12:13:49,235 - INFO - training batch 701, loss: 0.864, 22432/28000 datapoints
2025-03-07 12:13:49,614 - INFO - training batch 751, loss: 1.082, 24032/28000 datapoints
2025-03-07 12:13:49,969 - INFO - training batch 801, loss: 0.707, 25632/28000 datapoints
2025-03-07 12:13:50,367 - INFO - training batch 851, loss: 0.985, 27232/28000 datapoints
2025-03-07 12:13:50,582 - INFO - validation batch 1, loss: 0.691, 32/6976 datapoints
2025-03-07 12:13:50,674 - INFO - validation batch 51, loss: 1.384, 1632/6976 datapoints
2025-03-07 12:13:50,753 - INFO - validation batch 101, loss: 1.036, 3232/6976 datapoints
2025-03-07 12:13:50,844 - INFO - validation batch 151, loss: 1.216, 4832/6976 datapoints
2025-03-07 12:13:50,962 - INFO - validation batch 201, loss: 0.732, 6432/6976 datapoints
2025-03-07 12:13:51,009 - INFO - Epoch 18/800 done.
2025-03-07 12:13:51,009 - INFO - Final validation performance:
Loss: 1.012, top-1 acc: 0.688top-5 acc: 0.688
2025-03-07 12:13:51,011 - INFO - Beginning epoch 19/800
2025-03-07 12:13:51,021 - INFO - training batch 1, loss: 1.070, 32/28000 datapoints
2025-03-07 12:13:51,431 - INFO - training batch 51, loss: 1.209, 1632/28000 datapoints
2025-03-07 12:13:51,847 - INFO - training batch 101, loss: 0.712, 3232/28000 datapoints
2025-03-07 12:13:52,203 - INFO - training batch 151, loss: 1.014, 4832/28000 datapoints
2025-03-07 12:13:52,563 - INFO - training batch 201, loss: 1.079, 6432/28000 datapoints
2025-03-07 12:13:52,916 - INFO - training batch 251, loss: 0.829, 8032/28000 datapoints
2025-03-07 12:13:53,343 - INFO - training batch 301, loss: 1.044, 9632/28000 datapoints
2025-03-07 12:13:53,820 - INFO - training batch 351, loss: 0.970, 11232/28000 datapoints
2025-03-07 12:13:54,236 - INFO - training batch 401, loss: 0.991, 12832/28000 datapoints
2025-03-07 12:13:54,635 - INFO - training batch 451, loss: 1.021, 14432/28000 datapoints
2025-03-07 12:13:55,037 - INFO - training batch 501, loss: 0.723, 16032/28000 datapoints
2025-03-07 12:13:55,483 - INFO - training batch 551, loss: 1.107, 17632/28000 datapoints
2025-03-07 12:13:55,941 - INFO - training batch 601, loss: 1.125, 19232/28000 datapoints
2025-03-07 12:13:56,322 - INFO - training batch 651, loss: 0.634, 20832/28000 datapoints
2025-03-07 12:13:56,734 - INFO - training batch 701, loss: 0.822, 22432/28000 datapoints
2025-03-07 12:13:57,140 - INFO - training batch 751, loss: 1.021, 24032/28000 datapoints
2025-03-07 12:13:57,617 - INFO - training batch 801, loss: 0.648, 25632/28000 datapoints
2025-03-07 12:13:58,169 - INFO - training batch 851, loss: 0.951, 27232/28000 datapoints
2025-03-07 12:13:58,399 - INFO - validation batch 1, loss: 0.653, 32/6976 datapoints
2025-03-07 12:13:58,551 - INFO - validation batch 51, loss: 1.343, 1632/6976 datapoints
2025-03-07 12:13:58,692 - INFO - validation batch 101, loss: 0.972, 3232/6976 datapoints
2025-03-07 12:13:58,847 - INFO - validation batch 151, loss: 1.135, 4832/6976 datapoints
2025-03-07 12:13:59,029 - INFO - validation batch 201, loss: 0.702, 6432/6976 datapoints
2025-03-07 12:13:59,080 - INFO - Epoch 19/800 done.
2025-03-07 12:13:59,081 - INFO - Final validation performance:
Loss: 0.961, top-1 acc: 0.707top-5 acc: 0.707
2025-03-07 12:13:59,081 - INFO - Beginning epoch 20/800
2025-03-07 12:13:59,096 - INFO - training batch 1, loss: 1.006, 32/28000 datapoints
2025-03-07 12:13:59,656 - INFO - training batch 51, loss: 1.145, 1632/28000 datapoints
2025-03-07 12:14:00,129 - INFO - training batch 101, loss: 0.653, 3232/28000 datapoints
2025-03-07 12:14:00,628 - INFO - training batch 151, loss: 0.950, 4832/28000 datapoints
2025-03-07 12:14:01,205 - INFO - training batch 201, loss: 1.019, 6432/28000 datapoints
2025-03-07 12:14:01,889 - INFO - training batch 251, loss: 0.778, 8032/28000 datapoints
2025-03-07 12:14:02,467 - INFO - training batch 301, loss: 0.984, 9632/28000 datapoints
2025-03-07 12:14:03,223 - INFO - training batch 351, loss: 0.911, 11232/28000 datapoints
2025-03-07 12:14:04,122 - INFO - training batch 401, loss: 0.941, 12832/28000 datapoints
2025-03-07 12:14:04,538 - INFO - training batch 451, loss: 0.979, 14432/28000 datapoints
2025-03-07 12:14:05,060 - INFO - training batch 501, loss: 0.676, 16032/28000 datapoints
2025-03-07 12:14:05,546 - INFO - training batch 551, loss: 1.067, 17632/28000 datapoints
2025-03-07 12:14:06,028 - INFO - training batch 601, loss: 1.083, 19232/28000 datapoints
2025-03-07 12:14:06,475 - INFO - training batch 651, loss: 0.591, 20832/28000 datapoints
2025-03-07 12:14:06,872 - INFO - training batch 701, loss: 0.784, 22432/28000 datapoints
2025-03-07 12:14:07,282 - INFO - training batch 751, loss: 0.960, 24032/28000 datapoints
2025-03-07 12:14:07,671 - INFO - training batch 801, loss: 0.596, 25632/28000 datapoints
2025-03-07 12:14:08,050 - INFO - training batch 851, loss: 0.917, 27232/28000 datapoints
2025-03-07 12:14:08,251 - INFO - validation batch 1, loss: 0.619, 32/6976 datapoints
2025-03-07 12:14:08,411 - INFO - validation batch 51, loss: 1.303, 1632/6976 datapoints
2025-03-07 12:14:08,535 - INFO - validation batch 101, loss: 0.908, 3232/6976 datapoints
2025-03-07 12:14:08,644 - INFO - validation batch 151, loss: 1.055, 4832/6976 datapoints
2025-03-07 12:14:08,771 - INFO - validation batch 201, loss: 0.675, 6432/6976 datapoints
2025-03-07 12:14:08,829 - INFO - Epoch 20/800 done.
2025-03-07 12:14:08,829 - INFO - Final validation performance:
Loss: 0.912, top-1 acc: 0.722top-5 acc: 0.722
2025-03-07 12:14:08,831 - INFO - Beginning epoch 21/800
2025-03-07 12:14:08,842 - INFO - training batch 1, loss: 0.943, 32/28000 datapoints
2025-03-07 12:14:09,407 - INFO - training batch 51, loss: 1.078, 1632/28000 datapoints
2025-03-07 12:14:09,855 - INFO - training batch 101, loss: 0.597, 3232/28000 datapoints
2025-03-07 12:14:10,317 - INFO - training batch 151, loss: 0.892, 4832/28000 datapoints
2025-03-07 12:14:10,707 - INFO - training batch 201, loss: 0.960, 6432/28000 datapoints
2025-03-07 12:14:11,151 - INFO - training batch 251, loss: 0.733, 8032/28000 datapoints
2025-03-07 12:14:11,570 - INFO - training batch 301, loss: 0.932, 9632/28000 datapoints
2025-03-07 12:14:12,014 - INFO - training batch 351, loss: 0.856, 11232/28000 datapoints
2025-03-07 12:14:12,426 - INFO - training batch 401, loss: 0.896, 12832/28000 datapoints
2025-03-07 12:14:12,906 - INFO - training batch 451, loss: 0.943, 14432/28000 datapoints
2025-03-07 12:14:13,339 - INFO - training batch 501, loss: 0.634, 16032/28000 datapoints
2025-03-07 12:14:13,731 - INFO - training batch 551, loss: 1.029, 17632/28000 datapoints
2025-03-07 12:14:14,144 - INFO - training batch 601, loss: 1.044, 19232/28000 datapoints
2025-03-07 12:14:14,642 - INFO - training batch 651, loss: 0.552, 20832/28000 datapoints
2025-03-07 12:14:14,994 - INFO - training batch 701, loss: 0.750, 22432/28000 datapoints
2025-03-07 12:14:15,443 - INFO - training batch 751, loss: 0.899, 24032/28000 datapoints
2025-03-07 12:14:15,824 - INFO - training batch 801, loss: 0.551, 25632/28000 datapoints
2025-03-07 12:14:16,233 - INFO - training batch 851, loss: 0.886, 27232/28000 datapoints
2025-03-07 12:14:16,482 - INFO - validation batch 1, loss: 0.590, 32/6976 datapoints
2025-03-07 12:14:16,644 - INFO - validation batch 51, loss: 1.265, 1632/6976 datapoints
2025-03-07 12:14:16,792 - INFO - validation batch 101, loss: 0.845, 3232/6976 datapoints
2025-03-07 12:14:16,985 - INFO - validation batch 151, loss: 0.977, 4832/6976 datapoints
2025-03-07 12:14:17,115 - INFO - validation batch 201, loss: 0.650, 6432/6976 datapoints
2025-03-07 12:14:17,156 - INFO - Epoch 21/800 done.
2025-03-07 12:14:17,156 - INFO - Final validation performance:
Loss: 0.865, top-1 acc: 0.739top-5 acc: 0.739
2025-03-07 12:14:17,157 - INFO - Beginning epoch 22/800
2025-03-07 12:14:17,169 - INFO - training batch 1, loss: 0.882, 32/28000 datapoints
2025-03-07 12:14:17,739 - INFO - training batch 51, loss: 1.007, 1632/28000 datapoints
2025-03-07 12:14:18,261 - INFO - training batch 101, loss: 0.546, 3232/28000 datapoints
2025-03-07 12:14:18,748 - INFO - training batch 151, loss: 0.844, 4832/28000 datapoints
2025-03-07 12:14:19,133 - INFO - training batch 201, loss: 0.905, 6432/28000 datapoints
2025-03-07 12:14:19,515 - INFO - training batch 251, loss: 0.692, 8032/28000 datapoints
2025-03-07 12:14:19,861 - INFO - training batch 301, loss: 0.888, 9632/28000 datapoints
2025-03-07 12:14:20,182 - INFO - training batch 351, loss: 0.805, 11232/28000 datapoints
2025-03-07 12:14:20,508 - INFO - training batch 401, loss: 0.857, 12832/28000 datapoints
2025-03-07 12:14:20,821 - INFO - training batch 451, loss: 0.911, 14432/28000 datapoints
2025-03-07 12:14:21,123 - INFO - training batch 501, loss: 0.597, 16032/28000 datapoints
2025-03-07 12:14:21,427 - INFO - training batch 551, loss: 0.995, 17632/28000 datapoints
2025-03-07 12:14:21,754 - INFO - training batch 601, loss: 1.009, 19232/28000 datapoints
2025-03-07 12:14:22,056 - INFO - training batch 651, loss: 0.516, 20832/28000 datapoints
2025-03-07 12:14:22,353 - INFO - training batch 701, loss: 0.721, 22432/28000 datapoints
2025-03-07 12:14:22,641 - INFO - training batch 751, loss: 0.839, 24032/28000 datapoints
2025-03-07 12:14:22,949 - INFO - training batch 801, loss: 0.514, 25632/28000 datapoints
2025-03-07 12:14:23,263 - INFO - training batch 851, loss: 0.857, 27232/28000 datapoints
2025-03-07 12:14:23,418 - INFO - validation batch 1, loss: 0.564, 32/6976 datapoints
2025-03-07 12:14:23,528 - INFO - validation batch 51, loss: 1.232, 1632/6976 datapoints
2025-03-07 12:14:23,605 - INFO - validation batch 101, loss: 0.785, 3232/6976 datapoints
2025-03-07 12:14:23,695 - INFO - validation batch 151, loss: 0.906, 4832/6976 datapoints
2025-03-07 12:14:23,916 - INFO - validation batch 201, loss: 0.628, 6432/6976 datapoints
2025-03-07 12:14:23,972 - INFO - Epoch 22/800 done.
2025-03-07 12:14:23,973 - INFO - Final validation performance:
Loss: 0.823, top-1 acc: 0.753top-5 acc: 0.753
2025-03-07 12:14:23,973 - INFO - Beginning epoch 23/800
2025-03-07 12:14:23,983 - INFO - training batch 1, loss: 0.826, 32/28000 datapoints
2025-03-07 12:14:24,358 - INFO - training batch 51, loss: 0.937, 1632/28000 datapoints
2025-03-07 12:14:24,643 - INFO - training batch 101, loss: 0.501, 3232/28000 datapoints
2025-03-07 12:14:24,960 - INFO - training batch 151, loss: 0.803, 4832/28000 datapoints
2025-03-07 12:14:25,252 - INFO - training batch 201, loss: 0.856, 6432/28000 datapoints
2025-03-07 12:14:25,576 - INFO - training batch 251, loss: 0.656, 8032/28000 datapoints
2025-03-07 12:14:25,887 - INFO - training batch 301, loss: 0.850, 9632/28000 datapoints
2025-03-07 12:14:26,231 - INFO - training batch 351, loss: 0.761, 11232/28000 datapoints
2025-03-07 12:14:26,617 - INFO - training batch 401, loss: 0.824, 12832/28000 datapoints
2025-03-07 12:14:27,054 - INFO - training batch 451, loss: 0.882, 14432/28000 datapoints
2025-03-07 12:14:27,647 - INFO - training batch 501, loss: 0.563, 16032/28000 datapoints
2025-03-07 12:14:28,223 - INFO - training batch 551, loss: 0.963, 17632/28000 datapoints
2025-03-07 12:14:28,616 - INFO - training batch 601, loss: 0.979, 19232/28000 datapoints
2025-03-07 12:14:29,279 - INFO - training batch 651, loss: 0.486, 20832/28000 datapoints
2025-03-07 12:14:29,757 - INFO - training batch 701, loss: 0.694, 22432/28000 datapoints
2025-03-07 12:14:31,209 - INFO - training batch 751, loss: 0.781, 24032/28000 datapoints
2025-03-07 12:14:31,885 - INFO - training batch 801, loss: 0.486, 25632/28000 datapoints
2025-03-07 12:14:32,466 - INFO - training batch 851, loss: 0.830, 27232/28000 datapoints
2025-03-07 12:14:32,840 - INFO - validation batch 1, loss: 0.542, 32/6976 datapoints
2025-03-07 12:14:33,056 - INFO - validation batch 51, loss: 1.204, 1632/6976 datapoints
2025-03-07 12:14:33,213 - INFO - validation batch 101, loss: 0.731, 3232/6976 datapoints
2025-03-07 12:14:33,464 - INFO - validation batch 151, loss: 0.844, 4832/6976 datapoints
2025-03-07 12:14:33,714 - INFO - validation batch 201, loss: 0.608, 6432/6976 datapoints
2025-03-07 12:14:33,842 - INFO - Epoch 23/800 done.
2025-03-07 12:14:33,843 - INFO - Final validation performance:
Loss: 0.786, top-1 acc: 0.765top-5 acc: 0.765
2025-03-07 12:14:33,846 - INFO - Beginning epoch 24/800
2025-03-07 12:14:33,861 - INFO - training batch 1, loss: 0.775, 32/28000 datapoints
2025-03-07 12:14:34,384 - INFO - training batch 51, loss: 0.870, 1632/28000 datapoints
2025-03-07 12:14:34,797 - INFO - training batch 101, loss: 0.462, 3232/28000 datapoints
2025-03-07 12:14:35,157 - INFO - training batch 151, loss: 0.769, 4832/28000 datapoints
2025-03-07 12:14:35,546 - INFO - training batch 201, loss: 0.815, 6432/28000 datapoints
2025-03-07 12:14:35,866 - INFO - training batch 251, loss: 0.625, 8032/28000 datapoints
2025-03-07 12:14:36,220 - INFO - training batch 301, loss: 0.818, 9632/28000 datapoints
2025-03-07 12:14:36,559 - INFO - training batch 351, loss: 0.723, 11232/28000 datapoints
2025-03-07 12:14:36,906 - INFO - training batch 401, loss: 0.797, 12832/28000 datapoints
2025-03-07 12:14:37,251 - INFO - training batch 451, loss: 0.856, 14432/28000 datapoints
2025-03-07 12:14:37,817 - INFO - training batch 501, loss: 0.533, 16032/28000 datapoints
2025-03-07 12:14:38,324 - INFO - training batch 551, loss: 0.933, 17632/28000 datapoints
2025-03-07 12:14:38,776 - INFO - training batch 601, loss: 0.952, 19232/28000 datapoints
2025-03-07 12:14:39,206 - INFO - training batch 651, loss: 0.459, 20832/28000 datapoints
2025-03-07 12:14:39,661 - INFO - training batch 701, loss: 0.669, 22432/28000 datapoints
2025-03-07 12:14:40,109 - INFO - training batch 751, loss: 0.726, 24032/28000 datapoints
2025-03-07 12:14:40,466 - INFO - training batch 801, loss: 0.464, 25632/28000 datapoints
2025-03-07 12:14:40,786 - INFO - training batch 851, loss: 0.805, 27232/28000 datapoints
2025-03-07 12:14:40,946 - INFO - validation batch 1, loss: 0.522, 32/6976 datapoints
2025-03-07 12:14:41,033 - INFO - validation batch 51, loss: 1.180, 1632/6976 datapoints
2025-03-07 12:14:41,125 - INFO - validation batch 101, loss: 0.681, 3232/6976 datapoints
2025-03-07 12:14:41,215 - INFO - validation batch 151, loss: 0.794, 4832/6976 datapoints
2025-03-07 12:14:41,300 - INFO - validation batch 201, loss: 0.591, 6432/6976 datapoints
2025-03-07 12:14:41,334 - INFO - Epoch 24/800 done.
2025-03-07 12:14:41,334 - INFO - Final validation performance:
Loss: 0.754, top-1 acc: 0.777top-5 acc: 0.777
2025-03-07 12:14:41,335 - INFO - Beginning epoch 25/800
2025-03-07 12:14:41,350 - INFO - training batch 1, loss: 0.729, 32/28000 datapoints
2025-03-07 12:14:41,880 - INFO - training batch 51, loss: 0.808, 1632/28000 datapoints
2025-03-07 12:14:42,233 - INFO - training batch 101, loss: 0.430, 3232/28000 datapoints
2025-03-07 12:14:42,536 - INFO - training batch 151, loss: 0.741, 4832/28000 datapoints
2025-03-07 12:14:42,825 - INFO - training batch 201, loss: 0.780, 6432/28000 datapoints
2025-03-07 12:14:43,110 - INFO - training batch 251, loss: 0.598, 8032/28000 datapoints
2025-03-07 12:14:43,454 - INFO - training batch 301, loss: 0.791, 9632/28000 datapoints
2025-03-07 12:14:43,725 - INFO - training batch 351, loss: 0.691, 11232/28000 datapoints
2025-03-07 12:14:44,011 - INFO - training batch 401, loss: 0.775, 12832/28000 datapoints
2025-03-07 12:14:44,292 - INFO - training batch 451, loss: 0.833, 14432/28000 datapoints
2025-03-07 12:14:44,609 - INFO - training batch 501, loss: 0.505, 16032/28000 datapoints
2025-03-07 12:14:44,885 - INFO - training batch 551, loss: 0.905, 17632/28000 datapoints
2025-03-07 12:14:45,158 - INFO - training batch 601, loss: 0.930, 19232/28000 datapoints
2025-03-07 12:14:45,436 - INFO - training batch 651, loss: 0.436, 20832/28000 datapoints
2025-03-07 12:14:45,710 - INFO - training batch 701, loss: 0.646, 22432/28000 datapoints
2025-03-07 12:14:45,979 - INFO - training batch 751, loss: 0.676, 24032/28000 datapoints
2025-03-07 12:14:46,258 - INFO - training batch 801, loss: 0.448, 25632/28000 datapoints
2025-03-07 12:14:46,651 - INFO - training batch 851, loss: 0.786, 27232/28000 datapoints
2025-03-07 12:14:46,796 - INFO - validation batch 1, loss: 0.504, 32/6976 datapoints
2025-03-07 12:14:46,889 - INFO - validation batch 51, loss: 1.161, 1632/6976 datapoints
2025-03-07 12:14:46,975 - INFO - validation batch 101, loss: 0.636, 3232/6976 datapoints
2025-03-07 12:14:47,058 - INFO - validation batch 151, loss: 0.751, 4832/6976 datapoints
2025-03-07 12:14:47,144 - INFO - validation batch 201, loss: 0.577, 6432/6976 datapoints
2025-03-07 12:14:47,176 - INFO - Epoch 25/800 done.
2025-03-07 12:14:47,176 - INFO - Final validation performance:
Loss: 0.726, top-1 acc: 0.787top-5 acc: 0.787
2025-03-07 12:14:47,177 - INFO - Beginning epoch 26/800
2025-03-07 12:14:47,185 - INFO - training batch 1, loss: 0.689, 32/28000 datapoints
2025-03-07 12:14:47,524 - INFO - training batch 51, loss: 0.753, 1632/28000 datapoints
2025-03-07 12:14:47,845 - INFO - training batch 101, loss: 0.402, 3232/28000 datapoints
2025-03-07 12:14:48,148 - INFO - training batch 151, loss: 0.717, 4832/28000 datapoints
2025-03-07 12:14:48,453 - INFO - training batch 201, loss: 0.750, 6432/28000 datapoints
2025-03-07 12:14:48,749 - INFO - training batch 251, loss: 0.576, 8032/28000 datapoints
2025-03-07 12:14:49,046 - INFO - training batch 301, loss: 0.768, 9632/28000 datapoints
2025-03-07 12:14:49,349 - INFO - training batch 351, loss: 0.663, 11232/28000 datapoints
2025-03-07 12:14:49,656 - INFO - training batch 401, loss: 0.757, 12832/28000 datapoints
2025-03-07 12:14:49,939 - INFO - training batch 451, loss: 0.812, 14432/28000 datapoints
2025-03-07 12:14:50,222 - INFO - training batch 501, loss: 0.479, 16032/28000 datapoints
2025-03-07 12:14:50,512 - INFO - training batch 551, loss: 0.879, 17632/28000 datapoints
2025-03-07 12:14:50,793 - INFO - training batch 601, loss: 0.913, 19232/28000 datapoints
2025-03-07 12:14:51,082 - INFO - training batch 651, loss: 0.417, 20832/28000 datapoints
2025-03-07 12:14:51,387 - INFO - training batch 701, loss: 0.624, 22432/28000 datapoints
2025-03-07 12:14:51,684 - INFO - training batch 751, loss: 0.633, 24032/28000 datapoints
2025-03-07 12:14:52,054 - INFO - training batch 801, loss: 0.434, 25632/28000 datapoints
2025-03-07 12:14:52,351 - INFO - training batch 851, loss: 0.769, 27232/28000 datapoints
2025-03-07 12:14:52,504 - INFO - validation batch 1, loss: 0.486, 32/6976 datapoints
2025-03-07 12:14:52,596 - INFO - validation batch 51, loss: 1.144, 1632/6976 datapoints
2025-03-07 12:14:52,683 - INFO - validation batch 101, loss: 0.596, 3232/6976 datapoints
2025-03-07 12:14:52,769 - INFO - validation batch 151, loss: 0.717, 4832/6976 datapoints
2025-03-07 12:14:52,852 - INFO - validation batch 201, loss: 0.565, 6432/6976 datapoints
2025-03-07 12:14:52,881 - INFO - Epoch 26/800 done.
2025-03-07 12:14:52,882 - INFO - Final validation performance:
Loss: 0.701, top-1 acc: 0.794top-5 acc: 0.794
2025-03-07 12:14:52,882 - INFO - Beginning epoch 27/800
2025-03-07 12:14:52,892 - INFO - training batch 1, loss: 0.654, 32/28000 datapoints
2025-03-07 12:14:53,201 - INFO - training batch 51, loss: 0.704, 1632/28000 datapoints
2025-03-07 12:14:53,516 - INFO - training batch 101, loss: 0.379, 3232/28000 datapoints
2025-03-07 12:14:53,811 - INFO - training batch 151, loss: 0.696, 4832/28000 datapoints
2025-03-07 12:14:54,105 - INFO - training batch 201, loss: 0.726, 6432/28000 datapoints
2025-03-07 12:14:54,398 - INFO - training batch 251, loss: 0.557, 8032/28000 datapoints
2025-03-07 12:14:54,741 - INFO - training batch 301, loss: 0.748, 9632/28000 datapoints
2025-03-07 12:14:55,057 - INFO - training batch 351, loss: 0.638, 11232/28000 datapoints
2025-03-07 12:14:55,367 - INFO - training batch 401, loss: 0.743, 12832/28000 datapoints
2025-03-07 12:14:55,663 - INFO - training batch 451, loss: 0.794, 14432/28000 datapoints
2025-03-07 12:14:55,965 - INFO - training batch 501, loss: 0.455, 16032/28000 datapoints
2025-03-07 12:14:56,250 - INFO - training batch 551, loss: 0.853, 17632/28000 datapoints
2025-03-07 12:14:56,542 - INFO - training batch 601, loss: 0.898, 19232/28000 datapoints
2025-03-07 12:14:56,846 - INFO - training batch 651, loss: 0.400, 20832/28000 datapoints
2025-03-07 12:14:57,163 - INFO - training batch 701, loss: 0.604, 22432/28000 datapoints
2025-03-07 12:14:57,459 - INFO - training batch 751, loss: 0.597, 24032/28000 datapoints
2025-03-07 12:14:57,789 - INFO - training batch 801, loss: 0.423, 25632/28000 datapoints
2025-03-07 12:14:58,216 - INFO - training batch 851, loss: 0.754, 27232/28000 datapoints
2025-03-07 12:14:58,457 - INFO - validation batch 1, loss: 0.468, 32/6976 datapoints
2025-03-07 12:14:58,613 - INFO - validation batch 51, loss: 1.129, 1632/6976 datapoints
2025-03-07 12:14:58,738 - INFO - validation batch 101, loss: 0.559, 3232/6976 datapoints
2025-03-07 12:14:58,850 - INFO - validation batch 151, loss: 0.687, 4832/6976 datapoints
2025-03-07 12:14:58,937 - INFO - validation batch 201, loss: 0.554, 6432/6976 datapoints
2025-03-07 12:14:58,968 - INFO - Epoch 27/800 done.
2025-03-07 12:14:58,968 - INFO - Final validation performance:
Loss: 0.679, top-1 acc: 0.800top-5 acc: 0.800
2025-03-07 12:14:58,969 - INFO - Beginning epoch 28/800
2025-03-07 12:14:58,978 - INFO - training batch 1, loss: 0.624, 32/28000 datapoints
2025-03-07 12:14:59,264 - INFO - training batch 51, loss: 0.660, 1632/28000 datapoints
2025-03-07 12:14:59,683 - INFO - training batch 101, loss: 0.360, 3232/28000 datapoints
2025-03-07 12:15:00,058 - INFO - training batch 151, loss: 0.676, 4832/28000 datapoints
2025-03-07 12:15:00,492 - INFO - training batch 201, loss: 0.704, 6432/28000 datapoints
2025-03-07 12:15:00,861 - INFO - training batch 251, loss: 0.540, 8032/28000 datapoints
2025-03-07 12:15:01,161 - INFO - training batch 301, loss: 0.732, 9632/28000 datapoints
2025-03-07 12:15:01,475 - INFO - training batch 351, loss: 0.616, 11232/28000 datapoints
2025-03-07 12:15:01,783 - INFO - training batch 401, loss: 0.730, 12832/28000 datapoints
2025-03-07 12:15:02,081 - INFO - training batch 451, loss: 0.777, 14432/28000 datapoints
2025-03-07 12:15:02,394 - INFO - training batch 501, loss: 0.434, 16032/28000 datapoints
2025-03-07 12:15:02,737 - INFO - training batch 551, loss: 0.829, 17632/28000 datapoints
2025-03-07 12:15:03,051 - INFO - training batch 601, loss: 0.886, 19232/28000 datapoints
2025-03-07 12:15:03,387 - INFO - training batch 651, loss: 0.385, 20832/28000 datapoints
2025-03-07 12:15:03,848 - INFO - training batch 701, loss: 0.585, 22432/28000 datapoints
2025-03-07 12:15:04,264 - INFO - training batch 751, loss: 0.564, 24032/28000 datapoints
2025-03-07 12:15:04,876 - INFO - training batch 801, loss: 0.413, 25632/28000 datapoints
2025-03-07 12:15:05,323 - INFO - training batch 851, loss: 0.741, 27232/28000 datapoints
2025-03-07 12:15:05,533 - INFO - validation batch 1, loss: 0.451, 32/6976 datapoints
2025-03-07 12:15:05,665 - INFO - validation batch 51, loss: 1.115, 1632/6976 datapoints
2025-03-07 12:15:05,804 - INFO - validation batch 101, loss: 0.524, 3232/6976 datapoints
2025-03-07 12:15:05,921 - INFO - validation batch 151, loss: 0.663, 4832/6976 datapoints
2025-03-07 12:15:06,040 - INFO - validation batch 201, loss: 0.544, 6432/6976 datapoints
2025-03-07 12:15:06,093 - INFO - Epoch 28/800 done.
2025-03-07 12:15:06,093 - INFO - Final validation performance:
Loss: 0.659, top-1 acc: 0.805top-5 acc: 0.805
2025-03-07 12:15:06,094 - INFO - Beginning epoch 29/800
2025-03-07 12:15:06,117 - INFO - training batch 1, loss: 0.597, 32/28000 datapoints
2025-03-07 12:15:06,495 - INFO - training batch 51, loss: 0.621, 1632/28000 datapoints
2025-03-07 12:15:06,840 - INFO - training batch 101, loss: 0.345, 3232/28000 datapoints
2025-03-07 12:15:07,167 - INFO - training batch 151, loss: 0.657, 4832/28000 datapoints
2025-03-07 12:15:07,487 - INFO - training batch 201, loss: 0.685, 6432/28000 datapoints
2025-03-07 12:15:07,790 - INFO - training batch 251, loss: 0.526, 8032/28000 datapoints
2025-03-07 12:15:08,129 - INFO - training batch 301, loss: 0.717, 9632/28000 datapoints
2025-03-07 12:15:08,419 - INFO - training batch 351, loss: 0.594, 11232/28000 datapoints
2025-03-07 12:15:08,716 - INFO - training batch 401, loss: 0.719, 12832/28000 datapoints
2025-03-07 12:15:08,995 - INFO - training batch 451, loss: 0.761, 14432/28000 datapoints
2025-03-07 12:15:09,271 - INFO - training batch 501, loss: 0.414, 16032/28000 datapoints
2025-03-07 12:15:09,544 - INFO - training batch 551, loss: 0.805, 17632/28000 datapoints
2025-03-07 12:15:09,829 - INFO - training batch 601, loss: 0.876, 19232/28000 datapoints
2025-03-07 12:15:10,097 - INFO - training batch 651, loss: 0.371, 20832/28000 datapoints
2025-03-07 12:15:10,369 - INFO - training batch 701, loss: 0.567, 22432/28000 datapoints
2025-03-07 12:15:10,650 - INFO - training batch 751, loss: 0.536, 24032/28000 datapoints
2025-03-07 12:15:10,928 - INFO - training batch 801, loss: 0.406, 25632/28000 datapoints
2025-03-07 12:15:11,201 - INFO - training batch 851, loss: 0.729, 27232/28000 datapoints
2025-03-07 12:15:11,343 - INFO - validation batch 1, loss: 0.435, 32/6976 datapoints
2025-03-07 12:15:11,418 - INFO - validation batch 51, loss: 1.100, 1632/6976 datapoints
2025-03-07 12:15:11,500 - INFO - validation batch 101, loss: 0.493, 3232/6976 datapoints
2025-03-07 12:15:11,577 - INFO - validation batch 151, loss: 0.641, 4832/6976 datapoints
2025-03-07 12:15:11,651 - INFO - validation batch 201, loss: 0.538, 6432/6976 datapoints
2025-03-07 12:15:11,685 - INFO - Epoch 29/800 done.
2025-03-07 12:15:11,686 - INFO - Final validation performance:
Loss: 0.641, top-1 acc: 0.809top-5 acc: 0.809
2025-03-07 12:15:11,687 - INFO - Beginning epoch 30/800
2025-03-07 12:15:11,695 - INFO - training batch 1, loss: 0.572, 32/28000 datapoints
2025-03-07 12:15:11,993 - INFO - training batch 51, loss: 0.586, 1632/28000 datapoints
2025-03-07 12:15:12,290 - INFO - training batch 101, loss: 0.331, 3232/28000 datapoints
2025-03-07 12:15:12,589 - INFO - training batch 151, loss: 0.640, 4832/28000 datapoints
2025-03-07 12:15:12,873 - INFO - training batch 201, loss: 0.668, 6432/28000 datapoints
2025-03-07 12:15:13,141 - INFO - training batch 251, loss: 0.514, 8032/28000 datapoints
2025-03-07 12:15:13,413 - INFO - training batch 301, loss: 0.705, 9632/28000 datapoints
2025-03-07 12:15:13,708 - INFO - training batch 351, loss: 0.574, 11232/28000 datapoints
2025-03-07 12:15:14,004 - INFO - training batch 401, loss: 0.708, 12832/28000 datapoints
2025-03-07 12:15:14,342 - INFO - training batch 451, loss: 0.747, 14432/28000 datapoints
2025-03-07 12:15:14,642 - INFO - training batch 501, loss: 0.396, 16032/28000 datapoints
2025-03-07 12:15:14,962 - INFO - training batch 551, loss: 0.784, 17632/28000 datapoints
2025-03-07 12:15:15,249 - INFO - training batch 601, loss: 0.868, 19232/28000 datapoints
2025-03-07 12:15:15,530 - INFO - training batch 651, loss: 0.359, 20832/28000 datapoints
2025-03-07 12:15:15,889 - INFO - training batch 701, loss: 0.550, 22432/28000 datapoints
2025-03-07 12:15:16,221 - INFO - training batch 751, loss: 0.511, 24032/28000 datapoints
2025-03-07 12:15:16,582 - INFO - training batch 801, loss: 0.399, 25632/28000 datapoints
2025-03-07 12:15:16,945 - INFO - training batch 851, loss: 0.718, 27232/28000 datapoints
2025-03-07 12:15:17,114 - INFO - validation batch 1, loss: 0.418, 32/6976 datapoints
2025-03-07 12:15:17,214 - INFO - validation batch 51, loss: 1.087, 1632/6976 datapoints
2025-03-07 12:15:17,310 - INFO - validation batch 101, loss: 0.465, 3232/6976 datapoints
2025-03-07 12:15:17,411 - INFO - validation batch 151, loss: 0.621, 4832/6976 datapoints
2025-03-07 12:15:17,519 - INFO - validation batch 201, loss: 0.531, 6432/6976 datapoints
2025-03-07 12:15:17,553 - INFO - Epoch 30/800 done.
2025-03-07 12:15:17,553 - INFO - Final validation performance:
Loss: 0.625, top-1 acc: 0.813top-5 acc: 0.813
2025-03-07 12:15:17,555 - INFO - Beginning epoch 31/800
2025-03-07 12:15:17,565 - INFO - training batch 1, loss: 0.550, 32/28000 datapoints
2025-03-07 12:15:17,899 - INFO - training batch 51, loss: 0.554, 1632/28000 datapoints
2025-03-07 12:15:18,203 - INFO - training batch 101, loss: 0.320, 3232/28000 datapoints
2025-03-07 12:15:18,497 - INFO - training batch 151, loss: 0.624, 4832/28000 datapoints
2025-03-07 12:15:18,786 - INFO - training batch 201, loss: 0.651, 6432/28000 datapoints
2025-03-07 12:15:19,066 - INFO - training batch 251, loss: 0.503, 8032/28000 datapoints
2025-03-07 12:15:19,355 - INFO - training batch 301, loss: 0.693, 9632/28000 datapoints
2025-03-07 12:15:19,646 - INFO - training batch 351, loss: 0.555, 11232/28000 datapoints
2025-03-07 12:15:19,933 - INFO - training batch 401, loss: 0.698, 12832/28000 datapoints
2025-03-07 12:15:20,207 - INFO - training batch 451, loss: 0.734, 14432/28000 datapoints
2025-03-07 12:15:20,513 - INFO - training batch 501, loss: 0.379, 16032/28000 datapoints
2025-03-07 12:15:20,811 - INFO - training batch 551, loss: 0.763, 17632/28000 datapoints
2025-03-07 12:15:21,070 - INFO - training batch 601, loss: 0.861, 19232/28000 datapoints
2025-03-07 12:15:21,326 - INFO - training batch 651, loss: 0.347, 20832/28000 datapoints
2025-03-07 12:15:21,588 - INFO - training batch 701, loss: 0.534, 22432/28000 datapoints
2025-03-07 12:15:21,850 - INFO - training batch 751, loss: 0.488, 24032/28000 datapoints
2025-03-07 12:15:22,118 - INFO - training batch 801, loss: 0.393, 25632/28000 datapoints
2025-03-07 12:15:22,388 - INFO - training batch 851, loss: 0.707, 27232/28000 datapoints
2025-03-07 12:15:22,525 - INFO - validation batch 1, loss: 0.403, 32/6976 datapoints
2025-03-07 12:15:22,607 - INFO - validation batch 51, loss: 1.074, 1632/6976 datapoints
2025-03-07 12:15:22,682 - INFO - validation batch 101, loss: 0.440, 3232/6976 datapoints
2025-03-07 12:15:22,766 - INFO - validation batch 151, loss: 0.604, 4832/6976 datapoints
2025-03-07 12:15:22,853 - INFO - validation batch 201, loss: 0.526, 6432/6976 datapoints
2025-03-07 12:15:22,881 - INFO - Epoch 31/800 done.
2025-03-07 12:15:22,882 - INFO - Final validation performance:
Loss: 0.609, top-1 acc: 0.820top-5 acc: 0.820
2025-03-07 12:15:22,882 - INFO - Beginning epoch 32/800
2025-03-07 12:15:22,893 - INFO - training batch 1, loss: 0.531, 32/28000 datapoints
2025-03-07 12:15:23,173 - INFO - training batch 51, loss: 0.524, 1632/28000 datapoints
2025-03-07 12:15:23,471 - INFO - training batch 101, loss: 0.310, 3232/28000 datapoints
2025-03-07 12:15:23,758 - INFO - training batch 151, loss: 0.610, 4832/28000 datapoints
2025-03-07 12:15:24,057 - INFO - training batch 201, loss: 0.635, 6432/28000 datapoints
2025-03-07 12:15:24,394 - INFO - training batch 251, loss: 0.493, 8032/28000 datapoints
2025-03-07 12:15:24,775 - INFO - training batch 301, loss: 0.682, 9632/28000 datapoints
2025-03-07 12:15:25,277 - INFO - training batch 351, loss: 0.537, 11232/28000 datapoints
2025-03-07 12:15:25,699 - INFO - training batch 401, loss: 0.689, 12832/28000 datapoints
2025-03-07 12:15:26,034 - INFO - training batch 451, loss: 0.721, 14432/28000 datapoints
2025-03-07 12:15:26,359 - INFO - training batch 501, loss: 0.362, 16032/28000 datapoints
2025-03-07 12:15:26,789 - INFO - training batch 551, loss: 0.743, 17632/28000 datapoints
2025-03-07 12:15:27,093 - INFO - training batch 601, loss: 0.854, 19232/28000 datapoints
2025-03-07 12:15:27,382 - INFO - training batch 651, loss: 0.336, 20832/28000 datapoints
2025-03-07 12:15:27,684 - INFO - training batch 701, loss: 0.518, 22432/28000 datapoints
2025-03-07 12:15:27,966 - INFO - training batch 751, loss: 0.468, 24032/28000 datapoints
2025-03-07 12:15:28,236 - INFO - training batch 801, loss: 0.388, 25632/28000 datapoints
2025-03-07 12:15:28,507 - INFO - training batch 851, loss: 0.697, 27232/28000 datapoints
2025-03-07 12:15:28,640 - INFO - validation batch 1, loss: 0.387, 32/6976 datapoints
2025-03-07 12:15:28,717 - INFO - validation batch 51, loss: 1.061, 1632/6976 datapoints
2025-03-07 12:15:28,791 - INFO - validation batch 101, loss: 0.417, 3232/6976 datapoints
2025-03-07 12:15:28,865 - INFO - validation batch 151, loss: 0.589, 4832/6976 datapoints
2025-03-07 12:15:28,943 - INFO - validation batch 201, loss: 0.523, 6432/6976 datapoints
2025-03-07 12:15:28,971 - INFO - Epoch 32/800 done.
2025-03-07 12:15:28,971 - INFO - Final validation performance:
Loss: 0.595, top-1 acc: 0.824top-5 acc: 0.824
2025-03-07 12:15:28,972 - INFO - Beginning epoch 33/800
2025-03-07 12:15:28,980 - INFO - training batch 1, loss: 0.513, 32/28000 datapoints
2025-03-07 12:15:29,245 - INFO - training batch 51, loss: 0.496, 1632/28000 datapoints
2025-03-07 12:15:29,507 - INFO - training batch 101, loss: 0.302, 3232/28000 datapoints
2025-03-07 12:15:29,784 - INFO - training batch 151, loss: 0.596, 4832/28000 datapoints
2025-03-07 12:15:30,073 - INFO - training batch 201, loss: 0.620, 6432/28000 datapoints
2025-03-07 12:15:30,341 - INFO - training batch 251, loss: 0.483, 8032/28000 datapoints
2025-03-07 12:15:30,755 - INFO - training batch 301, loss: 0.673, 9632/28000 datapoints
2025-03-07 12:15:31,024 - INFO - training batch 351, loss: 0.519, 11232/28000 datapoints
2025-03-07 12:15:31,312 - INFO - training batch 401, loss: 0.680, 12832/28000 datapoints
2025-03-07 12:15:31,649 - INFO - training batch 451, loss: 0.709, 14432/28000 datapoints
2025-03-07 12:15:31,927 - INFO - training batch 501, loss: 0.347, 16032/28000 datapoints
2025-03-07 12:15:32,209 - INFO - training batch 551, loss: 0.724, 17632/28000 datapoints
2025-03-07 12:15:32,489 - INFO - training batch 601, loss: 0.849, 19232/28000 datapoints
2025-03-07 12:15:32,766 - INFO - training batch 651, loss: 0.325, 20832/28000 datapoints
2025-03-07 12:15:33,034 - INFO - training batch 701, loss: 0.503, 22432/28000 datapoints
2025-03-07 12:15:33,306 - INFO - training batch 751, loss: 0.449, 24032/28000 datapoints
2025-03-07 12:15:33,582 - INFO - training batch 801, loss: 0.383, 25632/28000 datapoints
2025-03-07 12:15:33,855 - INFO - training batch 851, loss: 0.687, 27232/28000 datapoints
2025-03-07 12:15:34,000 - INFO - validation batch 1, loss: 0.372, 32/6976 datapoints
2025-03-07 12:15:34,077 - INFO - validation batch 51, loss: 1.049, 1632/6976 datapoints
2025-03-07 12:15:34,180 - INFO - validation batch 101, loss: 0.395, 3232/6976 datapoints
2025-03-07 12:15:34,268 - INFO - validation batch 151, loss: 0.575, 4832/6976 datapoints
2025-03-07 12:15:34,359 - INFO - validation batch 201, loss: 0.520, 6432/6976 datapoints
2025-03-07 12:15:34,392 - INFO - Epoch 33/800 done.
2025-03-07 12:15:34,393 - INFO - Final validation performance:
Loss: 0.582, top-1 acc: 0.830top-5 acc: 0.830
2025-03-07 12:15:34,393 - INFO - Beginning epoch 34/800
2025-03-07 12:15:34,404 - INFO - training batch 1, loss: 0.496, 32/28000 datapoints
2025-03-07 12:15:34,784 - INFO - training batch 51, loss: 0.472, 1632/28000 datapoints
2025-03-07 12:15:35,112 - INFO - training batch 101, loss: 0.295, 3232/28000 datapoints
2025-03-07 12:15:35,504 - INFO - training batch 151, loss: 0.582, 4832/28000 datapoints
2025-03-07 12:15:35,834 - INFO - training batch 201, loss: 0.605, 6432/28000 datapoints
2025-03-07 12:15:36,162 - INFO - training batch 251, loss: 0.475, 8032/28000 datapoints
2025-03-07 12:15:36,481 - INFO - training batch 301, loss: 0.663, 9632/28000 datapoints
2025-03-07 12:15:36,793 - INFO - training batch 351, loss: 0.503, 11232/28000 datapoints
2025-03-07 12:15:37,109 - INFO - training batch 401, loss: 0.671, 12832/28000 datapoints
2025-03-07 12:15:37,443 - INFO - training batch 451, loss: 0.697, 14432/28000 datapoints
2025-03-07 12:15:37,740 - INFO - training batch 501, loss: 0.333, 16032/28000 datapoints
2025-03-07 12:15:38,026 - INFO - training batch 551, loss: 0.707, 17632/28000 datapoints
2025-03-07 12:15:38,311 - INFO - training batch 601, loss: 0.844, 19232/28000 datapoints
2025-03-07 12:15:38,618 - INFO - training batch 651, loss: 0.316, 20832/28000 datapoints
2025-03-07 12:15:38,885 - INFO - training batch 701, loss: 0.490, 22432/28000 datapoints
2025-03-07 12:15:39,162 - INFO - training batch 751, loss: 0.433, 24032/28000 datapoints
2025-03-07 12:15:39,437 - INFO - training batch 801, loss: 0.378, 25632/28000 datapoints
2025-03-07 12:15:39,727 - INFO - training batch 851, loss: 0.677, 27232/28000 datapoints
2025-03-07 12:15:39,861 - INFO - validation batch 1, loss: 0.357, 32/6976 datapoints
2025-03-07 12:15:39,937 - INFO - validation batch 51, loss: 1.037, 1632/6976 datapoints
2025-03-07 12:15:40,014 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-07 12:15:40,092 - INFO - validation batch 151, loss: 0.564, 4832/6976 datapoints
2025-03-07 12:15:40,178 - INFO - validation batch 201, loss: 0.517, 6432/6976 datapoints
2025-03-07 12:15:40,205 - INFO - Epoch 34/800 done.
2025-03-07 12:15:40,206 - INFO - Final validation performance:
Loss: 0.570, top-1 acc: 0.834top-5 acc: 0.834
2025-03-07 12:15:40,206 - INFO - Beginning epoch 35/800
2025-03-07 12:15:40,215 - INFO - training batch 1, loss: 0.482, 32/28000 datapoints
2025-03-07 12:15:40,502 - INFO - training batch 51, loss: 0.449, 1632/28000 datapoints
2025-03-07 12:15:40,777 - INFO - training batch 101, loss: 0.289, 3232/28000 datapoints
2025-03-07 12:15:41,042 - INFO - training batch 151, loss: 0.570, 4832/28000 datapoints
2025-03-07 12:15:41,315 - INFO - training batch 201, loss: 0.590, 6432/28000 datapoints
2025-03-07 12:15:41,588 - INFO - training batch 251, loss: 0.468, 8032/28000 datapoints
2025-03-07 12:15:41,866 - INFO - training batch 301, loss: 0.655, 9632/28000 datapoints
2025-03-07 12:15:42,128 - INFO - training batch 351, loss: 0.488, 11232/28000 datapoints
2025-03-07 12:15:42,421 - INFO - training batch 401, loss: 0.661, 12832/28000 datapoints
2025-03-07 12:15:42,721 - INFO - training batch 451, loss: 0.685, 14432/28000 datapoints
2025-03-07 12:15:43,008 - INFO - training batch 501, loss: 0.320, 16032/28000 datapoints
2025-03-07 12:15:43,274 - INFO - training batch 551, loss: 0.689, 17632/28000 datapoints
2025-03-07 12:15:43,555 - INFO - training batch 601, loss: 0.839, 19232/28000 datapoints
2025-03-07 12:15:43,825 - INFO - training batch 651, loss: 0.306, 20832/28000 datapoints
2025-03-07 12:15:44,083 - INFO - training batch 701, loss: 0.477, 22432/28000 datapoints
2025-03-07 12:15:44,351 - INFO - training batch 751, loss: 0.418, 24032/28000 datapoints
2025-03-07 12:15:44,654 - INFO - training batch 801, loss: 0.374, 25632/28000 datapoints
2025-03-07 12:15:45,043 - INFO - training batch 851, loss: 0.668, 27232/28000 datapoints
2025-03-07 12:15:45,179 - INFO - validation batch 1, loss: 0.342, 32/6976 datapoints
2025-03-07 12:15:45,327 - INFO - validation batch 51, loss: 1.026, 1632/6976 datapoints
2025-03-07 12:15:45,462 - INFO - validation batch 101, loss: 0.360, 3232/6976 datapoints
2025-03-07 12:15:45,563 - INFO - validation batch 151, loss: 0.554, 4832/6976 datapoints
2025-03-07 12:15:45,674 - INFO - validation batch 201, loss: 0.515, 6432/6976 datapoints
2025-03-07 12:15:45,715 - INFO - Epoch 35/800 done.
2025-03-07 12:15:45,715 - INFO - Final validation performance:
Loss: 0.559, top-1 acc: 0.839top-5 acc: 0.839
2025-03-07 12:15:45,716 - INFO - Beginning epoch 36/800
2025-03-07 12:15:45,724 - INFO - training batch 1, loss: 0.469, 32/28000 datapoints
2025-03-07 12:15:46,059 - INFO - training batch 51, loss: 0.428, 1632/28000 datapoints
2025-03-07 12:15:46,387 - INFO - training batch 101, loss: 0.285, 3232/28000 datapoints
2025-03-07 12:15:46,774 - INFO - training batch 151, loss: 0.557, 4832/28000 datapoints
2025-03-07 12:15:47,209 - INFO - training batch 201, loss: 0.575, 6432/28000 datapoints
2025-03-07 12:15:47,529 - INFO - training batch 251, loss: 0.461, 8032/28000 datapoints
2025-03-07 12:15:47,835 - INFO - training batch 301, loss: 0.645, 9632/28000 datapoints
2025-03-07 12:15:48,175 - INFO - training batch 351, loss: 0.474, 11232/28000 datapoints
2025-03-07 12:15:48,461 - INFO - training batch 401, loss: 0.653, 12832/28000 datapoints
2025-03-07 12:15:48,752 - INFO - training batch 451, loss: 0.673, 14432/28000 datapoints
2025-03-07 12:15:49,033 - INFO - training batch 501, loss: 0.307, 16032/28000 datapoints
2025-03-07 12:15:49,338 - INFO - training batch 551, loss: 0.671, 17632/28000 datapoints
2025-03-07 12:15:49,673 - INFO - training batch 601, loss: 0.833, 19232/28000 datapoints
2025-03-07 12:15:50,042 - INFO - training batch 651, loss: 0.297, 20832/28000 datapoints
2025-03-07 12:15:50,346 - INFO - training batch 701, loss: 0.466, 22432/28000 datapoints
2025-03-07 12:15:50,618 - INFO - training batch 751, loss: 0.403, 24032/28000 datapoints
2025-03-07 12:15:50,927 - INFO - training batch 801, loss: 0.370, 25632/28000 datapoints
2025-03-07 12:15:51,247 - INFO - training batch 851, loss: 0.658, 27232/28000 datapoints
2025-03-07 12:15:51,437 - INFO - validation batch 1, loss: 0.328, 32/6976 datapoints
2025-03-07 12:15:51,516 - INFO - validation batch 51, loss: 1.016, 1632/6976 datapoints
2025-03-07 12:15:51,600 - INFO - validation batch 101, loss: 0.345, 3232/6976 datapoints
2025-03-07 12:15:51,691 - INFO - validation batch 151, loss: 0.544, 4832/6976 datapoints
2025-03-07 12:15:52,102 - INFO - validation batch 201, loss: 0.513, 6432/6976 datapoints
2025-03-07 12:15:52,130 - INFO - Epoch 36/800 done.
2025-03-07 12:15:52,130 - INFO - Final validation performance:
Loss: 0.549, top-1 acc: 0.841top-5 acc: 0.841
2025-03-07 12:15:52,131 - INFO - Beginning epoch 37/800
2025-03-07 12:15:52,139 - INFO - training batch 1, loss: 0.456, 32/28000 datapoints
2025-03-07 12:15:52,416 - INFO - training batch 51, loss: 0.409, 1632/28000 datapoints
2025-03-07 12:15:52,698 - INFO - training batch 101, loss: 0.280, 3232/28000 datapoints
2025-03-07 12:15:52,990 - INFO - training batch 151, loss: 0.546, 4832/28000 datapoints
2025-03-07 12:15:53,270 - INFO - training batch 201, loss: 0.561, 6432/28000 datapoints
2025-03-07 12:15:53,546 - INFO - training batch 251, loss: 0.454, 8032/28000 datapoints
2025-03-07 12:15:53,832 - INFO - training batch 301, loss: 0.637, 9632/28000 datapoints
2025-03-07 12:15:54,108 - INFO - training batch 351, loss: 0.462, 11232/28000 datapoints
2025-03-07 12:15:54,387 - INFO - training batch 401, loss: 0.643, 12832/28000 datapoints
2025-03-07 12:15:54,654 - INFO - training batch 451, loss: 0.662, 14432/28000 datapoints
2025-03-07 12:15:54,976 - INFO - training batch 501, loss: 0.296, 16032/28000 datapoints
2025-03-07 12:15:55,251 - INFO - training batch 551, loss: 0.654, 17632/28000 datapoints
2025-03-07 12:15:55,572 - INFO - training batch 601, loss: 0.827, 19232/28000 datapoints
2025-03-07 12:15:55,870 - INFO - training batch 651, loss: 0.288, 20832/28000 datapoints
2025-03-07 12:15:56,171 - INFO - training batch 701, loss: 0.455, 22432/28000 datapoints
2025-03-07 12:15:56,500 - INFO - training batch 751, loss: 0.389, 24032/28000 datapoints
2025-03-07 12:15:56,811 - INFO - training batch 801, loss: 0.367, 25632/28000 datapoints
2025-03-07 12:15:57,130 - INFO - training batch 851, loss: 0.648, 27232/28000 datapoints
2025-03-07 12:15:57,290 - INFO - validation batch 1, loss: 0.315, 32/6976 datapoints
2025-03-07 12:15:57,385 - INFO - validation batch 51, loss: 1.006, 1632/6976 datapoints
2025-03-07 12:15:57,485 - INFO - validation batch 101, loss: 0.331, 3232/6976 datapoints
2025-03-07 12:15:57,582 - INFO - validation batch 151, loss: 0.536, 4832/6976 datapoints
2025-03-07 12:15:57,678 - INFO - validation batch 201, loss: 0.512, 6432/6976 datapoints
2025-03-07 12:15:57,710 - INFO - Epoch 37/800 done.
2025-03-07 12:15:57,710 - INFO - Final validation performance:
Loss: 0.540, top-1 acc: 0.845top-5 acc: 0.845
2025-03-07 12:15:57,711 - INFO - Beginning epoch 38/800
2025-03-07 12:15:57,719 - INFO - training batch 1, loss: 0.444, 32/28000 datapoints
2025-03-07 12:15:58,076 - INFO - training batch 51, loss: 0.392, 1632/28000 datapoints
2025-03-07 12:15:58,386 - INFO - training batch 101, loss: 0.276, 3232/28000 datapoints
2025-03-07 12:15:58,764 - INFO - training batch 151, loss: 0.535, 4832/28000 datapoints
2025-03-07 12:15:59,045 - INFO - training batch 201, loss: 0.548, 6432/28000 datapoints
2025-03-07 12:15:59,328 - INFO - training batch 251, loss: 0.447, 8032/28000 datapoints
2025-03-07 12:15:59,606 - INFO - training batch 301, loss: 0.628, 9632/28000 datapoints
2025-03-07 12:15:59,879 - INFO - training batch 351, loss: 0.451, 11232/28000 datapoints
2025-03-07 12:16:00,194 - INFO - training batch 401, loss: 0.635, 12832/28000 datapoints
2025-03-07 12:16:00,485 - INFO - training batch 451, loss: 0.651, 14432/28000 datapoints
2025-03-07 12:16:00,767 - INFO - training batch 501, loss: 0.285, 16032/28000 datapoints
2025-03-07 12:16:01,029 - INFO - training batch 551, loss: 0.638, 17632/28000 datapoints
2025-03-07 12:16:01,302 - INFO - training batch 601, loss: 0.819, 19232/28000 datapoints
2025-03-07 12:16:01,634 - INFO - training batch 651, loss: 0.280, 20832/28000 datapoints
2025-03-07 12:16:02,002 - INFO - training batch 701, loss: 0.446, 22432/28000 datapoints
2025-03-07 12:16:02,358 - INFO - training batch 751, loss: 0.376, 24032/28000 datapoints
2025-03-07 12:16:02,652 - INFO - training batch 801, loss: 0.363, 25632/28000 datapoints
2025-03-07 12:16:02,931 - INFO - training batch 851, loss: 0.638, 27232/28000 datapoints
2025-03-07 12:16:03,060 - INFO - validation batch 1, loss: 0.302, 32/6976 datapoints
2025-03-07 12:16:03,137 - INFO - validation batch 51, loss: 0.996, 1632/6976 datapoints
2025-03-07 12:16:03,216 - INFO - validation batch 101, loss: 0.319, 3232/6976 datapoints
2025-03-07 12:16:03,291 - INFO - validation batch 151, loss: 0.528, 4832/6976 datapoints
2025-03-07 12:16:03,364 - INFO - validation batch 201, loss: 0.510, 6432/6976 datapoints
2025-03-07 12:16:03,388 - INFO - Epoch 38/800 done.
2025-03-07 12:16:03,389 - INFO - Final validation performance:
Loss: 0.531, top-1 acc: 0.849top-5 acc: 0.849
2025-03-07 12:16:03,389 - INFO - Beginning epoch 39/800
2025-03-07 12:16:03,398 - INFO - training batch 1, loss: 0.433, 32/28000 datapoints
2025-03-07 12:16:03,742 - INFO - training batch 51, loss: 0.375, 1632/28000 datapoints
2025-03-07 12:16:04,006 - INFO - training batch 101, loss: 0.273, 3232/28000 datapoints
2025-03-07 12:16:04,295 - INFO - training batch 151, loss: 0.524, 4832/28000 datapoints
2025-03-07 12:16:04,567 - INFO - training batch 201, loss: 0.534, 6432/28000 datapoints
2025-03-07 12:16:04,856 - INFO - training batch 251, loss: 0.441, 8032/28000 datapoints
2025-03-07 12:16:05,175 - INFO - training batch 301, loss: 0.620, 9632/28000 datapoints
2025-03-07 12:16:05,562 - INFO - training batch 351, loss: 0.440, 11232/28000 datapoints
2025-03-07 12:16:05,988 - INFO - training batch 401, loss: 0.626, 12832/28000 datapoints
2025-03-07 12:16:06,363 - INFO - training batch 451, loss: 0.640, 14432/28000 datapoints
2025-03-07 12:16:06,692 - INFO - training batch 501, loss: 0.276, 16032/28000 datapoints
2025-03-07 12:16:07,020 - INFO - training batch 551, loss: 0.623, 17632/28000 datapoints
2025-03-07 12:16:07,335 - INFO - training batch 601, loss: 0.810, 19232/28000 datapoints
2025-03-07 12:16:07,672 - INFO - training batch 651, loss: 0.272, 20832/28000 datapoints
2025-03-07 12:16:07,979 - INFO - training batch 701, loss: 0.438, 22432/28000 datapoints
2025-03-07 12:16:08,271 - INFO - training batch 751, loss: 0.364, 24032/28000 datapoints
2025-03-07 12:16:08,581 - INFO - training batch 801, loss: 0.361, 25632/28000 datapoints
2025-03-07 12:16:08,903 - INFO - training batch 851, loss: 0.628, 27232/28000 datapoints
2025-03-07 12:16:09,070 - INFO - validation batch 1, loss: 0.289, 32/6976 datapoints
2025-03-07 12:16:09,164 - INFO - validation batch 51, loss: 0.987, 1632/6976 datapoints
2025-03-07 12:16:09,251 - INFO - validation batch 101, loss: 0.307, 3232/6976 datapoints
2025-03-07 12:16:09,329 - INFO - validation batch 151, loss: 0.519, 4832/6976 datapoints
2025-03-07 12:16:09,406 - INFO - validation batch 201, loss: 0.508, 6432/6976 datapoints
2025-03-07 12:16:09,436 - INFO - Epoch 39/800 done.
2025-03-07 12:16:09,436 - INFO - Final validation performance:
Loss: 0.522, top-1 acc: 0.851top-5 acc: 0.851
2025-03-07 12:16:09,437 - INFO - Beginning epoch 40/800
2025-03-07 12:16:09,444 - INFO - training batch 1, loss: 0.422, 32/28000 datapoints
2025-03-07 12:16:09,753 - INFO - training batch 51, loss: 0.360, 1632/28000 datapoints
2025-03-07 12:16:10,034 - INFO - training batch 101, loss: 0.270, 3232/28000 datapoints
2025-03-07 12:16:10,306 - INFO - training batch 151, loss: 0.514, 4832/28000 datapoints
2025-03-07 12:16:10,592 - INFO - training batch 201, loss: 0.522, 6432/28000 datapoints
2025-03-07 12:16:10,859 - INFO - training batch 251, loss: 0.435, 8032/28000 datapoints
2025-03-07 12:16:11,128 - INFO - training batch 301, loss: 0.612, 9632/28000 datapoints
2025-03-07 12:16:11,390 - INFO - training batch 351, loss: 0.430, 11232/28000 datapoints
2025-03-07 12:16:11,670 - INFO - training batch 401, loss: 0.617, 12832/28000 datapoints
2025-03-07 12:16:11,955 - INFO - training batch 451, loss: 0.630, 14432/28000 datapoints
2025-03-07 12:16:12,286 - INFO - training batch 501, loss: 0.266, 16032/28000 datapoints
2025-03-07 12:16:12,553 - INFO - training batch 551, loss: 0.608, 17632/28000 datapoints
2025-03-07 12:16:12,824 - INFO - training batch 601, loss: 0.799, 19232/28000 datapoints
2025-03-07 12:16:13,133 - INFO - training batch 651, loss: 0.264, 20832/28000 datapoints
2025-03-07 12:16:13,410 - INFO - training batch 701, loss: 0.431, 22432/28000 datapoints
2025-03-07 12:16:13,694 - INFO - training batch 751, loss: 0.351, 24032/28000 datapoints
2025-03-07 12:16:13,980 - INFO - training batch 801, loss: 0.358, 25632/28000 datapoints
2025-03-07 12:16:14,341 - INFO - training batch 851, loss: 0.619, 27232/28000 datapoints
2025-03-07 12:16:14,507 - INFO - validation batch 1, loss: 0.276, 32/6976 datapoints
2025-03-07 12:16:14,607 - INFO - validation batch 51, loss: 0.977, 1632/6976 datapoints
2025-03-07 12:16:14,720 - INFO - validation batch 101, loss: 0.297, 3232/6976 datapoints
2025-03-07 12:16:14,815 - INFO - validation batch 151, loss: 0.512, 4832/6976 datapoints
2025-03-07 12:16:14,914 - INFO - validation batch 201, loss: 0.506, 6432/6976 datapoints
2025-03-07 12:16:14,937 - INFO - Epoch 40/800 done.
2025-03-07 12:16:14,938 - INFO - Final validation performance:
Loss: 0.514, top-1 acc: 0.855top-5 acc: 0.855
2025-03-07 12:16:14,938 - INFO - Beginning epoch 41/800
2025-03-07 12:16:14,946 - INFO - training batch 1, loss: 0.412, 32/28000 datapoints
2025-03-07 12:16:15,314 - INFO - training batch 51, loss: 0.346, 1632/28000 datapoints
2025-03-07 12:16:15,616 - INFO - training batch 101, loss: 0.267, 3232/28000 datapoints
2025-03-07 12:16:15,951 - INFO - training batch 151, loss: 0.504, 4832/28000 datapoints
2025-03-07 12:16:16,282 - INFO - training batch 201, loss: 0.510, 6432/28000 datapoints
2025-03-07 12:16:16,675 - INFO - training batch 251, loss: 0.429, 8032/28000 datapoints
2025-03-07 12:16:17,085 - INFO - training batch 301, loss: 0.602, 9632/28000 datapoints
2025-03-07 12:16:17,539 - INFO - training batch 351, loss: 0.421, 11232/28000 datapoints
2025-03-07 12:16:17,898 - INFO - training batch 401, loss: 0.608, 12832/28000 datapoints
2025-03-07 12:16:18,251 - INFO - training batch 451, loss: 0.619, 14432/28000 datapoints
2025-03-07 12:16:18,571 - INFO - training batch 501, loss: 0.258, 16032/28000 datapoints
2025-03-07 12:16:18,909 - INFO - training batch 551, loss: 0.593, 17632/28000 datapoints
2025-03-07 12:16:19,257 - INFO - training batch 601, loss: 0.785, 19232/28000 datapoints
2025-03-07 12:16:19,614 - INFO - training batch 651, loss: 0.256, 20832/28000 datapoints
2025-03-07 12:16:19,986 - INFO - training batch 701, loss: 0.424, 22432/28000 datapoints
2025-03-07 12:16:20,321 - INFO - training batch 751, loss: 0.340, 24032/28000 datapoints
2025-03-07 12:16:20,646 - INFO - training batch 801, loss: 0.355, 25632/28000 datapoints
2025-03-07 12:16:20,966 - INFO - training batch 851, loss: 0.611, 27232/28000 datapoints
2025-03-07 12:16:21,128 - INFO - validation batch 1, loss: 0.265, 32/6976 datapoints
2025-03-07 12:16:21,228 - INFO - validation batch 51, loss: 0.968, 1632/6976 datapoints
2025-03-07 12:16:21,466 - INFO - validation batch 101, loss: 0.288, 3232/6976 datapoints
2025-03-07 12:16:21,622 - INFO - validation batch 151, loss: 0.503, 4832/6976 datapoints
2025-03-07 12:16:21,743 - INFO - validation batch 201, loss: 0.504, 6432/6976 datapoints
2025-03-07 12:16:21,800 - INFO - Epoch 41/800 done.
2025-03-07 12:16:21,801 - INFO - Final validation performance:
Loss: 0.506, top-1 acc: 0.858top-5 acc: 0.858
2025-03-07 12:16:21,805 - INFO - Beginning epoch 42/800
2025-03-07 12:16:21,830 - INFO - training batch 1, loss: 0.402, 32/28000 datapoints
2025-03-07 12:16:22,243 - INFO - training batch 51, loss: 0.334, 1632/28000 datapoints
2025-03-07 12:16:22,570 - INFO - training batch 101, loss: 0.265, 3232/28000 datapoints
2025-03-07 12:16:22,895 - INFO - training batch 151, loss: 0.495, 4832/28000 datapoints
2025-03-07 12:16:23,214 - INFO - training batch 201, loss: 0.498, 6432/28000 datapoints
2025-03-07 12:16:23,639 - INFO - training batch 251, loss: 0.424, 8032/28000 datapoints
2025-03-07 12:16:23,950 - INFO - training batch 301, loss: 0.593, 9632/28000 datapoints
2025-03-07 12:16:24,417 - INFO - training batch 351, loss: 0.412, 11232/28000 datapoints
2025-03-07 12:16:24,743 - INFO - training batch 401, loss: 0.600, 12832/28000 datapoints
2025-03-07 12:16:25,078 - INFO - training batch 451, loss: 0.609, 14432/28000 datapoints
2025-03-07 12:16:25,459 - INFO - training batch 501, loss: 0.250, 16032/28000 datapoints
2025-03-07 12:16:26,060 - INFO - training batch 551, loss: 0.578, 17632/28000 datapoints
2025-03-07 12:16:26,562 - INFO - training batch 601, loss: 0.771, 19232/28000 datapoints
2025-03-07 12:16:26,995 - INFO - training batch 651, loss: 0.249, 20832/28000 datapoints
2025-03-07 12:16:27,474 - INFO - training batch 701, loss: 0.418, 22432/28000 datapoints
2025-03-07 12:16:27,889 - INFO - training batch 751, loss: 0.329, 24032/28000 datapoints
2025-03-07 12:16:28,279 - INFO - training batch 801, loss: 0.353, 25632/28000 datapoints
2025-03-07 12:16:28,661 - INFO - training batch 851, loss: 0.604, 27232/28000 datapoints
2025-03-07 12:16:28,847 - INFO - validation batch 1, loss: 0.254, 32/6976 datapoints
2025-03-07 12:16:28,971 - INFO - validation batch 51, loss: 0.959, 1632/6976 datapoints
2025-03-07 12:16:29,083 - INFO - validation batch 101, loss: 0.280, 3232/6976 datapoints
2025-03-07 12:16:29,194 - INFO - validation batch 151, loss: 0.494, 4832/6976 datapoints
2025-03-07 12:16:29,303 - INFO - validation batch 201, loss: 0.502, 6432/6976 datapoints
2025-03-07 12:16:29,346 - INFO - Epoch 42/800 done.
2025-03-07 12:16:29,346 - INFO - Final validation performance:
Loss: 0.498, top-1 acc: 0.860top-5 acc: 0.860
2025-03-07 12:16:29,347 - INFO - Beginning epoch 43/800
2025-03-07 12:16:29,358 - INFO - training batch 1, loss: 0.392, 32/28000 datapoints
2025-03-07 12:16:29,712 - INFO - training batch 51, loss: 0.322, 1632/28000 datapoints
2025-03-07 12:16:30,077 - INFO - training batch 101, loss: 0.262, 3232/28000 datapoints
2025-03-07 12:16:30,618 - INFO - training batch 151, loss: 0.487, 4832/28000 datapoints
2025-03-07 12:16:31,005 - INFO - training batch 201, loss: 0.488, 6432/28000 datapoints
2025-03-07 12:16:31,381 - INFO - training batch 251, loss: 0.419, 8032/28000 datapoints
2025-03-07 12:16:31,729 - INFO - training batch 301, loss: 0.584, 9632/28000 datapoints
2025-03-07 12:16:32,106 - INFO - training batch 351, loss: 0.404, 11232/28000 datapoints
2025-03-07 12:16:32,482 - INFO - training batch 401, loss: 0.591, 12832/28000 datapoints
2025-03-07 12:16:32,853 - INFO - training batch 451, loss: 0.600, 14432/28000 datapoints
2025-03-07 12:16:33,201 - INFO - training batch 501, loss: 0.243, 16032/28000 datapoints
2025-03-07 12:16:33,674 - INFO - training batch 551, loss: 0.564, 17632/28000 datapoints
2025-03-07 12:16:34,006 - INFO - training batch 601, loss: 0.757, 19232/28000 datapoints
2025-03-07 12:16:34,339 - INFO - training batch 651, loss: 0.241, 20832/28000 datapoints
2025-03-07 12:16:34,748 - INFO - training batch 701, loss: 0.414, 22432/28000 datapoints
2025-03-07 12:16:35,364 - INFO - training batch 751, loss: 0.319, 24032/28000 datapoints
2025-03-07 12:16:35,964 - INFO - training batch 801, loss: 0.350, 25632/28000 datapoints
2025-03-07 12:16:36,522 - INFO - training batch 851, loss: 0.596, 27232/28000 datapoints
2025-03-07 12:16:36,874 - INFO - validation batch 1, loss: 0.243, 32/6976 datapoints
2025-03-07 12:16:37,018 - INFO - validation batch 51, loss: 0.951, 1632/6976 datapoints
2025-03-07 12:16:37,150 - INFO - validation batch 101, loss: 0.273, 3232/6976 datapoints
2025-03-07 12:16:37,281 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-07 12:16:37,427 - INFO - validation batch 201, loss: 0.500, 6432/6976 datapoints
2025-03-07 12:16:37,488 - INFO - Epoch 43/800 done.
2025-03-07 12:16:37,489 - INFO - Final validation performance:
Loss: 0.491, top-1 acc: 0.862top-5 acc: 0.862
2025-03-07 12:16:37,494 - INFO - Beginning epoch 44/800
2025-03-07 12:16:37,514 - INFO - training batch 1, loss: 0.383, 32/28000 datapoints
2025-03-07 12:16:37,963 - INFO - training batch 51, loss: 0.311, 1632/28000 datapoints
2025-03-07 12:16:38,373 - INFO - training batch 101, loss: 0.259, 3232/28000 datapoints
2025-03-07 12:16:38,833 - INFO - training batch 151, loss: 0.478, 4832/28000 datapoints
2025-03-07 12:16:39,414 - INFO - training batch 201, loss: 0.477, 6432/28000 datapoints
2025-03-07 12:16:40,069 - INFO - training batch 251, loss: 0.414, 8032/28000 datapoints
2025-03-07 12:16:40,694 - INFO - training batch 301, loss: 0.575, 9632/28000 datapoints
2025-03-07 12:16:41,374 - INFO - training batch 351, loss: 0.397, 11232/28000 datapoints
2025-03-07 12:16:41,857 - INFO - training batch 401, loss: 0.583, 12832/28000 datapoints
2025-03-07 12:16:42,240 - INFO - training batch 451, loss: 0.591, 14432/28000 datapoints
2025-03-07 12:16:42,577 - INFO - training batch 501, loss: 0.237, 16032/28000 datapoints
2025-03-07 12:16:42,899 - INFO - training batch 551, loss: 0.551, 17632/28000 datapoints
2025-03-07 12:16:43,213 - INFO - training batch 601, loss: 0.742, 19232/28000 datapoints
2025-03-07 12:16:43,529 - INFO - training batch 651, loss: 0.234, 20832/28000 datapoints
2025-03-07 12:16:43,885 - INFO - training batch 701, loss: 0.410, 22432/28000 datapoints
2025-03-07 12:16:44,208 - INFO - training batch 751, loss: 0.309, 24032/28000 datapoints
2025-03-07 12:16:44,575 - INFO - training batch 801, loss: 0.346, 25632/28000 datapoints
2025-03-07 12:16:44,924 - INFO - training batch 851, loss: 0.587, 27232/28000 datapoints
2025-03-07 12:16:45,104 - INFO - validation batch 1, loss: 0.232, 32/6976 datapoints
2025-03-07 12:16:45,226 - INFO - validation batch 51, loss: 0.942, 1632/6976 datapoints
2025-03-07 12:16:45,330 - INFO - validation batch 101, loss: 0.265, 3232/6976 datapoints
2025-03-07 12:16:45,429 - INFO - validation batch 151, loss: 0.479, 4832/6976 datapoints
2025-03-07 12:16:45,587 - INFO - validation batch 201, loss: 0.498, 6432/6976 datapoints
2025-03-07 12:16:45,630 - INFO - Epoch 44/800 done.
2025-03-07 12:16:45,630 - INFO - Final validation performance:
Loss: 0.483, top-1 acc: 0.866top-5 acc: 0.866
2025-03-07 12:16:45,632 - INFO - Beginning epoch 45/800
2025-03-07 12:16:45,643 - INFO - training batch 1, loss: 0.374, 32/28000 datapoints
2025-03-07 12:16:46,284 - INFO - training batch 51, loss: 0.301, 1632/28000 datapoints
2025-03-07 12:16:46,791 - INFO - training batch 101, loss: 0.256, 3232/28000 datapoints
2025-03-07 12:16:47,227 - INFO - training batch 151, loss: 0.470, 4832/28000 datapoints
2025-03-07 12:16:47,597 - INFO - training batch 201, loss: 0.468, 6432/28000 datapoints
2025-03-07 12:16:47,978 - INFO - training batch 251, loss: 0.409, 8032/28000 datapoints
2025-03-07 12:16:48,319 - INFO - training batch 301, loss: 0.567, 9632/28000 datapoints
2025-03-07 12:16:48,651 - INFO - training batch 351, loss: 0.390, 11232/28000 datapoints
2025-03-07 12:16:48,976 - INFO - training batch 401, loss: 0.575, 12832/28000 datapoints
2025-03-07 12:16:49,351 - INFO - training batch 451, loss: 0.582, 14432/28000 datapoints
2025-03-07 12:16:49,649 - INFO - training batch 501, loss: 0.230, 16032/28000 datapoints
2025-03-07 12:16:49,931 - INFO - training batch 551, loss: 0.537, 17632/28000 datapoints
2025-03-07 12:16:50,203 - INFO - training batch 601, loss: 0.727, 19232/28000 datapoints
2025-03-07 12:16:50,480 - INFO - training batch 651, loss: 0.227, 20832/28000 datapoints
2025-03-07 12:16:50,744 - INFO - training batch 701, loss: 0.407, 22432/28000 datapoints
2025-03-07 12:16:51,015 - INFO - training batch 751, loss: 0.300, 24032/28000 datapoints
2025-03-07 12:16:51,291 - INFO - training batch 801, loss: 0.343, 25632/28000 datapoints
2025-03-07 12:16:51,627 - INFO - training batch 851, loss: 0.578, 27232/28000 datapoints
2025-03-07 12:16:51,816 - INFO - validation batch 1, loss: 0.223, 32/6976 datapoints
2025-03-07 12:16:51,917 - INFO - validation batch 51, loss: 0.934, 1632/6976 datapoints
2025-03-07 12:16:52,018 - INFO - validation batch 101, loss: 0.259, 3232/6976 datapoints
2025-03-07 12:16:52,107 - INFO - validation batch 151, loss: 0.472, 4832/6976 datapoints
2025-03-07 12:16:52,201 - INFO - validation batch 201, loss: 0.495, 6432/6976 datapoints
2025-03-07 12:16:52,233 - INFO - Epoch 45/800 done.
2025-03-07 12:16:52,233 - INFO - Final validation performance:
Loss: 0.477, top-1 acc: 0.868top-5 acc: 0.868
2025-03-07 12:16:52,233 - INFO - Beginning epoch 46/800
2025-03-07 12:16:52,242 - INFO - training batch 1, loss: 0.366, 32/28000 datapoints
2025-03-07 12:16:52,524 - INFO - training batch 51, loss: 0.290, 1632/28000 datapoints
2025-03-07 12:16:52,799 - INFO - training batch 101, loss: 0.252, 3232/28000 datapoints
2025-03-07 12:16:53,099 - INFO - training batch 151, loss: 0.461, 4832/28000 datapoints
2025-03-07 12:16:53,399 - INFO - training batch 201, loss: 0.459, 6432/28000 datapoints
2025-03-07 12:16:53,678 - INFO - training batch 251, loss: 0.404, 8032/28000 datapoints
2025-03-07 12:16:53,948 - INFO - training batch 301, loss: 0.558, 9632/28000 datapoints
2025-03-07 12:16:54,225 - INFO - training batch 351, loss: 0.383, 11232/28000 datapoints
2025-03-07 12:16:54,506 - INFO - training batch 401, loss: 0.566, 12832/28000 datapoints
2025-03-07 12:16:54,781 - INFO - training batch 451, loss: 0.573, 14432/28000 datapoints
2025-03-07 12:16:55,052 - INFO - training batch 501, loss: 0.225, 16032/28000 datapoints
2025-03-07 12:16:55,318 - INFO - training batch 551, loss: 0.523, 17632/28000 datapoints
2025-03-07 12:16:55,592 - INFO - training batch 601, loss: 0.712, 19232/28000 datapoints
2025-03-07 12:16:55,869 - INFO - training batch 651, loss: 0.220, 20832/28000 datapoints
2025-03-07 12:16:56,188 - INFO - training batch 701, loss: 0.403, 22432/28000 datapoints
2025-03-07 12:16:56,545 - INFO - training batch 751, loss: 0.291, 24032/28000 datapoints
2025-03-07 12:16:56,839 - INFO - training batch 801, loss: 0.340, 25632/28000 datapoints
2025-03-07 12:16:57,137 - INFO - training batch 851, loss: 0.571, 27232/28000 datapoints
2025-03-07 12:16:57,307 - INFO - validation batch 1, loss: 0.213, 32/6976 datapoints
2025-03-07 12:16:57,411 - INFO - validation batch 51, loss: 0.927, 1632/6976 datapoints
2025-03-07 12:16:57,538 - INFO - validation batch 101, loss: 0.254, 3232/6976 datapoints
2025-03-07 12:16:57,627 - INFO - validation batch 151, loss: 0.465, 4832/6976 datapoints
2025-03-07 12:16:57,708 - INFO - validation batch 201, loss: 0.492, 6432/6976 datapoints
2025-03-07 12:16:57,737 - INFO - Epoch 46/800 done.
2025-03-07 12:16:57,737 - INFO - Final validation performance:
Loss: 0.470, top-1 acc: 0.870top-5 acc: 0.870
2025-03-07 12:16:57,738 - INFO - Beginning epoch 47/800
2025-03-07 12:16:57,748 - INFO - training batch 1, loss: 0.358, 32/28000 datapoints
2025-03-07 12:16:58,089 - INFO - training batch 51, loss: 0.281, 1632/28000 datapoints
2025-03-07 12:16:58,366 - INFO - training batch 101, loss: 0.249, 3232/28000 datapoints
2025-03-07 12:16:58,651 - INFO - training batch 151, loss: 0.452, 4832/28000 datapoints
2025-03-07 12:16:58,931 - INFO - training batch 201, loss: 0.450, 6432/28000 datapoints
2025-03-07 12:16:59,207 - INFO - training batch 251, loss: 0.399, 8032/28000 datapoints
2025-03-07 12:16:59,489 - INFO - training batch 301, loss: 0.552, 9632/28000 datapoints
2025-03-07 12:16:59,783 - INFO - training batch 351, loss: 0.377, 11232/28000 datapoints
2025-03-07 12:17:00,075 - INFO - training batch 401, loss: 0.559, 12832/28000 datapoints
2025-03-07 12:17:00,356 - INFO - training batch 451, loss: 0.565, 14432/28000 datapoints
2025-03-07 12:17:00,652 - INFO - training batch 501, loss: 0.219, 16032/28000 datapoints
2025-03-07 12:17:00,924 - INFO - training batch 551, loss: 0.509, 17632/28000 datapoints
2025-03-07 12:17:01,199 - INFO - training batch 601, loss: 0.696, 19232/28000 datapoints
2025-03-07 12:17:01,480 - INFO - training batch 651, loss: 0.213, 20832/28000 datapoints
2025-03-07 12:17:01,789 - INFO - training batch 701, loss: 0.401, 22432/28000 datapoints
2025-03-07 12:17:02,084 - INFO - training batch 751, loss: 0.283, 24032/28000 datapoints
2025-03-07 12:17:02,354 - INFO - training batch 801, loss: 0.336, 25632/28000 datapoints
2025-03-07 12:17:02,633 - INFO - training batch 851, loss: 0.563, 27232/28000 datapoints
2025-03-07 12:17:02,772 - INFO - validation batch 1, loss: 0.205, 32/6976 datapoints
2025-03-07 12:17:02,850 - INFO - validation batch 51, loss: 0.920, 1632/6976 datapoints
2025-03-07 12:17:02,927 - INFO - validation batch 101, loss: 0.249, 3232/6976 datapoints
2025-03-07 12:17:03,005 - INFO - validation batch 151, loss: 0.460, 4832/6976 datapoints
2025-03-07 12:17:03,081 - INFO - validation batch 201, loss: 0.489, 6432/6976 datapoints
2025-03-07 12:17:03,107 - INFO - Epoch 47/800 done.
2025-03-07 12:17:03,108 - INFO - Final validation performance:
Loss: 0.464, top-1 acc: 0.872top-5 acc: 0.872
2025-03-07 12:17:03,108 - INFO - Beginning epoch 48/800
2025-03-07 12:17:03,118 - INFO - training batch 1, loss: 0.351, 32/28000 datapoints
2025-03-07 12:17:03,378 - INFO - training batch 51, loss: 0.272, 1632/28000 datapoints
2025-03-07 12:17:03,652 - INFO - training batch 101, loss: 0.245, 3232/28000 datapoints
2025-03-07 12:17:03,917 - INFO - training batch 151, loss: 0.444, 4832/28000 datapoints
2025-03-07 12:17:04,182 - INFO - training batch 201, loss: 0.441, 6432/28000 datapoints
2025-03-07 12:17:04,451 - INFO - training batch 251, loss: 0.394, 8032/28000 datapoints
2025-03-07 12:17:04,733 - INFO - training batch 301, loss: 0.545, 9632/28000 datapoints
2025-03-07 12:17:05,004 - INFO - training batch 351, loss: 0.370, 11232/28000 datapoints
2025-03-07 12:17:05,270 - INFO - training batch 401, loss: 0.553, 12832/28000 datapoints
2025-03-07 12:17:05,547 - INFO - training batch 451, loss: 0.557, 14432/28000 datapoints
2025-03-07 12:17:05,812 - INFO - training batch 501, loss: 0.214, 16032/28000 datapoints
2025-03-07 12:17:06,117 - INFO - training batch 551, loss: 0.495, 17632/28000 datapoints
2025-03-07 12:17:06,659 - INFO - training batch 601, loss: 0.679, 19232/28000 datapoints
2025-03-07 12:17:07,001 - INFO - training batch 651, loss: 0.207, 20832/28000 datapoints
2025-03-07 12:17:07,265 - INFO - training batch 701, loss: 0.398, 22432/28000 datapoints
2025-03-07 12:17:07,539 - INFO - training batch 751, loss: 0.275, 24032/28000 datapoints
2025-03-07 12:17:07,807 - INFO - training batch 801, loss: 0.333, 25632/28000 datapoints
2025-03-07 12:17:08,076 - INFO - training batch 851, loss: 0.555, 27232/28000 datapoints
2025-03-07 12:17:08,204 - INFO - validation batch 1, loss: 0.196, 32/6976 datapoints
2025-03-07 12:17:08,275 - INFO - validation batch 51, loss: 0.912, 1632/6976 datapoints
2025-03-07 12:17:08,351 - INFO - validation batch 101, loss: 0.244, 3232/6976 datapoints
2025-03-07 12:17:08,421 - INFO - validation batch 151, loss: 0.454, 4832/6976 datapoints
2025-03-07 12:17:08,601 - INFO - validation batch 201, loss: 0.485, 6432/6976 datapoints
2025-03-07 12:17:08,677 - INFO - Epoch 48/800 done.
2025-03-07 12:17:08,678 - INFO - Final validation performance:
Loss: 0.458, top-1 acc: 0.874top-5 acc: 0.874
2025-03-07 12:17:08,679 - INFO - Beginning epoch 49/800
2025-03-07 12:17:08,689 - INFO - training batch 1, loss: 0.344, 32/28000 datapoints
2025-03-07 12:17:08,969 - INFO - training batch 51, loss: 0.263, 1632/28000 datapoints
2025-03-07 12:17:09,242 - INFO - training batch 101, loss: 0.242, 3232/28000 datapoints
2025-03-07 12:17:09,525 - INFO - training batch 151, loss: 0.435, 4832/28000 datapoints
2025-03-07 12:17:09,792 - INFO - training batch 201, loss: 0.433, 6432/28000 datapoints
2025-03-07 12:17:10,093 - INFO - training batch 251, loss: 0.389, 8032/28000 datapoints
2025-03-07 12:17:10,455 - INFO - training batch 301, loss: 0.538, 9632/28000 datapoints
2025-03-07 12:17:10,732 - INFO - training batch 351, loss: 0.363, 11232/28000 datapoints
2025-03-07 12:17:11,047 - INFO - training batch 401, loss: 0.546, 12832/28000 datapoints
2025-03-07 12:17:11,318 - INFO - training batch 451, loss: 0.548, 14432/28000 datapoints
2025-03-07 12:17:11,589 - INFO - training batch 501, loss: 0.209, 16032/28000 datapoints
2025-03-07 12:17:11,860 - INFO - training batch 551, loss: 0.481, 17632/28000 datapoints
2025-03-07 12:17:12,130 - INFO - training batch 601, loss: 0.662, 19232/28000 datapoints
2025-03-07 12:17:12,406 - INFO - training batch 651, loss: 0.201, 20832/28000 datapoints
2025-03-07 12:17:12,681 - INFO - training batch 701, loss: 0.396, 22432/28000 datapoints
2025-03-07 12:17:12,961 - INFO - training batch 751, loss: 0.267, 24032/28000 datapoints
2025-03-07 12:17:13,236 - INFO - training batch 801, loss: 0.330, 25632/28000 datapoints
2025-03-07 12:17:13,510 - INFO - training batch 851, loss: 0.547, 27232/28000 datapoints
2025-03-07 12:17:13,641 - INFO - validation batch 1, loss: 0.189, 32/6976 datapoints
2025-03-07 12:17:13,717 - INFO - validation batch 51, loss: 0.904, 1632/6976 datapoints
2025-03-07 12:17:13,794 - INFO - validation batch 101, loss: 0.240, 3232/6976 datapoints
2025-03-07 12:17:13,867 - INFO - validation batch 151, loss: 0.447, 4832/6976 datapoints
2025-03-07 12:17:13,941 - INFO - validation batch 201, loss: 0.482, 6432/6976 datapoints
2025-03-07 12:17:13,968 - INFO - Epoch 49/800 done.
2025-03-07 12:17:13,969 - INFO - Final validation performance:
Loss: 0.452, top-1 acc: 0.875top-5 acc: 0.875
2025-03-07 12:17:13,969 - INFO - Beginning epoch 50/800
2025-03-07 12:17:13,978 - INFO - training batch 1, loss: 0.338, 32/28000 datapoints
2025-03-07 12:17:14,244 - INFO - training batch 51, loss: 0.255, 1632/28000 datapoints
2025-03-07 12:17:14,516 - INFO - training batch 101, loss: 0.239, 3232/28000 datapoints
2025-03-07 12:17:14,788 - INFO - training batch 151, loss: 0.428, 4832/28000 datapoints
2025-03-07 12:17:15,054 - INFO - training batch 201, loss: 0.424, 6432/28000 datapoints
2025-03-07 12:17:15,319 - INFO - training batch 251, loss: 0.384, 8032/28000 datapoints
2025-03-07 12:17:15,596 - INFO - training batch 301, loss: 0.531, 9632/28000 datapoints
2025-03-07 12:17:15,860 - INFO - training batch 351, loss: 0.357, 11232/28000 datapoints
2025-03-07 12:17:16,127 - INFO - training batch 401, loss: 0.540, 12832/28000 datapoints
2025-03-07 12:17:16,445 - INFO - training batch 451, loss: 0.540, 14432/28000 datapoints
2025-03-07 12:17:16,750 - INFO - training batch 501, loss: 0.205, 16032/28000 datapoints
2025-03-07 12:17:17,054 - INFO - training batch 551, loss: 0.467, 17632/28000 datapoints
2025-03-07 12:17:17,379 - INFO - training batch 601, loss: 0.645, 19232/28000 datapoints
2025-03-07 12:17:17,711 - INFO - training batch 651, loss: 0.195, 20832/28000 datapoints
2025-03-07 12:17:18,021 - INFO - training batch 701, loss: 0.394, 22432/28000 datapoints
2025-03-07 12:17:18,333 - INFO - training batch 751, loss: 0.260, 24032/28000 datapoints
2025-03-07 12:17:18,643 - INFO - training batch 801, loss: 0.326, 25632/28000 datapoints
2025-03-07 12:17:18,941 - INFO - training batch 851, loss: 0.540, 27232/28000 datapoints
2025-03-07 12:17:19,083 - INFO - validation batch 1, loss: 0.181, 32/6976 datapoints
2025-03-07 12:17:19,170 - INFO - validation batch 51, loss: 0.898, 1632/6976 datapoints
2025-03-07 12:17:19,249 - INFO - validation batch 101, loss: 0.237, 3232/6976 datapoints
2025-03-07 12:17:19,329 - INFO - validation batch 151, loss: 0.441, 4832/6976 datapoints
2025-03-07 12:17:19,413 - INFO - validation batch 201, loss: 0.479, 6432/6976 datapoints
2025-03-07 12:17:19,444 - INFO - Epoch 50/800 done.
2025-03-07 12:17:19,445 - INFO - Final validation performance:
Loss: 0.447, top-1 acc: 0.876top-5 acc: 0.876
2025-03-07 12:17:19,445 - INFO - Beginning epoch 51/800
2025-03-07 12:17:19,454 - INFO - training batch 1, loss: 0.332, 32/28000 datapoints
2025-03-07 12:17:19,745 - INFO - training batch 51, loss: 0.248, 1632/28000 datapoints
2025-03-07 12:17:20,015 - INFO - training batch 101, loss: 0.237, 3232/28000 datapoints
2025-03-07 12:17:20,321 - INFO - training batch 151, loss: 0.420, 4832/28000 datapoints
2025-03-07 12:17:20,635 - INFO - training batch 201, loss: 0.416, 6432/28000 datapoints
2025-03-07 12:17:20,942 - INFO - training batch 251, loss: 0.379, 8032/28000 datapoints
2025-03-07 12:17:21,266 - INFO - training batch 301, loss: 0.524, 9632/28000 datapoints
2025-03-07 12:17:21,632 - INFO - training batch 351, loss: 0.351, 11232/28000 datapoints
2025-03-07 12:17:21,897 - INFO - training batch 401, loss: 0.534, 12832/28000 datapoints
2025-03-07 12:17:22,162 - INFO - training batch 451, loss: 0.531, 14432/28000 datapoints
2025-03-07 12:17:22,439 - INFO - training batch 501, loss: 0.201, 16032/28000 datapoints
2025-03-07 12:17:22,709 - INFO - training batch 551, loss: 0.455, 17632/28000 datapoints
2025-03-07 12:17:23,020 - INFO - training batch 601, loss: 0.629, 19232/28000 datapoints
2025-03-07 12:17:23,314 - INFO - training batch 651, loss: 0.188, 20832/28000 datapoints
2025-03-07 12:17:23,599 - INFO - training batch 701, loss: 0.392, 22432/28000 datapoints
2025-03-07 12:17:23,878 - INFO - training batch 751, loss: 0.253, 24032/28000 datapoints
2025-03-07 12:17:24,152 - INFO - training batch 801, loss: 0.323, 25632/28000 datapoints
2025-03-07 12:17:24,430 - INFO - training batch 851, loss: 0.533, 27232/28000 datapoints
2025-03-07 12:17:24,571 - INFO - validation batch 1, loss: 0.174, 32/6976 datapoints
2025-03-07 12:17:24,651 - INFO - validation batch 51, loss: 0.891, 1632/6976 datapoints
2025-03-07 12:17:24,727 - INFO - validation batch 101, loss: 0.234, 3232/6976 datapoints
2025-03-07 12:17:24,804 - INFO - validation batch 151, loss: 0.434, 4832/6976 datapoints
2025-03-07 12:17:24,882 - INFO - validation batch 201, loss: 0.475, 6432/6976 datapoints
2025-03-07 12:17:24,909 - INFO - Epoch 51/800 done.
2025-03-07 12:17:24,910 - INFO - Final validation performance:
Loss: 0.442, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 12:17:24,910 - INFO - Beginning epoch 52/800
2025-03-07 12:17:24,919 - INFO - training batch 1, loss: 0.327, 32/28000 datapoints
2025-03-07 12:17:25,199 - INFO - training batch 51, loss: 0.241, 1632/28000 datapoints
2025-03-07 12:17:25,477 - INFO - training batch 101, loss: 0.234, 3232/28000 datapoints
2025-03-07 12:17:25,757 - INFO - training batch 151, loss: 0.413, 4832/28000 datapoints
2025-03-07 12:17:26,027 - INFO - training batch 201, loss: 0.409, 6432/28000 datapoints
2025-03-07 12:17:26,290 - INFO - training batch 251, loss: 0.375, 8032/28000 datapoints
2025-03-07 12:17:26,619 - INFO - training batch 301, loss: 0.517, 9632/28000 datapoints
2025-03-07 12:17:27,031 - INFO - training batch 351, loss: 0.345, 11232/28000 datapoints
2025-03-07 12:17:27,416 - INFO - training batch 401, loss: 0.528, 12832/28000 datapoints
2025-03-07 12:17:27,713 - INFO - training batch 451, loss: 0.524, 14432/28000 datapoints
2025-03-07 12:17:27,996 - INFO - training batch 501, loss: 0.197, 16032/28000 datapoints
2025-03-07 12:17:28,271 - INFO - training batch 551, loss: 0.443, 17632/28000 datapoints
2025-03-07 12:17:28,553 - INFO - training batch 601, loss: 0.613, 19232/28000 datapoints
2025-03-07 12:17:28,817 - INFO - training batch 651, loss: 0.182, 20832/28000 datapoints
2025-03-07 12:17:29,082 - INFO - training batch 701, loss: 0.390, 22432/28000 datapoints
2025-03-07 12:17:29,354 - INFO - training batch 751, loss: 0.246, 24032/28000 datapoints
2025-03-07 12:17:29,630 - INFO - training batch 801, loss: 0.320, 25632/28000 datapoints
2025-03-07 12:17:29,905 - INFO - training batch 851, loss: 0.526, 27232/28000 datapoints
2025-03-07 12:17:30,056 - INFO - validation batch 1, loss: 0.168, 32/6976 datapoints
2025-03-07 12:17:30,145 - INFO - validation batch 51, loss: 0.884, 1632/6976 datapoints
2025-03-07 12:17:30,222 - INFO - validation batch 101, loss: 0.231, 3232/6976 datapoints
2025-03-07 12:17:30,292 - INFO - validation batch 151, loss: 0.429, 4832/6976 datapoints
2025-03-07 12:17:30,364 - INFO - validation batch 201, loss: 0.472, 6432/6976 datapoints
2025-03-07 12:17:30,392 - INFO - Epoch 52/800 done.
2025-03-07 12:17:30,392 - INFO - Final validation performance:
Loss: 0.437, top-1 acc: 0.877top-5 acc: 0.877
2025-03-07 12:17:30,393 - INFO - Beginning epoch 53/800
2025-03-07 12:17:30,402 - INFO - training batch 1, loss: 0.321, 32/28000 datapoints
2025-03-07 12:17:30,738 - INFO - training batch 51, loss: 0.235, 1632/28000 datapoints
2025-03-07 12:17:31,004 - INFO - training batch 101, loss: 0.231, 3232/28000 datapoints
2025-03-07 12:17:31,281 - INFO - training batch 151, loss: 0.406, 4832/28000 datapoints
2025-03-07 12:17:31,553 - INFO - training batch 201, loss: 0.402, 6432/28000 datapoints
2025-03-07 12:17:31,830 - INFO - training batch 251, loss: 0.370, 8032/28000 datapoints
2025-03-07 12:17:32,098 - INFO - training batch 301, loss: 0.511, 9632/28000 datapoints
2025-03-07 12:17:32,368 - INFO - training batch 351, loss: 0.339, 11232/28000 datapoints
2025-03-07 12:17:32,639 - INFO - training batch 401, loss: 0.522, 12832/28000 datapoints
2025-03-07 12:17:32,903 - INFO - training batch 451, loss: 0.516, 14432/28000 datapoints
2025-03-07 12:17:33,174 - INFO - training batch 501, loss: 0.194, 16032/28000 datapoints
2025-03-07 12:17:33,454 - INFO - training batch 551, loss: 0.431, 17632/28000 datapoints
2025-03-07 12:17:33,722 - INFO - training batch 601, loss: 0.598, 19232/28000 datapoints
2025-03-07 12:17:33,988 - INFO - training batch 651, loss: 0.177, 20832/28000 datapoints
2025-03-07 12:17:34,262 - INFO - training batch 701, loss: 0.388, 22432/28000 datapoints
2025-03-07 12:17:34,557 - INFO - training batch 751, loss: 0.239, 24032/28000 datapoints
2025-03-07 12:17:34,822 - INFO - training batch 801, loss: 0.316, 25632/28000 datapoints
2025-03-07 12:17:35,088 - INFO - training batch 851, loss: 0.519, 27232/28000 datapoints
2025-03-07 12:17:35,220 - INFO - validation batch 1, loss: 0.161, 32/6976 datapoints
2025-03-07 12:17:35,294 - INFO - validation batch 51, loss: 0.879, 1632/6976 datapoints
2025-03-07 12:17:35,368 - INFO - validation batch 101, loss: 0.228, 3232/6976 datapoints
2025-03-07 12:17:35,459 - INFO - validation batch 151, loss: 0.423, 4832/6976 datapoints
2025-03-07 12:17:35,538 - INFO - validation batch 201, loss: 0.469, 6432/6976 datapoints
2025-03-07 12:17:35,567 - INFO - Epoch 53/800 done.
2025-03-07 12:17:35,567 - INFO - Final validation performance:
Loss: 0.432, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 12:17:35,567 - INFO - Beginning epoch 54/800
2025-03-07 12:17:35,575 - INFO - training batch 1, loss: 0.316, 32/28000 datapoints
2025-03-07 12:17:35,864 - INFO - training batch 51, loss: 0.229, 1632/28000 datapoints
2025-03-07 12:17:36,142 - INFO - training batch 101, loss: 0.229, 3232/28000 datapoints
2025-03-07 12:17:36,416 - INFO - training batch 151, loss: 0.399, 4832/28000 datapoints
2025-03-07 12:17:36,753 - INFO - training batch 201, loss: 0.396, 6432/28000 datapoints
2025-03-07 12:17:37,076 - INFO - training batch 251, loss: 0.365, 8032/28000 datapoints
2025-03-07 12:17:37,351 - INFO - training batch 301, loss: 0.505, 9632/28000 datapoints
2025-03-07 12:17:37,625 - INFO - training batch 351, loss: 0.333, 11232/28000 datapoints
2025-03-07 12:17:37,901 - INFO - training batch 401, loss: 0.516, 12832/28000 datapoints
2025-03-07 12:17:38,210 - INFO - training batch 451, loss: 0.509, 14432/28000 datapoints
2025-03-07 12:17:38,535 - INFO - training batch 501, loss: 0.191, 16032/28000 datapoints
2025-03-07 12:17:38,852 - INFO - training batch 551, loss: 0.420, 17632/28000 datapoints
2025-03-07 12:17:39,137 - INFO - training batch 601, loss: 0.583, 19232/28000 datapoints
2025-03-07 12:17:39,421 - INFO - training batch 651, loss: 0.171, 20832/28000 datapoints
2025-03-07 12:17:39,698 - INFO - training batch 701, loss: 0.386, 22432/28000 datapoints
2025-03-07 12:17:39,981 - INFO - training batch 751, loss: 0.233, 24032/28000 datapoints
2025-03-07 12:17:40,269 - INFO - training batch 801, loss: 0.313, 25632/28000 datapoints
2025-03-07 12:17:40,573 - INFO - training batch 851, loss: 0.513, 27232/28000 datapoints
2025-03-07 12:17:40,703 - INFO - validation batch 1, loss: 0.155, 32/6976 datapoints
2025-03-07 12:17:40,778 - INFO - validation batch 51, loss: 0.872, 1632/6976 datapoints
2025-03-07 12:17:40,851 - INFO - validation batch 101, loss: 0.226, 3232/6976 datapoints
2025-03-07 12:17:40,928 - INFO - validation batch 151, loss: 0.418, 4832/6976 datapoints
2025-03-07 12:17:41,005 - INFO - validation batch 201, loss: 0.466, 6432/6976 datapoints
2025-03-07 12:17:41,032 - INFO - Epoch 54/800 done.
2025-03-07 12:17:41,032 - INFO - Final validation performance:
Loss: 0.428, top-1 acc: 0.879top-5 acc: 0.879
2025-03-07 12:17:41,033 - INFO - Beginning epoch 55/800
2025-03-07 12:17:41,040 - INFO - training batch 1, loss: 0.311, 32/28000 datapoints
2025-03-07 12:17:41,323 - INFO - training batch 51, loss: 0.224, 1632/28000 datapoints
2025-03-07 12:17:41,606 - INFO - training batch 101, loss: 0.226, 3232/28000 datapoints
2025-03-07 12:17:41,885 - INFO - training batch 151, loss: 0.393, 4832/28000 datapoints
2025-03-07 12:17:42,163 - INFO - training batch 201, loss: 0.391, 6432/28000 datapoints
2025-03-07 12:17:42,446 - INFO - training batch 251, loss: 0.361, 8032/28000 datapoints
2025-03-07 12:17:42,717 - INFO - training batch 301, loss: 0.499, 9632/28000 datapoints
2025-03-07 12:17:43,003 - INFO - training batch 351, loss: 0.328, 11232/28000 datapoints
2025-03-07 12:17:43,276 - INFO - training batch 401, loss: 0.510, 12832/28000 datapoints
2025-03-07 12:17:43,541 - INFO - training batch 451, loss: 0.502, 14432/28000 datapoints
2025-03-07 12:17:43,815 - INFO - training batch 501, loss: 0.188, 16032/28000 datapoints
2025-03-07 12:17:44,085 - INFO - training batch 551, loss: 0.410, 17632/28000 datapoints
2025-03-07 12:17:44,346 - INFO - training batch 601, loss: 0.569, 19232/28000 datapoints
2025-03-07 12:17:44,615 - INFO - training batch 651, loss: 0.166, 20832/28000 datapoints
2025-03-07 12:17:44,876 - INFO - training batch 701, loss: 0.385, 22432/28000 datapoints
2025-03-07 12:17:45,137 - INFO - training batch 751, loss: 0.227, 24032/28000 datapoints
2025-03-07 12:17:45,400 - INFO - training batch 801, loss: 0.309, 25632/28000 datapoints
2025-03-07 12:17:45,687 - INFO - training batch 851, loss: 0.506, 27232/28000 datapoints
2025-03-07 12:17:45,813 - INFO - validation batch 1, loss: 0.150, 32/6976 datapoints
2025-03-07 12:17:45,887 - INFO - validation batch 51, loss: 0.867, 1632/6976 datapoints
2025-03-07 12:17:45,970 - INFO - validation batch 101, loss: 0.225, 3232/6976 datapoints
2025-03-07 12:17:46,045 - INFO - validation batch 151, loss: 0.412, 4832/6976 datapoints
2025-03-07 12:17:46,124 - INFO - validation batch 201, loss: 0.463, 6432/6976 datapoints
2025-03-07 12:17:46,152 - INFO - Epoch 55/800 done.
2025-03-07 12:17:46,152 - INFO - Final validation performance:
Loss: 0.423, top-1 acc: 0.880top-5 acc: 0.880
2025-03-07 12:17:46,153 - INFO - Beginning epoch 56/800
2025-03-07 12:17:46,161 - INFO - training batch 1, loss: 0.306, 32/28000 datapoints
2025-03-07 12:17:46,450 - INFO - training batch 51, loss: 0.218, 1632/28000 datapoints
2025-03-07 12:17:46,716 - INFO - training batch 101, loss: 0.223, 3232/28000 datapoints
2025-03-07 12:17:47,044 - INFO - training batch 151, loss: 0.387, 4832/28000 datapoints
2025-03-07 12:17:47,397 - INFO - training batch 201, loss: 0.385, 6432/28000 datapoints
2025-03-07 12:17:47,751 - INFO - training batch 251, loss: 0.356, 8032/28000 datapoints
2025-03-07 12:17:48,082 - INFO - training batch 301, loss: 0.494, 9632/28000 datapoints
2025-03-07 12:17:48,399 - INFO - training batch 351, loss: 0.323, 11232/28000 datapoints
2025-03-07 12:17:48,738 - INFO - training batch 401, loss: 0.504, 12832/28000 datapoints
2025-03-07 12:17:49,067 - INFO - training batch 451, loss: 0.495, 14432/28000 datapoints
2025-03-07 12:17:49,384 - INFO - training batch 501, loss: 0.185, 16032/28000 datapoints
2025-03-07 12:17:49,686 - INFO - training batch 551, loss: 0.399, 17632/28000 datapoints
2025-03-07 12:17:49,975 - INFO - training batch 601, loss: 0.555, 19232/28000 datapoints
2025-03-07 12:17:50,251 - INFO - training batch 651, loss: 0.161, 20832/28000 datapoints
2025-03-07 12:17:50,531 - INFO - training batch 701, loss: 0.383, 22432/28000 datapoints
2025-03-07 12:17:50,806 - INFO - training batch 751, loss: 0.222, 24032/28000 datapoints
2025-03-07 12:17:51,077 - INFO - training batch 801, loss: 0.304, 25632/28000 datapoints
2025-03-07 12:17:51,345 - INFO - training batch 851, loss: 0.500, 27232/28000 datapoints
2025-03-07 12:17:51,485 - INFO - validation batch 1, loss: 0.145, 32/6976 datapoints
2025-03-07 12:17:51,560 - INFO - validation batch 51, loss: 0.861, 1632/6976 datapoints
2025-03-07 12:17:51,638 - INFO - validation batch 101, loss: 0.224, 3232/6976 datapoints
2025-03-07 12:17:51,716 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-07 12:17:51,796 - INFO - validation batch 201, loss: 0.460, 6432/6976 datapoints
2025-03-07 12:17:51,830 - INFO - Epoch 56/800 done.
2025-03-07 12:17:51,830 - INFO - Final validation performance:
Loss: 0.419, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 12:17:51,831 - INFO - Beginning epoch 57/800
2025-03-07 12:17:51,838 - INFO - training batch 1, loss: 0.301, 32/28000 datapoints
2025-03-07 12:17:52,124 - INFO - training batch 51, loss: 0.214, 1632/28000 datapoints
2025-03-07 12:17:52,390 - INFO - training batch 101, loss: 0.220, 3232/28000 datapoints
2025-03-07 12:17:52,655 - INFO - training batch 151, loss: 0.380, 4832/28000 datapoints
2025-03-07 12:17:52,917 - INFO - training batch 201, loss: 0.380, 6432/28000 datapoints
2025-03-07 12:17:53,179 - INFO - training batch 251, loss: 0.352, 8032/28000 datapoints
2025-03-07 12:17:53,444 - INFO - training batch 301, loss: 0.489, 9632/28000 datapoints
2025-03-07 12:17:53,704 - INFO - training batch 351, loss: 0.318, 11232/28000 datapoints
2025-03-07 12:17:53,974 - INFO - training batch 401, loss: 0.498, 12832/28000 datapoints
2025-03-07 12:17:54,239 - INFO - training batch 451, loss: 0.488, 14432/28000 datapoints
2025-03-07 12:17:54,559 - INFO - training batch 501, loss: 0.183, 16032/28000 datapoints
2025-03-07 12:17:54,829 - INFO - training batch 551, loss: 0.390, 17632/28000 datapoints
2025-03-07 12:17:55,089 - INFO - training batch 601, loss: 0.541, 19232/28000 datapoints
2025-03-07 12:17:55,358 - INFO - training batch 651, loss: 0.156, 20832/28000 datapoints
2025-03-07 12:17:55,639 - INFO - training batch 701, loss: 0.381, 22432/28000 datapoints
2025-03-07 12:17:55,904 - INFO - training batch 751, loss: 0.216, 24032/28000 datapoints
2025-03-07 12:17:56,195 - INFO - training batch 801, loss: 0.301, 25632/28000 datapoints
2025-03-07 12:17:56,494 - INFO - training batch 851, loss: 0.494, 27232/28000 datapoints
2025-03-07 12:17:56,630 - INFO - validation batch 1, loss: 0.140, 32/6976 datapoints
2025-03-07 12:17:56,717 - INFO - validation batch 51, loss: 0.854, 1632/6976 datapoints
2025-03-07 12:17:56,810 - INFO - validation batch 101, loss: 0.223, 3232/6976 datapoints
2025-03-07 12:17:56,918 - INFO - validation batch 151, loss: 0.402, 4832/6976 datapoints
2025-03-07 12:17:57,030 - INFO - validation batch 201, loss: 0.457, 6432/6976 datapoints
2025-03-07 12:17:57,065 - INFO - Epoch 57/800 done.
2025-03-07 12:17:57,065 - INFO - Final validation performance:
Loss: 0.415, top-1 acc: 0.881top-5 acc: 0.881
2025-03-07 12:17:57,066 - INFO - Beginning epoch 58/800
2025-03-07 12:17:57,075 - INFO - training batch 1, loss: 0.297, 32/28000 datapoints
2025-03-07 12:17:57,376 - INFO - training batch 51, loss: 0.209, 1632/28000 datapoints
2025-03-07 12:17:57,658 - INFO - training batch 101, loss: 0.218, 3232/28000 datapoints
2025-03-07 12:17:57,932 - INFO - training batch 151, loss: 0.374, 4832/28000 datapoints
2025-03-07 12:17:58,292 - INFO - training batch 201, loss: 0.374, 6432/28000 datapoints
2025-03-07 12:17:58,577 - INFO - training batch 251, loss: 0.347, 8032/28000 datapoints
2025-03-07 12:17:58,836 - INFO - training batch 301, loss: 0.484, 9632/28000 datapoints
2025-03-07 12:17:59,100 - INFO - training batch 351, loss: 0.313, 11232/28000 datapoints
2025-03-07 12:17:59,374 - INFO - training batch 401, loss: 0.493, 12832/28000 datapoints
2025-03-07 12:17:59,661 - INFO - training batch 451, loss: 0.481, 14432/28000 datapoints
2025-03-07 12:17:59,937 - INFO - training batch 501, loss: 0.180, 16032/28000 datapoints
2025-03-07 12:18:00,201 - INFO - training batch 551, loss: 0.380, 17632/28000 datapoints
2025-03-07 12:18:00,479 - INFO - training batch 601, loss: 0.527, 19232/28000 datapoints
2025-03-07 12:18:00,780 - INFO - training batch 651, loss: 0.151, 20832/28000 datapoints
2025-03-07 12:18:01,046 - INFO - training batch 701, loss: 0.379, 22432/28000 datapoints
2025-03-07 12:18:01,344 - INFO - training batch 751, loss: 0.211, 24032/28000 datapoints
2025-03-07 12:18:01,669 - INFO - training batch 801, loss: 0.297, 25632/28000 datapoints
2025-03-07 12:18:01,961 - INFO - training batch 851, loss: 0.488, 27232/28000 datapoints
2025-03-07 12:18:02,094 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-07 12:18:02,175 - INFO - validation batch 51, loss: 0.848, 1632/6976 datapoints
2025-03-07 12:18:02,257 - INFO - validation batch 101, loss: 0.221, 3232/6976 datapoints
2025-03-07 12:18:02,337 - INFO - validation batch 151, loss: 0.397, 4832/6976 datapoints
2025-03-07 12:18:02,416 - INFO - validation batch 201, loss: 0.455, 6432/6976 datapoints
2025-03-07 12:18:02,443 - INFO - Epoch 58/800 done.
2025-03-07 12:18:02,443 - INFO - Final validation performance:
Loss: 0.411, top-1 acc: 0.882top-5 acc: 0.882
2025-03-07 12:18:02,444 - INFO - Beginning epoch 59/800
2025-03-07 12:18:02,452 - INFO - training batch 1, loss: 0.293, 32/28000 datapoints
2025-03-07 12:18:02,729 - INFO - training batch 51, loss: 0.205, 1632/28000 datapoints
2025-03-07 12:18:03,006 - INFO - training batch 101, loss: 0.215, 3232/28000 datapoints
2025-03-07 12:18:03,276 - INFO - training batch 151, loss: 0.367, 4832/28000 datapoints
2025-03-07 12:18:03,550 - INFO - training batch 201, loss: 0.369, 6432/28000 datapoints
2025-03-07 12:18:03,814 - INFO - training batch 251, loss: 0.343, 8032/28000 datapoints
2025-03-07 12:18:04,072 - INFO - training batch 301, loss: 0.479, 9632/28000 datapoints
2025-03-07 12:18:04,334 - INFO - training batch 351, loss: 0.308, 11232/28000 datapoints
2025-03-07 12:18:04,610 - INFO - training batch 401, loss: 0.487, 12832/28000 datapoints
2025-03-07 12:18:04,905 - INFO - training batch 451, loss: 0.475, 14432/28000 datapoints
2025-03-07 12:18:05,180 - INFO - training batch 501, loss: 0.178, 16032/28000 datapoints
2025-03-07 12:18:05,449 - INFO - training batch 551, loss: 0.371, 17632/28000 datapoints
2025-03-07 12:18:05,714 - INFO - training batch 601, loss: 0.514, 19232/28000 datapoints
2025-03-07 12:18:05,980 - INFO - training batch 651, loss: 0.147, 20832/28000 datapoints
2025-03-07 12:18:06,258 - INFO - training batch 701, loss: 0.377, 22432/28000 datapoints
2025-03-07 12:18:06,521 - INFO - training batch 751, loss: 0.206, 24032/28000 datapoints
2025-03-07 12:18:06,776 - INFO - training batch 801, loss: 0.293, 25632/28000 datapoints
2025-03-07 12:18:07,093 - INFO - training batch 851, loss: 0.482, 27232/28000 datapoints
2025-03-07 12:18:07,246 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-07 12:18:07,362 - INFO - validation batch 51, loss: 0.842, 1632/6976 datapoints
2025-03-07 12:18:07,480 - INFO - validation batch 101, loss: 0.221, 3232/6976 datapoints
2025-03-07 12:18:07,587 - INFO - validation batch 151, loss: 0.393, 4832/6976 datapoints
2025-03-07 12:18:07,751 - INFO - validation batch 201, loss: 0.452, 6432/6976 datapoints
2025-03-07 12:18:07,830 - INFO - Epoch 59/800 done.
2025-03-07 12:18:07,831 - INFO - Final validation performance:
Loss: 0.408, top-1 acc: 0.884top-5 acc: 0.884
2025-03-07 12:18:07,832 - INFO - Beginning epoch 60/800
2025-03-07 12:18:07,849 - INFO - training batch 1, loss: 0.289, 32/28000 datapoints
2025-03-07 12:18:08,208 - INFO - training batch 51, loss: 0.202, 1632/28000 datapoints
2025-03-07 12:18:08,489 - INFO - training batch 101, loss: 0.212, 3232/28000 datapoints
2025-03-07 12:18:08,763 - INFO - training batch 151, loss: 0.361, 4832/28000 datapoints
2025-03-07 12:18:09,051 - INFO - training batch 201, loss: 0.363, 6432/28000 datapoints
2025-03-07 12:18:09,348 - INFO - training batch 251, loss: 0.338, 8032/28000 datapoints
2025-03-07 12:18:09,679 - INFO - training batch 301, loss: 0.475, 9632/28000 datapoints
2025-03-07 12:18:09,953 - INFO - training batch 351, loss: 0.304, 11232/28000 datapoints
2025-03-07 12:18:10,223 - INFO - training batch 401, loss: 0.481, 12832/28000 datapoints
2025-03-07 12:18:10,493 - INFO - training batch 451, loss: 0.468, 14432/28000 datapoints
2025-03-07 12:18:10,758 - INFO - training batch 501, loss: 0.176, 16032/28000 datapoints
2025-03-07 12:18:11,022 - INFO - training batch 551, loss: 0.362, 17632/28000 datapoints
2025-03-07 12:18:11,288 - INFO - training batch 601, loss: 0.502, 19232/28000 datapoints
2025-03-07 12:18:11,556 - INFO - training batch 651, loss: 0.142, 20832/28000 datapoints
2025-03-07 12:18:11,816 - INFO - training batch 701, loss: 0.374, 22432/28000 datapoints
2025-03-07 12:18:12,078 - INFO - training batch 751, loss: 0.202, 24032/28000 datapoints
2025-03-07 12:18:12,342 - INFO - training batch 801, loss: 0.289, 25632/28000 datapoints
2025-03-07 12:18:12,618 - INFO - training batch 851, loss: 0.475, 27232/28000 datapoints
2025-03-07 12:18:12,749 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-07 12:18:12,827 - INFO - validation batch 51, loss: 0.837, 1632/6976 datapoints
2025-03-07 12:18:12,903 - INFO - validation batch 101, loss: 0.220, 3232/6976 datapoints
2025-03-07 12:18:12,979 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-07 12:18:13,054 - INFO - validation batch 201, loss: 0.449, 6432/6976 datapoints
2025-03-07 12:18:13,084 - INFO - Epoch 60/800 done.
2025-03-07 12:18:13,084 - INFO - Final validation performance:
Loss: 0.404, top-1 acc: 0.885top-5 acc: 0.885
2025-03-07 12:18:13,085 - INFO - Beginning epoch 61/800
2025-03-07 12:18:13,092 - INFO - training batch 1, loss: 0.286, 32/28000 datapoints
2025-03-07 12:18:13,366 - INFO - training batch 51, loss: 0.198, 1632/28000 datapoints
2025-03-07 12:18:13,673 - INFO - training batch 101, loss: 0.210, 3232/28000 datapoints
2025-03-07 12:18:13,977 - INFO - training batch 151, loss: 0.354, 4832/28000 datapoints
2025-03-07 12:18:14,252 - INFO - training batch 201, loss: 0.358, 6432/28000 datapoints
2025-03-07 12:18:14,521 - INFO - training batch 251, loss: 0.334, 8032/28000 datapoints
2025-03-07 12:18:14,780 - INFO - training batch 301, loss: 0.471, 9632/28000 datapoints
2025-03-07 12:18:15,045 - INFO - training batch 351, loss: 0.300, 11232/28000 datapoints
2025-03-07 12:18:15,317 - INFO - training batch 401, loss: 0.475, 12832/28000 datapoints
2025-03-07 12:18:15,648 - INFO - training batch 451, loss: 0.462, 14432/28000 datapoints
2025-03-07 12:18:15,922 - INFO - training batch 501, loss: 0.173, 16032/28000 datapoints
2025-03-07 12:18:16,203 - INFO - training batch 551, loss: 0.354, 17632/28000 datapoints
2025-03-07 12:18:16,487 - INFO - training batch 601, loss: 0.491, 19232/28000 datapoints
2025-03-07 12:18:16,758 - INFO - training batch 651, loss: 0.138, 20832/28000 datapoints
2025-03-07 12:18:17,030 - INFO - training batch 701, loss: 0.372, 22432/28000 datapoints
2025-03-07 12:18:17,324 - INFO - training batch 751, loss: 0.197, 24032/28000 datapoints
2025-03-07 12:18:17,651 - INFO - training batch 801, loss: 0.285, 25632/28000 datapoints
2025-03-07 12:18:17,982 - INFO - training batch 851, loss: 0.470, 27232/28000 datapoints
2025-03-07 12:18:18,140 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-07 12:18:18,233 - INFO - validation batch 51, loss: 0.831, 1632/6976 datapoints
2025-03-07 12:18:18,327 - INFO - validation batch 101, loss: 0.220, 3232/6976 datapoints
2025-03-07 12:18:18,418 - INFO - validation batch 151, loss: 0.383, 4832/6976 datapoints
2025-03-07 12:18:18,518 - INFO - validation batch 201, loss: 0.446, 6432/6976 datapoints
2025-03-07 12:18:18,548 - INFO - Epoch 61/800 done.
2025-03-07 12:18:18,548 - INFO - Final validation performance:
Loss: 0.401, top-1 acc: 0.886top-5 acc: 0.886
2025-03-07 12:18:18,549 - INFO - Beginning epoch 62/800
2025-03-07 12:18:18,559 - INFO - training batch 1, loss: 0.282, 32/28000 datapoints
2025-03-07 12:18:18,876 - INFO - training batch 51, loss: 0.195, 1632/28000 datapoints
2025-03-07 12:18:19,184 - INFO - training batch 101, loss: 0.207, 3232/28000 datapoints
2025-03-07 12:18:19,496 - INFO - training batch 151, loss: 0.348, 4832/28000 datapoints
2025-03-07 12:18:19,786 - INFO - training batch 201, loss: 0.353, 6432/28000 datapoints
2025-03-07 12:18:20,070 - INFO - training batch 251, loss: 0.329, 8032/28000 datapoints
2025-03-07 12:18:20,349 - INFO - training batch 301, loss: 0.467, 9632/28000 datapoints
2025-03-07 12:18:20,647 - INFO - training batch 351, loss: 0.295, 11232/28000 datapoints
2025-03-07 12:18:20,927 - INFO - training batch 401, loss: 0.469, 12832/28000 datapoints
2025-03-07 12:18:21,198 - INFO - training batch 451, loss: 0.456, 14432/28000 datapoints
2025-03-07 12:18:21,483 - INFO - training batch 501, loss: 0.171, 16032/28000 datapoints
2025-03-07 12:18:21,778 - INFO - training batch 551, loss: 0.346, 17632/28000 datapoints
2025-03-07 12:18:22,042 - INFO - training batch 601, loss: 0.480, 19232/28000 datapoints
2025-03-07 12:18:22,337 - INFO - training batch 651, loss: 0.134, 20832/28000 datapoints
2025-03-07 12:18:22,606 - INFO - training batch 701, loss: 0.370, 22432/28000 datapoints
2025-03-07 12:18:22,865 - INFO - training batch 751, loss: 0.193, 24032/28000 datapoints
2025-03-07 12:18:23,128 - INFO - training batch 801, loss: 0.281, 25632/28000 datapoints
2025-03-07 12:18:23,388 - INFO - training batch 851, loss: 0.464, 27232/28000 datapoints
2025-03-07 12:18:23,520 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-07 12:18:23,596 - INFO - validation batch 51, loss: 0.826, 1632/6976 datapoints
2025-03-07 12:18:23,671 - INFO - validation batch 101, loss: 0.220, 3232/6976 datapoints
2025-03-07 12:18:23,746 - INFO - validation batch 151, loss: 0.378, 4832/6976 datapoints
2025-03-07 12:18:23,819 - INFO - validation batch 201, loss: 0.444, 6432/6976 datapoints
2025-03-07 12:18:23,842 - INFO - Epoch 62/800 done.
2025-03-07 12:18:23,843 - INFO - Final validation performance:
Loss: 0.398, top-1 acc: 0.886top-5 acc: 0.886
2025-03-07 12:18:23,843 - INFO - Beginning epoch 63/800
2025-03-07 12:18:23,851 - INFO - training batch 1, loss: 0.279, 32/28000 datapoints
2025-03-07 12:18:24,127 - INFO - training batch 51, loss: 0.192, 1632/28000 datapoints
2025-03-07 12:18:24,402 - INFO - training batch 101, loss: 0.205, 3232/28000 datapoints
2025-03-07 12:18:24,665 - INFO - training batch 151, loss: 0.342, 4832/28000 datapoints
2025-03-07 12:18:24,930 - INFO - training batch 201, loss: 0.347, 6432/28000 datapoints
2025-03-07 12:18:25,198 - INFO - training batch 251, loss: 0.324, 8032/28000 datapoints
2025-03-07 12:18:25,479 - INFO - training batch 301, loss: 0.463, 9632/28000 datapoints
2025-03-07 12:18:25,825 - INFO - training batch 351, loss: 0.292, 11232/28000 datapoints
2025-03-07 12:18:26,161 - INFO - training batch 401, loss: 0.463, 12832/28000 datapoints
2025-03-07 12:18:26,475 - INFO - training batch 451, loss: 0.450, 14432/28000 datapoints
2025-03-07 12:18:26,751 - INFO - training batch 501, loss: 0.169, 16032/28000 datapoints
2025-03-07 12:18:27,017 - INFO - training batch 551, loss: 0.338, 17632/28000 datapoints
2025-03-07 12:18:27,319 - INFO - training batch 601, loss: 0.469, 19232/28000 datapoints
2025-03-07 12:18:27,592 - INFO - training batch 651, loss: 0.130, 20832/28000 datapoints
2025-03-07 12:18:27,966 - INFO - training batch 701, loss: 0.368, 22432/28000 datapoints
2025-03-07 12:18:28,320 - INFO - training batch 751, loss: 0.189, 24032/28000 datapoints
2025-03-07 12:18:28,654 - INFO - training batch 801, loss: 0.278, 25632/28000 datapoints
2025-03-07 12:18:28,990 - INFO - training batch 851, loss: 0.458, 27232/28000 datapoints
2025-03-07 12:18:29,123 - INFO - validation batch 1, loss: 0.118, 32/6976 datapoints
2025-03-07 12:18:29,203 - INFO - validation batch 51, loss: 0.821, 1632/6976 datapoints
2025-03-07 12:18:29,281 - INFO - validation batch 101, loss: 0.219, 3232/6976 datapoints
2025-03-07 12:18:29,353 - INFO - validation batch 151, loss: 0.374, 4832/6976 datapoints
2025-03-07 12:18:29,430 - INFO - validation batch 201, loss: 0.441, 6432/6976 datapoints
2025-03-07 12:18:29,458 - INFO - Epoch 63/800 done.
2025-03-07 12:18:29,458 - INFO - Final validation performance:
Loss: 0.394, top-1 acc: 0.886top-5 acc: 0.886
2025-03-07 12:18:29,459 - INFO - Beginning epoch 64/800
2025-03-07 12:18:29,466 - INFO - training batch 1, loss: 0.275, 32/28000 datapoints
2025-03-07 12:18:29,746 - INFO - training batch 51, loss: 0.189, 1632/28000 datapoints
2025-03-07 12:18:30,011 - INFO - training batch 101, loss: 0.202, 3232/28000 datapoints
2025-03-07 12:18:30,276 - INFO - training batch 151, loss: 0.335, 4832/28000 datapoints
2025-03-07 12:18:30,583 - INFO - training batch 201, loss: 0.342, 6432/28000 datapoints
2025-03-07 12:18:30,864 - INFO - training batch 251, loss: 0.320, 8032/28000 datapoints
2025-03-07 12:18:31,129 - INFO - training batch 301, loss: 0.459, 9632/28000 datapoints
2025-03-07 12:18:31,395 - INFO - training batch 351, loss: 0.288, 11232/28000 datapoints
2025-03-07 12:18:31,664 - INFO - training batch 401, loss: 0.458, 12832/28000 datapoints
2025-03-07 12:18:31,950 - INFO - training batch 451, loss: 0.444, 14432/28000 datapoints
2025-03-07 12:18:32,211 - INFO - training batch 501, loss: 0.167, 16032/28000 datapoints
2025-03-07 12:18:32,480 - INFO - training batch 551, loss: 0.331, 17632/28000 datapoints
2025-03-07 12:18:32,748 - INFO - training batch 601, loss: 0.459, 19232/28000 datapoints
2025-03-07 12:18:33,011 - INFO - training batch 651, loss: 0.126, 20832/28000 datapoints
2025-03-07 12:18:33,280 - INFO - training batch 701, loss: 0.366, 22432/28000 datapoints
2025-03-07 12:18:33,543 - INFO - training batch 751, loss: 0.185, 24032/28000 datapoints
2025-03-07 12:18:33,808 - INFO - training batch 801, loss: 0.274, 25632/28000 datapoints
2025-03-07 12:18:34,073 - INFO - training batch 851, loss: 0.453, 27232/28000 datapoints
2025-03-07 12:18:34,202 - INFO - validation batch 1, loss: 0.114, 32/6976 datapoints
2025-03-07 12:18:34,280 - INFO - validation batch 51, loss: 0.815, 1632/6976 datapoints
2025-03-07 12:18:34,356 - INFO - validation batch 101, loss: 0.220, 3232/6976 datapoints
2025-03-07 12:18:34,434 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-07 12:18:34,515 - INFO - validation batch 201, loss: 0.438, 6432/6976 datapoints
2025-03-07 12:18:34,545 - INFO - Epoch 64/800 done.
2025-03-07 12:18:34,545 - INFO - Final validation performance:
Loss: 0.391, top-1 acc: 0.887top-5 acc: 0.887
2025-03-07 12:18:34,546 - INFO - Beginning epoch 65/800
2025-03-07 12:18:34,554 - INFO - training batch 1, loss: 0.272, 32/28000 datapoints
2025-03-07 12:18:34,830 - INFO - training batch 51, loss: 0.186, 1632/28000 datapoints
2025-03-07 12:18:35,094 - INFO - training batch 101, loss: 0.199, 3232/28000 datapoints
2025-03-07 12:18:35,359 - INFO - training batch 151, loss: 0.329, 4832/28000 datapoints
2025-03-07 12:18:35,632 - INFO - training batch 201, loss: 0.336, 6432/28000 datapoints
2025-03-07 12:18:35,894 - INFO - training batch 251, loss: 0.316, 8032/28000 datapoints
2025-03-07 12:18:36,162 - INFO - training batch 301, loss: 0.456, 9632/28000 datapoints
2025-03-07 12:18:36,437 - INFO - training batch 351, loss: 0.284, 11232/28000 datapoints
2025-03-07 12:18:36,704 - INFO - training batch 401, loss: 0.452, 12832/28000 datapoints
2025-03-07 12:18:36,967 - INFO - training batch 451, loss: 0.439, 14432/28000 datapoints
2025-03-07 12:18:37,231 - INFO - training batch 501, loss: 0.165, 16032/28000 datapoints
2025-03-07 12:18:37,523 - INFO - training batch 551, loss: 0.324, 17632/28000 datapoints
2025-03-07 12:18:37,800 - INFO - training batch 601, loss: 0.449, 19232/28000 datapoints
2025-03-07 12:18:38,105 - INFO - training batch 651, loss: 0.123, 20832/28000 datapoints
2025-03-07 12:18:38,377 - INFO - training batch 701, loss: 0.364, 22432/28000 datapoints
2025-03-07 12:18:38,660 - INFO - training batch 751, loss: 0.182, 24032/28000 datapoints
2025-03-07 12:18:38,929 - INFO - training batch 801, loss: 0.270, 25632/28000 datapoints
2025-03-07 12:18:39,202 - INFO - training batch 851, loss: 0.448, 27232/28000 datapoints
2025-03-07 12:18:39,340 - INFO - validation batch 1, loss: 0.112, 32/6976 datapoints
2025-03-07 12:18:39,418 - INFO - validation batch 51, loss: 0.810, 1632/6976 datapoints
2025-03-07 12:18:39,498 - INFO - validation batch 101, loss: 0.219, 3232/6976 datapoints
2025-03-07 12:18:39,575 - INFO - validation batch 151, loss: 0.366, 4832/6976 datapoints
2025-03-07 12:18:39,652 - INFO - validation batch 201, loss: 0.435, 6432/6976 datapoints
2025-03-07 12:18:39,680 - INFO - Epoch 65/800 done.
2025-03-07 12:18:39,681 - INFO - Final validation performance:
Loss: 0.388, top-1 acc: 0.888top-5 acc: 0.888
2025-03-07 12:18:39,681 - INFO - Beginning epoch 66/800
2025-03-07 12:18:39,689 - INFO - training batch 1, loss: 0.269, 32/28000 datapoints
2025-03-07 12:18:39,959 - INFO - training batch 51, loss: 0.183, 1632/28000 datapoints
2025-03-07 12:18:40,228 - INFO - training batch 101, loss: 0.197, 3232/28000 datapoints
2025-03-07 12:18:40,497 - INFO - training batch 151, loss: 0.323, 4832/28000 datapoints
2025-03-07 12:18:40,763 - INFO - training batch 201, loss: 0.331, 6432/28000 datapoints
2025-03-07 12:18:41,022 - INFO - training batch 251, loss: 0.312, 8032/28000 datapoints
2025-03-07 12:18:41,292 - INFO - training batch 301, loss: 0.452, 9632/28000 datapoints
2025-03-07 12:18:41,560 - INFO - training batch 351, loss: 0.280, 11232/28000 datapoints
2025-03-07 12:18:41,823 - INFO - training batch 401, loss: 0.446, 12832/28000 datapoints
2025-03-07 12:18:42,084 - INFO - training batch 451, loss: 0.433, 14432/28000 datapoints
2025-03-07 12:18:42,347 - INFO - training batch 501, loss: 0.162, 16032/28000 datapoints
2025-03-07 12:18:42,620 - INFO - training batch 551, loss: 0.316, 17632/28000 datapoints
2025-03-07 12:18:42,884 - INFO - training batch 601, loss: 0.440, 19232/28000 datapoints
2025-03-07 12:18:43,153 - INFO - training batch 651, loss: 0.119, 20832/28000 datapoints
2025-03-07 12:18:43,417 - INFO - training batch 701, loss: 0.362, 22432/28000 datapoints
2025-03-07 12:18:43,682 - INFO - training batch 751, loss: 0.178, 24032/28000 datapoints
2025-03-07 12:18:43,944 - INFO - training batch 801, loss: 0.267, 25632/28000 datapoints
2025-03-07 12:18:44,213 - INFO - training batch 851, loss: 0.442, 27232/28000 datapoints
2025-03-07 12:18:44,343 - INFO - validation batch 1, loss: 0.109, 32/6976 datapoints
2025-03-07 12:18:44,416 - INFO - validation batch 51, loss: 0.806, 1632/6976 datapoints
2025-03-07 12:18:44,497 - INFO - validation batch 101, loss: 0.219, 3232/6976 datapoints
2025-03-07 12:18:44,573 - INFO - validation batch 151, loss: 0.363, 4832/6976 datapoints
2025-03-07 12:18:44,647 - INFO - validation batch 201, loss: 0.433, 6432/6976 datapoints
2025-03-07 12:18:44,675 - INFO - Epoch 66/800 done.
2025-03-07 12:18:44,675 - INFO - Final validation performance:
Loss: 0.386, top-1 acc: 0.888top-5 acc: 0.888
2025-03-07 12:18:44,676 - INFO - Beginning epoch 67/800
2025-03-07 12:18:44,684 - INFO - training batch 1, loss: 0.266, 32/28000 datapoints
2025-03-07 12:18:44,949 - INFO - training batch 51, loss: 0.180, 1632/28000 datapoints
2025-03-07 12:18:45,210 - INFO - training batch 101, loss: 0.195, 3232/28000 datapoints
2025-03-07 12:18:45,480 - INFO - training batch 151, loss: 0.316, 4832/28000 datapoints
2025-03-07 12:18:45,784 - INFO - training batch 201, loss: 0.326, 6432/28000 datapoints
2025-03-07 12:18:46,103 - INFO - training batch 251, loss: 0.308, 8032/28000 datapoints
2025-03-07 12:18:46,383 - INFO - training batch 301, loss: 0.448, 9632/28000 datapoints
2025-03-07 12:18:46,665 - INFO - training batch 351, loss: 0.276, 11232/28000 datapoints
2025-03-07 12:18:46,967 - INFO - training batch 401, loss: 0.440, 12832/28000 datapoints
2025-03-07 12:18:47,265 - INFO - training batch 451, loss: 0.428, 14432/28000 datapoints
2025-03-07 12:18:47,561 - INFO - training batch 501, loss: 0.161, 16032/28000 datapoints
2025-03-07 12:18:47,840 - INFO - training batch 551, loss: 0.309, 17632/28000 datapoints
2025-03-07 12:18:48,147 - INFO - training batch 601, loss: 0.430, 19232/28000 datapoints
2025-03-07 12:18:48,521 - INFO - training batch 651, loss: 0.116, 20832/28000 datapoints
2025-03-07 12:18:48,874 - INFO - training batch 701, loss: 0.360, 22432/28000 datapoints
2025-03-07 12:18:49,189 - INFO - training batch 751, loss: 0.175, 24032/28000 datapoints
2025-03-07 12:18:49,506 - INFO - training batch 801, loss: 0.263, 25632/28000 datapoints
2025-03-07 12:18:49,819 - INFO - training batch 851, loss: 0.437, 27232/28000 datapoints
2025-03-07 12:18:49,982 - INFO - validation batch 1, loss: 0.107, 32/6976 datapoints
2025-03-07 12:18:50,083 - INFO - validation batch 51, loss: 0.801, 1632/6976 datapoints
2025-03-07 12:18:50,172 - INFO - validation batch 101, loss: 0.219, 3232/6976 datapoints
2025-03-07 12:18:50,260 - INFO - validation batch 151, loss: 0.359, 4832/6976 datapoints
2025-03-07 12:18:50,347 - INFO - validation batch 201, loss: 0.430, 6432/6976 datapoints
2025-03-07 12:18:50,378 - INFO - Epoch 67/800 done.
2025-03-07 12:18:50,378 - INFO - Final validation performance:
Loss: 0.383, top-1 acc: 0.889top-5 acc: 0.889
2025-03-07 12:18:50,379 - INFO - Beginning epoch 68/800
2025-03-07 12:18:50,387 - INFO - training batch 1, loss: 0.262, 32/28000 datapoints
2025-03-07 12:18:50,720 - INFO - training batch 51, loss: 0.177, 1632/28000 datapoints
2025-03-07 12:18:51,020 - INFO - training batch 101, loss: 0.192, 3232/28000 datapoints
2025-03-07 12:18:51,317 - INFO - training batch 151, loss: 0.310, 4832/28000 datapoints
2025-03-07 12:18:51,610 - INFO - training batch 201, loss: 0.320, 6432/28000 datapoints
2025-03-07 12:18:51,911 - INFO - training batch 251, loss: 0.305, 8032/28000 datapoints
2025-03-07 12:18:52,192 - INFO - training batch 301, loss: 0.445, 9632/28000 datapoints
2025-03-07 12:18:52,480 - INFO - training batch 351, loss: 0.272, 11232/28000 datapoints
2025-03-07 12:18:52,765 - INFO - training batch 401, loss: 0.434, 12832/28000 datapoints
2025-03-07 12:18:53,034 - INFO - training batch 451, loss: 0.423, 14432/28000 datapoints
2025-03-07 12:18:53,306 - INFO - training batch 501, loss: 0.159, 16032/28000 datapoints
2025-03-07 12:18:53,574 - INFO - training batch 551, loss: 0.303, 17632/28000 datapoints
2025-03-07 12:18:53,848 - INFO - training batch 601, loss: 0.422, 19232/28000 datapoints
2025-03-07 12:18:54,114 - INFO - training batch 651, loss: 0.112, 20832/28000 datapoints
2025-03-07 12:18:54,382 - INFO - training batch 701, loss: 0.358, 22432/28000 datapoints
2025-03-07 12:18:54,659 - INFO - training batch 751, loss: 0.172, 24032/28000 datapoints
2025-03-07 12:18:54,923 - INFO - training batch 801, loss: 0.259, 25632/28000 datapoints
2025-03-07 12:18:55,187 - INFO - training batch 851, loss: 0.431, 27232/28000 datapoints
2025-03-07 12:18:55,321 - INFO - validation batch 1, loss: 0.104, 32/6976 datapoints
2025-03-07 12:18:55,394 - INFO - validation batch 51, loss: 0.796, 1632/6976 datapoints
2025-03-07 12:18:55,478 - INFO - validation batch 101, loss: 0.219, 3232/6976 datapoints
2025-03-07 12:18:55,554 - INFO - validation batch 151, loss: 0.355, 4832/6976 datapoints
2025-03-07 12:18:55,629 - INFO - validation batch 201, loss: 0.428, 6432/6976 datapoints
2025-03-07 12:18:55,658 - INFO - Epoch 68/800 done.
2025-03-07 12:18:55,658 - INFO - Final validation performance:
Loss: 0.381, top-1 acc: 0.889top-5 acc: 0.889
2025-03-07 12:18:55,658 - INFO - Beginning epoch 69/800
2025-03-07 12:18:55,667 - INFO - training batch 1, loss: 0.260, 32/28000 datapoints
2025-03-07 12:18:55,935 - INFO - training batch 51, loss: 0.175, 1632/28000 datapoints
2025-03-07 12:18:56,211 - INFO - training batch 101, loss: 0.190, 3232/28000 datapoints
2025-03-07 12:18:56,492 - INFO - training batch 151, loss: 0.303, 4832/28000 datapoints
2025-03-07 12:18:56,772 - INFO - training batch 201, loss: 0.314, 6432/28000 datapoints
2025-03-07 12:18:57,051 - INFO - training batch 251, loss: 0.301, 8032/28000 datapoints
2025-03-07 12:18:57,323 - INFO - training batch 301, loss: 0.443, 9632/28000 datapoints
2025-03-07 12:18:57,626 - INFO - training batch 351, loss: 0.269, 11232/28000 datapoints
2025-03-07 12:18:57,902 - INFO - training batch 401, loss: 0.428, 12832/28000 datapoints
2025-03-07 12:18:58,217 - INFO - training batch 451, loss: 0.418, 14432/28000 datapoints
2025-03-07 12:18:58,574 - INFO - training batch 501, loss: 0.157, 16032/28000 datapoints
2025-03-07 12:18:58,859 - INFO - training batch 551, loss: 0.296, 17632/28000 datapoints
2025-03-07 12:18:59,130 - INFO - training batch 601, loss: 0.413, 19232/28000 datapoints
2025-03-07 12:18:59,414 - INFO - training batch 651, loss: 0.109, 20832/28000 datapoints
2025-03-07 12:18:59,697 - INFO - training batch 701, loss: 0.356, 22432/28000 datapoints
2025-03-07 12:18:59,967 - INFO - training batch 751, loss: 0.168, 24032/28000 datapoints
2025-03-07 12:19:00,241 - INFO - training batch 801, loss: 0.255, 25632/28000 datapoints
2025-03-07 12:19:00,537 - INFO - training batch 851, loss: 0.425, 27232/28000 datapoints
2025-03-07 12:19:00,673 - INFO - validation batch 1, loss: 0.102, 32/6976 datapoints
2025-03-07 12:19:00,749 - INFO - validation batch 51, loss: 0.792, 1632/6976 datapoints
2025-03-07 12:19:00,818 - INFO - validation batch 101, loss: 0.219, 3232/6976 datapoints
2025-03-07 12:19:00,889 - INFO - validation batch 151, loss: 0.351, 4832/6976 datapoints
2025-03-07 12:19:00,960 - INFO - validation batch 201, loss: 0.427, 6432/6976 datapoints
2025-03-07 12:19:00,983 - INFO - Epoch 69/800 done.
2025-03-07 12:19:00,983 - INFO - Final validation performance:
Loss: 0.378, top-1 acc: 0.889top-5 acc: 0.889
2025-03-07 12:19:00,984 - INFO - Beginning epoch 70/800
2025-03-07 12:19:00,991 - INFO - training batch 1, loss: 0.256, 32/28000 datapoints
2025-03-07 12:19:01,260 - INFO - training batch 51, loss: 0.172, 1632/28000 datapoints
2025-03-07 12:19:01,530 - INFO - training batch 101, loss: 0.187, 3232/28000 datapoints
2025-03-07 12:19:01,810 - INFO - training batch 151, loss: 0.297, 4832/28000 datapoints
2025-03-07 12:19:02,085 - INFO - training batch 201, loss: 0.309, 6432/28000 datapoints
2025-03-07 12:19:02,366 - INFO - training batch 251, loss: 0.297, 8032/28000 datapoints
2025-03-07 12:19:02,642 - INFO - training batch 301, loss: 0.441, 9632/28000 datapoints
2025-03-07 12:19:02,968 - INFO - training batch 351, loss: 0.265, 11232/28000 datapoints
2025-03-07 12:19:03,240 - INFO - training batch 401, loss: 0.422, 12832/28000 datapoints
2025-03-07 12:19:03,519 - INFO - training batch 451, loss: 0.413, 14432/28000 datapoints
2025-03-07 12:19:03,790 - INFO - training batch 501, loss: 0.155, 16032/28000 datapoints
2025-03-07 12:19:04,058 - INFO - training batch 551, loss: 0.289, 17632/28000 datapoints
2025-03-07 12:19:04,327 - INFO - training batch 601, loss: 0.404, 19232/28000 datapoints
2025-03-07 12:19:04,634 - INFO - training batch 651, loss: 0.106, 20832/28000 datapoints
2025-03-07 12:19:04,931 - INFO - training batch 701, loss: 0.353, 22432/28000 datapoints
2025-03-07 12:19:05,202 - INFO - training batch 751, loss: 0.165, 24032/28000 datapoints
2025-03-07 12:19:05,473 - INFO - training batch 801, loss: 0.251, 25632/28000 datapoints
2025-03-07 12:19:05,742 - INFO - training batch 851, loss: 0.420, 27232/28000 datapoints
2025-03-07 12:19:05,877 - INFO - validation batch 1, loss: 0.100, 32/6976 datapoints
2025-03-07 12:19:05,953 - INFO - validation batch 51, loss: 0.788, 1632/6976 datapoints
2025-03-07 12:19:06,034 - INFO - validation batch 101, loss: 0.218, 3232/6976 datapoints
2025-03-07 12:19:06,114 - INFO - validation batch 151, loss: 0.348, 4832/6976 datapoints
2025-03-07 12:19:06,193 - INFO - validation batch 201, loss: 0.425, 6432/6976 datapoints
2025-03-07 12:19:06,224 - INFO - Epoch 70/800 done.
2025-03-07 12:19:06,224 - INFO - Final validation performance:
Loss: 0.376, top-1 acc: 0.890top-5 acc: 0.890
2025-03-07 12:19:06,225 - INFO - Beginning epoch 71/800
2025-03-07 12:19:06,233 - INFO - training batch 1, loss: 0.253, 32/28000 datapoints
2025-03-07 12:19:06,524 - INFO - training batch 51, loss: 0.169, 1632/28000 datapoints
2025-03-07 12:19:06,809 - INFO - training batch 101, loss: 0.184, 3232/28000 datapoints
2025-03-07 12:19:07,103 - INFO - training batch 151, loss: 0.290, 4832/28000 datapoints
2025-03-07 12:19:07,381 - INFO - training batch 201, loss: 0.303, 6432/28000 datapoints
2025-03-07 12:19:07,698 - INFO - training batch 251, loss: 0.294, 8032/28000 datapoints
2025-03-07 12:19:07,988 - INFO - training batch 301, loss: 0.438, 9632/28000 datapoints
2025-03-07 12:19:08,265 - INFO - training batch 351, loss: 0.261, 11232/28000 datapoints
2025-03-07 12:19:08,599 - INFO - training batch 401, loss: 0.416, 12832/28000 datapoints
2025-03-07 12:19:09,060 - INFO - training batch 451, loss: 0.409, 14432/28000 datapoints
2025-03-07 12:19:09,376 - INFO - training batch 501, loss: 0.154, 16032/28000 datapoints
2025-03-07 12:19:09,657 - INFO - training batch 551, loss: 0.283, 17632/28000 datapoints
2025-03-07 12:19:09,942 - INFO - training batch 601, loss: 0.396, 19232/28000 datapoints
2025-03-07 12:19:10,222 - INFO - training batch 651, loss: 0.103, 20832/28000 datapoints
2025-03-07 12:19:10,515 - INFO - training batch 701, loss: 0.351, 22432/28000 datapoints
2025-03-07 12:19:10,794 - INFO - training batch 751, loss: 0.162, 24032/28000 datapoints
2025-03-07 12:19:11,077 - INFO - training batch 801, loss: 0.247, 25632/28000 datapoints
2025-03-07 12:19:11,353 - INFO - training batch 851, loss: 0.415, 27232/28000 datapoints
2025-03-07 12:19:11,493 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-07 12:19:11,570 - INFO - validation batch 51, loss: 0.785, 1632/6976 datapoints
2025-03-07 12:19:11,643 - INFO - validation batch 101, loss: 0.217, 3232/6976 datapoints
2025-03-07 12:19:11,718 - INFO - validation batch 151, loss: 0.344, 4832/6976 datapoints
2025-03-07 12:19:11,796 - INFO - validation batch 201, loss: 0.424, 6432/6976 datapoints
2025-03-07 12:19:11,823 - INFO - Epoch 71/800 done.
2025-03-07 12:19:11,824 - INFO - Final validation performance:
Loss: 0.374, top-1 acc: 0.891top-5 acc: 0.891
2025-03-07 12:19:11,824 - INFO - Beginning epoch 72/800
2025-03-07 12:19:11,831 - INFO - training batch 1, loss: 0.250, 32/28000 datapoints
2025-03-07 12:19:12,103 - INFO - training batch 51, loss: 0.167, 1632/28000 datapoints
2025-03-07 12:19:12,369 - INFO - training batch 101, loss: 0.182, 3232/28000 datapoints
2025-03-07 12:19:12,643 - INFO - training batch 151, loss: 0.284, 4832/28000 datapoints
2025-03-07 12:19:12,907 - INFO - training batch 201, loss: 0.298, 6432/28000 datapoints
2025-03-07 12:19:13,172 - INFO - training batch 251, loss: 0.290, 8032/28000 datapoints
2025-03-07 12:19:13,445 - INFO - training batch 301, loss: 0.436, 9632/28000 datapoints
2025-03-07 12:19:13,728 - INFO - training batch 351, loss: 0.257, 11232/28000 datapoints
2025-03-07 12:19:14,014 - INFO - training batch 401, loss: 0.410, 12832/28000 datapoints
2025-03-07 12:19:14,282 - INFO - training batch 451, loss: 0.404, 14432/28000 datapoints
2025-03-07 12:19:14,582 - INFO - training batch 501, loss: 0.152, 16032/28000 datapoints
2025-03-07 12:19:14,914 - INFO - training batch 551, loss: 0.277, 17632/28000 datapoints
2025-03-07 12:19:15,243 - INFO - training batch 601, loss: 0.389, 19232/28000 datapoints
2025-03-07 12:19:15,516 - INFO - training batch 651, loss: 0.100, 20832/28000 datapoints
2025-03-07 12:19:15,791 - INFO - training batch 701, loss: 0.349, 22432/28000 datapoints
2025-03-07 12:19:16,062 - INFO - training batch 751, loss: 0.160, 24032/28000 datapoints
2025-03-07 12:19:16,338 - INFO - training batch 801, loss: 0.243, 25632/28000 datapoints
2025-03-07 12:19:16,630 - INFO - training batch 851, loss: 0.410, 27232/28000 datapoints
2025-03-07 12:19:16,772 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-07 12:19:16,850 - INFO - validation batch 51, loss: 0.783, 1632/6976 datapoints
2025-03-07 12:19:16,925 - INFO - validation batch 101, loss: 0.216, 3232/6976 datapoints
2025-03-07 12:19:17,017 - INFO - validation batch 151, loss: 0.341, 4832/6976 datapoints
2025-03-07 12:19:17,126 - INFO - validation batch 201, loss: 0.423, 6432/6976 datapoints
2025-03-07 12:19:17,165 - INFO - Epoch 72/800 done.
2025-03-07 12:19:17,165 - INFO - Final validation performance:
Loss: 0.372, top-1 acc: 0.892top-5 acc: 0.892
2025-03-07 12:19:17,166 - INFO - Beginning epoch 73/800
2025-03-07 12:19:17,197 - INFO - training batch 1, loss: 0.247, 32/28000 datapoints
2025-03-07 12:19:17,521 - INFO - training batch 51, loss: 0.164, 1632/28000 datapoints
2025-03-07 12:19:17,838 - INFO - training batch 101, loss: 0.179, 3232/28000 datapoints
2025-03-07 12:19:18,144 - INFO - training batch 151, loss: 0.277, 4832/28000 datapoints
2025-03-07 12:19:18,447 - INFO - training batch 201, loss: 0.293, 6432/28000 datapoints
2025-03-07 12:19:18,815 - INFO - training batch 251, loss: 0.287, 8032/28000 datapoints
2025-03-07 12:19:19,130 - INFO - training batch 301, loss: 0.434, 9632/28000 datapoints
2025-03-07 12:19:19,460 - INFO - training batch 351, loss: 0.253, 11232/28000 datapoints
2025-03-07 12:19:19,787 - INFO - training batch 401, loss: 0.404, 12832/28000 datapoints
2025-03-07 12:19:20,107 - INFO - training batch 451, loss: 0.400, 14432/28000 datapoints
2025-03-07 12:19:20,428 - INFO - training batch 501, loss: 0.151, 16032/28000 datapoints
2025-03-07 12:19:20,755 - INFO - training batch 551, loss: 0.272, 17632/28000 datapoints
2025-03-07 12:19:21,061 - INFO - training batch 601, loss: 0.381, 19232/28000 datapoints
2025-03-07 12:19:21,361 - INFO - training batch 651, loss: 0.097, 20832/28000 datapoints
2025-03-07 12:19:21,657 - INFO - training batch 701, loss: 0.347, 22432/28000 datapoints
2025-03-07 12:19:21,938 - INFO - training batch 751, loss: 0.157, 24032/28000 datapoints
2025-03-07 12:19:22,225 - INFO - training batch 801, loss: 0.238, 25632/28000 datapoints
2025-03-07 12:19:22,510 - INFO - training batch 851, loss: 0.405, 27232/28000 datapoints
2025-03-07 12:19:22,652 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-07 12:19:22,731 - INFO - validation batch 51, loss: 0.780, 1632/6976 datapoints
2025-03-07 12:19:22,810 - INFO - validation batch 101, loss: 0.215, 3232/6976 datapoints
2025-03-07 12:19:22,887 - INFO - validation batch 151, loss: 0.337, 4832/6976 datapoints
2025-03-07 12:19:22,980 - INFO - validation batch 201, loss: 0.421, 6432/6976 datapoints
2025-03-07 12:19:23,011 - INFO - Epoch 73/800 done.
2025-03-07 12:19:23,011 - INFO - Final validation performance:
Loss: 0.370, top-1 acc: 0.893top-5 acc: 0.893
2025-03-07 12:19:23,012 - INFO - Beginning epoch 74/800
2025-03-07 12:19:23,020 - INFO - training batch 1, loss: 0.244, 32/28000 datapoints
2025-03-07 12:19:23,304 - INFO - training batch 51, loss: 0.162, 1632/28000 datapoints
2025-03-07 12:19:23,657 - INFO - training batch 101, loss: 0.177, 3232/28000 datapoints
2025-03-07 12:19:23,943 - INFO - training batch 151, loss: 0.271, 4832/28000 datapoints
2025-03-07 12:19:24,218 - INFO - training batch 201, loss: 0.287, 6432/28000 datapoints
2025-03-07 12:19:24,491 - INFO - training batch 251, loss: 0.283, 8032/28000 datapoints
2025-03-07 12:19:24,761 - INFO - training batch 301, loss: 0.432, 9632/28000 datapoints
2025-03-07 12:19:25,035 - INFO - training batch 351, loss: 0.249, 11232/28000 datapoints
2025-03-07 12:19:25,310 - INFO - training batch 401, loss: 0.398, 12832/28000 datapoints
2025-03-07 12:19:25,588 - INFO - training batch 451, loss: 0.396, 14432/28000 datapoints
2025-03-07 12:19:25,858 - INFO - training batch 501, loss: 0.149, 16032/28000 datapoints
2025-03-07 12:19:26,134 - INFO - training batch 551, loss: 0.266, 17632/28000 datapoints
2025-03-07 12:19:26,412 - INFO - training batch 601, loss: 0.373, 19232/28000 datapoints
2025-03-07 12:19:26,702 - INFO - training batch 651, loss: 0.095, 20832/28000 datapoints
2025-03-07 12:19:26,978 - INFO - training batch 701, loss: 0.345, 22432/28000 datapoints
2025-03-07 12:19:27,255 - INFO - training batch 751, loss: 0.154, 24032/28000 datapoints
2025-03-07 12:19:27,531 - INFO - training batch 801, loss: 0.234, 25632/28000 datapoints
2025-03-07 12:19:27,812 - INFO - training batch 851, loss: 0.401, 27232/28000 datapoints
2025-03-07 12:19:27,970 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-07 12:19:28,042 - INFO - validation batch 51, loss: 0.777, 1632/6976 datapoints
2025-03-07 12:19:28,115 - INFO - validation batch 101, loss: 0.214, 3232/6976 datapoints
2025-03-07 12:19:28,190 - INFO - validation batch 151, loss: 0.332, 4832/6976 datapoints
2025-03-07 12:19:28,264 - INFO - validation batch 201, loss: 0.419, 6432/6976 datapoints
2025-03-07 12:19:28,288 - INFO - Epoch 74/800 done.
2025-03-07 12:19:28,288 - INFO - Final validation performance:
Loss: 0.367, top-1 acc: 0.894top-5 acc: 0.894
2025-03-07 12:19:28,289 - INFO - Beginning epoch 75/800
2025-03-07 12:19:28,297 - INFO - training batch 1, loss: 0.242, 32/28000 datapoints
2025-03-07 12:19:28,583 - INFO - training batch 51, loss: 0.160, 1632/28000 datapoints
2025-03-07 12:19:28,909 - INFO - training batch 101, loss: 0.175, 3232/28000 datapoints
2025-03-07 12:19:29,295 - INFO - training batch 151, loss: 0.265, 4832/28000 datapoints
2025-03-07 12:19:29,624 - INFO - training batch 201, loss: 0.281, 6432/28000 datapoints
2025-03-07 12:19:29,908 - INFO - training batch 251, loss: 0.280, 8032/28000 datapoints
2025-03-07 12:19:30,194 - INFO - training batch 301, loss: 0.429, 9632/28000 datapoints
2025-03-07 12:19:30,526 - INFO - training batch 351, loss: 0.246, 11232/28000 datapoints
2025-03-07 12:19:30,812 - INFO - training batch 401, loss: 0.392, 12832/28000 datapoints
2025-03-07 12:19:31,102 - INFO - training batch 451, loss: 0.391, 14432/28000 datapoints
2025-03-07 12:19:31,405 - INFO - training batch 501, loss: 0.148, 16032/28000 datapoints
2025-03-07 12:19:31,694 - INFO - training batch 551, loss: 0.260, 17632/28000 datapoints
2025-03-07 12:19:31,981 - INFO - training batch 601, loss: 0.365, 19232/28000 datapoints
2025-03-07 12:19:32,259 - INFO - training batch 651, loss: 0.092, 20832/28000 datapoints
2025-03-07 12:19:32,538 - INFO - training batch 701, loss: 0.342, 22432/28000 datapoints
2025-03-07 12:19:32,823 - INFO - training batch 751, loss: 0.152, 24032/28000 datapoints
2025-03-07 12:19:33,098 - INFO - training batch 801, loss: 0.230, 25632/28000 datapoints
2025-03-07 12:19:33,377 - INFO - training batch 851, loss: 0.396, 27232/28000 datapoints
2025-03-07 12:19:33,516 - INFO - validation batch 1, loss: 0.091, 32/6976 datapoints
2025-03-07 12:19:33,590 - INFO - validation batch 51, loss: 0.775, 1632/6976 datapoints
2025-03-07 12:19:33,670 - INFO - validation batch 101, loss: 0.213, 3232/6976 datapoints
2025-03-07 12:19:33,745 - INFO - validation batch 151, loss: 0.328, 4832/6976 datapoints
2025-03-07 12:19:33,820 - INFO - validation batch 201, loss: 0.417, 6432/6976 datapoints
2025-03-07 12:19:33,844 - INFO - Epoch 75/800 done.
2025-03-07 12:19:33,844 - INFO - Final validation performance:
Loss: 0.365, top-1 acc: 0.894top-5 acc: 0.894
2025-03-07 12:19:33,845 - INFO - Beginning epoch 76/800
2025-03-07 12:19:33,852 - INFO - training batch 1, loss: 0.239, 32/28000 datapoints
2025-03-07 12:19:34,135 - INFO - training batch 51, loss: 0.158, 1632/28000 datapoints
2025-03-07 12:19:34,418 - INFO - training batch 101, loss: 0.172, 3232/28000 datapoints
2025-03-07 12:19:34,703 - INFO - training batch 151, loss: 0.259, 4832/28000 datapoints
2025-03-07 12:19:34,979 - INFO - training batch 201, loss: 0.276, 6432/28000 datapoints
2025-03-07 12:19:35,254 - INFO - training batch 251, loss: 0.276, 8032/28000 datapoints
2025-03-07 12:19:35,536 - INFO - training batch 301, loss: 0.426, 9632/28000 datapoints
2025-03-07 12:19:35,823 - INFO - training batch 351, loss: 0.242, 11232/28000 datapoints
2025-03-07 12:19:36,108 - INFO - training batch 401, loss: 0.386, 12832/28000 datapoints
2025-03-07 12:19:36,415 - INFO - training batch 451, loss: 0.387, 14432/28000 datapoints
2025-03-07 12:19:36,734 - INFO - training batch 501, loss: 0.147, 16032/28000 datapoints
2025-03-07 12:19:37,049 - INFO - training batch 551, loss: 0.255, 17632/28000 datapoints
2025-03-07 12:19:37,367 - INFO - training batch 601, loss: 0.357, 19232/28000 datapoints
2025-03-07 12:19:37,651 - INFO - training batch 651, loss: 0.090, 20832/28000 datapoints
2025-03-07 12:19:37,940 - INFO - training batch 701, loss: 0.340, 22432/28000 datapoints
2025-03-07 12:19:38,230 - INFO - training batch 751, loss: 0.150, 24032/28000 datapoints
2025-03-07 12:19:38,514 - INFO - training batch 801, loss: 0.226, 25632/28000 datapoints
2025-03-07 12:19:38,793 - INFO - training batch 851, loss: 0.390, 27232/28000 datapoints
2025-03-07 12:19:38,931 - INFO - validation batch 1, loss: 0.090, 32/6976 datapoints
2025-03-07 12:19:39,020 - INFO - validation batch 51, loss: 0.773, 1632/6976 datapoints
2025-03-07 12:19:39,123 - INFO - validation batch 101, loss: 0.212, 3232/6976 datapoints
2025-03-07 12:19:39,216 - INFO - validation batch 151, loss: 0.324, 4832/6976 datapoints
2025-03-07 12:19:39,294 - INFO - validation batch 201, loss: 0.415, 6432/6976 datapoints
2025-03-07 12:19:39,323 - INFO - Epoch 76/800 done.
2025-03-07 12:19:39,324 - INFO - Final validation performance:
Loss: 0.363, top-1 acc: 0.894top-5 acc: 0.894
2025-03-07 12:19:39,324 - INFO - Beginning epoch 77/800
2025-03-07 12:19:39,332 - INFO - training batch 1, loss: 0.236, 32/28000 datapoints
2025-03-07 12:19:39,631 - INFO - training batch 51, loss: 0.156, 1632/28000 datapoints
2025-03-07 12:19:39,921 - INFO - training batch 101, loss: 0.169, 3232/28000 datapoints
2025-03-07 12:19:40,206 - INFO - training batch 151, loss: 0.253, 4832/28000 datapoints
2025-03-07 12:19:40,497 - INFO - training batch 201, loss: 0.270, 6432/28000 datapoints
2025-03-07 12:19:40,782 - INFO - training batch 251, loss: 0.273, 8032/28000 datapoints
2025-03-07 12:19:41,067 - INFO - training batch 301, loss: 0.425, 9632/28000 datapoints
2025-03-07 12:19:41,351 - INFO - training batch 351, loss: 0.238, 11232/28000 datapoints
2025-03-07 12:19:41,662 - INFO - training batch 401, loss: 0.380, 12832/28000 datapoints
2025-03-07 12:19:41,942 - INFO - training batch 451, loss: 0.382, 14432/28000 datapoints
2025-03-07 12:19:42,220 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-07 12:19:42,512 - INFO - training batch 551, loss: 0.249, 17632/28000 datapoints
2025-03-07 12:19:42,794 - INFO - training batch 601, loss: 0.349, 19232/28000 datapoints
2025-03-07 12:19:43,131 - INFO - training batch 651, loss: 0.088, 20832/28000 datapoints
2025-03-07 12:19:43,408 - INFO - training batch 701, loss: 0.338, 22432/28000 datapoints
2025-03-07 12:19:43,690 - INFO - training batch 751, loss: 0.147, 24032/28000 datapoints
2025-03-07 12:19:43,967 - INFO - training batch 801, loss: 0.222, 25632/28000 datapoints
2025-03-07 12:19:44,247 - INFO - training batch 851, loss: 0.385, 27232/28000 datapoints
2025-03-07 12:19:44,385 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-07 12:19:44,461 - INFO - validation batch 51, loss: 0.771, 1632/6976 datapoints
2025-03-07 12:19:44,537 - INFO - validation batch 101, loss: 0.211, 3232/6976 datapoints
2025-03-07 12:19:44,612 - INFO - validation batch 151, loss: 0.320, 4832/6976 datapoints
2025-03-07 12:19:44,686 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-07 12:19:44,715 - INFO - Epoch 77/800 done.
2025-03-07 12:19:44,715 - INFO - Final validation performance:
Loss: 0.361, top-1 acc: 0.894top-5 acc: 0.894
2025-03-07 12:19:44,716 - INFO - Beginning epoch 78/800
2025-03-07 12:19:44,723 - INFO - training batch 1, loss: 0.233, 32/28000 datapoints
2025-03-07 12:19:45,004 - INFO - training batch 51, loss: 0.153, 1632/28000 datapoints
2025-03-07 12:19:45,282 - INFO - training batch 101, loss: 0.167, 3232/28000 datapoints
2025-03-07 12:19:45,560 - INFO - training batch 151, loss: 0.246, 4832/28000 datapoints
2025-03-07 12:19:45,838 - INFO - training batch 201, loss: 0.263, 6432/28000 datapoints
2025-03-07 12:19:46,112 - INFO - training batch 251, loss: 0.270, 8032/28000 datapoints
2025-03-07 12:19:46,390 - INFO - training batch 301, loss: 0.422, 9632/28000 datapoints
2025-03-07 12:19:46,690 - INFO - training batch 351, loss: 0.235, 11232/28000 datapoints
2025-03-07 12:19:46,966 - INFO - training batch 401, loss: 0.374, 12832/28000 datapoints
2025-03-07 12:19:47,239 - INFO - training batch 451, loss: 0.377, 14432/28000 datapoints
2025-03-07 12:19:47,516 - INFO - training batch 501, loss: 0.144, 16032/28000 datapoints
2025-03-07 12:19:47,797 - INFO - training batch 551, loss: 0.244, 17632/28000 datapoints
2025-03-07 12:19:48,095 - INFO - training batch 601, loss: 0.341, 19232/28000 datapoints
2025-03-07 12:19:48,377 - INFO - training batch 651, loss: 0.085, 20832/28000 datapoints
2025-03-07 12:19:48,653 - INFO - training batch 701, loss: 0.335, 22432/28000 datapoints
2025-03-07 12:19:48,930 - INFO - training batch 751, loss: 0.145, 24032/28000 datapoints
2025-03-07 12:19:49,224 - INFO - training batch 801, loss: 0.218, 25632/28000 datapoints
2025-03-07 12:19:49,616 - INFO - training batch 851, loss: 0.381, 27232/28000 datapoints
2025-03-07 12:19:49,787 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-07 12:19:49,899 - INFO - validation batch 51, loss: 0.769, 1632/6976 datapoints
2025-03-07 12:19:50,001 - INFO - validation batch 101, loss: 0.210, 3232/6976 datapoints
2025-03-07 12:19:50,110 - INFO - validation batch 151, loss: 0.318, 4832/6976 datapoints
2025-03-07 12:19:50,214 - INFO - validation batch 201, loss: 0.412, 6432/6976 datapoints
2025-03-07 12:19:50,248 - INFO - Epoch 78/800 done.
2025-03-07 12:19:50,248 - INFO - Final validation performance:
Loss: 0.359, top-1 acc: 0.895top-5 acc: 0.895
2025-03-07 12:19:50,249 - INFO - Beginning epoch 79/800
2025-03-07 12:19:50,258 - INFO - training batch 1, loss: 0.230, 32/28000 datapoints
2025-03-07 12:19:50,636 - INFO - training batch 51, loss: 0.151, 1632/28000 datapoints
2025-03-07 12:19:50,981 - INFO - training batch 101, loss: 0.165, 3232/28000 datapoints
2025-03-07 12:19:51,316 - INFO - training batch 151, loss: 0.240, 4832/28000 datapoints
2025-03-07 12:19:51,654 - INFO - training batch 201, loss: 0.258, 6432/28000 datapoints
2025-03-07 12:19:51,974 - INFO - training batch 251, loss: 0.267, 8032/28000 datapoints
2025-03-07 12:19:52,272 - INFO - training batch 301, loss: 0.419, 9632/28000 datapoints
2025-03-07 12:19:52,577 - INFO - training batch 351, loss: 0.231, 11232/28000 datapoints
2025-03-07 12:19:52,882 - INFO - training batch 401, loss: 0.368, 12832/28000 datapoints
2025-03-07 12:19:53,165 - INFO - training batch 451, loss: 0.372, 14432/28000 datapoints
2025-03-07 12:19:53,446 - INFO - training batch 501, loss: 0.143, 16032/28000 datapoints
2025-03-07 12:19:53,730 - INFO - training batch 551, loss: 0.239, 17632/28000 datapoints
2025-03-07 12:19:54,018 - INFO - training batch 601, loss: 0.334, 19232/28000 datapoints
2025-03-07 12:19:54,297 - INFO - training batch 651, loss: 0.083, 20832/28000 datapoints
2025-03-07 12:19:54,578 - INFO - training batch 701, loss: 0.333, 22432/28000 datapoints
2025-03-07 12:19:54,896 - INFO - training batch 751, loss: 0.143, 24032/28000 datapoints
2025-03-07 12:19:55,208 - INFO - training batch 801, loss: 0.214, 25632/28000 datapoints
2025-03-07 12:19:55,515 - INFO - training batch 851, loss: 0.376, 27232/28000 datapoints
2025-03-07 12:19:55,652 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-07 12:19:55,727 - INFO - validation batch 51, loss: 0.768, 1632/6976 datapoints
2025-03-07 12:19:55,801 - INFO - validation batch 101, loss: 0.209, 3232/6976 datapoints
2025-03-07 12:19:55,873 - INFO - validation batch 151, loss: 0.316, 4832/6976 datapoints
2025-03-07 12:19:55,946 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-07 12:19:55,974 - INFO - Epoch 79/800 done.
2025-03-07 12:19:55,974 - INFO - Final validation performance:
Loss: 0.358, top-1 acc: 0.895top-5 acc: 0.895
2025-03-07 12:19:55,974 - INFO - Beginning epoch 80/800
2025-03-07 12:19:55,982 - INFO - training batch 1, loss: 0.227, 32/28000 datapoints
2025-03-07 12:19:56,269 - INFO - training batch 51, loss: 0.149, 1632/28000 datapoints
2025-03-07 12:19:56,562 - INFO - training batch 101, loss: 0.163, 3232/28000 datapoints
2025-03-07 12:19:56,845 - INFO - training batch 151, loss: 0.234, 4832/28000 datapoints
2025-03-07 12:19:57,126 - INFO - training batch 201, loss: 0.252, 6432/28000 datapoints
2025-03-07 12:19:57,405 - INFO - training batch 251, loss: 0.264, 8032/28000 datapoints
2025-03-07 12:19:57,695 - INFO - training batch 301, loss: 0.416, 9632/28000 datapoints
2025-03-07 12:19:57,976 - INFO - training batch 351, loss: 0.226, 11232/28000 datapoints
2025-03-07 12:19:58,302 - INFO - training batch 401, loss: 0.361, 12832/28000 datapoints
2025-03-07 12:19:58,582 - INFO - training batch 451, loss: 0.367, 14432/28000 datapoints
2025-03-07 12:19:58,865 - INFO - training batch 501, loss: 0.141, 16032/28000 datapoints
2025-03-07 12:19:59,192 - INFO - training batch 551, loss: 0.234, 17632/28000 datapoints
2025-03-07 12:19:59,516 - INFO - training batch 601, loss: 0.325, 19232/28000 datapoints
2025-03-07 12:19:59,829 - INFO - training batch 651, loss: 0.081, 20832/28000 datapoints
2025-03-07 12:20:00,118 - INFO - training batch 701, loss: 0.330, 22432/28000 datapoints
2025-03-07 12:20:00,410 - INFO - training batch 751, loss: 0.141, 24032/28000 datapoints
2025-03-07 12:20:00,726 - INFO - training batch 801, loss: 0.210, 25632/28000 datapoints
2025-03-07 12:20:01,013 - INFO - training batch 851, loss: 0.371, 27232/28000 datapoints
2025-03-07 12:20:01,159 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-07 12:20:01,234 - INFO - validation batch 51, loss: 0.765, 1632/6976 datapoints
2025-03-07 12:20:01,313 - INFO - validation batch 101, loss: 0.208, 3232/6976 datapoints
2025-03-07 12:20:01,390 - INFO - validation batch 151, loss: 0.314, 4832/6976 datapoints
2025-03-07 12:20:01,470 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-07 12:20:01,494 - INFO - Epoch 80/800 done.
2025-03-07 12:20:01,494 - INFO - Final validation performance:
Loss: 0.356, top-1 acc: 0.895top-5 acc: 0.895
2025-03-07 12:20:01,495 - INFO - Beginning epoch 81/800
2025-03-07 12:20:01,502 - INFO - training batch 1, loss: 0.225, 32/28000 datapoints
2025-03-07 12:20:01,808 - INFO - training batch 51, loss: 0.148, 1632/28000 datapoints
2025-03-07 12:20:02,087 - INFO - training batch 101, loss: 0.160, 3232/28000 datapoints
2025-03-07 12:20:02,365 - INFO - training batch 151, loss: 0.228, 4832/28000 datapoints
2025-03-07 12:20:02,653 - INFO - training batch 201, loss: 0.245, 6432/28000 datapoints
2025-03-07 12:20:02,951 - INFO - training batch 251, loss: 0.261, 8032/28000 datapoints
2025-03-07 12:20:03,232 - INFO - training batch 301, loss: 0.413, 9632/28000 datapoints
2025-03-07 12:20:03,536 - INFO - training batch 351, loss: 0.223, 11232/28000 datapoints
2025-03-07 12:20:03,818 - INFO - training batch 401, loss: 0.355, 12832/28000 datapoints
2025-03-07 12:20:04,097 - INFO - training batch 451, loss: 0.363, 14432/28000 datapoints
2025-03-07 12:20:04,385 - INFO - training batch 501, loss: 0.140, 16032/28000 datapoints
2025-03-07 12:20:04,696 - INFO - training batch 551, loss: 0.229, 17632/28000 datapoints
2025-03-07 12:20:05,039 - INFO - training batch 601, loss: 0.317, 19232/28000 datapoints
2025-03-07 12:20:05,338 - INFO - training batch 651, loss: 0.079, 20832/28000 datapoints
2025-03-07 12:20:05,627 - INFO - training batch 701, loss: 0.328, 22432/28000 datapoints
2025-03-07 12:20:05,904 - INFO - training batch 751, loss: 0.139, 24032/28000 datapoints
2025-03-07 12:20:06,182 - INFO - training batch 801, loss: 0.207, 25632/28000 datapoints
2025-03-07 12:20:06,486 - INFO - training batch 851, loss: 0.367, 27232/28000 datapoints
2025-03-07 12:20:06,636 - INFO - validation batch 1, loss: 0.083, 32/6976 datapoints
2025-03-07 12:20:06,713 - INFO - validation batch 51, loss: 0.764, 1632/6976 datapoints
2025-03-07 12:20:06,789 - INFO - validation batch 101, loss: 0.206, 3232/6976 datapoints
2025-03-07 12:20:06,862 - INFO - validation batch 151, loss: 0.311, 4832/6976 datapoints
2025-03-07 12:20:06,935 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-07 12:20:06,961 - INFO - Epoch 81/800 done.
2025-03-07 12:20:06,961 - INFO - Final validation performance:
Loss: 0.354, top-1 acc: 0.896top-5 acc: 0.896
2025-03-07 12:20:06,961 - INFO - Beginning epoch 82/800
2025-03-07 12:20:06,970 - INFO - training batch 1, loss: 0.222, 32/28000 datapoints
2025-03-07 12:20:07,249 - INFO - training batch 51, loss: 0.146, 1632/28000 datapoints
2025-03-07 12:20:07,533 - INFO - training batch 101, loss: 0.158, 3232/28000 datapoints
2025-03-07 12:20:07,846 - INFO - training batch 151, loss: 0.223, 4832/28000 datapoints
2025-03-07 12:20:08,127 - INFO - training batch 201, loss: 0.239, 6432/28000 datapoints
2025-03-07 12:20:08,444 - INFO - training batch 251, loss: 0.258, 8032/28000 datapoints
2025-03-07 12:20:08,729 - INFO - training batch 301, loss: 0.410, 9632/28000 datapoints
2025-03-07 12:20:09,045 - INFO - training batch 351, loss: 0.219, 11232/28000 datapoints
2025-03-07 12:20:09,332 - INFO - training batch 401, loss: 0.349, 12832/28000 datapoints
2025-03-07 12:20:09,675 - INFO - training batch 451, loss: 0.357, 14432/28000 datapoints
2025-03-07 12:20:10,114 - INFO - training batch 501, loss: 0.138, 16032/28000 datapoints
2025-03-07 12:20:10,445 - INFO - training batch 551, loss: 0.225, 17632/28000 datapoints
2025-03-07 12:20:10,729 - INFO - training batch 601, loss: 0.310, 19232/28000 datapoints
2025-03-07 12:20:11,031 - INFO - training batch 651, loss: 0.077, 20832/28000 datapoints
2025-03-07 12:20:11,315 - INFO - training batch 701, loss: 0.325, 22432/28000 datapoints
2025-03-07 12:20:11,614 - INFO - training batch 751, loss: 0.137, 24032/28000 datapoints
2025-03-07 12:20:11,941 - INFO - training batch 801, loss: 0.203, 25632/28000 datapoints
2025-03-07 12:20:12,244 - INFO - training batch 851, loss: 0.362, 27232/28000 datapoints
2025-03-07 12:20:12,388 - INFO - validation batch 1, loss: 0.082, 32/6976 datapoints
2025-03-07 12:20:12,462 - INFO - validation batch 51, loss: 0.761, 1632/6976 datapoints
2025-03-07 12:20:12,564 - INFO - validation batch 101, loss: 0.205, 3232/6976 datapoints
2025-03-07 12:20:12,639 - INFO - validation batch 151, loss: 0.308, 4832/6976 datapoints
2025-03-07 12:20:12,715 - INFO - validation batch 201, loss: 0.406, 6432/6976 datapoints
2025-03-07 12:20:12,741 - INFO - Epoch 82/800 done.
2025-03-07 12:20:12,741 - INFO - Final validation performance:
Loss: 0.352, top-1 acc: 0.897top-5 acc: 0.897
2025-03-07 12:20:12,742 - INFO - Beginning epoch 83/800
2025-03-07 12:20:12,749 - INFO - training batch 1, loss: 0.219, 32/28000 datapoints
2025-03-07 12:20:13,104 - INFO - training batch 51, loss: 0.145, 1632/28000 datapoints
2025-03-07 12:20:13,490 - INFO - training batch 101, loss: 0.155, 3232/28000 datapoints
2025-03-07 12:20:13,819 - INFO - training batch 151, loss: 0.217, 4832/28000 datapoints
2025-03-07 12:20:14,099 - INFO - training batch 201, loss: 0.234, 6432/28000 datapoints
2025-03-07 12:20:14,384 - INFO - training batch 251, loss: 0.255, 8032/28000 datapoints
2025-03-07 12:20:14,669 - INFO - training batch 301, loss: 0.407, 9632/28000 datapoints
2025-03-07 12:20:15,047 - INFO - training batch 351, loss: 0.216, 11232/28000 datapoints
2025-03-07 12:20:15,374 - INFO - training batch 401, loss: 0.343, 12832/28000 datapoints
2025-03-07 12:20:15,665 - INFO - training batch 451, loss: 0.352, 14432/28000 datapoints
2025-03-07 12:20:15,952 - INFO - training batch 501, loss: 0.137, 16032/28000 datapoints
2025-03-07 12:20:16,241 - INFO - training batch 551, loss: 0.220, 17632/28000 datapoints
2025-03-07 12:20:16,533 - INFO - training batch 601, loss: 0.302, 19232/28000 datapoints
2025-03-07 12:20:16,835 - INFO - training batch 651, loss: 0.075, 20832/28000 datapoints
2025-03-07 12:20:17,120 - INFO - training batch 701, loss: 0.322, 22432/28000 datapoints
2025-03-07 12:20:17,406 - INFO - training batch 751, loss: 0.135, 24032/28000 datapoints
2025-03-07 12:20:17,692 - INFO - training batch 801, loss: 0.199, 25632/28000 datapoints
2025-03-07 12:20:17,978 - INFO - training batch 851, loss: 0.357, 27232/28000 datapoints
2025-03-07 12:20:18,116 - INFO - validation batch 1, loss: 0.081, 32/6976 datapoints
2025-03-07 12:20:18,210 - INFO - validation batch 51, loss: 0.760, 1632/6976 datapoints
2025-03-07 12:20:18,309 - INFO - validation batch 101, loss: 0.204, 3232/6976 datapoints
2025-03-07 12:20:18,410 - INFO - validation batch 151, loss: 0.306, 4832/6976 datapoints
2025-03-07 12:20:18,486 - INFO - validation batch 201, loss: 0.404, 6432/6976 datapoints
2025-03-07 12:20:18,512 - INFO - Epoch 83/800 done.
2025-03-07 12:20:18,513 - INFO - Final validation performance:
Loss: 0.351, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:20:18,513 - INFO - Beginning epoch 84/800
2025-03-07 12:20:18,521 - INFO - training batch 1, loss: 0.216, 32/28000 datapoints
2025-03-07 12:20:18,808 - INFO - training batch 51, loss: 0.143, 1632/28000 datapoints
2025-03-07 12:20:19,083 - INFO - training batch 101, loss: 0.153, 3232/28000 datapoints
2025-03-07 12:20:19,365 - INFO - training batch 151, loss: 0.211, 4832/28000 datapoints
2025-03-07 12:20:19,654 - INFO - training batch 201, loss: 0.227, 6432/28000 datapoints
2025-03-07 12:20:19,980 - INFO - training batch 251, loss: 0.252, 8032/28000 datapoints
2025-03-07 12:20:20,258 - INFO - training batch 301, loss: 0.404, 9632/28000 datapoints
2025-03-07 12:20:20,584 - INFO - training batch 351, loss: 0.212, 11232/28000 datapoints
2025-03-07 12:20:20,910 - INFO - training batch 401, loss: 0.337, 12832/28000 datapoints
2025-03-07 12:20:21,240 - INFO - training batch 451, loss: 0.347, 14432/28000 datapoints
2025-03-07 12:20:21,610 - INFO - training batch 501, loss: 0.135, 16032/28000 datapoints
2025-03-07 12:20:21,935 - INFO - training batch 551, loss: 0.215, 17632/28000 datapoints
2025-03-07 12:20:22,254 - INFO - training batch 601, loss: 0.295, 19232/28000 datapoints
2025-03-07 12:20:22,578 - INFO - training batch 651, loss: 0.073, 20832/28000 datapoints
2025-03-07 12:20:22,898 - INFO - training batch 701, loss: 0.319, 22432/28000 datapoints
2025-03-07 12:20:23,185 - INFO - training batch 751, loss: 0.133, 24032/28000 datapoints
2025-03-07 12:20:23,477 - INFO - training batch 801, loss: 0.195, 25632/28000 datapoints
2025-03-07 12:20:23,765 - INFO - training batch 851, loss: 0.352, 27232/28000 datapoints
2025-03-07 12:20:23,905 - INFO - validation batch 1, loss: 0.080, 32/6976 datapoints
2025-03-07 12:20:23,976 - INFO - validation batch 51, loss: 0.759, 1632/6976 datapoints
2025-03-07 12:20:24,047 - INFO - validation batch 101, loss: 0.204, 3232/6976 datapoints
2025-03-07 12:20:24,118 - INFO - validation batch 151, loss: 0.304, 4832/6976 datapoints
2025-03-07 12:20:24,190 - INFO - validation batch 201, loss: 0.403, 6432/6976 datapoints
2025-03-07 12:20:24,216 - INFO - Epoch 84/800 done.
2025-03-07 12:20:24,216 - INFO - Final validation performance:
Loss: 0.350, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:20:24,217 - INFO - Beginning epoch 85/800
2025-03-07 12:20:24,224 - INFO - training batch 1, loss: 0.214, 32/28000 datapoints
2025-03-07 12:20:24,514 - INFO - training batch 51, loss: 0.141, 1632/28000 datapoints
2025-03-07 12:20:24,801 - INFO - training batch 101, loss: 0.151, 3232/28000 datapoints
2025-03-07 12:20:25,083 - INFO - training batch 151, loss: 0.206, 4832/28000 datapoints
2025-03-07 12:20:25,365 - INFO - training batch 201, loss: 0.222, 6432/28000 datapoints
2025-03-07 12:20:25,648 - INFO - training batch 251, loss: 0.250, 8032/28000 datapoints
2025-03-07 12:20:25,926 - INFO - training batch 301, loss: 0.400, 9632/28000 datapoints
2025-03-07 12:20:26,207 - INFO - training batch 351, loss: 0.208, 11232/28000 datapoints
2025-03-07 12:20:26,504 - INFO - training batch 401, loss: 0.331, 12832/28000 datapoints
2025-03-07 12:20:26,795 - INFO - training batch 451, loss: 0.341, 14432/28000 datapoints
2025-03-07 12:20:27,104 - INFO - training batch 501, loss: 0.134, 16032/28000 datapoints
2025-03-07 12:20:27,383 - INFO - training batch 551, loss: 0.211, 17632/28000 datapoints
2025-03-07 12:20:27,660 - INFO - training batch 601, loss: 0.287, 19232/28000 datapoints
2025-03-07 12:20:27,944 - INFO - training batch 651, loss: 0.072, 20832/28000 datapoints
2025-03-07 12:20:28,220 - INFO - training batch 701, loss: 0.316, 22432/28000 datapoints
2025-03-07 12:20:28,525 - INFO - training batch 751, loss: 0.132, 24032/28000 datapoints
2025-03-07 12:20:28,803 - INFO - training batch 801, loss: 0.192, 25632/28000 datapoints
2025-03-07 12:20:29,082 - INFO - training batch 851, loss: 0.347, 27232/28000 datapoints
2025-03-07 12:20:29,228 - INFO - validation batch 1, loss: 0.078, 32/6976 datapoints
2025-03-07 12:20:29,299 - INFO - validation batch 51, loss: 0.758, 1632/6976 datapoints
2025-03-07 12:20:29,367 - INFO - validation batch 101, loss: 0.203, 3232/6976 datapoints
2025-03-07 12:20:29,437 - INFO - validation batch 151, loss: 0.302, 4832/6976 datapoints
2025-03-07 12:20:29,508 - INFO - validation batch 201, loss: 0.401, 6432/6976 datapoints
2025-03-07 12:20:29,532 - INFO - Epoch 85/800 done.
2025-03-07 12:20:29,532 - INFO - Final validation performance:
Loss: 0.348, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:20:29,533 - INFO - Beginning epoch 86/800
2025-03-07 12:20:29,541 - INFO - training batch 1, loss: 0.211, 32/28000 datapoints
2025-03-07 12:20:29,833 - INFO - training batch 51, loss: 0.140, 1632/28000 datapoints
2025-03-07 12:20:30,175 - INFO - training batch 101, loss: 0.148, 3232/28000 datapoints
2025-03-07 12:20:30,612 - INFO - training batch 151, loss: 0.200, 4832/28000 datapoints
2025-03-07 12:20:30,948 - INFO - training batch 201, loss: 0.216, 6432/28000 datapoints
2025-03-07 12:20:31,271 - INFO - training batch 251, loss: 0.246, 8032/28000 datapoints
2025-03-07 12:20:31,636 - INFO - training batch 301, loss: 0.397, 9632/28000 datapoints
2025-03-07 12:20:31,974 - INFO - training batch 351, loss: 0.205, 11232/28000 datapoints
2025-03-07 12:20:32,283 - INFO - training batch 401, loss: 0.325, 12832/28000 datapoints
2025-03-07 12:20:32,608 - INFO - training batch 451, loss: 0.336, 14432/28000 datapoints
2025-03-07 12:20:32,912 - INFO - training batch 501, loss: 0.133, 16032/28000 datapoints
2025-03-07 12:20:33,204 - INFO - training batch 551, loss: 0.207, 17632/28000 datapoints
2025-03-07 12:20:33,498 - INFO - training batch 601, loss: 0.280, 19232/28000 datapoints
2025-03-07 12:20:33,800 - INFO - training batch 651, loss: 0.070, 20832/28000 datapoints
2025-03-07 12:20:34,100 - INFO - training batch 701, loss: 0.314, 22432/28000 datapoints
2025-03-07 12:20:34,391 - INFO - training batch 751, loss: 0.130, 24032/28000 datapoints
2025-03-07 12:20:34,690 - INFO - training batch 801, loss: 0.188, 25632/28000 datapoints
2025-03-07 12:20:34,979 - INFO - training batch 851, loss: 0.342, 27232/28000 datapoints
2025-03-07 12:20:35,120 - INFO - validation batch 1, loss: 0.078, 32/6976 datapoints
2025-03-07 12:20:35,195 - INFO - validation batch 51, loss: 0.757, 1632/6976 datapoints
2025-03-07 12:20:35,270 - INFO - validation batch 101, loss: 0.201, 3232/6976 datapoints
2025-03-07 12:20:35,344 - INFO - validation batch 151, loss: 0.299, 4832/6976 datapoints
2025-03-07 12:20:35,419 - INFO - validation batch 201, loss: 0.400, 6432/6976 datapoints
2025-03-07 12:20:35,447 - INFO - Epoch 86/800 done.
2025-03-07 12:20:35,447 - INFO - Final validation performance:
Loss: 0.347, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:20:35,448 - INFO - Beginning epoch 87/800
2025-03-07 12:20:35,457 - INFO - training batch 1, loss: 0.207, 32/28000 datapoints
2025-03-07 12:20:35,782 - INFO - training batch 51, loss: 0.138, 1632/28000 datapoints
2025-03-07 12:20:36,076 - INFO - training batch 101, loss: 0.146, 3232/28000 datapoints
2025-03-07 12:20:36,352 - INFO - training batch 151, loss: 0.194, 4832/28000 datapoints
2025-03-07 12:20:36,633 - INFO - training batch 201, loss: 0.210, 6432/28000 datapoints
2025-03-07 12:20:36,922 - INFO - training batch 251, loss: 0.244, 8032/28000 datapoints
2025-03-07 12:20:37,216 - INFO - training batch 301, loss: 0.394, 9632/28000 datapoints
2025-03-07 12:20:37,517 - INFO - training batch 351, loss: 0.202, 11232/28000 datapoints
2025-03-07 12:20:37,815 - INFO - training batch 401, loss: 0.320, 12832/28000 datapoints
2025-03-07 12:20:38,182 - INFO - training batch 451, loss: 0.331, 14432/28000 datapoints
2025-03-07 12:20:38,847 - INFO - training batch 501, loss: 0.131, 16032/28000 datapoints
2025-03-07 12:20:39,152 - INFO - training batch 551, loss: 0.202, 17632/28000 datapoints
2025-03-07 12:20:39,443 - INFO - training batch 601, loss: 0.273, 19232/28000 datapoints
2025-03-07 12:20:39,733 - INFO - training batch 651, loss: 0.068, 20832/28000 datapoints
2025-03-07 12:20:40,049 - INFO - training batch 701, loss: 0.311, 22432/28000 datapoints
2025-03-07 12:20:40,403 - INFO - training batch 751, loss: 0.128, 24032/28000 datapoints
2025-03-07 12:20:40,822 - INFO - training batch 801, loss: 0.184, 25632/28000 datapoints
2025-03-07 12:20:41,211 - INFO - training batch 851, loss: 0.337, 27232/28000 datapoints
2025-03-07 12:20:41,365 - INFO - validation batch 1, loss: 0.077, 32/6976 datapoints
2025-03-07 12:20:41,466 - INFO - validation batch 51, loss: 0.757, 1632/6976 datapoints
2025-03-07 12:20:41,564 - INFO - validation batch 101, loss: 0.200, 3232/6976 datapoints
2025-03-07 12:20:41,662 - INFO - validation batch 151, loss: 0.298, 4832/6976 datapoints
2025-03-07 12:20:41,776 - INFO - validation batch 201, loss: 0.399, 6432/6976 datapoints
2025-03-07 12:20:41,807 - INFO - Epoch 87/800 done.
2025-03-07 12:20:41,808 - INFO - Final validation performance:
Loss: 0.346, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:20:41,810 - INFO - Beginning epoch 88/800
2025-03-07 12:20:41,820 - INFO - training batch 1, loss: 0.205, 32/28000 datapoints
2025-03-07 12:20:42,139 - INFO - training batch 51, loss: 0.137, 1632/28000 datapoints
2025-03-07 12:20:42,429 - INFO - training batch 101, loss: 0.144, 3232/28000 datapoints
2025-03-07 12:20:42,714 - INFO - training batch 151, loss: 0.188, 4832/28000 datapoints
2025-03-07 12:20:43,003 - INFO - training batch 201, loss: 0.204, 6432/28000 datapoints
2025-03-07 12:20:43,284 - INFO - training batch 251, loss: 0.240, 8032/28000 datapoints
2025-03-07 12:20:43,583 - INFO - training batch 301, loss: 0.391, 9632/28000 datapoints
2025-03-07 12:20:43,870 - INFO - training batch 351, loss: 0.199, 11232/28000 datapoints
2025-03-07 12:20:44,149 - INFO - training batch 401, loss: 0.314, 12832/28000 datapoints
2025-03-07 12:20:44,431 - INFO - training batch 451, loss: 0.325, 14432/28000 datapoints
2025-03-07 12:20:44,713 - INFO - training batch 501, loss: 0.130, 16032/28000 datapoints
2025-03-07 12:20:44,998 - INFO - training batch 551, loss: 0.198, 17632/28000 datapoints
2025-03-07 12:20:45,279 - INFO - training batch 601, loss: 0.266, 19232/28000 datapoints
2025-03-07 12:20:45,566 - INFO - training batch 651, loss: 0.067, 20832/28000 datapoints
2025-03-07 12:20:45,847 - INFO - training batch 701, loss: 0.309, 22432/28000 datapoints
2025-03-07 12:20:46,134 - INFO - training batch 751, loss: 0.127, 24032/28000 datapoints
2025-03-07 12:20:46,413 - INFO - training batch 801, loss: 0.180, 25632/28000 datapoints
2025-03-07 12:20:46,700 - INFO - training batch 851, loss: 0.332, 27232/28000 datapoints
2025-03-07 12:20:46,846 - INFO - validation batch 1, loss: 0.076, 32/6976 datapoints
2025-03-07 12:20:46,922 - INFO - validation batch 51, loss: 0.756, 1632/6976 datapoints
2025-03-07 12:20:46,998 - INFO - validation batch 101, loss: 0.199, 3232/6976 datapoints
2025-03-07 12:20:47,070 - INFO - validation batch 151, loss: 0.297, 4832/6976 datapoints
2025-03-07 12:20:47,142 - INFO - validation batch 201, loss: 0.397, 6432/6976 datapoints
2025-03-07 12:20:47,169 - INFO - Epoch 88/800 done.
2025-03-07 12:20:47,170 - INFO - Final validation performance:
Loss: 0.345, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:20:47,170 - INFO - Beginning epoch 89/800
2025-03-07 12:20:47,178 - INFO - training batch 1, loss: 0.202, 32/28000 datapoints
2025-03-07 12:20:47,462 - INFO - training batch 51, loss: 0.136, 1632/28000 datapoints
2025-03-07 12:20:47,745 - INFO - training batch 101, loss: 0.142, 3232/28000 datapoints
2025-03-07 12:20:48,028 - INFO - training batch 151, loss: 0.183, 4832/28000 datapoints
2025-03-07 12:20:48,305 - INFO - training batch 201, loss: 0.198, 6432/28000 datapoints
2025-03-07 12:20:48,585 - INFO - training batch 251, loss: 0.237, 8032/28000 datapoints
2025-03-07 12:20:48,888 - INFO - training batch 301, loss: 0.388, 9632/28000 datapoints
2025-03-07 12:20:49,168 - INFO - training batch 351, loss: 0.197, 11232/28000 datapoints
2025-03-07 12:20:49,452 - INFO - training batch 401, loss: 0.308, 12832/28000 datapoints
2025-03-07 12:20:49,921 - INFO - training batch 451, loss: 0.319, 14432/28000 datapoints
2025-03-07 12:20:50,199 - INFO - training batch 501, loss: 0.128, 16032/28000 datapoints
2025-03-07 12:20:50,523 - INFO - training batch 551, loss: 0.193, 17632/28000 datapoints
2025-03-07 12:20:50,922 - INFO - training batch 601, loss: 0.258, 19232/28000 datapoints
2025-03-07 12:20:51,469 - INFO - training batch 651, loss: 0.065, 20832/28000 datapoints
2025-03-07 12:20:51,816 - INFO - training batch 701, loss: 0.306, 22432/28000 datapoints
2025-03-07 12:20:52,159 - INFO - training batch 751, loss: 0.125, 24032/28000 datapoints
2025-03-07 12:20:52,496 - INFO - training batch 801, loss: 0.177, 25632/28000 datapoints
2025-03-07 12:20:52,884 - INFO - training batch 851, loss: 0.326, 27232/28000 datapoints
2025-03-07 12:20:53,058 - INFO - validation batch 1, loss: 0.075, 32/6976 datapoints
2025-03-07 12:20:53,142 - INFO - validation batch 51, loss: 0.756, 1632/6976 datapoints
2025-03-07 12:20:53,228 - INFO - validation batch 101, loss: 0.198, 3232/6976 datapoints
2025-03-07 12:20:53,338 - INFO - validation batch 151, loss: 0.295, 4832/6976 datapoints
2025-03-07 12:20:53,464 - INFO - validation batch 201, loss: 0.395, 6432/6976 datapoints
2025-03-07 12:20:53,501 - INFO - Epoch 89/800 done.
2025-03-07 12:20:53,502 - INFO - Final validation performance:
Loss: 0.344, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:20:53,503 - INFO - Beginning epoch 90/800
2025-03-07 12:20:53,517 - INFO - training batch 1, loss: 0.199, 32/28000 datapoints
2025-03-07 12:20:53,850 - INFO - training batch 51, loss: 0.135, 1632/28000 datapoints
2025-03-07 12:20:54,148 - INFO - training batch 101, loss: 0.139, 3232/28000 datapoints
2025-03-07 12:20:54,441 - INFO - training batch 151, loss: 0.178, 4832/28000 datapoints
2025-03-07 12:20:54,723 - INFO - training batch 201, loss: 0.193, 6432/28000 datapoints
2025-03-07 12:20:55,006 - INFO - training batch 251, loss: 0.234, 8032/28000 datapoints
2025-03-07 12:20:55,285 - INFO - training batch 301, loss: 0.384, 9632/28000 datapoints
2025-03-07 12:20:55,566 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-07 12:20:55,848 - INFO - training batch 401, loss: 0.302, 12832/28000 datapoints
2025-03-07 12:20:56,145 - INFO - training batch 451, loss: 0.314, 14432/28000 datapoints
2025-03-07 12:20:56,430 - INFO - training batch 501, loss: 0.127, 16032/28000 datapoints
2025-03-07 12:20:56,714 - INFO - training batch 551, loss: 0.188, 17632/28000 datapoints
2025-03-07 12:20:56,998 - INFO - training batch 601, loss: 0.252, 19232/28000 datapoints
2025-03-07 12:20:57,275 - INFO - training batch 651, loss: 0.064, 20832/28000 datapoints
2025-03-07 12:20:57,553 - INFO - training batch 701, loss: 0.303, 22432/28000 datapoints
2025-03-07 12:20:57,854 - INFO - training batch 751, loss: 0.124, 24032/28000 datapoints
2025-03-07 12:20:58,150 - INFO - training batch 801, loss: 0.173, 25632/28000 datapoints
2025-03-07 12:20:58,427 - INFO - training batch 851, loss: 0.320, 27232/28000 datapoints
2025-03-07 12:20:58,565 - INFO - validation batch 1, loss: 0.074, 32/6976 datapoints
2025-03-07 12:20:58,636 - INFO - validation batch 51, loss: 0.756, 1632/6976 datapoints
2025-03-07 12:20:58,711 - INFO - validation batch 101, loss: 0.197, 3232/6976 datapoints
2025-03-07 12:20:58,807 - INFO - validation batch 151, loss: 0.294, 4832/6976 datapoints
2025-03-07 12:20:58,885 - INFO - validation batch 201, loss: 0.394, 6432/6976 datapoints
2025-03-07 12:20:58,909 - INFO - Epoch 90/800 done.
2025-03-07 12:20:58,909 - INFO - Final validation performance:
Loss: 0.343, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:20:58,909 - INFO - Beginning epoch 91/800
2025-03-07 12:20:58,919 - INFO - training batch 1, loss: 0.197, 32/28000 datapoints
2025-03-07 12:20:59,200 - INFO - training batch 51, loss: 0.134, 1632/28000 datapoints
2025-03-07 12:20:59,484 - INFO - training batch 101, loss: 0.137, 3232/28000 datapoints
2025-03-07 12:20:59,763 - INFO - training batch 151, loss: 0.173, 4832/28000 datapoints
2025-03-07 12:21:00,042 - INFO - training batch 201, loss: 0.187, 6432/28000 datapoints
2025-03-07 12:21:00,327 - INFO - training batch 251, loss: 0.231, 8032/28000 datapoints
2025-03-07 12:21:00,651 - INFO - training batch 301, loss: 0.381, 9632/28000 datapoints
2025-03-07 12:21:00,944 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-07 12:21:01,229 - INFO - training batch 401, loss: 0.297, 12832/28000 datapoints
2025-03-07 12:21:01,518 - INFO - training batch 451, loss: 0.309, 14432/28000 datapoints
2025-03-07 12:21:01,806 - INFO - training batch 501, loss: 0.126, 16032/28000 datapoints
2025-03-07 12:21:02,084 - INFO - training batch 551, loss: 0.184, 17632/28000 datapoints
2025-03-07 12:21:02,360 - INFO - training batch 601, loss: 0.245, 19232/28000 datapoints
2025-03-07 12:21:02,642 - INFO - training batch 651, loss: 0.062, 20832/28000 datapoints
2025-03-07 12:21:02,941 - INFO - training batch 701, loss: 0.300, 22432/28000 datapoints
2025-03-07 12:21:03,229 - INFO - training batch 751, loss: 0.122, 24032/28000 datapoints
2025-03-07 12:21:03,510 - INFO - training batch 801, loss: 0.170, 25632/28000 datapoints
2025-03-07 12:21:03,791 - INFO - training batch 851, loss: 0.314, 27232/28000 datapoints
2025-03-07 12:21:03,927 - INFO - validation batch 1, loss: 0.073, 32/6976 datapoints
2025-03-07 12:21:03,995 - INFO - validation batch 51, loss: 0.756, 1632/6976 datapoints
2025-03-07 12:21:04,062 - INFO - validation batch 101, loss: 0.196, 3232/6976 datapoints
2025-03-07 12:21:04,133 - INFO - validation batch 151, loss: 0.292, 4832/6976 datapoints
2025-03-07 12:21:04,209 - INFO - validation batch 201, loss: 0.393, 6432/6976 datapoints
2025-03-07 12:21:04,237 - INFO - Epoch 91/800 done.
2025-03-07 12:21:04,237 - INFO - Final validation performance:
Loss: 0.342, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:21:04,238 - INFO - Beginning epoch 92/800
2025-03-07 12:21:04,246 - INFO - training batch 1, loss: 0.194, 32/28000 datapoints
2025-03-07 12:21:04,534 - INFO - training batch 51, loss: 0.133, 1632/28000 datapoints
2025-03-07 12:21:04,813 - INFO - training batch 101, loss: 0.134, 3232/28000 datapoints
2025-03-07 12:21:05,093 - INFO - training batch 151, loss: 0.169, 4832/28000 datapoints
2025-03-07 12:21:05,368 - INFO - training batch 201, loss: 0.180, 6432/28000 datapoints
2025-03-07 12:21:05,653 - INFO - training batch 251, loss: 0.228, 8032/28000 datapoints
2025-03-07 12:21:05,934 - INFO - training batch 301, loss: 0.377, 9632/28000 datapoints
2025-03-07 12:21:06,215 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-07 12:21:06,500 - INFO - training batch 401, loss: 0.291, 12832/28000 datapoints
2025-03-07 12:21:06,822 - INFO - training batch 451, loss: 0.303, 14432/28000 datapoints
2025-03-07 12:21:07,119 - INFO - training batch 501, loss: 0.124, 16032/28000 datapoints
2025-03-07 12:21:07,402 - INFO - training batch 551, loss: 0.180, 17632/28000 datapoints
2025-03-07 12:21:07,683 - INFO - training batch 601, loss: 0.239, 19232/28000 datapoints
2025-03-07 12:21:07,967 - INFO - training batch 651, loss: 0.061, 20832/28000 datapoints
2025-03-07 12:21:08,247 - INFO - training batch 701, loss: 0.298, 22432/28000 datapoints
2025-03-07 12:21:08,525 - INFO - training batch 751, loss: 0.120, 24032/28000 datapoints
2025-03-07 12:21:08,804 - INFO - training batch 801, loss: 0.166, 25632/28000 datapoints
2025-03-07 12:21:09,107 - INFO - training batch 851, loss: 0.308, 27232/28000 datapoints
2025-03-07 12:21:09,248 - INFO - validation batch 1, loss: 0.073, 32/6976 datapoints
2025-03-07 12:21:09,322 - INFO - validation batch 51, loss: 0.757, 1632/6976 datapoints
2025-03-07 12:21:09,394 - INFO - validation batch 101, loss: 0.196, 3232/6976 datapoints
2025-03-07 12:21:09,467 - INFO - validation batch 151, loss: 0.291, 4832/6976 datapoints
2025-03-07 12:21:09,538 - INFO - validation batch 201, loss: 0.392, 6432/6976 datapoints
2025-03-07 12:21:09,563 - INFO - Epoch 92/800 done.
2025-03-07 12:21:09,563 - INFO - Final validation performance:
Loss: 0.342, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:21:09,564 - INFO - Beginning epoch 93/800
2025-03-07 12:21:09,572 - INFO - training batch 1, loss: 0.191, 32/28000 datapoints
2025-03-07 12:21:09,857 - INFO - training batch 51, loss: 0.131, 1632/28000 datapoints
2025-03-07 12:21:10,140 - INFO - training batch 101, loss: 0.132, 3232/28000 datapoints
2025-03-07 12:21:10,425 - INFO - training batch 151, loss: 0.164, 4832/28000 datapoints
2025-03-07 12:21:10,710 - INFO - training batch 201, loss: 0.175, 6432/28000 datapoints
2025-03-07 12:21:11,125 - INFO - training batch 251, loss: 0.225, 8032/28000 datapoints
2025-03-07 12:21:11,533 - INFO - training batch 301, loss: 0.373, 9632/28000 datapoints
2025-03-07 12:21:11,865 - INFO - training batch 351, loss: 0.186, 11232/28000 datapoints
2025-03-07 12:21:12,157 - INFO - training batch 401, loss: 0.284, 12832/28000 datapoints
2025-03-07 12:21:12,443 - INFO - training batch 451, loss: 0.298, 14432/28000 datapoints
2025-03-07 12:21:12,728 - INFO - training batch 501, loss: 0.123, 16032/28000 datapoints
2025-03-07 12:21:13,026 - INFO - training batch 551, loss: 0.176, 17632/28000 datapoints
2025-03-07 12:21:13,311 - INFO - training batch 601, loss: 0.233, 19232/28000 datapoints
2025-03-07 12:21:13,605 - INFO - training batch 651, loss: 0.059, 20832/28000 datapoints
2025-03-07 12:21:13,882 - INFO - training batch 701, loss: 0.295, 22432/28000 datapoints
2025-03-07 12:21:14,155 - INFO - training batch 751, loss: 0.119, 24032/28000 datapoints
2025-03-07 12:21:14,434 - INFO - training batch 801, loss: 0.162, 25632/28000 datapoints
2025-03-07 12:21:14,714 - INFO - training batch 851, loss: 0.302, 27232/28000 datapoints
2025-03-07 12:21:14,850 - INFO - validation batch 1, loss: 0.072, 32/6976 datapoints
2025-03-07 12:21:14,921 - INFO - validation batch 51, loss: 0.758, 1632/6976 datapoints
2025-03-07 12:21:14,993 - INFO - validation batch 101, loss: 0.195, 3232/6976 datapoints
2025-03-07 12:21:15,065 - INFO - validation batch 151, loss: 0.291, 4832/6976 datapoints
2025-03-07 12:21:15,135 - INFO - validation batch 201, loss: 0.391, 6432/6976 datapoints
2025-03-07 12:21:15,159 - INFO - Epoch 93/800 done.
2025-03-07 12:21:15,159 - INFO - Final validation performance:
Loss: 0.341, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:21:15,160 - INFO - Beginning epoch 94/800
2025-03-07 12:21:15,167 - INFO - training batch 1, loss: 0.188, 32/28000 datapoints
2025-03-07 12:21:15,448 - INFO - training batch 51, loss: 0.130, 1632/28000 datapoints
2025-03-07 12:21:15,739 - INFO - training batch 101, loss: 0.130, 3232/28000 datapoints
2025-03-07 12:21:16,016 - INFO - training batch 151, loss: 0.160, 4832/28000 datapoints
2025-03-07 12:21:16,327 - INFO - training batch 201, loss: 0.170, 6432/28000 datapoints
2025-03-07 12:21:16,668 - INFO - training batch 251, loss: 0.221, 8032/28000 datapoints
2025-03-07 12:21:17,002 - INFO - training batch 301, loss: 0.369, 9632/28000 datapoints
2025-03-07 12:21:17,286 - INFO - training batch 351, loss: 0.184, 11232/28000 datapoints
2025-03-07 12:21:17,573 - INFO - training batch 401, loss: 0.278, 12832/28000 datapoints
2025-03-07 12:21:17,859 - INFO - training batch 451, loss: 0.292, 14432/28000 datapoints
2025-03-07 12:21:18,137 - INFO - training batch 501, loss: 0.121, 16032/28000 datapoints
2025-03-07 12:21:18,422 - INFO - training batch 551, loss: 0.171, 17632/28000 datapoints
2025-03-07 12:21:18,704 - INFO - training batch 601, loss: 0.227, 19232/28000 datapoints
2025-03-07 12:21:19,008 - INFO - training batch 651, loss: 0.058, 20832/28000 datapoints
2025-03-07 12:21:19,297 - INFO - training batch 701, loss: 0.292, 22432/28000 datapoints
2025-03-07 12:21:19,582 - INFO - training batch 751, loss: 0.117, 24032/28000 datapoints
2025-03-07 12:21:19,862 - INFO - training batch 801, loss: 0.159, 25632/28000 datapoints
2025-03-07 12:21:20,142 - INFO - training batch 851, loss: 0.296, 27232/28000 datapoints
2025-03-07 12:21:20,280 - INFO - validation batch 1, loss: 0.071, 32/6976 datapoints
2025-03-07 12:21:20,354 - INFO - validation batch 51, loss: 0.758, 1632/6976 datapoints
2025-03-07 12:21:20,426 - INFO - validation batch 101, loss: 0.195, 3232/6976 datapoints
2025-03-07 12:21:20,500 - INFO - validation batch 151, loss: 0.290, 4832/6976 datapoints
2025-03-07 12:21:20,572 - INFO - validation batch 201, loss: 0.389, 6432/6976 datapoints
2025-03-07 12:21:20,596 - INFO - Epoch 94/800 done.
2025-03-07 12:21:20,596 - INFO - Final validation performance:
Loss: 0.340, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:21:20,597 - INFO - Beginning epoch 95/800
2025-03-07 12:21:20,604 - INFO - training batch 1, loss: 0.185, 32/28000 datapoints
2025-03-07 12:21:20,891 - INFO - training batch 51, loss: 0.129, 1632/28000 datapoints
2025-03-07 12:21:21,239 - INFO - training batch 101, loss: 0.127, 3232/28000 datapoints
2025-03-07 12:21:21,585 - INFO - training batch 151, loss: 0.156, 4832/28000 datapoints
2025-03-07 12:21:21,915 - INFO - training batch 201, loss: 0.166, 6432/28000 datapoints
2025-03-07 12:21:22,257 - INFO - training batch 251, loss: 0.218, 8032/28000 datapoints
2025-03-07 12:21:22,595 - INFO - training batch 301, loss: 0.366, 9632/28000 datapoints
2025-03-07 12:21:22,925 - INFO - training batch 351, loss: 0.181, 11232/28000 datapoints
2025-03-07 12:21:23,252 - INFO - training batch 401, loss: 0.272, 12832/28000 datapoints
2025-03-07 12:21:23,564 - INFO - training batch 451, loss: 0.287, 14432/28000 datapoints
2025-03-07 12:21:23,888 - INFO - training batch 501, loss: 0.119, 16032/28000 datapoints
2025-03-07 12:21:24,236 - INFO - training batch 551, loss: 0.167, 17632/28000 datapoints
2025-03-07 12:21:24,542 - INFO - training batch 601, loss: 0.220, 19232/28000 datapoints
2025-03-07 12:21:24,833 - INFO - training batch 651, loss: 0.057, 20832/28000 datapoints
2025-03-07 12:21:25,128 - INFO - training batch 701, loss: 0.289, 22432/28000 datapoints
2025-03-07 12:21:25,415 - INFO - training batch 751, loss: 0.116, 24032/28000 datapoints
2025-03-07 12:21:25,745 - INFO - training batch 801, loss: 0.155, 25632/28000 datapoints
2025-03-07 12:21:26,035 - INFO - training batch 851, loss: 0.289, 27232/28000 datapoints
2025-03-07 12:21:26,178 - INFO - validation batch 1, loss: 0.070, 32/6976 datapoints
2025-03-07 12:21:26,255 - INFO - validation batch 51, loss: 0.759, 1632/6976 datapoints
2025-03-07 12:21:26,333 - INFO - validation batch 101, loss: 0.194, 3232/6976 datapoints
2025-03-07 12:21:26,409 - INFO - validation batch 151, loss: 0.290, 4832/6976 datapoints
2025-03-07 12:21:26,488 - INFO - validation batch 201, loss: 0.387, 6432/6976 datapoints
2025-03-07 12:21:26,514 - INFO - Epoch 95/800 done.
2025-03-07 12:21:26,514 - INFO - Final validation performance:
Loss: 0.340, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:21:26,515 - INFO - Beginning epoch 96/800
2025-03-07 12:21:26,523 - INFO - training batch 1, loss: 0.183, 32/28000 datapoints
2025-03-07 12:21:26,817 - INFO - training batch 51, loss: 0.127, 1632/28000 datapoints
2025-03-07 12:21:27,109 - INFO - training batch 101, loss: 0.125, 3232/28000 datapoints
2025-03-07 12:21:27,384 - INFO - training batch 151, loss: 0.152, 4832/28000 datapoints
2025-03-07 12:21:27,662 - INFO - training batch 201, loss: 0.161, 6432/28000 datapoints
2025-03-07 12:21:27,948 - INFO - training batch 251, loss: 0.214, 8032/28000 datapoints
2025-03-07 12:21:28,224 - INFO - training batch 301, loss: 0.362, 9632/28000 datapoints
2025-03-07 12:21:28,508 - INFO - training batch 351, loss: 0.178, 11232/28000 datapoints
2025-03-07 12:21:28,785 - INFO - training batch 401, loss: 0.267, 12832/28000 datapoints
2025-03-07 12:21:29,099 - INFO - training batch 451, loss: 0.282, 14432/28000 datapoints
2025-03-07 12:21:29,388 - INFO - training batch 501, loss: 0.118, 16032/28000 datapoints
2025-03-07 12:21:29,668 - INFO - training batch 551, loss: 0.163, 17632/28000 datapoints
2025-03-07 12:21:29,973 - INFO - training batch 601, loss: 0.215, 19232/28000 datapoints
2025-03-07 12:21:30,247 - INFO - training batch 651, loss: 0.055, 20832/28000 datapoints
2025-03-07 12:21:30,630 - INFO - training batch 701, loss: 0.287, 22432/28000 datapoints
2025-03-07 12:21:30,911 - INFO - training batch 751, loss: 0.115, 24032/28000 datapoints
2025-03-07 12:21:31,224 - INFO - training batch 801, loss: 0.152, 25632/28000 datapoints
2025-03-07 12:21:31,601 - INFO - training batch 851, loss: 0.283, 27232/28000 datapoints
2025-03-07 12:21:31,787 - INFO - validation batch 1, loss: 0.070, 32/6976 datapoints
2025-03-07 12:21:31,868 - INFO - validation batch 51, loss: 0.760, 1632/6976 datapoints
2025-03-07 12:21:31,952 - INFO - validation batch 101, loss: 0.193, 3232/6976 datapoints
2025-03-07 12:21:32,028 - INFO - validation batch 151, loss: 0.289, 4832/6976 datapoints
2025-03-07 12:21:32,101 - INFO - validation batch 201, loss: 0.385, 6432/6976 datapoints
2025-03-07 12:21:32,125 - INFO - Epoch 96/800 done.
2025-03-07 12:21:32,126 - INFO - Final validation performance:
Loss: 0.339, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:21:32,126 - INFO - Beginning epoch 97/800
2025-03-07 12:21:32,134 - INFO - training batch 1, loss: 0.180, 32/28000 datapoints
2025-03-07 12:21:32,415 - INFO - training batch 51, loss: 0.127, 1632/28000 datapoints
2025-03-07 12:21:32,695 - INFO - training batch 101, loss: 0.122, 3232/28000 datapoints
2025-03-07 12:21:32,970 - INFO - training batch 151, loss: 0.148, 4832/28000 datapoints
2025-03-07 12:21:33,263 - INFO - training batch 201, loss: 0.157, 6432/28000 datapoints
2025-03-07 12:21:33,549 - INFO - training batch 251, loss: 0.212, 8032/28000 datapoints
2025-03-07 12:21:33,847 - INFO - training batch 301, loss: 0.358, 9632/28000 datapoints
2025-03-07 12:21:34,158 - INFO - training batch 351, loss: 0.176, 11232/28000 datapoints
2025-03-07 12:21:34,458 - INFO - training batch 401, loss: 0.261, 12832/28000 datapoints
2025-03-07 12:21:34,747 - INFO - training batch 451, loss: 0.276, 14432/28000 datapoints
2025-03-07 12:21:35,030 - INFO - training batch 501, loss: 0.116, 16032/28000 datapoints
2025-03-07 12:21:35,311 - INFO - training batch 551, loss: 0.160, 17632/28000 datapoints
2025-03-07 12:21:35,592 - INFO - training batch 601, loss: 0.208, 19232/28000 datapoints
2025-03-07 12:21:35,872 - INFO - training batch 651, loss: 0.054, 20832/28000 datapoints
2025-03-07 12:21:36,150 - INFO - training batch 701, loss: 0.284, 22432/28000 datapoints
2025-03-07 12:21:36,429 - INFO - training batch 751, loss: 0.113, 24032/28000 datapoints
2025-03-07 12:21:36,708 - INFO - training batch 801, loss: 0.149, 25632/28000 datapoints
2025-03-07 12:21:36,998 - INFO - training batch 851, loss: 0.276, 27232/28000 datapoints
2025-03-07 12:21:37,139 - INFO - validation batch 1, loss: 0.070, 32/6976 datapoints
2025-03-07 12:21:37,218 - INFO - validation batch 51, loss: 0.760, 1632/6976 datapoints
2025-03-07 12:21:37,289 - INFO - validation batch 101, loss: 0.192, 3232/6976 datapoints
2025-03-07 12:21:37,357 - INFO - validation batch 151, loss: 0.290, 4832/6976 datapoints
2025-03-07 12:21:37,427 - INFO - validation batch 201, loss: 0.383, 6432/6976 datapoints
2025-03-07 12:21:37,456 - INFO - Epoch 97/800 done.
2025-03-07 12:21:37,456 - INFO - Final validation performance:
Loss: 0.339, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:21:37,456 - INFO - Beginning epoch 98/800
2025-03-07 12:21:37,464 - INFO - training batch 1, loss: 0.178, 32/28000 datapoints
2025-03-07 12:21:37,751 - INFO - training batch 51, loss: 0.126, 1632/28000 datapoints
2025-03-07 12:21:38,029 - INFO - training batch 101, loss: 0.120, 3232/28000 datapoints
2025-03-07 12:21:38,308 - INFO - training batch 151, loss: 0.143, 4832/28000 datapoints
2025-03-07 12:21:38,613 - INFO - training batch 201, loss: 0.152, 6432/28000 datapoints
2025-03-07 12:21:38,897 - INFO - training batch 251, loss: 0.208, 8032/28000 datapoints
2025-03-07 12:21:39,205 - INFO - training batch 301, loss: 0.354, 9632/28000 datapoints
2025-03-07 12:21:39,487 - INFO - training batch 351, loss: 0.173, 11232/28000 datapoints
2025-03-07 12:21:39,765 - INFO - training batch 401, loss: 0.255, 12832/28000 datapoints
2025-03-07 12:21:40,040 - INFO - training batch 451, loss: 0.270, 14432/28000 datapoints
2025-03-07 12:21:40,318 - INFO - training batch 501, loss: 0.114, 16032/28000 datapoints
2025-03-07 12:21:40,596 - INFO - training batch 551, loss: 0.156, 17632/28000 datapoints
2025-03-07 12:21:40,875 - INFO - training batch 601, loss: 0.203, 19232/28000 datapoints
2025-03-07 12:21:41,158 - INFO - training batch 651, loss: 0.053, 20832/28000 datapoints
2025-03-07 12:21:41,477 - INFO - training batch 701, loss: 0.282, 22432/28000 datapoints
2025-03-07 12:21:41,765 - INFO - training batch 751, loss: 0.112, 24032/28000 datapoints
2025-03-07 12:21:42,046 - INFO - training batch 801, loss: 0.146, 25632/28000 datapoints
2025-03-07 12:21:42,326 - INFO - training batch 851, loss: 0.270, 27232/28000 datapoints
2025-03-07 12:21:42,464 - INFO - validation batch 1, loss: 0.069, 32/6976 datapoints
2025-03-07 12:21:42,538 - INFO - validation batch 51, loss: 0.761, 1632/6976 datapoints
2025-03-07 12:21:42,634 - INFO - validation batch 101, loss: 0.192, 3232/6976 datapoints
2025-03-07 12:21:42,717 - INFO - validation batch 151, loss: 0.289, 4832/6976 datapoints
2025-03-07 12:21:42,786 - INFO - validation batch 201, loss: 0.382, 6432/6976 datapoints
2025-03-07 12:21:42,809 - INFO - Epoch 98/800 done.
2025-03-07 12:21:42,810 - INFO - Final validation performance:
Loss: 0.339, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:21:42,810 - INFO - Beginning epoch 99/800
2025-03-07 12:21:42,817 - INFO - training batch 1, loss: 0.175, 32/28000 datapoints
2025-03-07 12:21:43,101 - INFO - training batch 51, loss: 0.125, 1632/28000 datapoints
2025-03-07 12:21:43,386 - INFO - training batch 101, loss: 0.118, 3232/28000 datapoints
2025-03-07 12:21:43,668 - INFO - training batch 151, loss: 0.139, 4832/28000 datapoints
2025-03-07 12:21:43,942 - INFO - training batch 201, loss: 0.148, 6432/28000 datapoints
2025-03-07 12:21:44,220 - INFO - training batch 251, loss: 0.205, 8032/28000 datapoints
2025-03-07 12:21:44,498 - INFO - training batch 301, loss: 0.350, 9632/28000 datapoints
2025-03-07 12:21:44,777 - INFO - training batch 351, loss: 0.171, 11232/28000 datapoints
2025-03-07 12:21:45,062 - INFO - training batch 401, loss: 0.249, 12832/28000 datapoints
2025-03-07 12:21:45,347 - INFO - training batch 451, loss: 0.265, 14432/28000 datapoints
2025-03-07 12:21:45,626 - INFO - training batch 501, loss: 0.113, 16032/28000 datapoints
2025-03-07 12:21:45,906 - INFO - training batch 551, loss: 0.153, 17632/28000 datapoints
2025-03-07 12:21:46,185 - INFO - training batch 601, loss: 0.197, 19232/28000 datapoints
2025-03-07 12:21:46,469 - INFO - training batch 651, loss: 0.052, 20832/28000 datapoints
2025-03-07 12:21:46,753 - INFO - training batch 701, loss: 0.279, 22432/28000 datapoints
2025-03-07 12:21:47,056 - INFO - training batch 751, loss: 0.110, 24032/28000 datapoints
2025-03-07 12:21:47,337 - INFO - training batch 801, loss: 0.143, 25632/28000 datapoints
2025-03-07 12:21:47,614 - INFO - training batch 851, loss: 0.264, 27232/28000 datapoints
2025-03-07 12:21:47,754 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-07 12:21:47,824 - INFO - validation batch 51, loss: 0.762, 1632/6976 datapoints
2025-03-07 12:21:47,894 - INFO - validation batch 101, loss: 0.191, 3232/6976 datapoints
2025-03-07 12:21:47,965 - INFO - validation batch 151, loss: 0.288, 4832/6976 datapoints
2025-03-07 12:21:48,039 - INFO - validation batch 201, loss: 0.381, 6432/6976 datapoints
2025-03-07 12:21:48,062 - INFO - Epoch 99/800 done.
2025-03-07 12:21:48,062 - INFO - Final validation performance:
Loss: 0.338, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:21:48,063 - INFO - Beginning epoch 100/800
2025-03-07 12:21:48,070 - INFO - training batch 1, loss: 0.173, 32/28000 datapoints
2025-03-07 12:21:48,353 - INFO - training batch 51, loss: 0.124, 1632/28000 datapoints
2025-03-07 12:21:48,650 - INFO - training batch 101, loss: 0.116, 3232/28000 datapoints
2025-03-07 12:21:48,923 - INFO - training batch 151, loss: 0.135, 4832/28000 datapoints
2025-03-07 12:21:49,218 - INFO - training batch 201, loss: 0.143, 6432/28000 datapoints
2025-03-07 12:21:49,506 - INFO - training batch 251, loss: 0.201, 8032/28000 datapoints
2025-03-07 12:21:49,785 - INFO - training batch 301, loss: 0.345, 9632/28000 datapoints
2025-03-07 12:21:50,062 - INFO - training batch 351, loss: 0.168, 11232/28000 datapoints
2025-03-07 12:21:50,342 - INFO - training batch 401, loss: 0.244, 12832/28000 datapoints
2025-03-07 12:21:50,623 - INFO - training batch 451, loss: 0.260, 14432/28000 datapoints
2025-03-07 12:21:50,902 - INFO - training batch 501, loss: 0.111, 16032/28000 datapoints
2025-03-07 12:21:51,206 - INFO - training batch 551, loss: 0.149, 17632/28000 datapoints
2025-03-07 12:21:51,493 - INFO - training batch 601, loss: 0.191, 19232/28000 datapoints
2025-03-07 12:21:51,856 - INFO - training batch 651, loss: 0.051, 20832/28000 datapoints
2025-03-07 12:21:52,196 - INFO - training batch 701, loss: 0.276, 22432/28000 datapoints
2025-03-07 12:21:52,548 - INFO - training batch 751, loss: 0.109, 24032/28000 datapoints
2025-03-07 12:21:52,877 - INFO - training batch 801, loss: 0.140, 25632/28000 datapoints
2025-03-07 12:21:53,209 - INFO - training batch 851, loss: 0.257, 27232/28000 datapoints
2025-03-07 12:21:53,371 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-07 12:21:53,466 - INFO - validation batch 51, loss: 0.763, 1632/6976 datapoints
2025-03-07 12:21:53,556 - INFO - validation batch 101, loss: 0.191, 3232/6976 datapoints
2025-03-07 12:21:53,648 - INFO - validation batch 151, loss: 0.288, 4832/6976 datapoints
2025-03-07 12:21:53,738 - INFO - validation batch 201, loss: 0.380, 6432/6976 datapoints
2025-03-07 12:21:53,772 - INFO - Epoch 100/800 done.
2025-03-07 12:21:53,772 - INFO - Final validation performance:
Loss: 0.338, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:21:53,773 - INFO - Beginning epoch 101/800
2025-03-07 12:21:53,782 - INFO - training batch 1, loss: 0.170, 32/28000 datapoints
2025-03-07 12:21:54,111 - INFO - training batch 51, loss: 0.123, 1632/28000 datapoints
2025-03-07 12:21:54,429 - INFO - training batch 101, loss: 0.113, 3232/28000 datapoints
2025-03-07 12:21:54,733 - INFO - training batch 151, loss: 0.131, 4832/28000 datapoints
2025-03-07 12:21:55,025 - INFO - training batch 201, loss: 0.138, 6432/28000 datapoints
2025-03-07 12:21:55,350 - INFO - training batch 251, loss: 0.198, 8032/28000 datapoints
2025-03-07 12:21:55,640 - INFO - training batch 301, loss: 0.340, 9632/28000 datapoints
2025-03-07 12:21:55,937 - INFO - training batch 351, loss: 0.166, 11232/28000 datapoints
2025-03-07 12:21:56,219 - INFO - training batch 401, loss: 0.238, 12832/28000 datapoints
2025-03-07 12:21:56,504 - INFO - training batch 451, loss: 0.254, 14432/28000 datapoints
2025-03-07 12:21:56,787 - INFO - training batch 501, loss: 0.110, 16032/28000 datapoints
2025-03-07 12:21:57,088 - INFO - training batch 551, loss: 0.146, 17632/28000 datapoints
2025-03-07 12:21:57,384 - INFO - training batch 601, loss: 0.185, 19232/28000 datapoints
2025-03-07 12:21:57,665 - INFO - training batch 651, loss: 0.049, 20832/28000 datapoints
2025-03-07 12:21:57,952 - INFO - training batch 701, loss: 0.273, 22432/28000 datapoints
2025-03-07 12:21:58,266 - INFO - training batch 751, loss: 0.108, 24032/28000 datapoints
2025-03-07 12:21:58,550 - INFO - training batch 801, loss: 0.136, 25632/28000 datapoints
2025-03-07 12:21:58,833 - INFO - training batch 851, loss: 0.251, 27232/28000 datapoints
2025-03-07 12:21:58,973 - INFO - validation batch 1, loss: 0.067, 32/6976 datapoints
2025-03-07 12:21:59,046 - INFO - validation batch 51, loss: 0.764, 1632/6976 datapoints
2025-03-07 12:21:59,123 - INFO - validation batch 101, loss: 0.191, 3232/6976 datapoints
2025-03-07 12:21:59,199 - INFO - validation batch 151, loss: 0.288, 4832/6976 datapoints
2025-03-07 12:21:59,284 - INFO - validation batch 201, loss: 0.379, 6432/6976 datapoints
2025-03-07 12:21:59,323 - INFO - Epoch 101/800 done.
2025-03-07 12:21:59,323 - INFO - Final validation performance:
Loss: 0.338, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:21:59,324 - INFO - Beginning epoch 102/800
2025-03-07 12:21:59,333 - INFO - training batch 1, loss: 0.167, 32/28000 datapoints
2025-03-07 12:21:59,625 - INFO - training batch 51, loss: 0.122, 1632/28000 datapoints
2025-03-07 12:21:59,904 - INFO - training batch 101, loss: 0.111, 3232/28000 datapoints
2025-03-07 12:22:00,186 - INFO - training batch 151, loss: 0.127, 4832/28000 datapoints
2025-03-07 12:22:00,493 - INFO - training batch 201, loss: 0.134, 6432/28000 datapoints
2025-03-07 12:22:00,790 - INFO - training batch 251, loss: 0.194, 8032/28000 datapoints
2025-03-07 12:22:01,069 - INFO - training batch 301, loss: 0.336, 9632/28000 datapoints
2025-03-07 12:22:01,353 - INFO - training batch 351, loss: 0.163, 11232/28000 datapoints
2025-03-07 12:22:01,639 - INFO - training batch 401, loss: 0.232, 12832/28000 datapoints
2025-03-07 12:22:01,967 - INFO - training batch 451, loss: 0.249, 14432/28000 datapoints
2025-03-07 12:22:02,265 - INFO - training batch 501, loss: 0.108, 16032/28000 datapoints
2025-03-07 12:22:02,555 - INFO - training batch 551, loss: 0.142, 17632/28000 datapoints
2025-03-07 12:22:02,847 - INFO - training batch 601, loss: 0.179, 19232/28000 datapoints
2025-03-07 12:22:03,138 - INFO - training batch 651, loss: 0.049, 20832/28000 datapoints
2025-03-07 12:22:03,444 - INFO - training batch 701, loss: 0.270, 22432/28000 datapoints
2025-03-07 12:22:03,726 - INFO - training batch 751, loss: 0.107, 24032/28000 datapoints
2025-03-07 12:22:04,002 - INFO - training batch 801, loss: 0.134, 25632/28000 datapoints
2025-03-07 12:22:04,280 - INFO - training batch 851, loss: 0.244, 27232/28000 datapoints
2025-03-07 12:22:04,418 - INFO - validation batch 1, loss: 0.067, 32/6976 datapoints
2025-03-07 12:22:04,504 - INFO - validation batch 51, loss: 0.765, 1632/6976 datapoints
2025-03-07 12:22:04,577 - INFO - validation batch 101, loss: 0.190, 3232/6976 datapoints
2025-03-07 12:22:04,648 - INFO - validation batch 151, loss: 0.288, 4832/6976 datapoints
2025-03-07 12:22:04,722 - INFO - validation batch 201, loss: 0.378, 6432/6976 datapoints
2025-03-07 12:22:04,747 - INFO - Epoch 102/800 done.
2025-03-07 12:22:04,747 - INFO - Final validation performance:
Loss: 0.337, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:22:04,748 - INFO - Beginning epoch 103/800
2025-03-07 12:22:04,756 - INFO - training batch 1, loss: 0.165, 32/28000 datapoints
2025-03-07 12:22:05,038 - INFO - training batch 51, loss: 0.120, 1632/28000 datapoints
2025-03-07 12:22:05,322 - INFO - training batch 101, loss: 0.109, 3232/28000 datapoints
2025-03-07 12:22:05,613 - INFO - training batch 151, loss: 0.123, 4832/28000 datapoints
2025-03-07 12:22:05,900 - INFO - training batch 201, loss: 0.129, 6432/28000 datapoints
2025-03-07 12:22:06,182 - INFO - training batch 251, loss: 0.191, 8032/28000 datapoints
2025-03-07 12:22:06,462 - INFO - training batch 301, loss: 0.331, 9632/28000 datapoints
2025-03-07 12:22:06,741 - INFO - training batch 351, loss: 0.161, 11232/28000 datapoints
2025-03-07 12:22:07,028 - INFO - training batch 401, loss: 0.227, 12832/28000 datapoints
2025-03-07 12:22:07,321 - INFO - training batch 451, loss: 0.244, 14432/28000 datapoints
2025-03-07 12:22:07,604 - INFO - training batch 501, loss: 0.106, 16032/28000 datapoints
2025-03-07 12:22:07,896 - INFO - training batch 551, loss: 0.138, 17632/28000 datapoints
2025-03-07 12:22:08,174 - INFO - training batch 601, loss: 0.174, 19232/28000 datapoints
2025-03-07 12:22:08,460 - INFO - training batch 651, loss: 0.047, 20832/28000 datapoints
2025-03-07 12:22:08,735 - INFO - training batch 701, loss: 0.268, 22432/28000 datapoints
2025-03-07 12:22:09,014 - INFO - training batch 751, loss: 0.106, 24032/28000 datapoints
2025-03-07 12:22:09,297 - INFO - training batch 801, loss: 0.131, 25632/28000 datapoints
2025-03-07 12:22:09,609 - INFO - training batch 851, loss: 0.237, 27232/28000 datapoints
2025-03-07 12:22:09,750 - INFO - validation batch 1, loss: 0.067, 32/6976 datapoints
2025-03-07 12:22:09,824 - INFO - validation batch 51, loss: 0.766, 1632/6976 datapoints
2025-03-07 12:22:09,898 - INFO - validation batch 101, loss: 0.189, 3232/6976 datapoints
2025-03-07 12:22:09,971 - INFO - validation batch 151, loss: 0.289, 4832/6976 datapoints
2025-03-07 12:22:10,045 - INFO - validation batch 201, loss: 0.376, 6432/6976 datapoints
2025-03-07 12:22:10,072 - INFO - Epoch 103/800 done.
2025-03-07 12:22:10,072 - INFO - Final validation performance:
Loss: 0.337, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:22:10,072 - INFO - Beginning epoch 104/800
2025-03-07 12:22:10,080 - INFO - training batch 1, loss: 0.162, 32/28000 datapoints
2025-03-07 12:22:10,366 - INFO - training batch 51, loss: 0.119, 1632/28000 datapoints
2025-03-07 12:22:10,653 - INFO - training batch 101, loss: 0.107, 3232/28000 datapoints
2025-03-07 12:22:10,944 - INFO - training batch 151, loss: 0.118, 4832/28000 datapoints
2025-03-07 12:22:11,230 - INFO - training batch 201, loss: 0.126, 6432/28000 datapoints
2025-03-07 12:22:11,509 - INFO - training batch 251, loss: 0.187, 8032/28000 datapoints
2025-03-07 12:22:11,789 - INFO - training batch 301, loss: 0.327, 9632/28000 datapoints
2025-03-07 12:22:12,117 - INFO - training batch 351, loss: 0.159, 11232/28000 datapoints
2025-03-07 12:22:12,522 - INFO - training batch 401, loss: 0.221, 12832/28000 datapoints
2025-03-07 12:22:12,926 - INFO - training batch 451, loss: 0.239, 14432/28000 datapoints
2025-03-07 12:22:13,223 - INFO - training batch 501, loss: 0.105, 16032/28000 datapoints
2025-03-07 12:22:13,524 - INFO - training batch 551, loss: 0.135, 17632/28000 datapoints
2025-03-07 12:22:13,823 - INFO - training batch 601, loss: 0.169, 19232/28000 datapoints
2025-03-07 12:22:14,116 - INFO - training batch 651, loss: 0.046, 20832/28000 datapoints
2025-03-07 12:22:14,409 - INFO - training batch 701, loss: 0.265, 22432/28000 datapoints
2025-03-07 12:22:14,699 - INFO - training batch 751, loss: 0.104, 24032/28000 datapoints
2025-03-07 12:22:14,982 - INFO - training batch 801, loss: 0.128, 25632/28000 datapoints
2025-03-07 12:22:15,263 - INFO - training batch 851, loss: 0.231, 27232/28000 datapoints
2025-03-07 12:22:15,403 - INFO - validation batch 1, loss: 0.066, 32/6976 datapoints
2025-03-07 12:22:15,480 - INFO - validation batch 51, loss: 0.767, 1632/6976 datapoints
2025-03-07 12:22:15,554 - INFO - validation batch 101, loss: 0.188, 3232/6976 datapoints
2025-03-07 12:22:15,628 - INFO - validation batch 151, loss: 0.289, 4832/6976 datapoints
2025-03-07 12:22:15,703 - INFO - validation batch 201, loss: 0.375, 6432/6976 datapoints
2025-03-07 12:22:15,732 - INFO - Epoch 104/800 done.
2025-03-07 12:22:15,732 - INFO - Final validation performance:
Loss: 0.337, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:22:15,733 - INFO - Beginning epoch 105/800
2025-03-07 12:22:15,740 - INFO - training batch 1, loss: 0.160, 32/28000 datapoints
2025-03-07 12:22:16,029 - INFO - training batch 51, loss: 0.118, 1632/28000 datapoints
2025-03-07 12:22:16,310 - INFO - training batch 101, loss: 0.105, 3232/28000 datapoints
2025-03-07 12:22:16,625 - INFO - training batch 151, loss: 0.114, 4832/28000 datapoints
2025-03-07 12:22:16,915 - INFO - training batch 201, loss: 0.122, 6432/28000 datapoints
2025-03-07 12:22:17,209 - INFO - training batch 251, loss: 0.184, 8032/28000 datapoints
2025-03-07 12:22:17,497 - INFO - training batch 301, loss: 0.323, 9632/28000 datapoints
2025-03-07 12:22:17,782 - INFO - training batch 351, loss: 0.157, 11232/28000 datapoints
2025-03-07 12:22:18,057 - INFO - training batch 401, loss: 0.215, 12832/28000 datapoints
2025-03-07 12:22:18,331 - INFO - training batch 451, loss: 0.233, 14432/28000 datapoints
2025-03-07 12:22:18,616 - INFO - training batch 501, loss: 0.103, 16032/28000 datapoints
2025-03-07 12:22:18,892 - INFO - training batch 551, loss: 0.131, 17632/28000 datapoints
2025-03-07 12:22:19,167 - INFO - training batch 601, loss: 0.165, 19232/28000 datapoints
2025-03-07 12:22:19,450 - INFO - training batch 651, loss: 0.045, 20832/28000 datapoints
2025-03-07 12:22:19,747 - INFO - training batch 701, loss: 0.263, 22432/28000 datapoints
2025-03-07 12:22:20,025 - INFO - training batch 751, loss: 0.103, 24032/28000 datapoints
2025-03-07 12:22:20,301 - INFO - training batch 801, loss: 0.125, 25632/28000 datapoints
2025-03-07 12:22:20,584 - INFO - training batch 851, loss: 0.224, 27232/28000 datapoints
2025-03-07 12:22:20,722 - INFO - validation batch 1, loss: 0.066, 32/6976 datapoints
2025-03-07 12:22:20,795 - INFO - validation batch 51, loss: 0.768, 1632/6976 datapoints
2025-03-07 12:22:20,868 - INFO - validation batch 101, loss: 0.188, 3232/6976 datapoints
2025-03-07 12:22:20,941 - INFO - validation batch 151, loss: 0.291, 4832/6976 datapoints
2025-03-07 12:22:21,016 - INFO - validation batch 201, loss: 0.374, 6432/6976 datapoints
2025-03-07 12:22:21,042 - INFO - Epoch 105/800 done.
2025-03-07 12:22:21,042 - INFO - Final validation performance:
Loss: 0.337, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:22:21,043 - INFO - Beginning epoch 106/800
2025-03-07 12:22:21,050 - INFO - training batch 1, loss: 0.158, 32/28000 datapoints
2025-03-07 12:22:21,349 - INFO - training batch 51, loss: 0.117, 1632/28000 datapoints
2025-03-07 12:22:21,688 - INFO - training batch 101, loss: 0.103, 3232/28000 datapoints
2025-03-07 12:22:22,093 - INFO - training batch 151, loss: 0.110, 4832/28000 datapoints
2025-03-07 12:22:22,498 - INFO - training batch 201, loss: 0.119, 6432/28000 datapoints
2025-03-07 12:22:22,840 - INFO - training batch 251, loss: 0.180, 8032/28000 datapoints
2025-03-07 12:22:23,182 - INFO - training batch 301, loss: 0.318, 9632/28000 datapoints
2025-03-07 12:22:23,533 - INFO - training batch 351, loss: 0.155, 11232/28000 datapoints
2025-03-07 12:22:23,876 - INFO - training batch 401, loss: 0.209, 12832/28000 datapoints
2025-03-07 12:22:24,214 - INFO - training batch 451, loss: 0.227, 14432/28000 datapoints
2025-03-07 12:22:24,543 - INFO - training batch 501, loss: 0.102, 16032/28000 datapoints
2025-03-07 12:22:24,849 - INFO - training batch 551, loss: 0.127, 17632/28000 datapoints
2025-03-07 12:22:25,150 - INFO - training batch 601, loss: 0.160, 19232/28000 datapoints
2025-03-07 12:22:25,442 - INFO - training batch 651, loss: 0.044, 20832/28000 datapoints
2025-03-07 12:22:25,737 - INFO - training batch 701, loss: 0.260, 22432/28000 datapoints
2025-03-07 12:22:26,023 - INFO - training batch 751, loss: 0.102, 24032/28000 datapoints
2025-03-07 12:22:26,342 - INFO - training batch 801, loss: 0.122, 25632/28000 datapoints
2025-03-07 12:22:26,632 - INFO - training batch 851, loss: 0.218, 27232/28000 datapoints
2025-03-07 12:22:26,772 - INFO - validation batch 1, loss: 0.066, 32/6976 datapoints
2025-03-07 12:22:26,849 - INFO - validation batch 51, loss: 0.770, 1632/6976 datapoints
2025-03-07 12:22:26,926 - INFO - validation batch 101, loss: 0.188, 3232/6976 datapoints
2025-03-07 12:22:27,001 - INFO - validation batch 151, loss: 0.291, 4832/6976 datapoints
2025-03-07 12:22:27,078 - INFO - validation batch 201, loss: 0.373, 6432/6976 datapoints
2025-03-07 12:22:27,105 - INFO - Epoch 106/800 done.
2025-03-07 12:22:27,106 - INFO - Final validation performance:
Loss: 0.338, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:22:27,106 - INFO - Beginning epoch 107/800
2025-03-07 12:22:27,116 - INFO - training batch 1, loss: 0.156, 32/28000 datapoints
2025-03-07 12:22:27,421 - INFO - training batch 51, loss: 0.116, 1632/28000 datapoints
2025-03-07 12:22:27,707 - INFO - training batch 101, loss: 0.101, 3232/28000 datapoints
2025-03-07 12:22:27,996 - INFO - training batch 151, loss: 0.107, 4832/28000 datapoints
2025-03-07 12:22:28,276 - INFO - training batch 201, loss: 0.116, 6432/28000 datapoints
2025-03-07 12:22:28,563 - INFO - training batch 251, loss: 0.177, 8032/28000 datapoints
2025-03-07 12:22:28,841 - INFO - training batch 301, loss: 0.313, 9632/28000 datapoints
2025-03-07 12:22:29,120 - INFO - training batch 351, loss: 0.153, 11232/28000 datapoints
2025-03-07 12:22:29,407 - INFO - training batch 401, loss: 0.204, 12832/28000 datapoints
2025-03-07 12:22:29,724 - INFO - training batch 451, loss: 0.221, 14432/28000 datapoints
2025-03-07 12:22:30,004 - INFO - training batch 501, loss: 0.100, 16032/28000 datapoints
2025-03-07 12:22:30,287 - INFO - training batch 551, loss: 0.124, 17632/28000 datapoints
2025-03-07 12:22:30,769 - INFO - training batch 601, loss: 0.155, 19232/28000 datapoints
2025-03-07 12:22:31,227 - INFO - training batch 651, loss: 0.043, 20832/28000 datapoints
2025-03-07 12:22:31,616 - INFO - training batch 701, loss: 0.258, 22432/28000 datapoints
2025-03-07 12:22:31,912 - INFO - training batch 751, loss: 0.100, 24032/28000 datapoints
2025-03-07 12:22:32,199 - INFO - training batch 801, loss: 0.119, 25632/28000 datapoints
2025-03-07 12:22:32,606 - INFO - training batch 851, loss: 0.212, 27232/28000 datapoints
2025-03-07 12:22:32,789 - INFO - validation batch 1, loss: 0.065, 32/6976 datapoints
2025-03-07 12:22:32,887 - INFO - validation batch 51, loss: 0.772, 1632/6976 datapoints
2025-03-07 12:22:33,002 - INFO - validation batch 101, loss: 0.188, 3232/6976 datapoints
2025-03-07 12:22:33,103 - INFO - validation batch 151, loss: 0.292, 4832/6976 datapoints
2025-03-07 12:22:33,179 - INFO - validation batch 201, loss: 0.371, 6432/6976 datapoints
2025-03-07 12:22:33,202 - INFO - Epoch 107/800 done.
2025-03-07 12:22:33,203 - INFO - Final validation performance:
Loss: 0.338, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:22:33,203 - INFO - Beginning epoch 108/800
2025-03-07 12:22:33,213 - INFO - training batch 1, loss: 0.153, 32/28000 datapoints
2025-03-07 12:22:33,514 - INFO - training batch 51, loss: 0.114, 1632/28000 datapoints
2025-03-07 12:22:33,807 - INFO - training batch 101, loss: 0.099, 3232/28000 datapoints
2025-03-07 12:22:34,095 - INFO - training batch 151, loss: 0.103, 4832/28000 datapoints
2025-03-07 12:22:34,385 - INFO - training batch 201, loss: 0.113, 6432/28000 datapoints
2025-03-07 12:22:34,682 - INFO - training batch 251, loss: 0.173, 8032/28000 datapoints
2025-03-07 12:22:35,003 - INFO - training batch 301, loss: 0.309, 9632/28000 datapoints
2025-03-07 12:22:35,290 - INFO - training batch 351, loss: 0.151, 11232/28000 datapoints
2025-03-07 12:22:35,577 - INFO - training batch 401, loss: 0.198, 12832/28000 datapoints
2025-03-07 12:22:35,860 - INFO - training batch 451, loss: 0.215, 14432/28000 datapoints
2025-03-07 12:22:36,139 - INFO - training batch 501, loss: 0.099, 16032/28000 datapoints
2025-03-07 12:22:36,418 - INFO - training batch 551, loss: 0.120, 17632/28000 datapoints
2025-03-07 12:22:36,702 - INFO - training batch 601, loss: 0.151, 19232/28000 datapoints
2025-03-07 12:22:36,989 - INFO - training batch 651, loss: 0.042, 20832/28000 datapoints
2025-03-07 12:22:37,276 - INFO - training batch 701, loss: 0.255, 22432/28000 datapoints
2025-03-07 12:22:37,569 - INFO - training batch 751, loss: 0.099, 24032/28000 datapoints
2025-03-07 12:22:37,860 - INFO - training batch 801, loss: 0.117, 25632/28000 datapoints
2025-03-07 12:22:38,137 - INFO - training batch 851, loss: 0.206, 27232/28000 datapoints
2025-03-07 12:22:38,278 - INFO - validation batch 1, loss: 0.065, 32/6976 datapoints
2025-03-07 12:22:38,359 - INFO - validation batch 51, loss: 0.773, 1632/6976 datapoints
2025-03-07 12:22:38,436 - INFO - validation batch 101, loss: 0.188, 3232/6976 datapoints
2025-03-07 12:22:38,515 - INFO - validation batch 151, loss: 0.292, 4832/6976 datapoints
2025-03-07 12:22:38,589 - INFO - validation batch 201, loss: 0.370, 6432/6976 datapoints
2025-03-07 12:22:38,614 - INFO - Epoch 108/800 done.
2025-03-07 12:22:38,615 - INFO - Final validation performance:
Loss: 0.338, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:22:38,615 - INFO - Beginning epoch 109/800
2025-03-07 12:22:38,626 - INFO - training batch 1, loss: 0.151, 32/28000 datapoints
2025-03-07 12:22:38,910 - INFO - training batch 51, loss: 0.113, 1632/28000 datapoints
2025-03-07 12:22:39,208 - INFO - training batch 101, loss: 0.097, 3232/28000 datapoints
2025-03-07 12:22:39,512 - INFO - training batch 151, loss: 0.098, 4832/28000 datapoints
2025-03-07 12:22:39,822 - INFO - training batch 201, loss: 0.110, 6432/28000 datapoints
2025-03-07 12:22:40,099 - INFO - training batch 251, loss: 0.169, 8032/28000 datapoints
2025-03-07 12:22:40,374 - INFO - training batch 301, loss: 0.303, 9632/28000 datapoints
2025-03-07 12:22:40,658 - INFO - training batch 351, loss: 0.149, 11232/28000 datapoints
2025-03-07 12:22:40,947 - INFO - training batch 401, loss: 0.193, 12832/28000 datapoints
2025-03-07 12:22:41,226 - INFO - training batch 451, loss: 0.210, 14432/28000 datapoints
2025-03-07 12:22:41,535 - INFO - training batch 501, loss: 0.097, 16032/28000 datapoints
2025-03-07 12:22:41,816 - INFO - training batch 551, loss: 0.116, 17632/28000 datapoints
2025-03-07 12:22:42,088 - INFO - training batch 601, loss: 0.147, 19232/28000 datapoints
2025-03-07 12:22:42,367 - INFO - training batch 651, loss: 0.041, 20832/28000 datapoints
2025-03-07 12:22:42,692 - INFO - training batch 701, loss: 0.251, 22432/28000 datapoints
2025-03-07 12:22:42,973 - INFO - training batch 751, loss: 0.098, 24032/28000 datapoints
2025-03-07 12:22:43,268 - INFO - training batch 801, loss: 0.114, 25632/28000 datapoints
2025-03-07 12:22:43,582 - INFO - training batch 851, loss: 0.199, 27232/28000 datapoints
2025-03-07 12:22:43,724 - INFO - validation batch 1, loss: 0.065, 32/6976 datapoints
2025-03-07 12:22:43,797 - INFO - validation batch 51, loss: 0.776, 1632/6976 datapoints
2025-03-07 12:22:43,868 - INFO - validation batch 101, loss: 0.187, 3232/6976 datapoints
2025-03-07 12:22:43,940 - INFO - validation batch 151, loss: 0.294, 4832/6976 datapoints
2025-03-07 12:22:44,010 - INFO - validation batch 201, loss: 0.368, 6432/6976 datapoints
2025-03-07 12:22:44,034 - INFO - Epoch 109/800 done.
2025-03-07 12:22:44,034 - INFO - Final validation performance:
Loss: 0.338, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:22:44,034 - INFO - Beginning epoch 110/800
2025-03-07 12:22:44,042 - INFO - training batch 1, loss: 0.149, 32/28000 datapoints
2025-03-07 12:22:44,331 - INFO - training batch 51, loss: 0.112, 1632/28000 datapoints
2025-03-07 12:22:44,618 - INFO - training batch 101, loss: 0.095, 3232/28000 datapoints
2025-03-07 12:22:44,903 - INFO - training batch 151, loss: 0.095, 4832/28000 datapoints
2025-03-07 12:22:45,187 - INFO - training batch 201, loss: 0.108, 6432/28000 datapoints
2025-03-07 12:22:45,471 - INFO - training batch 251, loss: 0.165, 8032/28000 datapoints
2025-03-07 12:22:45,751 - INFO - training batch 301, loss: 0.299, 9632/28000 datapoints
2025-03-07 12:22:46,029 - INFO - training batch 351, loss: 0.147, 11232/28000 datapoints
2025-03-07 12:22:46,302 - INFO - training batch 401, loss: 0.188, 12832/28000 datapoints
2025-03-07 12:22:46,579 - INFO - training batch 451, loss: 0.204, 14432/28000 datapoints
2025-03-07 12:22:46,854 - INFO - training batch 501, loss: 0.095, 16032/28000 datapoints
2025-03-07 12:22:47,134 - INFO - training batch 551, loss: 0.113, 17632/28000 datapoints
2025-03-07 12:22:47,420 - INFO - training batch 601, loss: 0.142, 19232/28000 datapoints
2025-03-07 12:22:47,704 - INFO - training batch 651, loss: 0.040, 20832/28000 datapoints
2025-03-07 12:22:48,018 - INFO - training batch 701, loss: 0.249, 22432/28000 datapoints
2025-03-07 12:22:48,316 - INFO - training batch 751, loss: 0.097, 24032/28000 datapoints
2025-03-07 12:22:48,598 - INFO - training batch 801, loss: 0.111, 25632/28000 datapoints
2025-03-07 12:22:48,881 - INFO - training batch 851, loss: 0.193, 27232/28000 datapoints
2025-03-07 12:22:49,016 - INFO - validation batch 1, loss: 0.065, 32/6976 datapoints
2025-03-07 12:22:49,085 - INFO - validation batch 51, loss: 0.778, 1632/6976 datapoints
2025-03-07 12:22:49,157 - INFO - validation batch 101, loss: 0.187, 3232/6976 datapoints
2025-03-07 12:22:49,229 - INFO - validation batch 151, loss: 0.294, 4832/6976 datapoints
2025-03-07 12:22:49,300 - INFO - validation batch 201, loss: 0.366, 6432/6976 datapoints
2025-03-07 12:22:49,324 - INFO - Epoch 110/800 done.
2025-03-07 12:22:49,324 - INFO - Final validation performance:
Loss: 0.338, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:22:49,325 - INFO - Beginning epoch 111/800
2025-03-07 12:22:49,332 - INFO - training batch 1, loss: 0.146, 32/28000 datapoints
2025-03-07 12:22:49,615 - INFO - training batch 51, loss: 0.111, 1632/28000 datapoints
2025-03-07 12:22:49,924 - INFO - training batch 101, loss: 0.093, 3232/28000 datapoints
2025-03-07 12:22:50,201 - INFO - training batch 151, loss: 0.091, 4832/28000 datapoints
2025-03-07 12:22:50,483 - INFO - training batch 201, loss: 0.105, 6432/28000 datapoints
2025-03-07 12:22:50,763 - INFO - training batch 251, loss: 0.161, 8032/28000 datapoints
2025-03-07 12:22:51,041 - INFO - training batch 301, loss: 0.294, 9632/28000 datapoints
2025-03-07 12:22:51,319 - INFO - training batch 351, loss: 0.145, 11232/28000 datapoints
2025-03-07 12:22:51,602 - INFO - training batch 401, loss: 0.183, 12832/28000 datapoints
2025-03-07 12:22:51,882 - INFO - training batch 451, loss: 0.199, 14432/28000 datapoints
2025-03-07 12:22:52,157 - INFO - training batch 501, loss: 0.094, 16032/28000 datapoints
2025-03-07 12:22:52,434 - INFO - training batch 551, loss: 0.109, 17632/28000 datapoints
2025-03-07 12:22:52,733 - INFO - training batch 601, loss: 0.138, 19232/28000 datapoints
2025-03-07 12:22:53,148 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-07 12:22:53,586 - INFO - training batch 701, loss: 0.246, 22432/28000 datapoints
2025-03-07 12:22:53,921 - INFO - training batch 751, loss: 0.096, 24032/28000 datapoints
2025-03-07 12:22:54,253 - INFO - training batch 801, loss: 0.107, 25632/28000 datapoints
2025-03-07 12:22:54,599 - INFO - training batch 851, loss: 0.187, 27232/28000 datapoints
2025-03-07 12:22:54,764 - INFO - validation batch 1, loss: 0.065, 32/6976 datapoints
2025-03-07 12:22:54,854 - INFO - validation batch 51, loss: 0.780, 1632/6976 datapoints
2025-03-07 12:22:54,957 - INFO - validation batch 101, loss: 0.187, 3232/6976 datapoints
2025-03-07 12:22:55,078 - INFO - validation batch 151, loss: 0.296, 4832/6976 datapoints
2025-03-07 12:22:55,161 - INFO - validation batch 201, loss: 0.364, 6432/6976 datapoints
2025-03-07 12:22:55,191 - INFO - Epoch 111/800 done.
2025-03-07 12:22:55,191 - INFO - Final validation performance:
Loss: 0.338, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:22:55,192 - INFO - Beginning epoch 112/800
2025-03-07 12:22:55,201 - INFO - training batch 1, loss: 0.144, 32/28000 datapoints
2025-03-07 12:22:55,532 - INFO - training batch 51, loss: 0.110, 1632/28000 datapoints
2025-03-07 12:22:55,831 - INFO - training batch 101, loss: 0.092, 3232/28000 datapoints
2025-03-07 12:22:56,122 - INFO - training batch 151, loss: 0.087, 4832/28000 datapoints
2025-03-07 12:22:56,411 - INFO - training batch 201, loss: 0.103, 6432/28000 datapoints
2025-03-07 12:22:56,691 - INFO - training batch 251, loss: 0.157, 8032/28000 datapoints
2025-03-07 12:22:56,974 - INFO - training batch 301, loss: 0.289, 9632/28000 datapoints
2025-03-07 12:22:57,261 - INFO - training batch 351, loss: 0.143, 11232/28000 datapoints
2025-03-07 12:22:57,556 - INFO - training batch 401, loss: 0.177, 12832/28000 datapoints
2025-03-07 12:22:57,845 - INFO - training batch 451, loss: 0.193, 14432/28000 datapoints
2025-03-07 12:22:58,172 - INFO - training batch 501, loss: 0.092, 16032/28000 datapoints
2025-03-07 12:22:58,462 - INFO - training batch 551, loss: 0.106, 17632/28000 datapoints
2025-03-07 12:22:58,750 - INFO - training batch 601, loss: 0.134, 19232/28000 datapoints
2025-03-07 12:22:59,033 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-07 12:22:59,312 - INFO - training batch 701, loss: 0.243, 22432/28000 datapoints
2025-03-07 12:22:59,594 - INFO - training batch 751, loss: 0.095, 24032/28000 datapoints
2025-03-07 12:22:59,898 - INFO - training batch 801, loss: 0.105, 25632/28000 datapoints
2025-03-07 12:23:00,209 - INFO - training batch 851, loss: 0.181, 27232/28000 datapoints
2025-03-07 12:23:00,348 - INFO - validation batch 1, loss: 0.065, 32/6976 datapoints
2025-03-07 12:23:00,430 - INFO - validation batch 51, loss: 0.782, 1632/6976 datapoints
2025-03-07 12:23:00,521 - INFO - validation batch 101, loss: 0.186, 3232/6976 datapoints
2025-03-07 12:23:00,599 - INFO - validation batch 151, loss: 0.297, 4832/6976 datapoints
2025-03-07 12:23:00,672 - INFO - validation batch 201, loss: 0.363, 6432/6976 datapoints
2025-03-07 12:23:00,697 - INFO - Epoch 112/800 done.
2025-03-07 12:23:00,697 - INFO - Final validation performance:
Loss: 0.339, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:23:00,697 - INFO - Beginning epoch 113/800
2025-03-07 12:23:00,705 - INFO - training batch 1, loss: 0.141, 32/28000 datapoints
2025-03-07 12:23:00,997 - INFO - training batch 51, loss: 0.108, 1632/28000 datapoints
2025-03-07 12:23:01,275 - INFO - training batch 101, loss: 0.089, 3232/28000 datapoints
2025-03-07 12:23:01,563 - INFO - training batch 151, loss: 0.084, 4832/28000 datapoints
2025-03-07 12:23:01,851 - INFO - training batch 201, loss: 0.100, 6432/28000 datapoints
2025-03-07 12:23:02,131 - INFO - training batch 251, loss: 0.153, 8032/28000 datapoints
2025-03-07 12:23:02,406 - INFO - training batch 301, loss: 0.283, 9632/28000 datapoints
2025-03-07 12:23:02,693 - INFO - training batch 351, loss: 0.141, 11232/28000 datapoints
2025-03-07 12:23:03,038 - INFO - training batch 401, loss: 0.172, 12832/28000 datapoints
2025-03-07 12:23:03,352 - INFO - training batch 451, loss: 0.188, 14432/28000 datapoints
2025-03-07 12:23:03,650 - INFO - training batch 501, loss: 0.091, 16032/28000 datapoints
2025-03-07 12:23:03,933 - INFO - training batch 551, loss: 0.102, 17632/28000 datapoints
2025-03-07 12:23:04,249 - INFO - training batch 601, loss: 0.130, 19232/28000 datapoints
2025-03-07 12:23:04,547 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-07 12:23:04,834 - INFO - training batch 701, loss: 0.240, 22432/28000 datapoints
2025-03-07 12:23:05,123 - INFO - training batch 751, loss: 0.094, 24032/28000 datapoints
2025-03-07 12:23:05,422 - INFO - training batch 801, loss: 0.102, 25632/28000 datapoints
2025-03-07 12:23:05,708 - INFO - training batch 851, loss: 0.176, 27232/28000 datapoints
2025-03-07 12:23:05,848 - INFO - validation batch 1, loss: 0.065, 32/6976 datapoints
2025-03-07 12:23:05,924 - INFO - validation batch 51, loss: 0.784, 1632/6976 datapoints
2025-03-07 12:23:06,000 - INFO - validation batch 101, loss: 0.186, 3232/6976 datapoints
2025-03-07 12:23:06,077 - INFO - validation batch 151, loss: 0.298, 4832/6976 datapoints
2025-03-07 12:23:06,150 - INFO - validation batch 201, loss: 0.361, 6432/6976 datapoints
2025-03-07 12:23:06,177 - INFO - Epoch 113/800 done.
2025-03-07 12:23:06,178 - INFO - Final validation performance:
Loss: 0.339, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:23:06,178 - INFO - Beginning epoch 114/800
2025-03-07 12:23:06,187 - INFO - training batch 1, loss: 0.139, 32/28000 datapoints
2025-03-07 12:23:06,475 - INFO - training batch 51, loss: 0.106, 1632/28000 datapoints
2025-03-07 12:23:06,755 - INFO - training batch 101, loss: 0.088, 3232/28000 datapoints
2025-03-07 12:23:07,038 - INFO - training batch 151, loss: 0.081, 4832/28000 datapoints
2025-03-07 12:23:07,321 - INFO - training batch 201, loss: 0.098, 6432/28000 datapoints
2025-03-07 12:23:07,614 - INFO - training batch 251, loss: 0.149, 8032/28000 datapoints
2025-03-07 12:23:07,905 - INFO - training batch 301, loss: 0.278, 9632/28000 datapoints
2025-03-07 12:23:08,187 - INFO - training batch 351, loss: 0.139, 11232/28000 datapoints
2025-03-07 12:23:08,473 - INFO - training batch 401, loss: 0.168, 12832/28000 datapoints
2025-03-07 12:23:08,764 - INFO - training batch 451, loss: 0.183, 14432/28000 datapoints
2025-03-07 12:23:09,046 - INFO - training batch 501, loss: 0.089, 16032/28000 datapoints
2025-03-07 12:23:09,348 - INFO - training batch 551, loss: 0.100, 17632/28000 datapoints
2025-03-07 12:23:09,644 - INFO - training batch 601, loss: 0.127, 19232/28000 datapoints
2025-03-07 12:23:09,922 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-07 12:23:10,225 - INFO - training batch 701, loss: 0.237, 22432/28000 datapoints
2025-03-07 12:23:10,509 - INFO - training batch 751, loss: 0.093, 24032/28000 datapoints
2025-03-07 12:23:10,792 - INFO - training batch 801, loss: 0.100, 25632/28000 datapoints
2025-03-07 12:23:11,075 - INFO - training batch 851, loss: 0.170, 27232/28000 datapoints
2025-03-07 12:23:11,213 - INFO - validation batch 1, loss: 0.064, 32/6976 datapoints
2025-03-07 12:23:11,286 - INFO - validation batch 51, loss: 0.786, 1632/6976 datapoints
2025-03-07 12:23:11,361 - INFO - validation batch 101, loss: 0.186, 3232/6976 datapoints
2025-03-07 12:23:11,436 - INFO - validation batch 151, loss: 0.299, 4832/6976 datapoints
2025-03-07 12:23:11,514 - INFO - validation batch 201, loss: 0.359, 6432/6976 datapoints
2025-03-07 12:23:11,541 - INFO - Epoch 114/800 done.
2025-03-07 12:23:11,541 - INFO - Final validation performance:
Loss: 0.339, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:23:11,542 - INFO - Beginning epoch 115/800
2025-03-07 12:23:11,550 - INFO - training batch 1, loss: 0.136, 32/28000 datapoints
2025-03-07 12:23:11,831 - INFO - training batch 51, loss: 0.105, 1632/28000 datapoints
2025-03-07 12:23:12,121 - INFO - training batch 101, loss: 0.085, 3232/28000 datapoints
2025-03-07 12:23:12,407 - INFO - training batch 151, loss: 0.077, 4832/28000 datapoints
2025-03-07 12:23:12,696 - INFO - training batch 201, loss: 0.095, 6432/28000 datapoints
2025-03-07 12:23:12,981 - INFO - training batch 251, loss: 0.145, 8032/28000 datapoints
2025-03-07 12:23:13,356 - INFO - training batch 301, loss: 0.272, 9632/28000 datapoints
2025-03-07 12:23:13,757 - INFO - training batch 351, loss: 0.138, 11232/28000 datapoints
2025-03-07 12:23:14,052 - INFO - training batch 401, loss: 0.163, 12832/28000 datapoints
2025-03-07 12:23:14,343 - INFO - training batch 451, loss: 0.177, 14432/28000 datapoints
2025-03-07 12:23:14,637 - INFO - training batch 501, loss: 0.088, 16032/28000 datapoints
2025-03-07 12:23:14,924 - INFO - training batch 551, loss: 0.096, 17632/28000 datapoints
2025-03-07 12:23:15,219 - INFO - training batch 601, loss: 0.123, 19232/28000 datapoints
2025-03-07 12:23:15,511 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-07 12:23:15,816 - INFO - training batch 701, loss: 0.233, 22432/28000 datapoints
2025-03-07 12:23:16,110 - INFO - training batch 751, loss: 0.092, 24032/28000 datapoints
2025-03-07 12:23:16,395 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-07 12:23:16,682 - INFO - training batch 851, loss: 0.165, 27232/28000 datapoints
2025-03-07 12:23:16,821 - INFO - validation batch 1, loss: 0.064, 32/6976 datapoints
2025-03-07 12:23:16,896 - INFO - validation batch 51, loss: 0.788, 1632/6976 datapoints
2025-03-07 12:23:16,971 - INFO - validation batch 101, loss: 0.185, 3232/6976 datapoints
2025-03-07 12:23:17,047 - INFO - validation batch 151, loss: 0.299, 4832/6976 datapoints
2025-03-07 12:23:17,125 - INFO - validation batch 201, loss: 0.357, 6432/6976 datapoints
2025-03-07 12:23:17,149 - INFO - Epoch 115/800 done.
2025-03-07 12:23:17,149 - INFO - Final validation performance:
Loss: 0.339, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:23:17,150 - INFO - Beginning epoch 116/800
2025-03-07 12:23:17,157 - INFO - training batch 1, loss: 0.135, 32/28000 datapoints
2025-03-07 12:23:17,451 - INFO - training batch 51, loss: 0.103, 1632/28000 datapoints
2025-03-07 12:23:17,732 - INFO - training batch 101, loss: 0.084, 3232/28000 datapoints
2025-03-07 12:23:18,015 - INFO - training batch 151, loss: 0.074, 4832/28000 datapoints
2025-03-07 12:23:18,299 - INFO - training batch 201, loss: 0.093, 6432/28000 datapoints
2025-03-07 12:23:18,589 - INFO - training batch 251, loss: 0.141, 8032/28000 datapoints
2025-03-07 12:23:18,874 - INFO - training batch 301, loss: 0.266, 9632/28000 datapoints
2025-03-07 12:23:19,161 - INFO - training batch 351, loss: 0.136, 11232/28000 datapoints
2025-03-07 12:23:19,514 - INFO - training batch 401, loss: 0.157, 12832/28000 datapoints
2025-03-07 12:23:19,802 - INFO - training batch 451, loss: 0.172, 14432/28000 datapoints
2025-03-07 12:23:20,101 - INFO - training batch 501, loss: 0.086, 16032/28000 datapoints
2025-03-07 12:23:20,409 - INFO - training batch 551, loss: 0.093, 17632/28000 datapoints
2025-03-07 12:23:20,701 - INFO - training batch 601, loss: 0.119, 19232/28000 datapoints
2025-03-07 12:23:21,005 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-07 12:23:21,289 - INFO - training batch 701, loss: 0.230, 22432/28000 datapoints
2025-03-07 12:23:21,567 - INFO - training batch 751, loss: 0.091, 24032/28000 datapoints
2025-03-07 12:23:21,847 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-07 12:23:22,134 - INFO - training batch 851, loss: 0.159, 27232/28000 datapoints
2025-03-07 12:23:22,273 - INFO - validation batch 1, loss: 0.064, 32/6976 datapoints
2025-03-07 12:23:22,346 - INFO - validation batch 51, loss: 0.790, 1632/6976 datapoints
2025-03-07 12:23:22,424 - INFO - validation batch 101, loss: 0.186, 3232/6976 datapoints
2025-03-07 12:23:22,505 - INFO - validation batch 151, loss: 0.300, 4832/6976 datapoints
2025-03-07 12:23:22,587 - INFO - validation batch 201, loss: 0.356, 6432/6976 datapoints
2025-03-07 12:23:22,613 - INFO - Epoch 116/800 done.
2025-03-07 12:23:22,614 - INFO - Final validation performance:
Loss: 0.339, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:23:22,615 - INFO - Beginning epoch 117/800
2025-03-07 12:23:22,624 - INFO - training batch 1, loss: 0.133, 32/28000 datapoints
2025-03-07 12:23:22,917 - INFO - training batch 51, loss: 0.102, 1632/28000 datapoints
2025-03-07 12:23:23,213 - INFO - training batch 101, loss: 0.082, 3232/28000 datapoints
2025-03-07 12:23:23,544 - INFO - training batch 151, loss: 0.070, 4832/28000 datapoints
2025-03-07 12:23:23,869 - INFO - training batch 201, loss: 0.090, 6432/28000 datapoints
2025-03-07 12:23:24,204 - INFO - training batch 251, loss: 0.137, 8032/28000 datapoints
2025-03-07 12:23:24,549 - INFO - training batch 301, loss: 0.260, 9632/28000 datapoints
2025-03-07 12:23:24,891 - INFO - training batch 351, loss: 0.134, 11232/28000 datapoints
2025-03-07 12:23:25,221 - INFO - training batch 401, loss: 0.152, 12832/28000 datapoints
2025-03-07 12:23:25,573 - INFO - training batch 451, loss: 0.167, 14432/28000 datapoints
2025-03-07 12:23:25,890 - INFO - training batch 501, loss: 0.084, 16032/28000 datapoints
2025-03-07 12:23:26,197 - INFO - training batch 551, loss: 0.090, 17632/28000 datapoints
2025-03-07 12:23:26,501 - INFO - training batch 601, loss: 0.115, 19232/28000 datapoints
2025-03-07 12:23:26,794 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-07 12:23:27,086 - INFO - training batch 701, loss: 0.226, 22432/28000 datapoints
2025-03-07 12:23:27,365 - INFO - training batch 751, loss: 0.090, 24032/28000 datapoints
2025-03-07 12:23:27,663 - INFO - training batch 801, loss: 0.092, 25632/28000 datapoints
2025-03-07 12:23:27,951 - INFO - training batch 851, loss: 0.154, 27232/28000 datapoints
2025-03-07 12:23:28,089 - INFO - validation batch 1, loss: 0.064, 32/6976 datapoints
2025-03-07 12:23:28,163 - INFO - validation batch 51, loss: 0.791, 1632/6976 datapoints
2025-03-07 12:23:28,236 - INFO - validation batch 101, loss: 0.185, 3232/6976 datapoints
2025-03-07 12:23:28,308 - INFO - validation batch 151, loss: 0.302, 4832/6976 datapoints
2025-03-07 12:23:28,383 - INFO - validation batch 201, loss: 0.355, 6432/6976 datapoints
2025-03-07 12:23:28,407 - INFO - Epoch 117/800 done.
2025-03-07 12:23:28,407 - INFO - Final validation performance:
Loss: 0.339, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:23:28,408 - INFO - Beginning epoch 118/800
2025-03-07 12:23:28,418 - INFO - training batch 1, loss: 0.131, 32/28000 datapoints
2025-03-07 12:23:28,714 - INFO - training batch 51, loss: 0.100, 1632/28000 datapoints
2025-03-07 12:23:28,997 - INFO - training batch 101, loss: 0.080, 3232/28000 datapoints
2025-03-07 12:23:29,278 - INFO - training batch 151, loss: 0.067, 4832/28000 datapoints
2025-03-07 12:23:29,566 - INFO - training batch 201, loss: 0.088, 6432/28000 datapoints
2025-03-07 12:23:29,885 - INFO - training batch 251, loss: 0.133, 8032/28000 datapoints
2025-03-07 12:23:30,171 - INFO - training batch 301, loss: 0.254, 9632/28000 datapoints
2025-03-07 12:23:30,639 - INFO - training batch 351, loss: 0.132, 11232/28000 datapoints
2025-03-07 12:23:31,134 - INFO - training batch 401, loss: 0.148, 12832/28000 datapoints
2025-03-07 12:23:31,427 - INFO - training batch 451, loss: 0.161, 14432/28000 datapoints
2025-03-07 12:23:31,728 - INFO - training batch 501, loss: 0.082, 16032/28000 datapoints
2025-03-07 12:23:32,020 - INFO - training batch 551, loss: 0.087, 17632/28000 datapoints
2025-03-07 12:23:32,307 - INFO - training batch 601, loss: 0.111, 19232/28000 datapoints
2025-03-07 12:23:32,600 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-07 12:23:32,892 - INFO - training batch 701, loss: 0.223, 22432/28000 datapoints
2025-03-07 12:23:33,178 - INFO - training batch 751, loss: 0.089, 24032/28000 datapoints
2025-03-07 12:23:33,480 - INFO - training batch 801, loss: 0.089, 25632/28000 datapoints
2025-03-07 12:23:33,876 - INFO - training batch 851, loss: 0.149, 27232/28000 datapoints
2025-03-07 12:23:34,113 - INFO - validation batch 1, loss: 0.064, 32/6976 datapoints
2025-03-07 12:23:34,240 - INFO - validation batch 51, loss: 0.794, 1632/6976 datapoints
2025-03-07 12:23:34,354 - INFO - validation batch 101, loss: 0.184, 3232/6976 datapoints
2025-03-07 12:23:34,478 - INFO - validation batch 151, loss: 0.302, 4832/6976 datapoints
2025-03-07 12:23:34,556 - INFO - validation batch 201, loss: 0.352, 6432/6976 datapoints
2025-03-07 12:23:34,584 - INFO - Epoch 118/800 done.
2025-03-07 12:23:34,585 - INFO - Final validation performance:
Loss: 0.339, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:23:34,585 - INFO - Beginning epoch 119/800
2025-03-07 12:23:34,593 - INFO - training batch 1, loss: 0.129, 32/28000 datapoints
2025-03-07 12:23:34,886 - INFO - training batch 51, loss: 0.099, 1632/28000 datapoints
2025-03-07 12:23:35,179 - INFO - training batch 101, loss: 0.079, 3232/28000 datapoints
2025-03-07 12:23:35,472 - INFO - training batch 151, loss: 0.064, 4832/28000 datapoints
2025-03-07 12:23:35,760 - INFO - training batch 201, loss: 0.086, 6432/28000 datapoints
2025-03-07 12:23:36,047 - INFO - training batch 251, loss: 0.129, 8032/28000 datapoints
2025-03-07 12:23:36,334 - INFO - training batch 301, loss: 0.247, 9632/28000 datapoints
2025-03-07 12:23:36,625 - INFO - training batch 351, loss: 0.130, 11232/28000 datapoints
2025-03-07 12:23:36,911 - INFO - training batch 401, loss: 0.143, 12832/28000 datapoints
2025-03-07 12:23:37,202 - INFO - training batch 451, loss: 0.157, 14432/28000 datapoints
2025-03-07 12:23:37,490 - INFO - training batch 501, loss: 0.081, 16032/28000 datapoints
2025-03-07 12:23:37,782 - INFO - training batch 551, loss: 0.084, 17632/28000 datapoints
2025-03-07 12:23:38,066 - INFO - training batch 601, loss: 0.108, 19232/28000 datapoints
2025-03-07 12:23:38,349 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-07 12:23:38,632 - INFO - training batch 701, loss: 0.220, 22432/28000 datapoints
2025-03-07 12:23:38,938 - INFO - training batch 751, loss: 0.088, 24032/28000 datapoints
2025-03-07 12:23:39,237 - INFO - training batch 801, loss: 0.087, 25632/28000 datapoints
2025-03-07 12:23:39,519 - INFO - training batch 851, loss: 0.144, 27232/28000 datapoints
2025-03-07 12:23:39,660 - INFO - validation batch 1, loss: 0.064, 32/6976 datapoints
2025-03-07 12:23:39,735 - INFO - validation batch 51, loss: 0.797, 1632/6976 datapoints
2025-03-07 12:23:39,808 - INFO - validation batch 101, loss: 0.183, 3232/6976 datapoints
2025-03-07 12:23:39,882 - INFO - validation batch 151, loss: 0.303, 4832/6976 datapoints
2025-03-07 12:23:39,956 - INFO - validation batch 201, loss: 0.352, 6432/6976 datapoints
2025-03-07 12:23:39,984 - INFO - Epoch 119/800 done.
2025-03-07 12:23:39,984 - INFO - Final validation performance:
Loss: 0.340, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:23:39,985 - INFO - Beginning epoch 120/800
2025-03-07 12:23:39,993 - INFO - training batch 1, loss: 0.127, 32/28000 datapoints
2025-03-07 12:23:40,283 - INFO - training batch 51, loss: 0.097, 1632/28000 datapoints
2025-03-07 12:23:40,622 - INFO - training batch 101, loss: 0.077, 3232/28000 datapoints
2025-03-07 12:23:40,953 - INFO - training batch 151, loss: 0.061, 4832/28000 datapoints
2025-03-07 12:23:41,235 - INFO - training batch 201, loss: 0.084, 6432/28000 datapoints
2025-03-07 12:23:41,521 - INFO - training batch 251, loss: 0.126, 8032/28000 datapoints
2025-03-07 12:23:41,805 - INFO - training batch 301, loss: 0.240, 9632/28000 datapoints
2025-03-07 12:23:42,084 - INFO - training batch 351, loss: 0.128, 11232/28000 datapoints
2025-03-07 12:23:42,368 - INFO - training batch 401, loss: 0.138, 12832/28000 datapoints
2025-03-07 12:23:42,650 - INFO - training batch 451, loss: 0.151, 14432/28000 datapoints
2025-03-07 12:23:42,932 - INFO - training batch 501, loss: 0.079, 16032/28000 datapoints
2025-03-07 12:23:43,238 - INFO - training batch 551, loss: 0.082, 17632/28000 datapoints
2025-03-07 12:23:43,531 - INFO - training batch 601, loss: 0.105, 19232/28000 datapoints
2025-03-07 12:23:43,895 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-07 12:23:44,196 - INFO - training batch 701, loss: 0.216, 22432/28000 datapoints
2025-03-07 12:23:44,483 - INFO - training batch 751, loss: 0.087, 24032/28000 datapoints
2025-03-07 12:23:44,773 - INFO - training batch 801, loss: 0.084, 25632/28000 datapoints
2025-03-07 12:23:45,059 - INFO - training batch 851, loss: 0.139, 27232/28000 datapoints
2025-03-07 12:23:45,202 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 12:23:45,281 - INFO - validation batch 51, loss: 0.799, 1632/6976 datapoints
2025-03-07 12:23:45,357 - INFO - validation batch 101, loss: 0.183, 3232/6976 datapoints
2025-03-07 12:23:45,433 - INFO - validation batch 151, loss: 0.304, 4832/6976 datapoints
2025-03-07 12:23:45,516 - INFO - validation batch 201, loss: 0.350, 6432/6976 datapoints
2025-03-07 12:23:45,544 - INFO - Epoch 120/800 done.
2025-03-07 12:23:45,544 - INFO - Final validation performance:
Loss: 0.340, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:23:45,544 - INFO - Beginning epoch 121/800
2025-03-07 12:23:45,552 - INFO - training batch 1, loss: 0.125, 32/28000 datapoints
2025-03-07 12:23:45,845 - INFO - training batch 51, loss: 0.095, 1632/28000 datapoints
2025-03-07 12:23:46,126 - INFO - training batch 101, loss: 0.074, 3232/28000 datapoints
2025-03-07 12:23:46,407 - INFO - training batch 151, loss: 0.058, 4832/28000 datapoints
2025-03-07 12:23:46,689 - INFO - training batch 201, loss: 0.083, 6432/28000 datapoints
2025-03-07 12:23:46,976 - INFO - training batch 251, loss: 0.121, 8032/28000 datapoints
2025-03-07 12:23:47,259 - INFO - training batch 301, loss: 0.233, 9632/28000 datapoints
2025-03-07 12:23:47,576 - INFO - training batch 351, loss: 0.126, 11232/28000 datapoints
2025-03-07 12:23:47,862 - INFO - training batch 401, loss: 0.134, 12832/28000 datapoints
2025-03-07 12:23:48,141 - INFO - training batch 451, loss: 0.147, 14432/28000 datapoints
2025-03-07 12:23:48,429 - INFO - training batch 501, loss: 0.078, 16032/28000 datapoints
2025-03-07 12:23:48,712 - INFO - training batch 551, loss: 0.079, 17632/28000 datapoints
2025-03-07 12:23:48,998 - INFO - training batch 601, loss: 0.101, 19232/28000 datapoints
2025-03-07 12:23:49,284 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-07 12:23:49,574 - INFO - training batch 701, loss: 0.212, 22432/28000 datapoints
2025-03-07 12:23:49,868 - INFO - training batch 751, loss: 0.086, 24032/28000 datapoints
2025-03-07 12:23:50,149 - INFO - training batch 801, loss: 0.081, 25632/28000 datapoints
2025-03-07 12:23:50,454 - INFO - training batch 851, loss: 0.134, 27232/28000 datapoints
2025-03-07 12:23:50,623 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 12:23:50,716 - INFO - validation batch 51, loss: 0.802, 1632/6976 datapoints
2025-03-07 12:23:50,796 - INFO - validation batch 101, loss: 0.183, 3232/6976 datapoints
2025-03-07 12:23:50,871 - INFO - validation batch 151, loss: 0.304, 4832/6976 datapoints
2025-03-07 12:23:50,971 - INFO - validation batch 201, loss: 0.349, 6432/6976 datapoints
2025-03-07 12:23:51,002 - INFO - Epoch 121/800 done.
2025-03-07 12:23:51,002 - INFO - Final validation performance:
Loss: 0.340, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:23:51,004 - INFO - Beginning epoch 122/800
2025-03-07 12:23:51,012 - INFO - training batch 1, loss: 0.124, 32/28000 datapoints
2025-03-07 12:23:51,302 - INFO - training batch 51, loss: 0.094, 1632/28000 datapoints
2025-03-07 12:23:51,595 - INFO - training batch 101, loss: 0.073, 3232/28000 datapoints
2025-03-07 12:23:51,913 - INFO - training batch 151, loss: 0.056, 4832/28000 datapoints
2025-03-07 12:23:52,200 - INFO - training batch 201, loss: 0.081, 6432/28000 datapoints
2025-03-07 12:23:52,492 - INFO - training batch 251, loss: 0.118, 8032/28000 datapoints
2025-03-07 12:23:52,786 - INFO - training batch 301, loss: 0.227, 9632/28000 datapoints
2025-03-07 12:23:53,075 - INFO - training batch 351, loss: 0.124, 11232/28000 datapoints
2025-03-07 12:23:53,365 - INFO - training batch 401, loss: 0.129, 12832/28000 datapoints
2025-03-07 12:23:53,660 - INFO - training batch 451, loss: 0.142, 14432/28000 datapoints
2025-03-07 12:23:53,988 - INFO - training batch 501, loss: 0.076, 16032/28000 datapoints
2025-03-07 12:23:54,383 - INFO - training batch 551, loss: 0.077, 17632/28000 datapoints
2025-03-07 12:23:54,740 - INFO - training batch 601, loss: 0.098, 19232/28000 datapoints
2025-03-07 12:23:55,073 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-07 12:23:55,408 - INFO - training batch 701, loss: 0.208, 22432/28000 datapoints
2025-03-07 12:23:55,763 - INFO - training batch 751, loss: 0.084, 24032/28000 datapoints
2025-03-07 12:23:56,149 - INFO - training batch 801, loss: 0.079, 25632/28000 datapoints
2025-03-07 12:23:56,508 - INFO - training batch 851, loss: 0.130, 27232/28000 datapoints
2025-03-07 12:23:56,663 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 12:23:56,746 - INFO - validation batch 51, loss: 0.804, 1632/6976 datapoints
2025-03-07 12:23:56,829 - INFO - validation batch 101, loss: 0.182, 3232/6976 datapoints
2025-03-07 12:23:56,910 - INFO - validation batch 151, loss: 0.305, 4832/6976 datapoints
2025-03-07 12:23:56,994 - INFO - validation batch 201, loss: 0.348, 6432/6976 datapoints
2025-03-07 12:23:57,024 - INFO - Epoch 122/800 done.
2025-03-07 12:23:57,024 - INFO - Final validation performance:
Loss: 0.340, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:23:57,025 - INFO - Beginning epoch 123/800
2025-03-07 12:23:57,033 - INFO - training batch 1, loss: 0.122, 32/28000 datapoints
2025-03-07 12:23:57,340 - INFO - training batch 51, loss: 0.092, 1632/28000 datapoints
2025-03-07 12:23:57,642 - INFO - training batch 101, loss: 0.071, 3232/28000 datapoints
2025-03-07 12:23:57,937 - INFO - training batch 151, loss: 0.053, 4832/28000 datapoints
2025-03-07 12:23:58,260 - INFO - training batch 201, loss: 0.078, 6432/28000 datapoints
2025-03-07 12:23:58,555 - INFO - training batch 251, loss: 0.115, 8032/28000 datapoints
2025-03-07 12:23:58,838 - INFO - training batch 301, loss: 0.220, 9632/28000 datapoints
2025-03-07 12:23:59,131 - INFO - training batch 351, loss: 0.123, 11232/28000 datapoints
2025-03-07 12:23:59,418 - INFO - training batch 401, loss: 0.125, 12832/28000 datapoints
2025-03-07 12:23:59,702 - INFO - training batch 451, loss: 0.137, 14432/28000 datapoints
2025-03-07 12:23:59,985 - INFO - training batch 501, loss: 0.075, 16032/28000 datapoints
2025-03-07 12:24:00,264 - INFO - training batch 551, loss: 0.074, 17632/28000 datapoints
2025-03-07 12:24:00,588 - INFO - training batch 601, loss: 0.095, 19232/28000 datapoints
2025-03-07 12:24:00,914 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-07 12:24:01,201 - INFO - training batch 701, loss: 0.204, 22432/28000 datapoints
2025-03-07 12:24:01,494 - INFO - training batch 751, loss: 0.084, 24032/28000 datapoints
2025-03-07 12:24:01,784 - INFO - training batch 801, loss: 0.077, 25632/28000 datapoints
2025-03-07 12:24:02,078 - INFO - training batch 851, loss: 0.125, 27232/28000 datapoints
2025-03-07 12:24:02,219 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 12:24:02,296 - INFO - validation batch 51, loss: 0.807, 1632/6976 datapoints
2025-03-07 12:24:02,370 - INFO - validation batch 101, loss: 0.181, 3232/6976 datapoints
2025-03-07 12:24:02,447 - INFO - validation batch 151, loss: 0.305, 4832/6976 datapoints
2025-03-07 12:24:02,522 - INFO - validation batch 201, loss: 0.346, 6432/6976 datapoints
2025-03-07 12:24:02,546 - INFO - Epoch 123/800 done.
2025-03-07 12:24:02,546 - INFO - Final validation performance:
Loss: 0.340, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:24:02,547 - INFO - Beginning epoch 124/800
2025-03-07 12:24:02,554 - INFO - training batch 1, loss: 0.120, 32/28000 datapoints
2025-03-07 12:24:02,843 - INFO - training batch 51, loss: 0.090, 1632/28000 datapoints
2025-03-07 12:24:03,134 - INFO - training batch 101, loss: 0.070, 3232/28000 datapoints
2025-03-07 12:24:03,412 - INFO - training batch 151, loss: 0.051, 4832/28000 datapoints
2025-03-07 12:24:03,696 - INFO - training batch 201, loss: 0.076, 6432/28000 datapoints
2025-03-07 12:24:03,988 - INFO - training batch 251, loss: 0.111, 8032/28000 datapoints
2025-03-07 12:24:04,321 - INFO - training batch 301, loss: 0.214, 9632/28000 datapoints
2025-03-07 12:24:04,619 - INFO - training batch 351, loss: 0.121, 11232/28000 datapoints
2025-03-07 12:24:04,918 - INFO - training batch 401, loss: 0.121, 12832/28000 datapoints
2025-03-07 12:24:05,224 - INFO - training batch 451, loss: 0.133, 14432/28000 datapoints
2025-03-07 12:24:05,516 - INFO - training batch 501, loss: 0.073, 16032/28000 datapoints
2025-03-07 12:24:05,808 - INFO - training batch 551, loss: 0.072, 17632/28000 datapoints
2025-03-07 12:24:06,136 - INFO - training batch 601, loss: 0.092, 19232/28000 datapoints
2025-03-07 12:24:06,446 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-07 12:24:06,733 - INFO - training batch 701, loss: 0.200, 22432/28000 datapoints
2025-03-07 12:24:07,019 - INFO - training batch 751, loss: 0.083, 24032/28000 datapoints
2025-03-07 12:24:07,298 - INFO - training batch 801, loss: 0.074, 25632/28000 datapoints
2025-03-07 12:24:07,592 - INFO - training batch 851, loss: 0.121, 27232/28000 datapoints
2025-03-07 12:24:07,743 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 12:24:07,833 - INFO - validation batch 51, loss: 0.809, 1632/6976 datapoints
2025-03-07 12:24:07,906 - INFO - validation batch 101, loss: 0.181, 3232/6976 datapoints
2025-03-07 12:24:07,981 - INFO - validation batch 151, loss: 0.306, 4832/6976 datapoints
2025-03-07 12:24:08,057 - INFO - validation batch 201, loss: 0.346, 6432/6976 datapoints
2025-03-07 12:24:08,085 - INFO - Epoch 124/800 done.
2025-03-07 12:24:08,085 - INFO - Final validation performance:
Loss: 0.341, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:24:08,085 - INFO - Beginning epoch 125/800
2025-03-07 12:24:08,095 - INFO - training batch 1, loss: 0.119, 32/28000 datapoints
2025-03-07 12:24:08,380 - INFO - training batch 51, loss: 0.088, 1632/28000 datapoints
2025-03-07 12:24:08,665 - INFO - training batch 101, loss: 0.068, 3232/28000 datapoints
2025-03-07 12:24:08,946 - INFO - training batch 151, loss: 0.049, 4832/28000 datapoints
2025-03-07 12:24:09,256 - INFO - training batch 201, loss: 0.074, 6432/28000 datapoints
2025-03-07 12:24:09,547 - INFO - training batch 251, loss: 0.107, 8032/28000 datapoints
2025-03-07 12:24:09,834 - INFO - training batch 301, loss: 0.206, 9632/28000 datapoints
2025-03-07 12:24:10,113 - INFO - training batch 351, loss: 0.119, 11232/28000 datapoints
2025-03-07 12:24:10,397 - INFO - training batch 401, loss: 0.117, 12832/28000 datapoints
2025-03-07 12:24:10,712 - INFO - training batch 451, loss: 0.129, 14432/28000 datapoints
2025-03-07 12:24:11,003 - INFO - training batch 501, loss: 0.071, 16032/28000 datapoints
2025-03-07 12:24:11,281 - INFO - training batch 551, loss: 0.070, 17632/28000 datapoints
2025-03-07 12:24:11,569 - INFO - training batch 601, loss: 0.089, 19232/28000 datapoints
2025-03-07 12:24:11,864 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-07 12:24:12,146 - INFO - training batch 701, loss: 0.196, 22432/28000 datapoints
2025-03-07 12:24:12,427 - INFO - training batch 751, loss: 0.082, 24032/28000 datapoints
2025-03-07 12:24:12,716 - INFO - training batch 801, loss: 0.072, 25632/28000 datapoints
2025-03-07 12:24:13,014 - INFO - training batch 851, loss: 0.117, 27232/28000 datapoints
2025-03-07 12:24:13,157 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 12:24:13,231 - INFO - validation batch 51, loss: 0.813, 1632/6976 datapoints
2025-03-07 12:24:13,307 - INFO - validation batch 101, loss: 0.179, 3232/6976 datapoints
2025-03-07 12:24:13,386 - INFO - validation batch 151, loss: 0.307, 4832/6976 datapoints
2025-03-07 12:24:13,485 - INFO - validation batch 201, loss: 0.343, 6432/6976 datapoints
2025-03-07 12:24:13,520 - INFO - Epoch 125/800 done.
2025-03-07 12:24:13,521 - INFO - Final validation performance:
Loss: 0.341, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:24:13,521 - INFO - Beginning epoch 126/800
2025-03-07 12:24:13,531 - INFO - training batch 1, loss: 0.117, 32/28000 datapoints
2025-03-07 12:24:13,833 - INFO - training batch 51, loss: 0.086, 1632/28000 datapoints
2025-03-07 12:24:14,125 - INFO - training batch 101, loss: 0.066, 3232/28000 datapoints
2025-03-07 12:24:14,493 - INFO - training batch 151, loss: 0.047, 4832/28000 datapoints
2025-03-07 12:24:14,932 - INFO - training batch 201, loss: 0.073, 6432/28000 datapoints
2025-03-07 12:24:15,234 - INFO - training batch 251, loss: 0.105, 8032/28000 datapoints
2025-03-07 12:24:15,525 - INFO - training batch 301, loss: 0.198, 9632/28000 datapoints
2025-03-07 12:24:15,819 - INFO - training batch 351, loss: 0.117, 11232/28000 datapoints
2025-03-07 12:24:16,107 - INFO - training batch 401, loss: 0.113, 12832/28000 datapoints
2025-03-07 12:24:16,396 - INFO - training batch 451, loss: 0.124, 14432/28000 datapoints
2025-03-07 12:24:16,686 - INFO - training batch 501, loss: 0.070, 16032/28000 datapoints
2025-03-07 12:24:16,968 - INFO - training batch 551, loss: 0.067, 17632/28000 datapoints
2025-03-07 12:24:17,252 - INFO - training batch 601, loss: 0.086, 19232/28000 datapoints
2025-03-07 12:24:17,530 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-07 12:24:17,852 - INFO - training batch 701, loss: 0.193, 22432/28000 datapoints
2025-03-07 12:24:18,137 - INFO - training batch 751, loss: 0.081, 24032/28000 datapoints
2025-03-07 12:24:18,417 - INFO - training batch 801, loss: 0.070, 25632/28000 datapoints
2025-03-07 12:24:18,698 - INFO - training batch 851, loss: 0.112, 27232/28000 datapoints
2025-03-07 12:24:18,836 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 12:24:18,910 - INFO - validation batch 51, loss: 0.816, 1632/6976 datapoints
2025-03-07 12:24:18,982 - INFO - validation batch 101, loss: 0.180, 3232/6976 datapoints
2025-03-07 12:24:19,056 - INFO - validation batch 151, loss: 0.307, 4832/6976 datapoints
2025-03-07 12:24:19,311 - INFO - validation batch 201, loss: 0.343, 6432/6976 datapoints
2025-03-07 12:24:19,339 - INFO - Epoch 126/800 done.
2025-03-07 12:24:19,339 - INFO - Final validation performance:
Loss: 0.342, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:24:19,340 - INFO - Beginning epoch 127/800
2025-03-07 12:24:19,347 - INFO - training batch 1, loss: 0.116, 32/28000 datapoints
2025-03-07 12:24:19,639 - INFO - training batch 51, loss: 0.085, 1632/28000 datapoints
2025-03-07 12:24:19,923 - INFO - training batch 101, loss: 0.064, 3232/28000 datapoints
2025-03-07 12:24:20,205 - INFO - training batch 151, loss: 0.045, 4832/28000 datapoints
2025-03-07 12:24:20,487 - INFO - training batch 201, loss: 0.071, 6432/28000 datapoints
2025-03-07 12:24:20,804 - INFO - training batch 251, loss: 0.101, 8032/28000 datapoints
2025-03-07 12:24:21,096 - INFO - training batch 301, loss: 0.190, 9632/28000 datapoints
2025-03-07 12:24:21,377 - INFO - training batch 351, loss: 0.115, 11232/28000 datapoints
2025-03-07 12:24:21,659 - INFO - training batch 401, loss: 0.110, 12832/28000 datapoints
2025-03-07 12:24:21,968 - INFO - training batch 451, loss: 0.120, 14432/28000 datapoints
2025-03-07 12:24:22,297 - INFO - training batch 501, loss: 0.068, 16032/28000 datapoints
2025-03-07 12:24:22,600 - INFO - training batch 551, loss: 0.066, 17632/28000 datapoints
2025-03-07 12:24:22,883 - INFO - training batch 601, loss: 0.083, 19232/28000 datapoints
2025-03-07 12:24:23,161 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-07 12:24:23,439 - INFO - training batch 701, loss: 0.188, 22432/28000 datapoints
2025-03-07 12:24:23,725 - INFO - training batch 751, loss: 0.080, 24032/28000 datapoints
2025-03-07 12:24:24,004 - INFO - training batch 801, loss: 0.067, 25632/28000 datapoints
2025-03-07 12:24:24,283 - INFO - training batch 851, loss: 0.109, 27232/28000 datapoints
2025-03-07 12:24:24,439 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 12:24:24,540 - INFO - validation batch 51, loss: 0.817, 1632/6976 datapoints
2025-03-07 12:24:24,626 - INFO - validation batch 101, loss: 0.178, 3232/6976 datapoints
2025-03-07 12:24:24,703 - INFO - validation batch 151, loss: 0.310, 4832/6976 datapoints
2025-03-07 12:24:24,817 - INFO - validation batch 201, loss: 0.343, 6432/6976 datapoints
2025-03-07 12:24:24,849 - INFO - Epoch 127/800 done.
2025-03-07 12:24:24,849 - INFO - Final validation performance:
Loss: 0.342, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:24:24,850 - INFO - Beginning epoch 128/800
2025-03-07 12:24:24,858 - INFO - training batch 1, loss: 0.115, 32/28000 datapoints
2025-03-07 12:24:25,202 - INFO - training batch 51, loss: 0.083, 1632/28000 datapoints
2025-03-07 12:24:25,534 - INFO - training batch 101, loss: 0.063, 3232/28000 datapoints
2025-03-07 12:24:25,877 - INFO - training batch 151, loss: 0.043, 4832/28000 datapoints
2025-03-07 12:24:26,209 - INFO - training batch 201, loss: 0.070, 6432/28000 datapoints
2025-03-07 12:24:26,540 - INFO - training batch 251, loss: 0.098, 8032/28000 datapoints
2025-03-07 12:24:26,862 - INFO - training batch 301, loss: 0.184, 9632/28000 datapoints
2025-03-07 12:24:27,196 - INFO - training batch 351, loss: 0.113, 11232/28000 datapoints
2025-03-07 12:24:27,508 - INFO - training batch 401, loss: 0.106, 12832/28000 datapoints
2025-03-07 12:24:27,826 - INFO - training batch 451, loss: 0.116, 14432/28000 datapoints
2025-03-07 12:24:28,122 - INFO - training batch 501, loss: 0.066, 16032/28000 datapoints
2025-03-07 12:24:28,419 - INFO - training batch 551, loss: 0.064, 17632/28000 datapoints
2025-03-07 12:24:28,708 - INFO - training batch 601, loss: 0.081, 19232/28000 datapoints
2025-03-07 12:24:28,988 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-07 12:24:29,273 - INFO - training batch 701, loss: 0.185, 22432/28000 datapoints
2025-03-07 12:24:29,555 - INFO - training batch 751, loss: 0.079, 24032/28000 datapoints
2025-03-07 12:24:29,841 - INFO - training batch 801, loss: 0.065, 25632/28000 datapoints
2025-03-07 12:24:30,120 - INFO - training batch 851, loss: 0.105, 27232/28000 datapoints
2025-03-07 12:24:30,258 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 12:24:30,330 - INFO - validation batch 51, loss: 0.822, 1632/6976 datapoints
2025-03-07 12:24:30,403 - INFO - validation batch 101, loss: 0.178, 3232/6976 datapoints
2025-03-07 12:24:30,547 - INFO - validation batch 151, loss: 0.312, 4832/6976 datapoints
2025-03-07 12:24:30,620 - INFO - validation batch 201, loss: 0.343, 6432/6976 datapoints
2025-03-07 12:24:30,647 - INFO - Epoch 128/800 done.
2025-03-07 12:24:30,647 - INFO - Final validation performance:
Loss: 0.343, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:24:30,648 - INFO - Beginning epoch 129/800
2025-03-07 12:24:30,656 - INFO - training batch 1, loss: 0.113, 32/28000 datapoints
2025-03-07 12:24:30,980 - INFO - training batch 51, loss: 0.081, 1632/28000 datapoints
2025-03-07 12:24:31,263 - INFO - training batch 101, loss: 0.060, 3232/28000 datapoints
2025-03-07 12:24:31,546 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-07 12:24:31,834 - INFO - training batch 201, loss: 0.069, 6432/28000 datapoints
2025-03-07 12:24:32,120 - INFO - training batch 251, loss: 0.095, 8032/28000 datapoints
2025-03-07 12:24:32,402 - INFO - training batch 301, loss: 0.176, 9632/28000 datapoints
2025-03-07 12:24:32,689 - INFO - training batch 351, loss: 0.111, 11232/28000 datapoints
2025-03-07 12:24:32,980 - INFO - training batch 401, loss: 0.102, 12832/28000 datapoints
2025-03-07 12:24:33,266 - INFO - training batch 451, loss: 0.113, 14432/28000 datapoints
2025-03-07 12:24:33,547 - INFO - training batch 501, loss: 0.065, 16032/28000 datapoints
2025-03-07 12:24:33,827 - INFO - training batch 551, loss: 0.062, 17632/28000 datapoints
2025-03-07 12:24:34,104 - INFO - training batch 601, loss: 0.078, 19232/28000 datapoints
2025-03-07 12:24:34,386 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-07 12:24:34,700 - INFO - training batch 701, loss: 0.181, 22432/28000 datapoints
2025-03-07 12:24:35,113 - INFO - training batch 751, loss: 0.078, 24032/28000 datapoints
2025-03-07 12:24:35,431 - INFO - training batch 801, loss: 0.063, 25632/28000 datapoints
2025-03-07 12:24:35,724 - INFO - training batch 851, loss: 0.101, 27232/28000 datapoints
2025-03-07 12:24:35,870 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 12:24:35,947 - INFO - validation batch 51, loss: 0.825, 1632/6976 datapoints
2025-03-07 12:24:36,025 - INFO - validation batch 101, loss: 0.177, 3232/6976 datapoints
2025-03-07 12:24:36,106 - INFO - validation batch 151, loss: 0.312, 4832/6976 datapoints
2025-03-07 12:24:36,185 - INFO - validation batch 201, loss: 0.342, 6432/6976 datapoints
2025-03-07 12:24:36,210 - INFO - Epoch 129/800 done.
2025-03-07 12:24:36,210 - INFO - Final validation performance:
Loss: 0.344, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:24:36,211 - INFO - Beginning epoch 130/800
2025-03-07 12:24:36,220 - INFO - training batch 1, loss: 0.111, 32/28000 datapoints
2025-03-07 12:24:36,524 - INFO - training batch 51, loss: 0.079, 1632/28000 datapoints
2025-03-07 12:24:36,827 - INFO - training batch 101, loss: 0.059, 3232/28000 datapoints
2025-03-07 12:24:37,120 - INFO - training batch 151, loss: 0.040, 4832/28000 datapoints
2025-03-07 12:24:37,412 - INFO - training batch 201, loss: 0.068, 6432/28000 datapoints
2025-03-07 12:24:37,710 - INFO - training batch 251, loss: 0.092, 8032/28000 datapoints
2025-03-07 12:24:38,009 - INFO - training batch 301, loss: 0.168, 9632/28000 datapoints
2025-03-07 12:24:38,294 - INFO - training batch 351, loss: 0.110, 11232/28000 datapoints
2025-03-07 12:24:38,573 - INFO - training batch 401, loss: 0.098, 12832/28000 datapoints
2025-03-07 12:24:38,852 - INFO - training batch 451, loss: 0.109, 14432/28000 datapoints
2025-03-07 12:24:39,134 - INFO - training batch 501, loss: 0.063, 16032/28000 datapoints
2025-03-07 12:24:39,414 - INFO - training batch 551, loss: 0.060, 17632/28000 datapoints
2025-03-07 12:24:39,694 - INFO - training batch 601, loss: 0.075, 19232/28000 datapoints
2025-03-07 12:24:39,977 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-07 12:24:40,259 - INFO - training batch 701, loss: 0.177, 22432/28000 datapoints
2025-03-07 12:24:40,551 - INFO - training batch 751, loss: 0.077, 24032/28000 datapoints
2025-03-07 12:24:40,836 - INFO - training batch 801, loss: 0.061, 25632/28000 datapoints
2025-03-07 12:24:41,145 - INFO - training batch 851, loss: 0.097, 27232/28000 datapoints
2025-03-07 12:24:41,282 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 12:24:41,356 - INFO - validation batch 51, loss: 0.829, 1632/6976 datapoints
2025-03-07 12:24:41,431 - INFO - validation batch 101, loss: 0.178, 3232/6976 datapoints
2025-03-07 12:24:41,508 - INFO - validation batch 151, loss: 0.313, 4832/6976 datapoints
2025-03-07 12:24:41,581 - INFO - validation batch 201, loss: 0.343, 6432/6976 datapoints
2025-03-07 12:24:41,606 - INFO - Epoch 130/800 done.
2025-03-07 12:24:41,606 - INFO - Final validation performance:
Loss: 0.345, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:24:41,606 - INFO - Beginning epoch 131/800
2025-03-07 12:24:41,616 - INFO - training batch 1, loss: 0.110, 32/28000 datapoints
2025-03-07 12:24:41,923 - INFO - training batch 51, loss: 0.078, 1632/28000 datapoints
2025-03-07 12:24:42,205 - INFO - training batch 101, loss: 0.056, 3232/28000 datapoints
2025-03-07 12:24:42,488 - INFO - training batch 151, loss: 0.039, 4832/28000 datapoints
2025-03-07 12:24:42,772 - INFO - training batch 201, loss: 0.066, 6432/28000 datapoints
2025-03-07 12:24:43,064 - INFO - training batch 251, loss: 0.089, 8032/28000 datapoints
2025-03-07 12:24:43,347 - INFO - training batch 301, loss: 0.160, 9632/28000 datapoints
2025-03-07 12:24:43,640 - INFO - training batch 351, loss: 0.108, 11232/28000 datapoints
2025-03-07 12:24:43,952 - INFO - training batch 401, loss: 0.095, 12832/28000 datapoints
2025-03-07 12:24:44,228 - INFO - training batch 451, loss: 0.105, 14432/28000 datapoints
2025-03-07 12:24:44,510 - INFO - training batch 501, loss: 0.062, 16032/28000 datapoints
2025-03-07 12:24:44,806 - INFO - training batch 551, loss: 0.058, 17632/28000 datapoints
2025-03-07 12:24:45,162 - INFO - training batch 601, loss: 0.072, 19232/28000 datapoints
2025-03-07 12:24:45,452 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-07 12:24:45,742 - INFO - training batch 701, loss: 0.174, 22432/28000 datapoints
2025-03-07 12:24:46,041 - INFO - training batch 751, loss: 0.076, 24032/28000 datapoints
2025-03-07 12:24:46,330 - INFO - training batch 801, loss: 0.059, 25632/28000 datapoints
2025-03-07 12:24:46,620 - INFO - training batch 851, loss: 0.094, 27232/28000 datapoints
2025-03-07 12:24:46,763 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:24:46,837 - INFO - validation batch 51, loss: 0.832, 1632/6976 datapoints
2025-03-07 12:24:46,915 - INFO - validation batch 101, loss: 0.176, 3232/6976 datapoints
2025-03-07 12:24:46,995 - INFO - validation batch 151, loss: 0.315, 4832/6976 datapoints
2025-03-07 12:24:47,072 - INFO - validation batch 201, loss: 0.342, 6432/6976 datapoints
2025-03-07 12:24:47,100 - INFO - Epoch 131/800 done.
2025-03-07 12:24:47,100 - INFO - Final validation performance:
Loss: 0.345, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:24:47,101 - INFO - Beginning epoch 132/800
2025-03-07 12:24:47,109 - INFO - training batch 1, loss: 0.109, 32/28000 datapoints
2025-03-07 12:24:47,402 - INFO - training batch 51, loss: 0.076, 1632/28000 datapoints
2025-03-07 12:24:47,689 - INFO - training batch 101, loss: 0.055, 3232/28000 datapoints
2025-03-07 12:24:48,005 - INFO - training batch 151, loss: 0.037, 4832/28000 datapoints
2025-03-07 12:24:48,293 - INFO - training batch 201, loss: 0.065, 6432/28000 datapoints
2025-03-07 12:24:48,576 - INFO - training batch 251, loss: 0.087, 8032/28000 datapoints
2025-03-07 12:24:48,852 - INFO - training batch 301, loss: 0.152, 9632/28000 datapoints
2025-03-07 12:24:49,132 - INFO - training batch 351, loss: 0.106, 11232/28000 datapoints
2025-03-07 12:24:49,415 - INFO - training batch 401, loss: 0.092, 12832/28000 datapoints
2025-03-07 12:24:49,698 - INFO - training batch 451, loss: 0.102, 14432/28000 datapoints
2025-03-07 12:24:49,983 - INFO - training batch 501, loss: 0.060, 16032/28000 datapoints
2025-03-07 12:24:50,269 - INFO - training batch 551, loss: 0.056, 17632/28000 datapoints
2025-03-07 12:24:50,553 - INFO - training batch 601, loss: 0.070, 19232/28000 datapoints
2025-03-07 12:24:50,859 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-07 12:24:51,171 - INFO - training batch 701, loss: 0.170, 22432/28000 datapoints
2025-03-07 12:24:51,452 - INFO - training batch 751, loss: 0.076, 24032/28000 datapoints
2025-03-07 12:24:51,735 - INFO - training batch 801, loss: 0.057, 25632/28000 datapoints
2025-03-07 12:24:52,023 - INFO - training batch 851, loss: 0.091, 27232/28000 datapoints
2025-03-07 12:24:52,171 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:24:52,266 - INFO - validation batch 51, loss: 0.835, 1632/6976 datapoints
2025-03-07 12:24:52,346 - INFO - validation batch 101, loss: 0.177, 3232/6976 datapoints
2025-03-07 12:24:52,419 - INFO - validation batch 151, loss: 0.315, 4832/6976 datapoints
2025-03-07 12:24:52,497 - INFO - validation batch 201, loss: 0.342, 6432/6976 datapoints
2025-03-07 12:24:52,524 - INFO - Epoch 132/800 done.
2025-03-07 12:24:52,524 - INFO - Final validation performance:
Loss: 0.346, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:24:52,524 - INFO - Beginning epoch 133/800
2025-03-07 12:24:52,533 - INFO - training batch 1, loss: 0.107, 32/28000 datapoints
2025-03-07 12:24:52,820 - INFO - training batch 51, loss: 0.074, 1632/28000 datapoints
2025-03-07 12:24:53,099 - INFO - training batch 101, loss: 0.053, 3232/28000 datapoints
2025-03-07 12:24:53,423 - INFO - training batch 151, loss: 0.035, 4832/28000 datapoints
2025-03-07 12:24:53,734 - INFO - training batch 201, loss: 0.064, 6432/28000 datapoints
2025-03-07 12:24:54,024 - INFO - training batch 251, loss: 0.085, 8032/28000 datapoints
2025-03-07 12:24:54,312 - INFO - training batch 301, loss: 0.145, 9632/28000 datapoints
2025-03-07 12:24:54,593 - INFO - training batch 351, loss: 0.104, 11232/28000 datapoints
2025-03-07 12:24:54,878 - INFO - training batch 401, loss: 0.089, 12832/28000 datapoints
2025-03-07 12:24:55,218 - INFO - training batch 451, loss: 0.098, 14432/28000 datapoints
2025-03-07 12:24:55,693 - INFO - training batch 501, loss: 0.059, 16032/28000 datapoints
2025-03-07 12:24:56,032 - INFO - training batch 551, loss: 0.054, 17632/28000 datapoints
2025-03-07 12:24:56,364 - INFO - training batch 601, loss: 0.067, 19232/28000 datapoints
2025-03-07 12:24:56,697 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-07 12:24:57,025 - INFO - training batch 701, loss: 0.167, 22432/28000 datapoints
2025-03-07 12:24:57,352 - INFO - training batch 751, loss: 0.075, 24032/28000 datapoints
2025-03-07 12:24:57,666 - INFO - training batch 801, loss: 0.056, 25632/28000 datapoints
2025-03-07 12:24:57,979 - INFO - training batch 851, loss: 0.088, 27232/28000 datapoints
2025-03-07 12:24:58,134 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 12:24:58,206 - INFO - validation batch 51, loss: 0.839, 1632/6976 datapoints
2025-03-07 12:24:58,296 - INFO - validation batch 101, loss: 0.176, 3232/6976 datapoints
2025-03-07 12:24:58,384 - INFO - validation batch 151, loss: 0.317, 4832/6976 datapoints
2025-03-07 12:24:58,475 - INFO - validation batch 201, loss: 0.342, 6432/6976 datapoints
2025-03-07 12:24:58,507 - INFO - Epoch 133/800 done.
2025-03-07 12:24:58,507 - INFO - Final validation performance:
Loss: 0.347, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:24:58,508 - INFO - Beginning epoch 134/800
2025-03-07 12:24:58,517 - INFO - training batch 1, loss: 0.105, 32/28000 datapoints
2025-03-07 12:24:58,823 - INFO - training batch 51, loss: 0.073, 1632/28000 datapoints
2025-03-07 12:24:59,126 - INFO - training batch 101, loss: 0.051, 3232/28000 datapoints
2025-03-07 12:24:59,447 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-07 12:24:59,827 - INFO - training batch 201, loss: 0.063, 6432/28000 datapoints
2025-03-07 12:25:00,174 - INFO - training batch 251, loss: 0.082, 8032/28000 datapoints
2025-03-07 12:25:00,469 - INFO - training batch 301, loss: 0.139, 9632/28000 datapoints
2025-03-07 12:25:00,764 - INFO - training batch 351, loss: 0.103, 11232/28000 datapoints
2025-03-07 12:25:01,055 - INFO - training batch 401, loss: 0.086, 12832/28000 datapoints
2025-03-07 12:25:01,368 - INFO - training batch 451, loss: 0.095, 14432/28000 datapoints
2025-03-07 12:25:01,658 - INFO - training batch 501, loss: 0.057, 16032/28000 datapoints
2025-03-07 12:25:01,948 - INFO - training batch 551, loss: 0.052, 17632/28000 datapoints
2025-03-07 12:25:02,232 - INFO - training batch 601, loss: 0.065, 19232/28000 datapoints
2025-03-07 12:25:02,523 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-07 12:25:02,803 - INFO - training batch 701, loss: 0.163, 22432/28000 datapoints
2025-03-07 12:25:03,084 - INFO - training batch 751, loss: 0.074, 24032/28000 datapoints
2025-03-07 12:25:03,369 - INFO - training batch 801, loss: 0.054, 25632/28000 datapoints
2025-03-07 12:25:03,654 - INFO - training batch 851, loss: 0.085, 27232/28000 datapoints
2025-03-07 12:25:03,800 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:25:03,876 - INFO - validation batch 51, loss: 0.843, 1632/6976 datapoints
2025-03-07 12:25:03,950 - INFO - validation batch 101, loss: 0.176, 3232/6976 datapoints
2025-03-07 12:25:04,024 - INFO - validation batch 151, loss: 0.318, 4832/6976 datapoints
2025-03-07 12:25:04,112 - INFO - validation batch 201, loss: 0.341, 6432/6976 datapoints
2025-03-07 12:25:04,143 - INFO - Epoch 134/800 done.
2025-03-07 12:25:04,143 - INFO - Final validation performance:
Loss: 0.348, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:25:04,143 - INFO - Beginning epoch 135/800
2025-03-07 12:25:04,151 - INFO - training batch 1, loss: 0.104, 32/28000 datapoints
2025-03-07 12:25:04,447 - INFO - training batch 51, loss: 0.071, 1632/28000 datapoints
2025-03-07 12:25:04,729 - INFO - training batch 101, loss: 0.050, 3232/28000 datapoints
2025-03-07 12:25:05,009 - INFO - training batch 151, loss: 0.033, 4832/28000 datapoints
2025-03-07 12:25:05,326 - INFO - training batch 201, loss: 0.062, 6432/28000 datapoints
2025-03-07 12:25:05,620 - INFO - training batch 251, loss: 0.080, 8032/28000 datapoints
2025-03-07 12:25:05,908 - INFO - training batch 301, loss: 0.132, 9632/28000 datapoints
2025-03-07 12:25:06,186 - INFO - training batch 351, loss: 0.101, 11232/28000 datapoints
2025-03-07 12:25:06,464 - INFO - training batch 401, loss: 0.083, 12832/28000 datapoints
2025-03-07 12:25:06,745 - INFO - training batch 451, loss: 0.092, 14432/28000 datapoints
2025-03-07 12:25:07,025 - INFO - training batch 501, loss: 0.056, 16032/28000 datapoints
2025-03-07 12:25:07,303 - INFO - training batch 551, loss: 0.050, 17632/28000 datapoints
2025-03-07 12:25:07,587 - INFO - training batch 601, loss: 0.062, 19232/28000 datapoints
2025-03-07 12:25:07,879 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-07 12:25:08,167 - INFO - training batch 701, loss: 0.159, 22432/28000 datapoints
2025-03-07 12:25:08,449 - INFO - training batch 751, loss: 0.073, 24032/28000 datapoints
2025-03-07 12:25:08,730 - INFO - training batch 801, loss: 0.053, 25632/28000 datapoints
2025-03-07 12:25:09,012 - INFO - training batch 851, loss: 0.082, 27232/28000 datapoints
2025-03-07 12:25:09,154 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:25:09,232 - INFO - validation batch 51, loss: 0.848, 1632/6976 datapoints
2025-03-07 12:25:09,308 - INFO - validation batch 101, loss: 0.175, 3232/6976 datapoints
2025-03-07 12:25:09,385 - INFO - validation batch 151, loss: 0.320, 4832/6976 datapoints
2025-03-07 12:25:09,462 - INFO - validation batch 201, loss: 0.342, 6432/6976 datapoints
2025-03-07 12:25:09,490 - INFO - Epoch 135/800 done.
2025-03-07 12:25:09,491 - INFO - Final validation performance:
Loss: 0.349, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:25:09,491 - INFO - Beginning epoch 136/800
2025-03-07 12:25:09,499 - INFO - training batch 1, loss: 0.102, 32/28000 datapoints
2025-03-07 12:25:09,798 - INFO - training batch 51, loss: 0.070, 1632/28000 datapoints
2025-03-07 12:25:10,114 - INFO - training batch 101, loss: 0.048, 3232/28000 datapoints
2025-03-07 12:25:10,407 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-07 12:25:10,703 - INFO - training batch 201, loss: 0.060, 6432/28000 datapoints
2025-03-07 12:25:10,994 - INFO - training batch 251, loss: 0.077, 8032/28000 datapoints
2025-03-07 12:25:11,281 - INFO - training batch 301, loss: 0.125, 9632/28000 datapoints
2025-03-07 12:25:11,581 - INFO - training batch 351, loss: 0.099, 11232/28000 datapoints
2025-03-07 12:25:11,863 - INFO - training batch 401, loss: 0.080, 12832/28000 datapoints
2025-03-07 12:25:12,146 - INFO - training batch 451, loss: 0.089, 14432/28000 datapoints
2025-03-07 12:25:12,431 - INFO - training batch 501, loss: 0.055, 16032/28000 datapoints
2025-03-07 12:25:12,713 - INFO - training batch 551, loss: 0.047, 17632/28000 datapoints
2025-03-07 12:25:12,996 - INFO - training batch 601, loss: 0.060, 19232/28000 datapoints
2025-03-07 12:25:13,275 - INFO - training batch 651, loss: 0.019, 20832/28000 datapoints
2025-03-07 12:25:13,563 - INFO - training batch 701, loss: 0.154, 22432/28000 datapoints
2025-03-07 12:25:13,844 - INFO - training batch 751, loss: 0.072, 24032/28000 datapoints
2025-03-07 12:25:14,134 - INFO - training batch 801, loss: 0.051, 25632/28000 datapoints
2025-03-07 12:25:14,421 - INFO - training batch 851, loss: 0.079, 27232/28000 datapoints
2025-03-07 12:25:14,566 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:25:14,640 - INFO - validation batch 51, loss: 0.852, 1632/6976 datapoints
2025-03-07 12:25:14,714 - INFO - validation batch 101, loss: 0.175, 3232/6976 datapoints
2025-03-07 12:25:14,792 - INFO - validation batch 151, loss: 0.321, 4832/6976 datapoints
2025-03-07 12:25:14,867 - INFO - validation batch 201, loss: 0.342, 6432/6976 datapoints
2025-03-07 12:25:14,894 - INFO - Epoch 136/800 done.
2025-03-07 12:25:14,894 - INFO - Final validation performance:
Loss: 0.350, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:25:14,895 - INFO - Beginning epoch 137/800
2025-03-07 12:25:14,902 - INFO - training batch 1, loss: 0.101, 32/28000 datapoints
2025-03-07 12:25:15,181 - INFO - training batch 51, loss: 0.068, 1632/28000 datapoints
2025-03-07 12:25:15,493 - INFO - training batch 101, loss: 0.046, 3232/28000 datapoints
2025-03-07 12:25:15,899 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-07 12:25:16,213 - INFO - training batch 201, loss: 0.059, 6432/28000 datapoints
2025-03-07 12:25:16,525 - INFO - training batch 251, loss: 0.075, 8032/28000 datapoints
2025-03-07 12:25:16,857 - INFO - training batch 301, loss: 0.118, 9632/28000 datapoints
2025-03-07 12:25:17,184 - INFO - training batch 351, loss: 0.098, 11232/28000 datapoints
2025-03-07 12:25:17,496 - INFO - training batch 401, loss: 0.078, 12832/28000 datapoints
2025-03-07 12:25:17,793 - INFO - training batch 451, loss: 0.086, 14432/28000 datapoints
2025-03-07 12:25:18,087 - INFO - training batch 501, loss: 0.054, 16032/28000 datapoints
2025-03-07 12:25:18,377 - INFO - training batch 551, loss: 0.046, 17632/28000 datapoints
2025-03-07 12:25:18,663 - INFO - training batch 601, loss: 0.058, 19232/28000 datapoints
2025-03-07 12:25:18,959 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-07 12:25:19,238 - INFO - training batch 701, loss: 0.150, 22432/28000 datapoints
2025-03-07 12:25:19,521 - INFO - training batch 751, loss: 0.071, 24032/28000 datapoints
2025-03-07 12:25:19,799 - INFO - training batch 801, loss: 0.049, 25632/28000 datapoints
2025-03-07 12:25:20,081 - INFO - training batch 851, loss: 0.076, 27232/28000 datapoints
2025-03-07 12:25:20,220 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:25:20,299 - INFO - validation batch 51, loss: 0.858, 1632/6976 datapoints
2025-03-07 12:25:20,373 - INFO - validation batch 101, loss: 0.174, 3232/6976 datapoints
2025-03-07 12:25:20,451 - INFO - validation batch 151, loss: 0.324, 4832/6976 datapoints
2025-03-07 12:25:20,540 - INFO - validation batch 201, loss: 0.341, 6432/6976 datapoints
2025-03-07 12:25:20,566 - INFO - Epoch 137/800 done.
2025-03-07 12:25:20,566 - INFO - Final validation performance:
Loss: 0.352, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:25:20,566 - INFO - Beginning epoch 138/800
2025-03-07 12:25:20,575 - INFO - training batch 1, loss: 0.100, 32/28000 datapoints
2025-03-07 12:25:20,863 - INFO - training batch 51, loss: 0.067, 1632/28000 datapoints
2025-03-07 12:25:21,145 - INFO - training batch 101, loss: 0.044, 3232/28000 datapoints
2025-03-07 12:25:21,449 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-07 12:25:21,727 - INFO - training batch 201, loss: 0.058, 6432/28000 datapoints
2025-03-07 12:25:22,011 - INFO - training batch 251, loss: 0.073, 8032/28000 datapoints
2025-03-07 12:25:22,285 - INFO - training batch 301, loss: 0.113, 9632/28000 datapoints
2025-03-07 12:25:22,565 - INFO - training batch 351, loss: 0.096, 11232/28000 datapoints
2025-03-07 12:25:22,845 - INFO - training batch 401, loss: 0.076, 12832/28000 datapoints
2025-03-07 12:25:23,120 - INFO - training batch 451, loss: 0.083, 14432/28000 datapoints
2025-03-07 12:25:23,405 - INFO - training batch 501, loss: 0.052, 16032/28000 datapoints
2025-03-07 12:25:23,684 - INFO - training batch 551, loss: 0.044, 17632/28000 datapoints
2025-03-07 12:25:23,960 - INFO - training batch 601, loss: 0.056, 19232/28000 datapoints
2025-03-07 12:25:24,235 - INFO - training batch 651, loss: 0.018, 20832/28000 datapoints
2025-03-07 12:25:24,517 - INFO - training batch 701, loss: 0.146, 22432/28000 datapoints
2025-03-07 12:25:24,869 - INFO - training batch 751, loss: 0.070, 24032/28000 datapoints
2025-03-07 12:25:25,215 - INFO - training batch 801, loss: 0.048, 25632/28000 datapoints
2025-03-07 12:25:25,510 - INFO - training batch 851, loss: 0.073, 27232/28000 datapoints
2025-03-07 12:25:25,686 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:25:25,786 - INFO - validation batch 51, loss: 0.864, 1632/6976 datapoints
2025-03-07 12:25:25,867 - INFO - validation batch 101, loss: 0.174, 3232/6976 datapoints
2025-03-07 12:25:25,958 - INFO - validation batch 151, loss: 0.326, 4832/6976 datapoints
2025-03-07 12:25:26,053 - INFO - validation batch 201, loss: 0.340, 6432/6976 datapoints
2025-03-07 12:25:26,087 - INFO - Epoch 138/800 done.
2025-03-07 12:25:26,087 - INFO - Final validation performance:
Loss: 0.353, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:25:26,088 - INFO - Beginning epoch 139/800
2025-03-07 12:25:26,097 - INFO - training batch 1, loss: 0.098, 32/28000 datapoints
2025-03-07 12:25:26,435 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-07 12:25:26,787 - INFO - training batch 101, loss: 0.043, 3232/28000 datapoints
2025-03-07 12:25:27,147 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-07 12:25:27,496 - INFO - training batch 201, loss: 0.057, 6432/28000 datapoints
2025-03-07 12:25:27,850 - INFO - training batch 251, loss: 0.071, 8032/28000 datapoints
2025-03-07 12:25:28,191 - INFO - training batch 301, loss: 0.107, 9632/28000 datapoints
2025-03-07 12:25:28,521 - INFO - training batch 351, loss: 0.094, 11232/28000 datapoints
2025-03-07 12:25:28,855 - INFO - training batch 401, loss: 0.074, 12832/28000 datapoints
2025-03-07 12:25:29,169 - INFO - training batch 451, loss: 0.080, 14432/28000 datapoints
2025-03-07 12:25:29,495 - INFO - training batch 501, loss: 0.051, 16032/28000 datapoints
2025-03-07 12:25:29,801 - INFO - training batch 551, loss: 0.043, 17632/28000 datapoints
2025-03-07 12:25:30,098 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-07 12:25:30,377 - INFO - training batch 651, loss: 0.017, 20832/28000 datapoints
2025-03-07 12:25:30,697 - INFO - training batch 701, loss: 0.142, 22432/28000 datapoints
2025-03-07 12:25:30,982 - INFO - training batch 751, loss: 0.069, 24032/28000 datapoints
2025-03-07 12:25:31,267 - INFO - training batch 801, loss: 0.046, 25632/28000 datapoints
2025-03-07 12:25:31,583 - INFO - training batch 851, loss: 0.071, 27232/28000 datapoints
2025-03-07 12:25:31,728 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:25:31,802 - INFO - validation batch 51, loss: 0.870, 1632/6976 datapoints
2025-03-07 12:25:31,875 - INFO - validation batch 101, loss: 0.174, 3232/6976 datapoints
2025-03-07 12:25:31,952 - INFO - validation batch 151, loss: 0.328, 4832/6976 datapoints
2025-03-07 12:25:32,029 - INFO - validation batch 201, loss: 0.342, 6432/6976 datapoints
2025-03-07 12:25:32,054 - INFO - Epoch 139/800 done.
2025-03-07 12:25:32,054 - INFO - Final validation performance:
Loss: 0.355, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:25:32,055 - INFO - Beginning epoch 140/800
2025-03-07 12:25:32,063 - INFO - training batch 1, loss: 0.096, 32/28000 datapoints
2025-03-07 12:25:32,350 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-07 12:25:32,637 - INFO - training batch 101, loss: 0.041, 3232/28000 datapoints
2025-03-07 12:25:32,917 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-07 12:25:33,197 - INFO - training batch 201, loss: 0.056, 6432/28000 datapoints
2025-03-07 12:25:33,480 - INFO - training batch 251, loss: 0.068, 8032/28000 datapoints
2025-03-07 12:25:33,788 - INFO - training batch 301, loss: 0.102, 9632/28000 datapoints
2025-03-07 12:25:34,073 - INFO - training batch 351, loss: 0.093, 11232/28000 datapoints
2025-03-07 12:25:34,356 - INFO - training batch 401, loss: 0.071, 12832/28000 datapoints
2025-03-07 12:25:34,641 - INFO - training batch 451, loss: 0.077, 14432/28000 datapoints
2025-03-07 12:25:34,925 - INFO - training batch 501, loss: 0.050, 16032/28000 datapoints
2025-03-07 12:25:35,222 - INFO - training batch 551, loss: 0.041, 17632/28000 datapoints
2025-03-07 12:25:35,515 - INFO - training batch 601, loss: 0.052, 19232/28000 datapoints
2025-03-07 12:25:35,817 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-07 12:25:36,219 - INFO - training batch 701, loss: 0.137, 22432/28000 datapoints
2025-03-07 12:25:36,549 - INFO - training batch 751, loss: 0.068, 24032/28000 datapoints
2025-03-07 12:25:36,877 - INFO - training batch 801, loss: 0.045, 25632/28000 datapoints
2025-03-07 12:25:37,173 - INFO - training batch 851, loss: 0.068, 27232/28000 datapoints
2025-03-07 12:25:37,316 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:25:37,394 - INFO - validation batch 51, loss: 0.876, 1632/6976 datapoints
2025-03-07 12:25:37,479 - INFO - validation batch 101, loss: 0.174, 3232/6976 datapoints
2025-03-07 12:25:37,555 - INFO - validation batch 151, loss: 0.330, 4832/6976 datapoints
2025-03-07 12:25:37,631 - INFO - validation batch 201, loss: 0.341, 6432/6976 datapoints
2025-03-07 12:25:37,655 - INFO - Epoch 140/800 done.
2025-03-07 12:25:37,655 - INFO - Final validation performance:
Loss: 0.357, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:25:37,656 - INFO - Beginning epoch 141/800
2025-03-07 12:25:37,664 - INFO - training batch 1, loss: 0.095, 32/28000 datapoints
2025-03-07 12:25:38,004 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-07 12:25:38,331 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-07 12:25:38,633 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-07 12:25:38,918 - INFO - training batch 201, loss: 0.055, 6432/28000 datapoints
2025-03-07 12:25:39,208 - INFO - training batch 251, loss: 0.066, 8032/28000 datapoints
2025-03-07 12:25:39,493 - INFO - training batch 301, loss: 0.097, 9632/28000 datapoints
2025-03-07 12:25:39,782 - INFO - training batch 351, loss: 0.091, 11232/28000 datapoints
2025-03-07 12:25:40,072 - INFO - training batch 401, loss: 0.069, 12832/28000 datapoints
2025-03-07 12:25:40,352 - INFO - training batch 451, loss: 0.074, 14432/28000 datapoints
2025-03-07 12:25:40,633 - INFO - training batch 501, loss: 0.049, 16032/28000 datapoints
2025-03-07 12:25:40,914 - INFO - training batch 551, loss: 0.040, 17632/28000 datapoints
2025-03-07 12:25:41,199 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-07 12:25:41,484 - INFO - training batch 651, loss: 0.016, 20832/28000 datapoints
2025-03-07 12:25:41,795 - INFO - training batch 701, loss: 0.132, 22432/28000 datapoints
2025-03-07 12:25:42,085 - INFO - training batch 751, loss: 0.067, 24032/28000 datapoints
2025-03-07 12:25:42,385 - INFO - training batch 801, loss: 0.043, 25632/28000 datapoints
2025-03-07 12:25:42,665 - INFO - training batch 851, loss: 0.065, 27232/28000 datapoints
2025-03-07 12:25:42,805 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:25:42,884 - INFO - validation batch 51, loss: 0.883, 1632/6976 datapoints
2025-03-07 12:25:42,957 - INFO - validation batch 101, loss: 0.175, 3232/6976 datapoints
2025-03-07 12:25:43,034 - INFO - validation batch 151, loss: 0.333, 4832/6976 datapoints
2025-03-07 12:25:43,108 - INFO - validation batch 201, loss: 0.341, 6432/6976 datapoints
2025-03-07 12:25:43,136 - INFO - Epoch 141/800 done.
2025-03-07 12:25:43,136 - INFO - Final validation performance:
Loss: 0.359, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:25:43,138 - INFO - Beginning epoch 142/800
2025-03-07 12:25:43,146 - INFO - training batch 1, loss: 0.093, 32/28000 datapoints
2025-03-07 12:25:43,428 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-07 12:25:43,714 - INFO - training batch 101, loss: 0.038, 3232/28000 datapoints
2025-03-07 12:25:43,994 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-07 12:25:44,277 - INFO - training batch 201, loss: 0.054, 6432/28000 datapoints
2025-03-07 12:25:44,559 - INFO - training batch 251, loss: 0.064, 8032/28000 datapoints
2025-03-07 12:25:44,839 - INFO - training batch 301, loss: 0.095, 9632/28000 datapoints
2025-03-07 12:25:45,120 - INFO - training batch 351, loss: 0.089, 11232/28000 datapoints
2025-03-07 12:25:45,405 - INFO - training batch 401, loss: 0.067, 12832/28000 datapoints
2025-03-07 12:25:45,691 - INFO - training batch 451, loss: 0.071, 14432/28000 datapoints
2025-03-07 12:25:45,995 - INFO - training batch 501, loss: 0.047, 16032/28000 datapoints
2025-03-07 12:25:46,317 - INFO - training batch 551, loss: 0.039, 17632/28000 datapoints
2025-03-07 12:25:46,647 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-07 12:25:46,989 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-07 12:25:47,329 - INFO - training batch 701, loss: 0.128, 22432/28000 datapoints
2025-03-07 12:25:47,668 - INFO - training batch 751, loss: 0.066, 24032/28000 datapoints
2025-03-07 12:25:47,998 - INFO - training batch 801, loss: 0.042, 25632/28000 datapoints
2025-03-07 12:25:48,368 - INFO - training batch 851, loss: 0.063, 27232/28000 datapoints
2025-03-07 12:25:48,531 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:25:48,619 - INFO - validation batch 51, loss: 0.888, 1632/6976 datapoints
2025-03-07 12:25:48,699 - INFO - validation batch 101, loss: 0.175, 3232/6976 datapoints
2025-03-07 12:25:48,784 - INFO - validation batch 151, loss: 0.336, 4832/6976 datapoints
2025-03-07 12:25:48,865 - INFO - validation batch 201, loss: 0.342, 6432/6976 datapoints
2025-03-07 12:25:48,899 - INFO - Epoch 142/800 done.
2025-03-07 12:25:48,899 - INFO - Final validation performance:
Loss: 0.361, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:25:48,900 - INFO - Beginning epoch 143/800
2025-03-07 12:25:48,908 - INFO - training batch 1, loss: 0.091, 32/28000 datapoints
2025-03-07 12:25:49,216 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-07 12:25:49,512 - INFO - training batch 101, loss: 0.036, 3232/28000 datapoints
2025-03-07 12:25:49,795 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-07 12:25:50,087 - INFO - training batch 201, loss: 0.053, 6432/28000 datapoints
2025-03-07 12:25:50,370 - INFO - training batch 251, loss: 0.062, 8032/28000 datapoints
2025-03-07 12:25:50,659 - INFO - training batch 301, loss: 0.090, 9632/28000 datapoints
2025-03-07 12:25:50,943 - INFO - training batch 351, loss: 0.087, 11232/28000 datapoints
2025-03-07 12:25:51,227 - INFO - training batch 401, loss: 0.064, 12832/28000 datapoints
2025-03-07 12:25:51,504 - INFO - training batch 451, loss: 0.068, 14432/28000 datapoints
2025-03-07 12:25:51,811 - INFO - training batch 501, loss: 0.046, 16032/28000 datapoints
2025-03-07 12:25:52,094 - INFO - training batch 551, loss: 0.037, 17632/28000 datapoints
2025-03-07 12:25:52,375 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-07 12:25:52,682 - INFO - training batch 651, loss: 0.015, 20832/28000 datapoints
2025-03-07 12:25:52,962 - INFO - training batch 701, loss: 0.122, 22432/28000 datapoints
2025-03-07 12:25:53,290 - INFO - training batch 751, loss: 0.066, 24032/28000 datapoints
2025-03-07 12:25:53,624 - INFO - training batch 801, loss: 0.040, 25632/28000 datapoints
2025-03-07 12:25:53,903 - INFO - training batch 851, loss: 0.060, 27232/28000 datapoints
2025-03-07 12:25:54,045 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:25:54,119 - INFO - validation batch 51, loss: 0.896, 1632/6976 datapoints
2025-03-07 12:25:54,202 - INFO - validation batch 101, loss: 0.177, 3232/6976 datapoints
2025-03-07 12:25:54,283 - INFO - validation batch 151, loss: 0.339, 4832/6976 datapoints
2025-03-07 12:25:54,366 - INFO - validation batch 201, loss: 0.342, 6432/6976 datapoints
2025-03-07 12:25:54,394 - INFO - Epoch 143/800 done.
2025-03-07 12:25:54,394 - INFO - Final validation performance:
Loss: 0.363, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:25:54,395 - INFO - Beginning epoch 144/800
2025-03-07 12:25:54,403 - INFO - training batch 1, loss: 0.090, 32/28000 datapoints
2025-03-07 12:25:54,694 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-07 12:25:54,980 - INFO - training batch 101, loss: 0.035, 3232/28000 datapoints
2025-03-07 12:25:55,269 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-07 12:25:55,570 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-07 12:25:55,860 - INFO - training batch 251, loss: 0.060, 8032/28000 datapoints
2025-03-07 12:25:56,211 - INFO - training batch 301, loss: 0.087, 9632/28000 datapoints
2025-03-07 12:25:56,620 - INFO - training batch 351, loss: 0.085, 11232/28000 datapoints
2025-03-07 12:25:57,007 - INFO - training batch 401, loss: 0.062, 12832/28000 datapoints
2025-03-07 12:25:57,326 - INFO - training batch 451, loss: 0.066, 14432/28000 datapoints
2025-03-07 12:25:57,622 - INFO - training batch 501, loss: 0.045, 16032/28000 datapoints
2025-03-07 12:25:57,928 - INFO - training batch 551, loss: 0.036, 17632/28000 datapoints
2025-03-07 12:25:58,233 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-07 12:25:58,549 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-07 12:25:58,842 - INFO - training batch 701, loss: 0.118, 22432/28000 datapoints
2025-03-07 12:25:59,131 - INFO - training batch 751, loss: 0.065, 24032/28000 datapoints
2025-03-07 12:25:59,421 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-07 12:25:59,709 - INFO - training batch 851, loss: 0.058, 27232/28000 datapoints
2025-03-07 12:25:59,851 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:25:59,925 - INFO - validation batch 51, loss: 0.900, 1632/6976 datapoints
2025-03-07 12:26:00,005 - INFO - validation batch 101, loss: 0.177, 3232/6976 datapoints
2025-03-07 12:26:00,083 - INFO - validation batch 151, loss: 0.341, 4832/6976 datapoints
2025-03-07 12:26:00,157 - INFO - validation batch 201, loss: 0.342, 6432/6976 datapoints
2025-03-07 12:26:00,199 - INFO - Epoch 144/800 done.
2025-03-07 12:26:00,199 - INFO - Final validation performance:
Loss: 0.364, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:26:00,200 - INFO - Beginning epoch 145/800
2025-03-07 12:26:00,213 - INFO - training batch 1, loss: 0.089, 32/28000 datapoints
2025-03-07 12:26:00,547 - INFO - training batch 51, loss: 0.058, 1632/28000 datapoints
2025-03-07 12:26:00,836 - INFO - training batch 101, loss: 0.034, 3232/28000 datapoints
2025-03-07 12:26:01,158 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-07 12:26:01,505 - INFO - training batch 201, loss: 0.051, 6432/28000 datapoints
2025-03-07 12:26:01,857 - INFO - training batch 251, loss: 0.058, 8032/28000 datapoints
2025-03-07 12:26:02,167 - INFO - training batch 301, loss: 0.083, 9632/28000 datapoints
2025-03-07 12:26:02,492 - INFO - training batch 351, loss: 0.083, 11232/28000 datapoints
2025-03-07 12:26:02,873 - INFO - training batch 401, loss: 0.060, 12832/28000 datapoints
2025-03-07 12:26:03,180 - INFO - training batch 451, loss: 0.063, 14432/28000 datapoints
2025-03-07 12:26:03,471 - INFO - training batch 501, loss: 0.044, 16032/28000 datapoints
2025-03-07 12:26:03,761 - INFO - training batch 551, loss: 0.034, 17632/28000 datapoints
2025-03-07 12:26:04,048 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-07 12:26:04,337 - INFO - training batch 651, loss: 0.014, 20832/28000 datapoints
2025-03-07 12:26:04,650 - INFO - training batch 701, loss: 0.114, 22432/28000 datapoints
2025-03-07 12:26:04,939 - INFO - training batch 751, loss: 0.063, 24032/28000 datapoints
2025-03-07 12:26:05,227 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-07 12:26:05,510 - INFO - training batch 851, loss: 0.056, 27232/28000 datapoints
2025-03-07 12:26:05,646 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:26:05,722 - INFO - validation batch 51, loss: 0.906, 1632/6976 datapoints
2025-03-07 12:26:05,795 - INFO - validation batch 101, loss: 0.177, 3232/6976 datapoints
2025-03-07 12:26:05,872 - INFO - validation batch 151, loss: 0.343, 4832/6976 datapoints
2025-03-07 12:26:05,948 - INFO - validation batch 201, loss: 0.341, 6432/6976 datapoints
2025-03-07 12:26:05,983 - INFO - Epoch 145/800 done.
2025-03-07 12:26:05,983 - INFO - Final validation performance:
Loss: 0.366, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:26:05,984 - INFO - Beginning epoch 146/800
2025-03-07 12:26:05,992 - INFO - training batch 1, loss: 0.087, 32/28000 datapoints
2025-03-07 12:26:06,316 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-07 12:26:06,667 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-07 12:26:06,949 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-07 12:26:07,240 - INFO - training batch 201, loss: 0.049, 6432/28000 datapoints
2025-03-07 12:26:07,527 - INFO - training batch 251, loss: 0.056, 8032/28000 datapoints
2025-03-07 12:26:07,839 - INFO - training batch 301, loss: 0.080, 9632/28000 datapoints
2025-03-07 12:26:08,128 - INFO - training batch 351, loss: 0.081, 11232/28000 datapoints
2025-03-07 12:26:08,414 - INFO - training batch 401, loss: 0.058, 12832/28000 datapoints
2025-03-07 12:26:08,702 - INFO - training batch 451, loss: 0.061, 14432/28000 datapoints
2025-03-07 12:26:08,989 - INFO - training batch 501, loss: 0.043, 16032/28000 datapoints
2025-03-07 12:26:09,283 - INFO - training batch 551, loss: 0.033, 17632/28000 datapoints
2025-03-07 12:26:09,576 - INFO - training batch 601, loss: 0.043, 19232/28000 datapoints
2025-03-07 12:26:09,864 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-07 12:26:10,150 - INFO - training batch 701, loss: 0.108, 22432/28000 datapoints
2025-03-07 12:26:10,463 - INFO - training batch 751, loss: 0.063, 24032/28000 datapoints
2025-03-07 12:26:10,748 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-07 12:26:11,037 - INFO - training batch 851, loss: 0.054, 27232/28000 datapoints
2025-03-07 12:26:11,177 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:26:11,252 - INFO - validation batch 51, loss: 0.914, 1632/6976 datapoints
2025-03-07 12:26:11,326 - INFO - validation batch 101, loss: 0.178, 3232/6976 datapoints
2025-03-07 12:26:11,401 - INFO - validation batch 151, loss: 0.346, 4832/6976 datapoints
2025-03-07 12:26:11,482 - INFO - validation batch 201, loss: 0.344, 6432/6976 datapoints
2025-03-07 12:26:11,505 - INFO - Epoch 146/800 done.
2025-03-07 12:26:11,505 - INFO - Final validation performance:
Loss: 0.369, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:26:11,506 - INFO - Beginning epoch 147/800
2025-03-07 12:26:11,514 - INFO - training batch 1, loss: 0.086, 32/28000 datapoints
2025-03-07 12:26:11,803 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-07 12:26:12,111 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-07 12:26:12,393 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-07 12:26:12,677 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-07 12:26:12,963 - INFO - training batch 251, loss: 0.055, 8032/28000 datapoints
2025-03-07 12:26:13,238 - INFO - training batch 301, loss: 0.077, 9632/28000 datapoints
2025-03-07 12:26:13,529 - INFO - training batch 351, loss: 0.080, 11232/28000 datapoints
2025-03-07 12:26:13,810 - INFO - training batch 401, loss: 0.057, 12832/28000 datapoints
2025-03-07 12:26:14,090 - INFO - training batch 451, loss: 0.058, 14432/28000 datapoints
2025-03-07 12:26:14,372 - INFO - training batch 501, loss: 0.042, 16032/28000 datapoints
2025-03-07 12:26:14,665 - INFO - training batch 551, loss: 0.032, 17632/28000 datapoints
2025-03-07 12:26:14,961 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-07 12:26:15,238 - INFO - training batch 651, loss: 0.013, 20832/28000 datapoints
2025-03-07 12:26:15,520 - INFO - training batch 701, loss: 0.103, 22432/28000 datapoints
2025-03-07 12:26:15,806 - INFO - training batch 751, loss: 0.062, 24032/28000 datapoints
2025-03-07 12:26:16,090 - INFO - training batch 801, loss: 0.034, 25632/28000 datapoints
2025-03-07 12:26:16,372 - INFO - training batch 851, loss: 0.051, 27232/28000 datapoints
2025-03-07 12:26:16,522 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:26:16,627 - INFO - validation batch 51, loss: 0.919, 1632/6976 datapoints
2025-03-07 12:26:16,729 - INFO - validation batch 101, loss: 0.178, 3232/6976 datapoints
2025-03-07 12:26:16,867 - INFO - validation batch 151, loss: 0.349, 4832/6976 datapoints
2025-03-07 12:26:16,978 - INFO - validation batch 201, loss: 0.342, 6432/6976 datapoints
2025-03-07 12:26:17,009 - INFO - Epoch 147/800 done.
2025-03-07 12:26:17,010 - INFO - Final validation performance:
Loss: 0.370, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:26:17,010 - INFO - Beginning epoch 148/800
2025-03-07 12:26:17,020 - INFO - training batch 1, loss: 0.084, 32/28000 datapoints
2025-03-07 12:26:17,430 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-07 12:26:17,802 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-07 12:26:18,173 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-07 12:26:18,596 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-07 12:26:18,979 - INFO - training batch 251, loss: 0.053, 8032/28000 datapoints
2025-03-07 12:26:19,311 - INFO - training batch 301, loss: 0.074, 9632/28000 datapoints
2025-03-07 12:26:19,624 - INFO - training batch 351, loss: 0.078, 11232/28000 datapoints
2025-03-07 12:26:19,928 - INFO - training batch 401, loss: 0.055, 12832/28000 datapoints
2025-03-07 12:26:20,230 - INFO - training batch 451, loss: 0.056, 14432/28000 datapoints
2025-03-07 12:26:20,522 - INFO - training batch 501, loss: 0.041, 16032/28000 datapoints
2025-03-07 12:26:20,809 - INFO - training batch 551, loss: 0.031, 17632/28000 datapoints
2025-03-07 12:26:21,092 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-07 12:26:21,371 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-07 12:26:21,660 - INFO - training batch 701, loss: 0.098, 22432/28000 datapoints
2025-03-07 12:26:21,945 - INFO - training batch 751, loss: 0.061, 24032/28000 datapoints
2025-03-07 12:26:22,264 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-07 12:26:22,565 - INFO - training batch 851, loss: 0.050, 27232/28000 datapoints
2025-03-07 12:26:22,708 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:26:22,786 - INFO - validation batch 51, loss: 0.929, 1632/6976 datapoints
2025-03-07 12:26:22,860 - INFO - validation batch 101, loss: 0.178, 3232/6976 datapoints
2025-03-07 12:26:22,936 - INFO - validation batch 151, loss: 0.351, 4832/6976 datapoints
2025-03-07 12:26:23,010 - INFO - validation batch 201, loss: 0.342, 6432/6976 datapoints
2025-03-07 12:26:23,040 - INFO - Epoch 148/800 done.
2025-03-07 12:26:23,040 - INFO - Final validation performance:
Loss: 0.372, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:26:23,041 - INFO - Beginning epoch 149/800
2025-03-07 12:26:23,049 - INFO - training batch 1, loss: 0.082, 32/28000 datapoints
2025-03-07 12:26:23,334 - INFO - training batch 51, loss: 0.053, 1632/28000 datapoints
2025-03-07 12:26:23,626 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-07 12:26:23,906 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-07 12:26:24,192 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-07 12:26:24,645 - INFO - training batch 251, loss: 0.052, 8032/28000 datapoints
2025-03-07 12:26:24,958 - INFO - training batch 301, loss: 0.071, 9632/28000 datapoints
2025-03-07 12:26:25,239 - INFO - training batch 351, loss: 0.076, 11232/28000 datapoints
2025-03-07 12:26:25,525 - INFO - training batch 401, loss: 0.053, 12832/28000 datapoints
2025-03-07 12:26:25,804 - INFO - training batch 451, loss: 0.053, 14432/28000 datapoints
2025-03-07 12:26:26,088 - INFO - training batch 501, loss: 0.040, 16032/28000 datapoints
2025-03-07 12:26:26,372 - INFO - training batch 551, loss: 0.030, 17632/28000 datapoints
2025-03-07 12:26:26,654 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-07 12:26:26,976 - INFO - training batch 651, loss: 0.012, 20832/28000 datapoints
2025-03-07 12:26:27,262 - INFO - training batch 701, loss: 0.093, 22432/28000 datapoints
2025-03-07 12:26:27,561 - INFO - training batch 751, loss: 0.060, 24032/28000 datapoints
2025-03-07 12:26:27,861 - INFO - training batch 801, loss: 0.032, 25632/28000 datapoints
2025-03-07 12:26:28,161 - INFO - training batch 851, loss: 0.047, 27232/28000 datapoints
2025-03-07 12:26:28,307 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:26:28,391 - INFO - validation batch 51, loss: 0.937, 1632/6976 datapoints
2025-03-07 12:26:28,475 - INFO - validation batch 101, loss: 0.179, 3232/6976 datapoints
2025-03-07 12:26:28,558 - INFO - validation batch 151, loss: 0.353, 4832/6976 datapoints
2025-03-07 12:26:28,637 - INFO - validation batch 201, loss: 0.344, 6432/6976 datapoints
2025-03-07 12:26:28,665 - INFO - Epoch 149/800 done.
2025-03-07 12:26:28,665 - INFO - Final validation performance:
Loss: 0.375, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:26:28,666 - INFO - Beginning epoch 150/800
2025-03-07 12:26:28,676 - INFO - training batch 1, loss: 0.080, 32/28000 datapoints
2025-03-07 12:26:28,961 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-07 12:26:29,252 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-07 12:26:29,530 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-07 12:26:29,810 - INFO - training batch 201, loss: 0.045, 6432/28000 datapoints
2025-03-07 12:26:30,096 - INFO - training batch 251, loss: 0.050, 8032/28000 datapoints
2025-03-07 12:26:30,376 - INFO - training batch 301, loss: 0.069, 9632/28000 datapoints
2025-03-07 12:26:30,716 - INFO - training batch 351, loss: 0.074, 11232/28000 datapoints
2025-03-07 12:26:31,001 - INFO - training batch 401, loss: 0.052, 12832/28000 datapoints
2025-03-07 12:26:31,329 - INFO - training batch 451, loss: 0.052, 14432/28000 datapoints
2025-03-07 12:26:31,611 - INFO - training batch 501, loss: 0.038, 16032/28000 datapoints
2025-03-07 12:26:31,900 - INFO - training batch 551, loss: 0.028, 17632/28000 datapoints
2025-03-07 12:26:32,206 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-07 12:26:32,490 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-07 12:26:32,765 - INFO - training batch 701, loss: 0.087, 22432/28000 datapoints
2025-03-07 12:26:33,047 - INFO - training batch 751, loss: 0.059, 24032/28000 datapoints
2025-03-07 12:26:33,329 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-07 12:26:33,613 - INFO - training batch 851, loss: 0.045, 27232/28000 datapoints
2025-03-07 12:26:33,748 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:26:33,817 - INFO - validation batch 51, loss: 0.946, 1632/6976 datapoints
2025-03-07 12:26:33,885 - INFO - validation batch 101, loss: 0.178, 3232/6976 datapoints
2025-03-07 12:26:33,956 - INFO - validation batch 151, loss: 0.357, 4832/6976 datapoints
2025-03-07 12:26:34,027 - INFO - validation batch 201, loss: 0.344, 6432/6976 datapoints
2025-03-07 12:26:34,052 - INFO - Epoch 150/800 done.
2025-03-07 12:26:34,052 - INFO - Final validation performance:
Loss: 0.377, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:26:34,052 - INFO - Beginning epoch 151/800
2025-03-07 12:26:34,060 - INFO - training batch 1, loss: 0.079, 32/28000 datapoints
2025-03-07 12:26:34,342 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-07 12:26:34,629 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-07 12:26:34,904 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-07 12:26:35,183 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-07 12:26:35,463 - INFO - training batch 251, loss: 0.049, 8032/28000 datapoints
2025-03-07 12:26:35,741 - INFO - training batch 301, loss: 0.066, 9632/28000 datapoints
2025-03-07 12:26:36,015 - INFO - training batch 351, loss: 0.072, 11232/28000 datapoints
2025-03-07 12:26:36,293 - INFO - training batch 401, loss: 0.049, 12832/28000 datapoints
2025-03-07 12:26:36,571 - INFO - training batch 451, loss: 0.049, 14432/28000 datapoints
2025-03-07 12:26:36,858 - INFO - training batch 501, loss: 0.038, 16032/28000 datapoints
2025-03-07 12:26:37,210 - INFO - training batch 551, loss: 0.028, 17632/28000 datapoints
2025-03-07 12:26:37,600 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-07 12:26:37,897 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-07 12:26:38,189 - INFO - training batch 701, loss: 0.082, 22432/28000 datapoints
2025-03-07 12:26:38,478 - INFO - training batch 751, loss: 0.058, 24032/28000 datapoints
2025-03-07 12:26:38,767 - INFO - training batch 801, loss: 0.029, 25632/28000 datapoints
2025-03-07 12:26:39,055 - INFO - training batch 851, loss: 0.044, 27232/28000 datapoints
2025-03-07 12:26:39,193 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:26:39,265 - INFO - validation batch 51, loss: 0.954, 1632/6976 datapoints
2025-03-07 12:26:39,342 - INFO - validation batch 101, loss: 0.178, 3232/6976 datapoints
2025-03-07 12:26:39,413 - INFO - validation batch 151, loss: 0.358, 4832/6976 datapoints
2025-03-07 12:26:39,486 - INFO - validation batch 201, loss: 0.343, 6432/6976 datapoints
2025-03-07 12:26:39,510 - INFO - Epoch 151/800 done.
2025-03-07 12:26:39,510 - INFO - Final validation performance:
Loss: 0.379, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:26:39,510 - INFO - Beginning epoch 152/800
2025-03-07 12:26:39,518 - INFO - training batch 1, loss: 0.077, 32/28000 datapoints
2025-03-07 12:26:39,819 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-07 12:26:40,101 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-07 12:26:40,380 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-07 12:26:40,665 - INFO - training batch 201, loss: 0.043, 6432/28000 datapoints
2025-03-07 12:26:40,943 - INFO - training batch 251, loss: 0.047, 8032/28000 datapoints
2025-03-07 12:26:41,221 - INFO - training batch 301, loss: 0.064, 9632/28000 datapoints
2025-03-07 12:26:41,502 - INFO - training batch 351, loss: 0.070, 11232/28000 datapoints
2025-03-07 12:26:41,782 - INFO - training batch 401, loss: 0.048, 12832/28000 datapoints
2025-03-07 12:26:42,060 - INFO - training batch 451, loss: 0.047, 14432/28000 datapoints
2025-03-07 12:26:42,368 - INFO - training batch 501, loss: 0.037, 16032/28000 datapoints
2025-03-07 12:26:42,647 - INFO - training batch 551, loss: 0.026, 17632/28000 datapoints
2025-03-07 12:26:42,925 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-07 12:26:43,201 - INFO - training batch 651, loss: 0.011, 20832/28000 datapoints
2025-03-07 12:26:43,481 - INFO - training batch 701, loss: 0.077, 22432/28000 datapoints
2025-03-07 12:26:43,759 - INFO - training batch 751, loss: 0.057, 24032/28000 datapoints
2025-03-07 12:26:44,038 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-07 12:26:44,332 - INFO - training batch 851, loss: 0.042, 27232/28000 datapoints
2025-03-07 12:26:44,472 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:26:44,542 - INFO - validation batch 51, loss: 0.964, 1632/6976 datapoints
2025-03-07 12:26:44,614 - INFO - validation batch 101, loss: 0.178, 3232/6976 datapoints
2025-03-07 12:26:44,684 - INFO - validation batch 151, loss: 0.360, 4832/6976 datapoints
2025-03-07 12:26:44,758 - INFO - validation batch 201, loss: 0.343, 6432/6976 datapoints
2025-03-07 12:26:44,783 - INFO - Epoch 152/800 done.
2025-03-07 12:26:44,784 - INFO - Final validation performance:
Loss: 0.381, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:26:44,784 - INFO - Beginning epoch 153/800
2025-03-07 12:26:44,792 - INFO - training batch 1, loss: 0.075, 32/28000 datapoints
2025-03-07 12:26:45,080 - INFO - training batch 51, loss: 0.047, 1632/28000 datapoints
2025-03-07 12:26:45,360 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-07 12:26:45,640 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-07 12:26:45,913 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-07 12:26:46,194 - INFO - training batch 251, loss: 0.045, 8032/28000 datapoints
2025-03-07 12:26:46,475 - INFO - training batch 301, loss: 0.061, 9632/28000 datapoints
2025-03-07 12:26:46,755 - INFO - training batch 351, loss: 0.068, 11232/28000 datapoints
2025-03-07 12:26:47,041 - INFO - training batch 401, loss: 0.047, 12832/28000 datapoints
2025-03-07 12:26:47,361 - INFO - training batch 451, loss: 0.045, 14432/28000 datapoints
2025-03-07 12:26:47,687 - INFO - training batch 501, loss: 0.036, 16032/28000 datapoints
2025-03-07 12:26:48,011 - INFO - training batch 551, loss: 0.025, 17632/28000 datapoints
2025-03-07 12:26:48,336 - INFO - training batch 601, loss: 0.035, 19232/28000 datapoints
2025-03-07 12:26:48,692 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-07 12:26:49,031 - INFO - training batch 701, loss: 0.072, 22432/28000 datapoints
2025-03-07 12:26:49,361 - INFO - training batch 751, loss: 0.056, 24032/28000 datapoints
2025-03-07 12:26:49,676 - INFO - training batch 801, loss: 0.027, 25632/28000 datapoints
2025-03-07 12:26:49,975 - INFO - training batch 851, loss: 0.040, 27232/28000 datapoints
2025-03-07 12:26:50,123 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:26:50,200 - INFO - validation batch 51, loss: 0.973, 1632/6976 datapoints
2025-03-07 12:26:50,281 - INFO - validation batch 101, loss: 0.179, 3232/6976 datapoints
2025-03-07 12:26:50,373 - INFO - validation batch 151, loss: 0.364, 4832/6976 datapoints
2025-03-07 12:26:50,460 - INFO - validation batch 201, loss: 0.343, 6432/6976 datapoints
2025-03-07 12:26:50,489 - INFO - Epoch 153/800 done.
2025-03-07 12:26:50,489 - INFO - Final validation performance:
Loss: 0.384, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:26:50,490 - INFO - Beginning epoch 154/800
2025-03-07 12:26:50,498 - INFO - training batch 1, loss: 0.073, 32/28000 datapoints
2025-03-07 12:26:50,793 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-07 12:26:51,086 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-07 12:26:51,387 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-07 12:26:51,738 - INFO - training batch 201, loss: 0.040, 6432/28000 datapoints
2025-03-07 12:26:52,119 - INFO - training batch 251, loss: 0.044, 8032/28000 datapoints
2025-03-07 12:26:52,489 - INFO - training batch 301, loss: 0.058, 9632/28000 datapoints
2025-03-07 12:26:52,938 - INFO - training batch 351, loss: 0.065, 11232/28000 datapoints
2025-03-07 12:26:53,264 - INFO - training batch 401, loss: 0.045, 12832/28000 datapoints
2025-03-07 12:26:53,573 - INFO - training batch 451, loss: 0.043, 14432/28000 datapoints
2025-03-07 12:26:53,902 - INFO - training batch 501, loss: 0.035, 16032/28000 datapoints
2025-03-07 12:26:54,218 - INFO - training batch 551, loss: 0.024, 17632/28000 datapoints
2025-03-07 12:26:54,513 - INFO - training batch 601, loss: 0.034, 19232/28000 datapoints
2025-03-07 12:26:54,801 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-07 12:26:55,090 - INFO - training batch 701, loss: 0.067, 22432/28000 datapoints
2025-03-07 12:26:55,381 - INFO - training batch 751, loss: 0.054, 24032/28000 datapoints
2025-03-07 12:26:55,678 - INFO - training batch 801, loss: 0.026, 25632/28000 datapoints
2025-03-07 12:26:55,958 - INFO - training batch 851, loss: 0.038, 27232/28000 datapoints
2025-03-07 12:26:56,101 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:26:56,176 - INFO - validation batch 51, loss: 0.983, 1632/6976 datapoints
2025-03-07 12:26:56,254 - INFO - validation batch 101, loss: 0.178, 3232/6976 datapoints
2025-03-07 12:26:56,329 - INFO - validation batch 151, loss: 0.367, 4832/6976 datapoints
2025-03-07 12:26:56,404 - INFO - validation batch 201, loss: 0.345, 6432/6976 datapoints
2025-03-07 12:26:56,431 - INFO - Epoch 154/800 done.
2025-03-07 12:26:56,431 - INFO - Final validation performance:
Loss: 0.387, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:26:56,432 - INFO - Beginning epoch 155/800
2025-03-07 12:26:56,440 - INFO - training batch 1, loss: 0.071, 32/28000 datapoints
2025-03-07 12:26:56,729 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-07 12:26:57,010 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-07 12:26:57,322 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-07 12:26:57,743 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-07 12:26:58,267 - INFO - training batch 251, loss: 0.042, 8032/28000 datapoints
2025-03-07 12:26:58,569 - INFO - training batch 301, loss: 0.057, 9632/28000 datapoints
2025-03-07 12:26:58,867 - INFO - training batch 351, loss: 0.063, 11232/28000 datapoints
2025-03-07 12:26:59,160 - INFO - training batch 401, loss: 0.044, 12832/28000 datapoints
2025-03-07 12:26:59,458 - INFO - training batch 451, loss: 0.041, 14432/28000 datapoints
2025-03-07 12:26:59,750 - INFO - training batch 501, loss: 0.034, 16032/28000 datapoints
2025-03-07 12:27:00,045 - INFO - training batch 551, loss: 0.023, 17632/28000 datapoints
2025-03-07 12:27:00,336 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-07 12:27:00,638 - INFO - training batch 651, loss: 0.010, 20832/28000 datapoints
2025-03-07 12:27:00,928 - INFO - training batch 701, loss: 0.062, 22432/28000 datapoints
2025-03-07 12:27:01,212 - INFO - training batch 751, loss: 0.053, 24032/28000 datapoints
2025-03-07 12:27:01,496 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-07 12:27:01,777 - INFO - training batch 851, loss: 0.036, 27232/28000 datapoints
2025-03-07 12:27:01,925 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:27:01,999 - INFO - validation batch 51, loss: 0.994, 1632/6976 datapoints
2025-03-07 12:27:02,074 - INFO - validation batch 101, loss: 0.178, 3232/6976 datapoints
2025-03-07 12:27:02,148 - INFO - validation batch 151, loss: 0.369, 4832/6976 datapoints
2025-03-07 12:27:02,226 - INFO - validation batch 201, loss: 0.344, 6432/6976 datapoints
2025-03-07 12:27:02,258 - INFO - Epoch 155/800 done.
2025-03-07 12:27:02,258 - INFO - Final validation performance:
Loss: 0.389, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:27:02,259 - INFO - Beginning epoch 156/800
2025-03-07 12:27:02,271 - INFO - training batch 1, loss: 0.069, 32/28000 datapoints
2025-03-07 12:27:02,624 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-07 12:27:02,905 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-07 12:27:03,184 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-07 12:27:03,469 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-07 12:27:03,754 - INFO - training batch 251, loss: 0.041, 8032/28000 datapoints
2025-03-07 12:27:04,032 - INFO - training batch 301, loss: 0.054, 9632/28000 datapoints
2025-03-07 12:27:04,316 - INFO - training batch 351, loss: 0.060, 11232/28000 datapoints
2025-03-07 12:27:04,602 - INFO - training batch 401, loss: 0.043, 12832/28000 datapoints
2025-03-07 12:27:04,893 - INFO - training batch 451, loss: 0.039, 14432/28000 datapoints
2025-03-07 12:27:05,172 - INFO - training batch 501, loss: 0.033, 16032/28000 datapoints
2025-03-07 12:27:05,457 - INFO - training batch 551, loss: 0.022, 17632/28000 datapoints
2025-03-07 12:27:05,737 - INFO - training batch 601, loss: 0.031, 19232/28000 datapoints
2025-03-07 12:27:06,016 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-07 12:27:06,297 - INFO - training batch 701, loss: 0.058, 22432/28000 datapoints
2025-03-07 12:27:06,602 - INFO - training batch 751, loss: 0.052, 24032/28000 datapoints
2025-03-07 12:27:06,896 - INFO - training batch 801, loss: 0.024, 25632/28000 datapoints
2025-03-07 12:27:07,176 - INFO - training batch 851, loss: 0.035, 27232/28000 datapoints
2025-03-07 12:27:07,314 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:27:07,392 - INFO - validation batch 51, loss: 1.004, 1632/6976 datapoints
2025-03-07 12:27:07,476 - INFO - validation batch 101, loss: 0.177, 3232/6976 datapoints
2025-03-07 12:27:07,576 - INFO - validation batch 151, loss: 0.373, 4832/6976 datapoints
2025-03-07 12:27:07,678 - INFO - validation batch 201, loss: 0.343, 6432/6976 datapoints
2025-03-07 12:27:07,704 - INFO - Epoch 156/800 done.
2025-03-07 12:27:07,705 - INFO - Final validation performance:
Loss: 0.392, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:27:07,705 - INFO - Beginning epoch 157/800
2025-03-07 12:27:07,713 - INFO - training batch 1, loss: 0.069, 32/28000 datapoints
2025-03-07 12:27:08,020 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-07 12:27:08,313 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-07 12:27:08,611 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-07 12:27:08,904 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-07 12:27:09,197 - INFO - training batch 251, loss: 0.040, 8032/28000 datapoints
2025-03-07 12:27:09,493 - INFO - training batch 301, loss: 0.052, 9632/28000 datapoints
2025-03-07 12:27:09,777 - INFO - training batch 351, loss: 0.058, 11232/28000 datapoints
2025-03-07 12:27:10,063 - INFO - training batch 401, loss: 0.041, 12832/28000 datapoints
2025-03-07 12:27:10,350 - INFO - training batch 451, loss: 0.037, 14432/28000 datapoints
2025-03-07 12:27:10,632 - INFO - training batch 501, loss: 0.032, 16032/28000 datapoints
2025-03-07 12:27:10,935 - INFO - training batch 551, loss: 0.022, 17632/28000 datapoints
2025-03-07 12:27:11,219 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-07 12:27:11,502 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-07 12:27:11,783 - INFO - training batch 701, loss: 0.054, 22432/28000 datapoints
2025-03-07 12:27:12,060 - INFO - training batch 751, loss: 0.050, 24032/28000 datapoints
2025-03-07 12:27:12,344 - INFO - training batch 801, loss: 0.024, 25632/28000 datapoints
2025-03-07 12:27:12,658 - INFO - training batch 851, loss: 0.033, 27232/28000 datapoints
2025-03-07 12:27:12,800 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:27:12,877 - INFO - validation batch 51, loss: 1.014, 1632/6976 datapoints
2025-03-07 12:27:12,953 - INFO - validation batch 101, loss: 0.176, 3232/6976 datapoints
2025-03-07 12:27:13,028 - INFO - validation batch 151, loss: 0.374, 4832/6976 datapoints
2025-03-07 12:27:13,100 - INFO - validation batch 201, loss: 0.346, 6432/6976 datapoints
2025-03-07 12:27:13,127 - INFO - Epoch 157/800 done.
2025-03-07 12:27:13,127 - INFO - Final validation performance:
Loss: 0.395, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:27:13,128 - INFO - Beginning epoch 158/800
2025-03-07 12:27:13,136 - INFO - training batch 1, loss: 0.067, 32/28000 datapoints
2025-03-07 12:27:13,420 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-07 12:27:13,700 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-07 12:27:13,978 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-07 12:27:14,253 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-07 12:27:14,536 - INFO - training batch 251, loss: 0.038, 8032/28000 datapoints
2025-03-07 12:27:14,812 - INFO - training batch 301, loss: 0.050, 9632/28000 datapoints
2025-03-07 12:27:15,089 - INFO - training batch 351, loss: 0.056, 11232/28000 datapoints
2025-03-07 12:27:15,381 - INFO - training batch 401, loss: 0.040, 12832/28000 datapoints
2025-03-07 12:27:15,667 - INFO - training batch 451, loss: 0.036, 14432/28000 datapoints
2025-03-07 12:27:15,945 - INFO - training batch 501, loss: 0.031, 16032/28000 datapoints
2025-03-07 12:27:16,221 - INFO - training batch 551, loss: 0.021, 17632/28000 datapoints
2025-03-07 12:27:16,543 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-07 12:27:16,817 - INFO - training batch 651, loss: 0.009, 20832/28000 datapoints
2025-03-07 12:27:17,094 - INFO - training batch 701, loss: 0.050, 22432/28000 datapoints
2025-03-07 12:27:17,369 - INFO - training batch 751, loss: 0.049, 24032/28000 datapoints
2025-03-07 12:27:17,651 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-07 12:27:18,039 - INFO - training batch 851, loss: 0.032, 27232/28000 datapoints
2025-03-07 12:27:18,198 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:27:18,271 - INFO - validation batch 51, loss: 1.023, 1632/6976 datapoints
2025-03-07 12:27:18,386 - INFO - validation batch 101, loss: 0.176, 3232/6976 datapoints
2025-03-07 12:27:18,502 - INFO - validation batch 151, loss: 0.375, 4832/6976 datapoints
2025-03-07 12:27:18,605 - INFO - validation batch 201, loss: 0.345, 6432/6976 datapoints
2025-03-07 12:27:18,635 - INFO - Epoch 158/800 done.
2025-03-07 12:27:18,635 - INFO - Final validation performance:
Loss: 0.396, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:27:18,636 - INFO - Beginning epoch 159/800
2025-03-07 12:27:18,644 - INFO - training batch 1, loss: 0.065, 32/28000 datapoints
2025-03-07 12:27:18,991 - INFO - training batch 51, loss: 0.039, 1632/28000 datapoints
2025-03-07 12:27:19,327 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-07 12:27:19,690 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-07 12:27:20,086 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-07 12:27:20,434 - INFO - training batch 251, loss: 0.037, 8032/28000 datapoints
2025-03-07 12:27:20,749 - INFO - training batch 301, loss: 0.048, 9632/28000 datapoints
2025-03-07 12:27:21,049 - INFO - training batch 351, loss: 0.054, 11232/28000 datapoints
2025-03-07 12:27:21,335 - INFO - training batch 401, loss: 0.038, 12832/28000 datapoints
2025-03-07 12:27:21,630 - INFO - training batch 451, loss: 0.034, 14432/28000 datapoints
2025-03-07 12:27:21,909 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-07 12:27:22,187 - INFO - training batch 551, loss: 0.020, 17632/28000 datapoints
2025-03-07 12:27:22,474 - INFO - training batch 601, loss: 0.028, 19232/28000 datapoints
2025-03-07 12:27:22,778 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-07 12:27:23,062 - INFO - training batch 701, loss: 0.047, 22432/28000 datapoints
2025-03-07 12:27:23,350 - INFO - training batch 751, loss: 0.048, 24032/28000 datapoints
2025-03-07 12:27:23,630 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-07 12:27:23,907 - INFO - training batch 851, loss: 0.030, 27232/28000 datapoints
2025-03-07 12:27:24,055 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:27:24,125 - INFO - validation batch 51, loss: 1.036, 1632/6976 datapoints
2025-03-07 12:27:24,220 - INFO - validation batch 101, loss: 0.175, 3232/6976 datapoints
2025-03-07 12:27:24,325 - INFO - validation batch 151, loss: 0.378, 4832/6976 datapoints
2025-03-07 12:27:24,411 - INFO - validation batch 201, loss: 0.346, 6432/6976 datapoints
2025-03-07 12:27:24,440 - INFO - Epoch 159/800 done.
2025-03-07 12:27:24,440 - INFO - Final validation performance:
Loss: 0.399, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:27:24,441 - INFO - Beginning epoch 160/800
2025-03-07 12:27:24,448 - INFO - training batch 1, loss: 0.063, 32/28000 datapoints
2025-03-07 12:27:24,734 - INFO - training batch 51, loss: 0.039, 1632/28000 datapoints
2025-03-07 12:27:25,041 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-07 12:27:25,333 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-07 12:27:25,615 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-07 12:27:25,891 - INFO - training batch 251, loss: 0.035, 8032/28000 datapoints
2025-03-07 12:27:26,168 - INFO - training batch 301, loss: 0.045, 9632/28000 datapoints
2025-03-07 12:27:26,449 - INFO - training batch 351, loss: 0.051, 11232/28000 datapoints
2025-03-07 12:27:26,734 - INFO - training batch 401, loss: 0.037, 12832/28000 datapoints
2025-03-07 12:27:27,012 - INFO - training batch 451, loss: 0.032, 14432/28000 datapoints
2025-03-07 12:27:27,289 - INFO - training batch 501, loss: 0.029, 16032/28000 datapoints
2025-03-07 12:27:27,571 - INFO - training batch 551, loss: 0.019, 17632/28000 datapoints
2025-03-07 12:27:27,853 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-07 12:27:28,328 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-07 12:27:28,656 - INFO - training batch 701, loss: 0.043, 22432/28000 datapoints
2025-03-07 12:27:28,966 - INFO - training batch 751, loss: 0.046, 24032/28000 datapoints
2025-03-07 12:27:29,257 - INFO - training batch 801, loss: 0.021, 25632/28000 datapoints
2025-03-07 12:27:29,551 - INFO - training batch 851, loss: 0.029, 27232/28000 datapoints
2025-03-07 12:27:29,692 - INFO - validation batch 1, loss: 0.061, 32/6976 datapoints
2025-03-07 12:27:29,769 - INFO - validation batch 51, loss: 1.046, 1632/6976 datapoints
2025-03-07 12:27:29,846 - INFO - validation batch 101, loss: 0.175, 3232/6976 datapoints
2025-03-07 12:27:29,921 - INFO - validation batch 151, loss: 0.380, 4832/6976 datapoints
2025-03-07 12:27:30,007 - INFO - validation batch 201, loss: 0.347, 6432/6976 datapoints
2025-03-07 12:27:30,040 - INFO - Epoch 160/800 done.
2025-03-07 12:27:30,041 - INFO - Final validation performance:
Loss: 0.402, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:27:30,041 - INFO - Beginning epoch 161/800
2025-03-07 12:27:30,052 - INFO - training batch 1, loss: 0.061, 32/28000 datapoints
2025-03-07 12:27:30,348 - INFO - training batch 51, loss: 0.037, 1632/28000 datapoints
2025-03-07 12:27:30,713 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-07 12:27:31,004 - INFO - training batch 151, loss: 0.013, 4832/28000 datapoints
2025-03-07 12:27:31,292 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-07 12:27:31,579 - INFO - training batch 251, loss: 0.034, 8032/28000 datapoints
2025-03-07 12:27:31,864 - INFO - training batch 301, loss: 0.044, 9632/28000 datapoints
2025-03-07 12:27:32,205 - INFO - training batch 351, loss: 0.049, 11232/28000 datapoints
2025-03-07 12:27:32,494 - INFO - training batch 401, loss: 0.036, 12832/28000 datapoints
2025-03-07 12:27:32,795 - INFO - training batch 451, loss: 0.030, 14432/28000 datapoints
2025-03-07 12:27:33,114 - INFO - training batch 501, loss: 0.028, 16032/28000 datapoints
2025-03-07 12:27:33,393 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-07 12:27:33,672 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-07 12:27:33,953 - INFO - training batch 651, loss: 0.008, 20832/28000 datapoints
2025-03-07 12:27:34,233 - INFO - training batch 701, loss: 0.040, 22432/28000 datapoints
2025-03-07 12:27:34,519 - INFO - training batch 751, loss: 0.044, 24032/28000 datapoints
2025-03-07 12:27:34,800 - INFO - training batch 801, loss: 0.020, 25632/28000 datapoints
2025-03-07 12:27:35,081 - INFO - training batch 851, loss: 0.027, 27232/28000 datapoints
2025-03-07 12:27:35,217 - INFO - validation batch 1, loss: 0.061, 32/6976 datapoints
2025-03-07 12:27:35,290 - INFO - validation batch 51, loss: 1.058, 1632/6976 datapoints
2025-03-07 12:27:35,362 - INFO - validation batch 101, loss: 0.175, 3232/6976 datapoints
2025-03-07 12:27:35,437 - INFO - validation batch 151, loss: 0.380, 4832/6976 datapoints
2025-03-07 12:27:35,513 - INFO - validation batch 201, loss: 0.345, 6432/6976 datapoints
2025-03-07 12:27:35,540 - INFO - Epoch 161/800 done.
2025-03-07 12:27:35,541 - INFO - Final validation performance:
Loss: 0.404, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:27:35,541 - INFO - Beginning epoch 162/800
2025-03-07 12:27:35,549 - INFO - training batch 1, loss: 0.059, 32/28000 datapoints
2025-03-07 12:27:35,828 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-07 12:27:36,109 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-07 12:27:36,400 - INFO - training batch 151, loss: 0.013, 4832/28000 datapoints
2025-03-07 12:27:36,692 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-07 12:27:36,976 - INFO - training batch 251, loss: 0.033, 8032/28000 datapoints
2025-03-07 12:27:37,287 - INFO - training batch 301, loss: 0.042, 9632/28000 datapoints
2025-03-07 12:27:37,578 - INFO - training batch 351, loss: 0.047, 11232/28000 datapoints
2025-03-07 12:27:37,874 - INFO - training batch 401, loss: 0.035, 12832/28000 datapoints
2025-03-07 12:27:38,201 - INFO - training batch 451, loss: 0.029, 14432/28000 datapoints
2025-03-07 12:27:38,599 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-07 12:27:38,950 - INFO - training batch 551, loss: 0.018, 17632/28000 datapoints
2025-03-07 12:27:39,246 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-07 12:27:39,535 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-07 12:27:39,823 - INFO - training batch 701, loss: 0.038, 22432/28000 datapoints
2025-03-07 12:27:40,118 - INFO - training batch 751, loss: 0.043, 24032/28000 datapoints
2025-03-07 12:27:40,411 - INFO - training batch 801, loss: 0.020, 25632/28000 datapoints
2025-03-07 12:27:40,718 - INFO - training batch 851, loss: 0.026, 27232/28000 datapoints
2025-03-07 12:27:40,866 - INFO - validation batch 1, loss: 0.060, 32/6976 datapoints
2025-03-07 12:27:40,940 - INFO - validation batch 51, loss: 1.070, 1632/6976 datapoints
2025-03-07 12:27:41,016 - INFO - validation batch 101, loss: 0.174, 3232/6976 datapoints
2025-03-07 12:27:41,091 - INFO - validation batch 151, loss: 0.382, 4832/6976 datapoints
2025-03-07 12:27:41,167 - INFO - validation batch 201, loss: 0.346, 6432/6976 datapoints
2025-03-07 12:27:41,196 - INFO - Epoch 162/800 done.
2025-03-07 12:27:41,196 - INFO - Final validation performance:
Loss: 0.406, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:27:41,197 - INFO - Beginning epoch 163/800
2025-03-07 12:27:41,205 - INFO - training batch 1, loss: 0.057, 32/28000 datapoints
2025-03-07 12:27:41,486 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-07 12:27:41,777 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-07 12:27:42,060 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-07 12:27:42,345 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-07 12:27:42,634 - INFO - training batch 251, loss: 0.031, 8032/28000 datapoints
2025-03-07 12:27:42,943 - INFO - training batch 301, loss: 0.040, 9632/28000 datapoints
2025-03-07 12:27:43,229 - INFO - training batch 351, loss: 0.045, 11232/28000 datapoints
2025-03-07 12:27:43,520 - INFO - training batch 401, loss: 0.034, 12832/28000 datapoints
2025-03-07 12:27:43,805 - INFO - training batch 451, loss: 0.028, 14432/28000 datapoints
2025-03-07 12:27:44,088 - INFO - training batch 501, loss: 0.026, 16032/28000 datapoints
2025-03-07 12:27:44,370 - INFO - training batch 551, loss: 0.017, 17632/28000 datapoints
2025-03-07 12:27:44,655 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-07 12:27:44,940 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-07 12:27:45,220 - INFO - training batch 701, loss: 0.036, 22432/28000 datapoints
2025-03-07 12:27:45,501 - INFO - training batch 751, loss: 0.042, 24032/28000 datapoints
2025-03-07 12:27:45,779 - INFO - training batch 801, loss: 0.019, 25632/28000 datapoints
2025-03-07 12:27:46,074 - INFO - training batch 851, loss: 0.025, 27232/28000 datapoints
2025-03-07 12:27:46,214 - INFO - validation batch 1, loss: 0.059, 32/6976 datapoints
2025-03-07 12:27:46,288 - INFO - validation batch 51, loss: 1.084, 1632/6976 datapoints
2025-03-07 12:27:46,361 - INFO - validation batch 101, loss: 0.172, 3232/6976 datapoints
2025-03-07 12:27:46,441 - INFO - validation batch 151, loss: 0.384, 4832/6976 datapoints
2025-03-07 12:27:46,519 - INFO - validation batch 201, loss: 0.345, 6432/6976 datapoints
2025-03-07 12:27:46,548 - INFO - Epoch 163/800 done.
2025-03-07 12:27:46,548 - INFO - Final validation performance:
Loss: 0.409, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:27:46,548 - INFO - Beginning epoch 164/800
2025-03-07 12:27:46,556 - INFO - training batch 1, loss: 0.056, 32/28000 datapoints
2025-03-07 12:27:46,851 - INFO - training batch 51, loss: 0.033, 1632/28000 datapoints
2025-03-07 12:27:47,131 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-07 12:27:47,409 - INFO - training batch 151, loss: 0.012, 4832/28000 datapoints
2025-03-07 12:27:47,688 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-07 12:27:47,972 - INFO - training batch 251, loss: 0.031, 8032/28000 datapoints
2025-03-07 12:27:48,286 - INFO - training batch 301, loss: 0.039, 9632/28000 datapoints
2025-03-07 12:27:48,658 - INFO - training batch 351, loss: 0.043, 11232/28000 datapoints
2025-03-07 12:27:48,986 - INFO - training batch 401, loss: 0.033, 12832/28000 datapoints
2025-03-07 12:27:49,327 - INFO - training batch 451, loss: 0.026, 14432/28000 datapoints
2025-03-07 12:27:49,670 - INFO - training batch 501, loss: 0.025, 16032/28000 datapoints
2025-03-07 12:27:50,004 - INFO - training batch 551, loss: 0.017, 17632/28000 datapoints
2025-03-07 12:27:50,338 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-07 12:27:50,671 - INFO - training batch 651, loss: 0.007, 20832/28000 datapoints
2025-03-07 12:27:50,995 - INFO - training batch 701, loss: 0.033, 22432/28000 datapoints
2025-03-07 12:27:51,329 - INFO - training batch 751, loss: 0.040, 24032/28000 datapoints
2025-03-07 12:27:51,627 - INFO - training batch 801, loss: 0.018, 25632/28000 datapoints
2025-03-07 12:27:51,922 - INFO - training batch 851, loss: 0.024, 27232/28000 datapoints
2025-03-07 12:27:52,080 - INFO - validation batch 1, loss: 0.059, 32/6976 datapoints
2025-03-07 12:27:52,169 - INFO - validation batch 51, loss: 1.095, 1632/6976 datapoints
2025-03-07 12:27:52,245 - INFO - validation batch 101, loss: 0.172, 3232/6976 datapoints
2025-03-07 12:27:52,323 - INFO - validation batch 151, loss: 0.383, 4832/6976 datapoints
2025-03-07 12:27:52,400 - INFO - validation batch 201, loss: 0.346, 6432/6976 datapoints
2025-03-07 12:27:52,425 - INFO - Epoch 164/800 done.
2025-03-07 12:27:52,425 - INFO - Final validation performance:
Loss: 0.411, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:27:52,426 - INFO - Beginning epoch 165/800
2025-03-07 12:27:52,435 - INFO - training batch 1, loss: 0.054, 32/28000 datapoints
2025-03-07 12:27:52,719 - INFO - training batch 51, loss: 0.032, 1632/28000 datapoints
2025-03-07 12:27:53,020 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-07 12:27:53,301 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-07 12:27:53,581 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-07 12:27:53,870 - INFO - training batch 251, loss: 0.029, 8032/28000 datapoints
2025-03-07 12:27:54,145 - INFO - training batch 301, loss: 0.037, 9632/28000 datapoints
2025-03-07 12:27:54,424 - INFO - training batch 351, loss: 0.042, 11232/28000 datapoints
2025-03-07 12:27:54,705 - INFO - training batch 401, loss: 0.032, 12832/28000 datapoints
2025-03-07 12:27:54,984 - INFO - training batch 451, loss: 0.025, 14432/28000 datapoints
2025-03-07 12:27:55,258 - INFO - training batch 501, loss: 0.024, 16032/28000 datapoints
2025-03-07 12:27:55,542 - INFO - training batch 551, loss: 0.016, 17632/28000 datapoints
2025-03-07 12:27:55,816 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-07 12:27:56,097 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 12:27:56,388 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-07 12:27:56,680 - INFO - training batch 751, loss: 0.039, 24032/28000 datapoints
2025-03-07 12:27:56,958 - INFO - training batch 801, loss: 0.017, 25632/28000 datapoints
2025-03-07 12:27:57,242 - INFO - training batch 851, loss: 0.022, 27232/28000 datapoints
2025-03-07 12:27:57,377 - INFO - validation batch 1, loss: 0.058, 32/6976 datapoints
2025-03-07 12:27:57,446 - INFO - validation batch 51, loss: 1.107, 1632/6976 datapoints
2025-03-07 12:27:57,537 - INFO - validation batch 101, loss: 0.171, 3232/6976 datapoints
2025-03-07 12:27:57,606 - INFO - validation batch 151, loss: 0.386, 4832/6976 datapoints
2025-03-07 12:27:57,677 - INFO - validation batch 201, loss: 0.346, 6432/6976 datapoints
2025-03-07 12:27:57,701 - INFO - Epoch 165/800 done.
2025-03-07 12:27:57,701 - INFO - Final validation performance:
Loss: 0.414, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:27:57,702 - INFO - Beginning epoch 166/800
2025-03-07 12:27:57,709 - INFO - training batch 1, loss: 0.052, 32/28000 datapoints
2025-03-07 12:27:58,002 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-07 12:27:58,375 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-07 12:27:58,742 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-07 12:27:59,133 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-07 12:27:59,451 - INFO - training batch 251, loss: 0.027, 8032/28000 datapoints
2025-03-07 12:27:59,740 - INFO - training batch 301, loss: 0.035, 9632/28000 datapoints
2025-03-07 12:28:00,032 - INFO - training batch 351, loss: 0.040, 11232/28000 datapoints
2025-03-07 12:28:00,319 - INFO - training batch 401, loss: 0.031, 12832/28000 datapoints
2025-03-07 12:28:00,622 - INFO - training batch 451, loss: 0.023, 14432/28000 datapoints
2025-03-07 12:28:00,922 - INFO - training batch 501, loss: 0.024, 16032/28000 datapoints
2025-03-07 12:28:01,209 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-07 12:28:01,508 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-07 12:28:01,797 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 12:28:02,094 - INFO - training batch 701, loss: 0.029, 22432/28000 datapoints
2025-03-07 12:28:02,377 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-07 12:28:02,692 - INFO - training batch 801, loss: 0.017, 25632/28000 datapoints
2025-03-07 12:28:02,971 - INFO - training batch 851, loss: 0.021, 27232/28000 datapoints
2025-03-07 12:28:03,132 - INFO - validation batch 1, loss: 0.058, 32/6976 datapoints
2025-03-07 12:28:03,201 - INFO - validation batch 51, loss: 1.120, 1632/6976 datapoints
2025-03-07 12:28:03,270 - INFO - validation batch 101, loss: 0.171, 3232/6976 datapoints
2025-03-07 12:28:03,339 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-07 12:28:03,410 - INFO - validation batch 201, loss: 0.348, 6432/6976 datapoints
2025-03-07 12:28:03,434 - INFO - Epoch 166/800 done.
2025-03-07 12:28:03,434 - INFO - Final validation performance:
Loss: 0.417, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:28:03,435 - INFO - Beginning epoch 167/800
2025-03-07 12:28:03,442 - INFO - training batch 1, loss: 0.051, 32/28000 datapoints
2025-03-07 12:28:03,722 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-07 12:28:04,001 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-07 12:28:04,277 - INFO - training batch 151, loss: 0.011, 4832/28000 datapoints
2025-03-07 12:28:04,564 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-07 12:28:04,836 - INFO - training batch 251, loss: 0.027, 8032/28000 datapoints
2025-03-07 12:28:05,123 - INFO - training batch 301, loss: 0.034, 9632/28000 datapoints
2025-03-07 12:28:05,398 - INFO - training batch 351, loss: 0.038, 11232/28000 datapoints
2025-03-07 12:28:05,678 - INFO - training batch 401, loss: 0.030, 12832/28000 datapoints
2025-03-07 12:28:05,954 - INFO - training batch 451, loss: 0.022, 14432/28000 datapoints
2025-03-07 12:28:06,229 - INFO - training batch 501, loss: 0.023, 16032/28000 datapoints
2025-03-07 12:28:06,511 - INFO - training batch 551, loss: 0.015, 17632/28000 datapoints
2025-03-07 12:28:06,804 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-07 12:28:07,100 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 12:28:07,389 - INFO - training batch 701, loss: 0.027, 22432/28000 datapoints
2025-03-07 12:28:07,669 - INFO - training batch 751, loss: 0.035, 24032/28000 datapoints
2025-03-07 12:28:07,951 - INFO - training batch 801, loss: 0.016, 25632/28000 datapoints
2025-03-07 12:28:08,232 - INFO - training batch 851, loss: 0.020, 27232/28000 datapoints
2025-03-07 12:28:08,369 - INFO - validation batch 1, loss: 0.056, 32/6976 datapoints
2025-03-07 12:28:08,448 - INFO - validation batch 51, loss: 1.136, 1632/6976 datapoints
2025-03-07 12:28:08,533 - INFO - validation batch 101, loss: 0.169, 3232/6976 datapoints
2025-03-07 12:28:08,609 - INFO - validation batch 151, loss: 0.390, 4832/6976 datapoints
2025-03-07 12:28:08,714 - INFO - validation batch 201, loss: 0.347, 6432/6976 datapoints
2025-03-07 12:28:08,751 - INFO - Epoch 167/800 done.
2025-03-07 12:28:08,751 - INFO - Final validation performance:
Loss: 0.420, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:28:08,752 - INFO - Beginning epoch 168/800
2025-03-07 12:28:08,760 - INFO - training batch 1, loss: 0.049, 32/28000 datapoints
2025-03-07 12:28:09,068 - INFO - training batch 51, loss: 0.028, 1632/28000 datapoints
2025-03-07 12:28:09,351 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-07 12:28:09,629 - INFO - training batch 151, loss: 0.010, 4832/28000 datapoints
2025-03-07 12:28:09,910 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-07 12:28:10,190 - INFO - training batch 251, loss: 0.025, 8032/28000 datapoints
2025-03-07 12:28:10,476 - INFO - training batch 301, loss: 0.032, 9632/28000 datapoints
2025-03-07 12:28:10,759 - INFO - training batch 351, loss: 0.036, 11232/28000 datapoints
2025-03-07 12:28:11,043 - INFO - training batch 401, loss: 0.029, 12832/28000 datapoints
2025-03-07 12:28:11,333 - INFO - training batch 451, loss: 0.021, 14432/28000 datapoints
2025-03-07 12:28:11,628 - INFO - training batch 501, loss: 0.022, 16032/28000 datapoints
2025-03-07 12:28:11,916 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-07 12:28:12,210 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-07 12:28:12,503 - INFO - training batch 651, loss: 0.006, 20832/28000 datapoints
2025-03-07 12:28:12,788 - INFO - training batch 701, loss: 0.026, 22432/28000 datapoints
2025-03-07 12:28:13,079 - INFO - training batch 751, loss: 0.034, 24032/28000 datapoints
2025-03-07 12:28:13,381 - INFO - training batch 801, loss: 0.015, 25632/28000 datapoints
2025-03-07 12:28:13,665 - INFO - training batch 851, loss: 0.019, 27232/28000 datapoints
2025-03-07 12:28:13,807 - INFO - validation batch 1, loss: 0.056, 32/6976 datapoints
2025-03-07 12:28:13,885 - INFO - validation batch 51, loss: 1.148, 1632/6976 datapoints
2025-03-07 12:28:13,962 - INFO - validation batch 101, loss: 0.169, 3232/6976 datapoints
2025-03-07 12:28:14,040 - INFO - validation batch 151, loss: 0.392, 4832/6976 datapoints
2025-03-07 12:28:14,113 - INFO - validation batch 201, loss: 0.349, 6432/6976 datapoints
2025-03-07 12:28:14,142 - INFO - Epoch 168/800 done.
2025-03-07 12:28:14,142 - INFO - Final validation performance:
Loss: 0.423, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:28:14,143 - INFO - Beginning epoch 169/800
2025-03-07 12:28:14,151 - INFO - training batch 1, loss: 0.047, 32/28000 datapoints
2025-03-07 12:28:14,433 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-07 12:28:14,720 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-07 12:28:14,997 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-07 12:28:15,276 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-07 12:28:15,557 - INFO - training batch 251, loss: 0.025, 8032/28000 datapoints
2025-03-07 12:28:15,839 - INFO - training batch 301, loss: 0.031, 9632/28000 datapoints
2025-03-07 12:28:16,122 - INFO - training batch 351, loss: 0.035, 11232/28000 datapoints
2025-03-07 12:28:16,404 - INFO - training batch 401, loss: 0.028, 12832/28000 datapoints
2025-03-07 12:28:16,689 - INFO - training batch 451, loss: 0.020, 14432/28000 datapoints
2025-03-07 12:28:16,972 - INFO - training batch 501, loss: 0.021, 16032/28000 datapoints
2025-03-07 12:28:17,253 - INFO - training batch 551, loss: 0.014, 17632/28000 datapoints
2025-03-07 12:28:17,531 - INFO - training batch 601, loss: 0.018, 19232/28000 datapoints
2025-03-07 12:28:17,817 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 12:28:18,096 - INFO - training batch 701, loss: 0.024, 22432/28000 datapoints
2025-03-07 12:28:18,375 - INFO - training batch 751, loss: 0.032, 24032/28000 datapoints
2025-03-07 12:28:18,657 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-07 12:28:18,974 - INFO - training batch 851, loss: 0.018, 27232/28000 datapoints
2025-03-07 12:28:19,179 - INFO - validation batch 1, loss: 0.055, 32/6976 datapoints
2025-03-07 12:28:19,285 - INFO - validation batch 51, loss: 1.164, 1632/6976 datapoints
2025-03-07 12:28:19,364 - INFO - validation batch 101, loss: 0.169, 3232/6976 datapoints
2025-03-07 12:28:19,482 - INFO - validation batch 151, loss: 0.394, 4832/6976 datapoints
2025-03-07 12:28:19,603 - INFO - validation batch 201, loss: 0.349, 6432/6976 datapoints
2025-03-07 12:28:19,639 - INFO - Epoch 169/800 done.
2025-03-07 12:28:19,639 - INFO - Final validation performance:
Loss: 0.426, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:28:19,640 - INFO - Beginning epoch 170/800
2025-03-07 12:28:19,648 - INFO - training batch 1, loss: 0.046, 32/28000 datapoints
2025-03-07 12:28:19,997 - INFO - training batch 51, loss: 0.026, 1632/28000 datapoints
2025-03-07 12:28:20,342 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-07 12:28:20,689 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-07 12:28:21,024 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-07 12:28:21,353 - INFO - training batch 251, loss: 0.023, 8032/28000 datapoints
2025-03-07 12:28:21,665 - INFO - training batch 301, loss: 0.029, 9632/28000 datapoints
2025-03-07 12:28:21,968 - INFO - training batch 351, loss: 0.033, 11232/28000 datapoints
2025-03-07 12:28:22,267 - INFO - training batch 401, loss: 0.027, 12832/28000 datapoints
2025-03-07 12:28:22,588 - INFO - training batch 451, loss: 0.018, 14432/28000 datapoints
2025-03-07 12:28:22,879 - INFO - training batch 501, loss: 0.020, 16032/28000 datapoints
2025-03-07 12:28:23,166 - INFO - training batch 551, loss: 0.013, 17632/28000 datapoints
2025-03-07 12:28:23,493 - INFO - training batch 601, loss: 0.017, 19232/28000 datapoints
2025-03-07 12:28:23,774 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 12:28:24,073 - INFO - training batch 701, loss: 0.022, 22432/28000 datapoints
2025-03-07 12:28:24,355 - INFO - training batch 751, loss: 0.030, 24032/28000 datapoints
2025-03-07 12:28:24,648 - INFO - training batch 801, loss: 0.014, 25632/28000 datapoints
2025-03-07 12:28:24,928 - INFO - training batch 851, loss: 0.018, 27232/28000 datapoints
2025-03-07 12:28:25,063 - INFO - validation batch 1, loss: 0.054, 32/6976 datapoints
2025-03-07 12:28:25,139 - INFO - validation batch 51, loss: 1.176, 1632/6976 datapoints
2025-03-07 12:28:25,211 - INFO - validation batch 101, loss: 0.169, 3232/6976 datapoints
2025-03-07 12:28:25,284 - INFO - validation batch 151, loss: 0.397, 4832/6976 datapoints
2025-03-07 12:28:25,361 - INFO - validation batch 201, loss: 0.349, 6432/6976 datapoints
2025-03-07 12:28:25,389 - INFO - Epoch 170/800 done.
2025-03-07 12:28:25,389 - INFO - Final validation performance:
Loss: 0.429, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:28:25,390 - INFO - Beginning epoch 171/800
2025-03-07 12:28:25,398 - INFO - training batch 1, loss: 0.044, 32/28000 datapoints
2025-03-07 12:28:25,682 - INFO - training batch 51, loss: 0.024, 1632/28000 datapoints
2025-03-07 12:28:25,957 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-07 12:28:26,232 - INFO - training batch 151, loss: 0.009, 4832/28000 datapoints
2025-03-07 12:28:26,513 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-07 12:28:26,793 - INFO - training batch 251, loss: 0.023, 8032/28000 datapoints
2025-03-07 12:28:27,071 - INFO - training batch 301, loss: 0.028, 9632/28000 datapoints
2025-03-07 12:28:27,348 - INFO - training batch 351, loss: 0.031, 11232/28000 datapoints
2025-03-07 12:28:27,637 - INFO - training batch 401, loss: 0.026, 12832/28000 datapoints
2025-03-07 12:28:27,919 - INFO - training batch 451, loss: 0.017, 14432/28000 datapoints
2025-03-07 12:28:28,223 - INFO - training batch 501, loss: 0.019, 16032/28000 datapoints
2025-03-07 12:28:28,542 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-07 12:28:28,848 - INFO - training batch 601, loss: 0.017, 19232/28000 datapoints
2025-03-07 12:28:29,177 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 12:28:29,476 - INFO - training batch 701, loss: 0.021, 22432/28000 datapoints
2025-03-07 12:28:29,762 - INFO - training batch 751, loss: 0.029, 24032/28000 datapoints
2025-03-07 12:28:30,057 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-07 12:28:30,345 - INFO - training batch 851, loss: 0.017, 27232/28000 datapoints
2025-03-07 12:28:30,513 - INFO - validation batch 1, loss: 0.053, 32/6976 datapoints
2025-03-07 12:28:30,593 - INFO - validation batch 51, loss: 1.191, 1632/6976 datapoints
2025-03-07 12:28:30,670 - INFO - validation batch 101, loss: 0.170, 3232/6976 datapoints
2025-03-07 12:28:30,750 - INFO - validation batch 151, loss: 0.399, 4832/6976 datapoints
2025-03-07 12:28:30,825 - INFO - validation batch 201, loss: 0.351, 6432/6976 datapoints
2025-03-07 12:28:30,851 - INFO - Epoch 171/800 done.
2025-03-07 12:28:30,852 - INFO - Final validation performance:
Loss: 0.433, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:28:30,852 - INFO - Beginning epoch 172/800
2025-03-07 12:28:30,861 - INFO - training batch 1, loss: 0.043, 32/28000 datapoints
2025-03-07 12:28:31,184 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-07 12:28:31,479 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-07 12:28:31,764 - INFO - training batch 151, loss: 0.008, 4832/28000 datapoints
2025-03-07 12:28:32,053 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-07 12:28:32,336 - INFO - training batch 251, loss: 0.022, 8032/28000 datapoints
2025-03-07 12:28:32,632 - INFO - training batch 301, loss: 0.027, 9632/28000 datapoints
2025-03-07 12:28:32,914 - INFO - training batch 351, loss: 0.030, 11232/28000 datapoints
2025-03-07 12:28:33,201 - INFO - training batch 401, loss: 0.025, 12832/28000 datapoints
2025-03-07 12:28:33,506 - INFO - training batch 451, loss: 0.016, 14432/28000 datapoints
2025-03-07 12:28:33,786 - INFO - training batch 501, loss: 0.018, 16032/28000 datapoints
2025-03-07 12:28:34,068 - INFO - training batch 551, loss: 0.012, 17632/28000 datapoints
2025-03-07 12:28:34,349 - INFO - training batch 601, loss: 0.016, 19232/28000 datapoints
2025-03-07 12:28:34,636 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 12:28:34,916 - INFO - training batch 701, loss: 0.020, 22432/28000 datapoints
2025-03-07 12:28:35,197 - INFO - training batch 751, loss: 0.027, 24032/28000 datapoints
2025-03-07 12:28:35,478 - INFO - training batch 801, loss: 0.013, 25632/28000 datapoints
2025-03-07 12:28:35,758 - INFO - training batch 851, loss: 0.016, 27232/28000 datapoints
2025-03-07 12:28:35,895 - INFO - validation batch 1, loss: 0.053, 32/6976 datapoints
2025-03-07 12:28:35,968 - INFO - validation batch 51, loss: 1.203, 1632/6976 datapoints
2025-03-07 12:28:36,042 - INFO - validation batch 101, loss: 0.171, 3232/6976 datapoints
2025-03-07 12:28:36,115 - INFO - validation batch 151, loss: 0.402, 4832/6976 datapoints
2025-03-07 12:28:36,190 - INFO - validation batch 201, loss: 0.351, 6432/6976 datapoints
2025-03-07 12:28:36,217 - INFO - Epoch 172/800 done.
2025-03-07 12:28:36,217 - INFO - Final validation performance:
Loss: 0.436, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:28:36,218 - INFO - Beginning epoch 173/800
2025-03-07 12:28:36,227 - INFO - training batch 1, loss: 0.042, 32/28000 datapoints
2025-03-07 12:28:36,510 - INFO - training batch 51, loss: 0.022, 1632/28000 datapoints
2025-03-07 12:28:36,790 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-07 12:28:37,069 - INFO - training batch 151, loss: 0.008, 4832/28000 datapoints
2025-03-07 12:28:37,345 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-07 12:28:37,628 - INFO - training batch 251, loss: 0.020, 8032/28000 datapoints
2025-03-07 12:28:37,910 - INFO - training batch 301, loss: 0.025, 9632/28000 datapoints
2025-03-07 12:28:38,189 - INFO - training batch 351, loss: 0.028, 11232/28000 datapoints
2025-03-07 12:28:38,469 - INFO - training batch 401, loss: 0.024, 12832/28000 datapoints
2025-03-07 12:28:38,748 - INFO - training batch 451, loss: 0.015, 14432/28000 datapoints
2025-03-07 12:28:39,035 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-07 12:28:39,351 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-07 12:28:39,729 - INFO - training batch 601, loss: 0.015, 19232/28000 datapoints
2025-03-07 12:28:40,070 - INFO - training batch 651, loss: 0.005, 20832/28000 datapoints
2025-03-07 12:28:40,355 - INFO - training batch 701, loss: 0.018, 22432/28000 datapoints
2025-03-07 12:28:40,645 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-07 12:28:40,930 - INFO - training batch 801, loss: 0.012, 25632/28000 datapoints
2025-03-07 12:28:41,216 - INFO - training batch 851, loss: 0.015, 27232/28000 datapoints
2025-03-07 12:28:41,357 - INFO - validation batch 1, loss: 0.052, 32/6976 datapoints
2025-03-07 12:28:41,431 - INFO - validation batch 51, loss: 1.220, 1632/6976 datapoints
2025-03-07 12:28:41,505 - INFO - validation batch 101, loss: 0.171, 3232/6976 datapoints
2025-03-07 12:28:41,578 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-07 12:28:41,661 - INFO - validation batch 201, loss: 0.354, 6432/6976 datapoints
2025-03-07 12:28:41,692 - INFO - Epoch 173/800 done.
2025-03-07 12:28:41,693 - INFO - Final validation performance:
Loss: 0.440, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:28:41,693 - INFO - Beginning epoch 174/800
2025-03-07 12:28:41,702 - INFO - training batch 1, loss: 0.040, 32/28000 datapoints
2025-03-07 12:28:41,996 - INFO - training batch 51, loss: 0.021, 1632/28000 datapoints
2025-03-07 12:28:42,279 - INFO - training batch 101, loss: 0.009, 3232/28000 datapoints
2025-03-07 12:28:42,565 - INFO - training batch 151, loss: 0.008, 4832/28000 datapoints
2025-03-07 12:28:42,844 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-07 12:28:43,123 - INFO - training batch 251, loss: 0.019, 8032/28000 datapoints
2025-03-07 12:28:43,409 - INFO - training batch 301, loss: 0.024, 9632/28000 datapoints
2025-03-07 12:28:43,716 - INFO - training batch 351, loss: 0.027, 11232/28000 datapoints
2025-03-07 12:28:43,995 - INFO - training batch 401, loss: 0.023, 12832/28000 datapoints
2025-03-07 12:28:44,279 - INFO - training batch 451, loss: 0.014, 14432/28000 datapoints
2025-03-07 12:28:44,567 - INFO - training batch 501, loss: 0.017, 16032/28000 datapoints
2025-03-07 12:28:44,845 - INFO - training batch 551, loss: 0.011, 17632/28000 datapoints
2025-03-07 12:28:45,123 - INFO - training batch 601, loss: 0.014, 19232/28000 datapoints
2025-03-07 12:28:45,402 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-07 12:28:45,681 - INFO - training batch 701, loss: 0.017, 22432/28000 datapoints
2025-03-07 12:28:45,955 - INFO - training batch 751, loss: 0.024, 24032/28000 datapoints
2025-03-07 12:28:46,232 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-07 12:28:46,515 - INFO - training batch 851, loss: 0.014, 27232/28000 datapoints
2025-03-07 12:28:46,652 - INFO - validation batch 1, loss: 0.051, 32/6976 datapoints
2025-03-07 12:28:46,721 - INFO - validation batch 51, loss: 1.236, 1632/6976 datapoints
2025-03-07 12:28:46,789 - INFO - validation batch 101, loss: 0.170, 3232/6976 datapoints
2025-03-07 12:28:46,860 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-07 12:28:46,929 - INFO - validation batch 201, loss: 0.356, 6432/6976 datapoints
2025-03-07 12:28:46,954 - INFO - Epoch 174/800 done.
2025-03-07 12:28:46,954 - INFO - Final validation performance:
Loss: 0.444, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:28:46,955 - INFO - Beginning epoch 175/800
2025-03-07 12:28:46,962 - INFO - training batch 1, loss: 0.038, 32/28000 datapoints
2025-03-07 12:28:47,241 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-07 12:28:47,523 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 12:28:47,801 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-07 12:28:48,074 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-07 12:28:48,350 - INFO - training batch 251, loss: 0.018, 8032/28000 datapoints
2025-03-07 12:28:48,638 - INFO - training batch 301, loss: 0.022, 9632/28000 datapoints
2025-03-07 12:28:48,920 - INFO - training batch 351, loss: 0.025, 11232/28000 datapoints
2025-03-07 12:28:49,198 - INFO - training batch 401, loss: 0.022, 12832/28000 datapoints
2025-03-07 12:28:49,501 - INFO - training batch 451, loss: 0.014, 14432/28000 datapoints
2025-03-07 12:28:49,838 - INFO - training batch 501, loss: 0.016, 16032/28000 datapoints
2025-03-07 12:28:50,155 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-07 12:28:50,484 - INFO - training batch 601, loss: 0.013, 19232/28000 datapoints
2025-03-07 12:28:50,817 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-07 12:28:51,149 - INFO - training batch 701, loss: 0.016, 22432/28000 datapoints
2025-03-07 12:28:51,479 - INFO - training batch 751, loss: 0.022, 24032/28000 datapoints
2025-03-07 12:28:51,805 - INFO - training batch 801, loss: 0.011, 25632/28000 datapoints
2025-03-07 12:28:52,122 - INFO - training batch 851, loss: 0.014, 27232/28000 datapoints
2025-03-07 12:28:52,280 - INFO - validation batch 1, loss: 0.050, 32/6976 datapoints
2025-03-07 12:28:52,364 - INFO - validation batch 51, loss: 1.249, 1632/6976 datapoints
2025-03-07 12:28:52,445 - INFO - validation batch 101, loss: 0.172, 3232/6976 datapoints
2025-03-07 12:28:52,533 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-07 12:28:52,614 - INFO - validation batch 201, loss: 0.356, 6432/6976 datapoints
2025-03-07 12:28:52,644 - INFO - Epoch 175/800 done.
2025-03-07 12:28:52,645 - INFO - Final validation performance:
Loss: 0.447, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:28:52,645 - INFO - Beginning epoch 176/800
2025-03-07 12:28:52,653 - INFO - training batch 1, loss: 0.037, 32/28000 datapoints
2025-03-07 12:28:52,958 - INFO - training batch 51, loss: 0.019, 1632/28000 datapoints
2025-03-07 12:28:53,248 - INFO - training batch 101, loss: 0.008, 3232/28000 datapoints
2025-03-07 12:28:53,550 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-07 12:28:53,881 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-07 12:28:54,203 - INFO - training batch 251, loss: 0.018, 8032/28000 datapoints
2025-03-07 12:28:54,491 - INFO - training batch 301, loss: 0.021, 9632/28000 datapoints
2025-03-07 12:28:54,820 - INFO - training batch 351, loss: 0.024, 11232/28000 datapoints
2025-03-07 12:28:55,125 - INFO - training batch 401, loss: 0.021, 12832/28000 datapoints
2025-03-07 12:28:55,406 - INFO - training batch 451, loss: 0.013, 14432/28000 datapoints
2025-03-07 12:28:55,693 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-07 12:28:55,975 - INFO - training batch 551, loss: 0.010, 17632/28000 datapoints
2025-03-07 12:28:56,257 - INFO - training batch 601, loss: 0.012, 19232/28000 datapoints
2025-03-07 12:28:56,539 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-07 12:28:56,821 - INFO - training batch 701, loss: 0.015, 22432/28000 datapoints
2025-03-07 12:28:57,106 - INFO - training batch 751, loss: 0.021, 24032/28000 datapoints
2025-03-07 12:28:57,397 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-07 12:28:57,689 - INFO - training batch 851, loss: 0.013, 27232/28000 datapoints
2025-03-07 12:28:57,839 - INFO - validation batch 1, loss: 0.050, 32/6976 datapoints
2025-03-07 12:28:57,914 - INFO - validation batch 51, loss: 1.265, 1632/6976 datapoints
2025-03-07 12:28:57,992 - INFO - validation batch 101, loss: 0.172, 3232/6976 datapoints
2025-03-07 12:28:58,077 - INFO - validation batch 151, loss: 0.413, 4832/6976 datapoints
2025-03-07 12:28:58,153 - INFO - validation batch 201, loss: 0.358, 6432/6976 datapoints
2025-03-07 12:28:58,183 - INFO - Epoch 176/800 done.
2025-03-07 12:28:58,183 - INFO - Final validation performance:
Loss: 0.452, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:28:58,184 - INFO - Beginning epoch 177/800
2025-03-07 12:28:58,193 - INFO - training batch 1, loss: 0.035, 32/28000 datapoints
2025-03-07 12:28:58,518 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-07 12:28:58,820 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 12:28:59,115 - INFO - training batch 151, loss: 0.007, 4832/28000 datapoints
2025-03-07 12:28:59,409 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-07 12:28:59,716 - INFO - training batch 251, loss: 0.017, 8032/28000 datapoints
2025-03-07 12:29:00,101 - INFO - training batch 301, loss: 0.020, 9632/28000 datapoints
2025-03-07 12:29:00,461 - INFO - training batch 351, loss: 0.023, 11232/28000 datapoints
2025-03-07 12:29:00,772 - INFO - training batch 401, loss: 0.020, 12832/28000 datapoints
2025-03-07 12:29:01,056 - INFO - training batch 451, loss: 0.012, 14432/28000 datapoints
2025-03-07 12:29:01,344 - INFO - training batch 501, loss: 0.015, 16032/28000 datapoints
2025-03-07 12:29:01,635 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-07 12:29:01,934 - INFO - training batch 601, loss: 0.012, 19232/28000 datapoints
2025-03-07 12:29:02,231 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-07 12:29:02,536 - INFO - training batch 701, loss: 0.014, 22432/28000 datapoints
2025-03-07 12:29:02,836 - INFO - training batch 751, loss: 0.019, 24032/28000 datapoints
2025-03-07 12:29:03,115 - INFO - training batch 801, loss: 0.010, 25632/28000 datapoints
2025-03-07 12:29:03,396 - INFO - training batch 851, loss: 0.012, 27232/28000 datapoints
2025-03-07 12:29:03,537 - INFO - validation batch 1, loss: 0.049, 32/6976 datapoints
2025-03-07 12:29:03,611 - INFO - validation batch 51, loss: 1.282, 1632/6976 datapoints
2025-03-07 12:29:03,704 - INFO - validation batch 101, loss: 0.173, 3232/6976 datapoints
2025-03-07 12:29:03,793 - INFO - validation batch 151, loss: 0.417, 4832/6976 datapoints
2025-03-07 12:29:03,871 - INFO - validation batch 201, loss: 0.361, 6432/6976 datapoints
2025-03-07 12:29:03,898 - INFO - Epoch 177/800 done.
2025-03-07 12:29:03,898 - INFO - Final validation performance:
Loss: 0.456, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:29:03,899 - INFO - Beginning epoch 178/800
2025-03-07 12:29:03,907 - INFO - training batch 1, loss: 0.034, 32/28000 datapoints
2025-03-07 12:29:04,198 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-07 12:29:04,486 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 12:29:04,768 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-07 12:29:05,049 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-07 12:29:05,348 - INFO - training batch 251, loss: 0.016, 8032/28000 datapoints
2025-03-07 12:29:05,635 - INFO - training batch 301, loss: 0.019, 9632/28000 datapoints
2025-03-07 12:29:05,916 - INFO - training batch 351, loss: 0.022, 11232/28000 datapoints
2025-03-07 12:29:06,195 - INFO - training batch 401, loss: 0.019, 12832/28000 datapoints
2025-03-07 12:29:06,476 - INFO - training batch 451, loss: 0.011, 14432/28000 datapoints
2025-03-07 12:29:06,767 - INFO - training batch 501, loss: 0.014, 16032/28000 datapoints
2025-03-07 12:29:07,070 - INFO - training batch 551, loss: 0.009, 17632/28000 datapoints
2025-03-07 12:29:07,351 - INFO - training batch 601, loss: 0.011, 19232/28000 datapoints
2025-03-07 12:29:07,634 - INFO - training batch 651, loss: 0.004, 20832/28000 datapoints
2025-03-07 12:29:07,917 - INFO - training batch 701, loss: 0.014, 22432/28000 datapoints
2025-03-07 12:29:08,198 - INFO - training batch 751, loss: 0.018, 24032/28000 datapoints
2025-03-07 12:29:08,480 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-07 12:29:08,773 - INFO - training batch 851, loss: 0.012, 27232/28000 datapoints
2025-03-07 12:29:08,916 - INFO - validation batch 1, loss: 0.047, 32/6976 datapoints
2025-03-07 12:29:08,995 - INFO - validation batch 51, loss: 1.295, 1632/6976 datapoints
2025-03-07 12:29:09,073 - INFO - validation batch 101, loss: 0.172, 3232/6976 datapoints
2025-03-07 12:29:09,149 - INFO - validation batch 151, loss: 0.420, 4832/6976 datapoints
2025-03-07 12:29:09,228 - INFO - validation batch 201, loss: 0.361, 6432/6976 datapoints
2025-03-07 12:29:09,254 - INFO - Epoch 178/800 done.
2025-03-07 12:29:09,254 - INFO - Final validation performance:
Loss: 0.459, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:29:09,254 - INFO - Beginning epoch 179/800
2025-03-07 12:29:09,263 - INFO - training batch 1, loss: 0.032, 32/28000 datapoints
2025-03-07 12:29:09,570 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-07 12:29:09,893 - INFO - training batch 101, loss: 0.007, 3232/28000 datapoints
2025-03-07 12:29:10,216 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-07 12:29:10,514 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-07 12:29:10,804 - INFO - training batch 251, loss: 0.015, 8032/28000 datapoints
2025-03-07 12:29:11,104 - INFO - training batch 301, loss: 0.018, 9632/28000 datapoints
2025-03-07 12:29:11,397 - INFO - training batch 351, loss: 0.021, 11232/28000 datapoints
2025-03-07 12:29:11,677 - INFO - training batch 401, loss: 0.018, 12832/28000 datapoints
2025-03-07 12:29:11,957 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-07 12:29:12,240 - INFO - training batch 501, loss: 0.013, 16032/28000 datapoints
2025-03-07 12:29:12,527 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-07 12:29:12,810 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-07 12:29:13,093 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-07 12:29:13,374 - INFO - training batch 701, loss: 0.013, 22432/28000 datapoints
2025-03-07 12:29:13,657 - INFO - training batch 751, loss: 0.017, 24032/28000 datapoints
2025-03-07 12:29:13,964 - INFO - training batch 801, loss: 0.009, 25632/28000 datapoints
2025-03-07 12:29:14,250 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-07 12:29:14,386 - INFO - validation batch 1, loss: 0.046, 32/6976 datapoints
2025-03-07 12:29:14,463 - INFO - validation batch 51, loss: 1.312, 1632/6976 datapoints
2025-03-07 12:29:14,543 - INFO - validation batch 101, loss: 0.173, 3232/6976 datapoints
2025-03-07 12:29:14,621 - INFO - validation batch 151, loss: 0.424, 4832/6976 datapoints
2025-03-07 12:29:14,700 - INFO - validation batch 201, loss: 0.364, 6432/6976 datapoints
2025-03-07 12:29:14,726 - INFO - Epoch 179/800 done.
2025-03-07 12:29:14,726 - INFO - Final validation performance:
Loss: 0.464, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:29:14,727 - INFO - Beginning epoch 180/800
2025-03-07 12:29:14,736 - INFO - training batch 1, loss: 0.030, 32/28000 datapoints
2025-03-07 12:29:15,021 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-07 12:29:15,306 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-07 12:29:15,586 - INFO - training batch 151, loss: 0.006, 4832/28000 datapoints
2025-03-07 12:29:15,863 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-07 12:29:16,145 - INFO - training batch 251, loss: 0.014, 8032/28000 datapoints
2025-03-07 12:29:16,432 - INFO - training batch 301, loss: 0.017, 9632/28000 datapoints
2025-03-07 12:29:16,724 - INFO - training batch 351, loss: 0.020, 11232/28000 datapoints
2025-03-07 12:29:17,006 - INFO - training batch 401, loss: 0.018, 12832/28000 datapoints
2025-03-07 12:29:17,297 - INFO - training batch 451, loss: 0.010, 14432/28000 datapoints
2025-03-07 12:29:17,583 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-07 12:29:17,868 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-07 12:29:18,147 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-07 12:29:18,423 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-07 12:29:18,697 - INFO - training batch 701, loss: 0.012, 22432/28000 datapoints
2025-03-07 12:29:18,979 - INFO - training batch 751, loss: 0.016, 24032/28000 datapoints
2025-03-07 12:29:19,255 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-07 12:29:19,535 - INFO - training batch 851, loss: 0.011, 27232/28000 datapoints
2025-03-07 12:29:19,670 - INFO - validation batch 1, loss: 0.046, 32/6976 datapoints
2025-03-07 12:29:19,741 - INFO - validation batch 51, loss: 1.327, 1632/6976 datapoints
2025-03-07 12:29:19,812 - INFO - validation batch 101, loss: 0.176, 3232/6976 datapoints
2025-03-07 12:29:19,883 - INFO - validation batch 151, loss: 0.427, 4832/6976 datapoints
2025-03-07 12:29:19,954 - INFO - validation batch 201, loss: 0.366, 6432/6976 datapoints
2025-03-07 12:29:19,981 - INFO - Epoch 180/800 done.
2025-03-07 12:29:19,981 - INFO - Final validation performance:
Loss: 0.468, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:29:19,982 - INFO - Beginning epoch 181/800
2025-03-07 12:29:19,991 - INFO - training batch 1, loss: 0.029, 32/28000 datapoints
2025-03-07 12:29:20,389 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-07 12:29:20,771 - INFO - training batch 101, loss: 0.006, 3232/28000 datapoints
2025-03-07 12:29:21,098 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-07 12:29:21,431 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-07 12:29:21,762 - INFO - training batch 251, loss: 0.013, 8032/28000 datapoints
2025-03-07 12:29:22,101 - INFO - training batch 301, loss: 0.016, 9632/28000 datapoints
2025-03-07 12:29:22,435 - INFO - training batch 351, loss: 0.019, 11232/28000 datapoints
2025-03-07 12:29:22,756 - INFO - training batch 401, loss: 0.017, 12832/28000 datapoints
2025-03-07 12:29:23,066 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-07 12:29:23,366 - INFO - training batch 501, loss: 0.012, 16032/28000 datapoints
2025-03-07 12:29:23,666 - INFO - training batch 551, loss: 0.008, 17632/28000 datapoints
2025-03-07 12:29:23,980 - INFO - training batch 601, loss: 0.009, 19232/28000 datapoints
2025-03-07 12:29:24,263 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-07 12:29:24,546 - INFO - training batch 701, loss: 0.011, 22432/28000 datapoints
2025-03-07 12:29:24,830 - INFO - training batch 751, loss: 0.015, 24032/28000 datapoints
2025-03-07 12:29:25,130 - INFO - training batch 801, loss: 0.008, 25632/28000 datapoints
2025-03-07 12:29:25,422 - INFO - training batch 851, loss: 0.010, 27232/28000 datapoints
2025-03-07 12:29:25,562 - INFO - validation batch 1, loss: 0.045, 32/6976 datapoints
2025-03-07 12:29:25,631 - INFO - validation batch 51, loss: 1.346, 1632/6976 datapoints
2025-03-07 12:29:25,699 - INFO - validation batch 101, loss: 0.177, 3232/6976 datapoints
2025-03-07 12:29:25,769 - INFO - validation batch 151, loss: 0.432, 4832/6976 datapoints
2025-03-07 12:29:25,841 - INFO - validation batch 201, loss: 0.369, 6432/6976 datapoints
2025-03-07 12:29:25,864 - INFO - Epoch 181/800 done.
2025-03-07 12:29:25,864 - INFO - Final validation performance:
Loss: 0.474, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:29:25,865 - INFO - Beginning epoch 182/800
2025-03-07 12:29:25,873 - INFO - training batch 1, loss: 0.028, 32/28000 datapoints
2025-03-07 12:29:26,161 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-07 12:29:26,476 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-07 12:29:26,755 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-07 12:29:27,030 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-07 12:29:27,313 - INFO - training batch 251, loss: 0.012, 8032/28000 datapoints
2025-03-07 12:29:27,597 - INFO - training batch 301, loss: 0.015, 9632/28000 datapoints
2025-03-07 12:29:27,884 - INFO - training batch 351, loss: 0.017, 11232/28000 datapoints
2025-03-07 12:29:28,163 - INFO - training batch 401, loss: 0.016, 12832/28000 datapoints
2025-03-07 12:29:28,442 - INFO - training batch 451, loss: 0.009, 14432/28000 datapoints
2025-03-07 12:29:28,723 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-07 12:29:29,012 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-07 12:29:29,297 - INFO - training batch 601, loss: 0.009, 19232/28000 datapoints
2025-03-07 12:29:29,584 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-07 12:29:29,869 - INFO - training batch 701, loss: 0.011, 22432/28000 datapoints
2025-03-07 12:29:30,172 - INFO - training batch 751, loss: 0.014, 24032/28000 datapoints
2025-03-07 12:29:30,550 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-07 12:29:30,842 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-07 12:29:30,986 - INFO - validation batch 1, loss: 0.045, 32/6976 datapoints
2025-03-07 12:29:31,062 - INFO - validation batch 51, loss: 1.362, 1632/6976 datapoints
2025-03-07 12:29:31,140 - INFO - validation batch 101, loss: 0.178, 3232/6976 datapoints
2025-03-07 12:29:31,217 - INFO - validation batch 151, loss: 0.437, 4832/6976 datapoints
2025-03-07 12:29:31,296 - INFO - validation batch 201, loss: 0.372, 6432/6976 datapoints
2025-03-07 12:29:31,321 - INFO - Epoch 182/800 done.
2025-03-07 12:29:31,321 - INFO - Final validation performance:
Loss: 0.479, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:29:31,323 - INFO - Beginning epoch 183/800
2025-03-07 12:29:31,333 - INFO - training batch 1, loss: 0.026, 32/28000 datapoints
2025-03-07 12:29:31,632 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-07 12:29:31,931 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-07 12:29:32,220 - INFO - training batch 151, loss: 0.005, 4832/28000 datapoints
2025-03-07 12:29:32,518 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-07 12:29:32,807 - INFO - training batch 251, loss: 0.012, 8032/28000 datapoints
2025-03-07 12:29:33,093 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-07 12:29:33,376 - INFO - training batch 351, loss: 0.016, 11232/28000 datapoints
2025-03-07 12:29:33,684 - INFO - training batch 401, loss: 0.015, 12832/28000 datapoints
2025-03-07 12:29:34,005 - INFO - training batch 451, loss: 0.008, 14432/28000 datapoints
2025-03-07 12:29:34,314 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-07 12:29:34,598 - INFO - training batch 551, loss: 0.007, 17632/28000 datapoints
2025-03-07 12:29:34,876 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-07 12:29:35,160 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-07 12:29:35,449 - INFO - training batch 701, loss: 0.010, 22432/28000 datapoints
2025-03-07 12:29:35,736 - INFO - training batch 751, loss: 0.013, 24032/28000 datapoints
2025-03-07 12:29:36,023 - INFO - training batch 801, loss: 0.007, 25632/28000 datapoints
2025-03-07 12:29:36,307 - INFO - training batch 851, loss: 0.009, 27232/28000 datapoints
2025-03-07 12:29:36,447 - INFO - validation batch 1, loss: 0.044, 32/6976 datapoints
2025-03-07 12:29:36,532 - INFO - validation batch 51, loss: 1.378, 1632/6976 datapoints
2025-03-07 12:29:36,607 - INFO - validation batch 101, loss: 0.180, 3232/6976 datapoints
2025-03-07 12:29:36,682 - INFO - validation batch 151, loss: 0.440, 4832/6976 datapoints
2025-03-07 12:29:36,758 - INFO - validation batch 201, loss: 0.374, 6432/6976 datapoints
2025-03-07 12:29:36,788 - INFO - Epoch 183/800 done.
2025-03-07 12:29:36,788 - INFO - Final validation performance:
Loss: 0.483, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:29:36,789 - INFO - Beginning epoch 184/800
2025-03-07 12:29:36,796 - INFO - training batch 1, loss: 0.025, 32/28000 datapoints
2025-03-07 12:29:37,088 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-07 12:29:37,380 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-07 12:29:37,673 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-07 12:29:37,971 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-07 12:29:38,286 - INFO - training batch 251, loss: 0.011, 8032/28000 datapoints
2025-03-07 12:29:38,579 - INFO - training batch 301, loss: 0.014, 9632/28000 datapoints
2025-03-07 12:29:38,876 - INFO - training batch 351, loss: 0.015, 11232/28000 datapoints
2025-03-07 12:29:39,171 - INFO - training batch 401, loss: 0.014, 12832/28000 datapoints
2025-03-07 12:29:39,459 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-07 12:29:39,741 - INFO - training batch 501, loss: 0.010, 16032/28000 datapoints
2025-03-07 12:29:40,022 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-07 12:29:40,307 - INFO - training batch 601, loss: 0.008, 19232/28000 datapoints
2025-03-07 12:29:40,671 - INFO - training batch 651, loss: 0.003, 20832/28000 datapoints
2025-03-07 12:29:41,060 - INFO - training batch 701, loss: 0.009, 22432/28000 datapoints
2025-03-07 12:29:41,405 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-07 12:29:41,699 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-07 12:29:41,986 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-07 12:29:42,130 - INFO - validation batch 1, loss: 0.044, 32/6976 datapoints
2025-03-07 12:29:42,212 - INFO - validation batch 51, loss: 1.395, 1632/6976 datapoints
2025-03-07 12:29:42,310 - INFO - validation batch 101, loss: 0.182, 3232/6976 datapoints
2025-03-07 12:29:42,410 - INFO - validation batch 151, loss: 0.444, 4832/6976 datapoints
2025-03-07 12:29:42,496 - INFO - validation batch 201, loss: 0.377, 6432/6976 datapoints
2025-03-07 12:29:42,522 - INFO - Epoch 184/800 done.
2025-03-07 12:29:42,522 - INFO - Final validation performance:
Loss: 0.488, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:29:42,523 - INFO - Beginning epoch 185/800
2025-03-07 12:29:42,532 - INFO - training batch 1, loss: 0.023, 32/28000 datapoints
2025-03-07 12:29:42,856 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-07 12:29:43,158 - INFO - training batch 101, loss: 0.005, 3232/28000 datapoints
2025-03-07 12:29:43,447 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-07 12:29:43,746 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-07 12:29:44,031 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-07 12:29:44,341 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-07 12:29:44,628 - INFO - training batch 351, loss: 0.014, 11232/28000 datapoints
2025-03-07 12:29:44,910 - INFO - training batch 401, loss: 0.014, 12832/28000 datapoints
2025-03-07 12:29:45,190 - INFO - training batch 451, loss: 0.007, 14432/28000 datapoints
2025-03-07 12:29:45,471 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-07 12:29:45,749 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-07 12:29:46,036 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-07 12:29:46,312 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 12:29:46,592 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-07 12:29:46,870 - INFO - training batch 751, loss: 0.011, 24032/28000 datapoints
2025-03-07 12:29:47,151 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-07 12:29:47,457 - INFO - training batch 851, loss: 0.008, 27232/28000 datapoints
2025-03-07 12:29:47,597 - INFO - validation batch 1, loss: 0.043, 32/6976 datapoints
2025-03-07 12:29:47,666 - INFO - validation batch 51, loss: 1.413, 1632/6976 datapoints
2025-03-07 12:29:47,738 - INFO - validation batch 101, loss: 0.184, 3232/6976 datapoints
2025-03-07 12:29:47,814 - INFO - validation batch 151, loss: 0.449, 4832/6976 datapoints
2025-03-07 12:29:47,886 - INFO - validation batch 201, loss: 0.381, 6432/6976 datapoints
2025-03-07 12:29:47,910 - INFO - Epoch 185/800 done.
2025-03-07 12:29:47,910 - INFO - Final validation performance:
Loss: 0.494, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:29:47,910 - INFO - Beginning epoch 186/800
2025-03-07 12:29:47,919 - INFO - training batch 1, loss: 0.022, 32/28000 datapoints
2025-03-07 12:29:48,198 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-07 12:29:48,477 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-07 12:29:48,756 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-07 12:29:49,046 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-07 12:29:49,331 - INFO - training batch 251, loss: 0.010, 8032/28000 datapoints
2025-03-07 12:29:49,621 - INFO - training batch 301, loss: 0.012, 9632/28000 datapoints
2025-03-07 12:29:49,903 - INFO - training batch 351, loss: 0.013, 11232/28000 datapoints
2025-03-07 12:29:50,179 - INFO - training batch 401, loss: 0.013, 12832/28000 datapoints
2025-03-07 12:29:50,462 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-07 12:29:50,783 - INFO - training batch 501, loss: 0.009, 16032/28000 datapoints
2025-03-07 12:29:51,119 - INFO - training batch 551, loss: 0.006, 17632/28000 datapoints
2025-03-07 12:29:51,452 - INFO - training batch 601, loss: 0.007, 19232/28000 datapoints
2025-03-07 12:29:51,790 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 12:29:52,182 - INFO - training batch 701, loss: 0.008, 22432/28000 datapoints
2025-03-07 12:29:52,609 - INFO - training batch 751, loss: 0.010, 24032/28000 datapoints
2025-03-07 12:29:52,983 - INFO - training batch 801, loss: 0.006, 25632/28000 datapoints
2025-03-07 12:29:53,342 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-07 12:29:53,514 - INFO - validation batch 1, loss: 0.042, 32/6976 datapoints
2025-03-07 12:29:53,610 - INFO - validation batch 51, loss: 1.431, 1632/6976 datapoints
2025-03-07 12:29:53,699 - INFO - validation batch 101, loss: 0.184, 3232/6976 datapoints
2025-03-07 12:29:53,780 - INFO - validation batch 151, loss: 0.456, 4832/6976 datapoints
2025-03-07 12:29:53,862 - INFO - validation batch 201, loss: 0.382, 6432/6976 datapoints
2025-03-07 12:29:53,891 - INFO - Epoch 186/800 done.
2025-03-07 12:29:53,892 - INFO - Final validation performance:
Loss: 0.499, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:29:53,892 - INFO - Beginning epoch 187/800
2025-03-07 12:29:53,900 - INFO - training batch 1, loss: 0.021, 32/28000 datapoints
2025-03-07 12:29:54,211 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-07 12:29:54,542 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-07 12:29:54,834 - INFO - training batch 151, loss: 0.004, 4832/28000 datapoints
2025-03-07 12:29:55,135 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-07 12:29:55,419 - INFO - training batch 251, loss: 0.009, 8032/28000 datapoints
2025-03-07 12:29:55,712 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-07 12:29:55,993 - INFO - training batch 351, loss: 0.012, 11232/28000 datapoints
2025-03-07 12:29:56,280 - INFO - training batch 401, loss: 0.012, 12832/28000 datapoints
2025-03-07 12:29:56,602 - INFO - training batch 451, loss: 0.006, 14432/28000 datapoints
2025-03-07 12:29:56,892 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-07 12:29:57,180 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-07 12:29:57,468 - INFO - training batch 601, loss: 0.006, 19232/28000 datapoints
2025-03-07 12:29:57,764 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 12:29:58,059 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-07 12:29:58,366 - INFO - training batch 751, loss: 0.009, 24032/28000 datapoints
2025-03-07 12:29:58,667 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 12:29:58,976 - INFO - training batch 851, loss: 0.007, 27232/28000 datapoints
2025-03-07 12:29:59,131 - INFO - validation batch 1, loss: 0.042, 32/6976 datapoints
2025-03-07 12:29:59,237 - INFO - validation batch 51, loss: 1.449, 1632/6976 datapoints
2025-03-07 12:29:59,336 - INFO - validation batch 101, loss: 0.189, 3232/6976 datapoints
2025-03-07 12:29:59,433 - INFO - validation batch 151, loss: 0.462, 4832/6976 datapoints
2025-03-07 12:29:59,537 - INFO - validation batch 201, loss: 0.387, 6432/6976 datapoints
2025-03-07 12:29:59,569 - INFO - Epoch 187/800 done.
2025-03-07 12:29:59,570 - INFO - Final validation performance:
Loss: 0.506, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:29:59,570 - INFO - Beginning epoch 188/800
2025-03-07 12:29:59,585 - INFO - training batch 1, loss: 0.020, 32/28000 datapoints
2025-03-07 12:29:59,950 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-07 12:30:00,267 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-07 12:30:00,561 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-07 12:30:00,903 - INFO - training batch 201, loss: 0.008, 6432/28000 datapoints
2025-03-07 12:30:01,297 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-07 12:30:01,766 - INFO - training batch 301, loss: 0.011, 9632/28000 datapoints
2025-03-07 12:30:02,087 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-07 12:30:02,388 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-07 12:30:02,690 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-07 12:30:02,998 - INFO - training batch 501, loss: 0.008, 16032/28000 datapoints
2025-03-07 12:30:03,298 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-07 12:30:03,593 - INFO - training batch 601, loss: 0.006, 19232/28000 datapoints
2025-03-07 12:30:03,880 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 12:30:04,182 - INFO - training batch 701, loss: 0.007, 22432/28000 datapoints
2025-03-07 12:30:04,509 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-07 12:30:04,803 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 12:30:05,089 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-07 12:30:05,228 - INFO - validation batch 1, loss: 0.042, 32/6976 datapoints
2025-03-07 12:30:05,308 - INFO - validation batch 51, loss: 1.468, 1632/6976 datapoints
2025-03-07 12:30:05,382 - INFO - validation batch 101, loss: 0.188, 3232/6976 datapoints
2025-03-07 12:30:05,457 - INFO - validation batch 151, loss: 0.467, 4832/6976 datapoints
2025-03-07 12:30:05,540 - INFO - validation batch 201, loss: 0.389, 6432/6976 datapoints
2025-03-07 12:30:05,564 - INFO - Epoch 188/800 done.
2025-03-07 12:30:05,564 - INFO - Final validation performance:
Loss: 0.511, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:30:05,565 - INFO - Beginning epoch 189/800
2025-03-07 12:30:05,574 - INFO - training batch 1, loss: 0.018, 32/28000 datapoints
2025-03-07 12:30:05,868 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-07 12:30:06,152 - INFO - training batch 101, loss: 0.004, 3232/28000 datapoints
2025-03-07 12:30:06,442 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-07 12:30:06,734 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-07 12:30:07,019 - INFO - training batch 251, loss: 0.008, 8032/28000 datapoints
2025-03-07 12:30:07,306 - INFO - training batch 301, loss: 0.010, 9632/28000 datapoints
2025-03-07 12:30:07,618 - INFO - training batch 351, loss: 0.011, 11232/28000 datapoints
2025-03-07 12:30:07,913 - INFO - training batch 401, loss: 0.011, 12832/28000 datapoints
2025-03-07 12:30:08,197 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-07 12:30:08,483 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-07 12:30:08,764 - INFO - training batch 551, loss: 0.005, 17632/28000 datapoints
2025-03-07 12:30:09,050 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-07 12:30:09,335 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 12:30:09,625 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-07 12:30:09,916 - INFO - training batch 751, loss: 0.008, 24032/28000 datapoints
2025-03-07 12:30:10,201 - INFO - training batch 801, loss: 0.005, 25632/28000 datapoints
2025-03-07 12:30:10,494 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-07 12:30:10,636 - INFO - validation batch 1, loss: 0.041, 32/6976 datapoints
2025-03-07 12:30:10,725 - INFO - validation batch 51, loss: 1.485, 1632/6976 datapoints
2025-03-07 12:30:10,824 - INFO - validation batch 101, loss: 0.189, 3232/6976 datapoints
2025-03-07 12:30:10,916 - INFO - validation batch 151, loss: 0.473, 4832/6976 datapoints
2025-03-07 12:30:11,021 - INFO - validation batch 201, loss: 0.393, 6432/6976 datapoints
2025-03-07 12:30:11,062 - INFO - Epoch 189/800 done.
2025-03-07 12:30:11,062 - INFO - Final validation performance:
Loss: 0.516, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:30:11,063 - INFO - Beginning epoch 190/800
2025-03-07 12:30:11,073 - INFO - training batch 1, loss: 0.017, 32/28000 datapoints
2025-03-07 12:30:11,413 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-07 12:30:11,715 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 12:30:12,026 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-07 12:30:12,314 - INFO - training batch 201, loss: 0.007, 6432/28000 datapoints
2025-03-07 12:30:12,603 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-07 12:30:12,886 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-07 12:30:13,169 - INFO - training batch 351, loss: 0.010, 11232/28000 datapoints
2025-03-07 12:30:13,446 - INFO - training batch 401, loss: 0.010, 12832/28000 datapoints
2025-03-07 12:30:13,730 - INFO - training batch 451, loss: 0.005, 14432/28000 datapoints
2025-03-07 12:30:14,010 - INFO - training batch 501, loss: 0.007, 16032/28000 datapoints
2025-03-07 12:30:14,294 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 12:30:14,609 - INFO - training batch 601, loss: 0.005, 19232/28000 datapoints
2025-03-07 12:30:14,890 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 12:30:15,177 - INFO - training batch 701, loss: 0.006, 22432/28000 datapoints
2025-03-07 12:30:15,460 - INFO - training batch 751, loss: 0.007, 24032/28000 datapoints
2025-03-07 12:30:15,740 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-07 12:30:16,018 - INFO - training batch 851, loss: 0.006, 27232/28000 datapoints
2025-03-07 12:30:16,156 - INFO - validation batch 1, loss: 0.041, 32/6976 datapoints
2025-03-07 12:30:16,232 - INFO - validation batch 51, loss: 1.507, 1632/6976 datapoints
2025-03-07 12:30:16,312 - INFO - validation batch 101, loss: 0.192, 3232/6976 datapoints
2025-03-07 12:30:16,385 - INFO - validation batch 151, loss: 0.478, 4832/6976 datapoints
2025-03-07 12:30:16,467 - INFO - validation batch 201, loss: 0.398, 6432/6976 datapoints
2025-03-07 12:30:16,495 - INFO - Epoch 190/800 done.
2025-03-07 12:30:16,495 - INFO - Final validation performance:
Loss: 0.523, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:30:16,496 - INFO - Beginning epoch 191/800
2025-03-07 12:30:16,504 - INFO - training batch 1, loss: 0.016, 32/28000 datapoints
2025-03-07 12:30:16,809 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-07 12:30:17,097 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 12:30:17,414 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-07 12:30:17,696 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-07 12:30:17,983 - INFO - training batch 251, loss: 0.007, 8032/28000 datapoints
2025-03-07 12:30:18,283 - INFO - training batch 301, loss: 0.009, 9632/28000 datapoints
2025-03-07 12:30:18,595 - INFO - training batch 351, loss: 0.009, 11232/28000 datapoints
2025-03-07 12:30:18,886 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-07 12:30:19,178 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-07 12:30:19,474 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-07 12:30:19,769 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 12:30:20,054 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-07 12:30:20,343 - INFO - training batch 651, loss: 0.002, 20832/28000 datapoints
2025-03-07 12:30:20,624 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-07 12:30:20,901 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-07 12:30:21,194 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-07 12:30:21,580 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-07 12:30:21,726 - INFO - validation batch 1, loss: 0.041, 32/6976 datapoints
2025-03-07 12:30:21,802 - INFO - validation batch 51, loss: 1.528, 1632/6976 datapoints
2025-03-07 12:30:21,915 - INFO - validation batch 101, loss: 0.193, 3232/6976 datapoints
2025-03-07 12:30:22,031 - INFO - validation batch 151, loss: 0.484, 4832/6976 datapoints
2025-03-07 12:30:22,134 - INFO - validation batch 201, loss: 0.402, 6432/6976 datapoints
2025-03-07 12:30:22,163 - INFO - Epoch 191/800 done.
2025-03-07 12:30:22,163 - INFO - Final validation performance:
Loss: 0.530, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:30:22,164 - INFO - Beginning epoch 192/800
2025-03-07 12:30:22,173 - INFO - training batch 1, loss: 0.015, 32/28000 datapoints
2025-03-07 12:30:22,537 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-07 12:30:22,880 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 12:30:23,215 - INFO - training batch 151, loss: 0.003, 4832/28000 datapoints
2025-03-07 12:30:23,549 - INFO - training batch 201, loss: 0.006, 6432/28000 datapoints
2025-03-07 12:30:23,877 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-07 12:30:24,208 - INFO - training batch 301, loss: 0.008, 9632/28000 datapoints
2025-03-07 12:30:24,522 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-07 12:30:24,854 - INFO - training batch 401, loss: 0.009, 12832/28000 datapoints
2025-03-07 12:30:25,155 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-07 12:30:25,447 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-07 12:30:25,736 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 12:30:26,020 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-07 12:30:26,305 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 12:30:26,589 - INFO - training batch 701, loss: 0.005, 22432/28000 datapoints
2025-03-07 12:30:26,870 - INFO - training batch 751, loss: 0.006, 24032/28000 datapoints
2025-03-07 12:30:27,162 - INFO - training batch 801, loss: 0.004, 25632/28000 datapoints
2025-03-07 12:30:27,453 - INFO - training batch 851, loss: 0.005, 27232/28000 datapoints
2025-03-07 12:30:27,597 - INFO - validation batch 1, loss: 0.040, 32/6976 datapoints
2025-03-07 12:30:27,674 - INFO - validation batch 51, loss: 1.548, 1632/6976 datapoints
2025-03-07 12:30:27,753 - INFO - validation batch 101, loss: 0.195, 3232/6976 datapoints
2025-03-07 12:30:27,828 - INFO - validation batch 151, loss: 0.491, 4832/6976 datapoints
2025-03-07 12:30:27,904 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-07 12:30:27,930 - INFO - Epoch 192/800 done.
2025-03-07 12:30:27,930 - INFO - Final validation performance:
Loss: 0.536, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:30:27,931 - INFO - Beginning epoch 193/800
2025-03-07 12:30:27,939 - INFO - training batch 1, loss: 0.014, 32/28000 datapoints
2025-03-07 12:30:28,240 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-07 12:30:28,545 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 12:30:28,823 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 12:30:29,105 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-07 12:30:29,392 - INFO - training batch 251, loss: 0.006, 8032/28000 datapoints
2025-03-07 12:30:29,677 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 12:30:29,958 - INFO - training batch 351, loss: 0.008, 11232/28000 datapoints
2025-03-07 12:30:30,242 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-07 12:30:30,550 - INFO - training batch 451, loss: 0.004, 14432/28000 datapoints
2025-03-07 12:30:30,833 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-07 12:30:31,118 - INFO - training batch 551, loss: 0.004, 17632/28000 datapoints
2025-03-07 12:30:31,420 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-07 12:30:31,732 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 12:30:32,024 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 12:30:32,510 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-07 12:30:32,955 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-07 12:30:33,309 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-07 12:30:33,502 - INFO - validation batch 1, loss: 0.040, 32/6976 datapoints
2025-03-07 12:30:33,620 - INFO - validation batch 51, loss: 1.571, 1632/6976 datapoints
2025-03-07 12:30:33,727 - INFO - validation batch 101, loss: 0.197, 3232/6976 datapoints
2025-03-07 12:30:33,867 - INFO - validation batch 151, loss: 0.499, 4832/6976 datapoints
2025-03-07 12:30:33,993 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-07 12:30:34,030 - INFO - Epoch 193/800 done.
2025-03-07 12:30:34,031 - INFO - Final validation performance:
Loss: 0.544, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:30:34,031 - INFO - Beginning epoch 194/800
2025-03-07 12:30:34,043 - INFO - training batch 1, loss: 0.013, 32/28000 datapoints
2025-03-07 12:30:34,398 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-07 12:30:34,723 - INFO - training batch 101, loss: 0.003, 3232/28000 datapoints
2025-03-07 12:30:35,202 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 12:30:35,500 - INFO - training batch 201, loss: 0.005, 6432/28000 datapoints
2025-03-07 12:30:35,795 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-07 12:30:36,085 - INFO - training batch 301, loss: 0.007, 9632/28000 datapoints
2025-03-07 12:30:36,380 - INFO - training batch 351, loss: 0.007, 11232/28000 datapoints
2025-03-07 12:30:36,678 - INFO - training batch 401, loss: 0.008, 12832/28000 datapoints
2025-03-07 12:30:36,971 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-07 12:30:37,263 - INFO - training batch 501, loss: 0.005, 16032/28000 datapoints
2025-03-07 12:30:37,591 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 12:30:37,946 - INFO - training batch 601, loss: 0.004, 19232/28000 datapoints
2025-03-07 12:30:38,264 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 12:30:38,575 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 12:30:38,882 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-07 12:30:39,167 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-07 12:30:39,493 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-07 12:30:39,653 - INFO - validation batch 1, loss: 0.041, 32/6976 datapoints
2025-03-07 12:30:39,730 - INFO - validation batch 51, loss: 1.593, 1632/6976 datapoints
2025-03-07 12:30:39,805 - INFO - validation batch 101, loss: 0.200, 3232/6976 datapoints
2025-03-07 12:30:39,879 - INFO - validation batch 151, loss: 0.505, 4832/6976 datapoints
2025-03-07 12:30:39,952 - INFO - validation batch 201, loss: 0.419, 6432/6976 datapoints
2025-03-07 12:30:39,977 - INFO - Epoch 194/800 done.
2025-03-07 12:30:39,978 - INFO - Final validation performance:
Loss: 0.552, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:30:39,978 - INFO - Beginning epoch 195/800
2025-03-07 12:30:39,987 - INFO - training batch 1, loss: 0.012, 32/28000 datapoints
2025-03-07 12:30:40,276 - INFO - training batch 51, loss: 0.006, 1632/28000 datapoints
2025-03-07 12:30:40,582 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 12:30:40,911 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 12:30:41,219 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-07 12:30:41,518 - INFO - training batch 251, loss: 0.005, 8032/28000 datapoints
2025-03-07 12:30:41,891 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 12:30:42,269 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-07 12:30:42,579 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-07 12:30:42,870 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-07 12:30:43,192 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-07 12:30:43,485 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 12:30:43,772 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-07 12:30:44,066 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 12:30:44,364 - INFO - training batch 701, loss: 0.004, 22432/28000 datapoints
2025-03-07 12:30:44,666 - INFO - training batch 751, loss: 0.005, 24032/28000 datapoints
2025-03-07 12:30:44,976 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-07 12:30:45,259 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-07 12:30:45,399 - INFO - validation batch 1, loss: 0.041, 32/6976 datapoints
2025-03-07 12:30:45,474 - INFO - validation batch 51, loss: 1.615, 1632/6976 datapoints
2025-03-07 12:30:45,547 - INFO - validation batch 101, loss: 0.201, 3232/6976 datapoints
2025-03-07 12:30:45,620 - INFO - validation batch 151, loss: 0.513, 4832/6976 datapoints
2025-03-07 12:30:45,693 - INFO - validation batch 201, loss: 0.421, 6432/6976 datapoints
2025-03-07 12:30:45,717 - INFO - Epoch 195/800 done.
2025-03-07 12:30:45,717 - INFO - Final validation performance:
Loss: 0.558, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:30:45,718 - INFO - Beginning epoch 196/800
2025-03-07 12:30:45,727 - INFO - training batch 1, loss: 0.011, 32/28000 datapoints
2025-03-07 12:30:46,009 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-07 12:30:46,296 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 12:30:46,576 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 12:30:46,852 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-07 12:30:47,133 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-07 12:30:47,438 - INFO - training batch 301, loss: 0.006, 9632/28000 datapoints
2025-03-07 12:30:47,735 - INFO - training batch 351, loss: 0.006, 11232/28000 datapoints
2025-03-07 12:30:48,023 - INFO - training batch 401, loss: 0.007, 12832/28000 datapoints
2025-03-07 12:30:48,311 - INFO - training batch 451, loss: 0.003, 14432/28000 datapoints
2025-03-07 12:30:48,591 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-07 12:30:48,924 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 12:30:49,217 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-07 12:30:49,510 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 12:30:49,835 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 12:30:50,119 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 12:30:50,403 - INFO - training batch 801, loss: 0.003, 25632/28000 datapoints
2025-03-07 12:30:50,701 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 12:30:50,845 - INFO - validation batch 1, loss: 0.041, 32/6976 datapoints
2025-03-07 12:30:50,922 - INFO - validation batch 51, loss: 1.636, 1632/6976 datapoints
2025-03-07 12:30:50,997 - INFO - validation batch 101, loss: 0.204, 3232/6976 datapoints
2025-03-07 12:30:51,074 - INFO - validation batch 151, loss: 0.522, 4832/6976 datapoints
2025-03-07 12:30:51,152 - INFO - validation batch 201, loss: 0.429, 6432/6976 datapoints
2025-03-07 12:30:51,178 - INFO - Epoch 196/800 done.
2025-03-07 12:30:51,178 - INFO - Final validation performance:
Loss: 0.566, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:30:51,179 - INFO - Beginning epoch 197/800
2025-03-07 12:30:51,188 - INFO - training batch 1, loss: 0.010, 32/28000 datapoints
2025-03-07 12:30:51,499 - INFO - training batch 51, loss: 0.005, 1632/28000 datapoints
2025-03-07 12:30:51,826 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 12:30:52,162 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 12:30:52,525 - INFO - training batch 201, loss: 0.004, 6432/28000 datapoints
2025-03-07 12:30:52,875 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-07 12:30:53,237 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-07 12:30:53,567 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-07 12:30:53,904 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-07 12:30:54,227 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 12:30:54,529 - INFO - training batch 501, loss: 0.004, 16032/28000 datapoints
2025-03-07 12:30:54,828 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 12:30:55,151 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-07 12:30:55,452 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 12:30:55,745 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 12:30:56,029 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 12:30:56,316 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 12:30:56,602 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 12:30:56,741 - INFO - validation batch 1, loss: 0.041, 32/6976 datapoints
2025-03-07 12:30:56,813 - INFO - validation batch 51, loss: 1.659, 1632/6976 datapoints
2025-03-07 12:30:56,888 - INFO - validation batch 101, loss: 0.205, 3232/6976 datapoints
2025-03-07 12:30:56,959 - INFO - validation batch 151, loss: 0.528, 4832/6976 datapoints
2025-03-07 12:30:57,029 - INFO - validation batch 201, loss: 0.432, 6432/6976 datapoints
2025-03-07 12:30:57,054 - INFO - Epoch 197/800 done.
2025-03-07 12:30:57,054 - INFO - Final validation performance:
Loss: 0.573, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:30:57,055 - INFO - Beginning epoch 198/800
2025-03-07 12:30:57,063 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-07 12:30:57,346 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-07 12:30:57,630 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 12:30:57,913 - INFO - training batch 151, loss: 0.002, 4832/28000 datapoints
2025-03-07 12:30:58,207 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-07 12:30:58,491 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-07 12:30:58,769 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-07 12:30:59,046 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-07 12:30:59,331 - INFO - training batch 401, loss: 0.006, 12832/28000 datapoints
2025-03-07 12:30:59,620 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 12:30:59,908 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-07 12:31:00,193 - INFO - training batch 551, loss: 0.003, 17632/28000 datapoints
2025-03-07 12:31:00,491 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 12:31:00,787 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 12:31:01,062 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 12:31:01,343 - INFO - training batch 751, loss: 0.004, 24032/28000 datapoints
2025-03-07 12:31:01,658 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 12:31:02,013 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 12:31:02,201 - INFO - validation batch 1, loss: 0.041, 32/6976 datapoints
2025-03-07 12:31:02,308 - INFO - validation batch 51, loss: 1.681, 1632/6976 datapoints
2025-03-07 12:31:02,432 - INFO - validation batch 101, loss: 0.206, 3232/6976 datapoints
2025-03-07 12:31:02,569 - INFO - validation batch 151, loss: 0.535, 4832/6976 datapoints
2025-03-07 12:31:02,656 - INFO - validation batch 201, loss: 0.436, 6432/6976 datapoints
2025-03-07 12:31:02,684 - INFO - Epoch 198/800 done.
2025-03-07 12:31:02,685 - INFO - Final validation performance:
Loss: 0.580, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:31:02,685 - INFO - Beginning epoch 199/800
2025-03-07 12:31:02,694 - INFO - training batch 1, loss: 0.009, 32/28000 datapoints
2025-03-07 12:31:02,986 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-07 12:31:03,289 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 12:31:03,661 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 12:31:03,977 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-07 12:31:04,267 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 12:31:04,566 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-07 12:31:04,857 - INFO - training batch 351, loss: 0.005, 11232/28000 datapoints
2025-03-07 12:31:05,173 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-07 12:31:05,461 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 12:31:05,759 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-07 12:31:06,059 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 12:31:06,339 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 12:31:06,622 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 12:31:06,906 - INFO - training batch 701, loss: 0.003, 22432/28000 datapoints
2025-03-07 12:31:07,187 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 12:31:07,470 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 12:31:07,753 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 12:31:07,892 - INFO - validation batch 1, loss: 0.040, 32/6976 datapoints
2025-03-07 12:31:07,962 - INFO - validation batch 51, loss: 1.705, 1632/6976 datapoints
2025-03-07 12:31:08,037 - INFO - validation batch 101, loss: 0.210, 3232/6976 datapoints
2025-03-07 12:31:08,109 - INFO - validation batch 151, loss: 0.540, 4832/6976 datapoints
2025-03-07 12:31:08,183 - INFO - validation batch 201, loss: 0.440, 6432/6976 datapoints
2025-03-07 12:31:08,210 - INFO - Epoch 199/800 done.
2025-03-07 12:31:08,210 - INFO - Final validation performance:
Loss: 0.587, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:31:08,211 - INFO - Beginning epoch 200/800
2025-03-07 12:31:08,219 - INFO - training batch 1, loss: 0.008, 32/28000 datapoints
2025-03-07 12:31:08,514 - INFO - training batch 51, loss: 0.004, 1632/28000 datapoints
2025-03-07 12:31:08,836 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 12:31:09,128 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 12:31:09,408 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-07 12:31:09,700 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 12:31:09,987 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 12:31:10,272 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-07 12:31:10,561 - INFO - training batch 401, loss: 0.005, 12832/28000 datapoints
2025-03-07 12:31:10,844 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 12:31:11,124 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-07 12:31:11,410 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 12:31:11,700 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 12:31:11,988 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 12:31:12,315 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 12:31:12,598 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 12:31:12,883 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 12:31:13,167 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 12:31:13,309 - INFO - validation batch 1, loss: 0.039, 32/6976 datapoints
2025-03-07 12:31:13,387 - INFO - validation batch 51, loss: 1.728, 1632/6976 datapoints
2025-03-07 12:31:13,468 - INFO - validation batch 101, loss: 0.214, 3232/6976 datapoints
2025-03-07 12:31:13,548 - INFO - validation batch 151, loss: 0.550, 4832/6976 datapoints
2025-03-07 12:31:13,623 - INFO - validation batch 201, loss: 0.445, 6432/6976 datapoints
2025-03-07 12:31:13,652 - INFO - Epoch 200/800 done.
2025-03-07 12:31:13,652 - INFO - Final validation performance:
Loss: 0.595, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:31:13,653 - INFO - Beginning epoch 201/800
2025-03-07 12:31:13,661 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-07 12:31:13,952 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-07 12:31:14,240 - INFO - training batch 101, loss: 0.002, 3232/28000 datapoints
2025-03-07 12:31:14,537 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 12:31:14,854 - INFO - training batch 201, loss: 0.003, 6432/28000 datapoints
2025-03-07 12:31:15,168 - INFO - training batch 251, loss: 0.003, 8032/28000 datapoints
2025-03-07 12:31:15,468 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 12:31:15,750 - INFO - training batch 351, loss: 0.004, 11232/28000 datapoints
2025-03-07 12:31:16,031 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-07 12:31:16,312 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 12:31:16,600 - INFO - training batch 501, loss: 0.003, 16032/28000 datapoints
2025-03-07 12:31:16,881 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 12:31:17,161 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 12:31:17,451 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 12:31:17,741 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 12:31:18,024 - INFO - training batch 751, loss: 0.003, 24032/28000 datapoints
2025-03-07 12:31:18,302 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 12:31:18,584 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 12:31:18,724 - INFO - validation batch 1, loss: 0.040, 32/6976 datapoints
2025-03-07 12:31:18,798 - INFO - validation batch 51, loss: 1.751, 1632/6976 datapoints
2025-03-07 12:31:18,874 - INFO - validation batch 101, loss: 0.216, 3232/6976 datapoints
2025-03-07 12:31:18,947 - INFO - validation batch 151, loss: 0.558, 4832/6976 datapoints
2025-03-07 12:31:19,021 - INFO - validation batch 201, loss: 0.452, 6432/6976 datapoints
2025-03-07 12:31:19,048 - INFO - Epoch 201/800 done.
2025-03-07 12:31:19,049 - INFO - Final validation performance:
Loss: 0.603, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 12:31:19,049 - INFO - Beginning epoch 202/800
2025-03-07 12:31:19,057 - INFO - training batch 1, loss: 0.007, 32/28000 datapoints
2025-03-07 12:31:19,386 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-07 12:31:19,734 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 12:31:20,068 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 12:31:20,388 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 12:31:20,698 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 12:31:20,987 - INFO - training batch 301, loss: 0.004, 9632/28000 datapoints
2025-03-07 12:31:21,304 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 12:31:21,605 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-07 12:31:21,892 - INFO - training batch 451, loss: 0.002, 14432/28000 datapoints
2025-03-07 12:31:22,184 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 12:31:22,523 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 12:31:22,939 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 12:31:23,291 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 12:31:23,629 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 12:31:23,972 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 12:31:24,307 - INFO - training batch 801, loss: 0.002, 25632/28000 datapoints
2025-03-07 12:31:24,639 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 12:31:24,796 - INFO - validation batch 1, loss: 0.039, 32/6976 datapoints
2025-03-07 12:31:24,886 - INFO - validation batch 51, loss: 1.775, 1632/6976 datapoints
2025-03-07 12:31:24,971 - INFO - validation batch 101, loss: 0.221, 3232/6976 datapoints
2025-03-07 12:31:25,051 - INFO - validation batch 151, loss: 0.566, 4832/6976 datapoints
2025-03-07 12:31:25,135 - INFO - validation batch 201, loss: 0.460, 6432/6976 datapoints
2025-03-07 12:31:25,165 - INFO - Epoch 202/800 done.
2025-03-07 12:31:25,165 - INFO - Final validation performance:
Loss: 0.612, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:31:25,166 - INFO - Beginning epoch 203/800
2025-03-07 12:31:25,174 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-07 12:31:25,552 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-07 12:31:25,883 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 12:31:26,171 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 12:31:26,470 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 12:31:26,760 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 12:31:27,051 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 12:31:27,350 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 12:31:27,650 - INFO - training batch 401, loss: 0.004, 12832/28000 datapoints
2025-03-07 12:31:27,952 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 12:31:28,237 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 12:31:28,522 - INFO - training batch 551, loss: 0.002, 17632/28000 datapoints
2025-03-07 12:31:28,802 - INFO - training batch 601, loss: 0.002, 19232/28000 datapoints
2025-03-07 12:31:29,085 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 12:31:29,369 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 12:31:29,663 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 12:31:29,975 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 12:31:30,268 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 12:31:30,410 - INFO - validation batch 1, loss: 0.039, 32/6976 datapoints
2025-03-07 12:31:30,526 - INFO - validation batch 51, loss: 1.798, 1632/6976 datapoints
2025-03-07 12:31:30,602 - INFO - validation batch 101, loss: 0.224, 3232/6976 datapoints
2025-03-07 12:31:30,673 - INFO - validation batch 151, loss: 0.573, 4832/6976 datapoints
2025-03-07 12:31:30,753 - INFO - validation batch 201, loss: 0.465, 6432/6976 datapoints
2025-03-07 12:31:30,779 - INFO - Epoch 203/800 done.
2025-03-07 12:31:30,779 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:31:30,780 - INFO - Beginning epoch 204/800
2025-03-07 12:31:30,789 - INFO - training batch 1, loss: 0.006, 32/28000 datapoints
2025-03-07 12:31:31,072 - INFO - training batch 51, loss: 0.003, 1632/28000 datapoints
2025-03-07 12:31:31,356 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 12:31:31,643 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 12:31:31,922 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 12:31:32,195 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 12:31:32,476 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 12:31:32,818 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 12:31:33,097 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 12:31:33,380 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 12:31:33,664 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 12:31:33,942 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 12:31:34,244 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 12:31:34,538 - INFO - training batch 651, loss: 0.001, 20832/28000 datapoints
2025-03-07 12:31:34,827 - INFO - training batch 701, loss: 0.002, 22432/28000 datapoints
2025-03-07 12:31:35,111 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 12:31:35,421 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 12:31:35,711 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 12:31:35,854 - INFO - validation batch 1, loss: 0.039, 32/6976 datapoints
2025-03-07 12:31:35,929 - INFO - validation batch 51, loss: 1.821, 1632/6976 datapoints
2025-03-07 12:31:36,008 - INFO - validation batch 101, loss: 0.230, 3232/6976 datapoints
2025-03-07 12:31:36,091 - INFO - validation batch 151, loss: 0.580, 4832/6976 datapoints
2025-03-07 12:31:36,164 - INFO - validation batch 201, loss: 0.471, 6432/6976 datapoints
2025-03-07 12:31:36,194 - INFO - Epoch 204/800 done.
2025-03-07 12:31:36,194 - INFO - Final validation performance:
Loss: 0.628, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:31:36,195 - INFO - Beginning epoch 205/800
2025-03-07 12:31:36,202 - INFO - training batch 1, loss: 0.005, 32/28000 datapoints
2025-03-07 12:31:36,489 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-07 12:31:36,769 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 12:31:37,049 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 12:31:37,334 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 12:31:37,618 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 12:31:37,908 - INFO - training batch 301, loss: 0.003, 9632/28000 datapoints
2025-03-07 12:31:38,191 - INFO - training batch 351, loss: 0.003, 11232/28000 datapoints
2025-03-07 12:31:38,477 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 12:31:38,780 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 12:31:39,061 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 12:31:39,345 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 12:31:39,631 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 12:31:39,913 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:31:40,197 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 12:31:40,485 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 12:31:40,768 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 12:31:41,051 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 12:31:41,192 - INFO - validation batch 1, loss: 0.038, 32/6976 datapoints
2025-03-07 12:31:41,266 - INFO - validation batch 51, loss: 1.847, 1632/6976 datapoints
2025-03-07 12:31:41,343 - INFO - validation batch 101, loss: 0.229, 3232/6976 datapoints
2025-03-07 12:31:41,416 - INFO - validation batch 151, loss: 0.590, 4832/6976 datapoints
2025-03-07 12:31:41,493 - INFO - validation batch 201, loss: 0.475, 6432/6976 datapoints
2025-03-07 12:31:41,517 - INFO - Epoch 205/800 done.
2025-03-07 12:31:41,517 - INFO - Final validation performance:
Loss: 0.636, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:31:41,518 - INFO - Beginning epoch 206/800
2025-03-07 12:31:41,526 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 12:31:41,819 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-07 12:31:42,098 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 12:31:42,378 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 12:31:43,390 - INFO - training batch 201, loss: 0.002, 6432/28000 datapoints
2025-03-07 12:31:43,902 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 12:31:44,434 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 12:31:44,875 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 12:31:45,332 - INFO - training batch 401, loss: 0.003, 12832/28000 datapoints
2025-03-07 12:31:45,818 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 12:31:46,248 - INFO - training batch 501, loss: 0.002, 16032/28000 datapoints
2025-03-07 12:31:46,688 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 12:31:47,156 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 12:31:47,499 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:31:47,899 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 12:31:48,396 - INFO - training batch 751, loss: 0.002, 24032/28000 datapoints
2025-03-07 12:31:48,833 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 12:31:49,192 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 12:31:49,382 - INFO - validation batch 1, loss: 0.038, 32/6976 datapoints
2025-03-07 12:31:49,518 - INFO - validation batch 51, loss: 1.872, 1632/6976 datapoints
2025-03-07 12:31:49,649 - INFO - validation batch 101, loss: 0.235, 3232/6976 datapoints
2025-03-07 12:31:49,775 - INFO - validation batch 151, loss: 0.596, 4832/6976 datapoints
2025-03-07 12:31:49,876 - INFO - validation batch 201, loss: 0.482, 6432/6976 datapoints
2025-03-07 12:31:49,914 - INFO - Epoch 206/800 done.
2025-03-07 12:31:49,914 - INFO - Final validation performance:
Loss: 0.645, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:31:49,915 - INFO - Beginning epoch 207/800
2025-03-07 12:31:49,937 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 12:31:50,260 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-07 12:31:50,635 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 12:31:51,010 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 12:31:51,325 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 12:31:51,653 - INFO - training batch 251, loss: 0.002, 8032/28000 datapoints
2025-03-07 12:31:51,966 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 12:31:52,286 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 12:31:52,611 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 12:31:52,994 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 12:31:53,386 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 12:31:53,740 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 12:31:54,033 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 12:31:54,351 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:31:54,703 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 12:31:55,088 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 12:31:55,432 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 12:31:55,817 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 12:31:55,993 - INFO - validation batch 1, loss: 0.037, 32/6976 datapoints
2025-03-07 12:31:56,081 - INFO - validation batch 51, loss: 1.896, 1632/6976 datapoints
2025-03-07 12:31:56,173 - INFO - validation batch 101, loss: 0.238, 3232/6976 datapoints
2025-03-07 12:31:56,260 - INFO - validation batch 151, loss: 0.608, 4832/6976 datapoints
2025-03-07 12:31:56,351 - INFO - validation batch 201, loss: 0.489, 6432/6976 datapoints
2025-03-07 12:31:56,379 - INFO - Epoch 207/800 done.
2025-03-07 12:31:56,380 - INFO - Final validation performance:
Loss: 0.654, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:31:56,380 - INFO - Beginning epoch 208/800
2025-03-07 12:31:56,391 - INFO - training batch 1, loss: 0.004, 32/28000 datapoints
2025-03-07 12:31:56,722 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-07 12:31:57,024 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 12:31:57,364 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 12:31:57,700 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 12:31:58,039 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 12:31:58,334 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 12:31:58,642 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 12:31:58,929 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 12:31:59,212 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 12:31:59,500 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 12:31:59,787 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 12:32:00,077 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 12:32:00,356 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:32:00,658 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 12:32:00,940 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 12:32:01,224 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 12:32:01,524 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 12:32:01,669 - INFO - validation batch 1, loss: 0.037, 32/6976 datapoints
2025-03-07 12:32:01,744 - INFO - validation batch 51, loss: 1.924, 1632/6976 datapoints
2025-03-07 12:32:01,819 - INFO - validation batch 101, loss: 0.241, 3232/6976 datapoints
2025-03-07 12:32:01,906 - INFO - validation batch 151, loss: 0.616, 4832/6976 datapoints
2025-03-07 12:32:01,998 - INFO - validation batch 201, loss: 0.495, 6432/6976 datapoints
2025-03-07 12:32:02,029 - INFO - Epoch 208/800 done.
2025-03-07 12:32:02,029 - INFO - Final validation performance:
Loss: 0.663, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:32:02,030 - INFO - Beginning epoch 209/800
2025-03-07 12:32:02,039 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 12:32:02,328 - INFO - training batch 51, loss: 0.002, 1632/28000 datapoints
2025-03-07 12:32:02,618 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 12:32:02,902 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 12:32:03,204 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 12:32:03,535 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 12:32:03,955 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 12:32:04,308 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 12:32:04,750 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 12:32:05,082 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 12:32:05,376 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 12:32:05,679 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 12:32:06,008 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 12:32:06,319 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:32:06,694 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 12:32:06,985 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 12:32:07,269 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 12:32:07,558 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 12:32:07,703 - INFO - validation batch 1, loss: 0.037, 32/6976 datapoints
2025-03-07 12:32:07,778 - INFO - validation batch 51, loss: 1.954, 1632/6976 datapoints
2025-03-07 12:32:07,851 - INFO - validation batch 101, loss: 0.247, 3232/6976 datapoints
2025-03-07 12:32:07,927 - INFO - validation batch 151, loss: 0.624, 4832/6976 datapoints
2025-03-07 12:32:08,003 - INFO - validation batch 201, loss: 0.503, 6432/6976 datapoints
2025-03-07 12:32:08,030 - INFO - Epoch 209/800 done.
2025-03-07 12:32:08,030 - INFO - Final validation performance:
Loss: 0.673, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:32:08,031 - INFO - Beginning epoch 210/800
2025-03-07 12:32:08,039 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 12:32:08,326 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 12:32:08,606 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 12:32:08,886 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:32:09,164 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 12:32:09,448 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 12:32:09,733 - INFO - training batch 301, loss: 0.002, 9632/28000 datapoints
2025-03-07 12:32:10,015 - INFO - training batch 351, loss: 0.002, 11232/28000 datapoints
2025-03-07 12:32:10,293 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 12:32:10,589 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 12:32:10,902 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 12:32:11,177 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 12:32:11,459 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 12:32:11,735 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:32:12,015 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 12:32:12,296 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 12:32:12,581 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 12:32:12,862 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 12:32:12,996 - INFO - validation batch 1, loss: 0.037, 32/6976 datapoints
2025-03-07 12:32:13,067 - INFO - validation batch 51, loss: 1.980, 1632/6976 datapoints
2025-03-07 12:32:13,136 - INFO - validation batch 101, loss: 0.252, 3232/6976 datapoints
2025-03-07 12:32:13,205 - INFO - validation batch 151, loss: 0.636, 4832/6976 datapoints
2025-03-07 12:32:13,272 - INFO - validation batch 201, loss: 0.509, 6432/6976 datapoints
2025-03-07 12:32:13,299 - INFO - Epoch 210/800 done.
2025-03-07 12:32:13,299 - INFO - Final validation performance:
Loss: 0.683, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:32:13,300 - INFO - Beginning epoch 211/800
2025-03-07 12:32:13,307 - INFO - training batch 1, loss: 0.003, 32/28000 datapoints
2025-03-07 12:32:13,607 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 12:32:13,937 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 12:32:14,229 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:32:14,522 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 12:32:14,812 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 12:32:15,136 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 12:32:15,427 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 12:32:15,717 - INFO - training batch 401, loss: 0.002, 12832/28000 datapoints
2025-03-07 12:32:16,035 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 12:32:16,324 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 12:32:16,614 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 12:32:16,896 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 12:32:17,178 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:32:17,467 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 12:32:17,757 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 12:32:18,044 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 12:32:18,330 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 12:32:18,474 - INFO - validation batch 1, loss: 0.035, 32/6976 datapoints
2025-03-07 12:32:18,547 - INFO - validation batch 51, loss: 2.004, 1632/6976 datapoints
2025-03-07 12:32:18,620 - INFO - validation batch 101, loss: 0.253, 3232/6976 datapoints
2025-03-07 12:32:18,693 - INFO - validation batch 151, loss: 0.644, 4832/6976 datapoints
2025-03-07 12:32:18,767 - INFO - validation batch 201, loss: 0.515, 6432/6976 datapoints
2025-03-07 12:32:18,797 - INFO - Epoch 211/800 done.
2025-03-07 12:32:18,797 - INFO - Final validation performance:
Loss: 0.690, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:32:18,797 - INFO - Beginning epoch 212/800
2025-03-07 12:32:18,805 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 12:32:19,095 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 12:32:19,406 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 12:32:19,692 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:32:19,974 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 12:32:20,265 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 12:32:20,548 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 12:32:20,825 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 12:32:21,110 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 12:32:21,397 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 12:32:21,696 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 12:32:21,999 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 12:32:22,295 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 12:32:22,600 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:32:22,887 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 12:32:23,176 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 12:32:23,463 - INFO - training batch 801, loss: 0.001, 25632/28000 datapoints
2025-03-07 12:32:23,743 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 12:32:23,908 - INFO - validation batch 1, loss: 0.035, 32/6976 datapoints
2025-03-07 12:32:24,004 - INFO - validation batch 51, loss: 2.035, 1632/6976 datapoints
2025-03-07 12:32:24,125 - INFO - validation batch 101, loss: 0.259, 3232/6976 datapoints
2025-03-07 12:32:24,241 - INFO - validation batch 151, loss: 0.653, 4832/6976 datapoints
2025-03-07 12:32:24,352 - INFO - validation batch 201, loss: 0.524, 6432/6976 datapoints
2025-03-07 12:32:24,387 - INFO - Epoch 212/800 done.
2025-03-07 12:32:24,388 - INFO - Final validation performance:
Loss: 0.701, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:32:24,389 - INFO - Beginning epoch 213/800
2025-03-07 12:32:24,398 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 12:32:24,789 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 12:32:25,129 - INFO - training batch 101, loss: 0.001, 3232/28000 datapoints
2025-03-07 12:32:25,490 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:32:25,839 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 12:32:26,244 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 12:32:26,596 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 12:32:26,911 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 12:32:27,217 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 12:32:27,515 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 12:32:27,815 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 12:32:28,098 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 12:32:28,380 - INFO - training batch 601, loss: 0.001, 19232/28000 datapoints
2025-03-07 12:32:28,711 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:32:29,063 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 12:32:29,353 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 12:32:29,655 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:32:29,947 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 12:32:30,083 - INFO - validation batch 1, loss: 0.035, 32/6976 datapoints
2025-03-07 12:32:30,160 - INFO - validation batch 51, loss: 2.063, 1632/6976 datapoints
2025-03-07 12:32:30,233 - INFO - validation batch 101, loss: 0.264, 3232/6976 datapoints
2025-03-07 12:32:30,305 - INFO - validation batch 151, loss: 0.665, 4832/6976 datapoints
2025-03-07 12:32:30,380 - INFO - validation batch 201, loss: 0.532, 6432/6976 datapoints
2025-03-07 12:32:30,408 - INFO - Epoch 213/800 done.
2025-03-07 12:32:30,409 - INFO - Final validation performance:
Loss: 0.712, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:32:30,410 - INFO - Beginning epoch 214/800
2025-03-07 12:32:30,417 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 12:32:30,761 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 12:32:31,040 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:32:31,320 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:32:31,617 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 12:32:31,916 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 12:32:32,200 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 12:32:32,494 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 12:32:32,782 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 12:32:33,073 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:32:33,366 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 12:32:33,660 - INFO - training batch 551, loss: 0.001, 17632/28000 datapoints
2025-03-07 12:32:34,009 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:32:34,444 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:32:34,861 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 12:32:35,246 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 12:32:35,627 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:32:35,997 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 12:32:36,200 - INFO - validation batch 1, loss: 0.034, 32/6976 datapoints
2025-03-07 12:32:36,289 - INFO - validation batch 51, loss: 2.092, 1632/6976 datapoints
2025-03-07 12:32:36,376 - INFO - validation batch 101, loss: 0.268, 3232/6976 datapoints
2025-03-07 12:32:36,463 - INFO - validation batch 151, loss: 0.674, 4832/6976 datapoints
2025-03-07 12:32:36,576 - INFO - validation batch 201, loss: 0.539, 6432/6976 datapoints
2025-03-07 12:32:36,639 - INFO - Epoch 214/800 done.
2025-03-07 12:32:36,639 - INFO - Final validation performance:
Loss: 0.721, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:32:36,640 - INFO - Beginning epoch 215/800
2025-03-07 12:32:36,651 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 12:32:37,263 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 12:32:37,649 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:32:38,070 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:32:38,465 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 12:32:38,837 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 12:32:39,238 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 12:32:39,772 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 12:32:40,220 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 12:32:40,967 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:32:41,387 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 12:32:41,825 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:32:42,205 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:32:42,565 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:32:42,909 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:32:43,268 - INFO - training batch 751, loss: 0.001, 24032/28000 datapoints
2025-03-07 12:32:43,599 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:32:43,910 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 12:32:44,074 - INFO - validation batch 1, loss: 0.034, 32/6976 datapoints
2025-03-07 12:32:44,159 - INFO - validation batch 51, loss: 2.119, 1632/6976 datapoints
2025-03-07 12:32:44,247 - INFO - validation batch 101, loss: 0.274, 3232/6976 datapoints
2025-03-07 12:32:44,336 - INFO - validation batch 151, loss: 0.687, 4832/6976 datapoints
2025-03-07 12:32:44,423 - INFO - validation batch 201, loss: 0.547, 6432/6976 datapoints
2025-03-07 12:32:44,458 - INFO - Epoch 215/800 done.
2025-03-07 12:32:44,458 - INFO - Final validation performance:
Loss: 0.732, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:32:44,458 - INFO - Beginning epoch 216/800
2025-03-07 12:32:44,474 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 12:32:44,794 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 12:32:45,102 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:32:45,407 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:32:45,714 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 12:32:46,020 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 12:32:46,332 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 12:32:46,625 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 12:32:46,906 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 12:32:47,192 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:32:47,505 - INFO - training batch 501, loss: 0.001, 16032/28000 datapoints
2025-03-07 12:32:47,788 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:32:48,064 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:32:48,346 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:32:48,640 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:32:48,963 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:32:49,310 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:32:49,625 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:32:49,765 - INFO - validation batch 1, loss: 0.033, 32/6976 datapoints
2025-03-07 12:32:49,839 - INFO - validation batch 51, loss: 2.148, 1632/6976 datapoints
2025-03-07 12:32:49,922 - INFO - validation batch 101, loss: 0.277, 3232/6976 datapoints
2025-03-07 12:32:49,998 - INFO - validation batch 151, loss: 0.695, 4832/6976 datapoints
2025-03-07 12:32:50,071 - INFO - validation batch 201, loss: 0.555, 6432/6976 datapoints
2025-03-07 12:32:50,096 - INFO - Epoch 216/800 done.
2025-03-07 12:32:50,096 - INFO - Final validation performance:
Loss: 0.742, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:32:50,097 - INFO - Beginning epoch 217/800
2025-03-07 12:32:50,105 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 12:32:50,399 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 12:32:51,091 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:32:51,374 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:32:51,688 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:32:51,982 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:32:52,267 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 12:32:52,562 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 12:32:52,848 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 12:32:53,130 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:32:53,441 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:32:53,796 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:32:54,153 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:32:54,441 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:32:54,723 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:32:55,002 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:32:55,279 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:32:55,570 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:32:55,711 - INFO - validation batch 1, loss: 0.033, 32/6976 datapoints
2025-03-07 12:32:55,785 - INFO - validation batch 51, loss: 2.179, 1632/6976 datapoints
2025-03-07 12:32:55,881 - INFO - validation batch 101, loss: 0.281, 3232/6976 datapoints
2025-03-07 12:32:55,988 - INFO - validation batch 151, loss: 0.707, 4832/6976 datapoints
2025-03-07 12:32:56,076 - INFO - validation batch 201, loss: 0.563, 6432/6976 datapoints
2025-03-07 12:32:56,101 - INFO - Epoch 217/800 done.
2025-03-07 12:32:56,101 - INFO - Final validation performance:
Loss: 0.753, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:32:56,101 - INFO - Beginning epoch 218/800
2025-03-07 12:32:56,110 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 12:32:56,436 - INFO - training batch 51, loss: 0.001, 1632/28000 datapoints
2025-03-07 12:32:56,724 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:32:57,009 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:32:57,294 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:32:57,584 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:32:57,875 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 12:32:58,206 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 12:32:58,500 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 12:32:58,794 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:32:59,069 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:32:59,357 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:32:59,659 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:32:59,950 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:33:00,241 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:33:00,537 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:33:00,832 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:33:01,127 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:33:01,272 - INFO - validation batch 1, loss: 0.031, 32/6976 datapoints
2025-03-07 12:33:01,347 - INFO - validation batch 51, loss: 2.211, 1632/6976 datapoints
2025-03-07 12:33:01,438 - INFO - validation batch 101, loss: 0.286, 3232/6976 datapoints
2025-03-07 12:33:01,529 - INFO - validation batch 151, loss: 0.718, 4832/6976 datapoints
2025-03-07 12:33:01,609 - INFO - validation batch 201, loss: 0.565, 6432/6976 datapoints
2025-03-07 12:33:01,639 - INFO - Epoch 218/800 done.
2025-03-07 12:33:01,639 - INFO - Final validation performance:
Loss: 0.762, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:33:01,640 - INFO - Beginning epoch 219/800
2025-03-07 12:33:01,649 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 12:33:01,976 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:33:02,296 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:33:02,612 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:33:02,927 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:33:03,239 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:33:03,590 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 12:33:03,896 - INFO - training batch 351, loss: 0.001, 11232/28000 datapoints
2025-03-07 12:33:04,197 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 12:33:04,510 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:33:04,815 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:33:05,130 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:33:05,441 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:33:05,748 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:33:06,109 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:33:06,442 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:33:06,748 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:33:07,054 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:33:07,201 - INFO - validation batch 1, loss: 0.030, 32/6976 datapoints
2025-03-07 12:33:07,284 - INFO - validation batch 51, loss: 2.243, 1632/6976 datapoints
2025-03-07 12:33:07,362 - INFO - validation batch 101, loss: 0.292, 3232/6976 datapoints
2025-03-07 12:33:07,448 - INFO - validation batch 151, loss: 0.725, 4832/6976 datapoints
2025-03-07 12:33:07,533 - INFO - validation batch 201, loss: 0.573, 6432/6976 datapoints
2025-03-07 12:33:07,560 - INFO - Epoch 219/800 done.
2025-03-07 12:33:07,560 - INFO - Final validation performance:
Loss: 0.772, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:33:07,561 - INFO - Beginning epoch 220/800
2025-03-07 12:33:07,571 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 12:33:07,878 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:33:08,182 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:33:08,483 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:33:08,773 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:33:09,049 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:33:09,330 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:33:09,622 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:33:09,909 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 12:33:10,200 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:33:10,489 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:33:10,770 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:33:11,074 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:33:11,376 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:33:11,675 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:33:12,002 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:33:12,321 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:33:12,621 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:33:12,782 - INFO - validation batch 1, loss: 0.029, 32/6976 datapoints
2025-03-07 12:33:12,880 - INFO - validation batch 51, loss: 2.274, 1632/6976 datapoints
2025-03-07 12:33:12,980 - INFO - validation batch 101, loss: 0.295, 3232/6976 datapoints
2025-03-07 12:33:13,074 - INFO - validation batch 151, loss: 0.740, 4832/6976 datapoints
2025-03-07 12:33:13,155 - INFO - validation batch 201, loss: 0.575, 6432/6976 datapoints
2025-03-07 12:33:13,184 - INFO - Epoch 220/800 done.
2025-03-07 12:33:13,184 - INFO - Final validation performance:
Loss: 0.782, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:33:13,185 - INFO - Beginning epoch 221/800
2025-03-07 12:33:13,193 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 12:33:13,493 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:33:13,786 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:33:14,104 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:33:14,400 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:33:14,706 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:33:15,009 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:33:15,331 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:33:15,639 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 12:33:15,922 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:33:16,204 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:33:16,499 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:33:16,802 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:33:17,088 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:33:17,375 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:33:17,672 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:33:17,957 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:33:18,238 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:33:18,379 - INFO - validation batch 1, loss: 0.027, 32/6976 datapoints
2025-03-07 12:33:18,457 - INFO - validation batch 51, loss: 2.306, 1632/6976 datapoints
2025-03-07 12:33:18,532 - INFO - validation batch 101, loss: 0.299, 3232/6976 datapoints
2025-03-07 12:33:18,609 - INFO - validation batch 151, loss: 0.748, 4832/6976 datapoints
2025-03-07 12:33:18,683 - INFO - validation batch 201, loss: 0.581, 6432/6976 datapoints
2025-03-07 12:33:18,709 - INFO - Epoch 221/800 done.
2025-03-07 12:33:18,709 - INFO - Final validation performance:
Loss: 0.792, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:33:18,710 - INFO - Beginning epoch 222/800
2025-03-07 12:33:18,719 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 12:33:18,997 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:33:19,384 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:33:19,753 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:33:20,112 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:33:20,454 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:33:20,810 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:33:21,174 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:33:21,510 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:33:21,828 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:33:22,130 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:33:22,447 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:33:22,756 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:33:23,093 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:33:23,386 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:33:23,688 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:33:23,990 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:33:24,314 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:33:24,491 - INFO - validation batch 1, loss: 0.027, 32/6976 datapoints
2025-03-07 12:33:24,575 - INFO - validation batch 51, loss: 2.338, 1632/6976 datapoints
2025-03-07 12:33:24,685 - INFO - validation batch 101, loss: 0.303, 3232/6976 datapoints
2025-03-07 12:33:24,794 - INFO - validation batch 151, loss: 0.761, 4832/6976 datapoints
2025-03-07 12:33:24,898 - INFO - validation batch 201, loss: 0.586, 6432/6976 datapoints
2025-03-07 12:33:24,937 - INFO - Epoch 222/800 done.
2025-03-07 12:33:24,937 - INFO - Final validation performance:
Loss: 0.803, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:33:24,938 - INFO - Beginning epoch 223/800
2025-03-07 12:33:24,948 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 12:33:25,302 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:33:25,736 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:33:26,102 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:33:26,588 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:33:27,045 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:33:27,349 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:33:27,659 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:33:27,967 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:33:28,375 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:33:28,718 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:33:29,051 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:33:29,404 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:33:29,743 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:33:30,108 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:33:30,646 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:33:31,080 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:33:31,423 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:33:31,606 - INFO - validation batch 1, loss: 0.027, 32/6976 datapoints
2025-03-07 12:33:31,693 - INFO - validation batch 51, loss: 2.374, 1632/6976 datapoints
2025-03-07 12:33:31,772 - INFO - validation batch 101, loss: 0.309, 3232/6976 datapoints
2025-03-07 12:33:31,851 - INFO - validation batch 151, loss: 0.773, 4832/6976 datapoints
2025-03-07 12:33:31,925 - INFO - validation batch 201, loss: 0.595, 6432/6976 datapoints
2025-03-07 12:33:31,950 - INFO - Epoch 223/800 done.
2025-03-07 12:33:31,950 - INFO - Final validation performance:
Loss: 0.816, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:33:31,951 - INFO - Beginning epoch 224/800
2025-03-07 12:33:31,960 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 12:33:32,257 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:33:32,558 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:33:32,876 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:33:33,204 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:33:33,498 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:33:33,796 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:33:34,093 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:33:34,391 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:33:34,844 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:33:35,208 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:33:35,585 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:33:35,986 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:33:36,381 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:33:37,275 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:33:37,929 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:33:38,542 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:33:39,048 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:33:39,230 - INFO - validation batch 1, loss: 0.026, 32/6976 datapoints
2025-03-07 12:33:39,344 - INFO - validation batch 51, loss: 2.406, 1632/6976 datapoints
2025-03-07 12:33:39,477 - INFO - validation batch 101, loss: 0.313, 3232/6976 datapoints
2025-03-07 12:33:39,637 - INFO - validation batch 151, loss: 0.787, 4832/6976 datapoints
2025-03-07 12:33:39,761 - INFO - validation batch 201, loss: 0.600, 6432/6976 datapoints
2025-03-07 12:33:39,804 - INFO - Epoch 224/800 done.
2025-03-07 12:33:39,805 - INFO - Final validation performance:
Loss: 0.826, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:33:39,807 - INFO - Beginning epoch 225/800
2025-03-07 12:33:39,817 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:33:40,253 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:33:40,564 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:33:40,876 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:33:41,186 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:33:41,508 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:33:41,852 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:33:42,159 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:33:42,466 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:33:42,759 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:33:43,056 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:33:43,349 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:33:43,645 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:33:43,924 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:33:44,216 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:33:44,497 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:33:44,812 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:33:45,097 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:33:45,239 - INFO - validation batch 1, loss: 0.026, 32/6976 datapoints
2025-03-07 12:33:45,314 - INFO - validation batch 51, loss: 2.440, 1632/6976 datapoints
2025-03-07 12:33:45,389 - INFO - validation batch 101, loss: 0.319, 3232/6976 datapoints
2025-03-07 12:33:45,462 - INFO - validation batch 151, loss: 0.800, 4832/6976 datapoints
2025-03-07 12:33:45,535 - INFO - validation batch 201, loss: 0.606, 6432/6976 datapoints
2025-03-07 12:33:45,562 - INFO - Epoch 225/800 done.
2025-03-07 12:33:45,562 - INFO - Final validation performance:
Loss: 0.838, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:33:45,563 - INFO - Beginning epoch 226/800
2025-03-07 12:33:45,572 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:33:45,871 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:33:46,153 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:33:46,450 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:33:46,778 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:33:47,097 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:33:47,388 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:33:47,702 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:33:47,996 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:33:48,297 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:33:48,598 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:33:48,892 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:33:49,182 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:33:49,481 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:33:49,768 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:33:50,060 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:33:50,350 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:33:50,654 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:33:50,795 - INFO - validation batch 1, loss: 0.025, 32/6976 datapoints
2025-03-07 12:33:50,868 - INFO - validation batch 51, loss: 2.473, 1632/6976 datapoints
2025-03-07 12:33:50,943 - INFO - validation batch 101, loss: 0.326, 3232/6976 datapoints
2025-03-07 12:33:51,042 - INFO - validation batch 151, loss: 0.818, 4832/6976 datapoints
2025-03-07 12:33:51,142 - INFO - validation batch 201, loss: 0.619, 6432/6976 datapoints
2025-03-07 12:33:51,178 - INFO - Epoch 226/800 done.
2025-03-07 12:33:51,179 - INFO - Final validation performance:
Loss: 0.852, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:33:51,179 - INFO - Beginning epoch 227/800
2025-03-07 12:33:51,188 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:33:51,479 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:33:51,782 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:33:52,076 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:33:52,357 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:33:52,649 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:33:52,941 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:33:53,228 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:33:53,524 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:33:53,817 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:33:54,108 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:33:54,400 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:33:54,695 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:33:54,976 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:33:55,253 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:33:55,539 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:33:55,830 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:33:56,113 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:33:56,250 - INFO - validation batch 1, loss: 0.025, 32/6976 datapoints
2025-03-07 12:33:56,326 - INFO - validation batch 51, loss: 2.504, 1632/6976 datapoints
2025-03-07 12:33:56,401 - INFO - validation batch 101, loss: 0.331, 3232/6976 datapoints
2025-03-07 12:33:56,477 - INFO - validation batch 151, loss: 0.831, 4832/6976 datapoints
2025-03-07 12:33:56,554 - INFO - validation batch 201, loss: 0.624, 6432/6976 datapoints
2025-03-07 12:33:56,584 - INFO - Epoch 227/800 done.
2025-03-07 12:33:56,584 - INFO - Final validation performance:
Loss: 0.863, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:33:56,585 - INFO - Beginning epoch 228/800
2025-03-07 12:33:56,593 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:33:56,877 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:33:57,178 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:33:57,462 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:33:57,752 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:33:58,077 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:33:58,358 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:33:58,644 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:33:58,918 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:33:59,205 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:33:59,534 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:33:59,826 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:34:00,114 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:34:00,406 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:34:00,706 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:34:01,001 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:34:01,299 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:34:01,596 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:34:01,775 - INFO - validation batch 1, loss: 0.024, 32/6976 datapoints
2025-03-07 12:34:01,857 - INFO - validation batch 51, loss: 2.539, 1632/6976 datapoints
2025-03-07 12:34:01,937 - INFO - validation batch 101, loss: 0.335, 3232/6976 datapoints
2025-03-07 12:34:02,021 - INFO - validation batch 151, loss: 0.847, 4832/6976 datapoints
2025-03-07 12:34:02,135 - INFO - validation batch 201, loss: 0.634, 6432/6976 datapoints
2025-03-07 12:34:02,170 - INFO - Epoch 228/800 done.
2025-03-07 12:34:02,171 - INFO - Final validation performance:
Loss: 0.876, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:34:02,171 - INFO - Beginning epoch 229/800
2025-03-07 12:34:02,180 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:34:02,492 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:34:02,782 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:34:03,060 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:34:03,345 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:34:03,642 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:34:03,921 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:34:04,205 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:34:04,490 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:34:04,778 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:34:05,105 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:34:05,420 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:34:05,738 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:34:06,043 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:34:06,361 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:34:06,726 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:34:07,081 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:34:07,741 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:34:08,260 - INFO - validation batch 1, loss: 0.024, 32/6976 datapoints
2025-03-07 12:34:08,369 - INFO - validation batch 51, loss: 2.574, 1632/6976 datapoints
2025-03-07 12:34:08,486 - INFO - validation batch 101, loss: 0.340, 3232/6976 datapoints
2025-03-07 12:34:08,597 - INFO - validation batch 151, loss: 0.859, 4832/6976 datapoints
2025-03-07 12:34:08,701 - INFO - validation batch 201, loss: 0.644, 6432/6976 datapoints
2025-03-07 12:34:08,734 - INFO - Epoch 229/800 done.
2025-03-07 12:34:08,734 - INFO - Final validation performance:
Loss: 0.888, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:34:08,735 - INFO - Beginning epoch 230/800
2025-03-07 12:34:08,743 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:34:09,071 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:34:09,372 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:34:09,681 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:34:09,977 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:34:10,275 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:34:10,568 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:34:10,852 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:34:11,133 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:34:11,424 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:34:11,712 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:34:11,994 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:34:12,270 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:34:12,552 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:34:12,841 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:34:13,125 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:34:13,407 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:34:13,695 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:34:13,833 - INFO - validation batch 1, loss: 0.023, 32/6976 datapoints
2025-03-07 12:34:13,908 - INFO - validation batch 51, loss: 2.605, 1632/6976 datapoints
2025-03-07 12:34:13,984 - INFO - validation batch 101, loss: 0.342, 3232/6976 datapoints
2025-03-07 12:34:14,058 - INFO - validation batch 151, loss: 0.878, 4832/6976 datapoints
2025-03-07 12:34:14,133 - INFO - validation batch 201, loss: 0.651, 6432/6976 datapoints
2025-03-07 12:34:14,161 - INFO - Epoch 230/800 done.
2025-03-07 12:34:14,161 - INFO - Final validation performance:
Loss: 0.900, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:34:14,162 - INFO - Beginning epoch 231/800
2025-03-07 12:34:14,172 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:34:14,464 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:34:14,748 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:34:15,038 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:34:15,321 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:34:15,605 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:34:15,901 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:34:16,213 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:34:16,513 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:34:16,807 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:34:17,093 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:34:17,410 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:34:17,712 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:34:18,003 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:34:18,292 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:34:18,586 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:34:18,871 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:34:19,156 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:34:19,298 - INFO - validation batch 1, loss: 0.022, 32/6976 datapoints
2025-03-07 12:34:19,376 - INFO - validation batch 51, loss: 2.640, 1632/6976 datapoints
2025-03-07 12:34:19,457 - INFO - validation batch 101, loss: 0.352, 3232/6976 datapoints
2025-03-07 12:34:19,534 - INFO - validation batch 151, loss: 0.893, 4832/6976 datapoints
2025-03-07 12:34:19,608 - INFO - validation batch 201, loss: 0.654, 6432/6976 datapoints
2025-03-07 12:34:19,636 - INFO - Epoch 231/800 done.
2025-03-07 12:34:19,636 - INFO - Final validation performance:
Loss: 0.912, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:34:19,637 - INFO - Beginning epoch 232/800
2025-03-07 12:34:19,645 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:34:19,938 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:34:20,244 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:34:20,543 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:34:20,827 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:34:21,116 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:34:21,400 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:34:21,687 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:34:21,969 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:34:22,252 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:34:22,542 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:34:22,826 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:34:23,111 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:34:23,394 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:34:23,680 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:34:23,972 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:34:24,265 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:34:24,559 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:34:24,702 - INFO - validation batch 1, loss: 0.021, 32/6976 datapoints
2025-03-07 12:34:24,781 - INFO - validation batch 51, loss: 2.674, 1632/6976 datapoints
2025-03-07 12:34:24,862 - INFO - validation batch 101, loss: 0.361, 3232/6976 datapoints
2025-03-07 12:34:24,936 - INFO - validation batch 151, loss: 0.911, 4832/6976 datapoints
2025-03-07 12:34:25,015 - INFO - validation batch 201, loss: 0.667, 6432/6976 datapoints
2025-03-07 12:34:25,040 - INFO - Epoch 232/800 done.
2025-03-07 12:34:25,040 - INFO - Final validation performance:
Loss: 0.927, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:34:25,041 - INFO - Beginning epoch 233/800
2025-03-07 12:34:25,049 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:34:25,343 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:34:25,638 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:34:25,923 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:34:26,202 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:34:26,494 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:34:26,776 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:34:27,059 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:34:27,344 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:34:27,643 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:34:27,938 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:34:28,243 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:34:28,571 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:34:28,858 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:34:29,157 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:34:29,452 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:34:29,757 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:34:30,049 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:34:30,196 - INFO - validation batch 1, loss: 0.021, 32/6976 datapoints
2025-03-07 12:34:30,277 - INFO - validation batch 51, loss: 2.711, 1632/6976 datapoints
2025-03-07 12:34:30,354 - INFO - validation batch 101, loss: 0.366, 3232/6976 datapoints
2025-03-07 12:34:30,431 - INFO - validation batch 151, loss: 0.926, 4832/6976 datapoints
2025-03-07 12:34:30,616 - INFO - validation batch 201, loss: 0.675, 6432/6976 datapoints
2025-03-07 12:34:30,640 - INFO - Epoch 233/800 done.
2025-03-07 12:34:30,641 - INFO - Final validation performance:
Loss: 0.940, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:34:30,642 - INFO - Beginning epoch 234/800
2025-03-07 12:34:30,650 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:34:30,946 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:34:31,238 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:34:31,592 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:34:31,909 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:34:32,196 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:34:32,481 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:34:32,763 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:34:33,055 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:34:33,337 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:34:33,620 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:34:33,916 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:34:34,207 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:34:34,499 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:34:34,783 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:34:35,112 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:34:35,396 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:34:35,685 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:34:35,828 - INFO - validation batch 1, loss: 0.021, 32/6976 datapoints
2025-03-07 12:34:35,911 - INFO - validation batch 51, loss: 2.750, 1632/6976 datapoints
2025-03-07 12:34:35,988 - INFO - validation batch 101, loss: 0.373, 3232/6976 datapoints
2025-03-07 12:34:36,062 - INFO - validation batch 151, loss: 0.944, 4832/6976 datapoints
2025-03-07 12:34:36,136 - INFO - validation batch 201, loss: 0.682, 6432/6976 datapoints
2025-03-07 12:34:36,170 - INFO - Epoch 234/800 done.
2025-03-07 12:34:36,170 - INFO - Final validation performance:
Loss: 0.954, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:34:36,171 - INFO - Beginning epoch 235/800
2025-03-07 12:34:36,179 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:34:36,479 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:34:36,781 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:34:37,091 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:34:37,392 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:34:37,720 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:34:38,019 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:34:38,329 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:34:38,848 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:34:39,202 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:34:39,517 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:34:39,832 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:34:40,146 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:34:40,491 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:34:40,991 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:34:41,291 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:34:41,591 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:34:41,881 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:34:42,036 - INFO - validation batch 1, loss: 0.021, 32/6976 datapoints
2025-03-07 12:34:42,117 - INFO - validation batch 51, loss: 2.782, 1632/6976 datapoints
2025-03-07 12:34:42,190 - INFO - validation batch 101, loss: 0.383, 3232/6976 datapoints
2025-03-07 12:34:42,282 - INFO - validation batch 151, loss: 0.960, 4832/6976 datapoints
2025-03-07 12:34:42,359 - INFO - validation batch 201, loss: 0.686, 6432/6976 datapoints
2025-03-07 12:34:42,386 - INFO - Epoch 235/800 done.
2025-03-07 12:34:42,386 - INFO - Final validation performance:
Loss: 0.966, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:34:42,387 - INFO - Beginning epoch 236/800
2025-03-07 12:34:42,394 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:34:42,700 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:34:43,166 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:34:43,495 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:34:43,813 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:34:44,136 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:34:44,423 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:34:44,723 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:34:45,030 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:34:45,337 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:34:45,626 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:34:45,915 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:34:46,210 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:34:46,499 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:34:46,785 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:34:47,069 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:34:47,363 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:34:47,689 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:34:47,848 - INFO - validation batch 1, loss: 0.021, 32/6976 datapoints
2025-03-07 12:34:47,926 - INFO - validation batch 51, loss: 2.821, 1632/6976 datapoints
2025-03-07 12:34:48,004 - INFO - validation batch 101, loss: 0.388, 3232/6976 datapoints
2025-03-07 12:34:48,086 - INFO - validation batch 151, loss: 0.977, 4832/6976 datapoints
2025-03-07 12:34:48,169 - INFO - validation batch 201, loss: 0.698, 6432/6976 datapoints
2025-03-07 12:34:48,194 - INFO - Epoch 236/800 done.
2025-03-07 12:34:48,194 - INFO - Final validation performance:
Loss: 0.981, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:34:48,194 - INFO - Beginning epoch 237/800
2025-03-07 12:34:48,202 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:34:48,497 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:34:48,798 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:34:49,090 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:34:49,407 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:34:49,708 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:34:49,996 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:34:50,284 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:34:50,613 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:34:50,911 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:34:51,217 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:34:51,617 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:34:52,057 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:34:52,380 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:34:52,908 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:34:53,276 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:34:53,776 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:34:54,119 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:34:54,286 - INFO - validation batch 1, loss: 0.020, 32/6976 datapoints
2025-03-07 12:34:54,374 - INFO - validation batch 51, loss: 2.858, 1632/6976 datapoints
2025-03-07 12:34:54,534 - INFO - validation batch 101, loss: 0.391, 3232/6976 datapoints
2025-03-07 12:34:54,681 - INFO - validation batch 151, loss: 0.996, 4832/6976 datapoints
2025-03-07 12:34:54,805 - INFO - validation batch 201, loss: 0.699, 6432/6976 datapoints
2025-03-07 12:34:54,845 - INFO - Epoch 237/800 done.
2025-03-07 12:34:54,845 - INFO - Final validation performance:
Loss: 0.993, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:34:54,846 - INFO - Beginning epoch 238/800
2025-03-07 12:34:54,859 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:34:55,211 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:34:55,607 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:34:55,943 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:34:56,308 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:34:56,613 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:34:56,913 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:34:57,202 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:34:57,512 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:34:57,868 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:34:58,261 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:34:58,603 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:34:58,898 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:34:59,192 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:34:59,493 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:34:59,786 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:35:00,082 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:35:00,390 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:35:00,549 - INFO - validation batch 1, loss: 0.020, 32/6976 datapoints
2025-03-07 12:35:00,629 - INFO - validation batch 51, loss: 2.896, 1632/6976 datapoints
2025-03-07 12:35:00,715 - INFO - validation batch 101, loss: 0.404, 3232/6976 datapoints
2025-03-07 12:35:00,804 - INFO - validation batch 151, loss: 1.011, 4832/6976 datapoints
2025-03-07 12:35:00,905 - INFO - validation batch 201, loss: 0.709, 6432/6976 datapoints
2025-03-07 12:35:00,939 - INFO - Epoch 238/800 done.
2025-03-07 12:35:00,939 - INFO - Final validation performance:
Loss: 1.008, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:35:00,940 - INFO - Beginning epoch 239/800
2025-03-07 12:35:00,949 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:35:01,263 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:35:01,583 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:35:01,906 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:35:02,221 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:35:02,531 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:35:02,829 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:35:03,145 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:35:03,458 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:35:03,787 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:35:04,090 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:35:04,386 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:35:04,735 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:35:05,085 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:35:05,394 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:35:05,755 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:35:06,059 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:35:06,344 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:35:06,488 - INFO - validation batch 1, loss: 0.019, 32/6976 datapoints
2025-03-07 12:35:06,573 - INFO - validation batch 51, loss: 2.939, 1632/6976 datapoints
2025-03-07 12:35:06,651 - INFO - validation batch 101, loss: 0.411, 3232/6976 datapoints
2025-03-07 12:35:06,733 - INFO - validation batch 151, loss: 1.033, 4832/6976 datapoints
2025-03-07 12:35:06,815 - INFO - validation batch 201, loss: 0.714, 6432/6976 datapoints
2025-03-07 12:35:06,846 - INFO - Epoch 239/800 done.
2025-03-07 12:35:06,846 - INFO - Final validation performance:
Loss: 1.023, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:35:06,847 - INFO - Beginning epoch 240/800
2025-03-07 12:35:06,856 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:35:07,158 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:35:07,457 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:35:07,814 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:35:08,102 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:35:08,401 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:35:08,720 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:35:09,022 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:35:09,330 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:35:09,638 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:35:09,964 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:35:10,290 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:35:10,603 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:35:10,895 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:35:11,186 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:35:11,476 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:35:11,791 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:35:12,072 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:35:12,208 - INFO - validation batch 1, loss: 0.020, 32/6976 datapoints
2025-03-07 12:35:12,281 - INFO - validation batch 51, loss: 2.977, 1632/6976 datapoints
2025-03-07 12:35:12,352 - INFO - validation batch 101, loss: 0.421, 3232/6976 datapoints
2025-03-07 12:35:12,425 - INFO - validation batch 151, loss: 1.048, 4832/6976 datapoints
2025-03-07 12:35:12,499 - INFO - validation batch 201, loss: 0.717, 6432/6976 datapoints
2025-03-07 12:35:12,527 - INFO - Epoch 240/800 done.
2025-03-07 12:35:12,527 - INFO - Final validation performance:
Loss: 1.036, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:35:12,528 - INFO - Beginning epoch 241/800
2025-03-07 12:35:12,537 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:35:12,824 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:35:13,135 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:35:13,466 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:35:13,752 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:35:14,045 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:35:14,320 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:35:14,627 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:35:14,916 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:35:15,230 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:35:15,532 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:35:15,848 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:35:16,154 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:35:16,490 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:35:16,824 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:35:17,172 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:35:17,459 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:35:17,752 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:35:17,916 - INFO - validation batch 1, loss: 0.019, 32/6976 datapoints
2025-03-07 12:35:18,002 - INFO - validation batch 51, loss: 3.019, 1632/6976 datapoints
2025-03-07 12:35:18,088 - INFO - validation batch 101, loss: 0.429, 3232/6976 datapoints
2025-03-07 12:35:18,175 - INFO - validation batch 151, loss: 1.068, 4832/6976 datapoints
2025-03-07 12:35:18,251 - INFO - validation batch 201, loss: 0.723, 6432/6976 datapoints
2025-03-07 12:35:18,283 - INFO - Epoch 241/800 done.
2025-03-07 12:35:18,283 - INFO - Final validation performance:
Loss: 1.051, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:35:18,284 - INFO - Beginning epoch 242/800
2025-03-07 12:35:18,292 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:35:18,621 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:35:18,942 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:35:19,245 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:35:19,558 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:35:19,871 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:35:20,169 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:35:20,462 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:35:20,771 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:35:21,069 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:35:21,362 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:35:21,654 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:35:21,953 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:35:22,248 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:35:22,569 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:35:22,870 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:35:23,193 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:35:23,510 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:35:23,660 - INFO - validation batch 1, loss: 0.019, 32/6976 datapoints
2025-03-07 12:35:23,739 - INFO - validation batch 51, loss: 3.056, 1632/6976 datapoints
2025-03-07 12:35:23,815 - INFO - validation batch 101, loss: 0.437, 3232/6976 datapoints
2025-03-07 12:35:23,895 - INFO - validation batch 151, loss: 1.085, 4832/6976 datapoints
2025-03-07 12:35:23,972 - INFO - validation batch 201, loss: 0.732, 6432/6976 datapoints
2025-03-07 12:35:23,999 - INFO - Epoch 242/800 done.
2025-03-07 12:35:23,999 - INFO - Final validation performance:
Loss: 1.066, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:35:23,999 - INFO - Beginning epoch 243/800
2025-03-07 12:35:24,009 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:35:24,322 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:35:24,631 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:35:24,936 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:35:25,260 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:35:25,583 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:35:25,898 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:35:26,229 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:35:26,737 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:35:27,204 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:35:27,847 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:35:28,315 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:35:28,712 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:35:29,059 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:35:29,384 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:35:29,722 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:35:30,059 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:35:30,375 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:35:30,603 - INFO - validation batch 1, loss: 0.020, 32/6976 datapoints
2025-03-07 12:35:30,771 - INFO - validation batch 51, loss: 3.097, 1632/6976 datapoints
2025-03-07 12:35:30,899 - INFO - validation batch 101, loss: 0.449, 3232/6976 datapoints
2025-03-07 12:35:31,006 - INFO - validation batch 151, loss: 1.101, 4832/6976 datapoints
2025-03-07 12:35:31,095 - INFO - validation batch 201, loss: 0.739, 6432/6976 datapoints
2025-03-07 12:35:31,134 - INFO - Epoch 243/800 done.
2025-03-07 12:35:31,135 - INFO - Final validation performance:
Loss: 1.081, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:35:31,135 - INFO - Beginning epoch 244/800
2025-03-07 12:35:31,145 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:35:31,553 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:35:32,087 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:35:32,569 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:35:33,089 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:35:33,537 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:35:33,878 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:35:34,214 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:35:34,621 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:35:34,978 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:35:35,314 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:35:35,641 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:35:35,976 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:35:36,393 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:35:36,727 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:35:37,061 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:35:37,499 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:35:37,894 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:35:38,138 - INFO - validation batch 1, loss: 0.020, 32/6976 datapoints
2025-03-07 12:35:38,373 - INFO - validation batch 51, loss: 3.140, 1632/6976 datapoints
2025-03-07 12:35:38,594 - INFO - validation batch 101, loss: 0.454, 3232/6976 datapoints
2025-03-07 12:35:38,709 - INFO - validation batch 151, loss: 1.121, 4832/6976 datapoints
2025-03-07 12:35:38,857 - INFO - validation batch 201, loss: 0.742, 6432/6976 datapoints
2025-03-07 12:35:38,896 - INFO - Epoch 244/800 done.
2025-03-07 12:35:38,896 - INFO - Final validation performance:
Loss: 1.095, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:35:38,897 - INFO - Beginning epoch 245/800
2025-03-07 12:35:38,911 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:35:39,427 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:35:39,945 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:35:40,272 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:35:40,654 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:35:41,034 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:35:41,409 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:35:41,751 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:35:42,231 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:35:42,588 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:35:42,980 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:35:43,321 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:35:43,682 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:35:44,009 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:35:44,335 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:35:44,695 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:35:45,039 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:35:45,372 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:35:45,566 - INFO - validation batch 1, loss: 0.020, 32/6976 datapoints
2025-03-07 12:35:45,671 - INFO - validation batch 51, loss: 3.180, 1632/6976 datapoints
2025-03-07 12:35:45,780 - INFO - validation batch 101, loss: 0.464, 3232/6976 datapoints
2025-03-07 12:35:45,884 - INFO - validation batch 151, loss: 1.138, 4832/6976 datapoints
2025-03-07 12:35:45,982 - INFO - validation batch 201, loss: 0.753, 6432/6976 datapoints
2025-03-07 12:35:46,010 - INFO - Epoch 245/800 done.
2025-03-07 12:35:46,010 - INFO - Final validation performance:
Loss: 1.111, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:35:46,011 - INFO - Beginning epoch 246/800
2025-03-07 12:35:46,021 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:35:46,343 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:35:46,696 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:35:47,202 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:35:47,519 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:35:47,858 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:35:48,206 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:35:48,559 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:35:48,893 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:35:49,231 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:35:49,555 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:35:49,968 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:35:50,333 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:35:50,667 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:35:50,970 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:35:51,275 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:35:51,575 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:35:51,873 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:35:52,052 - INFO - validation batch 1, loss: 0.019, 32/6976 datapoints
2025-03-07 12:35:52,149 - INFO - validation batch 51, loss: 3.221, 1632/6976 datapoints
2025-03-07 12:35:52,231 - INFO - validation batch 101, loss: 0.476, 3232/6976 datapoints
2025-03-07 12:35:52,313 - INFO - validation batch 151, loss: 1.153, 4832/6976 datapoints
2025-03-07 12:35:52,397 - INFO - validation batch 201, loss: 0.756, 6432/6976 datapoints
2025-03-07 12:35:52,429 - INFO - Epoch 246/800 done.
2025-03-07 12:35:52,429 - INFO - Final validation performance:
Loss: 1.125, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:35:52,430 - INFO - Beginning epoch 247/800
2025-03-07 12:35:52,444 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:35:52,793 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:35:53,101 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:35:53,490 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:35:53,850 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:35:54,185 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:35:54,565 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:35:54,873 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:35:55,177 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:35:55,511 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:35:55,824 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:35:56,161 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:35:56,540 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:35:56,951 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:35:57,374 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:35:57,752 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:35:58,184 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:35:58,631 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:35:58,924 - INFO - validation batch 1, loss: 0.018, 32/6976 datapoints
2025-03-07 12:35:59,049 - INFO - validation batch 51, loss: 3.271, 1632/6976 datapoints
2025-03-07 12:35:59,158 - INFO - validation batch 101, loss: 0.485, 3232/6976 datapoints
2025-03-07 12:35:59,300 - INFO - validation batch 151, loss: 1.171, 4832/6976 datapoints
2025-03-07 12:35:59,390 - INFO - validation batch 201, loss: 0.759, 6432/6976 datapoints
2025-03-07 12:35:59,424 - INFO - Epoch 247/800 done.
2025-03-07 12:35:59,425 - INFO - Final validation performance:
Loss: 1.141, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:35:59,425 - INFO - Beginning epoch 248/800
2025-03-07 12:35:59,435 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:35:59,789 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:36:00,117 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:36:00,437 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:36:00,760 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:36:01,095 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:36:01,417 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:36:01,796 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:36:02,214 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:36:02,560 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:36:02,920 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:36:03,450 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:36:03,850 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:36:04,179 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:36:04,524 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:36:04,867 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:36:05,221 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:36:05,542 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:36:05,710 - INFO - validation batch 1, loss: 0.018, 32/6976 datapoints
2025-03-07 12:36:05,793 - INFO - validation batch 51, loss: 3.316, 1632/6976 datapoints
2025-03-07 12:36:05,875 - INFO - validation batch 101, loss: 0.500, 3232/6976 datapoints
2025-03-07 12:36:05,959 - INFO - validation batch 151, loss: 1.193, 4832/6976 datapoints
2025-03-07 12:36:06,040 - INFO - validation batch 201, loss: 0.766, 6432/6976 datapoints
2025-03-07 12:36:06,068 - INFO - Epoch 248/800 done.
2025-03-07 12:36:06,069 - INFO - Final validation performance:
Loss: 1.159, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:36:06,070 - INFO - Beginning epoch 249/800
2025-03-07 12:36:06,080 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:36:06,394 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:36:06,706 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:36:07,025 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:36:07,349 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:36:07,642 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:36:07,954 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:36:08,268 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:36:08,602 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:36:08,941 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:36:09,254 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:36:09,595 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:36:10,079 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:36:10,405 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:36:10,735 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:36:11,042 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:36:11,338 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:36:11,661 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:36:11,805 - INFO - validation batch 1, loss: 0.018, 32/6976 datapoints
2025-03-07 12:36:11,891 - INFO - validation batch 51, loss: 3.355, 1632/6976 datapoints
2025-03-07 12:36:11,982 - INFO - validation batch 101, loss: 0.513, 3232/6976 datapoints
2025-03-07 12:36:12,083 - INFO - validation batch 151, loss: 1.214, 4832/6976 datapoints
2025-03-07 12:36:12,171 - INFO - validation batch 201, loss: 0.774, 6432/6976 datapoints
2025-03-07 12:36:12,208 - INFO - Epoch 249/800 done.
2025-03-07 12:36:12,209 - INFO - Final validation performance:
Loss: 1.175, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:36:12,210 - INFO - Beginning epoch 250/800
2025-03-07 12:36:12,219 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:36:12,553 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:36:12,866 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:36:13,191 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:36:13,508 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:36:13,823 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:36:14,138 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:36:14,466 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:36:14,788 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:36:15,098 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:36:15,422 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:36:15,771 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:36:16,093 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:36:16,415 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:36:16,730 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:36:17,073 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:36:17,423 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:36:17,759 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:36:17,904 - INFO - validation batch 1, loss: 0.018, 32/6976 datapoints
2025-03-07 12:36:17,994 - INFO - validation batch 51, loss: 3.398, 1632/6976 datapoints
2025-03-07 12:36:18,078 - INFO - validation batch 101, loss: 0.525, 3232/6976 datapoints
2025-03-07 12:36:18,160 - INFO - validation batch 151, loss: 1.237, 4832/6976 datapoints
2025-03-07 12:36:18,238 - INFO - validation batch 201, loss: 0.789, 6432/6976 datapoints
2025-03-07 12:36:18,267 - INFO - Epoch 250/800 done.
2025-03-07 12:36:18,267 - INFO - Final validation performance:
Loss: 1.193, top-1 acc: 0.897top-5 acc: 0.897
2025-03-07 12:36:18,268 - INFO - Beginning epoch 251/800
2025-03-07 12:36:18,276 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:36:18,595 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:36:18,996 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:36:19,310 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:36:19,628 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:36:19,947 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:36:20,321 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:36:20,740 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:36:21,121 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:36:21,541 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:36:21,867 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:36:22,197 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:36:22,543 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:36:22,859 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:36:23,179 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:36:23,595 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:36:23,983 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:36:24,318 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:36:24,469 - INFO - validation batch 1, loss: 0.018, 32/6976 datapoints
2025-03-07 12:36:24,560 - INFO - validation batch 51, loss: 3.441, 1632/6976 datapoints
2025-03-07 12:36:24,670 - INFO - validation batch 101, loss: 0.533, 3232/6976 datapoints
2025-03-07 12:36:24,772 - INFO - validation batch 151, loss: 1.259, 4832/6976 datapoints
2025-03-07 12:36:24,854 - INFO - validation batch 201, loss: 0.801, 6432/6976 datapoints
2025-03-07 12:36:24,884 - INFO - Epoch 251/800 done.
2025-03-07 12:36:24,885 - INFO - Final validation performance:
Loss: 1.210, top-1 acc: 0.897top-5 acc: 0.897
2025-03-07 12:36:24,885 - INFO - Beginning epoch 252/800
2025-03-07 12:36:24,899 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:36:25,248 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:36:25,565 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:36:25,881 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:36:26,253 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:36:26,642 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:36:27,020 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:36:27,340 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:36:27,654 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:36:27,983 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:36:28,325 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:36:28,736 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:36:29,163 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:36:29,539 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:36:29,926 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:36:30,319 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:36:30,858 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:36:31,334 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:36:31,556 - INFO - validation batch 1, loss: 0.019, 32/6976 datapoints
2025-03-07 12:36:31,689 - INFO - validation batch 51, loss: 3.480, 1632/6976 datapoints
2025-03-07 12:36:31,827 - INFO - validation batch 101, loss: 0.544, 3232/6976 datapoints
2025-03-07 12:36:31,942 - INFO - validation batch 151, loss: 1.276, 4832/6976 datapoints
2025-03-07 12:36:32,058 - INFO - validation batch 201, loss: 0.817, 6432/6976 datapoints
2025-03-07 12:36:32,101 - INFO - Epoch 252/800 done.
2025-03-07 12:36:32,101 - INFO - Final validation performance:
Loss: 1.227, top-1 acc: 0.897top-5 acc: 0.897
2025-03-07 12:36:32,102 - INFO - Beginning epoch 253/800
2025-03-07 12:36:32,121 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:36:32,636 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:36:33,118 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:36:33,589 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:36:34,008 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:36:34,458 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:36:34,903 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:36:35,352 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:36:35,812 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:36:36,249 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:36:36,740 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:36:37,227 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:36:37,917 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:36:38,416 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:36:38,929 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:36:39,400 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:36:39,856 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:36:40,272 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:36:40,487 - INFO - validation batch 1, loss: 0.019, 32/6976 datapoints
2025-03-07 12:36:40,633 - INFO - validation batch 51, loss: 3.526, 1632/6976 datapoints
2025-03-07 12:36:40,764 - INFO - validation batch 101, loss: 0.551, 3232/6976 datapoints
2025-03-07 12:36:40,904 - INFO - validation batch 151, loss: 1.299, 4832/6976 datapoints
2025-03-07 12:36:41,102 - INFO - validation batch 201, loss: 0.827, 6432/6976 datapoints
2025-03-07 12:36:41,143 - INFO - Epoch 253/800 done.
2025-03-07 12:36:41,144 - INFO - Final validation performance:
Loss: 1.244, top-1 acc: 0.897top-5 acc: 0.897
2025-03-07 12:36:41,145 - INFO - Beginning epoch 254/800
2025-03-07 12:36:41,161 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:36:41,802 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:36:42,268 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:36:42,818 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:36:43,248 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:36:43,635 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:36:44,007 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:36:44,401 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:36:44,792 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:36:45,181 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:36:45,606 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:36:46,011 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:36:46,405 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:36:46,820 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:36:47,236 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:36:47,652 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:36:48,075 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:36:48,480 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:36:48,685 - INFO - validation batch 1, loss: 0.019, 32/6976 datapoints
2025-03-07 12:36:48,794 - INFO - validation batch 51, loss: 3.582, 1632/6976 datapoints
2025-03-07 12:36:48,907 - INFO - validation batch 101, loss: 0.557, 3232/6976 datapoints
2025-03-07 12:36:49,040 - INFO - validation batch 151, loss: 1.313, 4832/6976 datapoints
2025-03-07 12:36:49,166 - INFO - validation batch 201, loss: 0.839, 6432/6976 datapoints
2025-03-07 12:36:49,206 - INFO - Epoch 254/800 done.
2025-03-07 12:36:49,206 - INFO - Final validation performance:
Loss: 1.262, top-1 acc: 0.897top-5 acc: 0.897
2025-03-07 12:36:49,207 - INFO - Beginning epoch 255/800
2025-03-07 12:36:49,224 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:36:49,626 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:36:49,938 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:36:50,261 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:36:50,563 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:36:50,850 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:36:51,140 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:36:51,437 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:36:51,736 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:36:52,025 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:36:52,309 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:36:52,596 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:36:52,881 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:36:53,179 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:36:53,473 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:36:53,759 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:36:54,055 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:36:54,346 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:36:54,494 - INFO - validation batch 1, loss: 0.020, 32/6976 datapoints
2025-03-07 12:36:54,571 - INFO - validation batch 51, loss: 3.634, 1632/6976 datapoints
2025-03-07 12:36:54,648 - INFO - validation batch 101, loss: 0.566, 3232/6976 datapoints
2025-03-07 12:36:54,726 - INFO - validation batch 151, loss: 1.332, 4832/6976 datapoints
2025-03-07 12:36:54,819 - INFO - validation batch 201, loss: 0.855, 6432/6976 datapoints
2025-03-07 12:36:54,853 - INFO - Epoch 255/800 done.
2025-03-07 12:36:54,853 - INFO - Final validation performance:
Loss: 1.282, top-1 acc: 0.897top-5 acc: 0.897
2025-03-07 12:36:54,854 - INFO - Beginning epoch 256/800
2025-03-07 12:36:54,867 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:36:55,164 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:36:55,450 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:36:55,741 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:36:56,023 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:36:56,309 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:36:56,596 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:36:56,893 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:36:57,185 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:36:57,477 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:36:57,765 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:36:58,055 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:36:58,347 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:36:58,648 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:36:58,982 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:36:59,313 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:36:59,655 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:36:59,946 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:37:00,093 - INFO - validation batch 1, loss: 0.019, 32/6976 datapoints
2025-03-07 12:37:00,168 - INFO - validation batch 51, loss: 3.689, 1632/6976 datapoints
2025-03-07 12:37:00,246 - INFO - validation batch 101, loss: 0.573, 3232/6976 datapoints
2025-03-07 12:37:00,323 - INFO - validation batch 151, loss: 1.348, 4832/6976 datapoints
2025-03-07 12:37:00,399 - INFO - validation batch 201, loss: 0.867, 6432/6976 datapoints
2025-03-07 12:37:00,431 - INFO - Epoch 256/800 done.
2025-03-07 12:37:00,431 - INFO - Final validation performance:
Loss: 1.299, top-1 acc: 0.897top-5 acc: 0.897
2025-03-07 12:37:00,432 - INFO - Beginning epoch 257/800
2025-03-07 12:37:00,443 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:37:00,795 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:37:01,104 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:37:01,416 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:37:01,735 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:37:02,038 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:37:02,375 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:37:02,696 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:37:03,019 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:37:03,318 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:37:03,621 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:37:03,911 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:37:04,206 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:37:04,543 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:37:04,832 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:37:05,130 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:37:05,427 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:37:05,732 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:37:05,876 - INFO - validation batch 1, loss: 0.019, 32/6976 datapoints
2025-03-07 12:37:05,961 - INFO - validation batch 51, loss: 3.748, 1632/6976 datapoints
2025-03-07 12:37:06,045 - INFO - validation batch 101, loss: 0.581, 3232/6976 datapoints
2025-03-07 12:37:06,121 - INFO - validation batch 151, loss: 1.360, 4832/6976 datapoints
2025-03-07 12:37:06,201 - INFO - validation batch 201, loss: 0.872, 6432/6976 datapoints
2025-03-07 12:37:06,232 - INFO - Epoch 257/800 done.
2025-03-07 12:37:06,232 - INFO - Final validation performance:
Loss: 1.316, top-1 acc: 0.897top-5 acc: 0.897
2025-03-07 12:37:06,233 - INFO - Beginning epoch 258/800
2025-03-07 12:37:06,243 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:37:06,554 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:37:06,847 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:37:07,157 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:37:07,463 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:37:07,779 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:37:08,096 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:37:08,420 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:37:08,801 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:37:09,193 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:37:09,591 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:37:09,976 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:37:10,311 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:37:10,709 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:37:11,071 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:37:11,403 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:37:11,707 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:37:12,011 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:37:12,191 - INFO - validation batch 1, loss: 0.017, 32/6976 datapoints
2025-03-07 12:37:12,283 - INFO - validation batch 51, loss: 3.802, 1632/6976 datapoints
2025-03-07 12:37:12,394 - INFO - validation batch 101, loss: 0.589, 3232/6976 datapoints
2025-03-07 12:37:12,526 - INFO - validation batch 151, loss: 1.365, 4832/6976 datapoints
2025-03-07 12:37:12,622 - INFO - validation batch 201, loss: 0.873, 6432/6976 datapoints
2025-03-07 12:37:12,648 - INFO - Epoch 258/800 done.
2025-03-07 12:37:12,649 - INFO - Final validation performance:
Loss: 1.329, top-1 acc: 0.897top-5 acc: 0.897
2025-03-07 12:37:12,649 - INFO - Beginning epoch 259/800
2025-03-07 12:37:12,659 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:37:13,011 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:37:13,370 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:37:13,757 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:37:14,168 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:37:14,614 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:37:14,999 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:37:15,317 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:37:15,640 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:37:15,957 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:37:16,284 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:37:16,623 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:37:16,971 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:37:17,297 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:37:17,611 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:37:17,926 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:37:18,230 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:37:18,547 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:37:18,716 - INFO - validation batch 1, loss: 0.016, 32/6976 datapoints
2025-03-07 12:37:18,809 - INFO - validation batch 51, loss: 3.856, 1632/6976 datapoints
2025-03-07 12:37:18,885 - INFO - validation batch 101, loss: 0.587, 3232/6976 datapoints
2025-03-07 12:37:18,962 - INFO - validation batch 151, loss: 1.373, 4832/6976 datapoints
2025-03-07 12:37:19,044 - INFO - validation batch 201, loss: 0.875, 6432/6976 datapoints
2025-03-07 12:37:19,074 - INFO - Epoch 259/800 done.
2025-03-07 12:37:19,074 - INFO - Final validation performance:
Loss: 1.341, top-1 acc: 0.897top-5 acc: 0.897
2025-03-07 12:37:19,075 - INFO - Beginning epoch 260/800
2025-03-07 12:37:19,084 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:37:19,468 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:37:19,791 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:37:20,147 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:37:20,508 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:37:20,832 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:37:21,231 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:37:21,718 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:37:22,175 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:37:22,624 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:37:23,077 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:37:23,525 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:37:23,972 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:37:24,381 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:37:24,795 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:37:25,222 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:37:25,631 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:37:26,045 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:37:26,269 - INFO - validation batch 1, loss: 0.013, 32/6976 datapoints
2025-03-07 12:37:26,401 - INFO - validation batch 51, loss: 3.890, 1632/6976 datapoints
2025-03-07 12:37:26,547 - INFO - validation batch 101, loss: 0.558, 3232/6976 datapoints
2025-03-07 12:37:26,689 - INFO - validation batch 151, loss: 1.369, 4832/6976 datapoints
2025-03-07 12:37:26,817 - INFO - validation batch 201, loss: 0.883, 6432/6976 datapoints
2025-03-07 12:37:26,870 - INFO - Epoch 260/800 done.
2025-03-07 12:37:26,870 - INFO - Final validation performance:
Loss: 1.343, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:37:26,871 - INFO - Beginning epoch 261/800
2025-03-07 12:37:26,883 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:37:27,247 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:37:27,630 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:37:27,970 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:37:28,303 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:37:28,660 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:37:29,031 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:37:29,457 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:37:29,922 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:37:30,378 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:37:31,085 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:37:31,543 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:37:31,973 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-07 12:37:32,403 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:37:32,842 - INFO - training batch 701, loss: 0.001, 22432/28000 datapoints
2025-03-07 12:37:33,260 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:37:33,665 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:37:34,068 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:37:34,274 - INFO - validation batch 1, loss: 0.013, 32/6976 datapoints
2025-03-07 12:37:34,386 - INFO - validation batch 51, loss: 4.265, 1632/6976 datapoints
2025-03-07 12:37:34,506 - INFO - validation batch 101, loss: 0.481, 3232/6976 datapoints
2025-03-07 12:37:34,628 - INFO - validation batch 151, loss: 1.265, 4832/6976 datapoints
2025-03-07 12:37:34,744 - INFO - validation batch 201, loss: 0.881, 6432/6976 datapoints
2025-03-07 12:37:34,783 - INFO - Epoch 261/800 done.
2025-03-07 12:37:34,783 - INFO - Final validation performance:
Loss: 1.381, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:37:34,784 - INFO - Beginning epoch 262/800
2025-03-07 12:37:34,793 - INFO - training batch 1, loss: 0.001, 32/28000 datapoints
2025-03-07 12:37:35,194 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:37:35,542 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:37:35,855 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:37:36,202 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:37:36,503 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:37:36,804 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:37:37,112 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:37:37,457 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:37:37,753 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:37:38,047 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:37:38,335 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:37:38,630 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:37:38,943 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:37:39,266 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:37:39,619 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:37:39,955 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:37:40,252 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:37:40,397 - INFO - validation batch 1, loss: 0.059, 32/6976 datapoints
2025-03-07 12:37:40,475 - INFO - validation batch 51, loss: 4.340, 1632/6976 datapoints
2025-03-07 12:37:40,548 - INFO - validation batch 101, loss: 0.389, 3232/6976 datapoints
2025-03-07 12:37:40,624 - INFO - validation batch 151, loss: 1.230, 4832/6976 datapoints
2025-03-07 12:37:40,700 - INFO - validation batch 201, loss: 0.925, 6432/6976 datapoints
2025-03-07 12:37:40,727 - INFO - Epoch 262/800 done.
2025-03-07 12:37:40,727 - INFO - Final validation performance:
Loss: 1.389, top-1 acc: 0.895top-5 acc: 0.895
2025-03-07 12:37:40,728 - INFO - Beginning epoch 263/800
2025-03-07 12:37:40,736 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:37:41,035 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:37:41,337 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:37:41,643 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:37:42,003 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:37:42,296 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:37:42,594 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:37:42,899 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:37:43,208 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:37:43,520 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:37:43,818 - INFO - training batch 501, loss: 0.006, 16032/28000 datapoints
2025-03-07 12:37:44,138 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:37:44,466 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:37:44,768 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:37:45,075 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:37:45,396 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:37:45,897 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:37:46,415 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 12:37:46,630 - INFO - validation batch 1, loss: 0.028, 32/6976 datapoints
2025-03-07 12:37:46,802 - INFO - validation batch 51, loss: 4.487, 1632/6976 datapoints
2025-03-07 12:37:46,998 - INFO - validation batch 101, loss: 0.497, 3232/6976 datapoints
2025-03-07 12:37:47,427 - INFO - validation batch 151, loss: 1.199, 4832/6976 datapoints
2025-03-07 12:37:47,795 - INFO - validation batch 201, loss: 0.809, 6432/6976 datapoints
2025-03-07 12:37:47,876 - INFO - Epoch 263/800 done.
2025-03-07 12:37:47,877 - INFO - Final validation performance:
Loss: 1.404, top-1 acc: 0.897top-5 acc: 0.897
2025-03-07 12:37:47,878 - INFO - Beginning epoch 264/800
2025-03-07 12:37:47,891 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:37:48,560 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:37:48,958 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:37:49,320 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:37:49,688 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:37:50,065 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:37:50,458 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:37:50,820 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:37:51,209 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:37:51,612 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:37:52,023 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:37:52,429 - INFO - training batch 551, loss: 0.026, 17632/28000 datapoints
2025-03-07 12:37:52,823 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:37:53,189 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:37:53,679 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:37:54,180 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:37:54,508 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:37:54,870 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:37:55,024 - INFO - validation batch 1, loss: 0.022, 32/6976 datapoints
2025-03-07 12:37:55,106 - INFO - validation batch 51, loss: 4.371, 1632/6976 datapoints
2025-03-07 12:37:55,199 - INFO - validation batch 101, loss: 0.603, 3232/6976 datapoints
2025-03-07 12:37:55,316 - INFO - validation batch 151, loss: 1.100, 4832/6976 datapoints
2025-03-07 12:37:55,436 - INFO - validation batch 201, loss: 0.825, 6432/6976 datapoints
2025-03-07 12:37:55,478 - INFO - Epoch 264/800 done.
2025-03-07 12:37:55,478 - INFO - Final validation performance:
Loss: 1.384, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:37:55,479 - INFO - Beginning epoch 265/800
2025-03-07 12:37:55,493 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:37:55,928 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:37:56,345 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:37:56,743 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:37:57,139 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:37:57,561 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 12:37:57,955 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:37:58,386 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:37:58,746 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:37:59,102 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:37:59,441 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:37:59,763 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:38:00,096 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:38:00,403 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:38:00,717 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:38:01,019 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:38:01,308 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:38:01,603 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 12:38:01,752 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 12:38:01,829 - INFO - validation batch 51, loss: 4.224, 1632/6976 datapoints
2025-03-07 12:38:01,904 - INFO - validation batch 101, loss: 0.167, 3232/6976 datapoints
2025-03-07 12:38:01,983 - INFO - validation batch 151, loss: 1.168, 4832/6976 datapoints
2025-03-07 12:38:02,067 - INFO - validation batch 201, loss: 0.476, 6432/6976 datapoints
2025-03-07 12:38:02,093 - INFO - Epoch 265/800 done.
2025-03-07 12:38:02,093 - INFO - Final validation performance:
Loss: 1.208, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:38:02,094 - INFO - Beginning epoch 266/800
2025-03-07 12:38:02,102 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:38:02,419 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:38:02,717 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:38:03,030 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:38:03,321 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 12:38:03,626 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:38:03,925 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:38:04,264 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:38:04,594 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:38:04,898 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:38:05,214 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:38:05,512 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:38:05,830 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:38:06,133 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:38:06,444 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:38:06,740 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:38:07,092 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:38:07,399 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:38:07,556 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 12:38:07,641 - INFO - validation batch 51, loss: 4.204, 1632/6976 datapoints
2025-03-07 12:38:07,718 - INFO - validation batch 101, loss: 0.178, 3232/6976 datapoints
2025-03-07 12:38:07,798 - INFO - validation batch 151, loss: 1.206, 4832/6976 datapoints
2025-03-07 12:38:07,875 - INFO - validation batch 201, loss: 0.275, 6432/6976 datapoints
2025-03-07 12:38:07,900 - INFO - Epoch 266/800 done.
2025-03-07 12:38:07,900 - INFO - Final validation performance:
Loss: 1.175, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:38:07,900 - INFO - Beginning epoch 267/800
2025-03-07 12:38:07,908 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:38:08,201 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:38:08,503 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:38:08,797 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:38:09,097 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:38:09,388 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:38:09,680 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:38:09,974 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:38:10,293 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:38:10,587 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:38:10,884 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:38:11,167 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:38:11,462 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:38:11,788 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:38:12,092 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:38:12,381 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:38:12,671 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:38:12,961 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:38:13,109 - INFO - validation batch 1, loss: 0.013, 32/6976 datapoints
2025-03-07 12:38:13,187 - INFO - validation batch 51, loss: 4.174, 1632/6976 datapoints
2025-03-07 12:38:13,264 - INFO - validation batch 101, loss: 0.192, 3232/6976 datapoints
2025-03-07 12:38:13,344 - INFO - validation batch 151, loss: 1.216, 4832/6976 datapoints
2025-03-07 12:38:13,421 - INFO - validation batch 201, loss: 0.335, 6432/6976 datapoints
2025-03-07 12:38:13,452 - INFO - Epoch 267/800 done.
2025-03-07 12:38:13,452 - INFO - Final validation performance:
Loss: 1.186, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:38:13,453 - INFO - Beginning epoch 268/800
2025-03-07 12:38:13,471 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:38:13,791 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:38:14,098 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:38:14,400 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:38:14,698 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:38:14,990 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:38:15,280 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:38:15,573 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:38:15,874 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:38:16,164 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:38:16,463 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:38:16,808 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:38:17,104 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:38:17,399 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:38:17,716 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:38:18,009 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:38:18,315 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:38:18,623 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:38:18,778 - INFO - validation batch 1, loss: 0.013, 32/6976 datapoints
2025-03-07 12:38:18,865 - INFO - validation batch 51, loss: 4.164, 1632/6976 datapoints
2025-03-07 12:38:18,957 - INFO - validation batch 101, loss: 0.198, 3232/6976 datapoints
2025-03-07 12:38:19,038 - INFO - validation batch 151, loss: 1.207, 4832/6976 datapoints
2025-03-07 12:38:19,119 - INFO - validation batch 201, loss: 0.348, 6432/6976 datapoints
2025-03-07 12:38:19,146 - INFO - Epoch 268/800 done.
2025-03-07 12:38:19,146 - INFO - Final validation performance:
Loss: 1.186, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:38:19,147 - INFO - Beginning epoch 269/800
2025-03-07 12:38:19,155 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:38:19,487 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:38:19,820 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:38:20,147 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:38:20,454 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:38:20,755 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:38:21,061 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:38:21,365 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:38:21,670 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:38:21,961 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:38:22,252 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:38:22,601 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:38:22,893 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:38:23,180 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:38:23,473 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:38:23,761 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:38:24,046 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:38:24,333 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:38:24,485 - INFO - validation batch 1, loss: 0.013, 32/6976 datapoints
2025-03-07 12:38:24,574 - INFO - validation batch 51, loss: 4.153, 1632/6976 datapoints
2025-03-07 12:38:24,662 - INFO - validation batch 101, loss: 0.203, 3232/6976 datapoints
2025-03-07 12:38:24,745 - INFO - validation batch 151, loss: 1.201, 4832/6976 datapoints
2025-03-07 12:38:24,822 - INFO - validation batch 201, loss: 0.363, 6432/6976 datapoints
2025-03-07 12:38:24,846 - INFO - Epoch 269/800 done.
2025-03-07 12:38:24,847 - INFO - Final validation performance:
Loss: 1.186, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:38:24,847 - INFO - Beginning epoch 270/800
2025-03-07 12:38:24,855 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:38:25,156 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:38:25,458 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:38:25,788 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:38:26,097 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:38:26,400 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:38:26,724 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:38:27,040 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:38:27,342 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:38:27,650 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:38:27,997 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:38:28,302 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:38:28,608 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:38:28,899 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:38:29,201 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:38:29,502 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:38:29,802 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:38:30,120 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:38:30,302 - INFO - validation batch 1, loss: 0.012, 32/6976 datapoints
2025-03-07 12:38:30,378 - INFO - validation batch 51, loss: 4.142, 1632/6976 datapoints
2025-03-07 12:38:30,525 - INFO - validation batch 101, loss: 0.208, 3232/6976 datapoints
2025-03-07 12:38:30,635 - INFO - validation batch 151, loss: 1.198, 4832/6976 datapoints
2025-03-07 12:38:30,745 - INFO - validation batch 201, loss: 0.382, 6432/6976 datapoints
2025-03-07 12:38:30,782 - INFO - Epoch 270/800 done.
2025-03-07 12:38:30,783 - INFO - Final validation performance:
Loss: 1.188, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:38:30,783 - INFO - Beginning epoch 271/800
2025-03-07 12:38:30,793 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:38:31,145 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:38:31,457 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:38:31,781 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:38:32,111 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:38:32,430 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:38:32,741 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:38:33,052 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:38:33,375 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:38:33,680 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:38:33,978 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:38:34,268 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:38:34,575 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:38:34,866 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:38:35,158 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:38:35,490 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:38:35,793 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:38:36,083 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:38:36,237 - INFO - validation batch 1, loss: 0.012, 32/6976 datapoints
2025-03-07 12:38:36,316 - INFO - validation batch 51, loss: 4.127, 1632/6976 datapoints
2025-03-07 12:38:36,397 - INFO - validation batch 101, loss: 0.214, 3232/6976 datapoints
2025-03-07 12:38:36,477 - INFO - validation batch 151, loss: 1.200, 4832/6976 datapoints
2025-03-07 12:38:36,551 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-07 12:38:36,584 - INFO - Epoch 271/800 done.
2025-03-07 12:38:36,584 - INFO - Final validation performance:
Loss: 1.192, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:38:36,585 - INFO - Beginning epoch 272/800
2025-03-07 12:38:36,594 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:38:36,889 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:38:37,196 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:38:37,573 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:38:37,870 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:38:38,170 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:38:38,478 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:38:38,783 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:38:39,086 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:38:39,386 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:38:39,688 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:38:40,010 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:38:40,327 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:38:40,630 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:38:40,931 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:38:41,225 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:38:41,557 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:38:41,861 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:38:42,012 - INFO - validation batch 1, loss: 0.012, 32/6976 datapoints
2025-03-07 12:38:42,090 - INFO - validation batch 51, loss: 4.109, 1632/6976 datapoints
2025-03-07 12:38:42,167 - INFO - validation batch 101, loss: 0.222, 3232/6976 datapoints
2025-03-07 12:38:42,246 - INFO - validation batch 151, loss: 1.208, 4832/6976 datapoints
2025-03-07 12:38:42,325 - INFO - validation batch 201, loss: 0.443, 6432/6976 datapoints
2025-03-07 12:38:42,350 - INFO - Epoch 272/800 done.
2025-03-07 12:38:42,350 - INFO - Final validation performance:
Loss: 1.199, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:38:42,351 - INFO - Beginning epoch 273/800
2025-03-07 12:38:42,359 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:38:42,670 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:38:42,992 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:38:43,304 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:38:43,606 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:38:43,905 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:38:44,218 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:38:44,532 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:38:44,831 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:38:45,125 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:38:45,416 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:38:45,719 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:38:46,014 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:38:46,325 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:38:46,718 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:38:47,018 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:38:47,343 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:38:47,741 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:38:47,927 - INFO - validation batch 1, loss: 0.013, 32/6976 datapoints
2025-03-07 12:38:48,028 - INFO - validation batch 51, loss: 4.086, 1632/6976 datapoints
2025-03-07 12:38:48,126 - INFO - validation batch 101, loss: 0.232, 3232/6976 datapoints
2025-03-07 12:38:48,221 - INFO - validation batch 151, loss: 1.222, 4832/6976 datapoints
2025-03-07 12:38:48,325 - INFO - validation batch 201, loss: 0.488, 6432/6976 datapoints
2025-03-07 12:38:48,362 - INFO - Epoch 273/800 done.
2025-03-07 12:38:48,362 - INFO - Final validation performance:
Loss: 1.208, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:38:48,364 - INFO - Beginning epoch 274/800
2025-03-07 12:38:48,376 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:38:48,731 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:38:49,093 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:38:49,436 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:38:49,797 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:38:50,161 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:38:50,562 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:38:50,936 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:38:51,300 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:38:51,674 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:38:52,056 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:38:52,438 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:38:52,850 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:38:53,240 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:38:53,624 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:38:53,998 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:38:54,328 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:38:54,686 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:38:54,856 - INFO - validation batch 1, loss: 0.014, 32/6976 datapoints
2025-03-07 12:38:54,946 - INFO - validation batch 51, loss: 4.059, 1632/6976 datapoints
2025-03-07 12:38:55,037 - INFO - validation batch 101, loss: 0.244, 3232/6976 datapoints
2025-03-07 12:38:55,139 - INFO - validation batch 151, loss: 1.241, 4832/6976 datapoints
2025-03-07 12:38:55,268 - INFO - validation batch 201, loss: 0.540, 6432/6976 datapoints
2025-03-07 12:38:55,302 - INFO - Epoch 274/800 done.
2025-03-07 12:38:55,302 - INFO - Final validation performance:
Loss: 1.220, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:38:55,302 - INFO - Beginning epoch 275/800
2025-03-07 12:38:55,311 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:38:55,666 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:38:56,042 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:38:56,459 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:38:56,828 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:38:57,325 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:38:57,801 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:38:58,229 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:38:58,629 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:38:59,043 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:38:59,501 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:38:59,939 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:39:00,342 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:39:00,795 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:39:01,153 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:39:01,482 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:39:01,865 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:39:02,174 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:39:02,325 - INFO - validation batch 1, loss: 0.018, 32/6976 datapoints
2025-03-07 12:39:02,401 - INFO - validation batch 51, loss: 4.028, 1632/6976 datapoints
2025-03-07 12:39:02,483 - INFO - validation batch 101, loss: 0.259, 3232/6976 datapoints
2025-03-07 12:39:02,561 - INFO - validation batch 151, loss: 1.263, 4832/6976 datapoints
2025-03-07 12:39:02,642 - INFO - validation batch 201, loss: 0.599, 6432/6976 datapoints
2025-03-07 12:39:02,670 - INFO - Epoch 275/800 done.
2025-03-07 12:39:02,670 - INFO - Final validation performance:
Loss: 1.233, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:39:02,671 - INFO - Beginning epoch 276/800
2025-03-07 12:39:02,679 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:39:02,972 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:39:03,272 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:39:03,582 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:39:03,870 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:39:04,160 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:39:04,462 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:39:04,762 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:39:05,052 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:39:05,340 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:39:05,636 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:39:05,918 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:39:06,212 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:39:06,522 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:39:06,820 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:39:07,105 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:39:07,396 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:39:07,700 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:39:07,845 - INFO - validation batch 1, loss: 0.022, 32/6976 datapoints
2025-03-07 12:39:07,939 - INFO - validation batch 51, loss: 3.997, 1632/6976 datapoints
2025-03-07 12:39:08,026 - INFO - validation batch 101, loss: 0.273, 3232/6976 datapoints
2025-03-07 12:39:08,101 - INFO - validation batch 151, loss: 1.284, 4832/6976 datapoints
2025-03-07 12:39:08,185 - INFO - validation batch 201, loss: 0.658, 6432/6976 datapoints
2025-03-07 12:39:08,215 - INFO - Epoch 276/800 done.
2025-03-07 12:39:08,215 - INFO - Final validation performance:
Loss: 1.247, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:39:08,215 - INFO - Beginning epoch 277/800
2025-03-07 12:39:08,226 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:39:08,544 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:39:08,860 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:39:09,174 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:39:09,478 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:39:09,777 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:39:10,092 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:39:10,403 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:39:10,727 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:39:11,013 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:39:11,303 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:39:11,592 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:39:11,887 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:39:12,169 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:39:12,464 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:39:12,750 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:39:13,036 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:39:13,320 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:39:13,464 - INFO - validation batch 1, loss: 0.028, 32/6976 datapoints
2025-03-07 12:39:13,537 - INFO - validation batch 51, loss: 3.967, 1632/6976 datapoints
2025-03-07 12:39:13,609 - INFO - validation batch 101, loss: 0.281, 3232/6976 datapoints
2025-03-07 12:39:13,682 - INFO - validation batch 151, loss: 1.306, 4832/6976 datapoints
2025-03-07 12:39:13,753 - INFO - validation batch 201, loss: 0.712, 6432/6976 datapoints
2025-03-07 12:39:13,777 - INFO - Epoch 277/800 done.
2025-03-07 12:39:13,778 - INFO - Final validation performance:
Loss: 1.259, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:39:13,778 - INFO - Beginning epoch 278/800
2025-03-07 12:39:13,786 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:39:14,072 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:39:14,371 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:39:14,667 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:39:14,964 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:39:15,254 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:39:15,550 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:39:15,848 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:39:16,147 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:39:16,446 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:39:16,741 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:39:17,036 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:39:17,381 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:39:17,685 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:39:17,986 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:39:18,325 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:39:18,631 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:39:18,990 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:39:19,139 - INFO - validation batch 1, loss: 0.034, 32/6976 datapoints
2025-03-07 12:39:19,217 - INFO - validation batch 51, loss: 3.937, 1632/6976 datapoints
2025-03-07 12:39:19,295 - INFO - validation batch 101, loss: 0.281, 3232/6976 datapoints
2025-03-07 12:39:19,379 - INFO - validation batch 151, loss: 1.323, 4832/6976 datapoints
2025-03-07 12:39:19,462 - INFO - validation batch 201, loss: 0.757, 6432/6976 datapoints
2025-03-07 12:39:19,489 - INFO - Epoch 278/800 done.
2025-03-07 12:39:19,489 - INFO - Final validation performance:
Loss: 1.266, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:39:19,490 - INFO - Beginning epoch 279/800
2025-03-07 12:39:19,499 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:39:19,890 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:39:20,267 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:39:20,638 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:39:20,986 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:39:21,353 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:39:21,679 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:39:22,000 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:39:22,302 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:39:22,612 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:39:22,910 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:39:23,202 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:39:23,548 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:39:23,836 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:39:24,131 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:39:24,430 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:39:24,724 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:39:25,015 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:39:25,158 - INFO - validation batch 1, loss: 0.040, 32/6976 datapoints
2025-03-07 12:39:25,235 - INFO - validation batch 51, loss: 3.902, 1632/6976 datapoints
2025-03-07 12:39:25,309 - INFO - validation batch 101, loss: 0.281, 3232/6976 datapoints
2025-03-07 12:39:25,385 - INFO - validation batch 151, loss: 1.336, 4832/6976 datapoints
2025-03-07 12:39:25,462 - INFO - validation batch 201, loss: 0.801, 6432/6976 datapoints
2025-03-07 12:39:25,490 - INFO - Epoch 279/800 done.
2025-03-07 12:39:25,490 - INFO - Final validation performance:
Loss: 1.272, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:39:25,491 - INFO - Beginning epoch 280/800
2025-03-07 12:39:25,498 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:39:25,795 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:39:26,096 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:39:26,459 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:39:26,787 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:39:27,097 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:39:27,407 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:39:27,726 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:39:28,037 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:39:28,343 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:39:28,647 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:39:28,945 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:39:29,246 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:39:29,542 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:39:29,838 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:39:30,129 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:39:30,430 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:39:30,806 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:39:30,978 - INFO - validation batch 1, loss: 0.047, 32/6976 datapoints
2025-03-07 12:39:31,055 - INFO - validation batch 51, loss: 3.869, 1632/6976 datapoints
2025-03-07 12:39:31,132 - INFO - validation batch 101, loss: 0.286, 3232/6976 datapoints
2025-03-07 12:39:31,208 - INFO - validation batch 151, loss: 1.343, 4832/6976 datapoints
2025-03-07 12:39:31,289 - INFO - validation batch 201, loss: 0.842, 6432/6976 datapoints
2025-03-07 12:39:31,315 - INFO - Epoch 280/800 done.
2025-03-07 12:39:31,316 - INFO - Final validation performance:
Loss: 1.277, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:39:31,317 - INFO - Beginning epoch 281/800
2025-03-07 12:39:31,325 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:39:31,628 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:39:31,943 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:39:32,247 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:39:32,548 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:39:32,844 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:39:33,147 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:39:33,455 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:39:33,754 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:39:34,056 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:39:34,359 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:39:34,666 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:39:35,021 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:39:35,321 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:39:35,637 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:39:35,983 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:39:36,292 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:39:36,630 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:39:36,783 - INFO - validation batch 1, loss: 0.050, 32/6976 datapoints
2025-03-07 12:39:36,861 - INFO - validation batch 51, loss: 3.854, 1632/6976 datapoints
2025-03-07 12:39:36,940 - INFO - validation batch 101, loss: 0.297, 3232/6976 datapoints
2025-03-07 12:39:37,017 - INFO - validation batch 151, loss: 1.344, 4832/6976 datapoints
2025-03-07 12:39:37,097 - INFO - validation batch 201, loss: 0.861, 6432/6976 datapoints
2025-03-07 12:39:37,125 - INFO - Epoch 281/800 done.
2025-03-07 12:39:37,125 - INFO - Final validation performance:
Loss: 1.281, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:39:37,125 - INFO - Beginning epoch 282/800
2025-03-07 12:39:37,133 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:39:37,446 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:39:37,759 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:39:38,066 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:39:38,358 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:39:38,734 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:39:39,036 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:39:39,339 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:39:39,642 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:39:39,936 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:39:40,223 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:39:40,529 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:39:40,829 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:39:41,155 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:39:41,445 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:39:41,739 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:39:42,028 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:39:42,315 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:39:42,461 - INFO - validation batch 1, loss: 0.048, 32/6976 datapoints
2025-03-07 12:39:42,529 - INFO - validation batch 51, loss: 3.860, 1632/6976 datapoints
2025-03-07 12:39:42,602 - INFO - validation batch 101, loss: 0.314, 3232/6976 datapoints
2025-03-07 12:39:42,676 - INFO - validation batch 151, loss: 1.341, 4832/6976 datapoints
2025-03-07 12:39:42,750 - INFO - validation batch 201, loss: 0.877, 6432/6976 datapoints
2025-03-07 12:39:42,774 - INFO - Epoch 282/800 done.
2025-03-07 12:39:42,775 - INFO - Final validation performance:
Loss: 1.288, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:39:42,775 - INFO - Beginning epoch 283/800
2025-03-07 12:39:42,783 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:39:43,095 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:39:43,394 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:39:43,771 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:39:44,074 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:39:44,411 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:39:44,806 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:39:45,230 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:39:45,637 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:39:46,046 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:39:46,497 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:39:46,933 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:39:47,385 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:39:47,796 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:39:48,182 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:39:48,610 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:39:49,008 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:39:49,339 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:39:49,506 - INFO - validation batch 1, loss: 0.044, 32/6976 datapoints
2025-03-07 12:39:49,603 - INFO - validation batch 51, loss: 3.872, 1632/6976 datapoints
2025-03-07 12:39:49,691 - INFO - validation batch 101, loss: 0.332, 3232/6976 datapoints
2025-03-07 12:39:49,777 - INFO - validation batch 151, loss: 1.340, 4832/6976 datapoints
2025-03-07 12:39:49,865 - INFO - validation batch 201, loss: 0.882, 6432/6976 datapoints
2025-03-07 12:39:49,903 - INFO - Epoch 283/800 done.
2025-03-07 12:39:49,903 - INFO - Final validation performance:
Loss: 1.294, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:39:49,904 - INFO - Beginning epoch 284/800
2025-03-07 12:39:49,913 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:39:50,286 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:39:50,646 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:39:51,008 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:39:51,373 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:39:51,737 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:39:52,244 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:39:52,617 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:39:52,947 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:39:53,282 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:39:53,597 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:39:53,913 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:39:54,297 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:39:54,641 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:39:54,987 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:39:55,328 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:39:55,673 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:39:56,023 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:39:56,198 - INFO - validation batch 1, loss: 0.041, 32/6976 datapoints
2025-03-07 12:39:56,289 - INFO - validation batch 51, loss: 3.877, 1632/6976 datapoints
2025-03-07 12:39:56,385 - INFO - validation batch 101, loss: 0.346, 3232/6976 datapoints
2025-03-07 12:39:56,505 - INFO - validation batch 151, loss: 1.342, 4832/6976 datapoints
2025-03-07 12:39:56,611 - INFO - validation batch 201, loss: 0.893, 6432/6976 datapoints
2025-03-07 12:39:56,656 - INFO - Epoch 284/800 done.
2025-03-07 12:39:56,656 - INFO - Final validation performance:
Loss: 1.300, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:39:56,656 - INFO - Beginning epoch 285/800
2025-03-07 12:39:56,669 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:39:57,041 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:39:57,407 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:39:57,791 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:39:58,190 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:39:58,507 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:39:58,822 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:39:59,131 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:39:59,448 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:39:59,745 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:40:00,043 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:40:00,334 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:40:00,641 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:40:00,930 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:40:01,235 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:40:01,549 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:40:01,859 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:40:02,150 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:40:02,292 - INFO - validation batch 1, loss: 0.040, 32/6976 datapoints
2025-03-07 12:40:02,369 - INFO - validation batch 51, loss: 3.873, 1632/6976 datapoints
2025-03-07 12:40:02,461 - INFO - validation batch 101, loss: 0.364, 3232/6976 datapoints
2025-03-07 12:40:02,540 - INFO - validation batch 151, loss: 1.344, 4832/6976 datapoints
2025-03-07 12:40:02,613 - INFO - validation batch 201, loss: 0.891, 6432/6976 datapoints
2025-03-07 12:40:02,641 - INFO - Epoch 285/800 done.
2025-03-07 12:40:02,641 - INFO - Final validation performance:
Loss: 1.303, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:40:02,641 - INFO - Beginning epoch 286/800
2025-03-07 12:40:02,649 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:40:02,950 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:40:03,254 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:40:03,607 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:40:03,945 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:40:04,246 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:40:04,602 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:40:04,946 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:40:05,304 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:40:05,655 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:40:06,023 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:40:06,380 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:40:06,740 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:40:07,077 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:40:07,402 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:40:07,747 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:40:08,093 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:40:08,454 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:40:08,657 - INFO - validation batch 1, loss: 0.041, 32/6976 datapoints
2025-03-07 12:40:08,749 - INFO - validation batch 51, loss: 3.882, 1632/6976 datapoints
2025-03-07 12:40:08,868 - INFO - validation batch 101, loss: 0.393, 3232/6976 datapoints
2025-03-07 12:40:08,982 - INFO - validation batch 151, loss: 1.359, 4832/6976 datapoints
2025-03-07 12:40:09,095 - INFO - validation batch 201, loss: 0.900, 6432/6976 datapoints
2025-03-07 12:40:09,130 - INFO - Epoch 286/800 done.
2025-03-07 12:40:09,130 - INFO - Final validation performance:
Loss: 1.315, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:40:09,131 - INFO - Beginning epoch 287/800
2025-03-07 12:40:09,141 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:40:09,512 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:40:09,941 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:40:10,409 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:40:10,835 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:40:11,175 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:40:11,534 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:40:11,888 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:40:12,217 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:40:12,603 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:40:12,918 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:40:13,224 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:40:13,531 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:40:13,835 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:40:14,160 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:40:14,463 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:40:14,778 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:40:15,076 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:40:15,231 - INFO - validation batch 1, loss: 0.040, 32/6976 datapoints
2025-03-07 12:40:15,310 - INFO - validation batch 51, loss: 3.896, 1632/6976 datapoints
2025-03-07 12:40:15,388 - INFO - validation batch 101, loss: 0.424, 3232/6976 datapoints
2025-03-07 12:40:15,465 - INFO - validation batch 151, loss: 1.378, 4832/6976 datapoints
2025-03-07 12:40:15,547 - INFO - validation batch 201, loss: 0.909, 6432/6976 datapoints
2025-03-07 12:40:15,578 - INFO - Epoch 287/800 done.
2025-03-07 12:40:15,579 - INFO - Final validation performance:
Loss: 1.329, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:40:15,579 - INFO - Beginning epoch 288/800
2025-03-07 12:40:15,588 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:40:15,912 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:40:16,251 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:40:16,589 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:40:16,912 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:40:17,235 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:40:17,562 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:40:17,885 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:40:18,225 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:40:18,595 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:40:18,913 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:40:19,257 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:40:19,600 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:40:19,907 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:40:20,229 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:40:20,562 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:40:20,924 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:40:21,264 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:40:21,443 - INFO - validation batch 1, loss: 0.033, 32/6976 datapoints
2025-03-07 12:40:21,566 - INFO - validation batch 51, loss: 3.929, 1632/6976 datapoints
2025-03-07 12:40:21,665 - INFO - validation batch 101, loss: 0.463, 3232/6976 datapoints
2025-03-07 12:40:21,792 - INFO - validation batch 151, loss: 1.394, 4832/6976 datapoints
2025-03-07 12:40:21,882 - INFO - validation batch 201, loss: 0.919, 6432/6976 datapoints
2025-03-07 12:40:21,910 - INFO - Epoch 288/800 done.
2025-03-07 12:40:21,911 - INFO - Final validation performance:
Loss: 1.348, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:40:21,911 - INFO - Beginning epoch 289/800
2025-03-07 12:40:21,922 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:40:22,314 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:40:22,761 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:40:23,314 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:40:23,672 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:40:24,017 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:40:24,346 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:40:24,722 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:40:25,104 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:40:25,482 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:40:25,878 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:40:26,243 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:40:26,585 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:40:26,954 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:40:27,306 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:40:27,676 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:40:27,992 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:40:28,330 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:40:28,504 - INFO - validation batch 1, loss: 0.026, 32/6976 datapoints
2025-03-07 12:40:28,591 - INFO - validation batch 51, loss: 3.974, 1632/6976 datapoints
2025-03-07 12:40:28,682 - INFO - validation batch 101, loss: 0.483, 3232/6976 datapoints
2025-03-07 12:40:28,781 - INFO - validation batch 151, loss: 1.403, 4832/6976 datapoints
2025-03-07 12:40:28,872 - INFO - validation batch 201, loss: 0.916, 6432/6976 datapoints
2025-03-07 12:40:28,902 - INFO - Epoch 289/800 done.
2025-03-07 12:40:28,902 - INFO - Final validation performance:
Loss: 1.361, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:40:28,903 - INFO - Beginning epoch 290/800
2025-03-07 12:40:28,911 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:40:29,242 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:40:29,599 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:40:29,980 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:40:30,291 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:40:30,663 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:40:30,974 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:40:31,320 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:40:31,746 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:40:32,181 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:40:32,524 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:40:32,853 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:40:33,251 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:40:33,594 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:40:33,930 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:40:34,310 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:40:34,785 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:40:35,127 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:40:35,335 - INFO - validation batch 1, loss: 0.021, 32/6976 datapoints
2025-03-07 12:40:35,445 - INFO - validation batch 51, loss: 4.022, 1632/6976 datapoints
2025-03-07 12:40:35,564 - INFO - validation batch 101, loss: 0.507, 3232/6976 datapoints
2025-03-07 12:40:35,691 - INFO - validation batch 151, loss: 1.423, 4832/6976 datapoints
2025-03-07 12:40:35,805 - INFO - validation batch 201, loss: 0.921, 6432/6976 datapoints
2025-03-07 12:40:35,842 - INFO - Epoch 290/800 done.
2025-03-07 12:40:35,842 - INFO - Final validation performance:
Loss: 1.379, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:40:35,843 - INFO - Beginning epoch 291/800
2025-03-07 12:40:35,852 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:40:36,235 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:40:36,574 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:40:36,907 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:40:37,282 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:40:37,687 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:40:38,049 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:40:38,447 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:40:38,864 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:40:39,222 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:40:39,572 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:40:39,908 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:40:40,358 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:40:40,944 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:40:41,493 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:40:42,004 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:40:42,414 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:40:42,810 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:40:42,994 - INFO - validation batch 1, loss: 0.016, 32/6976 datapoints
2025-03-07 12:40:43,100 - INFO - validation batch 51, loss: 4.076, 1632/6976 datapoints
2025-03-07 12:40:43,200 - INFO - validation batch 101, loss: 0.521, 3232/6976 datapoints
2025-03-07 12:40:43,305 - INFO - validation batch 151, loss: 1.438, 4832/6976 datapoints
2025-03-07 12:40:43,401 - INFO - validation batch 201, loss: 0.922, 6432/6976 datapoints
2025-03-07 12:40:43,432 - INFO - Epoch 291/800 done.
2025-03-07 12:40:43,432 - INFO - Final validation performance:
Loss: 1.395, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:40:43,433 - INFO - Beginning epoch 292/800
2025-03-07 12:40:43,443 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:40:43,835 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:40:44,209 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:40:44,588 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:40:44,944 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:40:45,280 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:40:45,665 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:40:46,104 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:40:46,464 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:40:46,793 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:40:47,174 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:40:47,511 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:40:47,906 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:40:48,255 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:40:48,583 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:40:48,948 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:40:49,288 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:40:49,665 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:40:49,888 - INFO - validation batch 1, loss: 0.014, 32/6976 datapoints
2025-03-07 12:40:49,989 - INFO - validation batch 51, loss: 4.119, 1632/6976 datapoints
2025-03-07 12:40:50,121 - INFO - validation batch 101, loss: 0.537, 3232/6976 datapoints
2025-03-07 12:40:50,334 - INFO - validation batch 151, loss: 1.463, 4832/6976 datapoints
2025-03-07 12:40:50,483 - INFO - validation batch 201, loss: 0.948, 6432/6976 datapoints
2025-03-07 12:40:50,534 - INFO - Epoch 292/800 done.
2025-03-07 12:40:50,534 - INFO - Final validation performance:
Loss: 1.416, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:40:50,535 - INFO - Beginning epoch 293/800
2025-03-07 12:40:50,548 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:40:51,150 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:40:52,098 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:40:52,596 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:40:53,359 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:40:53,958 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:40:54,588 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:40:55,262 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:40:55,719 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:40:56,140 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:40:56,582 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:40:56,925 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:40:57,335 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:40:57,724 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:40:58,162 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:40:58,504 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:40:58,816 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:40:59,129 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:40:59,291 - INFO - validation batch 1, loss: 0.014, 32/6976 datapoints
2025-03-07 12:40:59,377 - INFO - validation batch 51, loss: 4.147, 1632/6976 datapoints
2025-03-07 12:40:59,459 - INFO - validation batch 101, loss: 0.555, 3232/6976 datapoints
2025-03-07 12:40:59,537 - INFO - validation batch 151, loss: 1.480, 4832/6976 datapoints
2025-03-07 12:40:59,629 - INFO - validation batch 201, loss: 0.962, 6432/6976 datapoints
2025-03-07 12:40:59,669 - INFO - Epoch 293/800 done.
2025-03-07 12:40:59,670 - INFO - Final validation performance:
Loss: 1.432, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:40:59,672 - INFO - Beginning epoch 294/800
2025-03-07 12:40:59,682 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:41:00,062 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:41:00,415 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:41:00,760 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:41:01,114 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:41:01,525 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:41:01,927 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:41:02,527 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:41:02,962 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:41:03,392 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:41:03,856 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:41:04,234 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:41:04,675 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:41:05,091 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:41:05,494 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:41:05,997 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:41:06,619 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:41:07,062 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:41:07,222 - INFO - validation batch 1, loss: 0.014, 32/6976 datapoints
2025-03-07 12:41:07,306 - INFO - validation batch 51, loss: 4.183, 1632/6976 datapoints
2025-03-07 12:41:07,399 - INFO - validation batch 101, loss: 0.560, 3232/6976 datapoints
2025-03-07 12:41:07,527 - INFO - validation batch 151, loss: 1.493, 4832/6976 datapoints
2025-03-07 12:41:07,639 - INFO - validation batch 201, loss: 0.969, 6432/6976 datapoints
2025-03-07 12:41:07,680 - INFO - Epoch 294/800 done.
2025-03-07 12:41:07,680 - INFO - Final validation performance:
Loss: 1.444, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:41:07,681 - INFO - Beginning epoch 295/800
2025-03-07 12:41:07,691 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:41:08,207 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:41:08,618 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:41:08,988 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:41:09,346 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:41:09,676 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:41:09,993 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:41:10,301 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:41:10,666 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:41:11,030 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:41:11,332 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:41:11,670 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:41:11,980 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:41:12,310 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:41:12,620 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:41:12,910 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:41:13,203 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:41:13,518 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:41:13,672 - INFO - validation batch 1, loss: 0.015, 32/6976 datapoints
2025-03-07 12:41:13,754 - INFO - validation batch 51, loss: 4.234, 1632/6976 datapoints
2025-03-07 12:41:13,833 - INFO - validation batch 101, loss: 0.574, 3232/6976 datapoints
2025-03-07 12:41:13,914 - INFO - validation batch 151, loss: 1.518, 4832/6976 datapoints
2025-03-07 12:41:14,010 - INFO - validation batch 201, loss: 0.979, 6432/6976 datapoints
2025-03-07 12:41:14,041 - INFO - Epoch 295/800 done.
2025-03-07 12:41:14,041 - INFO - Final validation performance:
Loss: 1.464, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:41:14,042 - INFO - Beginning epoch 296/800
2025-03-07 12:41:14,050 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:41:14,383 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:41:14,737 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:41:15,176 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:41:15,516 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:41:15,858 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:41:16,182 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:41:16,564 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:41:16,922 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:41:17,257 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:41:17,597 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:41:17,960 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:41:18,289 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:41:18,612 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:41:18,960 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:41:19,272 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:41:19,576 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:41:19,963 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:41:20,118 - INFO - validation batch 1, loss: 0.012, 32/6976 datapoints
2025-03-07 12:41:20,196 - INFO - validation batch 51, loss: 4.290, 1632/6976 datapoints
2025-03-07 12:41:20,275 - INFO - validation batch 101, loss: 0.593, 3232/6976 datapoints
2025-03-07 12:41:20,351 - INFO - validation batch 151, loss: 1.529, 4832/6976 datapoints
2025-03-07 12:41:20,435 - INFO - validation batch 201, loss: 0.996, 6432/6976 datapoints
2025-03-07 12:41:20,475 - INFO - Epoch 296/800 done.
2025-03-07 12:41:20,475 - INFO - Final validation performance:
Loss: 1.484, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:41:20,476 - INFO - Beginning epoch 297/800
2025-03-07 12:41:20,490 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:41:20,869 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:41:21,197 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:41:21,523 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:41:21,857 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:41:22,205 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:41:22,585 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:41:22,949 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:41:23,342 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:41:23,734 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:41:24,091 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:41:24,417 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:41:24,757 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:41:25,072 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:41:25,385 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:41:25,709 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:41:26,036 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:41:26,352 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:41:26,510 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 12:41:26,588 - INFO - validation batch 51, loss: 4.352, 1632/6976 datapoints
2025-03-07 12:41:26,667 - INFO - validation batch 101, loss: 0.608, 3232/6976 datapoints
2025-03-07 12:41:26,741 - INFO - validation batch 151, loss: 1.539, 4832/6976 datapoints
2025-03-07 12:41:26,817 - INFO - validation batch 201, loss: 0.981, 6432/6976 datapoints
2025-03-07 12:41:26,845 - INFO - Epoch 297/800 done.
2025-03-07 12:41:26,845 - INFO - Final validation performance:
Loss: 1.498, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:41:26,846 - INFO - Beginning epoch 298/800
2025-03-07 12:41:26,855 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:41:27,181 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:41:27,506 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:41:27,828 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:41:28,141 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:41:28,475 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:41:28,954 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:41:29,369 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:41:29,871 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:41:30,315 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:41:30,737 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:41:31,101 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:41:31,454 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:41:31,793 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:41:32,120 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:41:32,433 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:41:32,824 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:41:33,152 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:41:33,305 - INFO - validation batch 1, loss: 0.009, 32/6976 datapoints
2025-03-07 12:41:33,381 - INFO - validation batch 51, loss: 4.340, 1632/6976 datapoints
2025-03-07 12:41:33,453 - INFO - validation batch 101, loss: 0.614, 3232/6976 datapoints
2025-03-07 12:41:33,528 - INFO - validation batch 151, loss: 1.593, 4832/6976 datapoints
2025-03-07 12:41:33,602 - INFO - validation batch 201, loss: 0.977, 6432/6976 datapoints
2025-03-07 12:41:33,629 - INFO - Epoch 298/800 done.
2025-03-07 12:41:33,629 - INFO - Final validation performance:
Loss: 1.507, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:41:33,630 - INFO - Beginning epoch 299/800
2025-03-07 12:41:33,638 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:41:33,959 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:41:34,293 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:41:34,619 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:41:34,986 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:41:35,315 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:41:35,643 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:41:35,965 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:41:36,321 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:41:36,653 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:41:36,980 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:41:37,302 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:41:37,634 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:41:37,982 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:41:38,308 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:41:38,658 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:41:38,975 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:41:39,311 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:41:39,470 - INFO - validation batch 1, loss: 0.013, 32/6976 datapoints
2025-03-07 12:41:39,547 - INFO - validation batch 51, loss: 4.373, 1632/6976 datapoints
2025-03-07 12:41:39,621 - INFO - validation batch 101, loss: 0.571, 3232/6976 datapoints
2025-03-07 12:41:39,696 - INFO - validation batch 151, loss: 1.542, 4832/6976 datapoints
2025-03-07 12:41:39,773 - INFO - validation batch 201, loss: 1.030, 6432/6976 datapoints
2025-03-07 12:41:39,798 - INFO - Epoch 299/800 done.
2025-03-07 12:41:39,798 - INFO - Final validation performance:
Loss: 1.506, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:41:39,799 - INFO - Beginning epoch 300/800
2025-03-07 12:41:39,807 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:41:40,137 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:41:40,474 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:41:40,797 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:41:41,123 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:41:41,455 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:41:41,778 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:41:42,107 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:41:42,450 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:41:42,823 - INFO - training batch 451, loss: 0.001, 14432/28000 datapoints
2025-03-07 12:41:43,160 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:41:43,486 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:41:43,818 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:41:44,133 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:41:44,469 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:41:44,783 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:41:45,085 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:41:45,406 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:41:45,562 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:41:45,638 - INFO - validation batch 51, loss: 4.934, 1632/6976 datapoints
2025-03-07 12:41:45,714 - INFO - validation batch 101, loss: 0.954, 3232/6976 datapoints
2025-03-07 12:41:45,787 - INFO - validation batch 151, loss: 1.418, 4832/6976 datapoints
2025-03-07 12:41:45,860 - INFO - validation batch 201, loss: 0.805, 6432/6976 datapoints
2025-03-07 12:41:45,889 - INFO - Epoch 300/800 done.
2025-03-07 12:41:45,889 - INFO - Final validation performance:
Loss: 1.623, top-1 acc: 0.889top-5 acc: 0.889
2025-03-07 12:41:45,890 - INFO - Beginning epoch 301/800
2025-03-07 12:41:45,898 - INFO - training batch 1, loss: 0.002, 32/28000 datapoints
2025-03-07 12:41:46,223 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:41:46,551 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:41:46,874 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:41:47,190 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:41:47,524 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:41:47,870 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:41:48,187 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:41:48,522 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:41:48,845 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:41:49,163 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:41:49,479 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:41:49,806 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:41:50,114 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:41:50,436 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:41:50,747 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:41:51,072 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:41:51,401 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:41:51,558 - INFO - validation batch 1, loss: 0.017, 32/6976 datapoints
2025-03-07 12:41:51,633 - INFO - validation batch 51, loss: 4.604, 1632/6976 datapoints
2025-03-07 12:41:51,710 - INFO - validation batch 101, loss: 0.365, 3232/6976 datapoints
2025-03-07 12:41:51,785 - INFO - validation batch 151, loss: 1.317, 4832/6976 datapoints
2025-03-07 12:41:51,859 - INFO - validation batch 201, loss: 0.466, 6432/6976 datapoints
2025-03-07 12:41:51,889 - INFO - Epoch 301/800 done.
2025-03-07 12:41:51,889 - INFO - Final validation performance:
Loss: 1.354, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:41:51,890 - INFO - Beginning epoch 302/800
2025-03-07 12:41:51,898 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:41:52,217 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:41:52,540 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:41:52,880 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:41:53,183 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:41:53,525 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:41:53,853 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:41:54,178 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:41:54,509 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:41:54,823 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:41:55,142 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:41:55,449 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:41:55,766 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:41:56,078 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:41:56,391 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:41:56,695 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:41:56,997 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:41:57,320 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:41:57,473 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 12:41:57,548 - INFO - validation batch 51, loss: 4.398, 1632/6976 datapoints
2025-03-07 12:41:57,625 - INFO - validation batch 101, loss: 0.451, 3232/6976 datapoints
2025-03-07 12:41:57,707 - INFO - validation batch 151, loss: 1.580, 4832/6976 datapoints
2025-03-07 12:41:57,782 - INFO - validation batch 201, loss: 0.434, 6432/6976 datapoints
2025-03-07 12:41:57,805 - INFO - Epoch 302/800 done.
2025-03-07 12:41:57,806 - INFO - Final validation performance:
Loss: 1.374, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:41:57,806 - INFO - Beginning epoch 303/800
2025-03-07 12:41:57,818 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:41:58,189 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:41:58,535 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:41:58,869 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:41:59,189 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:41:59,525 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:41:59,853 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:42:00,169 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:42:00,515 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:42:00,830 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:42:01,150 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:42:01,462 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:42:01,788 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:42:02,138 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:42:02,495 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:42:02,858 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:42:03,178 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:42:03,515 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:42:03,679 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 12:42:03,765 - INFO - validation batch 51, loss: 4.426, 1632/6976 datapoints
2025-03-07 12:42:03,848 - INFO - validation batch 101, loss: 0.454, 3232/6976 datapoints
2025-03-07 12:42:03,948 - INFO - validation batch 151, loss: 1.548, 4832/6976 datapoints
2025-03-07 12:42:04,052 - INFO - validation batch 201, loss: 0.466, 6432/6976 datapoints
2025-03-07 12:42:04,088 - INFO - Epoch 303/800 done.
2025-03-07 12:42:04,088 - INFO - Final validation performance:
Loss: 1.380, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:42:04,089 - INFO - Beginning epoch 304/800
2025-03-07 12:42:04,098 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:42:04,427 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:42:04,782 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:42:05,106 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:42:05,425 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:42:05,760 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:42:06,101 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:42:06,519 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:42:06,877 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:42:07,205 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:42:07,532 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:42:07,913 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:42:08,263 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:42:08,596 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:42:08,935 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:42:09,262 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:42:09,583 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:42:09,927 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:42:10,083 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 12:42:10,161 - INFO - validation batch 51, loss: 4.424, 1632/6976 datapoints
2025-03-07 12:42:10,241 - INFO - validation batch 101, loss: 0.449, 3232/6976 datapoints
2025-03-07 12:42:10,318 - INFO - validation batch 151, loss: 1.545, 4832/6976 datapoints
2025-03-07 12:42:10,396 - INFO - validation batch 201, loss: 0.474, 6432/6976 datapoints
2025-03-07 12:42:10,424 - INFO - Epoch 304/800 done.
2025-03-07 12:42:10,424 - INFO - Final validation performance:
Loss: 1.379, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:42:10,425 - INFO - Beginning epoch 305/800
2025-03-07 12:42:10,433 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:42:10,759 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:42:11,083 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:42:11,404 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:42:11,729 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:42:12,060 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:42:12,538 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:42:12,871 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:42:13,409 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:42:13,786 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:42:14,215 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:42:14,638 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:42:15,104 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:42:15,526 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:42:15,937 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:42:16,311 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:42:16,689 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:42:17,079 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:42:17,252 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 12:42:17,342 - INFO - validation batch 51, loss: 4.428, 1632/6976 datapoints
2025-03-07 12:42:17,426 - INFO - validation batch 101, loss: 0.445, 3232/6976 datapoints
2025-03-07 12:42:17,512 - INFO - validation batch 151, loss: 1.538, 4832/6976 datapoints
2025-03-07 12:42:17,597 - INFO - validation batch 201, loss: 0.478, 6432/6976 datapoints
2025-03-07 12:42:17,630 - INFO - Epoch 305/800 done.
2025-03-07 12:42:17,630 - INFO - Final validation performance:
Loss: 1.379, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:42:17,631 - INFO - Beginning epoch 306/800
2025-03-07 12:42:17,641 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:42:17,976 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:42:18,310 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:42:18,639 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:42:19,001 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:42:19,375 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:42:19,786 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:42:20,200 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:42:20,658 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:42:21,094 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:42:21,535 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:42:21,933 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:42:22,307 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:42:22,664 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:42:23,027 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:42:23,373 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:42:23,689 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:42:24,032 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:42:24,217 - INFO - validation batch 1, loss: 0.007, 32/6976 datapoints
2025-03-07 12:42:24,309 - INFO - validation batch 51, loss: 4.434, 1632/6976 datapoints
2025-03-07 12:42:24,391 - INFO - validation batch 101, loss: 0.439, 3232/6976 datapoints
2025-03-07 12:42:24,473 - INFO - validation batch 151, loss: 1.530, 4832/6976 datapoints
2025-03-07 12:42:24,558 - INFO - validation batch 201, loss: 0.481, 6432/6976 datapoints
2025-03-07 12:42:24,590 - INFO - Epoch 306/800 done.
2025-03-07 12:42:24,590 - INFO - Final validation performance:
Loss: 1.378, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:42:24,591 - INFO - Beginning epoch 307/800
2025-03-07 12:42:24,600 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:42:24,925 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:42:25,256 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:42:25,645 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:42:26,019 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:42:26,444 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:42:26,863 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:42:27,253 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:42:27,657 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:42:28,037 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:42:28,398 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:42:28,741 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:42:29,111 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:42:29,501 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:42:29,883 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:42:30,234 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:42:30,736 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:42:31,385 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:42:31,554 - INFO - validation batch 1, loss: 0.008, 32/6976 datapoints
2025-03-07 12:42:31,637 - INFO - validation batch 51, loss: 4.441, 1632/6976 datapoints
2025-03-07 12:42:31,725 - INFO - validation batch 101, loss: 0.433, 3232/6976 datapoints
2025-03-07 12:42:31,810 - INFO - validation batch 151, loss: 1.522, 4832/6976 datapoints
2025-03-07 12:42:31,893 - INFO - validation batch 201, loss: 0.484, 6432/6976 datapoints
2025-03-07 12:42:31,922 - INFO - Epoch 307/800 done.
2025-03-07 12:42:31,922 - INFO - Final validation performance:
Loss: 1.378, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:42:31,923 - INFO - Beginning epoch 308/800
2025-03-07 12:42:31,935 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:42:32,312 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:42:32,646 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:42:32,990 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:42:33,336 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:42:33,678 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:42:34,001 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:42:34,335 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:42:34,680 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:42:34,995 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:42:35,322 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:42:35,674 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:42:36,413 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:42:36,778 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:42:37,106 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:42:37,431 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:42:37,771 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:42:38,114 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:42:38,279 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 12:42:38,359 - INFO - validation batch 51, loss: 4.448, 1632/6976 datapoints
2025-03-07 12:42:38,437 - INFO - validation batch 101, loss: 0.425, 3232/6976 datapoints
2025-03-07 12:42:38,521 - INFO - validation batch 151, loss: 1.516, 4832/6976 datapoints
2025-03-07 12:42:38,602 - INFO - validation batch 201, loss: 0.489, 6432/6976 datapoints
2025-03-07 12:42:38,632 - INFO - Epoch 308/800 done.
2025-03-07 12:42:38,632 - INFO - Final validation performance:
Loss: 1.377, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:42:38,633 - INFO - Beginning epoch 309/800
2025-03-07 12:42:38,641 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:42:38,983 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:42:39,327 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:42:39,648 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:42:39,988 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:42:40,323 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:42:40,669 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:42:41,009 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:42:41,357 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:42:41,690 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:42:42,007 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:42:42,332 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:42:42,660 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:42:42,985 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:42:43,339 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:42:43,661 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:42:43,975 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:42:44,300 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:42:44,533 - INFO - validation batch 1, loss: 0.012, 32/6976 datapoints
2025-03-07 12:42:44,619 - INFO - validation batch 51, loss: 4.456, 1632/6976 datapoints
2025-03-07 12:42:44,700 - INFO - validation batch 101, loss: 0.415, 3232/6976 datapoints
2025-03-07 12:42:44,782 - INFO - validation batch 151, loss: 1.510, 4832/6976 datapoints
2025-03-07 12:42:44,867 - INFO - validation batch 201, loss: 0.494, 6432/6976 datapoints
2025-03-07 12:42:44,901 - INFO - Epoch 309/800 done.
2025-03-07 12:42:44,902 - INFO - Final validation performance:
Loss: 1.377, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:42:44,902 - INFO - Beginning epoch 310/800
2025-03-07 12:42:44,910 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:42:45,269 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:42:45,599 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:42:45,931 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:42:46,260 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:42:46,707 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:42:47,113 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:42:47,463 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:42:47,862 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:42:48,255 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:42:48,602 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:42:48,933 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:42:49,274 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:42:49,606 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:42:49,940 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:42:50,285 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:42:50,592 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:42:50,915 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:42:51,067 - INFO - validation batch 1, loss: 0.015, 32/6976 datapoints
2025-03-07 12:42:51,141 - INFO - validation batch 51, loss: 4.463, 1632/6976 datapoints
2025-03-07 12:42:51,217 - INFO - validation batch 101, loss: 0.405, 3232/6976 datapoints
2025-03-07 12:42:51,294 - INFO - validation batch 151, loss: 1.506, 4832/6976 datapoints
2025-03-07 12:42:51,377 - INFO - validation batch 201, loss: 0.500, 6432/6976 datapoints
2025-03-07 12:42:51,404 - INFO - Epoch 310/800 done.
2025-03-07 12:42:51,404 - INFO - Final validation performance:
Loss: 1.378, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:42:51,405 - INFO - Beginning epoch 311/800
2025-03-07 12:42:51,413 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:42:51,741 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:42:52,066 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:42:52,391 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:42:52,716 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:42:53,068 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:42:53,417 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:42:53,763 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:42:54,114 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:42:54,450 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:42:54,798 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:42:55,126 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:42:55,459 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:42:55,783 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:42:56,124 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:42:56,429 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:42:56,739 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:42:57,056 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:42:57,215 - INFO - validation batch 1, loss: 0.018, 32/6976 datapoints
2025-03-07 12:42:57,298 - INFO - validation batch 51, loss: 4.471, 1632/6976 datapoints
2025-03-07 12:42:57,373 - INFO - validation batch 101, loss: 0.395, 3232/6976 datapoints
2025-03-07 12:42:57,453 - INFO - validation batch 151, loss: 1.503, 4832/6976 datapoints
2025-03-07 12:42:57,527 - INFO - validation batch 201, loss: 0.511, 6432/6976 datapoints
2025-03-07 12:42:57,553 - INFO - Epoch 311/800 done.
2025-03-07 12:42:57,553 - INFO - Final validation performance:
Loss: 1.379, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:42:57,554 - INFO - Beginning epoch 312/800
2025-03-07 12:42:57,561 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:42:57,879 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:42:58,262 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:42:58,589 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:42:58,911 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:42:59,245 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:42:59,578 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:42:59,893 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:43:00,243 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:43:00,571 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:43:00,904 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:43:01,236 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:43:01,577 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:43:01,913 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:43:02,241 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:43:02,549 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:43:02,856 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:43:03,176 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:43:03,335 - INFO - validation batch 1, loss: 0.021, 32/6976 datapoints
2025-03-07 12:43:03,415 - INFO - validation batch 51, loss: 4.477, 1632/6976 datapoints
2025-03-07 12:43:03,503 - INFO - validation batch 101, loss: 0.385, 3232/6976 datapoints
2025-03-07 12:43:03,600 - INFO - validation batch 151, loss: 1.501, 4832/6976 datapoints
2025-03-07 12:43:03,679 - INFO - validation batch 201, loss: 0.526, 6432/6976 datapoints
2025-03-07 12:43:03,705 - INFO - Epoch 312/800 done.
2025-03-07 12:43:03,705 - INFO - Final validation performance:
Loss: 1.382, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:43:03,706 - INFO - Beginning epoch 313/800
2025-03-07 12:43:03,713 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:43:04,033 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:43:04,368 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:43:04,698 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:43:05,015 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:43:05,347 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:43:05,676 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:43:06,003 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:43:06,354 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:43:06,674 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:43:07,007 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:43:07,338 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:43:07,687 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:43:08,011 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:43:08,336 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:43:08,658 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:43:08,993 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:43:09,326 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:43:09,480 - INFO - validation batch 1, loss: 0.025, 32/6976 datapoints
2025-03-07 12:43:09,558 - INFO - validation batch 51, loss: 4.482, 1632/6976 datapoints
2025-03-07 12:43:09,636 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-07 12:43:09,721 - INFO - validation batch 151, loss: 1.499, 4832/6976 datapoints
2025-03-07 12:43:09,804 - INFO - validation batch 201, loss: 0.545, 6432/6976 datapoints
2025-03-07 12:43:09,832 - INFO - Epoch 313/800 done.
2025-03-07 12:43:09,832 - INFO - Final validation performance:
Loss: 1.386, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:43:09,833 - INFO - Beginning epoch 314/800
2025-03-07 12:43:09,841 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:43:10,159 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:43:10,497 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:43:10,829 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:43:11,160 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:43:11,496 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:43:11,829 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:43:12,154 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:43:12,505 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:43:12,843 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:43:13,194 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:43:13,531 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:43:13,895 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:43:14,219 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:43:14,558 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:43:14,870 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:43:15,186 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:43:15,512 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:43:15,672 - INFO - validation batch 1, loss: 0.029, 32/6976 datapoints
2025-03-07 12:43:15,747 - INFO - validation batch 51, loss: 4.486, 1632/6976 datapoints
2025-03-07 12:43:15,824 - INFO - validation batch 101, loss: 0.372, 3232/6976 datapoints
2025-03-07 12:43:15,900 - INFO - validation batch 151, loss: 1.497, 4832/6976 datapoints
2025-03-07 12:43:15,977 - INFO - validation batch 201, loss: 0.569, 6432/6976 datapoints
2025-03-07 12:43:16,002 - INFO - Epoch 314/800 done.
2025-03-07 12:43:16,002 - INFO - Final validation performance:
Loss: 1.391, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:43:16,003 - INFO - Beginning epoch 315/800
2025-03-07 12:43:16,013 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:43:16,335 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:43:16,683 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:43:17,024 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:43:17,353 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:43:17,706 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:43:18,029 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:43:18,352 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:43:18,714 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:43:19,083 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:43:19,566 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:43:20,008 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:43:20,440 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:43:20,864 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:43:21,300 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:43:21,674 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:43:22,039 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:43:22,399 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:43:22,605 - INFO - validation batch 1, loss: 0.033, 32/6976 datapoints
2025-03-07 12:43:22,694 - INFO - validation batch 51, loss: 4.490, 1632/6976 datapoints
2025-03-07 12:43:22,781 - INFO - validation batch 101, loss: 0.370, 3232/6976 datapoints
2025-03-07 12:43:22,868 - INFO - validation batch 151, loss: 1.495, 4832/6976 datapoints
2025-03-07 12:43:22,974 - INFO - validation batch 201, loss: 0.596, 6432/6976 datapoints
2025-03-07 12:43:23,008 - INFO - Epoch 315/800 done.
2025-03-07 12:43:23,008 - INFO - Final validation performance:
Loss: 1.397, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:43:23,009 - INFO - Beginning epoch 316/800
2025-03-07 12:43:23,021 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:43:23,413 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:43:23,797 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:43:24,150 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:43:24,505 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:43:24,879 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:43:25,233 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:43:25,603 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:43:25,974 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:43:26,322 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:43:26,693 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:43:27,059 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:43:27,418 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:43:27,768 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:43:28,283 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:43:28,825 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:43:29,277 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:43:29,754 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:43:29,942 - INFO - validation batch 1, loss: 0.037, 32/6976 datapoints
2025-03-07 12:43:30,036 - INFO - validation batch 51, loss: 4.497, 1632/6976 datapoints
2025-03-07 12:43:30,133 - INFO - validation batch 101, loss: 0.372, 3232/6976 datapoints
2025-03-07 12:43:30,248 - INFO - validation batch 151, loss: 1.493, 4832/6976 datapoints
2025-03-07 12:43:30,363 - INFO - validation batch 201, loss: 0.627, 6432/6976 datapoints
2025-03-07 12:43:30,420 - INFO - Epoch 316/800 done.
2025-03-07 12:43:30,420 - INFO - Final validation performance:
Loss: 1.405, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:43:30,421 - INFO - Beginning epoch 317/800
2025-03-07 12:43:30,436 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:43:31,513 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:43:31,894 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:43:32,329 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:43:32,721 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:43:33,127 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:43:33,507 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:43:34,004 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:43:34,581 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:43:35,034 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:43:35,546 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:43:36,102 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:43:36,740 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:43:37,190 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:43:37,573 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:43:37,956 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:43:38,278 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:43:38,607 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:43:38,768 - INFO - validation batch 1, loss: 0.042, 32/6976 datapoints
2025-03-07 12:43:38,846 - INFO - validation batch 51, loss: 4.505, 1632/6976 datapoints
2025-03-07 12:43:38,922 - INFO - validation batch 101, loss: 0.376, 3232/6976 datapoints
2025-03-07 12:43:39,000 - INFO - validation batch 151, loss: 1.492, 4832/6976 datapoints
2025-03-07 12:43:39,078 - INFO - validation batch 201, loss: 0.664, 6432/6976 datapoints
2025-03-07 12:43:39,104 - INFO - Epoch 317/800 done.
2025-03-07 12:43:39,104 - INFO - Final validation performance:
Loss: 1.416, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:43:39,105 - INFO - Beginning epoch 318/800
2025-03-07 12:43:39,114 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:43:39,449 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:43:39,789 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:43:40,117 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:43:40,446 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:43:40,786 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:43:41,111 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:43:41,420 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:43:41,759 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:43:42,069 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:43:42,382 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:43:42,706 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:43:43,030 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:43:43,337 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:43:43,650 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:43:43,947 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:43:44,259 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:43:44,571 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:43:44,722 - INFO - validation batch 1, loss: 0.047, 32/6976 datapoints
2025-03-07 12:43:44,801 - INFO - validation batch 51, loss: 4.510, 1632/6976 datapoints
2025-03-07 12:43:44,875 - INFO - validation batch 101, loss: 0.381, 3232/6976 datapoints
2025-03-07 12:43:44,949 - INFO - validation batch 151, loss: 1.491, 4832/6976 datapoints
2025-03-07 12:43:45,021 - INFO - validation batch 201, loss: 0.710, 6432/6976 datapoints
2025-03-07 12:43:45,047 - INFO - Epoch 318/800 done.
2025-03-07 12:43:45,047 - INFO - Final validation performance:
Loss: 1.428, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:43:45,048 - INFO - Beginning epoch 319/800
2025-03-07 12:43:45,056 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:43:45,375 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:43:45,710 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:43:46,045 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:43:46,475 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:43:46,932 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:43:47,368 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:43:47,818 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:43:48,335 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:43:48,856 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:43:49,325 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:43:49,803 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:43:50,315 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:43:50,759 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:43:51,234 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:43:51,743 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:43:52,159 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:43:52,640 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:43:52,891 - INFO - validation batch 1, loss: 0.051, 32/6976 datapoints
2025-03-07 12:43:53,027 - INFO - validation batch 51, loss: 4.514, 1632/6976 datapoints
2025-03-07 12:43:53,159 - INFO - validation batch 101, loss: 0.390, 3232/6976 datapoints
2025-03-07 12:43:53,276 - INFO - validation batch 151, loss: 1.491, 4832/6976 datapoints
2025-03-07 12:43:53,418 - INFO - validation batch 201, loss: 0.753, 6432/6976 datapoints
2025-03-07 12:43:53,487 - INFO - Epoch 319/800 done.
2025-03-07 12:43:53,488 - INFO - Final validation performance:
Loss: 1.440, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:43:53,488 - INFO - Beginning epoch 320/800
2025-03-07 12:43:53,498 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:43:54,032 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:43:54,546 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:43:55,032 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:43:55,453 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:43:55,891 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:43:56,318 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:43:56,745 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:43:57,204 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:43:57,645 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:43:58,141 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:43:58,503 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:43:58,855 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:43:59,175 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:43:59,506 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:43:59,812 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:44:00,114 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:44:00,426 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:44:00,599 - INFO - validation batch 1, loss: 0.056, 32/6976 datapoints
2025-03-07 12:44:00,692 - INFO - validation batch 51, loss: 4.514, 1632/6976 datapoints
2025-03-07 12:44:00,787 - INFO - validation batch 101, loss: 0.397, 3232/6976 datapoints
2025-03-07 12:44:00,882 - INFO - validation batch 151, loss: 1.491, 4832/6976 datapoints
2025-03-07 12:44:00,976 - INFO - validation batch 201, loss: 0.783, 6432/6976 datapoints
2025-03-07 12:44:01,001 - INFO - Epoch 320/800 done.
2025-03-07 12:44:01,001 - INFO - Final validation performance:
Loss: 1.448, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:44:01,002 - INFO - Beginning epoch 321/800
2025-03-07 12:44:01,012 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:44:01,339 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:44:01,682 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:44:02,002 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:44:02,307 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:44:02,638 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:44:02,951 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:44:03,266 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:44:03,606 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:44:03,913 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:44:04,231 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:44:04,554 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:44:04,882 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:44:05,188 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:44:05,507 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:44:05,809 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:44:06,119 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:44:06,441 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:44:06,593 - INFO - validation batch 1, loss: 0.059, 32/6976 datapoints
2025-03-07 12:44:06,671 - INFO - validation batch 51, loss: 4.498, 1632/6976 datapoints
2025-03-07 12:44:06,743 - INFO - validation batch 101, loss: 0.396, 3232/6976 datapoints
2025-03-07 12:44:06,822 - INFO - validation batch 151, loss: 1.494, 4832/6976 datapoints
2025-03-07 12:44:06,896 - INFO - validation batch 201, loss: 0.799, 6432/6976 datapoints
2025-03-07 12:44:06,921 - INFO - Epoch 321/800 done.
2025-03-07 12:44:06,922 - INFO - Final validation performance:
Loss: 1.449, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:44:06,922 - INFO - Beginning epoch 322/800
2025-03-07 12:44:06,931 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:44:07,244 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:44:07,578 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:44:07,899 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:44:08,205 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:44:08,524 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:44:08,835 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:44:09,152 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:44:09,487 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:44:09,796 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:44:10,128 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:44:10,476 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:44:10,846 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:44:11,232 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:44:11,580 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:44:11,930 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:44:12,254 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:44:12,585 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:44:12,741 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 12:44:12,814 - INFO - validation batch 51, loss: 4.473, 1632/6976 datapoints
2025-03-07 12:44:12,885 - INFO - validation batch 101, loss: 0.394, 3232/6976 datapoints
2025-03-07 12:44:12,957 - INFO - validation batch 151, loss: 1.500, 4832/6976 datapoints
2025-03-07 12:44:13,025 - INFO - validation batch 201, loss: 0.807, 6432/6976 datapoints
2025-03-07 12:44:13,052 - INFO - Epoch 322/800 done.
2025-03-07 12:44:13,052 - INFO - Final validation performance:
Loss: 1.447, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:44:13,053 - INFO - Beginning epoch 323/800
2025-03-07 12:44:13,060 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:44:13,396 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:44:13,760 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:44:14,573 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:44:14,890 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:44:15,223 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:44:15,542 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:44:15,854 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:44:16,187 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:44:16,514 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:44:16,834 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:44:17,152 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:44:17,479 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:44:17,801 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:44:18,122 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:44:18,422 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:44:18,727 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:44:19,051 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:44:19,205 - INFO - validation batch 1, loss: 0.067, 32/6976 datapoints
2025-03-07 12:44:19,278 - INFO - validation batch 51, loss: 4.451, 1632/6976 datapoints
2025-03-07 12:44:19,354 - INFO - validation batch 101, loss: 0.393, 3232/6976 datapoints
2025-03-07 12:44:19,429 - INFO - validation batch 151, loss: 1.496, 4832/6976 datapoints
2025-03-07 12:44:19,509 - INFO - validation batch 201, loss: 0.818, 6432/6976 datapoints
2025-03-07 12:44:19,537 - INFO - Epoch 323/800 done.
2025-03-07 12:44:19,537 - INFO - Final validation performance:
Loss: 1.445, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:44:19,538 - INFO - Beginning epoch 324/800
2025-03-07 12:44:19,546 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:44:19,861 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:44:20,205 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:44:20,524 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:44:20,867 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:44:21,273 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:44:21,661 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:44:22,065 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:44:22,498 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:44:22,966 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:44:23,484 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:44:23,962 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:44:24,465 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:44:24,984 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:44:25,395 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:44:25,771 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:44:26,121 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:44:26,496 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:44:26,670 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 12:44:26,752 - INFO - validation batch 51, loss: 4.443, 1632/6976 datapoints
2025-03-07 12:44:26,833 - INFO - validation batch 101, loss: 0.394, 3232/6976 datapoints
2025-03-07 12:44:26,916 - INFO - validation batch 151, loss: 1.488, 4832/6976 datapoints
2025-03-07 12:44:27,003 - INFO - validation batch 201, loss: 0.824, 6432/6976 datapoints
2025-03-07 12:44:27,035 - INFO - Epoch 324/800 done.
2025-03-07 12:44:27,035 - INFO - Final validation performance:
Loss: 1.442, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:44:27,036 - INFO - Beginning epoch 325/800
2025-03-07 12:44:27,044 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:44:27,414 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:44:27,828 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:44:28,169 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:44:28,511 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:44:28,902 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:44:29,265 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:44:29,619 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:44:29,972 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:44:30,312 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:44:30,779 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:44:31,188 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:44:31,622 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:44:31,988 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:44:32,376 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:44:32,713 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:44:33,058 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:44:33,438 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:44:33,607 - INFO - validation batch 1, loss: 0.056, 32/6976 datapoints
2025-03-07 12:44:33,685 - INFO - validation batch 51, loss: 4.447, 1632/6976 datapoints
2025-03-07 12:44:33,772 - INFO - validation batch 101, loss: 0.391, 3232/6976 datapoints
2025-03-07 12:44:33,857 - INFO - validation batch 151, loss: 1.480, 4832/6976 datapoints
2025-03-07 12:44:33,935 - INFO - validation batch 201, loss: 0.832, 6432/6976 datapoints
2025-03-07 12:44:33,960 - INFO - Epoch 325/800 done.
2025-03-07 12:44:33,960 - INFO - Final validation performance:
Loss: 1.441, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:44:33,961 - INFO - Beginning epoch 326/800
2025-03-07 12:44:33,969 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:44:34,359 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:44:34,845 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:44:35,246 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:44:35,673 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:44:36,091 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:44:36,507 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:44:36,881 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:44:37,337 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:44:37,792 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:44:38,288 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:44:38,813 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:44:39,249 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:44:39,666 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:44:40,129 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:44:40,587 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:44:41,095 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:44:41,476 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:44:41,663 - INFO - validation batch 1, loss: 0.050, 32/6976 datapoints
2025-03-07 12:44:41,764 - INFO - validation batch 51, loss: 4.456, 1632/6976 datapoints
2025-03-07 12:44:41,880 - INFO - validation batch 101, loss: 0.398, 3232/6976 datapoints
2025-03-07 12:44:41,968 - INFO - validation batch 151, loss: 1.478, 4832/6976 datapoints
2025-03-07 12:44:42,049 - INFO - validation batch 201, loss: 0.838, 6432/6976 datapoints
2025-03-07 12:44:42,084 - INFO - Epoch 326/800 done.
2025-03-07 12:44:42,085 - INFO - Final validation performance:
Loss: 1.444, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:44:42,085 - INFO - Beginning epoch 327/800
2025-03-07 12:44:42,095 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:44:42,464 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:44:42,924 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:44:43,322 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:44:43,715 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:44:44,107 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:44:44,497 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:44:44,926 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:44:45,325 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:44:45,670 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:44:46,006 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:44:46,328 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:44:46,665 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:44:46,991 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:44:47,312 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:44:47,625 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:44:47,991 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:44:48,336 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:44:48,496 - INFO - validation batch 1, loss: 0.044, 32/6976 datapoints
2025-03-07 12:44:48,571 - INFO - validation batch 51, loss: 4.474, 1632/6976 datapoints
2025-03-07 12:44:48,649 - INFO - validation batch 101, loss: 0.404, 3232/6976 datapoints
2025-03-07 12:44:48,726 - INFO - validation batch 151, loss: 1.478, 4832/6976 datapoints
2025-03-07 12:44:48,801 - INFO - validation batch 201, loss: 0.849, 6432/6976 datapoints
2025-03-07 12:44:48,830 - INFO - Epoch 327/800 done.
2025-03-07 12:44:48,830 - INFO - Final validation performance:
Loss: 1.450, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:44:48,831 - INFO - Beginning epoch 328/800
2025-03-07 12:44:48,840 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:44:49,160 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:44:49,516 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:44:49,939 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:44:50,270 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:44:50,628 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:44:50,986 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:44:51,307 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:44:51,643 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:44:51,959 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:44:52,276 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:44:52,586 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:44:52,919 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:44:53,223 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:44:53,540 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:44:53,836 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:44:54,131 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:44:54,453 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:44:54,600 - INFO - validation batch 1, loss: 0.036, 32/6976 datapoints
2025-03-07 12:44:54,670 - INFO - validation batch 51, loss: 4.499, 1632/6976 datapoints
2025-03-07 12:44:54,737 - INFO - validation batch 101, loss: 0.416, 3232/6976 datapoints
2025-03-07 12:44:54,804 - INFO - validation batch 151, loss: 1.493, 4832/6976 datapoints
2025-03-07 12:44:54,895 - INFO - validation batch 201, loss: 0.837, 6432/6976 datapoints
2025-03-07 12:44:54,927 - INFO - Epoch 328/800 done.
2025-03-07 12:44:54,927 - INFO - Final validation performance:
Loss: 1.456, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:44:54,928 - INFO - Beginning epoch 329/800
2025-03-07 12:44:54,936 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:44:55,251 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:44:55,593 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:44:55,911 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:44:56,227 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:44:56,551 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:44:56,864 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:44:57,186 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:44:57,520 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:44:57,851 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:44:58,223 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:44:58,547 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:44:58,888 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:44:59,208 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:44:59,528 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:44:59,825 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:45:00,139 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:45:00,468 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:45:00,620 - INFO - validation batch 1, loss: 0.029, 32/6976 datapoints
2025-03-07 12:45:00,695 - INFO - validation batch 51, loss: 4.526, 1632/6976 datapoints
2025-03-07 12:45:00,767 - INFO - validation batch 101, loss: 0.412, 3232/6976 datapoints
2025-03-07 12:45:00,840 - INFO - validation batch 151, loss: 1.482, 4832/6976 datapoints
2025-03-07 12:45:00,913 - INFO - validation batch 201, loss: 0.819, 6432/6976 datapoints
2025-03-07 12:45:00,941 - INFO - Epoch 329/800 done.
2025-03-07 12:45:00,941 - INFO - Final validation performance:
Loss: 1.453, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:45:00,942 - INFO - Beginning epoch 330/800
2025-03-07 12:45:00,950 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:45:01,272 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:45:01,614 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:45:01,944 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:45:02,269 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:45:02,606 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:45:02,935 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:45:03,282 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:45:03,636 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:45:03,961 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:45:04,285 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:45:04,617 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:45:04,966 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:45:05,304 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:45:05,644 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:45:05,945 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:45:06,249 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:45:06,575 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:45:06,727 - INFO - validation batch 1, loss: 0.030, 32/6976 datapoints
2025-03-07 12:45:06,801 - INFO - validation batch 51, loss: 4.529, 1632/6976 datapoints
2025-03-07 12:45:06,871 - INFO - validation batch 101, loss: 0.429, 3232/6976 datapoints
2025-03-07 12:45:06,941 - INFO - validation batch 151, loss: 1.491, 4832/6976 datapoints
2025-03-07 12:45:07,013 - INFO - validation batch 201, loss: 0.835, 6432/6976 datapoints
2025-03-07 12:45:07,040 - INFO - Epoch 330/800 done.
2025-03-07 12:45:07,040 - INFO - Final validation performance:
Loss: 1.463, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:45:07,042 - INFO - Beginning epoch 331/800
2025-03-07 12:45:07,050 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:45:07,375 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:45:07,723 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:45:08,049 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:45:08,376 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:45:08,716 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:45:09,042 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:45:09,364 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:45:09,698 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:45:10,027 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:45:10,365 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:45:10,702 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:45:11,040 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:45:11,362 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:45:11,693 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:45:11,993 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:45:12,301 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:45:12,627 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:45:12,781 - INFO - validation batch 1, loss: 0.027, 32/6976 datapoints
2025-03-07 12:45:12,853 - INFO - validation batch 51, loss: 4.582, 1632/6976 datapoints
2025-03-07 12:45:12,926 - INFO - validation batch 101, loss: 0.446, 3232/6976 datapoints
2025-03-07 12:45:12,998 - INFO - validation batch 151, loss: 1.494, 4832/6976 datapoints
2025-03-07 12:45:13,069 - INFO - validation batch 201, loss: 0.841, 6432/6976 datapoints
2025-03-07 12:45:13,096 - INFO - Epoch 331/800 done.
2025-03-07 12:45:13,096 - INFO - Final validation performance:
Loss: 1.478, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:45:13,097 - INFO - Beginning epoch 332/800
2025-03-07 12:45:13,104 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:45:13,469 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:45:13,812 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:45:14,135 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:45:14,466 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:45:14,798 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:45:15,145 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:45:15,469 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:45:15,806 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:45:16,135 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:45:16,476 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:45:16,799 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:45:17,143 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:45:17,485 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 12:45:17,814 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:45:18,113 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:45:18,418 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:45:18,750 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:45:18,906 - INFO - validation batch 1, loss: 0.028, 32/6976 datapoints
2025-03-07 12:45:18,979 - INFO - validation batch 51, loss: 4.573, 1632/6976 datapoints
2025-03-07 12:45:19,054 - INFO - validation batch 101, loss: 0.496, 3232/6976 datapoints
2025-03-07 12:45:19,128 - INFO - validation batch 151, loss: 1.549, 4832/6976 datapoints
2025-03-07 12:45:19,200 - INFO - validation batch 201, loss: 0.916, 6432/6976 datapoints
2025-03-07 12:45:19,229 - INFO - Epoch 332/800 done.
2025-03-07 12:45:19,229 - INFO - Final validation performance:
Loss: 1.513, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:45:19,230 - INFO - Beginning epoch 333/800
2025-03-07 12:45:19,238 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:45:19,566 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 12:45:19,906 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:45:20,233 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:45:20,565 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:45:20,897 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:45:21,218 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:45:21,541 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:45:21,923 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:45:22,289 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:45:22,621 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:45:22,953 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:45:23,290 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:45:23,630 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:45:23,962 - INFO - training batch 701, loss: 0.056, 22432/28000 datapoints
2025-03-07 12:45:24,285 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:45:24,614 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:45:24,980 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:45:25,135 - INFO - validation batch 1, loss: 0.069, 32/6976 datapoints
2025-03-07 12:45:25,242 - INFO - validation batch 51, loss: 4.821, 1632/6976 datapoints
2025-03-07 12:45:25,345 - INFO - validation batch 101, loss: 0.493, 3232/6976 datapoints
2025-03-07 12:45:25,436 - INFO - validation batch 151, loss: 1.590, 4832/6976 datapoints
2025-03-07 12:45:25,510 - INFO - validation batch 201, loss: 1.116, 6432/6976 datapoints
2025-03-07 12:45:25,534 - INFO - Epoch 333/800 done.
2025-03-07 12:45:25,534 - INFO - Final validation performance:
Loss: 1.618, top-1 acc: 0.895top-5 acc: 0.895
2025-03-07 12:45:25,535 - INFO - Beginning epoch 334/800
2025-03-07 12:45:25,543 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:45:25,906 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:45:26,294 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:45:26,668 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:45:27,127 - INFO - training batch 201, loss: 0.058, 6432/28000 datapoints
2025-03-07 12:45:27,561 - INFO - training batch 251, loss: 0.153, 8032/28000 datapoints
2025-03-07 12:45:28,012 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:45:28,451 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:45:28,890 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:45:29,336 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:45:29,738 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:45:30,101 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:45:30,500 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:45:30,920 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:45:31,275 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:45:31,615 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:45:31,975 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:45:32,342 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-07 12:45:32,522 - INFO - validation batch 1, loss: 0.012, 32/6976 datapoints
2025-03-07 12:45:32,604 - INFO - validation batch 51, loss: 4.978, 1632/6976 datapoints
2025-03-07 12:45:32,683 - INFO - validation batch 101, loss: 0.490, 3232/6976 datapoints
2025-03-07 12:45:32,815 - INFO - validation batch 151, loss: 1.355, 4832/6976 datapoints
2025-03-07 12:45:32,901 - INFO - validation batch 201, loss: 0.907, 6432/6976 datapoints
2025-03-07 12:45:32,934 - INFO - Epoch 334/800 done.
2025-03-07 12:45:32,934 - INFO - Final validation performance:
Loss: 1.549, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:45:32,935 - INFO - Beginning epoch 335/800
2025-03-07 12:45:32,944 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:45:33,282 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:45:33,738 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:45:34,210 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:45:34,655 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:45:35,176 - INFO - training batch 251, loss: 0.004, 8032/28000 datapoints
2025-03-07 12:45:35,647 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 12:45:36,149 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:45:36,654 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:45:37,178 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:45:37,681 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:45:38,179 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:45:38,717 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:45:39,073 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:45:39,459 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:45:39,788 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:45:40,138 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:45:40,475 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:45:40,634 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 12:45:40,707 - INFO - validation batch 51, loss: 5.188, 1632/6976 datapoints
2025-03-07 12:45:40,780 - INFO - validation batch 101, loss: 0.374, 3232/6976 datapoints
2025-03-07 12:45:40,852 - INFO - validation batch 151, loss: 1.211, 4832/6976 datapoints
2025-03-07 12:45:40,927 - INFO - validation batch 201, loss: 0.755, 6432/6976 datapoints
2025-03-07 12:45:40,952 - INFO - Epoch 335/800 done.
2025-03-07 12:45:40,952 - INFO - Final validation performance:
Loss: 1.506, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 12:45:40,953 - INFO - Beginning epoch 336/800
2025-03-07 12:45:40,961 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:45:41,282 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:45:41,686 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:45:42,057 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:45:42,460 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:45:42,921 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:45:43,408 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:45:43,899 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:45:44,320 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:45:44,689 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:45:45,065 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:45:45,515 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:45:45,887 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:45:46,294 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:45:46,676 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:45:47,020 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:45:47,344 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:45:47,685 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:45:47,850 - INFO - validation batch 1, loss: 0.007, 32/6976 datapoints
2025-03-07 12:45:47,931 - INFO - validation batch 51, loss: 4.622, 1632/6976 datapoints
2025-03-07 12:45:48,005 - INFO - validation batch 101, loss: 0.745, 3232/6976 datapoints
2025-03-07 12:45:48,082 - INFO - validation batch 151, loss: 1.418, 4832/6976 datapoints
2025-03-07 12:45:48,162 - INFO - validation batch 201, loss: 1.019, 6432/6976 datapoints
2025-03-07 12:45:48,190 - INFO - Epoch 336/800 done.
2025-03-07 12:45:48,191 - INFO - Final validation performance:
Loss: 1.562, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:45:48,191 - INFO - Beginning epoch 337/800
2025-03-07 12:45:48,199 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:45:48,550 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:45:48,895 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:45:49,230 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:45:49,587 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:45:49,959 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:45:50,489 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:45:50,849 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:45:51,240 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:45:51,623 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:45:52,019 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:45:52,357 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:45:52,754 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:45:53,101 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:45:53,495 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:45:53,896 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:45:54,320 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:45:54,749 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:45:54,992 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:45:55,078 - INFO - validation batch 51, loss: 4.679, 1632/6976 datapoints
2025-03-07 12:45:55,166 - INFO - validation batch 101, loss: 0.584, 3232/6976 datapoints
2025-03-07 12:45:55,260 - INFO - validation batch 151, loss: 1.287, 4832/6976 datapoints
2025-03-07 12:45:55,359 - INFO - validation batch 201, loss: 0.769, 6432/6976 datapoints
2025-03-07 12:45:55,402 - INFO - Epoch 337/800 done.
2025-03-07 12:45:55,402 - INFO - Final validation performance:
Loss: 1.464, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:45:55,403 - INFO - Beginning epoch 338/800
2025-03-07 12:45:55,414 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:45:55,872 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:45:56,280 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:45:56,627 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:45:56,965 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:45:57,302 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:45:57,624 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:45:57,944 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:45:58,319 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:45:58,641 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:45:58,963 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:45:59,284 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:45:59,603 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:45:59,932 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:46:00,251 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:46:00,555 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:46:00,866 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:46:01,193 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:46:01,355 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:46:01,426 - INFO - validation batch 51, loss: 4.669, 1632/6976 datapoints
2025-03-07 12:46:01,501 - INFO - validation batch 101, loss: 0.577, 3232/6976 datapoints
2025-03-07 12:46:01,577 - INFO - validation batch 151, loss: 1.303, 4832/6976 datapoints
2025-03-07 12:46:01,663 - INFO - validation batch 201, loss: 0.785, 6432/6976 datapoints
2025-03-07 12:46:01,693 - INFO - Epoch 338/800 done.
2025-03-07 12:46:01,693 - INFO - Final validation performance:
Loss: 1.467, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:46:01,694 - INFO - Beginning epoch 339/800
2025-03-07 12:46:01,702 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:46:02,032 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:46:02,366 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:46:02,701 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:46:03,022 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:46:03,391 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:46:03,817 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:46:04,179 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:46:04,522 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:46:04,844 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:46:05,182 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 12:46:05,507 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:46:05,864 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:46:06,197 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:46:06,520 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:46:06,886 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:46:07,196 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:46:07,528 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:46:07,689 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:46:07,765 - INFO - validation batch 51, loss: 4.663, 1632/6976 datapoints
2025-03-07 12:46:07,836 - INFO - validation batch 101, loss: 0.572, 3232/6976 datapoints
2025-03-07 12:46:07,910 - INFO - validation batch 151, loss: 1.315, 4832/6976 datapoints
2025-03-07 12:46:07,979 - INFO - validation batch 201, loss: 0.795, 6432/6976 datapoints
2025-03-07 12:46:08,004 - INFO - Epoch 339/800 done.
2025-03-07 12:46:08,004 - INFO - Final validation performance:
Loss: 1.470, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:46:08,005 - INFO - Beginning epoch 340/800
2025-03-07 12:46:08,013 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:46:08,348 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:46:08,683 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:46:09,010 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:46:09,333 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:46:09,856 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:46:10,172 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:46:10,495 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:46:10,821 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:46:11,138 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:46:11,473 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 12:46:11,827 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:46:12,165 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:46:12,511 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:46:12,947 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:46:13,342 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:46:13,743 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:46:14,243 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:46:14,586 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:46:14,739 - INFO - validation batch 51, loss: 4.659, 1632/6976 datapoints
2025-03-07 12:46:14,878 - INFO - validation batch 101, loss: 0.568, 3232/6976 datapoints
2025-03-07 12:46:15,159 - INFO - validation batch 151, loss: 1.324, 4832/6976 datapoints
2025-03-07 12:46:15,268 - INFO - validation batch 201, loss: 0.804, 6432/6976 datapoints
2025-03-07 12:46:15,303 - INFO - Epoch 340/800 done.
2025-03-07 12:46:15,303 - INFO - Final validation performance:
Loss: 1.472, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:46:15,309 - INFO - Beginning epoch 341/800
2025-03-07 12:46:15,320 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:46:15,793 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:46:16,276 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:46:16,724 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:46:17,125 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:46:17,497 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:46:17,858 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:46:18,215 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:46:18,608 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:46:19,419 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:46:20,134 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 12:46:20,579 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:46:21,022 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:46:21,513 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:46:22,561 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:46:22,984 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:46:23,331 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:46:23,811 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:46:24,753 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:46:25,056 - INFO - validation batch 51, loss: 4.659, 1632/6976 datapoints
2025-03-07 12:46:25,244 - INFO - validation batch 101, loss: 0.564, 3232/6976 datapoints
2025-03-07 12:46:25,390 - INFO - validation batch 151, loss: 1.330, 4832/6976 datapoints
2025-03-07 12:46:25,512 - INFO - validation batch 201, loss: 0.809, 6432/6976 datapoints
2025-03-07 12:46:25,562 - INFO - Epoch 341/800 done.
2025-03-07 12:46:25,562 - INFO - Final validation performance:
Loss: 1.473, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:46:25,565 - INFO - Beginning epoch 342/800
2025-03-07 12:46:25,580 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:46:26,415 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:46:26,901 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:46:27,283 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:46:27,943 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:46:28,359 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:46:28,796 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:46:29,271 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:46:29,706 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:46:30,138 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:46:30,595 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:46:30,998 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:46:31,465 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:46:32,025 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:46:32,577 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:46:33,199 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:46:33,581 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:46:33,943 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:46:34,119 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 12:46:34,216 - INFO - validation batch 51, loss: 4.660, 1632/6976 datapoints
2025-03-07 12:46:34,294 - INFO - validation batch 101, loss: 0.561, 3232/6976 datapoints
2025-03-07 12:46:34,378 - INFO - validation batch 151, loss: 1.334, 4832/6976 datapoints
2025-03-07 12:46:34,478 - INFO - validation batch 201, loss: 0.811, 6432/6976 datapoints
2025-03-07 12:46:34,509 - INFO - Epoch 342/800 done.
2025-03-07 12:46:34,509 - INFO - Final validation performance:
Loss: 1.474, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:46:34,510 - INFO - Beginning epoch 343/800
2025-03-07 12:46:34,519 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:46:34,930 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:46:35,293 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:46:35,702 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:46:36,035 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:46:36,444 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:46:36,766 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:46:37,088 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:46:37,454 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:46:37,792 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:46:38,143 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:46:38,573 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:46:38,917 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:46:39,291 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:46:39,733 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:46:40,131 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:46:40,641 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:46:41,009 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:46:41,250 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 12:46:41,358 - INFO - validation batch 51, loss: 4.662, 1632/6976 datapoints
2025-03-07 12:46:41,510 - INFO - validation batch 101, loss: 0.557, 3232/6976 datapoints
2025-03-07 12:46:41,646 - INFO - validation batch 151, loss: 1.336, 4832/6976 datapoints
2025-03-07 12:46:41,755 - INFO - validation batch 201, loss: 0.811, 6432/6976 datapoints
2025-03-07 12:46:41,791 - INFO - Epoch 343/800 done.
2025-03-07 12:46:41,791 - INFO - Final validation performance:
Loss: 1.474, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:46:41,792 - INFO - Beginning epoch 344/800
2025-03-07 12:46:41,802 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:46:42,210 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:46:42,616 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:46:43,068 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:46:43,420 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:46:43,780 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:46:44,128 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:46:44,477 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:46:44,841 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:46:45,230 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:46:45,618 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:46:46,014 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:46:46,524 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:46:46,863 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:46:47,237 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:46:47,641 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:46:48,206 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:46:48,644 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:46:48,851 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 12:46:48,945 - INFO - validation batch 51, loss: 4.665, 1632/6976 datapoints
2025-03-07 12:46:49,036 - INFO - validation batch 101, loss: 0.553, 3232/6976 datapoints
2025-03-07 12:46:49,125 - INFO - validation batch 151, loss: 1.336, 4832/6976 datapoints
2025-03-07 12:46:49,286 - INFO - validation batch 201, loss: 0.808, 6432/6976 datapoints
2025-03-07 12:46:49,328 - INFO - Epoch 344/800 done.
2025-03-07 12:46:49,328 - INFO - Final validation performance:
Loss: 1.473, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:46:49,329 - INFO - Beginning epoch 345/800
2025-03-07 12:46:49,340 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:46:49,768 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:46:50,426 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:46:50,839 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:46:51,196 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:46:51,574 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:46:51,994 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:46:52,410 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:46:52,789 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:46:53,127 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:46:53,456 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:46:53,789 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:46:54,149 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:46:54,493 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:46:54,895 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:46:55,289 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:46:55,678 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:46:56,046 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:46:56,238 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 12:46:56,316 - INFO - validation batch 51, loss: 4.669, 1632/6976 datapoints
2025-03-07 12:46:56,404 - INFO - validation batch 101, loss: 0.547, 3232/6976 datapoints
2025-03-07 12:46:56,489 - INFO - validation batch 151, loss: 1.334, 4832/6976 datapoints
2025-03-07 12:46:56,595 - INFO - validation batch 201, loss: 0.804, 6432/6976 datapoints
2025-03-07 12:46:56,627 - INFO - Epoch 345/800 done.
2025-03-07 12:46:56,627 - INFO - Final validation performance:
Loss: 1.472, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:46:56,628 - INFO - Beginning epoch 346/800
2025-03-07 12:46:56,643 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:46:57,074 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:46:57,459 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:46:57,885 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:46:58,358 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:46:58,772 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:46:59,154 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:46:59,508 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:46:59,887 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:47:00,281 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:47:00,647 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:47:00,996 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:47:01,338 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:47:01,681 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:47:02,008 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:47:02,323 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:47:02,648 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:47:02,978 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:47:03,142 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 12:47:03,215 - INFO - validation batch 51, loss: 4.673, 1632/6976 datapoints
2025-03-07 12:47:03,295 - INFO - validation batch 101, loss: 0.539, 3232/6976 datapoints
2025-03-07 12:47:03,366 - INFO - validation batch 151, loss: 1.332, 4832/6976 datapoints
2025-03-07 12:47:03,442 - INFO - validation batch 201, loss: 0.800, 6432/6976 datapoints
2025-03-07 12:47:03,473 - INFO - Epoch 346/800 done.
2025-03-07 12:47:03,473 - INFO - Final validation performance:
Loss: 1.470, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:47:03,474 - INFO - Beginning epoch 347/800
2025-03-07 12:47:03,483 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:47:03,834 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:47:04,250 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:47:04,590 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:47:04,917 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:47:05,270 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:47:05,630 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:47:05,964 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:47:06,314 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:47:06,835 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:47:07,173 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:47:07,512 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:47:07,859 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:47:08,187 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:47:08,523 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:47:08,838 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:47:09,151 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:47:09,491 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:47:09,650 - INFO - validation batch 1, loss: 0.008, 32/6976 datapoints
2025-03-07 12:47:09,725 - INFO - validation batch 51, loss: 4.676, 1632/6976 datapoints
2025-03-07 12:47:09,799 - INFO - validation batch 101, loss: 0.529, 3232/6976 datapoints
2025-03-07 12:47:09,870 - INFO - validation batch 151, loss: 1.328, 4832/6976 datapoints
2025-03-07 12:47:09,951 - INFO - validation batch 201, loss: 0.797, 6432/6976 datapoints
2025-03-07 12:47:09,979 - INFO - Epoch 347/800 done.
2025-03-07 12:47:09,979 - INFO - Final validation performance:
Loss: 1.468, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:47:09,980 - INFO - Beginning epoch 348/800
2025-03-07 12:47:09,989 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:47:10,325 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:47:10,682 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:47:11,004 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:47:11,336 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:47:11,681 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:47:12,003 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:47:12,325 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:47:12,662 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:47:12,987 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:47:13,326 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:47:13,662 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:47:14,000 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:47:14,327 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:47:14,670 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:47:14,991 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:47:15,313 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:47:15,651 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:47:15,826 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 12:47:15,902 - INFO - validation batch 51, loss: 4.679, 1632/6976 datapoints
2025-03-07 12:47:15,975 - INFO - validation batch 101, loss: 0.518, 3232/6976 datapoints
2025-03-07 12:47:16,057 - INFO - validation batch 151, loss: 1.325, 4832/6976 datapoints
2025-03-07 12:47:16,141 - INFO - validation batch 201, loss: 0.798, 6432/6976 datapoints
2025-03-07 12:47:16,167 - INFO - Epoch 348/800 done.
2025-03-07 12:47:16,167 - INFO - Final validation performance:
Loss: 1.466, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:47:16,168 - INFO - Beginning epoch 349/800
2025-03-07 12:47:16,178 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:47:16,538 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:47:16,928 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:47:17,347 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:47:17,736 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:47:18,109 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:47:18,481 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:47:18,896 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:47:19,297 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:47:19,672 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:47:20,041 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:47:20,422 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:47:20,845 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:47:21,218 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:47:21,606 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:47:21,932 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:47:22,266 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:47:22,686 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:47:22,900 - INFO - validation batch 1, loss: 0.014, 32/6976 datapoints
2025-03-07 12:47:22,980 - INFO - validation batch 51, loss: 4.678, 1632/6976 datapoints
2025-03-07 12:47:23,066 - INFO - validation batch 101, loss: 0.507, 3232/6976 datapoints
2025-03-07 12:47:23,151 - INFO - validation batch 151, loss: 1.323, 4832/6976 datapoints
2025-03-07 12:47:23,241 - INFO - validation batch 201, loss: 0.803, 6432/6976 datapoints
2025-03-07 12:47:23,273 - INFO - Epoch 349/800 done.
2025-03-07 12:47:23,273 - INFO - Final validation performance:
Loss: 1.465, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:47:23,274 - INFO - Beginning epoch 350/800
2025-03-07 12:47:23,284 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:47:23,668 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:47:24,039 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:47:24,409 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:47:24,778 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:47:25,183 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:47:25,593 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:47:25,994 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:47:26,360 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:47:26,722 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:47:27,107 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:47:27,461 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:47:27,843 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:47:28,183 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:47:28,524 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:47:28,874 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:47:29,230 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:47:29,603 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:47:29,783 - INFO - validation batch 1, loss: 0.018, 32/6976 datapoints
2025-03-07 12:47:29,868 - INFO - validation batch 51, loss: 4.678, 1632/6976 datapoints
2025-03-07 12:47:29,961 - INFO - validation batch 101, loss: 0.496, 3232/6976 datapoints
2025-03-07 12:47:30,050 - INFO - validation batch 151, loss: 1.323, 4832/6976 datapoints
2025-03-07 12:47:30,143 - INFO - validation batch 201, loss: 0.812, 6432/6976 datapoints
2025-03-07 12:47:30,168 - INFO - Epoch 350/800 done.
2025-03-07 12:47:30,169 - INFO - Final validation performance:
Loss: 1.466, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:47:30,169 - INFO - Beginning epoch 351/800
2025-03-07 12:47:30,179 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:47:30,571 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:47:30,949 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:47:31,376 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:47:31,760 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:47:32,132 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:47:32,531 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:47:32,917 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:47:33,309 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:47:33,678 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:47:34,086 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:47:34,496 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:47:34,871 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:47:35,234 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:47:35,673 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:47:36,099 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:47:36,626 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:47:36,998 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:47:37,219 - INFO - validation batch 1, loss: 0.025, 32/6976 datapoints
2025-03-07 12:47:37,305 - INFO - validation batch 51, loss: 4.676, 1632/6976 datapoints
2025-03-07 12:47:37,391 - INFO - validation batch 101, loss: 0.486, 3232/6976 datapoints
2025-03-07 12:47:37,473 - INFO - validation batch 151, loss: 1.329, 4832/6976 datapoints
2025-03-07 12:47:37,558 - INFO - validation batch 201, loss: 0.826, 6432/6976 datapoints
2025-03-07 12:47:37,588 - INFO - Epoch 351/800 done.
2025-03-07 12:47:37,588 - INFO - Final validation performance:
Loss: 1.468, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:47:37,589 - INFO - Beginning epoch 352/800
2025-03-07 12:47:37,598 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:47:38,002 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:47:38,380 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:47:38,747 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:47:39,159 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:47:39,522 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:47:39,876 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:47:40,230 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:47:40,588 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:47:40,924 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:47:41,270 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:47:41,608 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:47:41,958 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:47:42,289 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:47:42,659 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:47:42,982 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:47:43,316 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:47:43,660 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:47:43,831 - INFO - validation batch 1, loss: 0.032, 32/6976 datapoints
2025-03-07 12:47:43,909 - INFO - validation batch 51, loss: 4.673, 1632/6976 datapoints
2025-03-07 12:47:43,983 - INFO - validation batch 101, loss: 0.479, 3232/6976 datapoints
2025-03-07 12:47:44,058 - INFO - validation batch 151, loss: 1.342, 4832/6976 datapoints
2025-03-07 12:47:44,141 - INFO - validation batch 201, loss: 0.845, 6432/6976 datapoints
2025-03-07 12:47:44,166 - INFO - Epoch 352/800 done.
2025-03-07 12:47:44,166 - INFO - Final validation performance:
Loss: 1.474, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:47:44,167 - INFO - Beginning epoch 353/800
2025-03-07 12:47:44,177 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:47:44,515 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:47:44,859 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:47:45,177 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:47:45,527 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:47:45,864 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:47:46,190 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:47:46,514 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:47:46,840 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:47:47,178 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:47:47,508 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:47:47,826 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:47:48,150 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:47:48,466 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:47:48,784 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:47:49,085 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:47:49,387 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:47:49,722 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:47:49,875 - INFO - validation batch 1, loss: 0.041, 32/6976 datapoints
2025-03-07 12:47:49,942 - INFO - validation batch 51, loss: 4.663, 1632/6976 datapoints
2025-03-07 12:47:50,008 - INFO - validation batch 101, loss: 0.476, 3232/6976 datapoints
2025-03-07 12:47:50,076 - INFO - validation batch 151, loss: 1.364, 4832/6976 datapoints
2025-03-07 12:47:50,146 - INFO - validation batch 201, loss: 0.870, 6432/6976 datapoints
2025-03-07 12:47:50,169 - INFO - Epoch 353/800 done.
2025-03-07 12:47:50,169 - INFO - Final validation performance:
Loss: 1.483, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:47:50,170 - INFO - Beginning epoch 354/800
2025-03-07 12:47:50,177 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:47:50,494 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:47:50,831 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:47:51,179 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:47:51,527 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:47:51,867 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:47:52,182 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:47:52,505 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:47:52,830 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:47:53,147 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:47:53,472 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:47:53,784 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:47:54,116 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:47:54,432 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:47:54,759 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:47:55,077 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:47:55,397 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:47:55,726 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:47:55,882 - INFO - validation batch 1, loss: 0.052, 32/6976 datapoints
2025-03-07 12:47:55,955 - INFO - validation batch 51, loss: 4.650, 1632/6976 datapoints
2025-03-07 12:47:56,027 - INFO - validation batch 101, loss: 0.478, 3232/6976 datapoints
2025-03-07 12:47:56,100 - INFO - validation batch 151, loss: 1.392, 4832/6976 datapoints
2025-03-07 12:47:56,173 - INFO - validation batch 201, loss: 0.898, 6432/6976 datapoints
2025-03-07 12:47:56,200 - INFO - Epoch 354/800 done.
2025-03-07 12:47:56,201 - INFO - Final validation performance:
Loss: 1.494, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:47:56,201 - INFO - Beginning epoch 355/800
2025-03-07 12:47:56,210 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:47:56,540 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:47:56,896 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:47:57,234 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:47:57,597 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:47:57,953 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:47:58,307 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:47:58,648 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:47:59,004 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:47:59,360 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:47:59,720 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:48:00,125 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:48:00,517 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:48:00,896 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:48:01,273 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:48:01,628 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:48:01,984 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:48:02,353 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:48:02,528 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 12:48:02,624 - INFO - validation batch 51, loss: 4.632, 1632/6976 datapoints
2025-03-07 12:48:02,715 - INFO - validation batch 101, loss: 0.479, 3232/6976 datapoints
2025-03-07 12:48:02,808 - INFO - validation batch 151, loss: 1.422, 4832/6976 datapoints
2025-03-07 12:48:02,905 - INFO - validation batch 201, loss: 0.927, 6432/6976 datapoints
2025-03-07 12:48:02,943 - INFO - Epoch 355/800 done.
2025-03-07 12:48:02,944 - INFO - Final validation performance:
Loss: 1.505, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:48:02,944 - INFO - Beginning epoch 356/800
2025-03-07 12:48:02,954 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:48:03,395 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:48:03,806 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:48:04,150 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:48:04,493 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:48:04,872 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:48:05,219 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:48:05,627 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:48:06,002 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:48:06,381 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:48:06,755 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:48:07,181 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:48:07,751 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:48:08,110 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:48:08,500 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:48:08,835 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:48:09,160 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:48:09,498 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:48:09,705 - INFO - validation batch 1, loss: 0.071, 32/6976 datapoints
2025-03-07 12:48:09,796 - INFO - validation batch 51, loss: 4.611, 1632/6976 datapoints
2025-03-07 12:48:09,880 - INFO - validation batch 101, loss: 0.482, 3232/6976 datapoints
2025-03-07 12:48:09,968 - INFO - validation batch 151, loss: 1.453, 4832/6976 datapoints
2025-03-07 12:48:10,053 - INFO - validation batch 201, loss: 0.955, 6432/6976 datapoints
2025-03-07 12:48:10,087 - INFO - Epoch 356/800 done.
2025-03-07 12:48:10,087 - INFO - Final validation performance:
Loss: 1.514, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:48:10,088 - INFO - Beginning epoch 357/800
2025-03-07 12:48:10,098 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:48:10,471 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:48:10,824 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:48:11,155 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:48:11,481 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:48:11,841 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:48:12,158 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:48:12,482 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:48:12,818 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:48:13,137 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:48:13,482 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:48:13,882 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:48:14,235 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:48:14,601 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:48:14,986 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:48:15,313 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:48:15,650 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:48:16,005 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:48:16,418 - INFO - validation batch 1, loss: 0.076, 32/6976 datapoints
2025-03-07 12:48:16,519 - INFO - validation batch 51, loss: 4.585, 1632/6976 datapoints
2025-03-07 12:48:16,623 - INFO - validation batch 101, loss: 0.486, 3232/6976 datapoints
2025-03-07 12:48:16,698 - INFO - validation batch 151, loss: 1.479, 4832/6976 datapoints
2025-03-07 12:48:16,774 - INFO - validation batch 201, loss: 0.979, 6432/6976 datapoints
2025-03-07 12:48:16,802 - INFO - Epoch 357/800 done.
2025-03-07 12:48:16,802 - INFO - Final validation performance:
Loss: 1.521, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:48:16,803 - INFO - Beginning epoch 358/800
2025-03-07 12:48:16,811 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:48:17,144 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:48:17,513 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:48:17,865 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:48:18,196 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:48:18,542 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:48:18,861 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:48:19,185 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:48:19,514 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:48:19,842 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:48:20,195 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:48:20,528 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:48:20,859 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:48:21,189 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:48:21,532 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:48:21,839 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:48:22,146 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:48:22,477 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:48:22,634 - INFO - validation batch 1, loss: 0.081, 32/6976 datapoints
2025-03-07 12:48:22,706 - INFO - validation batch 51, loss: 4.560, 1632/6976 datapoints
2025-03-07 12:48:22,778 - INFO - validation batch 101, loss: 0.491, 3232/6976 datapoints
2025-03-07 12:48:22,851 - INFO - validation batch 151, loss: 1.498, 4832/6976 datapoints
2025-03-07 12:48:22,923 - INFO - validation batch 201, loss: 0.992, 6432/6976 datapoints
2025-03-07 12:48:22,951 - INFO - Epoch 358/800 done.
2025-03-07 12:48:22,951 - INFO - Final validation performance:
Loss: 1.524, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:48:22,952 - INFO - Beginning epoch 359/800
2025-03-07 12:48:22,960 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:48:23,286 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:48:23,634 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:48:23,958 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:48:24,291 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:48:24,637 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:48:24,965 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:48:25,298 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:48:25,639 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:48:25,979 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:48:26,318 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:48:26,634 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:48:26,968 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:48:27,288 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:48:27,628 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:48:27,956 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:48:28,266 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:48:28,606 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:48:28,762 - INFO - validation batch 1, loss: 0.081, 32/6976 datapoints
2025-03-07 12:48:28,835 - INFO - validation batch 51, loss: 4.539, 1632/6976 datapoints
2025-03-07 12:48:28,908 - INFO - validation batch 101, loss: 0.496, 3232/6976 datapoints
2025-03-07 12:48:28,982 - INFO - validation batch 151, loss: 1.502, 4832/6976 datapoints
2025-03-07 12:48:29,053 - INFO - validation batch 201, loss: 0.993, 6432/6976 datapoints
2025-03-07 12:48:29,079 - INFO - Epoch 359/800 done.
2025-03-07 12:48:29,079 - INFO - Final validation performance:
Loss: 1.522, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:48:29,079 - INFO - Beginning epoch 360/800
2025-03-07 12:48:29,088 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:48:29,416 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:48:29,762 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:48:30,095 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:48:30,424 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:48:30,788 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:48:31,111 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:48:31,444 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:48:31,780 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:48:32,108 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:48:32,441 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:48:32,763 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:48:33,101 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:48:33,424 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:48:33,761 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:48:34,073 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:48:34,402 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:48:34,740 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:48:34,897 - INFO - validation batch 1, loss: 0.077, 32/6976 datapoints
2025-03-07 12:48:34,965 - INFO - validation batch 51, loss: 4.523, 1632/6976 datapoints
2025-03-07 12:48:35,036 - INFO - validation batch 101, loss: 0.498, 3232/6976 datapoints
2025-03-07 12:48:35,102 - INFO - validation batch 151, loss: 1.495, 4832/6976 datapoints
2025-03-07 12:48:35,172 - INFO - validation batch 201, loss: 0.984, 6432/6976 datapoints
2025-03-07 12:48:35,195 - INFO - Epoch 360/800 done.
2025-03-07 12:48:35,196 - INFO - Final validation performance:
Loss: 1.515, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:48:35,196 - INFO - Beginning epoch 361/800
2025-03-07 12:48:35,205 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:48:35,600 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:48:35,966 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:48:36,322 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:48:36,671 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:48:37,023 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:48:37,358 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:48:37,698 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:48:38,046 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:48:38,384 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:48:38,716 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:48:39,039 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:48:39,399 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:48:39,742 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:48:40,073 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:48:40,393 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:48:40,728 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:48:41,066 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:48:41,228 - INFO - validation batch 1, loss: 0.075, 32/6976 datapoints
2025-03-07 12:48:41,303 - INFO - validation batch 51, loss: 4.514, 1632/6976 datapoints
2025-03-07 12:48:41,377 - INFO - validation batch 101, loss: 0.493, 3232/6976 datapoints
2025-03-07 12:48:41,457 - INFO - validation batch 151, loss: 1.486, 4832/6976 datapoints
2025-03-07 12:48:41,535 - INFO - validation batch 201, loss: 0.969, 6432/6976 datapoints
2025-03-07 12:48:41,562 - INFO - Epoch 361/800 done.
2025-03-07 12:48:41,562 - INFO - Final validation performance:
Loss: 1.507, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:48:41,563 - INFO - Beginning epoch 362/800
2025-03-07 12:48:41,571 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:48:42,074 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:48:42,429 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:48:42,773 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:48:43,118 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:48:43,467 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:48:43,854 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:48:44,255 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:48:44,614 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:48:44,951 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:48:45,326 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:48:45,676 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:48:46,086 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:48:46,436 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:48:46,900 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:48:47,260 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:48:47,635 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:48:48,073 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:48:48,246 - INFO - validation batch 1, loss: 0.070, 32/6976 datapoints
2025-03-07 12:48:48,324 - INFO - validation batch 51, loss: 4.508, 1632/6976 datapoints
2025-03-07 12:48:48,403 - INFO - validation batch 101, loss: 0.486, 3232/6976 datapoints
2025-03-07 12:48:48,482 - INFO - validation batch 151, loss: 1.468, 4832/6976 datapoints
2025-03-07 12:48:48,561 - INFO - validation batch 201, loss: 0.953, 6432/6976 datapoints
2025-03-07 12:48:48,593 - INFO - Epoch 362/800 done.
2025-03-07 12:48:48,593 - INFO - Final validation performance:
Loss: 1.497, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:48:48,594 - INFO - Beginning epoch 363/800
2025-03-07 12:48:48,602 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:48:48,964 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:48:49,319 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:48:49,665 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:48:50,006 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:48:50,454 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:48:50,867 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:48:51,260 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:48:51,611 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:48:51,966 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:48:52,399 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:48:52,795 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:48:53,204 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:48:53,636 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:48:54,024 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:48:54,409 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:48:54,814 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:48:55,229 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:48:55,438 - INFO - validation batch 1, loss: 0.057, 32/6976 datapoints
2025-03-07 12:48:55,536 - INFO - validation batch 51, loss: 4.509, 1632/6976 datapoints
2025-03-07 12:48:55,640 - INFO - validation batch 101, loss: 0.465, 3232/6976 datapoints
2025-03-07 12:48:55,733 - INFO - validation batch 151, loss: 1.472, 4832/6976 datapoints
2025-03-07 12:48:55,834 - INFO - validation batch 201, loss: 0.932, 6432/6976 datapoints
2025-03-07 12:48:55,868 - INFO - Epoch 363/800 done.
2025-03-07 12:48:55,868 - INFO - Final validation performance:
Loss: 1.487, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:48:55,869 - INFO - Beginning epoch 364/800
2025-03-07 12:48:55,881 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:48:56,335 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:48:56,718 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:48:57,129 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:48:57,536 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:48:57,974 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:48:58,373 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:48:58,729 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:48:59,066 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:48:59,402 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:48:59,772 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:49:00,133 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 12:49:00,537 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:49:00,885 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:49:01,335 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:49:01,805 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:49:02,271 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:49:02,736 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:49:02,974 - INFO - validation batch 1, loss: 0.050, 32/6976 datapoints
2025-03-07 12:49:03,085 - INFO - validation batch 51, loss: 4.523, 1632/6976 datapoints
2025-03-07 12:49:03,198 - INFO - validation batch 101, loss: 0.466, 3232/6976 datapoints
2025-03-07 12:49:03,315 - INFO - validation batch 151, loss: 1.478, 4832/6976 datapoints
2025-03-07 12:49:03,403 - INFO - validation batch 201, loss: 0.925, 6432/6976 datapoints
2025-03-07 12:49:03,444 - INFO - Epoch 364/800 done.
2025-03-07 12:49:03,444 - INFO - Final validation performance:
Loss: 1.489, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:49:03,445 - INFO - Beginning epoch 365/800
2025-03-07 12:49:03,458 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:49:03,930 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:49:04,375 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:49:04,806 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:49:05,268 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:49:05,815 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:49:06,241 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:49:06,618 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:49:06,985 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:49:07,377 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:49:07,733 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:49:08,098 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 12:49:08,453 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:49:08,792 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:49:09,134 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:49:09,450 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:49:09,784 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:49:10,128 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:49:10,294 - INFO - validation batch 1, loss: 0.047, 32/6976 datapoints
2025-03-07 12:49:10,368 - INFO - validation batch 51, loss: 4.549, 1632/6976 datapoints
2025-03-07 12:49:10,443 - INFO - validation batch 101, loss: 0.463, 3232/6976 datapoints
2025-03-07 12:49:10,518 - INFO - validation batch 151, loss: 1.470, 4832/6976 datapoints
2025-03-07 12:49:10,592 - INFO - validation batch 201, loss: 0.916, 6432/6976 datapoints
2025-03-07 12:49:10,615 - INFO - Epoch 365/800 done.
2025-03-07 12:49:10,615 - INFO - Final validation performance:
Loss: 1.489, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:49:10,616 - INFO - Beginning epoch 366/800
2025-03-07 12:49:10,625 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:49:10,993 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:49:11,444 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:49:11,967 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:49:12,407 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:49:12,900 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:49:13,365 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:49:13,860 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:49:14,341 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:49:14,830 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:49:15,311 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:49:15,801 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 12:49:16,255 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:49:16,657 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:49:17,095 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:49:17,500 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:49:17,895 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:49:18,312 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:49:18,510 - INFO - validation batch 1, loss: 0.046, 32/6976 datapoints
2025-03-07 12:49:18,595 - INFO - validation batch 51, loss: 4.538, 1632/6976 datapoints
2025-03-07 12:49:18,709 - INFO - validation batch 101, loss: 0.453, 3232/6976 datapoints
2025-03-07 12:49:18,827 - INFO - validation batch 151, loss: 1.475, 4832/6976 datapoints
2025-03-07 12:49:18,923 - INFO - validation batch 201, loss: 0.896, 6432/6976 datapoints
2025-03-07 12:49:18,961 - INFO - Epoch 366/800 done.
2025-03-07 12:49:18,961 - INFO - Final validation performance:
Loss: 1.482, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:49:18,962 - INFO - Beginning epoch 367/800
2025-03-07 12:49:18,970 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:49:19,380 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:49:19,783 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:49:20,201 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:49:20,624 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 12:49:21,039 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:49:21,488 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:49:21,994 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:49:22,486 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:49:22,998 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:49:23,525 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:49:24,123 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:49:24,640 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:49:25,154 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:49:25,660 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:49:26,145 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:49:26,918 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 12:49:27,428 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:49:27,666 - INFO - validation batch 1, loss: 0.038, 32/6976 datapoints
2025-03-07 12:49:27,769 - INFO - validation batch 51, loss: 4.503, 1632/6976 datapoints
2025-03-07 12:49:27,873 - INFO - validation batch 101, loss: 0.481, 3232/6976 datapoints
2025-03-07 12:49:27,976 - INFO - validation batch 151, loss: 1.504, 4832/6976 datapoints
2025-03-07 12:49:28,081 - INFO - validation batch 201, loss: 0.889, 6432/6976 datapoints
2025-03-07 12:49:28,121 - INFO - Epoch 367/800 done.
2025-03-07 12:49:28,121 - INFO - Final validation performance:
Loss: 1.483, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:49:28,122 - INFO - Beginning epoch 368/800
2025-03-07 12:49:28,136 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:49:28,687 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:49:29,210 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:49:29,679 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:49:30,147 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:49:30,701 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:49:31,183 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:49:31,633 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:49:32,048 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:49:32,415 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:49:32,814 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:49:33,204 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:49:33,579 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 12:49:33,942 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 12:49:34,345 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:49:34,681 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:49:35,076 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:49:35,496 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:49:35,670 - INFO - validation batch 1, loss: 0.164, 32/6976 datapoints
2025-03-07 12:49:35,894 - INFO - validation batch 51, loss: 4.319, 1632/6976 datapoints
2025-03-07 12:49:35,996 - INFO - validation batch 101, loss: 1.086, 3232/6976 datapoints
2025-03-07 12:49:36,104 - INFO - validation batch 151, loss: 2.185, 4832/6976 datapoints
2025-03-07 12:49:36,252 - INFO - validation batch 201, loss: 2.176, 6432/6976 datapoints
2025-03-07 12:49:36,283 - INFO - Epoch 368/800 done.
2025-03-07 12:49:36,283 - INFO - Final validation performance:
Loss: 1.986, top-1 acc: 0.886top-5 acc: 0.886
2025-03-07 12:49:36,284 - INFO - Beginning epoch 369/800
2025-03-07 12:49:36,297 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:49:36,808 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:49:37,282 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:49:37,716 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:49:38,086 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:49:38,544 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:49:38,945 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:49:39,340 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:49:39,795 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:49:40,190 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:49:40,597 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:49:40,973 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:49:41,363 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:49:41,772 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:49:42,159 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:49:42,527 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:49:42,907 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:49:43,271 - INFO - training batch 851, loss: 0.002, 27232/28000 datapoints
2025-03-07 12:49:43,445 - INFO - validation batch 1, loss: 0.042, 32/6976 datapoints
2025-03-07 12:49:43,525 - INFO - validation batch 51, loss: 4.833, 1632/6976 datapoints
2025-03-07 12:49:43,633 - INFO - validation batch 101, loss: 0.839, 3232/6976 datapoints
2025-03-07 12:49:43,754 - INFO - validation batch 151, loss: 1.373, 4832/6976 datapoints
2025-03-07 12:49:43,845 - INFO - validation batch 201, loss: 1.234, 6432/6976 datapoints
2025-03-07 12:49:43,870 - INFO - Epoch 369/800 done.
2025-03-07 12:49:43,870 - INFO - Final validation performance:
Loss: 1.664, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:49:43,871 - INFO - Beginning epoch 370/800
2025-03-07 12:49:43,879 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:49:44,281 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:49:44,689 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:49:45,050 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:49:45,416 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:49:45,834 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:49:46,225 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:49:46,606 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:49:47,032 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:49:47,433 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:49:47,871 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:49:48,276 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:49:48,717 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:49:49,106 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:49:49,511 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:49:49,990 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:49:50,397 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:49:50,894 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:49:51,134 - INFO - validation batch 1, loss: 0.017, 32/6976 datapoints
2025-03-07 12:49:51,234 - INFO - validation batch 51, loss: 4.928, 1632/6976 datapoints
2025-03-07 12:49:51,331 - INFO - validation batch 101, loss: 0.774, 3232/6976 datapoints
2025-03-07 12:49:51,434 - INFO - validation batch 151, loss: 1.311, 4832/6976 datapoints
2025-03-07 12:49:51,528 - INFO - validation batch 201, loss: 1.115, 6432/6976 datapoints
2025-03-07 12:49:51,564 - INFO - Epoch 370/800 done.
2025-03-07 12:49:51,564 - INFO - Final validation performance:
Loss: 1.629, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:49:51,565 - INFO - Beginning epoch 371/800
2025-03-07 12:49:51,576 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:49:52,041 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:49:52,513 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:49:52,949 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:49:53,377 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:49:53,928 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:49:54,518 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:49:54,978 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:49:55,452 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:49:56,011 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:49:56,522 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:49:56,995 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:49:57,460 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:49:57,902 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:49:58,332 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:49:58,693 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:49:59,050 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:49:59,420 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:49:59,622 - INFO - validation batch 1, loss: 0.016, 32/6976 datapoints
2025-03-07 12:49:59,697 - INFO - validation batch 51, loss: 4.916, 1632/6976 datapoints
2025-03-07 12:49:59,772 - INFO - validation batch 101, loss: 0.764, 3232/6976 datapoints
2025-03-07 12:49:59,847 - INFO - validation batch 151, loss: 1.316, 4832/6976 datapoints
2025-03-07 12:49:59,922 - INFO - validation batch 201, loss: 1.113, 6432/6976 datapoints
2025-03-07 12:49:59,949 - INFO - Epoch 371/800 done.
2025-03-07 12:49:59,950 - INFO - Final validation performance:
Loss: 1.625, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:49:59,950 - INFO - Beginning epoch 372/800
2025-03-07 12:49:59,958 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:50:00,327 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:50:00,701 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:50:01,045 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:50:01,380 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:50:01,786 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:50:02,154 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:50:02,514 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:50:02,871 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:50:03,232 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:50:03,605 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:50:03,960 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:50:04,327 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:50:04,674 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:50:05,068 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:50:05,413 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:50:05,750 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:50:06,106 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:50:06,277 - INFO - validation batch 1, loss: 0.014, 32/6976 datapoints
2025-03-07 12:50:06,354 - INFO - validation batch 51, loss: 4.909, 1632/6976 datapoints
2025-03-07 12:50:06,428 - INFO - validation batch 101, loss: 0.759, 3232/6976 datapoints
2025-03-07 12:50:06,507 - INFO - validation batch 151, loss: 1.315, 4832/6976 datapoints
2025-03-07 12:50:06,578 - INFO - validation batch 201, loss: 1.107, 6432/6976 datapoints
2025-03-07 12:50:06,607 - INFO - Epoch 372/800 done.
2025-03-07 12:50:06,608 - INFO - Final validation performance:
Loss: 1.621, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:50:06,608 - INFO - Beginning epoch 373/800
2025-03-07 12:50:06,617 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:50:06,992 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:50:07,366 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:50:07,726 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:50:08,075 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:50:08,458 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:50:08,852 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:50:09,212 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:50:09,568 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:50:09,919 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:50:10,265 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:50:10,606 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:50:10,947 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:50:11,292 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:50:11,635 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:50:11,966 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:50:12,296 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:50:12,658 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:50:12,827 - INFO - validation batch 1, loss: 0.013, 32/6976 datapoints
2025-03-07 12:50:12,899 - INFO - validation batch 51, loss: 4.899, 1632/6976 datapoints
2025-03-07 12:50:12,970 - INFO - validation batch 101, loss: 0.754, 3232/6976 datapoints
2025-03-07 12:50:13,042 - INFO - validation batch 151, loss: 1.314, 4832/6976 datapoints
2025-03-07 12:50:13,117 - INFO - validation batch 201, loss: 1.098, 6432/6976 datapoints
2025-03-07 12:50:13,146 - INFO - Epoch 373/800 done.
2025-03-07 12:50:13,146 - INFO - Final validation performance:
Loss: 1.616, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:50:13,147 - INFO - Beginning epoch 374/800
2025-03-07 12:50:13,155 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:50:13,517 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:50:13,884 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:50:14,262 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:50:14,609 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:50:14,976 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:50:15,333 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:50:15,689 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:50:16,047 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:50:16,398 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:50:16,745 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:50:17,086 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:50:17,427 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:50:17,772 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:50:18,115 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:50:18,449 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:50:18,784 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:50:19,154 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:50:19,323 - INFO - validation batch 1, loss: 0.011, 32/6976 datapoints
2025-03-07 12:50:19,396 - INFO - validation batch 51, loss: 4.888, 1632/6976 datapoints
2025-03-07 12:50:19,479 - INFO - validation batch 101, loss: 0.749, 3232/6976 datapoints
2025-03-07 12:50:19,550 - INFO - validation batch 151, loss: 1.314, 4832/6976 datapoints
2025-03-07 12:50:19,623 - INFO - validation batch 201, loss: 1.088, 6432/6976 datapoints
2025-03-07 12:50:19,651 - INFO - Epoch 374/800 done.
2025-03-07 12:50:19,651 - INFO - Final validation performance:
Loss: 1.610, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:50:19,651 - INFO - Beginning epoch 375/800
2025-03-07 12:50:19,659 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:50:20,022 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:50:20,396 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:50:20,739 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:50:21,075 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:50:21,447 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:50:21,811 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:50:22,165 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:50:22,538 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:50:22,890 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:50:23,231 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:50:23,578 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:50:23,929 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:50:24,289 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:50:24,650 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:50:24,991 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:50:25,328 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:50:25,679 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:50:25,852 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 12:50:25,928 - INFO - validation batch 51, loss: 4.875, 1632/6976 datapoints
2025-03-07 12:50:26,002 - INFO - validation batch 101, loss: 0.742, 3232/6976 datapoints
2025-03-07 12:50:26,076 - INFO - validation batch 151, loss: 1.316, 4832/6976 datapoints
2025-03-07 12:50:26,157 - INFO - validation batch 201, loss: 1.077, 6432/6976 datapoints
2025-03-07 12:50:26,182 - INFO - Epoch 375/800 done.
2025-03-07 12:50:26,183 - INFO - Final validation performance:
Loss: 1.604, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:50:26,183 - INFO - Beginning epoch 376/800
2025-03-07 12:50:26,192 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:50:26,562 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:50:26,936 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:50:27,310 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:50:27,703 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:50:28,076 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:50:28,461 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:50:28,818 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:50:29,198 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:50:29,561 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:50:29,921 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:50:30,281 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:50:30,756 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:50:31,120 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:50:31,474 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:50:31,849 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:50:32,190 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:50:32,571 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:50:32,776 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 12:50:32,853 - INFO - validation batch 51, loss: 4.862, 1632/6976 datapoints
2025-03-07 12:50:32,934 - INFO - validation batch 101, loss: 0.735, 3232/6976 datapoints
2025-03-07 12:50:33,017 - INFO - validation batch 151, loss: 1.318, 4832/6976 datapoints
2025-03-07 12:50:33,093 - INFO - validation batch 201, loss: 1.065, 6432/6976 datapoints
2025-03-07 12:50:33,119 - INFO - Epoch 376/800 done.
2025-03-07 12:50:33,120 - INFO - Final validation performance:
Loss: 1.598, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:50:33,120 - INFO - Beginning epoch 377/800
2025-03-07 12:50:33,128 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:50:33,480 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:50:33,861 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:50:34,252 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:50:34,605 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:50:34,971 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:50:35,335 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:50:35,700 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:50:36,124 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:50:36,515 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:50:36,869 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:50:37,252 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:50:37,607 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:50:37,967 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:50:38,321 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:50:38,665 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:50:39,003 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:50:39,372 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:50:39,546 - INFO - validation batch 1, loss: 0.009, 32/6976 datapoints
2025-03-07 12:50:39,622 - INFO - validation batch 51, loss: 4.850, 1632/6976 datapoints
2025-03-07 12:50:39,698 - INFO - validation batch 101, loss: 0.726, 3232/6976 datapoints
2025-03-07 12:50:39,775 - INFO - validation batch 151, loss: 1.323, 4832/6976 datapoints
2025-03-07 12:50:39,858 - INFO - validation batch 201, loss: 1.055, 6432/6976 datapoints
2025-03-07 12:50:39,895 - INFO - Epoch 377/800 done.
2025-03-07 12:50:39,895 - INFO - Final validation performance:
Loss: 1.593, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:50:39,896 - INFO - Beginning epoch 378/800
2025-03-07 12:50:39,906 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:50:40,289 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:50:40,661 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:50:41,003 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:50:41,339 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:50:41,708 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:50:42,075 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:50:42,428 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:50:42,789 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:50:43,149 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:50:43,540 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:50:43,897 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:50:44,270 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:50:44,658 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:50:45,050 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:50:45,414 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:50:45,763 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:50:46,158 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:50:46,337 - INFO - validation batch 1, loss: 0.008, 32/6976 datapoints
2025-03-07 12:50:46,415 - INFO - validation batch 51, loss: 4.839, 1632/6976 datapoints
2025-03-07 12:50:46,501 - INFO - validation batch 101, loss: 0.716, 3232/6976 datapoints
2025-03-07 12:50:46,577 - INFO - validation batch 151, loss: 1.330, 4832/6976 datapoints
2025-03-07 12:50:46,655 - INFO - validation batch 201, loss: 1.045, 6432/6976 datapoints
2025-03-07 12:50:46,679 - INFO - Epoch 378/800 done.
2025-03-07 12:50:46,679 - INFO - Final validation performance:
Loss: 1.588, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:50:46,680 - INFO - Beginning epoch 379/800
2025-03-07 12:50:46,689 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:50:47,075 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:50:47,442 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:50:47,787 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:50:48,120 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:50:48,476 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:50:48,825 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:50:49,178 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:50:49,539 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:50:49,878 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:50:50,230 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:50:50,568 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:50:50,909 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:50:51,251 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:50:51,599 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:50:51,925 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:50:52,251 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:50:52,619 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:50:52,806 - INFO - validation batch 1, loss: 0.008, 32/6976 datapoints
2025-03-07 12:50:52,882 - INFO - validation batch 51, loss: 4.831, 1632/6976 datapoints
2025-03-07 12:50:52,955 - INFO - validation batch 101, loss: 0.705, 3232/6976 datapoints
2025-03-07 12:50:53,030 - INFO - validation batch 151, loss: 1.338, 4832/6976 datapoints
2025-03-07 12:50:53,104 - INFO - validation batch 201, loss: 1.036, 6432/6976 datapoints
2025-03-07 12:50:53,130 - INFO - Epoch 379/800 done.
2025-03-07 12:50:53,130 - INFO - Final validation performance:
Loss: 1.584, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:50:53,131 - INFO - Beginning epoch 380/800
2025-03-07 12:50:53,141 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:50:53,486 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:50:53,911 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:50:54,264 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:50:54,615 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:50:54,993 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:50:55,341 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:50:55,729 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:50:56,094 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:50:56,470 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:50:56,856 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:50:57,224 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:50:57,573 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:50:57,974 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:50:58,402 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:50:58,741 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:50:59,075 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:50:59,452 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:50:59,640 - INFO - validation batch 1, loss: 0.007, 32/6976 datapoints
2025-03-07 12:50:59,719 - INFO - validation batch 51, loss: 4.826, 1632/6976 datapoints
2025-03-07 12:50:59,797 - INFO - validation batch 101, loss: 0.692, 3232/6976 datapoints
2025-03-07 12:50:59,869 - INFO - validation batch 151, loss: 1.347, 4832/6976 datapoints
2025-03-07 12:50:59,939 - INFO - validation batch 201, loss: 1.029, 6432/6976 datapoints
2025-03-07 12:50:59,964 - INFO - Epoch 380/800 done.
2025-03-07 12:50:59,964 - INFO - Final validation performance:
Loss: 1.580, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:50:59,965 - INFO - Beginning epoch 381/800
2025-03-07 12:50:59,973 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:51:00,350 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:51:00,726 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:51:01,075 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:51:01,417 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:51:01,787 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:51:02,132 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:51:02,484 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:51:02,834 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:51:03,185 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:51:03,557 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:51:03,963 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:51:04,348 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:51:04,695 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:51:05,033 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:51:05,378 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:51:05,705 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:51:06,044 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:51:06,217 - INFO - validation batch 1, loss: 0.007, 32/6976 datapoints
2025-03-07 12:51:06,292 - INFO - validation batch 51, loss: 4.824, 1632/6976 datapoints
2025-03-07 12:51:06,365 - INFO - validation batch 101, loss: 0.676, 3232/6976 datapoints
2025-03-07 12:51:06,439 - INFO - validation batch 151, loss: 1.358, 4832/6976 datapoints
2025-03-07 12:51:06,517 - INFO - validation batch 201, loss: 1.025, 6432/6976 datapoints
2025-03-07 12:51:06,544 - INFO - Epoch 381/800 done.
2025-03-07 12:51:06,544 - INFO - Final validation performance:
Loss: 1.578, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:51:06,545 - INFO - Beginning epoch 382/800
2025-03-07 12:51:06,554 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:51:06,925 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:51:07,349 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:51:07,707 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:51:08,072 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:51:08,487 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:51:08,906 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:51:09,273 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:51:09,662 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:51:10,057 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:51:10,515 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:51:11,023 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:51:11,526 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:51:11,941 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:51:12,352 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:51:12,774 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:51:13,131 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:51:13,503 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:51:13,718 - INFO - validation batch 1, loss: 0.008, 32/6976 datapoints
2025-03-07 12:51:13,794 - INFO - validation batch 51, loss: 4.824, 1632/6976 datapoints
2025-03-07 12:51:13,869 - INFO - validation batch 101, loss: 0.657, 3232/6976 datapoints
2025-03-07 12:51:13,944 - INFO - validation batch 151, loss: 1.371, 4832/6976 datapoints
2025-03-07 12:51:14,019 - INFO - validation batch 201, loss: 1.022, 6432/6976 datapoints
2025-03-07 12:51:14,046 - INFO - Epoch 382/800 done.
2025-03-07 12:51:14,046 - INFO - Final validation performance:
Loss: 1.577, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:51:14,047 - INFO - Beginning epoch 383/800
2025-03-07 12:51:14,055 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:51:14,423 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:51:14,805 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:51:15,157 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:51:15,493 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:51:15,847 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:51:16,194 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:51:16,539 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:51:16,880 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:51:17,218 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:51:17,562 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:51:17,909 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:51:18,247 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:51:18,589 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:51:18,935 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:51:19,276 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:51:19,635 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:51:19,977 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:51:20,147 - INFO - validation batch 1, loss: 0.008, 32/6976 datapoints
2025-03-07 12:51:20,244 - INFO - validation batch 51, loss: 4.827, 1632/6976 datapoints
2025-03-07 12:51:20,316 - INFO - validation batch 101, loss: 0.636, 3232/6976 datapoints
2025-03-07 12:51:20,389 - INFO - validation batch 151, loss: 1.386, 4832/6976 datapoints
2025-03-07 12:51:20,460 - INFO - validation batch 201, loss: 1.023, 6432/6976 datapoints
2025-03-07 12:51:20,488 - INFO - Epoch 383/800 done.
2025-03-07 12:51:20,488 - INFO - Final validation performance:
Loss: 1.576, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:51:20,489 - INFO - Beginning epoch 384/800
2025-03-07 12:51:20,498 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:51:20,849 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:51:21,210 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:51:21,552 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:51:21,883 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:51:22,242 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:51:22,584 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:51:22,923 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:51:23,264 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:51:23,603 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:51:23,947 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:51:24,283 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:51:24,625 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:51:24,959 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:51:25,300 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:51:25,644 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:51:25,974 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:51:26,349 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:51:26,546 - INFO - validation batch 1, loss: 0.009, 32/6976 datapoints
2025-03-07 12:51:26,647 - INFO - validation batch 51, loss: 4.833, 1632/6976 datapoints
2025-03-07 12:51:26,739 - INFO - validation batch 101, loss: 0.612, 3232/6976 datapoints
2025-03-07 12:51:26,828 - INFO - validation batch 151, loss: 1.400, 4832/6976 datapoints
2025-03-07 12:51:26,915 - INFO - validation batch 201, loss: 1.024, 6432/6976 datapoints
2025-03-07 12:51:26,951 - INFO - Epoch 384/800 done.
2025-03-07 12:51:26,951 - INFO - Final validation performance:
Loss: 1.576, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:51:26,951 - INFO - Beginning epoch 385/800
2025-03-07 12:51:26,961 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:51:27,328 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:51:27,716 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:51:28,066 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:51:28,407 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:51:28,782 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:51:29,145 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:51:29,497 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:51:29,871 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:51:30,219 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:51:30,590 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:51:30,933 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:51:31,281 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:51:31,625 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:51:31,976 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:51:32,309 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:51:32,640 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:51:32,980 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:51:33,150 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 12:51:33,224 - INFO - validation batch 51, loss: 4.841, 1632/6976 datapoints
2025-03-07 12:51:33,299 - INFO - validation batch 101, loss: 0.588, 3232/6976 datapoints
2025-03-07 12:51:33,372 - INFO - validation batch 151, loss: 1.414, 4832/6976 datapoints
2025-03-07 12:51:33,445 - INFO - validation batch 201, loss: 1.025, 6432/6976 datapoints
2025-03-07 12:51:33,472 - INFO - Epoch 385/800 done.
2025-03-07 12:51:33,472 - INFO - Final validation performance:
Loss: 1.576, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:51:33,473 - INFO - Beginning epoch 386/800
2025-03-07 12:51:33,482 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:51:33,846 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:51:34,214 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:51:34,820 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:51:35,413 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:51:35,845 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:51:36,228 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:51:36,592 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:51:36,945 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:51:37,297 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:51:37,653 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:51:38,007 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:51:38,361 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:51:38,707 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:51:39,047 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:51:39,381 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:51:39,741 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:51:40,089 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:51:40,292 - INFO - validation batch 1, loss: 0.011, 32/6976 datapoints
2025-03-07 12:51:40,385 - INFO - validation batch 51, loss: 4.847, 1632/6976 datapoints
2025-03-07 12:51:40,456 - INFO - validation batch 101, loss: 0.566, 3232/6976 datapoints
2025-03-07 12:51:40,530 - INFO - validation batch 151, loss: 1.428, 4832/6976 datapoints
2025-03-07 12:51:40,601 - INFO - validation batch 201, loss: 1.028, 6432/6976 datapoints
2025-03-07 12:51:40,623 - INFO - Epoch 386/800 done.
2025-03-07 12:51:40,624 - INFO - Final validation performance:
Loss: 1.576, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:51:40,624 - INFO - Beginning epoch 387/800
2025-03-07 12:51:40,634 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:51:40,979 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:51:41,348 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:51:41,695 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:51:42,045 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:51:42,447 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:51:42,790 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:51:43,178 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:51:43,584 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:51:44,009 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:51:44,396 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:51:44,778 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:51:45,164 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:51:45,551 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:51:45,966 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:51:46,319 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:51:46,753 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:51:47,282 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:51:47,621 - INFO - validation batch 1, loss: 0.013, 32/6976 datapoints
2025-03-07 12:51:47,722 - INFO - validation batch 51, loss: 4.850, 1632/6976 datapoints
2025-03-07 12:51:47,985 - INFO - validation batch 101, loss: 0.543, 3232/6976 datapoints
2025-03-07 12:51:48,106 - INFO - validation batch 151, loss: 1.446, 4832/6976 datapoints
2025-03-07 12:51:48,199 - INFO - validation batch 201, loss: 1.034, 6432/6976 datapoints
2025-03-07 12:51:48,228 - INFO - Epoch 387/800 done.
2025-03-07 12:51:48,228 - INFO - Final validation performance:
Loss: 1.577, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:51:48,229 - INFO - Beginning epoch 388/800
2025-03-07 12:51:48,242 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:51:48,790 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:51:49,282 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:51:49,826 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:51:50,200 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:51:50,641 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:51:51,005 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:51:51,375 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:51:51,750 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:51:52,107 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:51:52,481 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:51:52,935 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:51:53,291 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:51:53,711 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:51:54,102 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:51:54,449 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:51:54,862 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:51:55,273 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:51:55,504 - INFO - validation batch 1, loss: 0.016, 32/6976 datapoints
2025-03-07 12:51:55,609 - INFO - validation batch 51, loss: 4.849, 1632/6976 datapoints
2025-03-07 12:51:55,696 - INFO - validation batch 101, loss: 0.521, 3232/6976 datapoints
2025-03-07 12:51:55,787 - INFO - validation batch 151, loss: 1.467, 4832/6976 datapoints
2025-03-07 12:51:55,879 - INFO - validation batch 201, loss: 1.044, 6432/6976 datapoints
2025-03-07 12:51:55,916 - INFO - Epoch 388/800 done.
2025-03-07 12:51:55,917 - INFO - Final validation performance:
Loss: 1.579, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:51:55,918 - INFO - Beginning epoch 389/800
2025-03-07 12:51:55,927 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:51:56,403 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:51:56,803 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:51:57,216 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:51:57,653 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:51:58,194 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:51:58,607 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:51:58,968 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:51:59,320 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:51:59,682 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:52:00,087 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:52:00,509 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:52:00,877 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:52:01,228 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:52:01,596 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:52:02,012 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:52:02,362 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:52:02,780 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:52:02,982 - INFO - validation batch 1, loss: 0.019, 32/6976 datapoints
2025-03-07 12:52:03,071 - INFO - validation batch 51, loss: 4.847, 1632/6976 datapoints
2025-03-07 12:52:03,144 - INFO - validation batch 101, loss: 0.500, 3232/6976 datapoints
2025-03-07 12:52:03,231 - INFO - validation batch 151, loss: 1.491, 4832/6976 datapoints
2025-03-07 12:52:03,318 - INFO - validation batch 201, loss: 1.059, 6432/6976 datapoints
2025-03-07 12:52:03,346 - INFO - Epoch 389/800 done.
2025-03-07 12:52:03,346 - INFO - Final validation performance:
Loss: 1.583, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:52:03,347 - INFO - Beginning epoch 390/800
2025-03-07 12:52:03,356 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:52:03,791 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:52:04,246 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:52:04,653 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:52:05,027 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:52:05,432 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:52:05,844 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:52:06,222 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:52:06,585 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:52:06,986 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:52:07,390 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:52:07,779 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:52:08,139 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:52:08,496 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 12:52:08,857 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:52:09,236 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:52:09,605 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:52:09,981 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:52:10,210 - INFO - validation batch 1, loss: 0.024, 32/6976 datapoints
2025-03-07 12:52:10,308 - INFO - validation batch 51, loss: 4.851, 1632/6976 datapoints
2025-03-07 12:52:10,408 - INFO - validation batch 101, loss: 0.483, 3232/6976 datapoints
2025-03-07 12:52:10,504 - INFO - validation batch 151, loss: 1.512, 4832/6976 datapoints
2025-03-07 12:52:10,597 - INFO - validation batch 201, loss: 1.071, 6432/6976 datapoints
2025-03-07 12:52:10,622 - INFO - Epoch 390/800 done.
2025-03-07 12:52:10,622 - INFO - Final validation performance:
Loss: 1.588, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:52:10,622 - INFO - Beginning epoch 391/800
2025-03-07 12:52:10,630 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:52:11,030 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:52:11,466 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:52:11,871 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:52:12,247 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:52:12,655 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:52:13,044 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:52:13,458 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:52:13,831 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:52:14,235 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:52:14,706 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:52:15,126 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:52:15,584 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:52:16,036 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:52:16,444 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:52:16,819 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:52:17,225 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:52:17,649 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:52:17,847 - INFO - validation batch 1, loss: 0.028, 32/6976 datapoints
2025-03-07 12:52:17,940 - INFO - validation batch 51, loss: 4.855, 1632/6976 datapoints
2025-03-07 12:52:18,038 - INFO - validation batch 101, loss: 0.469, 3232/6976 datapoints
2025-03-07 12:52:18,127 - INFO - validation batch 151, loss: 1.531, 4832/6976 datapoints
2025-03-07 12:52:18,218 - INFO - validation batch 201, loss: 1.076, 6432/6976 datapoints
2025-03-07 12:52:18,263 - INFO - Epoch 391/800 done.
2025-03-07 12:52:18,263 - INFO - Final validation performance:
Loss: 1.592, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:52:18,265 - INFO - Beginning epoch 392/800
2025-03-07 12:52:18,288 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:52:18,822 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:52:19,344 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:52:19,956 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:52:20,490 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:52:20,975 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:52:21,434 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:52:21,895 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:52:22,320 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:52:22,771 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:52:23,197 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:52:23,608 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:52:24,029 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:52:24,450 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:52:24,868 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:52:25,282 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:52:25,690 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:52:26,123 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:52:26,331 - INFO - validation batch 1, loss: 0.030, 32/6976 datapoints
2025-03-07 12:52:26,423 - INFO - validation batch 51, loss: 4.856, 1632/6976 datapoints
2025-03-07 12:52:26,518 - INFO - validation batch 101, loss: 0.465, 3232/6976 datapoints
2025-03-07 12:52:26,625 - INFO - validation batch 151, loss: 1.543, 4832/6976 datapoints
2025-03-07 12:52:26,730 - INFO - validation batch 201, loss: 1.070, 6432/6976 datapoints
2025-03-07 12:52:26,766 - INFO - Epoch 392/800 done.
2025-03-07 12:52:26,766 - INFO - Final validation performance:
Loss: 1.593, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:52:26,766 - INFO - Beginning epoch 393/800
2025-03-07 12:52:26,777 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:52:27,243 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:52:27,729 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:52:28,182 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:52:28,650 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:52:29,119 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:52:29,577 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:52:30,055 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:52:30,567 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:52:31,000 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:52:31,425 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:52:31,859 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:52:32,344 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:52:32,811 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:52:33,230 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:52:33,655 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:52:34,060 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:52:34,481 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:52:34,699 - INFO - validation batch 1, loss: 0.032, 32/6976 datapoints
2025-03-07 12:52:34,794 - INFO - validation batch 51, loss: 4.848, 1632/6976 datapoints
2025-03-07 12:52:34,886 - INFO - validation batch 101, loss: 0.465, 3232/6976 datapoints
2025-03-07 12:52:34,974 - INFO - validation batch 151, loss: 1.557, 4832/6976 datapoints
2025-03-07 12:52:35,068 - INFO - validation batch 201, loss: 1.067, 6432/6976 datapoints
2025-03-07 12:52:35,099 - INFO - Epoch 393/800 done.
2025-03-07 12:52:35,100 - INFO - Final validation performance:
Loss: 1.594, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:52:35,100 - INFO - Beginning epoch 394/800
2025-03-07 12:52:35,110 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:52:35,549 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:52:36,006 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:52:36,440 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:52:36,887 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:52:37,346 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:52:37,849 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:52:38,316 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:52:38,761 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:52:39,201 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:52:39,653 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:52:40,086 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:52:40,608 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:52:41,086 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:52:41,522 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:52:41,934 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:52:42,363 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:52:42,793 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:52:42,998 - INFO - validation batch 1, loss: 0.032, 32/6976 datapoints
2025-03-07 12:52:43,086 - INFO - validation batch 51, loss: 4.831, 1632/6976 datapoints
2025-03-07 12:52:43,176 - INFO - validation batch 101, loss: 0.469, 3232/6976 datapoints
2025-03-07 12:52:43,266 - INFO - validation batch 151, loss: 1.557, 4832/6976 datapoints
2025-03-07 12:52:43,361 - INFO - validation batch 201, loss: 1.047, 6432/6976 datapoints
2025-03-07 12:52:43,393 - INFO - Epoch 394/800 done.
2025-03-07 12:52:43,394 - INFO - Final validation performance:
Loss: 1.587, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:52:43,396 - INFO - Beginning epoch 395/800
2025-03-07 12:52:43,409 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:52:43,990 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:52:44,489 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:52:44,924 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:52:45,347 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:52:45,832 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:52:46,256 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:52:46,732 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:52:47,168 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:52:47,610 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:52:48,041 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:52:48,464 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:52:48,905 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:52:49,354 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:52:49,797 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:52:50,209 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:52:50,668 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:52:51,138 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:52:51,346 - INFO - validation batch 1, loss: 0.031, 32/6976 datapoints
2025-03-07 12:52:51,450 - INFO - validation batch 51, loss: 4.824, 1632/6976 datapoints
2025-03-07 12:52:51,564 - INFO - validation batch 101, loss: 0.462, 3232/6976 datapoints
2025-03-07 12:52:51,665 - INFO - validation batch 151, loss: 1.552, 4832/6976 datapoints
2025-03-07 12:52:51,766 - INFO - validation batch 201, loss: 1.026, 6432/6976 datapoints
2025-03-07 12:52:51,802 - INFO - Epoch 395/800 done.
2025-03-07 12:52:51,802 - INFO - Final validation performance:
Loss: 1.579, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:52:51,803 - INFO - Beginning epoch 396/800
2025-03-07 12:52:51,816 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:52:52,277 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:52:52,734 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:52:53,177 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:52:53,624 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:52:54,115 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:52:54,562 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:52:55,010 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:52:55,440 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:52:55,894 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 12:52:56,322 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:52:56,779 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 12:52:57,251 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:52:57,712 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 12:52:58,235 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:52:58,672 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:52:59,094 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 12:52:59,474 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:52:59,659 - INFO - validation batch 1, loss: 0.028, 32/6976 datapoints
2025-03-07 12:52:59,746 - INFO - validation batch 51, loss: 4.810, 1632/6976 datapoints
2025-03-07 12:52:59,835 - INFO - validation batch 101, loss: 0.473, 3232/6976 datapoints
2025-03-07 12:52:59,920 - INFO - validation batch 151, loss: 1.544, 4832/6976 datapoints
2025-03-07 12:53:00,005 - INFO - validation batch 201, loss: 1.025, 6432/6976 datapoints
2025-03-07 12:53:00,034 - INFO - Epoch 396/800 done.
2025-03-07 12:53:00,034 - INFO - Final validation performance:
Loss: 1.576, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:53:00,035 - INFO - Beginning epoch 397/800
2025-03-07 12:53:00,046 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:53:00,437 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:53:00,882 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:53:01,270 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:53:01,632 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:53:02,009 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:53:02,367 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:53:02,773 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:53:03,172 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:53:03,598 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 12:53:04,002 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:53:04,434 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 12:53:04,934 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:53:05,392 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 12:53:05,836 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:53:06,251 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:53:06,709 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 12:53:07,161 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:53:07,402 - INFO - validation batch 1, loss: 0.028, 32/6976 datapoints
2025-03-07 12:53:07,513 - INFO - validation batch 51, loss: 4.812, 1632/6976 datapoints
2025-03-07 12:53:07,633 - INFO - validation batch 101, loss: 0.491, 3232/6976 datapoints
2025-03-07 12:53:07,738 - INFO - validation batch 151, loss: 1.554, 4832/6976 datapoints
2025-03-07 12:53:07,847 - INFO - validation batch 201, loss: 1.026, 6432/6976 datapoints
2025-03-07 12:53:07,879 - INFO - Epoch 397/800 done.
2025-03-07 12:53:07,879 - INFO - Final validation performance:
Loss: 1.582, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:53:07,880 - INFO - Beginning epoch 398/800
2025-03-07 12:53:07,892 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:53:08,383 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:53:08,888 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:53:09,369 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:53:09,856 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:53:10,371 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:53:10,872 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:53:11,333 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:53:11,779 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:53:12,225 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:53:12,660 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:53:13,081 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 12:53:13,546 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:53:14,003 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 12:53:14,425 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:53:14,849 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 12:53:15,273 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 12:53:15,714 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:53:15,951 - INFO - validation batch 1, loss: 0.023, 32/6976 datapoints
2025-03-07 12:53:16,047 - INFO - validation batch 51, loss: 4.771, 1632/6976 datapoints
2025-03-07 12:53:16,145 - INFO - validation batch 101, loss: 0.474, 3232/6976 datapoints
2025-03-07 12:53:16,242 - INFO - validation batch 151, loss: 1.532, 4832/6976 datapoints
2025-03-07 12:53:16,336 - INFO - validation batch 201, loss: 0.995, 6432/6976 datapoints
2025-03-07 12:53:16,367 - INFO - Epoch 398/800 done.
2025-03-07 12:53:16,367 - INFO - Final validation performance:
Loss: 1.559, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:53:16,368 - INFO - Beginning epoch 399/800
2025-03-07 12:53:16,379 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:53:16,848 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 12:53:17,298 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:53:17,753 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:53:18,189 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:53:18,628 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:53:19,007 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:53:19,404 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:53:19,768 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:53:20,135 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:53:20,492 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 12:53:20,868 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:53:21,256 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:53:21,660 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 12:53:22,049 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:53:22,420 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 12:53:22,799 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 12:53:23,182 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:53:23,371 - INFO - validation batch 1, loss: 0.016, 32/6976 datapoints
2025-03-07 12:53:23,454 - INFO - validation batch 51, loss: 4.751, 1632/6976 datapoints
2025-03-07 12:53:23,546 - INFO - validation batch 101, loss: 0.473, 3232/6976 datapoints
2025-03-07 12:53:23,623 - INFO - validation batch 151, loss: 1.547, 4832/6976 datapoints
2025-03-07 12:53:23,699 - INFO - validation batch 201, loss: 0.969, 6432/6976 datapoints
2025-03-07 12:53:23,730 - INFO - Epoch 399/800 done.
2025-03-07 12:53:23,730 - INFO - Final validation performance:
Loss: 1.551, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:53:23,730 - INFO - Beginning epoch 400/800
2025-03-07 12:53:23,739 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:53:24,147 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 12:53:24,559 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:53:24,946 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:53:25,315 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:53:25,734 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:53:26,127 - INFO - training batch 301, loss: -0.000, 9632/28000 datapoints
2025-03-07 12:53:26,516 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:53:26,881 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:53:27,255 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:53:27,622 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:53:28,024 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 12:53:28,414 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 12:53:28,802 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 12:53:29,183 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:53:29,542 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:53:29,919 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 12:53:30,338 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 12:53:30,560 - INFO - validation batch 1, loss: 0.022, 32/6976 datapoints
2025-03-07 12:53:30,647 - INFO - validation batch 51, loss: 4.738, 1632/6976 datapoints
2025-03-07 12:53:30,732 - INFO - validation batch 101, loss: 0.577, 3232/6976 datapoints
2025-03-07 12:53:30,822 - INFO - validation batch 151, loss: 1.616, 4832/6976 datapoints
2025-03-07 12:53:30,903 - INFO - validation batch 201, loss: 1.066, 6432/6976 datapoints
2025-03-07 12:53:30,932 - INFO - Epoch 400/800 done.
2025-03-07 12:53:30,932 - INFO - Final validation performance:
Loss: 1.604, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:53:30,933 - INFO - Beginning epoch 401/800
2025-03-07 12:53:30,942 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:53:31,388 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:53:31,820 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:53:32,261 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:53:32,682 - INFO - training batch 201, loss: 0.001, 6432/28000 datapoints
2025-03-07 12:53:33,062 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:53:33,476 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:53:33,891 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:53:34,252 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:53:34,615 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:53:34,988 - INFO - training batch 501, loss: 0.011, 16032/28000 datapoints
2025-03-07 12:53:35,375 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:53:35,755 - INFO - training batch 601, loss: 0.010, 19232/28000 datapoints
2025-03-07 12:53:36,120 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:53:36,493 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:53:37,000 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:53:37,352 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:53:37,717 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:53:37,886 - INFO - validation batch 1, loss: 0.029, 32/6976 datapoints
2025-03-07 12:53:37,959 - INFO - validation batch 51, loss: 4.868, 1632/6976 datapoints
2025-03-07 12:53:38,037 - INFO - validation batch 101, loss: 0.374, 3232/6976 datapoints
2025-03-07 12:53:38,131 - INFO - validation batch 151, loss: 1.466, 4832/6976 datapoints
2025-03-07 12:53:38,214 - INFO - validation batch 201, loss: 0.667, 6432/6976 datapoints
2025-03-07 12:53:38,242 - INFO - Epoch 401/800 done.
2025-03-07 12:53:38,243 - INFO - Final validation performance:
Loss: 1.481, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:53:38,243 - INFO - Beginning epoch 402/800
2025-03-07 12:53:38,252 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:53:38,664 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:53:39,149 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:53:39,622 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:53:40,121 - INFO - training batch 201, loss: 0.154, 6432/28000 datapoints
2025-03-07 12:53:40,622 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:53:41,206 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:53:41,677 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:53:42,133 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:53:42,733 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:53:43,219 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:53:43,702 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:53:44,187 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:53:44,675 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:53:45,171 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:53:45,670 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:53:46,128 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:53:46,583 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:53:46,809 - INFO - validation batch 1, loss: 0.017, 32/6976 datapoints
2025-03-07 12:53:46,910 - INFO - validation batch 51, loss: 4.932, 1632/6976 datapoints
2025-03-07 12:53:47,011 - INFO - validation batch 101, loss: 0.473, 3232/6976 datapoints
2025-03-07 12:53:47,119 - INFO - validation batch 151, loss: 1.303, 4832/6976 datapoints
2025-03-07 12:53:47,234 - INFO - validation batch 201, loss: 0.800, 6432/6976 datapoints
2025-03-07 12:53:47,293 - INFO - Epoch 402/800 done.
2025-03-07 12:53:47,293 - INFO - Final validation performance:
Loss: 1.505, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:53:47,294 - INFO - Beginning epoch 403/800
2025-03-07 12:53:47,306 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:53:47,844 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:53:48,378 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:53:48,915 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:53:49,363 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:53:49,816 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:53:50,240 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:53:50,638 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:53:51,036 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:53:51,457 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:53:51,858 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:53:52,276 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:53:52,689 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:53:53,077 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:53:53,478 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:53:53,863 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:53:54,229 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:53:54,615 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:53:54,815 - INFO - validation batch 1, loss: 0.037, 32/6976 datapoints
2025-03-07 12:53:54,897 - INFO - validation batch 51, loss: 4.840, 1632/6976 datapoints
2025-03-07 12:53:54,991 - INFO - validation batch 101, loss: 0.429, 3232/6976 datapoints
2025-03-07 12:53:55,093 - INFO - validation batch 151, loss: 1.370, 4832/6976 datapoints
2025-03-07 12:53:55,200 - INFO - validation batch 201, loss: 0.870, 6432/6976 datapoints
2025-03-07 12:53:55,225 - INFO - Epoch 403/800 done.
2025-03-07 12:53:55,225 - INFO - Final validation performance:
Loss: 1.509, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:53:55,226 - INFO - Beginning epoch 404/800
2025-03-07 12:53:55,235 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:53:55,617 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:53:56,023 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:53:56,407 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:53:56,854 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:53:57,269 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:53:57,659 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:53:58,072 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:53:58,502 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:53:58,917 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:53:59,349 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:53:59,784 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:54:00,204 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:54:00,626 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:54:01,050 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:54:01,432 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:54:01,823 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:54:02,270 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:54:02,464 - INFO - validation batch 1, loss: 0.030, 32/6976 datapoints
2025-03-07 12:54:02,557 - INFO - validation batch 51, loss: 4.863, 1632/6976 datapoints
2025-03-07 12:54:02,650 - INFO - validation batch 101, loss: 0.423, 3232/6976 datapoints
2025-03-07 12:54:02,737 - INFO - validation batch 151, loss: 1.362, 4832/6976 datapoints
2025-03-07 12:54:02,824 - INFO - validation batch 201, loss: 0.851, 6432/6976 datapoints
2025-03-07 12:54:02,855 - INFO - Epoch 404/800 done.
2025-03-07 12:54:02,856 - INFO - Final validation performance:
Loss: 1.506, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:54:02,856 - INFO - Beginning epoch 405/800
2025-03-07 12:54:02,865 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:54:03,270 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:54:03,715 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:54:04,145 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:54:04,560 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:54:04,977 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:54:05,397 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:54:05,806 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:54:06,219 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:54:06,617 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:54:07,036 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:54:07,490 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:54:07,966 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:54:08,386 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:54:08,789 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:54:09,182 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:54:09,621 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:54:10,069 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:54:10,253 - INFO - validation batch 1, loss: 0.027, 32/6976 datapoints
2025-03-07 12:54:10,342 - INFO - validation batch 51, loss: 4.876, 1632/6976 datapoints
2025-03-07 12:54:10,424 - INFO - validation batch 101, loss: 0.416, 3232/6976 datapoints
2025-03-07 12:54:10,509 - INFO - validation batch 151, loss: 1.358, 4832/6976 datapoints
2025-03-07 12:54:10,589 - INFO - validation batch 201, loss: 0.843, 6432/6976 datapoints
2025-03-07 12:54:10,632 - INFO - Epoch 405/800 done.
2025-03-07 12:54:10,632 - INFO - Final validation performance:
Loss: 1.504, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:54:10,633 - INFO - Beginning epoch 406/800
2025-03-07 12:54:10,644 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:54:11,059 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:54:11,555 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:54:11,971 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:54:12,385 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:54:12,786 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:54:13,197 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:54:13,599 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:54:13,995 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:54:14,406 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:54:14,812 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:54:15,227 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:54:15,724 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:54:16,134 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:54:16,504 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:54:16,887 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:54:17,278 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:54:17,681 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:54:17,865 - INFO - validation batch 1, loss: 0.026, 32/6976 datapoints
2025-03-07 12:54:17,947 - INFO - validation batch 51, loss: 4.883, 1632/6976 datapoints
2025-03-07 12:54:18,031 - INFO - validation batch 101, loss: 0.410, 3232/6976 datapoints
2025-03-07 12:54:18,119 - INFO - validation batch 151, loss: 1.358, 4832/6976 datapoints
2025-03-07 12:54:18,204 - INFO - validation batch 201, loss: 0.839, 6432/6976 datapoints
2025-03-07 12:54:18,229 - INFO - Epoch 406/800 done.
2025-03-07 12:54:18,230 - INFO - Final validation performance:
Loss: 1.503, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:54:18,230 - INFO - Beginning epoch 407/800
2025-03-07 12:54:18,240 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:54:18,699 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:54:19,128 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:54:19,554 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:54:19,974 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:54:20,416 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:54:20,834 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:54:21,242 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:54:21,653 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:54:22,068 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:54:22,472 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:54:22,865 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:54:23,268 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:54:23,641 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:54:24,028 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:54:24,423 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:54:24,865 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:54:25,269 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:54:25,462 - INFO - validation batch 1, loss: 0.026, 32/6976 datapoints
2025-03-07 12:54:25,552 - INFO - validation batch 51, loss: 4.889, 1632/6976 datapoints
2025-03-07 12:54:25,647 - INFO - validation batch 101, loss: 0.403, 3232/6976 datapoints
2025-03-07 12:54:25,765 - INFO - validation batch 151, loss: 1.358, 4832/6976 datapoints
2025-03-07 12:54:25,851 - INFO - validation batch 201, loss: 0.837, 6432/6976 datapoints
2025-03-07 12:54:25,881 - INFO - Epoch 407/800 done.
2025-03-07 12:54:25,881 - INFO - Final validation performance:
Loss: 1.503, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:54:25,882 - INFO - Beginning epoch 408/800
2025-03-07 12:54:25,891 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:54:26,387 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:54:26,873 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:54:27,393 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:54:27,859 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:54:28,319 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:54:28,955 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:54:29,427 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:54:29,867 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:54:30,316 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:54:30,812 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:54:31,259 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:54:31,718 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:54:32,171 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:54:32,603 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:54:33,020 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:54:33,431 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:54:33,861 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:54:34,063 - INFO - validation batch 1, loss: 0.026, 32/6976 datapoints
2025-03-07 12:54:34,150 - INFO - validation batch 51, loss: 4.895, 1632/6976 datapoints
2025-03-07 12:54:34,238 - INFO - validation batch 101, loss: 0.398, 3232/6976 datapoints
2025-03-07 12:54:34,323 - INFO - validation batch 151, loss: 1.358, 4832/6976 datapoints
2025-03-07 12:54:34,408 - INFO - validation batch 201, loss: 0.836, 6432/6976 datapoints
2025-03-07 12:54:34,441 - INFO - Epoch 408/800 done.
2025-03-07 12:54:34,441 - INFO - Final validation performance:
Loss: 1.503, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:54:34,442 - INFO - Beginning epoch 409/800
2025-03-07 12:54:34,452 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:54:34,927 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:54:35,401 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:54:35,824 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:54:36,223 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:54:36,632 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:54:37,030 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:54:37,415 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:54:37,805 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:54:38,177 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:54:38,570 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:54:38,960 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:54:39,404 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:54:39,829 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:54:40,234 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:54:40,631 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:54:41,084 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:54:41,484 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:54:41,667 - INFO - validation batch 1, loss: 0.026, 32/6976 datapoints
2025-03-07 12:54:41,752 - INFO - validation batch 51, loss: 4.900, 1632/6976 datapoints
2025-03-07 12:54:41,861 - INFO - validation batch 101, loss: 0.395, 3232/6976 datapoints
2025-03-07 12:54:41,961 - INFO - validation batch 151, loss: 1.359, 4832/6976 datapoints
2025-03-07 12:54:42,049 - INFO - validation batch 201, loss: 0.837, 6432/6976 datapoints
2025-03-07 12:54:42,084 - INFO - Epoch 409/800 done.
2025-03-07 12:54:42,084 - INFO - Final validation performance:
Loss: 1.503, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:54:42,085 - INFO - Beginning epoch 410/800
2025-03-07 12:54:42,098 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:54:42,543 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:54:43,004 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:54:43,455 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:54:43,868 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:54:44,284 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:54:44,705 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:54:45,086 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:54:45,452 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:54:45,825 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:54:46,198 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:54:46,574 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:54:46,947 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:54:47,317 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:54:47,696 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:54:48,051 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:54:48,405 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:54:48,763 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:54:48,934 - INFO - validation batch 1, loss: 0.027, 32/6976 datapoints
2025-03-07 12:54:49,010 - INFO - validation batch 51, loss: 4.906, 1632/6976 datapoints
2025-03-07 12:54:49,085 - INFO - validation batch 101, loss: 0.393, 3232/6976 datapoints
2025-03-07 12:54:49,159 - INFO - validation batch 151, loss: 1.359, 4832/6976 datapoints
2025-03-07 12:54:49,236 - INFO - validation batch 201, loss: 0.839, 6432/6976 datapoints
2025-03-07 12:54:49,265 - INFO - Epoch 410/800 done.
2025-03-07 12:54:49,265 - INFO - Final validation performance:
Loss: 1.505, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:54:49,266 - INFO - Beginning epoch 411/800
2025-03-07 12:54:49,273 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:54:49,658 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:54:50,145 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:54:50,576 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:54:51,009 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:54:51,457 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:54:51,893 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:54:52,482 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:54:53,052 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:54:53,639 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:54:54,263 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:54:55,427 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:54:56,364 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:54:57,425 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:54:57,961 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:54:58,408 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:54:58,790 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:54:59,191 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:54:59,409 - INFO - validation batch 1, loss: 0.026, 32/6976 datapoints
2025-03-07 12:54:59,487 - INFO - validation batch 51, loss: 4.912, 1632/6976 datapoints
2025-03-07 12:54:59,573 - INFO - validation batch 101, loss: 0.392, 3232/6976 datapoints
2025-03-07 12:54:59,647 - INFO - validation batch 151, loss: 1.358, 4832/6976 datapoints
2025-03-07 12:54:59,721 - INFO - validation batch 201, loss: 0.841, 6432/6976 datapoints
2025-03-07 12:54:59,749 - INFO - Epoch 411/800 done.
2025-03-07 12:54:59,750 - INFO - Final validation performance:
Loss: 1.506, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:54:59,751 - INFO - Beginning epoch 412/800
2025-03-07 12:54:59,761 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:55:00,155 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:55:00,552 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:55:00,928 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:55:01,291 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:55:01,670 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:55:02,070 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:55:02,455 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:55:02,825 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:55:03,190 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:55:03,563 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:55:04,108 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:55:04,577 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:55:05,005 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:55:05,404 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:55:05,791 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:55:06,244 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:55:06,716 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:55:06,961 - INFO - validation batch 1, loss: 0.026, 32/6976 datapoints
2025-03-07 12:55:07,065 - INFO - validation batch 51, loss: 4.917, 1632/6976 datapoints
2025-03-07 12:55:07,178 - INFO - validation batch 101, loss: 0.392, 3232/6976 datapoints
2025-03-07 12:55:07,284 - INFO - validation batch 151, loss: 1.356, 4832/6976 datapoints
2025-03-07 12:55:07,387 - INFO - validation batch 201, loss: 0.843, 6432/6976 datapoints
2025-03-07 12:55:07,422 - INFO - Epoch 412/800 done.
2025-03-07 12:55:07,422 - INFO - Final validation performance:
Loss: 1.507, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:55:07,423 - INFO - Beginning epoch 413/800
2025-03-07 12:55:07,431 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:55:07,875 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:55:08,328 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:55:08,731 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:55:09,129 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:55:09,514 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:55:09,891 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:55:10,261 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:55:10,624 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:55:10,987 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:55:11,362 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:55:11,739 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:55:12,125 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:55:12,525 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:55:12,888 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:55:13,237 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:55:13,590 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:55:13,941 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:55:14,110 - INFO - validation batch 1, loss: 0.025, 32/6976 datapoints
2025-03-07 12:55:14,185 - INFO - validation batch 51, loss: 4.922, 1632/6976 datapoints
2025-03-07 12:55:14,259 - INFO - validation batch 101, loss: 0.394, 3232/6976 datapoints
2025-03-07 12:55:14,331 - INFO - validation batch 151, loss: 1.354, 4832/6976 datapoints
2025-03-07 12:55:14,406 - INFO - validation batch 201, loss: 0.846, 6432/6976 datapoints
2025-03-07 12:55:14,429 - INFO - Epoch 413/800 done.
2025-03-07 12:55:14,429 - INFO - Final validation performance:
Loss: 1.508, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:55:14,430 - INFO - Beginning epoch 414/800
2025-03-07 12:55:14,439 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:55:14,816 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:55:15,257 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:55:15,660 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:55:16,030 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:55:16,417 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:55:16,798 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:55:17,160 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:55:17,515 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:55:17,888 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:55:18,257 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:55:18,630 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:55:18,999 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:55:19,385 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:55:19,754 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:55:20,111 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:55:20,469 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:55:20,836 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:55:21,010 - INFO - validation batch 1, loss: 0.024, 32/6976 datapoints
2025-03-07 12:55:21,083 - INFO - validation batch 51, loss: 4.924, 1632/6976 datapoints
2025-03-07 12:55:21,158 - INFO - validation batch 101, loss: 0.397, 3232/6976 datapoints
2025-03-07 12:55:21,232 - INFO - validation batch 151, loss: 1.353, 4832/6976 datapoints
2025-03-07 12:55:21,302 - INFO - validation batch 201, loss: 0.853, 6432/6976 datapoints
2025-03-07 12:55:21,325 - INFO - Epoch 414/800 done.
2025-03-07 12:55:21,325 - INFO - Final validation performance:
Loss: 1.510, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:55:21,325 - INFO - Beginning epoch 415/800
2025-03-07 12:55:21,333 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:55:21,705 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:55:22,096 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:55:22,489 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:55:22,866 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:55:23,239 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:55:23,617 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:55:23,976 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:55:24,329 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:55:24,691 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:55:25,063 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:55:25,432 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:55:25,798 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:55:26,164 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:55:26,523 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:55:26,875 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:55:27,230 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:55:27,583 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:55:27,763 - INFO - validation batch 1, loss: 0.024, 32/6976 datapoints
2025-03-07 12:55:27,835 - INFO - validation batch 51, loss: 4.925, 1632/6976 datapoints
2025-03-07 12:55:27,909 - INFO - validation batch 101, loss: 0.402, 3232/6976 datapoints
2025-03-07 12:55:27,980 - INFO - validation batch 151, loss: 1.351, 4832/6976 datapoints
2025-03-07 12:55:28,051 - INFO - validation batch 201, loss: 0.862, 6432/6976 datapoints
2025-03-07 12:55:28,075 - INFO - Epoch 415/800 done.
2025-03-07 12:55:28,075 - INFO - Final validation performance:
Loss: 1.513, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:55:28,076 - INFO - Beginning epoch 416/800
2025-03-07 12:55:28,083 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:55:28,453 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:55:28,843 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:55:29,216 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:55:29,597 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:55:29,975 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:55:30,345 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:55:30,751 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:55:31,099 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:55:31,457 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:55:31,834 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:55:32,199 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:55:32,600 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:55:32,966 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:55:33,324 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:55:33,677 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:55:34,024 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:55:34,376 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:55:34,554 - INFO - validation batch 1, loss: 0.023, 32/6976 datapoints
2025-03-07 12:55:34,668 - INFO - validation batch 51, loss: 4.923, 1632/6976 datapoints
2025-03-07 12:55:34,770 - INFO - validation batch 101, loss: 0.408, 3232/6976 datapoints
2025-03-07 12:55:34,871 - INFO - validation batch 151, loss: 1.351, 4832/6976 datapoints
2025-03-07 12:55:34,966 - INFO - validation batch 201, loss: 0.875, 6432/6976 datapoints
2025-03-07 12:55:35,002 - INFO - Epoch 416/800 done.
2025-03-07 12:55:35,002 - INFO - Final validation performance:
Loss: 1.516, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:55:35,002 - INFO - Beginning epoch 417/800
2025-03-07 12:55:35,011 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:55:35,442 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:55:35,838 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:55:36,215 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:55:36,597 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:55:36,982 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:55:37,360 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:55:37,725 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:55:38,069 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:55:38,438 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:55:38,813 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:55:39,180 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:55:39,548 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:55:39,915 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:55:40,287 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:55:40,648 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:55:41,003 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:55:41,393 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:55:41,569 - INFO - validation batch 1, loss: 0.023, 32/6976 datapoints
2025-03-07 12:55:41,648 - INFO - validation batch 51, loss: 4.920, 1632/6976 datapoints
2025-03-07 12:55:41,720 - INFO - validation batch 101, loss: 0.416, 3232/6976 datapoints
2025-03-07 12:55:41,791 - INFO - validation batch 151, loss: 1.352, 4832/6976 datapoints
2025-03-07 12:55:41,865 - INFO - validation batch 201, loss: 0.892, 6432/6976 datapoints
2025-03-07 12:55:41,889 - INFO - Epoch 417/800 done.
2025-03-07 12:55:41,890 - INFO - Final validation performance:
Loss: 1.521, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:55:41,891 - INFO - Beginning epoch 418/800
2025-03-07 12:55:41,900 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:55:42,264 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:55:42,673 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:55:43,054 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:55:43,432 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:55:43,832 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:55:44,199 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:55:44,575 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:55:44,931 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:55:45,293 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:55:45,664 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:55:46,029 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:55:46,394 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:55:46,762 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:55:47,119 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:55:47,470 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:55:47,833 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:55:48,192 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:55:48,369 - INFO - validation batch 1, loss: 0.023, 32/6976 datapoints
2025-03-07 12:55:48,442 - INFO - validation batch 51, loss: 4.917, 1632/6976 datapoints
2025-03-07 12:55:48,516 - INFO - validation batch 101, loss: 0.425, 3232/6976 datapoints
2025-03-07 12:55:48,592 - INFO - validation batch 151, loss: 1.354, 4832/6976 datapoints
2025-03-07 12:55:48,663 - INFO - validation batch 201, loss: 0.912, 6432/6976 datapoints
2025-03-07 12:55:48,687 - INFO - Epoch 418/800 done.
2025-03-07 12:55:48,687 - INFO - Final validation performance:
Loss: 1.526, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:55:48,688 - INFO - Beginning epoch 419/800
2025-03-07 12:55:48,699 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:55:49,072 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:55:49,454 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:55:49,849 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:55:50,232 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:55:50,623 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:55:50,998 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:55:51,355 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:55:51,713 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:55:52,073 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:55:52,433 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:55:52,828 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:55:53,195 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:55:53,562 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:55:53,931 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:55:54,279 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:55:54,629 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:55:54,974 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:55:55,141 - INFO - validation batch 1, loss: 0.024, 32/6976 datapoints
2025-03-07 12:55:55,216 - INFO - validation batch 51, loss: 4.913, 1632/6976 datapoints
2025-03-07 12:55:55,287 - INFO - validation batch 101, loss: 0.434, 3232/6976 datapoints
2025-03-07 12:55:55,362 - INFO - validation batch 151, loss: 1.359, 4832/6976 datapoints
2025-03-07 12:55:55,439 - INFO - validation batch 201, loss: 0.935, 6432/6976 datapoints
2025-03-07 12:55:55,468 - INFO - Epoch 419/800 done.
2025-03-07 12:55:55,469 - INFO - Final validation performance:
Loss: 1.533, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:55:55,469 - INFO - Beginning epoch 420/800
2025-03-07 12:55:55,479 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:55:55,846 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:55:56,226 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:55:56,614 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:55:56,988 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:55:57,362 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:55:57,741 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:55:58,144 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:55:58,494 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:55:58,856 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:55:59,221 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:55:59,589 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:56:00,010 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:56:00,385 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:56:00,776 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:56:01,126 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:56:01,488 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:56:01,848 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:56:02,021 - INFO - validation batch 1, loss: 0.025, 32/6976 datapoints
2025-03-07 12:56:02,093 - INFO - validation batch 51, loss: 4.911, 1632/6976 datapoints
2025-03-07 12:56:02,166 - INFO - validation batch 101, loss: 0.441, 3232/6976 datapoints
2025-03-07 12:56:02,237 - INFO - validation batch 151, loss: 1.368, 4832/6976 datapoints
2025-03-07 12:56:02,310 - INFO - validation batch 201, loss: 0.959, 6432/6976 datapoints
2025-03-07 12:56:02,333 - INFO - Epoch 420/800 done.
2025-03-07 12:56:02,333 - INFO - Final validation performance:
Loss: 1.541, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:56:02,334 - INFO - Beginning epoch 421/800
2025-03-07 12:56:02,342 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:56:02,748 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:56:03,121 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:56:03,490 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:56:03,862 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:56:04,231 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:56:04,600 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:56:04,952 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:56:05,293 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:56:05,653 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:56:06,010 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:56:06,366 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:56:06,724 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:56:07,080 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:56:07,429 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:56:07,776 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:56:08,121 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:56:08,504 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:56:08,681 - INFO - validation batch 1, loss: 0.027, 32/6976 datapoints
2025-03-07 12:56:08,748 - INFO - validation batch 51, loss: 4.907, 1632/6976 datapoints
2025-03-07 12:56:08,814 - INFO - validation batch 101, loss: 0.446, 3232/6976 datapoints
2025-03-07 12:56:08,885 - INFO - validation batch 151, loss: 1.381, 4832/6976 datapoints
2025-03-07 12:56:08,955 - INFO - validation batch 201, loss: 0.986, 6432/6976 datapoints
2025-03-07 12:56:08,978 - INFO - Epoch 421/800 done.
2025-03-07 12:56:08,978 - INFO - Final validation performance:
Loss: 1.549, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:56:08,979 - INFO - Beginning epoch 422/800
2025-03-07 12:56:08,987 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:56:09,385 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:56:09,804 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:56:10,190 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:56:10,604 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:56:11,012 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:56:11,386 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:56:11,779 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:56:12,126 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:56:12,486 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:56:12,882 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:56:13,249 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:56:13,626 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:56:14,010 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:56:14,379 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:56:14,726 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:56:15,078 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:56:15,429 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:56:15,611 - INFO - validation batch 1, loss: 0.029, 32/6976 datapoints
2025-03-07 12:56:15,685 - INFO - validation batch 51, loss: 4.903, 1632/6976 datapoints
2025-03-07 12:56:15,757 - INFO - validation batch 101, loss: 0.447, 3232/6976 datapoints
2025-03-07 12:56:15,829 - INFO - validation batch 151, loss: 1.398, 4832/6976 datapoints
2025-03-07 12:56:15,901 - INFO - validation batch 201, loss: 1.012, 6432/6976 datapoints
2025-03-07 12:56:15,924 - INFO - Epoch 422/800 done.
2025-03-07 12:56:15,924 - INFO - Final validation performance:
Loss: 1.558, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:56:15,925 - INFO - Beginning epoch 423/800
2025-03-07 12:56:15,933 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:56:16,321 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:56:16,703 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:56:17,073 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:56:17,438 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:56:17,828 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:56:18,197 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:56:18,567 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:56:19,009 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:56:19,376 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:56:19,743 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:56:20,110 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:56:20,496 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:56:20,871 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:56:21,232 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:56:21,574 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:56:21,925 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:56:22,278 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:56:22,455 - INFO - validation batch 1, loss: 0.031, 32/6976 datapoints
2025-03-07 12:56:22,529 - INFO - validation batch 51, loss: 4.900, 1632/6976 datapoints
2025-03-07 12:56:22,605 - INFO - validation batch 101, loss: 0.447, 3232/6976 datapoints
2025-03-07 12:56:22,678 - INFO - validation batch 151, loss: 1.419, 4832/6976 datapoints
2025-03-07 12:56:22,750 - INFO - validation batch 201, loss: 1.036, 6432/6976 datapoints
2025-03-07 12:56:22,775 - INFO - Epoch 423/800 done.
2025-03-07 12:56:22,775 - INFO - Final validation performance:
Loss: 1.567, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:56:22,776 - INFO - Beginning epoch 424/800
2025-03-07 12:56:22,783 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:56:23,186 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:56:23,554 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:56:23,947 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:56:24,329 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:56:24,719 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:56:25,097 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:56:25,455 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:56:25,810 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:56:26,170 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:56:26,535 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:56:26,901 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:56:27,258 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 12:56:27,624 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:56:28,028 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:56:28,427 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:56:28,810 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:56:29,164 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:56:29,342 - INFO - validation batch 1, loss: 0.034, 32/6976 datapoints
2025-03-07 12:56:29,417 - INFO - validation batch 51, loss: 4.901, 1632/6976 datapoints
2025-03-07 12:56:29,492 - INFO - validation batch 101, loss: 0.444, 3232/6976 datapoints
2025-03-07 12:56:29,564 - INFO - validation batch 151, loss: 1.442, 4832/6976 datapoints
2025-03-07 12:56:29,635 - INFO - validation batch 201, loss: 1.062, 6432/6976 datapoints
2025-03-07 12:56:29,664 - INFO - Epoch 424/800 done.
2025-03-07 12:56:29,664 - INFO - Final validation performance:
Loss: 1.577, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:56:29,665 - INFO - Beginning epoch 425/800
2025-03-07 12:56:29,675 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:56:30,058 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:56:30,438 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:56:30,836 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:56:31,206 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:56:31,582 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:56:31,963 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:56:32,316 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:56:32,668 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:56:33,054 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:56:33,415 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:56:33,786 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:56:34,142 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 12:56:34,507 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:56:34,879 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:56:35,228 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:56:35,596 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:56:35,962 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:56:36,142 - INFO - validation batch 1, loss: 0.037, 32/6976 datapoints
2025-03-07 12:56:36,212 - INFO - validation batch 51, loss: 4.899, 1632/6976 datapoints
2025-03-07 12:56:36,284 - INFO - validation batch 101, loss: 0.444, 3232/6976 datapoints
2025-03-07 12:56:36,357 - INFO - validation batch 151, loss: 1.466, 4832/6976 datapoints
2025-03-07 12:56:36,430 - INFO - validation batch 201, loss: 1.079, 6432/6976 datapoints
2025-03-07 12:56:36,457 - INFO - Epoch 425/800 done.
2025-03-07 12:56:36,457 - INFO - Final validation performance:
Loss: 1.585, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:56:36,457 - INFO - Beginning epoch 426/800
2025-03-07 12:56:36,466 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:56:36,833 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:56:37,214 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:56:37,590 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:56:37,976 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:56:38,351 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:56:38,727 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:56:39,082 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:56:39,432 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:56:39,804 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:56:40,164 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:56:40,539 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:56:40,904 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:56:41,270 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:56:41,686 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:56:42,029 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:56:42,377 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:56:42,739 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:56:42,919 - INFO - validation batch 1, loss: 0.038, 32/6976 datapoints
2025-03-07 12:56:42,994 - INFO - validation batch 51, loss: 4.885, 1632/6976 datapoints
2025-03-07 12:56:43,106 - INFO - validation batch 101, loss: 0.448, 3232/6976 datapoints
2025-03-07 12:56:43,200 - INFO - validation batch 151, loss: 1.495, 4832/6976 datapoints
2025-03-07 12:56:43,273 - INFO - validation batch 201, loss: 1.084, 6432/6976 datapoints
2025-03-07 12:56:43,300 - INFO - Epoch 426/800 done.
2025-03-07 12:56:43,300 - INFO - Final validation performance:
Loss: 1.590, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:56:43,301 - INFO - Beginning epoch 427/800
2025-03-07 12:56:43,309 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:56:43,687 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:56:44,067 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:56:44,435 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:56:44,802 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:56:45,173 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:56:45,561 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:56:45,917 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:56:46,263 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:56:46,623 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:56:46,982 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:56:47,342 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:56:47,708 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:56:48,086 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:56:48,462 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:56:48,805 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:56:49,155 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:56:49,511 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:56:49,688 - INFO - validation batch 1, loss: 0.038, 32/6976 datapoints
2025-03-07 12:56:49,755 - INFO - validation batch 51, loss: 4.859, 1632/6976 datapoints
2025-03-07 12:56:49,823 - INFO - validation batch 101, loss: 0.464, 3232/6976 datapoints
2025-03-07 12:56:49,891 - INFO - validation batch 151, loss: 1.534, 4832/6976 datapoints
2025-03-07 12:56:49,958 - INFO - validation batch 201, loss: 1.083, 6432/6976 datapoints
2025-03-07 12:56:49,981 - INFO - Epoch 427/800 done.
2025-03-07 12:56:49,981 - INFO - Final validation performance:
Loss: 1.596, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:56:49,982 - INFO - Beginning epoch 428/800
2025-03-07 12:56:49,989 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:56:50,356 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:56:50,742 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:56:51,122 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:56:51,509 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:56:51,914 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:56:52,312 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:56:52,704 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:56:53,080 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:56:53,489 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:56:53,851 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:56:54,213 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:56:54,577 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:56:54,952 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:56:55,321 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:56:55,670 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 12:56:56,025 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:56:56,387 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:56:56,575 - INFO - validation batch 1, loss: 0.032, 32/6976 datapoints
2025-03-07 12:56:56,650 - INFO - validation batch 51, loss: 4.829, 1632/6976 datapoints
2025-03-07 12:56:56,723 - INFO - validation batch 101, loss: 0.488, 3232/6976 datapoints
2025-03-07 12:56:56,797 - INFO - validation batch 151, loss: 1.553, 4832/6976 datapoints
2025-03-07 12:56:56,869 - INFO - validation batch 201, loss: 1.093, 6432/6976 datapoints
2025-03-07 12:56:56,894 - INFO - Epoch 428/800 done.
2025-03-07 12:56:56,894 - INFO - Final validation performance:
Loss: 1.599, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:56:56,895 - INFO - Beginning epoch 429/800
2025-03-07 12:56:56,906 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:56:57,292 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:56:57,674 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:56:58,062 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:56:58,427 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:56:58,811 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:56:59,186 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:56:59,545 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:56:59,890 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:57:00,250 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:57:00,614 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:57:00,973 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:57:01,337 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:57:01,708 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:57:02,081 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:57:02,413 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 12:57:02,772 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:57:03,135 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:57:03,340 - INFO - validation batch 1, loss: 0.022, 32/6976 datapoints
2025-03-07 12:57:03,415 - INFO - validation batch 51, loss: 4.791, 1632/6976 datapoints
2025-03-07 12:57:03,490 - INFO - validation batch 101, loss: 0.518, 3232/6976 datapoints
2025-03-07 12:57:03,562 - INFO - validation batch 151, loss: 1.555, 4832/6976 datapoints
2025-03-07 12:57:03,633 - INFO - validation batch 201, loss: 1.052, 6432/6976 datapoints
2025-03-07 12:57:03,661 - INFO - Epoch 429/800 done.
2025-03-07 12:57:03,661 - INFO - Final validation performance:
Loss: 1.588, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:57:03,662 - INFO - Beginning epoch 430/800
2025-03-07 12:57:03,672 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:57:04,058 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:57:04,448 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:57:04,835 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:57:05,225 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:57:05,615 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:57:05,993 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:57:06,352 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:57:06,704 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:57:07,065 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:57:07,424 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:57:07,800 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:57:08,173 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:57:08,556 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 12:57:08,926 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:57:09,267 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 12:57:09,625 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 12:57:09,992 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:57:10,173 - INFO - validation batch 1, loss: 0.019, 32/6976 datapoints
2025-03-07 12:57:10,244 - INFO - validation batch 51, loss: 4.772, 1632/6976 datapoints
2025-03-07 12:57:10,316 - INFO - validation batch 101, loss: 0.527, 3232/6976 datapoints
2025-03-07 12:57:10,389 - INFO - validation batch 151, loss: 1.542, 4832/6976 datapoints
2025-03-07 12:57:10,461 - INFO - validation batch 201, loss: 1.037, 6432/6976 datapoints
2025-03-07 12:57:10,489 - INFO - Epoch 430/800 done.
2025-03-07 12:57:10,489 - INFO - Final validation performance:
Loss: 1.579, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:57:10,490 - INFO - Beginning epoch 431/800
2025-03-07 12:57:10,501 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:57:10,888 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:57:11,270 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:57:11,647 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:57:12,011 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:57:12,385 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:57:12,768 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:57:13,137 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:57:13,515 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:57:13,880 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:57:14,248 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:57:14,622 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:57:14,991 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:57:15,365 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 12:57:15,740 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:57:16,083 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 12:57:16,439 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:57:16,808 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:57:16,985 - INFO - validation batch 1, loss: 0.021, 32/6976 datapoints
2025-03-07 12:57:17,055 - INFO - validation batch 51, loss: 4.721, 1632/6976 datapoints
2025-03-07 12:57:17,132 - INFO - validation batch 101, loss: 0.563, 3232/6976 datapoints
2025-03-07 12:57:17,206 - INFO - validation batch 151, loss: 1.560, 4832/6976 datapoints
2025-03-07 12:57:17,279 - INFO - validation batch 201, loss: 1.069, 6432/6976 datapoints
2025-03-07 12:57:17,306 - INFO - Epoch 431/800 done.
2025-03-07 12:57:17,306 - INFO - Final validation performance:
Loss: 1.587, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:57:17,307 - INFO - Beginning epoch 432/800
2025-03-07 12:57:17,314 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:57:17,711 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 12:57:18,097 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:57:18,481 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:57:18,849 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:57:19,227 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:57:19,615 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:57:19,977 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 12:57:20,331 - INFO - training batch 401, loss: -0.000, 12832/28000 datapoints
2025-03-07 12:57:20,698 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:57:21,062 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:57:21,435 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:57:21,814 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 12:57:22,188 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:57:22,565 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 12:57:22,910 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 12:57:23,271 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 12:57:23,701 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:57:23,881 - INFO - validation batch 1, loss: 0.013, 32/6976 datapoints
2025-03-07 12:57:23,953 - INFO - validation batch 51, loss: 4.684, 1632/6976 datapoints
2025-03-07 12:57:24,024 - INFO - validation batch 101, loss: 0.550, 3232/6976 datapoints
2025-03-07 12:57:24,096 - INFO - validation batch 151, loss: 1.526, 4832/6976 datapoints
2025-03-07 12:57:24,168 - INFO - validation batch 201, loss: 1.025, 6432/6976 datapoints
2025-03-07 12:57:24,193 - INFO - Epoch 432/800 done.
2025-03-07 12:57:24,193 - INFO - Final validation performance:
Loss: 1.560, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 12:57:24,194 - INFO - Beginning epoch 433/800
2025-03-07 12:57:24,204 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:57:24,588 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 12:57:24,980 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 12:57:25,367 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:57:25,746 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:57:26,130 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:57:26,520 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:57:26,900 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:57:27,251 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:57:27,621 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:57:27,998 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:57:28,381 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:57:28,779 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 12:57:29,161 - INFO - training batch 651, loss: 0.112, 20832/28000 datapoints
2025-03-07 12:57:29,522 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:57:29,887 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:57:30,252 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:57:30,656 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:57:30,846 - INFO - validation batch 1, loss: 0.014, 32/6976 datapoints
2025-03-07 12:57:30,922 - INFO - validation batch 51, loss: 4.911, 1632/6976 datapoints
2025-03-07 12:57:30,993 - INFO - validation batch 101, loss: 0.556, 3232/6976 datapoints
2025-03-07 12:57:31,069 - INFO - validation batch 151, loss: 1.820, 4832/6976 datapoints
2025-03-07 12:57:31,144 - INFO - validation batch 201, loss: 0.637, 6432/6976 datapoints
2025-03-07 12:57:31,171 - INFO - Epoch 433/800 done.
2025-03-07 12:57:31,171 - INFO - Final validation performance:
Loss: 1.588, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 12:57:31,171 - INFO - Beginning epoch 434/800
2025-03-07 12:57:31,182 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:57:31,572 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:57:31,975 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:57:32,345 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:57:32,720 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:57:33,094 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:57:33,472 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:57:33,887 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:57:34,270 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:57:34,639 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:57:35,014 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:57:35,392 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:57:35,794 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:57:36,177 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:57:36,553 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:57:36,919 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:57:37,284 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:57:37,652 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 12:57:37,845 - INFO - validation batch 1, loss: 0.011, 32/6976 datapoints
2025-03-07 12:57:37,917 - INFO - validation batch 51, loss: 4.903, 1632/6976 datapoints
2025-03-07 12:57:37,990 - INFO - validation batch 101, loss: 0.437, 3232/6976 datapoints
2025-03-07 12:57:38,067 - INFO - validation batch 151, loss: 1.720, 4832/6976 datapoints
2025-03-07 12:57:38,138 - INFO - validation batch 201, loss: 0.752, 6432/6976 datapoints
2025-03-07 12:57:38,165 - INFO - Epoch 434/800 done.
2025-03-07 12:57:38,165 - INFO - Final validation performance:
Loss: 1.564, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:57:38,166 - INFO - Beginning epoch 435/800
2025-03-07 12:57:38,174 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:57:38,571 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:57:38,981 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:57:39,360 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:57:39,739 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:57:40,120 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:57:40,507 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:57:40,932 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:57:41,290 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:57:41,658 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:57:42,074 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:57:42,449 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:57:42,864 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 12:57:43,260 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:57:43,656 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:57:44,056 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:57:44,424 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:57:44,800 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:57:44,986 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 12:57:45,057 - INFO - validation batch 51, loss: 4.885, 1632/6976 datapoints
2025-03-07 12:57:45,129 - INFO - validation batch 101, loss: 0.389, 3232/6976 datapoints
2025-03-07 12:57:45,203 - INFO - validation batch 151, loss: 1.681, 4832/6976 datapoints
2025-03-07 12:57:45,274 - INFO - validation batch 201, loss: 0.735, 6432/6976 datapoints
2025-03-07 12:57:45,302 - INFO - Epoch 435/800 done.
2025-03-07 12:57:45,302 - INFO - Final validation performance:
Loss: 1.539, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:57:45,303 - INFO - Beginning epoch 436/800
2025-03-07 12:57:45,311 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:57:45,694 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:57:46,088 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:57:46,469 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:57:46,845 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:57:47,228 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:57:47,611 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:57:47,984 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:57:48,342 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:57:48,709 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:57:49,080 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:57:49,455 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:57:49,841 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 12:57:50,213 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:57:50,589 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:57:50,949 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:57:51,313 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:57:51,683 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:57:51,872 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 12:57:51,945 - INFO - validation batch 51, loss: 4.872, 1632/6976 datapoints
2025-03-07 12:57:52,017 - INFO - validation batch 101, loss: 0.370, 3232/6976 datapoints
2025-03-07 12:57:52,089 - INFO - validation batch 151, loss: 1.667, 4832/6976 datapoints
2025-03-07 12:57:52,161 - INFO - validation batch 201, loss: 0.729, 6432/6976 datapoints
2025-03-07 12:57:52,184 - INFO - Epoch 436/800 done.
2025-03-07 12:57:52,184 - INFO - Final validation performance:
Loss: 1.528, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:57:52,185 - INFO - Beginning epoch 437/800
2025-03-07 12:57:52,193 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:57:52,569 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:57:52,971 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:57:53,348 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:57:53,731 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:57:54,145 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:57:54,540 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:57:54,922 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:57:55,291 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:57:55,668 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:57:56,046 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:57:56,425 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:57:56,823 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:57:57,202 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:57:57,577 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:57:57,947 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:57:58,346 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:57:58,725 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:57:58,908 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 12:57:58,984 - INFO - validation batch 51, loss: 4.862, 1632/6976 datapoints
2025-03-07 12:57:59,063 - INFO - validation batch 101, loss: 0.363, 3232/6976 datapoints
2025-03-07 12:57:59,136 - INFO - validation batch 151, loss: 1.659, 4832/6976 datapoints
2025-03-07 12:57:59,212 - INFO - validation batch 201, loss: 0.725, 6432/6976 datapoints
2025-03-07 12:57:59,236 - INFO - Epoch 437/800 done.
2025-03-07 12:57:59,236 - INFO - Final validation performance:
Loss: 1.523, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:57:59,237 - INFO - Beginning epoch 438/800
2025-03-07 12:57:59,246 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:57:59,643 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:58:00,075 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:58:00,515 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:58:00,899 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:58:01,296 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:58:01,692 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:58:02,068 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:58:02,420 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:58:02,789 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:58:03,166 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:58:03,547 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:58:03,957 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:58:04,342 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:58:04,727 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:58:05,086 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:58:05,447 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:58:05,817 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:58:06,000 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 12:58:06,069 - INFO - validation batch 51, loss: 4.854, 1632/6976 datapoints
2025-03-07 12:58:06,143 - INFO - validation batch 101, loss: 0.363, 3232/6976 datapoints
2025-03-07 12:58:06,214 - INFO - validation batch 151, loss: 1.652, 4832/6976 datapoints
2025-03-07 12:58:06,287 - INFO - validation batch 201, loss: 0.724, 6432/6976 datapoints
2025-03-07 12:58:06,310 - INFO - Epoch 438/800 done.
2025-03-07 12:58:06,310 - INFO - Final validation performance:
Loss: 1.520, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:58:06,311 - INFO - Beginning epoch 439/800
2025-03-07 12:58:06,318 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:58:06,709 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:58:07,112 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:58:07,489 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:58:07,863 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:58:08,248 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:58:08,639 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:58:09,013 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:58:09,362 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:58:09,724 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:58:10,096 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:58:10,471 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:58:10,866 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:58:11,246 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:58:11,624 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:58:11,982 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:58:12,338 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:58:12,708 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:58:12,895 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:58:12,972 - INFO - validation batch 51, loss: 4.848, 1632/6976 datapoints
2025-03-07 12:58:13,047 - INFO - validation batch 101, loss: 0.366, 3232/6976 datapoints
2025-03-07 12:58:13,122 - INFO - validation batch 151, loss: 1.645, 4832/6976 datapoints
2025-03-07 12:58:13,196 - INFO - validation batch 201, loss: 0.725, 6432/6976 datapoints
2025-03-07 12:58:13,225 - INFO - Epoch 439/800 done.
2025-03-07 12:58:13,225 - INFO - Final validation performance:
Loss: 1.517, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:58:13,226 - INFO - Beginning epoch 440/800
2025-03-07 12:58:13,234 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:58:14,138 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:58:14,534 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:58:14,905 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:58:15,284 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:58:15,674 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:58:16,065 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:58:16,440 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:58:16,805 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:58:17,172 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:58:17,599 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:58:18,022 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:58:18,428 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:58:18,816 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:58:19,197 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:58:19,568 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:58:19,933 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:58:20,312 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:58:20,501 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:58:20,576 - INFO - validation batch 51, loss: 4.843, 1632/6976 datapoints
2025-03-07 12:58:20,654 - INFO - validation batch 101, loss: 0.369, 3232/6976 datapoints
2025-03-07 12:58:20,725 - INFO - validation batch 151, loss: 1.635, 4832/6976 datapoints
2025-03-07 12:58:20,798 - INFO - validation batch 201, loss: 0.729, 6432/6976 datapoints
2025-03-07 12:58:20,824 - INFO - Epoch 440/800 done.
2025-03-07 12:58:20,824 - INFO - Final validation performance:
Loss: 1.516, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:58:20,825 - INFO - Beginning epoch 441/800
2025-03-07 12:58:20,833 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:58:21,215 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:58:21,631 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:58:22,013 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:58:22,392 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:58:23,132 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:58:23,858 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:58:24,471 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:58:24,901 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:58:25,408 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:58:25,905 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:58:26,381 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:58:26,849 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:58:27,258 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:58:27,672 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:58:28,068 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:58:28,439 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:58:28,831 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:58:29,021 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:58:29,103 - INFO - validation batch 51, loss: 4.840, 1632/6976 datapoints
2025-03-07 12:58:29,179 - INFO - validation batch 101, loss: 0.372, 3232/6976 datapoints
2025-03-07 12:58:29,261 - INFO - validation batch 151, loss: 1.625, 4832/6976 datapoints
2025-03-07 12:58:29,344 - INFO - validation batch 201, loss: 0.735, 6432/6976 datapoints
2025-03-07 12:58:29,373 - INFO - Epoch 441/800 done.
2025-03-07 12:58:29,374 - INFO - Final validation performance:
Loss: 1.515, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:58:29,374 - INFO - Beginning epoch 442/800
2025-03-07 12:58:29,382 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:58:29,805 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:58:30,262 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:58:30,864 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:58:31,325 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:58:31,870 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:58:32,374 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:58:32,851 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:58:33,309 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:58:33,785 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:58:34,335 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:58:34,870 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:58:35,356 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:58:35,863 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:58:36,318 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:58:36,772 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:58:37,219 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:58:37,662 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:58:37,898 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:58:38,006 - INFO - validation batch 51, loss: 4.838, 1632/6976 datapoints
2025-03-07 12:58:38,144 - INFO - validation batch 101, loss: 0.376, 3232/6976 datapoints
2025-03-07 12:58:38,254 - INFO - validation batch 151, loss: 1.612, 4832/6976 datapoints
2025-03-07 12:58:38,360 - INFO - validation batch 201, loss: 0.743, 6432/6976 datapoints
2025-03-07 12:58:38,402 - INFO - Epoch 442/800 done.
2025-03-07 12:58:38,403 - INFO - Final validation performance:
Loss: 1.515, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:58:38,403 - INFO - Beginning epoch 443/800
2025-03-07 12:58:38,415 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:58:38,904 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:58:39,425 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:58:39,890 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:58:40,351 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:58:40,801 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:58:41,299 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:58:41,790 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:58:42,272 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:58:42,710 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:58:43,107 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:58:43,596 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:58:44,060 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:58:44,496 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:58:44,922 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:58:45,415 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:58:45,824 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:58:46,245 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:58:46,462 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:58:46,550 - INFO - validation batch 51, loss: 4.836, 1632/6976 datapoints
2025-03-07 12:58:46,638 - INFO - validation batch 101, loss: 0.379, 3232/6976 datapoints
2025-03-07 12:58:46,732 - INFO - validation batch 151, loss: 1.598, 4832/6976 datapoints
2025-03-07 12:58:46,824 - INFO - validation batch 201, loss: 0.752, 6432/6976 datapoints
2025-03-07 12:58:46,852 - INFO - Epoch 443/800 done.
2025-03-07 12:58:46,852 - INFO - Final validation performance:
Loss: 1.514, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:58:46,853 - INFO - Beginning epoch 444/800
2025-03-07 12:58:46,861 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:58:47,259 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:58:47,715 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:58:48,136 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:58:48,556 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:58:48,959 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:58:49,411 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:58:49,826 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:58:50,233 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:58:50,651 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:58:51,081 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:58:51,511 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:58:51,996 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:58:52,462 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:58:52,951 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:58:53,488 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:58:54,024 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:58:54,539 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:58:54,838 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:58:54,958 - INFO - validation batch 51, loss: 4.836, 1632/6976 datapoints
2025-03-07 12:58:55,068 - INFO - validation batch 101, loss: 0.380, 3232/6976 datapoints
2025-03-07 12:58:55,168 - INFO - validation batch 151, loss: 1.582, 4832/6976 datapoints
2025-03-07 12:58:55,275 - INFO - validation batch 201, loss: 0.760, 6432/6976 datapoints
2025-03-07 12:58:55,313 - INFO - Epoch 444/800 done.
2025-03-07 12:58:55,314 - INFO - Final validation performance:
Loss: 1.512, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:58:55,314 - INFO - Beginning epoch 445/800
2025-03-07 12:58:55,324 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:58:55,916 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:58:56,635 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:58:57,267 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:58:57,759 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:58:58,362 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:58:58,878 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:58:59,332 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:58:59,804 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:59:00,263 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:59:00,803 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:59:01,301 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:59:01,801 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:59:02,275 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:59:02,750 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:59:03,198 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:59:03,656 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:59:04,134 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:59:04,365 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:59:04,461 - INFO - validation batch 51, loss: 4.835, 1632/6976 datapoints
2025-03-07 12:59:04,578 - INFO - validation batch 101, loss: 0.380, 3232/6976 datapoints
2025-03-07 12:59:04,705 - INFO - validation batch 151, loss: 1.564, 4832/6976 datapoints
2025-03-07 12:59:04,810 - INFO - validation batch 201, loss: 0.768, 6432/6976 datapoints
2025-03-07 12:59:04,842 - INFO - Epoch 445/800 done.
2025-03-07 12:59:04,842 - INFO - Final validation performance:
Loss: 1.510, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:59:04,843 - INFO - Beginning epoch 446/800
2025-03-07 12:59:04,855 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:59:05,345 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:59:05,853 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:59:06,319 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:59:06,782 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:59:07,254 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:59:07,732 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:59:08,186 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:59:08,670 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:59:09,154 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:59:09,641 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:59:10,139 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:59:10,637 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:59:11,154 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:59:11,675 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:59:12,143 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:59:12,659 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:59:13,112 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:59:13,334 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:59:13,437 - INFO - validation batch 51, loss: 4.835, 1632/6976 datapoints
2025-03-07 12:59:13,531 - INFO - validation batch 101, loss: 0.379, 3232/6976 datapoints
2025-03-07 12:59:13,619 - INFO - validation batch 151, loss: 1.545, 4832/6976 datapoints
2025-03-07 12:59:13,706 - INFO - validation batch 201, loss: 0.775, 6432/6976 datapoints
2025-03-07 12:59:13,735 - INFO - Epoch 446/800 done.
2025-03-07 12:59:13,735 - INFO - Final validation performance:
Loss: 1.508, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:59:13,736 - INFO - Beginning epoch 447/800
2025-03-07 12:59:13,745 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:59:14,151 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:59:14,598 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:59:15,038 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:59:15,445 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:59:15,914 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:59:16,342 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:59:16,772 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:59:17,173 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:59:17,610 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:59:18,146 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:59:18,680 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:59:19,194 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:59:19,786 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:59:20,480 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:59:21,061 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:59:21,562 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:59:22,118 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:59:22,491 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:59:22,677 - INFO - validation batch 51, loss: 4.834, 1632/6976 datapoints
2025-03-07 12:59:22,765 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-07 12:59:22,848 - INFO - validation batch 151, loss: 1.527, 4832/6976 datapoints
2025-03-07 12:59:22,929 - INFO - validation batch 201, loss: 0.783, 6432/6976 datapoints
2025-03-07 12:59:22,959 - INFO - Epoch 447/800 done.
2025-03-07 12:59:22,959 - INFO - Final validation performance:
Loss: 1.505, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 12:59:22,960 - INFO - Beginning epoch 448/800
2025-03-07 12:59:22,971 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:59:23,414 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:59:24,112 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:59:24,725 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:59:25,271 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:59:25,810 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:59:26,380 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:59:26,910 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:59:27,455 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:59:27,967 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:59:28,465 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:59:28,958 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:59:29,438 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:59:29,967 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:59:30,426 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:59:30,901 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:59:31,348 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:59:31,821 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:59:32,041 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:59:32,140 - INFO - validation batch 51, loss: 4.831, 1632/6976 datapoints
2025-03-07 12:59:32,246 - INFO - validation batch 101, loss: 0.376, 3232/6976 datapoints
2025-03-07 12:59:32,337 - INFO - validation batch 151, loss: 1.510, 4832/6976 datapoints
2025-03-07 12:59:32,426 - INFO - validation batch 201, loss: 0.791, 6432/6976 datapoints
2025-03-07 12:59:32,457 - INFO - Epoch 448/800 done.
2025-03-07 12:59:32,457 - INFO - Final validation performance:
Loss: 1.502, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:59:32,458 - INFO - Beginning epoch 449/800
2025-03-07 12:59:32,467 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:59:32,933 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:59:33,432 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:59:33,892 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:59:34,368 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:59:34,867 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:59:35,376 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:59:35,837 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:59:36,292 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:59:36,814 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:59:37,362 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:59:37,860 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:59:38,347 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:59:38,834 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:59:39,320 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:59:39,807 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:59:40,240 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:59:40,647 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:59:40,875 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:59:40,971 - INFO - validation batch 51, loss: 4.826, 1632/6976 datapoints
2025-03-07 12:59:41,073 - INFO - validation batch 101, loss: 0.375, 3232/6976 datapoints
2025-03-07 12:59:41,171 - INFO - validation batch 151, loss: 1.495, 4832/6976 datapoints
2025-03-07 12:59:41,286 - INFO - validation batch 201, loss: 0.801, 6432/6976 datapoints
2025-03-07 12:59:41,323 - INFO - Epoch 449/800 done.
2025-03-07 12:59:41,323 - INFO - Final validation performance:
Loss: 1.500, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:59:41,324 - INFO - Beginning epoch 450/800
2025-03-07 12:59:41,336 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:59:41,794 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:59:42,224 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:59:42,673 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:59:43,095 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:59:43,572 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:59:44,013 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:59:44,390 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:59:44,762 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:59:45,158 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:59:45,559 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:59:45,945 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:59:46,336 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:59:46,729 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:59:47,116 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:59:47,489 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:59:47,865 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:59:48,236 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:59:48,441 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:59:48,538 - INFO - validation batch 51, loss: 4.818, 1632/6976 datapoints
2025-03-07 12:59:48,628 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-07 12:59:48,718 - INFO - validation batch 151, loss: 1.485, 4832/6976 datapoints
2025-03-07 12:59:48,807 - INFO - validation batch 201, loss: 0.815, 6432/6976 datapoints
2025-03-07 12:59:48,837 - INFO - Epoch 450/800 done.
2025-03-07 12:59:48,837 - INFO - Final validation performance:
Loss: 1.500, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:59:48,838 - INFO - Beginning epoch 451/800
2025-03-07 12:59:48,850 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:59:49,326 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:59:49,820 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:59:50,287 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:59:50,759 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 12:59:51,238 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 12:59:51,737 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 12:59:52,241 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 12:59:52,735 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 12:59:53,196 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 12:59:53,703 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 12:59:54,175 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 12:59:54,647 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 12:59:55,116 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 12:59:55,633 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 12:59:56,086 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 12:59:56,539 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 12:59:56,994 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 12:59:57,235 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 12:59:57,329 - INFO - validation batch 51, loss: 4.804, 1632/6976 datapoints
2025-03-07 12:59:57,419 - INFO - validation batch 101, loss: 0.381, 3232/6976 datapoints
2025-03-07 12:59:57,512 - INFO - validation batch 151, loss: 1.482, 4832/6976 datapoints
2025-03-07 12:59:57,603 - INFO - validation batch 201, loss: 0.830, 6432/6976 datapoints
2025-03-07 12:59:57,638 - INFO - Epoch 451/800 done.
2025-03-07 12:59:57,638 - INFO - Final validation performance:
Loss: 1.500, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 12:59:57,639 - INFO - Beginning epoch 452/800
2025-03-07 12:59:57,650 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 12:59:58,161 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 12:59:58,690 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 12:59:59,139 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 12:59:59,621 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:00:00,122 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:00:00,655 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:00:01,134 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:00:01,638 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:00:02,155 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:00:02,620 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:00:03,168 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:00:03,759 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:00:04,356 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:00:04,877 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:00:05,337 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:00:05,815 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:00:06,238 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:00:06,444 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:00:06,540 - INFO - validation batch 51, loss: 4.792, 1632/6976 datapoints
2025-03-07 13:00:06,635 - INFO - validation batch 101, loss: 0.389, 3232/6976 datapoints
2025-03-07 13:00:06,733 - INFO - validation batch 151, loss: 1.482, 4832/6976 datapoints
2025-03-07 13:00:06,830 - INFO - validation batch 201, loss: 0.844, 6432/6976 datapoints
2025-03-07 13:00:06,867 - INFO - Epoch 452/800 done.
2025-03-07 13:00:06,867 - INFO - Final validation performance:
Loss: 1.502, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:00:06,868 - INFO - Beginning epoch 453/800
2025-03-07 13:00:06,877 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:00:07,337 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:00:07,830 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:00:08,318 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:00:08,789 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:00:09,274 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:00:09,787 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:00:10,256 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:00:10,691 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:00:11,142 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:00:11,624 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:00:12,089 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:00:12,545 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:00:12,984 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:00:13,458 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:00:13,865 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:00:14,286 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:00:14,686 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:00:14,900 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:00:15,012 - INFO - validation batch 51, loss: 4.786, 1632/6976 datapoints
2025-03-07 13:00:15,110 - INFO - validation batch 101, loss: 0.396, 3232/6976 datapoints
2025-03-07 13:00:15,188 - INFO - validation batch 151, loss: 1.488, 4832/6976 datapoints
2025-03-07 13:00:15,272 - INFO - validation batch 201, loss: 0.862, 6432/6976 datapoints
2025-03-07 13:00:15,302 - INFO - Epoch 453/800 done.
2025-03-07 13:00:15,302 - INFO - Final validation performance:
Loss: 1.507, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:00:15,303 - INFO - Beginning epoch 454/800
2025-03-07 13:00:15,312 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:00:15,775 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:00:16,231 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:00:16,628 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:00:17,040 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:00:17,496 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:00:17,960 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:00:18,380 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:00:18,804 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:00:19,289 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:00:19,774 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:00:20,275 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:00:20,804 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:00:21,334 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:00:21,835 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:00:22,301 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:00:22,765 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:00:23,242 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:00:23,500 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 13:00:23,606 - INFO - validation batch 51, loss: 4.780, 1632/6976 datapoints
2025-03-07 13:00:23,712 - INFO - validation batch 101, loss: 0.403, 3232/6976 datapoints
2025-03-07 13:00:23,812 - INFO - validation batch 151, loss: 1.497, 4832/6976 datapoints
2025-03-07 13:00:23,922 - INFO - validation batch 201, loss: 0.879, 6432/6976 datapoints
2025-03-07 13:00:23,963 - INFO - Epoch 454/800 done.
2025-03-07 13:00:23,963 - INFO - Final validation performance:
Loss: 1.513, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:00:23,964 - INFO - Beginning epoch 455/800
2025-03-07 13:00:23,976 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:00:24,466 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:00:25,026 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:00:25,507 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:00:26,004 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:00:26,472 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:00:26,909 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:00:27,333 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:00:27,748 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:00:28,182 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:00:28,619 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:00:29,081 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:00:29,532 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:00:29,994 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:00:30,442 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:00:30,929 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:00:31,381 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:00:31,832 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:00:32,042 - INFO - validation batch 1, loss: 0.008, 32/6976 datapoints
2025-03-07 13:00:32,121 - INFO - validation batch 51, loss: 4.780, 1632/6976 datapoints
2025-03-07 13:00:32,205 - INFO - validation batch 101, loss: 0.406, 3232/6976 datapoints
2025-03-07 13:00:32,280 - INFO - validation batch 151, loss: 1.510, 4832/6976 datapoints
2025-03-07 13:00:32,352 - INFO - validation batch 201, loss: 0.894, 6432/6976 datapoints
2025-03-07 13:00:32,379 - INFO - Epoch 455/800 done.
2025-03-07 13:00:32,379 - INFO - Final validation performance:
Loss: 1.520, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:00:32,380 - INFO - Beginning epoch 456/800
2025-03-07 13:00:32,388 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:00:32,829 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:00:33,283 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:00:33,742 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:00:34,153 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:00:34,617 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:00:35,090 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:00:35,514 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:00:35,957 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:00:36,383 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:00:36,796 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:00:37,221 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:00:37,689 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:00:38,136 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:00:38,569 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:00:38,937 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:00:39,308 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:00:39,688 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:00:39,874 - INFO - validation batch 1, loss: 0.011, 32/6976 datapoints
2025-03-07 13:00:39,949 - INFO - validation batch 51, loss: 4.778, 1632/6976 datapoints
2025-03-07 13:00:40,021 - INFO - validation batch 101, loss: 0.414, 3232/6976 datapoints
2025-03-07 13:00:40,093 - INFO - validation batch 151, loss: 1.527, 4832/6976 datapoints
2025-03-07 13:00:40,168 - INFO - validation batch 201, loss: 0.917, 6432/6976 datapoints
2025-03-07 13:00:40,191 - INFO - Epoch 456/800 done.
2025-03-07 13:00:40,191 - INFO - Final validation performance:
Loss: 1.529, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:00:40,192 - INFO - Beginning epoch 457/800
2025-03-07 13:00:40,201 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:00:40,596 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:00:40,996 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:00:41,390 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:00:41,804 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:00:42,292 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:00:42,836 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:00:43,306 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:00:43,805 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:00:44,301 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:00:44,812 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:00:45,329 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:00:45,861 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:00:46,425 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:00:46,984 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:00:47,474 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:00:47,996 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:00:48,509 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:00:48,760 - INFO - validation batch 1, loss: 0.015, 32/6976 datapoints
2025-03-07 13:00:48,862 - INFO - validation batch 51, loss: 4.769, 1632/6976 datapoints
2025-03-07 13:00:48,959 - INFO - validation batch 101, loss: 0.423, 3232/6976 datapoints
2025-03-07 13:00:49,054 - INFO - validation batch 151, loss: 1.543, 4832/6976 datapoints
2025-03-07 13:00:49,145 - INFO - validation batch 201, loss: 0.938, 6432/6976 datapoints
2025-03-07 13:00:49,179 - INFO - Epoch 457/800 done.
2025-03-07 13:00:49,179 - INFO - Final validation performance:
Loss: 1.538, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:00:49,180 - INFO - Beginning epoch 458/800
2025-03-07 13:00:49,190 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:00:49,694 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:00:50,198 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:00:50,659 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:00:51,129 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:00:51,592 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:00:52,055 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:00:52,493 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:00:52,870 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:00:53,269 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:00:53,681 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:00:54,087 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:00:54,523 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:00:54,986 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:00:55,413 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:00:55,823 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:00:56,268 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:00:56,691 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:00:56,926 - INFO - validation batch 1, loss: 0.018, 32/6976 datapoints
2025-03-07 13:00:57,020 - INFO - validation batch 51, loss: 4.768, 1632/6976 datapoints
2025-03-07 13:00:57,107 - INFO - validation batch 101, loss: 0.438, 3232/6976 datapoints
2025-03-07 13:00:57,195 - INFO - validation batch 151, loss: 1.558, 4832/6976 datapoints
2025-03-07 13:00:57,300 - INFO - validation batch 201, loss: 0.959, 6432/6976 datapoints
2025-03-07 13:00:57,337 - INFO - Epoch 458/800 done.
2025-03-07 13:00:57,337 - INFO - Final validation performance:
Loss: 1.548, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:00:57,338 - INFO - Beginning epoch 459/800
2025-03-07 13:00:57,355 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:00:57,842 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:00:58,423 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:00:59,061 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:00:59,527 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:01:00,030 - INFO - training batch 251, loss: -0.000, 8032/28000 datapoints
2025-03-07 13:01:00,518 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:01:00,972 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:01:01,406 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:01:01,883 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:01:02,353 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:01:02,798 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:01:03,256 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:01:03,718 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:01:04,171 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:01:04,592 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:01:05,058 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:01:05,547 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:01:05,775 - INFO - validation batch 1, loss: 0.023, 32/6976 datapoints
2025-03-07 13:01:05,872 - INFO - validation batch 51, loss: 4.744, 1632/6976 datapoints
2025-03-07 13:01:05,964 - INFO - validation batch 101, loss: 0.457, 3232/6976 datapoints
2025-03-07 13:01:06,061 - INFO - validation batch 151, loss: 1.551, 4832/6976 datapoints
2025-03-07 13:01:06,190 - INFO - validation batch 201, loss: 0.966, 6432/6976 datapoints
2025-03-07 13:01:06,227 - INFO - Epoch 459/800 done.
2025-03-07 13:01:06,227 - INFO - Final validation performance:
Loss: 1.548, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:01:06,228 - INFO - Beginning epoch 460/800
2025-03-07 13:01:06,239 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:01:06,713 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:01:07,202 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:01:07,678 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:01:08,093 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:01:08,510 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:01:08,914 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:01:09,287 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:01:09,657 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:01:10,045 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:01:10,427 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:01:10,797 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:01:11,184 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:01:11,580 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:01:11,970 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:01:12,327 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:01:12,698 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:01:13,075 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:01:13,262 - INFO - validation batch 1, loss: 0.025, 32/6976 datapoints
2025-03-07 13:01:13,333 - INFO - validation batch 51, loss: 4.747, 1632/6976 datapoints
2025-03-07 13:01:13,405 - INFO - validation batch 101, loss: 0.486, 3232/6976 datapoints
2025-03-07 13:01:13,478 - INFO - validation batch 151, loss: 1.571, 4832/6976 datapoints
2025-03-07 13:01:13,557 - INFO - validation batch 201, loss: 0.988, 6432/6976 datapoints
2025-03-07 13:01:13,581 - INFO - Epoch 460/800 done.
2025-03-07 13:01:13,581 - INFO - Final validation performance:
Loss: 1.563, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:01:13,582 - INFO - Beginning epoch 461/800
2025-03-07 13:01:13,590 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:01:13,974 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:01:14,407 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:01:15,098 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:01:15,486 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:01:15,885 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:01:16,313 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:01:16,701 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:01:17,085 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:01:17,517 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:01:17,944 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:01:18,343 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:01:18,779 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:01:19,241 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:01:19,655 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:01:20,025 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:01:20,416 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:01:20,832 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:01:21,034 - INFO - validation batch 1, loss: 0.023, 32/6976 datapoints
2025-03-07 13:01:21,119 - INFO - validation batch 51, loss: 4.722, 1632/6976 datapoints
2025-03-07 13:01:21,207 - INFO - validation batch 101, loss: 0.516, 3232/6976 datapoints
2025-03-07 13:01:21,295 - INFO - validation batch 151, loss: 1.571, 4832/6976 datapoints
2025-03-07 13:01:21,383 - INFO - validation batch 201, loss: 1.010, 6432/6976 datapoints
2025-03-07 13:01:21,410 - INFO - Epoch 461/800 done.
2025-03-07 13:01:21,410 - INFO - Final validation performance:
Loss: 1.568, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:01:21,410 - INFO - Beginning epoch 462/800
2025-03-07 13:01:21,419 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:01:21,826 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:01:22,241 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:01:22,644 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:01:23,022 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:01:23,421 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:01:23,854 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:01:24,254 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:01:24,694 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:01:25,082 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:01:25,473 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:01:25,864 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:01:26,277 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:01:26,804 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:01:27,220 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:01:27,605 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:01:28,030 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:01:28,433 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:01:28,637 - INFO - validation batch 1, loss: 0.021, 32/6976 datapoints
2025-03-07 13:01:28,714 - INFO - validation batch 51, loss: 4.757, 1632/6976 datapoints
2025-03-07 13:01:28,788 - INFO - validation batch 101, loss: 0.558, 3232/6976 datapoints
2025-03-07 13:01:28,862 - INFO - validation batch 151, loss: 1.550, 4832/6976 datapoints
2025-03-07 13:01:28,940 - INFO - validation batch 201, loss: 0.997, 6432/6976 datapoints
2025-03-07 13:01:28,968 - INFO - Epoch 462/800 done.
2025-03-07 13:01:28,969 - INFO - Final validation performance:
Loss: 1.576, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:01:28,969 - INFO - Beginning epoch 463/800
2025-03-07 13:01:28,977 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:01:29,419 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:01:29,904 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:01:30,335 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:01:30,795 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:01:31,214 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:01:31,676 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:01:32,174 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:01:32,570 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:01:32,972 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:01:33,403 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:01:33,822 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:01:34,240 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:01:34,650 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:01:35,066 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:01:35,445 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:01:35,833 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:01:36,231 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:01:36,434 - INFO - validation batch 1, loss: 0.016, 32/6976 datapoints
2025-03-07 13:01:36,544 - INFO - validation batch 51, loss: 4.750, 1632/6976 datapoints
2025-03-07 13:01:36,623 - INFO - validation batch 101, loss: 0.571, 3232/6976 datapoints
2025-03-07 13:01:36,704 - INFO - validation batch 151, loss: 1.597, 4832/6976 datapoints
2025-03-07 13:01:36,778 - INFO - validation batch 201, loss: 1.077, 6432/6976 datapoints
2025-03-07 13:01:36,806 - INFO - Epoch 463/800 done.
2025-03-07 13:01:36,807 - INFO - Final validation performance:
Loss: 1.602, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:01:36,807 - INFO - Beginning epoch 464/800
2025-03-07 13:01:36,816 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:01:37,220 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:01:37,629 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:01:38,042 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:01:38,436 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:01:38,839 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:01:39,269 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:01:39,659 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:01:40,028 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:01:40,402 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:01:40,783 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:01:41,202 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:01:41,641 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:01:42,076 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:01:42,505 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:01:42,955 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:01:43,441 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:01:43,931 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:01:44,162 - INFO - validation batch 1, loss: 0.075, 32/6976 datapoints
2025-03-07 13:01:44,256 - INFO - validation batch 51, loss: 5.351, 1632/6976 datapoints
2025-03-07 13:01:44,340 - INFO - validation batch 101, loss: 1.530, 3232/6976 datapoints
2025-03-07 13:01:44,432 - INFO - validation batch 151, loss: 1.359, 4832/6976 datapoints
2025-03-07 13:01:44,528 - INFO - validation batch 201, loss: 1.516, 6432/6976 datapoints
2025-03-07 13:01:44,562 - INFO - Epoch 464/800 done.
2025-03-07 13:01:44,562 - INFO - Final validation performance:
Loss: 1.966, top-1 acc: 0.891top-5 acc: 0.891
2025-03-07 13:01:44,563 - INFO - Beginning epoch 465/800
2025-03-07 13:01:44,573 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:01:45,039 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:01:45,511 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:01:45,955 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:01:46,402 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:01:46,871 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:01:47,319 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:01:47,789 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:01:48,242 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:01:48,717 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:01:49,155 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:01:49,584 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:01:50,038 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:01:50,512 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:01:51,187 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:01:51,717 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:01:52,266 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:01:52,779 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:01:53,020 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:01:53,121 - INFO - validation batch 51, loss: 4.932, 1632/6976 datapoints
2025-03-07 13:01:53,236 - INFO - validation batch 101, loss: 0.544, 3232/6976 datapoints
2025-03-07 13:01:53,349 - INFO - validation batch 151, loss: 0.979, 4832/6976 datapoints
2025-03-07 13:01:53,435 - INFO - validation batch 201, loss: 0.722, 6432/6976 datapoints
2025-03-07 13:01:53,465 - INFO - Epoch 465/800 done.
2025-03-07 13:01:53,466 - INFO - Final validation performance:
Loss: 1.436, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:01:53,466 - INFO - Beginning epoch 466/800
2025-03-07 13:01:53,476 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:01:53,919 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:01:54,355 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:01:54,836 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:01:55,280 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:01:55,810 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:01:56,328 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:01:56,801 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:01:57,178 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:01:57,577 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:01:57,985 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:01:58,383 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:01:58,820 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:01:59,226 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:01:59,634 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:02:00,042 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:02:00,460 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:02:00,938 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:02:01,180 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:02:01,280 - INFO - validation batch 51, loss: 4.934, 1632/6976 datapoints
2025-03-07 13:02:01,377 - INFO - validation batch 101, loss: 0.546, 3232/6976 datapoints
2025-03-07 13:02:01,502 - INFO - validation batch 151, loss: 0.982, 4832/6976 datapoints
2025-03-07 13:02:01,585 - INFO - validation batch 201, loss: 0.783, 6432/6976 datapoints
2025-03-07 13:02:01,617 - INFO - Epoch 466/800 done.
2025-03-07 13:02:01,618 - INFO - Final validation performance:
Loss: 1.450, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:02:01,619 - INFO - Beginning epoch 467/800
2025-03-07 13:02:01,627 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:02:02,075 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:02:02,512 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:02:02,931 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:02:03,355 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:02:03,800 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:02:04,314 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:02:04,776 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:02:05,180 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:02:05,604 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:02:06,051 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:02:06,538 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:02:07,041 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:02:07,537 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:02:08,035 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:02:08,555 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:02:09,011 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:02:09,490 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:02:09,714 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:02:09,816 - INFO - validation batch 51, loss: 4.923, 1632/6976 datapoints
2025-03-07 13:02:09,907 - INFO - validation batch 101, loss: 0.544, 3232/6976 datapoints
2025-03-07 13:02:10,000 - INFO - validation batch 151, loss: 0.991, 4832/6976 datapoints
2025-03-07 13:02:10,111 - INFO - validation batch 201, loss: 0.789, 6432/6976 datapoints
2025-03-07 13:02:10,172 - INFO - Epoch 467/800 done.
2025-03-07 13:02:10,190 - INFO - Final validation performance:
Loss: 1.450, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:02:10,191 - INFO - Beginning epoch 468/800
2025-03-07 13:02:10,206 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:02:11,206 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:02:11,904 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:02:12,586 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:02:13,106 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:02:13,595 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:02:14,033 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:02:14,450 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:02:14,846 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:02:15,262 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:02:15,697 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:02:16,290 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:02:16,838 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:02:17,381 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:02:17,834 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:02:18,360 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:02:18,803 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:02:19,241 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:02:19,438 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 13:02:19,518 - INFO - validation batch 51, loss: 4.913, 1632/6976 datapoints
2025-03-07 13:02:19,592 - INFO - validation batch 101, loss: 0.540, 3232/6976 datapoints
2025-03-07 13:02:19,664 - INFO - validation batch 151, loss: 1.002, 4832/6976 datapoints
2025-03-07 13:02:19,738 - INFO - validation batch 201, loss: 0.794, 6432/6976 datapoints
2025-03-07 13:02:19,765 - INFO - Epoch 468/800 done.
2025-03-07 13:02:19,765 - INFO - Final validation performance:
Loss: 1.451, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:02:19,766 - INFO - Beginning epoch 469/800
2025-03-07 13:02:19,774 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:02:20,171 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:02:20,565 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:02:20,961 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:02:21,384 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:02:21,863 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:02:22,290 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:02:22,698 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:02:23,060 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:02:23,438 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:02:23,829 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:02:24,229 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:02:24,642 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:02:25,044 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:02:25,452 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:02:25,909 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:02:26,371 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:02:26,759 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:02:26,949 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 13:02:27,024 - INFO - validation batch 51, loss: 4.903, 1632/6976 datapoints
2025-03-07 13:02:27,123 - INFO - validation batch 101, loss: 0.537, 3232/6976 datapoints
2025-03-07 13:02:27,197 - INFO - validation batch 151, loss: 1.013, 4832/6976 datapoints
2025-03-07 13:02:27,268 - INFO - validation batch 201, loss: 0.796, 6432/6976 datapoints
2025-03-07 13:02:27,293 - INFO - Epoch 469/800 done.
2025-03-07 13:02:27,293 - INFO - Final validation performance:
Loss: 1.451, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:02:27,293 - INFO - Beginning epoch 470/800
2025-03-07 13:02:27,303 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:02:27,710 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:02:28,162 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:02:28,574 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:02:29,004 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:02:29,465 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:02:29,940 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:02:30,522 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:02:30,939 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:02:31,331 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:02:31,814 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:02:32,290 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:02:32,924 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:02:33,470 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:02:34,023 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:02:34,564 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:02:35,165 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:02:35,677 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:02:35,920 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 13:02:36,018 - INFO - validation batch 51, loss: 4.893, 1632/6976 datapoints
2025-03-07 13:02:36,121 - INFO - validation batch 101, loss: 0.532, 3232/6976 datapoints
2025-03-07 13:02:36,217 - INFO - validation batch 151, loss: 1.025, 4832/6976 datapoints
2025-03-07 13:02:36,314 - INFO - validation batch 201, loss: 0.796, 6432/6976 datapoints
2025-03-07 13:02:36,347 - INFO - Epoch 470/800 done.
2025-03-07 13:02:36,348 - INFO - Final validation performance:
Loss: 1.450, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:02:36,348 - INFO - Beginning epoch 471/800
2025-03-07 13:02:36,359 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:02:36,778 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:02:37,197 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:02:37,651 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:02:38,078 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:02:38,485 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:02:38,880 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:02:39,290 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:02:39,716 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:02:40,185 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:02:40,592 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:02:41,017 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:02:41,609 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:02:42,144 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:02:42,568 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:02:43,162 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:02:43,655 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:02:44,295 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:02:44,570 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 13:02:44,771 - INFO - validation batch 51, loss: 4.882, 1632/6976 datapoints
2025-03-07 13:02:44,886 - INFO - validation batch 101, loss: 0.526, 3232/6976 datapoints
2025-03-07 13:02:45,108 - INFO - validation batch 151, loss: 1.039, 4832/6976 datapoints
2025-03-07 13:02:45,270 - INFO - validation batch 201, loss: 0.794, 6432/6976 datapoints
2025-03-07 13:02:45,319 - INFO - Epoch 471/800 done.
2025-03-07 13:02:45,319 - INFO - Final validation performance:
Loss: 1.450, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:02:45,320 - INFO - Beginning epoch 472/800
2025-03-07 13:02:45,333 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:02:45,905 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:02:46,511 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:02:47,489 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:02:49,274 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:02:49,920 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:02:50,458 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:02:51,038 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:02:51,655 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:02:52,231 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:02:52,870 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:02:53,435 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:02:54,039 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:02:54,639 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:02:55,174 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:02:55,917 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:02:56,615 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:02:57,436 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:02:57,719 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 13:02:57,887 - INFO - validation batch 51, loss: 4.872, 1632/6976 datapoints
2025-03-07 13:02:58,127 - INFO - validation batch 101, loss: 0.518, 3232/6976 datapoints
2025-03-07 13:02:58,300 - INFO - validation batch 151, loss: 1.053, 4832/6976 datapoints
2025-03-07 13:02:58,429 - INFO - validation batch 201, loss: 0.791, 6432/6976 datapoints
2025-03-07 13:02:58,493 - INFO - Epoch 472/800 done.
2025-03-07 13:02:58,505 - INFO - Final validation performance:
Loss: 1.448, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:02:58,513 - INFO - Beginning epoch 473/800
2025-03-07 13:02:58,526 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:02:59,134 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:02:59,769 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:03:00,282 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:03:01,186 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:03:02,326 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:03:02,858 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:03:03,618 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:03:04,188 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:03:04,771 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:03:05,273 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:03:05,823 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:03:06,280 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:03:06,788 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:03:07,240 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:03:07,693 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:03:08,280 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:03:09,095 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:03:09,485 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:03:09,591 - INFO - validation batch 51, loss: 4.861, 1632/6976 datapoints
2025-03-07 13:03:09,709 - INFO - validation batch 101, loss: 0.508, 3232/6976 datapoints
2025-03-07 13:03:09,836 - INFO - validation batch 151, loss: 1.068, 4832/6976 datapoints
2025-03-07 13:03:09,951 - INFO - validation batch 201, loss: 0.787, 6432/6976 datapoints
2025-03-07 13:03:09,996 - INFO - Epoch 473/800 done.
2025-03-07 13:03:09,996 - INFO - Final validation performance:
Loss: 1.446, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:03:09,997 - INFO - Beginning epoch 474/800
2025-03-07 13:03:10,012 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:03:10,586 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:03:11,616 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:03:14,053 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:03:15,118 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:03:16,106 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:03:17,012 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:03:18,257 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:03:18,997 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:03:19,621 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:03:20,261 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:03:21,063 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:03:21,839 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:03:22,547 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:03:23,079 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:03:23,663 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:03:24,236 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:03:24,774 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:03:24,978 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:03:25,079 - INFO - validation batch 51, loss: 4.850, 1632/6976 datapoints
2025-03-07 13:03:25,183 - INFO - validation batch 101, loss: 0.495, 3232/6976 datapoints
2025-03-07 13:03:25,306 - INFO - validation batch 151, loss: 1.084, 4832/6976 datapoints
2025-03-07 13:03:25,462 - INFO - validation batch 201, loss: 0.783, 6432/6976 datapoints
2025-03-07 13:03:25,525 - INFO - Epoch 474/800 done.
2025-03-07 13:03:25,526 - INFO - Final validation performance:
Loss: 1.444, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:03:25,529 - INFO - Beginning epoch 475/800
2025-03-07 13:03:25,541 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:03:26,081 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:03:26,713 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:03:27,216 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:03:27,726 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:03:28,208 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:03:28,735 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:03:29,198 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:03:29,598 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:03:30,081 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:03:31,031 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:03:31,931 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:03:32,480 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:03:33,163 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:03:33,792 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:03:34,615 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:03:35,105 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:03:35,575 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:03:35,776 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:03:35,857 - INFO - validation batch 51, loss: 4.839, 1632/6976 datapoints
2025-03-07 13:03:35,936 - INFO - validation batch 101, loss: 0.481, 3232/6976 datapoints
2025-03-07 13:03:36,014 - INFO - validation batch 151, loss: 1.102, 4832/6976 datapoints
2025-03-07 13:03:36,094 - INFO - validation batch 201, loss: 0.780, 6432/6976 datapoints
2025-03-07 13:03:36,123 - INFO - Epoch 475/800 done.
2025-03-07 13:03:36,123 - INFO - Final validation performance:
Loss: 1.441, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:03:36,124 - INFO - Beginning epoch 476/800
2025-03-07 13:03:36,132 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:03:36,623 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:03:37,084 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:03:37,507 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:03:37,921 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:03:38,335 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:03:38,822 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:03:39,226 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:03:39,638 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:03:40,100 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:03:40,559 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:03:40,990 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:03:41,400 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:03:41,816 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:03:42,231 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:03:42,682 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:03:43,075 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:03:43,450 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:03:43,656 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:03:43,733 - INFO - validation batch 51, loss: 4.829, 1632/6976 datapoints
2025-03-07 13:03:43,807 - INFO - validation batch 101, loss: 0.466, 3232/6976 datapoints
2025-03-07 13:03:43,882 - INFO - validation batch 151, loss: 1.122, 4832/6976 datapoints
2025-03-07 13:03:43,977 - INFO - validation batch 201, loss: 0.778, 6432/6976 datapoints
2025-03-07 13:03:44,034 - INFO - Epoch 476/800 done.
2025-03-07 13:03:44,035 - INFO - Final validation performance:
Loss: 1.440, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:03:44,035 - INFO - Beginning epoch 477/800
2025-03-07 13:03:44,045 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:03:44,693 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:03:45,502 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:03:46,413 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:03:47,312 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:03:47,976 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:03:48,530 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:03:49,044 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:03:49,488 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:03:49,989 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:03:50,465 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:03:50,915 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:03:51,382 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:03:51,868 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:03:52,329 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:03:52,776 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:03:53,224 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:03:53,645 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:03:53,859 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:03:53,958 - INFO - validation batch 51, loss: 4.821, 1632/6976 datapoints
2025-03-07 13:03:54,038 - INFO - validation batch 101, loss: 0.451, 3232/6976 datapoints
2025-03-07 13:03:54,141 - INFO - validation batch 151, loss: 1.144, 4832/6976 datapoints
2025-03-07 13:03:54,253 - INFO - validation batch 201, loss: 0.778, 6432/6976 datapoints
2025-03-07 13:03:54,291 - INFO - Epoch 477/800 done.
2025-03-07 13:03:54,291 - INFO - Final validation performance:
Loss: 1.440, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:03:54,291 - INFO - Beginning epoch 478/800
2025-03-07 13:03:54,303 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:03:54,884 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:03:55,427 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:03:56,146 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:03:57,381 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:03:58,078 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:03:58,593 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:03:59,092 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:03:59,472 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:03:59,878 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:04:00,380 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:04:00,817 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:04:01,235 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:04:01,644 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:04:02,189 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:04:02,646 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:04:03,099 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:04:03,513 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:04:03,751 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:04:03,837 - INFO - validation batch 51, loss: 4.817, 1632/6976 datapoints
2025-03-07 13:04:03,925 - INFO - validation batch 101, loss: 0.438, 3232/6976 datapoints
2025-03-07 13:04:04,007 - INFO - validation batch 151, loss: 1.169, 4832/6976 datapoints
2025-03-07 13:04:04,112 - INFO - validation batch 201, loss: 0.782, 6432/6976 datapoints
2025-03-07 13:04:04,141 - INFO - Epoch 478/800 done.
2025-03-07 13:04:04,141 - INFO - Final validation performance:
Loss: 1.442, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:04:04,142 - INFO - Beginning epoch 479/800
2025-03-07 13:04:04,154 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:04:04,593 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:04:05,083 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:04:05,539 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:04:06,000 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:04:06,477 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:04:06,950 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:04:07,385 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:04:07,845 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:04:08,267 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:04:08,678 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:04:09,069 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:04:09,524 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:04:10,023 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:04:10,496 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:04:10,956 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:04:11,410 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:04:11,840 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:04:12,061 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:04:12,147 - INFO - validation batch 51, loss: 4.818, 1632/6976 datapoints
2025-03-07 13:04:12,238 - INFO - validation batch 101, loss: 0.428, 3232/6976 datapoints
2025-03-07 13:04:12,325 - INFO - validation batch 151, loss: 1.195, 4832/6976 datapoints
2025-03-07 13:04:12,418 - INFO - validation batch 201, loss: 0.789, 6432/6976 datapoints
2025-03-07 13:04:12,452 - INFO - Epoch 479/800 done.
2025-03-07 13:04:12,452 - INFO - Final validation performance:
Loss: 1.446, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:04:12,453 - INFO - Beginning epoch 480/800
2025-03-07 13:04:12,464 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:04:12,984 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:04:13,687 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:04:14,194 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:04:14,721 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:04:15,254 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:04:15,726 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:04:16,714 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:04:17,529 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:04:18,071 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:04:18,558 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:04:18,993 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:04:19,464 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:04:19,964 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:04:20,541 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:04:21,096 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:04:21,557 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:04:21,980 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:04:22,208 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:04:22,292 - INFO - validation batch 51, loss: 4.824, 1632/6976 datapoints
2025-03-07 13:04:22,391 - INFO - validation batch 101, loss: 0.421, 3232/6976 datapoints
2025-03-07 13:04:22,473 - INFO - validation batch 151, loss: 1.224, 4832/6976 datapoints
2025-03-07 13:04:22,558 - INFO - validation batch 201, loss: 0.800, 6432/6976 datapoints
2025-03-07 13:04:22,585 - INFO - Epoch 480/800 done.
2025-03-07 13:04:22,585 - INFO - Final validation performance:
Loss: 1.454, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:04:22,586 - INFO - Beginning epoch 481/800
2025-03-07 13:04:22,594 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:04:23,032 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:04:23,564 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:04:23,984 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:04:24,405 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:04:24,816 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:04:25,242 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:04:25,636 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:04:26,016 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:04:26,420 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:04:26,846 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:04:27,245 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:04:27,642 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:04:28,101 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:04:28,518 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:04:28,930 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:04:29,387 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:04:29,786 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:04:30,002 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:04:30,105 - INFO - validation batch 51, loss: 4.834, 1632/6976 datapoints
2025-03-07 13:04:30,203 - INFO - validation batch 101, loss: 0.416, 3232/6976 datapoints
2025-03-07 13:04:30,284 - INFO - validation batch 151, loss: 1.256, 4832/6976 datapoints
2025-03-07 13:04:30,363 - INFO - validation batch 201, loss: 0.815, 6432/6976 datapoints
2025-03-07 13:04:30,390 - INFO - Epoch 481/800 done.
2025-03-07 13:04:30,390 - INFO - Final validation performance:
Loss: 1.464, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:04:30,391 - INFO - Beginning epoch 482/800
2025-03-07 13:04:30,399 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:04:31,020 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:04:31,529 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:04:31,964 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:04:32,396 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:04:32,838 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:04:33,309 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:04:33,735 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:04:34,162 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:04:34,779 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:04:35,186 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:04:35,574 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:04:35,975 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:04:36,473 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:04:36,919 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:04:37,521 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:04:37,959 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:04:38,386 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:04:38,624 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:04:38,735 - INFO - validation batch 51, loss: 4.848, 1632/6976 datapoints
2025-03-07 13:04:38,852 - INFO - validation batch 101, loss: 0.412, 3232/6976 datapoints
2025-03-07 13:04:38,956 - INFO - validation batch 151, loss: 1.288, 4832/6976 datapoints
2025-03-07 13:04:39,074 - INFO - validation batch 201, loss: 0.835, 6432/6976 datapoints
2025-03-07 13:04:39,101 - INFO - Epoch 482/800 done.
2025-03-07 13:04:39,101 - INFO - Final validation performance:
Loss: 1.477, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:04:39,102 - INFO - Beginning epoch 483/800
2025-03-07 13:04:39,112 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:04:39,573 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:04:40,024 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:04:40,453 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:04:40,908 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:04:41,343 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:04:41,846 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:04:42,294 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:04:42,750 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:04:43,176 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:04:43,635 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:04:44,093 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:04:44,671 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:04:45,126 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:04:45,588 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:04:46,027 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:04:46,527 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:04:46,968 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:04:47,227 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:04:47,309 - INFO - validation batch 51, loss: 4.862, 1632/6976 datapoints
2025-03-07 13:04:47,388 - INFO - validation batch 101, loss: 0.411, 3232/6976 datapoints
2025-03-07 13:04:47,469 - INFO - validation batch 151, loss: 1.321, 4832/6976 datapoints
2025-03-07 13:04:47,555 - INFO - validation batch 201, loss: 0.858, 6432/6976 datapoints
2025-03-07 13:04:47,585 - INFO - Epoch 483/800 done.
2025-03-07 13:04:47,585 - INFO - Final validation performance:
Loss: 1.491, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:04:47,585 - INFO - Beginning epoch 484/800
2025-03-07 13:04:47,596 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:04:48,063 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:04:48,514 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:04:48,932 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:04:49,378 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:04:49,870 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:04:50,331 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:04:50,735 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:04:51,151 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:04:51,558 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:04:51,994 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:04:52,422 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:04:52,835 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:04:53,273 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:04:53,688 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:04:54,111 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:04:54,545 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:04:54,981 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:04:55,194 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:04:55,299 - INFO - validation batch 51, loss: 4.881, 1632/6976 datapoints
2025-03-07 13:04:55,387 - INFO - validation batch 101, loss: 0.411, 3232/6976 datapoints
2025-03-07 13:04:55,485 - INFO - validation batch 151, loss: 1.353, 4832/6976 datapoints
2025-03-07 13:04:55,569 - INFO - validation batch 201, loss: 0.879, 6432/6976 datapoints
2025-03-07 13:04:55,599 - INFO - Epoch 484/800 done.
2025-03-07 13:04:55,599 - INFO - Final validation performance:
Loss: 1.505, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:04:55,600 - INFO - Beginning epoch 485/800
2025-03-07 13:04:55,613 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:04:56,090 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:04:56,554 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:04:57,029 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:04:57,495 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:04:58,057 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:04:58,537 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:04:58,970 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:04:59,440 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:04:59,950 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:05:00,377 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:05:00,801 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:05:01,287 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:05:01,775 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:05:02,243 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:05:02,701 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:05:03,158 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:05:03,713 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:05:03,953 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:05:04,043 - INFO - validation batch 51, loss: 4.895, 1632/6976 datapoints
2025-03-07 13:05:04,151 - INFO - validation batch 101, loss: 0.413, 3232/6976 datapoints
2025-03-07 13:05:04,264 - INFO - validation batch 151, loss: 1.385, 4832/6976 datapoints
2025-03-07 13:05:04,370 - INFO - validation batch 201, loss: 0.901, 6432/6976 datapoints
2025-03-07 13:05:04,413 - INFO - Epoch 485/800 done.
2025-03-07 13:05:04,413 - INFO - Final validation performance:
Loss: 1.519, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:05:04,414 - INFO - Beginning epoch 486/800
2025-03-07 13:05:04,425 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:05:04,966 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:05:05,549 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:05:06,060 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:05:06,559 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:05:07,128 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:05:07,717 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:05:08,262 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:05:08,741 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:05:09,204 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:05:09,666 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:05:10,147 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:05:10,651 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:05:11,152 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:05:11,634 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:05:12,048 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:05:12,619 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:05:13,152 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:05:13,648 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:05:13,930 - INFO - validation batch 51, loss: 4.911, 1632/6976 datapoints
2025-03-07 13:05:14,158 - INFO - validation batch 101, loss: 0.416, 3232/6976 datapoints
2025-03-07 13:05:14,367 - INFO - validation batch 151, loss: 1.412, 4832/6976 datapoints
2025-03-07 13:05:14,521 - INFO - validation batch 201, loss: 0.927, 6432/6976 datapoints
2025-03-07 13:05:14,563 - INFO - Epoch 486/800 done.
2025-03-07 13:05:14,564 - INFO - Final validation performance:
Loss: 1.534, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:05:14,566 - INFO - Beginning epoch 487/800
2025-03-07 13:05:14,580 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:05:15,093 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:05:15,547 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:05:16,021 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:05:16,433 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:05:16,858 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:05:17,268 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:05:17,733 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:05:18,112 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:05:18,764 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:05:19,186 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:05:19,578 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:05:20,011 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:05:20,450 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:05:20,893 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:05:21,340 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:05:21,747 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:05:22,183 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:05:22,408 - INFO - validation batch 1, loss: 0.007, 32/6976 datapoints
2025-03-07 13:05:22,499 - INFO - validation batch 51, loss: 4.924, 1632/6976 datapoints
2025-03-07 13:05:22,585 - INFO - validation batch 101, loss: 0.421, 3232/6976 datapoints
2025-03-07 13:05:22,725 - INFO - validation batch 151, loss: 1.442, 4832/6976 datapoints
2025-03-07 13:05:22,839 - INFO - validation batch 201, loss: 0.958, 6432/6976 datapoints
2025-03-07 13:05:22,877 - INFO - Epoch 487/800 done.
2025-03-07 13:05:22,878 - INFO - Final validation performance:
Loss: 1.550, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:05:22,878 - INFO - Beginning epoch 488/800
2025-03-07 13:05:22,890 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:05:23,320 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:05:23,766 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:05:24,210 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:05:24,722 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:05:25,229 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:05:25,724 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:05:26,211 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:05:26,635 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:05:27,077 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:05:27,503 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:05:27,929 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:05:28,369 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:05:28,810 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:05:29,227 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:05:29,618 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:05:30,052 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:05:30,460 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:05:30,819 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 13:05:30,917 - INFO - validation batch 51, loss: 4.936, 1632/6976 datapoints
2025-03-07 13:05:31,013 - INFO - validation batch 101, loss: 0.436, 3232/6976 datapoints
2025-03-07 13:05:31,089 - INFO - validation batch 151, loss: 1.472, 4832/6976 datapoints
2025-03-07 13:05:31,165 - INFO - validation batch 201, loss: 0.981, 6432/6976 datapoints
2025-03-07 13:05:31,191 - INFO - Epoch 488/800 done.
2025-03-07 13:05:31,191 - INFO - Final validation performance:
Loss: 1.567, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:05:31,192 - INFO - Beginning epoch 489/800
2025-03-07 13:05:31,202 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:05:31,626 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:05:32,106 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:05:32,587 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:05:33,014 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:05:33,470 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:05:33,957 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:05:34,392 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:05:34,827 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:05:35,261 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:05:35,727 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:05:36,165 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:05:36,662 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:05:37,069 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:05:37,480 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:05:37,881 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:05:38,310 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:05:38,723 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:05:38,936 - INFO - validation batch 1, loss: 0.015, 32/6976 datapoints
2025-03-07 13:05:39,022 - INFO - validation batch 51, loss: 4.929, 1632/6976 datapoints
2025-03-07 13:05:39,123 - INFO - validation batch 101, loss: 0.457, 3232/6976 datapoints
2025-03-07 13:05:39,228 - INFO - validation batch 151, loss: 1.507, 4832/6976 datapoints
2025-03-07 13:05:39,320 - INFO - validation batch 201, loss: 1.018, 6432/6976 datapoints
2025-03-07 13:05:39,349 - INFO - Epoch 489/800 done.
2025-03-07 13:05:39,349 - INFO - Final validation performance:
Loss: 1.585, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:05:39,350 - INFO - Beginning epoch 490/800
2025-03-07 13:05:39,363 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:05:39,885 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:05:40,390 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:05:40,920 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:05:41,548 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:05:42,031 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:05:42,478 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:05:42,884 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:05:43,248 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:05:43,632 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:05:44,050 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:05:44,439 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:05:44,854 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:05:45,323 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:05:45,863 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:05:46,393 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:05:46,844 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:05:47,253 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:05:47,448 - INFO - validation batch 1, loss: 0.018, 32/6976 datapoints
2025-03-07 13:05:47,526 - INFO - validation batch 51, loss: 4.928, 1632/6976 datapoints
2025-03-07 13:05:47,598 - INFO - validation batch 101, loss: 0.480, 3232/6976 datapoints
2025-03-07 13:05:47,671 - INFO - validation batch 151, loss: 1.532, 4832/6976 datapoints
2025-03-07 13:05:47,758 - INFO - validation batch 201, loss: 1.037, 6432/6976 datapoints
2025-03-07 13:05:47,788 - INFO - Epoch 490/800 done.
2025-03-07 13:05:47,789 - INFO - Final validation performance:
Loss: 1.599, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:05:47,790 - INFO - Beginning epoch 491/800
2025-03-07 13:05:47,799 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:05:48,222 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:05:48,664 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:05:49,066 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:05:49,459 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:05:49,869 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:05:50,305 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:05:50,698 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:05:51,057 - INFO - training batch 401, loss: -0.000, 12832/28000 datapoints
2025-03-07 13:05:51,439 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:05:51,833 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:05:52,237 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:05:52,649 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:05:53,054 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:05:53,468 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:05:53,853 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:05:54,239 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:05:54,629 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:05:54,836 - INFO - validation batch 1, loss: 0.022, 32/6976 datapoints
2025-03-07 13:05:54,911 - INFO - validation batch 51, loss: 4.931, 1632/6976 datapoints
2025-03-07 13:05:54,988 - INFO - validation batch 101, loss: 0.502, 3232/6976 datapoints
2025-03-07 13:05:55,066 - INFO - validation batch 151, loss: 1.535, 4832/6976 datapoints
2025-03-07 13:05:55,140 - INFO - validation batch 201, loss: 1.048, 6432/6976 datapoints
2025-03-07 13:05:55,170 - INFO - Epoch 491/800 done.
2025-03-07 13:05:55,170 - INFO - Final validation performance:
Loss: 1.607, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:05:55,171 - INFO - Beginning epoch 492/800
2025-03-07 13:05:55,180 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:05:55,579 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:05:55,993 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:05:56,402 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:05:56,807 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:05:57,224 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:05:57,879 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:05:58,352 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:05:58,828 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:05:59,244 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:05:59,687 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:06:00,159 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:06:00,634 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:06:01,171 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:06:01,675 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:06:02,198 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:06:02,624 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:06:03,029 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:06:03,227 - INFO - validation batch 1, loss: 0.021, 32/6976 datapoints
2025-03-07 13:06:03,302 - INFO - validation batch 51, loss: 4.879, 1632/6976 datapoints
2025-03-07 13:06:03,378 - INFO - validation batch 101, loss: 0.524, 3232/6976 datapoints
2025-03-07 13:06:03,455 - INFO - validation batch 151, loss: 1.537, 4832/6976 datapoints
2025-03-07 13:06:03,532 - INFO - validation batch 201, loss: 1.034, 6432/6976 datapoints
2025-03-07 13:06:03,559 - INFO - Epoch 492/800 done.
2025-03-07 13:06:03,559 - INFO - Final validation performance:
Loss: 1.599, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:06:03,561 - INFO - Beginning epoch 493/800
2025-03-07 13:06:03,571 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:06:04,062 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:06:04,673 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:06:05,107 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:06:05,549 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:06:06,005 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:06:06,455 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:06:06,892 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:06:07,329 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:06:07,788 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:06:08,238 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:06:08,687 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:06:09,195 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:06:09,735 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:06:10,195 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:06:10,658 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:06:11,108 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:06:11,563 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:06:11,798 - INFO - validation batch 1, loss: 0.020, 32/6976 datapoints
2025-03-07 13:06:11,913 - INFO - validation batch 51, loss: 4.867, 1632/6976 datapoints
2025-03-07 13:06:12,010 - INFO - validation batch 101, loss: 0.591, 3232/6976 datapoints
2025-03-07 13:06:12,098 - INFO - validation batch 151, loss: 1.548, 4832/6976 datapoints
2025-03-07 13:06:12,177 - INFO - validation batch 201, loss: 1.029, 6432/6976 datapoints
2025-03-07 13:06:12,202 - INFO - Epoch 493/800 done.
2025-03-07 13:06:12,202 - INFO - Final validation performance:
Loss: 1.611, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:06:12,203 - INFO - Beginning epoch 494/800
2025-03-07 13:06:12,214 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:06:12,657 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:06:13,092 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:06:13,602 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:06:14,161 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:06:14,601 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:06:15,015 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:06:15,451 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:06:16,019 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:06:16,540 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:06:16,981 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:06:17,395 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:06:17,937 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:06:18,454 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:06:18,923 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:06:19,345 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:06:19,778 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:06:20,188 - INFO - training batch 851, loss: 0.221, 27232/28000 datapoints
2025-03-07 13:06:20,420 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 13:06:20,544 - INFO - validation batch 51, loss: 4.913, 1632/6976 datapoints
2025-03-07 13:06:20,628 - INFO - validation batch 101, loss: 0.270, 3232/6976 datapoints
2025-03-07 13:06:20,711 - INFO - validation batch 151, loss: 1.206, 4832/6976 datapoints
2025-03-07 13:06:20,804 - INFO - validation batch 201, loss: 1.635, 6432/6976 datapoints
2025-03-07 13:06:20,833 - INFO - Epoch 494/800 done.
2025-03-07 13:06:20,833 - INFO - Final validation performance:
Loss: 1.617, top-1 acc: 0.895top-5 acc: 0.895
2025-03-07 13:06:20,834 - INFO - Beginning epoch 495/800
2025-03-07 13:06:20,843 - INFO - training batch 1, loss: 0.151, 32/28000 datapoints
2025-03-07 13:06:21,324 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:06:21,784 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:06:22,234 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:06:22,703 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:06:23,174 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:06:23,675 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:06:24,136 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:06:24,556 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:06:24,975 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:06:25,420 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:06:25,859 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:06:26,340 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:06:26,847 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:06:27,341 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:06:27,864 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:06:28,364 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:06:28,833 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:06:29,051 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:06:29,132 - INFO - validation batch 51, loss: 4.872, 1632/6976 datapoints
2025-03-07 13:06:29,226 - INFO - validation batch 101, loss: 0.518, 3232/6976 datapoints
2025-03-07 13:06:29,303 - INFO - validation batch 151, loss: 1.164, 4832/6976 datapoints
2025-03-07 13:06:29,385 - INFO - validation batch 201, loss: 1.207, 6432/6976 datapoints
2025-03-07 13:06:29,415 - INFO - Epoch 495/800 done.
2025-03-07 13:06:29,416 - INFO - Final validation performance:
Loss: 1.552, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:06:29,416 - INFO - Beginning epoch 496/800
2025-03-07 13:06:29,427 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:06:29,916 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:06:30,425 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:06:31,180 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:06:31,847 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:06:32,360 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:06:32,809 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:06:33,218 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:06:33,658 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:06:34,127 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:06:34,626 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:06:35,081 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:06:35,575 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:06:36,094 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:06:36,680 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:06:37,129 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:06:37,556 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:06:37,989 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:06:38,192 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:06:38,269 - INFO - validation batch 51, loss: 4.752, 1632/6976 datapoints
2025-03-07 13:06:38,343 - INFO - validation batch 101, loss: 0.479, 3232/6976 datapoints
2025-03-07 13:06:38,419 - INFO - validation batch 151, loss: 1.258, 4832/6976 datapoints
2025-03-07 13:06:38,513 - INFO - validation batch 201, loss: 1.306, 6432/6976 datapoints
2025-03-07 13:06:38,544 - INFO - Epoch 496/800 done.
2025-03-07 13:06:38,544 - INFO - Final validation performance:
Loss: 1.559, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:06:38,545 - INFO - Beginning epoch 497/800
2025-03-07 13:06:38,560 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:06:39,008 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:06:39,438 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:06:39,834 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:06:40,246 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:06:40,665 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:06:41,131 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:06:41,613 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:06:42,002 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:06:42,405 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:06:42,845 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:06:43,252 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:06:43,747 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:06:44,204 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:06:44,632 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:06:45,023 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:06:45,446 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:06:45,840 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:06:46,040 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:06:46,115 - INFO - validation batch 51, loss: 4.754, 1632/6976 datapoints
2025-03-07 13:06:46,187 - INFO - validation batch 101, loss: 0.474, 3232/6976 datapoints
2025-03-07 13:06:46,261 - INFO - validation batch 151, loss: 1.263, 4832/6976 datapoints
2025-03-07 13:06:46,335 - INFO - validation batch 201, loss: 1.306, 6432/6976 datapoints
2025-03-07 13:06:46,360 - INFO - Epoch 497/800 done.
2025-03-07 13:06:46,360 - INFO - Final validation performance:
Loss: 1.560, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:06:46,361 - INFO - Beginning epoch 498/800
2025-03-07 13:06:46,371 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:06:46,778 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:06:47,195 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:06:47,581 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:06:47,964 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:06:48,370 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:06:48,778 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:06:49,161 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:06:49,525 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:06:49,892 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:06:50,297 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:06:50,672 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:06:51,091 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:06:51,495 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:06:51,892 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:06:52,280 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:06:52,677 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:06:53,056 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:06:53,242 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:06:53,310 - INFO - validation batch 51, loss: 4.753, 1632/6976 datapoints
2025-03-07 13:06:53,379 - INFO - validation batch 101, loss: 0.471, 3232/6976 datapoints
2025-03-07 13:06:53,449 - INFO - validation batch 151, loss: 1.268, 4832/6976 datapoints
2025-03-07 13:06:53,519 - INFO - validation batch 201, loss: 1.304, 6432/6976 datapoints
2025-03-07 13:06:53,542 - INFO - Epoch 498/800 done.
2025-03-07 13:06:53,542 - INFO - Final validation performance:
Loss: 1.560, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:06:53,543 - INFO - Beginning epoch 499/800
2025-03-07 13:06:53,552 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:06:53,933 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:06:54,353 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:06:54,786 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:06:55,201 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:06:55,652 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:06:56,104 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:06:56,502 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:06:56,874 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:06:57,273 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:06:57,726 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:06:58,135 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:06:58,544 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:06:58,949 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:06:59,401 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:06:59,867 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:07:00,391 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:07:00,813 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:07:01,048 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:07:01,153 - INFO - validation batch 51, loss: 4.752, 1632/6976 datapoints
2025-03-07 13:07:01,241 - INFO - validation batch 101, loss: 0.467, 3232/6976 datapoints
2025-03-07 13:07:01,321 - INFO - validation batch 151, loss: 1.274, 4832/6976 datapoints
2025-03-07 13:07:01,399 - INFO - validation batch 201, loss: 1.300, 6432/6976 datapoints
2025-03-07 13:07:01,431 - INFO - Epoch 499/800 done.
2025-03-07 13:07:01,432 - INFO - Final validation performance:
Loss: 1.559, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:07:01,432 - INFO - Beginning epoch 500/800
2025-03-07 13:07:01,444 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:07:01,985 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:07:02,640 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:07:03,151 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:07:03,656 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:07:04,195 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:07:04,707 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:07:05,187 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:07:05,694 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:07:06,228 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:07:06,711 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:07:07,197 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:07:07,686 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:07:08,187 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:07:08,702 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:07:09,155 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:07:09,576 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:07:09,975 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:07:10,169 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:07:10,245 - INFO - validation batch 51, loss: 4.750, 1632/6976 datapoints
2025-03-07 13:07:10,322 - INFO - validation batch 101, loss: 0.464, 3232/6976 datapoints
2025-03-07 13:07:10,409 - INFO - validation batch 151, loss: 1.279, 4832/6976 datapoints
2025-03-07 13:07:10,485 - INFO - validation batch 201, loss: 1.294, 6432/6976 datapoints
2025-03-07 13:07:10,516 - INFO - Epoch 500/800 done.
2025-03-07 13:07:10,516 - INFO - Final validation performance:
Loss: 1.557, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:07:10,517 - INFO - Beginning epoch 501/800
2025-03-07 13:07:10,526 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:07:10,938 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:07:11,378 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:07:11,836 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:07:12,265 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:07:12,732 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:07:13,208 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:07:13,620 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:07:14,025 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:07:14,444 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:07:14,947 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:07:15,385 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:07:15,855 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:07:16,296 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:07:16,760 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:07:17,211 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:07:17,636 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:07:18,077 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:07:18,291 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:07:18,366 - INFO - validation batch 51, loss: 4.747, 1632/6976 datapoints
2025-03-07 13:07:18,446 - INFO - validation batch 101, loss: 0.459, 3232/6976 datapoints
2025-03-07 13:07:18,524 - INFO - validation batch 151, loss: 1.284, 4832/6976 datapoints
2025-03-07 13:07:18,601 - INFO - validation batch 201, loss: 1.287, 6432/6976 datapoints
2025-03-07 13:07:18,630 - INFO - Epoch 501/800 done.
2025-03-07 13:07:18,630 - INFO - Final validation performance:
Loss: 1.556, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:07:18,631 - INFO - Beginning epoch 502/800
2025-03-07 13:07:18,640 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:07:19,071 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:07:19,522 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:07:20,091 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:07:20,552 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:07:21,029 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:07:21,556 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:07:21,988 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:07:22,429 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:07:22,842 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:07:23,278 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:07:23,670 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:07:24,082 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:07:24,525 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:07:24,973 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:07:25,394 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:07:25,826 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:07:26,227 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:07:26,423 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:07:26,501 - INFO - validation batch 51, loss: 4.743, 1632/6976 datapoints
2025-03-07 13:07:26,591 - INFO - validation batch 101, loss: 0.453, 3232/6976 datapoints
2025-03-07 13:07:26,674 - INFO - validation batch 151, loss: 1.288, 4832/6976 datapoints
2025-03-07 13:07:26,761 - INFO - validation batch 201, loss: 1.279, 6432/6976 datapoints
2025-03-07 13:07:26,790 - INFO - Epoch 502/800 done.
2025-03-07 13:07:26,790 - INFO - Final validation performance:
Loss: 1.553, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:07:26,790 - INFO - Beginning epoch 503/800
2025-03-07 13:07:26,800 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:07:27,248 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:07:27,717 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:07:28,158 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:07:28,596 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:07:29,034 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:07:29,493 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:07:29,912 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:07:30,322 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:07:30,750 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:07:31,205 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:07:31,640 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:07:32,064 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:07:32,480 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:07:32,899 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:07:33,296 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:07:33,692 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:07:34,087 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:07:34,289 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:07:34,369 - INFO - validation batch 51, loss: 4.740, 1632/6976 datapoints
2025-03-07 13:07:34,451 - INFO - validation batch 101, loss: 0.447, 3232/6976 datapoints
2025-03-07 13:07:34,543 - INFO - validation batch 151, loss: 1.291, 4832/6976 datapoints
2025-03-07 13:07:34,629 - INFO - validation batch 201, loss: 1.269, 6432/6976 datapoints
2025-03-07 13:07:34,654 - INFO - Epoch 503/800 done.
2025-03-07 13:07:34,654 - INFO - Final validation performance:
Loss: 1.550, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:07:34,655 - INFO - Beginning epoch 504/800
2025-03-07 13:07:34,667 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:07:35,116 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:07:35,587 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:07:36,027 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:07:36,436 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:07:36,903 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:07:37,367 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:07:37,798 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:07:38,222 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:07:38,697 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:07:39,152 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:07:39,568 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:07:39,990 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:07:40,423 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:07:40,878 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:07:41,315 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:07:41,798 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:07:42,227 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:07:42,433 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:07:42,517 - INFO - validation batch 51, loss: 4.737, 1632/6976 datapoints
2025-03-07 13:07:42,594 - INFO - validation batch 101, loss: 0.439, 3232/6976 datapoints
2025-03-07 13:07:42,673 - INFO - validation batch 151, loss: 1.293, 4832/6976 datapoints
2025-03-07 13:07:42,754 - INFO - validation batch 201, loss: 1.258, 6432/6976 datapoints
2025-03-07 13:07:42,787 - INFO - Epoch 504/800 done.
2025-03-07 13:07:42,787 - INFO - Final validation performance:
Loss: 1.546, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:07:42,788 - INFO - Beginning epoch 505/800
2025-03-07 13:07:42,799 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:07:43,297 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:07:43,812 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:07:44,339 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:07:45,045 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:07:45,534 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:07:46,115 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:07:47,306 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:07:48,374 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:07:48,919 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:07:49,534 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:07:50,036 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:07:50,695 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:07:51,446 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:07:51,977 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:07:52,437 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:07:52,868 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:07:53,308 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:07:53,531 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:07:53,613 - INFO - validation batch 51, loss: 4.736, 1632/6976 datapoints
2025-03-07 13:07:53,696 - INFO - validation batch 101, loss: 0.431, 3232/6976 datapoints
2025-03-07 13:07:53,777 - INFO - validation batch 151, loss: 1.295, 4832/6976 datapoints
2025-03-07 13:07:53,849 - INFO - validation batch 201, loss: 1.245, 6432/6976 datapoints
2025-03-07 13:07:53,878 - INFO - Epoch 505/800 done.
2025-03-07 13:07:53,878 - INFO - Final validation performance:
Loss: 1.541, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:07:53,879 - INFO - Beginning epoch 506/800
2025-03-07 13:07:53,888 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:07:54,353 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:07:54,869 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:07:55,346 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:07:55,852 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:07:56,401 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:07:56,908 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:07:57,366 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:07:57,802 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:07:58,289 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:07:58,771 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:07:59,213 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:07:59,638 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:08:00,063 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:08:00,567 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:08:01,043 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:08:01,451 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:08:01,956 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:08:02,206 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:08:02,327 - INFO - validation batch 51, loss: 4.735, 1632/6976 datapoints
2025-03-07 13:08:02,434 - INFO - validation batch 101, loss: 0.422, 3232/6976 datapoints
2025-03-07 13:08:02,539 - INFO - validation batch 151, loss: 1.295, 4832/6976 datapoints
2025-03-07 13:08:02,664 - INFO - validation batch 201, loss: 1.231, 6432/6976 datapoints
2025-03-07 13:08:02,705 - INFO - Epoch 506/800 done.
2025-03-07 13:08:02,706 - INFO - Final validation performance:
Loss: 1.537, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:08:02,707 - INFO - Beginning epoch 507/800
2025-03-07 13:08:02,724 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:08:03,322 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:08:03,813 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:08:04,259 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:08:04,729 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:08:05,223 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:08:05,755 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:08:06,176 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:08:06,600 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:08:07,153 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:08:07,654 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:08:08,095 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:08:08,559 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:08:09,020 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:08:09,463 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:08:09,891 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:08:10,358 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:08:10,832 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:08:11,054 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:08:11,148 - INFO - validation batch 51, loss: 4.737, 1632/6976 datapoints
2025-03-07 13:08:11,236 - INFO - validation batch 101, loss: 0.413, 3232/6976 datapoints
2025-03-07 13:08:11,340 - INFO - validation batch 151, loss: 1.295, 4832/6976 datapoints
2025-03-07 13:08:11,443 - INFO - validation batch 201, loss: 1.215, 6432/6976 datapoints
2025-03-07 13:08:11,479 - INFO - Epoch 507/800 done.
2025-03-07 13:08:11,480 - INFO - Final validation performance:
Loss: 1.532, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:08:11,481 - INFO - Beginning epoch 508/800
2025-03-07 13:08:11,496 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:08:12,075 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:08:12,581 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:08:13,047 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:08:13,574 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:08:14,249 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:08:14,911 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:08:15,424 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:08:15,828 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:08:16,224 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:08:16,654 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:08:17,059 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:08:17,461 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:08:17,880 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:08:18,274 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:08:18,670 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:08:19,079 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:08:19,464 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:08:19,657 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:08:19,734 - INFO - validation batch 51, loss: 4.741, 1632/6976 datapoints
2025-03-07 13:08:19,814 - INFO - validation batch 101, loss: 0.404, 3232/6976 datapoints
2025-03-07 13:08:19,888 - INFO - validation batch 151, loss: 1.296, 4832/6976 datapoints
2025-03-07 13:08:19,961 - INFO - validation batch 201, loss: 1.198, 6432/6976 datapoints
2025-03-07 13:08:19,987 - INFO - Epoch 508/800 done.
2025-03-07 13:08:19,987 - INFO - Final validation performance:
Loss: 1.528, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 13:08:19,988 - INFO - Beginning epoch 509/800
2025-03-07 13:08:19,997 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:08:20,394 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:08:20,808 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:08:21,206 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:08:21,600 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:08:22,077 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:08:22,525 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:08:22,899 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:08:23,264 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:08:23,651 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:08:24,058 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:08:24,450 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:08:24,858 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:08:25,290 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:08:25,690 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:08:26,078 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:08:26,502 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:08:26,918 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:08:27,108 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:08:27,188 - INFO - validation batch 51, loss: 4.748, 1632/6976 datapoints
2025-03-07 13:08:27,272 - INFO - validation batch 101, loss: 0.395, 3232/6976 datapoints
2025-03-07 13:08:27,361 - INFO - validation batch 151, loss: 1.298, 4832/6976 datapoints
2025-03-07 13:08:27,456 - INFO - validation batch 201, loss: 1.181, 6432/6976 datapoints
2025-03-07 13:08:27,490 - INFO - Epoch 509/800 done.
2025-03-07 13:08:27,491 - INFO - Final validation performance:
Loss: 1.525, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 13:08:27,492 - INFO - Beginning epoch 510/800
2025-03-07 13:08:27,504 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:08:27,955 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:08:28,487 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:08:28,949 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:08:29,395 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:08:29,839 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:08:30,306 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:08:30,826 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:08:31,291 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:08:31,771 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:08:32,297 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:08:32,753 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:08:33,266 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:08:33,776 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:08:34,307 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:08:34,841 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:08:35,366 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:08:35,854 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:08:36,097 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:08:36,185 - INFO - validation batch 51, loss: 4.758, 1632/6976 datapoints
2025-03-07 13:08:36,271 - INFO - validation batch 101, loss: 0.386, 3232/6976 datapoints
2025-03-07 13:08:36,360 - INFO - validation batch 151, loss: 1.301, 4832/6976 datapoints
2025-03-07 13:08:36,457 - INFO - validation batch 201, loss: 1.165, 6432/6976 datapoints
2025-03-07 13:08:36,486 - INFO - Epoch 510/800 done.
2025-03-07 13:08:36,486 - INFO - Final validation performance:
Loss: 1.522, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:08:36,487 - INFO - Beginning epoch 511/800
2025-03-07 13:08:36,500 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:08:36,936 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:08:37,396 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:08:37,842 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:08:38,263 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:08:38,738 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:08:39,203 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:08:39,642 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:08:40,056 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:08:40,457 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:08:40,898 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:08:41,315 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:08:41,760 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:08:42,231 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:08:42,693 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:08:43,203 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:08:43,780 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:08:44,715 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:08:44,944 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:08:45,036 - INFO - validation batch 51, loss: 4.771, 1632/6976 datapoints
2025-03-07 13:08:45,115 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-07 13:08:45,210 - INFO - validation batch 151, loss: 1.305, 4832/6976 datapoints
2025-03-07 13:08:45,316 - INFO - validation batch 201, loss: 1.149, 6432/6976 datapoints
2025-03-07 13:08:45,345 - INFO - Epoch 511/800 done.
2025-03-07 13:08:45,345 - INFO - Final validation performance:
Loss: 1.521, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:08:45,346 - INFO - Beginning epoch 512/800
2025-03-07 13:08:45,362 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:08:45,894 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:08:46,322 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:08:46,864 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:08:47,662 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:08:48,214 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:08:48,667 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:08:49,090 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:08:49,503 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:08:49,899 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:08:50,324 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:08:50,752 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:08:51,158 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:08:51,561 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:08:51,969 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:08:52,383 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:08:52,780 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:08:53,197 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:08:53,391 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:08:53,466 - INFO - validation batch 51, loss: 4.786, 1632/6976 datapoints
2025-03-07 13:08:53,545 - INFO - validation batch 101, loss: 0.368, 3232/6976 datapoints
2025-03-07 13:08:53,630 - INFO - validation batch 151, loss: 1.311, 4832/6976 datapoints
2025-03-07 13:08:53,711 - INFO - validation batch 201, loss: 1.133, 6432/6976 datapoints
2025-03-07 13:08:53,738 - INFO - Epoch 512/800 done.
2025-03-07 13:08:53,738 - INFO - Final validation performance:
Loss: 1.521, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:08:53,739 - INFO - Beginning epoch 513/800
2025-03-07 13:08:53,752 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:08:54,198 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:08:54,690 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:08:55,184 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:08:55,617 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:08:56,121 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:08:56,622 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:08:57,097 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:08:57,611 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:08:58,126 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:08:58,606 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:08:59,011 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:08:59,475 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:09:00,006 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:09:00,542 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:09:00,978 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:09:01,470 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:09:02,062 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:09:02,319 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 13:09:02,443 - INFO - validation batch 51, loss: 4.805, 1632/6976 datapoints
2025-03-07 13:09:02,553 - INFO - validation batch 101, loss: 0.361, 3232/6976 datapoints
2025-03-07 13:09:02,664 - INFO - validation batch 151, loss: 1.320, 4832/6976 datapoints
2025-03-07 13:09:02,811 - INFO - validation batch 201, loss: 1.118, 6432/6976 datapoints
2025-03-07 13:09:02,891 - INFO - Epoch 513/800 done.
2025-03-07 13:09:02,891 - INFO - Final validation performance:
Loss: 1.522, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:09:02,892 - INFO - Beginning epoch 514/800
2025-03-07 13:09:02,905 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:09:03,464 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:09:04,047 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:09:04,506 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:09:04,996 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:09:05,496 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:09:05,960 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:09:06,382 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:09:06,774 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:09:07,200 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:09:07,626 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:09:08,108 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:09:08,561 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:09:09,024 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:09:09,502 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:09:09,964 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:09:10,452 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:09:11,012 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:09:11,226 - INFO - validation batch 1, loss: 0.009, 32/6976 datapoints
2025-03-07 13:09:11,307 - INFO - validation batch 51, loss: 4.824, 1632/6976 datapoints
2025-03-07 13:09:11,383 - INFO - validation batch 101, loss: 0.357, 3232/6976 datapoints
2025-03-07 13:09:11,465 - INFO - validation batch 151, loss: 1.333, 4832/6976 datapoints
2025-03-07 13:09:11,567 - INFO - validation batch 201, loss: 1.105, 6432/6976 datapoints
2025-03-07 13:09:11,600 - INFO - Epoch 514/800 done.
2025-03-07 13:09:11,600 - INFO - Final validation performance:
Loss: 1.526, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:09:11,601 - INFO - Beginning epoch 515/800
2025-03-07 13:09:11,614 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:09:12,092 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:09:12,625 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:09:13,186 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:09:13,999 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:09:14,501 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:09:14,960 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:09:15,364 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:09:15,746 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:09:16,132 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:09:16,533 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:09:16,943 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:09:17,388 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:09:17,815 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:09:18,240 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:09:18,639 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:09:19,108 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:09:19,570 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:09:19,825 - INFO - validation batch 1, loss: 0.012, 32/6976 datapoints
2025-03-07 13:09:19,909 - INFO - validation batch 51, loss: 4.844, 1632/6976 datapoints
2025-03-07 13:09:19,989 - INFO - validation batch 101, loss: 0.356, 3232/6976 datapoints
2025-03-07 13:09:20,072 - INFO - validation batch 151, loss: 1.350, 4832/6976 datapoints
2025-03-07 13:09:20,163 - INFO - validation batch 201, loss: 1.097, 6432/6976 datapoints
2025-03-07 13:09:20,197 - INFO - Epoch 515/800 done.
2025-03-07 13:09:20,197 - INFO - Final validation performance:
Loss: 1.532, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:09:20,198 - INFO - Beginning epoch 516/800
2025-03-07 13:09:20,208 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:09:20,678 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:09:21,128 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:09:21,600 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:09:22,073 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:09:22,670 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:09:23,199 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:09:23,700 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:09:24,125 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:09:24,611 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:09:25,158 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:09:25,620 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:09:26,095 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:09:26,604 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:09:27,161 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:09:27,888 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:09:28,448 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:09:28,897 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:09:29,135 - INFO - validation batch 1, loss: 0.015, 32/6976 datapoints
2025-03-07 13:09:29,231 - INFO - validation batch 51, loss: 4.866, 1632/6976 datapoints
2025-03-07 13:09:29,332 - INFO - validation batch 101, loss: 0.360, 3232/6976 datapoints
2025-03-07 13:09:29,427 - INFO - validation batch 151, loss: 1.373, 4832/6976 datapoints
2025-03-07 13:09:29,526 - INFO - validation batch 201, loss: 1.085, 6432/6976 datapoints
2025-03-07 13:09:29,557 - INFO - Epoch 516/800 done.
2025-03-07 13:09:29,558 - INFO - Final validation performance:
Loss: 1.540, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:09:29,558 - INFO - Beginning epoch 517/800
2025-03-07 13:09:29,569 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:09:30,112 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:09:30,621 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:09:31,058 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:09:31,538 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:09:32,111 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:09:32,701 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:09:33,191 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:09:33,614 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:09:34,067 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:09:34,533 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:09:35,148 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:09:35,712 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:09:36,237 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:09:36,699 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:09:37,128 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:09:37,533 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:09:37,911 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:09:38,105 - INFO - validation batch 1, loss: 0.020, 32/6976 datapoints
2025-03-07 13:09:38,178 - INFO - validation batch 51, loss: 4.888, 1632/6976 datapoints
2025-03-07 13:09:38,250 - INFO - validation batch 101, loss: 0.374, 3232/6976 datapoints
2025-03-07 13:09:38,324 - INFO - validation batch 151, loss: 1.399, 4832/6976 datapoints
2025-03-07 13:09:38,397 - INFO - validation batch 201, loss: 1.086, 6432/6976 datapoints
2025-03-07 13:09:38,424 - INFO - Epoch 517/800 done.
2025-03-07 13:09:38,425 - INFO - Final validation performance:
Loss: 1.553, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:09:38,425 - INFO - Beginning epoch 518/800
2025-03-07 13:09:38,434 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:09:38,864 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:09:39,303 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:09:39,703 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:09:40,112 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:09:40,544 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:09:40,967 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:09:41,351 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:09:41,722 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:09:42,122 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:09:42,533 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:09:42,942 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:09:43,347 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:09:43,754 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:09:44,187 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:09:44,700 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:09:45,098 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:09:45,487 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:09:45,687 - INFO - validation batch 1, loss: 0.022, 32/6976 datapoints
2025-03-07 13:09:45,762 - INFO - validation batch 51, loss: 4.905, 1632/6976 datapoints
2025-03-07 13:09:45,839 - INFO - validation batch 101, loss: 0.390, 3232/6976 datapoints
2025-03-07 13:09:45,917 - INFO - validation batch 151, loss: 1.433, 4832/6976 datapoints
2025-03-07 13:09:45,991 - INFO - validation batch 201, loss: 1.080, 6432/6976 datapoints
2025-03-07 13:09:46,018 - INFO - Epoch 518/800 done.
2025-03-07 13:09:46,018 - INFO - Final validation performance:
Loss: 1.566, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:09:46,019 - INFO - Beginning epoch 519/800
2025-03-07 13:09:46,028 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:09:46,439 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:09:46,882 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:09:47,327 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:09:47,824 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:09:48,241 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:09:48,659 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:09:49,044 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:09:49,406 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:09:49,801 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:09:50,198 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:09:50,582 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:09:50,976 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:09:51,371 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:09:51,768 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:09:52,184 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:09:52,638 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:09:53,109 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:09:53,327 - INFO - validation batch 1, loss: 0.024, 32/6976 datapoints
2025-03-07 13:09:53,406 - INFO - validation batch 51, loss: 4.922, 1632/6976 datapoints
2025-03-07 13:09:53,483 - INFO - validation batch 101, loss: 0.415, 3232/6976 datapoints
2025-03-07 13:09:53,564 - INFO - validation batch 151, loss: 1.454, 4832/6976 datapoints
2025-03-07 13:09:53,642 - INFO - validation batch 201, loss: 1.072, 6432/6976 datapoints
2025-03-07 13:09:53,669 - INFO - Epoch 519/800 done.
2025-03-07 13:09:53,670 - INFO - Final validation performance:
Loss: 1.577, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:09:53,671 - INFO - Beginning epoch 520/800
2025-03-07 13:09:53,681 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:09:54,100 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:09:54,557 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:09:55,029 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:09:55,436 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:09:55,870 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:09:56,284 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:09:56,672 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:09:57,050 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:09:57,478 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:09:57,963 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:09:58,481 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:09:58,913 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:09:59,361 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:09:59,827 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:10:00,320 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:10:01,129 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:10:01,875 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:10:02,099 - INFO - validation batch 1, loss: 0.027, 32/6976 datapoints
2025-03-07 13:10:02,197 - INFO - validation batch 51, loss: 4.941, 1632/6976 datapoints
2025-03-07 13:10:02,287 - INFO - validation batch 101, loss: 0.454, 3232/6976 datapoints
2025-03-07 13:10:02,393 - INFO - validation batch 151, loss: 1.505, 4832/6976 datapoints
2025-03-07 13:10:02,489 - INFO - validation batch 201, loss: 1.093, 6432/6976 datapoints
2025-03-07 13:10:02,563 - INFO - Epoch 520/800 done.
2025-03-07 13:10:02,563 - INFO - Final validation performance:
Loss: 1.604, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:10:02,564 - INFO - Beginning epoch 521/800
2025-03-07 13:10:02,573 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:10:03,082 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:10:03,515 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:10:04,083 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:10:04,749 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:10:05,229 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:10:05,763 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:10:06,183 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:10:06,574 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:10:06,973 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:10:07,404 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:10:07,843 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:10:08,248 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:10:08,691 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:10:09,166 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:10:09,733 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:10:10,230 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:10:10,664 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:10:10,894 - INFO - validation batch 1, loss: 0.027, 32/6976 datapoints
2025-03-07 13:10:10,983 - INFO - validation batch 51, loss: 4.929, 1632/6976 datapoints
2025-03-07 13:10:11,097 - INFO - validation batch 101, loss: 0.478, 3232/6976 datapoints
2025-03-07 13:10:11,204 - INFO - validation batch 151, loss: 1.528, 4832/6976 datapoints
2025-03-07 13:10:11,300 - INFO - validation batch 201, loss: 1.093, 6432/6976 datapoints
2025-03-07 13:10:11,347 - INFO - Epoch 521/800 done.
2025-03-07 13:10:11,347 - INFO - Final validation performance:
Loss: 1.611, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:10:11,348 - INFO - Beginning epoch 522/800
2025-03-07 13:10:11,358 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:10:11,915 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:10:12,431 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:10:12,938 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:10:13,567 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:10:14,094 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:10:14,631 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:10:15,083 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:10:15,506 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:10:15,942 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:10:16,377 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:10:16,785 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:10:17,206 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:10:17,675 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:10:18,104 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:10:18,552 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:10:19,010 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:10:19,432 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:10:19,647 - INFO - validation batch 1, loss: 0.023, 32/6976 datapoints
2025-03-07 13:10:19,739 - INFO - validation batch 51, loss: 4.928, 1632/6976 datapoints
2025-03-07 13:10:19,825 - INFO - validation batch 101, loss: 0.497, 3232/6976 datapoints
2025-03-07 13:10:19,901 - INFO - validation batch 151, loss: 1.521, 4832/6976 datapoints
2025-03-07 13:10:19,977 - INFO - validation batch 201, loss: 1.075, 6432/6976 datapoints
2025-03-07 13:10:20,004 - INFO - Epoch 522/800 done.
2025-03-07 13:10:20,004 - INFO - Final validation performance:
Loss: 1.609, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:10:20,006 - INFO - Beginning epoch 523/800
2025-03-07 13:10:20,017 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:10:20,493 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:10:20,946 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:10:21,438 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:10:21,997 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:10:22,541 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:10:23,091 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:10:23,592 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:10:24,039 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:10:24,491 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:10:24,996 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:10:25,540 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:10:26,057 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:10:26,571 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:10:27,070 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:10:27,544 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:10:27,975 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:10:28,367 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:10:28,563 - INFO - validation batch 1, loss: 0.022, 32/6976 datapoints
2025-03-07 13:10:28,641 - INFO - validation batch 51, loss: 4.871, 1632/6976 datapoints
2025-03-07 13:10:28,714 - INFO - validation batch 101, loss: 0.503, 3232/6976 datapoints
2025-03-07 13:10:28,798 - INFO - validation batch 151, loss: 1.543, 4832/6976 datapoints
2025-03-07 13:10:28,889 - INFO - validation batch 201, loss: 1.087, 6432/6976 datapoints
2025-03-07 13:10:28,922 - INFO - Epoch 523/800 done.
2025-03-07 13:10:28,922 - INFO - Final validation performance:
Loss: 1.605, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:10:28,923 - INFO - Beginning epoch 524/800
2025-03-07 13:10:28,935 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:10:29,343 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:10:29,824 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:10:30,225 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:10:30,684 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:10:31,102 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:10:31,555 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:10:31,990 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:10:32,372 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:10:32,781 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:10:33,182 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:10:33,714 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:10:34,140 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:10:34,556 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:10:34,984 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:10:35,385 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:10:35,785 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:10:36,166 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:10:36,357 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 13:10:36,430 - INFO - validation batch 51, loss: 4.815, 1632/6976 datapoints
2025-03-07 13:10:36,510 - INFO - validation batch 101, loss: 0.512, 3232/6976 datapoints
2025-03-07 13:10:36,585 - INFO - validation batch 151, loss: 1.564, 4832/6976 datapoints
2025-03-07 13:10:36,660 - INFO - validation batch 201, loss: 1.038, 6432/6976 datapoints
2025-03-07 13:10:36,686 - INFO - Epoch 524/800 done.
2025-03-07 13:10:36,686 - INFO - Final validation performance:
Loss: 1.588, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:10:36,686 - INFO - Beginning epoch 525/800
2025-03-07 13:10:36,698 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:10:37,103 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:10:37,523 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:10:37,935 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:10:38,363 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:10:38,827 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:10:39,255 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:10:39,665 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:10:40,061 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:10:40,446 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:10:40,839 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:10:41,247 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:10:41,657 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:10:42,058 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:10:42,471 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:10:42,857 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:10:43,236 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:10:43,628 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:10:43,830 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:10:43,901 - INFO - validation batch 51, loss: 5.718, 1632/6976 datapoints
2025-03-07 13:10:43,972 - INFO - validation batch 101, loss: 1.095, 3232/6976 datapoints
2025-03-07 13:10:44,045 - INFO - validation batch 151, loss: 1.949, 4832/6976 datapoints
2025-03-07 13:10:44,116 - INFO - validation batch 201, loss: 1.963, 6432/6976 datapoints
2025-03-07 13:10:44,146 - INFO - Epoch 525/800 done.
2025-03-07 13:10:44,146 - INFO - Final validation performance:
Loss: 2.145, top-1 acc: 0.891top-5 acc: 0.891
2025-03-07 13:10:44,146 - INFO - Beginning epoch 526/800
2025-03-07 13:10:44,155 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:10:44,551 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:10:45,047 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:10:45,555 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:10:46,009 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:10:46,456 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:10:46,904 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:10:47,312 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:10:47,690 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:10:48,095 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:10:48,506 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:10:48,900 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:10:49,332 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:10:49,762 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:10:50,193 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:10:50,673 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:10:51,070 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:10:51,473 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:10:51,785 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:10:51,931 - INFO - validation batch 51, loss: 5.563, 1632/6976 datapoints
2025-03-07 13:10:52,146 - INFO - validation batch 101, loss: 0.385, 3232/6976 datapoints
2025-03-07 13:10:52,261 - INFO - validation batch 151, loss: 1.351, 4832/6976 datapoints
2025-03-07 13:10:52,353 - INFO - validation batch 201, loss: 1.220, 6432/6976 datapoints
2025-03-07 13:10:52,393 - INFO - Epoch 526/800 done.
2025-03-07 13:10:52,393 - INFO - Final validation performance:
Loss: 1.704, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:10:52,394 - INFO - Beginning epoch 527/800
2025-03-07 13:10:52,405 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:10:52,952 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:10:53,451 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:10:53,919 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:10:54,365 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:10:54,820 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:10:55,257 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:10:55,693 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:10:56,071 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:10:56,468 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:10:56,948 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:10:57,379 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:10:57,851 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:10:58,296 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:10:58,724 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:10:59,253 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:10:59,912 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:11:00,403 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:11:00,654 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:11:00,740 - INFO - validation batch 51, loss: 5.533, 1632/6976 datapoints
2025-03-07 13:11:00,826 - INFO - validation batch 101, loss: 0.368, 3232/6976 datapoints
2025-03-07 13:11:00,913 - INFO - validation batch 151, loss: 1.350, 4832/6976 datapoints
2025-03-07 13:11:01,003 - INFO - validation batch 201, loss: 1.187, 6432/6976 datapoints
2025-03-07 13:11:01,032 - INFO - Epoch 527/800 done.
2025-03-07 13:11:01,032 - INFO - Final validation performance:
Loss: 1.688, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:11:01,033 - INFO - Beginning epoch 528/800
2025-03-07 13:11:01,043 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:11:01,505 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:11:02,028 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:11:02,596 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:11:03,058 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:11:03,615 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:11:04,207 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:11:04,682 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:11:05,135 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:11:05,619 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:11:06,142 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:11:06,632 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:11:07,127 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:11:07,678 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:11:08,228 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:11:08,759 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:11:09,274 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:11:09,784 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:11:10,037 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:11:10,131 - INFO - validation batch 51, loss: 5.510, 1632/6976 datapoints
2025-03-07 13:11:10,231 - INFO - validation batch 101, loss: 0.358, 3232/6976 datapoints
2025-03-07 13:11:10,309 - INFO - validation batch 151, loss: 1.351, 4832/6976 datapoints
2025-03-07 13:11:10,386 - INFO - validation batch 201, loss: 1.165, 6432/6976 datapoints
2025-03-07 13:11:10,412 - INFO - Epoch 528/800 done.
2025-03-07 13:11:10,412 - INFO - Final validation performance:
Loss: 1.677, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:11:10,412 - INFO - Beginning epoch 529/800
2025-03-07 13:11:10,424 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:11:10,865 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:11:11,360 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:11:11,834 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:11:12,282 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:11:12,798 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:11:13,286 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:11:13,810 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:11:14,219 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:11:14,679 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:11:15,144 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:11:15,562 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:11:16,033 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:11:16,498 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:11:17,039 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:11:17,535 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:11:18,006 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:11:18,453 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:11:18,680 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:11:18,776 - INFO - validation batch 51, loss: 5.494, 1632/6976 datapoints
2025-03-07 13:11:18,872 - INFO - validation batch 101, loss: 0.353, 3232/6976 datapoints
2025-03-07 13:11:18,961 - INFO - validation batch 151, loss: 1.354, 4832/6976 datapoints
2025-03-07 13:11:19,051 - INFO - validation batch 201, loss: 1.150, 6432/6976 datapoints
2025-03-07 13:11:19,089 - INFO - Epoch 529/800 done.
2025-03-07 13:11:19,090 - INFO - Final validation performance:
Loss: 1.670, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:11:19,090 - INFO - Beginning epoch 530/800
2025-03-07 13:11:19,100 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:11:19,863 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:11:20,339 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:11:20,800 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:11:21,265 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:11:21,741 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:11:22,238 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:11:22,698 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:11:23,121 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:11:23,547 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:11:24,018 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:11:24,428 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:11:24,856 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:11:25,291 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:11:25,769 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:11:26,212 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:11:26,653 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:11:27,087 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:11:27,315 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:11:27,431 - INFO - validation batch 51, loss: 5.481, 1632/6976 datapoints
2025-03-07 13:11:27,558 - INFO - validation batch 101, loss: 0.350, 3232/6976 datapoints
2025-03-07 13:11:27,671 - INFO - validation batch 151, loss: 1.357, 4832/6976 datapoints
2025-03-07 13:11:27,783 - INFO - validation batch 201, loss: 1.140, 6432/6976 datapoints
2025-03-07 13:11:27,810 - INFO - Epoch 530/800 done.
2025-03-07 13:11:27,811 - INFO - Final validation performance:
Loss: 1.666, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:11:27,811 - INFO - Beginning epoch 531/800
2025-03-07 13:11:27,826 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:11:28,306 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:11:28,806 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:11:29,275 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:11:29,757 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:11:30,342 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:11:31,161 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:11:31,670 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:11:32,110 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:11:32,538 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:11:33,011 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:11:33,489 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:11:33,961 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:11:34,494 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:11:35,026 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:11:35,589 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:11:36,121 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:11:36,576 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:11:36,782 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:11:36,861 - INFO - validation batch 51, loss: 5.470, 1632/6976 datapoints
2025-03-07 13:11:36,943 - INFO - validation batch 101, loss: 0.346, 3232/6976 datapoints
2025-03-07 13:11:37,026 - INFO - validation batch 151, loss: 1.360, 4832/6976 datapoints
2025-03-07 13:11:37,116 - INFO - validation batch 201, loss: 1.135, 6432/6976 datapoints
2025-03-07 13:11:37,153 - INFO - Epoch 531/800 done.
2025-03-07 13:11:37,153 - INFO - Final validation performance:
Loss: 1.662, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:11:37,155 - INFO - Beginning epoch 532/800
2025-03-07 13:11:37,167 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:11:37,754 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:11:38,261 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:11:38,713 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:11:39,253 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:11:39,830 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:11:40,624 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:11:41,289 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:11:41,826 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:11:42,329 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:11:43,503 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:11:44,092 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:11:44,632 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:11:45,074 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:11:45,489 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:11:46,004 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:11:46,476 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:11:46,912 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:11:47,125 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:11:47,200 - INFO - validation batch 51, loss: 5.457, 1632/6976 datapoints
2025-03-07 13:11:47,282 - INFO - validation batch 101, loss: 0.342, 3232/6976 datapoints
2025-03-07 13:11:47,417 - INFO - validation batch 151, loss: 1.363, 4832/6976 datapoints
2025-03-07 13:11:47,557 - INFO - validation batch 201, loss: 1.131, 6432/6976 datapoints
2025-03-07 13:11:47,602 - INFO - Epoch 532/800 done.
2025-03-07 13:11:47,602 - INFO - Final validation performance:
Loss: 1.659, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:11:47,603 - INFO - Beginning epoch 533/800
2025-03-07 13:11:47,682 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:11:48,400 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:11:48,849 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:11:49,274 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:11:49,715 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:11:50,232 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:11:50,829 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:11:51,307 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:11:51,709 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:11:52,166 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:11:52,638 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:11:53,100 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:11:53,521 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:11:53,950 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:11:54,386 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:11:54,829 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:11:55,288 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:11:55,719 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:11:55,981 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:11:56,075 - INFO - validation batch 51, loss: 5.444, 1632/6976 datapoints
2025-03-07 13:11:56,191 - INFO - validation batch 101, loss: 0.338, 3232/6976 datapoints
2025-03-07 13:11:56,289 - INFO - validation batch 151, loss: 1.364, 4832/6976 datapoints
2025-03-07 13:11:56,388 - INFO - validation batch 201, loss: 1.128, 6432/6976 datapoints
2025-03-07 13:11:56,418 - INFO - Epoch 533/800 done.
2025-03-07 13:11:56,419 - INFO - Final validation performance:
Loss: 1.655, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:11:56,420 - INFO - Beginning epoch 534/800
2025-03-07 13:11:56,436 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:11:56,944 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:11:57,441 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:11:58,112 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:11:58,737 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:11:59,401 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:12:00,160 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:12:00,707 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:12:01,193 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:12:01,654 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:12:02,171 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:12:02,678 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:12:03,129 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:12:03,633 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:12:04,133 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:12:04,633 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:12:05,068 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:12:05,519 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:12:05,744 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:12:05,841 - INFO - validation batch 51, loss: 5.429, 1632/6976 datapoints
2025-03-07 13:12:05,929 - INFO - validation batch 101, loss: 0.333, 3232/6976 datapoints
2025-03-07 13:12:06,046 - INFO - validation batch 151, loss: 1.365, 4832/6976 datapoints
2025-03-07 13:12:06,135 - INFO - validation batch 201, loss: 1.126, 6432/6976 datapoints
2025-03-07 13:12:06,167 - INFO - Epoch 534/800 done.
2025-03-07 13:12:06,168 - INFO - Final validation performance:
Loss: 1.651, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:12:06,169 - INFO - Beginning epoch 535/800
2025-03-07 13:12:06,181 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:12:06,765 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:12:07,622 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:12:08,288 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:12:08,876 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:12:09,382 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:12:09,870 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:12:10,307 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:12:10,714 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:12:11,160 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:12:11,580 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:12:11,969 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:12:12,367 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:12:12,786 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:12:13,205 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:12:13,631 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:12:14,034 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:12:14,418 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:12:14,633 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:12:14,711 - INFO - validation batch 51, loss: 5.413, 1632/6976 datapoints
2025-03-07 13:12:14,784 - INFO - validation batch 101, loss: 0.329, 3232/6976 datapoints
2025-03-07 13:12:14,859 - INFO - validation batch 151, loss: 1.363, 4832/6976 datapoints
2025-03-07 13:12:14,933 - INFO - validation batch 201, loss: 1.125, 6432/6976 datapoints
2025-03-07 13:12:14,956 - INFO - Epoch 535/800 done.
2025-03-07 13:12:14,956 - INFO - Final validation performance:
Loss: 1.646, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:12:14,958 - INFO - Beginning epoch 536/800
2025-03-07 13:12:14,968 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:12:15,384 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:12:15,800 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:12:16,224 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:12:16,625 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:12:17,044 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:12:17,470 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:12:17,871 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:12:18,251 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:12:18,644 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:12:19,050 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:12:19,445 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:12:19,844 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:12:20,250 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:12:20,651 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:12:21,123 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:12:21,546 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:12:21,972 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:12:22,167 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:12:22,246 - INFO - validation batch 51, loss: 5.396, 1632/6976 datapoints
2025-03-07 13:12:22,327 - INFO - validation batch 101, loss: 0.325, 3232/6976 datapoints
2025-03-07 13:12:22,409 - INFO - validation batch 151, loss: 1.362, 4832/6976 datapoints
2025-03-07 13:12:22,492 - INFO - validation batch 201, loss: 1.125, 6432/6976 datapoints
2025-03-07 13:12:22,528 - INFO - Epoch 536/800 done.
2025-03-07 13:12:22,537 - INFO - Final validation performance:
Loss: 1.642, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:12:22,557 - INFO - Beginning epoch 537/800
2025-03-07 13:12:22,567 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:12:22,999 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:12:23,472 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:12:23,901 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:12:24,331 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:12:24,781 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:12:25,230 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:12:25,644 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:12:26,028 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:12:26,409 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:12:26,814 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:12:27,206 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:12:27,615 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:12:28,031 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:12:28,439 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:12:28,846 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:12:29,239 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:12:29,630 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:12:29,825 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:12:29,902 - INFO - validation batch 51, loss: 5.378, 1632/6976 datapoints
2025-03-07 13:12:30,000 - INFO - validation batch 101, loss: 0.322, 3232/6976 datapoints
2025-03-07 13:12:30,126 - INFO - validation batch 151, loss: 1.361, 4832/6976 datapoints
2025-03-07 13:12:30,306 - INFO - validation batch 201, loss: 1.127, 6432/6976 datapoints
2025-03-07 13:12:30,367 - INFO - Epoch 537/800 done.
2025-03-07 13:12:30,368 - INFO - Final validation performance:
Loss: 1.638, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:12:30,369 - INFO - Beginning epoch 538/800
2025-03-07 13:12:30,389 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:12:31,057 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:12:31,565 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:12:32,050 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:12:32,522 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:12:32,974 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:12:33,460 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:12:33,893 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:12:34,411 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:12:34,842 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:12:35,258 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:12:35,697 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:12:36,111 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:12:36,536 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:12:36,938 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:12:37,380 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:12:37,815 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:12:38,230 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:12:38,429 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:12:38,509 - INFO - validation batch 51, loss: 5.359, 1632/6976 datapoints
2025-03-07 13:12:38,587 - INFO - validation batch 101, loss: 0.319, 3232/6976 datapoints
2025-03-07 13:12:38,672 - INFO - validation batch 151, loss: 1.360, 4832/6976 datapoints
2025-03-07 13:12:38,759 - INFO - validation batch 201, loss: 1.130, 6432/6976 datapoints
2025-03-07 13:12:38,792 - INFO - Epoch 538/800 done.
2025-03-07 13:12:38,793 - INFO - Final validation performance:
Loss: 1.634, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:12:38,793 - INFO - Beginning epoch 539/800
2025-03-07 13:12:38,804 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:12:39,249 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:12:39,680 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:12:40,132 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:12:40,605 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:12:41,049 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:12:41,522 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:12:41,921 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:12:42,297 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:12:42,686 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:12:43,088 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:12:43,486 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:12:43,963 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:12:44,450 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:12:45,178 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:12:45,603 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:12:46,016 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:12:46,452 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:12:46,658 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:12:46,743 - INFO - validation batch 51, loss: 5.338, 1632/6976 datapoints
2025-03-07 13:12:46,826 - INFO - validation batch 101, loss: 0.314, 3232/6976 datapoints
2025-03-07 13:12:46,912 - INFO - validation batch 151, loss: 1.360, 4832/6976 datapoints
2025-03-07 13:12:46,986 - INFO - validation batch 201, loss: 1.133, 6432/6976 datapoints
2025-03-07 13:12:47,011 - INFO - Epoch 539/800 done.
2025-03-07 13:12:47,011 - INFO - Final validation performance:
Loss: 1.630, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:12:47,012 - INFO - Beginning epoch 540/800
2025-03-07 13:12:47,023 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:12:47,464 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:12:47,962 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:12:48,465 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:12:48,936 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:12:49,433 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:12:49,961 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:12:50,384 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:12:50,812 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:12:51,239 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:12:51,711 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:12:52,146 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:12:52,612 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:12:53,095 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:12:53,568 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:12:54,022 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:12:54,482 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:12:54,914 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:12:55,157 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:12:55,241 - INFO - validation batch 51, loss: 5.316, 1632/6976 datapoints
2025-03-07 13:12:55,325 - INFO - validation batch 101, loss: 0.309, 3232/6976 datapoints
2025-03-07 13:12:55,408 - INFO - validation batch 151, loss: 1.362, 4832/6976 datapoints
2025-03-07 13:12:55,489 - INFO - validation batch 201, loss: 1.139, 6432/6976 datapoints
2025-03-07 13:12:55,525 - INFO - Epoch 540/800 done.
2025-03-07 13:12:55,526 - INFO - Final validation performance:
Loss: 1.626, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:12:55,527 - INFO - Beginning epoch 541/800
2025-03-07 13:12:55,543 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:12:56,054 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:12:56,523 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:12:56,952 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:12:57,416 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:12:57,899 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:12:58,435 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:12:58,875 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:12:59,275 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:12:59,708 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:13:00,162 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:13:00,587 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:13:01,045 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:13:01,671 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:13:02,290 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:13:02,872 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:13:03,432 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:13:03,928 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:13:04,179 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:13:04,280 - INFO - validation batch 51, loss: 5.292, 1632/6976 datapoints
2025-03-07 13:13:04,368 - INFO - validation batch 101, loss: 0.303, 3232/6976 datapoints
2025-03-07 13:13:04,461 - INFO - validation batch 151, loss: 1.367, 4832/6976 datapoints
2025-03-07 13:13:04,558 - INFO - validation batch 201, loss: 1.146, 6432/6976 datapoints
2025-03-07 13:13:04,589 - INFO - Epoch 541/800 done.
2025-03-07 13:13:04,589 - INFO - Final validation performance:
Loss: 1.622, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:13:04,590 - INFO - Beginning epoch 542/800
2025-03-07 13:13:04,602 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:13:05,084 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:13:05,867 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:13:06,534 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:13:07,095 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:13:07,646 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:13:08,201 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:13:08,688 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:13:09,119 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:13:09,624 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:13:10,073 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:13:10,561 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:13:11,007 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:13:11,450 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:13:11,874 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:13:12,281 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:13:12,714 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:13:13,097 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:13:13,287 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:13:13,362 - INFO - validation batch 51, loss: 5.268, 1632/6976 datapoints
2025-03-07 13:13:13,450 - INFO - validation batch 101, loss: 0.297, 3232/6976 datapoints
2025-03-07 13:13:13,558 - INFO - validation batch 151, loss: 1.373, 4832/6976 datapoints
2025-03-07 13:13:13,659 - INFO - validation batch 201, loss: 1.155, 6432/6976 datapoints
2025-03-07 13:13:13,687 - INFO - Epoch 542/800 done.
2025-03-07 13:13:13,688 - INFO - Final validation performance:
Loss: 1.619, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:13:13,688 - INFO - Beginning epoch 543/800
2025-03-07 13:13:13,699 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:13:14,107 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:13:14,527 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:13:14,913 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:13:15,333 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:13:15,811 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:13:16,282 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:13:16,799 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:13:17,170 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:13:17,571 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:13:17,990 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:13:18,381 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:13:18,783 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:13:19,210 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:13:19,635 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:13:20,041 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:13:20,448 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:13:20,849 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:13:21,043 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:13:21,146 - INFO - validation batch 51, loss: 5.240, 1632/6976 datapoints
2025-03-07 13:13:21,220 - INFO - validation batch 101, loss: 0.290, 3232/6976 datapoints
2025-03-07 13:13:21,291 - INFO - validation batch 151, loss: 1.383, 4832/6976 datapoints
2025-03-07 13:13:21,379 - INFO - validation batch 201, loss: 1.166, 6432/6976 datapoints
2025-03-07 13:13:21,412 - INFO - Epoch 543/800 done.
2025-03-07 13:13:21,412 - INFO - Final validation performance:
Loss: 1.617, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:13:21,413 - INFO - Beginning epoch 544/800
2025-03-07 13:13:21,424 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:13:21,912 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:13:22,453 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:13:23,015 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:13:23,574 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:13:24,114 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:13:24,651 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:13:25,108 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:13:25,561 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:13:26,020 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:13:26,473 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:13:26,924 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:13:27,378 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:13:27,902 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:13:28,424 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:13:29,149 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:13:30,137 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:13:30,659 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:13:30,966 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 13:13:31,082 - INFO - validation batch 51, loss: 5.212, 1632/6976 datapoints
2025-03-07 13:13:31,203 - INFO - validation batch 101, loss: 0.285, 3232/6976 datapoints
2025-03-07 13:13:31,355 - INFO - validation batch 151, loss: 1.396, 4832/6976 datapoints
2025-03-07 13:13:31,456 - INFO - validation batch 201, loss: 1.178, 6432/6976 datapoints
2025-03-07 13:13:31,510 - INFO - Epoch 544/800 done.
2025-03-07 13:13:31,511 - INFO - Final validation performance:
Loss: 1.615, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:13:31,511 - INFO - Beginning epoch 545/800
2025-03-07 13:13:31,526 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:13:31,990 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:13:32,487 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:13:32,941 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:13:33,402 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:13:33,896 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:13:34,380 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:13:34,828 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:13:35,223 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:13:35,753 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:13:36,244 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:13:36,685 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:13:37,137 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:13:37,609 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:13:38,095 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:13:38,558 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:13:39,018 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:13:39,490 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:13:39,744 - INFO - validation batch 1, loss: 0.007, 32/6976 datapoints
2025-03-07 13:13:39,844 - INFO - validation batch 51, loss: 5.186, 1632/6976 datapoints
2025-03-07 13:13:39,950 - INFO - validation batch 101, loss: 0.281, 3232/6976 datapoints
2025-03-07 13:13:40,088 - INFO - validation batch 151, loss: 1.414, 4832/6976 datapoints
2025-03-07 13:13:40,207 - INFO - validation batch 201, loss: 1.191, 6432/6976 datapoints
2025-03-07 13:13:40,246 - INFO - Epoch 545/800 done.
2025-03-07 13:13:40,246 - INFO - Final validation performance:
Loss: 1.616, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:13:40,247 - INFO - Beginning epoch 546/800
2025-03-07 13:13:40,260 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:13:41,147 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:13:41,854 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:13:42,390 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:13:42,934 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:13:43,489 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:13:44,029 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:13:44,539 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:13:44,936 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:13:45,345 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:13:45,785 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:13:46,196 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:13:46,635 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:13:47,139 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:13:47,610 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:13:48,040 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:13:48,500 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:13:49,020 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:13:49,253 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 13:13:49,333 - INFO - validation batch 51, loss: 5.165, 1632/6976 datapoints
2025-03-07 13:13:49,413 - INFO - validation batch 101, loss: 0.284, 3232/6976 datapoints
2025-03-07 13:13:49,516 - INFO - validation batch 151, loss: 1.437, 4832/6976 datapoints
2025-03-07 13:13:49,617 - INFO - validation batch 201, loss: 1.208, 6432/6976 datapoints
2025-03-07 13:13:49,655 - INFO - Epoch 546/800 done.
2025-03-07 13:13:49,655 - INFO - Final validation performance:
Loss: 1.621, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:13:49,656 - INFO - Beginning epoch 547/800
2025-03-07 13:13:49,667 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:13:50,180 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:13:50,674 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:13:51,129 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:13:51,606 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:13:52,102 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:13:52,579 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:13:52,979 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:13:53,405 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:13:53,810 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:13:54,243 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:13:54,731 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:13:55,283 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:13:55,752 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:13:56,215 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:13:56,680 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:13:57,165 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:13:57,687 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:13:57,948 - INFO - validation batch 1, loss: 0.012, 32/6976 datapoints
2025-03-07 13:13:58,088 - INFO - validation batch 51, loss: 5.143, 1632/6976 datapoints
2025-03-07 13:13:58,200 - INFO - validation batch 101, loss: 0.292, 3232/6976 datapoints
2025-03-07 13:13:58,301 - INFO - validation batch 151, loss: 1.458, 4832/6976 datapoints
2025-03-07 13:13:58,404 - INFO - validation batch 201, loss: 1.212, 6432/6976 datapoints
2025-03-07 13:13:58,446 - INFO - Epoch 547/800 done.
2025-03-07 13:13:58,447 - INFO - Final validation performance:
Loss: 1.623, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:13:58,447 - INFO - Beginning epoch 548/800
2025-03-07 13:13:58,459 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:13:58,994 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:13:59,448 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:13:59,946 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:14:00,421 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:14:00,954 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:14:01,446 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:14:01,879 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:14:02,270 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:14:02,717 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:14:03,162 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:14:03,594 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:14:04,029 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:14:04,472 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:14:04,904 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:14:05,320 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:14:05,764 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:14:06,234 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:14:06,444 - INFO - validation batch 1, loss: 0.016, 32/6976 datapoints
2025-03-07 13:14:06,525 - INFO - validation batch 51, loss: 5.128, 1632/6976 datapoints
2025-03-07 13:14:06,601 - INFO - validation batch 101, loss: 0.308, 3232/6976 datapoints
2025-03-07 13:14:06,675 - INFO - validation batch 151, loss: 1.484, 4832/6976 datapoints
2025-03-07 13:14:06,753 - INFO - validation batch 201, loss: 1.221, 6432/6976 datapoints
2025-03-07 13:14:06,781 - INFO - Epoch 548/800 done.
2025-03-07 13:14:06,781 - INFO - Final validation performance:
Loss: 1.631, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:14:06,782 - INFO - Beginning epoch 549/800
2025-03-07 13:14:06,791 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:14:07,256 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:14:07,715 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:14:08,150 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:14:08,631 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:14:09,126 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:14:09,606 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:14:10,044 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:14:10,455 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:14:10,945 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:14:11,544 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:14:12,359 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:14:12,906 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:14:13,426 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:14:13,931 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:14:14,423 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:14:15,004 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:14:15,661 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:14:16,284 - INFO - validation batch 1, loss: 0.018, 32/6976 datapoints
2025-03-07 13:14:16,403 - INFO - validation batch 51, loss: 5.112, 1632/6976 datapoints
2025-03-07 13:14:16,489 - INFO - validation batch 101, loss: 0.331, 3232/6976 datapoints
2025-03-07 13:14:16,600 - INFO - validation batch 151, loss: 1.519, 4832/6976 datapoints
2025-03-07 13:14:16,694 - INFO - validation batch 201, loss: 1.221, 6432/6976 datapoints
2025-03-07 13:14:16,729 - INFO - Epoch 549/800 done.
2025-03-07 13:14:16,730 - INFO - Final validation performance:
Loss: 1.640, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:14:16,730 - INFO - Beginning epoch 550/800
2025-03-07 13:14:16,741 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:14:17,226 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:14:17,800 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:14:18,564 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:14:19,232 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:14:19,948 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:14:20,424 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:14:20,997 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:14:21,821 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:14:22,265 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:14:22,736 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:14:23,196 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:14:23,629 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:14:24,072 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:14:24,564 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:14:25,020 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:14:25,496 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:14:25,921 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:14:26,162 - INFO - validation batch 1, loss: 0.020, 32/6976 datapoints
2025-03-07 13:14:26,264 - INFO - validation batch 51, loss: 5.088, 1632/6976 datapoints
2025-03-07 13:14:26,355 - INFO - validation batch 101, loss: 0.358, 3232/6976 datapoints
2025-03-07 13:14:26,433 - INFO - validation batch 151, loss: 1.529, 4832/6976 datapoints
2025-03-07 13:14:26,512 - INFO - validation batch 201, loss: 1.208, 6432/6976 datapoints
2025-03-07 13:14:26,541 - INFO - Epoch 550/800 done.
2025-03-07 13:14:26,541 - INFO - Final validation performance:
Loss: 1.641, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:14:26,542 - INFO - Beginning epoch 551/800
2025-03-07 13:14:26,554 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:14:27,008 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:14:27,445 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:14:27,899 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:14:28,363 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:14:28,949 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:14:29,479 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:14:29,975 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:14:30,360 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:14:30,894 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:14:31,332 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:14:31,769 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:14:32,199 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:14:32,621 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:14:33,037 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:14:33,439 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:14:33,847 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:14:34,237 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:14:34,440 - INFO - validation batch 1, loss: 0.023, 32/6976 datapoints
2025-03-07 13:14:34,528 - INFO - validation batch 51, loss: 5.047, 1632/6976 datapoints
2025-03-07 13:14:34,604 - INFO - validation batch 101, loss: 0.365, 3232/6976 datapoints
2025-03-07 13:14:34,678 - INFO - validation batch 151, loss: 1.534, 4832/6976 datapoints
2025-03-07 13:14:34,751 - INFO - validation batch 201, loss: 1.197, 6432/6976 datapoints
2025-03-07 13:14:34,779 - INFO - Epoch 551/800 done.
2025-03-07 13:14:34,780 - INFO - Final validation performance:
Loss: 1.633, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:14:34,781 - INFO - Beginning epoch 552/800
2025-03-07 13:14:34,791 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:14:35,228 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:14:35,650 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:14:36,059 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:14:36,487 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:14:36,915 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:14:37,342 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:14:37,755 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:14:38,120 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:14:38,502 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:14:38,903 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:14:39,287 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:14:39,684 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:14:40,083 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:14:40,696 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:14:41,108 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:14:41,511 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:14:41,905 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:14:42,094 - INFO - validation batch 1, loss: 0.017, 32/6976 datapoints
2025-03-07 13:14:42,166 - INFO - validation batch 51, loss: 4.996, 1632/6976 datapoints
2025-03-07 13:14:42,241 - INFO - validation batch 101, loss: 0.406, 3232/6976 datapoints
2025-03-07 13:14:42,316 - INFO - validation batch 151, loss: 1.556, 4832/6976 datapoints
2025-03-07 13:14:42,388 - INFO - validation batch 201, loss: 1.162, 6432/6976 datapoints
2025-03-07 13:14:42,411 - INFO - Epoch 552/800 done.
2025-03-07 13:14:42,411 - INFO - Final validation performance:
Loss: 1.627, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:14:42,412 - INFO - Beginning epoch 553/800
2025-03-07 13:14:42,422 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:14:42,837 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:14:43,260 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:14:43,670 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:14:44,075 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:14:44,496 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:14:44,928 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:14:45,317 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:14:45,724 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:14:46,172 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:14:46,664 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:14:47,087 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:14:47,546 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:14:48,026 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:14:48,454 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:14:48,856 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:14:49,253 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:14:49,645 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:14:49,835 - INFO - validation batch 1, loss: 0.017, 32/6976 datapoints
2025-03-07 13:14:49,908 - INFO - validation batch 51, loss: 4.971, 1632/6976 datapoints
2025-03-07 13:14:49,980 - INFO - validation batch 101, loss: 0.454, 3232/6976 datapoints
2025-03-07 13:14:50,070 - INFO - validation batch 151, loss: 1.565, 4832/6976 datapoints
2025-03-07 13:14:50,169 - INFO - validation batch 201, loss: 1.150, 6432/6976 datapoints
2025-03-07 13:14:50,203 - INFO - Epoch 553/800 done.
2025-03-07 13:14:50,203 - INFO - Final validation performance:
Loss: 1.631, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:14:50,204 - INFO - Beginning epoch 554/800
2025-03-07 13:14:50,216 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:14:50,636 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:14:51,160 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:14:51,761 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:14:52,336 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:14:52,848 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:14:53,331 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:14:53,762 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:14:54,150 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:14:54,554 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:14:54,948 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:14:55,333 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:14:55,794 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:14:56,212 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:14:56,642 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:14:57,044 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:14:57,447 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:14:57,842 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:14:58,037 - INFO - validation batch 1, loss: 0.009, 32/6976 datapoints
2025-03-07 13:14:58,147 - INFO - validation batch 51, loss: 4.900, 1632/6976 datapoints
2025-03-07 13:14:58,232 - INFO - validation batch 101, loss: 0.532, 3232/6976 datapoints
2025-03-07 13:14:58,306 - INFO - validation batch 151, loss: 1.597, 4832/6976 datapoints
2025-03-07 13:14:58,383 - INFO - validation batch 201, loss: 1.145, 6432/6976 datapoints
2025-03-07 13:14:58,406 - INFO - Epoch 554/800 done.
2025-03-07 13:14:58,407 - INFO - Final validation performance:
Loss: 1.637, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:14:58,407 - INFO - Beginning epoch 555/800
2025-03-07 13:14:58,418 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:14:58,845 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:14:59,255 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:14:59,658 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:15:00,046 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-07 13:15:00,551 - INFO - training batch 251, loss: 0.001, 8032/28000 datapoints
2025-03-07 13:15:01,014 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:15:01,465 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:15:01,867 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:15:02,299 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:15:02,714 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:15:03,118 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:15:03,532 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:15:03,945 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:15:04,356 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:15:04,758 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 13:15:05,159 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:15:05,560 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:15:05,752 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:15:05,825 - INFO - validation batch 51, loss: 5.344, 1632/6976 datapoints
2025-03-07 13:15:05,902 - INFO - validation batch 101, loss: 0.496, 3232/6976 datapoints
2025-03-07 13:15:05,978 - INFO - validation batch 151, loss: 1.415, 4832/6976 datapoints
2025-03-07 13:15:06,052 - INFO - validation batch 201, loss: 1.368, 6432/6976 datapoints
2025-03-07 13:15:06,078 - INFO - Epoch 555/800 done.
2025-03-07 13:15:06,079 - INFO - Final validation performance:
Loss: 1.725, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:15:06,080 - INFO - Beginning epoch 556/800
2025-03-07 13:15:06,090 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:15:06,493 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:15:06,955 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:15:07,379 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:15:07,810 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:15:08,245 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:15:08,675 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:15:09,082 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:15:09,458 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:15:09,857 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:15:10,266 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:15:10,654 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:15:11,061 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:15:11,469 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:15:11,879 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:15:12,364 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:15:12,886 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:15:13,708 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:15:14,035 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:15:14,136 - INFO - validation batch 51, loss: 5.333, 1632/6976 datapoints
2025-03-07 13:15:14,261 - INFO - validation batch 101, loss: 0.480, 3232/6976 datapoints
2025-03-07 13:15:14,391 - INFO - validation batch 151, loss: 1.408, 4832/6976 datapoints
2025-03-07 13:15:14,552 - INFO - validation batch 201, loss: 1.365, 6432/6976 datapoints
2025-03-07 13:15:14,610 - INFO - Epoch 556/800 done.
2025-03-07 13:15:14,612 - INFO - Final validation performance:
Loss: 1.717, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:15:14,614 - INFO - Beginning epoch 557/800
2025-03-07 13:15:14,633 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:15:15,210 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:15:15,693 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:15:16,177 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:15:16,651 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:15:17,128 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:15:17,638 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:15:18,190 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:15:18,603 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:15:19,041 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:15:19,478 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:15:19,932 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:15:20,376 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:15:20,822 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:15:21,303 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:15:21,787 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:15:22,232 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:15:22,636 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:15:22,832 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:15:22,907 - INFO - validation batch 51, loss: 5.311, 1632/6976 datapoints
2025-03-07 13:15:22,986 - INFO - validation batch 101, loss: 0.464, 3232/6976 datapoints
2025-03-07 13:15:23,070 - INFO - validation batch 151, loss: 1.411, 4832/6976 datapoints
2025-03-07 13:15:23,148 - INFO - validation batch 201, loss: 1.372, 6432/6976 datapoints
2025-03-07 13:15:23,174 - INFO - Epoch 557/800 done.
2025-03-07 13:15:23,174 - INFO - Final validation performance:
Loss: 1.712, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:15:23,175 - INFO - Beginning epoch 558/800
2025-03-07 13:15:23,187 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:15:23,638 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:15:24,056 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:15:24,530 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:15:24,954 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:15:25,475 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:15:25,920 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:15:26,334 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:15:26,744 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:15:27,224 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:15:27,704 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:15:28,121 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:15:28,636 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:15:29,113 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:15:29,587 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:15:30,026 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:15:30,463 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:15:30,944 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:15:31,170 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:15:31,266 - INFO - validation batch 51, loss: 5.290, 1632/6976 datapoints
2025-03-07 13:15:31,360 - INFO - validation batch 101, loss: 0.452, 3232/6976 datapoints
2025-03-07 13:15:31,442 - INFO - validation batch 151, loss: 1.411, 4832/6976 datapoints
2025-03-07 13:15:31,524 - INFO - validation batch 201, loss: 1.377, 6432/6976 datapoints
2025-03-07 13:15:31,552 - INFO - Epoch 558/800 done.
2025-03-07 13:15:31,552 - INFO - Final validation performance:
Loss: 1.706, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:15:31,553 - INFO - Beginning epoch 559/800
2025-03-07 13:15:31,564 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:15:32,100 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:15:32,632 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:15:33,093 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:15:33,569 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:15:34,245 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:15:34,852 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:15:35,323 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:15:35,730 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:15:36,135 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:15:36,559 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:15:36,982 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:15:37,405 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:15:37,830 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:15:38,244 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:15:38,642 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:15:39,047 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:15:39,433 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:15:39,626 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:15:39,703 - INFO - validation batch 51, loss: 5.266, 1632/6976 datapoints
2025-03-07 13:15:39,778 - INFO - validation batch 101, loss: 0.441, 3232/6976 datapoints
2025-03-07 13:15:39,855 - INFO - validation batch 151, loss: 1.406, 4832/6976 datapoints
2025-03-07 13:15:39,930 - INFO - validation batch 201, loss: 1.378, 6432/6976 datapoints
2025-03-07 13:15:39,954 - INFO - Epoch 559/800 done.
2025-03-07 13:15:39,954 - INFO - Final validation performance:
Loss: 1.698, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:15:39,955 - INFO - Beginning epoch 560/800
2025-03-07 13:15:39,967 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:15:40,382 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:15:40,797 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:15:41,209 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:15:41,615 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:15:42,045 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:15:42,477 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:15:42,890 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:15:43,270 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:15:43,664 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:15:44,098 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:15:44,522 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:15:45,013 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:15:45,468 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:15:45,924 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:15:46,378 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:15:46,801 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:15:47,221 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:15:47,416 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:15:47,490 - INFO - validation batch 51, loss: 5.241, 1632/6976 datapoints
2025-03-07 13:15:47,572 - INFO - validation batch 101, loss: 0.432, 3232/6976 datapoints
2025-03-07 13:15:47,649 - INFO - validation batch 151, loss: 1.397, 4832/6976 datapoints
2025-03-07 13:15:47,729 - INFO - validation batch 201, loss: 1.374, 6432/6976 datapoints
2025-03-07 13:15:47,755 - INFO - Epoch 560/800 done.
2025-03-07 13:15:47,755 - INFO - Final validation performance:
Loss: 1.689, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:15:47,756 - INFO - Beginning epoch 561/800
2025-03-07 13:15:47,766 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:15:48,204 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:15:48,635 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:15:49,039 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:15:49,450 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:15:49,879 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:15:50,350 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:15:50,770 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:15:51,167 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:15:51,577 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:15:51,992 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:15:52,431 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:15:52,855 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:15:53,277 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:15:53,702 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:15:54,099 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:15:54,509 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:15:54,891 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:15:55,077 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:15:55,148 - INFO - validation batch 51, loss: 5.215, 1632/6976 datapoints
2025-03-07 13:15:55,224 - INFO - validation batch 101, loss: 0.423, 3232/6976 datapoints
2025-03-07 13:15:55,295 - INFO - validation batch 151, loss: 1.385, 4832/6976 datapoints
2025-03-07 13:15:55,367 - INFO - validation batch 201, loss: 1.367, 6432/6976 datapoints
2025-03-07 13:15:55,395 - INFO - Epoch 561/800 done.
2025-03-07 13:15:55,395 - INFO - Final validation performance:
Loss: 1.678, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:15:55,395 - INFO - Beginning epoch 562/800
2025-03-07 13:15:55,405 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:15:55,850 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:15:56,323 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:15:56,757 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:15:57,187 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:15:57,886 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:15:58,623 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:15:59,188 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:15:59,682 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:16:00,157 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:16:00,785 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:16:01,240 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:16:01,752 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:16:02,190 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:16:02,653 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:16:03,089 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:16:03,510 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:16:03,951 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:16:04,159 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:16:04,246 - INFO - validation batch 51, loss: 5.187, 1632/6976 datapoints
2025-03-07 13:16:04,341 - INFO - validation batch 101, loss: 0.415, 3232/6976 datapoints
2025-03-07 13:16:04,476 - INFO - validation batch 151, loss: 1.370, 4832/6976 datapoints
2025-03-07 13:16:04,594 - INFO - validation batch 201, loss: 1.357, 6432/6976 datapoints
2025-03-07 13:16:04,630 - INFO - Epoch 562/800 done.
2025-03-07 13:16:04,630 - INFO - Final validation performance:
Loss: 1.666, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:16:04,633 - INFO - Beginning epoch 563/800
2025-03-07 13:16:04,648 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:16:05,087 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:16:05,526 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:16:06,002 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:16:06,499 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:16:06,974 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:16:07,437 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:16:07,847 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:16:08,290 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:16:08,818 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:16:09,234 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:16:09,632 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:16:10,065 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:16:10,548 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:16:10,972 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:16:11,373 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:16:11,789 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:16:12,228 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:16:12,429 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:16:12,512 - INFO - validation batch 51, loss: 5.158, 1632/6976 datapoints
2025-03-07 13:16:12,594 - INFO - validation batch 101, loss: 0.407, 3232/6976 datapoints
2025-03-07 13:16:12,678 - INFO - validation batch 151, loss: 1.354, 4832/6976 datapoints
2025-03-07 13:16:12,787 - INFO - Epoch 563/800 done.
2025-03-07 13:16:12,787 - INFO - Final validation performance:
Loss: 1.653, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:16:12,788 - INFO - Beginning epoch 564/800
2025-03-07 13:16:12,799 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:16:14,238 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:16:14,684 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:16:15,103 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:16:15,545 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:16:16,001 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:16:16,566 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:16:17,129 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:16:17,598 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:16:18,086 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:16:18,611 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:16:19,057 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:16:19,506 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:16:19,990 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:16:20,420 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:16:20,826 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 13:16:21,274 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:16:21,736 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:16:21,955 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:16:22,035 - INFO - validation batch 51, loss: 5.129, 1632/6976 datapoints
2025-03-07 13:16:22,112 - INFO - validation batch 101, loss: 0.401, 3232/6976 datapoints
2025-03-07 13:16:22,199 - INFO - validation batch 151, loss: 1.335, 4832/6976 datapoints
2025-03-07 13:16:22,295 - INFO - validation batch 201, loss: 1.333, 6432/6976 datapoints
2025-03-07 13:16:22,335 - INFO - Epoch 564/800 done.
2025-03-07 13:16:22,336 - INFO - Final validation performance:
Loss: 1.640, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:16:22,336 - INFO - Beginning epoch 565/800
2025-03-07 13:16:22,349 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:16:22,811 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:16:23,266 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:16:23,737 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:16:24,166 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:16:24,670 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:16:25,141 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:16:25,572 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:16:25,993 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:16:26,406 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:16:26,840 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:16:27,273 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:16:27,736 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:16:28,245 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:16:28,674 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:16:29,108 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:16:29,580 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:16:30,027 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:16:30,258 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:16:30,352 - INFO - validation batch 51, loss: 5.100, 1632/6976 datapoints
2025-03-07 13:16:30,443 - INFO - validation batch 101, loss: 0.396, 3232/6976 datapoints
2025-03-07 13:16:30,593 - INFO - validation batch 151, loss: 1.316, 4832/6976 datapoints
2025-03-07 13:16:30,699 - INFO - validation batch 201, loss: 1.319, 6432/6976 datapoints
2025-03-07 13:16:30,733 - INFO - Epoch 565/800 done.
2025-03-07 13:16:30,733 - INFO - Final validation performance:
Loss: 1.626, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:16:30,734 - INFO - Beginning epoch 566/800
2025-03-07 13:16:30,747 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:16:31,305 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:16:31,783 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:16:32,230 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:16:32,709 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:16:33,262 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:16:33,862 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:16:34,325 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:16:34,753 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:16:35,181 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:16:35,723 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:16:36,226 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:16:36,686 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:16:37,128 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:16:37,886 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:16:38,336 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:16:38,754 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:16:39,160 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:16:39,378 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:16:39,463 - INFO - validation batch 51, loss: 5.074, 1632/6976 datapoints
2025-03-07 13:16:39,551 - INFO - validation batch 101, loss: 0.393, 3232/6976 datapoints
2025-03-07 13:16:39,633 - INFO - validation batch 151, loss: 1.297, 4832/6976 datapoints
2025-03-07 13:16:39,708 - INFO - validation batch 201, loss: 1.304, 6432/6976 datapoints
2025-03-07 13:16:39,741 - INFO - Epoch 566/800 done.
2025-03-07 13:16:39,741 - INFO - Final validation performance:
Loss: 1.614, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:16:39,742 - INFO - Beginning epoch 567/800
2025-03-07 13:16:39,753 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:16:40,189 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:16:40,688 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:16:41,131 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:16:41,603 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:16:42,074 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:16:42,567 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:16:43,022 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:16:43,424 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:16:43,887 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:16:44,413 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:16:44,874 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:16:45,491 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:16:46,020 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:16:46,480 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:16:46,898 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:16:47,325 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:16:47,765 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:16:47,978 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:16:48,055 - INFO - validation batch 51, loss: 5.050, 1632/6976 datapoints
2025-03-07 13:16:48,136 - INFO - validation batch 101, loss: 0.393, 3232/6976 datapoints
2025-03-07 13:16:48,221 - INFO - validation batch 151, loss: 1.279, 4832/6976 datapoints
2025-03-07 13:16:48,303 - INFO - validation batch 201, loss: 1.289, 6432/6976 datapoints
2025-03-07 13:16:48,333 - INFO - Epoch 567/800 done.
2025-03-07 13:16:48,333 - INFO - Final validation performance:
Loss: 1.603, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:16:48,334 - INFO - Beginning epoch 568/800
2025-03-07 13:16:48,346 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:16:48,833 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:16:49,347 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:16:49,779 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:16:50,243 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:16:50,738 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:16:51,203 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:16:51,628 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:16:52,182 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:16:52,601 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:16:53,061 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:16:53,516 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:16:53,986 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:16:54,419 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:16:54,844 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:16:55,238 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:16:55,652 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:16:56,037 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:16:56,229 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:16:56,315 - INFO - validation batch 51, loss: 5.030, 1632/6976 datapoints
2025-03-07 13:16:56,389 - INFO - validation batch 101, loss: 0.396, 3232/6976 datapoints
2025-03-07 13:16:56,468 - INFO - validation batch 151, loss: 1.265, 4832/6976 datapoints
2025-03-07 13:16:56,550 - INFO - validation batch 201, loss: 1.275, 6432/6976 datapoints
2025-03-07 13:16:56,574 - INFO - Epoch 568/800 done.
2025-03-07 13:16:56,574 - INFO - Final validation performance:
Loss: 1.594, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:16:56,574 - INFO - Beginning epoch 569/800
2025-03-07 13:16:56,585 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:16:57,022 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:16:57,598 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:16:58,193 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:16:58,645 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:16:59,131 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:16:59,606 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:17:00,042 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:17:00,425 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:17:00,826 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:17:01,240 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:17:01,653 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:17:02,078 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:17:02,486 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:17:02,933 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:17:03,351 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:17:03,759 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:17:04,185 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:17:04,398 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:17:04,482 - INFO - validation batch 51, loss: 5.014, 1632/6976 datapoints
2025-03-07 13:17:04,607 - INFO - validation batch 101, loss: 0.401, 3232/6976 datapoints
2025-03-07 13:17:04,765 - INFO - validation batch 151, loss: 1.255, 4832/6976 datapoints
2025-03-07 13:17:04,861 - INFO - validation batch 201, loss: 1.261, 6432/6976 datapoints
2025-03-07 13:17:04,896 - INFO - Epoch 569/800 done.
2025-03-07 13:17:04,897 - INFO - Final validation performance:
Loss: 1.587, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:17:04,897 - INFO - Beginning epoch 570/800
2025-03-07 13:17:04,911 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:17:05,397 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:17:05,884 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:17:06,313 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:17:06,798 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:17:07,379 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:17:07,950 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:17:08,384 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:17:08,772 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:17:09,180 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:17:09,589 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:17:10,001 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:17:10,485 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:17:10,940 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:17:11,372 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:17:11,792 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:17:12,283 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:17:12,798 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:17:13,017 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:17:13,117 - INFO - validation batch 51, loss: 5.002, 1632/6976 datapoints
2025-03-07 13:17:13,221 - INFO - validation batch 101, loss: 0.408, 3232/6976 datapoints
2025-03-07 13:17:13,317 - INFO - validation batch 151, loss: 1.250, 4832/6976 datapoints
2025-03-07 13:17:13,402 - INFO - validation batch 201, loss: 1.249, 6432/6976 datapoints
2025-03-07 13:17:13,433 - INFO - Epoch 570/800 done.
2025-03-07 13:17:13,433 - INFO - Final validation performance:
Loss: 1.582, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:17:13,434 - INFO - Beginning epoch 571/800
2025-03-07 13:17:13,447 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:17:13,915 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:17:14,408 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:17:14,854 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:17:15,298 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:17:15,782 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:17:16,282 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:17:16,739 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:17:17,186 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:17:17,612 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:17:18,069 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:17:18,495 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:17:18,944 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:17:19,384 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:17:19,847 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:17:20,264 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:17:20,692 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:17:21,075 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:17:21,271 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:17:21,349 - INFO - validation batch 51, loss: 4.993, 1632/6976 datapoints
2025-03-07 13:17:21,421 - INFO - validation batch 101, loss: 0.416, 3232/6976 datapoints
2025-03-07 13:17:21,505 - INFO - validation batch 151, loss: 1.249, 4832/6976 datapoints
2025-03-07 13:17:21,587 - INFO - validation batch 201, loss: 1.237, 6432/6976 datapoints
2025-03-07 13:17:21,614 - INFO - Epoch 571/800 done.
2025-03-07 13:17:21,614 - INFO - Final validation performance:
Loss: 1.580, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:17:21,614 - INFO - Beginning epoch 572/800
2025-03-07 13:17:21,625 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:17:22,065 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:17:22,542 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:17:22,991 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:17:23,418 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:17:23,878 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:17:24,363 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:17:24,800 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:17:25,205 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:17:25,647 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:17:26,107 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:17:26,601 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:17:27,071 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:17:27,550 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:17:28,016 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:17:28,478 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:17:28,917 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:17:29,315 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:17:29,521 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 13:17:29,598 - INFO - validation batch 51, loss: 4.987, 1632/6976 datapoints
2025-03-07 13:17:29,674 - INFO - validation batch 101, loss: 0.423, 3232/6976 datapoints
2025-03-07 13:17:29,760 - INFO - validation batch 151, loss: 1.252, 4832/6976 datapoints
2025-03-07 13:17:29,861 - INFO - validation batch 201, loss: 1.227, 6432/6976 datapoints
2025-03-07 13:17:29,899 - INFO - Epoch 572/800 done.
2025-03-07 13:17:29,899 - INFO - Final validation performance:
Loss: 1.579, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:17:29,899 - INFO - Beginning epoch 573/800
2025-03-07 13:17:29,911 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:17:30,385 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:17:30,995 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:17:31,462 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:17:31,923 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:17:32,438 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:17:33,000 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:17:33,445 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:17:33,854 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:17:34,299 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:17:34,755 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:17:35,175 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:17:35,615 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:17:36,082 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:17:36,569 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:17:37,005 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:17:37,443 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:17:37,916 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:17:38,153 - INFO - validation batch 1, loss: 0.007, 32/6976 datapoints
2025-03-07 13:17:38,274 - INFO - validation batch 51, loss: 4.983, 1632/6976 datapoints
2025-03-07 13:17:38,372 - INFO - validation batch 101, loss: 0.431, 3232/6976 datapoints
2025-03-07 13:17:38,479 - INFO - validation batch 151, loss: 1.259, 4832/6976 datapoints
2025-03-07 13:17:38,580 - INFO - validation batch 201, loss: 1.221, 6432/6976 datapoints
2025-03-07 13:17:38,613 - INFO - Epoch 573/800 done.
2025-03-07 13:17:38,614 - INFO - Final validation performance:
Loss: 1.580, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:17:38,615 - INFO - Beginning epoch 574/800
2025-03-07 13:17:38,626 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:17:39,275 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:17:39,885 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:17:40,365 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:17:40,831 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:17:41,361 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:17:41,829 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:17:42,235 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:17:42,719 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:17:43,206 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:17:43,680 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:17:44,129 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:17:44,573 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:17:45,024 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:17:45,491 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:17:45,966 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:17:46,402 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:17:46,803 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:17:46,998 - INFO - validation batch 1, loss: 0.009, 32/6976 datapoints
2025-03-07 13:17:47,089 - INFO - validation batch 51, loss: 4.979, 1632/6976 datapoints
2025-03-07 13:17:47,178 - INFO - validation batch 101, loss: 0.439, 3232/6976 datapoints
2025-03-07 13:17:47,260 - INFO - validation batch 151, loss: 1.268, 4832/6976 datapoints
2025-03-07 13:17:47,343 - INFO - validation batch 201, loss: 1.217, 6432/6976 datapoints
2025-03-07 13:17:47,369 - INFO - Epoch 574/800 done.
2025-03-07 13:17:47,369 - INFO - Final validation performance:
Loss: 1.582, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:17:47,370 - INFO - Beginning epoch 575/800
2025-03-07 13:17:47,382 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:17:47,815 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:17:48,254 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:17:48,734 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:17:49,167 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:17:49,637 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:17:50,068 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:17:50,537 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:17:50,919 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:17:51,340 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:17:51,801 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:17:52,216 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:17:52,648 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:17:53,103 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:17:53,548 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:17:53,962 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:17:54,381 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:17:54,793 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:17:54,999 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 13:17:55,076 - INFO - validation batch 51, loss: 4.979, 1632/6976 datapoints
2025-03-07 13:17:55,151 - INFO - validation batch 101, loss: 0.445, 3232/6976 datapoints
2025-03-07 13:17:55,227 - INFO - validation batch 151, loss: 1.281, 4832/6976 datapoints
2025-03-07 13:17:55,317 - INFO - validation batch 201, loss: 1.220, 6432/6976 datapoints
2025-03-07 13:17:55,347 - INFO - Epoch 575/800 done.
2025-03-07 13:17:55,347 - INFO - Final validation performance:
Loss: 1.587, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:17:55,348 - INFO - Beginning epoch 576/800
2025-03-07 13:17:55,359 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:17:55,784 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:17:56,237 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:17:56,684 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:17:57,122 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:17:57,725 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:17:58,226 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:17:58,692 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:17:59,074 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:17:59,478 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:17:59,926 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:18:00,343 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:18:00,779 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:18:01,245 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:18:01,891 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:18:02,430 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:18:02,872 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:18:03,332 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:18:03,535 - INFO - validation batch 1, loss: 0.011, 32/6976 datapoints
2025-03-07 13:18:03,614 - INFO - validation batch 51, loss: 4.973, 1632/6976 datapoints
2025-03-07 13:18:03,691 - INFO - validation batch 101, loss: 0.455, 3232/6976 datapoints
2025-03-07 13:18:03,770 - INFO - validation batch 151, loss: 1.297, 4832/6976 datapoints
2025-03-07 13:18:03,849 - INFO - validation batch 201, loss: 1.220, 6432/6976 datapoints
2025-03-07 13:18:03,877 - INFO - Epoch 576/800 done.
2025-03-07 13:18:03,877 - INFO - Final validation performance:
Loss: 1.591, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:18:03,878 - INFO - Beginning epoch 577/800
2025-03-07 13:18:03,889 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:18:04,326 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:18:04,857 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:18:05,370 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:18:05,853 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:18:06,325 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:18:06,773 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:18:07,194 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:18:07,562 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:18:08,015 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:18:08,467 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:18:08,962 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:18:09,420 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:18:09,857 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:18:10,294 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:18:10,698 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:18:11,125 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:18:11,514 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:18:11,704 - INFO - validation batch 1, loss: 0.011, 32/6976 datapoints
2025-03-07 13:18:11,785 - INFO - validation batch 51, loss: 4.971, 1632/6976 datapoints
2025-03-07 13:18:11,857 - INFO - validation batch 101, loss: 0.465, 3232/6976 datapoints
2025-03-07 13:18:11,928 - INFO - validation batch 151, loss: 1.318, 4832/6976 datapoints
2025-03-07 13:18:12,001 - INFO - validation batch 201, loss: 1.228, 6432/6976 datapoints
2025-03-07 13:18:12,025 - INFO - Epoch 577/800 done.
2025-03-07 13:18:12,025 - INFO - Final validation performance:
Loss: 1.598, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:18:12,026 - INFO - Beginning epoch 578/800
2025-03-07 13:18:12,036 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:18:12,460 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:18:13,031 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:18:13,585 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:18:14,024 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:18:14,502 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:18:14,955 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:18:15,384 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:18:15,804 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:18:16,230 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:18:16,666 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:18:17,110 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:18:17,542 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:18:18,058 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:18:18,530 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:18:18,987 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:18:19,450 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:18:19,844 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:18:20,046 - INFO - validation batch 1, loss: 0.012, 32/6976 datapoints
2025-03-07 13:18:20,128 - INFO - validation batch 51, loss: 4.972, 1632/6976 datapoints
2025-03-07 13:18:20,242 - INFO - validation batch 101, loss: 0.474, 3232/6976 datapoints
2025-03-07 13:18:20,325 - INFO - validation batch 151, loss: 1.347, 4832/6976 datapoints
2025-03-07 13:18:20,409 - INFO - validation batch 201, loss: 1.230, 6432/6976 datapoints
2025-03-07 13:18:20,442 - INFO - Epoch 578/800 done.
2025-03-07 13:18:20,442 - INFO - Final validation performance:
Loss: 1.607, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:18:20,443 - INFO - Beginning epoch 579/800
2025-03-07 13:18:20,454 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:18:20,872 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:18:21,323 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:18:21,788 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:18:22,283 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:18:22,833 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:18:23,385 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:18:23,820 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:18:24,224 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:18:24,704 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:18:25,183 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:18:25,619 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:18:26,059 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:18:26,489 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:18:26,946 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:18:27,354 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:18:27,776 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:18:28,175 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:18:28,380 - INFO - validation batch 1, loss: 0.014, 32/6976 datapoints
2025-03-07 13:18:28,461 - INFO - validation batch 51, loss: 4.972, 1632/6976 datapoints
2025-03-07 13:18:28,546 - INFO - validation batch 101, loss: 0.500, 3232/6976 datapoints
2025-03-07 13:18:28,619 - INFO - validation batch 151, loss: 1.381, 4832/6976 datapoints
2025-03-07 13:18:28,716 - INFO - validation batch 201, loss: 1.243, 6432/6976 datapoints
2025-03-07 13:18:28,764 - INFO - Epoch 579/800 done.
2025-03-07 13:18:28,764 - INFO - Final validation performance:
Loss: 1.622, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:18:28,765 - INFO - Beginning epoch 580/800
2025-03-07 13:18:28,776 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:18:29,243 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:18:29,682 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:18:30,587 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:18:31,047 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:18:31,501 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:18:32,218 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:18:32,735 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:18:33,255 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:18:33,715 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:18:34,167 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:18:34,687 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:18:35,186 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:18:35,668 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:18:36,114 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:18:36,566 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:18:36,990 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:18:37,223 - INFO - validation batch 1, loss: 0.015, 32/6976 datapoints
2025-03-07 13:18:37,343 - INFO - validation batch 51, loss: 4.959, 1632/6976 datapoints
2025-03-07 13:18:37,449 - INFO - validation batch 101, loss: 0.518, 3232/6976 datapoints
2025-03-07 13:18:37,558 - INFO - validation batch 151, loss: 1.410, 4832/6976 datapoints
2025-03-07 13:18:37,674 - INFO - validation batch 201, loss: 1.242, 6432/6976 datapoints
2025-03-07 13:18:37,709 - INFO - Epoch 580/800 done.
2025-03-07 13:18:37,709 - INFO - Final validation performance:
Loss: 1.629, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:18:37,710 - INFO - Beginning epoch 581/800
2025-03-07 13:18:37,724 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:18:38,211 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:18:38,731 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:18:39,254 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:18:39,773 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:18:40,302 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:18:40,839 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:18:41,346 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:18:41,893 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:18:42,410 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:18:42,905 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:18:43,319 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:18:43,730 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:18:44,137 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:18:44,546 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:18:44,949 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:18:45,351 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:18:45,731 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:18:45,922 - INFO - validation batch 1, loss: 0.017, 32/6976 datapoints
2025-03-07 13:18:45,996 - INFO - validation batch 51, loss: 4.966, 1632/6976 datapoints
2025-03-07 13:18:46,069 - INFO - validation batch 101, loss: 0.524, 3232/6976 datapoints
2025-03-07 13:18:46,144 - INFO - validation batch 151, loss: 1.443, 4832/6976 datapoints
2025-03-07 13:18:46,218 - INFO - validation batch 201, loss: 1.242, 6432/6976 datapoints
2025-03-07 13:18:46,246 - INFO - Epoch 581/800 done.
2025-03-07 13:18:46,246 - INFO - Final validation performance:
Loss: 1.639, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:18:46,247 - INFO - Beginning epoch 582/800
2025-03-07 13:18:46,257 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:18:46,736 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:18:47,153 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:18:47,580 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:18:48,047 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:18:48,513 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:18:49,014 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:18:49,447 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:18:49,856 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:18:50,294 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:18:50,783 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:18:51,263 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:18:51,718 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:18:52,183 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:18:52,695 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:18:53,158 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:18:53,610 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:18:54,018 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:18:54,241 - INFO - validation batch 1, loss: 0.012, 32/6976 datapoints
2025-03-07 13:18:54,333 - INFO - validation batch 51, loss: 4.919, 1632/6976 datapoints
2025-03-07 13:18:54,421 - INFO - validation batch 101, loss: 0.539, 3232/6976 datapoints
2025-03-07 13:18:54,517 - INFO - validation batch 151, loss: 1.471, 4832/6976 datapoints
2025-03-07 13:18:54,600 - INFO - validation batch 201, loss: 1.217, 6432/6976 datapoints
2025-03-07 13:18:54,637 - INFO - Epoch 582/800 done.
2025-03-07 13:18:54,637 - INFO - Final validation performance:
Loss: 1.632, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:18:54,638 - INFO - Beginning epoch 583/800
2025-03-07 13:18:54,651 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:18:55,099 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:18:55,579 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:18:56,032 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:18:56,488 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:18:56,957 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:18:57,439 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:18:57,878 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:18:58,260 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:18:58,719 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:18:59,178 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:18:59,601 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:19:00,071 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:19:00,528 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:19:00,992 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:19:01,514 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:19:02,022 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:19:02,522 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:19:02,766 - INFO - validation batch 1, loss: 0.014, 32/6976 datapoints
2025-03-07 13:19:02,864 - INFO - validation batch 51, loss: 4.933, 1632/6976 datapoints
2025-03-07 13:19:02,967 - INFO - validation batch 101, loss: 0.553, 3232/6976 datapoints
2025-03-07 13:19:03,058 - INFO - validation batch 151, loss: 1.484, 4832/6976 datapoints
2025-03-07 13:19:03,151 - INFO - validation batch 201, loss: 1.233, 6432/6976 datapoints
2025-03-07 13:19:03,185 - INFO - Epoch 583/800 done.
2025-03-07 13:19:03,186 - INFO - Final validation performance:
Loss: 1.643, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:19:03,187 - INFO - Beginning epoch 584/800
2025-03-07 13:19:03,202 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:19:03,787 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:19:04,286 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:19:04,952 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:19:05,581 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:19:06,099 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:19:06,587 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:19:07,001 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:19:07,368 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:19:07,759 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:19:08,161 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:19:08,565 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:19:08,987 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:19:09,469 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:19:09,958 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:19:10,397 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:19:10,924 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:19:11,388 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:19:11,613 - INFO - validation batch 1, loss: 0.008, 32/6976 datapoints
2025-03-07 13:19:11,706 - INFO - validation batch 51, loss: 4.926, 1632/6976 datapoints
2025-03-07 13:19:11,792 - INFO - validation batch 101, loss: 0.594, 3232/6976 datapoints
2025-03-07 13:19:11,890 - INFO - validation batch 151, loss: 1.490, 4832/6976 datapoints
2025-03-07 13:19:11,970 - INFO - validation batch 201, loss: 1.192, 6432/6976 datapoints
2025-03-07 13:19:11,998 - INFO - Epoch 584/800 done.
2025-03-07 13:19:11,998 - INFO - Final validation performance:
Loss: 1.642, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:19:11,999 - INFO - Beginning epoch 585/800
2025-03-07 13:19:12,009 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:19:12,496 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:19:12,997 - INFO - training batch 101, loss: 0.035, 3232/28000 datapoints
2025-03-07 13:19:13,490 - INFO - training batch 151, loss: 0.001, 4832/28000 datapoints
2025-03-07 13:19:13,934 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:19:14,362 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:19:14,786 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:19:15,178 - INFO - training batch 351, loss: 0.017, 11232/28000 datapoints
2025-03-07 13:19:15,585 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:19:16,002 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:19:16,442 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:19:16,886 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:19:17,383 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:19:17,878 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:19:18,368 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:19:18,907 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:19:19,483 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:19:20,035 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:19:20,257 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:19:20,349 - INFO - validation batch 51, loss: 4.320, 1632/6976 datapoints
2025-03-07 13:19:20,452 - INFO - validation batch 101, loss: 0.895, 3232/6976 datapoints
2025-03-07 13:19:20,563 - INFO - validation batch 151, loss: 1.210, 4832/6976 datapoints
2025-03-07 13:19:20,716 - INFO - validation batch 201, loss: 1.063, 6432/6976 datapoints
2025-03-07 13:19:20,762 - INFO - Epoch 585/800 done.
2025-03-07 13:19:20,762 - INFO - Final validation performance:
Loss: 1.498, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:19:20,763 - INFO - Beginning epoch 586/800
2025-03-07 13:19:20,776 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:19:21,377 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:19:21,967 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:19:22,465 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:19:22,901 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:19:23,344 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:19:23,798 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:19:24,226 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:19:24,596 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:19:24,956 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:19:25,412 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:19:25,876 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:19:26,277 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:19:26,686 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:19:27,073 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:19:27,479 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:19:27,927 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:19:28,340 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:19:28,534 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:19:28,608 - INFO - validation batch 51, loss: 4.357, 1632/6976 datapoints
2025-03-07 13:19:28,685 - INFO - validation batch 101, loss: 0.886, 3232/6976 datapoints
2025-03-07 13:19:28,760 - INFO - validation batch 151, loss: 1.142, 4832/6976 datapoints
2025-03-07 13:19:28,833 - INFO - validation batch 201, loss: 0.964, 6432/6976 datapoints
2025-03-07 13:19:28,859 - INFO - Epoch 586/800 done.
2025-03-07 13:19:28,859 - INFO - Final validation performance:
Loss: 1.470, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:19:28,859 - INFO - Beginning epoch 587/800
2025-03-07 13:19:28,869 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:19:29,314 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:19:29,755 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:19:30,148 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:19:30,585 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:19:31,001 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:19:31,420 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:19:31,813 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:19:32,181 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:19:32,963 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:19:33,839 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:19:34,385 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:19:35,069 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:19:35,625 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:19:36,095 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:19:36,534 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:19:36,986 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:19:37,434 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:19:37,639 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:19:37,731 - INFO - validation batch 51, loss: 4.376, 1632/6976 datapoints
2025-03-07 13:19:37,818 - INFO - validation batch 101, loss: 0.865, 3232/6976 datapoints
2025-03-07 13:19:37,903 - INFO - validation batch 151, loss: 1.133, 4832/6976 datapoints
2025-03-07 13:19:37,984 - INFO - validation batch 201, loss: 0.953, 6432/6976 datapoints
2025-03-07 13:19:38,009 - INFO - Epoch 587/800 done.
2025-03-07 13:19:38,009 - INFO - Final validation performance:
Loss: 1.465, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:19:38,011 - INFO - Beginning epoch 588/800
2025-03-07 13:19:38,020 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:19:38,443 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:19:38,881 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:19:39,283 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:19:39,729 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:19:40,160 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:19:40,640 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:19:41,204 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:19:41,656 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:19:42,098 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:19:42,607 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:19:43,083 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:19:43,607 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:19:44,119 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:19:44,576 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:19:45,072 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:19:45,547 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:19:45,963 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:19:46,182 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:19:46,270 - INFO - validation batch 51, loss: 4.391, 1632/6976 datapoints
2025-03-07 13:19:46,355 - INFO - validation batch 101, loss: 0.853, 3232/6976 datapoints
2025-03-07 13:19:46,431 - INFO - validation batch 151, loss: 1.138, 4832/6976 datapoints
2025-03-07 13:19:46,518 - INFO - validation batch 201, loss: 0.947, 6432/6976 datapoints
2025-03-07 13:19:46,549 - INFO - Epoch 588/800 done.
2025-03-07 13:19:46,550 - INFO - Final validation performance:
Loss: 1.466, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:19:46,550 - INFO - Beginning epoch 589/800
2025-03-07 13:19:46,561 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:19:47,053 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:19:47,505 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:19:47,976 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:19:48,419 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:19:48,867 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:19:49,318 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:19:49,780 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:19:50,174 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:19:50,579 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:19:51,045 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:19:51,574 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:19:52,078 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:19:52,584 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:19:53,086 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:19:53,614 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:19:54,126 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:19:54,590 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:19:54,854 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:19:54,936 - INFO - validation batch 51, loss: 4.405, 1632/6976 datapoints
2025-03-07 13:19:55,030 - INFO - validation batch 101, loss: 0.842, 3232/6976 datapoints
2025-03-07 13:19:55,124 - INFO - validation batch 151, loss: 1.149, 4832/6976 datapoints
2025-03-07 13:19:55,215 - INFO - validation batch 201, loss: 0.944, 6432/6976 datapoints
2025-03-07 13:19:55,246 - INFO - Epoch 589/800 done.
2025-03-07 13:19:55,247 - INFO - Final validation performance:
Loss: 1.468, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:19:55,247 - INFO - Beginning epoch 590/800
2025-03-07 13:19:55,259 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:19:55,758 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:19:56,240 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:19:56,670 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:19:57,126 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:19:57,632 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:19:58,191 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:19:58,650 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:19:59,081 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:19:59,469 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:19:59,923 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:20:00,360 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:20:00,817 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:20:01,260 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:20:01,699 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:20:02,133 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:20:02,595 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:20:03,037 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:20:03,256 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:20:03,343 - INFO - validation batch 51, loss: 4.420, 1632/6976 datapoints
2025-03-07 13:20:03,434 - INFO - validation batch 101, loss: 0.829, 3232/6976 datapoints
2025-03-07 13:20:03,521 - INFO - validation batch 151, loss: 1.163, 4832/6976 datapoints
2025-03-07 13:20:03,607 - INFO - validation batch 201, loss: 0.943, 6432/6976 datapoints
2025-03-07 13:20:03,642 - INFO - Epoch 590/800 done.
2025-03-07 13:20:03,643 - INFO - Final validation performance:
Loss: 1.471, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:20:03,643 - INFO - Beginning epoch 591/800
2025-03-07 13:20:03,657 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:20:04,115 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:20:04,555 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:20:05,036 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:20:05,476 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:20:05,997 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:20:06,498 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:20:06,982 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:20:07,400 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:20:07,834 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:20:08,394 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:20:09,071 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:20:09,620 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:20:10,153 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:20:10,659 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:20:11,167 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:20:11,736 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:20:12,322 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:20:12,557 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:20:12,666 - INFO - validation batch 51, loss: 4.435, 1632/6976 datapoints
2025-03-07 13:20:12,764 - INFO - validation batch 101, loss: 0.815, 3232/6976 datapoints
2025-03-07 13:20:12,877 - INFO - validation batch 151, loss: 1.179, 4832/6976 datapoints
2025-03-07 13:20:12,986 - INFO - validation batch 201, loss: 0.944, 6432/6976 datapoints
2025-03-07 13:20:13,021 - INFO - Epoch 591/800 done.
2025-03-07 13:20:13,021 - INFO - Final validation performance:
Loss: 1.474, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:20:13,022 - INFO - Beginning epoch 592/800
2025-03-07 13:20:13,037 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:20:13,615 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:20:14,138 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:20:14,580 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:20:15,066 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:20:15,570 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:20:16,086 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:20:16,592 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:20:17,138 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:20:17,596 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:20:18,088 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:20:18,560 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:20:19,064 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:20:19,482 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:20:19,887 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:20:20,299 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:20:20,710 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:20:21,105 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:20:21,287 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:20:21,359 - INFO - validation batch 51, loss: 4.450, 1632/6976 datapoints
2025-03-07 13:20:21,442 - INFO - validation batch 101, loss: 0.799, 3232/6976 datapoints
2025-03-07 13:20:21,519 - INFO - validation batch 151, loss: 1.196, 4832/6976 datapoints
2025-03-07 13:20:21,594 - INFO - validation batch 201, loss: 0.946, 6432/6976 datapoints
2025-03-07 13:20:21,616 - INFO - Epoch 592/800 done.
2025-03-07 13:20:21,617 - INFO - Final validation performance:
Loss: 1.478, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:20:21,617 - INFO - Beginning epoch 593/800
2025-03-07 13:20:21,626 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:20:22,109 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:20:22,563 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:20:23,001 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:20:23,488 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:20:24,005 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:20:24,573 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:20:25,040 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:20:25,480 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:20:25,882 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:20:26,294 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:20:26,682 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:20:27,083 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:20:27,501 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:20:27,923 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:20:28,319 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:20:28,757 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:20:29,181 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:20:29,392 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:20:29,481 - INFO - validation batch 51, loss: 4.466, 1632/6976 datapoints
2025-03-07 13:20:29,584 - INFO - validation batch 101, loss: 0.782, 3232/6976 datapoints
2025-03-07 13:20:29,675 - INFO - validation batch 151, loss: 1.213, 4832/6976 datapoints
2025-03-07 13:20:29,746 - INFO - validation batch 201, loss: 0.950, 6432/6976 datapoints
2025-03-07 13:20:29,773 - INFO - Epoch 593/800 done.
2025-03-07 13:20:29,773 - INFO - Final validation performance:
Loss: 1.482, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:20:29,774 - INFO - Beginning epoch 594/800
2025-03-07 13:20:29,785 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:20:30,235 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:20:30,692 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:20:31,090 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:20:31,566 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:20:32,074 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:20:32,551 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:20:32,967 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:20:33,347 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:20:33,771 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:20:34,328 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:20:34,867 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:20:35,357 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:20:35,787 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:20:36,201 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:20:36,663 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:20:37,094 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:20:37,639 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:20:37,874 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:20:37,984 - INFO - validation batch 51, loss: 4.483, 1632/6976 datapoints
2025-03-07 13:20:38,098 - INFO - validation batch 101, loss: 0.764, 3232/6976 datapoints
2025-03-07 13:20:38,213 - INFO - validation batch 151, loss: 1.230, 4832/6976 datapoints
2025-03-07 13:20:38,343 - INFO - validation batch 201, loss: 0.955, 6432/6976 datapoints
2025-03-07 13:20:38,388 - INFO - Epoch 594/800 done.
2025-03-07 13:20:38,389 - INFO - Final validation performance:
Loss: 1.487, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:20:38,391 - INFO - Beginning epoch 595/800
2025-03-07 13:20:38,406 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:20:39,108 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:20:39,644 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:20:40,078 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:20:40,532 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:20:40,969 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:20:41,403 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:20:41,844 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:20:42,216 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:20:42,605 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:20:43,018 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:20:43,413 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:20:43,814 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:20:44,224 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:20:44,705 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:20:45,149 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:20:45,607 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:20:46,032 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:20:46,239 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:20:46,320 - INFO - validation batch 51, loss: 4.503, 1632/6976 datapoints
2025-03-07 13:20:46,400 - INFO - validation batch 101, loss: 0.746, 3232/6976 datapoints
2025-03-07 13:20:46,488 - INFO - validation batch 151, loss: 1.246, 4832/6976 datapoints
2025-03-07 13:20:46,567 - INFO - validation batch 201, loss: 0.962, 6432/6976 datapoints
2025-03-07 13:20:46,598 - INFO - Epoch 595/800 done.
2025-03-07 13:20:46,598 - INFO - Final validation performance:
Loss: 1.491, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:20:46,599 - INFO - Beginning epoch 596/800
2025-03-07 13:20:46,611 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:20:47,092 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:20:47,651 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:20:48,102 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:20:48,533 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:20:48,997 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:20:49,444 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:20:49,843 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:20:50,235 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:20:50,657 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:20:51,083 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:20:51,477 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:20:51,902 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:20:52,360 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:20:52,812 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:20:53,253 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:20:53,719 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:20:54,147 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:20:54,389 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:20:54,477 - INFO - validation batch 51, loss: 4.526, 1632/6976 datapoints
2025-03-07 13:20:54,592 - INFO - validation batch 101, loss: 0.726, 3232/6976 datapoints
2025-03-07 13:20:54,704 - INFO - validation batch 151, loss: 1.259, 4832/6976 datapoints
2025-03-07 13:20:54,866 - INFO - validation batch 201, loss: 0.969, 6432/6976 datapoints
2025-03-07 13:20:54,911 - INFO - Epoch 596/800 done.
2025-03-07 13:20:54,911 - INFO - Final validation performance:
Loss: 1.496, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:20:54,912 - INFO - Beginning epoch 597/800
2025-03-07 13:20:54,924 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:20:55,428 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:20:55,906 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:20:56,371 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:20:56,836 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:20:57,360 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:20:57,877 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:20:58,385 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:20:58,828 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:20:59,339 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:20:59,996 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:21:00,527 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:21:01,056 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:21:01,600 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:21:02,094 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:21:02,539 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:21:03,012 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:21:03,466 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:21:03,705 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:21:03,809 - INFO - validation batch 51, loss: 4.552, 1632/6976 datapoints
2025-03-07 13:21:03,907 - INFO - validation batch 101, loss: 0.704, 3232/6976 datapoints
2025-03-07 13:21:04,005 - INFO - validation batch 151, loss: 1.271, 4832/6976 datapoints
2025-03-07 13:21:04,103 - INFO - validation batch 201, loss: 0.978, 6432/6976 datapoints
2025-03-07 13:21:04,135 - INFO - Epoch 597/800 done.
2025-03-07 13:21:04,135 - INFO - Final validation performance:
Loss: 1.501, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:21:04,136 - INFO - Beginning epoch 598/800
2025-03-07 13:21:04,147 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:21:04,634 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:21:05,044 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:21:05,433 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:21:05,839 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:21:06,258 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:21:06,688 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:21:07,079 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:21:07,475 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:21:07,898 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:21:08,304 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:21:08,721 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:21:09,158 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:21:09,587 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:21:10,140 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:21:10,678 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:21:11,111 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:21:11,522 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:21:11,713 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:21:11,793 - INFO - validation batch 51, loss: 4.581, 1632/6976 datapoints
2025-03-07 13:21:11,870 - INFO - validation batch 101, loss: 0.682, 3232/6976 datapoints
2025-03-07 13:21:11,946 - INFO - validation batch 151, loss: 1.282, 4832/6976 datapoints
2025-03-07 13:21:12,026 - INFO - validation batch 201, loss: 0.986, 6432/6976 datapoints
2025-03-07 13:21:12,054 - INFO - Epoch 598/800 done.
2025-03-07 13:21:12,054 - INFO - Final validation performance:
Loss: 1.506, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:21:12,055 - INFO - Beginning epoch 599/800
2025-03-07 13:21:12,066 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:21:12,501 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:21:12,941 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:21:13,362 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:21:13,794 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:21:14,228 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:21:14,672 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:21:15,382 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:21:15,880 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:21:16,272 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:21:16,682 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:21:17,085 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:21:17,479 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:21:17,903 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:21:18,307 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:21:18,727 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:21:19,252 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:21:20,050 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:21:20,290 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:21:20,382 - INFO - validation batch 51, loss: 4.614, 1632/6976 datapoints
2025-03-07 13:21:20,467 - INFO - validation batch 101, loss: 0.658, 3232/6976 datapoints
2025-03-07 13:21:20,554 - INFO - validation batch 151, loss: 1.292, 4832/6976 datapoints
2025-03-07 13:21:20,659 - INFO - validation batch 201, loss: 0.994, 6432/6976 datapoints
2025-03-07 13:21:20,692 - INFO - Epoch 599/800 done.
2025-03-07 13:21:20,692 - INFO - Final validation performance:
Loss: 1.512, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:21:20,693 - INFO - Beginning epoch 600/800
2025-03-07 13:21:20,705 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:21:21,149 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:21:21,632 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:21:22,115 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:21:22,565 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:21:23,083 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:21:23,621 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:21:24,068 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:21:24,517 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:21:24,985 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:21:25,426 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:21:25,871 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:21:26,354 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:21:26,873 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:21:27,401 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:21:27,888 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:21:28,414 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:21:28,956 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:21:29,220 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:21:29,337 - INFO - validation batch 51, loss: 4.651, 1632/6976 datapoints
2025-03-07 13:21:29,446 - INFO - validation batch 101, loss: 0.633, 3232/6976 datapoints
2025-03-07 13:21:29,570 - INFO - validation batch 151, loss: 1.303, 4832/6976 datapoints
2025-03-07 13:21:29,687 - INFO - validation batch 201, loss: 1.006, 6432/6976 datapoints
2025-03-07 13:21:29,724 - INFO - Epoch 600/800 done.
2025-03-07 13:21:29,724 - INFO - Final validation performance:
Loss: 1.519, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:21:29,725 - INFO - Beginning epoch 601/800
2025-03-07 13:21:29,742 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:21:30,719 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:21:31,270 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:21:31,743 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:21:32,336 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:21:32,978 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:21:33,426 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:21:33,822 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:21:34,180 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:21:34,562 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:21:34,968 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:21:35,403 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:21:35,818 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:21:36,321 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:21:37,124 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:21:37,789 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:21:38,265 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:21:38,738 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:21:38,973 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:21:39,076 - INFO - validation batch 51, loss: 4.687, 1632/6976 datapoints
2025-03-07 13:21:39,178 - INFO - validation batch 101, loss: 0.607, 3232/6976 datapoints
2025-03-07 13:21:39,275 - INFO - validation batch 151, loss: 1.317, 4832/6976 datapoints
2025-03-07 13:21:39,368 - INFO - validation batch 201, loss: 1.020, 6432/6976 datapoints
2025-03-07 13:21:39,399 - INFO - Epoch 601/800 done.
2025-03-07 13:21:39,399 - INFO - Final validation performance:
Loss: 1.526, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:21:39,400 - INFO - Beginning epoch 602/800
2025-03-07 13:21:39,413 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:21:39,919 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:21:40,433 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:21:40,975 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:21:41,458 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:21:41,986 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:21:42,482 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:21:43,007 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:21:43,448 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:21:43,914 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:21:44,576 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:21:45,238 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:21:45,753 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:21:46,264 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:21:46,689 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:21:47,139 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:21:47,582 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:21:47,975 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:21:48,180 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:21:48,270 - INFO - validation batch 51, loss: 4.722, 1632/6976 datapoints
2025-03-07 13:21:48,352 - INFO - validation batch 101, loss: 0.580, 3232/6976 datapoints
2025-03-07 13:21:48,432 - INFO - validation batch 151, loss: 1.335, 4832/6976 datapoints
2025-03-07 13:21:48,532 - INFO - validation batch 201, loss: 1.036, 6432/6976 datapoints
2025-03-07 13:21:48,572 - INFO - Epoch 602/800 done.
2025-03-07 13:21:48,572 - INFO - Final validation performance:
Loss: 1.535, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:21:48,573 - INFO - Beginning epoch 603/800
2025-03-07 13:21:48,588 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:21:49,078 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:21:49,562 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:21:49,964 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:21:50,402 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:21:50,898 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:21:51,371 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:21:51,772 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:21:52,140 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:21:52,537 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:21:53,008 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:21:53,433 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:21:53,838 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:21:54,245 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:21:54,649 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:21:55,085 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:21:55,498 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:21:55,882 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:21:56,076 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:21:56,149 - INFO - validation batch 51, loss: 4.753, 1632/6976 datapoints
2025-03-07 13:21:56,222 - INFO - validation batch 101, loss: 0.553, 3232/6976 datapoints
2025-03-07 13:21:56,296 - INFO - validation batch 151, loss: 1.357, 4832/6976 datapoints
2025-03-07 13:21:56,368 - INFO - validation batch 201, loss: 1.055, 6432/6976 datapoints
2025-03-07 13:21:56,395 - INFO - Epoch 603/800 done.
2025-03-07 13:21:56,396 - INFO - Final validation performance:
Loss: 1.544, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:21:56,396 - INFO - Beginning epoch 604/800
2025-03-07 13:21:56,407 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:21:56,827 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:21:57,242 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:21:57,634 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:21:58,071 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:21:58,551 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:21:58,977 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:21:59,366 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:21:59,780 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:22:00,211 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:22:00,652 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:22:01,043 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:22:01,481 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:22:01,929 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:22:02,345 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:22:02,794 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:22:03,304 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:22:03,742 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:22:03,936 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:22:04,012 - INFO - validation batch 51, loss: 4.785, 1632/6976 datapoints
2025-03-07 13:22:04,086 - INFO - validation batch 101, loss: 0.525, 3232/6976 datapoints
2025-03-07 13:22:04,158 - INFO - validation batch 151, loss: 1.382, 4832/6976 datapoints
2025-03-07 13:22:04,233 - INFO - validation batch 201, loss: 1.076, 6432/6976 datapoints
2025-03-07 13:22:04,261 - INFO - Epoch 604/800 done.
2025-03-07 13:22:04,261 - INFO - Final validation performance:
Loss: 1.554, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:22:04,262 - INFO - Beginning epoch 605/800
2025-03-07 13:22:04,272 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:22:04,722 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:22:05,191 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:22:05,687 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:22:06,179 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:22:06,675 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:22:07,148 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:22:07,574 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:22:08,015 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:22:08,490 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:22:09,010 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:22:09,477 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:22:09,911 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:22:10,396 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:22:10,897 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:22:11,418 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 13:22:11,904 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:22:12,497 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:22:12,809 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:22:12,963 - INFO - validation batch 51, loss: 4.810, 1632/6976 datapoints
2025-03-07 13:22:13,137 - INFO - validation batch 101, loss: 0.503, 3232/6976 datapoints
2025-03-07 13:22:13,258 - INFO - validation batch 151, loss: 1.408, 4832/6976 datapoints
2025-03-07 13:22:13,406 - INFO - validation batch 201, loss: 1.093, 6432/6976 datapoints
2025-03-07 13:22:13,455 - INFO - Epoch 605/800 done.
2025-03-07 13:22:13,455 - INFO - Final validation performance:
Loss: 1.563, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:22:13,456 - INFO - Beginning epoch 606/800
2025-03-07 13:22:13,472 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:22:14,798 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:22:15,289 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:22:15,719 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:22:16,184 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:22:16,632 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:22:17,063 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:22:17,485 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:22:17,861 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:22:18,270 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:22:18,718 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:22:19,135 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:22:19,550 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:22:19,980 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:22:20,425 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:22:20,878 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 13:22:21,383 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:22:21,824 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:22:22,024 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:22:22,109 - INFO - validation batch 51, loss: 4.833, 1632/6976 datapoints
2025-03-07 13:22:22,186 - INFO - validation batch 101, loss: 0.488, 3232/6976 datapoints
2025-03-07 13:22:22,271 - INFO - validation batch 151, loss: 1.436, 4832/6976 datapoints
2025-03-07 13:22:22,382 - INFO - validation batch 201, loss: 1.114, 6432/6976 datapoints
2025-03-07 13:22:22,417 - INFO - Epoch 606/800 done.
2025-03-07 13:22:22,417 - INFO - Final validation performance:
Loss: 1.575, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:22:22,418 - INFO - Beginning epoch 607/800
2025-03-07 13:22:22,430 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:22:22,931 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:22:23,402 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:22:23,838 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:22:24,286 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:22:24,762 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:22:25,273 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:22:25,723 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:22:26,131 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:22:26,569 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:22:27,018 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:22:27,433 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:22:27,902 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:22:28,322 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:22:28,810 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:22:29,280 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 13:22:29,746 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:22:30,214 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:22:30,443 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:22:30,685 - INFO - validation batch 51, loss: 4.854, 1632/6976 datapoints
2025-03-07 13:22:30,781 - INFO - validation batch 101, loss: 0.475, 3232/6976 datapoints
2025-03-07 13:22:30,865 - INFO - validation batch 151, loss: 1.464, 4832/6976 datapoints
2025-03-07 13:22:30,968 - INFO - validation batch 201, loss: 1.132, 6432/6976 datapoints
2025-03-07 13:22:30,998 - INFO - Epoch 607/800 done.
2025-03-07 13:22:30,998 - INFO - Final validation performance:
Loss: 1.585, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:22:30,999 - INFO - Beginning epoch 608/800
2025-03-07 13:22:31,015 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:22:31,500 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:22:31,973 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:22:32,414 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:22:32,890 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:22:33,344 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:22:33,797 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:22:34,217 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:22:34,618 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:22:35,065 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:22:35,568 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:22:36,057 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:22:36,949 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:22:37,594 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:22:38,127 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:22:38,626 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 13:22:39,268 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:22:39,807 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:22:40,043 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:22:40,140 - INFO - validation batch 51, loss: 4.869, 1632/6976 datapoints
2025-03-07 13:22:40,236 - INFO - validation batch 101, loss: 0.478, 3232/6976 datapoints
2025-03-07 13:22:40,358 - INFO - validation batch 151, loss: 1.485, 4832/6976 datapoints
2025-03-07 13:22:40,472 - INFO - validation batch 201, loss: 1.143, 6432/6976 datapoints
2025-03-07 13:22:40,514 - INFO - Epoch 608/800 done.
2025-03-07 13:22:40,515 - INFO - Final validation performance:
Loss: 1.596, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:22:40,516 - INFO - Beginning epoch 609/800
2025-03-07 13:22:40,532 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:22:41,105 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:22:41,811 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:22:42,369 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:22:42,883 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:22:43,398 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:22:44,005 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:22:44,572 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:22:44,973 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:22:45,426 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:22:45,868 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:22:46,350 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:22:46,769 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:22:47,196 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:22:47,628 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:22:48,088 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 13:22:48,502 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:22:48,950 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:22:49,151 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 13:22:49,240 - INFO - validation batch 51, loss: 4.861, 1632/6976 datapoints
2025-03-07 13:22:49,326 - INFO - validation batch 101, loss: 0.476, 3232/6976 datapoints
2025-03-07 13:22:49,430 - INFO - validation batch 151, loss: 1.507, 4832/6976 datapoints
2025-03-07 13:22:49,523 - INFO - validation batch 201, loss: 1.151, 6432/6976 datapoints
2025-03-07 13:22:49,561 - INFO - Epoch 609/800 done.
2025-03-07 13:22:49,561 - INFO - Final validation performance:
Loss: 1.600, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:22:49,562 - INFO - Beginning epoch 610/800
2025-03-07 13:22:49,581 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:22:50,057 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:22:50,498 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:22:50,926 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:22:51,368 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:22:51,857 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:22:52,367 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:22:52,795 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:22:53,152 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:22:53,548 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:22:53,947 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:22:54,332 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:22:54,724 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:22:55,135 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:22:55,547 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:22:55,944 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 13:22:56,359 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:22:56,740 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:22:56,934 - INFO - validation batch 1, loss: 0.008, 32/6976 datapoints
2025-03-07 13:22:57,018 - INFO - validation batch 51, loss: 4.864, 1632/6976 datapoints
2025-03-07 13:22:57,096 - INFO - validation batch 101, loss: 0.478, 3232/6976 datapoints
2025-03-07 13:22:57,174 - INFO - validation batch 151, loss: 1.518, 4832/6976 datapoints
2025-03-07 13:22:57,247 - INFO - validation batch 201, loss: 1.162, 6432/6976 datapoints
2025-03-07 13:22:57,270 - INFO - Epoch 610/800 done.
2025-03-07 13:22:57,270 - INFO - Final validation performance:
Loss: 1.606, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:22:57,270 - INFO - Beginning epoch 611/800
2025-03-07 13:22:57,280 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:22:57,699 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:22:58,146 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:22:58,549 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:22:58,951 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:22:59,375 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:22:59,815 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:23:00,208 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:23:00,571 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:23:00,966 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:23:01,361 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:23:01,764 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:23:02,172 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:23:02,587 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:23:03,038 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:23:03,445 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 13:23:03,941 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:23:04,412 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:23:04,633 - INFO - validation batch 1, loss: 0.012, 32/6976 datapoints
2025-03-07 13:23:04,730 - INFO - validation batch 51, loss: 4.862, 1632/6976 datapoints
2025-03-07 13:23:04,835 - INFO - validation batch 101, loss: 0.491, 3232/6976 datapoints
2025-03-07 13:23:04,936 - INFO - validation batch 151, loss: 1.530, 4832/6976 datapoints
2025-03-07 13:23:05,049 - INFO - validation batch 201, loss: 1.179, 6432/6976 datapoints
2025-03-07 13:23:05,083 - INFO - Epoch 611/800 done.
2025-03-07 13:23:05,083 - INFO - Final validation performance:
Loss: 1.615, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:23:05,084 - INFO - Beginning epoch 612/800
2025-03-07 13:23:05,097 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:23:05,662 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:23:06,155 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:23:06,628 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:23:07,093 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:23:07,588 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:23:08,135 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:23:08,752 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:23:09,295 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:23:09,741 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:23:10,192 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:23:10,633 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:23:11,083 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:23:11,631 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:23:12,132 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:23:12,574 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 13:23:13,086 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:23:13,570 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:23:13,797 - INFO - validation batch 1, loss: 0.015, 32/6976 datapoints
2025-03-07 13:23:13,896 - INFO - validation batch 51, loss: 4.836, 1632/6976 datapoints
2025-03-07 13:23:14,023 - INFO - validation batch 101, loss: 0.505, 3232/6976 datapoints
2025-03-07 13:23:14,132 - INFO - validation batch 151, loss: 1.535, 4832/6976 datapoints
2025-03-07 13:23:14,228 - INFO - validation batch 201, loss: 1.163, 6432/6976 datapoints
2025-03-07 13:23:14,265 - INFO - Epoch 612/800 done.
2025-03-07 13:23:14,265 - INFO - Final validation performance:
Loss: 1.611, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:23:14,266 - INFO - Beginning epoch 613/800
2025-03-07 13:23:14,277 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:23:14,780 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:23:15,219 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:23:15,635 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:23:16,049 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:23:16,518 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:23:16,950 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:23:17,337 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:23:17,711 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:23:18,116 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:23:18,507 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:23:18,900 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:23:19,309 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:23:19,716 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:23:20,128 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:23:20,524 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:23:20,938 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:23:21,316 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:23:21,502 - INFO - validation batch 1, loss: 0.014, 32/6976 datapoints
2025-03-07 13:23:21,578 - INFO - validation batch 51, loss: 4.846, 1632/6976 datapoints
2025-03-07 13:23:21,649 - INFO - validation batch 101, loss: 0.482, 3232/6976 datapoints
2025-03-07 13:23:21,720 - INFO - validation batch 151, loss: 1.496, 4832/6976 datapoints
2025-03-07 13:23:21,794 - INFO - validation batch 201, loss: 1.130, 6432/6976 datapoints
2025-03-07 13:23:21,817 - INFO - Epoch 613/800 done.
2025-03-07 13:23:21,817 - INFO - Final validation performance:
Loss: 1.594, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:23:21,818 - INFO - Beginning epoch 614/800
2025-03-07 13:23:21,828 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:23:22,262 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:23:22,694 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:23:23,088 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:23:23,485 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:23:23,913 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:23:24,351 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:23:24,744 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:23:25,123 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:23:25,528 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:23:25,978 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:23:26,406 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:23:26,852 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:23:27,292 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:23:27,812 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:23:28,244 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:23:28,673 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:23:29,090 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:23:29,291 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:23:29,369 - INFO - validation batch 51, loss: 4.878, 1632/6976 datapoints
2025-03-07 13:23:29,444 - INFO - validation batch 101, loss: 0.406, 3232/6976 datapoints
2025-03-07 13:23:29,542 - INFO - validation batch 151, loss: 1.425, 4832/6976 datapoints
2025-03-07 13:23:29,629 - INFO - validation batch 201, loss: 1.108, 6432/6976 datapoints
2025-03-07 13:23:29,661 - INFO - Epoch 614/800 done.
2025-03-07 13:23:29,661 - INFO - Final validation performance:
Loss: 1.564, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:23:29,661 - INFO - Beginning epoch 615/800
2025-03-07 13:23:29,673 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:23:30,111 - INFO - training batch 51, loss: 0.119, 1632/28000 datapoints
2025-03-07 13:23:30,619 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:23:31,059 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:23:31,472 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:23:31,931 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:23:32,391 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:23:32,807 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:23:33,192 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:23:33,564 - INFO - training batch 451, loss: 0.124, 14432/28000 datapoints
2025-03-07 13:23:34,005 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:23:34,410 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:23:34,820 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:23:35,231 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:23:35,651 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:23:36,069 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:23:36,511 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:23:36,973 - INFO - training batch 851, loss: 0.004, 27232/28000 datapoints
2025-03-07 13:23:37,177 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:23:37,248 - INFO - validation batch 51, loss: 5.039, 1632/6976 datapoints
2025-03-07 13:23:37,323 - INFO - validation batch 101, loss: 0.425, 3232/6976 datapoints
2025-03-07 13:23:37,401 - INFO - validation batch 151, loss: 1.062, 4832/6976 datapoints
2025-03-07 13:23:37,476 - INFO - validation batch 201, loss: 1.385, 6432/6976 datapoints
2025-03-07 13:23:37,504 - INFO - Epoch 615/800 done.
2025-03-07 13:23:37,504 - INFO - Final validation performance:
Loss: 1.583, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:23:37,504 - INFO - Beginning epoch 616/800
2025-03-07 13:23:37,517 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:23:37,943 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:23:38,361 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:23:38,805 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:23:39,223 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:23:39,674 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:23:40,063 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:23:40,454 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:23:40,925 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:23:41,402 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:23:41,931 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:23:42,455 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:23:43,015 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:23:43,502 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:23:44,010 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:23:44,467 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:23:44,942 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:23:45,358 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:23:45,581 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:23:45,671 - INFO - validation batch 51, loss: 5.196, 1632/6976 datapoints
2025-03-07 13:23:45,749 - INFO - validation batch 101, loss: 0.095, 3232/6976 datapoints
2025-03-07 13:23:45,826 - INFO - validation batch 151, loss: 0.911, 4832/6976 datapoints
2025-03-07 13:23:45,902 - INFO - validation batch 201, loss: 1.207, 6432/6976 datapoints
2025-03-07 13:23:45,928 - INFO - Epoch 616/800 done.
2025-03-07 13:23:45,929 - INFO - Final validation performance:
Loss: 1.482, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:23:45,929 - INFO - Beginning epoch 617/800
2025-03-07 13:23:45,943 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:23:46,352 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:23:46,770 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:23:47,224 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:23:47,734 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:23:48,251 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:23:48,739 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:23:49,206 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:23:49,638 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:23:50,087 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:23:50,517 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:23:50,938 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:23:51,377 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:23:51,803 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:23:52,215 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:23:52,703 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:23:53,165 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:23:53,602 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:23:53,826 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:23:53,915 - INFO - validation batch 51, loss: 5.189, 1632/6976 datapoints
2025-03-07 13:23:54,004 - INFO - validation batch 101, loss: 0.106, 3232/6976 datapoints
2025-03-07 13:23:54,096 - INFO - validation batch 151, loss: 0.931, 4832/6976 datapoints
2025-03-07 13:23:54,187 - INFO - validation batch 201, loss: 1.227, 6432/6976 datapoints
2025-03-07 13:23:54,217 - INFO - Epoch 617/800 done.
2025-03-07 13:23:54,217 - INFO - Final validation performance:
Loss: 1.491, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:23:54,218 - INFO - Beginning epoch 618/800
2025-03-07 13:23:54,230 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:23:54,683 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:23:55,137 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:23:55,583 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:23:56,061 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:23:56,580 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:23:57,031 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:23:57,468 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:23:57,889 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:23:58,303 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:23:58,714 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:23:59,123 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:23:59,555 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:23:59,981 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:24:00,423 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:24:00,868 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:24:01,323 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:24:01,756 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:24:01,971 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:24:02,057 - INFO - validation batch 51, loss: 5.182, 1632/6976 datapoints
2025-03-07 13:24:02,140 - INFO - validation batch 101, loss: 0.117, 3232/6976 datapoints
2025-03-07 13:24:02,227 - INFO - validation batch 151, loss: 0.947, 4832/6976 datapoints
2025-03-07 13:24:02,308 - INFO - validation batch 201, loss: 1.238, 6432/6976 datapoints
2025-03-07 13:24:02,346 - INFO - Epoch 618/800 done.
2025-03-07 13:24:02,346 - INFO - Final validation performance:
Loss: 1.497, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:24:02,347 - INFO - Beginning epoch 619/800
2025-03-07 13:24:02,359 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:24:02,840 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:24:03,650 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:24:04,184 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:24:04,713 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:24:05,214 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:24:05,708 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:24:06,156 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:24:06,584 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:24:07,038 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:24:07,618 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:24:08,168 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:24:08,668 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:24:09,179 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:24:09,687 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:24:10,205 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:24:10,731 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:24:11,194 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:24:11,424 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:24:11,534 - INFO - validation batch 51, loss: 5.173, 1632/6976 datapoints
2025-03-07 13:24:11,632 - INFO - validation batch 101, loss: 0.125, 3232/6976 datapoints
2025-03-07 13:24:11,730 - INFO - validation batch 151, loss: 0.962, 4832/6976 datapoints
2025-03-07 13:24:11,826 - INFO - validation batch 201, loss: 1.244, 6432/6976 datapoints
2025-03-07 13:24:11,861 - INFO - Epoch 619/800 done.
2025-03-07 13:24:11,861 - INFO - Final validation performance:
Loss: 1.501, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:24:11,862 - INFO - Beginning epoch 620/800
2025-03-07 13:24:11,875 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:24:12,383 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:24:12,880 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:24:13,301 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:24:13,744 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:24:14,186 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:24:14,611 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:24:15,005 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:24:15,377 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:24:15,768 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:24:16,167 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:24:16,558 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:24:16,952 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:24:17,358 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:24:17,763 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:24:18,169 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:24:18,585 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:24:18,967 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:24:19,157 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:24:19,253 - INFO - validation batch 51, loss: 5.162, 1632/6976 datapoints
2025-03-07 13:24:19,329 - INFO - validation batch 101, loss: 0.132, 3232/6976 datapoints
2025-03-07 13:24:19,404 - INFO - validation batch 151, loss: 0.977, 4832/6976 datapoints
2025-03-07 13:24:19,478 - INFO - validation batch 201, loss: 1.246, 6432/6976 datapoints
2025-03-07 13:24:19,506 - INFO - Epoch 620/800 done.
2025-03-07 13:24:19,506 - INFO - Final validation performance:
Loss: 1.504, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:24:19,506 - INFO - Beginning epoch 621/800
2025-03-07 13:24:19,517 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:24:19,912 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:24:20,336 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:24:20,745 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:24:21,161 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:24:21,604 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:24:22,090 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:24:22,516 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:24:22,978 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:24:23,430 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:24:23,875 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:24:24,302 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:24:24,730 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:24:25,191 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:24:25,638 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:24:26,067 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:24:26,494 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:24:26,926 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:24:27,121 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:24:27,197 - INFO - validation batch 51, loss: 5.149, 1632/6976 datapoints
2025-03-07 13:24:27,270 - INFO - validation batch 101, loss: 0.138, 3232/6976 datapoints
2025-03-07 13:24:27,342 - INFO - validation batch 151, loss: 0.992, 4832/6976 datapoints
2025-03-07 13:24:27,417 - INFO - validation batch 201, loss: 1.247, 6432/6976 datapoints
2025-03-07 13:24:27,444 - INFO - Epoch 621/800 done.
2025-03-07 13:24:27,444 - INFO - Final validation performance:
Loss: 1.506, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:24:27,445 - INFO - Beginning epoch 622/800
2025-03-07 13:24:27,455 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:24:27,862 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:24:28,259 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:24:28,658 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:24:29,070 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:24:29,503 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:24:29,927 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:24:30,327 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:24:30,830 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:24:31,211 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:24:31,614 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:24:32,007 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:24:32,397 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:24:32,885 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:24:33,294 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:24:33,703 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:24:34,124 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:24:34,512 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:24:34,705 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:24:34,774 - INFO - validation batch 51, loss: 5.136, 1632/6976 datapoints
2025-03-07 13:24:34,841 - INFO - validation batch 101, loss: 0.143, 3232/6976 datapoints
2025-03-07 13:24:34,907 - INFO - validation batch 151, loss: 1.009, 4832/6976 datapoints
2025-03-07 13:24:34,973 - INFO - validation batch 201, loss: 1.246, 6432/6976 datapoints
2025-03-07 13:24:34,997 - INFO - Epoch 622/800 done.
2025-03-07 13:24:34,997 - INFO - Final validation performance:
Loss: 1.507, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:24:34,998 - INFO - Beginning epoch 623/800
2025-03-07 13:24:35,009 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:24:35,443 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:24:35,865 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:24:36,265 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:24:36,746 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:24:37,209 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:24:37,684 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:24:38,233 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:24:38,681 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:24:39,086 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:24:39,547 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:24:39,967 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:24:40,374 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:24:40,844 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:24:41,293 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:24:41,795 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:24:42,298 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:24:42,730 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:24:42,959 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:24:43,034 - INFO - validation batch 51, loss: 5.123, 1632/6976 datapoints
2025-03-07 13:24:43,110 - INFO - validation batch 101, loss: 0.148, 3232/6976 datapoints
2025-03-07 13:24:43,182 - INFO - validation batch 151, loss: 1.026, 4832/6976 datapoints
2025-03-07 13:24:43,256 - INFO - validation batch 201, loss: 1.245, 6432/6976 datapoints
2025-03-07 13:24:43,281 - INFO - Epoch 623/800 done.
2025-03-07 13:24:43,281 - INFO - Final validation performance:
Loss: 1.509, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:24:43,281 - INFO - Beginning epoch 624/800
2025-03-07 13:24:43,293 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:24:43,734 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:24:44,170 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:24:44,579 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:24:44,996 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:24:45,430 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:24:45,887 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:24:46,274 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:24:46,646 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:24:47,035 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:24:47,429 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:24:47,877 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:24:48,289 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:24:48,689 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:24:49,087 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:24:49,501 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:24:49,920 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:24:50,304 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:24:50,492 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:24:50,570 - INFO - validation batch 51, loss: 5.112, 1632/6976 datapoints
2025-03-07 13:24:50,643 - INFO - validation batch 101, loss: 0.154, 3232/6976 datapoints
2025-03-07 13:24:50,715 - INFO - validation batch 151, loss: 1.045, 4832/6976 datapoints
2025-03-07 13:24:50,791 - INFO - validation batch 201, loss: 1.243, 6432/6976 datapoints
2025-03-07 13:24:50,816 - INFO - Epoch 624/800 done.
2025-03-07 13:24:50,816 - INFO - Final validation performance:
Loss: 1.511, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:24:50,817 - INFO - Beginning epoch 625/800
2025-03-07 13:24:50,826 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:24:51,234 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:24:51,643 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:24:52,086 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:24:52,547 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:24:53,012 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:24:53,439 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:24:53,838 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:24:54,204 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:24:54,598 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:24:54,999 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:24:55,391 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:24:55,830 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:24:56,236 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:24:56,644 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:24:57,055 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:24:57,483 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:24:57,904 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:24:58,111 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:24:58,185 - INFO - validation batch 51, loss: 5.102, 1632/6976 datapoints
2025-03-07 13:24:58,274 - INFO - validation batch 101, loss: 0.160, 3232/6976 datapoints
2025-03-07 13:24:58,359 - INFO - validation batch 151, loss: 1.066, 4832/6976 datapoints
2025-03-07 13:24:58,434 - INFO - validation batch 201, loss: 1.241, 6432/6976 datapoints
2025-03-07 13:24:58,462 - INFO - Epoch 625/800 done.
2025-03-07 13:24:58,462 - INFO - Final validation performance:
Loss: 1.514, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:24:58,463 - INFO - Beginning epoch 626/800
2025-03-07 13:24:58,473 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:24:58,902 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:24:59,365 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:24:59,806 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:25:00,234 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:25:00,692 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:25:01,123 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:25:01,519 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:25:01,896 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:25:02,280 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:25:02,678 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:25:03,110 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:25:03,506 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:25:03,962 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:25:04,396 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:25:04,817 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:25:05,230 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:25:05,616 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:25:05,806 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:25:05,881 - INFO - validation batch 51, loss: 5.093, 1632/6976 datapoints
2025-03-07 13:25:05,954 - INFO - validation batch 101, loss: 0.167, 3232/6976 datapoints
2025-03-07 13:25:06,024 - INFO - validation batch 151, loss: 1.088, 4832/6976 datapoints
2025-03-07 13:25:06,097 - INFO - validation batch 201, loss: 1.237, 6432/6976 datapoints
2025-03-07 13:25:06,120 - INFO - Epoch 626/800 done.
2025-03-07 13:25:06,120 - INFO - Final validation performance:
Loss: 1.518, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:25:06,121 - INFO - Beginning epoch 627/800
2025-03-07 13:25:06,131 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:25:06,542 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:25:06,995 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:25:07,400 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:25:07,816 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:25:08,249 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:25:08,669 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:25:09,061 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:25:09,428 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:25:09,817 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:25:10,216 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:25:10,611 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:25:11,003 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:25:11,404 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:25:11,806 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:25:12,210 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:25:12,625 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:25:13,008 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:25:13,213 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:25:13,302 - INFO - validation batch 51, loss: 5.086, 1632/6976 datapoints
2025-03-07 13:25:13,384 - INFO - validation batch 101, loss: 0.174, 3232/6976 datapoints
2025-03-07 13:25:13,463 - INFO - validation batch 151, loss: 1.112, 4832/6976 datapoints
2025-03-07 13:25:13,541 - INFO - validation batch 201, loss: 1.232, 6432/6976 datapoints
2025-03-07 13:25:13,567 - INFO - Epoch 627/800 done.
2025-03-07 13:25:13,568 - INFO - Final validation performance:
Loss: 1.521, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:25:13,568 - INFO - Beginning epoch 628/800
2025-03-07 13:25:13,578 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:25:13,986 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:25:14,393 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:25:14,793 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:25:15,196 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:25:15,635 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:25:16,072 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:25:16,460 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:25:16,844 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:25:17,226 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:25:17,622 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:25:18,019 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:25:18,421 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:25:18,827 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:25:19,225 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:25:19,634 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:25:20,050 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:25:20,447 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:25:20,682 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:25:20,777 - INFO - validation batch 51, loss: 5.078, 1632/6976 datapoints
2025-03-07 13:25:20,875 - INFO - validation batch 101, loss: 0.180, 3232/6976 datapoints
2025-03-07 13:25:20,971 - INFO - validation batch 151, loss: 1.136, 4832/6976 datapoints
2025-03-07 13:25:21,071 - INFO - validation batch 201, loss: 1.225, 6432/6976 datapoints
2025-03-07 13:25:21,106 - INFO - Epoch 628/800 done.
2025-03-07 13:25:21,106 - INFO - Final validation performance:
Loss: 1.524, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:25:21,107 - INFO - Beginning epoch 629/800
2025-03-07 13:25:21,119 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:25:21,583 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:25:22,036 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:25:22,567 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:25:23,001 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:25:23,481 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:25:23,914 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:25:24,309 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:25:24,703 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:25:25,089 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:25:25,498 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:25:25,895 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:25:26,293 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:25:26,696 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:25:27,096 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:25:27,496 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:25:27,923 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:25:28,307 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:25:28,493 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:25:28,580 - INFO - validation batch 51, loss: 5.070, 1632/6976 datapoints
2025-03-07 13:25:28,656 - INFO - validation batch 101, loss: 0.186, 3232/6976 datapoints
2025-03-07 13:25:28,728 - INFO - validation batch 151, loss: 1.161, 4832/6976 datapoints
2025-03-07 13:25:28,801 - INFO - validation batch 201, loss: 1.217, 6432/6976 datapoints
2025-03-07 13:25:28,825 - INFO - Epoch 629/800 done.
2025-03-07 13:25:28,825 - INFO - Final validation performance:
Loss: 1.527, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:25:28,826 - INFO - Beginning epoch 630/800
2025-03-07 13:25:28,837 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:25:29,252 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:25:29,670 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:25:30,076 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:25:30,490 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:25:31,044 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:25:31,531 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:25:31,947 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:25:32,328 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:25:32,731 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:25:33,138 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:25:33,554 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:25:33,950 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:25:34,366 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:25:34,797 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:25:35,203 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:25:35,615 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:25:35,993 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:25:36,189 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:25:36,263 - INFO - validation batch 51, loss: 5.062, 1632/6976 datapoints
2025-03-07 13:25:36,337 - INFO - validation batch 101, loss: 0.193, 3232/6976 datapoints
2025-03-07 13:25:36,412 - INFO - validation batch 151, loss: 1.185, 4832/6976 datapoints
2025-03-07 13:25:36,486 - INFO - validation batch 201, loss: 1.210, 6432/6976 datapoints
2025-03-07 13:25:36,512 - INFO - Epoch 630/800 done.
2025-03-07 13:25:36,512 - INFO - Final validation performance:
Loss: 1.530, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:25:36,513 - INFO - Beginning epoch 631/800
2025-03-07 13:25:36,526 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:25:36,937 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:25:37,341 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:25:37,745 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:25:38,154 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:25:38,592 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:25:39,016 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:25:39,406 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:25:39,780 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:25:40,167 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:25:40,567 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:25:40,954 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:25:41,345 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:25:41,768 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:25:42,189 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:25:42,599 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:25:43,018 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:25:43,402 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:25:43,609 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:25:43,686 - INFO - validation batch 51, loss: 5.052, 1632/6976 datapoints
2025-03-07 13:25:43,767 - INFO - validation batch 101, loss: 0.201, 3232/6976 datapoints
2025-03-07 13:25:43,841 - INFO - validation batch 151, loss: 1.209, 4832/6976 datapoints
2025-03-07 13:25:43,914 - INFO - validation batch 201, loss: 1.205, 6432/6976 datapoints
2025-03-07 13:25:43,940 - INFO - Epoch 631/800 done.
2025-03-07 13:25:43,940 - INFO - Final validation performance:
Loss: 1.534, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:25:43,941 - INFO - Beginning epoch 632/800
2025-03-07 13:25:43,952 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:25:44,359 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:25:44,794 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:25:45,222 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:25:45,682 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:25:46,177 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:25:46,638 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:25:47,158 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:25:47,634 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:25:48,074 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:25:48,494 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:25:48,913 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:25:49,300 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:25:49,745 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:25:50,150 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:25:50,557 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:25:51,010 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:25:51,399 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:25:51,623 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:25:51,702 - INFO - validation batch 51, loss: 5.043, 1632/6976 datapoints
2025-03-07 13:25:51,775 - INFO - validation batch 101, loss: 0.213, 3232/6976 datapoints
2025-03-07 13:25:51,850 - INFO - validation batch 151, loss: 1.233, 4832/6976 datapoints
2025-03-07 13:25:51,932 - INFO - validation batch 201, loss: 1.203, 6432/6976 datapoints
2025-03-07 13:25:51,961 - INFO - Epoch 632/800 done.
2025-03-07 13:25:51,961 - INFO - Final validation performance:
Loss: 1.539, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:25:51,961 - INFO - Beginning epoch 633/800
2025-03-07 13:25:51,972 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:25:52,388 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:25:52,808 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:25:53,247 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:25:53,752 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:25:54,199 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:25:54,629 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:25:55,057 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:25:55,421 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:25:55,814 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:25:56,213 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:25:56,608 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:25:57,002 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:25:57,402 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:25:57,852 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:25:58,367 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:25:58,787 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:25:59,176 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:25:59,404 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:25:59,476 - INFO - validation batch 51, loss: 5.035, 1632/6976 datapoints
2025-03-07 13:25:59,553 - INFO - validation batch 101, loss: 0.226, 3232/6976 datapoints
2025-03-07 13:25:59,628 - INFO - validation batch 151, loss: 1.256, 4832/6976 datapoints
2025-03-07 13:25:59,699 - INFO - validation batch 201, loss: 1.205, 6432/6976 datapoints
2025-03-07 13:25:59,722 - INFO - Epoch 633/800 done.
2025-03-07 13:25:59,722 - INFO - Final validation performance:
Loss: 1.545, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:25:59,723 - INFO - Beginning epoch 634/800
2025-03-07 13:25:59,734 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:26:00,136 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:26:00,552 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:26:00,951 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:26:01,371 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:26:01,826 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:26:02,254 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:26:02,673 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:26:03,070 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:26:03,588 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:26:04,170 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:26:04,815 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:26:05,411 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:26:05,985 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:26:06,527 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:26:07,052 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:26:07,553 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:26:07,964 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:26:08,159 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:26:08,237 - INFO - validation batch 51, loss: 5.030, 1632/6976 datapoints
2025-03-07 13:26:08,315 - INFO - validation batch 101, loss: 0.240, 3232/6976 datapoints
2025-03-07 13:26:08,392 - INFO - validation batch 151, loss: 1.278, 4832/6976 datapoints
2025-03-07 13:26:08,467 - INFO - validation batch 201, loss: 1.212, 6432/6976 datapoints
2025-03-07 13:26:08,492 - INFO - Epoch 634/800 done.
2025-03-07 13:26:08,493 - INFO - Final validation performance:
Loss: 1.553, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:26:08,493 - INFO - Beginning epoch 635/800
2025-03-07 13:26:08,505 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:26:08,923 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:26:09,351 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:26:09,792 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:26:10,240 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:26:10,762 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:26:11,236 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:26:11,735 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:26:12,150 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:26:12,586 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:26:13,014 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:26:13,432 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:26:13,919 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:26:14,395 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:26:14,881 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:26:15,326 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:26:15,862 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:26:16,283 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:26:16,525 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:26:16,625 - INFO - validation batch 51, loss: 5.025, 1632/6976 datapoints
2025-03-07 13:26:16,733 - INFO - validation batch 101, loss: 0.255, 3232/6976 datapoints
2025-03-07 13:26:16,826 - INFO - validation batch 151, loss: 1.297, 4832/6976 datapoints
2025-03-07 13:26:16,920 - INFO - validation batch 201, loss: 1.221, 6432/6976 datapoints
2025-03-07 13:26:16,955 - INFO - Epoch 635/800 done.
2025-03-07 13:26:16,955 - INFO - Final validation performance:
Loss: 1.560, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:26:16,956 - INFO - Beginning epoch 636/800
2025-03-07 13:26:16,968 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:26:17,459 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:26:17,929 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:26:18,401 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:26:18,889 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:26:19,480 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:26:20,014 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:26:20,548 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:26:21,176 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:26:21,738 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:26:22,217 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:26:22,702 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:26:23,133 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:26:23,589 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:26:24,106 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:26:24,593 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:26:25,074 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:26:25,538 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:26:25,779 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:26:25,873 - INFO - validation batch 51, loss: 5.026, 1632/6976 datapoints
2025-03-07 13:26:25,961 - INFO - validation batch 101, loss: 0.271, 3232/6976 datapoints
2025-03-07 13:26:26,039 - INFO - validation batch 151, loss: 1.315, 4832/6976 datapoints
2025-03-07 13:26:26,116 - INFO - validation batch 201, loss: 1.229, 6432/6976 datapoints
2025-03-07 13:26:26,145 - INFO - Epoch 636/800 done.
2025-03-07 13:26:26,145 - INFO - Final validation performance:
Loss: 1.569, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:26:26,146 - INFO - Beginning epoch 637/800
2025-03-07 13:26:26,157 - INFO - training batch 1, loss: -0.000, 32/28000 datapoints
2025-03-07 13:26:26,586 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:26:27,027 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:26:27,449 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:26:27,897 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:26:28,362 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:26:28,820 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:26:29,259 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:26:29,675 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:26:30,132 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:26:30,650 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:26:31,096 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:26:31,539 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:26:31,960 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:26:32,375 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:26:32,802 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:26:33,234 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:26:33,617 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:26:33,803 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:26:33,877 - INFO - validation batch 51, loss: 5.030, 1632/6976 datapoints
2025-03-07 13:26:33,951 - INFO - validation batch 101, loss: 0.286, 3232/6976 datapoints
2025-03-07 13:26:34,051 - INFO - validation batch 151, loss: 1.332, 4832/6976 datapoints
2025-03-07 13:26:34,127 - INFO - validation batch 201, loss: 1.235, 6432/6976 datapoints
2025-03-07 13:26:34,154 - INFO - Epoch 637/800 done.
2025-03-07 13:26:34,154 - INFO - Final validation performance:
Loss: 1.577, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:26:34,155 - INFO - Beginning epoch 638/800
2025-03-07 13:26:34,164 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:26:34,566 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:26:34,985 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:26:35,387 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:26:35,841 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:26:36,287 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:26:36,714 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:26:37,102 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:26:37,475 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:26:37,876 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:26:38,308 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:26:38,766 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:26:39,184 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:26:39,588 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:26:39,996 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:26:40,409 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:26:40,879 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:26:41,402 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:26:41,651 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:26:41,794 - INFO - validation batch 51, loss: 5.030, 1632/6976 datapoints
2025-03-07 13:26:41,918 - INFO - validation batch 101, loss: 0.302, 3232/6976 datapoints
2025-03-07 13:26:42,011 - INFO - validation batch 151, loss: 1.351, 4832/6976 datapoints
2025-03-07 13:26:42,102 - INFO - validation batch 201, loss: 1.233, 6432/6976 datapoints
2025-03-07 13:26:42,128 - INFO - Epoch 638/800 done.
2025-03-07 13:26:42,128 - INFO - Final validation performance:
Loss: 1.584, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:26:42,129 - INFO - Beginning epoch 639/800
2025-03-07 13:26:42,142 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:26:42,594 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:26:43,054 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:26:43,557 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:26:44,147 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:26:44,768 - INFO - training batch 251, loss: -0.000, 8032/28000 datapoints
2025-03-07 13:26:45,339 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:26:45,853 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:26:46,367 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:26:46,895 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:26:47,421 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:26:47,921 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:26:48,377 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:26:48,874 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:26:49,367 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:26:49,825 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:26:50,254 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:26:50,718 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:26:50,936 - INFO - validation batch 1, loss: 0.007, 32/6976 datapoints
2025-03-07 13:26:51,018 - INFO - validation batch 51, loss: 5.035, 1632/6976 datapoints
2025-03-07 13:26:51,113 - INFO - validation batch 101, loss: 0.323, 3232/6976 datapoints
2025-03-07 13:26:51,206 - INFO - validation batch 151, loss: 1.368, 4832/6976 datapoints
2025-03-07 13:26:51,328 - INFO - validation batch 201, loss: 1.230, 6432/6976 datapoints
2025-03-07 13:26:51,366 - INFO - Epoch 639/800 done.
2025-03-07 13:26:51,366 - INFO - Final validation performance:
Loss: 1.592, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:26:51,366 - INFO - Beginning epoch 640/800
2025-03-07 13:26:51,377 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:26:51,838 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:26:52,314 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:26:52,825 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:26:53,301 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:26:53,803 - INFO - training batch 251, loss: -0.000, 8032/28000 datapoints
2025-03-07 13:26:54,439 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:26:54,923 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:26:55,377 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:26:55,810 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:26:56,241 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:26:56,760 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:26:57,245 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:26:57,770 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:26:58,389 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:26:59,065 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:26:59,621 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:27:00,102 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:27:00,363 - INFO - validation batch 1, loss: 0.009, 32/6976 datapoints
2025-03-07 13:27:00,468 - INFO - validation batch 51, loss: 5.032, 1632/6976 datapoints
2025-03-07 13:27:00,562 - INFO - validation batch 101, loss: 0.351, 3232/6976 datapoints
2025-03-07 13:27:00,643 - INFO - validation batch 151, loss: 1.389, 4832/6976 datapoints
2025-03-07 13:27:00,724 - INFO - validation batch 201, loss: 1.220, 6432/6976 datapoints
2025-03-07 13:27:00,753 - INFO - Epoch 640/800 done.
2025-03-07 13:27:00,754 - INFO - Final validation performance:
Loss: 1.600, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:27:00,754 - INFO - Beginning epoch 641/800
2025-03-07 13:27:00,765 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:27:01,228 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:27:01,678 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:27:02,108 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:27:02,521 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:27:02,972 - INFO - training batch 251, loss: -0.000, 8032/28000 datapoints
2025-03-07 13:27:03,444 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:27:03,916 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:27:04,294 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:27:04,710 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:27:05,155 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:27:05,603 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:27:06,017 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:27:06,427 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:27:06,833 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:27:07,235 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:27:07,647 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:27:08,045 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:27:08,235 - INFO - validation batch 1, loss: 0.008, 32/6976 datapoints
2025-03-07 13:27:08,307 - INFO - validation batch 51, loss: 5.031, 1632/6976 datapoints
2025-03-07 13:27:08,377 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-07 13:27:08,449 - INFO - validation batch 151, loss: 1.400, 4832/6976 datapoints
2025-03-07 13:27:08,524 - INFO - validation batch 201, loss: 1.204, 6432/6976 datapoints
2025-03-07 13:27:08,552 - INFO - Epoch 641/800 done.
2025-03-07 13:27:08,552 - INFO - Final validation performance:
Loss: 1.601, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:27:08,553 - INFO - Beginning epoch 642/800
2025-03-07 13:27:08,562 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:27:08,959 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:27:09,380 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:27:09,803 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:27:10,215 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:27:10,709 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:27:11,205 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:27:11,676 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:27:12,052 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:27:12,459 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:27:12,908 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:27:13,379 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:27:13,866 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:27:14,418 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:27:14,904 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:27:15,348 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:27:15,806 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:27:16,252 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:27:16,501 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 13:27:16,591 - INFO - validation batch 51, loss: 4.998, 1632/6976 datapoints
2025-03-07 13:27:16,681 - INFO - validation batch 101, loss: 0.389, 3232/6976 datapoints
2025-03-07 13:27:16,783 - INFO - validation batch 151, loss: 1.427, 4832/6976 datapoints
2025-03-07 13:27:16,871 - INFO - validation batch 201, loss: 1.200, 6432/6976 datapoints
2025-03-07 13:27:16,906 - INFO - Epoch 642/800 done.
2025-03-07 13:27:16,906 - INFO - Final validation performance:
Loss: 1.605, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:27:16,907 - INFO - Beginning epoch 643/800
2025-03-07 13:27:16,920 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:27:17,440 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:27:17,964 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:27:18,556 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:27:19,091 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:27:19,586 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:27:20,087 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:27:20,553 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:27:20,965 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:27:21,432 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:27:21,856 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:27:22,297 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:27:22,775 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:27:23,218 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:27:23,658 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:27:24,090 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:27:24,571 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:27:25,014 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:27:25,223 - INFO - validation batch 1, loss: 0.012, 32/6976 datapoints
2025-03-07 13:27:25,297 - INFO - validation batch 51, loss: 4.985, 1632/6976 datapoints
2025-03-07 13:27:25,384 - INFO - validation batch 101, loss: 0.404, 3232/6976 datapoints
2025-03-07 13:27:25,470 - INFO - validation batch 151, loss: 1.462, 4832/6976 datapoints
2025-03-07 13:27:25,549 - INFO - validation batch 201, loss: 1.181, 6432/6976 datapoints
2025-03-07 13:27:25,574 - INFO - Epoch 643/800 done.
2025-03-07 13:27:25,574 - INFO - Final validation performance:
Loss: 1.609, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:27:25,575 - INFO - Beginning epoch 644/800
2025-03-07 13:27:25,585 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:27:26,046 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:27:26,500 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:27:26,939 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:27:27,376 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:27:27,842 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:27:28,309 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:27:28,773 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:27:29,180 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:27:29,649 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:27:30,099 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:27:30,595 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:27:31,356 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:27:31,912 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:27:32,430 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:27:32,936 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:27:33,452 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:27:33,948 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:27:34,184 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 13:27:34,283 - INFO - validation batch 51, loss: 4.951, 1632/6976 datapoints
2025-03-07 13:27:34,360 - INFO - validation batch 101, loss: 0.415, 3232/6976 datapoints
2025-03-07 13:27:34,436 - INFO - validation batch 151, loss: 1.469, 4832/6976 datapoints
2025-03-07 13:27:34,512 - INFO - validation batch 201, loss: 1.186, 6432/6976 datapoints
2025-03-07 13:27:34,539 - INFO - Epoch 644/800 done.
2025-03-07 13:27:34,540 - INFO - Final validation performance:
Loss: 1.606, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:27:34,540 - INFO - Beginning epoch 645/800
2025-03-07 13:27:34,551 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:27:35,002 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:27:35,459 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:27:35,913 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:27:36,349 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:27:36,791 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:27:37,235 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:27:37,645 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:27:38,041 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:27:38,494 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:27:38,904 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:27:39,315 - INFO - training batch 551, loss: 0.118, 17632/28000 datapoints
2025-03-07 13:27:39,726 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:27:40,155 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:27:40,619 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:27:41,005 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:27:41,482 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:27:41,920 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:27:42,130 - INFO - validation batch 1, loss: 0.032, 32/6976 datapoints
2025-03-07 13:27:42,201 - INFO - validation batch 51, loss: 5.176, 1632/6976 datapoints
2025-03-07 13:27:42,278 - INFO - validation batch 101, loss: 0.244, 3232/6976 datapoints
2025-03-07 13:27:42,360 - INFO - validation batch 151, loss: 1.832, 4832/6976 datapoints
2025-03-07 13:27:42,434 - INFO - validation batch 201, loss: 0.577, 6432/6976 datapoints
2025-03-07 13:27:42,459 - INFO - Epoch 645/800 done.
2025-03-07 13:27:42,460 - INFO - Final validation performance:
Loss: 1.572, top-1 acc: 0.894top-5 acc: 0.894
2025-03-07 13:27:42,460 - INFO - Beginning epoch 646/800
2025-03-07 13:27:42,470 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:27:42,942 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:27:43,431 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:27:43,934 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:27:44,428 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:27:44,915 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:27:45,409 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:27:45,876 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:27:46,419 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:27:46,922 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:27:47,428 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:27:47,901 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:27:48,420 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:27:48,922 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:27:49,373 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:27:49,796 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:27:50,276 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:27:50,730 - INFO - training batch 851, loss: 0.001, 27232/28000 datapoints
2025-03-07 13:27:50,992 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:27:51,126 - INFO - validation batch 51, loss: 5.625, 1632/6976 datapoints
2025-03-07 13:27:51,235 - INFO - validation batch 101, loss: 0.348, 3232/6976 datapoints
2025-03-07 13:27:51,340 - INFO - validation batch 151, loss: 1.941, 4832/6976 datapoints
2025-03-07 13:27:51,445 - INFO - validation batch 201, loss: 1.468, 6432/6976 datapoints
2025-03-07 13:27:51,484 - INFO - Epoch 646/800 done.
2025-03-07 13:27:51,484 - INFO - Final validation performance:
Loss: 1.876, top-1 acc: 0.894top-5 acc: 0.894
2025-03-07 13:27:51,485 - INFO - Beginning epoch 647/800
2025-03-07 13:27:51,498 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:27:52,147 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:27:52,689 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:27:53,149 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:27:53,613 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:27:54,064 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:27:54,518 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:27:54,970 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:27:55,429 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:27:55,847 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:27:56,279 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:27:56,704 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:27:57,117 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:27:57,543 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:27:57,957 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:27:58,416 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:27:58,852 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:27:59,248 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:27:59,454 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:27:59,541 - INFO - validation batch 51, loss: 5.371, 1632/6976 datapoints
2025-03-07 13:27:59,620 - INFO - validation batch 101, loss: 0.210, 3232/6976 datapoints
2025-03-07 13:27:59,693 - INFO - validation batch 151, loss: 1.600, 4832/6976 datapoints
2025-03-07 13:27:59,765 - INFO - validation batch 201, loss: 1.094, 6432/6976 datapoints
2025-03-07 13:27:59,790 - INFO - Epoch 647/800 done.
2025-03-07 13:27:59,790 - INFO - Final validation performance:
Loss: 1.655, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:27:59,791 - INFO - Beginning epoch 648/800
2025-03-07 13:27:59,803 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:28:00,283 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:28:00,811 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:28:01,274 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:28:01,744 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:28:02,252 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:28:02,789 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:28:03,290 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:28:03,733 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:28:04,203 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:28:04,692 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:28:05,148 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:28:05,626 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:28:06,075 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:28:06,580 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:28:07,033 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:28:07,506 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:28:07,946 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:28:08,163 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:28:08,247 - INFO - validation batch 51, loss: 5.348, 1632/6976 datapoints
2025-03-07 13:28:08,330 - INFO - validation batch 101, loss: 0.209, 3232/6976 datapoints
2025-03-07 13:28:08,415 - INFO - validation batch 151, loss: 1.591, 4832/6976 datapoints
2025-03-07 13:28:08,489 - INFO - validation batch 201, loss: 1.063, 6432/6976 datapoints
2025-03-07 13:28:08,517 - INFO - Epoch 648/800 done.
2025-03-07 13:28:08,517 - INFO - Final validation performance:
Loss: 1.642, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:28:08,518 - INFO - Beginning epoch 649/800
2025-03-07 13:28:08,530 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:28:08,994 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:28:09,451 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:28:09,913 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:28:10,388 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:28:10,854 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:28:11,362 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:28:11,852 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:28:12,244 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:28:12,672 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:28:13,103 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:28:13,528 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:28:13,969 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:28:14,396 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:28:14,808 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:28:15,244 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:28:15,784 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:28:16,252 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:28:16,495 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:28:16,593 - INFO - validation batch 51, loss: 5.331, 1632/6976 datapoints
2025-03-07 13:28:16,684 - INFO - validation batch 101, loss: 0.210, 3232/6976 datapoints
2025-03-07 13:28:16,775 - INFO - validation batch 151, loss: 1.585, 4832/6976 datapoints
2025-03-07 13:28:16,866 - INFO - validation batch 201, loss: 1.036, 6432/6976 datapoints
2025-03-07 13:28:16,900 - INFO - Epoch 649/800 done.
2025-03-07 13:28:16,900 - INFO - Final validation performance:
Loss: 1.632, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:28:16,901 - INFO - Beginning epoch 650/800
2025-03-07 13:28:16,914 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:28:17,473 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:28:18,067 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:28:18,575 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:28:19,099 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:28:19,663 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:28:20,262 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:28:20,813 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:28:21,289 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:28:21,779 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:28:22,244 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:28:22,654 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:28:23,078 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:28:23,503 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:28:23,923 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:28:24,371 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:28:24,840 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:28:25,281 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:28:25,496 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:28:25,580 - INFO - validation batch 51, loss: 5.316, 1632/6976 datapoints
2025-03-07 13:28:25,660 - INFO - validation batch 101, loss: 0.211, 3232/6976 datapoints
2025-03-07 13:28:25,737 - INFO - validation batch 151, loss: 1.580, 4832/6976 datapoints
2025-03-07 13:28:25,811 - INFO - validation batch 201, loss: 1.013, 6432/6976 datapoints
2025-03-07 13:28:25,835 - INFO - Epoch 650/800 done.
2025-03-07 13:28:25,835 - INFO - Final validation performance:
Loss: 1.624, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:28:25,837 - INFO - Beginning epoch 651/800
2025-03-07 13:28:25,849 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:28:26,324 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:28:26,806 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:28:27,261 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:28:27,743 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:28:28,225 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:28:28,719 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:28:29,157 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:28:29,534 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:28:29,957 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:28:30,374 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:28:30,859 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:28:31,274 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:28:31,720 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:28:32,233 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:28:32,715 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:28:33,159 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:28:33,553 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:28:33,750 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:28:33,828 - INFO - validation batch 51, loss: 5.302, 1632/6976 datapoints
2025-03-07 13:28:33,907 - INFO - validation batch 101, loss: 0.212, 3232/6976 datapoints
2025-03-07 13:28:33,982 - INFO - validation batch 151, loss: 1.576, 4832/6976 datapoints
2025-03-07 13:28:34,060 - INFO - validation batch 201, loss: 0.993, 6432/6976 datapoints
2025-03-07 13:28:34,084 - INFO - Epoch 651/800 done.
2025-03-07 13:28:34,084 - INFO - Final validation performance:
Loss: 1.617, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:28:34,085 - INFO - Beginning epoch 652/800
2025-03-07 13:28:34,096 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:28:34,548 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:28:34,978 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:28:35,400 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:28:35,807 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:28:36,244 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:28:36,689 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:28:37,110 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:28:37,520 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:28:38,004 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:28:38,439 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:28:38,846 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:28:39,265 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:28:39,705 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:28:40,143 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:28:40,570 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:28:41,001 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:28:41,409 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:28:41,612 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:28:41,684 - INFO - validation batch 51, loss: 5.289, 1632/6976 datapoints
2025-03-07 13:28:41,764 - INFO - validation batch 101, loss: 0.214, 3232/6976 datapoints
2025-03-07 13:28:41,847 - INFO - validation batch 151, loss: 1.573, 4832/6976 datapoints
2025-03-07 13:28:41,922 - INFO - validation batch 201, loss: 0.979, 6432/6976 datapoints
2025-03-07 13:28:41,947 - INFO - Epoch 652/800 done.
2025-03-07 13:28:41,947 - INFO - Final validation performance:
Loss: 1.611, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:28:41,948 - INFO - Beginning epoch 653/800
2025-03-07 13:28:41,960 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:28:42,412 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:28:42,862 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:28:43,287 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:28:43,699 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:28:44,137 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:28:44,602 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:28:45,030 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:28:45,518 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:28:46,033 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:28:46,534 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:28:47,025 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:28:47,562 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:28:48,181 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:28:48,689 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:28:49,168 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:28:49,660 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:28:50,126 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:28:50,368 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:28:50,463 - INFO - validation batch 51, loss: 5.277, 1632/6976 datapoints
2025-03-07 13:28:50,580 - INFO - validation batch 101, loss: 0.216, 3232/6976 datapoints
2025-03-07 13:28:50,673 - INFO - validation batch 151, loss: 1.570, 4832/6976 datapoints
2025-03-07 13:28:50,753 - INFO - validation batch 201, loss: 0.972, 6432/6976 datapoints
2025-03-07 13:28:50,778 - INFO - Epoch 653/800 done.
2025-03-07 13:28:50,778 - INFO - Final validation performance:
Loss: 1.607, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:28:50,779 - INFO - Beginning epoch 654/800
2025-03-07 13:28:50,789 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:28:51,224 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:28:51,672 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:28:52,076 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:28:52,472 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:28:52,897 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:28:53,323 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:28:53,721 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:28:54,085 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:28:54,489 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:28:54,884 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:28:55,277 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:28:55,694 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:28:56,113 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:28:56,528 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:28:56,923 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:28:57,332 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:28:57,713 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:28:57,910 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:28:57,987 - INFO - validation batch 51, loss: 5.266, 1632/6976 datapoints
2025-03-07 13:28:58,082 - INFO - validation batch 101, loss: 0.216, 3232/6976 datapoints
2025-03-07 13:28:58,154 - INFO - validation batch 151, loss: 1.567, 4832/6976 datapoints
2025-03-07 13:28:58,228 - INFO - validation batch 201, loss: 0.971, 6432/6976 datapoints
2025-03-07 13:28:58,255 - INFO - Epoch 654/800 done.
2025-03-07 13:28:58,255 - INFO - Final validation performance:
Loss: 1.604, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:28:58,255 - INFO - Beginning epoch 655/800
2025-03-07 13:28:58,265 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:28:58,695 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:28:59,112 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:28:59,504 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:28:59,903 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:29:00,339 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:29:00,782 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:29:01,193 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:29:01,570 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:29:01,977 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:29:02,376 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:29:02,773 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:29:03,164 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:29:03,565 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:29:03,967 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:29:04,357 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:29:04,776 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:29:05,153 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:29:05,343 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:29:05,417 - INFO - validation batch 51, loss: 5.253, 1632/6976 datapoints
2025-03-07 13:29:05,498 - INFO - validation batch 101, loss: 0.216, 3232/6976 datapoints
2025-03-07 13:29:05,626 - INFO - validation batch 151, loss: 1.562, 4832/6976 datapoints
2025-03-07 13:29:05,714 - INFO - validation batch 201, loss: 0.975, 6432/6976 datapoints
2025-03-07 13:29:05,738 - INFO - Epoch 655/800 done.
2025-03-07 13:29:05,738 - INFO - Final validation performance:
Loss: 1.601, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:29:05,739 - INFO - Beginning epoch 656/800
2025-03-07 13:29:05,751 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:29:06,178 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:29:06,613 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:29:07,028 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:29:07,543 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:29:08,058 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:29:08,602 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:29:09,127 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:29:09,619 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:29:10,199 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:29:10,780 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:29:11,294 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:29:11,795 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:29:12,353 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:29:12,818 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:29:13,298 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:29:13,783 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:29:14,203 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:29:14,432 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:29:14,538 - INFO - validation batch 51, loss: 5.238, 1632/6976 datapoints
2025-03-07 13:29:14,641 - INFO - validation batch 101, loss: 0.214, 3232/6976 datapoints
2025-03-07 13:29:14,727 - INFO - validation batch 151, loss: 1.555, 4832/6976 datapoints
2025-03-07 13:29:14,803 - INFO - validation batch 201, loss: 0.980, 6432/6976 datapoints
2025-03-07 13:29:14,827 - INFO - Epoch 656/800 done.
2025-03-07 13:29:14,828 - INFO - Final validation performance:
Loss: 1.598, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:29:14,828 - INFO - Beginning epoch 657/800
2025-03-07 13:29:14,838 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:29:15,300 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:29:15,795 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:29:16,233 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:29:16,742 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:29:17,240 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:29:17,759 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:29:18,262 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:29:18,677 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:29:19,130 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:29:19,635 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:29:20,184 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:29:20,640 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:29:21,081 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:29:21,499 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:29:21,934 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:29:22,412 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:29:22,845 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:29:23,074 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:29:23,165 - INFO - validation batch 51, loss: 5.220, 1632/6976 datapoints
2025-03-07 13:29:23,257 - INFO - validation batch 101, loss: 0.213, 3232/6976 datapoints
2025-03-07 13:29:23,349 - INFO - validation batch 151, loss: 1.547, 4832/6976 datapoints
2025-03-07 13:29:23,440 - INFO - validation batch 201, loss: 0.987, 6432/6976 datapoints
2025-03-07 13:29:23,473 - INFO - Epoch 657/800 done.
2025-03-07 13:29:23,474 - INFO - Final validation performance:
Loss: 1.593, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:29:23,474 - INFO - Beginning epoch 658/800
2025-03-07 13:29:23,485 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:29:24,003 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:29:24,529 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:29:25,013 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:29:25,493 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:29:26,045 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:29:26,577 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:29:27,078 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:29:27,475 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:29:27,913 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:29:28,341 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:29:28,736 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:29:29,130 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:29:29,536 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:29:29,943 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:29:30,348 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:29:30,818 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:29:31,192 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:29:31,391 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:29:31,468 - INFO - validation batch 51, loss: 5.201, 1632/6976 datapoints
2025-03-07 13:29:31,545 - INFO - validation batch 101, loss: 0.212, 3232/6976 datapoints
2025-03-07 13:29:31,622 - INFO - validation batch 151, loss: 1.536, 4832/6976 datapoints
2025-03-07 13:29:31,697 - INFO - validation batch 201, loss: 0.994, 6432/6976 datapoints
2025-03-07 13:29:31,728 - INFO - Epoch 658/800 done.
2025-03-07 13:29:31,728 - INFO - Final validation performance:
Loss: 1.589, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:29:31,729 - INFO - Beginning epoch 659/800
2025-03-07 13:29:31,740 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:29:32,167 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:29:32,587 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:29:32,974 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:29:33,365 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:29:33,817 - INFO - training batch 251, loss: -0.000, 8032/28000 datapoints
2025-03-07 13:29:34,348 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:29:34,773 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:29:35,136 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:29:35,551 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:29:35,994 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:29:36,396 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:29:36,802 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:29:37,210 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:29:37,619 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:29:38,034 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:29:38,445 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:29:38,822 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:29:39,009 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:29:39,085 - INFO - validation batch 51, loss: 5.179, 1632/6976 datapoints
2025-03-07 13:29:39,161 - INFO - validation batch 101, loss: 0.212, 3232/6976 datapoints
2025-03-07 13:29:39,238 - INFO - validation batch 151, loss: 1.525, 4832/6976 datapoints
2025-03-07 13:29:39,317 - INFO - validation batch 201, loss: 1.000, 6432/6976 datapoints
2025-03-07 13:29:39,341 - INFO - Epoch 659/800 done.
2025-03-07 13:29:39,341 - INFO - Final validation performance:
Loss: 1.583, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:29:39,342 - INFO - Beginning epoch 660/800
2025-03-07 13:29:39,354 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:29:39,786 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:29:40,202 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:29:40,597 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:29:40,992 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:29:41,412 - INFO - training batch 251, loss: -0.000, 8032/28000 datapoints
2025-03-07 13:29:41,844 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:29:42,236 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:29:42,589 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:29:42,981 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:29:43,377 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:29:43,765 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:29:44,159 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:29:44,560 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:29:44,970 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:29:45,371 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:29:45,793 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:29:46,197 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:29:46,401 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:29:46,476 - INFO - validation batch 51, loss: 5.157, 1632/6976 datapoints
2025-03-07 13:29:46,547 - INFO - validation batch 101, loss: 0.213, 3232/6976 datapoints
2025-03-07 13:29:46,617 - INFO - validation batch 151, loss: 1.512, 4832/6976 datapoints
2025-03-07 13:29:46,689 - INFO - validation batch 201, loss: 1.005, 6432/6976 datapoints
2025-03-07 13:29:46,712 - INFO - Epoch 660/800 done.
2025-03-07 13:29:46,712 - INFO - Final validation performance:
Loss: 1.577, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:29:46,713 - INFO - Beginning epoch 661/800
2025-03-07 13:29:46,724 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:29:47,167 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:29:47,660 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:29:48,128 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:29:48,613 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:29:49,093 - INFO - training batch 251, loss: -0.000, 8032/28000 datapoints
2025-03-07 13:29:49,552 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:29:49,961 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:29:50,330 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:29:50,732 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:29:51,140 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:29:51,539 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:29:51,953 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:29:52,379 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:29:52,789 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:29:53,191 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:29:53,605 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:29:53,980 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:29:54,173 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:29:54,275 - INFO - validation batch 51, loss: 5.134, 1632/6976 datapoints
2025-03-07 13:29:54,377 - INFO - validation batch 101, loss: 0.216, 3232/6976 datapoints
2025-03-07 13:29:54,456 - INFO - validation batch 151, loss: 1.498, 4832/6976 datapoints
2025-03-07 13:29:54,538 - INFO - validation batch 201, loss: 1.010, 6432/6976 datapoints
2025-03-07 13:29:54,567 - INFO - Epoch 661/800 done.
2025-03-07 13:29:54,567 - INFO - Final validation performance:
Loss: 1.572, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:29:54,567 - INFO - Beginning epoch 662/800
2025-03-07 13:29:54,577 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:29:55,093 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:29:55,579 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:29:56,001 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:29:56,646 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:29:57,179 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:29:57,682 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:29:58,172 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:29:58,564 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:29:58,975 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:29:59,468 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:29:59,974 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:30:00,403 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:30:00,813 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:30:01,251 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:30:01,667 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:30:02,115 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:30:02,519 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:30:02,714 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:30:02,790 - INFO - validation batch 51, loss: 5.110, 1632/6976 datapoints
2025-03-07 13:30:02,868 - INFO - validation batch 101, loss: 0.220, 3232/6976 datapoints
2025-03-07 13:30:02,940 - INFO - validation batch 151, loss: 1.485, 4832/6976 datapoints
2025-03-07 13:30:03,013 - INFO - validation batch 201, loss: 1.016, 6432/6976 datapoints
2025-03-07 13:30:03,036 - INFO - Epoch 662/800 done.
2025-03-07 13:30:03,037 - INFO - Final validation performance:
Loss: 1.567, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:30:03,037 - INFO - Beginning epoch 663/800
2025-03-07 13:30:03,048 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:30:03,456 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:30:03,871 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:30:04,277 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:30:04,687 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:30:05,119 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:30:05,545 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:30:05,969 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:30:06,346 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:30:06,735 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:30:07,124 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:30:07,508 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:30:07,904 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:30:08,313 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:30:08,722 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:30:09,126 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:30:09,533 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:30:09,905 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:30:10,090 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:30:10,162 - INFO - validation batch 51, loss: 5.085, 1632/6976 datapoints
2025-03-07 13:30:10,236 - INFO - validation batch 101, loss: 0.226, 3232/6976 datapoints
2025-03-07 13:30:10,322 - INFO - validation batch 151, loss: 1.472, 4832/6976 datapoints
2025-03-07 13:30:10,395 - INFO - validation batch 201, loss: 1.023, 6432/6976 datapoints
2025-03-07 13:30:10,423 - INFO - Epoch 663/800 done.
2025-03-07 13:30:10,423 - INFO - Final validation performance:
Loss: 1.562, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:30:10,424 - INFO - Beginning epoch 664/800
2025-03-07 13:30:10,433 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:30:10,856 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:30:11,258 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:30:11,671 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:30:12,065 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:30:12,486 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:30:12,919 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:30:13,312 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:30:13,673 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:30:14,074 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:30:14,486 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:30:14,888 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:30:15,280 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:30:15,683 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:30:16,126 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:30:16,600 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:30:17,076 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:30:17,482 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:30:17,671 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:30:17,751 - INFO - validation batch 51, loss: 5.058, 1632/6976 datapoints
2025-03-07 13:30:17,823 - INFO - validation batch 101, loss: 0.235, 3232/6976 datapoints
2025-03-07 13:30:17,901 - INFO - validation batch 151, loss: 1.463, 4832/6976 datapoints
2025-03-07 13:30:17,977 - INFO - validation batch 201, loss: 1.033, 6432/6976 datapoints
2025-03-07 13:30:18,002 - INFO - Epoch 664/800 done.
2025-03-07 13:30:18,003 - INFO - Final validation performance:
Loss: 1.558, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:30:18,004 - INFO - Beginning epoch 665/800
2025-03-07 13:30:18,014 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:30:18,443 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:30:18,885 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:30:19,324 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:30:19,751 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:30:20,196 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:30:20,653 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:30:21,067 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:30:21,518 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:30:21,978 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:30:22,407 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:30:22,833 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:30:23,338 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:30:23,806 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:30:24,284 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:30:24,785 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:30:25,231 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:30:25,691 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:30:25,915 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:30:26,012 - INFO - validation batch 51, loss: 5.027, 1632/6976 datapoints
2025-03-07 13:30:26,113 - INFO - validation batch 101, loss: 0.245, 3232/6976 datapoints
2025-03-07 13:30:26,200 - INFO - validation batch 151, loss: 1.457, 4832/6976 datapoints
2025-03-07 13:30:26,279 - INFO - validation batch 201, loss: 1.041, 6432/6976 datapoints
2025-03-07 13:30:26,309 - INFO - Epoch 665/800 done.
2025-03-07 13:30:26,310 - INFO - Final validation performance:
Loss: 1.555, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:30:26,310 - INFO - Beginning epoch 666/800
2025-03-07 13:30:26,325 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:30:26,849 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:30:27,368 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:30:27,837 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:30:28,368 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:30:28,880 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:30:29,362 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:30:29,814 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:30:30,284 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:30:30,953 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:30:31,416 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:30:31,880 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:30:32,340 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:30:32,811 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:30:33,278 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:30:33,740 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:30:34,209 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:30:34,649 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:30:34,865 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 13:30:34,944 - INFO - validation batch 51, loss: 4.994, 1632/6976 datapoints
2025-03-07 13:30:35,027 - INFO - validation batch 101, loss: 0.258, 3232/6976 datapoints
2025-03-07 13:30:35,113 - INFO - validation batch 151, loss: 1.455, 4832/6976 datapoints
2025-03-07 13:30:35,192 - INFO - validation batch 201, loss: 1.053, 6432/6976 datapoints
2025-03-07 13:30:35,226 - INFO - Epoch 666/800 done.
2025-03-07 13:30:35,227 - INFO - Final validation performance:
Loss: 1.553, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:30:35,227 - INFO - Beginning epoch 667/800
2025-03-07 13:30:35,237 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:30:35,715 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:30:36,241 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:30:36,683 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:30:37,114 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:30:37,545 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:30:37,976 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:30:38,376 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:30:38,757 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:30:39,148 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:30:39,546 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:30:39,942 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:30:40,344 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:30:40,758 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:30:41,199 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:30:41,611 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:30:42,029 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:30:42,452 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:30:42,661 - INFO - validation batch 1, loss: 0.009, 32/6976 datapoints
2025-03-07 13:30:42,734 - INFO - validation batch 51, loss: 4.964, 1632/6976 datapoints
2025-03-07 13:30:42,812 - INFO - validation batch 101, loss: 0.276, 3232/6976 datapoints
2025-03-07 13:30:42,885 - INFO - validation batch 151, loss: 1.458, 4832/6976 datapoints
2025-03-07 13:30:42,959 - INFO - validation batch 201, loss: 1.065, 6432/6976 datapoints
2025-03-07 13:30:42,982 - INFO - Epoch 667/800 done.
2025-03-07 13:30:42,982 - INFO - Final validation performance:
Loss: 1.554, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:30:42,983 - INFO - Beginning epoch 668/800
2025-03-07 13:30:42,992 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:30:43,418 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:30:43,846 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:30:44,256 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:30:44,671 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:30:45,109 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:30:45,544 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:30:45,945 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:30:46,312 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:30:46,734 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:30:47,138 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:30:47,537 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:30:47,957 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:30:48,372 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:30:48,784 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:30:49,185 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 13:30:49,592 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:30:49,960 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:30:50,148 - INFO - validation batch 1, loss: 0.012, 32/6976 datapoints
2025-03-07 13:30:50,223 - INFO - validation batch 51, loss: 4.928, 1632/6976 datapoints
2025-03-07 13:30:50,295 - INFO - validation batch 101, loss: 0.298, 3232/6976 datapoints
2025-03-07 13:30:50,369 - INFO - validation batch 151, loss: 1.463, 4832/6976 datapoints
2025-03-07 13:30:50,442 - INFO - validation batch 201, loss: 1.079, 6432/6976 datapoints
2025-03-07 13:30:50,470 - INFO - Epoch 668/800 done.
2025-03-07 13:30:50,470 - INFO - Final validation performance:
Loss: 1.556, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:30:50,471 - INFO - Beginning epoch 669/800
2025-03-07 13:30:50,482 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:30:50,909 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:30:51,320 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:30:51,717 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:30:52,122 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:30:52,547 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:30:52,974 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:30:53,367 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:30:53,729 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:30:54,127 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:30:54,560 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:30:54,951 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:30:55,342 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:30:55,743 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:30:56,153 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:30:56,556 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 13:30:56,993 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:30:57,365 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:30:57,553 - INFO - validation batch 1, loss: 0.015, 32/6976 datapoints
2025-03-07 13:30:57,627 - INFO - validation batch 51, loss: 4.910, 1632/6976 datapoints
2025-03-07 13:30:57,707 - INFO - validation batch 101, loss: 0.308, 3232/6976 datapoints
2025-03-07 13:30:57,782 - INFO - validation batch 151, loss: 1.472, 4832/6976 datapoints
2025-03-07 13:30:57,856 - INFO - validation batch 201, loss: 1.095, 6432/6976 datapoints
2025-03-07 13:30:57,880 - INFO - Epoch 669/800 done.
2025-03-07 13:30:57,881 - INFO - Final validation performance:
Loss: 1.560, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:30:57,881 - INFO - Beginning epoch 670/800
2025-03-07 13:30:57,892 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:30:58,339 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:30:58,773 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:30:59,182 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:30:59,592 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:31:00,021 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:31:00,461 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:31:00,864 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:31:01,230 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:31:01,623 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:31:02,033 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:31:02,433 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:31:02,828 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:31:03,225 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:31:03,693 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:31:04,268 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 13:31:04,743 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:31:05,171 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:31:05,372 - INFO - validation batch 1, loss: 0.018, 32/6976 datapoints
2025-03-07 13:31:05,450 - INFO - validation batch 51, loss: 4.896, 1632/6976 datapoints
2025-03-07 13:31:05,535 - INFO - validation batch 101, loss: 0.330, 3232/6976 datapoints
2025-03-07 13:31:05,623 - INFO - validation batch 151, loss: 1.481, 4832/6976 datapoints
2025-03-07 13:31:05,710 - INFO - validation batch 201, loss: 1.102, 6432/6976 datapoints
2025-03-07 13:31:05,737 - INFO - Epoch 670/800 done.
2025-03-07 13:31:05,737 - INFO - Final validation performance:
Loss: 1.566, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:31:05,738 - INFO - Beginning epoch 671/800
2025-03-07 13:31:05,748 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:31:06,253 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:31:06,812 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:31:07,310 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:31:07,790 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:31:08,384 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:31:08,838 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:31:09,266 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:31:09,640 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:31:10,035 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:31:10,434 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:31:10,851 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:31:11,262 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:31:11,668 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:31:12,078 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:31:12,483 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 13:31:12,901 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:31:13,273 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:31:13,457 - INFO - validation batch 1, loss: 0.018, 32/6976 datapoints
2025-03-07 13:31:13,535 - INFO - validation batch 51, loss: 4.889, 1632/6976 datapoints
2025-03-07 13:31:13,616 - INFO - validation batch 101, loss: 0.364, 3232/6976 datapoints
2025-03-07 13:31:13,697 - INFO - validation batch 151, loss: 1.488, 4832/6976 datapoints
2025-03-07 13:31:13,773 - INFO - validation batch 201, loss: 1.104, 6432/6976 datapoints
2025-03-07 13:31:13,797 - INFO - Epoch 671/800 done.
2025-03-07 13:31:13,797 - INFO - Final validation performance:
Loss: 1.573, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:31:13,798 - INFO - Beginning epoch 672/800
2025-03-07 13:31:13,810 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:31:14,221 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:31:14,676 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:31:15,069 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:31:15,485 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:31:15,923 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:31:16,400 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:31:16,806 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:31:17,222 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:31:17,636 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:31:18,049 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:31:18,448 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:31:18,841 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:31:19,237 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:31:19,645 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:31:20,067 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:31:20,486 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:31:20,912 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:31:21,099 - INFO - validation batch 1, loss: 0.018, 32/6976 datapoints
2025-03-07 13:31:21,173 - INFO - validation batch 51, loss: 4.873, 1632/6976 datapoints
2025-03-07 13:31:21,250 - INFO - validation batch 101, loss: 0.380, 3232/6976 datapoints
2025-03-07 13:31:21,330 - INFO - validation batch 151, loss: 1.490, 4832/6976 datapoints
2025-03-07 13:31:21,400 - INFO - validation batch 201, loss: 1.098, 6432/6976 datapoints
2025-03-07 13:31:21,426 - INFO - Epoch 672/800 done.
2025-03-07 13:31:21,426 - INFO - Final validation performance:
Loss: 1.572, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:31:21,427 - INFO - Beginning epoch 673/800
2025-03-07 13:31:21,437 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:31:21,984 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:31:22,586 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:31:23,062 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:31:23,537 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:31:24,024 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:31:24,502 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:31:24,934 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:31:25,331 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:31:25,749 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:31:26,172 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:31:26,576 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:31:26,999 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:31:27,455 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:31:27,937 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:31:28,368 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:31:28,812 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:31:29,244 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:31:29,438 - INFO - validation batch 1, loss: 0.013, 32/6976 datapoints
2025-03-07 13:31:29,515 - INFO - validation batch 51, loss: 4.856, 1632/6976 datapoints
2025-03-07 13:31:29,592 - INFO - validation batch 101, loss: 0.412, 3232/6976 datapoints
2025-03-07 13:31:29,671 - INFO - validation batch 151, loss: 1.504, 4832/6976 datapoints
2025-03-07 13:31:29,745 - INFO - validation batch 201, loss: 1.102, 6432/6976 datapoints
2025-03-07 13:31:29,774 - INFO - Epoch 673/800 done.
2025-03-07 13:31:29,775 - INFO - Final validation performance:
Loss: 1.577, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:31:29,775 - INFO - Beginning epoch 674/800
2025-03-07 13:31:29,785 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:31:30,198 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:31:30,690 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:31:31,132 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:31:31,546 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:31:32,025 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:31:32,482 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:31:32,921 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:31:33,300 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:31:33,705 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:31:34,167 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:31:34,571 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:31:34,975 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:31:35,420 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:31:35,863 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:31:36,268 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:31:36,690 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:31:37,083 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:31:37,296 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 13:31:37,369 - INFO - validation batch 51, loss: 4.841, 1632/6976 datapoints
2025-03-07 13:31:37,445 - INFO - validation batch 101, loss: 0.432, 3232/6976 datapoints
2025-03-07 13:31:37,520 - INFO - validation batch 151, loss: 1.542, 4832/6976 datapoints
2025-03-07 13:31:37,605 - INFO - validation batch 201, loss: 1.064, 6432/6976 datapoints
2025-03-07 13:31:37,635 - INFO - Epoch 674/800 done.
2025-03-07 13:31:37,635 - INFO - Final validation performance:
Loss: 1.578, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:31:37,635 - INFO - Beginning epoch 675/800
2025-03-07 13:31:37,649 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:31:38,150 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:31:38,647 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:31:39,130 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:31:39,636 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:31:40,161 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:31:40,638 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:31:41,052 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:31:41,430 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:31:41,831 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:31:42,261 - INFO - training batch 501, loss: 0.109, 16032/28000 datapoints
2025-03-07 13:31:42,689 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:31:43,090 - INFO - training batch 601, loss: 0.003, 19232/28000 datapoints
2025-03-07 13:31:43,483 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:31:43,885 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:31:44,317 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:31:44,741 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:31:45,151 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:31:45,335 - INFO - validation batch 1, loss: 0.000, 32/6976 datapoints
2025-03-07 13:31:45,407 - INFO - validation batch 51, loss: 5.653, 1632/6976 datapoints
2025-03-07 13:31:45,480 - INFO - validation batch 101, loss: 0.760, 3232/6976 datapoints
2025-03-07 13:31:45,555 - INFO - validation batch 151, loss: 1.658, 4832/6976 datapoints
2025-03-07 13:31:45,627 - INFO - validation batch 201, loss: 1.280, 6432/6976 datapoints
2025-03-07 13:31:45,653 - INFO - Epoch 675/800 done.
2025-03-07 13:31:45,653 - INFO - Final validation performance:
Loss: 1.870, top-1 acc: 0.895top-5 acc: 0.895
2025-03-07 13:31:45,654 - INFO - Beginning epoch 676/800
2025-03-07 13:31:45,663 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:31:46,066 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:31:46,492 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:31:46,913 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:31:47,330 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:31:47,808 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:31:48,259 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:31:48,712 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:31:49,090 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:31:49,511 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:31:49,934 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:31:50,364 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:31:50,816 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:31:51,269 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:31:51,759 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:31:52,226 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:31:52,672 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:31:53,110 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:31:53,326 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:31:53,416 - INFO - validation batch 51, loss: 5.457, 1632/6976 datapoints
2025-03-07 13:31:53,507 - INFO - validation batch 101, loss: 0.484, 3232/6976 datapoints
2025-03-07 13:31:53,604 - INFO - validation batch 151, loss: 1.520, 4832/6976 datapoints
2025-03-07 13:31:53,695 - INFO - validation batch 201, loss: 1.067, 6432/6976 datapoints
2025-03-07 13:31:53,731 - INFO - Epoch 676/800 done.
2025-03-07 13:31:53,731 - INFO - Final validation performance:
Loss: 1.706, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:31:53,732 - INFO - Beginning epoch 677/800
2025-03-07 13:31:53,744 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:31:54,247 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:31:54,745 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:31:55,280 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:31:55,756 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:31:56,221 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:31:56,686 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:31:57,097 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:31:57,529 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:31:57,936 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:31:58,411 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:31:58,811 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:31:59,215 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:31:59,616 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:32:00,032 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:32:00,440 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:32:00,854 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:32:01,239 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:32:01,427 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:32:01,504 - INFO - validation batch 51, loss: 5.459, 1632/6976 datapoints
2025-03-07 13:32:01,581 - INFO - validation batch 101, loss: 0.477, 3232/6976 datapoints
2025-03-07 13:32:01,655 - INFO - validation batch 151, loss: 1.515, 4832/6976 datapoints
2025-03-07 13:32:01,734 - INFO - validation batch 201, loss: 1.080, 6432/6976 datapoints
2025-03-07 13:32:01,764 - INFO - Epoch 677/800 done.
2025-03-07 13:32:01,765 - INFO - Final validation performance:
Loss: 1.706, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:32:01,766 - INFO - Beginning epoch 678/800
2025-03-07 13:32:01,774 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:32:02,184 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:32:02,639 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:32:03,038 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:32:03,438 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:32:03,856 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:32:04,291 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:32:04,694 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:32:05,055 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:32:05,457 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:32:05,868 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:32:06,273 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:32:06,806 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:32:07,310 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:32:07,774 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:32:08,197 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:32:08,627 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:32:09,018 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:32:09,207 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:32:09,284 - INFO - validation batch 51, loss: 5.445, 1632/6976 datapoints
2025-03-07 13:32:09,366 - INFO - validation batch 101, loss: 0.470, 3232/6976 datapoints
2025-03-07 13:32:09,445 - INFO - validation batch 151, loss: 1.514, 4832/6976 datapoints
2025-03-07 13:32:09,517 - INFO - validation batch 201, loss: 1.080, 6432/6976 datapoints
2025-03-07 13:32:09,542 - INFO - Epoch 678/800 done.
2025-03-07 13:32:09,542 - INFO - Final validation performance:
Loss: 1.702, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:32:09,543 - INFO - Beginning epoch 679/800
2025-03-07 13:32:09,553 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:32:10,015 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:32:10,462 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:32:10,882 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:32:11,279 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:32:11,700 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:32:12,137 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:32:12,532 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:32:13,007 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:32:13,527 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:32:13,968 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:32:14,402 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:32:14,847 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:32:15,320 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:32:15,833 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:32:16,338 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:32:16,796 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:32:17,204 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:32:17,399 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:32:17,486 - INFO - validation batch 51, loss: 5.427, 1632/6976 datapoints
2025-03-07 13:32:17,601 - INFO - validation batch 101, loss: 0.462, 3232/6976 datapoints
2025-03-07 13:32:17,685 - INFO - validation batch 151, loss: 1.512, 4832/6976 datapoints
2025-03-07 13:32:17,766 - INFO - validation batch 201, loss: 1.078, 6432/6976 datapoints
2025-03-07 13:32:17,792 - INFO - Epoch 679/800 done.
2025-03-07 13:32:17,792 - INFO - Final validation performance:
Loss: 1.696, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:32:17,792 - INFO - Beginning epoch 680/800
2025-03-07 13:32:17,804 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:32:18,267 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:32:18,735 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:32:19,145 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:32:19,584 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:32:20,024 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:32:20,465 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:32:20,875 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:32:21,249 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:32:21,642 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:32:22,093 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:32:22,499 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:32:22,903 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:32:23,307 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:32:23,721 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:32:24,126 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:32:24,555 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:32:24,948 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:32:25,140 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:32:25,214 - INFO - validation batch 51, loss: 5.407, 1632/6976 datapoints
2025-03-07 13:32:25,288 - INFO - validation batch 101, loss: 0.454, 3232/6976 datapoints
2025-03-07 13:32:25,364 - INFO - validation batch 151, loss: 1.509, 4832/6976 datapoints
2025-03-07 13:32:25,436 - INFO - validation batch 201, loss: 1.074, 6432/6976 datapoints
2025-03-07 13:32:25,468 - INFO - Epoch 680/800 done.
2025-03-07 13:32:25,468 - INFO - Final validation performance:
Loss: 1.689, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:32:25,469 - INFO - Beginning epoch 681/800
2025-03-07 13:32:25,478 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:32:25,899 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:32:26,328 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:32:26,729 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:32:27,128 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:32:27,545 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:32:28,007 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:32:28,404 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:32:28,811 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:32:29,220 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:32:29,621 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:32:30,011 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:32:30,422 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:32:30,870 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:32:31,287 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:32:31,698 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:32:32,117 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:32:32,500 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:32:32,691 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:32:32,764 - INFO - validation batch 51, loss: 5.385, 1632/6976 datapoints
2025-03-07 13:32:32,836 - INFO - validation batch 101, loss: 0.445, 3232/6976 datapoints
2025-03-07 13:32:32,909 - INFO - validation batch 151, loss: 1.503, 4832/6976 datapoints
2025-03-07 13:32:32,982 - INFO - validation batch 201, loss: 1.069, 6432/6976 datapoints
2025-03-07 13:32:33,013 - INFO - Epoch 681/800 done.
2025-03-07 13:32:33,013 - INFO - Final validation performance:
Loss: 1.680, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:32:33,013 - INFO - Beginning epoch 682/800
2025-03-07 13:32:33,025 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:32:33,493 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:32:33,953 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:32:34,354 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:32:34,774 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:32:35,192 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:32:35,638 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:32:36,030 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:32:36,391 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:32:36,802 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:32:37,202 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:32:37,598 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:32:38,022 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:32:38,422 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:32:38,878 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:32:39,301 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:32:39,708 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:32:40,084 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:32:40,267 - INFO - validation batch 1, loss: 0.001, 32/6976 datapoints
2025-03-07 13:32:40,340 - INFO - validation batch 51, loss: 5.361, 1632/6976 datapoints
2025-03-07 13:32:40,413 - INFO - validation batch 101, loss: 0.436, 3232/6976 datapoints
2025-03-07 13:32:40,487 - INFO - validation batch 151, loss: 1.495, 4832/6976 datapoints
2025-03-07 13:32:40,561 - INFO - validation batch 201, loss: 1.063, 6432/6976 datapoints
2025-03-07 13:32:40,585 - INFO - Epoch 682/800 done.
2025-03-07 13:32:40,585 - INFO - Final validation performance:
Loss: 1.671, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:32:40,585 - INFO - Beginning epoch 683/800
2025-03-07 13:32:40,596 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:32:41,005 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:32:41,435 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:32:41,829 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:32:42,228 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:32:42,649 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:32:43,094 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:32:43,488 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:32:43,856 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:32:44,279 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:32:44,760 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:32:45,180 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:32:45,634 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:32:46,075 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:32:46,511 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:32:46,945 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:32:47,374 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:32:47,767 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:32:47,969 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:32:48,046 - INFO - validation batch 51, loss: 5.334, 1632/6976 datapoints
2025-03-07 13:32:48,119 - INFO - validation batch 101, loss: 0.428, 3232/6976 datapoints
2025-03-07 13:32:48,271 - INFO - validation batch 201, loss: 1.056, 6432/6976 datapoints
2025-03-07 13:32:48,293 - INFO - Epoch 683/800 done.
2025-03-07 13:32:48,294 - INFO - Final validation performance:
Loss: 1.662, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:32:48,294 - INFO - Beginning epoch 684/800
2025-03-07 13:32:48,306 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:32:49,585 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:32:50,028 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:32:50,492 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:32:50,949 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:32:51,391 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:32:51,895 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:32:52,371 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:32:52,803 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:32:53,206 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:32:53,627 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:32:54,029 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:32:54,431 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:32:54,894 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:32:55,369 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:32:55,857 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:32:56,344 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:32:56,761 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:32:56,958 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:32:57,036 - INFO - validation batch 51, loss: 5.307, 1632/6976 datapoints
2025-03-07 13:32:57,114 - INFO - validation batch 101, loss: 0.422, 3232/6976 datapoints
2025-03-07 13:32:57,193 - INFO - validation batch 151, loss: 1.483, 4832/6976 datapoints
2025-03-07 13:32:57,275 - INFO - validation batch 201, loss: 1.051, 6432/6976 datapoints
2025-03-07 13:32:57,301 - INFO - Epoch 684/800 done.
2025-03-07 13:32:57,301 - INFO - Final validation performance:
Loss: 1.653, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:32:57,302 - INFO - Beginning epoch 685/800
2025-03-07 13:32:57,313 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:32:57,784 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:32:58,314 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:32:58,713 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:32:59,116 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:32:59,552 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:33:00,008 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:33:00,411 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:33:00,792 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:33:01,185 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:33:01,599 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:33:01,998 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:33:02,396 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:33:02,798 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:33:03,219 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:33:03,652 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:33:04,100 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:33:04,509 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:33:04,720 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:33:04,808 - INFO - validation batch 51, loss: 5.279, 1632/6976 datapoints
2025-03-07 13:33:04,891 - INFO - validation batch 101, loss: 0.417, 3232/6976 datapoints
2025-03-07 13:33:04,977 - INFO - validation batch 151, loss: 1.479, 4832/6976 datapoints
2025-03-07 13:33:05,074 - INFO - validation batch 201, loss: 1.047, 6432/6976 datapoints
2025-03-07 13:33:05,130 - INFO - Epoch 685/800 done.
2025-03-07 13:33:05,131 - INFO - Final validation performance:
Loss: 1.645, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:33:05,131 - INFO - Beginning epoch 686/800
2025-03-07 13:33:05,148 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:33:05,738 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:33:06,277 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:33:06,793 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:33:07,251 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:33:07,778 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:33:08,415 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:33:08,897 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:33:09,303 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:33:09,713 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:33:10,122 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:33:10,527 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:33:10,990 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:33:11,483 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:33:12,050 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:33:12,570 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:33:13,200 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:33:13,687 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:33:13,918 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:33:13,999 - INFO - validation batch 51, loss: 5.251, 1632/6976 datapoints
2025-03-07 13:33:14,079 - INFO - validation batch 101, loss: 0.414, 3232/6976 datapoints
2025-03-07 13:33:14,160 - INFO - validation batch 151, loss: 1.477, 4832/6976 datapoints
2025-03-07 13:33:14,240 - INFO - validation batch 201, loss: 1.046, 6432/6976 datapoints
2025-03-07 13:33:14,270 - INFO - Epoch 686/800 done.
2025-03-07 13:33:14,271 - INFO - Final validation performance:
Loss: 1.638, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:33:14,271 - INFO - Beginning epoch 687/800
2025-03-07 13:33:14,282 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:33:14,737 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:33:15,201 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:33:15,666 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:33:16,161 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:33:16,632 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:33:17,140 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:33:17,676 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:33:18,099 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:33:18,558 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:33:19,030 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:33:19,484 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:33:19,980 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:33:20,452 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:33:20,958 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:33:21,455 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:33:21,963 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:33:22,494 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:33:22,811 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:33:22,936 - INFO - validation batch 51, loss: 5.225, 1632/6976 datapoints
2025-03-07 13:33:23,040 - INFO - validation batch 101, loss: 0.413, 3232/6976 datapoints
2025-03-07 13:33:23,148 - INFO - validation batch 151, loss: 1.475, 4832/6976 datapoints
2025-03-07 13:33:23,259 - INFO - validation batch 201, loss: 1.046, 6432/6976 datapoints
2025-03-07 13:33:23,287 - INFO - Epoch 687/800 done.
2025-03-07 13:33:23,287 - INFO - Final validation performance:
Loss: 1.633, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:33:23,288 - INFO - Beginning epoch 688/800
2025-03-07 13:33:23,300 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:33:23,772 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:33:24,280 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:33:24,742 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:33:25,229 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:33:25,851 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:33:26,367 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:33:26,804 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:33:27,273 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:33:27,730 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:33:28,187 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:33:28,642 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:33:29,063 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:33:29,498 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:33:29,939 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:33:30,399 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:33:30,897 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:33:31,330 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:33:31,539 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:33:31,614 - INFO - validation batch 51, loss: 5.202, 1632/6976 datapoints
2025-03-07 13:33:31,695 - INFO - validation batch 101, loss: 0.413, 3232/6976 datapoints
2025-03-07 13:33:31,785 - INFO - validation batch 151, loss: 1.475, 4832/6976 datapoints
2025-03-07 13:33:31,866 - INFO - validation batch 201, loss: 1.049, 6432/6976 datapoints
2025-03-07 13:33:31,897 - INFO - Epoch 688/800 done.
2025-03-07 13:33:31,897 - INFO - Final validation performance:
Loss: 1.629, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:33:31,898 - INFO - Beginning epoch 689/800
2025-03-07 13:33:31,912 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:33:32,417 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:33:32,926 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:33:33,389 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:33:33,975 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:33:34,804 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:33:35,526 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:33:36,117 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:33:36,607 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:33:37,018 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:33:37,441 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:33:37,848 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:33:38,251 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:33:38,723 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:33:39,303 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:33:39,894 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:33:40,408 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:33:40,912 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:33:41,156 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:33:41,258 - INFO - validation batch 51, loss: 5.181, 1632/6976 datapoints
2025-03-07 13:33:41,362 - INFO - validation batch 101, loss: 0.413, 3232/6976 datapoints
2025-03-07 13:33:41,490 - INFO - validation batch 151, loss: 1.476, 4832/6976 datapoints
2025-03-07 13:33:41,576 - INFO - validation batch 201, loss: 1.054, 6432/6976 datapoints
2025-03-07 13:33:41,605 - INFO - Epoch 689/800 done.
2025-03-07 13:33:41,605 - INFO - Final validation performance:
Loss: 1.626, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:33:41,606 - INFO - Beginning epoch 690/800
2025-03-07 13:33:41,618 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:33:42,084 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:33:42,548 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:33:42,954 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:33:43,362 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:33:43,795 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:33:44,348 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:33:44,813 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:33:45,217 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:33:45,659 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:33:46,139 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:33:46,599 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:33:47,067 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:33:47,570 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:33:48,095 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:33:48,581 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:33:49,021 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:33:49,413 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:33:49,602 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 13:33:49,680 - INFO - validation batch 51, loss: 5.164, 1632/6976 datapoints
2025-03-07 13:33:49,762 - INFO - validation batch 101, loss: 0.414, 3232/6976 datapoints
2025-03-07 13:33:49,836 - INFO - validation batch 151, loss: 1.478, 4832/6976 datapoints
2025-03-07 13:33:49,918 - INFO - validation batch 201, loss: 1.062, 6432/6976 datapoints
2025-03-07 13:33:49,941 - INFO - Epoch 690/800 done.
2025-03-07 13:33:49,941 - INFO - Final validation performance:
Loss: 1.625, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:33:49,942 - INFO - Beginning epoch 691/800
2025-03-07 13:33:49,953 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:33:50,388 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:33:50,827 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:33:51,238 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:33:51,661 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:33:52,158 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:33:52,694 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:33:53,244 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:33:53,780 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:33:54,339 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:33:54,848 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:33:55,380 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:33:55,917 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:33:56,428 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:33:56,954 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:33:57,484 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:33:58,035 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:33:58,591 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:33:58,924 - INFO - validation batch 1, loss: 0.007, 32/6976 datapoints
2025-03-07 13:33:59,045 - INFO - validation batch 51, loss: 5.148, 1632/6976 datapoints
2025-03-07 13:33:59,176 - INFO - validation batch 101, loss: 0.414, 3232/6976 datapoints
2025-03-07 13:33:59,264 - INFO - validation batch 151, loss: 1.481, 4832/6976 datapoints
2025-03-07 13:33:59,364 - INFO - validation batch 201, loss: 1.075, 6432/6976 datapoints
2025-03-07 13:33:59,394 - INFO - Epoch 691/800 done.
2025-03-07 13:33:59,394 - INFO - Final validation performance:
Loss: 1.625, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:33:59,395 - INFO - Beginning epoch 692/800
2025-03-07 13:33:59,407 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:33:59,957 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:34:00,528 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:34:01,049 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:34:01,568 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:34:02,104 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:34:02,570 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:34:03,027 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:34:03,538 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:34:04,069 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:34:04,659 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:34:05,216 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:34:05,819 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:34:06,340 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:34:06,891 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:34:07,496 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:34:08,180 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:34:08,862 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:34:09,124 - INFO - validation batch 1, loss: 0.008, 32/6976 datapoints
2025-03-07 13:34:09,234 - INFO - validation batch 51, loss: 5.135, 1632/6976 datapoints
2025-03-07 13:34:09,349 - INFO - validation batch 101, loss: 0.414, 3232/6976 datapoints
2025-03-07 13:34:09,460 - INFO - validation batch 151, loss: 1.486, 4832/6976 datapoints
2025-03-07 13:34:09,579 - INFO - validation batch 201, loss: 1.091, 6432/6976 datapoints
2025-03-07 13:34:09,624 - INFO - Epoch 692/800 done.
2025-03-07 13:34:09,624 - INFO - Final validation performance:
Loss: 1.627, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:34:09,625 - INFO - Beginning epoch 693/800
2025-03-07 13:34:09,648 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:34:10,242 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:34:10,769 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:34:11,253 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:34:11,732 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:34:12,214 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:34:12,741 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:34:13,204 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:34:13,625 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:34:14,058 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:34:14,589 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:34:15,081 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:34:15,635 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:34:16,108 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:34:16,585 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:34:17,075 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:34:17,583 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:34:18,039 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:34:18,248 - INFO - validation batch 1, loss: 0.009, 32/6976 datapoints
2025-03-07 13:34:18,334 - INFO - validation batch 51, loss: 5.122, 1632/6976 datapoints
2025-03-07 13:34:18,413 - INFO - validation batch 101, loss: 0.414, 3232/6976 datapoints
2025-03-07 13:34:18,493 - INFO - validation batch 151, loss: 1.493, 4832/6976 datapoints
2025-03-07 13:34:18,590 - INFO - validation batch 201, loss: 1.113, 6432/6976 datapoints
2025-03-07 13:34:18,620 - INFO - Epoch 693/800 done.
2025-03-07 13:34:18,620 - INFO - Final validation performance:
Loss: 1.630, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:34:18,621 - INFO - Beginning epoch 694/800
2025-03-07 13:34:18,631 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:34:19,131 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:34:19,604 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:34:20,038 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:34:20,484 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:34:21,015 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:34:21,483 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:34:21,938 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:34:22,338 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:34:22,893 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:34:23,726 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:34:24,279 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:34:24,851 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:34:25,402 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:34:25,929 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:34:26,408 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:34:26,888 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:34:27,316 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:34:27,533 - INFO - validation batch 1, loss: 0.009, 32/6976 datapoints
2025-03-07 13:34:27,622 - INFO - validation batch 51, loss: 5.108, 1632/6976 datapoints
2025-03-07 13:34:27,720 - INFO - validation batch 101, loss: 0.413, 3232/6976 datapoints
2025-03-07 13:34:27,815 - INFO - validation batch 151, loss: 1.501, 4832/6976 datapoints
2025-03-07 13:34:27,895 - INFO - validation batch 201, loss: 1.138, 6432/6976 datapoints
2025-03-07 13:34:27,925 - INFO - Epoch 694/800 done.
2025-03-07 13:34:27,926 - INFO - Final validation performance:
Loss: 1.634, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:34:27,926 - INFO - Beginning epoch 695/800
2025-03-07 13:34:27,938 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:34:28,402 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:34:28,875 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:34:29,330 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:34:29,753 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:34:30,191 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:34:30,737 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:34:31,238 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:34:31,762 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:34:32,317 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:34:32,939 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:34:33,500 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:34:33,973 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:34:34,432 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:34:34,918 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:34:35,404 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:34:35,883 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:34:36,357 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:34:36,597 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 13:34:36,697 - INFO - validation batch 51, loss: 5.091, 1632/6976 datapoints
2025-03-07 13:34:36,801 - INFO - validation batch 101, loss: 0.412, 3232/6976 datapoints
2025-03-07 13:34:36,917 - INFO - validation batch 151, loss: 1.510, 4832/6976 datapoints
2025-03-07 13:34:37,082 - INFO - validation batch 201, loss: 1.163, 6432/6976 datapoints
2025-03-07 13:34:37,276 - INFO - Epoch 695/800 done.
2025-03-07 13:34:37,315 - INFO - Final validation performance:
Loss: 1.637, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:34:37,317 - INFO - Beginning epoch 696/800
2025-03-07 13:34:37,382 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:34:38,783 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:34:39,465 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:34:39,999 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:34:40,520 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:34:41,104 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:34:41,799 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:34:42,417 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:34:43,016 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:34:44,146 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:34:44,689 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:34:45,364 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:34:45,830 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:34:46,268 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:34:46,771 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:34:47,250 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:34:47,773 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:34:48,285 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:34:48,603 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 13:34:48,739 - INFO - validation batch 51, loss: 5.074, 1632/6976 datapoints
2025-03-07 13:34:48,899 - INFO - validation batch 101, loss: 0.412, 3232/6976 datapoints
2025-03-07 13:34:49,063 - INFO - validation batch 151, loss: 1.518, 4832/6976 datapoints
2025-03-07 13:34:49,229 - INFO - validation batch 201, loss: 1.188, 6432/6976 datapoints
2025-03-07 13:34:49,304 - INFO - Epoch 696/800 done.
2025-03-07 13:34:49,305 - INFO - Final validation performance:
Loss: 1.640, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:34:49,309 - INFO - Beginning epoch 697/800
2025-03-07 13:34:49,332 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:34:50,140 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:34:50,730 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:34:51,223 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:34:51,660 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:34:52,143 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:34:52,604 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:34:53,006 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:34:53,405 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:34:53,868 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:34:54,291 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:34:54,703 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:34:55,134 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:34:55,602 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:34:56,065 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:34:56,506 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:34:56,936 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:34:57,365 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:34:57,592 - INFO - validation batch 1, loss: 0.012, 32/6976 datapoints
2025-03-07 13:34:57,680 - INFO - validation batch 51, loss: 5.054, 1632/6976 datapoints
2025-03-07 13:34:57,788 - INFO - validation batch 101, loss: 0.416, 3232/6976 datapoints
2025-03-07 13:34:57,886 - INFO - validation batch 151, loss: 1.527, 4832/6976 datapoints
2025-03-07 13:34:57,969 - INFO - validation batch 201, loss: 1.213, 6432/6976 datapoints
2025-03-07 13:34:57,997 - INFO - Epoch 697/800 done.
2025-03-07 13:34:57,998 - INFO - Final validation performance:
Loss: 1.645, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:34:57,998 - INFO - Beginning epoch 698/800
2025-03-07 13:34:58,013 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:34:58,509 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:34:58,953 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:34:59,372 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:34:59,815 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:35:00,311 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:35:00,779 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:35:01,201 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:35:01,588 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:35:01,992 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:35:02,398 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:35:02,797 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:35:03,214 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:35:03,629 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:35:04,041 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:35:04,460 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:35:04,887 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:35:05,301 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:35:05,495 - INFO - validation batch 1, loss: 0.013, 32/6976 datapoints
2025-03-07 13:35:05,572 - INFO - validation batch 51, loss: 5.034, 1632/6976 datapoints
2025-03-07 13:35:05,651 - INFO - validation batch 101, loss: 0.425, 3232/6976 datapoints
2025-03-07 13:35:05,728 - INFO - validation batch 151, loss: 1.536, 4832/6976 datapoints
2025-03-07 13:35:05,801 - INFO - validation batch 201, loss: 1.230, 6432/6976 datapoints
2025-03-07 13:35:05,828 - INFO - Epoch 698/800 done.
2025-03-07 13:35:05,829 - INFO - Final validation performance:
Loss: 1.648, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:35:05,829 - INFO - Beginning epoch 699/800
2025-03-07 13:35:05,840 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:35:06,257 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:35:06,692 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:35:07,109 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:35:07,525 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:35:07,974 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:35:08,422 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:35:08,831 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:35:09,203 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:35:09,661 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:35:10,081 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:35:10,488 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:35:10,909 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:35:11,319 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:35:11,734 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:35:12,144 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:35:12,569 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:35:12,960 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:35:13,158 - INFO - validation batch 1, loss: 0.014, 32/6976 datapoints
2025-03-07 13:35:13,232 - INFO - validation batch 51, loss: 5.000, 1632/6976 datapoints
2025-03-07 13:35:13,306 - INFO - validation batch 101, loss: 0.437, 3232/6976 datapoints
2025-03-07 13:35:13,380 - INFO - validation batch 151, loss: 1.543, 4832/6976 datapoints
2025-03-07 13:35:13,459 - INFO - validation batch 201, loss: 1.241, 6432/6976 datapoints
2025-03-07 13:35:13,485 - INFO - Epoch 699/800 done.
2025-03-07 13:35:13,485 - INFO - Final validation performance:
Loss: 1.647, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:35:13,486 - INFO - Beginning epoch 700/800
2025-03-07 13:35:13,496 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:35:13,920 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:35:14,357 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:35:14,840 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:35:15,294 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:35:15,750 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:35:16,205 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:35:16,621 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:35:17,011 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:35:17,452 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:35:17,888 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:35:18,297 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:35:18,721 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:35:19,163 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:35:19,619 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:35:20,062 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:35:20,502 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:35:20,920 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:35:21,144 - INFO - validation batch 1, loss: 0.016, 32/6976 datapoints
2025-03-07 13:35:21,252 - INFO - validation batch 51, loss: 4.968, 1632/6976 datapoints
2025-03-07 13:35:21,355 - INFO - validation batch 101, loss: 0.445, 3232/6976 datapoints
2025-03-07 13:35:21,450 - INFO - validation batch 151, loss: 1.545, 4832/6976 datapoints
2025-03-07 13:35:21,561 - INFO - validation batch 201, loss: 1.257, 6432/6976 datapoints
2025-03-07 13:35:21,591 - INFO - Epoch 700/800 done.
2025-03-07 13:35:21,592 - INFO - Final validation performance:
Loss: 1.646, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:35:21,592 - INFO - Beginning epoch 701/800
2025-03-07 13:35:21,605 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:35:22,091 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:35:22,592 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:35:23,039 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:35:23,505 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:35:24,012 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:35:24,499 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:35:24,984 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:35:25,387 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:35:25,841 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:35:26,256 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:35:26,893 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:35:27,500 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:35:28,100 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:35:28,663 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:35:29,213 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:35:29,740 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:35:30,270 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:35:30,769 - INFO - validation batch 1, loss: 0.017, 32/6976 datapoints
2025-03-07 13:35:30,908 - INFO - validation batch 51, loss: 4.930, 1632/6976 datapoints
2025-03-07 13:35:31,051 - INFO - validation batch 101, loss: 0.459, 3232/6976 datapoints
2025-03-07 13:35:31,183 - INFO - validation batch 151, loss: 1.552, 4832/6976 datapoints
2025-03-07 13:35:31,433 - INFO - validation batch 201, loss: 1.247, 6432/6976 datapoints
2025-03-07 13:35:31,512 - INFO - Epoch 701/800 done.
2025-03-07 13:35:31,512 - INFO - Final validation performance:
Loss: 1.641, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:35:31,513 - INFO - Beginning epoch 702/800
2025-03-07 13:35:31,528 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:35:32,436 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:35:33,341 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:35:34,291 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:35:35,107 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:35:35,828 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:35:36,411 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:35:36,879 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:35:37,351 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:35:38,032 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:35:38,764 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:35:39,291 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:35:39,936 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:35:40,523 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:35:41,013 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:35:41,493 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:35:42,092 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:35:42,541 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:35:42,754 - INFO - validation batch 1, loss: 0.018, 32/6976 datapoints
2025-03-07 13:35:42,857 - INFO - validation batch 51, loss: 4.933, 1632/6976 datapoints
2025-03-07 13:35:43,012 - INFO - validation batch 101, loss: 0.467, 3232/6976 datapoints
2025-03-07 13:35:43,161 - INFO - validation batch 151, loss: 1.547, 4832/6976 datapoints
2025-03-07 13:35:43,282 - INFO - validation batch 201, loss: 1.232, 6432/6976 datapoints
2025-03-07 13:35:43,346 - INFO - Epoch 702/800 done.
2025-03-07 13:35:43,347 - INFO - Final validation performance:
Loss: 1.639, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:35:43,351 - INFO - Beginning epoch 703/800
2025-03-07 13:35:43,376 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:35:43,997 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:35:44,677 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:35:45,213 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:35:45,729 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:35:46,334 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:35:46,900 - INFO - training batch 301, loss: -0.000, 9632/28000 datapoints
2025-03-07 13:35:47,459 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:35:47,980 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:35:48,700 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:35:49,362 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:35:50,081 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:35:50,632 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:35:51,094 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:35:51,546 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:35:52,065 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:35:52,549 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:35:52,942 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:35:53,132 - INFO - validation batch 1, loss: 0.024, 32/6976 datapoints
2025-03-07 13:35:53,212 - INFO - validation batch 51, loss: 4.898, 1632/6976 datapoints
2025-03-07 13:35:53,290 - INFO - validation batch 101, loss: 0.497, 3232/6976 datapoints
2025-03-07 13:35:53,365 - INFO - validation batch 151, loss: 1.556, 4832/6976 datapoints
2025-03-07 13:35:53,439 - INFO - validation batch 201, loss: 1.266, 6432/6976 datapoints
2025-03-07 13:35:53,470 - INFO - Epoch 703/800 done.
2025-03-07 13:35:53,471 - INFO - Final validation performance:
Loss: 1.648, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:35:53,471 - INFO - Beginning epoch 704/800
2025-03-07 13:35:53,482 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:35:53,923 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:35:54,398 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:35:54,848 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:35:55,289 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:35:55,719 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:35:56,165 - INFO - training batch 301, loss: -0.000, 9632/28000 datapoints
2025-03-07 13:35:56,575 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:35:57,004 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:35:57,410 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:35:57,818 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:35:58,239 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:35:58,674 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:35:59,088 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:35:59,512 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:35:59,946 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:36:00,471 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:36:00,908 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:36:01,155 - INFO - validation batch 1, loss: 0.024, 32/6976 datapoints
2025-03-07 13:36:01,238 - INFO - validation batch 51, loss: 4.922, 1632/6976 datapoints
2025-03-07 13:36:01,324 - INFO - validation batch 101, loss: 0.501, 3232/6976 datapoints
2025-03-07 13:36:01,438 - INFO - validation batch 151, loss: 1.560, 4832/6976 datapoints
2025-03-07 13:36:01,534 - INFO - validation batch 201, loss: 1.280, 6432/6976 datapoints
2025-03-07 13:36:01,573 - INFO - Epoch 704/800 done.
2025-03-07 13:36:01,573 - INFO - Final validation performance:
Loss: 1.657, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:36:01,579 - INFO - Beginning epoch 705/800
2025-03-07 13:36:01,611 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:36:02,195 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:36:02,795 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:36:03,408 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:36:04,028 - INFO - training batch 201, loss: -0.000, 6432/28000 datapoints
2025-03-07 13:36:04,599 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:36:05,138 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:36:05,597 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:36:06,043 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:36:06,488 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:36:06,923 - INFO - training batch 501, loss: 0.156, 16032/28000 datapoints
2025-03-07 13:36:07,393 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:36:07,867 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:36:08,337 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:36:08,855 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:36:09,338 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:36:09,920 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:36:10,516 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:36:10,827 - INFO - validation batch 1, loss: 0.011, 32/6976 datapoints
2025-03-07 13:36:11,010 - INFO - validation batch 51, loss: 5.755, 1632/6976 datapoints
2025-03-07 13:36:11,137 - INFO - validation batch 101, loss: 0.422, 3232/6976 datapoints
2025-03-07 13:36:11,302 - INFO - validation batch 151, loss: 1.273, 4832/6976 datapoints
2025-03-07 13:36:11,409 - INFO - validation batch 201, loss: 1.504, 6432/6976 datapoints
2025-03-07 13:36:11,484 - INFO - Epoch 705/800 done.
2025-03-07 13:36:11,484 - INFO - Final validation performance:
Loss: 1.793, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:36:11,485 - INFO - Beginning epoch 706/800
2025-03-07 13:36:11,497 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:36:12,050 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:36:12,573 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:36:13,023 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:36:13,457 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:36:13,914 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:36:14,395 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:36:14,870 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:36:15,319 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:36:15,769 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:36:16,258 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:36:16,818 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:36:17,581 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:36:18,209 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:36:18,742 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:36:19,245 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:36:19,730 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:36:20,157 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:36:20,376 - INFO - validation batch 1, loss: 0.024, 32/6976 datapoints
2025-03-07 13:36:20,462 - INFO - validation batch 51, loss: 5.654, 1632/6976 datapoints
2025-03-07 13:36:20,545 - INFO - validation batch 101, loss: 0.262, 3232/6976 datapoints
2025-03-07 13:36:20,635 - INFO - validation batch 151, loss: 1.348, 4832/6976 datapoints
2025-03-07 13:36:20,719 - INFO - validation batch 201, loss: 1.500, 6432/6976 datapoints
2025-03-07 13:36:20,745 - INFO - Epoch 706/800 done.
2025-03-07 13:36:20,745 - INFO - Final validation performance:
Loss: 1.758, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 13:36:20,746 - INFO - Beginning epoch 707/800
2025-03-07 13:36:20,758 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:36:21,243 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:36:21,709 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:36:22,176 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:36:22,693 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:36:23,298 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:36:23,847 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:36:24,367 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:36:24,964 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:36:25,489 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:36:26,013 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:36:26,510 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:36:26,977 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:36:27,412 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:36:27,849 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:36:28,249 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:36:28,675 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:36:29,071 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:36:29,308 - INFO - validation batch 1, loss: 0.021, 32/6976 datapoints
2025-03-07 13:36:29,407 - INFO - validation batch 51, loss: 5.649, 1632/6976 datapoints
2025-03-07 13:36:29,514 - INFO - validation batch 101, loss: 0.277, 3232/6976 datapoints
2025-03-07 13:36:29,630 - INFO - validation batch 151, loss: 1.360, 4832/6976 datapoints
2025-03-07 13:36:29,733 - INFO - validation batch 201, loss: 1.498, 6432/6976 datapoints
2025-03-07 13:36:29,760 - INFO - Epoch 707/800 done.
2025-03-07 13:36:29,760 - INFO - Final validation performance:
Loss: 1.761, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 13:36:29,761 - INFO - Beginning epoch 708/800
2025-03-07 13:36:29,771 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:36:30,210 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:36:30,719 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:36:31,125 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:36:31,543 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:36:31,956 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:36:32,384 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:36:32,784 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:36:33,162 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:36:33,553 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:36:33,963 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:36:34,360 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:36:34,831 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:36:35,289 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:36:35,761 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:36:36,201 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:36:36,658 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:36:37,072 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:36:37,272 - INFO - validation batch 1, loss: 0.016, 32/6976 datapoints
2025-03-07 13:36:37,347 - INFO - validation batch 51, loss: 5.649, 1632/6976 datapoints
2025-03-07 13:36:37,425 - INFO - validation batch 101, loss: 0.286, 3232/6976 datapoints
2025-03-07 13:36:37,511 - INFO - validation batch 151, loss: 1.360, 4832/6976 datapoints
2025-03-07 13:36:37,592 - INFO - validation batch 201, loss: 1.483, 6432/6976 datapoints
2025-03-07 13:36:37,623 - INFO - Epoch 708/800 done.
2025-03-07 13:36:37,623 - INFO - Final validation performance:
Loss: 1.759, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 13:36:37,623 - INFO - Beginning epoch 709/800
2025-03-07 13:36:37,634 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:36:38,065 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:36:38,510 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:36:38,940 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:36:39,371 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:36:39,807 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:36:40,260 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:36:40,773 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:36:41,206 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:36:41,636 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:36:42,100 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:36:42,524 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:36:42,937 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:36:43,367 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:36:43,785 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:36:44,182 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:36:44,605 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:36:45,102 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:36:45,345 - INFO - validation batch 1, loss: 0.012, 32/6976 datapoints
2025-03-07 13:36:45,441 - INFO - validation batch 51, loss: 5.649, 1632/6976 datapoints
2025-03-07 13:36:45,533 - INFO - validation batch 101, loss: 0.294, 3232/6976 datapoints
2025-03-07 13:36:45,630 - INFO - validation batch 151, loss: 1.355, 4832/6976 datapoints
2025-03-07 13:36:45,705 - INFO - validation batch 201, loss: 1.464, 6432/6976 datapoints
2025-03-07 13:36:45,732 - INFO - Epoch 709/800 done.
2025-03-07 13:36:45,732 - INFO - Final validation performance:
Loss: 1.755, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 13:36:45,733 - INFO - Beginning epoch 710/800
2025-03-07 13:36:45,744 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:36:46,168 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:36:46,608 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:36:47,025 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:36:47,445 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:36:47,886 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:36:48,347 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:36:48,763 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:36:49,146 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:36:49,544 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:36:49,969 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:36:50,404 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:36:50,961 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:36:51,404 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:36:51,843 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:36:52,278 - INFO - training batch 751, loss: -0.000, 24032/28000 datapoints
2025-03-07 13:36:52,755 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:36:53,196 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:36:53,392 - INFO - validation batch 1, loss: 0.009, 32/6976 datapoints
2025-03-07 13:36:53,467 - INFO - validation batch 51, loss: 5.648, 1632/6976 datapoints
2025-03-07 13:36:53,549 - INFO - validation batch 101, loss: 0.302, 3232/6976 datapoints
2025-03-07 13:36:53,626 - INFO - validation batch 151, loss: 1.348, 4832/6976 datapoints
2025-03-07 13:36:53,713 - INFO - validation batch 201, loss: 1.444, 6432/6976 datapoints
2025-03-07 13:36:53,744 - INFO - Epoch 710/800 done.
2025-03-07 13:36:53,745 - INFO - Final validation performance:
Loss: 1.750, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 13:36:53,745 - INFO - Beginning epoch 711/800
2025-03-07 13:36:53,759 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:36:54,281 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:36:54,724 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:36:55,145 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:36:55,660 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:36:56,209 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:36:56,753 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:36:57,178 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:36:57,647 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:36:58,153 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:36:58,694 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:36:59,205 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:36:59,642 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:37:00,061 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:37:00,513 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:37:01,054 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:37:01,545 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:37:01,967 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:37:02,176 - INFO - validation batch 1, loss: 0.007, 32/6976 datapoints
2025-03-07 13:37:02,252 - INFO - validation batch 51, loss: 5.645, 1632/6976 datapoints
2025-03-07 13:37:02,332 - INFO - validation batch 101, loss: 0.308, 3232/6976 datapoints
2025-03-07 13:37:02,408 - INFO - validation batch 151, loss: 1.340, 4832/6976 datapoints
2025-03-07 13:37:02,483 - INFO - validation batch 201, loss: 1.424, 6432/6976 datapoints
2025-03-07 13:37:02,509 - INFO - Epoch 711/800 done.
2025-03-07 13:37:02,509 - INFO - Final validation performance:
Loss: 1.745, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:37:02,510 - INFO - Beginning epoch 712/800
2025-03-07 13:37:02,522 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:37:02,963 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:37:03,424 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:37:03,889 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:37:04,350 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:37:04,776 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:37:05,210 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:37:05,633 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:37:06,010 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:37:06,407 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:37:06,827 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:37:07,241 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:37:07,672 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:37:08,082 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:37:08,519 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:37:08,922 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:37:09,341 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:37:09,733 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:37:09,929 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:37:10,002 - INFO - validation batch 51, loss: 5.639, 1632/6976 datapoints
2025-03-07 13:37:10,075 - INFO - validation batch 101, loss: 0.314, 3232/6976 datapoints
2025-03-07 13:37:10,147 - INFO - validation batch 151, loss: 1.332, 4832/6976 datapoints
2025-03-07 13:37:10,222 - INFO - validation batch 201, loss: 1.405, 6432/6976 datapoints
2025-03-07 13:37:10,245 - INFO - Epoch 712/800 done.
2025-03-07 13:37:10,246 - INFO - Final validation performance:
Loss: 1.739, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:37:10,246 - INFO - Beginning epoch 713/800
2025-03-07 13:37:10,258 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:37:10,814 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:37:11,380 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:37:11,795 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:37:12,220 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:37:12,655 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:37:13,108 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:37:13,507 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:37:13,877 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:37:14,262 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:37:14,675 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:37:15,066 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:37:15,452 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:37:15,846 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:37:16,246 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:37:16,630 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:37:17,041 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:37:17,434 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:37:17,638 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:37:17,718 - INFO - validation batch 51, loss: 5.629, 1632/6976 datapoints
2025-03-07 13:37:17,814 - INFO - validation batch 101, loss: 0.316, 3232/6976 datapoints
2025-03-07 13:37:17,898 - INFO - validation batch 151, loss: 1.324, 4832/6976 datapoints
2025-03-07 13:37:17,981 - INFO - validation batch 201, loss: 1.386, 6432/6976 datapoints
2025-03-07 13:37:18,008 - INFO - Epoch 713/800 done.
2025-03-07 13:37:18,009 - INFO - Final validation performance:
Loss: 1.732, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 13:37:18,009 - INFO - Beginning epoch 714/800
2025-03-07 13:37:18,021 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:37:18,453 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:37:18,890 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:37:19,298 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:37:19,721 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:37:20,137 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:37:20,568 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:37:20,959 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:37:21,368 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:37:21,844 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:37:22,276 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:37:22,742 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:37:23,191 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:37:23,666 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:37:24,116 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:37:24,553 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:37:25,006 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:37:25,573 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:37:25,805 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:37:25,904 - INFO - validation batch 51, loss: 5.616, 1632/6976 datapoints
2025-03-07 13:37:26,001 - INFO - validation batch 101, loss: 0.316, 3232/6976 datapoints
2025-03-07 13:37:26,089 - INFO - validation batch 151, loss: 1.317, 4832/6976 datapoints
2025-03-07 13:37:26,188 - INFO - validation batch 201, loss: 1.368, 6432/6976 datapoints
2025-03-07 13:37:26,223 - INFO - Epoch 714/800 done.
2025-03-07 13:37:26,223 - INFO - Final validation performance:
Loss: 1.724, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:37:26,224 - INFO - Beginning epoch 715/800
2025-03-07 13:37:26,237 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:37:26,788 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:37:27,321 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:37:27,815 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:37:28,310 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:37:28,774 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:37:29,291 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:37:29,801 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:37:30,314 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:37:30,950 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:37:31,545 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:37:31,980 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:37:32,402 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:37:32,827 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:37:33,262 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:37:33,669 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:37:34,093 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:37:34,484 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:37:34,675 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:37:34,750 - INFO - validation batch 51, loss: 5.599, 1632/6976 datapoints
2025-03-07 13:37:34,823 - INFO - validation batch 101, loss: 0.313, 3232/6976 datapoints
2025-03-07 13:37:34,896 - INFO - validation batch 151, loss: 1.311, 4832/6976 datapoints
2025-03-07 13:37:34,967 - INFO - validation batch 201, loss: 1.350, 6432/6976 datapoints
2025-03-07 13:37:34,991 - INFO - Epoch 715/800 done.
2025-03-07 13:37:34,991 - INFO - Final validation performance:
Loss: 1.715, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 13:37:34,991 - INFO - Beginning epoch 716/800
2025-03-07 13:37:35,001 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:37:35,441 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:37:35,865 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:37:36,356 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:37:36,803 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:37:37,268 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:37:37,794 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:37:38,275 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:37:38,733 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:37:39,217 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:37:39,697 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:37:40,174 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:37:40,619 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:37:41,052 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:37:41,579 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:37:42,033 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:37:42,503 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:37:42,965 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:37:43,181 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:37:43,271 - INFO - validation batch 51, loss: 5.580, 1632/6976 datapoints
2025-03-07 13:37:43,354 - INFO - validation batch 101, loss: 0.307, 3232/6976 datapoints
2025-03-07 13:37:43,434 - INFO - validation batch 151, loss: 1.307, 4832/6976 datapoints
2025-03-07 13:37:43,529 - INFO - validation batch 201, loss: 1.333, 6432/6976 datapoints
2025-03-07 13:37:43,564 - INFO - Epoch 716/800 done.
2025-03-07 13:37:43,564 - INFO - Final validation performance:
Loss: 1.706, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 13:37:43,565 - INFO - Beginning epoch 717/800
2025-03-07 13:37:43,578 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:37:44,071 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:37:44,630 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:37:45,295 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:37:45,924 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:37:46,470 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:37:47,058 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:37:47,532 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:37:48,024 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:37:48,604 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:37:49,158 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:37:49,689 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:37:50,208 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:37:50,735 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:37:51,264 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:37:51,869 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:37:52,540 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:37:53,172 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:37:53,504 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:37:53,645 - INFO - validation batch 51, loss: 5.559, 1632/6976 datapoints
2025-03-07 13:37:53,767 - INFO - validation batch 101, loss: 0.301, 3232/6976 datapoints
2025-03-07 13:37:53,877 - INFO - validation batch 151, loss: 1.304, 4832/6976 datapoints
2025-03-07 13:37:53,980 - INFO - validation batch 201, loss: 1.317, 6432/6976 datapoints
2025-03-07 13:37:54,022 - INFO - Epoch 717/800 done.
2025-03-07 13:37:54,022 - INFO - Final validation performance:
Loss: 1.697, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 13:37:54,023 - INFO - Beginning epoch 718/800
2025-03-07 13:37:54,039 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:37:54,574 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:37:55,059 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:37:55,517 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:37:56,027 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:37:56,501 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:37:56,967 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:37:57,416 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:37:57,845 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:37:58,349 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:37:58,804 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:37:59,243 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:37:59,702 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:38:00,122 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:38:00,598 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:38:01,039 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:38:01,546 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:38:02,027 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:38:02,242 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:38:02,330 - INFO - validation batch 51, loss: 5.536, 1632/6976 datapoints
2025-03-07 13:38:02,415 - INFO - validation batch 101, loss: 0.295, 3232/6976 datapoints
2025-03-07 13:38:02,501 - INFO - validation batch 151, loss: 1.302, 4832/6976 datapoints
2025-03-07 13:38:02,595 - INFO - validation batch 201, loss: 1.300, 6432/6976 datapoints
2025-03-07 13:38:02,626 - INFO - Epoch 718/800 done.
2025-03-07 13:38:02,626 - INFO - Final validation performance:
Loss: 1.687, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:38:02,627 - INFO - Beginning epoch 719/800
2025-03-07 13:38:02,638 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:38:03,236 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:38:03,941 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:38:04,451 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:38:05,102 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:38:05,834 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:38:06,338 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:38:06,751 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:38:07,150 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:38:07,657 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:38:08,374 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:38:08,916 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:38:09,316 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:38:09,771 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:38:10,309 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:38:10,754 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:38:11,211 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:38:11,797 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:38:12,201 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:38:12,356 - INFO - validation batch 51, loss: 5.510, 1632/6976 datapoints
2025-03-07 13:38:12,532 - INFO - validation batch 101, loss: 0.290, 3232/6976 datapoints
2025-03-07 13:38:12,853 - INFO - validation batch 151, loss: 1.301, 4832/6976 datapoints
2025-03-07 13:38:13,130 - INFO - validation batch 201, loss: 1.281, 6432/6976 datapoints
2025-03-07 13:38:13,217 - INFO - Epoch 719/800 done.
2025-03-07 13:38:13,218 - INFO - Final validation performance:
Loss: 1.677, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 13:38:13,218 - INFO - Beginning epoch 720/800
2025-03-07 13:38:13,242 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:38:14,717 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:38:15,638 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:38:16,415 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:38:17,249 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:38:18,099 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:38:18,649 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:38:19,146 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:38:19,619 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:38:20,095 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:38:20,604 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:38:21,096 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:38:21,598 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:38:22,104 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:38:22,635 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:38:23,146 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:38:23,619 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:38:24,077 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:38:24,302 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:38:24,395 - INFO - validation batch 51, loss: 5.484, 1632/6976 datapoints
2025-03-07 13:38:24,499 - INFO - validation batch 101, loss: 0.285, 3232/6976 datapoints
2025-03-07 13:38:24,592 - INFO - validation batch 151, loss: 1.302, 4832/6976 datapoints
2025-03-07 13:38:24,684 - INFO - validation batch 201, loss: 1.261, 6432/6976 datapoints
2025-03-07 13:38:24,722 - INFO - Epoch 720/800 done.
2025-03-07 13:38:24,722 - INFO - Final validation performance:
Loss: 1.667, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:38:24,723 - INFO - Beginning epoch 721/800
2025-03-07 13:38:24,734 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:38:25,258 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:38:25,962 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:38:26,596 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:38:27,123 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:38:27,663 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:38:28,382 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:38:28,847 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:38:29,312 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:38:29,779 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:38:30,213 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:38:30,688 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:38:31,109 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:38:31,532 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:38:31,996 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:38:32,417 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:38:32,870 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:38:33,304 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:38:33,495 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:38:33,578 - INFO - validation batch 51, loss: 5.457, 1632/6976 datapoints
2025-03-07 13:38:33,652 - INFO - validation batch 101, loss: 0.279, 3232/6976 datapoints
2025-03-07 13:38:33,737 - INFO - validation batch 151, loss: 1.305, 4832/6976 datapoints
2025-03-07 13:38:33,820 - INFO - validation batch 201, loss: 1.240, 6432/6976 datapoints
2025-03-07 13:38:33,851 - INFO - Epoch 721/800 done.
2025-03-07 13:38:33,851 - INFO - Final validation performance:
Loss: 1.657, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:38:33,852 - INFO - Beginning epoch 722/800
2025-03-07 13:38:33,863 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:38:34,329 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:38:34,834 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:38:35,348 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:38:35,887 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:38:36,375 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:38:36,866 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:38:37,278 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:38:37,660 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:38:38,123 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:38:38,540 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:38:38,937 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:38:39,333 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:38:39,730 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:38:40,134 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:38:40,536 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:38:40,964 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:38:41,352 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:38:41,547 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 13:38:41,622 - INFO - validation batch 51, loss: 5.431, 1632/6976 datapoints
2025-03-07 13:38:41,704 - INFO - validation batch 101, loss: 0.273, 3232/6976 datapoints
2025-03-07 13:38:41,779 - INFO - validation batch 151, loss: 1.311, 4832/6976 datapoints
2025-03-07 13:38:41,851 - INFO - validation batch 201, loss: 1.220, 6432/6976 datapoints
2025-03-07 13:38:41,884 - INFO - Epoch 722/800 done.
2025-03-07 13:38:41,884 - INFO - Final validation performance:
Loss: 1.648, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:38:41,885 - INFO - Beginning epoch 723/800
2025-03-07 13:38:41,899 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:38:42,436 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:38:42,880 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:38:43,312 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:38:43,729 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:38:44,160 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:38:44,612 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:38:45,014 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:38:45,387 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:38:45,788 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:38:46,193 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:38:46,592 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:38:46,982 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:38:47,377 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:38:47,795 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:38:48,191 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:38:48,609 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:38:48,988 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:38:49,173 - INFO - validation batch 1, loss: 0.007, 32/6976 datapoints
2025-03-07 13:38:49,247 - INFO - validation batch 51, loss: 5.404, 1632/6976 datapoints
2025-03-07 13:38:49,320 - INFO - validation batch 101, loss: 0.267, 3232/6976 datapoints
2025-03-07 13:38:49,393 - INFO - validation batch 151, loss: 1.318, 4832/6976 datapoints
2025-03-07 13:38:49,471 - INFO - validation batch 201, loss: 1.201, 6432/6976 datapoints
2025-03-07 13:38:49,493 - INFO - Epoch 723/800 done.
2025-03-07 13:38:49,494 - INFO - Final validation performance:
Loss: 1.639, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 13:38:49,495 - INFO - Beginning epoch 724/800
2025-03-07 13:38:49,505 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:38:49,915 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:38:50,338 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:38:50,741 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:38:51,148 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:38:51,572 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:38:52,201 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:38:52,818 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:38:53,362 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:38:53,817 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:38:54,302 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:38:54,755 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:38:55,171 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:38:55,591 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:38:55,996 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:38:56,402 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:38:56,844 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:38:57,276 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:38:57,474 - INFO - validation batch 1, loss: 0.009, 32/6976 datapoints
2025-03-07 13:38:57,549 - INFO - validation batch 51, loss: 5.376, 1632/6976 datapoints
2025-03-07 13:38:57,621 - INFO - validation batch 101, loss: 0.261, 3232/6976 datapoints
2025-03-07 13:38:57,692 - INFO - validation batch 151, loss: 1.329, 4832/6976 datapoints
2025-03-07 13:38:57,771 - INFO - validation batch 201, loss: 1.187, 6432/6976 datapoints
2025-03-07 13:38:57,795 - INFO - Epoch 724/800 done.
2025-03-07 13:38:57,795 - INFO - Final validation performance:
Loss: 1.633, top-1 acc: 0.903top-5 acc: 0.903
2025-03-07 13:38:57,796 - INFO - Beginning epoch 725/800
2025-03-07 13:38:57,806 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:38:58,300 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:38:58,719 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:38:59,119 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:38:59,524 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:38:59,963 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:39:00,411 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:39:00,810 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:39:01,189 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:39:01,590 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:39:02,001 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:39:02,426 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:39:02,824 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:39:03,223 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:39:03,657 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:39:04,060 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:39:04,484 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:39:04,869 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:39:05,060 - INFO - validation batch 1, loss: 0.011, 32/6976 datapoints
2025-03-07 13:39:05,139 - INFO - validation batch 51, loss: 5.348, 1632/6976 datapoints
2025-03-07 13:39:05,211 - INFO - validation batch 101, loss: 0.258, 3232/6976 datapoints
2025-03-07 13:39:05,286 - INFO - validation batch 151, loss: 1.344, 4832/6976 datapoints
2025-03-07 13:39:05,359 - INFO - validation batch 201, loss: 1.174, 6432/6976 datapoints
2025-03-07 13:39:05,388 - INFO - Epoch 725/800 done.
2025-03-07 13:39:05,388 - INFO - Final validation performance:
Loss: 1.627, top-1 acc: 0.902top-5 acc: 0.902
2025-03-07 13:39:05,389 - INFO - Beginning epoch 726/800
2025-03-07 13:39:05,400 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:39:05,829 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:39:06,323 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:39:06,761 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:39:07,248 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:39:07,762 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:39:08,315 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:39:08,764 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:39:09,147 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:39:09,557 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:39:09,973 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:39:10,373 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:39:10,774 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:39:11,222 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:39:11,685 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:39:12,092 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:39:12,533 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:39:12,916 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:39:13,105 - INFO - validation batch 1, loss: 0.013, 32/6976 datapoints
2025-03-07 13:39:13,177 - INFO - validation batch 51, loss: 5.318, 1632/6976 datapoints
2025-03-07 13:39:13,249 - INFO - validation batch 101, loss: 0.260, 3232/6976 datapoints
2025-03-07 13:39:13,321 - INFO - validation batch 151, loss: 1.360, 4832/6976 datapoints
2025-03-07 13:39:13,394 - INFO - validation batch 201, loss: 1.169, 6432/6976 datapoints
2025-03-07 13:39:13,421 - INFO - Epoch 726/800 done.
2025-03-07 13:39:13,421 - INFO - Final validation performance:
Loss: 1.624, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:39:13,422 - INFO - Beginning epoch 727/800
2025-03-07 13:39:13,433 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:39:13,851 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:39:14,275 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:39:14,680 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:39:15,085 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:39:15,509 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:39:16,090 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:39:16,532 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:39:16,916 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:39:17,327 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:39:17,747 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:39:18,153 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:39:18,575 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:39:19,029 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:39:19,556 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:39:20,034 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:39:20,558 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:39:21,071 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:39:21,328 - INFO - validation batch 1, loss: 0.017, 32/6976 datapoints
2025-03-07 13:39:21,433 - INFO - validation batch 51, loss: 5.280, 1632/6976 datapoints
2025-03-07 13:39:21,575 - INFO - validation batch 101, loss: 0.275, 3232/6976 datapoints
2025-03-07 13:39:21,731 - INFO - validation batch 151, loss: 1.380, 4832/6976 datapoints
2025-03-07 13:39:21,949 - INFO - validation batch 201, loss: 1.163, 6432/6976 datapoints
2025-03-07 13:39:22,026 - INFO - Epoch 727/800 done.
2025-03-07 13:39:22,027 - INFO - Final validation performance:
Loss: 1.623, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:39:22,029 - INFO - Beginning epoch 728/800
2025-03-07 13:39:22,045 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:39:22,744 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:39:23,364 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:39:23,873 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:39:24,326 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:39:24,786 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:39:25,245 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:39:25,652 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:39:26,026 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:39:26,442 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:39:26,868 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:39:27,293 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:39:27,756 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:39:28,170 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:39:28,597 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:39:29,004 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:39:29,428 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:39:29,815 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:39:30,006 - INFO - validation batch 1, loss: 0.021, 32/6976 datapoints
2025-03-07 13:39:30,078 - INFO - validation batch 51, loss: 5.238, 1632/6976 datapoints
2025-03-07 13:39:30,150 - INFO - validation batch 101, loss: 0.299, 3232/6976 datapoints
2025-03-07 13:39:30,228 - INFO - validation batch 151, loss: 1.405, 4832/6976 datapoints
2025-03-07 13:39:30,305 - INFO - validation batch 201, loss: 1.164, 6432/6976 datapoints
2025-03-07 13:39:30,332 - INFO - Epoch 728/800 done.
2025-03-07 13:39:30,332 - INFO - Final validation performance:
Loss: 1.626, top-1 acc: 0.901top-5 acc: 0.901
2025-03-07 13:39:30,332 - INFO - Beginning epoch 729/800
2025-03-07 13:39:30,344 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:39:30,913 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:39:31,446 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:39:31,950 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:39:32,494 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:39:33,069 - INFO - training batch 251, loss: -0.000, 8032/28000 datapoints
2025-03-07 13:39:33,566 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:39:33,979 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:39:34,354 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:39:34,752 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:39:35,151 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:39:35,546 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:39:35,948 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:39:36,337 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:39:36,747 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:39:37,141 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:39:37,587 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:39:37,995 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:39:38,186 - INFO - validation batch 1, loss: 0.025, 32/6976 datapoints
2025-03-07 13:39:38,260 - INFO - validation batch 51, loss: 5.205, 1632/6976 datapoints
2025-03-07 13:39:38,333 - INFO - validation batch 101, loss: 0.319, 3232/6976 datapoints
2025-03-07 13:39:38,414 - INFO - validation batch 151, loss: 1.422, 4832/6976 datapoints
2025-03-07 13:39:38,486 - INFO - validation batch 201, loss: 1.163, 6432/6976 datapoints
2025-03-07 13:39:38,510 - INFO - Epoch 729/800 done.
2025-03-07 13:39:38,510 - INFO - Final validation performance:
Loss: 1.627, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:39:38,511 - INFO - Beginning epoch 730/800
2025-03-07 13:39:38,525 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:39:38,959 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:39:39,374 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:39:39,786 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:39:40,190 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:39:40,629 - INFO - training batch 251, loss: -0.000, 8032/28000 datapoints
2025-03-07 13:39:41,072 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:39:41,471 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:39:41,834 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:39:42,227 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:39:42,647 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:39:43,063 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:39:43,476 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:39:43,881 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:39:44,300 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:39:44,711 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:39:45,130 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:39:45,513 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:39:45,705 - INFO - validation batch 1, loss: 0.031, 32/6976 datapoints
2025-03-07 13:39:45,791 - INFO - validation batch 51, loss: 5.177, 1632/6976 datapoints
2025-03-07 13:39:45,867 - INFO - validation batch 101, loss: 0.348, 3232/6976 datapoints
2025-03-07 13:39:45,937 - INFO - validation batch 151, loss: 1.444, 4832/6976 datapoints
2025-03-07 13:39:46,009 - INFO - validation batch 201, loss: 1.165, 6432/6976 datapoints
2025-03-07 13:39:46,036 - INFO - Epoch 730/800 done.
2025-03-07 13:39:46,036 - INFO - Final validation performance:
Loss: 1.633, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:39:46,037 - INFO - Beginning epoch 731/800
2025-03-07 13:39:46,047 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:39:46,480 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:39:46,901 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:39:47,299 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:39:47,704 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:39:48,126 - INFO - training batch 251, loss: -0.000, 8032/28000 datapoints
2025-03-07 13:39:48,566 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:39:48,954 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:39:49,314 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:39:49,715 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:39:50,115 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:39:50,508 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:39:50,918 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:39:51,311 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:39:51,727 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:39:52,136 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:39:52,559 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:39:52,985 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:39:53,179 - INFO - validation batch 1, loss: 0.032, 32/6976 datapoints
2025-03-07 13:39:53,253 - INFO - validation batch 51, loss: 5.144, 1632/6976 datapoints
2025-03-07 13:39:53,330 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-07 13:39:53,404 - INFO - validation batch 151, loss: 1.459, 4832/6976 datapoints
2025-03-07 13:39:53,479 - INFO - validation batch 201, loss: 1.163, 6432/6976 datapoints
2025-03-07 13:39:53,503 - INFO - Epoch 731/800 done.
2025-03-07 13:39:53,504 - INFO - Final validation performance:
Loss: 1.635, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:39:53,504 - INFO - Beginning epoch 732/800
2025-03-07 13:39:53,517 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:39:53,943 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:39:54,369 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:39:54,784 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:39:55,191 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:39:55,622 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:39:56,062 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:39:56,475 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:39:56,842 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:39:57,233 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:39:57,638 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:39:58,082 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:39:58,481 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:39:58,880 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:39:59,283 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:39:59,708 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:40:00,135 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:40:00,532 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:40:00,727 - INFO - validation batch 1, loss: 0.035, 32/6976 datapoints
2025-03-07 13:40:00,799 - INFO - validation batch 51, loss: 5.102, 1632/6976 datapoints
2025-03-07 13:40:00,872 - INFO - validation batch 101, loss: 0.406, 3232/6976 datapoints
2025-03-07 13:40:00,944 - INFO - validation batch 151, loss: 1.473, 4832/6976 datapoints
2025-03-07 13:40:01,016 - INFO - validation batch 201, loss: 1.158, 6432/6976 datapoints
2025-03-07 13:40:01,041 - INFO - Epoch 732/800 done.
2025-03-07 13:40:01,041 - INFO - Final validation performance:
Loss: 1.635, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:40:01,042 - INFO - Beginning epoch 733/800
2025-03-07 13:40:01,051 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:40:01,479 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:40:01,916 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:40:02,329 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:40:02,762 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:40:03,242 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:40:03,738 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:40:04,173 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:40:04,552 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:40:04,999 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:40:05,598 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:40:06,052 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:40:06,486 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:40:06,946 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:40:07,404 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:40:07,868 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:40:08,324 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:40:08,745 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:40:08,940 - INFO - validation batch 1, loss: 0.035, 32/6976 datapoints
2025-03-07 13:40:09,013 - INFO - validation batch 51, loss: 5.084, 1632/6976 datapoints
2025-03-07 13:40:09,098 - INFO - validation batch 101, loss: 0.434, 3232/6976 datapoints
2025-03-07 13:40:09,180 - INFO - validation batch 151, loss: 1.479, 4832/6976 datapoints
2025-03-07 13:40:09,259 - INFO - validation batch 201, loss: 1.124, 6432/6976 datapoints
2025-03-07 13:40:09,288 - INFO - Epoch 733/800 done.
2025-03-07 13:40:09,288 - INFO - Final validation performance:
Loss: 1.631, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:40:09,289 - INFO - Beginning epoch 734/800
2025-03-07 13:40:09,301 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:40:09,782 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:40:10,241 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:40:10,669 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:40:11,095 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:40:11,611 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:40:12,185 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:40:12,661 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:40:13,082 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:40:13,486 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:40:13,937 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:40:14,340 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:40:14,787 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:40:15,239 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:40:15,699 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:40:16,133 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:40:16,609 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:40:17,056 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:40:17,287 - INFO - validation batch 1, loss: 0.028, 32/6976 datapoints
2025-03-07 13:40:17,370 - INFO - validation batch 51, loss: 5.088, 1632/6976 datapoints
2025-03-07 13:40:17,463 - INFO - validation batch 101, loss: 0.427, 3232/6976 datapoints
2025-03-07 13:40:17,554 - INFO - validation batch 151, loss: 1.452, 4832/6976 datapoints
2025-03-07 13:40:17,634 - INFO - validation batch 201, loss: 1.095, 6432/6976 datapoints
2025-03-07 13:40:17,663 - INFO - Epoch 734/800 done.
2025-03-07 13:40:17,663 - INFO - Final validation performance:
Loss: 1.618, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:40:17,664 - INFO - Beginning epoch 735/800
2025-03-07 13:40:17,675 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:40:18,108 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:40:18,578 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:40:19,026 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:40:19,475 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:40:19,921 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:40:20,381 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:40:20,784 - INFO - training batch 351, loss: -0.000, 11232/28000 datapoints
2025-03-07 13:40:21,154 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:40:21,581 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:40:22,045 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:40:22,491 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:40:22,947 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:40:23,424 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:40:23,911 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:40:24,298 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:40:24,751 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:40:25,174 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:40:25,385 - INFO - validation batch 1, loss: 0.148, 32/6976 datapoints
2025-03-07 13:40:25,483 - INFO - validation batch 51, loss: 4.699, 1632/6976 datapoints
2025-03-07 13:40:25,597 - INFO - validation batch 101, loss: 0.419, 3232/6976 datapoints
2025-03-07 13:40:25,688 - INFO - validation batch 151, loss: 1.432, 4832/6976 datapoints
2025-03-07 13:40:25,784 - INFO - validation batch 201, loss: 1.234, 6432/6976 datapoints
2025-03-07 13:40:25,816 - INFO - Epoch 735/800 done.
2025-03-07 13:40:25,816 - INFO - Final validation performance:
Loss: 1.586, top-1 acc: 0.896top-5 acc: 0.896
2025-03-07 13:40:25,817 - INFO - Beginning epoch 736/800
2025-03-07 13:40:25,829 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:40:26,403 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:40:27,079 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:40:27,615 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:40:28,176 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-07 13:40:28,628 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:40:29,068 - INFO - training batch 301, loss: 0.005, 9632/28000 datapoints
2025-03-07 13:40:29,476 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:40:29,871 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:40:30,311 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:40:30,776 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:40:31,180 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:40:31,586 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:40:31,993 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:40:32,401 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:40:32,803 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:40:33,346 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:40:33,820 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:40:34,089 - INFO - validation batch 1, loss: 0.058, 32/6976 datapoints
2025-03-07 13:40:34,193 - INFO - validation batch 51, loss: 4.438, 1632/6976 datapoints
2025-03-07 13:40:34,292 - INFO - validation batch 101, loss: 0.325, 3232/6976 datapoints
2025-03-07 13:40:34,391 - INFO - validation batch 151, loss: 1.740, 4832/6976 datapoints
2025-03-07 13:40:34,488 - INFO - validation batch 201, loss: 1.043, 6432/6976 datapoints
2025-03-07 13:40:34,525 - INFO - Epoch 736/800 done.
2025-03-07 13:40:34,525 - INFO - Final validation performance:
Loss: 1.521, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:40:34,525 - INFO - Beginning epoch 737/800
2025-03-07 13:40:34,538 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:40:35,147 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:40:35,725 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:40:36,227 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:40:36,690 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:40:37,128 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:40:37,617 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:40:38,105 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:40:38,625 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:40:39,182 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:40:39,734 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:40:40,252 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:40:40,818 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:40:41,338 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:40:41,899 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:40:42,421 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:40:42,970 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:40:43,478 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:40:43,688 - INFO - validation batch 1, loss: 0.046, 32/6976 datapoints
2025-03-07 13:40:43,765 - INFO - validation batch 51, loss: 4.491, 1632/6976 datapoints
2025-03-07 13:40:43,847 - INFO - validation batch 101, loss: 0.308, 3232/6976 datapoints
2025-03-07 13:40:43,926 - INFO - validation batch 151, loss: 1.684, 4832/6976 datapoints
2025-03-07 13:40:44,004 - INFO - validation batch 201, loss: 1.005, 6432/6976 datapoints
2025-03-07 13:40:44,032 - INFO - Epoch 737/800 done.
2025-03-07 13:40:44,033 - INFO - Final validation performance:
Loss: 1.507, top-1 acc: 0.897top-5 acc: 0.897
2025-03-07 13:40:44,033 - INFO - Beginning epoch 738/800
2025-03-07 13:40:44,043 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:40:44,483 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:40:44,928 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:40:45,416 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:40:45,966 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:40:46,440 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:40:46,908 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:40:47,312 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:40:47,710 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:40:48,120 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:40:48,606 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:40:49,107 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:40:49,568 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:40:50,017 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:40:50,484 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:40:50,954 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:40:51,420 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:40:51,874 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:40:52,087 - INFO - validation batch 1, loss: 0.048, 32/6976 datapoints
2025-03-07 13:40:52,185 - INFO - validation batch 51, loss: 4.509, 1632/6976 datapoints
2025-03-07 13:40:52,288 - INFO - validation batch 101, loss: 0.302, 3232/6976 datapoints
2025-03-07 13:40:52,405 - INFO - validation batch 151, loss: 1.670, 4832/6976 datapoints
2025-03-07 13:40:52,535 - INFO - validation batch 201, loss: 0.995, 6432/6976 datapoints
2025-03-07 13:40:52,583 - INFO - Epoch 738/800 done.
2025-03-07 13:40:52,584 - INFO - Final validation performance:
Loss: 1.505, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:40:52,586 - INFO - Beginning epoch 739/800
2025-03-07 13:40:52,599 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:40:53,165 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:40:53,762 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:40:54,191 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:40:54,664 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:40:55,115 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:40:55,573 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:40:55,981 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:40:56,369 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:40:56,828 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:40:57,311 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:40:57,802 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:40:58,320 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:40:58,844 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:40:59,385 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:40:59,915 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:41:00,454 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:41:00,942 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:41:01,151 - INFO - validation batch 1, loss: 0.051, 32/6976 datapoints
2025-03-07 13:41:01,233 - INFO - validation batch 51, loss: 4.524, 1632/6976 datapoints
2025-03-07 13:41:01,313 - INFO - validation batch 101, loss: 0.299, 3232/6976 datapoints
2025-03-07 13:41:01,394 - INFO - validation batch 151, loss: 1.660, 4832/6976 datapoints
2025-03-07 13:41:01,477 - INFO - validation batch 201, loss: 0.991, 6432/6976 datapoints
2025-03-07 13:41:01,501 - INFO - Epoch 739/800 done.
2025-03-07 13:41:01,502 - INFO - Final validation performance:
Loss: 1.505, top-1 acc: 0.897top-5 acc: 0.897
2025-03-07 13:41:01,502 - INFO - Beginning epoch 740/800
2025-03-07 13:41:01,514 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:41:01,996 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:41:02,429 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:41:02,846 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:41:03,269 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:41:03,723 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:41:04,164 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:41:04,560 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:41:04,936 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:41:05,329 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:41:05,754 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:41:06,144 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:41:06,557 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:41:06,965 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:41:07,377 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:41:07,790 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:41:08,208 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:41:08,592 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:41:08,778 - INFO - validation batch 1, loss: 0.054, 32/6976 datapoints
2025-03-07 13:41:08,849 - INFO - validation batch 51, loss: 4.541, 1632/6976 datapoints
2025-03-07 13:41:08,922 - INFO - validation batch 101, loss: 0.298, 3232/6976 datapoints
2025-03-07 13:41:08,992 - INFO - validation batch 151, loss: 1.650, 4832/6976 datapoints
2025-03-07 13:41:09,061 - INFO - validation batch 201, loss: 0.990, 6432/6976 datapoints
2025-03-07 13:41:09,084 - INFO - Epoch 740/800 done.
2025-03-07 13:41:09,084 - INFO - Final validation performance:
Loss: 1.506, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:41:09,085 - INFO - Beginning epoch 741/800
2025-03-07 13:41:09,095 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:41:09,522 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:41:09,976 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:41:10,393 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:41:10,834 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:41:11,277 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:41:11,751 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:41:12,200 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:41:12,599 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:41:13,017 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:41:13,469 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:41:13,985 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:41:14,448 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:41:14,979 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:41:15,504 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:41:15,935 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:41:16,397 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:41:16,797 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:41:16,997 - INFO - validation batch 1, loss: 0.057, 32/6976 datapoints
2025-03-07 13:41:17,072 - INFO - validation batch 51, loss: 4.558, 1632/6976 datapoints
2025-03-07 13:41:17,144 - INFO - validation batch 101, loss: 0.300, 3232/6976 datapoints
2025-03-07 13:41:17,245 - INFO - validation batch 151, loss: 1.640, 4832/6976 datapoints
2025-03-07 13:41:17,329 - INFO - validation batch 201, loss: 0.990, 6432/6976 datapoints
2025-03-07 13:41:17,355 - INFO - Epoch 741/800 done.
2025-03-07 13:41:17,355 - INFO - Final validation performance:
Loss: 1.509, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:41:17,355 - INFO - Beginning epoch 742/800
2025-03-07 13:41:17,367 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:41:17,830 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:41:18,331 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:41:18,878 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:41:19,401 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:41:19,924 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:41:20,499 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:41:21,013 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:41:21,437 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:41:21,937 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:41:22,592 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:41:23,108 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:41:23,603 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:41:24,570 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:41:25,088 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:41:25,546 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:41:25,991 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:41:26,385 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:41:26,584 - INFO - validation batch 1, loss: 0.060, 32/6976 datapoints
2025-03-07 13:41:26,658 - INFO - validation batch 51, loss: 4.576, 1632/6976 datapoints
2025-03-07 13:41:26,744 - INFO - validation batch 101, loss: 0.304, 3232/6976 datapoints
2025-03-07 13:41:26,821 - INFO - validation batch 151, loss: 1.629, 4832/6976 datapoints
2025-03-07 13:41:26,906 - INFO - validation batch 201, loss: 0.994, 6432/6976 datapoints
2025-03-07 13:41:26,940 - INFO - Epoch 742/800 done.
2025-03-07 13:41:26,940 - INFO - Final validation performance:
Loss: 1.512, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:41:26,941 - INFO - Beginning epoch 743/800
2025-03-07 13:41:26,953 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:41:27,475 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:41:27,906 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:41:28,368 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:41:28,841 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:41:29,279 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:41:29,728 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:41:30,117 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:41:30,525 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:41:31,005 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:41:31,428 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:41:31,845 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:41:32,265 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:41:32,673 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:41:33,094 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:41:33,502 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:41:33,942 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:41:34,338 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:41:34,524 - INFO - validation batch 1, loss: 0.063, 32/6976 datapoints
2025-03-07 13:41:34,601 - INFO - validation batch 51, loss: 4.594, 1632/6976 datapoints
2025-03-07 13:41:34,683 - INFO - validation batch 101, loss: 0.310, 3232/6976 datapoints
2025-03-07 13:41:34,768 - INFO - validation batch 151, loss: 1.616, 4832/6976 datapoints
2025-03-07 13:41:34,870 - INFO - validation batch 201, loss: 0.998, 6432/6976 datapoints
2025-03-07 13:41:34,903 - INFO - Epoch 743/800 done.
2025-03-07 13:41:34,903 - INFO - Final validation performance:
Loss: 1.516, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:41:34,904 - INFO - Beginning epoch 744/800
2025-03-07 13:41:34,919 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:41:35,375 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:41:35,844 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:41:36,257 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:41:36,708 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:41:37,183 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:41:37,644 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:41:38,050 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:41:38,425 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:41:38,836 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:41:39,248 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:41:39,650 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:41:40,070 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:41:40,472 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:41:40,894 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:41:41,299 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:41:41,716 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:41:42,114 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:41:42,316 - INFO - validation batch 1, loss: 0.065, 32/6976 datapoints
2025-03-07 13:41:42,403 - INFO - validation batch 51, loss: 4.612, 1632/6976 datapoints
2025-03-07 13:41:42,493 - INFO - validation batch 101, loss: 0.317, 3232/6976 datapoints
2025-03-07 13:41:42,591 - INFO - validation batch 151, loss: 1.601, 4832/6976 datapoints
2025-03-07 13:41:42,680 - INFO - validation batch 201, loss: 1.005, 6432/6976 datapoints
2025-03-07 13:41:42,708 - INFO - Epoch 744/800 done.
2025-03-07 13:41:42,708 - INFO - Final validation performance:
Loss: 1.520, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:41:42,709 - INFO - Beginning epoch 745/800
2025-03-07 13:41:42,724 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:41:43,201 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:41:43,629 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:41:44,055 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:41:44,481 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:41:44,941 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:41:45,494 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:41:45,908 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:41:46,303 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:41:46,775 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:41:47,242 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:41:47,693 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:41:48,167 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:41:48,749 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:41:49,232 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:41:49,787 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:41:50,564 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:41:51,584 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:41:52,039 - INFO - validation batch 1, loss: 0.068, 32/6976 datapoints
2025-03-07 13:41:52,172 - INFO - validation batch 51, loss: 4.630, 1632/6976 datapoints
2025-03-07 13:41:52,252 - INFO - validation batch 101, loss: 0.325, 3232/6976 datapoints
2025-03-07 13:41:52,333 - INFO - validation batch 151, loss: 1.584, 4832/6976 datapoints
2025-03-07 13:41:52,411 - INFO - validation batch 201, loss: 1.012, 6432/6976 datapoints
2025-03-07 13:41:52,446 - INFO - Epoch 745/800 done.
2025-03-07 13:41:52,446 - INFO - Final validation performance:
Loss: 1.524, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:41:52,447 - INFO - Beginning epoch 746/800
2025-03-07 13:41:52,462 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:41:52,999 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:41:53,490 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:41:53,966 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:41:54,948 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:41:55,448 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:41:55,909 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:41:56,339 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:41:56,771 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:41:57,191 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:41:57,616 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:41:58,026 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:41:58,485 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:41:58,902 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:41:59,325 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:41:59,736 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:42:00,201 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:42:00,586 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:42:00,788 - INFO - validation batch 1, loss: 0.070, 32/6976 datapoints
2025-03-07 13:42:00,872 - INFO - validation batch 51, loss: 4.648, 1632/6976 datapoints
2025-03-07 13:42:00,946 - INFO - validation batch 101, loss: 0.332, 3232/6976 datapoints
2025-03-07 13:42:01,019 - INFO - validation batch 151, loss: 1.565, 4832/6976 datapoints
2025-03-07 13:42:01,094 - INFO - validation batch 201, loss: 1.019, 6432/6976 datapoints
2025-03-07 13:42:01,125 - INFO - Epoch 746/800 done.
2025-03-07 13:42:01,126 - INFO - Final validation performance:
Loss: 1.527, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:42:01,126 - INFO - Beginning epoch 747/800
2025-03-07 13:42:01,137 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:42:01,597 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:42:02,043 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:42:02,464 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:42:02,937 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:42:03,380 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:42:03,839 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:42:04,283 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:42:04,676 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:42:05,107 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:42:05,612 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:42:06,031 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:42:06,452 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:42:06,876 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:42:07,299 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:42:07,708 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:42:08,136 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:42:08,548 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:42:08,739 - INFO - validation batch 1, loss: 0.071, 32/6976 datapoints
2025-03-07 13:42:08,812 - INFO - validation batch 51, loss: 4.666, 1632/6976 datapoints
2025-03-07 13:42:08,888 - INFO - validation batch 101, loss: 0.337, 3232/6976 datapoints
2025-03-07 13:42:08,961 - INFO - validation batch 151, loss: 1.546, 4832/6976 datapoints
2025-03-07 13:42:09,036 - INFO - validation batch 201, loss: 1.028, 6432/6976 datapoints
2025-03-07 13:42:09,059 - INFO - Epoch 747/800 done.
2025-03-07 13:42:09,059 - INFO - Final validation performance:
Loss: 1.530, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:42:09,060 - INFO - Beginning epoch 748/800
2025-03-07 13:42:09,073 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:42:09,504 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:42:09,931 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:42:10,337 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:42:10,775 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:42:11,211 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:42:11,672 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:42:12,082 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:42:12,459 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:42:12,873 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:42:13,285 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:42:13,688 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:42:14,117 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:42:14,548 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:42:14,970 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:42:15,381 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:42:15,802 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:42:16,188 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:42:16,375 - INFO - validation batch 1, loss: 0.073, 32/6976 datapoints
2025-03-07 13:42:16,448 - INFO - validation batch 51, loss: 4.682, 1632/6976 datapoints
2025-03-07 13:42:16,522 - INFO - validation batch 101, loss: 0.342, 3232/6976 datapoints
2025-03-07 13:42:16,604 - INFO - validation batch 151, loss: 1.528, 4832/6976 datapoints
2025-03-07 13:42:16,675 - INFO - validation batch 201, loss: 1.038, 6432/6976 datapoints
2025-03-07 13:42:16,698 - INFO - Epoch 748/800 done.
2025-03-07 13:42:16,698 - INFO - Final validation performance:
Loss: 1.532, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:42:16,699 - INFO - Beginning epoch 749/800
2025-03-07 13:42:16,709 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:42:17,129 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:42:17,551 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:42:17,967 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:42:18,398 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:42:18,842 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:42:19,292 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:42:19,693 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:42:20,092 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:42:20,552 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:42:21,045 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:42:21,593 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:42:22,045 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:42:22,491 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:42:22,970 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:42:23,403 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:42:23,842 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:42:24,241 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:42:24,457 - INFO - validation batch 1, loss: 0.074, 32/6976 datapoints
2025-03-07 13:42:24,532 - INFO - validation batch 51, loss: 4.698, 1632/6976 datapoints
2025-03-07 13:42:24,608 - INFO - validation batch 101, loss: 0.345, 3232/6976 datapoints
2025-03-07 13:42:24,703 - INFO - validation batch 151, loss: 1.512, 4832/6976 datapoints
2025-03-07 13:42:24,777 - INFO - validation batch 201, loss: 1.047, 6432/6976 datapoints
2025-03-07 13:42:24,802 - INFO - Epoch 749/800 done.
2025-03-07 13:42:24,802 - INFO - Final validation performance:
Loss: 1.535, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:42:24,803 - INFO - Beginning epoch 750/800
2025-03-07 13:42:24,814 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:42:25,260 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:42:25,724 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:42:26,164 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:42:26,715 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:42:27,237 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:42:27,815 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:42:28,366 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:42:29,083 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:42:29,537 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:42:29,986 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:42:30,407 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:42:30,867 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:42:31,306 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:42:31,799 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:42:32,256 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:42:32,770 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:42:33,248 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:42:33,497 - INFO - validation batch 1, loss: 0.075, 32/6976 datapoints
2025-03-07 13:42:33,594 - INFO - validation batch 51, loss: 4.712, 1632/6976 datapoints
2025-03-07 13:42:33,694 - INFO - validation batch 101, loss: 0.347, 3232/6976 datapoints
2025-03-07 13:42:33,773 - INFO - validation batch 151, loss: 1.498, 4832/6976 datapoints
2025-03-07 13:42:33,854 - INFO - validation batch 201, loss: 1.056, 6432/6976 datapoints
2025-03-07 13:42:33,888 - INFO - Epoch 750/800 done.
2025-03-07 13:42:33,889 - INFO - Final validation performance:
Loss: 1.538, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:42:33,890 - INFO - Beginning epoch 751/800
2025-03-07 13:42:33,901 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:42:34,401 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:42:34,948 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:42:35,483 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:42:36,051 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:42:36,536 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:42:37,006 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:42:37,398 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:42:37,775 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:42:38,172 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:42:38,640 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:42:39,077 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:42:39,507 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:42:39,951 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:42:40,441 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:42:40,987 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:42:41,497 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:42:42,028 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:42:42,236 - INFO - validation batch 1, loss: 0.075, 32/6976 datapoints
2025-03-07 13:42:42,317 - INFO - validation batch 51, loss: 4.728, 1632/6976 datapoints
2025-03-07 13:42:42,407 - INFO - validation batch 101, loss: 0.349, 3232/6976 datapoints
2025-03-07 13:42:42,493 - INFO - validation batch 151, loss: 1.487, 4832/6976 datapoints
2025-03-07 13:42:42,587 - INFO - validation batch 201, loss: 1.063, 6432/6976 datapoints
2025-03-07 13:42:42,615 - INFO - Epoch 751/800 done.
2025-03-07 13:42:42,615 - INFO - Final validation performance:
Loss: 1.540, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:42:42,616 - INFO - Beginning epoch 752/800
2025-03-07 13:42:42,628 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:42:43,100 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:42:43,556 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:42:43,962 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:42:44,387 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:42:44,850 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:42:45,333 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:42:45,803 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:42:46,265 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:42:46,725 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:42:47,199 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:42:47,754 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:42:48,211 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:42:48,647 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:42:49,085 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:42:49,537 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:42:50,033 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:42:50,478 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:42:50,685 - INFO - validation batch 1, loss: 0.075, 32/6976 datapoints
2025-03-07 13:42:50,772 - INFO - validation batch 51, loss: 4.741, 1632/6976 datapoints
2025-03-07 13:42:50,857 - INFO - validation batch 101, loss: 0.352, 3232/6976 datapoints
2025-03-07 13:42:50,934 - INFO - validation batch 151, loss: 1.477, 4832/6976 datapoints
2025-03-07 13:42:51,011 - INFO - validation batch 201, loss: 1.068, 6432/6976 datapoints
2025-03-07 13:42:51,039 - INFO - Epoch 752/800 done.
2025-03-07 13:42:51,039 - INFO - Final validation performance:
Loss: 1.543, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:42:51,040 - INFO - Beginning epoch 753/800
2025-03-07 13:42:51,051 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:42:51,516 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:42:51,947 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:42:52,365 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:42:52,859 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:42:53,330 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:42:53,837 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:42:54,282 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:42:54,698 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:42:55,160 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:42:55,591 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:42:56,004 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:42:56,460 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:42:56,895 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:42:57,333 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:42:57,754 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:42:58,247 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:42:58,640 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:42:58,829 - INFO - validation batch 1, loss: 0.074, 32/6976 datapoints
2025-03-07 13:42:58,903 - INFO - validation batch 51, loss: 4.755, 1632/6976 datapoints
2025-03-07 13:42:58,979 - INFO - validation batch 101, loss: 0.354, 3232/6976 datapoints
2025-03-07 13:42:59,052 - INFO - validation batch 151, loss: 1.471, 4832/6976 datapoints
2025-03-07 13:42:59,123 - INFO - validation batch 201, loss: 1.074, 6432/6976 datapoints
2025-03-07 13:42:59,148 - INFO - Epoch 753/800 done.
2025-03-07 13:42:59,148 - INFO - Final validation performance:
Loss: 1.546, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:42:59,148 - INFO - Beginning epoch 754/800
2025-03-07 13:42:59,158 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:42:59,664 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:43:00,132 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:43:00,616 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:43:01,086 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:43:01,626 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:43:02,285 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:43:02,809 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:43:03,240 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:43:03,707 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:43:04,160 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:43:04,748 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:43:05,219 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:43:05,665 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:43:06,135 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:43:06,617 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:43:07,148 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:43:07,560 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:43:07,769 - INFO - validation batch 1, loss: 0.073, 32/6976 datapoints
2025-03-07 13:43:07,853 - INFO - validation batch 51, loss: 4.773, 1632/6976 datapoints
2025-03-07 13:43:07,967 - INFO - validation batch 101, loss: 0.355, 3232/6976 datapoints
2025-03-07 13:43:08,129 - INFO - validation batch 151, loss: 1.468, 4832/6976 datapoints
2025-03-07 13:43:08,220 - INFO - validation batch 201, loss: 1.081, 6432/6976 datapoints
2025-03-07 13:43:08,250 - INFO - Epoch 754/800 done.
2025-03-07 13:43:08,250 - INFO - Final validation performance:
Loss: 1.550, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:43:08,251 - INFO - Beginning epoch 755/800
2025-03-07 13:43:08,266 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:43:08,736 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:43:09,279 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:43:09,771 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:43:10,293 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:43:10,798 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:43:11,309 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:43:11,765 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:43:12,220 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:43:12,707 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:43:13,192 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:43:13,658 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:43:14,136 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:43:14,624 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:43:15,170 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:43:15,634 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:43:16,159 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:43:16,589 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:43:16,821 - INFO - validation batch 1, loss: 0.071, 32/6976 datapoints
2025-03-07 13:43:16,925 - INFO - validation batch 51, loss: 4.795, 1632/6976 datapoints
2025-03-07 13:43:17,030 - INFO - validation batch 101, loss: 0.355, 3232/6976 datapoints
2025-03-07 13:43:17,119 - INFO - validation batch 151, loss: 1.466, 4832/6976 datapoints
2025-03-07 13:43:17,220 - INFO - validation batch 201, loss: 1.093, 6432/6976 datapoints
2025-03-07 13:43:17,254 - INFO - Epoch 755/800 done.
2025-03-07 13:43:17,255 - INFO - Final validation performance:
Loss: 1.556, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:43:17,255 - INFO - Beginning epoch 756/800
2025-03-07 13:43:17,268 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:43:17,770 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:43:18,241 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:43:18,681 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:43:19,130 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:43:19,586 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:43:20,072 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:43:20,542 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:43:20,973 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:43:21,503 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:43:23,019 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:43:23,934 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:43:24,563 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:43:25,093 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:43:25,572 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:43:26,110 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:43:26,619 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:43:27,262 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:43:27,573 - INFO - validation batch 1, loss: 0.069, 32/6976 datapoints
2025-03-07 13:43:27,778 - INFO - validation batch 51, loss: 4.819, 1632/6976 datapoints
2025-03-07 13:43:27,899 - INFO - validation batch 101, loss: 0.353, 3232/6976 datapoints
2025-03-07 13:43:27,996 - INFO - validation batch 151, loss: 1.467, 4832/6976 datapoints
2025-03-07 13:43:28,090 - INFO - validation batch 201, loss: 1.105, 6432/6976 datapoints
2025-03-07 13:43:28,124 - INFO - Epoch 756/800 done.
2025-03-07 13:43:28,125 - INFO - Final validation performance:
Loss: 1.563, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:43:28,128 - INFO - Beginning epoch 757/800
2025-03-07 13:43:28,144 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:43:28,669 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:43:29,140 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:43:29,674 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:43:30,166 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:43:30,664 - INFO - training batch 251, loss: -0.000, 8032/28000 datapoints
2025-03-07 13:43:31,129 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:43:31,565 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:43:32,014 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:43:32,455 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:43:32,902 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:43:33,305 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:43:33,725 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:43:34,134 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:43:34,575 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:43:35,110 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:43:35,719 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:43:36,220 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:43:36,477 - INFO - validation batch 1, loss: 0.065, 32/6976 datapoints
2025-03-07 13:43:36,587 - INFO - validation batch 51, loss: 4.849, 1632/6976 datapoints
2025-03-07 13:43:36,698 - INFO - validation batch 101, loss: 0.349, 3232/6976 datapoints
2025-03-07 13:43:36,826 - INFO - validation batch 151, loss: 1.466, 4832/6976 datapoints
2025-03-07 13:43:36,959 - INFO - validation batch 201, loss: 1.114, 6432/6976 datapoints
2025-03-07 13:43:36,989 - INFO - Epoch 757/800 done.
2025-03-07 13:43:36,989 - INFO - Final validation performance:
Loss: 1.569, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:43:36,990 - INFO - Beginning epoch 758/800
2025-03-07 13:43:37,001 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:43:37,616 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:43:38,328 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:43:39,039 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:43:39,892 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:43:40,744 - INFO - training batch 251, loss: -0.000, 8032/28000 datapoints
2025-03-07 13:43:41,329 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:43:41,848 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:43:42,332 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:43:42,847 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:43:43,428 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:43:44,085 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:43:44,624 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:43:45,302 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:43:45,975 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:43:46,609 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:43:47,143 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:43:47,626 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:43:47,844 - INFO - validation batch 1, loss: 0.064, 32/6976 datapoints
2025-03-07 13:43:47,940 - INFO - validation batch 51, loss: 4.872, 1632/6976 datapoints
2025-03-07 13:43:48,017 - INFO - validation batch 101, loss: 0.345, 3232/6976 datapoints
2025-03-07 13:43:48,099 - INFO - validation batch 151, loss: 1.476, 4832/6976 datapoints
2025-03-07 13:43:48,191 - INFO - validation batch 201, loss: 1.124, 6432/6976 datapoints
2025-03-07 13:43:48,226 - INFO - Epoch 758/800 done.
2025-03-07 13:43:48,226 - INFO - Final validation performance:
Loss: 1.576, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:43:48,227 - INFO - Beginning epoch 759/800
2025-03-07 13:43:48,238 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:43:48,743 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:43:49,212 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:43:49,648 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:43:50,107 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:43:50,567 - INFO - training batch 251, loss: -0.000, 8032/28000 datapoints
2025-03-07 13:43:51,076 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:43:51,711 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:43:52,271 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:43:52,841 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:43:53,321 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:43:53,841 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:43:54,453 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:43:55,017 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:43:55,521 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:43:55,960 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:43:56,406 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:43:56,809 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:43:57,005 - INFO - validation batch 1, loss: 0.060, 32/6976 datapoints
2025-03-07 13:43:57,110 - INFO - validation batch 51, loss: 4.887, 1632/6976 datapoints
2025-03-07 13:43:57,209 - INFO - validation batch 101, loss: 0.349, 3232/6976 datapoints
2025-03-07 13:43:57,289 - INFO - validation batch 151, loss: 1.485, 4832/6976 datapoints
2025-03-07 13:43:57,372 - INFO - validation batch 201, loss: 1.122, 6432/6976 datapoints
2025-03-07 13:43:57,400 - INFO - Epoch 759/800 done.
2025-03-07 13:43:57,400 - INFO - Final validation performance:
Loss: 1.581, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:43:57,401 - INFO - Beginning epoch 760/800
2025-03-07 13:43:57,413 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:43:58,149 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:43:58,757 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:43:59,270 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:43:59,816 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:44:00,332 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:44:00,859 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:44:01,306 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:44:01,716 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:44:02,161 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:44:02,602 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:44:03,050 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:44:03,617 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:44:04,076 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:44:04,503 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:44:04,963 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:44:05,452 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:44:05,879 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:44:06,076 - INFO - validation batch 1, loss: 0.064, 32/6976 datapoints
2025-03-07 13:44:06,152 - INFO - validation batch 51, loss: 4.889, 1632/6976 datapoints
2025-03-07 13:44:06,235 - INFO - validation batch 101, loss: 0.357, 3232/6976 datapoints
2025-03-07 13:44:06,307 - INFO - validation batch 151, loss: 1.498, 4832/6976 datapoints
2025-03-07 13:44:06,382 - INFO - validation batch 201, loss: 1.119, 6432/6976 datapoints
2025-03-07 13:44:06,405 - INFO - Epoch 760/800 done.
2025-03-07 13:44:06,405 - INFO - Final validation performance:
Loss: 1.585, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:44:06,407 - INFO - Beginning epoch 761/800
2025-03-07 13:44:06,419 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:44:06,849 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:44:07,271 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:44:07,686 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:44:08,138 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:44:08,618 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:44:09,101 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:44:09,542 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:44:10,041 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:44:10,540 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:44:10,973 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:44:11,403 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:44:11,842 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:44:12,281 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:44:12,726 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:44:13,137 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:44:13,554 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:44:13,947 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:44:14,141 - INFO - validation batch 1, loss: 0.062, 32/6976 datapoints
2025-03-07 13:44:14,218 - INFO - validation batch 51, loss: 4.882, 1632/6976 datapoints
2025-03-07 13:44:14,290 - INFO - validation batch 101, loss: 0.353, 3232/6976 datapoints
2025-03-07 13:44:14,372 - INFO - validation batch 151, loss: 1.508, 4832/6976 datapoints
2025-03-07 13:44:14,447 - INFO - validation batch 201, loss: 1.102, 6432/6976 datapoints
2025-03-07 13:44:14,478 - INFO - Epoch 761/800 done.
2025-03-07 13:44:14,478 - INFO - Final validation performance:
Loss: 1.581, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:44:14,479 - INFO - Beginning epoch 762/800
2025-03-07 13:44:14,489 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:44:14,952 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:44:15,388 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:44:15,832 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:44:16,282 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:44:16,768 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:44:17,288 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:44:17,876 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:44:18,294 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:44:18,820 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:44:19,334 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:44:19,815 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:44:20,466 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:44:20,917 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:44:21,356 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:44:21,798 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:44:22,242 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:44:22,761 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:44:23,079 - INFO - validation batch 1, loss: 0.064, 32/6976 datapoints
2025-03-07 13:44:23,234 - INFO - validation batch 51, loss: 4.896, 1632/6976 datapoints
2025-03-07 13:44:23,361 - INFO - validation batch 101, loss: 0.361, 3232/6976 datapoints
2025-03-07 13:44:23,449 - INFO - validation batch 151, loss: 1.522, 4832/6976 datapoints
2025-03-07 13:44:23,554 - INFO - validation batch 201, loss: 1.087, 6432/6976 datapoints
2025-03-07 13:44:23,597 - INFO - Epoch 762/800 done.
2025-03-07 13:44:23,597 - INFO - Final validation performance:
Loss: 1.586, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:44:23,598 - INFO - Beginning epoch 763/800
2025-03-07 13:44:23,616 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:44:24,130 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:44:24,655 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:44:25,195 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:44:25,709 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:44:26,309 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:44:26,832 - INFO - training batch 301, loss: -0.000, 9632/28000 datapoints
2025-03-07 13:44:27,285 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:44:27,689 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:44:28,108 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:44:28,557 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:44:29,033 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:44:29,485 - INFO - training batch 601, loss: -0.000, 19232/28000 datapoints
2025-03-07 13:44:29,933 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:44:30,484 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:44:31,021 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:44:31,680 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:44:32,180 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:44:32,392 - INFO - validation batch 1, loss: 0.071, 32/6976 datapoints
2025-03-07 13:44:32,468 - INFO - validation batch 51, loss: 4.919, 1632/6976 datapoints
2025-03-07 13:44:32,546 - INFO - validation batch 101, loss: 0.383, 3232/6976 datapoints
2025-03-07 13:44:32,632 - INFO - validation batch 151, loss: 1.540, 4832/6976 datapoints
2025-03-07 13:44:32,711 - INFO - validation batch 201, loss: 1.077, 6432/6976 datapoints
2025-03-07 13:44:32,749 - INFO - Epoch 763/800 done.
2025-03-07 13:44:32,749 - INFO - Final validation performance:
Loss: 1.598, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:44:32,750 - INFO - Beginning epoch 764/800
2025-03-07 13:44:32,763 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:44:33,224 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:44:33,707 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:44:34,300 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:44:34,779 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:44:35,263 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:44:35,758 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:44:36,318 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:44:36,772 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:44:37,217 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:44:37,712 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:44:38,194 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:44:38,703 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:44:39,219 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:44:39,721 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:44:40,251 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:44:40,974 - INFO - training batch 801, loss: -0.000, 25632/28000 datapoints
2025-03-07 13:44:41,436 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:44:41,663 - INFO - validation batch 1, loss: 0.046, 32/6976 datapoints
2025-03-07 13:44:41,754 - INFO - validation batch 51, loss: 4.953, 1632/6976 datapoints
2025-03-07 13:44:41,832 - INFO - validation batch 101, loss: 0.415, 3232/6976 datapoints
2025-03-07 13:44:41,920 - INFO - validation batch 151, loss: 1.522, 4832/6976 datapoints
2025-03-07 13:44:42,018 - INFO - validation batch 201, loss: 1.082, 6432/6976 datapoints
2025-03-07 13:44:42,047 - INFO - Epoch 764/800 done.
2025-03-07 13:44:42,047 - INFO - Final validation performance:
Loss: 1.604, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:44:42,047 - INFO - Beginning epoch 765/800
2025-03-07 13:44:42,058 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:44:42,570 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:44:43,042 - INFO - training batch 101, loss: -0.000, 3232/28000 datapoints
2025-03-07 13:44:43,505 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:44:43,962 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:44:44,481 - INFO - training batch 251, loss: 0.108, 8032/28000 datapoints
2025-03-07 13:44:44,960 - INFO - training batch 301, loss: 0.013, 9632/28000 datapoints
2025-03-07 13:44:45,470 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:44:45,925 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:44:46,344 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:44:46,777 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:44:47,222 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:44:47,655 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:44:48,082 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:44:48,502 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:44:48,939 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:44:49,365 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:44:49,761 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 13:44:49,953 - INFO - validation batch 1, loss: 0.010, 32/6976 datapoints
2025-03-07 13:44:50,031 - INFO - validation batch 51, loss: 5.246, 1632/6976 datapoints
2025-03-07 13:44:50,104 - INFO - validation batch 101, loss: 0.616, 3232/6976 datapoints
2025-03-07 13:44:50,180 - INFO - validation batch 151, loss: 1.402, 4832/6976 datapoints
2025-03-07 13:44:50,258 - INFO - validation batch 201, loss: 0.992, 6432/6976 datapoints
2025-03-07 13:44:50,285 - INFO - Epoch 765/800 done.
2025-03-07 13:44:50,286 - INFO - Final validation performance:
Loss: 1.653, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:44:50,286 - INFO - Beginning epoch 766/800
2025-03-07 13:44:50,295 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:44:50,802 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:44:51,286 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:44:51,736 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:44:52,182 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:44:52,627 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:44:53,119 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:44:53,582 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:44:54,011 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:44:54,415 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:44:54,859 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:44:55,297 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:44:55,711 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:44:56,158 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:44:56,570 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:44:57,026 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:44:57,466 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:44:57,873 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:44:58,108 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:44:58,179 - INFO - validation batch 51, loss: 5.151, 1632/6976 datapoints
2025-03-07 13:44:58,253 - INFO - validation batch 101, loss: 0.608, 3232/6976 datapoints
2025-03-07 13:44:58,325 - INFO - validation batch 151, loss: 1.389, 4832/6976 datapoints
2025-03-07 13:44:58,397 - INFO - validation batch 201, loss: 0.879, 6432/6976 datapoints
2025-03-07 13:44:58,422 - INFO - Epoch 766/800 done.
2025-03-07 13:44:58,422 - INFO - Final validation performance:
Loss: 1.606, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:44:58,423 - INFO - Beginning epoch 767/800
2025-03-07 13:44:58,432 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:44:58,849 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:44:59,352 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:44:59,778 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:45:00,208 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:45:00,693 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:45:01,158 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:45:01,614 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:45:02,018 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:45:02,447 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:45:02,873 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:45:03,327 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:45:03,754 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:45:04,195 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:45:04,624 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:45:05,083 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:45:05,526 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:45:05,975 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:45:06,226 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:45:06,318 - INFO - validation batch 51, loss: 5.127, 1632/6976 datapoints
2025-03-07 13:45:06,407 - INFO - validation batch 101, loss: 0.591, 3232/6976 datapoints
2025-03-07 13:45:06,497 - INFO - validation batch 151, loss: 1.400, 4832/6976 datapoints
2025-03-07 13:45:06,597 - INFO - validation batch 201, loss: 0.880, 6432/6976 datapoints
2025-03-07 13:45:06,631 - INFO - Epoch 767/800 done.
2025-03-07 13:45:06,631 - INFO - Final validation performance:
Loss: 1.600, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:45:06,632 - INFO - Beginning epoch 768/800
2025-03-07 13:45:06,642 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:45:07,185 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:45:07,732 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:45:08,290 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:45:08,919 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:45:09,562 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:45:10,180 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:45:10,847 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:45:11,336 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:45:11,914 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:45:12,448 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:45:13,252 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:45:13,986 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:45:14,609 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:45:15,251 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:45:15,796 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:45:16,366 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:45:16,806 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:45:17,016 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:45:17,102 - INFO - validation batch 51, loss: 5.105, 1632/6976 datapoints
2025-03-07 13:45:17,179 - INFO - validation batch 101, loss: 0.574, 3232/6976 datapoints
2025-03-07 13:45:17,257 - INFO - validation batch 151, loss: 1.408, 4832/6976 datapoints
2025-03-07 13:45:17,341 - INFO - validation batch 201, loss: 0.880, 6432/6976 datapoints
2025-03-07 13:45:17,368 - INFO - Epoch 768/800 done.
2025-03-07 13:45:17,368 - INFO - Final validation performance:
Loss: 1.594, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:45:17,369 - INFO - Beginning epoch 769/800
2025-03-07 13:45:17,379 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:45:17,918 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:45:18,420 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:45:18,876 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:45:19,351 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:45:19,870 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:45:20,354 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:45:20,810 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:45:21,229 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:45:21,650 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:45:22,366 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:45:23,084 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:45:23,696 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:45:24,186 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:45:24,638 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:45:25,115 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:45:25,579 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:45:25,980 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:45:26,171 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:45:26,242 - INFO - validation batch 51, loss: 5.084, 1632/6976 datapoints
2025-03-07 13:45:26,330 - INFO - validation batch 101, loss: 0.558, 3232/6976 datapoints
2025-03-07 13:45:26,422 - INFO - validation batch 151, loss: 1.417, 4832/6976 datapoints
2025-03-07 13:45:26,495 - INFO - validation batch 201, loss: 0.881, 6432/6976 datapoints
2025-03-07 13:45:26,520 - INFO - Epoch 769/800 done.
2025-03-07 13:45:26,520 - INFO - Final validation performance:
Loss: 1.588, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:45:26,522 - INFO - Beginning epoch 770/800
2025-03-07 13:45:26,531 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:45:26,957 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:45:27,403 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:45:27,824 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:45:28,237 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:45:28,673 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:45:29,137 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:45:29,559 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:45:29,970 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:45:30,367 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:45:30,993 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:45:31,587 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:45:32,054 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:45:32,479 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:45:32,926 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:45:33,422 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:45:33,890 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:45:34,301 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:45:34,499 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:45:34,588 - INFO - validation batch 51, loss: 5.064, 1632/6976 datapoints
2025-03-07 13:45:34,674 - INFO - validation batch 101, loss: 0.543, 3232/6976 datapoints
2025-03-07 13:45:34,761 - INFO - validation batch 151, loss: 1.424, 4832/6976 datapoints
2025-03-07 13:45:34,855 - INFO - validation batch 201, loss: 0.881, 6432/6976 datapoints
2025-03-07 13:45:34,889 - INFO - Epoch 770/800 done.
2025-03-07 13:45:34,890 - INFO - Final validation performance:
Loss: 1.583, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:45:34,890 - INFO - Beginning epoch 771/800
2025-03-07 13:45:34,900 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:45:35,394 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:45:35,846 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:45:36,260 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:45:36,699 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:45:37,126 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:45:37,590 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:45:38,014 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:45:38,403 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:45:38,798 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:45:39,211 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:45:39,638 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:45:40,037 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:45:40,451 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:45:40,855 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:45:41,378 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:45:41,815 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:45:42,198 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:45:42,411 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:45:42,488 - INFO - validation batch 51, loss: 5.044, 1632/6976 datapoints
2025-03-07 13:45:42,570 - INFO - validation batch 101, loss: 0.529, 3232/6976 datapoints
2025-03-07 13:45:42,645 - INFO - validation batch 151, loss: 1.431, 4832/6976 datapoints
2025-03-07 13:45:42,720 - INFO - validation batch 201, loss: 0.882, 6432/6976 datapoints
2025-03-07 13:45:42,746 - INFO - Epoch 771/800 done.
2025-03-07 13:45:42,747 - INFO - Final validation performance:
Loss: 1.577, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:45:42,747 - INFO - Beginning epoch 772/800
2025-03-07 13:45:42,755 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:45:43,214 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:45:43,671 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:45:44,093 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:45:44,514 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:45:44,950 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:45:45,409 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:45:45,831 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:45:46,222 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:45:46,639 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:45:47,054 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:45:47,472 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:45:47,886 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:45:48,295 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:45:48,696 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:45:49,107 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:45:49,513 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:45:49,900 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:45:50,090 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:45:50,162 - INFO - validation batch 51, loss: 5.024, 1632/6976 datapoints
2025-03-07 13:45:50,253 - INFO - validation batch 101, loss: 0.516, 3232/6976 datapoints
2025-03-07 13:45:50,336 - INFO - validation batch 151, loss: 1.438, 4832/6976 datapoints
2025-03-07 13:45:50,422 - INFO - validation batch 201, loss: 0.881, 6432/6976 datapoints
2025-03-07 13:45:50,453 - INFO - Epoch 772/800 done.
2025-03-07 13:45:50,453 - INFO - Final validation performance:
Loss: 1.572, top-1 acc: 0.898top-5 acc: 0.898
2025-03-07 13:45:50,454 - INFO - Beginning epoch 773/800
2025-03-07 13:45:50,463 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:45:50,979 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:45:51,481 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:45:51,905 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:45:52,353 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:45:52,801 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:45:53,256 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:45:53,669 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:45:54,057 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:45:54,448 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:45:54,868 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:45:55,280 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:45:55,685 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:45:56,141 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:45:56,573 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:45:57,012 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:45:57,423 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:45:57,814 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:45:58,005 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:45:58,126 - INFO - validation batch 51, loss: 5.005, 1632/6976 datapoints
2025-03-07 13:45:58,197 - INFO - validation batch 101, loss: 0.505, 3232/6976 datapoints
2025-03-07 13:45:58,270 - INFO - validation batch 151, loss: 1.444, 4832/6976 datapoints
2025-03-07 13:45:58,342 - INFO - validation batch 201, loss: 0.880, 6432/6976 datapoints
2025-03-07 13:45:58,366 - INFO - Epoch 773/800 done.
2025-03-07 13:45:58,366 - INFO - Final validation performance:
Loss: 1.567, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:45:58,367 - INFO - Beginning epoch 774/800
2025-03-07 13:45:58,376 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:45:58,805 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:45:59,241 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:45:59,658 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:46:00,073 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:46:00,520 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:46:00,993 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:46:01,406 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:46:01,803 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:46:02,263 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:46:02,755 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:46:03,185 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:46:03,610 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:46:04,026 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:46:04,432 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:46:04,863 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:46:05,274 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:46:05,674 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:46:05,868 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:46:05,939 - INFO - validation batch 51, loss: 4.988, 1632/6976 datapoints
2025-03-07 13:46:06,013 - INFO - validation batch 101, loss: 0.495, 3232/6976 datapoints
2025-03-07 13:46:06,091 - INFO - validation batch 151, loss: 1.450, 4832/6976 datapoints
2025-03-07 13:46:06,164 - INFO - validation batch 201, loss: 0.880, 6432/6976 datapoints
2025-03-07 13:46:06,190 - INFO - Epoch 774/800 done.
2025-03-07 13:46:06,191 - INFO - Final validation performance:
Loss: 1.563, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:46:06,192 - INFO - Beginning epoch 775/800
2025-03-07 13:46:06,200 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:46:06,640 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:46:07,130 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:46:07,534 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:46:07,950 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:46:08,375 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:46:08,824 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:46:09,228 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:46:09,613 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:46:09,995 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:46:10,410 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:46:10,856 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:46:11,274 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:46:11,690 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:46:12,098 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:46:12,517 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:46:12,932 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:46:13,315 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:46:13,511 - INFO - validation batch 1, loss: 0.002, 32/6976 datapoints
2025-03-07 13:46:13,588 - INFO - validation batch 51, loss: 4.975, 1632/6976 datapoints
2025-03-07 13:46:13,662 - INFO - validation batch 101, loss: 0.486, 3232/6976 datapoints
2025-03-07 13:46:13,737 - INFO - validation batch 151, loss: 1.457, 4832/6976 datapoints
2025-03-07 13:46:13,817 - INFO - validation batch 201, loss: 0.881, 6432/6976 datapoints
2025-03-07 13:46:13,844 - INFO - Epoch 775/800 done.
2025-03-07 13:46:13,845 - INFO - Final validation performance:
Loss: 1.560, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:46:13,845 - INFO - Beginning epoch 776/800
2025-03-07 13:46:13,853 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:46:14,280 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:46:14,723 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:46:15,124 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:46:15,535 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:46:15,987 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:46:16,449 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:46:16,884 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:46:17,273 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:46:17,664 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:46:18,077 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:46:18,496 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:46:18,903 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:46:19,310 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:46:19,721 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:46:20,137 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:46:20,554 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:46:20,938 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:46:21,132 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:46:21,202 - INFO - validation batch 51, loss: 4.965, 1632/6976 datapoints
2025-03-07 13:46:21,274 - INFO - validation batch 101, loss: 0.477, 3232/6976 datapoints
2025-03-07 13:46:21,353 - INFO - validation batch 151, loss: 1.465, 4832/6976 datapoints
2025-03-07 13:46:21,425 - INFO - validation batch 201, loss: 0.883, 6432/6976 datapoints
2025-03-07 13:46:21,450 - INFO - Epoch 776/800 done.
2025-03-07 13:46:21,450 - INFO - Final validation performance:
Loss: 1.558, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:46:21,451 - INFO - Beginning epoch 777/800
2025-03-07 13:46:21,460 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:46:21,916 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:46:22,352 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:46:22,771 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:46:23,178 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:46:23,611 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:46:24,054 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:46:24,459 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:46:24,898 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:46:25,280 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:46:25,700 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:46:26,116 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:46:26,528 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:46:26,963 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:46:27,373 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:46:27,800 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:46:28,212 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:46:28,601 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:46:28,815 - INFO - validation batch 1, loss: 0.003, 32/6976 datapoints
2025-03-07 13:46:28,899 - INFO - validation batch 51, loss: 4.957, 1632/6976 datapoints
2025-03-07 13:46:28,971 - INFO - validation batch 101, loss: 0.469, 3232/6976 datapoints
2025-03-07 13:46:29,044 - INFO - validation batch 151, loss: 1.472, 4832/6976 datapoints
2025-03-07 13:46:29,115 - INFO - validation batch 201, loss: 0.887, 6432/6976 datapoints
2025-03-07 13:46:29,142 - INFO - Epoch 777/800 done.
2025-03-07 13:46:29,142 - INFO - Final validation performance:
Loss: 1.558, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:46:29,143 - INFO - Beginning epoch 778/800
2025-03-07 13:46:29,151 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:46:29,570 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:46:30,015 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:46:30,439 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:46:30,982 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:46:31,458 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:46:31,946 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:46:32,367 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:46:32,775 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:46:33,164 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:46:33,578 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:46:33,998 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:46:34,403 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:46:34,818 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:46:35,219 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:46:35,632 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:46:36,041 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:46:36,417 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:46:36,613 - INFO - validation batch 1, loss: 0.004, 32/6976 datapoints
2025-03-07 13:46:36,691 - INFO - validation batch 51, loss: 4.952, 1632/6976 datapoints
2025-03-07 13:46:36,765 - INFO - validation batch 101, loss: 0.461, 3232/6976 datapoints
2025-03-07 13:46:36,842 - INFO - validation batch 151, loss: 1.479, 4832/6976 datapoints
2025-03-07 13:46:36,918 - INFO - validation batch 201, loss: 0.893, 6432/6976 datapoints
2025-03-07 13:46:36,953 - INFO - Epoch 778/800 done.
2025-03-07 13:46:36,954 - INFO - Final validation performance:
Loss: 1.558, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:46:36,955 - INFO - Beginning epoch 779/800
2025-03-07 13:46:36,965 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:46:37,443 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:46:37,907 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:46:38,325 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:46:38,743 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:46:39,188 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:46:39,647 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:46:40,055 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:46:40,443 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:46:40,834 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:46:41,480 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:46:41,950 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:46:42,408 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:46:42,839 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:46:43,245 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:46:43,663 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:46:44,082 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:46:44,564 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:46:44,807 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:46:44,904 - INFO - validation batch 51, loss: 4.948, 1632/6976 datapoints
2025-03-07 13:46:45,072 - INFO - validation batch 101, loss: 0.454, 3232/6976 datapoints
2025-03-07 13:46:45,228 - INFO - validation batch 151, loss: 1.485, 4832/6976 datapoints
2025-03-07 13:46:45,308 - INFO - validation batch 201, loss: 0.903, 6432/6976 datapoints
2025-03-07 13:46:45,339 - INFO - Epoch 779/800 done.
2025-03-07 13:46:45,339 - INFO - Final validation performance:
Loss: 1.559, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:46:45,340 - INFO - Beginning epoch 780/800
2025-03-07 13:46:45,352 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:46:45,916 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:46:46,387 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:46:46,817 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:46:47,261 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:46:47,697 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:46:48,160 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:46:48,571 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:46:48,955 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:46:49,345 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:46:49,763 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:46:50,171 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:46:50,574 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:46:50,983 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:46:51,384 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:46:51,805 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:46:52,213 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:46:52,604 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:46:52,795 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 13:46:52,868 - INFO - validation batch 51, loss: 4.944, 1632/6976 datapoints
2025-03-07 13:46:52,939 - INFO - validation batch 101, loss: 0.446, 3232/6976 datapoints
2025-03-07 13:46:53,013 - INFO - validation batch 151, loss: 1.491, 4832/6976 datapoints
2025-03-07 13:46:53,084 - INFO - validation batch 201, loss: 0.916, 6432/6976 datapoints
2025-03-07 13:46:53,107 - INFO - Epoch 780/800 done.
2025-03-07 13:46:53,108 - INFO - Final validation performance:
Loss: 1.560, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:46:53,108 - INFO - Beginning epoch 781/800
2025-03-07 13:46:53,117 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:46:53,548 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:46:53,988 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:46:54,398 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:46:54,816 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:46:55,255 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:46:55,714 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:46:56,122 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:46:56,560 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:46:56,975 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:46:57,429 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:46:57,860 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:46:58,280 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:46:58,700 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:46:59,110 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:46:59,533 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:46:59,955 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:47:00,351 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:47:00,539 - INFO - validation batch 1, loss: 0.007, 32/6976 datapoints
2025-03-07 13:47:00,617 - INFO - validation batch 51, loss: 4.940, 1632/6976 datapoints
2025-03-07 13:47:00,689 - INFO - validation batch 101, loss: 0.436, 3232/6976 datapoints
2025-03-07 13:47:00,763 - INFO - validation batch 151, loss: 1.498, 4832/6976 datapoints
2025-03-07 13:47:00,837 - INFO - validation batch 201, loss: 0.931, 6432/6976 datapoints
2025-03-07 13:47:00,860 - INFO - Epoch 781/800 done.
2025-03-07 13:47:00,861 - INFO - Final validation performance:
Loss: 1.562, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:47:00,861 - INFO - Beginning epoch 782/800
2025-03-07 13:47:00,871 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:47:01,292 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:47:01,801 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:47:02,225 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:47:02,638 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:47:03,069 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:47:03,520 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:47:03,932 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:47:04,315 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:47:04,702 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:47:05,109 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:47:05,541 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:47:06,054 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:47:06,588 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:47:07,123 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:47:07,670 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:47:08,114 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:47:08,515 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:47:08,717 - INFO - validation batch 1, loss: 0.009, 32/6976 datapoints
2025-03-07 13:47:08,791 - INFO - validation batch 51, loss: 4.937, 1632/6976 datapoints
2025-03-07 13:47:08,865 - INFO - validation batch 101, loss: 0.424, 3232/6976 datapoints
2025-03-07 13:47:08,940 - INFO - validation batch 151, loss: 1.507, 4832/6976 datapoints
2025-03-07 13:47:09,016 - INFO - validation batch 201, loss: 0.949, 6432/6976 datapoints
2025-03-07 13:47:09,044 - INFO - Epoch 782/800 done.
2025-03-07 13:47:09,044 - INFO - Final validation performance:
Loss: 1.565, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:47:09,045 - INFO - Beginning epoch 783/800
2025-03-07 13:47:09,055 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:47:09,474 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:47:09,928 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:47:10,343 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:47:10,759 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:47:11,192 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:47:11,656 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:47:12,124 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:47:12,595 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:47:12,988 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:47:13,403 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:47:13,817 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:47:14,227 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:47:14,649 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:47:15,052 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:47:15,463 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:47:15,876 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:47:16,253 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:47:16,438 - INFO - validation batch 1, loss: 0.011, 32/6976 datapoints
2025-03-07 13:47:16,511 - INFO - validation batch 51, loss: 4.936, 1632/6976 datapoints
2025-03-07 13:47:16,585 - INFO - validation batch 101, loss: 0.412, 3232/6976 datapoints
2025-03-07 13:47:16,658 - INFO - validation batch 151, loss: 1.515, 4832/6976 datapoints
2025-03-07 13:47:16,732 - INFO - validation batch 201, loss: 0.970, 6432/6976 datapoints
2025-03-07 13:47:16,755 - INFO - Epoch 783/800 done.
2025-03-07 13:47:16,755 - INFO - Final validation performance:
Loss: 1.569, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:47:16,756 - INFO - Beginning epoch 784/800
2025-03-07 13:47:16,767 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:47:17,241 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:47:17,708 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:47:18,110 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:47:18,519 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:47:18,955 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:47:19,404 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:47:19,811 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:47:20,202 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:47:20,592 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:47:21,003 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:47:21,408 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:47:21,822 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:47:22,233 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:47:22,644 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:47:23,061 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:47:23,479 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:47:23,869 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:47:24,060 - INFO - validation batch 1, loss: 0.014, 32/6976 datapoints
2025-03-07 13:47:24,143 - INFO - validation batch 51, loss: 4.938, 1632/6976 datapoints
2025-03-07 13:47:24,218 - INFO - validation batch 101, loss: 0.400, 3232/6976 datapoints
2025-03-07 13:47:24,289 - INFO - validation batch 151, loss: 1.521, 4832/6976 datapoints
2025-03-07 13:47:24,362 - INFO - validation batch 201, loss: 0.992, 6432/6976 datapoints
2025-03-07 13:47:24,390 - INFO - Epoch 784/800 done.
2025-03-07 13:47:24,390 - INFO - Final validation performance:
Loss: 1.573, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:47:24,391 - INFO - Beginning epoch 785/800
2025-03-07 13:47:24,400 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:47:24,816 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:47:25,267 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:47:25,684 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:47:26,098 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:47:26,530 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:47:26,981 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:47:27,387 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:47:27,797 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:47:28,185 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:47:28,597 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:47:29,005 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:47:29,416 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:47:29,838 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:47:30,244 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:47:30,709 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:47:31,130 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:47:31,557 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:47:31,751 - INFO - validation batch 1, loss: 0.017, 32/6976 datapoints
2025-03-07 13:47:31,839 - INFO - validation batch 51, loss: 4.941, 1632/6976 datapoints
2025-03-07 13:47:31,912 - INFO - validation batch 101, loss: 0.391, 3232/6976 datapoints
2025-03-07 13:47:31,985 - INFO - validation batch 151, loss: 1.528, 4832/6976 datapoints
2025-03-07 13:47:32,057 - INFO - validation batch 201, loss: 1.016, 6432/6976 datapoints
2025-03-07 13:47:32,084 - INFO - Epoch 785/800 done.
2025-03-07 13:47:32,084 - INFO - Final validation performance:
Loss: 1.579, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:47:32,085 - INFO - Beginning epoch 786/800
2025-03-07 13:47:32,094 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:47:32,504 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:47:32,955 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:47:33,366 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:47:33,783 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:47:34,216 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:47:34,664 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:47:35,068 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:47:35,449 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:47:35,830 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:47:36,234 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:47:36,636 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:47:37,041 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:47:37,450 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:47:37,885 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:47:38,292 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:47:38,717 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:47:39,103 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:47:39,295 - INFO - validation batch 1, loss: 0.019, 32/6976 datapoints
2025-03-07 13:47:39,367 - INFO - validation batch 51, loss: 4.946, 1632/6976 datapoints
2025-03-07 13:47:39,438 - INFO - validation batch 101, loss: 0.387, 3232/6976 datapoints
2025-03-07 13:47:39,511 - INFO - validation batch 151, loss: 1.531, 4832/6976 datapoints
2025-03-07 13:47:39,586 - INFO - validation batch 201, loss: 1.036, 6432/6976 datapoints
2025-03-07 13:47:39,610 - INFO - Epoch 786/800 done.
2025-03-07 13:47:39,610 - INFO - Final validation performance:
Loss: 1.584, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:47:39,610 - INFO - Beginning epoch 787/800
2025-03-07 13:47:39,621 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:47:40,033 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:47:40,479 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:47:40,890 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:47:41,302 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:47:41,737 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:47:42,183 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:47:42,594 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:47:42,978 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:47:43,382 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:47:43,797 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:47:44,198 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:47:44,609 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:47:45,048 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:47:45,455 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:47:45,865 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:47:46,283 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:47:46,674 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:47:46,866 - INFO - validation batch 1, loss: 0.023, 32/6976 datapoints
2025-03-07 13:47:46,938 - INFO - validation batch 51, loss: 4.956, 1632/6976 datapoints
2025-03-07 13:47:47,009 - INFO - validation batch 101, loss: 0.383, 3232/6976 datapoints
2025-03-07 13:47:47,081 - INFO - validation batch 151, loss: 1.535, 4832/6976 datapoints
2025-03-07 13:47:47,153 - INFO - validation batch 201, loss: 1.060, 6432/6976 datapoints
2025-03-07 13:47:47,179 - INFO - Epoch 787/800 done.
2025-03-07 13:47:47,179 - INFO - Final validation performance:
Loss: 1.591, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:47:47,179 - INFO - Beginning epoch 788/800
2025-03-07 13:47:47,190 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:47:47,617 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:47:48,083 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:47:48,491 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:47:48,898 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:47:49,359 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:47:49,808 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:47:50,214 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:47:50,601 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:47:50,988 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:47:51,392 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:47:51,793 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:47:52,197 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:47:52,596 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:47:52,990 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:47:53,384 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:47:53,800 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:47:54,185 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:47:54,375 - INFO - validation batch 1, loss: 0.028, 32/6976 datapoints
2025-03-07 13:47:54,448 - INFO - validation batch 51, loss: 4.963, 1632/6976 datapoints
2025-03-07 13:47:54,521 - INFO - validation batch 101, loss: 0.383, 3232/6976 datapoints
2025-03-07 13:47:54,597 - INFO - validation batch 151, loss: 1.543, 4832/6976 datapoints
2025-03-07 13:47:54,668 - INFO - validation batch 201, loss: 1.080, 6432/6976 datapoints
2025-03-07 13:47:54,694 - INFO - Epoch 788/800 done.
2025-03-07 13:47:54,694 - INFO - Final validation performance:
Loss: 1.599, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:47:54,695 - INFO - Beginning epoch 789/800
2025-03-07 13:47:54,705 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:47:55,133 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:47:55,580 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:47:55,985 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:47:56,393 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:47:56,836 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:47:57,286 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:47:57,691 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:47:58,134 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:47:58,525 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:47:58,947 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:47:59,350 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:47:59,761 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:48:00,170 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:48:00,584 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:48:01,000 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:48:01,432 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:48:01,853 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:48:02,050 - INFO - validation batch 1, loss: 0.032, 32/6976 datapoints
2025-03-07 13:48:02,121 - INFO - validation batch 51, loss: 4.963, 1632/6976 datapoints
2025-03-07 13:48:02,195 - INFO - validation batch 101, loss: 0.386, 3232/6976 datapoints
2025-03-07 13:48:02,265 - INFO - validation batch 151, loss: 1.559, 4832/6976 datapoints
2025-03-07 13:48:02,336 - INFO - validation batch 201, loss: 1.107, 6432/6976 datapoints
2025-03-07 13:48:02,359 - INFO - Epoch 789/800 done.
2025-03-07 13:48:02,359 - INFO - Final validation performance:
Loss: 1.609, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:48:02,360 - INFO - Beginning epoch 790/800
2025-03-07 13:48:02,370 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:48:02,799 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:48:03,234 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:48:03,647 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:48:04,063 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:48:04,500 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:48:04,950 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:48:05,359 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:48:05,742 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:48:06,170 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:48:06,609 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:48:07,014 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:48:07,459 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:48:07,889 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:48:08,302 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:48:08,707 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:48:09,129 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:48:09,514 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:48:09,710 - INFO - validation batch 1, loss: 0.038, 32/6976 datapoints
2025-03-07 13:48:09,782 - INFO - validation batch 51, loss: 4.968, 1632/6976 datapoints
2025-03-07 13:48:09,855 - INFO - validation batch 101, loss: 0.383, 3232/6976 datapoints
2025-03-07 13:48:09,926 - INFO - validation batch 151, loss: 1.563, 4832/6976 datapoints
2025-03-07 13:48:09,996 - INFO - validation batch 201, loss: 1.120, 6432/6976 datapoints
2025-03-07 13:48:10,020 - INFO - Epoch 790/800 done.
2025-03-07 13:48:10,020 - INFO - Final validation performance:
Loss: 1.615, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:48:10,021 - INFO - Beginning epoch 791/800
2025-03-07 13:48:10,037 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:48:10,486 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:48:10,981 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:48:11,382 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:48:11,794 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:48:12,230 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:48:12,709 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:48:13,166 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:48:13,570 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:48:14,010 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:48:14,420 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:48:14,821 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:48:15,238 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:48:15,644 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:48:16,055 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:48:16,460 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:48:16,884 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:48:17,267 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:48:17,459 - INFO - validation batch 1, loss: 0.036, 32/6976 datapoints
2025-03-07 13:48:17,529 - INFO - validation batch 51, loss: 4.952, 1632/6976 datapoints
2025-03-07 13:48:17,605 - INFO - validation batch 101, loss: 0.349, 3232/6976 datapoints
2025-03-07 13:48:17,679 - INFO - validation batch 151, loss: 1.542, 4832/6976 datapoints
2025-03-07 13:48:17,757 - INFO - validation batch 201, loss: 1.104, 6432/6976 datapoints
2025-03-07 13:48:17,785 - INFO - Epoch 791/800 done.
2025-03-07 13:48:17,785 - INFO - Final validation performance:
Loss: 1.597, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:48:17,786 - INFO - Beginning epoch 792/800
2025-03-07 13:48:17,796 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:48:18,242 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:48:18,673 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:48:19,118 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:48:19,530 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:48:19,968 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:48:20,438 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:48:20,850 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:48:21,227 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:48:21,618 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:48:22,204 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:48:22,629 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:48:23,035 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:48:23,437 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:48:23,850 - INFO - training batch 701, loss: -0.000, 22432/28000 datapoints
2025-03-07 13:48:24,257 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:48:24,681 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:48:25,067 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:48:25,269 - INFO - validation batch 1, loss: 0.044, 32/6976 datapoints
2025-03-07 13:48:25,341 - INFO - validation batch 51, loss: 4.950, 1632/6976 datapoints
2025-03-07 13:48:25,412 - INFO - validation batch 101, loss: 0.341, 3232/6976 datapoints
2025-03-07 13:48:25,484 - INFO - validation batch 151, loss: 1.529, 4832/6976 datapoints
2025-03-07 13:48:25,557 - INFO - validation batch 201, loss: 1.098, 6432/6976 datapoints
2025-03-07 13:48:25,583 - INFO - Epoch 792/800 done.
2025-03-07 13:48:25,583 - INFO - Final validation performance:
Loss: 1.592, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:48:25,584 - INFO - Beginning epoch 793/800
2025-03-07 13:48:25,594 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:48:26,029 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:48:26,463 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:48:26,880 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:48:27,288 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:48:27,733 - INFO - training batch 251, loss: -0.000, 8032/28000 datapoints
2025-03-07 13:48:28,209 - INFO - training batch 301, loss: -0.000, 9632/28000 datapoints
2025-03-07 13:48:28,611 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:48:28,984 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:48:29,375 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:48:29,777 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:48:30,172 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:48:30,621 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:48:31,137 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:48:31,608 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:48:32,024 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:48:32,443 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:48:32,825 - INFO - training batch 851, loss: -0.000, 27232/28000 datapoints
2025-03-07 13:48:33,019 - INFO - validation batch 1, loss: 0.070, 32/6976 datapoints
2025-03-07 13:48:33,090 - INFO - validation batch 51, loss: 4.941, 1632/6976 datapoints
2025-03-07 13:48:33,161 - INFO - validation batch 101, loss: 0.339, 3232/6976 datapoints
2025-03-07 13:48:33,233 - INFO - validation batch 151, loss: 1.514, 4832/6976 datapoints
2025-03-07 13:48:33,304 - INFO - validation batch 201, loss: 1.108, 6432/6976 datapoints
2025-03-07 13:48:33,331 - INFO - Epoch 793/800 done.
2025-03-07 13:48:33,331 - INFO - Final validation performance:
Loss: 1.594, top-1 acc: 0.899top-5 acc: 0.899
2025-03-07 13:48:33,332 - INFO - Beginning epoch 794/800
2025-03-07 13:48:33,342 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:48:33,769 - INFO - training batch 51, loss: -0.000, 1632/28000 datapoints
2025-03-07 13:48:34,201 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:48:34,608 - INFO - training batch 151, loss: -0.000, 4832/28000 datapoints
2025-03-07 13:48:35,011 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:48:35,452 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:48:35,907 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:48:36,311 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:48:36,696 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:48:37,095 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:48:37,485 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:48:37,886 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:48:38,321 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:48:38,731 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:48:39,139 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:48:39,547 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:48:39,967 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:48:40,356 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:48:40,546 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-07 13:48:40,624 - INFO - validation batch 51, loss: 4.986, 1632/6976 datapoints
2025-03-07 13:48:40,697 - INFO - validation batch 101, loss: 0.376, 3232/6976 datapoints
2025-03-07 13:48:40,769 - INFO - validation batch 151, loss: 1.471, 4832/6976 datapoints
2025-03-07 13:48:40,842 - INFO - validation batch 201, loss: 1.169, 6432/6976 datapoints
2025-03-07 13:48:40,865 - INFO - Epoch 794/800 done.
2025-03-07 13:48:40,865 - INFO - Final validation performance:
Loss: 1.620, top-1 acc: 0.897top-5 acc: 0.897
2025-03-07 13:48:40,866 - INFO - Beginning epoch 795/800
2025-03-07 13:48:40,877 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:48:41,312 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:48:41,768 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:48:42,200 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:48:42,618 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-07 13:48:43,058 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:48:43,499 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:48:43,885 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:48:44,264 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:48:44,644 - INFO - training batch 451, loss: -0.000, 14432/28000 datapoints
2025-03-07 13:48:45,059 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:48:45,463 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:48:45,888 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:48:46,308 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:48:46,708 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:48:47,109 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:48:47,518 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:48:47,908 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:48:48,097 - INFO - validation batch 1, loss: 0.030, 32/6976 datapoints
2025-03-07 13:48:48,168 - INFO - validation batch 51, loss: 4.968, 1632/6976 datapoints
2025-03-07 13:48:48,260 - INFO - validation batch 101, loss: 0.595, 3232/6976 datapoints
2025-03-07 13:48:48,347 - INFO - validation batch 151, loss: 1.186, 4832/6976 datapoints
2025-03-07 13:48:48,420 - INFO - validation batch 201, loss: 1.233, 6432/6976 datapoints
2025-03-07 13:48:48,446 - INFO - Epoch 795/800 done.
2025-03-07 13:48:48,446 - INFO - Final validation performance:
Loss: 1.602, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:48:48,447 - INFO - Beginning epoch 796/800
2025-03-07 13:48:48,457 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:48:48,880 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:48:49,297 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:48:49,726 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:48:50,134 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:48:50,580 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:48:51,051 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:48:51,489 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:48:51,886 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:48:52,281 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:48:52,703 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:48:53,092 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:48:53,510 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:48:53,915 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:48:54,315 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:48:54,746 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:48:55,181 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:48:55,627 - INFO - training batch 851, loss: 0.003, 27232/28000 datapoints
2025-03-07 13:48:55,830 - INFO - validation batch 1, loss: 0.162, 32/6976 datapoints
2025-03-07 13:48:55,904 - INFO - validation batch 51, loss: 5.911, 1632/6976 datapoints
2025-03-07 13:48:55,977 - INFO - validation batch 101, loss: 0.434, 3232/6976 datapoints
2025-03-07 13:48:56,085 - INFO - validation batch 151, loss: 1.528, 4832/6976 datapoints
2025-03-07 13:48:56,159 - INFO - validation batch 201, loss: 1.401, 6432/6976 datapoints
2025-03-07 13:48:56,187 - INFO - Epoch 796/800 done.
2025-03-07 13:48:56,187 - INFO - Final validation performance:
Loss: 1.887, top-1 acc: 0.896top-5 acc: 0.896
2025-03-07 13:48:56,188 - INFO - Beginning epoch 797/800
2025-03-07 13:48:56,200 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:48:56,638 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:48:57,084 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:48:57,507 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:48:57,946 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:48:58,390 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:48:58,832 - INFO - training batch 301, loss: 0.001, 9632/28000 datapoints
2025-03-07 13:48:59,246 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:48:59,631 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:49:00,046 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:49:00,574 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:49:01,129 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:49:01,673 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:49:02,187 - INFO - training batch 651, loss: 0.000, 20832/28000 datapoints
2025-03-07 13:49:02,603 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:49:03,041 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:49:03,450 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:49:03,841 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:49:04,035 - INFO - validation batch 1, loss: 0.009, 32/6976 datapoints
2025-03-07 13:49:04,108 - INFO - validation batch 51, loss: 5.141, 1632/6976 datapoints
2025-03-07 13:49:04,188 - INFO - validation batch 101, loss: 0.368, 3232/6976 datapoints
2025-03-07 13:49:04,265 - INFO - validation batch 151, loss: 1.364, 4832/6976 datapoints
2025-03-07 13:49:04,339 - INFO - validation batch 201, loss: 0.924, 6432/6976 datapoints
2025-03-07 13:49:04,362 - INFO - Epoch 797/800 done.
2025-03-07 13:49:04,362 - INFO - Final validation performance:
Loss: 1.561, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:49:04,363 - INFO - Beginning epoch 798/800
2025-03-07 13:49:04,372 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:49:04,796 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:49:05,231 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:49:05,631 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:49:06,043 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:49:06,471 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:49:06,932 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:49:07,329 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:49:07,692 - INFO - training batch 401, loss: 0.001, 12832/28000 datapoints
2025-03-07 13:49:08,099 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:49:08,502 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:49:08,896 - INFO - training batch 551, loss: 0.000, 17632/28000 datapoints
2025-03-07 13:49:09,315 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:49:09,724 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:49:10,138 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:49:10,553 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:49:10,962 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:49:11,373 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:49:11,585 - INFO - validation batch 1, loss: 0.006, 32/6976 datapoints
2025-03-07 13:49:11,673 - INFO - validation batch 51, loss: 5.198, 1632/6976 datapoints
2025-03-07 13:49:11,758 - INFO - validation batch 101, loss: 0.283, 3232/6976 datapoints
2025-03-07 13:49:11,849 - INFO - validation batch 151, loss: 1.261, 4832/6976 datapoints
2025-03-07 13:49:11,933 - INFO - validation batch 201, loss: 0.829, 6432/6976 datapoints
2025-03-07 13:49:11,958 - INFO - Epoch 798/800 done.
2025-03-07 13:49:11,958 - INFO - Final validation performance:
Loss: 1.516, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:49:11,959 - INFO - Beginning epoch 799/800
2025-03-07 13:49:11,970 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:49:12,400 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:49:12,810 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:49:13,200 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:49:13,612 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:49:14,041 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:49:14,484 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:49:14,891 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:49:15,257 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:49:15,656 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:49:16,058 - INFO - training batch 501, loss: 0.000, 16032/28000 datapoints
2025-03-07 13:49:16,502 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:49:16,959 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:49:17,376 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:49:17,802 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:49:18,223 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:49:18,647 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:49:19,043 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:49:19,230 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:49:19,305 - INFO - validation batch 51, loss: 5.193, 1632/6976 datapoints
2025-03-07 13:49:19,376 - INFO - validation batch 101, loss: 0.271, 3232/6976 datapoints
2025-03-07 13:49:19,447 - INFO - validation batch 151, loss: 1.259, 4832/6976 datapoints
2025-03-07 13:49:19,518 - INFO - validation batch 201, loss: 0.822, 6432/6976 datapoints
2025-03-07 13:49:19,547 - INFO - Epoch 799/800 done.
2025-03-07 13:49:19,547 - INFO - Final validation performance:
Loss: 1.510, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:49:19,548 - INFO - Beginning epoch 800/800
2025-03-07 13:49:19,558 - INFO - training batch 1, loss: 0.000, 32/28000 datapoints
2025-03-07 13:49:19,982 - INFO - training batch 51, loss: 0.000, 1632/28000 datapoints
2025-03-07 13:49:20,401 - INFO - training batch 101, loss: 0.000, 3232/28000 datapoints
2025-03-07 13:49:20,795 - INFO - training batch 151, loss: 0.000, 4832/28000 datapoints
2025-03-07 13:49:21,211 - INFO - training batch 201, loss: 0.000, 6432/28000 datapoints
2025-03-07 13:49:21,638 - INFO - training batch 251, loss: 0.000, 8032/28000 datapoints
2025-03-07 13:49:22,086 - INFO - training batch 301, loss: 0.000, 9632/28000 datapoints
2025-03-07 13:49:22,491 - INFO - training batch 351, loss: 0.000, 11232/28000 datapoints
2025-03-07 13:49:22,858 - INFO - training batch 401, loss: 0.000, 12832/28000 datapoints
2025-03-07 13:49:23,255 - INFO - training batch 451, loss: 0.000, 14432/28000 datapoints
2025-03-07 13:49:23,652 - INFO - training batch 501, loss: -0.000, 16032/28000 datapoints
2025-03-07 13:49:24,047 - INFO - training batch 551, loss: -0.000, 17632/28000 datapoints
2025-03-07 13:49:24,474 - INFO - training batch 601, loss: 0.000, 19232/28000 datapoints
2025-03-07 13:49:24,878 - INFO - training batch 651, loss: -0.000, 20832/28000 datapoints
2025-03-07 13:49:25,279 - INFO - training batch 701, loss: 0.000, 22432/28000 datapoints
2025-03-07 13:49:25,706 - INFO - training batch 751, loss: 0.000, 24032/28000 datapoints
2025-03-07 13:49:26,105 - INFO - training batch 801, loss: 0.000, 25632/28000 datapoints
2025-03-07 13:49:26,486 - INFO - training batch 851, loss: 0.000, 27232/28000 datapoints
2025-03-07 13:49:26,670 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:49:26,741 - INFO - validation batch 51, loss: 5.184, 1632/6976 datapoints
2025-03-07 13:49:26,813 - INFO - validation batch 101, loss: 0.261, 3232/6976 datapoints
2025-03-07 13:49:26,884 - INFO - validation batch 151, loss: 1.257, 4832/6976 datapoints
2025-03-07 13:49:26,958 - INFO - validation batch 201, loss: 0.814, 6432/6976 datapoints
2025-03-07 13:49:26,985 - INFO - Epoch 800/800 done.
2025-03-07 13:49:26,985 - INFO - Final validation performance:
Loss: 1.504, top-1 acc: 0.900top-5 acc: 0.900
2025-03-07 13:49:26,985 - INFO - Finished training in 5854.43 seconds.
2025-03-07 13:49:26,988 - INFO - Model trained in {train_time:.2f} s
2025-03-07 13:49:26,988 - INFO - Evaluating model...
2025-03-07 13:49:26,993 - INFO - validation batch 1, loss: 0.005, 32/6976 datapoints
2025-03-07 13:49:27,083 - INFO - validation batch 51, loss: 5.184, 1632/6976 datapoints
2025-03-07 13:49:27,167 - INFO - validation batch 101, loss: 0.261, 3232/6976 datapoints
2025-03-07 13:49:27,240 - INFO - validation batch 151, loss: 1.257, 4832/6976 datapoints
2025-03-07 13:49:27,311 - INFO - validation batch 201, loss: 0.814, 6432/6976 datapoints
2025-03-07 13:49:27,339 - INFO - Done evaluating.
2025-03-07 13:49:27,339 - INFO - Average final validation loss: 1.504
2025-03-07 13:49:27,340 - INFO - Saving...
2025-03-07 13:50:15,244 - INFO - Done saving.
2025-03-07 13:50:15,245 - INFO - Successfully completed hyperparameter combination 1 of 1